{
    "BaimosTechnologies": "Yes! been awake all night at this one, you can't imagine how much I thank you.\nFor others that might encounter this, here are the error logs:\n07-05 05:58:28.451: W/asset(28655): Copying FileAsset 0x773781c8 (zip:/data/app/com.google.vrtoolkit.cardboard.samples.treasurehunt-1.apk:/resources.arsc) to buffer size 2776 to make it aligned.\n07-05 05:58:28.461: W/dalvikvm(28655): threadid=1: thread exiting with uncaught exception (group=0x41686e18)\n07-05 05:58:28.471: E/AndroidRuntime(28655): FATAL EXCEPTION: main\n07-05 05:58:28.471: E/AndroidRuntime(28655): Process: com.google.vrtoolkit.cardboard.samples.treasurehunt, PID: 28655\n07-05 05:58:28.471: E/AndroidRuntime(28655): java.lang.RuntimeException: Unable to instantiate activity ComponentInfo{com.google.vrtoolkit.cardboard.samples.treasurehunt/com.google.vrtoolkit.cardboard.samples.treasurehunt.MainActivity}: java.lang.ClassNotFoundException: Didn't find class \"com.google.vrtoolkit.cardboard.samples.treasurehunt.MainActivity\" on path: DexPathList[[zip file \"/data/app/com.google.vrtoolkit.cardboard.samples.treasurehunt-1.apk\"],nativeLibraryDirectories=[/data/app-lib/com.google.vrtoolkit.cardboard.samples.treasurehunt-1, /vendor/lib, /system/lib]]\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2514)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2653)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.ActivityThread.access$800(ActivityThread.java:156)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1355)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.os.Handler.dispatchMessage(Handler.java:102)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.os.Looper.loop(Looper.java:157)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.ActivityThread.main(ActivityThread.java:5872)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at java.lang.reflect.Method.invokeNative(Native Method)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at java.lang.reflect.Method.invoke(Method.java:515)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:858)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:674)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at dalvik.system.NativeStart.main(Native Method)\n07-05 05:58:28.471: E/AndroidRuntime(28655): Caused by: java.lang.ClassNotFoundException: Didn't find class \"com.google.vrtoolkit.cardboard.samples.treasurehunt.MainActivity\" on path: DexPathList[[zip file \"/data/app/com.google.vrtoolkit.cardboard.samples.treasurehunt-1.apk\"],nativeLibraryDirectories=[/data/app-lib/com.google.vrtoolkit.cardboard.samples.treasurehunt-1, /vendor/lib, /system/lib]]\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at dalvik.system.BaseDexClassLoader.findClass(BaseDexClassLoader.java:56)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at java.lang.ClassLoader.loadClass(ClassLoader.java:497)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at java.lang.ClassLoader.loadClass(ClassLoader.java:457)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.Instrumentation.newActivity(Instrumentation.java:1079)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2505)\n07-05 05:58:28.471: E/AndroidRuntime(28655):    ... 11 more\n. ",
    "keyboardsurfer": "L developer preview has been some time ago.\nThere were no more people adding to this issue.\nFeel free to re-open if the issue still occurs.\n. If this is a potential fix to this sample please prepare a pull request.\n. ",
    "borismus": "Why closed? No longer an issue?\n. Should be fixed, thanks for reporting.\n. Try reloading the page with a clean cache.\nOn Fri, Oct 17, 2014 at 3:25 PM Braden Anderson notifications@github.com\nwrote:\n\nStill seems to be broken for me.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard/issues/13#issuecomment-59584392\n.\n. \n",
    "edwardthefma": "i was going to dubble check my code and make shure its correct but its still crashing  i think i might have loaded it incorrectly in intellaj so i want to be shure dont want to rase a false flag due to my programming knowledge which is still basic \n. Hopefully this will get fixed soon\n. ",
    "n1cholson": "Time to reopen this bug.  I'm getting the same error!  It appears to be a problem in the cardboard library.  \"Surface size 1280x670 does not match the expected screen size 1280x720. Rendering is disabled\"  I'm guessing there's an error in the math for handling certain screen sizes.  No source to the cardboard library?  What gives?\n. The crash is being experienced by others.  It appears that the cardboard library is failing to correctly calculate the screen size, causing rendering to be disabled.\n. The sample treasurehunt app is exiting for me, too.  The error I see in the debugger is: \"Surface size 1280x670 does not match the expected screen size of 1280x720.  Rendering is disabled.  The tag for this message is \"CardboardView\".  The device is a Note II and it has a 1280x720 screen.  \nI don't see that error message in the treasurehunt source so I expect it's being generated by the cardboard library. \nBy the way, most of the demo apps (tour guide, youtube) in the Cardboard App work fine but the Windy Day demo doesn't crashes.\nAnyone know what's going wrong?\n. I've traced the problem to a function in cardboard.jar's CardboardView.java file.\nIt appears that there are some inconsistencies when checking screen width and height as discussed here: http://stackoverflow.com/questions/10991194/android-displaymetrics-returns-incorrect-screen-size-in-pixels-on-ics\nI'm considering some workarounds.  One possible approach is to override the .jar file's function.  Not certain how to do that in java but I gather that it's possible.  Another approach would be to rebuild the .jar with a fix that gets around the screen height bug.  Another work around would be to just move all the cardboard .jar code into the app, but this requires a fair amount of editing.\nHere's the source.  Line 586.1021 is where the problem occurs.\n/*  580:     /     public void onSurfaceChanged(GL10 gl, int width, int height)\n/  581:     /     {\n/  582:1015 /       if (this.mShuttingDown) {\n/  583:1016 /         return;\n/  584:     /       }\n/  585:1020 /       ScreenParams screen = this.mHmd.getScreen();\n/  586:1021 /       if ((width != screen.getWidth()) || (height != screen.getHeight()))\n/  587:     /       {\n/  588:1022 /         if (!this.mInvalidSurfaceSize)\n/  589:     /         {\n/  590:1023 /           GLES20.glClear(16384);\n/  591:1024 /           Log.w(\"CardboardView\", \"Surface size \" + width + \"x\" + height + \" does not match the expected screen size \" + screen.getWidth() + \"x\" + screen.getHeight() + \". Rendering is disabled.\");\n/  592:     /         }\n/  593:1030 /         this.mInvalidSurfaceSize = true;\n/  594:     /       }\n/  595:     /       else\n/  596:     /       {\n/  597:1032 /         this.mInvalidSurfaceSize = false;\n/  598:     /       }\n/  599:1037 /       this.mRenderer.onSurfaceChanged(width, height);\n/  600:     /     }\n/  601:     */   \n. I've managed to build my own version of cardboard.jar and patched it to ignore the error.  Still having other OpenGL draw problems but now will be able to debug. I'll share the fix when it's working. \n. The fix for the first error is described here:\nhttps://developer.android.com/training/system-ui/status.html\nand requires a simple change to the manifest. It disables the status bar when in full screen mode.  \nThere is still another part of the sample app that is causing a GL error of 1280 which translates to a bad enum value. This occurs between the first and second draw frames.\n. @kofiav\nI've stopped working on it for now due to other priorities.  It appears that there are only a couple of errors in cardboard which I managed to fix but I was having some difficulty reassembling cardboard.jar such that it would properly expose the sensor components.\nI'm more than a little concerned that the authors are noticeably absent from the forum and don't seem to be interested in providing any support.  Perhaps this was just a demo for Google I/O and that they've no intention of supporting it further. If so, they should really let everyone know.\nLooking at what's going on in this emerging market, it looks like the library that developers will settle on will be produced by Samsung or Oculus Rift.  I'm particularly interested in the possibilities of the Samsung Note 4 and the Gear VR headset.  \nIt's clear from working with cardboard that a 1-bit button as an input device is woefully inadequate for navigating 3D spaces.  Schemes that involve looking at your feet to move forward aren't the answer. I experimented with hooking up a bluetooth game controller, and that feels like a good solution.  \nIf I get time I make work on the cardboard.jar a little bit more but it may be wasted effort if the authors have abandoned it.\n. There appears to be an error in the library.  Look through the logs to see if there's an error that indicates the screen size does not match expected screen size, and that rendering is disabled.\n. ",
    "googlebot": "Thanks for the pull request.\nIt looks like this is your first contribution to a Google open source project, or you're using an email address we haven't seen before. Before proceeding, you'll need to sign the Contributor License Agreement (CLA) below:\nhttps://developers.google.com/open-source/cla/individual\nOnce you've done that, please reply here to let us know.\nNote: Please be sure the email address you use when signing the CLA matches the email address used in your commit message.\n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project, in which case you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. CLAs look good, thanks!\n ok \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. CLAs look good, thanks!\n ok \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. CLAs look good, thanks!\n ok \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. CLAs look good, thanks!\n ok \n. We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA (login here to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n need_author_cla \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf you signed the CLA as a corporation, please let us know the company's name.\n\n need_sender_cla \n. CLAs look good, thanks!\n ok \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check your existing CLA data and verify that your email is set on your git commits.\nIf your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n need_sender_cla \n. Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n:memo: Please visit https://cla.developers.google.com/ to sign.\nOnce you've signed, please reply here (e.g. I signed it!) and we'll verify.  Thanks.\n\n\nIf you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check your existing CLA data and verify that your email is set on your git commits.\nIf your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n need_sender_cla \n. CLAs look good, thanks!\n ok \n. ",
    "ghchinoy": "This was helpful for me. Also, used the \"Sync Project with Gradle Files\" (Tools > Android) which made Build > Make work. Thanks!\nAlso, fwiw, I have a signed CLA (from other projects, Glass) and can repost the pull if necessary (though I think @yangcheng 's is more than adequate).\n. ",
    "gleitz": "This helped me successfully build the project. Thanks!\n. ",
    "scenek": "Seems that this is no longer valid.\n. ",
    "sigmaxipi": "Closing this old request. There shouldn't be any issues building with Android Studio now.\n. Closing this since the files have drastically changed. But thanks for pointing out the issue. I've updated all the samples to use match_parent. Alternative architectures are now available. Instructions are at /libraries/native/README.md\n. @ph0b : including the other architectures by default means people might accidentally include other architectures if their build process isn't configured correctly. This would bloat their app and they might not notice. Requiring the extra step of explicitly including alternative architectures avoids this problem. \nThere is no perfect solution that supports all the use cases with zero extra configuration.\n. We've switched to using multiple architectures in the .aars\n. An AAR is a zip file with a well defined structure. You could unzip it and repack it if required but this is prone to break in the future.\n. The complexity of managing resources is why we ship .aar files. Otherwise, it becomes tricky to have multiple components with their own set of resources and native files. That was why we switched to .aar files. This is the standard way for all Android projects. Eclipse is no longer supported so you will need a custom workflow to develop in it.\n. Call VrVideoView.loadVideo when you want to change videos. You can test this with the simplevideowidget sample by launching and running adb shell am start -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -a android.intent.action.VIEW -d file:///sdcard/FILENAME.mp4. Then use .seekTo(0) to reset the position.\n. The protobuf libraries have now been extracted.\n. If you want more complex touch & gyro controls, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Eclipse isn't supported in our SDK because it can't handle complex libraries which include resources and native code. You should transition to Android Studio as soon as possible.\nThe issue you're seeing is a missing native lib. Run unzip APP.apk on your Eclipse apk and note all the .so files in it. Compare this with a sample built with Gradle. You will need to get libpano_video_renderer.so into your APK. The .so is in libraries/videowidget/videowidget.aar. You can unzip it and then edit your build process to include it in your APK.\nBut the specific library and filenames may change in future releases so you may have issues in the future.\n. Use file:///sdcard/congo.mp4 as a workaround\n. The Droid X doesn't have a gyroscope so it can't be used as a controller.\n. Docs have been updated.\n. What happens when you run gradlew build on the command line in a fresh clone without using Android Studio? Also, the current treasurehunt/build.gradle file is configured to use **gradle-experimental:0.4.0\" for now.\nThe relevant error in your log is error: 'thread' in namespace 'std' does not name a type\n   std::thread audio_initialization_thread_;. In your previous NDK projects, were you able to reference std::thread? If no, there might be something wrong with your C++11 configuration.\n. What are you trying to do? Are you referring to GvrActivity.onCardboardTrigger()? VrPanoramaView doesn't extend GvrActivity so this functionality isn't available. Instead use VrEventListener.onClick() via VrPanoramaView.setEventListener()\n. What is the full stacktrace? Is it failing to load an .so file? If so, the error might be due to using a mix of 64-bit and 32-bit native libraries. You should build a 32-bit version of your native code or see libraries/native/README.md for details on how to use 64-bit versions of GVR.\n. This is fixed now that the .aars include multiple architectures.\n. Yes. We're working on distributing via a standard repository instead of just shipping .aar files. Stay tuned.\n. Is android:largeHeap=\"true\" set in your AndroidManifest.xml's <application> tag?\n. The SDK only ships 32-bit ARM libraries in the .aars. If you want to run on x86 emulators, you need to follow the directions at https://github.com/googlevr/gvr-android-sdk/tree/master/libraries/native\n. We're planning on reworking the .aar distribution system as part of https://github.com/googlevr/gvr-android-sdk/issues/114 and this will streamline alternative architectures of the GVR SDK. But until that is ready, you will need to configure custom build steps for your app.\n. Do you want rotation or direction? For rotation, use HeadTransform.getEulerAngles to get pitch, yaw, and roll. For direction, use .getForwardVector to get an x,y,z vector.\n. You don't need to add these files to the .aar. See the instructions at samples/sdk-simplepanowidget/build.gradle for info on how to properly configure your build system.\n. Does the video play properly with another video player on Glass? That would isolate an issue with the decoder. Also, does this happen with videos of other sizes? Some decoders assume the video is a multiple of 32 (or another number) and cause a mismatch between the video decoding and GL rendering. Try videos that are 1920x1080 and also 1024x1024.\n. This is due to duplicate protobuf libraries in GVR and other apps. If you're manually the protobuf library, you can remove it from your build file. If another .aar is including it, then you will need to edit the classes.jar inside the .aar and delete the duplicate classes in one of the .aars\n. An .aar file is just a standard .zip file so you can use normal zip programs to extract files from it and add new files back in. The classes.jar file in it is also a standard .jar file which contains many .class files. You will need to extract the classes.jar from common.aar. Then delete all the .class files in that .jar that cause errors (note the class name in the error message) which should be everything under com/google/protobuf. Then put the modified classes.jar back into the common.aar\n. If you want a custom videoplayer without distortion, consider using the Video360 sample as a starting point. You can use standard OpenGL to render without distortion. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. There are no plans to add this functionality since it would be difficult to add in a cross-platform manner and the VrView codebase is meant to be cross platform. If you want to create a custom 360 media player with this functionality, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. We don't plan on adding this functionality. If you need it, consider using the Video360 sample as a starting point for a custom widget. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. I think this specific issue has been fixed. We improved rotation handling for VrView, but there are still some bugs because rotation is tricky on Android. If your specific issue isn't fixed, consider using the Video360 sample as a starting point to create a custom widget. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. If you want more complex touch & gyro controls, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. If you want a more complex touch & gyro controls for a 360 media player, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. The UI inside the VR View widgets is designed to be consistent across apps. Your best option is to have a link outside the VR View that is appropriately labeled and goes to your desired destination.\n. Try this config:\n```\n-keep class com.google.vr.** { native ; }\n-keep class com.google.vr.cardboard.annotations.UsedByNative\n-keep @com.google.vr.cardboard.annotations.UsedByNative class \n-keepclassmembers class * {\n    @com.google.vr.cardboard.annotations.UsedByNative ;\n}\n-keep class com.google.vr.cardboard.UsedByNative\n-keep @com.google.vr.cardboard.UsedByNative class \n-keepclassmembers class * {\n    @com.google.vr.cardboard.UsedByNative ;\n}\n-keep public class com.google.vr.sdk.widgets.pano.VrPanoramaEventListener { ; }\n-keep public class com.google.vr.sdk.widgets.pano.VrPanoramaView$Options { ; }\n```\n. Thanks for the info. I've updated my comment with better formatting. The next SDK version will have ship with a proguard config so you will be able to directly use that.\n. DASH support has been added to the VrView sample. See https://github.com/googlevr/gvr-android-sdk/tree/master/samples/sdk-simplevideowidget/src/main/assets for sample videos.\nIf you want support for other video formats, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. The new SDK has exoplayer as an external dependency.\n. This feature in GVR is called Async Reprojection.\n. This is the expected behavior. The Treasure Hunt samples are meant to be pure Cardboard apps so they don't have Daydream Controller support. Controller Paint was meant to show off the Daydream Controller API so it uses that API.\n. We won't support non-gradle builds because it becomes extremely complicated to maintain multiple parallel build systems. Your best option would be to write a preprocessing step that unzips the .aar and reconfigures it to match what your build system expects. ADT is deprecated so your best option is to migrate your project to gradle.\nThe general Android NDK build system is still in flux, so you'll need to look at that project to determine when it will be compatible with your build requirements. The current plan for the GVR NDK is to ship our library code as .so files rather than static libs.\n. GVR uses the standard OpenGL APIs for the actual rendering. See https://developer.android.com/training/graphics/opengl/environment.html and https://developer.android.com/guide/topics/graphics/opengl.html for more info on how to get started with OpenGL on Android. Or you could look at something like https://github.com/Rajawali/Rajawali for a more high-level approach.\n. If you need a custom touch listener, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Thank you for the info. We've fixed the typo.\n. Thank you for the info. We've fixed the typo.\n. The Realm.io library has native code for multiple architectures. If you unzip the apk that is crashing, you'll probably see a arm+arm64 libraries from Realm and only arm libraries from GVR. If so, you're running into a variation of https://github.com/googlevr/gvr-android-sdk/issues/38 and will need to follow the directions at https://github.com/googlevr/gvr-android-sdk/tree/master/libraries/native to resolve it.\n. What is the exact error message? Can you run adb logcat -c, run the app, and then run adb logcat to get the full crash logs?\n. With the latest SDK, the .aars have arm, arm64, and x86 binaries built in. This might prevent this class of issues caused by using the GVR SDK with other native libraries.\n. VrWidgetView.getHeadRotation returns the current rotation of the user's head. It will set the yawAndPitch variable that you pass into it. If you Log that variable, do you see it changing?\n. If you want more complex touch & gyro controls, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Fixed. Thanks for the note.\n. You need to compile with SDK 24. The android:enableVrMode=\"@string/gvr_vr_mode_component\" referred to in sdk-treasurehunt/src/main/AndroidManifest.xml refers to R.attr.enableVrMode which was added in N.\nMake sure to update your SDK in Android Studio so that you have API 24.\n. You were trying to install an arm build on an x86 emulator. SDK released this week should work without issues.\n. As noted on the exoplayer thread, this is an issue with how strict exoplayer when dealing with malformed videos. You can either wait for the updated exoplayer and update to that or reencode the video.  avconv -i stitch.mp4 -strict experimental stitch2.mp4 generated a playable video for me. You can also use Handbrake or any other encoder to reencode the video.\n. Thanks for the heads up. We'll update the release notes.\n. com.google.protobuf.nano:protobuf-javanano:3.1.0 is out now so you can update to that. But it's the same code in both of the jars so you can stick with alpha-7 if you want.\n. What are you using the SurfaceView for? Changing the compositing behavior of the VrWidgetView can cause some issues when due to the lifecycle of VrWidgetView on rotations and other layout changes.\n. We ran into many issues related to Surface compositing in the past so this will require some more testing on multiple devices before we can determine if the proposed API works as expected. As an unsupported work around, you could directly access the underlying GLSurfaceView (via a series of getChildAt(0) calls) and try setting its Z Order directly. This hack may break if we change the layout, but it should work for you until we can determine that the Z order works as expected for all our supported devices.\n. Did you update your gradle files to pull in external dependencies? We unbundled our protobuf and exoplayer dependencies: https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-treasurehunt/build.gradle\n. We've changed the Overlay to automatically fade to dark grey after a while.. Can you play the video with other video players on the device? Also, you could try reencoding the video using Handbrake or some other tool in case it's a format issue.\n. Exoplayer changed their APIs quite a bit in their 2.0 release: https://github.com/google/ExoPlayer/blob/dev-v2/RELEASENOTES.md.\nThanks for the note. We'll look at upgrading the widget to use 2.0 APIs\n. @SrujithPoondla the Exoplayer upgrade isn't a straightforward refactor since there were functional changes in Exoplayer. There is no timeline on the upgrade in GVR, but Exoplayer allows you to use 1.x and 2.x packages together. Are there Exoplayer 2.0 specific features you need in the GVR SDK?\n. We'll need the full stack trace & logs to debug this. Also, the output of unzip YOURAPK.apk would be helpful if this is due to JNI code.\n. What is the list of files inside your apk? This error normally happens if you're missing a file so to debug it, we'll need a list of all the files in your apk.\n. This is fixed now. Thanks for the note.. We are working on fixing this so the NDK samples use the same build system as the SDK Java samples. This will allow them to use a standard dependency statement to pack the .so into the apk by depending on the .aar the way the SDK Java samples do.\n. Migrating to a repo rather than local .aars is also being worked on. But it's stuck on the issue you mentioned. I don't think there is a good solution to get NDK builds to depend on pure jcenter based aars. I've found various hacks related to depending on exploded jars, but the best option so far is to still ship the .aars in the git repo in addition to jcenter, add an extraction task (shown below) and have the NDK samples depend on the extraction task for the JNI builds while SDK samples can use either local .aars or jcenter libraries.\nIt should suffice until the gradle system for the NDK gets full aar support.\nIn root/build.gradle\n```\ntask extractAudioSo(type: Copy) {\n    from zipTree(\"${project.rootDir}/libraries/audio.aar\")\n    into \"${project.rootDir}/libraries/\"\n    include \"jni/**/libgvr_audio.so\"\n}\ntask extractGvrSo(type: Copy) {\n    from zipTree(\"${project.rootDir}/libraries/base.aar\")\n    into \"${project.rootDir}/libraries/\"\n    include \"jni/**/libgvr.so\"\n}\ntask extractNdk { }\nextractNdk.dependsOn extractAudioSo\nextractNdk.dependsOn extractGvrSo\n```\n. The .SOs are now supplied via aars and use a more standard build system. It's still not perfect because automatic extraction of an .so from and .aar requires a command line operation.. The sdk-treasurehunt sample has been updated to run on Daydream via the Cardboard emulation mode. See the recent changes for TreasureHunt.java and its AndroidManifest.xml for more info.. Also consider the new Video360 sample if you want to create a panorama viewer with more functionality. See https://developers.google.com/vr/android/samples/video360 for more details.. We haven't released the new APIs to enable Cardboard apps to run on Daydream View. This will be part of the next SDK release. For now, you'll need to only use your Cardboard app on a Cardboard headset.\nhttps://github.com/googlevr/gvr-android-sdk/issues/286 tracks this issue.\n. The common.aar contains Java code and resources used by the NDK so it will need to be linked into your project. Your suggested build.gradle changes to include common.aar should work. However, I think your syntax is slightly off. I was using\n```\ndependencies {\n    compile (name: \"audio\", ext: \"aar\")\n    compile (name: \"base\", ext: \"aar\")\n    compile (name: \"common\", ext: \"aar\")\ncompile 'com.google.protobuf.nano:protobuf-javanano:3.1.0'\n\n}\n``\nin the module'sbuild.gradle` and\n```\nallprojects {\n    repositories {\n        jcenter()\n    // Location of the .aar files for the SDK\n    flatDir {\n        dir \"${project.rootDir}/libraries\"\n    }\n}\n\n}\n``\nin the rootbuild.gradle` to get the module to depend on the .aar.\nIn the next release, we're consolidating the NDK & SDK build systems so the exact way to include the GVR NDK in your own project will change, but what you're doing should work for now.. You should only have libgvr.so and libgvr_audio.so in your APK along with your own app's library. Those are the two NDK libraries. The other two libraries are for the SDK and come in via base.aar and audio.aar which you don't need in your NDK app. In the next GVR release, we'll merge the NDK & SDK to avoid this confusion. You should avoid everything outside the ndk/ directory in this repository for now since those are part of the SDK.\nYou'll need to link against gvr and gvr_audio in order to get your app's own native code to compile and link successfully: https://github.com/googlevr/gvr-android-sdk/blob/master/ndk/demos/treasurehunt/app/build.gradle#L29. And you'll need ndk/lib/common_library.aar to get the NDK-specific Java code. Use ndk/demos/treasurehunt/ as a starting point.\nThe error caused when loading libmain_android.so might be due to having multiple architectures in your APK. Do you have armeabi and arm64 in your APK?. We refactored the location of .aars for .8, but you can always see the full repo history at https://github.com/googlevr/gvr-android-sdk/commits/master. The .6 release is at https://github.com/googlevr/gvr-android-sdk/commit/7fa8fc70fc7434938b09dea5df25465a610b70ef and the .7 release is at https://github.com/googlevr/gvr-android-sdk/commit/6f712333b790f2fb250c854d923da474d47d0558. . This is unrelated to the GVR SDK. The first 10 lines of your build.gradle file are in conflict with the rest of the file. Delete those lines and the file will parse correctly.. This complex functionality is beyond the scope of the VrView widgets. You'll need to develop a custom app using https://github.com/googlevr/gvr-android-sdk/issues/510 as a starting point to add more functionality.. Did you extract the NDK?\nFrom the NDK's Get Started page:\n\n\nExtract the NDK .so files by running the command ./gradlew :extractNdk.\nIn settings.gradle, uncomment the following lines:\n include ':samples:ndk-controllerpaint'\ninclude ':samples:ndk-treasurehunt'. @gpx1000 the :extractNdk task is part of the build dependencies in gradle, but Android Studio doesn't seem to properly recognize these dependencies. If you run gradlew build, the :extractNdk task will run automatically as part of building the NDK samples. But if you just build from Android Studio, the task will not run and you will get compilation errors.\n\n\nFor the next release, I'll try to streamline it some more but since the NDK + gradle are still experimental, there will probably still be some hacks and hiccups to get .SOs from .AARs.. @gpx1000,  I couldn't get your code to work since Android Studio appears to use :samples-ndk-treasurehunt:assembleFatDebug as the task name. However,\nbuild.dependsOn(':extractNdk')\ntasks.whenTaskAdded { task ->\n    if (task.name.contains('assemble')) {\n        task.dependsOn(':extractNdk')\n    }\n}\nresults in a config that works with both command line gradle and AS builds. \nI will update the SDK to use this dependency if I can't get your suggestion from https://github.com/googlevr/gvr-android-sdk/issues/315 to work. Thanks for the help.. Thanks for the note. You can also get the model from the Unity repo but we'll add it to the assets directory of this repo.. You should use the assets in the Unity repo for now. I will add those assets to this repo in the future. The files are C4D & FBX models with PNG textures so most modeling tools will be able to convert them to OBJ.. FBX model at https://github.com/googlevr/gvr-android-sdk/tree/master/assets/controller. Regarding battery levels: this is something we're looking at exposing across all SDKs.\nRegarding second question: see DaydreamApi.exitFromVr. There is no official support yet for having an NDK project depend on .so from .aars so every semi-automated or automated solution to do this ends up having hacks in it. Another option I saw was to use the exploded-aar directory as the source for the native module.\nIn the end, I decided that the current :extractNdk rule was the least worst option. (I still need to try your suggestion for improving the task dependency). Every NDK project I've found has a slightly different build structure with its own hacks and drawbacks. For now, I think it's cleaner to let devs find a solution that works best with their own build system until the NDK officially supports aars from maven.. There are no plans to support Eclipse since Gradle is the build system that Android apps should use going forward. You should migrate your project to Gradle.\nYour specific issue is caused by not having the required dependencies in your project. If you look at the SDK dependencies for the sdk-common library, it says it requires the protobug-javanano library. You'll need to get those libraries and add them to your project. You will need to do this for all the gvr libraries and these dependencies might change in the future. You will also need to make sure you are using the resources and .so files from the .aars or you will get runtime errors.\nYou'll need to look at the .pom files for all the libraries and their dependencies with each new SDK release.. Thanks for the info and patch. However, our build system dynamically generates the SDK layout so your patch is incompatible with it. I will fix this issue on our end. I opened https://github.com/googlevr/gvr-android-sdk/issues/319 if you want to track this.. This is now fixed: https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-controllerclient/src/main/java/com/google/vr/sdk/samples/controllerclient/ControllerClientActivity.java. Exoplayer is supposed to support both v1 & v2 in the same project: https://medium.com/google-exoplayer/exoplayer-2-x-new-package-and-class-names-ef8e1d9ba96f\nCan you try manually adding ExoPlayer v1 to your project and checking if it gets included in the final set of class files? You can check the list of classes by examining the MODULE/build/intermediates/.../jars/main.jar file.. You'll need to perform some extra steps to get Gradle to include both versions: http://stackoverflow.com/questions/29374885/multiple-version-of-dependencies-in-gradle\nI haven't tried this so I'm not sure how well it works with ExoPlayer. If it doesn't work, try opening an issue on the Exoplayer GitHub repo regarding multiple version support.\nYou can also wait for the next version of the SDK which should have Exoplayer 2.x support: https://github.com/googlevr/gvr-android-sdk/issues/278. After some more experimenting, I wasn't able to get Gradle to pull in both versions of Exoplayer. You can check with the Exoplayer team if they have a workaround or wait for https://github.com/googlevr/gvr-android-sdk/issues/278. Are you able to build other Gradle-based projects? This looks like a general problem with your machine's build setup.. Consider using the Video360 sample as a starting point. It uses Android basic MediaPlayer, but you can swap that out of any custom media player that renders to a Surface. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. @tvkamara are you rendering DRM video or non-DRM video? These APIs are primarily meant for DRM video in VR or video that needs to render at 60fps while the rest of the VR scene renders at a lower framerate.. @tvkamara depending on your setup, using the viewport API might not affect your video rendering latency. You can use setAsyncReprojectionEnabled without using the Viewport API. Most of our samples use it.\nDo you actually need the VR functionality or do you just want low-latency 2D video? If so, rendering video to an Android SurfaceView is the fastest way since it skips Android compositing steps. Using a TextureView is the second fastest since it adds an extra frame of latency due to Android compositing. Using the GVR API is overkill unless you want the 1) 3D rendering, 2) head tracking, and 3) distortion correction. Each of these steps adds some latency.. Due to the rendering and distortion step in GVR, SurfaceView will probably be faster for basic video. The latency improvements in VR mode are meant to reduce motion-to-photon latency so they won't have as significant of an impact on video rendering latency. The extra overhead related to rendering the 3D scene might also increase the latency compared to a SurfaceView.. Setting an arbitrary head rotation ended up being complex due to the interactions with rotations from the gyro. There are many edge cases where the interaction does unexpected things.\nWhat are your use cases for this? Two options we're looking at are 1) enable the dev to inject fake panning events (similar to how current touch input works) and 2) a new sample app demonstrating how to implement a custom widget view with gyro + touch input.. @Cooper6334, it's unlikely that VrView will ever support arbitrary pitch offsets that would allow the user to lie back and have the view automatically adjust. The interactions between pitch offsets and gyro poses become too complex for most users due to gimbal lock and non-commutative rotations\nCustom yaw would need to be handled on a per-app basis.\nFor this case 2) would be the best option since you could customize the UI as you desired.. @tao1 Are these use cases mutually exclusive? That is, a user will either be using only a dpad or only a headset to control the TV and not both at the same time? \n@Ornolfr , does your use case use head tracking? Or is it a device fixed in place that is only manipulated through pitch & yaw settings rather than the device's sensor?. If you want more complex touch & gryro controlls, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Is this issue only happening with the Unity SDK? If so, you should open an issue on the Unity SDK tracker. Also were you able to build and deploy the Unity samples on those devices?. This looks like a codec issue. Can you play the video file on those phones directly? Push https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-simplevideowidget/src/main/assets/congo.mp4 to the phone and use adb shell am start -a android.intent.action.VIEW -d file:///sdcard/PATH/congo.mp4 -t video/mp4 to play it.. Are there any advantages to using using CMake? It's useful for Gradle projects that already depend on it, but it's not as useful for standalone Gradle projects.. The NDK + Gradle + AAR build system isn't complete yet and every project has a slightly different NDK system. GVR uses a pure Gradle system to keep the sample build files simple so we'll stick with that for now. If the CMake system has better support for Maven AARs, then we'll switch to that.\nThanks for the suggestion.. You need com.google.intent.category.DAYDREAM but you have android.intent.category.DAYDREAM your manifest.. Do you just want the head pose? If so see the TreasureHunt samples which use head orientation as input. If you want raw sensor data, you would need to use the standard Android Sensor API. We're not going to publish the VrView's source code. It has complex internal dependencies on Google code  and crossplatform components so people won't be able to build it.\nWe are looking at publishing a minimal sample that demonstrates how to create a 360 image & video viewer using the general GVR SDK. This will provide much of the desired VrView functionality but without the dependencies.. There are no plans to add this functionality. If you want a more complex media player, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. If you want a more complex touch & gyro controls for a 360 media player, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. The VrView widgets are meant as simple 360 viewers for apps that don't have complex requirements for viewing 360 media. If you want more functionality such as hotspots, consider using the Video360 sample as a starting point. See #510 for more info.. https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/VrVideoActivity.java#L296 is the code that handles Daydream controller events.  You'll need to replace that code with whatever input mechanism you want. Then have SceneRenderer.setControllerOrientation and SceneRenderer.handleClick figure out how to map the events to a hotspot. CanvasQuad.translateClick is one example that converts from controller orientation to touch events on a floating 2D quad.. You'll want to listen for touches in MonoscopicView.onTouch. That code only tracks drags, but it could be modified to detect taps.. What is the source image that you are using? You need to have an equirectangular projected image that covers the entire sphere. If you use Cardboard camera to capture the image, it won't capture the top and bottom of the sphere so the widget shows black in that area. You can edit the image to replace the black part with whatever content you want.. For the 2D mode, do you need any Daydream functionality such as head-tracking or controller input? If not, the easiest option is to use a separate Android Activity that has no GVR code but calls your app's renderer in monoscopic mode. If you only need head tracking, then you could use Android's sensor APIs rather than GVR's APIs.\nThe code for your 2D Activity would be something like this:\nActivity.java:\n```\n    // Configure sensors and touch in the Activity constructor.\n    sensorManager = (SensorManager) context.getSystemService(Context.SENSOR_SERVICE);\n    // TYPE_ROTATION_VECTOR is the easiest sensor since it handles all the hard math for fusion.\n    orientationSensor = sensorManager.getDefaultSensor(Sensor.TYPE_ROTATION_VECTOR);\n    phoneOrientationListener = new PhoneOrientationListener();\n  }\n@Override\n  public void onResume() {\n    super.onResume();\n    // Use the fastest sensor readings.\n    sensorManager.registerListener(\n        phoneOrientationListener, orientationSensor, SensorManager.SENSOR_DELAY_GAME);\n  }\n```\nHandle sensor events:\n// Detect sensor events and save them as a matrix.\n  private class PhoneOrientationListener implements SensorEventListener {\n    @Override\n    public void onSensorChanged(SensorEvent event) {\n      synchronized (/* you need to synchronize between this event thread and the GL thread */) {\n        // Android coordinate system assumes Y points North and Z points to the sky. OpenGL has\n        // Y pointing up and Z pointing toward the user.\n        SensorManager.getRotationMatrixFromVector(phoneInWorldSpaceMatrix, event.values);\n        // Rotate from Android coordinates to OpenGL coordinates.\n        Matrix.rotateM(phoneInWorldSpaceMatrix, 0, 90, 1, 0, 0);\n      }\n    }\n  }\nTransform GL camera based on sensor data. If you're using the NDK for rendering, pass this matrix to your native code.\npublic void onDrawFrame(GL10 unused) {\n  ...\n  synchronized (...) {\n    Matrix.multiplyMM(viewMatrix, 0, phoneInWorldSpaceMatrix, 0, cameraMatrix, 0);\n  }\n  ...\n}. The root of the issue is that without distortion, the undistorted texture is mapped 1-to-1 to the screen. If the texture is smaller than the screen, you will see it repeated on the edges. Is this repetition visible in your viewer?. What are your requirements for this app? Normally, you shouldn't disable distortion correction unless you're running on a very low-power device.. Two workarounds I can think of:\n  1.  Add a custom view to the layout that's black and covers the top of the 3D view.\n  2.  Use https://vr.google.com/cardboard/viewerprofilegenerator/ to create a fake viewer profile with 0.0 distortion. Enabling distortion correction with this viewer profile should be similar tto disabling distortion with a normal viewer profile.. @anthonycr, this is the best workaround for now. The other option is to limit the Activity to landscape rather than sensorLandscape.. We've improved rotation handling so these issues should be fixed.. This is fixed now.. In general, you can use any standard Android APIs with GVR including custom usb/bluetooth controllers. Since this is a Unity-specific issue, you should open an issue on the GVR Unity tracker.. Why are you directly updating the viewer params? The VrView widgets have a setting icon that shows up in VR mode and can be used to update the viewer params.. Try calling GvrUiLayout.launchOrInstallGvrApp(this) inside your Activity. That will mimic clicking on the Settings button and launch the Cardboard Settings or Google VR Settings.. If you want more control of the user experience, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Thanks for the note. I'll update the build to properly handle clean operations.. If you can come up with a simple code snippet to do this, I'll add it to the build. I'm used to blaze which properly handles caching dependencies so I'm not sure what the best option is in gradle. But I think updating the clean task should be sufficient for now.. Thanks for the alternative solution. However, it's more heavyweight than I would like for the SDK sample. I'm going to go with the option of adding a proper clean task to the main build.gradle file. Other teams might have more complex build systems and I don't want to entangle them with Gradle dependency rules. The proper solution is for the NDK to support .so dependencies in .aars, but this will have to suffice until then.\ntask deleteNdk(type: Delete) {\n    delete \"${project.rootDir}/libraries/\"\n}\nclean.dependsOn(deleteNdk). Declining this in favor of a cleaning task. But thanks for proposing an alternative.. Are you just trying to record video of the app while it's running? Take a look at adb screenrecord.. This is beyond the design of VrVideoView, but it should still be doable using adb screenrecord. If you run the sdk-simplevideowidget sample, enter fullscreen mode, and run adb screenrecord, isn't the result what you want?. You can run adb screenrecord on a production app as long as the phone has debugging enabled. But you won't be able to run in on arbitrary user devices.\nVideo recording functionality won't be part of the widget's feature set. There are screen recording apps on the Play Store and you can also add this functionality to your app: http://stackoverflow.com/questions/15244009/android-screen-recorder-code-example. What is the specific URL you are having problems with? Can Exoplayer decode that video format? Try to view it with the Exoplayer sample: https://github.com/google/ExoPlayer. There's no plans to support directly viewing YouTube videos inside VrView. Using an intent to open YouTube (or YouTube VR for Daydream) are the best options.. Is this your app that has the problem? You should should use sustained performance mode to reduce the phone's power draw.. This appears to be an Exoplayer issue. Can you play the same video in Exoplayer when not using the Video Widget? . There's no support for directly accessing the Exoplayer instance. You should file this issue with the Exoplayer team and the fix will eventually be rolled into VrView.. The SDK is closed-source. We don't have any plans to open source it.. VrVideoView is meant to be a turnkey solution so it doesn't support other media players. However, we're working on a generic video player sample which will demonstrate how to swap out the media player.. Do you see any errors in the log? And what was the media file you were trying to load? Can you load it using Android's built in media viewers or the two sample VrView apps?. You can add a ROTATION_VECTOR or similar sensor to your app to record the current orientation. Then you can turn that orientation into yaw, pitch, roll when you detect a touch.. Consider using the Video360 sample as a starting point for building your own pano viewer with custom touch input. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. If you install the simplevideowidget sample, try adb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity  -d \"file:///android_asset/hls/iceland.m3u8\" --ei inputFormat 2 --ei inputType 2\nAre you having trouble with HLS videos?. You should be able to get it via the commit history.\nFor example, the Dec 10 2014 commit: https://github.com/googlevr/gvr-android-sdk/commit/22eb99d345e1974171930b8b6e3da1171431fd24\ngit log and git checkout 22eb99d345e1974171930b8b6e3da1171431fd24 will let you do the same thing on a local repo.. You also need to account for the time between frame submission and when the rendered image is sent to the physical pixels on the display. +50ms is a good estimate.. What is the memory usage of your app? See https://developer.android.com/studio/profile/investigate-ram.html for more details.. There is no global shader value for this, but you could define it yourself. When using the NDK, you would have a DrawEye function in your code. You could set a uniform in your shader based on this value.\nYou could also have a different scene graph for each eye consisting of mostly the same objects, but have two different nodes for the mesh that is different for each eye.\nAnother option I've used for stereo video is to have the mesh encoded as an array of [x,y,z, leftU, leftV, rightU, rightV]. Then I use the same shader for both eyes but have a call similar to glVertexAttribPointer(textureAttributeId, size, type, stride, pointerToData + (eye == LEFT) ? 3 : 5). That allows using one array for all the data in the mesh but only adjusts the offset based on eye being rendered.\n. See https://developers.google.com/vr/concepts/vrview for details about the video format. You will need a camera that supports 360 capture and can export equirectangular images.. The VrView widgets don't support this sort of click detection. You could add it yourself using something like https://github.com/googlevr/gvr-android-sdk/issues/381, but the better option is to use the general GVR SDK if you want more UI.. Consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Try https://developers.google.com/vr/android/reference/com/google/vr/sdk/base/GvrView.html#setRenderTargetScale(float) with a number less than 1. \nThe Java TreasureHunt sample uses the default of 1. The C++ uses a half that size. However, it uses MSAA to compensate. This results in a tradeoff between clarity and app FPS. Depending on your specific scene, you should experiment with various configurations.. I added the timing code from https://www.youtube.com/watch?v=GETPU5ACAJQ and ran the SDK sample on my Pixel XL. I had an fps of 60 with an avg frame time of 2-3. I made no other configuration changes to the sample.\nDo you have any system configurations on your Pixel that might interfere with app rendering?\nAlso, could you try profiling the NDK & SDK samples with either Android Device Monitor's Method Profiling  or SysTrace? Those tools should show why the sample was running slowly. Note that when running the method profiler, it will take 6-8ms to render a frame but the run time for CardboardViewNativeImple.nativeOnDrawFrame should match the onNewFrame to onFinishFrame time in your code.. With the 80 drawCube calls per eye, you will start running into Java + GL related overhead. If you change the timing method to only cover the GL calls, the 80 drawCube Java calls will be using more CPU than the 80 C++ drawCube calls. If you implement this sample without any VR code and have 2*80 drawCube calls, you'll see the same problem. Also note that the drawCube call will also call isLookingAtObject which performs Matrix math. These operations involve JNI calls so they add extra overhead if used frequently.. This looks like an issue with the GVR build system that is creating sdk-videowidget 1.4. In order to streamline the build system, we baked in some proguarded classes into the .aar. This will cause issues with people who also depend on other libraries that also bake in proguarded classes such as GMS.\nYou'll need to use 1.3 until we fix our build flow. Sorry for the inconvenience. . This is fixed now.. This is beyond the functionality of the VrView widgets. If you need to add extra UI, you should use the standard GVR SDK as a starting point to add additional features.. You will need to decode the fetch the Bitmap from the URL with your own code and pass the Bitmap object to VrPanoramaView. See http://stackoverflow.com/questions/8992964/android-load-from-url-to-bitmap for an example.. setDistortionCorrectionEnabled is meant for very low end Cardboard devices where the GPU isn't fast enough to correct distortion. It should almost never be used because it will result in a bad user experience. setAsyncReprojectionEnabled is meant for Daydream Ready devices and will result in a completely different render path than Cardboard render path. \nThe proper behavior here should be that setDistortionCorrectionEnabled is ignored rather than rendering a black screen, but the two options should never be used together.. There are no plans to add support for FileDescriptors. If you want to add this functionality to your app, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. The vertical touch tracking was never publicly exposed in our APIs because it doesn't work well with the gyro input. Some people noticed an internal flag for this, but that code was not meant to be public.. I pushed the video to my phone and then ran adb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"file:///sdcard/vr/videos/\u4eba\u5927oss.mp4\". The video played as expected. Are you able to view the video using the phone's built-in video viewer via adb shell am start -a android.intent.action.VIEW -t video/mpeg   -d \"file:///sdcard/vr/videos/\u4eba\u5927oss.mp4\"?. Does the video work on your HM-NOTE using the built-in Photos app? You can use adb shell am start -a android.intent.action.VIEW -t video/mpeg -d \"file:///sdcard/vr/videos/\u4eba\u5927oss.mp4\" to load it. That video is 4096x2048 which might be too large for old devices. You could try resizing it to 1920x960 and see if it works.. Also, what does the error in logcat say?. @i3games Chrome requires the installation of VR services even for non-Daydream devices when using VR functionality in Chrome\n@yihanseattle what app are you seeing this with?. Which custom device? Is this a consumer phone? Or does it have a custom build of Android?. Does your custom build have the flags listed in https://android.googlesource.com/platform/frameworks/native/+/android-7.1.1_r58/data/etc/android.hardware.vr.high_performance.xml ? Those cause the apps to try to enable Daydream rendering which requires Google VR Services.. The best way is to recreate the Activity as suggested in https://github.com/googlevr/gvr-android-sdk/issues/355. Or you could recreate the just the View.. If you need more control over the layout, consider using https://github.com/googlevr/gvr-android-sdk/issues/510. We don't have any plans of exposing our Exoplayer functionality due to its tight integration with various parts of our code. We are working on a sample that demonstrates how to implement many of the VrView features that people want including swapping out the Exoplayer instance or customizing it.. Asynchronous Reprojection requires a strong integration between the app, operating system, and hardware. This functionality is only limited to Daydream Ready devices right now. If you run a Cardboard app on these devices, you can enable async reprojection in the Cardboard app and the performance will improve, but setAsyncReprojectionEnabled will fail on non-Daydream Ready devices right now.. Transparency is beyond the design of the widgets. If you want to implement something like this, you probably don't need the GVR framework at all since this AR app would only work outside of VR mode. You should look at a plan Android's OpenGL + camera APIs. You can look at SurfaceTexture and GL_TEXTURE_EXTERNAL_OES  which would let you get the camera preview working in an OpenGL scene as a quad or some other mesh. You would also do something similar with MediaPlayer and render to another texture in OpenGL. Then you could overlay and blend these meshes however you want.. You won't be able to use GVR's sensor fusion code like that. Android does have an NDK sensor API. You can use that an implement sensor fusion on top of it. See smus.com/sensor-fusion-prediction-webvr/ for more info on how to implement sensor fusion.. What device are you seeing this problem on?. Tablets aren't support for the VrView widget,s but consider using the Video360 sample as a starting point for a custom app. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. This is probably a right-handed vr left-handed issue. OpenGL is right-handed but Unity is left-handed. So you'll need to convert if you are trying to use GVR (which is right-handed like OpenGL and other parts of Android) in Unity.\nSee https://answers.unity.com/questions/38924/unity-is-a-left-handed-coordinate-system-why.html . Using the Android GVR SDK inside Unity isn't supported. You should use the GVR Unity SDK directly. But if you do use the Android GVR SDK, you'll need to make sure all the conversions are correct.. Some things to check:\n  Are you running into this issue when using the simplevideowidget sample that comes with the SDK?\n  Are you using Proguard?\n  Does your final APK have the SphericalMetadataOuterClass$SphericalMetadata class? It's inside the classes.jar file that's inside the sdk-videowidget-1.60.0.aar file.. This isn't a supported method in the SDK. You should only use methods that are documented on the dev site. This method is only implemented for the video widget rather than the image widget which is why you're seeing a crash.. That API is still a private method so you shouldn't rely on it. If you want a pure touch-controlled 360 media player, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. This might be due to the high resolution of the video. Can you try reencoding to a smaller resolution? 4k is 3840x2160 and might work better.. There isn't an easy way to bring in a single Unity component into an Java VR app. You can create a new Unity Activity with the File Selector and then use the standard Android Intent system to send data between the two Activities, but this will result in a cross-Activity transition and will be slightly slower than implementing your own File Selector UI in Java.. Sorry. There was a publishing error. This should be fixed now.. Zooming isn't going to be supporte in VrView. If you want this functionality, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info. You can change the FOV used by MonoscopicView to effectively zoom the virtual camera.. Are you referring to the 2D mode or VR mode? The 2D mode uses 110 as the FOV on the long axis and adjusts the short axis based on the aspect ratio. In VR mode, the FOV is dependent on the distortion correction which is calculated from the viewer parameters.. There's no way to see the internals of VrView since we aren't planning on open sourcing it. But you can look at Video360 for more info one way of configuring the field of view for magic window UIs. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. exitFromVr is the correct API. When you want to exit, call that method. with a unique requestCode. The SDK will show an intermediate screen and then call your Activity with Activity.onActivityResult using that request code. At this point, the user has removed the phone from their headset so it's safe to perform a standard Activity launch using startActivity and an Intent targeting your 2D Activity. Then have your 2D Activity request permission via ActivityCompat.requestPermissions. Once the permissions are granted, launch your VR Activity.. See the new Video360 sample for information on how to use this API: https://developers.google.com/vr/android/samples/video360#permissions_and_hybrid_vr_app_flow. That app isn't open. But an API will be available for it. See https://blog.google/products/google-vr/poly-browse-discover-and-download-3d-objects-and-scenes/ for more info.. If you want more complex touch & gyro controls, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. This looks like a video decoding issue. Does the video play on that device using Android's build in media player? If it plays in the Android player, you should also try using ExoPlayer without using VrView to see if it's an Exoplayer specific issue.. There is no NDK version of the VrView widgets. However, consider using the Video360 sample as a starting point. It's pure Java, but it demonstrates the OpenGL and math required to render a 360 video in VR. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Each .aar has its own AndroidManifest.xml and the READ_EXTERNAL_STORAGE permission comes from https://github.com/googlevr/gvr-android-sdk/blob/master/libraries/sdk-base-1.70.0.aar where it's used to store a shared viewer profile on the sdcard. However, that has <uses-sdk android:minSdkVersion=\"19\" android:targetSdkVersion=\"19\"/>. and no maxSdkVersion\nYou can try using aapt dump permissions $THE_APK to see if this is the issue or try to track down which library is adding that permission to the final APK.. Can you provide more details about your development setup? We haven't been able to reproduce this issue.\nHave you seen this issue with older revisions of the SDK? Does a clean checkout of the git repo + a command line gradle build work?. @davidcox70, we're investigating this issue. Did you start seeing this on Nov 1st? We think it's caused by a change on that date rather than a recent build of GVR Services. Can you verify using the Performance HUD similar to @dustinkerstein? This issue manifests as a VMiss events happening even when the app is consistently rendering at 60fps. So launching the Daydream Home app and waiting for everything to settle will show 60fps on the graph but the screen will be flashing red due to the VMisses.\n@dustinkerstein the issue you're seeing is different from @davidcox70 who is seeing an issue that started manifesting on Exynos S8 devices on Nov 1st.. @dustinkerstein The issue was caused by a configuration change that happened on November 1st. It's not a new apk. We're working on updating the configuration so the VMiss issue should go away once the new configuration propagates. You can wait 24 hours or try speeding this up by clearing data for GVR Services.. The VrView widgets are meant as simple 360 viewers for apps that don't have complex requirements for viewing 360 media. If you want 2d-in-VR UI, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. @riadhnet , see https://developers.google.com/vr/android/samples/video360 for information. The second screenshot shows a floating UI in VR.. The sample as written does require Daydream since it uses Daydream-specific functionality like the controller and VR transitions. However, you can remove the Daydream functionality if you want it to work on plain Cardboard.\nTo do this:\n\nDelete the Daydream entries from AndroidManifest.xml\nDelete the DaydreamApi code from VideoActivity. This is only used to perform Daydream transitions into VR. You can use standard Android Intents for a Cardboard launch.\nCreate a new version of VrVideoActivity that doesn't use DaydreamApi or ControllerManager. You'll need to use the gaze and tap code from the Treasure Hunt sample instead of the controller input.. Fixed in https://github.com/googlevr/gvr-android-sdk/releases/tag/v1.150.0. What is the video file you're trying to play? This can sometimes happen if there are insufficient resources to decode the video.. The VrView widgets are meant as simple 360 viewers for apps that don't have complex requirements for viewing 360 media. If you want custom controls, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. The VrView widgets are meant as simple 360 viewers for apps that don't have complex requirements for viewing 360 media. If you want to support both images and video in your app, consider using the Video360 sample as a starting point. See https://github.com/googlevr/gvr-android-sdk/issues/510 for more info.. Why do you want an orthographic projection for an eye? When viewed in VR, this will not look correct.\n\nIf you really need an orthographic projection, you can generate one using Matrix.orthoM and tan of the angles stored in the eye's FieldOfView. You shouldn't use an orthographic matrix for  HUD. It can prevent proper stereo convergence in VR. Instead, considering rendering a quad (or other HUD components) with a rotation based on onNewFrame's headTransform.getEulerAngles. This will allow you to lock the HUD to the user's head.. Thanks for the note. For now, repacking the aar is the only workaround. We'll fix this properly for the next release.. This has been fixed in v1.130.0. The GVR SDK that you see on GitHub is actually built using an internal google build system. This internal build system already uses variables similar to what you're proposing so the \"1.120.0\" string you're replacing is already dynamically generated.\nI'll take a look at consolidating the buildToolsVersion\n. You pass in an array to hold the results.\nfloat[] yawAndPitch = new float[2];\nview.getHeadRotation(yawAndPitch);\nfloat yaw = yawAndPitch[0];\nfloat pitch = yawAndPitch[0];. What device are you seeing this issue on?\nThis is a bug in how the video player handles video textures. When Android creates a Surface to decode video, some devices create a Surface that is slightly larger than the actual video. Then they set a matrix on Surface which is exposed in SurfaceTexture.getTransformMatrix. Unfortunately, VrView doesn't check this matrix nor pass it down to the GL code. So the GL code samples garbage outside the video frame and that renders as green pixels at the south pole.\nThis is complicated to fix in the existing code and it only happens on some devices. You could try resizing the video to find a size that works for the device.. Correct, I meant resizing the video file. Since that's not possible, you should considering using the video360 sample which will let you build your own video use the SurfaceTexture's transformation matrix.. sdk-common-1.130.0.aar has the fix.\n. The sample as written does require Daydream since it uses Daydream-specific functionality like the controller and VR transitions. However, you can remove the Daydream functionality if you want it to work on plain Cardboard.\nTo do this:\n\nDelete the Daydream entries from AndroidManifest.xml\nDelete the DaydreamApi code from VideoActivity. This is only used to perform Daydream transitions into VR. You can use standard Android Intents for a Cardboard launch.\nCreate a new version of VrVideoActivity that doesn't use DaydreamApi or ControllerManager. You'll need to use the gaze and tap code from the Treasure Hunt sample instead of the controller input.. I'll add a section to https://developers.google.com/vr/android/samples/video360 about converting the sample into a Cardboard app.. This functionality is beyond what the spatial audio API was designed for. Since the audio that is played back to the user depends on their head position, there is way to save it to disk and play it back.\n\nhttp://smus.com/spatial-audio-web-vr/ and the related code is a good starting point for information how how the spatial audio is generated from the user's head position and basic audio sources.. For the type of complicated hit detection you're doing, the sample code won't be sufficient. The sample code only works because there are no transformations of the floating quad or the controller. Since you have multiple matrix operations, you will need to use a hit detection library such as the one in https://github.com/Rajawali/Rajawali. @nyankosoft, @sjfricke: you may be using a newer version of the NDK than what is supported. The existing samples use gradle-experimental:0.9.3 which uses an old NDK header layout. In the next version of the SDK, we're switching from the experimental NDK plugin to the standard NDK plugin which should fix this issue.\nIf you install NDK r15c or earlier, the build will work. If you install only NDK r16b or later, the build will fail due to the header layout. More information about header migration is at https://android.googlesource.com/platform/ndk/+/ndk-release-r16/CHANGELOG.md and the linked docs.. We aren't planning on adding new features to VrView at this time. You should use the video360 sample if you need more functionality.. Take a look at the Video 360 sample. It uses Android's MediaPlayer to render video. You cause use PlaybackParams.setSpeed(float) to control the speed of the video.. Is this only happening with your app or do you see it with the samples like TreasureHunt & Video360? You shouldn't need to use getEulerAngles when rendering. eye.getEyeView() should give you the view you want. headTransform isn't normally used for rendering. It's meant to adjust aspects of the VR scene that depend on the user's head pose such as audio or gaze tracking.\nCan you record a video of your phone while you're having this problem and share it?. The VrVideoView widget is targeted for immersive videos so it doesn't have support for basic planar videos. However, take a look a the Video360 sample. This is a sample built on the standard GVR APIs. It's targeted for Daydream rather than Cardboard since it uses a controller, but you can rip out the Daydream-specific code and use the gaze input from TreasureHunt. \nThe sample only renders to a sphere, but the Mesh.createUvSphere(...) method takes in many parameters. You could use this to create a \"plane\" that is actually a small subsection of a sphere. I've used that code to experiment with rendering planar 3D movies in VR.. Yes. Please let us know if you have any problems with the video360 sample.. This has been fixed with v1.130.0.. You can directly use a GvrView in a custom Activity. If you need more control, you can also use GvrLayout as demonstrated in the videoplayer sample.. You'll have to profile the app's performance using https://developer.android.com/studio/profile/traceview.html, https://developer.android.com/studio/profile/android-profiler.html or https://developer.android.com/studio/command-line/systrace.html\nYou'll will need to be careful with 2D animations inside VR. Due to the heavy load on the GPU from the VR system, the 2D animation may stutter since it is not in sync with the VR rendering system. \nYou should instrument your code and make sure the View.draw operations are not happening too frequently. Your View.draw and unlockCanvasAndPost should only be called when the 2D View has changed. If the texture is large (in terms of number of pixels) then the drawing operation and updating of the SurfaceTexture will use a lot of GPU bandwidth due to the amount of pixels being copied.\nIf you do need to have some part of your app's 2D Views updating frequently such as an animating spinner, then it would be a good idea to have that animating part run in its own small CanvasQuad so that the amount of pixels that are redrawn each frame is as low as possible.. @bluemarvin this is an Android framework issue since GVR doesn't do anything special for the Android IME. Consider overriding the TextView with a custom class that handles all the focus events. Or you might be able to use TextInputView.setInputType to avoid bringing up the keyboard.. https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-treasurehunt/src/main/AndroidManifest.xml declares com.google.intent.category.DAYDREAM and com.google.intent.category.CARDBOARD so the app runs on both Daydream & non-Daydream phones. \nIf you only want to support Cardboard mode, you can remove all the Daydream references in the manifest and in TreasureHuntActivity.java.. What are you trying to show on the TV? Would Daydream + Cast do what you want?. The reticle will only work if you're using a Daydream device with a controller. For Cardboard, you can use Treasure Hunt's headTransform.getQuaternion to control the reticle.. Can you play that video file on the device using any 2d video app? The MT6750 chipset might not be able to handle such a high resolution video.. What are the full set of dependencies in your application? This error happens when one of the GVR SDK libraries has the same Java class as another dependency. The builder complains that two dependencies have the class and it can't figure out which class to use.\nIn the short term, you could try editing the sdk-base.aar's classes.jar file and removing the problematic CodedOutputByteBufferNano.class file.\nIn the long term, we'll need to update our SDK build system to avoid having this extra class file.\n. Without the full set of dependencies for the project, it's not possible to diagnose the issue. One of the dependencies has a copy of the com.google.protobuf.nano.CodedOutputByteBufferNano class. sdk-base depends on sdk-common which depends on com.google.protobuf.nano:protobuf-javanano.\nI verified that this class isn't in any of the SDK's aars so it's baked into another dependency's aar.. It looks like this issue regressed between 1.80 & 1.90 of the SDK. We'll fix this in the next version of the SDK. But the workaround mentioned in #71 should also work if you modify the audio library's AndroidManifest.xml. We have no plans to add this functionality to VrWidgetView. Instead we created the video360 sample which demonstrates creating a custom 360 viewer and you can add whatever functionality you need. See #510 for more info.. VrVideoView is meant for 360 videos and it's not possible to pack those into a side-by-side video file without heavy distortion.\nThere is no plan to add new functionality to VrVideoView, but there is a new open source video360 sample that you can use to play side-by-side videos: https://github.com/googlevr/gvr-android-sdk/issues/510. Can you capture a bugreport using adb bugreport? That will provide more info.\nSome more steps to try:\n\nMake sure VR mode isn't enabled by using AndroidCompat.html#setVrModeEnabled(false). VR mode can affect the clock speeds and other low level aspects of the device. The AndroidManifest.xml should also not have any enableVrMode entry.\nMake sure getAsyncReprojectionEnabled returns false. This affects how the app renders content to the display.. Unfortunately, there is no clean solution because other browsers don't advertise if they have VR support enabled. You could use the launch2dActivity demonstrated by VrVideoActivity to be safe, but that would result in an awkward flow if the target Activity supports VR. You could also scan the installed packages for com.google.intent.category.DAYDREAM and only launch the Intent if you can find a browser that works with Daydream.. The ndk/base/GvrLayout.getGvrApi() method should be fully usable from a pure Java application without adding NDK support to your app. The ndk.base vs sdk.base is a historical artifact of how the APIs evolved rather than a limit on which functions can be used from what type of code.. It looks like there is no easy way to get the GvrApi from GvrView. We'll add an API for this.\n\nOne short-term option is to switch from GvrView to GvrLayout like the videoplayer sample. The general code would be the same. The GvrView.StereoRenderer.onDrawEye code would be replaced with the VideoSceneRenderer.drawScene and VideoSceneRenderer.drawEye code since the NDK API is slightly lower level than the SDK API.. This is fixed in v1.170. Thanks for pointing this out. We'll update the sample.. If you're just going to use landscape everywhere, you'll need to change MonoscopicView$Renderer.onDrawFrame to include an extra 90 degree displayRotationMatrix multiplication on the viewMatrix before it's used. You'll also need to update the TouchTracker logic to account for this. If you want to make the code more general and support rotating the phone, you'll need to:\n\nAdd an OrientationEventListener to detect when the user flips their phone 180 degrees. This will need to save the current rotation as displayRotationDegrees which is 0, 90, 180, or 270.\nUpdate displayRotationMatrix on a rotation based on the new displayRotationDegrees value.\nUpdate TouchTracker based on the displayRotationDegrees\nMake sure onSurfaceChanged handles the new FOV properly.\nMake sure your Activity's lifecycle handles all the changes.\n\nSupporting rotation while the app is playing a video can be tricky so you will need to be careful and handle all the edge cases.\n. https://gist.github.com/sigmaxipi/b9d4cbfb3410e5be6c5279f56c09b391 is a patch that demonstrates the basic functionality required for supporting rotation. I haven't tested it in depth, but it appears to support standard rotations.\nDue to the complexity of dealing with rotations while rendering 3D or playing video, it's better to make sure your Activity is fixed in one rotation or you will need to perform thorough testing.\n. The patch shows that changes I made to https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/MonoscopicView.java but those changes are not checked in since they haven't gone through thorough testing.\nYou can download the patch and use git apply to modify your local copy of the SDK. Or manually apply the changes into  your own app.. In general, the Android Binder system doesn't let you intercept or forge calls without a rooted device.\nIf your headset is a standard Cardboard headset, you can force Daydream apps to run by skipping the compatibility check. This isn't a supported way of using custom headsets and may break in the future, but it should work for now.. We have no plans to support other languages, but Flutter does allow for Java bindings and that may be an easier path than the C bindings. https://flutter.io/platform-channels/#example-java shows how to connect a Flutter & Java system. https://github.com/sigmaxipi/gvr-clojure/blob/master/src/clojure/me/sxp/gvrclojure/main.clj was my experiment with using Clojure on Android + the Java SDK to get basic VR rendering. You may be able to combine the two. You would need to start with GvrView & GvrView$StereoRenderer. Then override the StereoRenderer's onDrawEye to call Dart code. Then you should be able to embed this custom GvrView inside a Flutter app.\nThis will probably be easier than trying to use the C APIs since they require much more glue to get a minimal app on Android. If you do get it working, please share your code. When I was playing around with Clojure & VR, the ability to hot reload my code was amazing. From what I've read, Dart's IDE will also let you hot reload code.. When your app is configured for 6dof tracking in the manifest, the head transform matrix provided by the SDK will have true 6dof data. Are you not seeing translational components in it?. The best option is to contact the GearVR Framework team and ask them to expose position.\nYou can also use GvrApi.getHeadSpaceFromStartSpaceRotation. See https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-videoplayer/src/main/java/com/google/vr/sdk/samples/videoplayer/VideoSceneRenderer.java#L207 or any of the NDK samples for more info.. Do you have a crash stack? While mixing headers and libs from different versions won't work, this normally causes a linker error rather than a runtime crash. GVR actually loads a runtime library from Google VR Services which is installed on Daydream devices and designed to be backwards compatible. However, the s6 isn't a Daydream device so it won't have GVR Services which is may be why the app crashed.\nThe build issue is similar to https://github.com/googlevr/gvr-android-sdk/issues/315\nThe problem is that there isn't any clean way of shipping native headers and libraries via .aars. I don't know if this has changed since the last time I investigated but the other issue has notes and possible workarounds. Since everyone has a slightly different build setup, there are hacks which will work for some people but not others.\nIf you find a good solution, please let us know.. We've release 1.170 and all the build.gradle files for the samples have been updated.. The core problem is that many developers wanted slightly different functionality for mixing custom yaw/pitch config and gyro-based config and there was no way to support all of them.\nInstead we created the video360 sample which demonstrates creating a custom 360 viewer which whatever functionality you need. See #510 for more info.. Mesh.glDraw takes in a model-view-projection matrix but SceneRenderer.glDrawFrame only passes in a view-projection matrix since there was no need for a rotation matrix in this sample. You'll need to add a rotation matrix in either of those two functions. Reticle.glDrawFrame shows how to take in a view-projection matrix & rotation matrix to update the reticle. You'll want to replicate this for Mesh.. If you changed the viewProjectionMatrix, you would end up rotating the world and not the mesh. This is OK for MonoscopicView where the only item in the world is the mesh, but wouldn't be the proper way of doing it for a more complicated GL scene.. The performance HUD is lives in Google VR Services rather than the SDK. It's designed to work with Daydream apps that need to maintain 60fps rather than Cardboard apps that don't have a strict FPS requirement. The S7 is not Daydream Ready but the S9 is so your friend's phone will show the PerfHUD for Daydream apps and Cardboard apps running in Daydream-compatible mode.. You are right that the order of matrix multiplication is different from what you expected. The gvr_get_head_space_from_start_space_transform() API was meant for use when rendering the scene from the camera pose. If you want to extract the head position, you need to use the inverse of this.\nAlso, note that the value in step 2 above is incorrect. In OpenGL, if you step backwards, the Z position of your head in the world will increase. However, the position of the world with respect to your head will decrease. Similarly, you should check the value in step 3 since turning your head to your right will cause your head's yaw to decrease.\nIf you want to extract the head's position & rotation, you want to take the inverse of the gvr_get_head_space_from_start_space_transform() matrix and read the translation from that matrix. You can use a standard matrix inverse algorithm, but this may be slow. You can also take advantage of the fact that the head pose is a rotation + translation matrix and have something like:\nhead_space_from_start_space_rotation = extract_rotation(head_space_from_start_space_matrix);\n  head_in_world_rotation = transpose(head_space_from_start_space_rotation); // The transpose of a pure rotation matrix is the same as its inverse but faster to calculate\n  head_in_world_position = -1 * head_in_world_rotation * head_space_from_start_space_matrix;. Can you provide more information? This looks like you were running the org.mozilla.vrbrowser app on an Oculus Go. This looks like a bug in the Mozilla app. It should avoid calling any GVR functions when running on Oculus VR devices. Can you file a bug on the Mozilla tracker?. Tracked at https://github.com/MozillaReality/FirefoxReality/issues/586. There are no plans to add more functionality to the VrView widgets. But you more complex controls for a 360 media player, consider using the Video360 sample as a starting point. See #510 for more info.. That module should switch over to the general API used in the video360 sample instead of the VrView API.. What is the issue?. We have no plans to add this functionality to VrWidgetView. Instead we created the video360 sample which demonstrates creating a custom 360 viewer and you can add whatever functionality you need. See #510 for more info.. You can use the video360 sample as a starting point to create more complex image viewers. The sample only supports the Daydream controller, but you can copy the code from the hellovr samples to add support for gaze input. The sample also shows how to render a floating 2D UI in VR using standard Android Views and you can use that functionality to show thumbnails.. See the documentation at https://developers.google.com/vr/android/samples/video360#ui_and_adb_commands_to_load_media and https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/MediaLoader.java#L42\nYou will need to run\nadb shell am start \\\n  -a android.intent.action.VIEW \\\n  -n com.google.vr.sdk.samples.video360/.VrVideoActivity \\\n  --ei stereoFormat 2 \\\n  -d \"file:///sdcard/IMAGE.JPG\". https://github.com/googlevr/gvr-android-sdk/blob/master/samples/ndk-hellovr/src/main/jni/hello_vr_app.cc#L453 has\nfloat ground_y = gvr_api_->GetCurrentProperties().Get(\n                       GVR_PROPERTY_TRACKING_FLOOR_HEIGHT, &floor_height)\n                       ? floor_height.f\n                       : kDefaultFloorHeight;\nhttps://developers.google.com/vr/reference/android/com/google/vr/ndk/base/GvrApi#getCurrentProperties() and https://developers.google.com/vr/reference/android/com/google/vr/ndk/base/Properties.PropertyType#TRACKING_FLOOR_HEIGHT are the matching Java APIs.\n~~However, after looking through the code, I see that there is a bug where the properties object isn't refreshed and it's possible for the floor height to change while the app is running as the tracking system adapts. This bug is being tracked internally and will be fixed in an upcoming release.~~. I've attached a patch for code that will go into a future version of sdk-hellovr. I've verified that it works on a Mirage Solo. I'm not familiar with Kotlin and it's not a supported language for GVR, but the snippet you provided appears correct. Does the .get call return true? And are you calling it each frame? My comment above about the value not refreshing was incorrect and the Java API appears to be working as expected.\nFLOOR_HEIGHT.patch.txt\n. Is this issue specific to the GVR classes? GvrAPI does have some multi-classloader dynamic loading magic under the hood and it may be interfering with Kotlin. While GVR doesn't support other languages, this was the first issue of this type that we've heard of.. Can you read bytes from the file directly? If not, you may be missing permissions or have a typo in the file name.. What is the error that you are seeing? Do the samples work if you build them directly from the repo? Did you grant your app permission to read from disk?. We're investigating this issue. Note that the code for the profile generator is open sourced at https://github.com/google/wwgc. The site has been updated.. Thanks for pointing it out.\nThis happens if you use NDK r17c (Jun '18) or greater which removed MIPS support. As a workaround, change the root build.gradle to use 3.2.1 and gradle/wrapper/gradle-wrapper.properties to use 4.6\nWe'll update the default version & config.. Updating the gradle version also causes some Lint errors so you may need to update the various build.gradle and AndroidManifest.xml files to properly selection SDK 26+. I managed to reproduce this by setting the distributionUrl in my wrapper/gradle-wrapper.properties to 4.10.1. This happens if you upgrade the NDK to r19.\nIn the settings.gradle at the project root, try removing everything except the include ... lines. We'll update the project to support the newer NDK. Sorry about that. https://github.com/googlevr/gvr-android-sdk/releases/tag/v1.190.0 has been created.. This is fixed in v1.9 of the Cardboard app which is currently rolling out to production. This should be fixed by Wednesday.. Unity issues are tracked at https://github.com/googlevr/gvr-unity-sdk/issues\nhttps://github.com/googlevr/gvr-unity-sdk/issues/1008 tracks 64-bit support.. That looks like the controller reticle which shouldn't be drawn when using the 2D rendering mode.  Can you try changing https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/rendering/SceneRenderer.java#L252 so that reticle.glDraw(...) is only called if eyeType != Type.MONOCULAR. https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/MediaLoader.java#L266 is the code that sets the loaded bitmap as the texture for rendering. If you hold onto the Surface that is returned there, you can call\nCanvas c = displaySurface.lockCanvas(null);\n      c.drawBitmap(NEW BITMAP, 0, 0, null);\n      displaySurface.unlockCanvasAndPost(c);\nwith the new Bitmap without recreating the Activity.. How is the image distorted? Does changing the stereoFormat help?. Try increasing the number of triangles in the sphere to get rid of the waviness: https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/MediaLoader.java#L93\nThe sample media is top-bottom stereo but you may be using monoscopic panoramas which is why they look different: https://developers.google.com/vr/discover/360-degree-media. I haven't tried it, but I think the flow would be something like:\n\nCalculate X & Y in pixels from the center of the rendered view.\nCalculate horizontal & vertical angles of the touch from the camera viewpoint based on these X & Y. \nIf the user was always facing forward, then these angles would map to the point of the sphere where they were touching the screen. But since the user is rotating the phone, you need to modify this touchpoint by applying the inverse of viewMatrix.. The projection matrix is stored in MonoscopicView.Renderer.projectionMatrix, but you shouldn't need it except for rendering. The view matrix is calculated in MonoscopicView.Renderer.onDrawFrame based on deviceOrientationMatrix with an adjustment from the touch input.. The VrPanoramaView widgets have been deprecated. You should switch over to the code in the video360 sample which allows more customization. See #510 for more info.. Given the viewMatrix at https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/MonoscopicView.java#L315 you can multiple that with a vector <0,0,-1> and then compute the atan(x,z) of the resulting vector to get the yaw angle.. See https://threejs.org/docs/#api/en/math/Euler.setFromRotationMatrix which converts from a rotation matrix to Euler angles. The source code is at https://github.com/mrdoob/three.js/blob/34dc2478c684066257e4e39351731a93c6107ef5/src/math/Euler.js#L133. You'll want to implement your own version of Euler.setFromRotationMatrix using the three.js source code as a starting point. Then you can pass in the viewMatrix into that function to extract the yaw angle. . The FOV is computed at https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/MonoscopicView.java#L301. Answered in https://github.com/googlevr/gvr-android-sdk/issues/615. Can you check VR Settings -> Developer options -> Enable GVR head tracking service and see if that is enabled? If so, can you disable it and reboot?. Which version of the Cardboard app are you using? This issue should have been fixed with the new release on Feb 19th.. The videowidget library is no longer supported. You should migrate over to the open source video360 sample.\n\nIf this crash is only happening on a specific device, you could try to play the video on that device using a different app and see if it's an issue with the codec. Or try reencoding the video and playing that version.. See https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360/VideoUiView.java#L157 is the code that handles the UI for 2D & VR mode.. This may be a compatibility issue with the video stream format and the default Media Player. The sample was primarily designed to demonstrate the VR rendering aspects and not the video playback functionality. Instead of using Android's MediaPlayer, the general recommendation for video playback on Android is to use a more powerful player like https://github.com/google/ExoPlayer which has better format compatibility.. GVR isn't supported on x86 devices other than emulators. You should remove the x86 & x86_64 versions of the .so from your app. . Yes. The x86 GVR library in the SDK is only meant for testing on emulators.. ",
    "MoxorTheOne": "You're not guiving any info to help you.\nWere is the stack trace? witch device, OS version.\ndoes the https://play.google.com/store/apps/details?id=com.google.samples.apps.cardboarddemo&hl=en\nworks, did you modify somethig?\n. ",
    "redpotatojae": "Sorry, I was not specific enough.\nI have also tried to get the demo app from Google Play and it ran fine on my phone (https://play.google.com/store/apps/details?id=com.google.samples.apps.cardboarddemo&hl=en).\nI got the source code and imported into eclipse and I tried to run the sample code on my phone.\nI did not modify anything except adding a Source \"MainActivity/java\" and adding a libraries \"cardboard.jar\"\nfyi, My device is Galaxy s3 4.4.2 running. \n. ",
    "kofiav": "Has anyone else been able to come up with a workaround for this issue? It is very frustrating. Is this a legitimate issue affecting all Android devices or is it one that can be avoided by only using certain Android devices?\n. @n1cholson \nI know you commented over a month ago, but were you able to find a complete fix?\n. @n1cholson \nThank you for responding. Unfortunately I have to use Cardboard for a project so it is critical that I identify and fix any issues present. I too am concerned that the authors are not providing support and aren't being very responsive. The idea for Cardboard was that it would be a black-box that would allow developers to defer all the extra work required to render a stereoscopic projection to the library. If we have to take time to investigate the library itself, then the project has already failed to meet one of its goals. What a bummer. \nNavigating a 3D environment with a magnet only is indeed limiting. It looks to me like it would be possible to move along the z-axis by utilizing the smartphone's sensors but I do not know how feasible this is. In any case, I suppose I have no choice but to construct a functional copy of the jar before I can move on. Thank you for notifying us of the screen size issue. I will update you and anyone else on this thread if I make any progress. \n. Device: Nexus 5\nAPI Level: (target: 18) (min: 18)\nThe app starts on fullscreen mode with no issues, but no rendering occurs. The reason, as n1cholson so eloquently stated is: \n\"Surface size ????x1080 does not match the expected screen size of 1920x1080. Rendering is disabled\"\nI should say that the Cardboard Sample  Code runs fine for me. It's only when I tried using the Google Cardboard library for my own personal and quite separate project that I encountered this issue. \n. +2\n. ",
    "Shirokuroneko": "If you are extending a CardboardActivity it should be setting fullscreen mode for you on creation. What device and API level are you using?\n. ",
    "kchodorow": "A hacky way around this that worked for me:\n```\n// Get the CardboardView.\nCardboardView view = (CardboardView) findViewById(R.id.cardboard_view);\nview.setRenderer(this);\nsetCardboardView(view);\n// Manually set the screen size.\nDisplay display = getWindowManager().getDefaultDisplay();\nScreenParams params = new ScreenParams(display);\nparams.setWidth(/ desired width /);\nparams.setHeight(/ desired height /);\nview.updateScreenParams(params);\n```\n. ",
    "3spin-dev": "We had the same issue with the Galaxy S2. The Nexus 5 worked fine out of the box.\n. ",
    "flankechen": "@kchodorow \nbut what width and hight to set? in\nparams.setWidth(/* desired width /);\nparams.setHeight(/ desired height */);\nI have a device with resolution 1980*1080 with no on screen navigation bar.  and it render two strange \"small\" view on the screen. \n10-28 16:14:55.012: D/OpenGLRenderer(9162): Enabling debug mode 0\n10-28 16:14:55.042: I/MainActivity(9162): onSurfaceCreated\n10-28 16:14:55.052: W/CardboardView(9162): Surface size 1920x1005 does not match the expected screen size 1920x1080. Rendering is disabled.\n10-28 16:14:55.052: I/MainActivity(9162): onSurfaceChanged\n10-28 16:14:55.052: I/MainActivity(9162): surfaceWidht960\n10-28 16:14:55.052: I/MainActivity(9162): surfaceHeight1005\n10-28 16:14:55.112: V/RenderScript(9162): Application requested CPU execution\n10-28 16:14:55.112: V/RenderScript(9162): 0x7733da88 Launching thread(s), CPUs 4\n10-28 16:14:55.132: E/ffi_jank(9162): timespan = 64.74047\n10-28 16:14:55.182: E/ffi_jank(9162): timespan = 32.909218\n10-28 16:14:55.212: I/MainActivity(9162): onSurfaceChanged\n10-28 16:14:55.212: I/MainActivity(9162): surfaceWidht960\n10-28 16:14:55.212: I/MainActivity(9162): surfaceHeight1080\nthat's strange, height change in these two renderer onsufaceChanged()\n. zbendefy, thanks for your replay.\nI have try fullscreen mode, phones with or without navigate bar. It seems that this is bug of cardboard SDK, some phones even render views \"super small\", which is even in the latest update and some of the carboard games.\nHopefully, google guys would fixed this soon. \n. ",
    "KopierKatze": "This issue bugs me as well. On my Nexus 4, the resolution should be 1280x768. Logcat reports 1196x718. The app starts normally and works, but the Views for the left and right eye are very small.\nI tried manually setting the size of the cardboardView in onCreate and i tempered with the topMargin in CardboardOverlayEyeView, since it is 256. So far, i haven't seen any changes in the Layout.\nkchodorow's solution didn't work for me. \nDoes anyone have another solution?\n. ",
    "polymesh": "I am getting the same \"surface...does not match the screen size\" error on a TF201 (Transformer Prime) which is 1280x800 but for some reason it is only able to get 1280x752. I don't expect people to use a cardboard app on their tablet, but I do expect it to work on a variety of devices. This is concerning...\nWorks fine for my Nexus4.\n. Now that I think about it, the TF201 has a bar at the bottom (software buttons) which cannot be hidden and annoyingly takes up screen real estate. So it seems like whatever CardboardActivity is doing to get the width and height of the device is not getting the USABLE width and height. I remember I had to account for this in a previous app. Looking at my code, I got my dimensions from EGL, I think there is something equivalent that can be called on the view.\nI can now verify that I get rendering happening after doing this (discovered by kchodorow):\n// Manually set the screen size.\nDisplay display = getWindowManager().getDefaultDisplay();\nScreenParams params = new ScreenParams(display);\nparams.setWidth(/* desired USABLE width /);\nparams.setHeight(/ desired USABLE height */);\nview.updateScreenParams(params);\nnote the \"USABLE\" addition above. I misunderstood the purpose of calling updateScreenParams(), it is not to give the actual dimensions of your screen, but the usable dimensions so it matches the drawing surface determined by the cardboard API (it should be getting the usable width/height from EGL internally me thinks).\nNow having said this, my eyes currently render side by side, don't take up full real estate, and the contents are rendered sideways... but those are different problems. For the orientation problem, here's something else this API should be doing (accounting for different device accelerometer orientations):\nhttp://stackoverflow.com/questions/5877780/orientation-from-android-accelerometer\n. +1\n. ",
    "jitsuCM": "Follow these to make sure everything goes fine:\n1) Download and install cardboard app from the playstore. It creates some data that the lib would want to read later.\n2) Make sure you have the following two options in your manifest:\n        \nOtherwise it will nag you about the mismatched screen size.\n. ",
    "nathanmartz": "Closing super old thread.\n. Closing super old thread.\n. Closing very old thread.\n. Closing very old thread.\n. We appreciate the feedback, but closing this as it's not really an \"issue\" with the Cardboard SDK.\n. Closing very old thread.\n. Closing old and likely fixed thread. Please reopen if issue is still relevant.\n. Please post \"how do I\" questions to our stack overflow page. This site is just for bug reporting in the SDK.\n. Bug is long fixed. Closing.\n. Thanks for the note. Is there an actual fix here? The linked repo is just a clone of a decompiled SDK as far as I can tell.\n. FYI that we think this is an actual SDK bug. Looking into a fix for next release.\n. We test extensively on that device. Please try updating to 0.6.0. Reopen the thread if you still have issues.\n. We've worked around getting bad DPI issues, so this should be fixed for now. Please reopen if not.\n. Closing old thread. Please reopen if there are still issues w/ latest SDK.\n. Thanks for the feedback but our goal is to improve head tracking, not disable it.\n. Closing thread due to lack of response from OP.\n. How to questions should be posted on stack overflow. Closing this issue.\n. This is by design so that we don't fragment the user experience.\n. The Cardboard SDK implements the official WWGC spec, which requires the viewer provide a single button input. The getHasMagnet function is leftover and may be removed in a future version of the SDK.\n. Sorry, but running on GearVR requires using their SDK, which only they distribute. If you would like them to support Cardboard apps, that would be a great request to submit to Samsung and/or Oculus.\n. Hi, Ben. We don't have any plans to support auto-detection like this, as it would just tell users what they already know - the app doesn't work on their device. The correct approach is to use your app manifest (we supply a sample one in the Cardboard SDK) as well as the whitelist/blacklist features in the Play store to ensure you only run on compatible devices.\n. Sorry, but we can't provide legal advice on whether the cardboard SDK is\ncompliant or not with the license of another product.\nOn Sun, Feb 7, 2016, 9:53 AM motorsep notifications@github.com wrote:\n\nFrom the developer of the engine: \"The sdk is apache 2, but the GPL covers\nthe entire work, including any libraries. You can do what you want with the\nheaders Google provides, but that's not the source, and thus not\ncompatible.\"\nI am guessing he is talking about whatever comes in .jar with SDK or any\nlibs that come in object form with SDK.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/52#issuecomment-181063199\n.\n. Which SDK are you using? This is somewhat better in 0.6.0.\n\nAlso, the fastest solution is to implement Vertex Distortion\n. Please check out the Treasure Hunt sample, as it shows how to pull all of those pieces together.\n. I'm sorry but I don't understand this question. Can you be more specific about your use case and the problem you are trying to solve?\n. We don't plan to provide that exactly, but you can use the existing widgets and add your own UI on top of them if you like.\n. Thanks for the feedback, but we need to keep this focused on actual issues :)\n. Thank you for the bug report!\n. These are important to the Cardboard ecosystem and are not designed to be hidden.\n. There's not much we can do about that. It means that the GPU simply has very little memory to work with.\n. Is this on a 4.4 phone? If so, it's a known issue and we are working on a\nfix.\nOn Mon, Apr 18, 2016, 1:36 AM sophietsen8634 notifications@github.com\nwrote:\n\nAfter I have clicked the cardboard button on the VrVideoView and back to\nthe previous activity, a black line shown on the screen and never disappear.\n[image: screenshot_2016-04-18-12-18-48]\nhttps://cloud.githubusercontent.com/assets/10460670/14598151/8df36b0c-0583-11e6-83d7-b58949a323df.png\n[image: screenshot_2016-04-18-12-19-03]\nhttps://cloud.githubusercontent.com/assets/10460670/14598152/8df3f6e4-0583-11e6-8fb4-a5af5a185cce.png\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/74\n. I think so, yes.\n. We're looking into a fix for our next update.\n\nOn Sat, May 7, 2016 at 5:04 AM, Adam J. notifications@github.com wrote:\n\nunfortunately +1 for Galaxy S7 and Android 6.0.1. Is there any workaround?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/75#issuecomment-217631676\n. We can repro this issue here and are working on a fix. We think it's a\ndriver bug of some sort.\n\nOn Mon, May 23, 2016 at 6:59 PM, James Masterman notifications@github.com\nwrote:\n\nI am also seeing this issue on a Samsung S7 running Android 6.0.1. Screen\nis black or sometimes flickers dark green on VrVideoView player. I can hear\nthe sound, just no video. Same app has no problems on Nexus 6P or Nexus 5.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/75#issuecomment-221146586\n. This is definitely an important bug that we are tracking and working on\nfixing internally. Hopefully we'll have something for our next release in\nearly July.\n\nOn Wed, Jun 22, 2016 at 6:06 PM, Capture.Direct notifications@github.com\nwrote:\n\nMy Samsung Galaxy S2 8 inch tablet updated itself to Android 6.0.1 this\nmorning and I now see the same issue on it (everything worked fine before\nthe update).\nI'm looking forward to the fix for this. Thank you to the Google devs for\nyour responsivness on this issue so far.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/75#issuecomment-227922273,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ANamfm-41Eey40jqADjo7GJeby2aaNOVks5qOdwpgaJpZM4IM8rg\n.\n. Thanks!\n. Most likely that video is too high res for the older phones to decode. Some\nolder phones can only do up to 1080p.\n\nOn Thu, Apr 28, 2016, 6:28 AM Willian Rodriguez notifications@github.com\nwrote:\n\nWhen i try to play a 360 video using the widget VrVideoView in my samsung\ns4 (Android 5.1 and another with android 4.4) i get this error:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.Exynos.avc.dec, MediaFormat(1, video/avc, -1,\n1821804, 3840, 1920, 0, 1.0, -1, -1, null, 60000000, false, -1, -1, -1, -1)\nHowever in my samsung s6 works fine\nFull stack trace:\n11:56:27.636 20688-21125/py.com.vrex.vrexplayer I/ACodec: [] Now\nuninitialized\n04-28 11:56:27.666 20688-21166/py.com.vrex.vrexplayer I/OMXClient: Using\nclient-side OMX mux.\n04-28 11:56:27.736 20688-21166/py.com.vrex.vrexplayer E/ACodec:\nconfigureCodec multi window instance fail appPid : 20688\n04-28 11:56:27.741 20688-21166/py.com.vrex.vrexplayer E/ACodec:\n[OMX.Exynos.avc.dec] configureCodec returning error -38\n04-28 11:56:27.741 20688-21166/py.com.vrex.vrexplayer E/ACodec:\nsignalError(omxError 0x80001001, internalError -2147483648)\n04-28 11:56:27.741 20688-21165/py.com.vrex.vrexplayer E/MediaCodec: Codec\nreported err 0x80001001, actionCode 0, while in state 3\n04-28 11:56:27.741 20688-21125/py.com.vrex.vrexplayer E/MediaCodec:\nconfigure failed with err 0x80001001, resetting...\n04-28 11:56:27.746 20688-21166/py.com.vrex.vrexplayer I/ACodec:\n[OMX.Exynos.avc.dec] Now uninitialized\n04-28 11:56:27.746 20688-21125/py.com.vrex.vrexplayer I/ACodec: [] Now\nuninitialized\n04-28 11:56:27.751 20688-21166/py.com.vrex.vrexplayer I/OMXClient: Using\nclient-side OMX mux.\n04-28 11:56:27.791 20688-21125/py.com.vrex.vrexplayer\nE/ExoPlayerImplInternal: Internal track renderer error.\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.Exynos.avc.dec, MediaFormat(1, video/avc, -1,\n1821804, 3840, 1920, 0, 1.0, -1, -1, null, 60000000, false, -1, -1, -1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.notifyAndThrowDecoderInitError(MediaCodecTrackRenderer.java:414)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:400)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:766)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:524)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:507)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:434)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:145)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.Exynos.avc.dec, MediaFormat(1, video/avc, -1,\n1821804, 3840, 1920, 0, 1.0, -1, -1, null, 60000000, false, -1, -1, -1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:400)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:766)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:524)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:507)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:434)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:145)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by: android.media.MediaCodec$CodecException: Error 0x80001001\nat android.media.MediaCodec.native_configure(Native Method)\nat android.media.MediaCodec.configure(MediaCodec.java:577)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.configureCodec(MediaCodecVideoTrackRenderer.java:328)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:389)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:766)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:524)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:507)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:434)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:145)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n04-28 11:56:27.791 20688-20688/py.com.vrex.vrexplayer\nE/VrVideoPlayerInternal: 234830220.onPlayerError\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.Exynos.avc.dec, MediaFormat(1, video/avc, -1,\n1821804, 3840, 1920, 0, 1.0, -1, -1, null, 60000000, false, -1, -1, -1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.notifyAndThrowDecoderInitError(MediaCodecTrackRenderer.java:414)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:400)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:766)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:524)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:507)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:434)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:145)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.Exynos.avc.dec, MediaFormat(1, video/avc, -1,\n1821804, 3840, 1920, 0, 1.0, -1, -1, null, 60000000, false, -1, -1, -1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:400)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:766)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:524)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:507)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:434)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:145)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by: android.media.MediaCodec$CodecException: Error 0x80001001\nat android.media.MediaCodec.native_configure(Native Method)\nat android.media.MediaCodec.configure(MediaCodec.java:577)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.configureCodec(MediaCodecVideoTrackRenderer.java:328)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:389)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:766)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:334)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:524)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:507)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:129)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:434)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:213)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:145)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/80\n. Cardboard rendering changes depending on the device you are using and the viewer you have setup. It's not necessarily supposed to always be full screen on every phone, but to look good when you view it in VR.\n. Thanks for posting the images. You said that you saw it on a Nexus device,\ntoo? If so, which one? Also, which viewer do you have paired?\n\nOn Fri, May 6, 2016, 1:02 AM bd5155716 notifications@github.com wrote:\n\n@nathanmartz https://github.com/nathanmartz please see above images. It\nis not what I want.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/83#issuecomment-217374911\n. OK. Odd. Can you send an image of the Nexus 4, too? And can you confirm\nthat it actually looks wedding when you view the screen through a VR viewer?\n\nOn Fri, May 6, 2016, 1:15 AM bd5155716 notifications@github.com wrote:\n\n@naokirodion https://github.com/naokirodion Thank you for your reply.\nIt is nexus 4. In Samsung galaxy, it looks good.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/83#issuecomment-217377809\n. Yeah. We rely on the phone to report a proper DPI but many do not. We have an internal database of overrides, but it doesn't have that device in it.\n\nI'm very surprised that you are seeing the problem on the Nexus 4. That's a standard test device for us.\n. Hi, Leonardo. Sorry for the confusion. The current version requires you\ninclude the YT 360 metadata (\nhttps://support.google.com/youtube/answer/6178631?hl=en) for stereo. We'll\nchange the API in a future release to let you specify whether the content\nis mono or stereo, but for now this will work for you.\n-Nathan\nOn Fri, May 13, 2016 at 5:00 AM, Leonardo Cavaletti \nnotifications@github.com wrote:\n\nDeveloping on a Samsung Galaxy S5 with Android 4.4.2\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/85#issuecomment-219024286\n. We're looking into this now. We'll post more info here shortly. Sorry for\nthe inconvenience!\n\nOn Thu, May 19, 2016, 2:14 AM andna notifications@github.com wrote:\n\nLG G2 also reported with trobule to install the apk.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/88#issuecomment-220270129\n. Great! Was due to a build process bug. Shouldn't happen again.\n. Sorry, we don't support swapping media players.\n\nOn Thu, May 19, 2016, 2:13 AM Millertoken notifications@github.com wrote:\n\ncan i use other mediaplayer to paly videos on VideoWidget?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/89\n. There is no Vulkan support in our sdks currently but we definitely agree\nthat there's a ton of potential for it to improve performance in VR. We'll\nbe looking into adding Vulkan support in a later SDK update, but no hard\ndates to talk about right now.\n\nOn Thu, May 19, 2016, 4:30 AM Oscar Barenys notifications@github.com\nwrote:\n\nHi,\ndon't know if a stupid question..\nbut just browsing the code can't search any reference to Vulkan support..\nas Vulkan may allow even better support for VR games asking if Google VR\nNDK SDK allows or not Vulkan as a graphics API?\nif not asking if an app supporting Vulkan+Google VR Daydream will be\nposible via updated Google VR SDK or also will require platform updates?\ni.e. a new version of Android maybe Android O next year..\nthanks..\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/90\n. There is no way to do it in Android presently, but we'll look into that for\nthe next release.\n\nOn Thu, May 19, 2016 at 10:11 AM, Tom Renn notifications@github.com wrote:\n\nThe VR View for the web\nhttps://developers.google.com/vr/concepts/vrview#control_parameters has\na start_yaw control parameter. I don't see a way to do it in the 0.8.0\nrelease. Is there a way to achieve this or plans to add it in a future\nrelease?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/91\n. We're looking into that now and will have more info in a bit.\n\nOn Mon, May 23, 2016 at 6:01 PM, Mikul notifications@github.com wrote:\n\n@nathanmartz https://github.com/nathanmartz ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/92#issuecomment-221139050\n. We are only supporting one daydream controller, which is by design.\n\nOn Sat, May 21, 2016, 10:05 PM JTheCoder notifications@github.com wrote:\n\nFrom the Google IO 2016 keynotes, seems Google VR is supporting multiple\ninput controllers , but current ControllerManager seems only support one\ncom.google.vr.sdk.controller , is that a missing feature?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/95\n. I'm sorry but Eclipse is no longer supported. \n. The Google VR SDK is only for Cardboard and Daydream.\n. VR Video View does not currently support spatial audio as part of the movie payload. However, the SDK includes APIs for spatial audio as well as examples for how to use them. You can combine these with a Video View.\n. Looks like this is resolved.\n. HDMI output is not a supported use case for our SDK.\n. We don't currently plan to add SxS stereo support as we are standardizing on over/under for 360 stereo.\n. You can find the license in the LICENSE.md file.\n. Sorry, leewp, but we generally can't make promises around specific release timing here.\n. We need to keep GitHub issues specific to actual bugs in the SDK. For questions like this, please post on Stack Overflow.\n. Please post questions \"how to\" like this to StackOverflow. We need to keep GitHub Issues focused on actual bugs.\n. This is very much intentional. User studies suggested that without this screen users often don't know what to do.\n. It should only appear on the first run, then you pair a viewer, then you should not see it again (unless you uninstall and reinstall the app, possibly including development pushes).\n. By \"tutorial\" you mean the \"place your phone into the cardboard\" or the\n\"please scan a cardboard\" screen? If it's the former, that's by design.\n\nOn Wed, Aug 3, 2016 at 11:08 PM, xdf103 notifications@github.com wrote:\n\nI have two activities, a play list activity (a simple ListView) and a play\nactivity (using GvrView). Every time I go from the play list activity to\nthe play activity, I see the tutorial screen, e.g. list activity -> play\nactivity (tutorial screen appears) -> go back to list activity -> play\nactivity (tutorial screen appears again) . How do I configure it to appear\nonly once?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/118#issuecomment-237461261,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfrPY8bEBBsT-0ijLgNbcaite1T05ks5qcYHigaJpZM4I3_Rl\n.\n. No. See my original comments.\n. Hmm. That seems bad. The transition screen should only appear when entering\nVR, not exiting it. We'll look into this...\n\nOn Wed, Aug 10, 2016, 1:42 AM xdf103 notifications@github.com wrote:\n\nWe encountered another problem with \"place your phone into the cardboard\"\nscreen. Our workflow is list activity -> play activity -> back to list\nactivity. For the 2nd step play activity -> back to list activity, we now\nhave to press the back button twice. Press once, it will show the \"place\nyour phone into the cardboard\" again and continue to the play activity\nagain. Only after two presses, it will go back to the previous activity\n(the list activity). This is inconvenient and seems illogical. Is there\nanyway to fix this?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/118#issuecomment-238790045,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfhxvfZ1eeiYTyzp13TogrzeKkTatks5qeYDmgaJpZM4I3_Rl\n.\n. The general idea of the transition screen is that it should appear every time the user goes from 2D into VR to ensure users understand how to insert their phone in the viewer. You'd be amazed at how often people misunderstand this idea, turn things the wrong way, etc. The screen disappears as soon as the phone is in landscape, so it's not actually obtrusive IMHO. Are you seeing the screen during VR->VR transitions rather than 2D->VR?\n. They'll be on the site by the end of the week.\n\nOn Thu, Jul 7, 2016 at 4:10 AM, Rik Heijdens notifications@github.com\nwrote:\n\nThanks! Where can I find release notes for 0.8.5? They do not appear to be\non the release notes page (yet).\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/120#issuecomment-231049319,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ANamftMdSb2NUJdsRBOOBXjp43n5gC-Aks5qTN6ngaJpZM4I4bq1\n.\n. It does not and we have no plans to as it's effectively a proprietary Adobe format. We did just release support for HLS.\n. You can try the new HLS support we added in 0.8.1. That may manage memory more efficiently as it streams in the content.\n. You would need to use the lower level GVRView APIs and write OpenGL code to render the buttons. You can't use regular android UI elements in VR.\n. Thanks for posting this workaround. The demand is pretty obvious for programatic control of view modes, so we're planning to add that in the next release.\n. So, you're saying that HLS \"just works\"? If so, then I highly recommend HLS.\n. There is not currently but it's a popular request. We're planning to add it for a release later this summer.\n. You'll need to implement that yourself by rotating the camera based on the\nhead orientation.\n\nOn Tue, Jun 28, 2016, 7:12 PM Richard Hsu notifications@github.com wrote:\n\nHi,\nI'm using a GVRView to display an image but the image does not pan since\nit is not a VRPanorama View. Is there a way to add that effect in the\nGVRView? The reason I cannot use the original VRPanorama view is that I\nwanted to draw buttons on the view which required using GVRView and the\nOpenGL library.\nThanks.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/136, or mute the\nthread\nhttps://github.com/notifications/unsubscribe/ANamfutTbARpPbowjmk1E5cMt3UHBykZks5qQdSPgaJpZM4JAtSe\n.\n. VR view only supports 360 images. They can be mono or stereo. If they are mono, they should be 2:1 aspect ratio. 1:1 for stereo images. You can find more on the specs here: developers.google.com/vr/concepts/vrview\n. Hi. For \"how to\" questions, please use sites like Stack Overflow. We need to keep this space focused on actual bugs in the SDK.\n. Hi. What errors do you see in the logcat?\n\nOn Tue, Jul 5, 2016 at 2:12 AM, Eephone Xu notifications@github.com wrote:\n\nWhen I run the sample called simplevideowidget on Huawei Devices.\nI could get some audio output from my phone but the VrVideoView is still\nblack!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/142#issuecomment-230426770,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ANamfnnbPtfiEABYqqwda6llSjsVzybPks5qSh_3gaJpZM4JE6dD\n.\n. There is not currently, but it's a popular request.\n. Hi. We do not support YT as a source in VR view. You need to host the content yourself.\n. It looks like you have a file that the device is unable to read. Can you\nplay this stream on device outside if VR View? If not, you need to dig more\ninto encoding for HLS, which isn't something can really provide support for\nhere.\n\nOn Sat, Aug 6, 2016, 12:22 AM ashwin-sectorqube notifications@github.com\nwrote:\n\nOn Loading .m3u8 file i am getting error like this.... please help\n08-06 12:48:06.611 11657-11671/com.google.vr.sdk.samples.simplevideowidget\nE/ExoPlayerImplInternal: Internal track renderer error.\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException:\nNone of the available extractors (WebmExtractor, FragmentedMp4Extractor,\nMp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor,\nOggExtractor, PsExtractor, WavExtractor) could read the stream.\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:263)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:149)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.incrementalPrepareInternal(ExoPlayerImplInternal.java:275)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:205)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:207)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by:\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException:\nNone of the available extractors (WebmExtractor, FragmentedMp4Extractor,\nMp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor,\nOggExtractor, PsExtractor, WavExtractor) could read the stream.\nat\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractorHolder.selectExtractor(ExtractorSampleSource.java:899)\nat\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractingLoadable.load(ExtractorSampleSource.java:829)\nat\ncom.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:209)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\nat\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\n08-06 12:48:06.612 11657-11657/com.google.vr.sdk.samples.simplevideowidget\nE/VrVideoPlayerInternal: 9750259.onPlayerError\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException:\nNone of the available extractors (WebmExtractor, FragmentedMp4Extractor,\nMp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor,\nOggExtractor, PsExtractor, WavExtractor) could read the stream.\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:263)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:149)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.incrementalPrepareInternal(ExoPlayerImplInternal.java:275)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:205)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:207)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by:\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException:\nNone of the available extractors (WebmExtractor, FragmentedMp4Extractor,\nMp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor,\nOggExtractor, PsExtractor, WavExtractor) could read the stream.\nat\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractorHolder.selectExtractor(ExtractorSampleSource.java:899)\nat\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractingLoadable.load(ExtractorSampleSource.java:829)\nat\ncom.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:209)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\nat\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\n08-06 12:48:06.620 11657-11657/com.google.vr.sdk.samples.simplevideowidget\nE/SimpleVrVideoActivity: Error loading video:\ncom.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException:\nNone of the available extractors (WebmExtractor, FragmentedMp4Extractor,\nMp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor,\nOggExtractor, PsExtractor, WavExtractor) could read the stream.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/145#issuecomment-238010447,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfiDcx4hIvFOVUX3JQwk4BCxC293hks5qdDY2gaJpZM4JGVkf\n.\n. Very likely there is an encoding issue in that video that for some reason\nmost phones handle but your Google Glass decoder has an issue with.\n\nOn Wed, Jul 6, 2016 at 7:46 PM, Rupayan Neogy notifications@github.com\nwrote:\n\nGoogle Glass. I don't think I would - as I said, it works perfectly on\nother android devices. I'll try and take a video soon.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/146#issuecomment-230965214,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ANamfmyO-_izTYfQCdqLl5d541jX1Efiks5qTGhxgaJpZM4JGY8Z\n.\n. We're actually going to be removing support for the magnet trigger in the next release or the one after, so that will hopefully fix your problem :)\n. The best solution would be to use the built in android screen shot tools. We do not plan to add frame capture to the GVR SDK.\n. That's a standard Android question. A bit of web searching should get you sorted out.\n. Please be more specific. It's not clear what problem you need help with.\n. That means that whatever codec you used for that video isn't supported on the E5. If you want to support that phone you need to re-encode with a codec that it supports.\n. Many hardware decoders require video whose dimensions are divisible by 16.\nSome phones can't handle resolutions higher than 1080p.\n\nOn Mon, Jul 11, 2016, 8:22 PM Ahmed Hegazy notifications@github.com wrote:\n\n@nathanmartz https://github.com/nathanmartz\nThe codec is supported by the device. Can it be a resolution's issue? It's\ntoo big to be handled by the device!\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Shark 3d 360 - panocam3d.com.mp4':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 19529854\n    compatible_brands: mp42isom\n    creation_time   : 2013-12-10 11:56:33\n  Duration: 00:00:40.41, start: 0.000000, bitrate: 11144 kb/s\n    Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 192 kb/s (default)\n    Metadata:\n      creation_time   : 2013-12-10 11:56:33\n      handler_name    : Sound Media Handler\n    Stream #0:1(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv), 2300x2300 [SAR 1:1 DAR 1:1], 10950 kb/s, 30 fps, 30 tbr, 30 tbn, 60 tbc (default)\n    Metadata:\n      creation_time   : 2013-12-10 11:56:33\n      handler_name    : Video Media Handler\n      encoder         : AVC Coding\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/152#issuecomment-231927525,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ANamfmgEGaooYb76-JON8qYCKMMViqo8ks5qUwh7gaJpZM4JI7OB\n.\n. There is no special support for 180 degree video. You can make a 360 video that is black for the back half if you like, or you can implement your own support using the lower level GVR View.\n. Closing as this is a dupe of your other recent questions.\n. What version of the SDK are you using? I believe we fixed this in 0.8.1 or 0.8.5.\n. Thanks for the bug report. What phone and OS are you using?\n. Thanks again for all of the detail. This bug is in our internal tracker\nnow, but no firm ETA on a fix.\n\nOn Wed, Jul 13, 2016 at 11:38 PM, yubaolinfish notifications@github.com\nwrote:\n\n[image: device-2016-07-14-143233]\nhttps://cloud.githubusercontent.com/assets/10411717/16830302/9cf46fac-49d0-11e6-826d-5f05cabf6a33.png\nThanks.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/157#issuecomment-232571984,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ANamfhdw53dLyzXMRnH6q5rhCS6VDMXTks5qVdl9gaJpZM4JMDOY\n.\n. Thanks for the suggestions. Regarding the gear options, I recommend you implement them in VR or add an additional 2D button yourself. We are unlikely to add them anytime soon.\n\nRegarding disabling elements of the UI, we've added more info in this very similar Unity thread: https://github.com/googlevr/gvr-unity-sdk/issues/266\n. This space is just for issues with the SDK. For \"how to\" questions please use Stackoverflow.\n. Thanks for the bug report. We caught this ourselves and are in the process\nof fixing it.\nOn Fri, Jul 15, 2016 at 8:28 PM, Sebastian Kagemann \nnotifications@github.com wrote:\n\nThe Controller Paint APK is linked twice here\nhttps://developers.google.com/vr/concepts/dev-kit-setup; however it now\nseems to missing from the repo.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/162, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfgC4bW6h8ZrbxL1gUmebuSCnKcMjks5qWE_igaJpZM4JN6OS\n.\n. Which version of the SDK are you using? I believe this was fixed in 0.8.5.\n\nOn Wed, Jul 20, 2016 at 8:41 AM, basselAlshK notifications@github.com\nwrote:\n\nI'm using the Cardboard SDK to play 360 videos on my Samsung Galaxy s7\nedage, Android 6.0.1. I am trying the example provided with the SDK, I saw\nthe Issue:\n75 https://github.com/googlevr/gvr-android-sdk/issues/75\nit seems that the same problem happens again with S7 and this is the\nMonitor Log:\n07-20 17:30:21.943 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nD/ContextRelationManager: ContextRelationManager() : FEATURE_ENABLED=true\n07-20 17:30:21.943 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nD/RelationGraph: garbageCollect()\n07-20 17:30:21.953 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nW/ResourcesManager: getTopLevelResources:\n/data/app/com.google.vr.sdk.samples.simplevideowidget-2/base.apk / 1.0\nrunning in com.google.vr.sdk.samples.simplevideowidget rsrc of package\ncom.google.vr.sdk.samples.simplevideowidget\n07-20 17:30:21.953 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: Inside getClassLibPath + mLibMap{0=, 1=}\n07-20 17:30:21.963 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nD/ResourcesManager: For user 0 new overlays fetched Null\n07-20 17:30:21.963 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: Inside getClassLibPath caller\n07-20 17:30:21.983 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nD/InjectionManager: InjectionManager\n07-20 17:30:21.983 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nD/InjectionManager: fillFeatureStoreMap\ncom.google.vr.sdk.samples.simplevideowidget\n07-20 17:30:21.993 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: Constructor\ncom.google.vr.sdk.samples.simplevideowidget, Feature store :{}\n07-20 17:30:21.993 25643-25643/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: featureStore :{}\n07-20 17:30:22.143 25643-25651/com.google.vr.sdk.samples.simplevideowidget\nI/art: System.exit called, status: 1\n07-20 17:30:22.143 25643-25651/com.google.vr.sdk.samples.simplevideowidget\nI/AndroidRuntime: VM exiting with result code 1, cleanup skipped.\n07-20 17:30:34.813 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/ContextRelationManager: ContextRelationManager() : FEATURE_ENABLED=true\n07-20 17:30:34.823 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/RelationGraph: garbageCollect()\n07-20 17:30:34.823 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nW/ResourcesManager: getTopLevelResources:\n/data/app/com.google.vr.sdk.samples.simplevideowidget-1/base.apk / 1.0\nrunning in com.google.vr.sdk.samples.simplevideowidget rsrc of package\ncom.google.vr.sdk.samples.simplevideowidget\n07-20 17:30:34.823 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: Inside getClassLibPath + mLibMap{0=, 1=}\n07-20 17:30:34.823 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/ResourcesManager: For user 0 new overlays fetched Null\n07-20 17:30:34.833 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: Inside getClassLibPath caller\n07-20 17:30:34.833 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/InjectionManager: InjectionManager\n07-20 17:30:34.833 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/InjectionManager: fillFeatureStoreMap\ncom.google.vr.sdk.samples.simplevideowidget\n07-20 17:30:34.833 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: Constructor\ncom.google.vr.sdk.samples.simplevideowidget, Feature store :{}\n07-20 17:30:34.833 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: featureStore :{}\n07-20 17:30:34.843 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nW/ResourcesManager: getTopLevelResources:\n/data/app/com.google.vr.sdk.samples.simplevideowidget-1/base.apk / 1.0\nrunning in com.google.vr.sdk.samples.simplevideowidget rsrc of package\ncom.google.vr.sdk.samples.simplevideowidget\n07-20 17:30:34.843 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/RelationGraph: garbageCollect()\n07-20 17:30:34.903 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/ExoPlayerImpl: Init 1.5.7\n07-20 17:30:34.993 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/SimpleVrVideoActivity: Intent is not ACTION_VIEW. Using the default video.\n07-20 17:30:34.993 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/Activity: performCreate Call Injection manager\n07-20 17:30:34.993 25859-25913/com.google.vr.sdk.samples.simplevideowidget\nI/SphericalMetadataMP4: Located spherical metadata:\n<?xml version=\"1.0\"?> xmlns:rdf=\"\nhttp://www.w3.org/1999/02/22-rdf-syntax-ns#\"\nxmlns:GSpherical=\"http://ns.google.com/videos/1.0/spherical/\n\">GSpherical:Sphericaltrue/GSpherical:SphericalGSpherical:Stitchedtrue\n/GSpherical:StitchedGSpherical:StitchingSoftwareSpherical Metadata Tool\n/GSpherical:StitchingSoftwareGSpherical:ProjectionTypeequirectangular\n/GSpherical:ProjectionTypeGSpherical:StereoModetop-bottom\n/GSpherical:StereoMode/rdf:SphericalVideo\n07-20 17:30:35.003 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nI/VrWidgetRenderer: Native renderer has just been destroyed. Dropping\nrequest.\n07-20 17:30:35.013 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: dispatchOnViewCreated > Target :\ncom.google.vr.sdk.samples.simplevideowidget.SimpleVrVideoActivity\nisFragment :false\n07-20 17:30:35.013 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nI/VrWidgetRenderer: Native renderer has just been destroyed. Dropping\nrequest.\n07-20 17:30:35.023 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/SecWifiDisplayUtil: Metadata value : SecSettings2\n07-20 17:30:35.023 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/ViewRootImpl: #1 https://github.com/googlevr/gvr-android-sdk/issues/1\nmView = com.android.internal.policy.PhoneWindow$DecorView{48a558 I.E......\nR.....ID 0,0-0,0}\n07-20 17:30:35.033 25859-25929/com.google.vr.sdk.samples.simplevideowidget\nD/OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\n07-20 17:30:35.033 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/AudioCapabilities: Unsupported mime audio/mpeg-L1\n07-20 17:30:35.033 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/AudioCapabilities: Unsupported mime audio/mpeg-L2\n07-20 17:30:35.033 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/AudioCapabilities: Unsupported mime audio/x-ms-wma\n07-20 17:30:35.033 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/AudioCapabilities: Unsupported mime audio/x-ima\n07-20 17:30:35.033 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile/level 32768/2 for video/mp4v-es\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.043 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/wvc1\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/x-ms-wmv\n07-20 17:30:35.053 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile/level 32768/2 for video/mp4v-es\n07-20 17:30:35.063 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/wvc1\n07-20 17:30:35.063 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/x-ms-wmv\n07-20 17:30:35.063 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/x-ms-wmv7\n07-20 17:30:35.063 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/x-ms-wmv8\n07-20 17:30:35.063 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/mp43\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.073 25859-25929/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xde7457c4\n07-20 17:30:35.073 25859-25929/com.google.vr.sdk.samples.simplevideowidget\nI/OpenGLRenderer: Initialized EGL, version 1.4\n[ 07-20 17:30:35.073 25859:25929 D/         ]\n                                                                                     ro.exynos.dss isEnabled: 0\n07-20 17:30:35.073 25859-25929/com.google.vr.sdk.samples.simplevideowidget\nD/mali_winsys: new_window_surface returns 0x3000, [1440x2560]-format:1\n07-20 17:30:35.083 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile/level 32768/2 for video/mp4v-es\n07-20 17:30:35.083 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b4c4\n07-20 17:30:35.093 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/mali_winsys: new_window_surface returns 0x3000, [1360x1000]-format:1\n07-20 17:30:35.093 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nW/art: Attempt to remove non-JNI local reference, dumping thread\n07-20 17:30:35.103 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b3ac\n07-20 17:30:35.113 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nW/DisplayListCanvas: DisplayListCanvas is started on unbinded RenderNode\n(without mOwningView)\n07-20 17:30:35.113 25859-25929/com.google.vr.sdk.samples.simplevideowidget\nD/libGLESv1: DTS_GLAPI : DTS is not allowed for Package :\ncom.google.vr.sdk.samples.simplevideowidget\n07-20 17:30:35.123 25859-25958/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:30:35.123 25859-25958/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:30:35.133 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nI/VideoCapabilities: Unsupported profile 4 for video/mp4v-es\n07-20 17:30:35.153 25859-25960/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:30:35.153 25859-25960/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:30:35.173 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: dispatchCreateOptionsMenu\n:com.google.vr.sdk.samples.simplevideowidget.SimpleVrVideoActivity\n07-20 17:30:35.173 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/InjectionManager: dispatchPrepareOptionsMenu\n:com.google.vr.sdk.samples.simplevideowidget.SimpleVrVideoActivity\n07-20 17:30:35.173 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/ViewRootImpl: MSG_RESIZED_REPORT: ci=Rect(0, 96 - 0, 0) vi=Rect(0, 96 -\n0, 0) or=1\n07-20 17:30:35.193 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/Timeline: Timeline: Activity_idle id: android.os.BinderProxy@5017e5a\nhttps://github.com/android.os.BinderProxy/gvr-android-sdk/commit/5017e5a\ntime:4830975\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unsupported mime video/sorenson\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706433 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.203 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nW/VideoCapabilities: Unrecognized profile 2130706434 for video/avc\n07-20 17:30:35.223 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [] Now uninitialized\n07-20 17:30:35.223 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/OMXClient: Using client-side OMX mux.\n07-20 17:30:35.223 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Loaded\n07-20 17:30:35.243 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: >>>UHQA ACodec::configureCodec : 10027000, 15000000\n07-20 17:30:35.243 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: >>> getPortFormat 16, OMX.SEC.aac.dec\n07-20 17:30:35.243 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Loaded->Idle\n07-20 17:30:35.253 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Idle->Executing\n07-20 17:30:35.253 25859-25897/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [] Now uninitialized\n07-20 17:30:35.263 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Executing\n07-20 17:30:35.263 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/OMXClient: Using client-side OMX mux.\n07-20 17:30:35.273 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Loaded\n07-20 17:30:35.273 25859-25996/com.google.vr.sdk.samples.simplevideowidget\nI/MediaCodec: [OMX.Exynos.avc.dec] setting surface generation to 26479617\n07-20 17:30:35.273 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: can't find wfdsink-exynos-enable\n07-20 17:30:35.283 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Loaded->Idle\n07-20 17:30:35.283 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nD/SurfaceUtils: set up nativeWindow 0xd9b6e808 for 1920x1080, color 0x105,\nrotation 0, usage 0x2900\n07-20 17:30:35.283 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] configureOutputBuffersFromNativeWindow\nsetBufferCount : 7, minUndequeuedBuffers : 5\n07-20 17:30:35.293 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Idle->Executing\n07-20 17:30:35.293 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: >>> getPortFormat 16, OMX.SEC.aac.dec\n07-20 17:30:35.303 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:30:35.313 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now handling output port settings change\n07-20 17:30:35.313 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nW/AHierarchicalStateMachine: Warning message AMessage(what = 'omxI') = {\nint32_t type = 0\nint32_t event = 3\nint32_t data1 = 1\nint32_t data2 = 117440527\n} unhandled in root state.\n07-20 17:30:35.313 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nD/SurfaceUtils: set up nativeWindow 0xd9b6e808 for 1920x1088, color 0x105,\nrotation 0, usage 0x2900\n07-20 17:30:35.313 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] configureOutputBuffersFromNativeWindow\nsetBufferCount : 15, minUndequeuedBuffers : 5\n07-20 17:30:35.343 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:30:35.373 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/SimpleVrVideoActivity: Sucessfully loaded video 10027\n07-20 17:30:35.393 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.393 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nW/GLConsumer: [SurfaceTexture-1-25859-0] bindTextureImage: clearing GL\nerror: 0x500\n07-20 17:30:35.413 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.703 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.713 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.743 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.773 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.813 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.833 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.863 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.903 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.943 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:35.963 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/libEGL: eglInitialize EGLDisplay = 0xeeb9b324\n07-20 17:30:45.643 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] signalFlush\n07-20 17:30:45.643 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/9 output).\n[ 07-20 17:30:45.643  3147:25986 I/         ]\n                                                                             SAACD_COMP_Reset() in\n07-20 17:30:45.643 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Flushing\n07-20 17:30:45.643 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:30:45.643 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:30:45.643 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Executing\n07-20 17:30:45.653 25859-25996/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] signalFlush\n07-20 17:30:45.653 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/15 output).\n07-20 17:30:45.653 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Flushing\n07-20 17:30:45.663 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:30:45.663 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:30:45.663 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:30:55.883 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] signalFlush\n07-20 17:30:55.883 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/9 output).\n[ 07-20 17:30:55.883  3147:25986 I/         ]\n                                                                             SAACD_COMP_Reset() in\n07-20 17:30:55.893 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Flushing\n07-20 17:30:55.893 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:30:55.893 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:30:55.893 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Executing\n07-20 17:30:55.893 25859-25996/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] signalFlush\n07-20 17:30:55.893 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/15 output).\n07-20 17:30:55.893 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Flushing\n07-20 17:30:55.913 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:30:55.913 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:30:55.913 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:30:57.473 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nV/ActivityThread: updateVisibility : ActivityRecord{7627f8a\ntoken=android.os.BinderProxy@5017e5a\n{com.google.vr.sdk.samples.simplevideowidget/com.google.vr.sdk.samples.simplevideowidget.SimpleVrVideoActivity}}\nshow : true\n07-20 17:31:35.823 25859-25959/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:31:35.823 25859-25959/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:31:35.873 25859-25865/com.google.vr.sdk.samples.simplevideowidget\nW/art: Suspending all threads took: 24.720ms\n07-20 17:34:09.782 25859-25960/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:34:09.782 25859-25960/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:34:09.792 25859-25898/com.google.vr.sdk.samples.simplevideowidget\nD/mali_winsys: new_window_surface returns 0x3000, [1360x1000]-format:1\n07-20 17:34:09.812 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nI/Timeline: Timeline: Activity_idle id: android.os.BinderProxy@5017e5a\nhttps://github.com/android.os.BinderProxy/gvr-android-sdk/commit/5017e5a\ntime:5046019\n07-20 17:34:09.832 25859-25967/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:34:09.832 25859-25967/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:34:11.122 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/ViewRootImpl: ViewPostImeInputStage processPointer 0\n07-20 17:34:11.192 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nD/ViewRootImpl: ViewPostImeInputStage processPointer 1\n07-20 17:34:20.012 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] signalFlush\n07-20 17:34:20.012 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/9 output).\n[ 07-20 17:34:20.012  3147:25986 I/         ]\n                                                                             SAACD_COMP_Reset() in\n07-20 17:34:20.012 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Flushing\n07-20 17:34:20.022 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:34:20.022 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:34:20.022 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Executing\n07-20 17:34:20.022 25859-25996/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] signalFlush\n07-20 17:34:20.022 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/15 output).\n07-20 17:34:20.022 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Flushing\n07-20 17:34:20.032 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:34:20.032 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:34:20.032 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:34:30.262 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] signalFlush\n07-20 17:34:30.262 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/9 output).\n[ 07-20 17:34:30.262  3147:25986 I/         ]\n                                                                             SAACD_COMP_Reset() in\n07-20 17:34:30.262 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Flushing\n07-20 17:34:30.262 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:34:30.262 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:34:30.262 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Executing\n07-20 17:34:30.262 25859-25996/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] signalFlush\n07-20 17:34:30.262 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/15 output).\n07-20 17:34:30.272 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Flushing\n07-20 17:34:30.272 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:34:30.282 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:34:30.282 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:34:40.502 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] signalFlush\n07-20 17:34:40.502 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/9 output).\n[ 07-20 17:34:40.502  3147:25986 I/         ]\n                                                                             SAACD_COMP_Reset() in\n07-20 17:34:40.502 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Flushing\n07-20 17:34:40.502 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:34:40.502 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:34:40.502 25859-25980/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.SEC.aac.dec] Now Executing\n07-20 17:34:40.512 25859-25996/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] signalFlush\n07-20 17:34:40.512 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] ExecutingState flushing now (codec owns 0/5\ninput, 0/15 output).\n07-20 17:34:40.512 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Flushing\n07-20 17:34:40.512 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,0)\n07-20 17:34:40.522 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] FlushingState onOMXEvent(0,1,1)\n07-20 17:34:40.522 25859-25997/com.google.vr.sdk.samples.simplevideowidget\nI/ACodec: [OMX.Exynos.avc.dec] Now Executing\n07-20 17:34:41.632 25859-25859/com.google.vr.sdk.samples.simplevideowidget\nV/ActivityThread: updateVisibility : ActivityRecord{7627f8a\ntoken=android.os.BinderProxy@5017e5a\n{com.google.vr.sdk.samples.simplevideowidget/com.google.vr.sdk.samples.simplevideowidget.SimpleVrVideoActivity}}\nshow : true\n07-20 17:35:10.172 25859-25965/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n07-20 17:35:10.172 25859-25965/com.google.vr.sdk.samples.simplevideowidget\nI/System.out: (HTTPLog)-Static: isSBSettingEnabled false\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/167, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfnEZ07Q79wYGWzwTfZ2yE4mPWnBfks5qXkGggaJpZM4JQ6fY\n.\n. You can change he pano programmatically, but you have to write the logic that determines when to switch the pano and to what yourself.\n. Great!\n. The problem is that you are using a video size (2048x2048) that is not supported by the decoder on that card. As noted in the VrView docs, some decoders max out at 1080p.\n. When you say \"using monoscopic\" you mean when the video is encoded as mono or when you are viewing monoscopically (like in magic window mode)?\n. This smells like a bug in our code...\n. Hi. These forums are for bug reports in the SDK. \"how do\" questions should go to a place like Stack Overflow.\n. Not all developers want to use Unity. The iOS and Android SDKs support native developers.\n. I think this is the same format issue as your other post:\n\n07-25 12:54:16.214 7909-7909/ E/VrEventListener: 833001350.onLoadError: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: OMX.qcom.video.decoder.avc, MediaFormat(1, video/avc, -1, 966939, 4096, 2048, 0, 1.0, -1, -1, null, 49949900, false, -1, -1, -1, -1, -1)\n. We already provide API access for play/pause/stop/seek (iOS is the same but missing seek currently). What are you looking for that isn't there?\n. Looks like that file is encoded as a .ts which is not a supported format.\nUse mp4 or HLS instead.\nOn Tue, Jul 26, 2016 at 5:33 PM, yubaolinfish notifications@github.com\nwrote:\n\nHello, videoWidgetView.getDuration() euqal to -1 (simpleVideoWidget),\nthanks.\nuri:\nhttp://222.203.241.36:5001/nn_vod.ts?id=4215ca756d80e86bc4fe21710903b315&url_c1=56525f303732362e74732000&nn_ak=018234d1474795f92715562735fa1c6535&npips=219.232.84.70:5100&ncmsid=100187&ngs=5796bef7000c44e3b0d372ff635b1c27&nft=ts&nn_user_id=&ndi=&ndv=&nfm=&nst=iptv&nn_core_test=ganweijiang&nca=%26nn_cp%3d00030&nal=01f7be9657060745fb6057b10831952ed62c30f51b8057\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/175, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamftgXpphY6PdKHAHFmUcaXzfXJCzwks5qZqdZgaJpZM4JVubP\n.\n. What phone are you testing on? The phone has to have a gyro for head\ntracking to work.\n\nOn Sat, Jul 30, 2016 at 3:32 AM, Dylan Winn-Brown notifications@github.com\nwrote:\n\nHi All,\nI am using the SDK in my android app to display a 360 video with\nVRVideoView but don't seem to have the head tracking\nfunctionality...anyone else experienced this?\nThis is how I'm calling it:\n@Nullable\n        @Override\n        public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {\n            View view = inflater.inflate(R.layout.fragment_fourth, container,false);\n            videoWidgetView = (VrVideoView) view.findViewById(R.id.video_view);\n```\n        try {\n            videoWidgetView.loadVideoFromAsset(\"video.mp4\", null);\n            videoWidgetView.pauseVideo();\n        } catch(IOException ex) {\n            //Do nothing\n        }\n    Button mClickButton1 = (Button) view.findViewById(R.id.button);\n    mClickButton1.setOnClickListener(new View.OnClickListener() {\n        @Override\n        public void onClick(View view) {\n                videoWidgetView.playVideo();\n        }\n    });\n\n\n    setRetainInstance(true);\n    return view;\n}\n\n//Set title\npublic void onResume(){\n    super.onResume();\n    ((MainActivity) getActivity()).setActionBarTitle(\"VR Experience\");\n\n\n}\n\n```\nThanks in advance\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/176, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfj-ut_SWbg2hkTuixXAeN7-Vrkg2ks5qayhPgaJpZM4JYx0x\n.\n. In VR mode, it's expected that you'll have that padding and curve. The amount depends on your viewer and your phone, the goal is that it looks correct when viewed through the viewer, not just looking at the naked screen.\n. The problem may be that we don't have the Lenovo K3 note in our device database and it is reporting erroneous DPI information. What do you mean the phone has a \"VR mode feature\"? What does enabling this feature do? Also, which cardboard viewer are you using? Did you pair it (using the settings gear)?\n. PS - I just checked and the Lenovo K3 Note does not have a real gyro and so likely the head tracking will not be good. This doesn't have anything to do with your viewer problem, but thought I would pass along the information.\n. The next SDK update will include an ability to make the view fullscreen,\nbut it will still have the padding and curve as those are a function of the\ndistortion correction logic, which is not optional.\n\nOn Sat, Jul 30, 2016 at 9:30 PM, Rajesh Jadav notifications@github.com\nwrote:\n\ncan i make VrPanoramaview full screen and remove padding and curve?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/177#issuecomment-236409320,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfmx3i-hFGa0uewl33APMTaH3CLUqks5qbCT-gaJpZM4JYzUu\n.\n. I'm sorry but these issues are for bugs in the SDK. For more general \"how to\" questions, please use a site like StackOverflow.\n. I'm sorry but we can't give out legal advice here beyond what's already published in the license file.\n. Hi. This forum is for bugs with the SDK. For \"how to\" questions please post on StackOverflow or a similar resource.\n. Hi. Can you tell us a bit more about the specific kinds of effects you are trying to achieve?\n. If you're getting an error, please share them here if they are todo w/ the Media Controllers, otherwise create a new bug if the m3u8 errors are unrelated to adding Media Controllers.\n. We already answered that question.\n\n\"Just add media controller widgets on top of your View programmatically.\nPlease ask Stack Overflow for more details.\"\nOn Sat, Aug 6, 2016, 12:03 AM ashwin-sectorqube notifications@github.com\nwrote:\n\nSorry for that....I'm Sharing an attachment .... i need to set\nmediacontrollers on this screen...[image: Inline image 1] is that possible?\nOn Sat, Aug 6, 2016 at 12:26 PM, nathanmartz notifications@github.com\nwrote:\n\nIf you're getting an error, please share them here if they are todo w/\nthe\nMedia Controllers, otherwise create a new bug if the m3u8 errors are\nunrelated to adding Media Controllers.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\n<\nhttps://github.com/googlevr/gvr-android-sdk/issues/188#issuecomment-238009602\n,\nor mute the thread\n<\nhttps://github.com/notifications/unsubscribe-auth/ATpFKnQaXeiMrcW3l99GXPVf0G4i6Pitks5qdDAZgaJpZM4Jdgkj\n.\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/188#issuecomment-238009848,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfoUIyjp5VOkk3SYECHgiOLevgUTcks5qdDHVgaJpZM4Jdgkj\n.\n. I assume you are talking about VR view? If so, we have no plans to allow developers to remove that feature. Otherwise there's not very much \"VR\" to it at all :)\n. Which version of the SDK are you using? I thought we'd fixed this for the 1.0 release.\n. Thanks for the info. We'll address this info in a future update.\n. I'm sorry but we do not allow changing this element of VR View. If you want\ncomplete control over this UI you'll need to implement your own 360\nplayback on top of the low level GVRView class.\n\nOn Wed, Aug 10, 2016, 1:54 AM Ankit Gupta notifications@github.com wrote:\n\nI am able to play VR video in my application from internal storage as well\nas from remote URI. But what i need is i want to redirect my app users to\nmy desired link when they touch \"i\" or information view (You can have a\nlook at the view i am talking about) . Currently user is redirected to a\ndefault link which shows information about Google VR. I do not want this.\nPlease help me out of this issue. Thanks.\n[image: cropped]\nhttps://cloud.githubusercontent.com/assets/13251443/17545918/2a5a7134-5efd-11e6-9a46-e186ec3290a1.png\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/198, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfl4IZz7i56GC6FJZjUXlDPmYFm7Aks5qeYOggaJpZM4Jg35u\n.\n. Not currently but it's a feature we have discussed in the past. For now\nyou'd need to implement it yourself using head orientation (new to 0.9) and\nyou own hotspot logic.\n\nOn Wed, Aug 10, 2016, 5:32 AM kchecker notifications@github.com wrote:\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/199, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfu_iU0E1neYq2rJzSM0RJ32JC9Dpks5qebbjgaJpZM4JhDGS\n.\n. I am not, which is why we plan to add support for this (in VR view native and web).\n. This is just sample code, but thanks for the bug report.\n. Yes, this device doesn't have a gyro, which we require for head tracking. You should make a gyro required in your app manifest.\n. Thanks for the feature request. We have this in our internal tracker, but it's a ways out. Right now we're doing HLS because most people want both iOS and Android.\n. I'm sorry, but I don't really understand the request. Can you rephrase it?\n. In the latest SDK, you can procedurally change between fullscreen and VR and embedded. If you want to add your own buttons then you can do whatever you like and then programmatically change the viewing mode.\n. Yes, this is a bug on our side. We're working to get it fixed for the next release. Until then the workaround described here is the best.\n. What device is this on? There's a good chance the video is higher\nresolution than your phone can decode.\n\nOn Sun, Aug 21, 2016, 8:16 PM J.Chou notifications@github.com wrote:\n\nwhen load a vr video,i got the error message as follow\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc,\n-1, 1341518, 3840, 2160, 0, 1.0, -1, -1, null, 71137733, false, -1, -1, -1,\n-1, -1)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/210, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfpsg3lOqCDKOOlv3ufg0IS26LYZTks5qiRR7gaJpZM4Jpesv\n.\n. I don't have information on that device, but I bet if you make a 1080p or 720p version of this video, it will play.\n\nMy recommendation is that if you want maximum compatability, you need two versions of each video - one that is max res and another that is 1080p. You serve the 1080p one by default and the max res one on devices that you know can handle the higher resolution.\n. The 0.7 release notes are out of date. There currently is, by design, no way to disable the VR transition screen.\n. Just wanted to give an update here. We're discussing more internally, but I think we'll be able to be more flexible with transition screens in an upcoming release. The aperature (divider, gear, etc) will still be \"baked in\" but we'll be working to make them less obtrusive while in VR.\n. This is not currently supported, but is something we are looking into. What format is your spatial audio in currently?\n. We don't have any plans to support live video in VR View. You can roll your own 360 viewer using the lower level GVR View classes, though.\n. Hi, maneets. Good questions. We'll have official docs on them closer to launch, but for now here are your answers...\nYou're basically right that scanline racing is what lets you write directly to the font buffer. Async reprojection effectively requires scanline racing (otherwise it's not async) but it's the thing that shaves off additional latency by doing additional warping at the last possible moment. Although the concepts are technically independent, we encourage people to think of them as a single unit.\nBoth scanline racing and async reprojection are available in the 0.9 NDK. We explain how to use the API in this I/O talk: https://www.youtube.com/watch?v=9MIa1lviO_s or you can check out the NDK Treasure Hunt sample.\nScanline racing and async reprojection are not things that you can just \"turn on\". They require specific features in the kernel, drivers, OS, and SDK to work at all well. Also, high quality smartphone VR isn't just about these two technologies, but also an IMU that can provide high quality head tracking, a sufficiently powerful SoC, etc. That's why the Daydream ready spec exists, because most phones are not, in total, capable of delivering a high quality VR experience.\n. Async reprojection only works on Daydream ready phones, the first of which\ncome out later this year. You can find more information in this IO talk:\nhttps://www.youtube.com/watch?v=9MIa1lviO_s\nOn Sun, Aug 28, 2016 at 2:45 AM, xdf103 notifications@github.com wrote:\n\nHow to enable Async Reprojection? Is there any requirement for using it?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/219#issuecomment-242965757,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfmUW-7rq2GyY7vPB9LsRzlKjiz08ks5qkVi0gaJpZM4JttNs\n.\n. Thanks for the bug report. We'll look into it.\n. Closing double post.\n. These Issues are actually for reporting bugs in the SDK. For \"how do I\" type questions, please post to something like Stack Overflow.\n. We don't support zoom in/out as that's not really natural (or necessary) once you go into VR.\n. I'm sorry but we can't give legal advice here beyond what is included in the repository.\n. Can you share a few links to the videos that fail to un in cardboard mode? What phone are you using to test?\n. follower, thanks for calling this out. We'll fix on our side.\n. Hi, no. VrPanoramaView is not intended to be that customizable. If you want that level of control, you should use the lower level GVR View classes where you can do anything you like in OpenGL.\n. Hi. Bluetooth controllers are not a part of the official cardboard spec, so you we can't provide support for them.\n. Hi. We don't provide source for the gvr library.\n. This is exactly the right place to post this kind of issue. Thank you!\n\nOn Fri, Sep 16, 2016, 6:51 AM CAMOBAP notifications@github.com wrote:\n\nI faced with device specific issue for\nhttp://www.gsmarena.com/leeco_le_1s-8055.php\nNothing special in logs, but UI looks like this:\n-\nFor\n   https://github.com/googlevr/gvr-android-sdk/tree/master/samples/sdk-treasurehunt\n   [image: Android GVR SDK]\n   https://cloud.githubusercontent.com/assets/2169738/18588018/60fe3f70-7c2d-11e6-8e91-44bcc900c40c.jpg\n   -\nFor Unity app\n   [image: Unity GVR SDK]\n   https://cloud.githubusercontent.com/assets/2169738/18588019/60fe747c-7c2d-11e6-9cdd-4cca1d83089b.JPG\nIs this right place to post such bugs?\nWhat additional info can I provide?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/243, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfgykg8Aa5LDinCDomk-Y6jK_eStBks5qqp7NgaJpZM4J-9b3\n.\n. I'm sorry but we have no plans to do that currently.\n. Yes, that's the issue and the fix.\n. Thanks for the note, but we're focused on VR, not on all image formats.\n. Hi. Questions like this are better posted for StackOverflow as this forum is just for issues and bugs in the actual SDK.\n. Can you post a sample file that is causing the problem? Also, have you\ntried this using the new 1.0 SDK?\n\nOn Thu, Sep 22, 2016 at 9:02 AM, Alexander notifications@github.com wrote:\n\nHello, have a problems with different files from 360 camera.\nSome files is playback good, but with some I have errors.\nNexus 5, Android 6.01. But have same error on other device also.\nLog..\nE/LoadTask: Unexpected exception loading stream\njava.lang.IllegalArgumentException\nat com.google.android.exoplayer.util.Assertions.checkArgument(\nAssertions.java:39)\nat com.google.android.exoplayer.extractor.mp4.AtomParsers.\nparseStbl(AtomParsers.java:242)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessMoovAtom(Mp4Extractor.java:312)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessAtomEnded(Mp4Extractor.java:254)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nreadAtomPayload(Mp4Extractor.java:245)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nread(Mp4Extractor.java:130)\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$\nExtractingLoadable.load(ExtractorSampleSource.java:837)\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:224)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nW/Adreno-ES20: : GL_INVALID_ENUM\nE/LoadTask: Unexpected exception loading stream\njava.lang.IllegalArgumentException\nat com.google.android.exoplayer.util.Assertions.checkArgument(\nAssertions.java:39)\nat com.google.android.exoplayer.extractor.mp4.AtomParsers.\nparseStbl(AtomParsers.java:242)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessMoovAtom(Mp4Extractor.java:312)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessAtomEnded(Mp4Extractor.java:254)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nreadAtomPayload(Mp4Extractor.java:245)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nread(Mp4Extractor.java:130)\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$\nExtractingLoadable.load(ExtractorSampleSource.java:837)\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:224)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nE/LoadTask: Unexpected exception loading stream\njava.lang.IllegalArgumentException\nat com.google.android.exoplayer.util.Assertions.checkArgument(\nAssertions.java:39)\nat com.google.android.exoplayer.extractor.mp4.AtomParsers.\nparseStbl(AtomParsers.java:242)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessMoovAtom(Mp4Extractor.java:312)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessAtomEnded(Mp4Extractor.java:254)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nreadAtomPayload(Mp4Extractor.java:245)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nread(Mp4Extractor.java:130)\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$\nExtractingLoadable.load(ExtractorSampleSource.java:837)\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:224)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nE/LoadTask: Unexpected exception loading stream\njava.lang.IllegalArgumentException\nat com.google.android.exoplayer.util.Assertions.checkArgument(\nAssertions.java:39)\nat com.google.android.exoplayer.extractor.mp4.AtomParsers.\nparseStbl(AtomParsers.java:242)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessMoovAtom(Mp4Extractor.java:312)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessAtomEnded(Mp4Extractor.java:254)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nreadAtomPayload(Mp4Extractor.java:245)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nread(Mp4Extractor.java:130)\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$\nExtractingLoadable.load(ExtractorSampleSource.java:837)\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:224)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nE/ExoPlayerImplInternal: Internal track renderer error.\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.upstream.Loader$UnexpectedLoaderException:\nUnexpected IllegalArgumentException: null\nat com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(\nSampleSourceTrackRenderer.java:263)\nat com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(\nSampleSourceTrackRenderer.java:149)\nat com.google.android.exoplayer.ExoPlayerImplInternal.\nincrementalPrepareInternal(ExoPlayerImplInternal.java:275)\nat com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(\nExoPlayerImplInternal.java:205)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:148)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat com.google.android.exoplayer.util.PriorityHandlerThread.\nrun(PriorityHandlerThread.java:40)\nCaused by: com.google.android.exoplayer.upstream.Loader$UnexpectedLoaderException:\nUnexpected IllegalArgumentException: null\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:237)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nCaused by: java.lang.IllegalArgumentException\nat com.google.android.exoplayer.util.Assertions.checkArgument(\nAssertions.java:39)\nat com.google.android.exoplayer.extractor.mp4.AtomParsers.\nparseStbl(AtomParsers.java:242)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessMoovAtom(Mp4Extractor.java:312)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessAtomEnded(Mp4Extractor.java:254)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nreadAtomPayload(Mp4Extractor.java:245)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nread(Mp4Extractor.java:130)\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$\nExtractingLoadable.load(ExtractorSampleSource.java:837)\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:224)\nat java.util.concurrent.Executors$RunnableAdapter.\ncall(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nE/VrVideoPlayerInternal: 216933125.onPlayerError\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.upstream.Loader$UnexpectedLoaderException:\nUnexpected IllegalArgumentException: null\nat com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(\nSampleSourceTrackRenderer.java:263)\nat com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(\nSampleSourceTrackRenderer.java:149)\nat com.google.android.exoplayer.ExoPlayerImplInternal.\nincrementalPrepareInternal(ExoPlayerImplInternal.java:275)\nat com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(\nExoPlayerImplInternal.java:205)\nat android.os.Handler.dispatchMessage(Handler.java:98)\nat android.os.Looper.loop(Looper.java:148)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat com.google.android.exoplayer.util.PriorityHandlerThread.\nrun(PriorityHandlerThread.java:40)\nCaused by: com.google.android.exoplayer.upstream.Loader$UnexpectedLoaderException:\nUnexpected IllegalArgumentException: null\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:237)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nCaused by: java.lang.IllegalArgumentException\nat com.google.android.exoplayer.util.Assertions.checkArgument(\nAssertions.java:39)\nat com.google.android.exoplayer.extractor.mp4.AtomParsers.\nparseStbl(AtomParsers.java:242)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessMoovAtom(Mp4Extractor.java:312)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nprocessAtomEnded(Mp4Extractor.java:254)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nreadAtomPayload(Mp4Extractor.java:245)\nat com.google.android.exoplayer.extractor.mp4.Mp4Extractor.\nread(Mp4Extractor.java:130)\nat com.google.android.exoplayer.extractor.ExtractorSampleSource$\nExtractingLoadable.load(ExtractorSampleSource.java:837)\nat com.google.android.exoplayer.upstream.Loader$LoadTask.run(\nLoader.java:224)\nat java.util.concurrent.Executors$RunnableAdapter.\ncall(Executors.java:423)\nat java.util.concurrent.FutureTask.run(FutureTask.java:237)\nat java.util.concurrent.ThreadPoolExecutor.runWorker(\nThreadPoolExecutor.java:1113)\nat java.util.concurrent.ThreadPoolExecutor$Worker.run(\nThreadPoolExecutor.java:588)\nat java.lang.Thread.run(Thread.java:818)\nE/ru.justbrains.vrrentals.HomeFragment$VrVideoListener: loadError\ncom.google.android.exoplayer.upstream.Loader$UnexpectedLoaderException:\nUnexpected IllegalArgumentException: null\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/250, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamflim0GcshLt1tQhDmu0f269WJL3cks5qsqafgaJpZM4KEEYx\n.\n. Thanks for the heads up. We're looking into this issue now.\n\nOn Thu, Sep 22, 2016, 2:35 PM Mike Nakhimovich notifications@github.com\nwrote:\n\nalso we needed to add following dependency compile\n'com.google.protobuf.nano:protobuf-javanano:3.0.0-alpha-7'\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/251#issuecomment-249035029,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfuo9JBXs8pkRhqbYC4BbJtjJD9qhks5qsvSrgaJpZM4KEYI-\n.\n. OK. This issue should be fixed now.\n\nOn Thu, Sep 22, 2016, 2:49 PM Nathan Martz nsm@google.com wrote:\n\nThanks for the heads up. We're looking into this issue now.\nOn Thu, Sep 22, 2016, 2:35 PM Mike Nakhimovich notifications@github.com\nwrote:\nalso we needed to add following dependency compile\n'com.google.protobuf.nano:protobuf-javanano:3.0.0-alpha-7'\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/251#issuecomment-249035029,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfuo9JBXs8pkRhqbYC4BbJtjJD9qhks5qsvSrgaJpZM4KEYI-\n.\n. Thanks for the feedback. We don't plan to let devs disable this UI in the future, but we do want to make sure the standard UI works well for applications like yours (hence the changes in this release). Thanks for the additional ideas. We'll look into them for future releases.\n. Sorry, closed because we have a tracker for this internally and there are similar suggestions in other open threads here.\n. The Moto G1 doesn't have a gyro which is required for the automatic panning.\n. All of the instructions are here: https://developers.google.com/vr/concepts/dev-kit-setup\n. I'm sorry but as you can see the underlying video decoder isn't supported in the emulator so you'll need to test video widgets on device.\n. I think the issue was these missing dependencies, so I'm closing the issue. Please reopen if it's actually unresolved.\n. Thanks for the feature request. I'll add it to our backlog but right now stuff like this isn't our top priority right now.\n. Thanks for the suggestion. We are likely be more flexible with transition views in an upcoming update.\n. We don't currently support DASH but we're looking into it for Android. iOS\nwill be HLS only for the forseeable future.\n\nOn Tue, Oct 4, 2016 at 12:43 PM, SrujithPoondla notifications@github.com\nwrote:\n\nNow this sdk is supporting HLS, is there any way to get support for DASH\nas exoplayer supports DASH?\nIs there any other way to play dash 360 degree videos\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/263, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfimrC_x8ROgtEbk-X4n8gshyb5Ztks5qwqx5gaJpZM4KOE96\n.\n. We don't provide source for this library, and there are other open threads that discuss it in more detail.\n. It's not a bug but it is a feature we're looking to add. Closing this out as it's already tracked elsewhere here.\n. What phone is that on? Not all phones can play a video that high res. Can\nthe phone play the video outside of VR view?\n\nOn Sun, Oct 9, 2016, 2:51 AM SnowMusic notifications@github.com wrote:\n\ni cannot load my online video by using loadVideo:\nOptions options = new Options();\noptions.inputType = Options.FORMAT_DEFAULT;\nvideoWidgetView.loadVideo(Uri.parse(\"\nhttp://www.bandaoapp.com/bandao/uploads/media/20160719/Teaser.mp4\"),\noptions);\nerror like this:\n0-09 17:47:43.555 17947-17966/com.finger.gates.vrapplication\nE/ExoPlayerImplInternal: Internal track renderer error.\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc,\n-1, 1036784, 3840, 2048, 0, 1.0, -1, -1, null, 29397000, false, -1, -1, -1,\n-1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.notifyAndThrowDecoderInitError(MediaCodecTrackRenderer.java:427)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:413)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:797)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:333)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:540)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:523)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:128)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:432)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:211)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:192)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc,\n-1, 1036784, 3840, 2048, 0, 1.0, -1, -1, null, 29397000, false, -1, -1, -1,\n-1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:413)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:797)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:333)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:540)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:523)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:128)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:432)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:211)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:192)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by: android.media.MediaCodec$CodecException: Error 0x80001001\nat android.media.MediaCodec.native_configure(Native Method)\nat android.media.MediaCodec.configure(MediaCodec.java:590)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.configureCodec(MediaCodecVideoTrackRenderer.java:328)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:402)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:797)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:333)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:540)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:523)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:128)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:432)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:211)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:192)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n10-09 17:47:43.557 17947-17947/com.finger.gates.vrapplication\nE/VrVideoPlayerInternal: 921861740.onPlayerError\ncom.google.android.exoplayer.ExoPlaybackException:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc,\n-1, 1036784, 3840, 2048, 0, 1.0, -1, -1, null, 29397000, false, -1, -1, -1,\n-1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.notifyAndThrowDecoderInitError(MediaCodecTrackRenderer.java:427)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:413)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:797)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:333)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:540)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:523)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:128)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:432)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:211)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:192)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc,\n-1, 1036784, 3840, 2048, 0, 1.0, -1, -1, null, 29397000, false, -1, -1, -1,\n-1, -1)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:413)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:797)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:333)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:540)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:523)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:128)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:432)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:211)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:192)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\nCaused by: android.media.MediaCodec$CodecException: Error 0x80001001\nat android.media.MediaCodec.native_configure(Native Method)\nat android.media.MediaCodec.configure(MediaCodec.java:590)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.configureCodec(MediaCodecVideoTrackRenderer.java:328)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:402)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.onInputFormatChanged(MediaCodecTrackRenderer.java:797)\nat\ncom.google.android.exoplayer.MediaCodecVideoTrackRenderer.onInputFormatChanged(MediaCodecVideoTrackRenderer.java:333)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.readFormat(MediaCodecTrackRenderer.java:540)\nat\ncom.google.android.exoplayer.MediaCodecTrackRenderer.doSomeWork(MediaCodecTrackRenderer.java:523)\nat\ncom.google.android.exoplayer.SampleSourceTrackRenderer.doSomeWork(SampleSourceTrackRenderer.java:128)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.doSomeWork(ExoPlayerImplInternal.java:432)\nat\ncom.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:211)\nat android.os.Handler.dispatchMessage(Handler.java:107)\nat android.os.Looper.loop(Looper.java:192)\nat android.os.HandlerThread.run(HandlerThread.java:61)\nat\ncom.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n10-09 17:47:43.569 17947-17947/com.finger.gates.vrapplication\nE/SimpleVrVideoActivity: Error loading video:\ncom.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException:\nDecoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc,\n-1, 1036784, 3840, 2048, 0, 1.0, -1, -1, null, 29397000, false, -1, -1, -1,\n-1, -1)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/267, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamfvQkoLtGs_pfLhCALKUoIuCHZXz0ks5qyLk7gaJpZM4KR9eF\n.\n. SnowMusic, thanks for the info. What phone are you using to get this error?\n. FFMPEG is a stand alone library and not part of the google VR SDK.\n. That's right. The images are a superset of of the binaries created when compiling Android source. We don't supply raw APKs or source for the Google VR Service.\n. I'm sorry but we don't allow developers to customize these standard, cross application affordances.\n. Thanks!. Hi. This forum is for bugs and other issues with the SDK. For \"how to\" questions please post on stack overflow or similar site.\n. I'm sorry but right now we only support HLS and do not currenly plan to support RTSP.\n. This has already been discussed at length in a few other threads here, but\na quick recap is that while we won't be making these elements optional we\nare going to make them less obtrusive, hiding them while users are in VR,\netc.\n\nThe back button exists because many users aren't familiar with the swipe\ndown to show system bar  on phones without physical buttons and without\nthat they didn't know how to exit the app and felt \"trapped\" in VR. Not\nknowing how to leave makes them not want to go into VR again.\nBTW - what phone and viewer are you using?\nOn Sat, Oct 29, 2016, 6:56 AM Riccardo Di Meo notifications@github.com\nwrote:\n\nOn some wide-angle headsets (especially good quality ones, which is\nironic...) the top left and top right icons for respectively, \"back\" and\n\"configure\" are visible while watching VR content.\nBesides being downright annoying and useless in VR mode, they provide some\nlight discomfort, as looking at them delivers each eye a different view.\nNow, I know you explicitly removed the option to hide the configure button\nand the middle line (which btw looks very nice now that's shorter) in\n1.0.0, but it was a really bad call, so please reconsider it, as:\n- it could have been acceptable when there was only one button at the\n  bottom center (under the nose), not after moving it at the corners where\n  they are now visible.\n- it might be considered as arrogant toward the developers (\"we force\n  you to keep our stuff on your screen, because we know better\")\n- they provide little of no benefit to the user. You even provide a\n  transition screen to allow them to put the visor before the VR\n  content shows up, so how are they supposed to operate the buttons\n  anyway?\nMy next task is to navigate the view hierarchy to disable the buttons\nthrough reflection, if possible, or to recreate the GVRView from scratch,\nif required, if it isn't possible, but I'd rather avoid that... :)\nSuggested workarounds:\n- re-instate the setSettingsButtonEnabled and add a\n  setBackButtonEnabled (was there really a point to add a back button in\n  the first place???)\nAlso consider providing a standard intent, to fire up the VR configuration\nactivity as a complement to the \"gear button\" for apps/situations where it\nmakes sense to have the VR configured before it's actually on the\nuser's face, for a 2D UI integration (sorry for my ignorance if you already\ndid: I didn't check.. :) )?\nAnyway, despite the arguing, still a big fan, so keep up the good work! ;-)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/284, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ANamflma_77XKY5FN6kQ3-u26ijyzderks5q41CQgaJpZM4KkHmT\n.\n. Thanks for your feedback here. I can't share the specifics of the view hierarchy here or guarantee that they won't change in the future, but if you look around at other posts here you'll find others who have successfully dug through the view hierarchy.\n. The current drift correction logic is designed to optimize for latency, not smoothness. We will continue to improve the drift algorithm over time, but it will not fundamentally change.\n. There are many 3D asset loaders that are compatible with OpenGL already. We don't plan to add one to the GVR SDK.\n. We don't support hotspots in the native VR view but the web version supports exactly what you want.\n. Your explanation of how that function behaves in Daydream mode is correct. However, to get below 20ms motion-to-photon latency you actually have to have both async reprojection and scanline racing. Vertex shader distortion, although a great technique for Cardboard apps, isn't compatible with async reprojection. Given that vertex shader distortion + scanline racing won't get you low enough latency to be a Daydream application we don't expose and API that enables that combination.. If you want a custom player you need to build it on top of the lower level GVRView.. These are good questions, but they are better asked on a place like stack overflow as the discussion here is only for actual bugs in the SDK.. That API doesn't exist anymore. The vignette enables performance optimizations so you don't want to disable it ever.. We can't give legal advice beyond what's in the license file.. gpx1000, thanks for sharing. I think this issue is resolved now.. binoculars88, what device are you seeing this behavior on? What version of the SDK are you using?. I'm sorry but we don't support this and don't current play to.. Sounds like this issue is resolved.. I'm sorry but we don't support tablets in the cardboard SDK.. For cardboard apps we require those permissions for the viewer pairing to be read and written properly.. We don't support live streaming HLS in the VR View widgets.. Can you explain what you are doing here? It sounds like you are trying to manually integrate the GVR SDK into Unity? If so, it's already integrated in 5.6 and above. . Head tracking is a fundamental part of the VR SDK. If you don't want head tracking, but to shut down GVR.. In the GVR SDK, head tracking and stereo rendering are fairly tightly coupled. We do not formally support one without the other, and it's likely to be a lot of work for you to try to work around that.. We don't have any built in support for that, no. You would need to manually copy the texture for one eye and render that instead of the scene.. What device and what version of the sdk are you using?\n\nOn Sep 21, 2017 1:58 PM, \"Leo Cavalcante\" notifications@github.com wrote:\n09-21 17:53:45.852 3615-3720/com.hellovr E/AndroidRuntime: FATAL\nEXCEPTION: GLThread 31579\n                                                           Process:\ncom.hellovr, PID: 3615\njava.lang.RuntimeException: createContext failed: EGL_BAD_CONTEXT\n                                                               at\ncom.google.vr.ndk.base.GvrSurfaceView$EglHelper.throwEglException(GvrSurfaceView.java:1226)\n                                                               at\ncom.google.vr.ndk.base.GvrSurfaceView$EglHelper.throwEglException(GvrSurfaceView.java:1217)\n                                                               at\ncom.google.vr.ndk.base.GvrSurfaceView$EglHelper.start(GvrSurfaceView.java:1051)\n                                                               at\ncom.google.vr.ndk.base.GvrSurfaceView$GLThread.guardedRun(GvrSurfaceView.java:1479)\n                                                               at\ncom.google.vr.ndk.base.GvrSurfaceView$GLThread.run(GvrSurfaceView.java:1323)\nHelp?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/477, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamflFeCsk2R4atAasBDJbWdtfstGlTks5sks4MgaJpZM4Pf6JH\n.\n. There's not technical limitation here. HelloAR is just a very simple demo.. Adam, you can set the default viewer which will work as long as they\nhaven't already paired a viewer on that phone. Will that work for you?\nOn Wed, Nov 8, 2017 at 9:26 AM, Adam Szofran notifications@github.com\nwrote:\n\nHi Jared,\nMy company makes a VR business communication app aimed at architecture and\nconstruction and we bundle a specific VR viewer with it. Like this:\nhttp://www.visualvocal.com/\nWe recognize the importance of not automatically overriding the user's\nselected VR viewer. I totally get that. However, we'd really like to make\nit easy for our customers to configure our app to use the bundled viewer\nvia a prompt and button that we show at startup. Something like, \"Tap here\nto use the bundled viewer. [OK]\". Right now the best we can do is dump them\ninto the Android VR Settings UI which can be a bit bewildering for a\nfirst-time user.\nWhat about introducing a new permission that allows apps to set the\nviewer? (e.g. CONFIGURE_VR_VIEWER) That would mostly protect against\nmalicious apps but would allow a better user experience for business apps\nlike Visual Vocal.\nThanks,\nAdam\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/490#issuecomment-342891640,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ANamfniM9FoNDfbl-hHDFBGTMdE_tWvEks5s0eQzgaJpZM4QVPDP\n.\n. Adam, you should be able to use SetViewerProfile in CardboardHelpers.cs. This will pair the viewer you specify as long as the user hasn't paired one already.. Multiview is a very new feature and requires driver support to work robustly. There are some cases where the device is capable but there are driver bugs, and in those cases we have to disable multi-view until the driver bug is fixed.. Our standard format is over-under video. It's pretty straightforward to implement SxS yourself, but that's a \"how to\" question better asked on StackOverflow.. \n",
    "mnstrspeed": "I second that. It doesn't seem like anyone is going to be updating this project anymore, so at least let us learn from the source code and adapt it for our own VR projects.\n. ",
    "chaosconst": "+1, please open source your code for further development. since there're lot of problems in the jar ...\n. ",
    "dcerisano": "+3\n. Looks like buddy over here has decomplied the vrtoolkit as well.\nThanks buddy!\nhttps://github.com/Zomega/Cardboard/tree/master/src/com/google/vrtoolkit/cardboard\n@rsanchezsaez has done it too, and included extra packages like sensor, etc:\nhttps://github.com/rsanchezsaez/cardboard-java/tree/master/CardboardSample/src/main/java/com/google/vrtoolkit/cardboard\nThanks @rsanchezsaez !\n. I have heard that the latest version has been open-sourced by Google.\n. It is a rumor. Perhaps you could confirm or disprove it.\n. Try using the opensourced sdk's above to produce pull requests as arguments against the  closed-source sdk. \neg. https://github.com/googlesamples/cardboard-java/issues/17\n. Gee, wouldn't it be great if there was an opensource mobile VR library that did not use Cardboard, Daydream, Gear, etc, closed libraries at all, but runs on all of them? . +nathanmartz, since the official head tracking class is not open source, it cannot be supported by github users, as per our requests. There are significant design advancements (not \"fixes\") to many of the SDK classes required. This is only one of them. \nYou may as well close this as not a github \"issue\". I gave sufficient detail for your designers and engineers to know what to do.\n. ",
    "di1": "+1\n. ",
    "westonal": "+1\nFrom here: https://developers.google.com/cardboard/android/\n\"We're keeping the hardware and software open to encourage community participation and compatibility with VR content available elsewhere.\"\nHow can it be both open and only in your private repos?\n. Well done @rsanchezsaez Thanks!\n. ",
    "zfarm": "We are trying to expand the available screen space. We are useing the latest XX high def resolution phone LG G3 2560 x 1440 and the sdk locks us off at a \"cropped\" size. Any ideas on how to expand that to full screen \n. ",
    "rsanchezsaez": "As a stop-gag until Google releases the original source, I decompiled the bytecode using Luyten. This fork compiles and runs purely from source (tested on Android Studio 1.0.2).\nA sucky problem is that all the GL_CONSTANTS are (expectedly) decompiled to their integer values instead of to their #define names. This is specially evident on DistortionRenderer.java.\nIf anybody feels like replacing those back and submitting a pull request, that'd be great.\n. I think @Zomega's decompilation is from an older CardboardSDK version (it's 7 month's old). Mine's from the latest one. :-)\n. Hey,\nI just got a CardboardSDK iOS port (I completed the work started by @2equinox2k) up and running with the Treasure example. Some small features are missing, but it works quite alright. I'll be working more on it later.\nCheers!\n. In case anybody cares @eleventigers fixed this on our newer SDK decompilation (https://github.com/rsanchezsaez/cardboard-java/commit/11a95bc8189a994568a8f8bc7b159026d46e0567).\n. This may be due to the HeadTracker matrix degenerating under some some circumstances. As a workaround, I'd try pausing and resuming the CardboardView on game restart. Like this:\ngetCardboardView().onPause();\n     getCardboardView().onResume();\nwhich resets the HeadTracker as a side effect.\n. You can close the issue if you want.\n. ",
    "rahul27": "+1\n. I noticed this issue on the sample app as well. The thread count associated with MagnetSensor.java increases every time I pause and resume the app.\n. I see a similar error on the S6 running Android 6.0.1 : \njava.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol \"__aeabi_memclr8\"\nHave only the arm v7 libraries included in my case as well. \n. Adding the line doesn't work for me either, am on NDK version 13.0.331. The problem however goes away when I set compileSdkVersion  to 21. Here is a link I found while looking for answers:\nhttps://android.googlesource.com/platform/bionic/+/6d142bcf34ffd49efaf4285bb2af63a1636706f9%5E!/\nI am guessing these symbols were marked private in M.. Nope, it crashes with compileSdkVersion 25. Are you guys planning to migrate from experimental to 2.2.3 in the future?. ",
    "D3m0n92": "+1\n. Open source! +1\n. Nice! Good work @dcerisano !\n. - Unity 5.2.0p1\nAndroid: On some devices Screen.dpi returns more accurate values.\n2015-09-18 16:40 GMT+02:00 barak066 notifications@github.com:\n\nmoneytoo, have you fixed the source files in this git ? if i have lenovo\nk910 - what values should i change ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/24#issuecomment-141471739\n.\n. \n",
    "mjsibbald": "Is there anybody that has done it wiith the latest version? I would be for ever grateful.\n. That would be nice.... were can we find it?\n. Same here. Tested on Note 4\n. Just tested the previous version. That one is working. Please fix this. in the latest version\n. Hi David,\nYes it does not give me the distorted image anymore. But the effect is very different from 0.5.2. There is a big bar in the middle now and on bigger resolution it's showing even more space on top and the sides. \nIn 0.5.2. it gave me fullscreen split. If you know what I mean. I probably know why this is happening, besides the big bar in the middle. I really needed the the splitscreen to fill the entire screen. \nNot sure if this helps in anyway, because I appreciate the fix very much. I would prefer it to be some kind of option. like fit cardbaord true, or fullscreenVR = true.\nThank you!\n. Is there a way I can set this programmatically?\n. Yeah I figured that part out. But thanks for confirming. Is there any fallback for these situations?\nThanks! \n\nOn 22 Jun 2015, at 20:04, smdol notifications@github.com wrote:\nThis big is caused by certain phones that report an incorrect DPI value. The DPI is used with the resolution to compute the size of the phone screen in mm, which of them used to compute the projection matrix and viewport for rendering. An incorrect DPI therefore makes the phone seem to be bigger or smaller than it really is, which leads to this effect.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/googlesamples/cardboard-java/issues/24#issuecomment-114202096.\n. Hey Thanks!\nThis one does have a gyroscope (Vivo x510t) Chinese phone. \nI think I know what you are saying with the qrcode.\n. Just found out when I set setLowLatencyModeEnabled(false) it shows again. Why is this blocking in these versions?\n. \n",
    "lrq3000": "+1, please open source.\n. ",
    "udev": "+1\n. ",
    "Zomega": "@rsanchezsaez\nThat's correct: My decompilation was made a day or two after the Cardboard launched and was never built successfully, so it's probably not the best place to start.\nI work at Google now, so I can't keep working on this sort of thing. Glad to see people excited about VR though!\n. ",
    "serghov": "+1\n. ",
    "njam": "+1\n. ",
    "luav": "+1\n. ",
    "fcoulombe": "+1\n. latest\n. +1\n. thanks!\n. ",
    "boyce-ywr": "+\n. ",
    "jiangzhouq": "Come on\n. ",
    "gwald": "+1\n. ",
    "babysource": "+1\n. In some scenarios, We need to do something before or after at the time of back. So, I hope to be able to customize the  \u2018fullscreen_back_button\u2019  button events.\n. ",
    "jacksonkr": "+1\n. ",
    "zhxj22": "+1, really.\n. ",
    "sp-1234": "\nWe appreciate the feedback, but closing this as it's not really an \"issue\" with the Cardboard SDK.\n\nWhat is it then?\n. You did not fix the issue\u2014the code on the linked page is still the same as before.\nSo why did you close the issue? \ud83d\udc3c \n. You could at least open the source code so that developers can change things themselves if you can't.\n. Same problem\n. So where is it? There were several releases since then, and these forced UI controls are still too big and too bright and look gross when using cardboard.\nTo be honest, I am wondering, do you even test this SDK on yourselves?\u2026. Anyway it's better to eschew built-in distortion correction and do it yourself using vertex displacement technique, because it's faster and can give higher quality picture.. > async reprojection\nWhat is it?. ",
    "jisuz": "+1\n. ",
    "Lingyuezhixing": "+1\n. ",
    "NanLen": "+1\n. ",
    "jzhu1224": "+1\n. ",
    "tiantian20007": "+1\n. ",
    "ejoebstl": "+1. ",
    "CarlLee": "+1. ",
    "bluefish625": "+1. ",
    "bluej100": "Still seems to be broken for me.\n. Confirmed. Sorry about that. Thanks a bunch!\n. ",
    "zbendefy": "I suppose there is a total of 75 pixel tall padding/gap in the layout, which you need to remove. If there is no padding, maybe you did not enable fullscreen mode. Make sure you hide the statusbar and the application header correctly.\n. Is that in the cardboard api? or do you mean i should get a forward vector using the viewmatrix of the eye?\nEdit: Thanks for the hint. I took the first 3 elements from the 3rd row of the transposed Viewmatrix of the left eye, that gave me the forward vector i was looking for.\nWhat does the HeadTransform.getForwardVector() give me exactly then?\n. ",
    "GDG-Thess": "Did you find any solution?\nAs we are implementing a cardboard app and trying to get this feature as well for showing panos of touristic destinations.\nPlease do ping us as we have an imminent deadline to showcase our project ...\nThanks\n. ",
    "chebTS": "Hi! Any luck with that? I am trying to do the same :-)\n. ",
    "ghost": "You can just use transform.forward on the camera's transform. Or preferably\non a game object that is right in between the two cameras.\nOn Mon, Jan 5, 2015 at 11:34 AM, zbendefy notifications@github.com wrote:\n\nI'm trying to use the HeadTransform.getForwardVector() method to get the\ncamera view direction, but the returned value seems to be off. When i\nrotate my phone on the screen's plane (roll) in a full circle, the z value\n(3rd item in the returned array) is changing from -1 to 1, and back to -1,\neven though the camera direction stays the same (i'm looking at the same\nobject during rotating).\nphone type: galaxy note 3\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/18.\n\n\nDEVIN S WEIDIGNER\nBA in Game Art & Design\n254.458.4393\n. My Samsung Galaxy S2 8 inch tablet updated itself to Android 6.0.1 this morning and I now see the same issue on it (everything worked fine before the update).\nI'm looking forward to the fix for this.  Thank you to the Google devs for your responsivness on this issue so far. \n. So what was the problem? I'm experiencing the same issue, but on Samsung S7... Works nicely with Nexus 6.\nThe only \"native\" code I'm using is the Realm database and Crashlytics. Other than that, nothing.\n. The solution to my problem:\nInside build.gradle (Module: app)\nbuildTypes {\n    release {\n        ndk {\n            abiFilters \"armeabi\", \"armeabi-v7a\", \"x86\"\n        }\n    }\n}\n. ",
    "R1ck77": "As of now, the leak is still there (even though Google re-factored the code and moved magneticSensor into an instance of a SensorConnector class). I solved this problem (also thanks to your information) using reflection.\nYou can find my the solution here:\nMemory leak in CardboardActivity\nStill, it would be good if the issue could be fixed in the codebase (it's an one-liner after all).\n. Hi esminis, \nsince I had your same issue, I have investigated the problem, and it looks like that the reason because the textures are not sampled correctly, is that the cardboard SDK developers have used a texture sampler object, and probably they forgot to unbind it at the start of each stereo renderer callback (this can be verified by checking the OpenGL trace in a the android monitor).\nThis is especially confusing, as sampler objects are really OpenGL ES 3.0-only features, but some vendors return OpenGL ES3.0 contexts on ES3-capable devices, even if setEGLContextClientVersion (2) is specified (or at least this is true for Qualcomm), as it might be permitted by the method definition.\nTo be frank, I think behavior can be seriously categorized as a bug, as the sampler object will be used even if the app is created with OpenGL ES2.0 in mind, but running on a OpenGL ES 3.0 capable device (at least a Qualcomm-based one), leaving the app developer no easy way to work around the issue (there is no glBindSampler in GLES20...).\nA temporary work around for you could be: \n1. if you are doing OpenGL ES3.x, just be aware of the currently bound sampler, and handle your opengl state accordingly\n2. if you are doing OpenGL ES2.x things get  more complicated: you have to check if your current context is really a OpenGL ES3.x context and, only in that case, use some GLES30 functions to turn the sampler object(s) on and off.\nOf course this will be required only until the cardboard developers will have fixed the issue (which IMHO would mean unbinding them correctly at the start of each StereoRenderer callback, turning them nicely invisible...).\nHope this helps,\nRiccardo \n. Confirmed in v0.5.8 too: I didn't a thorough check of the source of the problem as you did, but I can confirm that the activity is leaking (as it also happened with the previous java-based implementations)...\nBtw, are we actually writing to anyone at all? Is anyone in the developer's group reading this or are we wasting our time?\nBecause there are like 26 bugs, not 2600, which means 5 for each contributor, and after a cursory search, not a single one I have browsed had a developer assigned to it, or seemed to have received any kind of attention from the deves (even just a \"Thank you, we are working on that!\"). \nIt' very sad to say, but for being a technology Google is investing so much on, until now the support for developers quite sucks. :(\n. Hi David, \nthanks for the ACK: I'm very glad to hear that the support for the SDK is growing, and I look forward for the issue to be resolved (or for any details on the matter that could help us work around the issue with reflection, as we did with this one: https://github.com/googlesamples/cardboard-java/issues/19). \nHave a nice day! \nRiccardo\n. You're welcome: I'm looking forward for the next version  :)\nCheers\n. Sorry to bother you (and glad to see a fair amount of activity on the tracker), I know you are busy, but is there any heads up on this issue?\nI'm asking because I was wondering if there is something we can do via reflection to work around the problem, even though it seems located in the native layer... \n. Thank you very much for the prompt and kind answer and keep up the good work (and have some great holidays)! \nI'll stop pestering you now, and wait patiently for the next release :)\n. Checked the new release and works like a charm (for saying nothing of all other goodies, like the sound support)! Thank you! \n. Hi smdol, if it can be of any help, I'm pretty sure that the first message (the one related to the screen parameters file not found) is irrelevant: I get it on my devices all the time, and they work like a charm.\nI think they are the byproduct of some kind of semi-hidden feature to configure the screen of the device along with the headset in the sdk, but it's not yet used or fully documented (I saw some hints about it in the APIs, though).\nThe second one, a segmentation fault is definitely the culprit. Weird it happens only on Tango boards (wild guess: some incomplete software implementation on the Os side? They are development devices after all...). Good luck with your issue (and cardboard or not, congratulations for your device. Quite some envy here :) ).\n. @openforeveryone nope. My device has the cardboard properly configured and the Cardboard screen parameter warning is still there in logcat. \nAgain, it's only a conjecture, but it might be searching for a file serialization of this\n. @koubiak Thank you for the explanation. I understand that the Hall sensor has been a source of trouble since Cardboard's inception, but why discard it now that you got rid of the magnetic trigger and it could actually be useful? \nI mean, instead of estimating the gyroscope bias, wouldn't make more sense to estimate the compass bias (where integration isn't involved), in order to discard the compass only in the worst case scenarios?\nI don't have hard data, but I would say that the drift worsened quite noticeably on my Nexus 5 in the transition from 0.7.0 to 1.0.2. \nI don't have much information yet because I released my update just yesterday, but a One Plus One user noticed the same pattern.\nMy conjecture is that turning the compass data down is probably going to penalize older models where the accelerometer + gyroscope alone just don't cut it, so it would be probably great to have the compass back, at least conditionally...\n@andregm3 the algorithm it's pretty good overall, and it actually relies heavily on the compass (to the point it was unusable with the old cardboard 1.0), but it's not that responsive (which is why I still prefer the Google VR's algorithm, though maybe I'll have to find a way to revert to the old HeadTracker).\n. Thank you, for the support and quick reply: let me know if you need any kind of data or measurement that might help you.\n. @ajavamind the Google VR SDK doesn't actually uses the GPS: you can tell by checking the permissions \nof your app (or the ones of the treasurehunt demo, if you want):\n$ aapt d permissions your_app.apk\nand notice that no location-related permission is used (GPS isn't of much use indoor, but we have project Tango to look forward to :) ).\n. Oh, now I see!\nI have checked the app, but the calibration seems more an \"internal to the app\" thing to me, than something that might affect the gyro/accelerometer operations system-wide (as far as I know, no Android API to calibrate the sensors exists).\nNeither I can or want to doubt your observations, but unless there is some kind of slim physical/electrical explanation (not a software one), I would be inclined to suspect a fortunate coincidence (but I'm by no means an expert).\n. Sorry for pestering you, @koubiak, but did you perchance change anything about orientation in the 1.0.3 release?\nBecause I did a couple of tests (3 in total...) and it seems to be better than the previous one: I'm looking right now at my phone displaying my vr scene on a tripod, and I don't see a noticeable drifting (a couple of degrees every minute at most).\nMaybe I'm just making a fool of myself (I'm the first to be aware that this attitude of few and spotty tests not reliable) and I'm just chasing ghosts, otherwise, great job! ;-)\n. Sorry: still running on Nexus 5.\nThank you for the info!\nIl lun 21 nov 2016, 15:52 Pierre Fite-Georgel notifications@github.com ha\nscritto:\n\nWhich device are you testing on? This is always a important data point for\nus.\nGenerally we always try to include the latest tweak in our release.\nOn Sat, Nov 19, 2016 at 6:01 AM, Riccardo Di Meo <notifications@github.com\n\nwrote:\nSorry for pestering you, @koubiak https://github.com/koubiak, but did\nyou perchance change anything about orientation in the 1.0.3 release?\nBecause I did a couple of tests (3 in total...) and it seems to be better\nthan the previous one: I'm looking right now at my phone displaying my vr\nscene on a tripod, and I don't see a noticeable drifting (a couple of\ndegrees every minute at most).\nMaybe I'm just making a fool of myself (I'm the first to be aware that\nthis attitude of few and spotty tests not reliable) and I'm just chasing\nghosts, otherwise, great job! ;-)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n<\nhttps://github.com/googlevr/gvr-android-sdk/issues/45#issuecomment-261715528\n,\nor mute the thread\n<\nhttps://github.com/notifications/unsubscribe-auth/ABgVoo_uNbWbjRP0sgHlAJp74xfVaZfzks5q_wFUgaJpZM4G22w9\n.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/45#issuecomment-261958827,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AMb8Mk17lTZjTdXgKLx1ELYVELhVTOA8ks5rAbA6gaJpZM4G22w9\n.\n. I'm not a lawyer and I'm not a [EDIT: cardboard sdk] developer, but this link might clarify the situation for you:\n\nWhat legal issues come up if I use GPL-incompatible libraries with GPL software?\nIf I understand it right (and, again, I might be getting it totally wrong!), you should ask the quake-like engine author for an exception to the license, in order to be able to integrate his/her code in your program.\nLate answer, but this might be of some use to someone else.\n. Thank you David!\nI'm glad to find out that the magnetic trigger is disappearing (no matter how nice an idea it was, when the project started).\nTo be honest, the addition of the setConvertTapIntoTrigger(), as a feature, still surprises me a bit.\nI understand it must be more a nicety to developers (thanks!), rather than a necessity, as I don't see the point to create a workaround for something as simple as:\nmCardboardView.setOnTouchListener(new OnTouchListener() {\n    [...]\n}\nI mean, it's android 101 stuff: a developer not able to figure that out, isn't probably (yet) in the league for a VR app... :)\nPersonally, I always kept it set to false, as doing so (and setting the onTouchListener manually) is the only way to discriminate the origin of a trigger event.\nThat's a nice thing to have, as it allows to filter out magnetic events only (I offer my users an option to do that, and I personally use it).\nI know it may look pointless but this is not an uncommon scenario:\n- user without proper headset configuration (magnetic trigger reported when not really present)\n- big headphones while using the VR app, for more immersion\nwhich usually leads to at least a couple annoying spurious magnetic trigger events. \nTherefore, if you are really going to remove the setConvertTapIntoTrigger and make it the default, could you please consider changing the signature of onCardboardTrigger to include information about the source of the event (a string or enum of sorts, if not even a luxurious structure with other event details... :) )?\nCheers,\nRiccardo\n. fair enough :) \nCongratulations to whoever did that, anyway!\n. 1. git clone https://github.com/googlesamples/cardboard-java.git\n2. cd cardboard-java\n3. ./gradlew assembleDebug\n4. aapt d permissions samples/treasurehunt/build/outputs/apk/samples-treasurehunt-debug.apk\nwhich will yield:\npackage: com.google.vrtoolkit.cardboard.samples.treasurehunt\n uses-permission: name='android.permission.INTERNET'\n uses-permission: name='android.permission.NFC'\n uses-permission: name='android.permission.VIBRATE'\n uses-permission: name='android.permission.READ_EXTERNAL_STORAGE'\n uses-permission: name='android.permission.WRITE_EXTERNAL_STORAGE'\n uses-permission: name='android.permission.READ_PHONE_STATE'  <---------- !!!!\nI'm quite certain that you take privacy seriously, which is why I'm not accusing you of having added that on purpose (as a matter of fact I'm a fan of your work), but may I suggest you to take bug reports seriously as well? The fact that your demo requires the READ_PHONE_STATE was already clearly stated in my first message.\nThat said, I think we started with the wrong foot: I'm more than willing to collaborate and provide further details on the matter, and I'll welcome your help, as soon as you'll look into the issue.\n. This is also my conclusion.\nThank you for the update: this is already something I can use, to take some heat off on the store. \nIf it can be of help, I think the only \"local\" factor involved might be the java version I'm using (you can get all other details quicker from the demo):\n$ java -version\njava version \"1.8.0_60\"\nJava(TM) SE Runtime Environment (build 1.8.0_60-b27)\nJava HotSpot(TM) 64-Bit Server VM (build 25.60-b23, mixed mode)\n$ cat /etc/issue\nUbuntu 14.04.4 LTS \\n \\l\nbut I would be quite surprised if it would matter: I didn't update neither java or my distro since the last release, so until now the SDK seems to be the only discriminant.\nAs I said in the first message, I would put my money on a missing min-target in the AARs manifests (but it's just a semi-informed guess).\nThank you for your help: I look forward to hear from you!\n. Hi @jdduke, I have further investigated the issue in order to provide my users with a fixed version, and I found the solution to the problem.\nThe root cause was indeed the missing <uses-sdk> element in at least library-common and library-audio (I didn't check the other aar, as I don't use them).\nAdding the line:\n<uses-sdk android:minSdkVersion=\"16\"/>\nto the AndroidManifest.xml of library-common and library-audio (\"16\" has been picked for consistency with library-core which declares the tag, but any number above 3 would have done)  fixes the issue for both the treasure hunt demo, and my app.\nFor those who may be experiencing the same issue, here are the steps to temporarily fix the problem\n1. locate in your project directory the location where the Cardboard SDK aar are stored\n2. unzip each aar in turn, in a separate directory\n3. check whether the AndroidManifest.xml within each contains the <uses-sdk android:minSdkVersion=\"16\"/> and, if not, add it\n4. for each modified directory, repack the content with zip, making sure to maintain the original structure, and replace the aar in your project with it.\nHope this helps.\n. Nope :) \ncore.aar requires  WRITE_EXTERNAL_STORAGE already, therefore the READ_EXTERNAL_STORAGE permission is implied:\nFrom the READ_EXTERNAL_STORAGE documentation:\nAny app that declares the WRITE_EXTERNAL_STORAGE permission is implicitly granted this permission.\nAnd btw, this doesn't prevent the read permission to show up in the google play store when installing, even if not really needed.\nAgain, not a big deal at all, just not the best possible style...\n(and btw... the link you are citing is wrong too: #68 :) )\n. I think that documenting the feature would fix the problem nicely! \nEven without counting the added complexity that my suggested addition would introduce (and that I didn't foresee before your answer), on second thought the usage scenarios for it would be so limited, that its introduction would be hardly warranted (in particular the option to disable the wakelock entirely made admittedly no sense)...\nTo further confirm that just documenting is the right call, I found the issue because my app is a virtual cinema, so probably one of the very few types of app where the user is supposed to be mostly still.\nLooking forward to update to the new GVR (and maybe give the NDK a go): keep up the good work!\n. Thank you! Keep up the good work, looking forward for the news in a couple of days ;-)\n. You're welcome: keep up the good work!\n. Thank you for the prompt answer, and sorry if this was discussed somewhere else: I just checked the opened issues, not the closed ones (my bad) and I didn't found it there.\nThe phone + VR combination I'm using is:  Homido + Nexus 5. I get people on the store complaining about the central line, just figure if I post the app with \"everbuttons\" on.\nAbout the back button, maybe I didn't explain myself clearly, when I said \n\nwas there really a point to add a back button in the first place???\n\nI didn't mean that it couldn't be useful for the user, but that's 101 stuff that shouldn't have place in the SDK.\nIf you want to create a VR application you have to deal with OpenGL (or Vulkan...), perspective matrices, and all sort for stuff: someone who can't add a button in the top left corner of a layout with a simple finish() in the setOnClickListener's body in less than 5\" is never going to be in the target of your SDK. Stuff like that might make sense for the Unity/Unreal SDK, more aimed at people with graphics skill set.\nCreating this sort of stuff for the the lazy developers (and I'm proudly in the pack), and allowing them to disable it, is a nicety, but forcing people to keep on turns it into a constraint, something that can get in the way. \nIt's a one size-fits-all approach that can't match all requirements: think about people developing VR apps with full withe background...\nAnyway, if you plan to make the overlay button disappear after a while, I guess it would solve the issue nicely, at least for me.\nIn the meantime, is there any chance to have the id or locations of the views in question? I don't think it will be that hard to find them, but not having to do it would be very nice...\n. Thanks!\n. ",
    "dav-cz": "This should be fixed with v0.6. Thanks for the reports!\n. Thanks for the reports!\nThis should be now fixed in v0.5.3, it'd be great if you guys could confirm it's fixed on your side?\n. Hi mjsibbald, \nGlad to hear it works better for you now :)\nAs smold explained, we try to only render the parts of the screen that are visible through the lenses, which saves rendering power.  And no, this can't be disabled programmatically.\nIf you have a headset that actually lets you see more than what the SDK displays, and if your headset doesn't have a parameter QR code, you can try to create your own one by visiting this calibration tool page we just launched.\nhttps://www.google.com/get/cardboard/viewerprofilegenerator.html\nHope that helps!\n. Closing this issue, since 0.6 update should fix this. @esminis, thanks for the report and please re-open if that's not the case.\n. Hi, very sorry for the lack of response. Our team is better staffed now so we'll have better dev support. Thanks esminis for the original report, and thanks R1ck77 for bringing back this issue to our attention. We will definitely look into it. \n. Thanks for tips Riccardo, that was helpful! This issue should be fixed in the next version.\n. The issue is fixed in our internal repo, the fix will be pushed on github for our next public release, which should happen some time after the holiday break.\nYou're correct, one of the sources for the leak was in our native code at the jni level, which you won't be able to fix via reflection.\n. Thanks for the help and nice words, @R1ck77! Closing this bug now.\n. Thanks for the report. We're on it and we'll push a fix asap.\n. @robhor, we just pushed 0.5.8 to fix this issue.\n@capsur, yes that would be nice! it's on our todo list ;)\n. s-gv, did you try the suggestion from jclova on Stack Overflow? Even though only armeabi-v7a binaries are currently shipped, they should work fine on arm64 phones. \n. Looks like this has been fixed with Android 6.0.1. Please re-open if you see this issue again.\n. This should be now fixed with 0.6. Thanks for the report!\n. Should be fixed in v0.8, thanks!\n. Hi Kanawish, we plan to ship binaries for other architectures in the next version.\nAs you mentioned, currently only armeabi-v7a binaries are shipped. Even though they might not be optimal, these should run well on arm v8 for sure and on x86 phones using emulation (at least it seemed pretty functional on the x86 phones we tested)\n. Just to confirm, when you say \"building failed for Nexus 5X\", do you mean the sample app from the SDK or your own code?  For me the sample app compiles and runs fine on Nexus 5X, with SDK 0.5.8.\nIf you mean your own code, and if you have your own native libraries, then you might have to apply abiFilters like you mentioned or copy all libraries into the same abi directory. (Though I've never tried that)\nLet me know what your situation is, this way we could document that properly in a central place.\nThank you!\n. Ok, so to summarize, if you use gradle 1.3.1, then\n- you can build and run the sample SDK app on your N5X.\n- you get an UnsatisfiedLinkError at run time for your own project, again on N5X.\nDoes your own project contain other .so libraries?\n. One problem we have is that our native library is folded into a jar, which doesn't play well with gradle's abiFilters. Therefore having libs for multiple architectures into the jar could break applications that compile native code for only a subset of architectures, when they run on phones with cpus the application didn't compile for.\nFor the next release we plan to ship the SDK as an AAR, which will overall greatly help with this issue. Thanks for your patience!\n. This was fixed some time ago. Please re-open if you still see the issue.\n. Thanks for your report Ruben, we'll look into that.\nDo you use a headset with a magnet? or a Cardboard v2 with conductive tape that touches the screen?\n. Hi Guanshan. It looks like your phone might be reporting an incorrect DPI, which prevents the SDK from drawing the two images at the right place on the screen.\nAccording to the numbers you gave, the phone DPI should be around 534, not 640.\nWhat is your phone model? Even better, could you give us the output of the following: \nadb shell getprop | grep \"model|manufacturer|hardware|product.name|lcd_density\"\nThis way we could add a DPI override in our SDK for your phone model.\nThanks!\n. Great, glad it worked!  I will close this issue then.\n. Closing this issue, please ask this type of questions on stack overflow using the \"google-cardboard\" tag. i.e, similar to this issue http://stackoverflow.com/questions/34264857/big-parallax-with-left-and-right-eyes/34276469#34276469.\n. Hi, just curious, do you happen to have a rooted phone?\nOur code doesn't use eglSwapInterval on phone with Android api 4.1.\nCould you report what Build.VERSION.SDK_INT returns on your phone?\n. Fixed in v0.8, the View now correctly shows up (blank) in the design preview. Thanks for reporting.\n. Have you tried unrolling that URL? createFromUri() assumes that the URL is fully unrolled.\nFYI we may deprecate that function as it could hurt the ecosystem if developers overrule what users have selected. At least we'll make it no-op if the user has paired a specific viewer.\nSo I'm curious to hear about your use case, do you plan to bundle your app with your own custom viewer and therefore would like to optimize the experience with that custom viewer?\nThanks!\n. Have you tried using CardboardView instead of CardboardActivity?\nCardboardView does most of the VR work (stereo rendering, head tracking, etc). \n. Closing this as we don't plan to make GvrActivity extend AppCompatActivity. \nHaving your own Activity that holds a full screen GvrView (formely called CardboardView) is probably the way to go.\n. Thanks for the report, we'll look into it. \nWe're probably going to just remove setConvertTapIntoTrigger(), since it should be always set to true now that we have way more Cardboard v2-like viewers in the wild than original Cardboard viewers with magnet.\nIn the meantime I guess I'd say refrain from calling setConvertTapIntoTrigger(false).\n. Thanks for the feedback, and thanks for raising the issue of spurious magnet triggers.\nThis comforts us in our decision to remove support for magnet trigger detection, as communicated in our v0.8 release notes. Magnet detection has never been 100% reliable, and also takes some cpu load. Most users these days use a cardboard v2 compatible viewer with a touch screen mechanism. Correspondingly, we marked setConvertTapIntoTrigger() as deprecated. I'm therefore closing this issue.\n. I think this is expected (if I understand your issue correctly)\nWhat happens is that the viewport dimensions depend on what Cardboard-compatible viewer is currently paired to your phone. In order to read what viewer is paired, the app needs to be granted read access to the S/D card.\nThe first time onDrawEye is ever called, that permission hasn't been granted yet, so the SDK assumes default viewer params. In the mean time, the permission dialog is shown to the user, user accepts to grant permission, and when the app is resumed the SDK can now read the actual viewer params and resize the viewports accordingly -- hence the different viewport dimensions.\nHope that helps!\n. \"\"\"So if I understand it correctly, the only real solution would be changing the storing of the viewer profile to some other place where no storage permission is needed, which was being worked on:\"\"\"\nYes you're right, the solution in 0.7.0 is a temporary patch so that there's a way for this work, but it's far from an ideal solution. We're working on a better solution where these parameters are stored in a central place that is not the S/D card, stay tuned!\n. @mariobodemann is correct, no more jar files, we use aar files instead.\nI'm going to close this bug. @xdreamz, let us know if you notice any broken links to the jar files in our documentation. Thanks!\n. Andrew, did you look at https://developers.google.com/cardboard/android/get-started#start_your_own_project?\nIt explains how to use the aars into your own project either using Android Studio or directly editing your gradle file.\n. Looks like this feature is popular! Thanks for the feedback, we'll definitely place this high on our TODO list.\n. We added support for remote URLs (e.g. www.domain.com/file.mp4) in v 0.8. Pretty basic for now as it supports only mono 360, but we'll improve this in future versions.\n. By the way, thanks all for the massive feedback on this issue. This has helped up prioritize this even while we were super focused on adding support for NDK and Daydream developer preview.\n. Hi @aaronliew, could you create a separate bug for this? with logcat / phone model / android API / whether you have a back screen with a sample video such as http://techslides.com/demos/sample-videos/small.mp4 \n. What phone / Android version are you using? Anything interesting in logcat?\nI'm able to play your video with the sample app on Nexus 5 running Android 5.0.1.\n\nadb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"http://video1.nytimes.com/video/360-demo/cool.mp4\" --ei inputFormat 1 \n. There's no official way to do this programmatically yet, but we could add one in future versions.\n\nIf you absolutely need this now, you can work around it by inspecting the view hierarchy to find the \"cardboard\" VR mode button, and programmatically call performClick() on it. No guarantee that this will be supported by future versions of the API, though.\n. This is fixed in v0.8. Thanks for the reports!\n. The core library actually needs the READ_EXTERNAL_STORAGE permission to access the profile of the currently-paired Cardboard viewer. \nSee https://developers.google.com/cardboard/android/get-started#manifest_file\n. Oh I see, I didn't realize this bug was about READ_EXTERNAL_STORAGE being redundant. Thanks for clarifying.\nYes, we should get rid of that one too, thanks for reporting.\n. Fixed in v0.8. \nWRITE_EXTERNAL_STORAGE is not required, so we just declare READ_EXTERNAL_STORAGE. \n. Sorry, we haven't been able to solve that one yet. We are definitely looking into it and hope to get a fix in the next version. Thanks for your patience!\n. Good news, we should have a fix for that in our next release! At least it is fixed on Samsung 6 running 6.0.1. We'll try to test this on more phones mentioned in this thread.\n. Today!\nhttps://developers.google.com/vr/android/release-notes\nWe tested on Samsung Galaxy S7 Edge (6.0.1) Samsung Galaxy S6 Edge+ (6.0.1) and Samsung S6 (6.0.1). Let us know if you still see an issue on a particular Samsung phone.\n. @jeremysciarappa . Yes it's fixed, just update to the latest AARs from the repo (\"GVR Android SDK v0.8.5\" commit) and things should work. \nI also updated the release note to a link that actually works, thanks for reporting.\n. Closing this, as this is not currently on our roadmap, we focus on 360 content for now.\n. Sorry for the delay and thanks for the feedback. Indeed we have an idle detection in the SDK.\nAs we've learned (sometimes the hard way), adding options for customization in the SDK means a larger API surface, more tests to write, more QA, and over time slower development velocity. So we're trying as much as possible to have default behaviors that make sense for most users. And I think having this activated by default so that the screen doesn't lock while in VR is the right thing to do.\nSo what about we add documentation describing this behavior, and explain that if developers don't want this behavior they can add the flag you mention to their GvrView? (thanks for taking the time to write this to unlock others btw)\n. Closing this one for now.\n. Thanks for flagging and sorry for the inconvenience. We'll try to address this in the next version.\n. This is currently blocked by the fact that Bazel doesn't support importing AARs in android builds. \nhttps://github.com/bazelbuild/bazel/issues/564\n. No plan to open source the common widget UI code for now, sorry!\n(but if you're adventurous you'll notice that our java code is currently not obfuscated)\n. Closing this issue.\nAs Nathan said we probably won't support swapping to mediaplayer, but should be able to support m3u8 via ExoPlayer. Filed here https://github.com/googlevr/gvr-android-sdk/issues/89.\nThanks!\n. @mikulbhatt, @Millertoken, do the URLs that you want to play always end up with .m3u8?\n. Looks like HLS is popular!\n@mikulbhatt, thanks. We're going to add an explicit option in the API so that the video format can be specified by developers (HLS vs regular container formats like mp4).\nWould you (or somebody else on the thread) have a m3u8 test file you could share that we could test against? We tried with a couple of sample files mentioned in the ExoPlayer docs but I'd just want to double check with more files.\n. @mikulbhatt thanks for the link, I just tried and playback works. However that video is not in 360 equirectangular format, so it looks stretched.\nFor the gvr release update, hopefully we'll have it out sometime next week.\n. This is now working with this morning's update.\nUse the loadVideo(url, options) function, with options.inputFormat = Options.FORMAT_HLS.\nWe still need to update the documentation reference, should happen very soon. In the mean time you can take a look at the code for the sample video app.\nIn particular @mikulbhatt's HLS stream can now be played using the following command:\nadb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"http://yahooios2-i.akamaihd.net/hls/live/224964/iosstream/adinsert_test/master.m3u8\" --ei inputFormat 2\n. GVR_NO_CPP_WRAPPER is now present in the latest version. \n. With v0.8.1, \"/sdcard/congo.mp4\" is now a valid path, no need for the \"file:///\" prefix anymore.\n. VrPanoramaView is not currently designed to perform well in ListView.\nIt uses GLSurfaceView, and from experience you can't really have more than 3 or 4 of these views rendered at the same time on the screen, as it generates artifacts as the ones you described. Also it's a bit heavy weight as each view will spin its own thread, perform rendering at a high frame-rate, etc. So it will be hard to guarantee smooth scrolling in these conditions.\nThat being said, you can find work-arounds. Take a look at what we do in the Cardboard App for Android, in the \"Get apps\" tab. We have a ListView with regular images, and also one (and only one!) VrPanoramaView. As the user scrolls, we look at the most visible item in the list. For that item, we trigger a LoadImageFromBitmap for the corresponding panorama. When it's loaded, we move the VrPanoramaView at the right position in the list and fade it to 100% visibility.\nThis way we have something that is smooth and still shows some panorama goodness.\nIn any case thanks for flagging this, we should add comments in the doc to specify that is not recommended to have more than one or two active VrPanoramaView's in a layout.\nHope that helps.\n. @chuangzai, you're welcome!\n. Hi, could you print a bit more of what you see in logcat? \nAlso what is the Android API version for the S6?\n. Do you see any other suspicious log errors before that, like something mentioning native code or undefined symbol errors?\n. It looks there might issues with loading the native library on the S6 device.\nAre you able to run the sample apps ?\nDo you have other native code in your application?\n If so, looking at https://github.com/googlevr/gvr-android-sdk/tree/master/libraries/native might be helpful.\n. What @nihalmehdi (thanks!) suggested should work.  Or you could choose to lock the orientation for your specific activity. Please re-open if you think there's an issue with the SDK itself. \n. VrPanoramaView doesn't support magnet clicks. We now consider magnet clicks deprecated (not reliable across all phones) so we didn't add support for new code, see 0.8 release note here:\nhttps://developers.google.com/vr/android/release-notes#new\n. @xm007forgithub, did you try adding a \"file:///\" prefix to your local URIs? e.g. \"file:///sdcard/FILENAME.MP4\"\n. Closing this bug -- using a \"/sdcard/FILENAME.MP4\" or similar path should now work with v0.8.1 without adding a \"file:///\" prefix. \nPlease re-open if you still see this issue.\n. We filed an issue internally, thanks for the report!\n. Hi @BrendanParks, did you check VrVideoView? It lets you stream 360 videos (e.g. http://domain.com/file.mp4) in VR that you can view inside a Cardboard headset. \n. This only supports public media paths officially. It's backed by ExoPlayer though, so the answer to that issue https://github.com/google/ExoPlayer/issues/625 might work  -- making sure all HTTP connections use the same cookie store, potentially by installing a default cookie manager. I haven't tried, though.\n. @azeemmohd. With v0.8.1 VrVideoView now supports HLS streams, you can check the SimpleVrVideoActivity.java sample to see how to use it.\n@grobm, were you able to look at VrVideoView and see if it can fit your needs? If not, it'd be great to know what's missing. Thanks!\n. @arumani You're right, currently remote videos are assumed to be spherical AND monocular. There's currently no way to specify that the remote video is spherical and 3D (i.e. with top-bottom frames for left and right eyes). This will be added soon via the VrVideoView.Options object.\n. Feature added in 0.8.5.\nSee how the sample video app was updated, you can now specify the video type (mono vs stereo over under):\nOptions options = new Options();\noptions.inputType = Options.TYPE_STEREO_OVER_UNDER;\n. Hi @azeemmohd, we had an issue with the push yesterday. With today's update you'll find HLS support in VrVideoView. \nUse the loadVideo(url, options) function, with options.inputFormat = Options.FORMAT_HLS.\nIn particular your video now works with the sample video app:\n\nadb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"http://vevoplaylist-live.hls.adaptive.level3.net/vevo/ch1/appleman.m3u8\" --ei inputFormat 2\n. Please post this on Stack Overflow. It looks like a general proguard / Android release question, and not a particular issue with the VR SDK.\n. Thanks for report, this should be fixed in our next release.\n. Fixed in 0.8.5\n. Thanks for the reports. This will be fixed in our upcoming release.\n. Fixed with v 0.9.0\nhttps://developers.google.com/vr/android/release-notes\n. Hi @digitalbuddha, this (esp. post #1) looks like a duplicate of https://github.com/googlevr/gvr-android-sdk/issues/75 (for which we hope to have a fix!).  So I'm closing this issue.\n\nCould you create a separate issue for post #2 focused on Android N, and ideally tell us \n- if you see this both with mp4 and hls files?\n- if you only have this problem with Android N, and not with earlier versions of Android.\n  Thanks!\n. I'm not sure I understand the issue ... \n\"How can i change the position when change orientation.\"\nwhat position? what orientation?\n. Closing this for now. @KCHariram please reopen with more details if #135 doesn't solve it (thanks @RamIndani !)\n. With v0.9.0 there's now an official API for this.\n. Thanks for the report, I forwarded this to relevant folks in our team.\n. Marking this a duplicate of https://github.com/googlevr/gvr-android-sdk/issues/38\n. (Re-opening this until we add official support for it)\n. We're working on it. It should be there in the next version which we plan to push within 2, 3 weeks. \n. Yes this was implemented in v0.9.0, you can check out release notes here:\nhttps://developers.google.com/vr/android/release-notes\n. Closed as duplicate of https://github.com/googlevr/gvr-android-sdk/issues/132.\nFeedback noted!\n. We'll have a new API for this in our upcoming release.\nSee this other issue that tracks this:\nhttps://github.com/googlevr/gvr-android-sdk/issues/143\n. FYI this will be fixed in our upcoming release.\n. Fixed with v 0.9.0\nhttps://developers.google.com/vr/android/release-notes\n. With v 0.9.0 there's now an API to return the head position with yaw, pitch angles.\n. Thanks for the report. I was able to reproduce this just now. \nSadly it was too late to figure a fix for today's release, but we hope to release one soon.\n. Just a quick update that a fix for this was found, it will be pushed in our next update.\n. Fixed in v 0.9.0\nhttps://developers.google.com/vr/android/release-notes\n. @ashwin-sectorqube -- please don't change the topic of this thread. This is a different issue, most likely because you didn't specify inputType = FORMAT_HLS, which is necessary to play m3u8 files as explained in the reference documentation.\n. @ashwin-sectorqube please create a new issue for this with logcat and code snippet used to play the file.\n. So on what Android device do you see the issue?\nCould you provide a link to your video somehow? \nAlso do you see this issue if you play this video with Media Player or ExoPlayer directly?\n. Closing this, most likely it's a platform issue for which we can't do much.\nPlease re-open with more specifics once you've tried what @sigmaxipi suggested.\n. Thanks for the reminder. Marking this as a duplicate of https://github.com/googlevr/gvr-android-sdk/issues/81, as it's the same underlying problem (deps are baked in when they shouldn't).\n. Closing as obsolete since support for magnet triggers have been officially removed.\nhttps://developers.google.com/vr/android/release-notes\n. Not sure what this exactly means, but fullscreen and VR view use the exact same layout (same GL view). Only the 3D rendering part is different.\nPlease re-open with more context if needed.\n. Yeah, there was a little delay between the code push and the release note update. They're in sync now.\nhttps://developers.google.com/vr/android/release-notes\n. We don't plan to offer an option to disable distortion correction. Disabling it wouldn't help either, as the problem is probably that this phone is reporting a bad DPI. Hence the SDK doesn't position the center of the two views at the right place. \nCould you run this adb command below, and also report the exact size of your screen? (Is it really 5'5 inches?)\nadb shell getprop | grep \"model|manufacturer|hardware|product.name|lcd_density\"\n. This should be fixed now.\n. This is a duplicate of \nhttps://github.com/googlevr/gvr-android-sdk/issues/145\n. Sounds like a reasonable request. Can probably be exposed through a SetVolume(0.0 ... 1.0) API.\nIt's going to be tricky for you to have user controls for it in VR though, is that OK?\n. Just a quick update that this came in too late to be included in the release that we'll push in coming days, but we'll add it in the version after that one (~early Sept). Thanks for your patience!\n. This was added in v1.0.0\nhttps://developers.google.com/vr/android/release-notes#gvr_sdk_for_android_v100. @basselAlshK. Glad that the updated worked for you!  Closing this bug.\n@RamIndani, the version number is buried inside base.aar, \ncom.google.vr.sdk.base.Constants.VERSION;\nShould contain a string like \"0.8.5\".\n. @smore9982 can you try with a more recent SDK? \nI'm able to play your video sample without any issues using a Nexus 6, VR sdk v1.10.0 and this command:\nadb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d http://mediadelivery.mlbcontrol.net/2016/internal_tests/mlb/vr/congo_v01.mp4 --ei inputType 2. The only feature missing is being able to control the volume. So I'm closing this as a duplicate of \nhttps://github.com/googlevr/gvr-android-sdk/issues/165\n. Closing this.\n@dwinnbrown, your phone doesn't have a gyro so head tracking will not work correctly, sorry :/\n@RajeshJadav, there's already an issue for this -- https://github.com/googlevr/gvr-android-sdk/issues/143\n. @RajeshJadav, we will never make it possible to go in fullscreen stereo mode without the padding and curve, so I'm closing this issue. \nIf you think VR rendering on your phone is not correct please file a separate issue focused on that. But since your phone doesn't have a gyro the experience is never going to be great.\n. That's more a Stack Overflow / general Android development type of question.\nIn short, load the image file from the SD card into a Bitmap, then call LoadImageFromBitmap().\n. Duplicate of https://github.com/googlevr/gvr-android-sdk/issues/122\n. Closing this. Corresponding issue on unity repo: https://github.com/googlevr/gvr-unity-sdk/issues/285\n. There's currently no official way to do that, and it's very unlikely there will ever be.\nWe really believe both the transition view and the setting icon are important for the user experience.\n. I'm not sure I fully understand this request, in particular \" if I do this with a VR view, I instead get a video that is facing sideways.\"\nIf I run our sample apps (pano and video) with phone locked in portrait mode, and then I press fullscreen, the VR View goes fullscreen and the pano or video content appear with what seems a correct orientation.  i.e  the bottom of the video corresponds to the bottom of the phone (where the back/home/recent Android nav buttons are) when I hold my phone in portrait orientation. \n. > I need to put media Controllers inside CardBoard view(VR) in Simplevideo widget ..is that possible ?\nJust add media controller widgets on top of your View programmatically. Please ask Stack Overflow for more details.\n\nDoes this player support .m3u8 file ?\n\nYes, as explained in our API reference \n. With v 0.9.0 there's now an API to return the head position with yaw, pitch angles.\nClosing this since I think that should get you covered. Please re-open if that's not the case.\n. Hi, thanks for this feedback. \nThe VR View API for the web lets you specify the initial yaw angle, and we're planning to add that to the Android and iOS APIs, see this issue\nWould that be sufficient? Or do you really need to be able to set the head rotation at any time? (which can be quite jarring in VR)\n. Great, I'll close this bug then since it's a duplicate of issue 91.\nIn terms of timeline, our next push should be around early September.\n. Do you see this problem with the latest version that was pushed last week? \nhttps://developers.google.com/vr/android/release-notes\n. No worries! Just curious, which \"Releases\" section are you referring to? (or in general if something is not clear on our site let us know)\n. Thanks for this feedback. \nThat is confusing indeed, we should do a better job tagging these updates.\n. Try adding this to your proguard config so that the functions referenced in c++ are not hidden:\n-keep public class com.google.vr.sdk.widgets.pano.VrPanoramaEventListener { ; }\n-keep public class com.google.vr.sdk.widgets.pano.VrPanoramaView$Options { ; }\nYou're right we need to add these in a proper proguard-rules file, most probably in the next version.\nThanks for the feedback!\n. Thanks for the reports. I was able to reproduce this and find a fix. It will be in our next release.\n@digitalbuddha you were right the problem was that the view was just being detached, a last frame update was sent but the GL context was gone.\n. This was fixed in 1.0.0. \n(but we forgot to mention it in our release notes) \n. @jayspringfield, yes we'll do exactly that in our next release. \nNot an excuse, but it was very easy for us to miss this as ExoPlayer is developed at Google and therefore super easy to pull in and compile with our internal build system :)\n. FYI we've been able to reproduce this bug Samsung S5 and Nexus 4, both running Android 4.4.2.\nIt looks like the UI theme gets broken for some reasons on these devices, potentially due to some GL texture corruption. At this point it's pretty hard to know if it's something we can fix in the short term or not.\n. We actually tried that but the issue was that TextureView was consuming a lot of CPU cycles.\nThe good news is that it seems the GLSurfaceView lag and black borders look fixed on Android N.\n. That's because our AARs currently don't have x86 binaries.\nClosing as duplicate of this issue: https://github.com/googlevr/gvr-android-sdk/issues/38\n(which mentions a work around)\n. The SimpleVrVideoActivity demo can play m3u8 stream, see:\nadb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"http://storage.googleapis.com/vrview/examples/video/hls/congo.m3u8\" --ei inputType 2 --ei inputFormat 2\nSo it's most likely a problem with ExoPlayer not being able to play your video. Try to modify the exoplayer samples on their github to play your video and see if it works. If it doesn't work, reach out to them.\n. Duplicate of https://github.com/googlevr/gvr-android-sdk/issues/118\n. Closing this until a video link is provided so this can be reproduced.. Thanks all for helping on this! \nClosing the issue as it should work with the latest sdk. Please re-open if that's not the case.\n. Release notes for v1.0.0 were updated.\n. @genshenx please open a separate issue for this. Closing this as using VrVideoView with SurfaceView is not a supported use case.. GvrActivity is a very simple class that indeed goes into fullscreen by default.\nYou can try using GvrView instead. It is generally designed with fullscreen in mind and anything else than fullscreen will look strange in stereoscopic mode. But assuming you want to render in monoscopic mode (using setStereoModeEnabled(false)) then it might probably do what you want?. Not sure we can do much here ... Could you try posting that stack trace to the ExoPlayer project?\nhttps://github.com/google/ExoPlayer\n. Closing this, assuming @SnowMusic meant problem is solved. . Updated link:\nhttps://github.com/googlevr/gvr-android-sdk/search?utf8=%E2%9C%93&q=kPredictionTimeWithoutVsyncNanos. Update, we should have migrated to Exoplayer2 by our next update (probably sometime in February).. We migrated to ExoPlayer2.1. and above in v1.20.0.\nhttps://developers.google.com/vr/android/release-notes. Closing until we get more information from OP.. Thanks for the report. This should be fixed in our next release.. This is fixed in v1.20.0, thanks again for the report!\nhttps://developers.google.com/vr/android/release-notes. Thanks for the feedback. \nUnless there's a massive demand for this feature, I'm afraid we'll have to say no to this to keep our API surface focused on VR, which is our primary use case. \nThe embedded rendering mode is there to give users a preview of what the VR mode is. If we provide an option to disable sensor tracking, then our library starts to become a standard, generic photo viewer library, and clients will gradually want more and more features that go with that assumption. Which would then result in less time for us to implement truly VR oriented features. Hope you understand!\n. Please reopen with clear instructions on how to reproduce this.. Thanks for the bug report. We're able to reproduce, hopefully this should be fixed in our next version.\nFor your workaround, have you tried removing the VrVideoView from its parent layout before creating a new one, e.g. contentView.removeView(videoWidgetView); \n. This is fixed in v1.20.0, thanks for your patience.\nhttps://developers.google.com/vr/android/release-notes. Since you're using an mp4 file and not an HLS file, you should use options.inputFormat = Options.FORMAT_DEFAULT;\nCould you try that and report back?. Could you try to play the video with ExoPlayer directly (that's the library VrVideoView uses for playback) and see if it works? You can try downloading the exoplayer (v1) repo from here:\nhttps://github.com/google/ExoPlayer/tree/release-v1\nThen build the sample app. See if the MP4 samples work on your phone. Then try to modify the code to play your video instead -- the easiest way is if you could host your file on a local http server and then modify their sample file to point to your video.\nAnother thing you could try is encoding your mp4 to HLS, and play back using the HLS input option.\nTo convert a video to HLS on Linux you can simply start with:\n\nffmpeg -i input.mp4 output.m3u8. That seems like a generic codec / Exoplayer issue.\nCould you try explaining your problem at https://github.com/google/ExoPlayer, specifying your phone model and Android version?. No, and I don't think it's something we're planning to add. \n\nIf you really want to customize things, here are some ways you could explore (untested, non-official, \"maybe broken in the future\" etc):\n1) disable the standard VR button and create your own that you'd place on top of the view\n2) or access the current VR button with some view.getChildAt() calls, then call setLayoutParams with your new width, height on it.. Closing this as there's nothing we can do on the SDK side.. Thanks for your feedback!\nWe currently have no plans to do something similar on Android or iOS. It would add a lot of surface to the API and it would only be for panoramas, while most of our usage is on videos.. Thanks for the report! \nThe new v1.20.0 AARs are now correctly pushed to bintray, which should solve this issue. \nPlease re-open if that's not the case, thanks again.. ",
    "smdol": "That was the release back in January.  You can find it in the commit history here:\nhttps://github.com/googlevr/gvr-android-sdk/commits/master\n(There doesn't seem to be a tag for it.)\n. The black area around the edges is an artifact of the Cardboard viewer device that your phone is paired with.  It is based on the actual area of the screen you can see through the lenses.  You control this by scanning a QR code in the Cardboard app.  Some viewers like the Go4d can see the whole screen.\n. This big is caused by certain phones that report an incorrect DPI value.  The DPI is used with the resolution to compute the size of the phone screen in mm, which of them used to compute the projection matrix and viewport for rendering.  An incorrect DPI therefore makes the phone seem to be bigger or smaller than it really is, which leads to this effect.\n. Hm.  Sorry for the typos.  big = bug, which of them = which is then.\n. At the moment, there is no good fallback.  Phones that do this are like phones that do not have a gyro: unsuited for use in Cardboard.  There is a hacky fallback for users who are savvy, which is to customize a QR code so that their viewer measurements are scanned the same as wrong DPI / right DPI.\n. The usual cause of this is that the DPI reported by the phone does not match reality.  This throws off the calculation of the physical size of the phone, making the Cardboard SDK think the phone is bigger or smaller than it really is.  (In this case, bigger.)  There's currently no software workaround, unfortunately.  As a hack, some users have gone to the Cardboard profile generator site and made their own custom QR codes with scaled physical dimensions to compensate.\n. I'm just as surprised that phones can get away with reporting bogus xdpi/ydpi values, as those are supposed to be the physical pixel size.  There's no other way I know of to calculate the size of the screen in mm from software.  (If anyone one knows one, which isn't also subject to manufacturer-specified inaccuracies, let us know.)\n. Can you run \"adb logcat\" and see if there are any error messages that indicate where the crash is coming from?\n. Can you paste the adb logcat messages from Unity here?  You can use \"adb logcat -s Unity\" so all the log messages from other Android services are not included.\n. Hm.  I don't really see any useful messages in that listing.  I would next suggest running adb logcat (without -s Unity), and look for the long message from Unity (\"D/Unity (???): GL_AMD_compressed_ATC_texture GL_AMD_performance_monitor GL_A\nMD_program_binary_Z400 GL_EXT_debug_label GL_EXT_debug_marker GL_EXT_discard_fra\nmebuffer GL_EXT_robustness GL_EXT_texture_format_BGRA8888...\"), which is where the app is starting.  Then scan after that point to where the crash occurs.\nIs there a stack trace in the log?  It would be helpful to see the exact point where the crash happens.\n. Yes, with v0.5.2 this should be possible, but if you are using GazeInputModule then you'll probably have to test for it being touched using Input.touch directly.  If you are not using GazeInputModule, then the button should just work (let me know if it does not).\n. First, this message looks bad but is harmless:\nD/HeadMountedDisplayManager(22547): Cardboard screen parameters file not found: java.io.FileNotFoundException: /storage/emulated/0/Cardboard/phone_params: open failed: ENOENT (No such file or directory)\nThe actual error occurred here:\nF/art     (22547): art/runtime/check_jni.cc:64] JNI DETECTED ERROR IN APPLICATION: java_object == null\nF/art     (22547): art/runtime/check_jni.cc:64]     in call to GetObjectClass\nThere is some JNI code in the native layer that tries to get the display metrics (DPI, mainly).  This error could mean that it does not have the correct application context or classloader.\n. It definitely has to be fixed in house.  At the very least, a few additional null-checks would be in order...\n. There are some JNI calls made way down in the native code layer of the SDK that need to reach back up  into Java land.  The code in question is doing the typical JNI sequence \"get pointer to class Foo; ok, get pointer to method Bar; ok, call that method\", and one of those \"get pointer to...\" calls is returning NULL for some reason.  I know that the native layer of the SDK must have pointers to the application context and class loader given to it, or exactly that error will occur.  (@R1ck77, yep, these JNI calls are trying to get profile data about the phone and viewer.)  So the actual bug is not here, but earlier during initialization when these pointers should be getting passed to the native layer.  Alternatively, there is some kind of context mismatch caused by mixing Tango and Cardboard at the Java level.  Or I could be all wet and the problem is only vaguely related.  I'll make sure some Java folks on the Cardboard team have seen this bug.\n. This is definitely a bug in the SDK, down in the native code layer.  The team that works on that layer is aware of the bug, so it will be fixed at some point.  In the meantime, I can point you to code that will let you make workaround: http://stackoverflow.com/questions/32200052/unity-cardboard-orientation-landscape-right-upside-down\n. Which version of Android (on which phones) are you seeing the problem?\n. Which phones (and versions of Android) show the problem for you?\n. Is this an app you built?  Definitely make sure your manifest asks for permission to read external storage, if you don't have that already.\n. OK, you might want to look through adb not for your app, but for when you actually scan the QR code within the Cardboard app.  See if there are any messages about failing to save the data to storage, or network problems if it tries to unroll a shortened URI.\n. The Cardboard SDK license is Apache 2.0.\n. Can you post this over on the gvr-unity-sdk Issues page?  Also, I just checked and the .aar file has a skeleton manifest in it which does not specify an SDK level, as you suspected.\n. Let's handle this on the gvr-unity-sdk Issues page, where I've posted a question for you.\n. In the first picture, the phone was in portrait mode when the SDK asked for its screen resolution, which is used to compute the physical phone size, so it got a taller-than-wide result.  In the second photo, this shows that the phone is reporting an incorrect PPI (in this case, too low), which makes the phone seem much smaller than it really is.  One can see evidence of this in the first picture as well.\n. ",
    "veonua": "mess confirmed for Nexus5\n. ",
    "svenhenrik": "Confirmed on LG G2. If I get the view and turn off distortion in onSurfaceCreated I get an undistorted display, but it is still not correctly rendered. The left view takes up ~60% of the screen instead of 50%, but the divider and gear icon are still centered.\n. Yeah, that's how I do it now, sort of. I invert the headmatrix and apply it to the eyeview in the first calls to onDrawEye and save the two eye matrices, then I apply them onto my own rotation. Works, but the SDK is still wasting resources doing headtracking in the background.\n. I get INSTALL_FAILED_NO_MATCHING_ABIS when trying to install the sample app on X86/X86_64 emulator. Does arm emulation work on the Emulator? If not, that native X86 support would be very nice. I'm not going to get all preachy, but making the whole SDK open source would also come be more than welcome...\nAnyway, details: I'm using Android Studio 1.5.1 and a fresh clone of this repo. When I open the project I'm prompted to switch to Gradle 1.2.0, but it actually sets it to 1.5.0. Using 1.2.0 gives the same result. Apart from that I've made no changes. Tried running on emulator using X86 and X86_64, and install fails on both.\nAdding the abiFilters snippet above to CardboardSample/build.gradle gives me the following error instead, and aborts installation:\nThe currently selected variant \"debug\" uses split APKs, but none of the 1 split apks are compatible with the current device with density \"-1\" and ABIs \"x86\".\n. Closing the issue immediately doesn't exactly inspire confidence that you'll actually look into it, but thanks for the response.\n. Ok, sounds great. Thanks again! :)\n. I noticed the new (1.20) SDK still doesn't seem to have an arm model, but a place holder for the API?\nAny chance you could fill us in a bit on the status? I was hoping the Android SDK would be more on par with the Unity SDK feature wise before the restrictions on the Daydream store were lifted, but now I'm torn between waiting for a proper arm model in the SDK or implementing my own to fill the requirements.. Great work niusounds! A question before I try integrating it: I see that you don't use the gyro input, I'm guessing you can't pass acceleration in the update data either? Does it still give a decent result?. The blog post is very helpful, but it uses the acceleration readings from the controller, which is only available in the NDK library if I'm not mistaken. Any chance we could have methods corresponding to GetAccel and GetGyro in gvr::ControllerState in the Android SDK any time soon?. Thanks gpx1000, but the problem is that the Java SDK does not have any access methods to get the acceleration from the controller. I could of course include the native library and do a native call to GetAccel(), but it would be nice if it was also exposed in the Controller Java class.. ",
    "keaukraine": "I confirm both garbled rendering and incorrect proportion for left/right views.\nDevices - Google Nexus 4 and LG G3.\nTo reproduce garbled screen issue, it is enough to add 1 line of code in onCreate:\n```\n...\nsuper.onCreate(savedInstanceState);\nsetContentView(R.layout.common_ui);\nCardboardView cardboardView = (CardboardView) findViewById(R.id.cardboard_view);\ncardboardView.setDistortionCorrectionEnabled(false); // added this\ncardboardView.setRenderer(this);\nsetCardboardView(cardboardView);\n...\n```\nAnd when I switch setDistortionCorrectionEnabled() 'on the fly' (in my case, going to settings activity, returning back to VR activity and disable distortion) it results in incorrect proportions bug.\n. ",
    "MorrisLaw": "I signed\n. ",
    "moneytoo": "Same issue here (?), with Lenovo Vibe Z2 Pro (model: K920, device: kingdom_row). It used to work just fine but I'm not sure if it was when I still was on KK or running older version of Cardboard. I don't notice any difference when editing ro.sf.lcd_density. \n\nlog: https://gist.github.com/moneytoo/86c6ae5c7f888b9320a4\n. I waited for an fw update for Lenovo K920 (K920_S271_150907_ROW) which I received but the issue is still there. It's device sold in Europe via official channels, it contains Google apps so I believe it passed all the Google compatibility/certification tests. \nAre vendors required to define/report real physical device screen size? Is there such thing in Android compatibility definitions or tests? Why did you for sake switch to something that you (or anyone else) even can't ensure (is that xdpi/ydpi?).\nDo you expect end users to generate their QR code? I know resolution, physical size, PPI etc of my device but I find it need lots and lots tries to find out the best values. Tell me what should I put there if it's so easy.\n. So I finaly managed to fix it. I had to tweak both reported real DPI and use custom QR to fix vr lens parameters. I may try writing to Lenovo about the DPI but I just hoped you are in better position to iron all things out (and prevent such vendor bugs)...\nXposedBridge.hookAllMethods(XposedHelpers.findClass(\"android.view.Display\", lpparam.classLoader), \"getRealMetrics\", new XC_MethodHook() {\n            @Override\n            protected void afterHookedMethod(MethodHookParam param) throws Throwable {\n                DisplayMetrics dm = (DisplayMetrics) param.args[0];\n                dm.xdpi = dm.ydpi = dm.xdpi * 3.0f;\n                param.args[0] = dm;\n            }           \n        });\n. @barak066 It's a fix requiring Xposed framework (which requires root and unlocked bootloader). Let's try discussing it more at https://forums.lenovo.com/t5/K-and-Vibe-Z-Series-Smartphones/incorret-display-on-google-cardboard-on-K910-vibe-Z/m-p/2094256/highlight/false#M12040 to make Lenovo notice of the issue.\n. Still no luck with the new version 1.8 (on Lenovo K920). I did scan the QR code on the Carboard v2 (Cardboard I/O 2015).\n. ",
    "h0man": "Same issue here with OnePlus Two just out of the box and i have no idea how to fix it..\n\n. Thanks @smdol for the quick response ! I'll try that ! \n. ",
    "barak066": "moneytoo, have you fixed the source files in this git ? if i have lenovo k910 - what values should i change ?\n. ",
    "albeirojr": "This is the QR Code Google Cardboard for Lenovo K910 Vibe Z.  It's only accurate but works.\n\n. ",
    "kapil42319": "Can anyone share the custom qr code for lenovo k920  for cardboard v2\n. ",
    "anchak": "I made it.\n\n. ",
    "Panoktok": "@anchak thanks for this..may i know what is your settings for this?i am using it for now since i cant find one for my ZTE AXON ELITE...and i just got my bobovr z4...but its not a full screen one...im trying to experiment on the settings for my QR CODE..\n. ",
    "bd5155716": "@Panoktok I had the same issue.\nIf you already fixed it, please let me know.\n\n. @zzg111222 I had the same issue.\nIf you already fixed it, please give me a crash course.\n. \n\n. @nathanmartz please see above images. It is not what I want.\n. @naokirodion Thank you for your reply.\nIt is nexus 4. In Samsung galaxy, it looks good.\n. @nathanmartz The first image is one thing of the Nexus 4.\nI attached my apk file. \nNew folder.zip\n. @nathanmartz Please let me know your thought.\n. @naokirodion can you let me know the way to fix this bug? Thank you\n. ",
    "SamovarGolden": "Here is my solution for Lenovo K920 (Vibe Z2 Pro) from https://vr.google.com/cardboard/viewerprofilegenerator/\n\nSome optimizations could be done still, but my eyes already tired.\nHere is settings I've used:\n45.0\n185.0\n0.100\n0.100\n78\n73\n78\n78\n. Oh sorry, i though it's tread for Lenovo Vibe Z2 Pro (K920) =)\nWill update my post\n. ",
    "koubiak": "Can you provide the phone model and brand? So we can check if we can help.\nThanks\nOn Tue, Jun 21, 2016 at 1:20 PM, Sergii notifications@github.com wrote:\n\nHere is my solution from\nhttps://vr.google.com/cardboard/viewerprofilegenerator/\n[image: qr_viewer_profile]\nhttps://cloud.githubusercontent.com/assets/1113047/16244821/1b076460-37fe-11e6-9ef9-7fb0c73f4cfc.png\nSome optimizations could be done still, but my eyes already tired.\nHere is settings I've use:\n45.0\n185.0\n0.100\n0.100\n78\n73\n78\n78\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/24#issuecomment-227559245,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ABgVopl4GgQciIIGmV8vAZxkZGKqzjW_ks5qOEdxgaJpZM4FIyHT\n.\n. Hi,\n\nThanks Chris for flagging this issue. Drift is something we are working\nhard to reduce especially on a device like the note4. Unfortunately it is\nnot something easy to fix.  The only thing I can say is that we are working\non it, so stay tuned.\nAs an FYI, the current implementation of the sensor fusion does not use the\nmagnetometer because of the problem you mentioned.\nIf you see other problematic devices please let us know.\nOn Wed, Dec 16, 2015 at 1:10 PM, Francois Coulombe <notifications@github.com\n\nwrote:\n+1\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/45#issuecomment-165240067\n.\n. @R1ck77 Thanks for the pointer. We never used the mag on cardboard for anything else that the trigger detection. We are using mag on daydream ready device with great result (e.g. Pixel / Pixel XL). I am trying to look into the regression you pointed out and try to see why this happens. Thanks a gain for pointed it out.\n\n@andregm3 Our code is designed for VR so it has latency consideration that the code you are pointing out does not have. Otherwise it is an interesting solution.\n. Thanks Andy. We will try to investigate the regression.\nOn Sat, Nov 12, 2016 at 11:33 AM, Andy Modla notifications@github.com\nwrote:\n\nFYI, Using the Samsung S6, my app built with 0.9.1 SDK did not experience\nany perceivable drift. When I moved to 1.0.3 there is now a large amount of\ndrift that prevents me from publishing with the latest SDK.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/45#issuecomment-260143150,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgVovqEO8HK5iuwPBp5T1ue_59E1WQcks5q9hSAgaJpZM4G22w9\n.\n. Which device are you testing on? This is always a important data point for\nus.\n\nGenerally we always try to include the latest tweak in our release.\nOn Sat, Nov 19, 2016 at 6:01 AM, Riccardo Di Meo notifications@github.com\nwrote:\n\nSorry for pestering you, @koubiak https://github.com/koubiak, but did\nyou perchance change anything about orientation in the 1.0.3 release?\nBecause I did a couple of tests (3 in total...) and it seems to be better\nthan the previous one: I'm looking right now at my phone displaying my vr\nscene on a tripod, and I don't see a noticeable drifting (a couple of\ndegrees every minute at most).\nMaybe I'm just making a fool of myself (I'm the first to be aware that\nthis attitude of few and spotty tests not reliable) and I'm just chasing\nghosts, otherwise, great job! ;-)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/45#issuecomment-261715528,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgVoo_uNbWbjRP0sgHlAJp74xfVaZfzks5q_wFUgaJpZM4G22w9\n.\n. Do you mean that tracking does not work for yaw when in fullscreen or that orientation gets reset when you transition between modes? \n\n'Reset' restarts the tracker and therefore you should see the same part of the panorama when starting in the newly transitioned view.\n. We will investigate and update you.\nOn Jul 7, 2016 7:39 PM, \"\u8c22\u79cb\u9e4f\" notifications@github.com wrote:\n\nyes, when I transform the mode from EMBEDDED to FULLSCREEN, I want to keep\nmy yaw .do not reset it ,I find out the pitch is still works,but yaw has\nbeen reseted.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/140#issuecomment-231261820,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/ABgVopek7UvL8IACDr57VUDmWslDp9swks5qTbhLgaJpZM4JEPZj\n.\n. Hi Guillaume\n\nWe will try to take a look at this and get back to you.\nPierre\nOn Dec 22, 2016 9:40 AM, \"Guillaume Petitpierre\" notifications@github.com\nwrote:\n\nHello !\nI'm writing an app for the Cardboard, but since I've updated my Nexus 5X\nto Android 7.1.1, I can't run it anymore.\nI get this debug message, and nothing on screen after:\nAndroidNCompat: VR mode is not supported on this N device.\nWhat should I do ?\nThank you\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/325, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABgVoi-FavKojChjWVT5Q6cajgy6eyjMks5rKrYmgaJpZM4LUNZV\n.\n. Hi,\n\nI just wanted to let you know that we landed a partial fix in 1.20 which\nshould mitigate the issue.  The problem should be fully fix in the\nfollowing release.\nI am keeping the issue open for the moment.\nThanks again for bringing this to our attention.\nPierre\nOn Wed, Jan 25, 2017 at 7:24 AM, Jared Duke notifications@github.com\nwrote:\n\nThanks for the update, narrowing the regression range between 1.0.0 and\n1.0.1 is very helpful. We're looking into this internally, and will post an\nupdate with our findings.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/335#issuecomment-275137175,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgVoqZjrvncieuJqOdjyNvdbinMh7e4ks5rV2lDgaJpZM4Le8F6\n.\n. Do you know if rendering is frozen or tracking is frozen? If you have an\nanimation in your app is it still playing and only the pose does not get\nupdated?\n\nOn Fri, Feb 10, 2017 at 1:53 AM, Gen notifications@github.com wrote:\n\nI pause tracking in onStop, and resume it in onStart.\n@Override\nprotected void onStart() {\n    super.onStart();\n    gvrLayout.getGvrApi().resumeTracking();\n}\n@Override\nprotected void onStop() {\n    super.onStop();\n    gvrLayout.getGvrApi().pauseTracking();\n}\nBut, when I move app to background and resume the app several times, the\nscreen will be frozen.\nAnd I move app to background again, it will work fine this time.\nAnd I write this test code, to test it.\n@Override\npublic void onBackPressed() {\n    gvrLayout.getGvrApi().pauseTracking();\n    gvrLayout.getGvrApi().resumeTracking();\n}\nPress the back button several times, the screen will be frozen too.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/368, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABgVogbJzb67IouiOlMUSoSk25xKXXhZks5rbDOWgaJpZM4L9MPd\n.\n. What are you trying to do? Are you trying to implement  your own sensor\nfusion in c++ or are you trying to use GVR's sensorfusion in c++?\n\nOn Wed, May 3, 2017 at 12:22 AM, Ralf_Nick notifications@github.com wrote:\n\nIf I want to implement the sensor fusion into c++ code, the algorithm is\nin the packge \u201ccom.google.vr.sdk.base.sensors\u201d, is there anyone who have\ndone this? Thanks !\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/417, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABgVoiPReYaulm1V2Vtz-52ZElDDtRw7ks5r2Cs3gaJpZM4NPCWd\n.\n. That does not sound right. We will start investigate on our side.\n\nOn Mon, Oct 16, 2017 at 6:20 PM, liquid8d notifications@github.com wrote:\n\nWhen connecting to a real controller using the emulator app (along with\nUnity), the controller appears to be found and connected to, but as soon as\nany input is received, the app crashes. There is a crash dump:\n10-16 21:03:53.253 26083 26138 D BluetoothGatt: onClientConnectionState() - status=0 clientIf=6 device=XX:XX:XX:XX:XX:XX\n10-16 21:03:53.254 26083 26987 D BluetoothGatt: requestConnectionPriority() - params: 1\n10-16 21:03:53.256 26083 26987 I VrCtl.GattController: GATT connection priority set to HIGH.\n10-16 21:03:53.257 26083 26987 I VrCtl.GattController: Connection successful, discovering services.\n10-16 21:03:53.257 26083 26987 D BluetoothGatt: discoverServices() - device: XX:XX:XX:XX:XX:XX\n10-16 21:03:53.262 26083 26987 I VrCtl.ControllerService: Controller GoogleDaydreamControllerV1 state updated to: CONNECTING\n10-16 21:03:53.265  3291  3313 E bt_btif_gattc: btif_gattc_upstreams_evt: Unhandled event (7)!\n10-16 21:03:53.266  3291  3313 I chatty  : uid=1002(bluetooth) BT Service Call identical 4 lines\n10-16 21:03:53.266  3291  3313 E bt_btif_gattc: btif_gattc_upstreams_evt: Unhandled event (7)!\n10-16 21:03:53.269  3291  3313 D bt_bta_gattc: bta_gattc_get_gatt_db\n10-16 21:03:53.270  2068  2068 I TrustAgent.Tracker: [BluetoothConnectionTracker] Bluetooth connect broadast for Daydream controller XX:XX:XX:XX:XX:XX\n10-16 21:03:53.273 26083 26138 D BluetoothGatt: onSearchComplete() = Device=XX:XX:XX:XX:XX:XX Status=0\n10-16 21:03:53.274 26083 26987 I VrCtl.GattController: Service discovery complete, configuring characteristic notifications.\n10-16 21:03:53.274 26083 26987 D BluetoothGatt: setCharacteristicNotification() - uuid: 00000001-1000-1000-8000-XXXXXXXXXXX enable: true\n10-16 21:03:53.302 26083 26083 I VrSessionManager: .startTransition()\n10-16 21:03:53.527  2313  2620 I Publisher: Triggered Adaptive Discovery\n10-16 21:03:53.532  2313  2620 I Publisher: 2 Cast devices.\n10-16 21:03:53.532  2313  2620 I Publisher: \"Living Room\" (XXXXXXXXXXXXXXXXXXXXXXXX) supported([172DDEF2, 51DEDFBB]) notSupported([%urn:x-cast:com.google.cast.media]) expired(false)\n10-16 21:03:53.532  2313  2620 I Publisher: \"Office\" (XXXXXXXXXXXXXXXXXXXXXXX) supported([172DDEF2, 51DEDFBB]) notSupported([%urn:x-cast:com.google.cast.media]) expired(false)\n10-16 21:03:53.621 25720 25738 D [ACT]:ao: processing priority = NORMAL\n10-16 21:03:53.642  2730  2730 W com.comcast.hsf:NWD_SDK: type=1400 audit(0.0:3812): avc: denied { search } for comm=5365727669636520546872656164 name=\"600000.qcom,pcie\" dev=\"sysfs\" ino=18014 scontext=u:r:untrusted_app_25:s0:c512,c768 tcontext=u:object_r:sysfs_pcie:s0 tclass=dir permissive=0\n10-16 21:03:53.743 26083 26987 I VrCtl.GattController: Set battery level notifications: true\n10-16 21:03:53.743 26083 26987 D BluetoothGatt: setCharacteristicNotification() - uuid: 00002a19-0000-1000-8000-XXXXXXXXXXX enable: true\n10-16 21:03:53.782 26083 26109 W GvrApi  : GvrApi.shutdown() should be called to ensure resource cleanup\n10-16 21:03:54.103 26083 26083 I VrSessionManager: .finishTransition()\n10-16 21:03:54.124   902  6859 I ActivityManager: START u0 {act=android.intent.action.MAIN cat=[com.google.intent.category.DAYDREAM] flg=0x34210000 cmp=com.google.vr.inputcompanion/.MainActivity bnds=[30,498][306,870]} from uid 10194\n10-16 21:03:54.149  3291  3313 D bt_btif_scanner: btif_gatts_upstreams_evt: Unhandled event (26)\n10-16 21:03:54.149 26083 26112 D BluetoothGatt: onConnectionUpdated() - Device=XX:XX:XX:XX:XX:XX interval=12 latency=0 timeout=2000 status=0\n10-16 21:03:54.270 26083 26083 D AudioTrack: stop() called with 177792 frames delivered\n10-16 21:03:54.270 26083 26083 D         : PlayerBase::stop() from IPlayer\n10-16 21:03:54.328 26083 26987 I VrCtl.GattController: Device info read complete, completing with completeConnection().\n10-16 21:03:54.328 26083 26987 I VrCtl.GattController: Connection established, controller info read, finalizing connection.\n10-16 21:03:54.328 26083 26987 I VrCtl.GattController: State change STATE_CONNECTING --> STATE_CONNECTED\n10-16 21:03:54.328 26083 26987 I VrCtl.GattController: Controller connected:\n10-16 21:03:54.328   488   488 D SurfaceFlinger: Backpressure trigger, skipping transaction & refresh!\n10-16 21:03:54.329 26083 26987 I VrCtl.GattController: ControllerInfo[manufacturerName=Google Inc., modelNumber=Daydream controller, hardwareRevision=0003.ffff, firmwareRevision=1.0.35, softwareRevision=825796af, batteryLevel=96]\n10-16 21:03:54.329 26083 26987 I VrCtl.PaprikaController: Reporting controller connected.\n10-16 21:03:54.329 26083 26987 I VrCtl.ActiveControllerStateMachine: Connected to paired controller.\n10-16 21:03:54.329 26083 26987 I VrCtl.ActiveControllerStateMachine: Controller GoogleDaydreamControllerV1 state change STATE_PREPARING --> STATE_ACTIVE\n10-16 21:03:54.329 26083 26987 I VrCtl.ActiveControllerStateMachine: Controller GoogleDaydreamControllerV1 connected.\n10-16 21:03:54.330 26083 26987 I VrCtl.ControllerService: Controller GoogleDaydreamControllerV1 state updated to: CONNECTING\n10-16 21:03:54.330 26083 26987 I VrCtl.ControllerService: Controller GoogleDaydreamControllerV1 state updated to: CONNECTED\n10-16 21:03:54.352   902  6859 I ActivityManager: Config changes=480 {1.0 310mcc260mnc [en_US] ldltr sw411dp w411dp h659dp 560dpi nrml widecg port vrheadset finger -keyb/v/h -nav/h appBounds=Rect(0, 0 - 1440, 2392) s.54}\n10-16 21:03:54.387   488   488 D SurfaceFlinger: Backpressure trigger, skipping transaction & refresh!\n10-16 21:03:54.400   902  6859 I ActivityManager: Override config changes=480 {1.0 310mcc260mnc [en_US] ldltr sw411dp w411dp h659dp 560dpi nrml widecg port vrheadset finger -keyb/v/h -nav/h appBounds=Rect(0, 0 - 1440, 2392) s.54} for displayId=0\n10-16 21:03:54.408   902  6859 I WindowManager: Failed to capture screenshot of Token{de14dd8 ActivityRecord{9e8a4bb u0 com.google.vr.vrcore/.daydream.MetaworldActivity t1238}} appWin=Window{e9c1b4 u0 com.google.vr.vrcore/com.google.vr.vrcore.daydream.MetaworldActivity} drawState=4\n10-16 21:03:54.469   902   927 W Looper  : Dispatch took 169ms on android.ui, h=Handler (com.android.server.am.ActivityManagerService$UiHandler) {768ccfd} cb=null msg=31\n10-16 21:03:54.473 26083 26083 I VrCtl.ControllerService: Removing listener 10085:26083:com.google.vr.internal.controller.LISTENER_KEY for all controllers.\n10-16 21:03:54.481   902  1157 I InputReader: Reconfiguring input devices.  changes=0x00000004\n10-16 21:03:54.482   902  1157 I InputReader: Device reconfigured: id=8, name='synaptics_dsxv26', size 1440x2560, orientation 0, mode 1, display id 0\n10-16 21:03:54.585   902  6861 W AppOps  : Finishing op nesting under-run: uid 10085 pkg com.google.vr.vrcore code 24 time=0 duration=0 nesting=0\n10-16 21:03:54.607 26580 27107 I NetworkSocketServer: Running socket listener thread.\n10-16 21:03:54.608 26580 27107 I NetworkSocketServer: Listening\n10-16 21:03:54.610 26580 27108 W BluetoothAdapter: getBluetoothService() called with no BluetoothManagerCallback\n10-16 21:03:54.614 26083 26083 I daq     : Ui Overlay view reset\n10-16 21:03:54.614 26580 27108 I BluetoothSocketServer: Awaiting bluetooth connection.\n10-16 21:03:54.620   902  2208 W AppOps  : Finishing op nesting under-run: uid 10085 pkg com.google.vr.vrcore code 24 time=0 duration=0 nesting=0\n10-16 21:03:54.675 26083 26083 I daq     : Ui Overlay view reset\n10-16 21:03:54.762  5321 27105 W BluetoothAdapter: getBluetoothService() called with no BluetoothManagerCallback\n10-16 21:03:54.770  4268 27116 D DatabaseIndexingManager: Indexing locale 'en_US' took 6 millis\n10-16 21:03:54.777 26083 26983 E libEGL  : call to OpenGL ES API with no current context (logged once per thread)\n10-16 21:03:54.853 26580 27107 I NetworkSocketServer: ServerSocket.accept() received socket.\n10-16 21:03:54.855 26580 27107 F libc    : Fatal signal 11 (SIGSEGV), code 1, fault addr 0x40 in tid 27107 (Socket Server)\n10-16 21:03:54.936 27123 27123 I crash_dump64: obtaining output fd from tombstoned\n10-16 21:03:54.936   747   747 I /system/bin/tombstoned: received crash request for pid 26580\n10-16 21:03:54.938  1337  1337 D StatusBar: disable\n10-16 21:03:54.940 27123 27123 I crash_dump64: performing dump of process 26580 (target tid = 27107)\n10-16 21:03:54.940 27123 27123 F DEBUG   :                \n10-16 21:03:54.940 27123 27123 F DEBUG   : Build fingerprint: 'google/marlin/marlin:8.0.0/OPR3.170623.007/4286350:user/release-keys'\n10-16 21:03:54.940 27123 27123 F DEBUG   : Revision: '0'\n10-16 21:03:54.940 27123 27123 F DEBUG   : ABI: 'arm64'\n10-16 21:03:54.940 27123 27123 F DEBUG   : pid: 26580, tid: 27107, name: Socket Server  >>> com.google.vr.inputcompanion <<<\n10-16 21:03:54.940 27123 27123 F DEBUG   : signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x40\n10-16 21:03:54.940 27123 27123 F DEBUG   : Cause: null pointer dereference\n10-16 21:03:54.940 27123 27123 F DEBUG   :     x0   0000000000000000  x1   00000077d91f8210  x2   0000000000000000  x3   000000000fffffff\n10-16 21:03:54.940 27123 27123 F DEBUG   :     x4   000000001fffffff  x5   00000077f5f060b8  x6   0000000000000000  x7   0000000000000000\n10-16 21:03:54.940 27123 27123 F DEBUG   :     x8   00000077d91f9718  x9   0000000000000001  x10  0000000000000000  x11  0000000000000000\n10-16 21:03:54.940 27123 27123 F DEBUG   :     x12  0000000000000794  x13  0000000000000008  x14  000000000000000d  x15  00000077e6ab3000\n10-16 21:03:54.941 27123 27123 F DEBUG   :     x16  00000077f7b31b88  x17  00000077f786e718  x18  0000000000000020  x19  00000077f5e4ec00\n10-16 21:03:54.941 27123 27123 F DEBUG   :     x20  00000077f5ccac00  x21  00000077d9f72e00  x22  00000077d91f85bc  x23  00000077ddf0bb29\n10-16 21:03:54.941 27123 27123 F DEBUG   :     x24  000000000000000c  x25  00000077d9f72e98  x26  0000000000000000  x27  0000000000000002\n10-16 21:03:54.941 27123 27123 F DEBUG   :     x28  0000000000000003  x29  00000077d91f83f8  x30  00000077daa78ca8\n10-16 21:03:54.941 27123 27123 F DEBUG   :     sp   00000077d91f8240  pc   00000077dab443f8  pstate 0000000060000000\n10-16 21:03:54.946 27123 27123 F DEBUG   :\n10-16 21:03:54.946 27123 27123 F DEBUG   : backtrace:\n10-16 21:03:54.946 27123 27123 F DEBUG   :     #00 pc 00000000004923f8  /data/app/com.google.vr.vrcore-MdT05S5wF4kqVOHk7w2wFQ==/lib/arm64/libvrcore_native.so\n10-16 21:03:54.946 27123 27123 F DEBUG   :     #01 pc 00000000003c6ca4  /data/app/com.google.vr.vrcore-MdT05S5wF4kqVOHk7w2wFQ==/lib/arm64/libvrcore_native.so\n10-16 21:03:54.946 27123 27123 F DEBUG   :     #02 pc 00000000003b9170  /data/app/com.google.vr.vrcore-MdT05S5wF4kqVOHk7w2wFQ==/lib/arm64/libvrcore_native.so (gvr_initialize_gl+44)\n10-16 21:03:54.946 27123 27123 F DEBUG   :     #03 pc 000000000004e7bc  /data/app/com.google.vr.inputcompanion-ENChjSPGP0LZLvKCcjRUnw==/lib/arm64/libcontroller_jni.so\n10-16 21:03:54.946 27123 27123 F DEBUG   :     #04 pc 000000000007c2d4  /data/app/com.google.vr.inputcompanion-ENChjSPGP0LZLvKCcjRUnw==/oat/arm64/base.odex (offset 0x42000)\n10-16 21:03:54.968   902  1138 I WindowManager: Screen frozen for +664ms due to Window{13d4dbf u0 StatusBar}\n10-16 21:03:55.041  1337  1351 I zygote64: NativeAllocBackground concurrent copying GC freed 70603(3MB) AllocSpace objects, 0(0B) LOS objects, 49% free, 6MB/12MB, paused 626us total 157.811ms\n10-16 21:03:55.621 25720 25738 D [ACT]:ao: processing priority = HIGH\n10-16 21:03:56.147   747   747 E /system/bin/tombstoned: Tombstone written to: /data/tombstones//tombstone_09\n10-16 21:03:56.150   902 27124 W ActivityManager:   Force finishing activity com.google.vr.inputcompanion/.MainActivity\n10-16 21:03:56.159 26580 26820 I Choreographer: Skipped 74 frames!  The application may be doing too much work on its main thread.\n10-16 21:03:56.160 26580 26580 I Choreographer: Skipped 74 frames!  The application may be doing too much work on its main thread.\n10-16 21:03:56.162   902   951 I BootReceiver: Copying /data/tombstones/tombstone_09 to DropBox (SYSTEM_TOMBSTONE)\n10-16 21:03:56.170   649   649 E lowmemorykiller: Error writing /proc/26580/oom_score_adj; errno=22\n10-16 21:03:56.183   902  6865 I WindowManager: WIN DEATH: Window{567bcb7 u0 com.google.vr.inputcompanion/com.google.vr.inputcompanion.MainActivity}\n10-16 21:03:56.183   902  6861 I ActivityManager: Process com.google.vr.inputcompanion (pid 26580) has died: vis  +99TOP\n10-16 21:03:56.183   902  1156 E InputDispatcher: Received spurious receive callback for unknown input channel.  fd=278, events=0x9\n10-16 21:03:56.184 26083 26112 I DaydreamManagerImpl: Daydream client died for: ComponentInfo{com.google.vr.inputcompanion/com.google.vr.inputcompanion.MainActivity}\n10-16 21:03:56.184 26083 26112 W DaydreamManagerImpl: Displaying crash notification for: ComponentInfo{com.google.vr.inputcompanion/com.google.vr.inputcompanion.MainActivity}\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/484, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/ABgVoj1UuCBoB_IE3nrLeMq5JUqPtBOUks5stADtgaJpZM4P7czS\n.\n. \n",
    "DatNotData": "I have a Blu One Life X2. Can anyone help? \n. ",
    "JTatum95": "\nQR code for the Blu Life One X2.\n. ",
    "ketchupmaster987": "With my  Galaxy J7 V, I have a couple of similar problems. For some apps the view only shows up as 2 small squares like so\n\nor there are lines across the viewer\n\n. These 2 problems only happen for certain apps and I don't know how to fix either of them.\n. ",
    "starkiller343": "I have a Sarlar 3d VR headset and a T-Mobile Revvl Plus. Could anyone help me? I'm having the same issue where the splitscreen is smaller than it should be. Is there a qr code that will help? Please.. I have a Sarlar 3d VR headset and a T-Mobile Revvl Plus. Could anyone help me? I'm having the same issue where the splitscreen is smaller than it should be. Is there a qr code that will help? Please.. ",
    "jdduke": "@starkiller343: Would you mind attaching a screenshot of the problem?. Yeah, this looks like an issue with the SDK, and an internal bug has been filed for tracking. For completeness, which version of the SDK are you using?\n. This should be fixed in the next release, thanks for the bug report. I'll keep this issue open until the fix ships.\n. Legacy Cardboard devices with magnetic sensors are no longer officially supported by the SDK.. Thanks for the suggestion. The magnetic trigger is no longer supported by the SDK, so I'll close this for now.. HI @R1ck77, are you still seeing this behavior in the latest SDK release? If so, feel free to re-open the issue; a lot has gone into our tracking pipeline in the past year.. Note that you'll also need to call these methods after you call onResume() on the GvrView. The documentation has been updated to reflect this.. Per the original discussion, createFromUri() only works with unrolled Uris, and at the moment we don't have any plans to support automatic unrolling. Note that there is a native API that would do the unrolling, though it doesn't work across all devices and its use is discouraged.. Note that Google VR Services is now the primary provider for viewer parameter storage, and is available on all Kitkat+ devices. This application eliminates the need for every client to declare storage permissions.. > I just found out that my newly updated application requires \"READ_PHONE_STATE\" permission, after a rightfully concerned user reported that to me.\n\nAfter a brief investigation, it resulted that\nthe new version of the Cardboard SDK apparently requires it\nno cardboard aar directly declares it\n\nREAD_PHONE_STATE is neither requested by the Cardboard SDK nor any of the sample apps. How did you come to this conclusion? We take privacy very seriously, and would never add such a permission without due diligence.\n. I see. That permission has never been added explicitly to the Cardboard SDK (see https://github.com/googlesamples/cardboard-java/blob/master/samples/treasurehunt/src/main/AndroidManifest.xml#L7). It looks instead like this may be a Gradle-specific quirk (see, for example, https://code.google.com/p/android/issues/detail?id=80278, https://github.com/commonsguy/cwac-merge/issues/16).\nWhat version of Android Studio are you running?\n. > What version of Android Studio are you running?\nOK, ignore that. Clearly I don't use the gradle-based build setup very often. We'll investigate this issue, but just to be clear, the READ_PHONE_STATE permission is not explicitly added by the Cardboard SDK.\n. Yes, it's quite possible we're lacking some metadata with the library manifest/build files. Thanks for reporting the issue, and for the detailed bug report. I'll make sure this issue is prioritized and passed along to the right folks.\n. Thanks @R1ck77 , I'll pass that along. \n. Hi @bd5155716, would you mind testing against the latest SDK release? If you're still seeing the problem, feel free to re-open this bug. Thanks.. What side effects does your onCardboardTrigger override have? If it injects (directly or indirectly) touch events into the View hierarchy, or detaches and re-attaches the CardboardView to the View hierarchy, that could in theory lead to an infinite loop.\nThe CardboardView trigger detection simply listens to MotionEvent's of type ACTION_DOWN, dispatching the call to the trigger listener when such events are detected. Clients can replicate/tweak this detection directly by overriding CardboardView.onTouchEvent().\nA potential workaround (without knowing more details about your program) might be to temporarily disable trigger detection by calling CardboardActivity.setConvertTapIntoTrigger(false) in onCreate, then re-enable it on onResume. Again, without knowing what the side effects of our trigger override are, it's hard to prescribe a solution.\n. I haven't yet been able to reproduce the problem locally. A couple clarifying questions:\n1. What device model and Android version are you running?\n2. Can you reproduce the problem on other phones?\n3. When you say \"infinite\" loop, do you mean that it's literally a loop in which no other activity occurs, only dispatch of onCardboardTrigger()? Or is it simply that the onCardboardTrigger() method is called repeatedly each frame (or repeatedly per frame), but the app is not in a frozen state?\n4. Can you reproduce this behavior with the TreasureHunt sample in the SDK?\nThanks, hopefully we can get to the bottom of this.\n. One more question, I'm assuming this happens regardless of which Cardboard viewer you're using? That is, you can reproduce the issue when the phone is isolated and not anywhere near a Cardboard viewer? Just want to rule out this being related to the magnetometer trigger detection.\nIt could very well be an issue specific to HTC and/or the M8 phone. I'll see if I can reproduce under the same conditions, thanks for the feedback.\n. Thanks. Another bit that might be helpful is if you could log the stack trace in your onCardboardTrigger() call and post it here, e.g., android.util.Log.w(\"onCardboardTrigger\", Log.getStackTraceString(new Exception()));\nAs that could spam the logcat if called repeatedly, you could also just throw an exception...\n. We don't have any immediate plans to support Bazel with the public samples. We'll reopen this in the future if that changes. Thanks for the request.. Still nothing concrete to share, but Vulkan support is definitely a high priority item on our radar.. Hi @oscarbg, we'll be sure to open the issue when we have any updates to share on the matter.. Hi @ajavamind, is there a particular API or feature of GLSurfaceView that you require? The getGLSurfaceView() method was technically hidden, and added only as a temporary stopgap measure to ease the transition away from depending on GLSurfaceView directly. Note that we do expose a subset of GLSurfaceView's API directly, e.g., setEGLConfigChooser(), setEGLConfigContext(), and queueEvent().\nThe primary motiation for removing GLSurfaceView from the public API is that it gives GvrView's implementation a lot more freedom to customize the View hierarchy and tailor the SurfaceView interaction.\nIf there is need and strong demand, we're open to evolving GvrView's API to accommodate any gaps in functionality that may have been introduced.\n. Hi @astennu , thanks for the feedback.\nCan I ask which platform in particular is causing your problems? The current API is only supported on Android, with iOS support forthcoming. Both of these platforms provide C++11-compatible compilers, and have done so for quite some time.\nWe'll look into splitting out the C++ bits from the C headers in a future release. In the meantime, you can either 1) not include the header on unsupported platforms, or 2) remove the C++ bits from the header. \n. @astennu, with the latest release (0.8.5), defining GVR_NO_CPP_WRAPPER before including the GVR headers will suppress inclusion of the C++ wrapper code. Hope that helps. Cheers.\n```\ndefine GVR_NO_CPP_WRAPPER\ninclude \"gvr.h\"\n```\n. You're absolutely right, my mistake. It looks like the GVR_NO_CPP_WRAPPER change missed the branch cut by just a few hours. It will be included in the next (monthly) release. Apologies for the confusion.\n. Which version of gcc are you using? And which NDK version? I believe std::thread may require either clang or gcc 4.8. If that's an issue for you, we could probably remove the std::thread dependency in the NDK sample(s) altogether.\n. Hey @qqwazerty, out of curiosity, which phone/device were you using at the time? Thanks.. There's not a lot we can do on our end to fix this, unfortunately. . The FOV angles in the headset proto aren't meant to be perfectly representative of the headset's actual FOV. Rather, they're used as an optimization to avoid rendering pixels that cannot be seen, and are generally larger than the actual FOV.. For now the solution is as discussed, using HLS. We might consider streaming improvements at later date.. This looks like an issue with the decoder on the device. Let us know if the problem persists with the latest SDK release.. This appears to be an issue specific to Android 4.4.2, likely driver-related. We weren't able to find a sufficiently simple workaround, short of an Android upgrade.. Without more feedback, there's not a lot we can do. Feel free to re-open if this is still an issue.. Hi @fcoulombe , sorry for the trouble here. It looks like our Release Notes and API documentation pages have yet to be updated (https://developers.google.com/vr/android/release-notes).\nIn short, we've renamed \"GvrView.setVRModeEnabled\" to \"GvrView.setStereoModeEnabled\". This was to disambiguate the feature with the new Android N \"VR Mode\" feature (wrapped by AndroidCompat.setVrModeEnabled), where the latter is more about enabling VR-releated features on the device rather than toggling mono/stereo mode. Hope that helps!\n. Thanks for the confirmation @p-fischer.\n@iNicod, at the moment we don't have any plans to support simultaneous gyro + touch tracking, but we'll consider it for the future.. Thanks for the report, Tyler. We're tracking this internally and will try to have a fix with the next release. If I might ask, which Android phone model exhibits this issue?\n. Unable to repro on a few of the KitKat devices we have lying around. Would you mind sharing the \"adb logcat\" output when you click on the settings button? It may give some hints as to whether there are missing resources with the popup dialog\n. Thanks for the details Tyler, and which Android version are you running on the S5 (5.0? 5.0.1?)?\n. Hi @TylerMcCraw , I wasn't able to repro this but I also don't have access to the exact same device/build. Can you confirm whether the issue is still reproducible for you, with the latest SDK drop?\n. Given the lack of repro, there's not much we can do on our end. If somebody could attach a bug report which captures the repro, that would be helpful. Thanks.. Do you observe this only when embedded in the ViewPager? There are a few different custom container types that are known to have issues with embedding of the VrPanoramaView. We'll see about improving this.. setVRModeEnabled() has been renamed to setStereoModeEnabled(). For more context see the release notes @ https://developers.google.com/vr/android/release-notes.\n. There have been quite a few changes and improvements in the SDK over the past number of months. Are you still able to reproduce the problem on this device?. Feel free to re-open if this remains an issue. In general, devices that do not accurately report their DPI will manifest similar visual artifacts. We can whitelist them if there's sufficient demand.. @chr314 does this issue still reproduce with the latest (1.40.0) SDK?. Which headset and phone (device + Android version) are you using?. Also, do you see the same issue on your phone using the SDK TreasureHunt sample?. OK, thanks for the update, glad it's working!. Thanks @R1ck77 for the observation, and you're absolutely right. The API+feature may have been released a bit prematurely, and the documentation is rather lacking. We'll looking into improving this in a future release. Thanks again, and please never hesitate to file bugs if you find the documentation incomplete or confusing.\n. Hi @khrismuc, thanks for the feedback, we'll be sure to get this cleaned for the next release.\n. This should be resolved with the latest 1.10.0 release, thanks for the feedback.. We'll be tweaking the size and making these UI elements less prominent for the next release.\n. Hi @kpilyugin. We don't have any immediate plans to expose the setRenderMode API, though if there is additional demand from more developers we may consider it.\nYou might be interested in some of our lower-level APIs, like GvrLayout and GvrApi, which let you install your own GLSurfaceView or custom SurfaceView into the VR pipeline. See also the guide @ https://developers.google.com/vr/android/ndk/gvr-ndk-walkthrough. If you prefer not to work with native code, there are complete Java bindings to the native APIs, documented @ https://developers.google.com/vr/android/ndk/jni/reference/com/google/vr/ndk/base/GvrApi. We'll be releasing a sample in an upcoming release which implements some of the GvrView functionality in terms of the lower-level Java GvrApi + GvrLayout bindings.\n. Per the workaround suggested by using GvrApi + GvrLayout bindings directly, I'm going to go ahead and close this request. The sample mentioned will actually be part of this month's SDK release. . Hi @lingkang1988, our typical recommendation is to add ~50 milliseconds to the current time at the start of your frame.  There's an example of how to do this in our NDK TreasureHunt sample @ https://github.com/googlevr/gvr-android-sdk/blob/master/ndk/demos/treasurehunt/app/src/main/jni/vr/gvr/demos/treasure_hunt/jni/treasure_hunt_renderer.cc#L385.\n. There have been quite a few tweaks to ExoPlayer (the library we use to handle video playback) in the intervening months. Does the latest SDK resolve the issue you had observed?. Feel free to re-open if this continues to be an issue. Thanks.. Thanks for the feedback @scorpeeon, we'll be sure to address this in an upcoming release. A few of the samples have evolved over time, so there are some rough edges and redundancies that do need to be addressed.\n. Hi @v14gh, thanks for the feedback. This is bit of an oversight in the SDK. We've tried to keep the GvrView API as tight and streamlined as we can, but there are some gaps, e.g., inconsistencies between the output surface format and the (offscreen) render target format. We'll look into exposing some API hooks to resolve this, or try to do something slightly more intelligent for the next SDK release.\nOne thing to note is that it's perfectly acceptable for the surface and app render targets to have different formats, e.g., the output surface might have 0 depth as long as the app's render target has a suitable depth component.\n. We've gone ahead and added an API for this, to be included with the next release several weeks from now. Check the release notes for details on usage. Cheers.\n. > Anyway it's better to eschew built-in distortion correction and do it yourself using vertex displacement technique, because it's faster and can give higher quality picture.\nThis may be true for Cardboard apps, but low-latency Daydream-compatible apps require use of async reprojection, which is itself incompatible with vertex-based distortion.\nYou can now configure the depth/stencil format of the offscreen framebuffer using GvrView.setDepthStencilFormat(). Note that the integer argument doesn't map to a GL format, rather it maps to one of the predefined formats specified by BufferSpec.DepthStencilFormat.. Async reprojection, as implemented in the GVR SDK, does the following:\n\nCreates a separate \"reprojection\" render thread for drawing to the screen (decoupling app framerate from display framerate, ensuring 60 fps, making app frame submission \"async\")\nEnables reprojection of the app framebuffer using the latest headpose at the last possible moment before rendering\nEnables rendering directly to the front buffer for the reprojection thread (for low-latency rendering)\n\nSee also issue #219 .. Hi @mkeblx, that's a good observation. The reason we haven't yet added the DAYDREAM category to the SDK's TreasureHunt sample is because it's not (yet) technically Daydream-compatible. That is, it doesn't handle Daydream controller input.\nThis will be resolved in the next release in several weeks. We've added a simple API to GvrView that Cardboard app developers can use to bootstrap Daydream controller support, making controller button clicks emulate Cardboard trigger events. The release notes will offer details about this new API.\n. Thanks for the report @anakin78z, we'll be sure to get this fixed in the next SDK release. Apologies for the oversight.\n. This should be fixed with the latest 1.10.0 release, thanks again for the feedback.. No change at the moment, and no concrete plans to support this for the native VR views.. Thanks for the feedback, @gpx1000. It's actually an oversight on our part to not have added the orientation value to that sample's android:configChanges manifest attribute. This will be fixed in the next SDK update.. This should be resolved with the latest 1.10.0 release, thanks for the feedback.. Hi @jbrown101st , would you mind posting you Activity manifest bits here (redacted where appropriate)? In theory it should be possible to create a Daydream-compatible, GvrView-based app using the current public SDK, assuming you're using the existing Controller API.\nInternally, validating that an Activity is Daydream-compatible requires that:\n1. The DAYDREAM <intent-filter> category is specified, <category android:name=\"com.google.intent.category.DAYDREAM\" />\n2. The Activity is exported (this is the default assuming your Activity has an <intent-filter>\n3. An action is specified for the <intent-filter>, e.g., <action android:name=\"android.intent.action.MAIN\" />.\n. Hi @jclova. If you don't have a Daydream headset, and you try to run an app which is both Daydream and Cardboard-compatible (as indicated in your manifest), then the app should run without any problems, in Cardboard mode. The \"default\" headset is Cardboard, on both Pixel and non-Pixel phones.\n\n\"This Cardboard application is not compatible with Daydream headsets\"\n\nYou'll only see this if you've explicitly paired a Daydream headset, and the app does not define DAYDREAM in the manifest.\n\n\"Place your phone into the Daydream headset\" \n\nYou'll see this in 2 cases:\n  1) You've explicitly paired a Daydream headset, and the app does define DAYDREAM in the manifest.\n  2) You've paired a Cardboard headset, and the app only defines DAYDREAM (not CARDBOARD) in the manifest. In that case, we actually first show a warning saying that the app may not be compatible with your Cardboard headset.. > However, without having a cardboard without QR code around, you're stuck.\nAre you asking this from a development perspective? Or from a regular user's perspective? All (or nearly all) Cardboard devices have a QR code embedded on the device, so this shouldn't really be a problem for most users.\nIf you're just talking about the difficulty of switching back and forth for development, there are plenty of Cardboard QR codes on the internet you could use. Alternatively, you can clear the app cache/data for Google VR Services. We might consider adding a \"shortcut\" default option, as you suggested, though we haven't really seen the need so far.. Hi @jakemharris, can I ask which API you're using for your AR app? Are you using GvrView? Or GvrLayout? If you don't need stereo/VR capabilities, try calling \"setStereoModeEnabled(false)\" on GvrView or GvrLayout (whichever one you're using).. > Is this GvrLayout object still relevant in that setup?\nIndeed, GvrLayout is required regarless of the Activity type. It's from GvrLayout that you obtain your GvrApi instance, and from there the native gvr_context handle.\n\nDo we have to tell GVR about our EGL context somehow?\n\nNot explicitly, as long as you call gvr_initialize_gl appropriately. That said, the View that you provide as your \"presentation\" view, to GvrLayout, should in general be capable of display GL content. If you're using async reprojection, this isn't technically required, as we create our own SurfaceView for frontbuffer rendering when async reprojection is enabled.\n. > it won't work on cardboard-only devices? i.e. without async reprojection?\nProbably not, though we haven't really tested this path so it's hard to say for sure. What you'd probably want to do is use a SurfaceView instead of a View, plumbing down the Surface from Java into native, as shown in this example: https://github.com/wwlinx/android-native-egl-example-buck. You should still be able to use the EGL context you've created from native.. Yes, @windbagjacket, in theory that should accommodate your needs. However, we haven't done extensive testing with this approach yet, so you might hit some snags along the way. In the meantime, we'll try to vet this configuration internally, providing some code snippets/documentation accordingly.. >  \"Place your phone inside the headset\" screen and controller calibration that I was seeing on every launch when not using NativeActivity\nAre you forwarding the Activity lifecycle events to GvrLayout? Via GvrLayout.onPause()/onResume()/\n\nThe settings and quit buttons are also missing now.\n\nYeah, this is a general limitation with NativeActivity, as the settings/exit buttons are View-based. There are crude workarounds, which involve doing something like:\ngetWindow().takeSurface( null );\ngetWindow().setContentView( gvrLayout );\nin your NativeActivity's onCreate() method. However, the buttons will remain unresponsive to MotionEvents (as they're delivered directly at the native layer).. Hi @ssaroha. At the moment, the video Surface API is only supported when async reprojection is enabled. We're actively working on Cardboard (without async reprojection) support for the video Surface API.\nHowever, note that, without async reprojection, the video Surface API doesn't buy you a whole lot in terms of functionality (e.g., playing protected content without need a protected GL context). For the Cardboard case, you can simply draw the Surface quad directly into your scene.. Hi @ssaroha, apologies for the delayed response. We haven't yet exposed the more general API for supporting arbitrary Surfaces, and they still require use of async reprojection. I'll post back here if/when that changes. . Hi @weicui1, can you be more specific about which API you're using? Are you using the VrPanoramaView? Or GvrView?. Hi @Borys637 , did you find a solution to your problem? . Yeah, there are a number of devices that misreport their DPI, which can result in incorrect rendering at runtime. Sometimes it's only slightly off, but other devices actually override the native display resolution, while still reporting the native DPI.\nI'll see if we can add these devices to our DPI override whitelist.. There are a number of devices which misreport their DPI, and we have an internal whitelist we use to \"fix\" the DPI.. Not a bother at all, we'll try to make the native library extraction more painless/automatic with the next release. Thanks for the feedback.. Controller battery levels are now reported from both the native and Java controller APIs.. Can you try adding System.loadLibrary(\"c++_shared\") to MainActivity before the other library loads (@ https://github.com/googlevr/gvr-android-sdk/blob/master/samples/ndk-treasurehunt/src/main/java/com/google/vr/ndk/samples/treasurehunt/MainActivity.java#L48)? So it would be:\nstatic {\n    System.loadLibrary(\"c++_shared\");\n    System.loadLibrary(\"gvr\");\n    System.loadLibrary(\"gvr_audio\");\n    System.loadLibrary(\"treasurehunt_jni\");\n  }\n. Also, if both of you (@rahul27 and @scorpeeon) could share which version of the NDK you're using, that would be helpful. Thanks.. Wow... That is a pretty depressing bug, and @rahul27 it looks like that completely explains the behavior seen here.  I don't suppose it makes any difference if you set compileSdkVersion to 25?. @scorpeeon it sounds like this is a general Android platform/framework issue, unrelated to the actual GVR SDK. That is, if you compile/run a native app, without including the GVR SDK, you'll likely run into the same issue. It would be good to have this reported directly to the Android team @ https://source.android.com/source/report-bugs.html.. Please follow https://code.google.com/p/android/issues/detail?id=231870 for resolving this issue, there's nothing we can do on the GVR platform side, unfortunately.. Note that the 1.50 release (after the upcoming one) will switch to using CMake for NDK builds.. Hi @achuvm, is this for a Daydream-compatible app? Or just a generic Cardboard app?. For now, can you try using GvrLayout.setStereoModeEnabled()? That will effectively disable the UI layer and other Daydream/VR-specific features. However, you may still run into issues if you enable async reprojection and then try to render directly to your Surface while in mono mode.. GvrLayout.setStereoModeEnabled is a hidden method (i.e., you can call it, but it's undocumented), which is why I suggest it only with reservation, to see if it might meet your needs. If there is sufficient demand, we may standardize it and make it part of the public API. . Hi @SnowMusic, are you still running into this issue with the latest release?. Happy to re-open with additional details or if this is still reproducible.. Have a look at the NOTICE as a complete listing of all licenses for code included in our samples and the binaries for the GVR SDK.\n. > AndroidNCompat: VR mode is not supported on this N device.\nThis is a benign/informational log message only, it shouldn't actually impact your app. After starting your app, could you capture a bug report (adb bugreport cardboard_bug.zip) and attach here? Or could you share the actual app in question? Which version of the SDK are you using? . Hi @drksnw, thanks for the feedback. For now, I would remove android:enableVrMode=\"@string/gvr_vr_mode_component\" from your AndroidManifest.xml, and instead in your Activity.onCreate() add the following call:\nAndroidCompat.setVrModeEnabled(this, true)\nWe'll investigate why this exception is being thrown at the platform level, as AndroidCompat actually handles this case properly. The actual exception thrown is coming from:\n01-12 17:38:01.663  4972 13132 E ActivityManager: Activity Manager Crash\n01-12 17:38:01.663  4972 13132 E ActivityManager: java.lang.UnsupportedOperationException: VR mode not supported on this device!\n01-12 17:38:01.663  4972 13132 E ActivityManager:   at com.android.server.am.ActivityManagerService.setVrMode(ActivityManagerService.java:12682)\n01-12 17:38:01.663  4972 13132 E ActivityManager:   at android.app.ActivityManagerNative.onTransact(ActivityManagerNative.java:2930)\n01-12 17:38:01.663  4972 13132 E ActivityManager:   at com.android.server.am.ActivityManagerService.onTransact(ActivityManagerService.java:2794)\n01-12 17:38:01.663  4972 13132 E ActivityManager:   at android.os.Binder.execTransact(Binder.java:565)\nIf you run the TreasureHunt/ControllerPaint samples from the SDK, are you seeing the same crash?. @drksnw I just tried to repro on a 5x with 7.1.1, and didn't see any issues with TreasureHunt/ControllerPaint, which use both the android:enableVrMode attribute as well as the AndroidCompat.setVrModeEnabled API.\nIf you remove all references to VR mode, does your app work with GVR SDK 1.10.0 and your 5x with 7.1.1?. If you're using GvrView, make sure you're including base.aar in your dependency list.. Glad it's working for you now!. >  I get the \"Place your phone into the headset\" screen followed by the controller test screen, over and over again. The application's screen never appears.\nAre you using a Daydream View headset+controller? What happens after you complete the controller calibration step? A bug report or the logcat would be helpful, thanks.. Yeah, those logs are a bit puzzling, it's as if VrCore fails to persist the active VR state, which causes the ControllerPaint to continually re-trigger the VR entry flow when resumed.\nAre you only seeing this issue when you deploy the app from Android Studio? Can you repro when launching the sample directly from Android's launcher? or from within VR via the Daydream app launcher? Do any other Daydream apps exhibit this issue on your device? You might try clearing \"Google VR Services\" app data/cache. I haven't been able to repro locally so far, but I haven't tried deploying directly from Android Studio.. OK, thanks for the update. Do you have the same issue with the TreasureHunt sample? Or is it just ControllerPaint? Apologies for asking so many questions, just trying to diagnose the problem.. VrActivityTheme is defined in common.aar. It's not clear why your project would fail to find this at runtime, assuming it's including the correct common.aar library (though I didn't see a resource failure in your logcat, maybe there was a runtime exception getting stripped out?).\n@sigmaxipi any ideas? . If you add:\ncompile 'com.google.vr:sdk-common1.10.0'\nto the dependencies, does that resolve the problem?. Woops, that should have been\ncompile 'com.google.vr:sdk-common:1.10.0'. Interesting, though I'm still unable to reproduce the issue.  Just to confirm, you're using a stock Google Pixel? With Android 7.1? Could you share the build number (Settings -> About phone -> Build number).  And you're not running any background utility/third-party apps that try to evict processes/Activities or manage memory/CPU? And you haven't enabled the \"Don't keep activities\" settings in Android developer options?\nThe fact that base.aar includes those resources is actually an oversight (thanks for pointing that out!), and should be resolved in the next SDK push. However, it's not clear why removing the windowDisablePreview attribute from the style would resolve the issue you're seeing.\n. No worries, thanks for your patience in debugging the issue. I suspect enabling the \"Don't keep activities\" confuses our bookkeeping for the active VR app, which causes the repeating VR entry screen loop. Regardless, it's good to know what the symptoms here look like, I'll see if there's anything else we should be doing on our end to properly handle this case. Cheers.. We're still finalizing the keyboard SDK and APIs.. Hi @b95505017, we'll be release a video player sample in the next SDK release, which shows how to use the low-level video viewport API. This is particularly relevant if you'd like to play protected content, though the API is functional only on Daydream-ready phones.\nIf you simply want to inject a Surface into your scene, you might try using GvrView + drawing a SurfaceTexture-backed GL quad.. Hi @tvkamara, good catch. The videoplayer sample will be included in a (near) future release. It should help serve as a guide for using an external Surface for the exact purpose you need, rendering video with async reprojection. We'll update this bug when the sample has been released.\nIn the meantime, is there any particular part of the \"Using video viewports\" guide which you feel needs more detail or explanation?. Per the original request, the video player sample is now open source, but please consider the advice of @sigmaxipi for your needs. Thanks.. Hi @Ornolfr, there's an undocumented API which allows touch-based control of the widget view (VrWidgetView.setPureTouchTracking(true)). Will that work for your needs?. @bri-bri just to be clear, are you saying this drift is not present in the 1.0.0 release? Or the 0.9.0 release?\nAlso, could you please add more details about your setup, e.g., phone model, Android build version, etc...? And do you experience the same drift in the SDK/NDK samples? Thanks.. Sorry, that last comment was, do you experience the same drift in all the SDK/NDK samples. Also, are you using a Daydream headset? Or a Cardboard headset?. @SoumyaBasheer does this issue occur for you with the 1.0.0 SDK release?. Thanks for the update, narrowing the regression range between 1.0.0 and 1.0.1 is very helpful. We're looking into this internally, and will post an update with our findings.. A great number of tracking-related fixes have gone into our tracking pipeline in the past year, thanks for bringing this to our attention.. Hi @lixiang-robot, we're definitely aware of the demand for Vulkan support, and have been actively investigating related integration. However, at this time we still have nothing concrete to share, and it will likely be some time (i.e., more than just another SDK release or two) before that changes. Rest assured that we're not ignoring this issue, however, and thanks for expressing your interest.. This sounds like a Xiaomi platform issue, as the added Display should never be null. In the meantime, we'll add some safeguards to the GVR SDK. The workaround should be in the next GVR SDK release.\nUnfortunately, I'm not sure this is something you can fix on your end, though you might ask and report under what circumstances your users are seeing this issue.. @Chico3001 does this issue still reproduce with the latest (1.40.0) SDK release?. In theory the 6P should still work properly with the emulator, however, the controller+emulator path is not officially supported (or tested) on pre-N devices. Can you try upgrading your 6P to Android Nougat (7.0+) and get back to us?. Hey @Cbaoj , could you try again with the latest (1.40.0) emulator APK, and the latest version of Google VR Services? Thanks.. Closing without further feedback or error logs.. Hi @dthian, thanks for the feedback. We're hoping to consolidate and standardize our arm model as part of the public GVR SDK/NDK, though we don't have a definitive timeline for releasing this.\nThe API wasn't included with the initial 1.0 launch as we didn't feel like we'd perfected the implementation, and wanted to get some initial feedback from Unity/Unreal developers before pushing it out more broadly. @gpx1000's suggestion should be a good starting point, and I'll update this thread when we have more to share. . Apologies for the delayed response. We're still working on this, though we don't have a concrete ETA.. Hey folk, the arm model has seen a good amount of iteration internally, but we've finally converged on something and we should be ready to expose this in the public API within the next release or two. Thanks for your patience.. The arm model will be included in the upcoming SDK release (in several weeks). This will initially only be exposed through the native controller C API.. @mgatelabs: Yes, due to time constraints the arm model API was released first only as part of the native APIs. We'll be working to add support for the Java APIs as well. Apologies for the hassle.. When you're running in mono 2D mode, do you actually need any behavior provided by GvrLayout or the NDK? If you don't (i.e., you don't need distortion rendering or head tracking), my first suggestion would be to swap out GvrLayout for whatever kind of View you need to properly render in 2D.\nNote that there's an \"unofficial\" API to disable some stereo mode features, via GvrLayout.setStereoModeEnabled(). However, all this does is disable the UI overlay and prevent any VR entry screens from showing; you'd still need to customize your render path to avoid the distortion path. Without async reprojection, this should be fairly straightforward, as you can simply bind the default framebuffer and render as usual. However, with async reprojection, that approach will not work, and there's actually no good workaround that allows you to preserve GvrLayout's position in your View hierarchy. This is actually a known issue with GvrView, that it doesn't actually support toggling distortion correction when async reprojection is enabled. We'll see about addressing this in a future release, and will post here with more details.\n. @scorpeeon I'm going to close this out per the latest comments, feel free to file a new issue with additional needs, thanks.. Closing per the suggested workarounds.. Hi @ChrisCW1 , are you using the latest version of the GVR SDK?. We're looking into this, thanks for the report.. Apologies for the delayed response.\nThe issue here is that these devices are shipping with VR mode support, but don't actually ship with Google VR Services installed on the system image. We'll soon be releasing Google VR Services to all devices that have Android N, not just Daydream-ready devices, at which point users will be able to download and install the app and continue using VR.\nWe'll also be updating the next SDK release to suppress this warning dialog for VrVideoView.  I'll close this bug when both Google VR Services is universally available and we've released the updated SDK. Thanks for your patience.. Google VR Services is now available for all Android N devices, so your users should have no issues downloading and installing it. We've also updated the widgets to avoid triggering the dialog when Google VR Services is unavailable.. Thanks for the feedback @pbnjay. You're absolutely right, that is not valid C and appears to have slipped through the cracks. We'll be sure to fix with the next release. Cheers.. Hi @dbsGen, are you still experiencing this issue with the latest SDK? Also, on what Android device (including OS version) did you observe the issue? Thanks.. Closing without further repro steps or details.. Hi @scorpeeon, thanks for the feedback. These samples have evolved over time, and you are absolutely correct that there are some issues with thread-safety. We'll try to update these to ensure consistent thread-access when necessary..\nIn particular, the methods \nnativeOnCreate()\nnativeOnDestroy()\nare fine to invoke from the UI thread (create() because there is not yet any native object, and destroy() because at that point we've stopped the GL thread), but the others ought to occur on the GL thread as you've stated.. This should be addressed in the latest SDK release, thanks again for the feedback!. Hi @dvdobrovolskiy, any chance you could share a bug report (adb bugreport video_tracking.zip) or some logs which capture the problem? Thanks.. Unfortunately, there's no way to explicitly suppress thermal throttling other than reducing the workload of your app. The simplest way is to enable sustained performance mode per @sigmaxip's suggestion, and tuning your app workload accordingly.. Currently, the gvr_buffer_viewport_set_external_surface_id API is intended solely for use with the video APIs exposed by GvrLayout. See the SDK video guide for sample usage, and the SDK Video Player Sample. We'll be fleshing out this API a bit more in a future release, but note that it is currently restricted to compositing quad layers into eye space, i.e., it doesn't support arbitrary sampling from the external Surface.\nWould it be sufficient for the API to create and return a Surface you can provide to your codec (or rendering framework, by way of eglCreateWindowSurface())?. We depend directly on ExoPlayer (https://github.com/google/ExoPlayer) for loading video, and there have been quite a few updates to that library since September. Feel free to re-open the issue if the loading behavior is still flaky.. By chance, do you have display scaling configured on our S7 (configured in the \"Display\" section of Android settings)? We've seen some issues related to custom display scaling configurations, and will be rolling out a fix as part of the broader Google VR Services release to all N devices.. Thanks for the report, we'll start the investigation.. Unfortunately, this issue appears to be with the phone's GPU driver. Please give it a try with the Android N update for this phone, and re-open the issue if it's still a problem.. Interesting, thanks for the report. Is it only the 6p which continues to struggle using the smaller render target scale, or does the Pixel XL show similar numbers?. Thanks for the suggestion. At this point, we're likely not going to extend the Eye class all that much, but you can use the built-in Matrix.invertM() Android method.. Apologies, but we cannot offer any specific legal guidance. The linked Apache License is the correct one for our project, the code contained therein and its use in any dependent projects. On a more general note, there are many commercial projects which use libgvr_audio.so.. Hi @ian-wevr, I'll make sure one of our developers follows up on this soon, both with respect to the tearing as well as the GL state mutation.. Hi @ian-wevr. It's possible this issue was resolved with a recent Google VR Services push (version 1.5).. Have you installed Google VR Services from https://play.google.com/store/apps/details?id=com.google.vr.vrcore&hl=en?. > Yes and I actually deleted the 1.30 version from my source folder and installed the 1.40 version and I still have that problem.\nRight, but I'm talking about the app Google VR Services, available from the Play Store. This is separate from the Google VR SDK that you're using to compile your app. Have you installed the app from the Play Store? If so, can you please capture a bug report: adb bugreport vrservices_warning.zip.. Hi @binoculars88. The latest videowidget release should no longer trigger this message. Can you give it a try?. @Roselynn39: Which web browser (including version) are you using that triggered this message? Chrome currently requires the installation of Google VR Services in order to use the latest VR functionality. Is it not available with your tablet?. Regardless, we're planning to remove the installation prompt on devices that aren't Daydream-ready. Expect a fix in the next SDK release (targeting mid-February).. The latest release should no longer trigger this prompt.. So, this only happens when you've paired a Daydream headset. We actually use the touch contact with the Daydream View headset to automatically align the displayed image. This allows convergence if the phone is slightly misaligned in the headset.. Please re-open with a full bug report or more complete logs. Thanks!. @Anton111111 : That's correct, the current sample only supports Daydream-ready phones.. Hi @hrmsa, we're working on a sample for generalized video support. In the meantime, you can simply draw your SurfaceTexture as a quad in your scene using the usual GVR APIs (e.g., GvrView).. In general, tablets aren't well supported by the Daydream/Cardboard APIs. At some point we might revisit this. Sorry for the trouble.. What if you change your screen resolution back to the native resolution? Does that resolve the issue?\nSee also the discussion @ https://github.com/googlevr/gvr-unity-sdk/issues/421. You might try installing Google VR Services to see if that helps?. We're actually rolling out an update for Google VR Services that will prompt the user to update their resolution to native, but we'll only do that for Daydream-ready devices like the S8. In the meantime, my suggestion would be to not enable VR mode (Activity.setVrModeEnabled()) on the S7.. Feel free to re-open with additional details or context for the problem.. Thanks for the report. Tablets aren't officially supported on the Cardboard/Daydream platform. Can I ask what the use-case is for the app you're testing? Are you using a panoramic widget? Or GvrView?. Hi @swratten, are you still seeing this error with the latest SDK release?. Closing without further feedback. Note that tablets aren't officially supported with the GVR SDK.. Feel free to re-open if you're seeing the same problem after reencoding to a smaller resolution.. Hi @nikhilcheruku12, you're absolutely right that the controller assets aren't included in the GVR SDK, though we do embed the assets in the Unity/Unreal GVR SDKs. We'll see about fixing this discrepancy.\nIn the meantime, we will be including a new API for arm model support in the next SDK release.. The Java APIs do not currently support the arm model. It is accessible via the native APIs, though it looks like our devsite docs don't yet reflect the addition. The API is described here: https://github.com/googlevr/gvr-android-sdk/blob/master/libraries/headers/vr/gvr/capi/include/gvr_controller.h#L226. . Thanks for the report, this is fixed in the latest SDK.. Can you re-post this to the GVR Unity GitHub repo? https://github.com/googlevr/gvr-unity-sdk. Thanks.. Hi @miraclehwan, DaydreamApi.create() will only return a valid instance if you're running on a Daydream-ready phone. Otherwise it returns null. What model phone are you using?. You cannot pass null as the PendingIntent argument. You need to use something like:\nIntent permissionsIntent = new Intent(context, /* insert activity class here */);\nPendingIntent pendingPermissionsIntent = PendingIntent.getActivity(context, 0, permissionsIntent, PendingIntent.FLAG_ONE_SHOT);\nWhere you use the appropriate class/ComponentName for the Activity that will request the permission.. @miraclehwan: The only existing prompt to exit VR is provided by DaydreamApi.exitFromVr().. Did that not work for you?. This can occur when entering VR mode, when the screen enables low persistence mode and enforces certain brightness values. Typically the brightness is set to a level that is deemed consistent across Daydream devices. If your app is purely a Cardboard app, you might consider disabling VR mode, but if it supports Daydream, unfortunately there's no way around this at the moment.. Do you have enableVrMode in your Activity manifest?. See https://github.com/googlevr/gvr-android-sdk/blob/532b73c745e61256232176951e657694664ef122/settings.gradle#L13. You need to run the extractNdk() step first. . You'll need to run the extractNdk() step to pull the libraries out of the .aar file. See also https://github.com/googlevr/gvr-android-sdk/blob/532b73c745e61256232176951e657694664ef122/settings.gradle#L13.. Thanks for the report, but the VideoPlayer is only supported on Daydream-ready devices (the Nexus 9 is not Daydream-ready). Execution on unsupported devices will often result in undefined behavior (see the restriction @ https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-videoplayer/src/main/AndroidManifest.xml#L21).. This VideoPlayer sample uses some special APIs for drawing protected content to externally-managed Surfaces, a path which is unsupported on non-Daydream devices. The videowidget uses a very different rendering approach.. @moonfan: Can you share which version of Google VR Services you have installed? And what Android build you're using? Thanks. If you could capture and share a bug report, that would be even better. . There was an issue with the VideoPlayer sample on Huawei devices, but it should have been fixed in the latest 1.80.0 release. Can you try again with the updated libraries?. Feel free to re-open with additional details about the issue. Thanks.. Thanks for the feedback, we're investigating internally.. The next SDK release should properly restrict multiview only to whitelisted devices that are known to support the feature. Apologies for any confusion.. Can you provide more details about the leak? Do you still see the leak in the latest SDK?. Happy to reopen the issue if it's still reproducible with the latest SDK (there have been a large number of changes/fixes since August).. This is a limitation of the VrPanoramaView, which uses a dialog when fullscreen mode is enabled. I'll add this as a feature request, thanks for the report.. Hi @oliguo, your general VR content interaction question would be better served on StackOverflow.. Hi @jkane001, any chance you can share an APK that has the minimal repro? We haven't been able to repro the problem on our end. A bug report might also help. Thanks.. No worries, thanks for the update!. We'll be releasing a new sample in the next SDK release which is dedicated to 360 video rendering. The existing samples-sdk-videoplayer sample is focused primarily on rendering (flat) DRM-protected video using a fast path on Daydream devices.. Thanks for the feedback @ian-wevr. If you could capture a bug report or the logcat when you observe this issue, that would be helpful. Also, what device and (exact) Android version/build are you using? It's possible this was an issue that has since been fixed in Android Oreo.. Yeah, this appears to be a regression in Android in N MR2 (7.1.2), which has since been fixed on Android O. Thanks for flagging, I'll go ahead and close this as the only permanent solution here would be to upgrade to O.. Any chance you could capture and attach a bug report? Thanks. setVrModeEnabled() shouldn't crash either, as long as you have the latest install of Google VR Services.\nEnabling async reprojection also allows frontbuffer rendering, which should reduce motion-to-photon latency.. Without further comment it's hard to diagnose. Feel free to re-open with more details.. Duplicate of issue #484 . Hi @mug797. You should only use the enableAsyncReprojectionVideoSurface() variant if you need to either show DRM-protected or high fidelity video in your application. The external Surface here represents the Surface into which the application can decode the video content, which is then composited by the GVR distortion pipeline.. Hi @leocavalcante, does this problem exist with the latest SDK release (1.80.0)?. If possible, either an attached logcat dump or a full bug report (adb bugreport s8_crash.zip) of the issue would be helpful. Thanks.. Without further details or feedback it's hard to troubleshoot this further. We haven't yet been able to repro. If you can provide more data we'll happily investigate further.. Can you be more specific about the failure you're seeing?. Hi @Adam-VisualVocal. The \"flicker\" you observe is a function of the low persistence display setting when entering VR mode. Low persistent reduces motion blur, and makes for a crisper VR experience.\nThat said, some users are particularly sensitive to this flicker, which is why Pixel phones allow users to toggle off low persistence to reduce flicker. We explicitly don't expose an API to disable this as most users benefit from the low persistence mode, so it should not be up to the app, but to the user.\nAs far as the S8, I'll flag this issue to Samsung to see about exposing the option to users going forward. Thanks for the feedback.. > On the Samsung Galaxy S8 series there is no setting to reduce flicker as far as I know. Because some OEMs aren\u2019t exposing this setting, we need an API to control it programmatically.\nI agree that this needs to be addressed. I've flagged the issue internally and we'll be passing it along to Samsung (and other OEMs) to see about exposing this user setting more broadly.\n\nIt only makes the display dim and flickery for 100% of the people I've shown this to.\n\nJust curious, do you show it to them out of the headset? Or only in the headset? The flicker is far more apparent when looking at the phone as you would normally look at them outside of the headset, from a distance of a foot or two+. So the experience as viewed from several feet away (as captured in the video) may not translate directly to the experience in the headset.\n. > For the moment, ours is a Cardboard app so we're using a range of viewers\nIf you don't absolutely need low-latency rendering, you could stop enabling VR mode (and also not use async reprojection, if you were doing so previously). Enabling VR mode is what puts the device into low-persistence mode, and is really only required for Daydream apps that use async reprojection.. So, there are two slightly different knobs here:\n1) Android's \"VR\" mode\n\nEnabled via [Activity.setVrModeEnabled](https://developer.android.com/reference/android/app/Activity.html#setVrModeEnabled(boolean, android.content.ComponentName), or AndroidCompat.setVrModeEnabled\nThis is an Android-specific setting which puts the system in a state highly tailored to immersive VR experience, e.g., enabling low-persistence on the display, adjusting clock rates, etc... It's not actually immediately involved in stereo rendering.\n\n2) GvrView's \"Stereo\" mode\n- Enabled via GvrView.setStereoModeEnabled\n- This is what actually enables stereo, per-eye rendering callbacks in the VR composition pipeline.\nFor historical reasons, the two APIs are orthogonal, and you can safely use GVR's \"Stereo\" mode for Cardboard apps without enabling Android's \"VR\" mode (the latter having been introduced in Android N, available only on certain phones).. Ah, I didn't realize you were using Unity. You might post a note on StackOverflow and/or https://github.com/googlevr/gvr-unity-sdk to see if there's a way to selectively toggle the Android VR mode while still getting stereo Cardboard support.. Hi @mug797 . The position field is used in conjunction with the arm/elbow model. See also the ApplyArmModel method.. Hi @dustinkerstein, can you provide any more details about repro conditions? Are you using the GVR SDK directly, or an engine (Unreal/Unity)? It would also help if you could attach or send a bug report which captures the problem (adb bugreport missed_frames.zip). Also, is the dropped frame behave similar between the Pixel XL and the Moto Z, or are there differences? Thanks.. @dustinkerstein: That would actually be very helpful. Feel free to email me directly if you prefer not to attach. Thanks.. Hi @davidcox70, would you mind filing a separate bug, describing your symptoms, the Android version on the device, the exact device model (there are many S8 flavors)? Preferably with a bug report that has the \"enable performance monitoring\" option enabled from the developer settings on Google VR Services (you can activate developer options by tapping the Build version icon from the settings menu 7 times). Thanks.. Right, I'm not disputing that the symptoms appear similar. Howeer, the S8 can have very different performance profiles depending on the model (Mali vs Qualcomm).\nAlso, @davidcox70, when you say \"sticky\" head tracking, is it just a single frame that is being dropped? Or multiple frames? How frequently does this occur in Daydream home?. Those of you observing the issue on the S8 exynos, if you could capture a bug report and forward to me (let me know if you'd prefer a reply from a google.com alias), that would be very helpful. . Thanks for the reports, we've finally been able to repro the issue on our end. I'll report back as details emerge. And thanks for your patience.. Hey all, yesterday we pushed an updated rendering configuration for Exynos-based S8 devices. That should alleviate the periodic frame drops seen on these devices. Please confirm whether you notice an improvement. Note that you might need to restart your device (or at the very least, kill your application process completely) for the new configuration to take effect. I should also note that you'll need the latest version of Google VR Services.. Yes, some apps that are heavy might still exhibit the occasional stutter, but there should be at least some slack affordance now for hitting vsync. Thanks all for your patience.. That kind of error is typically benign, and shouldn't cause a crash unless the class is used (rather than simply referenced). Can you post the full logcat or bug report?. The key problem here is that the SDK VideoPlayer sample is intended only for Daydream-ready devices, and has a minSdkVersion of API 24. Running on an API 19 device will likely fail in a number of different ways.. Hi @liquid8d, are you still able to reproduce the crash with the latest emulator and Google VR Services release?. Closing until further feedback and confirmation that this is still an issue. Thanks for the report.. You're absolutely right, this should be fixed now.. Right, we're in the middle of migrating our release notes to GitHub (see https://github.com/googlevr/gvr-android-sdk/releases/tag/v1.100.0).. Hi @Adam-VisualVocal, this is a legacy API that unfortunately isn't well documented. We'll try to address that in the next release.\nIn general, programmatic switching of the headset is discouraged, and is now no longer supported. It should typically be the user's choice to select the headset with which they want to experience VR. Can I ask what specific use-case you have in mind?\n. It looks like part of the issue is that the API for setting the default profile is infrequently used, and the policy for Google VR Services has always been to reject headset injection from any untrusted source. This is probably why you're only hitting the gvr_set_default_viewer_profile issue on Daydream-ready devices, as they have Google VR Services preinstalled.\nWe've recently added some UI to Google VR Services to simplify switching between headsets (there's a \"Recent\" headset section when you go to switch the headset). Would that, together with a fix that enables gvr_set_default_viewer_profile with VR Services, be sufficient for your needs?. Actually, @Adam-VisualVocal, which API(s) are you using for Cardboard support? If you're using GvrView, you can call GvrView.updateViewerParams() to override the parameters for just the local Cardboard app. Note that you'll probably have to call this after every Activity.onResume() signal, as we manually read the system viewer params after every GvrView.onResume() call.\nThat's probably the surest bet for now to make your app's experience consistent and self-contained. Let me know if that works for you.\nIn the meantime, HeadMountedDisplayManager is mostly an internal implementation detail, and it's probably a mistake for it to be documented publicly, for the reasons mentioned earlier about being a legacy API.\n. This will be fixed in the next release of Google VR Services (~mid May). That is, the API should function as long as no headset has been explicitly paired by the user (or by another app).. If anybody can still repro with the latest SDK release, it would help to include the logcat output of the repro. Thanks.. The current videoplayer sample is Daydream-only. The sample requires a specific set of hardware/software features to use the accelerated video path.. Due to the complexity and fragility of the previous implementation of GL state restoration, we were forced to deprecate and remove the API. You'll have to write your app in such a way as to not assume anything about GL state before/after drawing your scene.. Hi @enginegl , could you try changing the VrActivity manifest from\nandroid:configChanges=\"orientation|screenSize\"\nto\nandroid:configChanges=\"orientation|screenSize|uiMode\"\nAndroid O introduces a new \"vrheadset\" UI mode, which can cause Activity recreation unless you explicitly declare that you handle such a configuration change in your manifest. With our next GVR SDK release, our samples will be updated to indicate the appropriate configChangesflags.  If that doesn't work, please re-open the bug. Cheers.. Yes, you'll want to add uiMode to any Activity that acts as a transition point into or out of VR.. Hi @hankewei, are you still observing the crash with the latest SDK release?. Happy to re-open the issue if it's still reproducible.. HI @njudit8, can you include which version of the SDK you're using, and which version of Google VR Services (if any) you have installed? Thanks.. @njudit8: Are you seeing the same problem with the SimpleVideoWidget sample provided by the SDK? Have you updated your SDK to the latest 1.20.0 release? The VR Views (pano/video widgets) wouldn't necessarily be fixed by a VrCore upgrade.. Hi @njudit8. We landed a fix in the 1.30 SDK release. Pleas give that a try, and re-open if it's still unresolved. Thanks for your patience.. What exactly do you mean by a \"switch openning\"? You should be able to use this API on any supported headset, though it will only return a rotation matrix for existing Cardboard/Daydream headsets.. GVR_FEATURE_HARDWARE_BUFFERS is a purely option feature, and shouldn't be used in most cases. It's perfectly fine for the platform to report that this feature is unsupported.\nCan you add any more details about the failure you're seeing? What Android device/version are you using? Can you include a bug report or logs of the failure? Thanks.. Without more details, it's hard to proceed. Feel free to re-open this bug if you have a concrete use-case that requires this feature, otherwise it's probably not the API you're looking for.. Thanks for the report, you're absolutely right, that should reference setRenderTargetScale(). This has been fixed internally, and will be included in the release after the one that will be pushed next week. Cheers.. The NDK TreasureHunt sample offers an example of drawing a gaze-centered reticle: https://github.com/googlevr/gvr-android-sdk/blob/master/samples/ndk-treasurehunt/src/main/jni/treasure_hunt_renderer.cc#L474. The code is slightly different, as it's not using the higher-level Java APIs, but that should be a good template to follow.\nBeyond that, this kind of question is probably better posed on StackOverflow.. Hi @SopMar, you'll need to make sure that you have version 26 of the Android SDK Build-tools installed with your local Android SDK installation. Here are some instructions to help guide you through the process.. Thanks for the report @shauntc, we're tracking this issue internally. I'll reply when we have something more to share.. Hi @Anton111111, it is by design that the recenter behavior is yaw-only. You could implement your own form of pitch recentering by storing a rotation offset at the time of recenter, and applying that to the provided poses thereafter.. Which flavor of the GVR API are you using? Is it VrVideoView? Or GvrView? Or Unity?\nThere is some related discussion in #490. With GvrView, you could update the parameters to be that of your viewer whenever the app resumes. That approach doesn't override the globally configured viewer.\nAlternatively, you can try setting the \"default\" viewer to be your viewer, but that only works if no global viewer has been configured previously (by way of the Cardboard or Google VR Services apps).\n. Feel free to re-open if none of the offered suggestions work for you.. Thanks for the request, @hannesa2. While we don't accept pull requests directly, we're tracking this suggestion internally. Cheers.. HI @Anton111111, this kind of question is better suited to StackOverflow.. Hi @radvani, thanks for the report. \n\nCan this be fixed in a future release, or are these libraries incompatible?\n\nYes, we'll look into fixing this for the next release.\n\nAs a workaround, will it break things if I simply repackage the gvr-common AAR by removing these three classes, instead making it rely on the ARCore equivalents?\n\nYep, that should work.. Both the gvr-common.aar and the embedded classes.jar file are simple zip archives. so you should be able to extract the .aar, then the.jar, remove the offending classes, then zip them back up in turn.\nThe conflicts should be removed (or at least sufficiently obfuscated/altered) in the next release in mid February.. Yes, we'll be pushing an updated SDK version next week, hopefully by Wednesday.. Thanks for the proposal. We don't accept pull requests directly, but we'll be sure to update our samples to use the latest ExoPlayer version in the next release (ETA mid February).. Thanks for the fix. While we don't accept pull requests directly, we'll be sure to include a fix in the next release.. Hi @MrCsabaToth, the VideoPlayer sample does currently require a Daydream-ready device. Part of the problem is that the OnePlus 3t has declared itself as a Daydream-ready device, but it hasn't actually undergone Daydream-ready certification, so not all of the associated software features may work correctly. Are you able to install the Daydream app from the Play Store?. Also, would you mind sharing what Android build you're using with the OnePlus 3t? Are you by chance using OxygenOS or one of the other mod flavors that has manually marked the device as being Daydream-capable?. Could you include a bug report or logs, or at the very least more information about the Android and device version you're using?. You'll probably have better luck posting this on https://github.com/googlevr/gvr-unity-sdk, though I don't think this is related to the core GVR SDK.. You can access those settings from the developer section of Google VR Services:\n1. Open VR settings (tap the gear icon on a Daydream app).\n2. Tap the \"Build Version\" button 7 times.\n3. Open the \"Developer Options\" section.. Thanks @rickardeklof, we're now tracking this internally. Just to be clear, are you using the GVR SDK directly (if so, are you using GvrView? or the NDK)? Or are you using Unity? A full bug report and/or repro APK would be helpful. I'll reach out to you directly.. Sounds good, I'll follow up privately.. Just an update here, we've discovered some issues in the GPU driver that are causing the visual artifacts, and are awaiting feedback from Qualcomm. Thanks for your patience.. We don't have any immediate plans, but if you have a strong use-case for shipping an x86 binary on the Play Store we can consider it. Most x86 devices can consume the native arm libraries that we ship.\nThe x86 libraries that we publish are intended primarily for testing with emulators, where there's no Play Store requirement for embedding both 32 and 64-bit native libraries.. > Is this a general Android feature?\nNot generally, no, though most x86 phones that I'm aware of can also execute arm libraries.\n\nAn x86 Android device like a Chromebook could run an Android app that is packaged with only arm libs?\n\nI believe Chromebooks will run some kind of emulation (different than direct binary translation) for arm Android apps, but I'm not 100% sure.. Were you able to resolve the issue? How exactly are you building the project? Can you post a complete build log?. Without additional feedback it's hard to troubleshoot the problem, feel free to re-open with more details.. The latest 1.40.0 release adds support for CMake.. Hi @isometriq, thanks for the report, we're investigating this internally.\nIf you get a chance to capture a bug report of the issue on your S8, that would be extremely helpful. In particular, it would help to know the exact device name/model, what version of Android you're running, and what version of Google VR Services you have installed. Thanks.. If you have the Android SDK, or access to adb, you can use:\nadb bugreport s8_gvr_bug.zip\nThere are additional instructions here if you don't have access to adb. I'll pm you my @google.com email address to which you can send the report. Thanks.. The log spam will be removed in the next SDK release, expected next week.. This should no longer be an issue with the latest release.. You're absolutely right, looks like the fix just missed the 1.30 release. It will be in the next release, 2 weeks from now. I'll reopen until that is pushed.. Fixed in the 1.40.0 release.. Hi @cversek. The VR mode brightness is intentionally decoupled from the regular system brightness, as the user-customized screen brightness doesn't always map well to the VR experience, particularly with a low-persistence display.\nThat said, there was some plumbing added in Android O to support adjustment of the VR brightness. We'll look into exposing this plumbing publicly for Android P.. What Android version is running on your device?\nUnfortunately, until this is addressed in Android P, the only way for you to handle this in your app is to scale the brightness/contrast of your assets. I should also note that the ability to disable low-persistence is intentionally left to the user, and not the developer; different users are more susceptible to the side effects of low-persistence.. @cversek, could you try doing the following: \n1) Disable wifi\n2) Clear the data/cache for Google Play Services\n3) Clear the data/cache for Google VR Services\nThe Pixel 2 XL display required some workarounds in the GVR SDK which might impact your ability to hit a certain low brightness threshold. By resetting these settings (and disabling wifi to keep them propagating again), you might be able to achieve a lower value. If that makes a difference for you, feel free to message me offline and we can consider a more direct alternative.. Per offline discussion, this seems to be a function of the device. VR-specific brightness may be exposed in a future Android release.. Thanks all for the reports, we'll look into this and report back tomorrow. The mono mode of GvrView isn't quite as thoroughly tested as stereo (\"VR\") mode, so this probably slipped through the cracks during testing of the 1.13 release.\nIf any of you have a link to an existing app in the Play Store (or just a sample app) that is broken with the 1.13 Google VR Services build, feel free to send the link to me directly as that will help speed the investigation.. Thanks @shauntc, that's quite helpful as we weren't seeing this with our non-stereo builds of the GvrView-based TreasureHunt sample. Stay tuned for an update.. Those of you hitting this issue, could you please check to make sure that, when your Activity is resumed and/or your content is active, you're either calling GvrView.onResume (for the SDK) or GvrLayout.onResume (for the NDK)?. Can anybody else confirm whether adding .onResume() calls resolves the issues they're seeing? We're debating a hotfix rollout of Google VR Services, but if the suggested workaround works for everybody we might hold off.. OK, just be sure to call .onPause() when your Activity is paused and/or the magic window experience is paused, and also .shutdown() when your Activity is destroyed and/or you no longer need to use the GvrView/GvrLayout instance.. Assuming the onResume() call works for everybody, I'm going to close this issue. If folks are unable to work around the issue, feel free to add a note here and I'll consider reopening. Apologies for the unexpected breakage, I'll be sure to add some stronger notes to our documentation about the need for calling onResume()/onPause()/shutdown().. The sdk-common library is required for the widgets. Can you try removing the exclusion of that library?. We're pushing a fix for the aidl collision in the next release, which should be pushed tomorrow or Wednesday.. The S8's display will enter low-persistence mode when VR mode is enabled. When viewing the display outside of a VR headset, this can make it seem like it's flickering unusually. However, when viewed inside the headset, it actually improves the experience by reducing apparent motion blur.. Feel free to re-open if you find that this is an issue with the SDK or you're having trouble profiling per the suggestions from @sigmaxipi.. Good catch, we'll try to get this fixed in the next release.. Expect a doc fix in the 1.50 release. Thanks again for the report.. I'm not aware of any specific change that might have caused this. Are you using the GVR SDK directly, or one of the engines (Unity/Unreal)? Is your application manifest identical to what is was previously?. Yeah, you might also try explicitly/programatically adjusting focus when the Daydream Activity is shown. Feel free to re-open the issue if you think this is specific to Daydream.. Hi @dkshin. The VideoPlayer sample is actually only supported on Daydream-ready phones, so it's not unexpected that you're seeing issues on the 5x.\nDuplicate of #523.. Does the SDK sample (SimpleVideoWidget) work properly for you?. Would you mind attaching a bug report that captures the issue on this device? Or sending a bug report to me directly? Thanks.. Hi @fanrenyi, without access to this specific device, and without a bug report, there's no much more we can do.. Hi @Anton111111, for better or worse, this is expected behavior on Samsung devices when the device enters VR mode. You'll have to exit VR via the \"X\" button in order to use or interact with the system UI.. Right, those are Cardboard apps, and they may not enable the system VR mode. Daydream apps are required to enable the Android system VR mode.. Any chance you can attach a bug report that captures the problem?. A bug report will show stack traces for the other threads of the ANR. Without it, it's hard to say what exactly is blocking the main thread.. Hi @davidcox70, would you mind filing this on the Unity-specific GitHub project? Thanks!. I don't quite understand the question, can you try attaching a screenshot and/or bug report?. There's no API to do this unfortunately. The problem is that the external Display can have different dimensions than the phone Display, so it doesn't always make sense to try to mirror the displays. Can I ask why exactly you need the phone screen functional in this case?. Hi @achuvm, can you try adding uiMode to the android:configChanges attribute in your manifest?. Hi @Consti10, what device are you using when you observe the issue? And what orientation is your Activity? You mentioned that this behavior changed in 1.140.0; was it different in 1.130.0? Thanks.. Actually, this sounds a lot like issue #536. Can you make sure you're calling GvrLayout.onResume() when the Activity is resumed (and onPause() when the Activity is paused)?. Hi @VR-Nima, you're right that this particularly scenario yields suboptimal UX. We'll look into improving this to avoid users getting stuck.. Hi @Consti10, for the case where the Activity is being resumed multiple times, this can happen on Daydream-ready phones (like the ZTE Axon 7) when the VR session is first started. Have you enabled the \"Skip VR entry screens\" in the developer options, by chance?. Vertex distortion is incompatible with async reprojection, as you noted, but we require async reprojection for all Daydream apps (https://developers.google.com/vr/distribute/daydream/performance-requirements#PS-P2). Why are you more concerned about video latency than motion-to-photon latency? You won't be able to get the necessary ~20ms motion-to-photon latency on a Daydream-ready phone without frontbuffer rendering, which is implied with GVR's async reprojection.\nTo indicate that your app is Daydream-compatible, you must specify that in the Activity manifest using <category android:name=\"com.google.intent.category.DAYDREAM\" />. See also https://developers.google.com/vr/reference/vr-manifest#platform_compatibility.. If you add <category android:name=\"com.google.intent.category.DAYDREAM\" /> to your Activity's manifest, that should at least allow your app to proceed through the VR entry screens successfully with a Daydream View headset. Can you give that a try?\nNote that that will still interrupt your app when it is first launched, but it won't require the user to modify the developer settings.. > So the user shouldn't be able to start the VR activity from \"Daydream home\" but with these settings he can.\nYou can prevent the Activity from appearing in the Daydream VR launcher by marking it with android:exported=\"false\". \nThe problem I am seeing here is that this activity is not a \"Daydream activity\" because it breaks with the basic daydream principles like \"always have a controller for navigation, usw\" , it just wants to use the daydream headset as a normal VR headset.\nDoes your app not use the Cardboard trigger at all? We're considering adding support for a Daydream app declaring \"optional\" controller support, which would avoid the controller connection UI when entering VR. Would that work for you?\nNote that that would still interrupt your Activity to show the 2D transition screen.\nGoing back to the root of the problem, is the brief Activity resume->pause->resume sequence causing problems besides redundant GL context creation? Or are you simply wanting to optimize the flow and avoid some of the associated jank?. > > Does your app not use the Cardboard trigger at all? We're considering adding support for a Daydream app declaring \"optional\" controller support, which would avoid the controller connection UI when entering VR. Would that work for you?\n\nNo, I'm not using it. That would be great. How long will it be until that's possible ?\n\nPotentially with the next release of Google VR Services (in ~6 weeks).\n\nI can get rid of that using mGvrLayout.getUiLayout().setTransitionViewEnabled(false);\n\nThat works for Cardboard, but for Daydream we require the transition view. We might revisit that decision in the future to reduce VR entry friction.\n\nNonetheless, documenting this behaviour would be great. It took me quite a while to figure it out.\n\nWe'll soon be publishing some documentation for all of the developer options, including the \"Skip VR entry screens\" option. I'll make sure we make a note that this currently will result in a rapid resume/pause/resume sequence of the app on Daydream-ready devices.\n. Hi @kpilyugin, we're investigating this now, will report back with our findings.. Is your (client) GL context ES 2 or ES 3? If you're unsure, and you're using a GLSurfaceView, can you try calling GLSurfaceView.setEGLContextClientVersion(3)? . Good to know. We're tracking this internally and I'll let you know when we have an ETA for a fix.. > Is there some way that I can inject the right codecs or change some config to support the file?\nYou'll likely need to use a downscaled video asset to get this to work automatically on lower-end devices.\n. Any chance you can attach the surrounding logs (adb logcat) for context? Or send a bug report directly?. ",
    "FreeWifiInVan": "The T-Mobile revvle plus has 2 small squares and I don't know how to fix them. ",
    "Angie-Ie": "Yes I have runned the adb logcat. In the script cardboard.cs, this part: InitDevice(); crashed and went error, it force close the program. But when I tried the demo scene of cardboard package on other smartphone (Xiaomi HM1S) it successfully worked.\nFYI:\n- The android version of LG L90 is Kitkat 4.4.\n- The Windy Day from cardboard demo successfully worked too.\n. C:\\Users\\Vina\\AppData\\Local\\Android\\sdk\\platform-tools> adb logcat -s Unity\n--------- beginning of /dev/log/system\n--------- beginning of /dev/log/main\nD/Unity   (11709): GL_AMD_compressed_ATC_texture GL_AMD_performance_monitor GL_A\nMD_program_binary_Z400 GL_EXT_debug_label GL_EXT_debug_marker GL_EXT_discard_fra\nmebuffer GL_EXT_robustness GL_EXT_texture_format_BGRA8888 GL_EXT_texture_type_2_\n10_10_10_REV GL_NV_fence GL_OES_compressed_ETC1_RGB8_texture GL_OES_depth_textur\ne GL_OES_depth24 GL_OES_EGL_image GL_OES_EGL_image_external GL_OES_element_index\nuint GL_OES_fbo_render_mipmap GL_OES_fragment_precision_high GL_OES_get_program\n_binary GL_OES_packed_depth_stencil GL_OES_depth_texture_cube_map GL_OES_rgb8_rg\nba8 GL_OES_standard_derivatives GL_OES_texture_3D GL_OES_texture_float GL_OES_te\nxture_half_float GL_OES_texture_half_float_linear GL_OES_texture_npot GL_OES_ver\ntex_half_float GL_OES_vertex_type_10_10_10_2 GL_OES_vertex_array_object GL_QCOM\nalpha_test GL_QCOM_binning_control GL_QCOM_driver_control GL_QCOM_perfmon_global\n_mode GL_QCOM_extended_get GL_QCOM_extended_get2 GL_QCOM_tiled_rendering GL_QCOM\n_writeonly_rendering GL_EXT_sRGB GL_EXT_sRGB_write_control GL_EXT_texture_sRGB_d\nec\nD/Unity   (11709): ode GL_EXT_texture_filter_anisotropic GL_EXT_multisampled_ren\nder_to_texture GL_EXT_color_buffer_float GL_EXT_color_buffer_half_float GL_EXT_d\nisjoint_timer_query\nI/Unity   (11709): CardboardMain (Cardboard)\nI/Unity   (11709):\nI/Unity   (11709): (Filename: ./artifacts/generated/common/runtime/UnityEngineDe\nbugBindings.gen.cpp Line: 65)\nI/Unity   (11709):\nI/Unity   (11709): Profile\nI/Unity   (11709):\nI/Unity   (11709): (Filename: ./artifacts/generated/common/runtime/UnityEngineDe\nbugBindings.gen.cpp Line: 65)\nI/Unity   (11709):\nI/Unity   (11709): AndroidVRDevice\nI/Unity   (11709):\nI/Unity   (11709): (Filename: ./artifacts/generated/common/runtime/UnityEngineDe\nbugBindings.gen.cpp Line: 65)\nI/Unity   (11709):\nI/Unity   (11709): 236.6095\nI/Unity   (11709):\nI/Unity   (11709): (Filename: ./artifacts/generated/common/runtime/UnityEngineDe\nbugBindings.gen.cpp Line: 65)\nI/Unity   (11709):\nI/Unity   (11709): SetEventCallback\nI/Unity   (11709):\nI/Unity   (11709): (Filename: ./artifacts/generated/common/runtime/UnityEngineDe\nbugBindings.gen.cpp Line: 65)\nI/Unity   (11709):\n. Hai, i did try, the scan after that point not show any errors\nD/Unity(23684): GL_AMD_compressed_ATC_texture GL_AMD_performance_monitor\nGL_AMD_program_binary_Z400 GL_EXT_debug_label\n                GL_EXT_debug_marker GL_EXT_discard_framebuffer\nGL_EXT_robustness GL_EXT_texture_format_BGRA8888\n                GL_EXT_texture_type_2_10_10_10_REV GL_NV_fence\nGL_OES_compressed_ETC1_RGB8_texture GL_OES_depth_texture\n                GL_OES_depth24 GL_OES_EGL_image GL_OES_EGL_image_external\nGL_OES_element_index_uint GL_OES_fbo_render_mipmap\n                GL_OES_fragment_precision_high GL_OES_get_program_binary\nGL_OES_packed_depth_stencil GL_OES_depth_texture_cube_map\n                GL_OES_rgb8_rgba8 GL_OES_standard_derivatives\nGL_OES_texture_3D GL_OES_texture_float GL_OES_texture_half_float\n                GL_OES_texture_half_float_linear GL_OES_texture_npot\nGL_OES_vertex_half_float GL_OES_vertex_type_10_10_10_2\n                GL_OES_vertex_array_object GL_QCOM_alpha_test\nGL_QCOM_binning_control GL_QCOM_driver_control\n                GL_QCOM_perfmon_global_mode GL_QCOM_extended_get\nGL_QCOM_extended_get2\n                GL_QCOM_tiled_rendering GL_QCOM_writeonly_rendering\nGL_EXT_sRGB GL_EXT_sRGB_write_control\n                GL_EXT_texture_sRGB_dec\n07-13 10:14:27.562: D/Unity(23684): ode GL_EXT_texture_filter_anisotropic\n                GL_EXT_multisampled_render_to_texture\nGL_EXT_color_buffer_float GL_EXT_color_buffer_half_float\n                GL_EXT_disjoint_timer_query\n07-13 10:14:27.572: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.582: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.582: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.582: D/BluetoothAdapter(1235): 1106803368: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.592: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.602: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.602: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.602: D/BluetoothAdapter(1871): 1106597072: getState() :\n mService = null. Returning STATE_OFF\n07-13 10:14:27.612: I/RemoteControlStatusBar(1235): showRemoteControlView\n[isEnabled]:false [isPortraitOri]:false\n07-13 10:14:27.612: I/RemoteControlStatusBar(1235): showRemoteControlView\n[irRcVisibility]:8 [irRcInfoVisibility]:8\n07-13 10:14:27.612: I/RemoteControlStatusBar(1235): End\nshowRemoteControlView\nUsing cardboard v  0.4.10 running well in my phone\nThank you for your help\nOn Sat, Jul 11, 2015 at 7:24 AM, smdol notifications@github.com wrote:\n\nHm. I don't really see any useful messages in that listing. I would next\nsuggest running adb logcat (without -s Unity), and look for the long\nmessage from Unity (\"D/Unity (???): GL_AMD_compressed_ATC_texture\nGL_AMD_performance_monitor GL_A\nMD_program_binary_Z400 GL_EXT_debug_label GL_EXT_debug_marker\nGL_EXT_discard_fra\nmebuffer GL_EXT_robustness GL_EXT_texture_format_BGRA8888...\"), which is\nwhere the app is starting. Then scan after that point to where the crash\noccurs.\nIs there a stack trace in the log? It would be helpful to see the exact\npoint where the crash happens.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/googlesamples/cardboard-java/issues/25#issuecomment-120555501\n.\n. \n",
    "TheFakeMontyOnTheRun": "That could be useful.\n@svenhenrik , for now, I suggest you counter the rotations from eye matrix. I did that for when my user decides to disable the VR mode, allowing for joystick control of the XZ angle (but I decided to keep the YZ rotation).\nNot the best and optimal solution, but works.\n. Hello @sigmaxipi,\ntried your suggestion, but the result was the same.\nTo be fair, I tried using std::mutex in the past and faced similar issues. How integrated with my host's toolchain is NDK? I kinda expected it to use it's own stuff - and since I have't touched it, everything should be ok.\n. AFAIK, the newest stable NDK version defaults to Clang, right? I'm no NDK 12. Maybe I could try moving into the bleeding edge (since I'm already using gradle-experimental, after all)?\n. I could try removing it, if that's of any help, so we would be sure if the culprit lies on std::thread.\n. By simply commenting out anything touched by the audio initialization thread, I was able to finally run the demo. Thanks!\n(sorry it took me so long. I was incredibly busy).\n. Also, after updating my NDK to the newest version (just released, it seems), the pristine version from the repo now works.\n. ",
    "esminis": "I can confirm - I get ES3.x context instead of ES2.x and sampler object is bound...\nThanks Riccardo for solution. I hope this problem gets fixed\n. > Most x86 devices can consume the native arm libraries that we ship.\nMost but not all. The other issue is if APK is already providing other x86_64 libraries then app will only load x86_64 libraries and will not try x86 or Arm libraries\n\nThe x86 libraries that we publish are intended primarily for testing with emulators, where there's no Play Store requirement for embedding both 32 and 64-bit native libraries.\n\nWhat do you mean there is no requirement to provide 64-bit native libraries, did you read document by Google that we will not be able to upload apps without providing 64-bit native libraries: https://developer.android.com/distribute/best-practices/develop/64-bit\n\nStarting August 1, 2019, your apps published on Google Play will need to support 64-bit architectures.. So as I understand this is official answer from Google VR team - x86 / x86_64 is not supported and will not be supported.. \n",
    "oon3m0oo": "Indeed, when rendering to a context that supports ES3 we use a sampler object, and it wasn't getting cleaned up before calling back to the application.  We'll have a fix in the next release that should properly restore the state.  Thanks for flagging this!\n. ",
    "capsur": "Could an issue like this by any chance convince you to make the SDK available in Maven Central? :smile: \n. ",
    "robhor": "\n@robhor, we just pushed 0.5.8 to fix this issue.\n\nThanks :smile: \n. ",
    "Gousetis": "Can you confirm that your render callback is being executed? If you don't have logs/print statements coming from your render loop, it is likely that the time synchronization logic has a bug in it.\nIf you are getting draw calls, can you check for GL errors, and let me know which Android API version you are running on? Low-latency mode has various implementations based on API, and the bug will depend on what version your phone is running.\n. Hey @ian-wevr, I'll give you a bit of background info but I'll need a bit more data to help debug the issue.\nWhite tear lines/speckles means that the asynchronous thread is being stalled/blocked for much longer than usual. There are a number of possible reasons, and some of the debug logging can help narrow it down.\nCan you get a logcat while the speckles/tears are visible, but with the \"enable developer logs\" and \"enable performance monitoring\" options enabled. If you capture a huge log, just give me a five or six second period of timestamps that show the speckling.\nThe most likely culprit is that you're got some un-preemptable GL work on your application thread. Do you use a compute shader? Do you have a small offscreen render target that consumes the majority of your GPU load (e.g. some sort of expensive lighting pass). Do you use another GL context to render content and/or use Android to render a View heirarchy into a separate buffer?. I would not expect gvr_frame_submit to change any state when asynchronously reprojecting. When you are not asynchronously reprojecting (e.g. normal cardboard flow) there is quite a bit of state change. But I assume you are asynchronously reprojecting, since you're seeing tearing artifacts, yes?. ",
    "hsingla94": "@smdol  Sorry didn't got you and tried searching on stackoverflow didn't got anything. Can you provide a small example ??\n. ",
    "omrison": "Hi,\nI don\u2019t know why I am receiving these emails. Is there a way I can remove myself from the distribution list?\nThanks!\nFrom: hsingla94 [mailto:notifications@github.com]\nSent: Tuesday, October 27, 2015 12:15 PM\nTo: googlesamples/cardboard-java\nSubject: Re: [cardboard-java] Can i add a UI buttons on the screen ?? (#32)\n@smdolhttps://github.com/smdol Sorry didn't got you and tried searching on stackoverflow didn't got anything. Can you provide a small example ??\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/googlesamples/cardboard-java/issues/32#issuecomment-151442990.\n\nThis footnote confirms that this email message has been scanned by\nPineApp Mail-SeCure for the presence of malicious code, vandals & computer viruses.\n\n. ",
    "s-gv": "Update: Downgrading to v0.5.4, which seems to be Java only, fixes the issue.\n. ",
    "kanawish": "I am getting the same issue with Nexus 5X. \nCaused by: java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file \"/data/app/<app>/base.apk\"],nativeLibraryDirectories=[/data/app/<app>/lib/arm64, /data/app/<app>/base.apk!/lib/arm64-v8a, /vendor/lib64, /system/lib64]]] couldn't find \"libvrtoolkit.so\"\n. Yesterday, I actually met someone at the AndroidTO conference who ran into the same issue and found a fix. Apparently the problem can be solved by adding abiFilters to your build. That person shared with me the following gradle snippet: \nNote 1: I did not yet try this myself. \nNote 2: Just saw that this solution was posted to stack overflow, so it's looking very good.\ngroovy\nbuildTypes {\n   release { \n      ndk {\n         abiFilters \"armabi-v7a\", \"armabi\" // Should do the trick.\n      }\n   }\n   debug { \n      ndk {\n         abiFilters \"armabi-v7a\", \"armabi\" // Should do the trick.\n      }\n   }\n}\n. Re-reading my original comment, I realize I didn't even explain that building for Nexus5x (armv8) failed, in the same manner as people have reported for x86. \nHappy to learn you'll be adding further native support :) thank you.\n. Ah! I've made a mistake here. I went back and double checked with the 5X, and it is indeed my project that was the source of the issue, and I'm running into a totally different issue. I've managed to reproduce it in the sample code. It looks like a jni library inclusion bug. \nIf I add an Android library module to the sample code, reconfigure the project to use the latest gradle plugin, (2.0.0-alpha1) and move the .jar into this module, I actually get the following at build time:\n`Error:Execution failed for task ':mylibrary:transformNative_libsWithSyncJniLibsForRelease'.\n\njava.io.FileNotFoundException: /$HOME$/android-samples/cardboard-java/mylibrary/build/intermediates/bundles/release/jni/lib/armeabi-v7a/libvrtoolkit.so (No such file or directory)`\n\nThis should (?) normally work. Apparently this is a known issue:\nhttps://github.com/nickbutcher/plaid/issues/45\nhttps://code.google.com/p/android/issues/detail?id=193063\nIf I roll back to Gradle plugin 1.3.1, the build succeeds and indeed works on the 5X. \n. Now, I've gone and rolled back my own personal project to use the 1.3.1 gradle plugin, and I am getting an unsatisfied link error (that's why I was originally so certain I was missing a arm64-v8a .so)\njava.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file \"/data/app/com.kanawish.androidvrtalk-1/base.apk\"],nativeLibraryDirectories=[/data/app/com.kanawish.androidvrtalk-1/lib/arm64, /data/app/com.kanawish.androidvrtalk-1/base.apk!/lib/arm64-v8a, /vendor/lib64, /system/lib64]]] couldn't find \"libvrtoolkit.so\"\nLooking at the stack trace, I'm not sure what I'm doing that is so different than the sample code. \nIf I try to apply the abi filter fix to my config, I get \nThe currently selected variant \"debug\" uses split APKs, but none of the 1 split apks are compatible with the current device with density \"420\" and ABIs \"arm64-v8a, armeabi-v7a, armeabi\".\nwhen trying to run on the 5X. Not sure for now what to try next. I'll report if I find anything else.\nFull stack trace:\nProcess: com.kanawish.androidvrtalk, PID: 25399\n java.lang.RuntimeException: Unable to start activity ComponentInfo{com.kanawish.androidvrtalk/com.kanawish.androidvrtalk.ui.VrTalkActivity}: android.view.InflateException: Binary XML file line #9: Binary XML file line #9: Error inflating class com.google.vrtoolkit.cardboard.CardboardView\n     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2416)\n     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)\n     at android.app.ActivityThread.-wrap11(ActivityThread.java)\n     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)\n     at android.os.Handler.dispatchMessage(Handler.java:102)\n     at android.os.Looper.loop(Looper.java:148)\n     at android.app.ActivityThread.main(ActivityThread.java:5417)\n     at java.lang.reflect.Method.invoke(Native Method)\n     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\n     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\n  Caused by: android.view.InflateException: Binary XML file line #9: Binary XML file line #9: Error inflating class com.google.vrtoolkit.cardboard.CardboardView\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:539)\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:423)\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:374)\n     at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:393)\n     at android.app.Activity.setContentView(Activity.java:2166)\n     at com.kanawish.androidvrtalk.ui.VrTalkActivity.onCreate(VrTalkActivity.java:291)\n     at android.app.Activity.performCreate(Activity.java:6237)\n     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)\n     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2369)\n     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)\u00a0\n     at android.app.ActivityThread.-wrap11(ActivityThread.java)\u00a0\n     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)\u00a0\n     at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n     at android.os.Looper.loop(Looper.java:148)\u00a0\n     at android.app.ActivityThread.main(ActivityThread.java:5417)\u00a0\n     at java.lang.reflect.Method.invoke(Native Method)\u00a0\n     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\u00a0\n     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\u00a0\n  Caused by: android.view.InflateException: Binary XML file line #9: Error inflating class com.google.vrtoolkit.cardboard.CardboardView\n     at android.view.LayoutInflater.createView(LayoutInflater.java:645)\n     at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:764)\n     at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:704)\n     at android.view.LayoutInflater.rInflate(LayoutInflater.java:835)\n     at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:515)\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:423)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:374)\u00a0\n     at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:393)\u00a0\n     at android.app.Activity.setContentView(Activity.java:2166)\u00a0\n     at com.kanawish.androidvrtalk.ui.VrTalkActivity.onCreate(VrTalkActivity.java:291)\u00a0\n     at android.app.Activity.performCreate(Activity.java:6237)\u00a0\n     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)\u00a0\n     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2369)\u00a0\n     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)\u00a0\n     at android.app.ActivityThread.-wrap11(ActivityThread.java)\u00a0\n     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)\u00a0\n     at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n     at android.os.Looper.loop(Looper.java:148)\u00a0\n     at android.app.ActivityThread.main(ActivityThread.java:5417)\u00a0\n     at java.lang.reflect.Method.invoke(Native Method)\u00a0\n     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\u00a0\n     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\u00a0\n  Caused by: java.lang.reflect.InvocationTargetException\n     at java.lang.reflect.Constructor.newInstance(Native Method)\n     at android.view.LayoutInflater.createView(LayoutInflater.java:619)\n     at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:764)\u00a0\n     at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:704)\u00a0\n     at android.view.LayoutInflater.rInflate(LayoutInflater.java:835)\u00a0\n     at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:515)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:423)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:374)\u00a0\n     at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:393)\u00a0\n     at android.app.Activity.setContentView(Activity.java:2166)\u00a0\n     at com.kanawish.androidvrtalk.ui.VrTalkActivity.onCreate(VrTalkActivity.java:291)\u00a0\n     at android.app.Activity.performCreate(Activity.java:6237)\u00a0\n     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)\u00a0\n     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2369)\u00a0\n     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)\u00a0\n     at android.app.ActivityThread.-wrap11(ActivityThread.java)\u00a0\n     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)\u00a0\n     at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n     at android.os.Looper.loop(Looper.java:148)\u00a0\n     at android.app.ActivityThread.main(ActivityThread.java:5417)\u00a0\n     at java.lang.reflect.Method.invoke(Native Method)\u00a0\n     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\u00a0\n     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\u00a0\n  Caused by: java.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file \"/data/app/com.kanawish.androidvrtalk-1/base.apk\"],nativeLibraryDirectories=[/data/app/com.kanawish.androidvrtalk-1/lib/arm64, /data/app/com.kanawish.androidvrtalk-1/base.apk!/lib/arm64-v8a, /vendor/lib64, /system/lib64]]] couldn't find \"libvrtoolkit.so\"\n     at java.lang.Runtime.loadLibrary(Runtime.java:367)\n     at java.lang.System.loadLibrary(System.java:1076)\n     at com.google.vrtoolkit.cardboard.CardboardViewNativeImpl.<init>(CardboardViewNativeImpl.java:103)\n     at com.google.vrtoolkit.cardboard.ImplementationSelector.createCardboardViewApi(ImplementationSelector.java:35)\n     at com.google.vrtoolkit.cardboard.CardboardView.init(CardboardView.java:905)\n     at com.google.vrtoolkit.cardboard.CardboardView.<init>(CardboardView.java:241)\n     at java.lang.reflect.Constructor.newInstance(Native Method)\u00a0\n     at android.view.LayoutInflater.createView(LayoutInflater.java:619)\u00a0\n     at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:764)\u00a0\n     at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:704)\u00a0\n     at android.view.LayoutInflater.rInflate(LayoutInflater.java:835)\u00a0\n     at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:798)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:515)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:423)\u00a0\n     at android.view.LayoutInflater.inflate(LayoutInflater.java:374)\u00a0\n     at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:393)\u00a0\n     at android.app.Activity.setContentView(Activity.java:2166)\u00a0\n     at com.kanawish.androidvrtalk.ui.VrTalkActivity.onCreate(VrTalkActivity.java:291)\u00a0\n     at android.app.Activity.performCreate(Activity.java:6237)\u00a0\n     at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)\u00a0\n     at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2369)\u00a0\n     at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)\u00a0\n     at android.app.ActivityThread.-wrap11(ActivityThread.java)\u00a0\n     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)\u00a0\n     at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n     at android.os.Looper.loop(Looper.java:148)\u00a0\n     at android.app.ActivityThread.main(ActivityThread.java:5417)\u00a0\n     at java.lang.reflect.Method.invoke(Native Method)\u00a0\n     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\u00a0\n     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\n. @dav-cz I don't have any other .so in my project that I can see. (I don't have any of my own, and I took a quick look at my project dependencies, I did not see any other native libs.)\nI'll try playing around with my project structure when I find some time, see if I can isolate the issue, or perhaps replicate it with the Cardboard SDK sample code.\n. @jclova and others that might be interested, (while waiting on the new .aar structure Cardboard SDK) I seem to have a solution specifically for the 'lib build' problem in my own library. The hack is to extract the libvrtoolkit.so file from the cardboard .jar, and move it into my library module under myModule/main/jniLibs/armeabi-v7a/libvrtoolkit.so.\nI still include the cardboard.jar under myModule/lib as I would otherwise.\nNOTE: Using AS 2.0 beta2 and it's associated build tools\nADDENDUM: With this hack, I now see it actually still breaks at runtime on non armv7 devices, so your best bet is to keep cardboard.jar in your application module, closely following the structure of the Treasure hunt example.\n. Hello @jazzyjester. I've personally been off Eclipse since pre-Android-Studio days, so I can't really speak to that setup or the build chain on an Eclipse setup.\nAs of writing, the only way I got my example code running cross-platform under the new build system was by moving away from using library modules (as per above discussion). The hack above worked for arm-v7a devices, but the final .APK crashes at native lib load time.\nIf you're curious, check out my un-modularized code sample. It's messy, but for my purposes (an Intro-to-Cardboard conference talk) it does the job.\n. I've been seeing this issue on the Tango NVidia/Shield tablet, in my attempts to get the Cardboard Java SDK working on it. The proposed workaround seems straightforward enough. \nSomewhat related, I'm hoping to use the Tango APIs to get some head positional tracking capabilities, (on top of the current head orientation tracking). If anyone on this thread has pointers, or is looking for similar info, I've posted a Stack Overflow question \n. ",
    "powderluv": "Im using buck to build for arm64-v8a and my app fails to load with the same stack trace posted above. I think if the next cardboard.jar included the various other architectures it should work. Im going to try to stub the native lib to see if I can get it to work on arm64-v8a. \n. ",
    "marktani": "I had the same issue on my OnePlus One.\n- I could perfectly build and run the sample SDK on the phone. \n- I got a similar linker error during run time for my own project on the phone.\nI fixed it by changing the gradle version for my own project from 1.3.0 to 1.5.0 and that's it.\n. ",
    "Chainfire": "Still no support for anything else than arm v7a with 0.6.0. If there's any real reason (compiler incompatibilities, hand-optimized assembler not easily ported, cthulhu being in a particularly bad mood, whatever), I'm sure we could all understand if you'd just share it.\n. ",
    "jclova": "Hi @kanawish,\nI am the guy whom you met in AndroidTO.\nAlso the same person who posted the solution to the stackoverflow.\nbuildTypes {\n   release { \n      ndk {\n         abiFilters \"armabi-v7a\", \"armabi\" // Should do the trick.\n      }\n   }\n   debug { \n      ndk {\n         abiFilters \"armabi-v7a\", \"armabi\" // Should do the trick.\n      }\n   }\n}\nAbove code made it work for me for all Intel devices (Zenfone 5) & 64-bit devices (S6, Note 5).\nHowever, like @kanawish mentioned, when I build a library that uses CardboardSDK, then it doesn't work. I get a compile time error: \n```\nError:Execution failed for task ':(project):transformNative_libsWithSyncJniLibsForRelease'.\n\njava.io.FileNotFoundException: /(path)/build/intermediates/bundles/release/jni/lib/armeabi-v7a/libvrtoolkit.so (No such file or directory)\n\n```\nYou can easily reproduce this:\n1.  Create an empty project.\n2.  Create an Android library module.\n3. Add cardboard.jar to the libarary/lib folder.\n4. Add \"compile fileTree(dir: 'libs', include: ['*.jar'])\" to the library build.gradle.\n5. Press: \"Sync Project with Gradle Files\" button.\nFor convenience, I attached the project for you to easily reproduce this issue.\nhttps://drive.google.com/open?id=0BygTefPD845LbERwcTFqakR1aDg\nI hope aar solves this issue.\nCardboardSDKTest2.zip\n. Thank you @kanawish, your solution works like a charm.\n. Also confirming @kanawish's ADDENDUM above.\nNon armv7 devices don't work. Reverting back to the old version that doesn't use libvrtoolkit.so.\nI will wait for the AAR.\n. I know this thread has been closed, but I don't think following command fixes the issue.\n<intent-filter>\n<action android:name=\"activities.PlaybackActivity\" />\n<category android:name=\"com.google.intent.category.DAYDREAM\" />\n<category android:name=\"com.google.intent.category.CARDBOARD\" />\n</intent-filter>\nAbove code will now force users to pair a Daydream Headset & controller. You cannot continue without pairing a controller. What if you don't have a Daydream headset (at the moment) and just want to view using the cardboard headset (and possibly one that does not have a QR code)? On non-Pixel phones, a default cardboard value is being used to play in the VR mode. However, on Pixel phone, you either get:\n1. \"This Cardboard application is not compatible with Daydream headsets\" error without above code in the AndroidManifest.\n2. \"Place your phone into the Daydream headset\" + \"To get started, aim forward and hold the Home button\" message and cannot continue without paring with above code in the AndroidManifest\nIn summary, I am asking if there is a solution for a Pixel phone if you only have a cardboard with you that does not have a QR code.. @jdduke \nAssuming the app has enabled both Daydream & Cardboard:\n<intent-filter>\n<action android:name=\"activities.PlaybackActivity\" />\n<category android:name=\"com.google.intent.category.DAYDREAM\" />\n<category android:name=\"com.google.intent.category.CARDBOARD\" />\n</intent-filter>\nSteps:\n1. Launch the app (from the Pixel phone)\nResult: OK, plays in the cardboard\n2. Launch a daydream app\n3. Launch the app\nResult: Ask you to insert into daydream viewer (and then connect Daydream controller). Only way to view in the cardboard is to select settings -> Scan QR code -> Scan a cardboard QR code.\nIf we could at least select 'default' cardboard option without scanning QR code, then it will be good. However, without having a cardboard without QR code around, you're stuck.\nPlease let me know if I am only seeing this issue.\n. Btw, I am asking from a regular user's perspective.\nThe current solution not the end of the world, but I was just hoping if there is any simpler/more intuitive solution.\nIt would be really nice to have a 'default' cardboard option to select for those who does not have the non-QR code cardboards.. Similar. I ran this sample app on Pixel phone and I only see a black screen with a spinning wheel (not animating) in the center. No sound either.\nFrom the source, I only modified the build tool version to \"25.0.3\".\n. Screenshot: http://imgur.com/a/tt1n8\nPixel phone: Android 7.1.2\nAndroid Studio: 3.0 beta 1\nSource code: Latest 1.80.0 release\nOnly modified build too version to '25.0.3'\nDependency versions:\n    compile 'com.google.android.exoplayer:exoplayer:r2.4.0'\n    compile 'com.google.android.exoplayer:extension-gvr:r2.4.0'\n    compile 'com.google.vr:sdk-base:1.80.0'\n    compile 'com.google.vr:sdk-common:1.80.0'. ",
    "jazzyjester": "Hello \nI tried @kanawish solution in eclipse and it didn't worked.\nI have error like that in 0.6.0 cardboard.jar version\n[2016-02-22 17:06:52 --Default] The library 'cardboard.jar' contains native libraries that will not run on the device.\n[2016-02-22 17:06:52 --Default] Additionally some of those libraries will interfer with the installation of the application because of their location in lib/\n[2016-02-22 17:06:52 --Default] lib/ is reserved for NDK libraries.\n[2016-02-22 17:06:52 --Default] The following libraries were found:\n[2016-02-22 17:06:52 --Default]  - lib/armeabi-v7a/libvrtoolkit.so\n. ",
    "ph0b": "I've seen the AAR has been released with v0.7.0 but it only includes armeabi-v7a architecture.\narm64-v8a and x86 libraries are available separately here: https://github.com/googlesamples/cardboard-java/tree/master/libraries/native\nWhy not including these by default in the AAR?\nIt's much less error-prone for developers to filter them out when needed, using abiFilter for example, than having to reinclude them manually outside of the gradle dependency system, after having noticed crashes such as the ones related above.\nHaving armeabi-v7a only aars causes a lot of troubles when the rest of your codebase supports other architectures. Can you please improve this and support a maximum of architectures directly within the .aar ? btw, this issue is quite related to this improvement I've proposed regarding lint-checks about the handling of dependency with native components: https://code.google.com/p/android/issues/detail?id=94805 \n. both ways will lead apps that aren't configured correctly, with a consistent set of libs for each architecture, to crash. It's not just bloat.\nIn any case, it's a lot better to let people use abiFilter to filter architectures if they want, which is truly 1 step that is going to survive across version upgrades, than the other way around that requires 4 manual steps for each new releases - which is going to lead to even more crashes when people will upgrade the .aar and not the additional libs.\n. ",
    "isometriq": "Here's a follow-up ..I was able to run the latest GVR lib on the emulator. I've answered my issue here, with some instructions:\nhttps://github.com/googlevr/gvr-android-sdk/issues/138\nI've only used the trick that was proposed and discussed here ..so thanks for that.\n. Ok, I was able to make it work!\n1. unzip the \"base.aar\" file\n2. go to \"/jni\"\n3. create a folder \"x86\"\n4. copy the \"libgvrbase.so\" file from here:\n   https://github.com/googlevr/gvr-android-sdk/tree/master/libraries/native/x86\n5. zip the contents (and rename back to \"base.aar\" file), cleanup, etc\n6. compile and run\nIMPORTANT: I had to make sure the \".aar\" file and \".so\" were from the same version (got all the files from tag 0.8.1)\nThis now it works in the Nexus5 API21 emulator with recommended settings and HAXM accelerated.\nFound the hints here:\nhttps://github.com/googlevr/gvr-android-sdk/tree/master/libraries/native\n. Works with the files from tag 0.9.1\n. Ok, I did not realized this had changed. I can see that also in the \"get-started\".\n. It works now\n. Tested on another phone (LG G6) and I did not get the messages. Will try other ones as the occasion arises.. Tested other ones: Samsung S6 and Samsung S7.\nI did not get the message also on these.\nOnly on the Samsung S7, these 2 warnings appearing when shutting down:\n01-22 14:44:50.096 18029-18745/com.testing.gvr W/native: sensor_fusion_mahony.cc:189 Invalid timestamps detected.  Time step between successive gyroscope sensor samples exceeded threshold. Resetting orientation filter and bias.\n01-22 14:45:05.576 18029-18777/com.testing.gvr W/native: sensor_fusion_mahony.cc:189 Invalid timestamps detected.  Time step between successive gyroscope sensor samples exceeded threshold. Resetting orientation filter and bias.. Can you point in the right direction to create such a report ?\nI can provide the device info, but if the report includes it, I would rather use that.. ",
    "guanshan": "In  CardboardView.java, the  function onTouchEvent has been implemented like this\uff1a\npublic boolean onTouchEvent(MotionEvent e) {\n        if (this.cardboardViewApi.onTouchEvent(e)) {\n            return true;\n        }\n        return super.onTouchEvent(e);\n}\nso\uff0c If you want get the ACTION_DOWN event\uff0coverride it.\n. @dav-cz Thanks for your reply.\nIt's our own VR machine.\nI change the dpi, and it works finally.\nThank you so much!\n. ",
    "openforeveryone": "Yes the first error, as I understand, is simply an exception thrown when trying to read the settings for the cardboard hardware and this happens on any device that has not scanned a cardboard barcode (or for which the file had been removed). This just causes cardboard SDK to use the default settings and carry on regardless.\nThe JNI error, which is clearly causing the crash, is indeed a little odd to only be happening on Tango. Will it be possible for you (once you to do the check that JNI requires and see if the object you have is null before calling GetObjectClass) to do something graceful here? \nIt is worth noting that the Tango Tablet does report a sensible DPI:\njava\nDisplayMetrics metrics = new DisplayMetrics();\ngetWindowManager().getDefaultDisplay().getMetrics(metrics);\n Log.i(TAG, \"Screen Density: \" + metrics.density);\n Log.i(TAG, \"Screen Density DPI: \" + metrics.densityDpi);\nPrints:\nScreen Density: 2.0\nScreen Density DPI: 320\nWhile I have enough experience working with JNI on Android to probably be able to fix this myself (or at least find a workaround) it is happening from within the binary blob libvrtoolkit.so within the SDK. So it looks like it will have to be fixed by yourself Smdol or someone else with access to the source code and preferably also to a Tango Tablet.\n. I have just tested v0.6.0 with my Tango tablet and it would seem that this issue has now been resolved.\n. This should be corrected by pressing the settings button, pressing \"setup\" then \"switch viewer\". You can then scan the QR code printed on your cardboard device.\nIf there is no QR code for your cardboard or it does not work, you can make a new one at https://www.google.co.uk/get/cardboard/viewerprofilegenerator/. (This may not work with Firefox)\n. I have a blog post on how to play equirectangular 3d vr videos here: https://matthewwellings.com/blog/playing-vr-videos-in-cardboard-apps/ . \n. ",
    "RubenGarcia": "I don't know. \nI'm using the cardboard from \nhttp://mini.com/360\n. I signed it!\n. ",
    "andregm3": "check this app has drift solution:\nhttps://play.google.com/store/apps/details?id=org.hitlabnz.sensor_fusion_demo\nOpen Source:\nhttps://bitbucket.org/apacha/sensor-fusion-demo/\n. Also a disable distortion correction button would be nice, and you can let only advanced users to access this if you want.\n. we don't want it only in our games, we want it in all.\n. ",
    "ajavamind": "FYI, Using the Samsung S6,  my app built with 0.9.1 SDK did not experience any perceivable drift. When I moved to 1.0.3 there is now a large amount of drift that prevents me from publishing with the latest SDK.\n. Also just discovered that with 0.9.1 my app will drift after 20 seconds (with static display/fixture), but by running https://play.google.com/store/apps/details?id=com.eclipsim.gpsstatus2&hl=en\na GPS status and calibration app to calibrate, this latent drift problem went away. \nCould these drift issues be resolved with GPS calibration in Viewer settings button function?\nthanks!\n. My mistake saying GPS calibration, the app does not have a GPS calibration, it has a pitch/roll and a compass calibration.\n. Thanks Jared, I'm able to remove use of GLSurfaceView in the code afterall,\nso I don't need getGLSurfaceView() going forward. thanks,\nAndy\nOn Fri, May 20, 2016 at 7:42 PM, Jared Duke notifications@github.com\nwrote:\n\nHi @ajavamind https://github.com/ajavamind, is there a particular API\nor feature of GLSurfaceView that you require? The getGLSurfaceView() method\nwas technically hidden, and added only as a temporary stopgap measure to\nease the transition away from depending on GLSurfaceView directly. Note\nthat we do expose a subset of GLSurfaceView's API directly, e.g.,\nsetEGLConfigChooser(), setEGLConfigContext(), and queueEvent().\nThe primary motiation for removing GLSurfaceView from the public API is\nthat it gives GvrView's implementation a lot more freedom to customize the\nView hierarchy and tailor the SurfaceView interaction.\nIf there is need and strong demand, we're open to evolving GvrView's API\nto accommodate any gaps in functionality that may have been introduced.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/93#issuecomment-220742941\n. Adding my view of this issue: The alignment marker and settings button are now seen in larger field of view viewers. Developers must be able to control this visual distraction and be able to remove its display.\n. The app is Cardboard only. I tried using AndroidCompat.setVrModeEnabled(this, false) to disable VR mode but it still dims the screen on the S8 despite being Cardboard only.. No. The Samsung S6 and S7 phones have Android 7 updates from T-Mobile and do not exhibit dim screen issue, only the S8.. Is there any way to disable low persistence mode which seems to be cause of problem with the S8? My answer to this question was to disable Google VR Services (version 1.7.161000338. Then my Cardboard only app screen brightness did NOT dim anymore.\nI would suggest @jdduke, please reopen this bug.. \n",
    "yolanother": "This one I know I'm seeing on the same L devices as the other thread that is going, but I believe I also experienced this with the note 5 as well. I can get the updates to apply if I remove the cardboardview  and recreate it.\n. Android L. NVIDIA Shield TV\n. App I built and other sample apps as well. I'm seeing the message saying that the config file was read successfully. I have seen the failure message on other projects that don't have permission to read external storage.\n. Do you have a suggestion for what tags I should be watching for? I'm currently monitoring HeadMountedDisplayManager which is where the \"Successfully read device params from external storage.\" came from.\n. Here is a full log from an unmodified CardboardSample:\nI/ActivityManager(  610): Start proc 21484:com.google.vrtoolkit.cardboard.samples.treasurehunt/u0a69 for activity com.google.vrtoolkit.cardboard.samples.treasurehunt/.MainActivity\nI/art     (21484): Debugger is no longer active\nV/NFC     (21484): this device does not have NFC support\nE/PhoneParams(21484): Error parsing param record: incorrect sentinel.\nI/HeadMountedDisplayManager(21484): Successfully read device params from external storage\nD/CardboardViewNativeImpl(21484): NativeProxy not found\nD/CardboardViewNativeImpl(21484): Loading native library vrtoolkit\nD/CardboardViewNativeImpl(21484): Native library loaded\nW/art     (21484): Attempt to remove local handle scope entry from IRT, ignoring\nW/art     (21484): Attempt to remove local handle scope entry from IRT, ignoring\nW/art     (21484): Native thread exiting without having called DetachCurrentThread (maybe it's going to use a pthread_key_create destructor?): Thread[14,tid=21509,Native,Thread*=0x64434100,peer=0x12d100a0,\"Thread-2137\"]\nW/art     (21484): Attempt to remove local handle scope entry from IRT, ignoring\nW/art     (21484): Attempt to remove local handle scope entry from IRT, ignoring\nE/PhoneParams(21484): Error parsing param record: incorrect sentinel.\nD/OpenGLRenderer(21484): Use EGL_SWAP_BEHAVIOR_PRESERVED: true\nI/OpenGLRenderer(21484): Initialized EGL, version 1.4\nD/OpenGLRenderer(21484): Enabling debug mode 0\nV/RenderScript(21484): 0x64416400 Launching thread(s), CPUs 4\nI/MainActivity(21484): onSurfaceCreated\nI/MainActivity(21484): onSurfaceChanged\nW/System.err(21484): java.lang.SecurityException: Permission denied (missing INTERNET permission?)\nW/System.err(21484):    at java.net.InetAddress.lookupHostByName(InetAddress.java:451)\nW/System.err(21484):    at java.net.InetAddress.getAllByNameImpl(InetAddress.java:252)\nW/System.err(21484):    at java.net.InetAddress.getAllByName(InetAddress.java:215)\nW/System.err(21484):    at com.android.okhttp.HostResolver$1.getAllByName(HostResolver.java:29)\nW/System.err(21484):    at com.android.okhttp.internal.http.RouteSelector.resetNextInetSocketAddress(RouteSelector.java:232)\nW/System.err(21484):    at com.android.okhttp.internal.http.RouteSelector.next(RouteSelector.java:124)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpEngine.connect(HttpEngine.java:272)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpEngine.sendRequest(HttpEngine.java:211)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:382)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.connect(HttpURLConnectionImpl.java:106)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getOutputStream(HttpURLConnectionImpl.java:217)\nW/System.err(21484):    at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getOutputStream(DelegatingHttpsURLConnection.java:218)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getOutputStream(HttpsURLConnectionImpl.java:25)\nW/System.err(21484): Caused by: android.system.GaiException: android_getaddrinfo failed: EAI_NODATA (No address associated with hostname)\nW/System.err(21484):    at libcore.io.Posix.android_getaddrinfo(Native Method)\nW/System.err(21484):    at libcore.io.ForwardingOs.android_getaddrinfo(ForwardingOs.java:55)\nW/System.err(21484):    at java.net.InetAddress.lookupHostByName(InetAddress.java:438)\nW/System.err(21484):    ... 12 more\nW/System.err(21484): Caused by: android.system.ErrnoException: android_getaddrinfo failed: EACCES (Permission denied)\nW/System.err(21484):    ... 15 more\nW/System.err(21484): java.lang.NullPointerException: Attempt to invoke interface method 'void com.android.okhttp.internal.http.Transport.writeRequestHeaders(com.android.okhttp.Request)' on a null object reference\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:611)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:388)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:332)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponseCode(HttpURLConnectionImpl.java:500)\nW/System.err(21484):    at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getResponseCode(DelegatingHttpsURLConnection.java:105)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:25)\nW/System.err(21484): java.lang.NullPointerException: Attempt to invoke interface method 'void com.android.okhttp.internal.http.Transport.writeRequestHeaders(com.android.okhttp.Request)' on a null object reference\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:611)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:388)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:332)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getHeaderFieldKey(HttpURLConnectionImpl.java:170)\nW/System.err(21484):    at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getHeaderFieldKey(DelegatingHttpsURLConnection.java:202)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getHeaderFieldKey(HttpsURLConnectionImpl.java:25)\nW/System.err(21484): java.lang.NullPointerException: Attempt to invoke interface method 'void com.android.okhttp.internal.http.Transport.writeRequestHeaders(com.android.okhttp.Request)' on a null object reference\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpEngine.readResponse(HttpEngine.java:611)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.execute(HttpURLConnectionImpl.java:388)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getResponse(HttpURLConnectionImpl.java:332)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpURLConnectionImpl.getHeaderField(HttpURLConnectionImpl.java:148)\nW/System.err(21484):    at com.android.okhttp.internal.http.DelegatingHttpsURLConnection.getHeaderField(DelegatingHttpsURLConnection.java:174)\nW/System.err(21484):    at com.android.okhttp.internal.http.HttpsURLConnectionImpl.getHeaderField(HttpsURLConnectionImpl.java:25)\nE/nvwsi   (21484): failed to get fences from file\nAnd here is a full log with internet permission added:\nI/ActivityManager(  610): Start proc 24555:com.google.vrtoolkit.cardboard.samples.treasurehunt/u0a69 for activity com.google.vrtoolkit.cardboard.samples.treasurehunt/.MainActivity\nE/art     (24555): Failed sending reply to debugger: Broken pipe\nI/art     (24555): Debugger is no longer active\nV/NFC     (24555): this device does not have NFC support\nE/PhoneParams(24555): Error parsing param record: incorrect sentinel.\nI/HeadMountedDisplayManager(24555): Successfully read device params from external storage\nD/CardboardViewNativeImpl(24555): NativeProxy not found\nD/CardboardViewNativeImpl(24555): Loading native library vrtoolkit\nD/CardboardViewNativeImpl(24555): Native library loaded\nW/art     (24555): Attempt to remove local handle scope entry from IRT, ignoring\nW/art     (24555): Attempt to remove local handle scope entry from IRT, ignoring\nW/art     (24555): Attempt to remove local handle scope entry from IRT, ignoring\nW/art     (24555): Native thread exiting without having called DetachCurrentThread (maybe it's going to use a pthread_key_create destructor?): Thread[14,tid=24576,Native,Thread*=0x64435500,peer=0x12d100a0,\"Thread-2142\"]\nW/art     (24555): Attempt to remove local handle scope entry from IRT, ignoring\nE/PhoneParams(24555): Error parsing param record: incorrect sentinel.\nD/OpenGLRenderer(24555): Use EGL_SWAP_BEHAVIOR_PRESERVED: true\nI/OpenGLRenderer(24555): Initialized EGL, version 1.4\nD/OpenGLRenderer(24555): Enabling debug mode 0\nV/RenderScript(24555): 0x64416400 Launching thread(s), CPUs 4\nI/MainActivity(24555): onSurfaceCreated\nI/MainActivity(24555): onSurfaceChanged\nE/nvwsi   (24555): failed to get fences from file\n. Interesting I ran with my new config through an old version of cardboard-java sdk, turned off write_external_storage, and ran it with the new version and it worked. Then I did it with write_external_storage granted and it still worked, so I'm not sure what was causing things to break for me. I'll update if I am still broken once I have time to do more testing.\n. ",
    "cemrich": "Thank you for your response!\nJust to understand your design decision: Why is it you can distinguish between the magnet trigger and any other or no input method then? Is this a leftover from an older API? \nPlease don't get me wrong, but I think a good UI for devices without trigger has to look different than for devices with any trigger (regardless of the type). For example you would need a \"select by long gaze\" feature for devices without trigger only. For other devices the progress indicator could be confusing, because you can select items more intuitively by using the provided button. So CardboardDeviceParams#getHasTrigger() instead of CardboardDeviceParams#getHasMagnet() would help a lot.\n. Thank you very much for the clarification.\n. ",
    "bfouet-gpsw": "Are you able to provide some sort of a list of the supported devices, based on testing on your side, and what we users have reported?\nAt least, having a way to get the error from the SDK instead of the silent fail would help to build the black list dynamically: when a device fails, an error could be sent back to the developer to help him build the list.\nPlease note that I get your point, I'm just trying to find a way to ease our lives as developers on top of the SDK.\n. Hi @dav-cz, the returned version is 16.\nI just got side-tracked by the messages in the logcat actually. I think the real issue on this tablet is that is has no sensor support so installing my app on it makes little sense anyway.\nI just tried modifying my renderer a bit so that it forces matrix it receives to the identity, and I can then see the display works just fine.\n(a lot of noise for nothing, sorry about that :-) )\n. ",
    "motorsep": "From the developer of the engine: \"The sdk is apache 2, but the GPL covers the entire work, including any libraries. You can do what you want with the headers Google provides, but that's not the source, and thus not compatible.\"\nI am guessing he is talking about whatever comes in .jar with SDK or any libs that come in object form with SDK.\n. ",
    "sh39sxn": "In the meanwhile I have tried the app on a real device which is connected to the pc/android studio.\nThis way the app works but the rendering problem in android studio still exists.\nI want to develop an own app based on this cardboard-java app. I need a solution for this problem.\nDoes really nobody have the same problem or knows a solution?\n. ",
    "anakin78z": "I did try unrolling the URL. \nThe use case was that we had about a thousand people at the TED conference download a cardboard app for a session and then handed them specific cardboard headsets to use. We wanted the app to default to the settings for the viewer we handed out, since we knew it's the one they would be using, and there wasn't any time during the session to set up each viewer first. \nIdeally we can default to a specific viewer of our choice, which would then be replaced by whatever the user scans, if the user scans a new headset. \n. Confirming this issue (and also the issue with getting 1 star reviews as a result). \nA bit surprised nobody is assigned to this yet. \n. ",
    "susmit": "I signed it!.\n. ",
    "sewasewa777": "I signed it!. Yo.  #58. #523. H. G. V.  #581. G. #596. #598. ffda940. #599. #602. ",
    "RamIndani": "I used CardboardView but I am not able to get head tracking to work. Do you have any pointers. I have created XML element in layout with CardboardView and setting renderer from fragment.\n. @nathanmartz Treasure Hunt sample sets the setGvrView(gvrView); and extends GvrActivity, setGvrView(GvrView) is not available if you are extending AppCompatActivity or any Fragment. \n. @KCHariram I am not sure what exactly you are trying to do but see if approach mentioned in #135 works for you.\n. The solution so far is to inflate the landscape/horizontal fragment view again, remove previous fragment from parent view and attach new fragment. This works only when you are not allowing activity to destroy when orientation changes.\n. Most probably you are experiencing black screen because your view is destroyed and recreated, try reloading video when orientation changes. I assumed some things before commenting, what I am saying may not apply for you but if you haven't given try to it then please try once. To better understand what I am saying is to refer android docs regarding orientation change handling in android here\n. Yes, that's why I said for now this is the solution, another question raises when implementing orientation changes is \"How do you know if user is rotating to change the app orientation or rotating to view 360 video at certain angle?\". If you find any better solution then please share.\n. Thanks for the updates.\n. With the latest version of library I am able to reproduce this bug for Samsung Galaxy S3 with Android version 5.1.1 (Cyanogenmod) but I haven't faced this issue on Samsung Galaxy S6 with Android version 5.1.1, Can anyone please confirm? [I face this issue more often in debug mode] @dav-cz Can you please check this?\n. Very basic question, but I am not able to figure out the version number of the library I am using. How to verify which version is referenced in the application? \n. Thanks @dav-cz  I was able to locate it.\n. ",
    "scorpeeon": "dav-cz: great idea, I wouldn't think about that. I tested it by granting the storage permission and not granting the camera permission so that the prompt would still appear, and it indeed looks like in this case that onDrawEye() is called with the correct viewport parameters even when the prompt is shown. So it really isn't the prompt interfering, just the temporary lack of storage permission that's causing this.\nBut this is a bit confusing to me. Based on the changelog I thought the known issue for SDK v0.6.0 for the broken pairing on API 23 was solved in SDK v0.7.0, but apparently this means that it isn't really the case. It's merely a small patch so that when you click the settings icon, it asks for the storage permission, so afterwards it works correctly. But it doesn't solve the problem because as long as you don't click the settings icon, the storage permission is still not granted which is still needed to read the stored Cardboard profile, so an incorrect (default?) profile will be used.\nSo if I understand it correctly, the only real solution would be changing the storing of the viewer profile to some other place where no storage permission is needed, which was being worked on:\n\"We're working on a replacement to our current solution of storing the viewer profile on the S/D card.\"\nSo is this still a known issue that is still being worked on?\n. Were there changes regarding this in the latest release (v0.8.0)?\nI don't see any info in the changelog, but the WRITE_EXTERNAL_STORAGE permission has been removed from the sample app. (though targetSDK got downgraded from 23 to 22...)\n. This issue looks to be fixed in the improved sample app in v1.10.0, so I think it can be closed. @jdduke I added that line, but it doesn't seem to make a difference, it's always crashing when loading the treasurehunt_jni library.\nI'm using the latest stable NDK (installed through Android Studio, shows version 13.1.3345770 - I assume this should be r13b)\nBut I also tried with r14-beta1 and saw no difference.\nOne more thing: it looks like I can reproduce this issue on Nexus 5 and Nexus 7 (2013), both running 6.0.1 - so it looks like it's not a Samsung-related issue. Maybe it's Marshmallow-related? I checked and it looks like the Samsung Grand Duos also ran 6.x (not 5.x like I assumed) - so it looks like all devices I have problem with this run Marshmallow.. I can confirm the problem goes away if I set compileSdkVersion to 21.\n(also had to remove attributes 'enableVrMode' and 'resizeableActivity' from manifest to make it compile). @jduke yeah that's what I thought, thanks for the reply.\nReported it here:\nhttps://code.google.com/p/android/issues/detail?id=231870. Great, thanks for the quick reply!\nSo in my specific case, the app would basically need to have 2 modes: normal VR mode (with head tracking, undistortion and async reprojection all enabled) and normal 2D mode (without all these things). There's no need to switch between them runtime, so I would most likely do that by 2 specific product flavors. (also the issue you mentioned about toggling undistortion shouldn't be a big problem in this case)\nAs far as I know, GvrLayout is needed to be able to create a native GVR context, so swapping that out would need some fundamental changes to the code basically removing most (or all) GVR specific functionality from that build flavor. It might be less problematic as I imagine it now, but I'd go first with a more simple approach if it's possible (as the simple method I mentioned in the Java API).\nYeah, I think the simplest way would be just using the default framebuffer, I'll try and see how it goes. Thanks!. @jduke yeah no problem. your comment was very helpful, I could make it work as you mentioned just by binding the default framebuffer. One other issue I saw was that first the depth buffer didn't work properly, then I realized that was because in the GVR sample apps the GLSurfaceView is initialized with a depth size of 0 (surfaceView.setEGLConfigChooser(8, 8, 8, 0, 0, 0)) but after using a GLSurfaceView with the correct parameters and 16 bit depth size, it all worked as expected.\nThanks for the help again.. Great, thanks!. ",
    "mariobodemann": "afaik, there are no jar files any more. You would need to download the sdk sample and us the aar files in the libraries folder ... \nhttps://developers.google.com/cardboard/android/download\n. ",
    "andrewminton": "Is there a best practice for importing these .aar files I nto our own projects? Classes aren't available when importing the .aar files alone and the docs aren't very clean on this change to .aar at all.\n. ",
    "guanpy": "I want to custom players like this\n\n. ",
    "kfung0426": "+1\nI am seeking remote url support too\n. ",
    "lingkang1988": "This feature is useful, looking forward to seeing it soon\n. Thanks, nathanmartz. I know the SDK includes APIs for spatial audio, however the APIs only accept audio files instead of video files. So if I use google sdk to enable spatial audio when playing video, I need to prepare a separate audio file which is not that accepted.\nSo I have the following two questions:\n1. How does the SDK implement spatial audio? With libraries such as OpenSL ES and Open AL or audio library written by Google? I tried Android OpenSL ES, it seems has no supports for 3D audio(game profile).\n2. If I want to use spatial audio in video playing with Google VR SDK, what is the best practice(as detailed as possible)? \n. ",
    "jksfood": "+1,as soon as possible\n. OK,sorry for my bad english!\nWhy demo of the panoramic picture is on the two parts of the kind, we generally use is a 180 degree panoramic picture ah, panoWidgetView will put this picture drawing, but part of the round black, this is not what I want results.\n. is it need special type  360 image?\n. http://7xs0qt.media1.z0.glb.clouddn.com/search/index/1467357613879.jpg       like this image,why it is mot useful?\n. @xieqiupeng  is that means :http://7xs0qt.media1.z0.glb.clouddn.com/search/index/1467357613879.jpg    this photo is 3d,but the cardboard can only support panorama?\n. ",
    "5bruce": "I met the same trouble.It just can play the local video by this method(loadVideo(Uri)).But if your file is too big ,it does not work.I want to enter the video link, then you can play video. Do not know how to get. This is my demand is not supported? This function is perfect or. thanks!\n. ",
    "wwrrss": "+1 this is a must have! \n. Same issue with note 5 upgraded to Android 6.0.1., i have another note 5 with Android 5.1 and is working fine. \n. ok, thanks for the answer, i will try with a lower resolution \n. ",
    "kvenn": "Just as a follow up to anyone who's interested:\nThe iOS SDK supports this so I can only imagine it is in the pipeline - this is also version 0.7.0 so I have big dreams for this SDK in the future. So I wouldn't really recommend trying to find a way around it.\nBUT if you're really in a pinch (like I was), I got remote URL's to work by building a custom downloader which downloads the .mp4 video resource to the device. Then when it reaches about 10% completion, I start playing the file back using the SDK's loadVideo(String) method. I have a catch in the onError for FileNotFoundExceptions which tells the system to wait a bit, then resume playback when there has been additional progress on the download. This is pretty much just a crummy buffer implementation.\nIt worked fine and was easy to write, but was by no means optimal.\n. ",
    "humhann": "+1, would be very welcoming to have\n. ",
    "BrendanParks": "+1, an out-of-the-box solution to this would be totally awesome\n. ",
    "Millertoken": "@dav-cz hello,when this can be completed?And how can i use other mediaplayers play videos on the videowidget?\n. i also want to play m3u8 videos,can you do this first,please?thank you very much.@dav-cz\n. ",
    "aaronliew": "@dav-cz , thanks for your effort. I have issues in playing the sample video from both local and remote uri. The video was playing, however, the whole screen was black. All I heard was just the audio.  Do you have any suggestions to fix this issue?\n. ",
    "digitalbuddha": "@dav-cz I'm having trouble playing a remote video due to inability to buffer.  The video in question is: http://video1.nytimes.com/video/360-demo/cool.mp4\nWhen I drop the video in as a static asset everything plays perfectly. When trying to stream, the video stops and does not start on its own again.  Is there a way to control how much is download before starting as well as general buffering strategies?\nThe only code change I made to SimpleVrVideoActivity is to change the url in async task to videoWidgetView.loadVideo(Uri.parse(\"http://video1.nytimes.com/video/360-demo/cool.mp4\"),new Options());\nI see that there's some generated code that deals with exoplayer, maybe there are more hooks that can be exposed?\n. 5x N beta 4. Will confirm on lots of devices on Monday\nOn Jun 17, 2016 7:20 PM, \"David Coz\" notifications@github.com wrote:\n\nWhat phone / Android version are you using? Any thing interesting in\nlogcat?\nI'm able to play your video with the sample app on Nexus 5 running Android\n5.0.1.\nadb shell am start -a android.intent.action.VIEW -n\ncom.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"\nhttp://video1.nytimes.com/video/360-demo/cool.mp4\" --ei inputFormat 1\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/65#issuecomment-226903302,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AEUX3KCQ3G8JSKtdYJnVN47GYLtnwwHzks5qMyuugaJpZM4H_rWg\n.\n. @dav-cz apologies for posting on an older issue but we did some more tests and the issue is only on N Beta devices.  Just a heads up that there seems to be buffering difference between 5X M & 5X N Beta 4\n. Thank you so much!\n\nOn Jul 6, 2016 9:11 PM, \"David Coz\" notifications@github.com wrote:\n\nClosed #75 https://github.com/googlevr/gvr-android-sdk/issues/75.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/75#event-715133271,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AEUX3Hk-jdRLYHovyEY5-aREdDPvVarGks5qTFJGgaJpZM4IM8rg\n.\n. hi @dav-cz I posted this in a closed issue.  We're trying to implement VrVideView in NY Times app, I'm having trouble playing a remote video due to inability to buffer.  The video in question is: http://video1.nytimes.com/video/360-demo/cool.mp4\n\nWhen I drop the video in as a static asset everything plays perfectly. When trying to stream, the video stops and does not start on its own again.  Is there a way to control how much is download before starting as well as general buffering strategies?\nThe only code change I made to SimpleVrVideoActivity is to change the url in async task to videoWidgetView.loadVideo(Uri.parse(\"http://video1.nytimes.com/video/360-demo/cool.mp4\"),new Options());\nI see that there's some generated code that deals with exoplayer, maybe there are more hooks that can be exposed?\n. Additionally on a nexus 5x running android N preview 4, playing a remote video using the following command:\nadb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity -d \"http://video1.nytimes.com/video/360-demo/cool.mp4\" --ei inputFormat 1\nCauses a video that is very laggy. By that I mean the video will play for 1 second then stop audio/video. Few seconds later it will start video/audio again. This is over a 4g connection that has no problems playing other videos (youtube or within NYT app for example)\n. Even if we can use HLS it seems like SDK issues that are specific to a Nexus Phone and a public API need to be addressed. \n. What about for prod release will there be 2 versions or do we need to recompile ourselves? \n. Thank you much! Will try in am\n. Would you happen to know if the gist would work for video view too?\nOn Jun 28, 2016 10:01 PM, \"gary-domain\" notifications@github.com wrote:\n\nAlso other side affects are, enableTouchTracking = true will make the\nmethod the internal method this.sensorsHelper.areTrackingSensorsAvailable()\nbecome false at all times which from I can see affects ViewRotator class.\nSo far I can't see massive issues though. And also I'm not sure what other\nclasses access that variable.\nSo I think using my gist is probably safer, that way you keep the\nfunctionality of areTrackingSensorsAvailable() in tact.\nAlso note that this obviously has been done by design by the team and I'm\nsure there's reasons for it so, expect it to be buggy:\nif(this.sensorsHelper.areTrackingSensorsAvailable()) {\ntouchTracker.setTouchSpeed(0.0F, 0.0F);\n}\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/132#issuecomment-229236571,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AEUX3GJnTvwndquPNQWccDCd5z4ZHf98ks5qQdIGgaJpZM4I_lI8\n.\n. It's hacky but this worked for me in the SimpleVrVideoActivity\n\n//suggested by comments in:  https://github.com/googlevr/gvr-android-sdk/issues/66\n    private void fullscreenHack() {\n        ((ViewGroup)((ViewGroup)((ViewGroup)((ViewGroup)((ViewGroup)findViewById(R.id.main_layout))\n                .getChildAt(0))\n                .getChildAt(0))\n                .getChildAt(1))\n                .getChildAt(2))\n                .getChildAt(1)\n                .performClick();\n    }\n. This is second issue of this type. Same problem with exoplayer. Is there any reason why gvr has to be a fat jar? \n. Sorry for confusion. I want to be able to lock in portrait but when I press the full screen button, I'd like to have the bottom of the view be landscape rather than portrait.  Most  video players only show landscape full screen and I'll like GVR to act this way as well. (See youtube UI as example)\n. Hey, I can explain the bug a little better. If I have activity rotation turned on and rotate my phone. I can observe that the video is now sideways.  I don't believe it is correct for the gvr to lock in what direction is bottom even after the activity has destroyed and recreated.  If I had to guess I'd say the problem is that there is a Singleton maintaining the state of direction across rotation.  Please fix to ease in the creation of custom controls that face the same direction as the video does (upon rotation)\n. Does this need to be done for VideoView as well or do they just work?\n. We are having same issue. We are putting a vrview inside of a recyclerview. There is only 1 videview which we keep moving to the \"visible\" viewholder.  Every so often (1 out of 5-10 times) the above error is thrown when we try to attach the view to a new parent. \n. Here's a bit more info: the error is being thrown from a native method\nstatic void SurfaceTexture_updateTexImage(JNIEnv* env, jobject thiz)\n{\n    sp<SurfaceTexture> surfaceTexture(SurfaceTexture_getSurfaceTexture(env, thiz));\n    status_t err = surfaceTexture->updateTexImage();\n    if (err == INVALID_OPERATION) {\n        jniThrowException(env, IllegalStateException, \"Unable to update texture contents (see \"\n                \"logcat for details)\");\n    } else if (err < 0) {\n        jniThrowRuntimeException(env, \"Error during updateTexImage (see logcat for details)\");\n    }\n}\nwhich comes from java land here\n```\n public synchronized void updateTexture() {\n        if(this.needUpdateTexture) {\n            if(this.surfaceTexture != null) {\n                this.surfaceTexture.updateTexImage();\n            }\n        this.needUpdateTexture = false;\n    }\n\n}\n\n```\nWe see that we check whether the surfaceTexture is null which is great but I have a theory that the issue is that the view is currently detached.  Pure speculation but I bet if check whether the view is attached the crash will go away.   Alternatively maybe swallow the exception as it is just a single frame not updating, I don't think it should crash the app.\nHope this helps :-)\n. Nope. I was able to decompile the Java method. As for the native call, that was part of android sdk24 source \n. also we needed to add following dependency compile 'com.google.protobuf.nano:protobuf-javanano:3.0.0-alpha-7'\n. If it helps what we noticed was different is that the artifact in releases tab does not have the set volume method \n. V2 seamlessly supports switching from a WiFi to 4g. That's the top feature I've seen so far \n. I believe this is due to wrong version of Java (JDK)\nOn Fri, Dec 9, 2016 at 2:03 PM, Matt Scarpino notifications@github.com\nwrote:\n\nI tried to extract the libraries, but I got an error:\njava.lang.UnsupportedClassVersionError: com/android/build/gradle/model/AppComponentModelPlugin\n: Unsupported major.minor version 52.0\nFrom what I've read online, this means my SDK or NDK isn't current enough.\nBut I've updated both of them as best I can using SDK Manager.\nI also tried opening the SDK in Android Studio, and it gave me the\nfollowing error:\nInvalid file: file://.../gvr-android-sdk/libraries/base/build.gradle\nIt's looking for the build.gradle file in the old libraries/base\ndirectory. But that's gone.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/308#issuecomment-266094193,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AEUX3ISZnYUKUxKT3lY90KY9cgGbNMxsks5rGaXvgaJpZM4LI-f2\n.\n. \n",
    "nihalmehdi": "Below code works for me...\nView framelayout = ((ViewGroup) panoWidgetView).getChildAt(0);\n        ((ViewGroup)((ViewGroup)((ViewGroup)framelayout).getChildAt(1)).getChildAt(2)).getChildAt(0).performClick();\n. I put the code within \n protected void onCreate(Bundle savedInstanceState) {\n....\nView framelayout = ((ViewGroup) panoWidgetView).getChildAt(0);\n((ViewGroup)((ViewGroup)((ViewGroup)framelayout).getChildAt(1)).getChildAt(2)).getChildAt(0).performClick();\n...\n}\n. workaround that works for me..\npublic class DownloadVideoTask extends AsyncTask {\n    String videoUrl =\"http://host/test.mp4\"\n    private VrVideoView vrvideoView;\n    private Context context;\n    DownloadVideoTask (VrVideoView vrvideoView,Context context)\n    {\n        this.vrvideoView = vrvideoView;\n        this.context = context;\n    }\n```\n@Override\nprotected Uri doInBackground(String... url) {\n    //HttpsURLConnection.setDefaultSSLSocketFactory(new NoSSLv3Factory());\n    HttpURLConnection urlConnection = null;\n    String fileName = \"test.mp4\";\n    String filepath = context.getFilesDir() + File.separator + fileName;\n    File file = null;\n    try {\n        URL videoUri = new java.net.URL(videoUrl);\n        urlConnection = (HttpURLConnection) videoUri.openConnection();\n        urlConnection.connect();\n        InputStream in = urlConnection.getInputStream();\n        FileOutputStream output = context.openFileOutput(fileName, context.MODE_PRIVATE);\n        Utility.copyFile(in,output);\n    }\n    catch (java.net.MalformedURLException mex){\n        String test = mex.toString();\n        //Toast.makeText(\"Utility\", mex.getMessage(), Toast.LENGTH_LONG);\n    }\n    catch (Exception ex)\n    {\n        String test = ex.toString();\n        //Toast.makeText(\"tag\",ex.getMessage(),Toast.LENGTH_LONG);\n    }\n    finally {\n        if( urlConnection!= null ) {\n            urlConnection.disconnect();\n        }\n    }\nreturn Uri.parse(filepath);\n\n}\npublic String getVideoUrl() {\n    return videoUrl;\n}\n@Override\nprotected void onPostExecute(Uri videoUri) {\n    try {\n        vrvideoView.loadVideo(videoUri);\n        vrvideoView.playVideo();\n    }\n    catch (Exception ex){\n        String msg = ex.getMessage();\n        //Toast.makeText(this,\"Test\",3000)\n    }\n}\n```\n}\n. It is a below utility method.. that i missed to share earlier..\n public static void copyFile(InputStream in, OutputStream out) throws IOException {\n        byte[] buffer = new byte[1024];\n        int read;\n        while((read = in.read(buffer)) != -1){\n            out.write(buffer, 0, read);\n        }\n    }\n. Wants to try work around .. here it is..\npublic class DownloadVideoTask extends AsyncTask {\n    String videoUrl =\"http://host/test.mp4\"\n    private VrVideoView vrvideoView;\n    private Context context;\n    DownloadVideoTask (VrVideoView vrvideoView,Context context)\n    {\n        this.vrvideoView = vrvideoView;\n        this.context = context;\n    }\n```\n@Override\nprotected Uri doInBackground(String... url) {\n    //HttpsURLConnection.setDefaultSSLSocketFactory(new NoSSLv3Factory());\n    HttpURLConnection urlConnection = null;\n    String fileName = \"dubai1.mp4\";\n    String filepath = context.getFilesDir() + File.separator + fileName;\n    File file = null;\n    try {\n        URL videoUri = new java.net.URL(videoUrl);\n        urlConnection = (HttpURLConnection) videoUri.openConnection();\n        urlConnection.connect();\n        InputStream in = urlConnection.getInputStream();\n        FileOutputStream output = context.openFileOutput(fileName, context.MODE_PRIVATE);\n        Utility.copyFile(in,output);\n    }\n    catch (java.net.MalformedURLException mex){\n        String test = mex.toString();\n        //Toast.makeText(\"Utility\", mex.getMessage(), Toast.LENGTH_LONG);\n    }\n    catch (Exception ex)\n    {\n        String test = ex.toString();\n        //Toast.makeText(\"tag\",ex.getMessage(),Toast.LENGTH_LONG);\n    }\n    finally {\n        if( urlConnection!= null ) {\n            urlConnection.disconnect();\n        }\n    }\nreturn Uri.parse(filepath);\n\n}\npublic String getVideoUrl() {\n    return videoUrl;\n}\n@Override\nprotected void onPostExecute(Uri videoUri) {\n    try {\n        vrvideoView.loadVideo(videoUri);\n        vrvideoView.playVideo();\n    }\n    catch (Exception ex){\n        String msg = ex.getMessage();\n}\n\n}\n```\n}\n. Disable auto-rotate in your phone from setting option...\n. I wants to navigate to another view when i am within Full VR Panorma View using magnetic latch. Does VrEventListener.onClick() works on magnetic latch movement.\n. Thanks Dav for the update... when can we expect new device with controller..\n. workaround that works for me..probably you need to get image from databases instead of web hosted..\npublic class DownloadVideoTask extends AsyncTask {\nString videoUrl =\"http://host/test.mp4\"\nprivate VrVideoView vrvideoView;\nprivate Context context;\nDownloadVideoTask (VrVideoView vrvideoView,Context context)\n{\nthis.vrvideoView = vrvideoView;\nthis.context = context;\n}\n@Override\nprotected Uri doInBackground(String... url) {\n    //HttpsURLConnection.setDefaultSSLSocketFactory(new NoSSLv3Factory());\n    HttpURLConnection urlConnection = null;\n    String fileName = \"test.mp4\";\n    String filepath = context.getFilesDir() + File.separator + fileName;\n    File file = null;\n    try {\n        URL videoUri = new java.net.URL(videoUrl);\n        urlConnection = (HttpURLConnection) videoUri.openConnection();\n        urlConnection.connect();\n        InputStream in = urlConnection.getInputStream();\n        FileOutputStream output = context.openFileOutput(fileName, context.MODE_PRIVATE);\n        Utility.copyFile(in,output);\n    }\n    catch (java.net.MalformedURLException mex){\n        String test = mex.toString();\n        //Toast.makeText(\"Utility\", mex.getMessage(), Toast.LENGTH_LONG);\n    }\n    catch (Exception ex)\n    {\n        String test = ex.toString();\n        //Toast.makeText(\"tag\",ex.getMessage(),Toast.LENGTH_LONG);\n    }\n    finally {\n        if( urlConnection!= null ) {\n            urlConnection.disconnect();\n        }\n    }\nreturn Uri.parse(filepath);\n}\npublic String getVideoUrl() {\n    return videoUrl;\n}\n@Override\nprotected void onPostExecute(Uri videoUri) {\n    try {\n        vrvideoView.loadVideo(videoUri);\n        vrvideoView.playVideo();\n    }\n    catch (Exception ex){\n        String msg = ex.getMessage();\n        //Toast.makeText(this,\"Test\",3000)\n    }\n}\n}\nUtility method-\npublic static void copyFile(InputStream in, OutputStream out) throws IOException {\n        byte[] buffer = new byte[1024];\n        int read;\n        while((read = in.read(buffer)) != -1){\n            out.write(buffer, 0, read);\n        }\n    }\n. ",
    "hegazy": "I think this is a very important feature. Videos to be opened in fullscreen is a necessity, I think. \n. videoWidgetView.post(new Runnable() {\n            @Override\n            public void run() {\n                videoWidgetView.fullScreenDialog.setOnDismissListener(new DialogInterface.OnDismissListener() {\n                    @Override\n                    public void onDismiss(DialogInterface dialog) {\n                        videoWidgetView.setVisibility(View.INVISIBLE);\n                        finish();\n                    }\n                });\n            }\n        });\nI'm using this to go back to the previous activity from fullscreen mode. I think it's time to add these options to the library.\n. @nathanmartz That will be very cool!\n. I'm having problems with the above solution. This is the stacktrace of it.\njava.lang.NullPointerException: Attempt to invoke virtual method 'boolean com.google.vr.sdk.widgets.video.VideoTexture.getIsTextureSet()' on a null object reference\n    at com.google.vr.sdk.widgets.video.VrVideoPlayerInternal.prepareFrame(VrVideoPlayerInternal.java:342)\n    at com.google.vr.sdk.widgets.video.VrVideoRenderer.onDrawFrame(VrVideoRenderer.java:57)\n    at android.opengl.GLSurfaceView$GLThread.guardedRun(GLSurfaceView.java:1535)\n    at android.opengl.GLSurfaceView$GLThread.run(GLSurfaceView.java:1240)\nW/MessageQueue: Handler (com.google.android.exoplayer.upstream.Loader$LoadTask) {e4b2179} sending message to a Handler on a dead thread\njava.lang.IllegalStateException: Handler (com.google.android.exoplayer.upstream.Loader$LoadTask) {e4b2179} sending message to a Handler on a dead thread\n    at android.os.MessageQueue.enqueueMessage(MessageQueue.java:543)  \n    at android.os.Handler.enqueueMessage(Handler.java:631)\n    at android.os.Handler.sendMessageAtTime(Handler.java:600)\n    at android.os.Handler.sendMessageDelayed(Handler.java:570)\n    at android.os.Handler.sendEmptyMessageDelayed(Handler.java:534)   \n    at android.os.Handler.sendEmptyMessage(Handler.java:519)\n    at com.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:212)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:237)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\n    at java.lang.Thread.run(Thread.java:818)\nE/WindowManager: android.view.WindowLeaked: Activity com.example.cardboard.video.VideoCardBoardActivity has leaked window com.android.internal.policy.PhoneWindow$DecorView{3619b1f V.E...... R....... 0,0-2560,1440} that was originally added here\n   at android.view.ViewRootImpl.<init>(ViewRootImpl.java:369)\n   at android.view.WindowManagerGlobal.addView(WindowManagerGlobal.java:299)\n   at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:85)\n   at android.app.Dialog.show(Dialog.java:319)\n   at com.google.vr.sdk.widgets.common.FullScreenDialog.show(FullScreenDialog.java:79)\n   at com.google.vr.sdk.widgets.common.VrWidgetView.toggleFullScreen(VrWidgetView.java:387)\n   at com.google.vr.sdk.widgets.common.VrWidgetView.access$100(VrWidgetView.java:46)\n   at com.google.vr.sdk.widgets.common.VrWidgetView$4.onClick(VrWidgetView.java:329)\n   at android.view.View.performClick(View.java:5204)\n   at com.example.cardboard.video.VideoCardBoardActivity.fullscreenHack(VideoCardBoardActivity.java:99)\n   at com.example.cardboard.video.VideoCardBoardActivity.onCreate(VideoCardBoardActivity.java:89)\n   at android.app.Activity.performCreate(Activity.java:6251)\n   at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)\n   at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2369)\n   at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2476)\n   at android.app.ActivityThread.-wrap11(ActivityThread.java)\n   at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1344)\n   at android.os.Handler.dispatchMessage(Handler.java:102)\n   at android.os.Looper.loop(Looper.java:148)\n   at android.app.ActivityThread.main(ActivityThread.java:5417)\n   at java.lang.reflect.Method.invoke(Native Method)\n   at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\n   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\n. @nathanmartz \nThe codec is supported by the device. Can it be a resolution's issue? It's too big to be handled by the device!\nInput #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Shark 3d 360 - panocam3d.com.mp4':\n  Metadata:\n    major_brand     : mp42\n    minor_version   : 19529854\n    compatible_brands: mp42isom\n    creation_time   : 2013-12-10 11:56:33\n  Duration: 00:00:40.41, start: 0.000000, bitrate: 11144 kb/s\n    Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 192 kb/s (default)\n    Metadata:\n      creation_time   : 2013-12-10 11:56:33\n      handler_name    : Sound Media Handler\n    Stream #0:1(eng): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv), 2300x2300 [SAR 1:1 DAR 1:1], 10950 kb/s, 30 fps, 30 tbr, 30 tbn, 60 tbc (default)\n    Metadata:\n      creation_time   : 2013-12-10 11:56:33\n      handler_name    : Video Media Handler\n      encoder         : AVC Coding\n. ",
    "fjrobles": "nihalmehdi, where do you put the code?? in class VideoLoaderTask?\ni have like that...\nclass VideoLoaderTask extends AsyncTask, Void, Boolean> {\n    @Override\n    protected Boolean doInBackground(Pair... fileInformation) {\n      try {\n         if (fileInformation == null || fileInformation.length < 1\n          || fileInformation[0] == null || fileInformation[0].first == null) {\n          // No intent was specified, so we default to playing the local stereo-over-under video.\n          Options options = new Options();\n          options.inputType = Options.TYPE_STEREO_OVER_UNDER;\n           videoWidgetView.loadVideoFromAsset(\"congo.mp4\", options);\n           View framelayout = ((ViewGroup) videoWidgetView).getChildAt(0);\n           ((ViewGroup)((ViewGroup)((ViewGroup)framelayout).getChildAt(1)).getChildAt(2)).getChildAt(0).performClick();\n         }\n      } catch (IOException e) {\n        // An error here is normally due to being unable to locate the file.\n        loadVideoStatus = LOAD_VIDEO_STATUS_ERROR;\n      }\n      return true;\n    }\n. ",
    "Tanksta": "If it is still needed. Make sure you have the lastest version ( tested on 0.9.1 )\n For fullscreen use\nvideoWidgetView.setDisplayMode(VrVideoView.DisplayMode.FULLSCREEN_MONO);\nfor vr glasses use\nvideoWidgetView.setDisplayMode(\n        VrVideoView.DisplayMode.FULLSCREEN_STEREO\n    );\n. ",
    "leewp": "GPU\u4e0d\u884c\n. Excuse me ,how long it will be\n. OK\uff0cThank you!\n. ",
    "abhi2015": "@nathanmartz Was this fixed? Currently facing the same issue with gvr SDKv1.0 as well on a Galaxy S4 running 4.4.\n. @dav-cz  Do we have support for adaptive decoding in HLS i.e. playback of streams with adaptive bitrate profiles (SMIL)?\n. @nathanmartz Do we have support for adaptive decoding in the player i.e. support for adaptive bit rate profiles (SMIL)?\n. Getting the same issue on a galaxy S3 running Android 4.4 \n\n. ",
    "nirajan770": "As a follow up, I tried the samples-simplevideowidget on Samsung Galaxy S6 and and Note 4 running Android 6.0.1. In both cases, the video did not display, with occasional green color flickering.\nI was wondering if anyone else has experienced similar issues with Samsung phones. LG Nexus5 running Android 6.0.1 works normal. \n. ",
    "jpetrich": "I have been encountering the same exact issue on the Samsung Galaxy S6 and Samsung Galaxy S6 Edge+.  Would really appreciate a workaround or fix.  Adding the native libraries made it not crash, but then this problem cropped up.\n. ",
    "jakon89": "unfortunately +1 for Galaxy S7 and Android 6.0.1. Is there any workaround?\n. ",
    "pandone": "this issue is still present in sdk v0.8.0\n. ",
    "cliffgr": "+1 s6 error\n. Device : Samsung s6 6.0.1 Api: 23\nError:\nUnable to start activity ComponentInfo{com.ethos.doers/com.ethos.ar.ui.view360.View360Activity}: android.view.InflateException: Binary XML file line #8: Binary XML file line #8: Error inflating class com.google.vr.sdk.widgets.pano.VrPanoramaView\n                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3254)\n                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\n                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\n                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\n                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\n                                                            at android.os.Looper.loop(Looper.java:158)\n                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\n                                                            at java.lang.reflect.Method.invoke(Native Method)\n                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\n                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\n                                                         Caused by: android.view.InflateException: Binary XML file line #8: Binary XML file line #8: Error inflating class com.google.vr.sdk.widgets.pano.VrPanoramaView\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:551)\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\n                                                            at android.support.v7.app.AppCompatDelegateImplV7.setContentView(AppCompatDelegateImplV7.java:276)\n                                                            at android.support.v7.app.AppCompatActivity.setContentView(AppCompatActivity.java:139)\n                                                            at com.ethos.ar.ui.view360.View360Activity.onCreate(View360Activity.java:37)\n                                                            at android.app.Activity.performCreate(Activity.java:6876)\n                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\n                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\n                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\u00a0\n                                                         Caused by: android.view.InflateException: Binary XML file line #8: Error inflating class com.google.vr.sdk.widgets.pano.VrPanoramaView\n                                                            at android.view.LayoutInflater.createView(LayoutInflater.java:657)\n                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:776)\n                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:716)\n                                                            at android.view.LayoutInflater.rInflate(LayoutInflater.java:847)\n                                                            at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:810)\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:527)\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\u00a0\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\u00a0\n                                                            at android.support.v7.app.AppCompatDelegateImplV7.setContentView(AppCompatDelegateImplV7.java:276)\u00a0\n                                                            at android.support.v7.app.AppCompatActivity.setContentView(AppCompatActivity.java:139)\u00a0\n                                                            at com.ethos.ar.ui.view360.View360Activity.onCreate(View360Activity.java:37)\u00a0\n                                                            at android.app.Activity.performCreate(Activity.java:6876)\u00a0\n                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\u00a0\n                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\u00a0\n                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\u00a0\n                                                         Caused by: java.lang.reflect.InvocationTargetException\n                                                            at java.lang.reflect.Constructor.newInstance(Native Method)\n                                                            at android.view.LayoutInflater.createView(LayoutInflater.java:631)\n                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:776)\u00a0\n                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:716)\u00a0\n                                                            at android.view.LayoutInflater.rInflate(LayoutInflater.java:847)\u00a0\n                                                            at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:810)\u00a0\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:527)\u00a0\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\u00a0\n                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\u00a0\n                                                            at android.support.v7.app.AppCompatDelegateImplV7.setContentView(AppCompatDelegateImplV7.java:276)\u00a0\n                                                            at android.support.v7.app.AppCompatActivity.setContentView(AppCompatActivity.java:139)\u00a0\n                                                            at com.ethos.ar.ui.view360.View360Activity.onCreate(View360Activity.java:37)\u00a0\n                                                            at android.app.Activity.performCreate(Activity.java:6876)\u00a0\n                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\u00a0\n                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\u00a0\n                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\n. ",
    "JamesMasterman": "I am also seeing this issue on a Samsung S7 running Android 6.0.1. Screen is black or sometimes flickers dark green on VrVideoView player. I can hear the sound, just no video. Same app has no problems on Nexus 6P or Nexus 5. \n. ",
    "guardianrol": "Hello friends.\nI have the same problem, I would like to know if they have any solution date. Greetings.\n. ",
    "adriagil": "Hello everyone,\nsame problem here.\nIts working fine (no giroscope) on older versions with Android v4 but the same behavior happening with Android 6.0.1 and Galaxy S6.\nCheers!\n. ",
    "consoleassert": "+1 s6 error :) Have any fix?\n. ",
    "KCHariram": "I have Galaxy Tab S2 with 6.0.1 OS, and have the same problem. The video sounds are working fine but unfortunately unable to load the videos. \nThanks in advance\nHariram KC \n. ",
    "xieqiupeng": "+1 Samsung S6 6.0.1 error.\n. I have the same question.\n. that form of picture or video used for 3d mode. the top picture will be rendered for your left eye,the bottom one for your right eye. 3d is difference from panorama. it makes feeling stereo not wide,\u8bdd\u8bf4use english very \u8d39\u52b2\u3002\n. yes, when I transform the mode from EMBEDDED to FULLSCREEN, I want to keep my yaw .do not reset it ,I find out the pitch is still works,but yaw has been reseted.\n. thank you very much.\n. As a follow up.. ",
    "jeremysciarappa": "Tried the link, but couldn't access it. So is it officially fixed now? Is there anything that we need to do on our end? \n. Thanks for the update. Any chance the new gvr release will have a fix for the 6.0.1 issue listed in #75?\n. ",
    "ShayFB": "Hi,\nCan you share please some technical details about the fix?\nI'm working on different application and I just encounter the same issue on Samsung tablet 6.0.1 (which worked perfectly before Samsung OTA)\nThank you in advance!!. Hi,\nI know this was fixed in 0.8.5.\nCan someone please explain me what was the fix?\nI encountered this problem with another application.\nThanks  in advance, highly appreciated!\n. ",
    "swratten": "Hi there,\nI am also experiencing the same issues with a Samsung Tablet (SM-T810)(Samsung Galaxy Tab S2) on 6.0.1 using the latest SDK version (1.30.0).. ",
    "markusekblad": "Been using 1.30.0 for more than a week on a Samsung S6 without any issues and then this just appeared for me half an hour ago on every (HLS) stream I tried. A device restart seems to have fixed it this time tho.. @andrewlewis @dcower  Does this apply to the VrVideoView or is it only for building your own video player?\nI'm exploring how to add spatial audio to our VR video app which uses the VrVideoView. One solution is to go with the Facebook/TwoBigEars engine for spatial audio but then you have to have a separate sound file and sync the players which is not ideal.. ",
    "bohuang3d": "What's the check-in that fixed the issue last year? We could use it, thanks\n. ",
    "findeway": "@sigmaxipi Thanks for you reply! But the thing is if I unzip the aar, I'll have to copy the resources manually into the main module which I don't want to. I need to make my library easily used (even for someone who still uses eclipse).\n. ",
    "jinbiaochenstayhungry": "i guess i was so blind\uff0ci  look twice, they are actual have different gradle setting.\none for\n  compile project(':libraries-audio')\n    compile project(':libraries-common')\n    compile project(':libraries-core')\nthe other one is:\n compile project(':libraries-common')\n    compile project(':libraries-commonwidget')\n    compile project(':libraries-videowidget')\nwhat confused me is that \uff1a\nTreasureHuntActivity is not correspond to the file path\uff0cbut it still works okay,i test in a new android studio project , it really work,  gradle may have do some job ?.  suggestion:move file to correspond file path.\n. ",
    "chr314": "I think the sdk recognizes your phone as tablet because this is how cardboard apps look on tablets\n. I will try tomorrow. @jdduke  the problem not fixed . hello @jdduke sorry for late reply\nim using nexus 5x\nwith samples its working fine i had problem with rendering 2d images\ni have rewritten the code with different way and its working now. https://developers.google.com/vr/android/release-notes\n\"VR mode\" renamed to \"Stereo mode\"\n. ",
    "maneets": "onCardboardTrigger() override method sets a boolean variable to true. onDrawEye() method checks this boolean variable, if true, loads a different texture and set this variable to false.\nMy activity class extends CardboardActivity and implements StereoRenderer. CardboardView and Renderer are set in onCreate() method very similar to the way sample TreasureHuntActivity does the initialization.\nI would try your suggested potential workaround. But by the way you have explained trigger detection, I don't know why it should work. In the entire application, I never inject touch events, never detach/re-attach CardboardView in hierarchy. setCardboardView(this) is called just once on onCreate() method of my Activity. Thanks for your quick response. Appreciate it!\n. Some more information on this:\n- Tried workaround of calling setConvertTapIntoTrigger(false) onCreate() and set it to true onResume(), didn't help.\n- Tried overriding onTouchEvent() or register touch listener on CardboardView and setConvertTapIntoTrigger(false) in onCreate(), issue is resolved. Only side-effect is https://github.com/googlesamples/cardboard-java/issues/60, so older Cardboard version with magnets are now unsupported.\n- Implemented another workaround (would like to remove it as soon as underlying issue is resolved). So if subsequent calls to onCardboardTrigger() is made within 10ms, it cannot be a human touch, so treat it as nop.\n- Another observation: Whenever onCardboardTrigger() starts getting called in a loop, it usually lasts for 10-50 seconds and then stops.\nIf above helps you in identifying issue in Cardboard sdk or my application, it would be great to let us know. Thanks for your inputs.\n. Thanks jdduke for taking out time for this. Here is the required information:\n1. What device model and Android version are you running?\n   Device: HTC One M8\n   Android version: 5.0.2\n2. Can you reproduce the problem on other phones?\n   Not yet. Tried on HTC M8 and Samsung Note 5.\n3. When you say \"infinite\" loop, do you mean that it's literally a loop in which no other activity occurs, only dispatch of onCardboardTrigger()? Or is it simply that the onCardboardTrigger() method is called repeatedly each frame (or repeatedly per frame), but the app is not in a frozen state?\n   Latter statement. onCardboardTrigger() getting called multiple times in a frame/repeatedly over frames but app is not frozen.\n4. Can you reproduce this behavior with the TreasureHunt sample in the SDK?\n   Oh, thank you for asking this question. Tested TreasureHunt sample app on same HTC M8, yes I am hitting it often here too and because cardboard trigger is supposed to vibrate phone when hit, HTC M8 vibrates crazily on hitting this issue.\nSo this would imply that HTC did something wrong while modifying Vanilla Android such that I am hitting this issue with my HTC M8 phone with Cardboard apps? However, Cardboard apps including mine is working fine on other phones. Thanks for your questions.\n. Yes, I can reproduce it when the phone is isolated. The fact that I cannot hit it with Samsung Note 5 or Shield Portable suggests a very M8 HTC_Android 5.0.2 issue to me. Thanks for your active involvement here.\n. ",
    "leoncvlt": "Developing on a Samsung Galaxy S5 with Android 5.0\n. I see, worth mentioning in the supported format sections maybe.\nUsed the python script and now works fine. Thanks!\n. ",
    "aj-michael": "Hi, just as an update on this, we are currently working on AAR import support in Bazel. There are a few problems that we are still thinking about the solutions for, but a limited version of the aar_import rule is now available in Bazel. Unfortunately, it does not yet support native libraries in AARs which I've noticed that libraries/common/base.aar includes.\n. Hmm, I notice that this class was present in the 1.0.1 release zip inside libraries/base/base.aar. Nevermind ignore this.It's in libraries/sdk-common-1.60.0.aar. Not sure how I missed that.. ",
    "alexliu-liu": "+1 when could these source code opend?\n. ",
    "mikulbhatt": "+1\n. any update or plans to support HLS? gvr-ios supports it, gvr-android doesn't \n. @nathanmartz ? @cyisrael ?\n. @dav-cz correct, the urls i want to play ends up with .m3u8 for 90% cases\n. @dav-cz  you can try this test url - http://yahooios2-i.akamaihd.net/hls/live/224964/iosstream/adinsert_test/master.m3u8\nPlease let me know if I can help in anyway. When should I expect to have gvr release with this feature?\n. thanks @dav-cz , yes that video is not in 360. Glad it will be available next week. Thanks a lot!\n. ",
    "arumani": "@dav-cz Doesn't customizing UI(replace .png, modify layout.xml, etc.) in .aar file violate license? (unzip -> modify -> zip -> use in apk)\nI'm sorry to comment closed issue. \n. Hi @dav-cz. I have the same problem with @BrendanParks.\n\"congo.mp4\" in samples/simplevideowidget is \"Spherical and 3D Top-bottom\" video. And it's ok when I drop the video in as a static asset. But when trying to stream ( http://s3.amazonaws.com/googlevr-test/congo.mp4 ), it seems as below. Maybe the video is processed as \"Spherical and NOT 3D\".\n\n\nXperia Z1f + Android 4.4.2\n. @dav-cz Thanks for your reply. I'm looking forward to it !\n. ",
    "nirajsanghvi": "Update: Getting failure to install on a Nexus 5 as well.\n. It looks like the updated .apk in https://github.com/googlevr/gvr-android-sdk/commit/0954a01934199b8536755f06688d98e3d2a958e4 has fixed the issue. I was able to install and run the controller emulator on the Nexus 6, Nexus 5, and the Galaxy Note 4 successfully. Thanks! \n. ",
    "ReedL": "Seeing very similar issue trying to install the controller emulator with a Nexus 6 and a Nexus 4, although my error message is \"[INSTALL_FAILED_NO_MATCHING_ABIS: Failed to extract native libraries, res=-113]\"\n. ",
    "andna": "LG G2 also reported with trobule to install the apk.\n. ",
    "phuctk93": "HI, LG VU II and HTC one M8 have a same issue! Thank you very much GG Team!\n. ",
    "spawnlt": "Actually install doesn't work again on the latest version v1.8  (phone NEXUS 5 M 6.0.1). Only got working some older version working v0.8.1. ",
    "lixiang-robot": "Any updates so far? Without any game engines, can I develop native Daydream VR apps with Vulkan?. ",
    "griffin2000": "Same as @lixiang-robot said. Any updates?. What's the situation with this? Is it still not possible to develop Vulkan apps for Daydream? @gpx1000 is it even possible to do GL-Vulkan interop?. ",
    "oscarbg": "from IO we know is part on Daydream 2.0 SDK shipping this fall!. Hi @nathanmartz @jdduke,\nStill no news on daydream 2.0 Euphrates with vulkan support.. hope for a release at GDC next week or google I/O 2018 at least,right?\nBTW issue should be kept open..\n. ",
    "vagnercsouza": "I also need to set the yaw position at runtime. My app is going to be used inside a car, and the video's center needs to be locked at car's center. That's my suggestion for next release.\nThanks.\n. ",
    "lawrencewqy": "i also want to play .m3u8 videos over HLS, please do this first,thank you .\n. ",
    "grobm": "HLS would be nice!\n. @dav-cz I assume this is not only public media paths but supports tokenized paths as well?\n. ",
    "azeemmohd": "@dav-cz : Is the update for HLS playback support out yet?\n. It doesn't support live playback of .m3u8 streams, just a remote video hosted on a public media path.\n. Sample HLS stream that I am testing: httplive://vevoplaylist-live.hls.adaptive.level3.net/vevo/ch1/appleman.m3u8\n. @dav-cz : That's awesome, thanks a lot.\n. ",
    "jietan": "@dav-cz Is the HLS streaming supported in the Google VR SDK for IOS? If not, is there any plan to support it? Thanks.. ",
    "janinurminen": "Hello @jdduke, yeah we are currently integrating this new GVR API on Android. Of course looking for same API to iOS as well at some point. Basically our codebase just don't use STL, exceptions, RTTI and other stuff due to cross-platform (mobile, desktop and consoles), speed and code size reasons. Pretty common game technology decisions. Also NDK runtime mix with dozens of different libraries becomes nightmarish if we would start to use APIs with STL.\nAs a temporal solution I just removed C++ forcing from headers to get integration task done, but thought to ping you guys about this so you can make changes for the future releases.\n. At least current master doesn't contain this fix or am I missing something?\n. ",
    "731942771": "@nathanmartz Eh...... Could you have a try ?\n. @sigmaxipi Thanks a lot, i'll have a try.\n. ",
    "baaloo87": "Thank you very much, it works. If this is the way it should be done I suggest to update the reference.\n. ",
    "gvsharma": "it is working in my nexus and one plus\n. ",
    "liuhao722": "Utility.copyFile(in,output);\nwhat's this content from jar?\n. Under the advice, how to play the network VR video streaming, thank you\n. ",
    "chuangzai": "@dav-cz Thank you for your help and patience.It's useful for me.\n. ",
    "Billo4ka": "Here the same problem but with GvrView.\nMy class extends GvrActivity\nError: \nandroid.view.InflateException: Binary XML file line #8: Binary XML file line #8: Error inflating class com.google.vr.sdk.base.GvrView\nXML:\nRelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"\n    xmlns:tools=\"http://schemas.android.com/tools\"\n    android:layout_width=\"match_parent\"\n    android:layout_height=\"match_parent\">\n<com.google.vr.sdk.base.GvrView\n    android:id=\"@+id/gvr_view\"\n    android:layout_width=\"fill_parent\"\n    android:layout_height=\"fill_parent\"\n    android:layout_alignParentTop=\"true\"\n    android:layout_alignParentLeft=\"true\" />\n\nGradle :\n    compile project(':audio')\n    compile project(':base')\n    compile project(':common')\nDevice : Samsung s6 6.0.1 Api: 23\n. crash started after:\nD/ConfigUtils: Parameters file not found for reading: java.io.FileNotFoundException: /storage/emulated/0/Cardboard/current_device_params: open failed: EACCES (Permission denied)\nD/CardboardViewNativeImpl: Loading native library gvrbase\nD/AndroidRuntime: Shutting down VM\non other devices everything is ok:\nD/CardboardViewNativeImpl: Loading native library gvrbase\nD/CardboardViewNativeImpl: Native library loaded\n. Thanks, it helped!\n. ",
    "jdknox": "I should have checked that.  I was only considering the accelerometer.\n. ",
    "vreiche": "I was using unity to develop for cardboard. It works, just in publishing settings you need to disable VR mode, but make sure it's active on VR Main.\n. ",
    "yinli": "It already supports in version 0.8.\nThanks you guys very much.\n. ",
    "Ood-Tsen": "VrVideo using ExoPlayer library.\nSo it depends on the codec capability and extractor in ExoPlayer.\n. I didn't dig it in. At least you got to rewrite a VrVideoPlayerInternal by yourself.\n. ",
    "FirmianaRain": "Hi, can we  replace ExoPlayer with other player, such as  ijkplayer?\n. ",
    "jkammerl": "The Google VR SDK on Android supports the decoding and binaural rendering of an ambisonic soundfile. You could separately trigger spatial audio playback together with the video playback, but then the synchronization of both media streams will be quite challenging. Android's Exoplayer and the spatial audio engine have very different buffering schemes and signal paths, so unfortunately I don't think this is easily possible. However, I agree that this is an interesting feature which is worth considering in a future release. \n. Currently, we don't support FOA playback from ExoPlayer. \n. The Google VR Android API doesn't support the processing of raw PCM audio buffers at the moment. Note that the binaural stereo output also would need to be played back via the Exoplayer buffer queues to ensure synchronization with the video stream. \n. Using the TrackRenderer interface to render spatial audio in the Exoplayer should work. It good to know that there is demand for such feature and we might consider it in future SDK updates. The Google VR SDK is not open-sourced. \n. The upcoming GVR release will contain an API that enables the rendering PCM buffers of ambisonics and standard 5.1 surround content into real-time head-tracked binaural stereo. This API can for instance be wrapped into an AudioTrackRenderer for the Exoplayer to binaurally decode 360 video with ambisonics. Stay tuned.. it will become available soon. . GVR uses OpenSL ES to decode sound files and it seems picky about the header format of Wav files. You could try reencoding the WAV file with tools like Audacity or ffmpeg which worked for me in the past. Alternatively, using a compressed multi-channel Ogg/Vorbis container should work as well. \n. You are correct. The current Android API is designed to provide a simple, high-level spatialization engine that allows to playback sound objects and ambisonic soundfields from APK assets/SD card and the processing of raw PCM buffers is not supported atm. But it is interesting to hear that there's demand for it. Are you planning to implement an AudioTrackRenderer for the ExoPlayer?  Are you using our Android Java or NDK API?\n. As previously discuss, the current API doesn't allow for the processing of PCM buffers. We'll consider providing corresponding methods in future releases.\n. We are currently working on a separate spatial audio API that reads in PCM buffers of surround sound as well as ambisonic soundfield content to render binaural stereo. It is designed to be integrated into media players to enable head-tracked binaural audio. It will be part of the GVR spatial audio components soon. . We just released it! Please take a look at the GvrSurround Java and native C API. It has been designed to binaurally render surround sound/ambisonics PCM buffers of varying buffer sizes in 360 video player applications. Fyi, we are currently working on wrapper code that will facilitate the integration into the Exoplayer. \n. The Exoplayer V2 recently added a wrapper for the GvrSurround API (see announcement here). We are working on more sample code. In the meantime, here is their integration code. \n. Loading sound files from the SD card should work. Please make sure that you add \n<uses-permission android:name=\"android.permission.READ_EXTERNAL_STORAGE\" />`\nto your manifest and since Android N, you also need to trigger an intent to ask to user to grand external storage permission. \n. Are you preloading the ambisonic soundfield prior to playback? Could you share more information about the platform/phone you are using?\n. Thanks for the info. I'm able to reproduce this bug. We'll work on a fix for the next release. \n. It should already have been fixed in v1.0. Please let us know if you still encounter any problems.\n. The GvrAudioEngine supports the playback of mono, stereo and ambisonics audio assets. It is however not possible to synchronize audio playback from GvrAudioEngine with VrVideoVideo. \nTo address this issue and are currently working on adding support for the processing of raw PCM buffers. This will enable the integration of the Google spatialization libraries directly into the audio pipelines of video decoders. Stay tuned!\n. The documentation for GvrAudioEngine.createSoundfield correctly says:\n\nAmbisonic soundfields do not need to be preloaded. They are directly streamed and rendered from the compressed audio file.\n\ncreateSoundfield/createSoundObject/createStereoSound fist look into the internal sample cache if the soundfile has been preloaded. If it's not found, then it initializes the playback using streamed decoding. \nStreamed playback should also work for createStrereoSound. Could you provide more details how it fails? Does it return an invalid sound id?\n. Thanks for the detailed analysis. That's helpful! Originally the support for stereo playback has been mostly designed for music streaming but I don't see why it also shouldn't work with preloaded sound files. I'll run some more tests and if I can reproduce this issue, we'll fix it in the next release. \n. I ran some tests but couldn't reproduce the bug. Stereo sound playback works with and without preloading for me. Do you have a minimal example on github that reproduces this bug?\n. Thanks for your bug report. I agree with you that this ambiguity between paused and stopped is unfortunate and obviously a crash should never happen for an invalid function argument. In the current release IsSoundPlaying should return false when it is paused as well as when it is stopped. We'll investigate this in more detail and work on a fix for the upcoming release. \n. With the latest update, we added a IsSourceIdValid() method which allows you to determine if a source handle is in a playable state. The crash has been fixed too. Thanks again for your valuable feedback!. Thanks for reaching out. Adding seeking support is already on our radar. I also like your suggestion to add a \"source finished\" callback. I'll discuss it with our team.   . Apologies for the confusion. You are correct, it seems our header comments haven't been updated during a recent refactoring of the API. We'll fix this in our next release. In the meantime, please take a look at how the head rotation is applied to the audio engine in the NDK treasure hunt example:\nhttps://github.com/googlevr/gvr-android-sdk/blob/master/samples/ndk-treasurehunt/src/main/jni/treasure_hunt_renderer.cc#L545\nHere, the head view matrix is an affine 4x4 transformation matrix which combines a rotation matrix and a translation vector. See also https://en.wikipedia.org/wiki/Affine_transformation. We'll work on a sample to demonstrate the integration into the ExoPlayer. In the meantime, could you explain in more detail how it crashes?. Thanks for the report. It seems crashing when trying to throw an Exception about the input buffer type. \nWe'll fix this in the next release and update the documentation accordingly. In the meantime, you should switch to direct ByteBuffers for audio I/O and it should work. \n  ByteBuffer inputByteBuffer =\n    ByteBuffer.allocateDirect(2 // num channels  \n        * 2 // 16bit samples \n        *  numSamples).order(ByteOrder.LITTLE_ENDIAN);\n\n. The GVRAudio component uses OpenSL ES to playback spatialized audio.. Thanks for the report. We'll take a look at this asap. . Hi, I ran some tests but am not able to reproduce any glitchy output. Could you give us more detailed instructions how to reproduce this issue?. The Exoplayer project recently announced support  for the GvrSurroundRenderer API. \nHere's their integration code. If you have more questions, please let us know. \n. virajkarandikar@ I ran some tests and it worked well for me. Note that the JAVA API uses buffer sizes in bytes (which is easier to use in the context of ByteBuffers) and the C API uses samples. Is it possible that this is mixed up in your code? If not, please share some sample code that allows us to reproduce the issue.. I looked at your code. I believe you a mixing up the metrics of your size variables (bytes/samples). \nIn line 49:\naudioSurroundApi->AddInterleavedInput(in, input_len);\nYou are calling AddInterleavedInput which takes in the number of samples. Assuming input_len contains the number of samples of your \"in\" buffer, the following memcpy seems wrong since you are multiplying it by SAMPLE_SIZE_IN_BYTES. \nmemcpy(out, in, input_len * OUTPUT_CHANNELS * SAMPLE_SIZE_IN_BYTES);\nIf you still think there is a bug on our side, I'll reopen the issue. . This is a duplicate to issue #386 . I agree. I can confirm it's on our roadmap.. Good question! You are correct, the GvrAudioSurround class is single-threaded. To keep the latency of the head rotation at a minimum, you should set the most recent head orientation sample right before you call gvr_audio_surround_get_interleaved_output which triggers the internal processing of the input buffers.  . Our native APIs are available for Android and iOS. Linux is currently not supported. \nOn Android, you could use our GvrSurround API  to process raw PCM buffers and write the output into a soundfile. . Thanks for reporting the wrong link. We'll fix it soon! In the meantime, here's the correct one: https://github.com/google/spatial-media/tree/master/spatial-audio. We use Android's media codec APIs to decode sound files. The list of supported formats can be found here:\nhttp://developer.android.com/guide/appendix/media-formats.html\nFor wav files, only 8- and 16-bit linear PCM with sampling rates of 8000, 16000 and 44100 Hz are supported. \n. gvr_audio_surround_get_available_output_size_samples returns the number of samples available in the output buffer. Since it outputs a stereo audio stream, you'll need to divided that number by two to get the available output frames. . VrVideoView does not support spatial audio. For an example how to integrate spatial audio rendering directly into ExoPlayer, see the videoplayer example in the SDK. gvr-audio supports all common audio sample rates. Most of our APIs support int16 and float PCM input.  Could explain what you mean by \"gvr-audio in video playback\" in more detail? Which of our audio APIs are you using exactly and which calls trigger the crash? If you could attach an Android Bug Report, that'd be helpful. . Please share sample code on Github which makes it much easier to review. \nAlso double check if the target buffer for gvr_audio_surround_get_interleaved_output is large enough. I would expect signal 7 (SIGBUS), code 1 (BUS_ADRALN) if your target pointer is invalid or the corresponding target buffer too small. . Here's the function signature:\nint64_t gvr_audio_surround_add_interleaved_input(\n    gvr_audio_surround_context* api, const int16_t* input_buffer_ptr,\n    int64_t num_samples);\nThe buffer size is specified in number of samples ans not number of frames. Since the output is a binaural stereo audio feed, it's 2 * number of frames. . Could you share the exact configuration/initialization with me?  What's the frames per buffer size and sample rate you are using to reproduce the crash? . The current API does not support asynchronous preloading but you can execute this call from a separate thread. Streamed playback is designed to keep the memory footprint low and therefore doesn't perform caching of decoded audio data.  . ",
    "niusounds": "\ud83d\udc4d \n. I tried these codes\njava\nGvrAudioEngine audioEngine = new GvrAudioEngine(getContext(), GvrAudioEngine.RenderingMode.BINAURAL_HIGH_QUALITY);\nfinal File file = new File(Environment.getExternalStorageDirectory(), \"Ambi.wav\");\nint ambisonicId = audioEngine.createSoundfield(file.getAbsolutePath());\nbut ambisonicId is -1. I added <uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\"/> in AndroidManifest.xml. targetSdkVersion is 19.\nI tried some methods, finally I found that these codes run successfully. (It plays strange distorted sound. But it may be other problem, not a bug in GVR library.)\njava\nGvrAudioEngine audioEngine = new GvrAudioEngine(getContext(), GvrAudioEngine.RenderingMode.BINAURAL_HIGH_QUALITY);\nfinal File file = new File(Environment.getExternalStorageDirectory(), \"Ambi.wav\");\nfinal String filename = file.getAbsolutePath();\naudioEngine.preloadSoundFile(filename);\nint ambisonicId = audioEngine.createSoundfield(file.getAbsolutePath());\nAPI Document says Ambisonic soundfields do not need to be preloaded. I think it is not needed to call preloadSoundFile. Is it wrong?\n. This issue will be the same topic with #197 so I close here.\n. In addition, GvrAudioEngine.createStereoSound fails when sound is not preloaded. It is not written in document.\nIs this behavior expected? or bug?\n. Sorry, I made a mistake with copy & paste. I wanted to write GvrAudioEngine.createSoundObject at my first comment.\n. > Streamed playback should also work for createStrereoSound. Could you provide more details how it fails? Does it return an invalid sound id?\nI tried these codes (simplified from my actual project's code)\njava\n// with preloading\naudioEngine.preloadSoundFile(\"bgm.ogg\");\nint soundId = audioEngine.createStereoSound(\"bgm.ogg\");\n// soundId = some valid id\naudioEngine.playSound(soundId, true); // success\njava\n// without preloading\nint soundId = audioEngine.createStereoSound(\"bgm.ogg\");\n// soundId = GvrAudioEngine.INVALID_ID\naudioEngine.playSound(soundId, true); // failure\ncreateSoundObject works correctly in both case.\njava\n// with preloading\naudioEngine.preloadSoundFile(\"se.ogg\");\nint soundId = audioEngine.createSoundObject(\"se.ogg\");\n// soundId = some valid id\naudioEngine.playSound(soundId, false); // success\njava\n// without preloading\nint soundId = audioEngine.createSoundObject(\"se.ogg\");\n// soundId = some valid id\naudioEngine.playSound(soundId, false); // success\n. I created an Android project for reproducing this issue.\nhttps://github.com/niusounds/GvrAudio-issue\nPlease see com/eje_c/gvraudioproblem/MainActivity.java#20\n. I have ported arm model to Java from Unreal's C++!\nhttps://gist.github.com/niusounds/ceaa9034a4e8f62902de1ab654b180a3. ",
    "markya0616": "Yes, we also need this feature!!!!\nCan we use the left and right audio channel to create the spatial audio effects?\n. ",
    "honjane": "Upgrade to v0.8.0 \uff0cis working\n. ",
    "qqwazerty": "It think this must have been with a Nexus 5.. ",
    "dri94": "This error is still present on the galaxy s7. android.view.InflateException: Binary XML file line #15: Binary XML file line #15: Error inflating class com.google.vr.sdk.widgets.video.VrVideoView\n. I have tested this on code that is known to work and has previously worked 100%. This issue is happening on a stock Google Pixel.. ",
    "trusttri": "Mine is galaxy s6, and I am having the same issue.\n. 10-25 07:22:14.531 4701-4701/com.appinventor.vrjaneim E/AndroidRuntime: FATAL EXCEPTION: main\n                                                                        Process: com.appinventor.vrjaneim, PID: 4701\n                                                                        java.lang.RuntimeException: Unable to start activity ComponentInfo{com.appinventor.vrjaneim/com.appinventor.vrjaneim.VirtualActivity}: android.view.InflateException: Binary XML file line #9: Binary XML file line #9: Error inflating class com.google.vr.sdk.base.GvrView\n                                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3254)\n                                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\n                                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\n                                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\n                                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\n                                                                            at android.os.Looper.loop(Looper.java:158)\n                                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\n                                                                            at java.lang.reflect.Method.invoke(Native Method)\n                                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\n                                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\n                                                                         Caused by: android.view.InflateException: Binary XML file line #9: Binary XML file line #9: Error inflating class com.google.vr.sdk.base.GvrView\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:551)\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\n                                                                            at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:474)\n                                                                            at android.app.Activity.setContentView(Activity.java:2387)\n                                                                            at com.appinventor.vrjaneim.VirtualActivity.onCreate(VirtualActivity.java:49)\n                                                                            at android.app.Activity.performCreate(Activity.java:6876)\n                                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\n                                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\n                                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\u00a0\n                                                                         Caused by: android.view.InflateException: Binary XML file line #9: Error inflating class com.google.vr.sdk.base.GvrView\n                                                                            at android.view.LayoutInflater.createView(LayoutInflater.java:657)\n                                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:776)\n                                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:716)\n                                                                            at android.view.LayoutInflater.rInflate(LayoutInflater.java:847)\n                                                                            at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:810)\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:527)\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\u00a0\n                                                                            at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:474)\u00a0\n                                                                            at android.app.Activity.setContentView(Activity.java:2387)\u00a0\n                                                                            at com.appinventor.vrjaneim.VirtualActivity.onCreate(VirtualActivity.java:49)\u00a0\n                                                                            at android.app.Activity.performCreate(Activity.java:6876)\u00a0\n                                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\u00a0\n                                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\u00a0\n                                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\u00a0\n                                                                         Caused by: java.lang.reflect.InvocationTargetException\n                                                                            at java.lang.reflect.Constructor.newInstance(Native Method)\n                                                                            at android.view.LayoutInflater.createView(LayoutInflater.java:631)\n                                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:776)\u00a0\n                                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:716)\u00a0\n                                                                            at android.view.LayoutInflater.rInflate(LayoutInflater.java:847)\u00a0\n                                                                            at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:810)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:527)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\u00a0\n                                                                            at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:474)\u00a0\n                                                                            at android.app.Activity.setContentView(Activity.java:2387)\u00a0\n                                                                            at com.appinventor.vrjaneim.VirtualActivity.onCreate(VirtualActivity.java:49)\u00a0\n                                                                            at android.app.Activity.performCreate(Activity.java:6876)\u00a0\n                                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\u00a0\n                                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\u00a0\n                                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\u00a0\n                                                                         Caused by: java.lang.NoClassDefFoundError: com.google.vrtoolkit.cardboard.proto.nano.Phone$PhoneParams\n                                                                            at com.google.vr.cardboard.ConfigUtils.readPhoneParamsFromExternalStorage(SourceFile:124)\n                                                                            at com.google.vr.cardboard.LegacyVrParamsProvider.readPhoneParams(SourceFile:37)\n                                                                            at com.google.vr.sdk.base.HeadMountedDisplayManager.createScreenParams(HeadMountedDisplayManager.java:163)\n                                                                            at com.google.vr.sdk.base.HeadMountedDisplayManager.<init>(HeadMountedDisplayManager.java:53)\n                                                                            at com.google.vr.sdk.base.CardboardViewNativeImpl.<init>(CardboardViewNativeImpl.java:81)\n                                                                            at com.google.vr.sdk.base.ImplementationSelector.createCardboardViewApi(ImplementationSelector.java:34)\n                                                                            at com.google.vr.sdk.base.GvrView.init(GvrView.java:764)\n                                                                            at com.google.vr.sdk.base.GvrView.<init>(GvrView.java:255)\n                                                                            at java.lang.reflect.Constructor.newInstance(Native Method)\u00a0\n                                                                            at android.view.LayoutInflater.createView(LayoutInflater.java:631)\u00a0\n                                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:776)\u00a0\n                                                                            at android.view.LayoutInflater.createViewFromTag(LayoutInflater.java:716)\u00a0\n                                                                            at android.view.LayoutInflater.rInflate(LayoutInflater.java:847)\u00a0\n                                                                            at android.view.LayoutInflater.rInflateChildren(LayoutInflater.java:810)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:527)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:429)\u00a0\n                                                                            at android.view.LayoutInflater.inflate(LayoutInflater.java:380)\u00a0\n                                                                            at com.android.internal.policy.PhoneWindow.setContentView(PhoneWindow.java:474)\u00a0\n                                                                            at android.app.Activity.setContentView(Activity.java:2387)\u00a0\n                                                                            at com.appinventor.vrjaneim.VirtualActivity.onCreate(VirtualActivity.java:49)\u00a0\n                                                                            at android.app.Activity.performCreate(Activity.java:6876)\u00a0\n                                                                            at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1135)\u00a0\n                                                                            at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3207)\u00a0\n                                                                            at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3350)\u00a0\n                                                                            at android.app.ActivityThread.access$1100(ActivityThread.java:222)\u00a0\n                                                                            at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1795)\u00a0\n                                                                            at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\n                                                                            at android.os.Looper.loop(Looper.java:158)\u00a0\n                                                                            at android.app.ActivityThread.main(ActivityThread.java:7229)\u00a0\n                                                                            at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\u00a0\n                                                                            at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\n`<?xml version=\"1.0\" encoding=\"utf-8\"?>\n\n<com.google.vr.sdk.base.GvrView\n    android:id=\"@+id/gvr_view\"\n    android:layout_width=\"fill_parent\"\n    android:layout_height=\"fill_parent\"\n    android:layout_alignParentTop=\"true\"\n    android:layout_alignParentLeft=\"true\" />\n\nIt seems I have a error from <com.google.vr.sdk.base.GvrView\n`\n. Sorry, but do you mean to post my apk file here..? Is that possible?\nIf I remove the xml part of com.google.vr.sdk.base.GvrView then the app runs fine.\n. ",
    "bsmith42": "Any future option to add TYPE_STEREO_PARALLEL_VIEW (for side by side video vs. over_under)?\n. Thanks for the quick response!  I brought it up since Ricoh Theta uses it.\n. ",
    "albertoruibal": "Great! Thank you!\n. No, it's not official. I created this alternative repo to distribute our jmini3d-vr-demo in github. I will keep it updated while the official repo is not published.\n. Finally, there is an official repository at http://google.bintray.com/googlevr and we removed our repo at https://bintray.com/mobialia/maven/\nMore info on how to use the official repo at: https://developers.google.com/vr/android/get-started. ",
    "CAMOBAP795": "I don't know is it official or not but I found dependencies here https://bintray.com/mobialia\nTemplate:\nhttps://bintray.com/mobialia/maven/com.google.gvr.*\nExamples:\nhttps://bintray.com/mobialia/maven/com.google.gvr.base\nhttps://bintray.com/mobialia/maven/com.google.gvr.audio\nhttps://bintray.com/mobialia/maven/com.google.gvr.common\n. @smdol looks like you right (almost), this device have next specification display spec 5.5 in, IPS, 1080 x 1920 pixels, 24 bit\nAnd market helper apps and adb shell dumpsys display reports 440 DPI\nBut https://www.sven.de/dpi/ reports 400.53 PPI\n*AFAIK DPI and PPI in context of phone screens the same, correct me if I'm wrong.\n. ",
    "b95505017": "Any news here? It seems that gvr still not distribute to jCenter.\n. ",
    "leo-plus": "Is that GoPro ODYSSEY? Or 360Heros ?\n. ",
    "chenwulue": "Thanks,I will do it\n. ",
    "xdf103": "We understand that it is intentional to have the tutorial screen, but it could become annoying as users have to see it on every screen. Is it possible to disable/hide it, or configure it to display only once? \n. I have two activities, a play list activity (a simple ListView) and a play activity (using GvrView). Every time I go from the play list activity to the play activity, I see the tutorial screen, e.g. list activity -> play activity (tutorial screen appears) -> go back to list activity -> play activity (tutorial screen appears again) . How do I configure it to appear only once? \n. I mean \"place your phone into the cardboard\" screen\n. Is there any way to disable/hide it?\n. @nathanmartz please ignore that issue. I found out it was our problem, not an issue in GVR. However, we found the transition screen a bit annoying. Both our activities (the list activity and the play activity) use GvrActivity. When the user first start list activity, he sees the transition screen. After that every time he chooses a video to play, he will see the transition screen. It would be good if the SDK can give us the control to decide when to show the transition screen, otherwise we may have to write our own SDK. \n. Yes. We are seeing the screen during VR-VR transactions, i.e. going from one GvrActivity to another GvrActivity. \n. We can extract the 4 channel FOA audio data from ExoPlayer. Is there any way to pass this audio data stream to Google VR SDK to play out spatial audio?\n. Is Google going to open source the native methods, e.g. nativeCreateSoundfield? If yes, where can I find the source code? I would like to know how the soundfield function is implemented. \n. I noticed that VrVideoView uses ExoPlayer to read from video. Why not add a TrackRenderer to render spatial audio if the video contains ambisonic audio? Is it very difficult to add this feature or is there any limitation?\n. We are playing a 360 video with spatial audio (first-order ambisonic ACN SN3D Ambix format) using exoplayer. The video part is working fine and I can also hear the audio sound, but the sound is not spatial. I am thinking of implementing a custom TrackRenderer to render spatial audio. Are there any reference or documents for rendering spatial audio? \n. How to enable Async Reprojection? Is there any requirement for using it?\n. ",
    "RikHeijdens": "Thanks! Where can I find release notes for 0.8.5? They do not appear to be on the release notes page (yet).\n. ",
    "rhsu0268": "I've had this happen to me too. It means that the image or video is too big. Try to make it smaller and try again. \n. I see. I was able to embed a gvrview on top of a panorama view. That actually worked out. But rotating the camera is something I will try in the future. \n. Thank you. \n. ",
    "dvdobrovolskiy": "I tried to say I cannot. Video 360 in stereo and 4K resolution is big by nature\n. yes, Large heap is on. But I believe some android firmwares my set own limitation. I use MIUI\n. ",
    "jayspringfield": "I got this when I didn't import the entire cardboard SDK project and instead tried to just import one of the samples.\n. My app would crash because another library it included for video streaming used methods missing from the older version of ExoPlayer.  If I included the newer one in my build.gradle file, I would get ZipExceptions because of the duplicate classes.\nI ended up unzipping the aar and then the classes.jar inside of it, deleting the ExoPlayer classes and putting the whole thing back together.  I could then include ExoPlayer in build.gradle.  Everything seems to be working fine as far as I can tell (but anyone else who tries this does it their own risk!).\nMoving forward, it's bad SDK practice to include class files from 3rd party libraries due to this type of conflict, especially when you're using gradle and those classes are available in a public maven repo.  Can't you just remove that source from the videowidget build path and use something like this:\ncompile 'com.google.android.exoplayer:exoplayer:r1.5.7'\n. No worries, guys.  I realize it's early on for this SDK and sometimes things just get done the quick and dirty way.  Looking forward to the future releases.\n. ",
    "electmk": "@dav-cz \nHow to back from the full screen mode directly to previous activity ??\n@hegazy \nI tried your code with (VrPanoramaView) but i get error in (fullScreenDialog). @Awsom3D \nI got error (Method does not override method from its superclass) when i put the method in VrPanoramaActivity. @Awsom3D \nIt's worked .. thank you \nBut it shows a black screen for seconds before finish .. Can I avoid this?. @dav-cz \nWill there be support soon ? Or delayed for a long time ?\n. @dav-cz \nHave you been support now on SDK v0.9.0 ?\nAnd how i know what's new on each update ?\n. @dav-cz \n@RamIndani \nHow I know which version is referenced in the app?\nI didn't find (com.google.vr.sdk.base.Constants.VERSION;) in any file \n. @nathanmartz \n@sigmaxipi \nI use panoWidgetView.setDisplayMode(3) to Direct entry Vr mode but still appears (fullscreen_back_button) which opens (pano fullscreen) .. I would like to handle (fullscreen_back_button) button event to finish and back to previous activity. @jdduke \nRelease Notes has not changed since V 1.80\nhttps://developers.google.com/vr/android/release-notes. ",
    "Awsom3D": "@dav-cz \nI don't see how the official API fix this problem.\nExiting the fullscreen mode still does not exit the activity.\n@electmk the code from @hegazy worked on older version of the gvr-android-sdk : 1.20.0 for instance.\nThe new solution is to use the onDisplayModeChanged callback from VrPanoramaEventListener.\n@Override\npublic void onDisplayModeChanged(int newDisplayMode) {\n    super.onDisplayModeChanged(newDisplayMode);\n    if (newDisplayMode == VrWidgetView.DisplayMode.EMBEDDED) {\n        VrPanoramaActivity.this.finish();\n    }\n}. @electmk as said before the onDisplayModeChanged callback is from VrPanoramaEventListener, not VrPanoramaActivity.\nFrom your VrPanoramaActivity onCreate you should set a VrPanoramaEventListener on your VrPanoramaView :\npanoWidgetView = (VrPanoramaView) findViewById(R.id.pano_view);\npanoWidgetView.setEventListener(new ActivityEventListener());\nThen from this listener, override the onDisplayModeChanged callback\nprivate class ActivityEventListener extends VrPanoramaEventListener {\n  @Override\n  public void onDisplayModeChanged(int newDisplayMode) {\n  [...]. @electmk sorry, no clue.. ",
    "gary-lo": "Here's some unsupported hacks:\nhttps://gist.github.com/gary-domain/0a455ee35eaba6da7591e09627d2d1f2\nOr simply:\nTrackingSensorsHelper.enableTouchTracking = true;\nBefore initiating the view.\nThis has some side affects (i.e. hides the VrButton). \nWhich seems to get offset by:\nTrackingSensorsHelper.showVRModeButtonForTesting = true; \nBut yeah, these are hacks.\n. Also other side affects are, enableTouchTracking = true will make the method the internal method this.sensorsHelper.areTrackingSensorsAvailable() become false at all times which from I can see affects ViewRotator class. So far I can't see massive issues though. And also I'm not sure what other classes access that variable.\nSo I think using my gist is probably safer, that way you keep the functionality of areTrackingSensorsAvailable() in tact.\nAlso note that this obviously has been done by design by the team and I'm sure there's reasons for it so, expect it to be buggy:\nif(this.sensorsHelper.areTrackingSensorsAvailable()) {\n   touchTracker.setTouchSpeed(0.0F, 0.0F);\n}\n. The gist itself wont. It should in theory since they extend the same base class. You'll have to repeat the same process.\nI.e. create a new class that extends videoview in that same package.\npublic class TouchEnabledVrVideoView extends VrVideoView {\nHaven't tested it though.\n. ",
    "zhangleiuser": "I also have this problem, hope to add the pan gesture as soon as possible!\n. ",
    "ghenzhimura": "is touch tracking disabled by default in v1.0.1? how to enable it again? @dav-cz \n. ",
    "24ark": "Thanks a lot. It works.\n. ",
    "ariviere": "The issue with this method is that you have a black screen while going from portrait to landscape and vice versa. Isn't it possible to have \"android:configChanges=\"orientation|keyboard|keyboardHidden|screenSize\" and to tell your video that the orientation changed so it can adapt automatically ?\n. Yes, my view is destroyed and recreated but if I don't use configChanges=\"orientation|keyboard|keyboardHidden|screenSize\". But if I use it, it won't be destroyed and recreated. My problem is that the video doesn't have the correct orientation if I do that just like your screenshot.\nBy removing the previous fragment and attach a new fragment, I guess you destroy and recreate the video, so you also have a black screen right ? And the problem would be the same by reloading the video (except if you use a method I don't know).\nI guess what you didn't understand is that the video is starting after the black screen, but I want to avoid it and keep a clean user experience.\n. Cool, thanks! The idea is to have a mute/unmute button on the video before the user go in VR.\n. Yes, I noticed that, thank you!. I couldn't get it to work too. \nI've seen in the TouchTracker class that there is a \"verticalTrackingEnabled\" boolean but even in fullscreen (where it's supposed to be enabled), it's not scrolling vertically.\nVertical scrolling is an important feature in the project I'm working on :(\n. I'm using the latest version of the SDK (1.0.0) with the \"simplevideowidget\" sample and a HLS file since I cannot get the file \"congo.mp4\" to play. I click on the fullscreen button and when I try to scroll vertically, nothing happens.\nAlso, is it possible to get an option to activate the vertical scrolling even when we're not in fullscreen ?\n. Up! \nDid anyone found a workaround for this issue while we wait for an official fix ? I tried to extend classes from the library but too many methods and attributes are private :(. According to the release note, it's not fixed https://developers.google.com/vr/android/release-notes\nBut I haven't tried it yet. This issue has also been reported here https://github.com/googlevr/gvr-android-sdk/issues/196\nHopefully we can get a fix soon. I went into the code on earlier versions of the library and it was possible to modify it to add the feature. In fact, vertical drag was disabled on purpose \ud83d\ude41. But I can't use this fix anymore because this part of the code has been moved to another file written in C.. ",
    "lukassruc": "I used HeadTransform in SimpleVrVideoActivity app, but it didn\u00b4t work. Is there any option how to show x,y,z vector concretely in this app?\n(I don\u00b4t know how to involve the HeadTransform class into this app..)\nThank you\n. Of course, I do not expect a real legal advice. I wanted only non-binding solution that is practically used.\n(I have already read many information about apache license, but I stil don\u00b4t know how to deal with this)\n. ",
    "vinjn": "Please use English\n. ",
    "sheeyphone": "When I run the sample called simplevideowidget on Huawei Devices.\nI could get some audio output from my phone but the VrVideoView is still black!\n. logcat:\n07-11 11:54:06.111 9957-9957/com.google.vr.sdk.samples.simplevideowidget I/HwCust: Constructor found for class android.app.HwCustHwWallpaperManagerImpl\n07-11 11:54:06.236 9957-9957/com.google.vr.sdk.samples.simplevideowidget I/ExoPlayerImpl: Init 1.5.8\n07-11 11:54:06.322 9957-9957/com.google.vr.sdk.samples.simplevideowidget I/SimpleVrVideoActivity: Intent is not ACTION_VIEW. Using the default video.\n07-11 11:54:06.328 9957-10014/com.google.vr.sdk.samples.simplevideowidget I/VrWidgetRenderer: Native renderer has just been destroyed. Dropping request.\n07-11 11:54:06.329 9957-10015/com.google.vr.sdk.samples.simplevideowidget I/SphericalMetadataMP4: Located spherical metadata:\n                                                                                                  <?xml version=\"1.0\"?>GSpherical:Sphericaltrue/GSpherical:SphericalGSpherical:Stitchedtrue/GSpherical:StitchedGSpherical:StitchingSoftwareSpherical Metadata Tool/GSpherical:StitchingSoftwareGSpherical:ProjectionTypeequirectangular/GSpherical:ProjectionTypeGSpherical:StereoModetop-bottom/GSpherical:StereoMode/rdf:SphericalVideo\n07-11 11:54:06.415 9957-10016/com.google.vr.sdk.samples.simplevideowidget E/HAL: load: id=gralloc != hmi->id=gralloc\n07-11 11:54:06.416 9957-10016/com.google.vr.sdk.samples.simplevideowidget I/OpenGLRenderer: Initialized EGL, version 1.4\n07-11 11:54:06.478 9957-10014/com.google.vr.sdk.samples.simplevideowidget W/art: Attempt to remove non-JNI local reference, dumping thread\n07-11 11:54:06.539 9957-10035/com.google.vr.sdk.samples.simplevideowidget I/System: core_booster, getBoosterConfig = false\n07-11 11:54:06.601 9957-10038/com.google.vr.sdk.samples.simplevideowidget I/System: core_booster, getBoosterConfig = false\n07-11 11:54:06.771 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported profile 64 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported profile 64 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported profile 64 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported profile 64 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported profile 64 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported profile 64 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized level 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized level 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized level 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized level 0 for video/avc\n07-11 11:54:06.772 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile 0 for video/avc\n07-11 11:54:06.775 9957-10013/com.google.vr.sdk.samples.simplevideowidget I/VideoCapabilities: Unsupported profile 16384 for video/mp4v-es\n07-11 11:54:06.775 9957-10013/com.google.vr.sdk.samples.simplevideowidget I/VideoCapabilities: Unsupported profile 16384 for video/mp4v-es\n07-11 11:54:06.783 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported mime video/x-pn-realvideo\n07-11 11:54:06.787 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported mime video/mpeg\n07-11 11:54:06.791 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 0/0 for video/mpeg2\n07-11 11:54:06.792 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 0/2 for video/mpeg2\n07-11 11:54:06.792 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 0/3 for video/mpeg2\n07-11 11:54:06.796 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 32768/2 for video/mp4v-es\n07-11 11:54:06.803 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported mime video/vc1\n07-11 11:54:06.811 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unsupported mime video/x-flv\n07-11 11:54:06.815 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 0/0 for video/mpeg2\n07-11 11:54:06.815 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 0/2 for video/mpeg2\n07-11 11:54:06.815 9957-10013/com.google.vr.sdk.samples.simplevideowidget W/VideoCapabilities: Unrecognized profile/level 0/3 for video/mpeg2\n07-11 11:54:06.849 9957-10013/com.google.vr.sdk.samples.simplevideowidget I/VideoCapabilities: Unsupported profile 4 for video/mp4v-es\n07-11 11:54:06.869 9957-10059/com.google.vr.sdk.samples.simplevideowidget I/OMXClient: Using client-side OMX mux.\n07-11 11:54:06.889 9957-10059/com.google.vr.sdk.samples.simplevideowidget I/IMG-OMX: IMG_OMXLibWrapper library libomx_vxd.so mLibHandle:0xb2c4d004\n07-11 11:54:06.893 9957-10059/com.google.vr.sdk.samples.simplevideowidget I/IMG-OMX: IMG_OMXLibWrapper library libomx_vxe.so mLibHandle:0xb2c4d344\n07-11 11:54:06.893 9957-10059/com.google.vr.sdk.samples.simplevideowidget E/IMGTOPAZ: OMX_Init done\n07-11 11:54:06.893 9957-10059/com.google.vr.sdk.samples.simplevideowidget E/IMGTOPAZ: Encoder nIndex is overflow or ComponentName is NULL\n07-11 11:54:06.912 9957-10060/com.google.vr.sdk.samples.simplevideowidget I/SoftAAC2: limiting to stereo output\n07-11 11:54:06.912 9957-10060/com.google.vr.sdk.samples.simplevideowidget I/SoftAAC2: Reconfiguring decoder: 0->48000 Hz, 0->2 channels\n07-11 11:54:06.920 9957-10063/com.google.vr.sdk.samples.simplevideowidget I/OMXClient: Using client-side OMX mux.\n07-11 11:54:06.925 9957-10062/com.google.vr.sdk.samples.simplevideowidget I/MediaCodec: [OMX.IMG.MSVDX.Decoder.AVC] setting surface generation to 10195969\n07-11 11:54:06.927 9957-10063/com.google.vr.sdk.samples.simplevideowidget I/HwExtendedCodec: mime is [video/avc] at setVideoFormat\n07-11 11:54:06.985 9957-10013/com.google.vr.sdk.samples.simplevideowidget I/AudioTrack-JNI: audioTrack send start state to pg\n07-11 11:54:07.054 9957-9957/com.google.vr.sdk.samples.simplevideowidget I/SimpleVrVideoActivity: Sucessfully loaded video 10027\n07-11 11:54:07.056 9957-10014/com.google.vr.sdk.samples.simplevideowidget W/GLConsumer: [SurfaceTexture-1-9957-0] bindTextureImage: clearing GL error: 0x500\n. ",
    "LeeSniper": "I got the same problem. When I run my app on HM2A, the video was played correctly. But when I tried to run my app on Huawei mate8 there was only sound but VrVideoView was black.\n. ",
    "marcelvoss95": "Is it possible to render Panorama Image into GvrView to use HeadTransform ?\n. ",
    "rneogy": "If you create a empty vrview behind the panorama view, you can use the vrview to get the headview, quaternion, etc. Not exactly the most efficient way, but works for now.\nI too am wondering how exactly the VrPanoramaView widget works/how can one recreate the experience using VrView. Is this answered anywhere?\n. Google Glass. I don't think I would - as I said, it works perfectly on other android devices. I'll try and take a video soon.\n. Hi,\nYeah I think yaw should be plenty enough. Just essentially so that I can set what direction they're looking.\nDo you have an estimate of when this feature would be added to Google VR? \nThanks!\n. ",
    "ashwin-sectorqube": "On Loading .m3u8 file i am getting error like this.... please help \n08-06 12:48:06.611 11657-11671/com.google.vr.sdk.samples.simplevideowidget E/ExoPlayerImplInternal: Internal track renderer error.\n                                                                                                    com.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException: None of the available extractors (WebmExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\n                                                                                                        at com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:263)\n                                                                                                        at com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:149)\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.incrementalPrepareInternal(ExoPlayerImplInternal.java:275)\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:205)\n                                                                                                        at android.os.Handler.dispatchMessage(Handler.java:107)\n                                                                                                        at android.os.Looper.loop(Looper.java:207)\n                                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)\n                                                                                                        at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n                                                                                                     Caused by: com.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException: None of the available extractors (WebmExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\n                                                                                                        at com.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractorHolder.selectExtractor(ExtractorSampleSource.java:899)\n                                                                                                        at com.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractingLoadable.load(ExtractorSampleSource.java:829)\n                                                                                                        at com.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:209)\n                                                                                                        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\n                                                                                                        at java.util.concurrent.FutureTask.run(FutureTask.java:237)\n                                                                                                        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\n                                                                                                        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\n                                                                                                        at java.lang.Thread.run(Thread.java:818)\n08-06 12:48:06.612 11657-11657/com.google.vr.sdk.samples.simplevideowidget E/VrVideoPlayerInternal: 9750259.onPlayerError\n                                                                                                    com.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException: None of the available extractors (WebmExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\n                                                                                                        at com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:263)\n                                                                                                        at com.google.android.exoplayer.SampleSourceTrackRenderer.maybeThrowError(SampleSourceTrackRenderer.java:149)\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.incrementalPrepareInternal(ExoPlayerImplInternal.java:275)\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:205)\n                                                                                                        at android.os.Handler.dispatchMessage(Handler.java:107)\n                                                                                                        at android.os.Looper.loop(Looper.java:207)\n                                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)\n                                                                                                        at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n                                                                                                     Caused by: com.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException: None of the available extractors (WebmExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\n                                                                                                        at com.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractorHolder.selectExtractor(ExtractorSampleSource.java:899)\n                                                                                                        at com.google.android.exoplayer.extractor.ExtractorSampleSource$ExtractingLoadable.load(ExtractorSampleSource.java:829)\n                                                                                                        at com.google.android.exoplayer.upstream.Loader$LoadTask.run(Loader.java:209)\n                                                                                                        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:423)\n                                                                                                        at java.util.concurrent.FutureTask.run(FutureTask.java:237)\n                                                                                                        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1113)\n                                                                                                        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:588)\n                                                                                                        at java.lang.Thread.run(Thread.java:818)\n08-06 12:48:06.620 11657-11657/com.google.vr.sdk.samples.simplevideowidget E/SimpleVrVideoActivity: Error loading video: com.google.android.exoplayer.extractor.ExtractorSampleSource$UnrecognizedInputFormatException: None of the available extractors (WebmExtractor, FragmentedMp4Extractor, Mp4Extractor, Mp3Extractor, AdtsExtractor, TsExtractor, FlvExtractor, OggExtractor, PsExtractor, WavExtractor) could read the stream.\n. http://playertest.longtailvideo.com/adaptive/bbbfull/bbbfull.m3u8 \nthis is my file\n. ok sorry.... ive tried that too....\nOn Mon, Aug 8, 2016 at 10:05 PM, David Coz notifications@github.com wrote:\n\n@ashwin-sectorqube https://github.com/ashwin-sectorqube -- please don't\nchange the topic of this thread. This is a different issue, most likely\nbecause you didn't specify inputType = FORMAT_HLS, which is necessary to\nplay m3u8 files as explained in the reference documentation\nhttps://developers.google.com/vr/android/reference/com/google/vr/sdk/widgets/video/VrVideoView.html#loadVideo(Uri,%20com.google.vr.sdk.widgets.video.VrVideoView.Options)\n.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/145#issuecomment-238293724,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ATpFKsSIup0uZmw8F10rwrV7nKkcwfueks5qd1rkgaJpZM4JGVkf\n.\n. hi,\n Still im getting the same error on loading .m3u8 file\n\nOn Fri, Aug 5, 2016 at 10:57 PM, David Coz notifications@github.com wrote:\n\nClosed #188 https://github.com/googlevr/gvr-android-sdk/issues/188.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/188#event-746925573,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ATpFKsrsgAaKTb7h6Ojwk5Uo5RssBYGuks5qc3KFgaJpZM4Jdgkj\n.\n. Sorry for that....I'm Sharing an attachment .... i need to set\nmediacontrollers on this screen...[image: Inline image 1] is that possible?\n\nOn Sat, Aug 6, 2016 at 12:26 PM, nathanmartz notifications@github.com\nwrote:\n\nIf you're getting an error, please share them here if they are todo w/ the\nMedia Controllers, otherwise create a new bug if the m3u8 errors are\nunrelated to adding Media Controllers.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/188#issuecomment-238009602,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ATpFKnQaXeiMrcW3l99GXPVf0G4i6Pitks5qdDAZgaJpZM4Jdgkj\n.\n. \n",
    "anurag7141": "For playing m3u8 all you need to do is change the options input forma to  and it will workUri uri = Uri.parse(\"https:proper_url.m3u8\");\n                VrVideoView.Options vrVideoView = new VrVideoView.Options();\n                vrVideoView.inputFormat = VrVideoView.Options.FORMAT_HLS;\n                videoWidgetView.loadVideo(uri, vrVideoView);. ",
    "clarle": "@dav-cz This issue is still happening - do you think it'll be removed anytime?\nThanks!. ",
    "prathimode": "Actually i want to take a screenshot of the view which i am seeing in VR. How can that achieved? \n. @nathanmartz Can you  please point which Screen shot tools i can use here? I need to capture the screenshot programatically.\n. @nathanmartz yes there are some solution but most of them are with getting the content of view and another is to use the adb commend but for that you need a rooted device. but both is not feasible for me here as in case of view content data is not coming for video so i was looking for frame extraction from the video itself.\n. ",
    "WeixiangZhang": "Thanks for your reply.\nHere is output and I am sure the display is 5.5' inches with 1080p resolution.\n- [ro.boot.hardware]: [mt6735]\n- [ro.hardware]: [mt6735]\n- [ro.meizu.hardware.battery]: []\n- [ro.meizu.hardware.emmc]: [HAG2e]\n- [ro.meizu.hardware.psn]: [81116E68D802]\n- [ro.meizu.hardware.version]: [0x57101002]\n- [ro.meizu.product.model]: [M5710]\n- [ro.product.manufacturer]: [Meizu]\n- [ro.product.model]: [m2 note]\n- [ro.product.name]: [m2note]\n- [ro.sf.lcd_density]: [480]\n. ",
    "yubaolinfish": "Two versions (0.8.1 and 0.8.5) have this issue.\n.\n0.8.5 gets here.\n\n0.8.1 gets here.\n\n. \nThanks.\n. ",
    "cpena": "Hi, \nI have the same issue:\n\n(The last button is an image)\nThe OS version is:\n\nBest regards,\nChristian\n. ",
    "mebalzer": "I would like throw my hat into the ring on this as well.  NEODiVR uPLAy lenses make most of the UI overlay visible, so a way to turn this off with the Google VR setting menu would be great. \n. ",
    "dcower": "@xdf103 We use that approach to enable spatial audio rendering in YouTube Android and similar apps. Could you expand a bit on what you're looking for here? E.g., are you looking for spatial-audio-only playback or 360-video-with-spatial-audio playback? Do you need streaming video/audio? Feel free to reach out privately ([my username]@google.com) if you prefer.\n. ",
    "gtStation": "@xdf103 have you happened to have found the resources to start your Spatial audio rendering? We are in need of a similar solution.. @jkammerl  - that is great to hear.\nWill this be included in the Unity version of the plugin?\nWhat about ambisonics for iOS?\nWhich platforms can I use GVR SDK in terms of audio? Will the spatializer work on Oculus Rift/HTC, (PlayStation??). @jkammerl \nSo playing an MP4 with ambisonic will be possible through the GVR SDK?\nDo you have a rough (or better) estimation of when will it be released? (beta release?). @jkammerl is there an ETA for the Exoplayer wrapper?. ",
    "andrewlewis": "Regarding support for spatial audio rendering in ExoPlayer: we recently pushed an ExoPlayer GVR extension to our development branch. It provides GvrAudioProcessor which wraps GvrAudioSurround from the GVR SDK. There's some information on how to use this on our blog.. @fashioncj We moved the method to DefaultRenderersFactory, so the new pattern is to subclass DefaultRenderersFactory (or implement RenderersFactory) and pass it to ExoPlayerFactory.newSimpleInstance.. ",
    "fashioncj": "@andrewlewis Can you provide a sample demo for GvrAudioProcessor. I can't find a override function buildAudioProcessors on new SimpleExoPlayer(){}. My extentions version is \ncompile 'com.google.android.exoplayer:exoplayer:r2.4.3' and \n   compile 'com.google.android.exoplayer:extension-gvr:r2.4.3'. ",
    "sani3854": "How to youtube video play in VrVideoView (google)?\nmy code is :+1: \nVrVideoView.Options options = new VrVideoView.Options();\n                    //options.inputType = VrVideoView.Options.TYPE_STEREO_OVER_UNDER;\n                    // videoWidgetView.loadVideoFromAsset(\"congo.mp4\", options);\n                options.inputFormat = VrVideoView.Options.FORMAT_HLS;\n                options.inputType = VrVideoView.Options.TYPE_MONO; // for 360 video\n\n                videoWidgetView.loadVideo(Uri.parse(\"https://www.youtube.com/watch?v=H6SsB3JYqQg\"), options);\n                videoWidgetView.playVideo();\n\nError is  Error fetching video manifest com.google.android.exoplayer.ParserException: Failed to parse the playlist, could not identify any tags.\nAny solutions???. ",
    "JerryChin": "It's not fixed!\n. ",
    "StefanLiu007": "Thanks\n. ",
    "basselkassem": "I am using Android 6.0 Marshmallow Api level 23 \n. I update the google.vr.sdk and it worked very well, Thanks alot\n. ",
    "lantianm": "It's been a while after it is fixed, but i have same issue with my Galaxy S6 and S7 with Android M.\nIt seems that so library was updated for fix it.\ndoes anybody know what exact root cause this blank screen at the Android 6.0.1?\nIs it driver issue? or some else android platform related issue?\n. ",
    "b005t3r": "I have the same question as @ShayFB - what was the fix?. ",
    "yijianwang": "Finally, I found the solution. Just as I inferred, I need to convert YUY2 to YUV420 before the H264 encoding and streaming.\n. I solved this issue. It is caused by my device that is too old and doesn't support video larger than 1080p.\n. Awesome! Thank you!. ",
    "smore9982": "Why does the video play when using monoscopic then? It's the same source url that I am using.\n. Sorry. I meant when I pass this option in the call to load video.\nvideoOptions.inputType = Options.TYPE_MONO;\nThis worked on the moto x but failed when using videoOptions.inputType = Options.TYPE_STEREO_OVER_UNDER\n. Reducing the size of the video resolved the issue on the note 3.\n. ",
    "dwinnbrown": "I think you may be correct, I was testing on a Vodafone Smart Prime 6 - (unfortunately don't have a nexus) and after some research it doesn't appear to have a gyro. I think my brothers old LG might have one though so will try it out on that if I can.\nThanks\n. I was talking about the ViddeoView - just wandered because we can disable it in iOS\n. ",
    "RajeshJadav": "I also want to use Head Tracking with VrPanoramaView. but i can not find any sample or guidelines for it. how can i determine head position in VrPanoramaView?\n. But when i am viewing through cardboard viewer it is not displaying properly and display different images in cardboard viewer. I am using Lenovo K3 note which has VR mode feature if i use phone's VR mode then it does not have padding and curve and images look properly in cardboard viewer.\n. can i make VrPanoramaview full screen and remove padding and curve?\n. ",
    "flybear528": "you can set 2 VrPanoramaviews in your layout;this is my way to get VRmodel\npanoWidgetView = (VrPanoramaView) findViewById(R.id.pano_view);\n    panoWidgetView.setEventListener(new ActivityEventListener());\npanoWidgetView2= (VrPanoramaView) findViewById(R.id.pano_view2);\npanoWidgetView2.setEventListener(new ActivityEventListener());\n. ",
    "MaheshCapcee": "ok\n. ",
    "sayangel": "oops wrong repo. will do!\n. ",
    "jarivk": "Say there is a app where compressed audio in ambisonic format is streamed over network. Received stream needs to be decoded first and then processed through VR audio engine before rendering. There is no way to process a chunk of PCM data through VR audio engine with current APIs.\nAs per my understanding, current APIs only work with audio files embedded in the app.\n. I don't have answer to your first question right now as we are still exploring. Right now we are experimenting with Java, but might move to NDK in future.\n. I see that Youtube also streams ambisonic audio and renders with spatial effect. How does it do that? How can one implement similar functionality in a custom app?\n. Any chance of this getting supported in next release ?\n. Any update on this ?. @jkammerl that is good to know. looking forward to it.. @jkammerl Thanks! API working as expected!. I think this issue can be closed now.. Using 0.9.1\n- Without preloadSoundFile(), createSoundfield() fails.\n- With preloadSoundFile(), createSoundfield() works but audio is full of glitches.\nUsing 0.8.0\n- createSoundfield() & playback works without any issues with or without preloadSoundFile().\nTested on Nexus9 with Android 7.0 NRD90.\n. Any update on when this will be fixed ?\n. Seeing same issue. addInput() call crashes.. Thanks. Using allocateDirect works.. Audio is fine with v1.40 Java API.. @jkammerl Can you please provide some help here?. Thanks @jkammerl\nI am facing this issue with NDK APIs. I am able to use java surround API.. @jkammerl Can you reopen this issue?. Here is my NDK code http://www.chopapp.com/#7lt94dyq\nBelow is the log for my usage. NDK API doesn't produce any output for every alternate input frame. Also the output when played is very noisy.\n04-03 17:44:30.897 607-5663/com.example.vkarandikar.vrrender E/SurroundDecoder: surround_format 1 input_channels 2 frames_per_buffer 512 sample_rate 44100\n04-03 17:44:31.071 607-5663/com.example.vkarandikar.vrrender E/SurroundDecoder: NULL\n04-03 17:44:31.103 607-5663/com.example.vkarandikar.vrrender D/SurroundDecoder: in 512 output 1024\n04-03 17:44:31.104 607-5663/com.example.vkarandikar.vrrender E/SurroundDecoder: NULL\n04-03 17:44:31.107 607-5663/com.example.vkarandikar.vrrender D/SurroundDecoder: in 512 output 1024\n04-03 17:44:31.108 607-5663/com.example.vkarandikar.vrrender E/SurroundDecoder: NULL\n04-03 17:44:31.113 607-5663/com.example.vkarandikar.vrrender D/SurroundDecoder: in 512 output 1024\n..........\n04-03 17:44:32.813 607-5663/com.example.vkarandikar.vrrender D/VRRender: Playback finished. @jkammerl any update on this?. @jkammerl Your doubt is understandable. But that is not the case. \"input_len\" contains the number of stereo samples as expected by AddInterleavedInput(). SAMPLE_SIZE_IN_BYTES is defined as 2 in the same source file. So memcpy() is copying correct number of bytes from input to output. Also the playback is fine with memcpy() code enabled. But playback is glitchy with SDK processed output.\nI am going to check with v1.60.1. Will update after that.. ",
    "lindenle": ":+1: any updates?. @jkammerl Have the examples been updated? We are having some trouble figuring out how to use the API correctly.\n. ",
    "mjanousek": "Next revision (with setHeadRotation()) haven't been created. Have anyone information about it? When it would be created? @dav-cz ?\nThanks!. ",
    "JayaWei": "I also have the same problem.\n. ",
    "Carlos-CR": "Alright, seems with the latest push it is indeed resolved. My fault for just checking the \"Releases\" section and taking the Jun 11 for granted. Sorry for the inconvenience.\n. In the main Github page for the project, \"<> Code\", right above the files, there's a rundown listing number of commits, branches, contributors and releases. In the releases section, there are only 2 releases listed, latest one being from Jun 11th. \n. Not sure if it is the same issue, but from the screenshots it looks so. I recently had similar issues happening only on S7 and S8 devices. The solution, as it turned out, had to do with a setting in Samsung devices, under Settings > Screen > Screen Resolution. Having anything other than the max resolution caused the issue.\nDropping this just in case anyone else also had this issue.. ",
    "DCarretero59": "Any update on this issue?? Been trying to solve this for a while\n. Does anyone know if it has been fixed in the 1.20 update? Gonna try another way if it's not unfortunately.. It's not unfortunately . ",
    "LandChanning": "I got the same trouble, hope this problem will be solved soon.. ",
    "p-fischer": "I also need to enable vertical scrolling via gestures.\nEven when I'm setting \"verticalTrackingEnabled\" to true it works in neither fullscreen nor non-fullscreen mode. \n. I did some debugging:\nIn fullscreen mode, the flag \"verticalTrackingEnabled\" (see VrWidgetView) is set to true. The onTouchListener (see TouchTracker) recognizes movement on both x- and y-axis. Finally, VrWidgetRenderer calls method nativeOnPanningEvent with dx and dy having values other than 0. This is where I lost track. Sadly, it seems, this issue can only been fixed in native code.. Has anyone found a workaround / hack to enable vertical scrolling?\n@nathanmartz Can you give us some status update please?. I updated to version 1.60.0 and tried that new method setPureTouchTracking() however that leads to an immediate app crash producing the following stack trace:\njava.lang.UnsatisfiedLinkError: No implementation found for void com.google.vr.sdk.widgets.pano.VrPanoramaRenderer.nativeSetPureTouchTracking(long, boolean) (tried Java_com_google_vr_sdk_widgets_pano_VrPanoramaRenderer_nativeSetPureTouchTracking and Java_com_google_vr_sdk_widgets_pano_VrPanoramaRenderer_nativeSetPureTouchTracking__JZ)\n  at com.google.vr.sdk.widgets.pano.VrPanoramaRenderer.nativeSetPureTouchTracking(Native Method)\n  at com.google.vr.sdk.widgets.common.VrWidgetRenderer$SetPureTouchTrackingRequest.execute(VrWidgetRenderer.java:322)\n  at com.google.vr.sdk.widgets.common.VrWidgetRenderer.executeApiRequestOnGlThread(VrWidgetRenderer.java:257)\n  at com.google.vr.sdk.widgets.common.VrWidgetRenderer.onSurfaceCreated(VrWidgetRenderer.java:120)\n  at com.google.vr.sdk.widgets.pano.VrPanoramaRenderer.onSurfaceCreated(VrPanoramaRenderer.java:63)\n  at android.opengl.GLSurfaceView$GLThread.guardedRun(GLSurfaceView.java:1503)\n  at android.opengl.GLSurfaceView$GLThread.run(GLSurfaceView.java:1240)\n@isagorr did you run into the same issue?  . I opened a new issue for that problem #434 . I tested this again with version 1.80.0 and \"pure touch tracking\" mode is now implemented for VrPanoramaView :)\nSummed up: vertical camara movements through gestures work now. Just not in the hybrid way together with gyroscope navigation, but as a separate mode.\nIn general, I would really appreciate version change logs and if the GitHub issues would be updated with that kind of information by the maintainers of the library.. I'm using VrPanoramaView - just as the sample app simplepanowidget does. Hi @sigmaxipi , thank you for your answer.\nSince I'm desperately looking for a way to make vertical panning available for panoramas, I'm willing to test experimental API too. Do you know if that method will be implemented for VrPanoramaRenderer eventually?\nMore importantly: Do you know an existing way, how the camera can be moved vertically via touch gestures?. I tested this again with version 1.80.0 and \"pure touch tracking\" mode is now implemented for VrPanoramaView :)\nIn general, I would really appreciate version change logs and if the GitHub issues would be updated with that kind of information.. ",
    "isagorr": "It's not yet fixed in 1.30 either.. This is one of the most commented issues, and yet did not get fixed with the new 1.60 release :(\nWhereas there is a new feature setPureTouchTracking(); vertical tracking actually works if this is set (but no gyro obviously). Not fair :P. @p-fischer I just tried it and yes, it crashes. Works with VrVideoView though.. setPureTouchTracking() in v1.60. ",
    "SMikhlevskiy": "I do not have a gyro on my phone. Without vertical scrolling , the widget looks terrible. Will the bug fix in the near future or should I look for another library?. ",
    "iNicod": "Do you know if we can keep both gestures and gyroscope enabled ?. ",
    "Gervil": "The solution for this is only set this setPureTouchTracking(true);\n. The solution for this is only set this setPureTouchTracking(true);. ",
    "DungLai": "Hi @jarivk, could you please show me how to playback after createSoundField? \nI use gvrAudioEngine.playSound(soundFieldId, true); but they produce white noise only.\nI'm using v1.120.0, Samsung galaxy S7, android 7.0.. @Raisongran No ambisonic can't be mono format. It's 4 channels wav file. Make sure bit depth is 32 otherwise they will produce white noise.. The problem has been solved!\nThanks to Hector Centeno, the developer of AmbiExplorer (available on Android PlayStore).\nMy ambisonic file is in wrong bits depth (24 bits) and it causes white noise, I render again to 32 bits and now they work, no more white/glitchy noise.\nRegards.. ",
    "Raisongran": "@DungLai, I had same problem. Make sure that your sound is in mono format.. @anokta, can you help me with audio stream support? I already spent a lot of time on tormented with GVRAudioSurround, but still have no clue how to deal with it: I can't find a code samples with implementation of it. So, it would be great if you(or someone else?) will share working sample.. ",
    "AnkitAndroaid": "@nathanmartz  Is there a way or method to hide this icon without implementing my own 360 playback. Because this is not giving a good UX in my app.\n. ",
    "kchecker": "Thanks for your response. \nAre you aware of a similar solution in Javascript or a Web based library for doing interlinked Panoramas like StreetView?\n. ",
    "dekalo-stanislav": "@dav-cz thank you for your feedback, but after add proguard-rules.pro with mentioned lines, nothing changes, still native crash.\n08-22 10:52:59.639 199-199/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\n08-22 10:52:59.639 199-199/? A/DEBUG: Build fingerprint: 'google/hammerhead/hammerhead:6.0.1/MOB30Y/3067468:user/release-keys'\n08-22 10:52:59.639 199-199/? A/DEBUG: Revision: '11'\n08-22 10:52:59.640 199-199/? A/DEBUG: ABI: 'arm'\n08-22 10:52:59.640 199-199/? A/DEBUG: pid: 28426, tid: 28446, name: GLThread 9988  >>> com.google.vr.sdk.samples.simplevideowidget <<<\n08-22 10:52:59.640 199-199/? A/DEBUG: signal 6 (SIGABRT), code -6 (SI_TKILL), fault addr --------\n08-22 10:52:59.656 199-199/? A/DEBUG:     r0 00000000  r1 00006f1e  r2 00000006  r3 af09f978\n08-22 10:52:59.656 199-199/? A/DEBUG:     r4 af09f980  r5 af09f930  r6 00000002  r7 0000010c\n08-22 10:52:59.656 199-199/? A/DEBUG:     r8 b6d70ec0  r9 b4db6a00  sl af09f4bc  fp 00000000\n08-22 10:52:59.656 199-199/? A/DEBUG:     ip 00000006  sp af09f2c8  lr b6d36b61  pc b6d38f50  cpsr 400d0010\n08-22 10:52:59.674 199-199/? A/DEBUG: backtrace:\n08-22 10:52:59.674 199-199/? A/DEBUG:     #00 pc 00041f50  /system/lib/libc.so (tgkill+12)\n08-22 10:52:59.674 199-199/? A/DEBUG:     #01 pc 0003fb5d  /system/lib/libc.so (pthread_kill+32)\n08-22 10:52:59.674 199-199/? A/DEBUG:     #02 pc 0001c30f  /system/lib/libc.so (raise+10)\n08-22 10:52:59.674 199-199/? A/DEBUG:     #03 pc 000194c1  /system/lib/libc.so (__libc_android_abort+34)\n08-22 10:52:59.674 199-199/? A/DEBUG:     #04 pc 000174ac  /system/lib/libc.so (abort+4)\n08-22 10:52:59.675 199-199/? A/DEBUG:     #05 pc 0007cf01  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #06 pc 0001536d  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #07 pc 0007ac8f  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #08 pc 0007acb3  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #09 pc 00079051  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #10 pc 00079191  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #11 pc 0007921d  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #12 pc 0001ef53  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #13 pc 0001efdf  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #14 pc 0001f139  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so\n08-22 10:52:59.675 199-199/? A/DEBUG:     #15 pc 0000fff9  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/lib/arm/libpano_video_renderer.so (Java_com_google_vr_sdk_widgets_video_VrVideoRenderer_nativeResize+8)\n08-22 10:52:59.676 199-199/? A/DEBUG:     #16 pc 0017329d  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/oat/arm/base.odex (offset 0x94000) (void com.google.vr.sdk.widgets.video.VrVideoRenderer.nativeResize(long, int, int, float, float, int)+136)\n08-22 10:52:59.676 199-199/? A/DEBUG:     #17 pc 0016e431  /data/app/com.google.vr.sdk.samples.simplevideowidget-2/oat/arm/base.odex (offset 0x94000) (void com.google.vr.sdk.widgets.a.i.onSurfaceChanged(javax.microedition.khronos.opengles.GL10, int, int)+164)\n08-22 10:52:59.676 199-199/? A/DEBUG:     #18 pc 7317a42d  /data/dalvik-cache/arm/system@framework@boot.oat (offset 0x1ec9000)\n. @sigmaxipi it works. Thank you.\nBTW: In first line should be: -keep class com.google.vr.** { native <methods>; }, it seems <methods> was eaten by formatter.\n. @digitalbuddha, do you have access to google-vr lib source code? I did not saw any in public access.\n. ",
    "ChristianBecker": "@sigmaxipi: Can you tell us when the next SDK version will be released so that we'll benefit from the shipped proguard config?\n. ",
    "alexio": "Also having this issue in a recyclerview. Injecting the videoview into the appropriate viewholder during onAttachededToWindow and removing it from the viewholder during onDetachedFromWindow. It will randomly crash when trying to insert/play the videoview when the viewholder is attached. Scrolling up and down will reproduce this issue. \nOnly tested it on a Nexus 6P so far.\n. ",
    "MegaThomas": "Thank you, I think I'll probably customize ExoPlayer myself. :sweat_smile:\n. Nope, since the VrVideoView is in the .jar file, I can't modify it directly.\n. ",
    "githubQueen": "@MegaThomas did you find a way to customize ExoPlayer? I'm also interested in receiving a Dash-Livestream and display it in VR Mode. Would be helpful if you could share some information :) \n. ",
    "SrujithPoondla": "@MegaThomas @nathanmartz @githubQueen did any one found a way to get DASH support in VR SDK or any one worked on that could you please explain in brief the procedure to follow.\n. Thanks for the answer, I have another question regarding libraries you provided as .aar files. Is there any way i can get source code of those .aar files?  @nathanmartz \n. @sigmaxipi when can we expect this upgrade to exoplayer 2.0 APIs?\n. ",
    "ryango": "are you getting duplicate dex?\ncan try excluding the dependency from the aar and if the versions aren't that different you might get lucky\nhttp://stackoverflow.com/questions/23640030/gradle-exclude-specific-files-inside-dependency\n(should probably open source the sdk! :))\n. Ah that's pretty disappointing. We're building a buttonless experience that goes from mono to stereo via rotation and the mono->stereo transition is really nice without the transition view and very confusing with some screen popping up in between.\nThe SDK is awesome and I'm happy to have it instead of having to write all the hard stuff from scratch, however it would be a lot more useful if it were more configurable. Probably going to have to roll this from scratch before shipping unless you change your mind :).\nAdditionally, it looks like the setTransitionViewEnabled in GvrView works (setting it in the treasure hunt sample is effective) so this is inconsistent within the sdk. Kind of a bummer to have a no-op function in an SDK that claims to do something very specific.\nWORKAROUND: For those reading this, you can also unzip the common aar, modify the transition view xml to customize it and then rezip it.\ncd \nmkdir explode\ncd explode\ncp ../common.aar .\nunzip ../common.aar .\nrm common.aar\n(modify res/layout/transition_view.xml keeping all ids present)\nzip -ur ../common.aar *\nand you have your own custom transition view\n. That's awesome! Thanks Nathan. I think it is fair to have the divider and gear as that gives people an entry point to changing their viewer.\n. Thanks again. I think this is a great step to enabling a lot more experiences to be built on your sdk. Looking forward to seeing what people build and keep up the great work.. also realize that this might incur unacceptable delay and if you've already evaluated this please close and my apologies\n. m3u8 is probably hls. is there an hls extractor?\n. (exoplayer definitely has one, as it was built by youtube to handle hls)\n. i think it uses exoplayer underneath which i dont think supports rtsp\nhttps://github.com/google/ExoPlayer/issues/55\n. ",
    "ManojJangra": "Please  suggest me, IMA ads  dependency  for new exo player.. ",
    "queenvictoria": "Duplicate of #107 \n. ",
    "iknow4": "Device is MEIZU-M578C,and android version is 5.1\nwhat is your suggestion about this question?\n. ",
    "kamol0001tk": "Fixing \n. ",
    "TylerMcCraw": "That's great!\nThe model of the phone is:\nVerizon HTC One M9 LTE\nHTC6535LVW\nLet me know if you need anything else.\n. I tried checking for logs, but, unfortunately, no logs are printed when I click on the settings icon button which shows the Configure dialog.\nI did notice that when I press the back button after this dialog is already displayed, there are two logs. They may not be helpful though.\n08-25 09:21:11.344 29476-29476/com.smashingboxes.threesixtyvideoplayerdemo W/InputEventReceiver: Attempted to finish an input event but the input event receiver has already been disposed.\n08-25 09:21:11.344 29476-29476/com.smashingboxes.threesixtyvideoplayerdemo E/ViewRootImpl: sendUserActionEvent() mView == null\n. Actually, I just realized that I completely told you the wrong device before.\nI have so many test devices on my desk right now that I think I just got confused about which one had the issue between the time that I saw the issue and when I actually reported it.\nSorry about leading you on a wild goose chase \ud83d\ude2c \nCould you try reproducing on a Samsung Galaxy S5?\nModel is: SAMSUNG-SM-G900A\nThe issue is definitely on this device.\n. ",
    "ponychen": "I'm getting the same issue on Samsung Galaxy Note 8.0 (GT-N5110) running Android 4.4.2.. ",
    "palfu": "Any format supported, using GvrAudioEngine and VrVideoVidew at the same time? Mono\u3001stereo or ambi?\n. ",
    "fengqingyun2008": "I have do this,\n            videoOptions.inputFormat = intent.getIntExtra(\"inputFormat\", Options.FORMAT_HLS);\n            videoOptions.inputType = intent.getIntExtra(\"inputType\", Options.FORMAT_DEFAULT);\n        fileUri = Uri.parse(\"http://192.168.1.100:8080/hls/test.m3u8\");\n        backgroundVideoLoaderTask.execute(Pair.create(fileUri, videoOptions));\nbut demo also conn't play m3u8 stream.\n. ",
    "leonardokidd": "Thanks for your reply. I'm trying to build a low latency live streaming and the latency of hls is more than 10s. Because it uses exoplayer, do you think http-flv may satisfy the requirements? Any advices? Thanks again.\n. ",
    "Hamabama": "Found it. Here is explained how to get the actual app running. https://developers.google.com/vr/android/ndk/get-started\n. ",
    "bk138": "Found out this was a bug on our side, as a timer did some interaction with a (hardware-accelerated) WebView while the VrWidget was showing. Thus closing. Sry for the noise.\n. ",
    "aboutqx": "Can there be an api like this?\n. ",
    "mtl3jx": "Also having this issue... following.... ",
    "ryannichols": "Not in VR, but the question was for Pano, where you might have something that's easy to see in full VR, yet is difficult and small in pano mode (especially in portrait). We've seen this behavior quite a bit in pano and been asked for it often by users.\n. ",
    "mudin3i": "Did you find any solution?. ",
    "follower": "FYI I'm not going to sign the CLA for this change.\n. FYI I'm not going to sign the CLA for this change.\n. FYI I'm not going to sign the CLA for this change.\n. ",
    "Zoriak22": "related to unity.\n. ",
    "s1mar": "Update: After removing the realm io plugin,it works,but my whole database and content provider implementation is based on realm,please come up with a fix as soon as possible !!!\n. I added this to my app gradle build file:\nFirst this,ndk { abiFilters \"armeabi-v7a\" } and the app started running on my device which is a one plus 2 but still refused to run on my other test device,which is a Sony M4 pro Aqua.\nSo,then I added packagingOptions { exclude \"lib/arm64-v8a/librealm-jni.so\" }\nto my build.gradle file,the app still runs fine on my phone but on the other device it gives weird erros like unable to locate the global application code file and what not.\nNow,the one plus 2 has a combination of A57 and A53 cores whereas the other uses 4 A53 cores, but both use the same armv8 instruction set,so I am confused now what's causing it to run on some devices and not on others\n. I'll try the latest sdk v1.0.0 and let you know\n. ",
    "kneth": "@s1mar @sigmaxipi I have written a minimal app and cannot reproduce it: https://github.com/realm/realm-java/issues/3441\n. ",
    "acrive82": "Also, remeber to set proguard rules\n```\nDon't obfuscate any NDK/SDK code. This makes the debugging of stack traces in\nin release builds easier.\n-keepnames class com.google.vr.ndk. { *; }\n-keepnames class com.google.vr.sdk. { *; }\nThese are part of the SDK <-> VrCore interfaces for GVR.\n-keepnames class com.google.vr.vrcore.library.api.* { ; }\nThese are part of the Java <-> native interfaces for GVR.\n-keep class com.google.vr.** { native ; }\n-keep class com.google.vr.cardboard.annotations.UsedByNative\n-keep @com.google.vr.cardboard.annotations.UsedByNative class \n-keepclassmembers class * {\n    @com.google.vr.cardboard.annotations.UsedByNative ;\n}\n-keep class com.google.vr.cardboard.UsedByNative\n-keep @com.google.vr.cardboard.UsedByNative class \n-keepclassmembers class * {\n    @com.google.vr.cardboard.UsedByNative ;\n}\n```\n. Solved\nThe solution is: Set proguard to do not obfuscate the code! (Cut'n'paste from sample project...)\n. ",
    "myflashlab": "You were right! Thanks. The look of the method mislead me, However, when the device orientation happens, the returning float[] numbers are always 0.0 and 0.0. I wonder if you have faced a similar problem also? (When in fullscreen mode, it always returns with correct values)\n. ",
    "Ornolfr": "@sigmaxipi It seems that this method now returns void. And by invoking it with different float values nothing changes. Any info how could rotation angles be get/set?. #191 I can see that's issue is closed with promise that method setHeadRotation() would be created in September, 2016 revisions.. @sigmaxipi Imagine a device in VR hub standing in public. Everybody could use it, rotate and leave it with that angle. When the content updates it becomes recentered again, but there is wrong angle from that moment. That's why I need to set the angles. By the way, my use case seems to need to set the angles when the video is loaded, not at runtime. For instance, VrVideoView.Options could have two additional float fields pitch and yaw, and the VrVideoView#loadVideo() method could rely on these values.. @sigmaxipi using head tracking only. I said that users could rotate the device to look at the video in different angles. And I need to set the starting pitch and yaw angles when the video is loaded only.. ",
    "Eulerianial": "But I just cloned the git repository and it was enableVR used in that.\nCan we update the Git repo as it doesn't align with instructions given here: https://developers.google.com/vr/android/get-started\n. After switching to SDK24, the APK gives error:\nadb shell pm install -r \"/data/local/tmp/com.google.vr.sdk.samples.treasurehunt\"\n    pkg: /data/local/tmp/com.google.vr.sdk.samples.treasurehunt\nFailure [INSTALL_FAILED_NO_MATCHING_ABIS]\n$ adb shell pm uninstall com.google.vr.sdk.samples.treasurehunt\nDELETE_FAILED_INTERNAL_ERROR\nError while Installing APK\n. ",
    "MrCsabaToth": "@Eulerianial could your resolve this? I'm experiencing the same thing. My phone is Lollipop 5.0 (API 21). I set target SDK everywhere to 24 wherever I could.. @sigmaxipi That really valuable input, could we add this into a README next to that particular sample? I can make a PR as well.. @jdduke I'm going with the \"stock\" OxygenOS Open Beta 20 (that's the latest) right now. And at this point I'm with the OnePlus's recovery, but back in the summer I was demoing DayDream for a bunch of people and I had it rooted, TWRP recovery and I used the two liner DayDream hack. (OP 3t after all is as powerful as a Pixel XL, with actually more memory. I know that the latency can be different but in my eyes the lower resolution is even an advantage regarding heat and speed, although it decreases quality). Anyways, the past of the device may have to do something with this. Since it was daydream hacked I had at least 4 OS updates. Right now I'm not rooted, but I haven't deleted any Android apps which were installed before for DayDream (I think it's one or two core apps from the App Store). Sorry about that.\n  . @sigmaxipi I'll possibly try to make that change, it could be a variation of the existing example if embraced. A lot of people are not DayDream compatible, so they can benefit from that.. ",
    "timonchev": "Its https://s3.eu-central-1.amazonaws.com/3dreal/stitch.mp4 In usual players file opened good. File from SYVR360 APP https://play.google.com/store/apps/details?id=com.mitong.syvr360&hl=ru\nWill try now and report! Tried 0.9.1 version.\n. with 1.0 same problem. Pls see report from exoplayer, can you fix it also? \nhttps://github.com/google/ExoPlayer/issues/1850\n. ",
    "SeLoRBIS": "Sorry for this issue, i read the new : samples-sdk-simplevideowidget project and now we have two libraries to add in the build.gradle : \ncompile 'com.google.android.exoplayer:exoplayer:r1.5.10'\ncompile 'com.google.protobuf.nano:protobuf-javanano:3.0.0-alpha-7'\nI try tomorrow to reproduce the first error with the S7\n. ",
    "yooseunghun": "@sigmaxipi \nI develop an application which has a display rendered by native C code thru JNI. So Now I use SurfaceView. What are the issues ? Can you let me know more details? Now I have already used VideoView(which is extended from SurfaceView) on my SurfaceView as well. But there is no issue about rotations, layout chagnes.\n. ",
    "genshenx": "@sigmaxipi \nI develop a player which show the picture by native method : ANativeWindow_lock() and ANativeWindow_unlockAndPost(), I know in VR mode the display latency has been cut down to less than 20ms,  So how can I make  my display latency to about 20ms? Can you give me some advices?\nOr I shoud use the other display methods? Thanks\n. ",
    "solomon2": "@nathanmartz    this feature not has yet \uff0c when you prepare to add?. ",
    "lecion": "@dav-cz thx a lot.. ",
    "SnowMusic": "ofcourse the phone can play the video.there had no problem when i use the demo on the android phone,but when i use \"videoWidgetView.loadVideo(Uri.parse(\"http://www.bandaoapp.com/bandao/uploads/media/20160719/Teaser.mp4\"), options);\",it failed and give me that error info.(my English is very poor,sorry)\n. and when i put the video res into asset file ,it prompts error ,too.\n. huawei hornor h60-l02\u53d1\u81ea\u7f51\u6613\u90ae\u7bb1\u5927\u5e08\n        On 10/10/2016 10:59, nathanmartz wrote:SnowMusic, thanks for the info. What phone are you using to get this error?\n\u2014You are receiving this because you authored the thread.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/googlevr/gvr-android-sdk\",\"title\":\"googlevr/gvr-android-sdk\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/googlevr/gvr-android-sdk\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@nathanmartz in #267: SnowMusic, thanks for the info. What phone are you using to get this error?\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/googlevr/gvr-android-sdk/issues/267#issuecomment-252531266\"}}}\n. \n        yes.\u53d1\u81ea\u7f51\u6613\u90ae\u7bb1\u5927\u5e08\n        On 12/12/2016 18:55, duckzq wrote:are you solve the problem?\n\n\u2014You are receiving this because you authored the thread.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/googlevr/gvr-android-sdk\",\"title\":\"googlevr/gvr-android-sdk\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/googlevr/gvr-android-sdk\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@duckzq in #267: are you solve the problem?\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/googlevr/gvr-android-sdk/issues/267#issuecomment-266398943\"}}}. android studio v2.2.3\njdk1.8\nmac os.\ngradle 2.14.0\n.  no.only this project. i can build other project with success..  videoWidgetView.setInfoButtonEnabled(false);. adb shell am start -a android.intent.action.VIEW -n com.google.vr.sdk.samples.simplevideowidget/.SimpleVrVideoActivity  -d \"http://vr.bandaoapp.com/2017%E5%B9%B4/%E4%B8%A4%E4%BC%9A/%E4%BA%BA%E5%A4%A7oss.mp4\"     i use this. it toast \"error loading video:null\",too. after now i try this on my device,mi-4c API21 ,it worked.but when i did this on my HM-NOTE API19,it faild.. ",
    "maudmcok": "hi you ll be post your error  Snow\n2016-10-10 1:33 GMT+00:00 SnowMusic notifications@github.com:\n\nand when i put the video res into asset file ,it prompts error ,too.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/267#issuecomment-252526591,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AG3GsFo-PExll3Rvt8MRRg9mW0VmOTVzks5qyZXvgaJpZM4KR9eF\n.\n\n\nMau.D mcok\n. ",
    "duckzq": "Is the problem solved?. ",
    "amalcev": "Yes, we've tried different formats and tools.\nAs for Handbrake tool, we have tried to encode videos using it and we have similar behavior like with congo.mp4 file (which comes with SDK sample).\nHowever it's also not perfect, please have a look on sample app with congo.mp4:\nhttps://cloud.noveogroup.com/index.php/s/KIedRQvTNogd9zS\n(test made on LG G3 Android 5)\nThis Handbrake-encoded files we have only one issue - video is grayed from time to time. \nWe've also tried to play all our test videos and congo.mp4 in default LG G3 video player, it plays all of them perfectly without such issues (not taking into account that default player doesn't support 360 videos and plays them as plain videos).\n. ",
    "fhcampbell": "Has this been solved?. ",
    "quarkcore": "@sigmaxipi might this be the reason for the follwing error, too?\nFAILURE: Build failed with an exception.\n- What went wrong:\n  Execution failed for task ':app:transformClassesWithInstantRunForDebug'.\n\ncom/google/android/exoplayer/util/ManifestFetcher$ManifestCallback\n- Try:\n  Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.\n\nBUILD FAILED\nTotal time: 30.733 secs\n. ",
    "gpx1000": "That would be nice, might I also recommend at least publishing a maven public repo?  Naturally, it would make things even easier on both the java and ndk side to be able to simply do this for any new project:\nrepositories {\nmaven { url 'https://someurl/public' }\n}\ndependencies {\ncompile (name: 'daydream', ext: 'aar')\n}\nOr something similar to that.  However, it leaves open one hole, which is how to tell cmake / ndkbuild how to link against a so file hanging out in the aar.  Not sure what the easiest way to solve that part of the problem.\n. Might I suggest in the next SDK release update the extractNdk task to be incremental thus if the libs don't exist it will automatically run just as if there's a new download of the aar it will also correctly run automatically to refresh those libs.. @sigmaxipi If I might be so bold as to make a quick suggestion:\nTry this:\ntasks.whenTaskAdded { task ->\n    if (task.name == 'assemble') {\n        task.dependsOn extractNdk\n    }\n}\nThe command line gradlew build actually builds all tasks where as Android Studio will run a version of Assemble to help reduce the amount of time spent building tasks that aren't needed.\nLocally, I have gotten the above suggestion to work well for me.\nYou might also look into migrating to cmake and the stable plugin rather than the experimental.\n. Happy to help.  And you're right, the name should never equal assemble.  This is what happens when I suggest code off the top of my head; small bugs.. Completely understood on the no official support yet.  Wanted to share a suggestion for how one could setup a build that almost completely doesn't need to download anything out of git in order to get setup.\nI would point out to any that are trying similar things, exploded-aar directory generation depends upon the version of Android Studio and gradle being used (AS 2.3 Canary 3 doesn't seem to create that folder) as does the order of operations in that folder's generation vs the ndk build.\nI would request that the header files get added to the aar files.  In my ideal world, the only time I'd use the git repo is to research the sample projects.. FWIW, I would expect you could do all of your rendering in a Vulkan system then copy the final image to the gl texture that is passed back to Daydream.  That final copy would be slow, but it \"should\" work until we get Google to give us Vulkan Daydream SDK support.. I'd expect it to be possible.  It's kind of a fool's errand as doing so will really negate nearly every reason I can think of for going to the effort of using Vulkan in the first place.  The thing that's missing right now is an ability to do some form of synchronization between the two, at least in the version of Vulkan that is supported on most devices.  (Don't forget that the new Vulkan standard that was announced just prior to GDC is the one where it first got the synchronization extensions; it'll take time to get everywhere).\nNvidia devices are an exception as they do have the updated semaphore in the new khronos Vulkan extension supported.  Plus NVidia does have the ability to share contexts between GL and Vulkan, but that's really the exception to the rule; and even that has several issues.\nQualcomm and Google are really pushing multiview for optimization in VR; which I agree is a better path right now, as most apps are going to benefit the most from optimizing GLES and reducing draw calls than they will from allowing lower level work.  It's my expectation that it might be a while before that extension makes it to all mobile VR platforms; which is really the only thing that's holding Vulkan back from being an option for modules inside apps.  However, Vulkan might not even be the best path forward for VR when all is said and done; but I am excited by the possibilities and look forward to porting my Vulkan game engine over to VR.\nThat said, for want of a synchronization system you really have to be mindful of what state is happening on the graphics card and manage it so that when one engine is drawing the other is not.  Graphics hardware don't have any synchronization and they'll do exactly what you tell them to do as infuriating as their obedience to written code might be.\nIn any case the approach to take if you want to try this, is a wholly separate render pipeline where one render pipeline renders to a texture that the other uses as a pre-rendered texture.  This is possible in both languages and provides a way to get memory off the graphics card that both languages understand thus it's your communication point.\nPlease note that the end result is really not going to be very fast as you would have to have one engine render the scene and then the other take over.  It'd be an interesting toy, but I certainly would avoid putting it in a professional product if I had the option.. I just finished implementing an arm model.  I took heavily from the implementation that is in Unreal daydream sdk.\nIf you look at UpdateFromTorso and UpdatefromController functions in their Unreal or Unity SDK's you'll see how they're doing it.  It's actually a really simple system that uses the two known quaternions (head view direction and controller direction) and assumes positions exactly as you'd expect (rotate + translate).. I'm working on a tutorial series that uses both GearVR and Daydream to control a drone from a VR app.  I just covered how to do the arm model.  http://www.gpxblog.com/2017/04/build-custom-arm-model-for-vr.html  It is originally taken from the same Unreal C++ code as above.  I extrapolated it a bit and made it also work for the GearVR controller.  Enjoy.. It should be a fairly easy process to rewrite the entire thing in Java.  you need to know the current orientation of the controller and the current angular acceleration.  Technically you don't really need the accel, but that makes the resulting arm model not natural in the way it moves.\nThere are a few problems with this method, it doesn't completely work for all positions of your arm for one. If you need highly accurate tracking, I'd look for adding in other solutions to get 6DOF.  Qualcomm's VR has Leap inbuilt for such capabilities.  I've also had success putting tango phones in hands, as well as Vive tracking.  For most usecases however, this process should work pretty well.. Maybe a better thought so not every full rebuild would require getting the zip files would be to craft a way to only require the task reupdate itself when the md5 sum has changed something like this:\n1.) place manifest showing md5sum for ndk libs as an artifact in your maven.\n2.) modify the extractNDK task to have one extra line inside the blank closure:\ntask extractNDK {\noutputs.upToDateWhen { \n//compare md5 of local file against one listed in manifest artifact; exercise left for reader.\n}\n}\nIt's slightly more work but it would make it so there's no extra unzipping necessary and would model correctly when the outputs are indeed out of date.  It shouldn't really matter for most projects, and honestly this is much easier to do with a plugin to intellij to properly handle the ndk libs inside aars.  But the missing piece is having a MD5 manifest artifact to compare against.. I was considering writing a plugin as I have other projects that face the similar problem of ndk libs inside aar files.  If I do that, I'll open source it and you're welcome to use it.\nFor now, I'll see if I can come up with some simple gradle to do what I'm talking about sometime tonight or this weekend.  There's many small things that I wish gradle would do out of the box.\nAre you in need of any snippets to do the first part? (add md5sum manifest to an artifact that maven can publish) or are you good there?. Please see pull request #361. I signed it!. I signed it!. Thanks for the clarifications.\nIt would seem problematic that the GLDriver is saying an extension is supported and yet it really shouldn't be used; as if it's not supported, the driver shouldn't advertise it in the first place.  Thus, I'm a bit surprised by the desire to blacklist the GL feature on certain devices.  However, will accommodate and on Daydream devices have the code run the check. \nThe other two responses align with my expectations, Thanks again!. ",
    "v14gh": "Hi @jdduke,\nThank you very much for the information and the API modifications, we are looking forward to the changes in the next release!\n. ",
    "mkeblx": "Great, thanks. Looking forward to next release.\n. ",
    "dekemega": "is there any change on this topic .. . Hi ,\nme too i wanna add hotspots to make the navigation between scenes easier ... please add hotspot support. ",
    "radvani": "In addition, it's unclear in the documentation what IsSoundPlaying is supposed to return if a sound is paused. Is a paused sound playing? Or does IsSoundPlaying only refer to whether an AudioSourceId is valid? We need a way to differentiate the three sound states: paused, playing, and invalid.\n. ",
    "jbrown101st": "Simple mistake on my part. I was able to get it working by specifying the activity as the action inside the intent filter (previously had android.intent.action.Main). Just a heads up for anyone with a similar issue.\n<intent-filter>\n<action android:name=\"activities.PlaybackActivity\" />\n<category android:name=\"com.google.intent.category.DAYDREAM\" />\n<category android:name=\"com.google.intent.category.CARDBOARD\" />\n</intent-filter>\n. ",
    "jakemharris": "I'm having the same issue. I have an augmented reality application and I'm using cardboard for head tracking to only show my AR when looking a certain direction and then just load camera view. For some reason, only with pixel phones, it wont launch this activity without paring daydream. IT works fine like pokemon go for all phones EXCEPT the pixel. I get \"This Cardboard application is not compatible with Daydream headsets\". I have updated the manifest to include:\ncategory android:name=\"com.google.intent.category.DAYDREAM\" />\ncategory android:name=\"com.google.intent.category.CARDBOARD\" />\nhowever, now it wants to pare a daydream headset and tries to force daydream when all I want to do  is show the camera view with my AR. Again, all other phones and devices work perfectly like pokemon go without any problems. Its just the Pixel phones :(. ",
    "gouletr": "@sigmaxipi Thanks for the reply. I'm confused a little, can you confirm if...\nI still need to link with those .so manually?\nhttps://github.com/googlevr/gvr-android-sdk/blob/master/ndk/lib/android_arm/libgvr.so\nhttps://github.com/googlevr/gvr-android-sdk/blob/master/ndk/lib/android_arm/libgvr_audio.so\nAnd what about this .aar file?\nhttps://github.com/googlevr/gvr-android-sdk/blob/master/ndk/lib/common_library.aar\ni.e. Do I need it along with the .aar files located under https://github.com/googlevr/gvr-android-sdk/tree/master/libraries, or they replace it, or are the same?. Also, forgot to mention, now when I unpack my packaged .apk app, I now see this in the /lib/armeabi-v7a folder:\nlibgvr.so\nlibgvr_audio.so\nlibgvrbase.so\nlibmain_android.so\nlibvraudio_engine.so\nis that correct, missing anything? I'm asking because now that we believe we link properly with those .aar files, we get an instant crash upon loading the app stating that it can't load libmain_android.so, which worked fine before we link with GVR.. @sigmaxipi ok thanks for clarifying, I was indeed importing files from the libraries folder. Now I only link with ndk/lib/android_arm/libgvr.so and ndk/lib/android_arm/libgvr_audio.so, and gradle is only including ndk/lib/common_libraries.aar.\nNow I verified the content of the .apk and I only see one folder under lib named armeabi-v7a, which now only contains libgvr.so, libgvr_audio.so and libmain_android.so.\nBut I still get the same crash, logcat only reporting:\nI art     : Late-enabling -Xcheck:jni\nW ActivityThread: Application com.autodesk.stingray is waiting for the debugger on port 8100...\nI System.out: Sending WAIT chunk\nI art     : Debugger is active\nI System.out: Debugger has connected\nI System.out: waiting for debugger to settle...\nI System.out: waiting for debugger to settle...\nI System.out: waiting for debugger to settle...\nI System.out: waiting for debugger to settle...\nI System.out: waiting for debugger to settle...\nI System.out: waiting for debugger to settle...\nI System.out: waiting for debugger to settle...\nI System.out: debugger has settled (1403)\nI art     : Background sticky concurrent mark sweep GC freed 3231(167KB) AllocSpace objects, 0(0B) LOS objects, 67% free, 414KB/1285KB, paused 16.352ms total 138.398ms\nI Stingray: [Activity] Starts Stingray with file server host\nD OpenGLRenderer: Use EGL_SWAP_BEHAVIOR_PRESERVED: true\nE AndroidRuntime: Caused by: java.lang.IllegalArgumentException: Unable to load native library: /data/app/com.autodesk.stingray-2/lib/arm/libmain_android.so\nD AndroidRuntime: Shutting down VM\nE AndroidRuntime: FATAL EXCEPTION: main\nE AndroidRuntime: Process: com.autodesk.stingray, PID: 11202\nE AndroidRuntime: java.lang.RuntimeException: Unable to start activity ComponentInfo{com.autodesk.stingray/com.autodesk.StingrayActivity}: java.lang.IllegalArgumentException: Unable to load native library: /data/app/com.autodesk.stingray-2/lib/arm/libmain_android.so\nE AndroidRuntime:   at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2458)\nE AndroidRuntime:   at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2518)\nE AndroidRuntime:   at android.app.ActivityThread.-wrap11(ActivityThread.java)\nE AndroidRuntime:   at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1345)\nE AndroidRuntime:   at android.os.Handler.dispatchMessage(Handler.java:104)\nE AndroidRuntime:   at android.os.Looper.loop(Looper.java:148)\nE AndroidRuntime:   at android.app.ActivityThread.main(ActivityThread.java:5460)\nE AndroidRuntime:   at java.lang.reflect.Method.invoke(Native Method)\nE AndroidRuntime:   at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)\nE AndroidRuntime:   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)\nE AndroidRuntime:   at android.app.NativeActivity.onCreate(NativeActivity.java:182)\nE AndroidRuntime:   at com.autodesk.StingrayActivity.onCreate(StingrayActivity.java:23)\nE AndroidRuntime:   at android.app.Activity.performCreate(Activity.java:6237)\nE AndroidRuntime:   at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1107)\nE AndroidRuntime:   at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2411)\nE AndroidRuntime:   ... 9 more. Ah I found the issue! Sorry for the noise, I'm still very new to Android development. I was just missing this in my Activity:\nstatic {\n    System.loadLibrary(\"gvr\");\n    System.loadLibrary(\"gvr_audio\");\n}\nThanks for all the help!. So that means if I do:\ngvrLayout.setPresentationView(new View());\nit won't work on cardboard-only devices? i.e. without async reprojection?. @windbagjacket I made it work on Google Pixel phones by doing:\ngvrLayout = new GvrLayout(this);\ngvrLayout.setAsyncReprojectionEnabled(true);\ngvrLayout.setPresentationView(new View(this));\n...as opposed to use a SurfaceView.\nHowever this won't work on devices that do not support async reprojection since as I understand the GVR SDK won't create a custom GL surface and you end up rendering at the wrong place.. @jdduke To continue on the topic, I tried to make it work by creating a SurfaceView instead of a View, and so far it isn't working for me. I looked into the sample you linked but our engine uses OS callbacks such as:\ncpp\nactivity->callbacks->onWindowFocusChanged = &aac::focus_changed;\nactivity->callbacks->onNativeWindowCreated = &aac::window_created;\nactivity->callbacks->onNativeWindowResized = &aac::window_resized;\nactivity->callbacks->onNativeWindowRedrawNeeded = &aac::window_redraw_needed;\nactivity->callbacks->onNativeWindowDestroyed = &aac::window_destroyed;\n...to get the native window pointer, while in the example you linked it gets the native window pointer from the SurfaceView.\nSo how does this mix with creating a SurfaceView if the window we get in these callbacks is not the window from the SurfaceView we created on the java side? Is there a way to tell Android to not create a new window and instead use our SurfaceView's window? Sorry if that sounds inaccurate, learning the ropes as I go... :). ",
    "esseak": "Hi @vadimneta \nI got same error when I start a new project. Then I try create a VrVideoView programmatically I get more error details,\"not found com.google.android.exoplayer\", so I add dependency compile 'com.google.android.exoplayer:exoplayer:r1.5.10' as same as google's vr sdk samples in my Build.gradle file and then VrVideoView show in my android phone.\nIt works for me.. ",
    "vadimneta": "Thank you very much ,\nIt did the trick!\nIt works!. ",
    "windbagjacket": "Hi. We're actually having the exact same problem as gouletr with Android - we use android_native_app_glue, create the EGL/GL context in native code and have an almost empty NativeActivity.\nI just wanted to clarify... are you saying it should work fine if in my java onCreate() I do:\ngvrLayout = new GvrLayout(this);\ngvrLayout.setAsyncReprojectionEnabled(true);\ngvrLayout.setPresentationView(new SurfaceView);\nAs long as I pass the gvrLayout to my native code and call gvr_initialize_gl?\nGreat SDK, just trying to get my head around these implementation details!\nA sample showing how to do this correctly would be fantastic.\nThanks.. Thanks @jdduke & @gouletr, I have it working doing the same thing now. \nAs an aside, I notice that doing this through NativeActivity also seems to bypass the usual \"Place your phone inside the headset\" screen and controller calibration that I was seeing on every launch when not using NativeActivity. Not much of an issue though - it's actually quite useful when iterating as having to calibrate at every re-run was getting cumbersome. The settings and quit buttons are also missing now. . ",
    "ian-wevr": "I'm porting an existing mostly-native Android app to Daydream that's landed on the SurfaceView approach mentioned by jdduke and with scanline racing. In general it works well (using 1.0.1) but there's often obvious short vertical white tears that can happen anywhere -- seems to be subtly timing related, perhaps, as it happens during more intensive portions of our application.\nThis shows up in the log output:\nI/GVR: [vr/gvr/render/scanline_racer.cc:420] Scanline racing enabled without context sharing\nI've had a hard time finding documentation that suggests what can cause this message and/or if this is related to the tearing issues. When I create the GL context, does it need to be shared with any particular existing GL context, or is it enough to create any GL context, make it current, and call gvr_initialize_gl()?\n. I, too, have this question -- I'm working with an engine that assembles and manages its own framebuffer objects, hence using a framebuffer object directly with this engine is impossible without some fairly deep modification. Right now I'm working around this by resolving into GVR's swapchain framebuffer with some hacked in GL calls, but it's a notable performance/heat hit. If I can't use my own textures, can I at least get a GL renderbuffer handle or GL texture handle like in other VR platforms?. @jdduke I can't speak for MortimerGoro, but as long as rendering to the surface is as fast as using gvr_frame_bind_buffer is (without the need to copy) and there's no other performance penalty, that would work well in my case.. We've also noticed that gvr_frame_submit() seems to change our GL state which causes our rendering problems if we don't force the states back to known values. Is this expected? Is there a specification of what GL states may change after gvr_frame_submit()?. Thanks, jdduke.\nAdding a little more info:\nThe white \"tear\" lines seem to be highly timing dependent. When we disable sustained performance mode their frequency is vastly reduced. When we have background activity (e.g. our app downloads in the background) they are more prevalent.. @Gousetis, my apologies for the delay in response. Yes, we are asynchronously reprojecting. We don't use a compute shader, have no separate render targets and only a forward pass, and don't use another GL context to render content -- only the context gvr_initialize_gl() is called in.\nHowever, we decode videos with hardware support, and we perform background downloading. When both of these occur at once, the speckling seems to occur frequently.\nI'll get you a logcat as soon as I can -- I'm not familiar with the \"enable developer logs\" and \"enable performance monitoring\" options and can't seem to find documentation -- where should I be looking for these or their documentation?. Aha, didn't realize Daydream had its own developer settings! Wish I knew about these earlier. :). Closing this for now -- despite getting this issue consistently for months, it seems to have disappeared on our side and we haven't been able to replicate it over the course of a week. There's a lot of moving pieces, some beyond our control, so I can't begin to fathom how this has resolved itself.\nThanks for the help/feedback! I'll reopen this issue should the problem return in a way we cannot resolve.. Thanks for your responses.\n@jdduke \n\nAndroid version/build are you using?\n\n7.1.2 / NJH47D\n\nIf you could capture a bug report or the logcat when you observe this issue, that would be helpful.\n\nI should be able to get to this tomorrow (8/31).\n@fredsa \n\nCan you compare what you're seeing with what you get when this Android setting is applied?\n\nI'll see if I can find a way to compare tomorrow (8/31) -- the problem is intermittent, so it's difficult to avoid false negatives.. ",
    "ssaroha": "@gouletr @jdduke I am trying to get the sample video application working on cardboard-only devices which do not support async reprojection.\nTo get this working I tried to modify the following piece of code in WatchVideoActivity.java\n```\nif (!isSurfaceEnabled || !isAsyncReprojectionEnabled) {\n      // The device does not support this API, video will not play.\n      Log.e(\n          TAG,\n          \"UnsupportedException: \"\n              + (!isAsyncReprojectionEnabled ? \"Async Reprojection not supported. \" : \"\")\n              + (!isSurfaceEnabled ? \"Async Reprojection Video Surface not enabled.\" : \"\"));\n```\n}\nto this:\n```\nif (!isSurfaceEnabled || !isAsyncReprojectionEnabled) {\n      // The device does not support this API, still go ahead with default surface.\ninitVideoPlayer();\n  // The ExternalSurface buffer the GvrApi should reference when drawing the video buffer. This\n  // must be called after enabling the Async Reprojection video surface.\n\n//      renderer.setVideoSurfaceId(gvrLayout.getAsyncReprojectionVideoSurfaceId());\n      // Simulate cardboard trigger to play/pause video playback.\n  gvrLayout.enableCardboardTriggerEmulation(triggerRunnable);\n\n  // The default value puts the viewport behind the eye, so it's invisible. Set the transform\n  // now to ensure the video is visible when rendering starts.\n  renderer.setVideoTransform(videoTransform);\n\n  surfaceView.setOnTouchListener(\n          new View.OnTouchListener() {\n            @Override\n            public boolean onTouch(View view, MotionEvent event) {\n              if (event.getActionMasked() == MotionEvent.ACTION_DOWN) {\n                triggerRunnable.run();\n                return true;\n              }\n              return false;\n            }\n          });\n\n```\neffectively I just commented out the setVideoSurfaceId, to avoid using the AsyncReprojectionVideo Surface.\nCompiling and running this modified sample on cardboard-only device just shows the stereoscopic 2 eye view but no video frame in there. \nWhat should I be setting for the surfaceId when there is no AsyncReprojection video surface?\nAnything else I should be modifying to get video frame to show in cardboard only devices.\nthanks\nsatender\n. Thanks @jdduke. I took a stab at removing references to video surface api for async reprojection in the sample example file WatchVideoActivity.java\nHere is the diff: https://github.com/ssaroha/gvr-android-sdk/commit/0712f03b04b44ec55ff4d9c4fe08214327b964af \nI am still a newbie in OpenGL and need a little help  to figure out how to draw the surface quad in the scene.\nI am extending the VideoSceneRenderer whereby it implements SurfaceTexture.OnFrameAvailableListener. In the OnSurfaceCreated method of VideoSceneRenderer class I created the SurfaceTexture object, and the corresponding surface object.\nmSurface = new SurfaceTexture(); // I still need to figure out how to give it one of the existing GL textures\nmSurface.setOnFrameAvailableListener(this);\nSurface surface = new Surface(mSurface);\nMy goal was that this surface can then be used video scene.  In the videoscene class there is updateViewport method implementation which calls BufferViewPort.setExternalSurfaceId here: https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-videoplayer/src/main/java/com/google/vr/sdk/samples/videoplayer/VideoScene.java#L90\nI am wondering how to provide this new surface to BufferViewPort(s), as there doesn't see to be any setSurface method on BufferViewPort.\nAm I on the right track or is there a better way to modify the sample program while still able to use the videoHoleProgram and spriteProgram.\nappreciate your help!\n. ",
    "weicui1": "Hi, I was using VrPanoramaView. And just wonder if it can be used as some normal 360 imageviewer widget in android apps. For example, being set some initial viewpoint and user can only adjust viewpoint via touch and drag on picture. thanks. ",
    "sharukhmohammed": "I have the same issue, I have a Fragment with VrPanoramaView as a background. Screen flashes and it's either black or white (Black for onResume or redrawing & White for \nBitmap bitmap = Bitmap.createBitmap(containerView.getWidth(),containerView.getHeight(),\nBitmap.Config.ARGB_8888);\n        Canvas c = new Canvas(bitmap);\n        containerView.draw(c);\n. ",
    "Borys637": "Hello! I did not expect that someone is interested in my problem ...)\nThe solution to my problem came after many trials and tests of similar phones firmware.\nThe problem is in the phone Lenovo Vibe Z2 Pro (K920). The phone is registered in the data error screen resolution. Screen resolution 1440 * 2560 DPI. The pixel density - 490 DPI. xdpi / ydpi - 160/160. It is not right! Therefore, when I first start the program, I honestly pointed cardboard 490 DPI. Adjust the screen was correct, but after reading Qr code I see two tiny screen ..... and should be something that I set up. Then again, I installed the program and introduced a 160 DPI. Now everything has turned out well. When setting up or after setting up the same screen.\nIf I try to contact the technical support for Lenovo, then this phone is already out of production and I probably no help (((...\nMy friend  had the same problem with the phone Zte z7max 5,5 fhd.  xdpi / ydpi - 403/160. It is impossible to create a Qr code.\nIn principle, such a lot of options and I think, that may Cardboard program developers should review the algorithm coding .....\n. I do not quite understand the last - \"I'll see if we can add these devices\nto our DPI override whitelist.\"\n2016-12-15 20:24 GMT+02:00 Jared Duke notifications@github.com:\n\nYeah, there are a number of devices that misreport their DPI, which can\nresult in incorrect rendering at runtime. Sometimes it's only slightly off,\nbut other devices actually override the native display resolution, while\nstill reporting the native DPI.\nI'll see if we can add these devices to our DPI override whitelist.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/305#issuecomment-267402459,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AXTtrpmhTmdHhSeeKF7Hz5uffgv-m9Yyks5rIYXpgaJpZM4LHt0-\n.\n. So, the problem is solved with a DPI. https://forum.xda-developers.com/k920\n  .... and everything was working as it is necessary!\nhttps://forum.xda-developers.com/k920/development/rom-cyanogenmod-14-1-t3488879\n.\n\n2017-01-14 0:50 GMT+02:00 Jared Duke notifications@github.com:\n\nThere are a number of devices which misreport their DPI, and we have an\ninternal whitelist we use to \"fix\" the DPI.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/305#issuecomment-272569435,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AXTtrllgEg9EX90oSWp927S4ac2IqdmWks5rR_-rgaJpZM4LHt0-\n.\n. \n",
    "mattscar": "I tried to extract the libraries, but I got an error:\njava.lang.UnsupportedClassVersionError: com/android/build/gradle/model/AppComponentModelPlugin : Unsupported major.minor version 52.0\nFrom what I've read online, this means my SDK or NDK isn't current enough. But I've updated both of them as best I can using SDK Manager.\nI also tried opening the SDK in Android Studio, and it gave me the following error:\nInvalid file: file://.../gvr-android-sdk/libraries/base/build.gradle\nIt's looking for the build.gradle file in the old libraries/base directory. But that's gone.\n. Sure enough, that did it. Sorry for the bother.. Hi,\nYes, I have a Daydream headset and controller. After inserting the phone into the headset and completing the controller calibration, the window returns to the \"Insert device into headset\" screen. It repeats this loop (calibration and insert device) repeatedly.\nThis problem started after I updated the Google VR Services on my Google Pixel. I copied the LogCat output to a text file and removed every line not containing \"vr\" or \"controller\".\nThanks,\nMatt\nlogcat_vr.txt\n. I cleared the data/cache for Google VR Services and ran the sample from the Android launcher, I got the same looping problem as before.\nBut when I ran the sample from inside the Daydream environment, it worked fine.. Yes, I encounter the same problem with the TreasureHunt sample.\nI've found a way to fix the problem. In the project's manifest, the android:theme attribute is set to \"@style/VrActivityTheme\". When I remove the attribute from , the app works fine.\nThe project's res folder doesn't contain any style resources. Is \"VrActivityTheme\" supposed to be provided by the Google VR Service?. Judging from the module's build.gradle file, it looks like the only AAR included in the build is the base library:\ndependencies {\n    compile 'com.google.vr:sdk-base:1.10.0'\n}. No it doesn't. I wondered how the project could compile without a definition for @style/VrActivityTheme. I did some searching, and base.aar has its own definition that's exactly the same as the one in common.aar. Here's what it looks like:\n<style name=\"VrActivityTheme\" parent=\"@android:style/Theme.Black.NoTitleBar\">\n<item name=\"android:windowFullscreen\">true</item>\n<item name=\"android:windowAnimationStyle\">@null</item>\n<item name=\"android:windowActionBar\">false</item>\n<item name=\"android:windowDisablePreview\">true</item>\n<item name=\"android:windowContentOverlay\">@null</item>\n</style>\nI think one of these items is preventing the app from running properly (at least on my system). I'll do some tests and report back.. The app worked fine after I removed the android:windowDisablePreview item. That is, I removed the following line from the VrActivityTheme definition:\n<item name=\"android:windowDisablePreview\">true</item>. I'm using a stock Google Pixel running Android 7.1.1. Build number NMF260.\nI did have the \"Don't keep activities\" setting enabled. After I disabled that, my issues went away. \nI guess everything's cleared up. Sorry for all the bother.\n. Never mind. I was using an old libgvro.so library.. ",
    "ogoguel": "Thanks for your feedback : looking forward for the next version.\nI've finally fixed it by re-creating the whole activity every time I want to play a movie, but I'll have a look at removing the VrVideoView. Great. BTW why don't you open source the full sdk ? It would help the community helping you :)\nKeep up the good work anyway.. ",
    "dthian": "Just a quick follow up - are the controller assets available yet for the Android SDK? I've been looking around through the Android documentation but can't seem to find one. If not, is there a rough time frame date of when they would be made available? And finally, would they be available in Obj formats as well? Thanks!. I've been looking at unity's version at [1]. However, it seems like unity is performing the calculations based on a left-handed coordinate system. Is there a right-handed version of this? If not, what would be the proper way to translate this into a right handed system? Thanks!\n[1] - https://github.com/googlevr/gvr-unity-sdk/blob/master/GoogleVR/Scripts/Controller/GvrArmModel.cs . update: I've found Unreal's GVR model at [1]. And will be giving that a shot as well. This class seems to be following the same coordinate space as the GVR SDK, so that may be a win for right-handed versions.\n[1] - https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Plugins/Runtime/GoogleVR/GoogleVRController/Source/GoogleVRController/Private/ArmModel/gvr_arm_model.cpp. Awesome, thanks! . ",
    "rajkumarbhaji": "Dear All, \nI am also facing same issue.  I am using following gradle settings\n    dependencies {\n        classpath \"com.android.tools.build:gradle-experimental:0.8.3\"\n    // NOTE: Do not place your application dependencies here; they belong\n    // in the individual module build.gradle files\n}\n\n\n        toolchain = \"gcc\"\n        toolchainVersion = \"4.9\"\n        moduleName = \"bagbash_jni\"\n        stl = \"c++_static\"\n        cppFlags.add(\"-std=c++11\")\n        cppFlags.add(\"-fexceptions\")\n        cppFlags.add(\"-frtti\")\n        cppFlags.add(\"-Wall\")\n        cppFlags.add(\"-Wextra\")\n\nI am getting following exception and the application is crashing. But it is working fine in older android versions. I am trying to run in Samsung S5 Android version 6.0+\n04-26 21:44:40.832 7842-7842/? E/AndroidRuntime: FATAL EXCEPTION: main\n                                                 Process: com.bagbash.bagbash, PID: 7842\n                                                 java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol \"__aeabi_atexit\" referenced by \"/data/app/com.bagbash.bagbash-2/lib/arm/libbagbash_jni.so\"...\n                                                     at java.lang.Runtime.loadLibrary(Runtime.java:372)\n                                                     at java.lang.System.loadLibrary(System.java:1076)\n                                                     at com.bagbash.android.bb_app.android.BagBashApplication.(BagBashApplication.java:38)\n                                                     at java.lang.Class.newInstance(Native Method)\n                                                     at android.app.Instrumentation.newApplication(Instrumentation.java:1019)\n                                                     at android.app.Instrumentation.newApplication(Instrumentation.java:1004)\n                                                     at android.app.LoadedApk.makeApplication(LoadedApk.java:666)\n                                                     at android.app.ActivityThread.handleBindApplication(ActivityThread.java:6290)\n                                                     at android.app.ActivityThread.access$1800(ActivityThread.java:221)\n                                                     at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1860)\n                                                     at android.os.Handler.dispatchMessage(Handler.java:102)\n                                                     at android.os.Looper.loop(Looper.java:158)\n                                                     at android.app.ActivityThread.main(ActivityThread.java:7225)\n                                                     at java.lang.reflect.Method.invoke(Native Method)\n                                                     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1230)\n                                                     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1120)\nThank you in advance.. ",
    "AdamNowaczyk": "Ok, I think this is something wrong with my setup. I can run the app, but Intellij IDEA is reporting issues as it cannot find the VrWidgetView.... ",
    "achuvm": "Hi @jdduke this is for an app we hope will support both. Thanks,. Hi, is there any update on this issue?. Hi @jdduke, the issue is that GvrLayout (from the NDK) doesn't have a setStereoModeEnabled() method which we can call.\nThe SDK uses the GvrView which does have a setStereoModeEnabled() method, but we're using the NDK rather than the SDK.. Ahh, found it. We were using the 1.02.0 version of the SDK which didnt have it. Upgraded to the 1.10.0 version of the SDK and I see it now. Thanks!. Hi @jdduke \nWe just ran into this issue today with our product (our S7 just got its Nougat update).\nIs there an ETA as to when that change to the Google VR Service will go out?\nThanks,. Hi Kesef, you need to open the Play Store, find the Google VR Services app and install it.\n\n. Hi Jared,\nThanks! That fixed it for us, the phone was set to 1080p (vs the native 1440p).. Hi @jdduke,\nAhh that works! Thanks!. ",
    "hannesa2": "I signed it!\nI add this email to my google account , where I agreed to CLA.. Hava a look to https://stackoverflow.com/questions/44230509/cant-build-an-official-example-from-google/44340736#44340736 Here you see the workaround. I made it work out of the box https://github.com/googlevr/gvr-android-sdk/pull/602. Btw, after I fixed it locally this issue is still open\n\n. Your logic https://github.com/googlevr/gvr-android-sdk/blob/ffda940638229c1a960e90326275f7c2a029fe1c/settings.gradle#L24 doesn't work anymore. Here https://github.com/googlevr/gvr-android-sdk/pull/602 you see the solution . ",
    "jschm1": "Hi Sigmaxipi, thanks for your reply.\nI might be including a wrong Gradle dependency for ExoPlayer V2. It has the same group id and artifact id as for version 1 (only the version differs):\ncompile 'com.google.android.exoplayer:exoplayer:r2.0.4'\n\nVrVideoView uses this version in it's POM file:\ncom.google.android.exoplayer:exoplayer:r1.5.10\n\nIf I include both, Gradle will simply pick the latest version 2.0.4.\nIs there another v2 specific Gradle dependency for ExoPlayer version 2?\nWhen I look under app/build/intermediates/exploded-aar/com.google.android.exoplayer/exoplayer/\nthere's only one subfolder with \"r2.0.4/jars\". In this folder, there's a classes.jar with ExoPlayer 2 in it (com.google.android.exoplayer2.*)\nI guess it comes down to the Gradle problem I mentioned above, with identical group ids and artifact ids for V1 and v2?. Alright, thanks for heads up!. ",
    "AlvaroFalcon": "Did you solve this?. Any solution to this?. ",
    "zilet": "Want to revisit this one. Is the license the same for the parts of the library that are closed source?. ",
    "drksnw": "Hello !\nSorry for my late answer, but I was on holiday...\nSo I'm using the GVR 1.10.0, and I just tested on my work phone, which is running Android 6.0.1, and the application won't work either.\nHere's the bug report:\nbug.txt\nYou can take a look at my repo to see if I'm missing something important...\nYou'll need a Config.java file, which looks like this:\njava\npublic class Config {\n    private static final String STREET_VIEW_API_KEY = \"<your-streetview-image-api-key>\";\n    public static final String STREET_VIEW_BASE_URL = \"https://maps.googleapis.com/maps/api/streetview?size=512x512&key=\"+STREET_VIEW_API_KEY;\n    public static final String STREET_VIEW_METADATA_URL = \"https://maps.googleapis.com/maps/api/streetview/metadata?key=\"+STREET_VIEW_API_KEY+\"&pano=\";\n    public static final String STREET_VIEW_CBK_URL = \"http://cbk0.google.com/cbk?output=json&hl=x-local&ll=\";\n}\nThank you very much for your help !\nEDIT: As a workaround, I rolled back the GVR SDK to version 0.9.1, and it works with this version.\nEDIT 2: \nI tried on my Nexus 5X with the version 0.9.1 again, this time I get this error message\nAndroidNCompat: Failed to set VR mode: java.lang.UnsupportedOperationException: VR mode not supported on this device!\nHere's the bug.zip\n. Hi @jdduke, I just tried to remove all VR mode references, and installed the GVR SDK 1.10.0, but this time I get that exception (which is not thrown on GVR SDK 0.9.1): android.view.InflateException: Binary XML file line #9: Binary XML file line #9: Error inflating class com.google.vr.sdk.base.GvrView\nEDIT: I have this warning too W/System: ClassLoader referenced unknown path: /system/framework/tcmclient.jar so I checked with adb shell, and the file is missing. Is that anything to do with my problem ?. Ok, thank you it worked !\nBut now, I don't have any errors left, but the screen is still white (Instead of the Please put your phone in the cardboard screen).\nSo now, I don't have any idea from where the problem might be coming.... Ok I've found what wasn't working on my app...\nI've got a loop which blocked the main thread, but I have no idea why it worked on Android 6.0.1 and not on Android 7.1.1...\nThank you very much for your help !. ",
    "411Productions": "Unsubscribe\nMichael Zyda, Director\nUSC GamePipe Laboratory\n746 West Adams, EGG Building\nLos Angeles, CA 90089-7725\nZyda@usc.eduZyda@usc.edu\n310-463-5774\n310-496-0557 Fax\nOn Jan 4, 2017, at 2:36 PM, Jared Duke notifications@github.com<mailto:notifications@github.com> wrote:\nIf you add:\ncompile 'com.google.vr:sdk-common1.10.0'\nto the dependencies, does that resolve the problem?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHubhttps://github.com/googlevr/gvr-android-sdk/issues/326#issuecomment-270507353, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AONNx1EwsKU3uDGuYGx62LIIs_FFvXHqks5rPB7ngaJpZM4LVUuA.\n. ",
    "AlanChauchet": "Yup I tried that. Unfortunately whith this option I now have this error =>\n01-05 14:33:52.153 26883-26898/com.google.vr.sdk.samples.simplevideowidget E/ExoPlayerImplInternal: Internal track renderer error.\n                                                                                                    com.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc, -1, 501486, 4096, 2304, 0, 1.0, -1, -1, null, 198200000, false, -1, -1, -1, -1, -1)\n                                                                                                        at com.google.android.exoplayer.MediaCodecTrackRenderer.notifyAndThrowDecoderInitError(MediaCodecTrackRenderer.java:427)\n                                                                                                        at com.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:413)\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.setSurface(MediaCodecVideoTrackRenderer.java:314)\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.handleMessage(MediaCodecVideoTrackRenderer.java:295)\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.sendMessageInternal(ExoPlayerImplInternal.java:587)\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:227)\n                                                                                                        at android.os.Handler.dispatchMessage(Handler.java:107)\n                                                                                                        at android.os.Looper.loop(Looper.java:207)\n                                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)\n                                                                                                        at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\n                                                                                                     Caused by: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(1, video/avc, -1, 501486, 4096, 2304, 0, 1.0, -1, -1, null, 198200000, false, -1, -1, -1, -1, -1)\n                                                                                                        at com.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:413)\u00a0\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.setSurface(MediaCodecVideoTrackRenderer.java:314)\u00a0\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.handleMessage(MediaCodecVideoTrackRenderer.java:295)\u00a0\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.sendMessageInternal(ExoPlayerImplInternal.java:587)\u00a0\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:227)\u00a0\n                                                                                                        at android.os.Handler.dispatchMessage(Handler.java:107)\u00a0\n                                                                                                        at android.os.Looper.loop(Looper.java:207)\u00a0\n                                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)\u00a0\n                                                                                                        at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40)\u00a0\n                                                                                                     Caused by: android.media.MediaCodec$CodecException: Error 0x80001001\n                                                                                                        at android.media.MediaCodec.native_configure(Native Method)\n                                                                                                        at android.media.MediaCodec.configure(MediaCodec.java:1791)\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.configureCodec(MediaCodecVideoTrackRenderer.java:328)\n                                                                                                        at com.google.android.exoplayer.MediaCodecTrackRenderer.maybeInitCodec(MediaCodecTrackRenderer.java:402)\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.setSurface(MediaCodecVideoTrackRenderer.java:314)\u00a0\n                                                                                                        at com.google.android.exoplayer.MediaCodecVideoTrackRenderer.handleMessage(MediaCodecVideoTrackRenderer.java:295)\u00a0\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.sendMessageInternal(ExoPlayerImplInternal.java:587)\u00a0\n                                                                                                        at com.google.android.exoplayer.ExoPlayerImplInternal.handleMessage(ExoPlayerImplInternal.java:227)\u00a0\n                                                                                                        at android.os.Handler.dispatchMessage(Handler.java:107)\u00a0\n                                                                                                        at android.os.Looper.loop(Looper.java:207)\u00a0\n                                                                                                        at android.os.HandlerThread.run(HandlerThread.java:61)\u00a0\n                                                                                                        at com.google.android.exoplayer.util.PriorityHandlerThread.run(PriorityHandlerThread.java:40). Thanks for your response. I'll try that asap and get back to you right after.  Alright so whatever I try with my video (direct ExoPlayer player or HLS input) I get the following error:\nExoPlayerImplInternal: Internal track renderer error.\n                                                                                                    com.google.android.exoplayer.ExoPlaybackException: com.google.android.exoplayer.MediaCodecTrackRenderer$DecoderInitializationException: Decoder init failed: OMX.MTK.VIDEO.DECODER.AVC, MediaFormat(null, video/avc, -1, -1, 4096, 2304, -1, 1.0, -1, -1, null, -1, false, -1, -1, -1, -1, -1). ",
    "tweenk": "This is a bug in Android Nougat that is already fixed in master. This extension is guaranteed to be implemented on every Daydream-ready phone, but it's erroneously not included in the EGL whitelist in eglApi.cpp.\nNougat version:\nhttps://android.googlesource.com/platform/frameworks/native/+/nougat-mr1.2-release/opengl/libs/EGL/eglApi.cpp\nMaster:\nhttps://android.googlesource.com/platform/frameworks/native/+/master/opengl/libs/EGL/eglApi.cpp. We found the root cause and have a fix under review.. This has been fixed internally and the fix should be present in the next release.. ",
    "klausw": "Thank you for clarifying. I think I'll go with the workaround of checking for the other VR-related extensions then and assuming that the priorities are available too if those are present.. ",
    "AmirBraham": "As far as I know, Google is working on supporting it in an upcoming version of their UnitySDK but I have no information on when that will be released.. ",
    "tvkamara": "Thank you @jdduke and @sigmaxipi for swift responds. My goal is actually to present a video frame for the user as quickly as possible (research project in a university). So every millisecond counts and I believe using scanline racing I might save a couple. My problem is that the only way I believe this is possible at the moment is to use this GVR API which bundles scanline racing with async reprojection. So at the moment I'm trying to portrait the video frames in a 3D setting using the getting started tutorials as reference. This could be a bit of an overkill for my purposes, please let me know if there is an easier way.\nI have no need for DRM. I guess the easiest option for me would be if I could just enable scanline racing in my existing SurfaceView. Anyway, the upcoming sample will probably help me in my task. I noticed the viewports guide also changed a bit in the last update, I haven't tried applying it extensively. My lack of experience in 3D rendering with Android is probably the cause why I failed with the last set of instructions. A complete example would really help.. @sigmaxipi low-latency 2D is my primary goal at this point. I might want to test other scenarios as well, so I'm still interested in the upcoming sample.\nAndroid SurfaceView is what I'm using at the moment. It is fast but I was wondering if it could be even faster with scanline racing or front buffer rendering. I believe a SurfaceView is always at least double-buffered right?. ",
    "nixbyte": "I still waiting for this issue to be closed and I'll use setHeadRotation() method in my project. ",
    "tao1": "I need that feature for Android TV platform. My first use case for Android TV would change head rotation when using direction pad.\nSecond use case would use a paired phone : head rotation from phone is applied to video playing on tv.. @sigmaxipi Yes mutually exclusive would be fine\nI have a third use case: phone used as a touchpad to change rotation on TV.. Many many thanks !\nNotice this method is not yet documented: https://developers.google.com/vr/android/reference/com/google/vr/sdk/widgets/common/VrWidgetView. I guess you are watching all conversations on your side Charles6666. I doubt I can do that on my side.\nThere's a small bug when using setPureTouchTracking(true), video starts with a 180 degrees offset, meaning you don't see video center at start but the opposite direction. Furthermore this offset remains when you drag video using touch gestures, I mean getHeadRotation() still has a 180 degrees offset. . This is about a 5 lines addition in your code whereas reimplement all VrView features from video360 sample is pretty big. If only your SDK was open source, I could fork it...\nWell, thanks for your response.. ",
    "Cooper6334": "In my case, I like to let user lie on bed but look forward.\nI think this feature only needs setHeadRotationOffset(), but not call setHeadRotation() by myself every time.. Same issue. \nThis dialog shows every time when I press the x button at the left top corner on VrVideoView.\nI'm using HTC M9 with Android 7.0 and Google VR SDK 1.10.0. ",
    "Fenchelbach": "Have you found a solution or a workaround yet?. ",
    "SoumyaBasheer": "I have the same issue of Persistent camera drift after OnPause -> OnResume as @bri-bri  specified.\nI have used 1.10.0 version.I have tested in Galaxy S6,note 3 ,Nexus.I have the same issue in  TreasureHunt sample.Does any other faces the same issue?Have any solutions?. @jdduke I am experiancing this in TreasureHuntSample which  extends GvrActivity and implements StereoRenderer. @bri-bri Is it fixed?Any update?. @jdduke I have checked  1.0.0 SDK release TreasureHunt  sample..the drift does not occur for it.also checked 1.0.1 TreasureHunt sample and there is drift in it.but as @bri-bri  specified have to use 1.10.0 for Daydream publishing requirement. ",
    "bri-bri": "Apologies for the delayed response. I have been using 1.0.0 to avoid this issue; but this won't be possible now because of the Daydream publishing requirement to use version 1.10.0+.\nThe drift doesn't occur for me with the 1.0.0 SDK Release; it only happens on 1.0.1, 1.0.3, and 1.10.0.\nI have tested and reproduced on both Galaxy S6 and Galaxy S7 phones in a cardboard viewer. I've reproduced with the SDK/NDK TreasureHunt demo, as well as in my own Native Android App, and with the Unity GoogleVR Demo scenes built for android.\nEdit: I've built using android:targetSdkVersion=\"19\" through \"23\" and reproduced the bug across all these Android API levels.. ",
    "Oleur": "This issue is happening with the Unity SDK and as I do not have those devices I was not able to reproduce this issue with the sample apps. \nI will open an issue on the Unity SDK tracker. \nThanks. ",
    "Chico3001": "Yes... i can play the file directly... i have been making tests and it seems that the error triggers when \"the place your phone in the cardboard\" screen is active and the movie ends and restarts... . ",
    "SumoDino": "Lol never mind I for some reason I had to turn my phone on its other side! . ",
    "Cbaoj": "Thanks for the reply.  the Nexus6P is running image 7.0.0 (NBD91K) actually.. ",
    "nikhilcheruku12": "jdduke I was wondering if the controller arm model has been released yet.\nI have been using The Google VR SDK for android in conjunction with OpenGL to code my app. I need to use a controller laser pointer to implement some of the functionalities. I have looked at the Google VR SDK for android and there doesn't seem to be any support for this in the API. I know that there is support in the android SDK. Does anyone know how I can implement the controller pointer part with the SDK for android?\nWHat do you think is the best way to proceed. Is it possible to integarate unity or unreal code solely for the controller laser pointer part while coding the rest with the gvr-sdk?. ",
    "mgatelabs": "In the 1.70 release?  So is it just me, or does the new Controller object in java not implement the arm?. The Controller & ControllerManager classes have been added, and they provide details on the orientation and button status, but the position information seems broken.  The sample https://github.com/googlevr/gvr-android-sdk/blob/master/samples/sdk-controllerclient/src/main/java/com/google/vr/sdk/samples/controllerclient/ControllerClientActivity.java may be helpful, but it seems a bit broken.. Well, its not in Java, but it's in C++ code, closing.. I figured it out by looking into the .h files.\nYou need to call the ApplyArmModel method before each controller update in order for the position to be updated correctly.\ncontrollerApi->ApplyArmModel(gvr::kControllerRightHanded, gvr::kArmModelBehaviorSyncGaze, api->GetHeadSpaceFromStartSpaceRotation(gvr_get_time_point_now()));\n. Figured out, closing. ",
    "rawnsley": "@jdduke +1 for Java SDK support ASAP. There's not much sense in mandating the use of an arm model if everyone uses a different model.. @sigmaxipi I use GvrView rather than GvrLayout so I don't have that option. For example, how would you get GvrApi in the Treasure Hunt sample?. Thanks @sigmaxipi . I'll try the suggested workaround.. ",
    "ivalduan": "Probably there is no real advantage of cmake vs makefiles in the contest of just a few files, but seems to be the build trend with android ndk docs and samples. What is no doubts confusing is the use of experimental plugin dsl syntax now that gradle plugin supports everything needed. Maybe someone finds this useful so I shared here, feel free to reject the pull request if it doesn't meet standards.. ",
    "mdelacalle": "OMG!\nThanks!. ",
    "michelePap": "@dav-cz Hi, has anything changed about adding hotspot?\nI started using vrview for the web but i could only use the two default cardboard viewer, so i decided to look at android sdk, but there are no hotspot implementation.\nThanks. ",
    "MukeshKumarS": "Hi,\nplease add hotspot support. ",
    "munjliew": "did anyone find an alternative?. ",
    "ganico": "@sigmaxipi is there any reference to do this feature on video360?. do I really need to use the VrVideoActivity? or I can apply the same function on VideoActivity since I don't need the Daydream type of view. or is there a function on VideoActivity to get the (x,y,z) coordinates? so I can do some computation something like this (please see attached file) this is what I did on iOS.. i'm trying to replicate it here..\n\n. yeah!! I saw that already, alright.. So i'll try that part to check the touches.. Thank you so much again for your quick quick response.. @sigmaxipi any idea how to convert MonoscopicView.onTouch into world coordinate?. > Is there any sample code for this issue, please? I am also looking for this feature of 360 sample.\ndid you find an answer for this?? or any alternative way to do it?. > https://gist.github.com/sigmaxipi/b9d4cbfb3410e5be6c5279f56c09b391 is a patch that demonstrates the basic functionality required for supporting rotation. I haven't tested it in depth, but it appears to support standard rotations.\n\nDue to the complexity of dealing with rotations while rendering 3D or playing video, it's better to make sure your Activity is fixed in one rotation or you will need to perform thorough testing.\n\nThank you so much for the quick response, sorry i'm no expert on GIT terminologies. So when you patch is it on your sample projects or all I need is to get the changes that you did there? currently my reference is this sample \"https://github.com/googlevr/gvr-android-sdk/tree/master/samples/sdk-video360/src/main/java/com/google/vr/sdk/samples/video360\" does this sample have that implementation?\nApology for the long message. it worked!! thank you so much!! @sigmaxipi  :). Sorry for the long response.\nI tried the sample and it's perfectly working but when I tried to incorporate it on my project it seems that the gradle doesn't download everything for me to use it in the activity. Btw i'm using kotlin but I think that shouldn't be a problem.\nI already removed my codes so I forgot already the error since i'm trying the     implementation 'com.google.vr:sdk-panowidget:1.150.0' and it's perfectly working fine but as what you've said on the previous issues better to start here \"https://github.com/googlevr/gvr-android-sdk/issues/510?fbclid=IwAR1W1mY1zVpm0P-HH3gb67cDusRBT8NogLjjjz3IySTRe2Wk1PSFiKXAUp4\" if we need a more complex panoramic view.. @sigmaxipi it worked!! thank you for your quick response ;) I'll post some more question :). I saw it, alright.. will try it tonight, thanks for the quick response :). @sigmaxipi what should I set to stereoFormat? I tried using 0, 1 & 2... 0 = the lines became wavy, 1 = image becomes half then 2 = it's like it became sphere...\nwhen i'm using VrPanoramaView, the view looks normal but since it's designed for just viewing so i switched to the one that you recommended.\nI also noticed on gvr-android-sdk-vv1.180.0 the sample asset looks like this.. my asset doesn't look like that, it's just looks like a normal panorama image.\n\n. I did several testing I finally got it here:\nprivate static final int DEFAULT_SPHERE_ROWS = 36;//30;//24;//18;//12;\nprivate static final int DEFAULT_SPHERE_COLUMNS = 72;//60;//48;//36;//24;. @sigmaxipi thank you for your response but i'm not 100% familiar with this computation actually.. I'm actually using my own instinct to solve this problem BWOHOHOHO!!! anyway still thanks for your response.. I got some idea about it.. @sigmaxipi thank you for your information.. i'll take note of that... @sigmaxipi sorry, i don't quite understand most the things that you mentioned.. could you give a sample code to illustrate your response... thank you so much and sorry.. so basically this is the code that you're talking about \"Math.atan2(x,z)\" right? so i'm not totally sure how would I get the x & z from this line of code \"Matrix.multiplyMM(viewProjectionMatrix, 0, projectionMatrix, 0, viewMatrix, 0);\" would you help me understand this part? . @sigmaxipi ohh.. that's what you mean? hmmm.. analyzing the library seems it has a way to get the angle, just need some tweaks. Anyway thanks for your responses, i'll try to investigate more on the code, maybe I can find something to use then convert into the current angle. Thanks for your response.. @sigmaxipi yes, but I wanna get the current value as the user pan or move the device... my question here on #615 you give me this line of code \"Matrix.multiplyMM(viewProjectionMatrix, 0, projectionMatrix, 0, viewMatrix, 0);\" which i'm not sure how can I extract the current angle that I have.. would you give a sample code to illustrate it?\n. ",
    "yoavya": "When in the cardboard the edges are not visible however I would like to avoid this issue from accruing at all. I can't display the texture on the entire screen because my requirements demand that i present them at a fixed size. How can I solve this? . Honestly it's just a cosmetic requirement by my client. The images I am presenting are 2D so there is no real need for distortion (although it doesn't harm anything). Is there a way to solve this issue without enabling the distortion correction ?. ",
    "anthonycr": "This bug is also reproducible using the latest sdk-simplevideowidget sample project included in the SDK. Repro steps, tested on Nexus 5X:\n1. Open the simplevideowidget app and rotate device into landscape. Embedded player is displaying the video correctly.\n2. Rotate the device by 180 degrees. This will not trigger an orientation change and so the Activity and VrVideoView will not be recreated. The embedded player is now displaying the video upside down.. @Lannylanlol the only solution I have found is to recreate the VrVideoView when the device rotates in increments of 90 degrees. If your activity is recreated on configuration change, then this is taken care of you for 90 and 270 degree rotations, but not 180. In order to recreate it for 180 degree rotations, you need to use an OrientationEventListener as follows:\n```java\nActivity activity;\nint oldOrientation;\n...\nactivity = this;\nDisplay display = ((WindowManager) getSystemService(WINDOW_SERVICE)).getDefaultDisplay();\noldOrientation = display.getOrientation();\nOrientationEventListener listener = new OrientationEventListener(activity) {\n@Override\npublic void onOrientationChanged(int newOrientation) {\n    if ((newOrientation - oldOrientation) % 2 == 0 && newOrientation != oldOrientation) {\n        // This is a 180 degree rotation, destroy your VrVideoView.\n    }\n\n    oldOrientation = newOrientation.\n}\n\n}\nlistener.enable();\n```. ",
    "Lannylanlol": "This also happens with my app which integrates the last version of sdk-videowidget:1.30.0.\nMy app uses orientation sensorlandscape and when I rotate the device, all the layout works fine but the videoView rotates displaying the video upside down.\nAny solutions? \nThanks.. any suggestions for this issue?. Trying to use demo app of exoplayer 2, the same issue occurs. It seems to\nbe a problem of switching the highest bitrate on some devices. There is a\nway to get the instance of exoplayer from videowidget and select the lowest\nbitrate?\nOn 10 Mar 2017 10:30 pm, \"SxP\" notifications@github.com wrote:\n\nThis appears to be an Exoplayer issue. Can you play the same video in\nExoplayer when not using the Video Widget?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/375#issuecomment-285790012,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABZDcRuoiaJEnMKSIDXaOd0BnHrkYXEiks5rkcELgaJpZM4MQ-qW\n.\n. Note: I need to use the DisplayMode set to EMBEDDED, which causes the issue. I tried to use display Mode set to FULLSCREEN MONO and the vrVideoView rotates correctly. \nIs there a way to avoid the rotation for the Embedded display mode as the FULLSCREEN MONO does?\nThanks\n. \n",
    "aarshaw": "Basically looking for an Android equivalent to setViewerParamsFromUrl:withCompletion: from the iOS API. It's not obvious enough that it's there and what functionality it has.\nWe want to allow the user to setup the app and configure their viewer params in an onboarding section before they enter VR mode.. ",
    "keakalamudo": "+1. ",
    "ChrisCW1": "Hi @jdduke,\nyes - same with the latest relase / i tried the sample app (SimpleVrVideoActivity)... \nSide By Side view (tap on cardboard icon) is not possible anymore because of this Warning!\nThe warning appears in background and the player stops and you cant resume - because of the mentioned Warning that waits for your input in background.. \n. ",
    "GuyAglionby": "Any update on this issue? Same device, using the latest version of the SDK.. ",
    "kesefworld": "Hi, I am building vr games and I also have this problem.  I have  (as far as I know) the latest google VR sdk version 1.30. To test my apk I build and run it to my galaxy s7 edge and when I run the game that google warning comes up. Like I said I'm using the latest sdk version so why am I still seeing this warning message? Thanks in advance. . Thanks for the response but I actually have it uploaded to the phone for about a month now but I still get the warning. . Yes and I actually deleted the 1.30 version from my source folder and installed the 1.40 version and I still have that problem.  I am wondering, is there any settings I have to perform on my phone in order to stop the message from appearing? . On my Samsung 7 edge\nOn Jul 12, 2017 3:55 PM, \"nathanmartz\" notifications@github.com wrote:\n\nbinoculars88, what device are you seeing this behavior on? What version of\nthe SDK are you using?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/405#issuecomment-314878733,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/Aabf2JWl1oV5l-IHT032jvCQkoYoCCCKks5sNSS8gaJpZM4M_wfB\n.\n. \n",
    "Leifzhang": "I  try  the version  1.40.  already fix it. ",
    "jmgirven": "Thanks, but no, this would be a feature of the product. I feel like I want to write the decoded, visually corrected frames of a 360 video to a surface. Then take one copy of that surface and display it to the screen. And another to write to a file with MediaCodec or similar. Both being responsive to the users position, accelerometer, etc.. I can't run adb screenrecord in a production app, on a user I don't knows device, right?. ",
    "kpilyugin": "Found it in GvrUiLayout, so closing this issue.. It's ES2, GLSurfaceView.setEGLContextClientVersion(3) crashes.. ",
    "anton-knyazev": "```\nint duration = 3; // seconds\nint sampleRate = 11025;\nint numSamples = duration * sampleRate;\ndouble sample[] = new double[numSamples];\ndouble freqOfTone = 440; // hz\nbyte generatedSnd[] = new byte[2 * numSamples];\nByteBuffer inputByteBuffer = ByteBuffer.wrap(generatedSnd)\nGvrAudioSurround   surroundEngine = new GvrAudioSurround(GvrAudioSurround.SurroundFormat.SURROUND_STEREO,\n                sampleRate, 2, numSamples * 2);\nsurroundEngine.addInput(inputByteBuffer, inputByteBuffer.position() , inputByteBuffer.limit()); // crash\n```\nFatal signal 11 (SIGSEGV), code 1, fault addr 0x0 in tid 7545 (com.example.app)\ndebuggerd: handling request: pid=7545 uid=10103 gid=10103 tid=7545\n\nBuild fingerprint: 'google/bullhead/bullhead:7.1.1/N4F26I/3532671:user/release-keys'\n Revision: 'rev_1.0'\n ABI: 'arm64'\n pid: 7545, tid: 7545, name: com.example.app  >>> com.example.app <<<\n signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0\n     x0   0000000000000000  x1   0000000000000002  x2   000000767c1c72a8  x3   0000000000004099\n     x4   0000000000000000  x5   000000767c8bcd90  x6   0000000000000000  x7   0000000000000000\n     x8   0000000000000002  x9   000000765f50d000  x10  0000000000000002  x11  00000000ffffffff\n     x12  0000007696a0c630  x13  0000007696c03e00  x14  0000007696c03e00  x15  0000000000000000\n     x16  000000767cac2c68  x17  0000007697061908  x18  0000000000ffffeb  x19  000000767c1c7260\n     x20  0000000000004099  x21  0000000000004099  x22  0000000000004099  x23  0000000000000000\n     x24  000000767a3c1180  x25  0000000000010266  x26  0000007696a95a98  x27  0000000000000001\n     x28  0000007696a95a00  x29  0000007ffe3e8fd8  x30  000000767ca64c48\n     sp   0000007ffe3e8ce0  pc   000000767ca64f18  pstate 0000000080000000\n backtrace:\n     #00 pc 000000000005af18  /data/app/com.example.app-2/lib/arm64/libgvr_audio.so\n     #01 pc 000000000005ac44  /data/app/com.example.app-2/lib/arm64/libgvr_audio.so\n     #02 pc 0000000000018150  /data/app/com.example.app-2/lib/arm64/libgvr_audio.so\n     #03 pc 0000000000015cfc  /data/app/com.example.app-2/lib/arm64/libgvr_audio.so (Java_com_google_vr_sdk_audio_GvrAudioSurround_nativeAddInput+584)\n     #04 pc 00000000004cd154  /data/app/com.example.app-2/oat/arm64/base.odex (offset 0x492000)\n. ",
    "harrya": "Downgraded to 6.1 Marshmallow.. ",
    "dbsGen": "@koubiak ,Tracking is frozen,rendering is ok.. ",
    "jplgarcia": "I\u00b4d really like to know that. I need to be able to play a vrVideo on my app and do more stuff at the same time! . ",
    "MortimerGoro": "Tried those hacks but no luck:\nfib = gvr_frame_get_framebuffer_object(frame, 0);\nbindFrameBuffer(fid);\nglFramebufferTexture2D(gl::FRAMEBUFFER, gl::COLOR_ATTACHMENT0, gl::TEXTURE_2D, texture_id, 0);\ngvr_frame_bind_buffer(frame, 0);\nglFramebufferTexture2D(gl::FRAMEBUFFER, gl::COLOR_ATTACHMENT0, gl::TEXTURE_2D, texture_id, 0);\ngvr_frame_unbind(frame);\nI know that I can render with a quad but that requires a lot of work specially in a module based architecture (loading gl symbols, shaders, etc..). It would be great to simply specify a texture_id which exists. For example, the OpenVR API allows to do that easily.. I got it working attaching the texture to a custom fbo and using BlitFramebuffer  ;)\n@jdduke  In my case I wouldn't use that API because I can't change the surface where the \"framework\" renders to.. Thanks, I thought that physical pixels latency was smaller.. ",
    "irajuneau": "We are also experiencing this issue on 1.80.0. It appears to be triggered by a low level error. Most of the time the video content works, however sometimes it doesn't. It happens with some regularity on a Galaxy Note 4 running 6.0.1 (Samsung-SM-N910V). The content it struggles with can be found @ http://cnnios-f.akamaihd.net/i/cnn/big/360/vr/2017/09/23/egypt-tomb-luxor-discovery_1636224_,960x540_2500,416x240_200,480x270_400,640x360_600,640x360_800,768x432_1500,1280x720_3500,1920x1080_5904,.mp4.csmil/master.m3u8\nI have attached an error log as well. It appears to be triggered on the line that begins with 09-25 14:13:11.802 27075-27075/com.cnn.mobile.android.phone.debug E/VrVideoPlayer:\nThis error only happens in a minority of the time it is called, maybe once every 20 calls or so it will provide this error. However, once it is encountered the first time, it appears that almost every other call to the content will fail after.\ngoogle_issue.log\n. ",
    "wangkangmao": "@sigmaxipi thanks\uff0chas now been resolved. ",
    "nicholas-yangding": "oh,  by the way, this hub only resever the version >= 0.8f,  I want to find the older version <0.8\nThanks!. anyone could answered me?. ",
    "Cristo86": "In Version 1.40.0 (maybe before it was too, haven't tried) settings.gradle explains the reason of those ndk disabled modules:\n// NDK samples are disabled by default because they need the Android NDK to be\n// installed in addition to the SDK. To build them, first extract the NDK .so\n// files by running \"./gradlew :extractNdk\" which will create a libraries/jni\n// folder. Then uncomment these lines to enable the NDK samples and synchronize\n// Android Studio.\nThe get started page instructs the same in some initial paragraphs.. ",
    "alculquicondor": "I'm still getting Plugin with id 'com.android.model.application' not found., even when running ./gradlew :extractNdk. What should I do?. ",
    "niteshxor": "use image array to open random images  . any reference please give me link or example . ",
    "miqt": "thanks. ",
    "alexeysuvorov": "We still see huge difference between NDK and SDK on Nexus 6P when we make buffer smaller:\nNDK\nrender target scale: 1\nfps: 26.973026, avg. frame time: 35\nfps: 27.053141, avg. frame time: 37\nfps: 26.785715, avg. frame time: 32\nfps: 27.158098, avg. frame time: 36\nfps: 27.397261, avg. frame time: 32\nfps: 27.667984, avg. frame time: 32\nfps: 27.722773, avg. frame time: 33\nfps: 28.292683, avg. frame time: 30\nfps: 34.179688, avg. frame time: 30\nrender target scale: 0.5\nfps: 59.820538, avg. frame time: 16\nfps: 60.098522, avg. frame time: 14\nfps: 54.848186, avg. frame time: 21\nfps: 59.880241, avg. frame time: 15\nfps: 59.760956, avg. frame time: 16\nfps: 59.642147, avg. frame time: 16\nfps: 60.000000, avg. frame time: 15\nSDK\nMSAA off, renderTargetScale 1\nfps: 22.504892, avg. frame time: 35\nfps: 23.210833, avg. frame time: 38\nfps: 22.977022, avg. frame time: 33\nfps: 22.931206, avg. frame time: 36\nfps: 23.391813, avg. frame time: 31\nfps: 23.437500, avg. frame time: 30\nMSAA x2, # render target scale: 0.5\nfps: 27.722773, avg. frame time: 30\nfps: 28.375734, avg. frame time: 31\nfps: 28.855721, avg. frame time: 34\nfps: 26.706232, avg. frame time: 31. Pixel XL usually 20% better than Nexus 6P, but overall situation is still not good enough for immersive VR experience.\nData above is for treasure hunt when you have about 50 cubes. Let me know if you want me to upload this sample somewhere.. Hello, after your message we was confused and decided to look around on our side. We made same test on another Mac and another Ubuntu PC with same pixel. It is kind of magic, but we could finally see 60 FPS in treasurehunt with one cube. \nBut difference between SDK and NDK is still huge even if we make target scale 1 for ndk. I made a diff for master branch to demonstrate changes we made.\nWe made 80 cube draw and can see 20-25 fps difference between SDK vs NDK\nNDK\n04-10 18:38:48.432 20055-20100/? D/MainActivity: fps: 57.884232, avg. frame time: 15\n04-10 18:38:49.433 20055-20100/? D/MainActivity: fps: 57.942059, avg. frame time: 15\n04-10 18:38:50.448 20055-20100/? D/MainActivity: fps: 59.113300, avg. frame time: 16\n04-10 18:38:51.464 20055-20100/? D/MainActivity: fps: 57.086613, avg. frame time: 14\n04-10 18:38:52.468 20055-20100/? D/MainActivity: fps: 59.760956, avg. frame time: 11\n04-10 18:38:53.483 20055-20100/? D/MainActivity: fps: 59.113300, avg. frame time: 7\nSDK\n04-10 18:39:45.516 20300-20356/? D/TreasureHuntActivity: fps: 39.370079, avg. frame time: 19\n04-10 18:39:46.520 20300-20356/? D/TreasureHuntActivity: fps: 38.844620, avg. frame time: 20\n04-10 18:39:47.523 20300-20356/? D/TreasureHuntActivity: fps: 39.920158, avg. frame time: 20\n04-10 18:39:48.554 20300-20356/? D/TreasureHuntActivity: fps: 36.821705, avg. frame time: 20\n04-10 18:39:49.572 20300-20356/? D/TreasureHuntActivity: fps: 36.345776, avg. frame time: 19\n04-10 18:39:50.594 20300-20356/? D/TreasureHuntActivity: fps: 36.238983, avg. frame time: 20\n04-10 18:39:51.595 20300-20356/? D/TreasureHuntActivity: fps: 35.928143, avg. frame time: 20\n04-10 18:39:52.597 20300-20356/? D/TreasureHuntActivity: fps: 35.964035, avg. frame time: 20\nLet's drop Nexus from this equation - nobody use it anyway.\n. Sounds reasonable. Thank you.. > setDistortionCorrectionEnabled is meant for very low end Cardboard devices where the GPU isn't fast enough to correct distortion\nLooks like pixel XL is not fast enough to correct distortion )\nWe just think it may be better way to implement distortion correction as describe in this article: https://ustwo.com/blog/vr-distortion-correction-using-vertex-displacement. \nWe still trying to get around our problem with big screen Nexus & Pixel phones as described in https://github.com/googlevr/gvr-android-sdk/issues/393. setAsyncReprojectionEnabled shown can give good experience even on 30FPS, but as you mentioned it works ok only on Daydream ready devices.. So, looks like this use case is not valid because of implementation of setAsyncReprojectionEnabled. ",
    "chaseout": "Having the same issue here.Did you find any solution for this?. ",
    "vokhuyet": "same issue ?\nanybody can tell me solution to fix it ? please. ",
    "binoculars88": "Is there a way to disable this message? My app works 100% fine even if Google VR Services isn't installed, but the user experience is so much worse when this warning pops up... . nathanmartz, I'm using this in a Cordova app. Both Novonity Plugin VR (which uses com.google.vr:sdk-videowidget:1.10.0) and Cordova VR Plugin show the popup message on Android N+. Is there a way to disable the warning? Player works fine without Google VR Services too.... ",
    "Roselynn39": "I use a Samsung tablet that this message shows on. I am not a tech person at all, how do I get rid of it?  I don't even use apps much, email, google, etc.  It comes up EVERYTIME I open up the tablet and on everything I use.  Have to hit cancel twice.  Started after viewing a condo \"tour\" on a website.  HELP ME, PLEASE.  What is a videowidget?  Please remember, I won't understand much other than 1,2,3 in simple terms.. It is asking me to go to the Google play store and install app.  Don't like the sound of that nor do I think it would help like jdduke talks about.  Thanks in advance.. ",
    "i3games": "It still triggers the prompt on non-daydream devices like the Moto G5 on Chrome 71 (Android 8.1.0). > @i3games Chrome requires the installation of VR services even for non-Daydream devices when using VR functionality in Chrome\n\nWhere can I report this bug? \n. \n",
    "yihanseattle": "I'm running 'com.google.vr:sdk-base:1.190.0'. It still triggers the prompt. Please let us know if there is anything we can do manually to disable the dialog prompt. Thanks. > @i3games Chrome requires the installation of VR services even for non-Daydream devices when using VR functionality in Chrome\n\n@yihanseattle what app are you seeing this with?\n\nHey @sigmaxipi , I'm just running the HelloVRActivity from sdk-hellovr sample on a custom device. The device I'm running on does not have google play services. But I was able to bypass by installing Google VR Service and enable the Google VR Service. I'm not sure how to bypass the prompt without installing Google VR Service. It would be great if you could give me any suggestions. Thanks!. @sigmaxipi It has a custom build of Android 7.1. Do you happen to know how to disable the prompt programmatically? why it's still showing? Or Google VR SDK will show the prompt on a device with custom build of Android? Thanks!. Hey @sigmaxipi , you are right! We no longer see the warning prompt after removing the flags in the OS. That was the cause! Thank you so much! . Thanks @sigmaxipi again! I had the same issue when upgrading to NDK r19. You saved my life twice :). ",
    "famagusta": "Figured it out. Send intent with data  https://play.google.com/vr/store/apps/details?id. I see a new version is out (1.70.0). Has the support for arm model been added?. ",
    "AnNEDoMini": "Maybe just expose gyro/rotation related methods?. ",
    "prideout": "1) We recommend calling IsFeatureSupported rather than checking for extensions directly because Google VR Services may need to blacklist the feature on certain devices. \n2) Correct, a single draw call corresponds to both eyes.  The sequence of draw calls that composes the scene needs to occur only once.\n3) It's fine to mix several types of BufferViewport objects in a single swap chain.  One can be an external surface, while another is a multiview buffer.. Multiview is an experimental feature on non-Daydream devices, if they happen to support the relevant OpenGL extensions.\nGoing forward, we will only support this feature on Daydream-ready devices, since other devices don't necessarily pass our OpenGL driver conformance tests.. Hi Niel, you can use texture unit 0 if you re-bind the texture in the onDrawEye method:\nGLES20.glActiveTexture(GLES20.GL_TEXTURE0);\nGLES20.glBindTexture(GLES20.GL_TEXTURE_2D, this.textures[0]);\n...\nGLES20.glDrawArrays(GLES20.GL_TRIANGLES, 0,\n    triangleCoords.length / POS_COORDS_PER_VERTEX);\n\nOn Cardboard devices, GVR resets the active texture binding on every frame in order to perform distortion and composition. For performance reasons, it does not restore the previous texture binding. We'll work on documenting this behavior.\nDoes this fix the issue?. ",
    "AntonAFA": "Thanks for reply. When do you plan to release the sample? Also if it is possible right now to swap the instance of the exoplayer, can you please provide me with some code snippet of doing so?. ",
    "Anton111111": "is it mean that video player sample will work only on daydream phone ready?. I want draw something like HUD. Cab you describe more about tan ?. Thanks you are right ;). Forgot add link to video.\nhttps://github.com/Anton111111/GVRVideoProblemSample/raw/master/video/3.mp4. This issue I see in Huawei Nova (can-l11).\nI don't understand what did you mean when say \n\"You could try resizing the video to find a size that works for the device.\" Did you mean resize video file ? I can't resize video file because I get file from server.. Thanks. I understood. . But cardboard app from Google play and YouTube don't  have this problem. . Another question. Where in https://github.com/googlevr/gvr-android-sdk/tree/master/samples/sdk-treasurehunt is system VR mode enabled?\nIs it manifest parameter or something other ? \nAnd why you say about daydream app? This sample is not daydream app. . I've already tried remove com.google.intent.category.DAYDREAM. But it still don't show navigation bar on samsung phones. . ",
    "hankewei": "Thank you for your answer.\nAs you say, gvr_audio_surround_get_interleaved_output triggers the internal processing of the input buffers.\nThen, gvr_audio_surround_get_available_output_size_samples only calculates the number of available output frames.\nIs that so?. @jkammerl \nThank you for your answer.\nAs you say, gvr_audio_surround_get_interleaved_output triggers the internal processing of the input buffers.\nThen, gvr_audio_surround_get_available_output_size_samples only calculates the number of available output frames.\nIs that so?\n. Thank you very much.\nThe video file\nurl\uff1ahttp://pan.baidu.com/s/1i59v7VJ password\uff1aigf4\nThe pcm data\nurl\uff1ahttp://pan.baidu.com/s/1hr7f5qs password\uff1aeo42\nThe code fragment adapting gvr-audio to Android audioflinger\nurl\uff1ahttp://pan.baidu.com/s/1i5muWvj password\uff1anxxg. What sampling rate does gvr-audio support? \nWhich PCM data formats are supported?. I adapt gvr-audio to Android AudioMixer, and consider it as a special downmixer. \nThe code fragment \nurl\uff1ahttp://pan.baidu.com/s/1i5muWvj password\uff1anxxg\nThe video file\nurl\uff1ahttp://pan.baidu.com/s/1i59v7VJ password\uff1aigf4\nAndroid Bug Report\n2.log\nAn error\uff08signal 7 (SIGBUS), code 1 (BUS_ADRALN)\uff09 occurred while calling gvr_audio_surround_get_interleaved_output.\nI suspect that this bug is related to the sampling rate, because when I adjust the output of decoder to 48000Hz, the error disappears.\n. \ncode.zip\nThe target buffer is big enough( 1024 frames).   gvr_audio_surround_get_interleaved_output  only request 941 frames.\nThe num_samples, input param of gvr_audio_surround_get_interleaved_output, need to be an integer multiple of process_num_frames?. I find that it's okay if num_samples is a multiple of 4\uff0c  i.e.  gvr_audio_surround_get_interleaved_output request even number frames . Why?. Thank you. \nI know \"num_samples = num_frames * num_channels\", and My input and output are guaranteed to be a complete frame. When gvr_audio_surround_get_interleaved_output request 941 frames,  i.e. 941 * 2 \nsamples, the program crashed. When gvr_audio_surround_get_interleaved_output request 940 frames,  i.e. 940 * 2 samples, it's normal. . new GVRBufferProvider(channelMask,\n             mMixerChannelMask, AUDIO_FORMAT_PCM_16_BIT,\n             mOrigSampleRate, 1024);\n//channelMask--AUDIO_CHANNEL_OUT_5POINT1  mMixerChannelMask--AUDIO_CHANNEL_OUT_STEREO mOrigSampleRate--44100 bufferFrameCount--1024\ngvr_audio_surround_context* gvr_audio_surround_create(\n    gvr_audio_surround_format_type surround_format, int32_t num_input_channels,\n    int32_t frames_per_processing, int sample_rate_hz);\n//surround_format--GVR_AUDIO_SURROUND_FORMAT_SURROUND_FIVE_DOT_ONE num_input_channels--6 frames_per_processing--256 sample_rate_hz--44100\nWhen gvr_audio_surround_get_interleaved_output request 941 frames, i.e. 941 * 2\nsamples, the program crashed. . ",
    "hc-tronic": "Hi Sigmaxipi,\nThanks for the advice. You are right, I already implemented my idea in OpenGL. The problem was, that I couldn't find such a precise solution for head tracking as implemented in GVR (probably 6 axis Kalman filter?). Do you know a reliable discrete solution for head tracking, which I could use with OpenGL?. ",
    "RalfNick": "I build a opengl demo, but is c++ code , and i want to use theGVR's sensorfusion in c++.. I know that. I just want to understand the algorithm , and i hope i can  do something, such as optimization algorithm\uff01And i have another question, the native libs are part of the Unity engine and android ! The aar package is for the android. I want to know the difference between native libs and aar when used in android. Though native libs can be used in android , and what the aar is used for? Thanks a lot!. ",
    "YunzhongTianjing": "@RalfNick ,Something you maybe want:\nhttps://developers.google.com/vr/android/ndk/download\nhttps://github.com/googlevr/gvr-android-sdk/tree/master/libraries/headers/vr/gvr/capi/include. ",
    "YoungBill": "anyone can help me?. ",
    "codelurch": "Had installed the VR Services without success. Indeed it helped to change resolution as discussed in 421. Thanks for the quick answer. I didn't find this discussion.\nIs there a chance to give the user feedback about problematic config like checking supported setups/resolution?. ",
    "miraleung": "Are you using the GVR Unity SDK? We no longer need to use base.aar; the native libs have become part of the Unity engine as of 5.6.. ",
    "taixiang": "yes , I miss someThing ,  after I add 'compile 'com.google.protobuf.nano:protobuf-javanano:3.0.0-alpha-7'' , it run well , thank you ,so I close this issue . ",
    "reganking": "Experienced the same issue on AS 2.3 beta (updating to 3 now). \nCheck https://bintray.com/google/googlevr/sdk-audio which indicates 1.60.1 isn't available yet (mentioned by https://stackoverflow.com/a/44199529).\nSolution: Change ALL instances from 1.60.1 to 1.60.0 ... if just changing dependencies for one sample project, gradle will still complain.\nYou may get additional dependency issues for com.android.support:support-annotations:25.2.0 and com.android.support:support-core-utils:25.2.0 if you're building the videowidget sample.\n. Additional dependency issues might be resolved with update to \"Google Repository\" and \"Android Support repository\" in the Android SDK Manager. Worked here for AS 2.3 beta.. ",
    "micdic": "I've changed all the projects  instances from 1.60.1 to 1.60.0 and it now compiles correctly.\nNo other dependency issues found.\nThanks really for your support. @reganking . ",
    "lachlansleight": "Oops - just realised I posted this in the wrong repo - I have way too many tabs open learning about this issue hehe. Reposting in the Unity SDK repo. Apologies!. ",
    "darsor": "I'm also try to use pure touch-controlled mode on a panorama. This seems like a basic feature, since the panorama isn't very useful without it.\nIf there is another workaround, let us know!. ",
    "Howard9891": "Ok thanks . ",
    "axel20000": "I'm wondering the same thing.. ",
    "oliguo": "me too. ",
    "rfn123": "@sigmaxipi Yes I was actually referring to the VR mode, thanks for your reply! Is there any way to see how the FOV is calculated there?. ",
    "miraclehwan": "@sigmaxipi \nThank you for your comment.\nCould I get a sample code please? I want to refer sample code.. I used pixel phone.\nDo you have example code?\nI try to exitfromvr. But i got a pendingintent null point error. So I create another solve the problem.\nCoulde you check my another solve the problem code?\nI want publishing my app in daydreamstore.. @jdduke \nThank you for your code.\nI can move to 2D Activity. but I can't show prompt.\n\nHow can i show prompt ??. ",
    "ECSGuy": "Just from what is on the website currently (not sure if you already solved this), but here is the text before the image you posted (the one about 'Prompt the user to remove their phone'):\n\nThis is meant to be a very rare occurrence, and only for a small set of circumstances. One reason might be needing to prompt the user to accept a dangerous permission. Unfortunately, currently dangerous permissions can only be accepted with 2D monoscopic dialog boxes. This won\u2019t be addressed with in-VR dialog boxes until the next version of Android. Another reason might be displaying a webview, for a login process with a third party that requires the web.\nWhen making this transition, your app must do the following:\nPrompt the user to remove their phone.\nDetect the orientation change to portrait to switch over to 2D.\nProvide the user with a button to return them to VR.\n\nSo in your game/app (either with Android widgets or your own game rendering a UI) you must do the prompting (e.g. drawing the UI screen telling the user to remove their headset, etc). It looks like they plan to address permissions later...\nMatt. Quick update, NVidia have confirmed that they are NOT injecting any permissions, etc.  Just a quick shout out to Daniel Horowitz and Mikhail Filimonov; thank you SO much for answering so quickly!  And, er, sorry I'm grumpy... :|. sigmaxipi,\n  THANK YOU!  I'll run the tool as soon as I can (travelling right now)....  (I'm chomping at the bit to check these!!)\nMatt. Apologies; I've had a family emergency for the past week or so.  I'll get back to you on this asap; thanks again for answering!. Hey sigmaxipi,\n  It looks like my partner, Francois, found a way around this.  I didn't have the override (tools:* statement) in the right place.  It must be AFTER the application:\n...\n\n\n...\nAnyhow, we aren't able to locate the exact place/binary where the extraneous permission is inserted.  Our guess at this point is the com.android plug-in for gradle somehow contributing this (we leave the version at the default; when I tried changing this lots of other dependencies on gradle versions complained, etc.)\nI hope this is some kind of help to anyone else that isn't able to get around this issue.  Thanks, sigmaxipi for your help!\nMatt. ",
    "threesn": "I had the same issue with a cardboard-only app built with Unity. With Google VR services enabled on the S8, calling AndroidCompat.setVrModeEnabled(this, false) after switching to VR solved the screen brightness issue!. ",
    "baroquedub": "@threesn Thanks David, that could possibly solve my problem as I'm in Unity too... how do you call AndroidCompat.setVrModeEnabled(this, false) ?\nI'm using 2017.2 and can't see AndroidCompat under UnityEngine.XR.XRSettings.\nI'm using this to switch to VR:\n```\nIEnumerator SwitchToVR() {\n    string[] DaydreamDevices = new string[] { \"daydream\", \"cardboard\" };\n    XRSettings.LoadDeviceByName(DaydreamDevices);\n// Must wait one frame after calling XRSettings.LoadDeviceByName().\nyield return null;\n\n// Now it's ok to enable VR mode.\nXRSettings.enabled = true;\nUnityEngine.XR.XRSettings.eyeTextureResolutionScale = GlobalVars.vrRenderScale;\n\n}\n```\nIdeally I'd like it to work for either Daydream or Cardboard.\n(Was not seeing this on my Android 7.0 Samsung S6 but now a problem on my shiny new S9 running Oreo). ",
    "libinta": "Thanks. Which portion is not supported on Nexus 9? Does the stream portion? Since the samplevideowidget seems play ok. ",
    "moonfan": "@jdduke The latest 1.80.0 release works fine now, thanks for your help!. ",
    "Timper-yang": "I have the same problem.. ",
    "yinleunglai": "I also get this leak issue. . ",
    "bipin-logic": "Thank you, Nathan, for your reply.\n\nOn August 18, 2017 at 11:00 PM Nathan Martz notifications@github.com wrote:\nHead tracking is a fundamental part of the VR SDK. If you don't want head tracking, but to shut down GVR.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/googlevr/gvr-android-sdk/issues/465#issuecomment-323414010 , or mute the thread https://github.com/notifications/unsubscribe-auth/AdqG3R7Er-TOvr3MbpKN5dRtdwO0QYTMks5sZcpTgaJpZM4O7EmK .\n\n\n. ",
    "jkane001": "Actually, I think it's been fixed somewhere along the way, because I cannot reproduce it on my own project anymore. The only change I've made to the pano is updating the library to the latest.\nThanks, and sorry for not closing this before - I never noticed that the problem went away!. ",
    "fredsa": "I wonder if you're seeing the effects of the device failing to enter low persistence mode.\nCan you compare what you're seeing with what you get when this Android setting is applied?\nSettings > Display > Advanced > When device is in VR: Reduce flicker\n. The latest release notes are available on the releases page:\nhttps://github.com/googlevr/gvr-android-sdk/releases\nWe'll make sure we update the old release notes page to redirect there.. ",
    "dustinkerstein": "I can't speak to your first issue, but the second issue sounds like this https://github.com/googlevr/gvr-unity-sdk/issues/671 - Can you replicate this crash when setting your S8 to WQHD?. Hey @jdduke, I'm using Unity 2017.1.1p1 which I believe is based on the GVR 1.80 NDK. \nBelow are two bug reports, one from 1.8.163477258 which was taken during an app run which didn't show any vsync misses and another from 1.10.170928015 which was taken during the same app/scene but had around 4-5 vsync misses.\nmissed_frames1.8.163477258.zip\nmissed_frames1.10.170928015.zip\nThe vsync miss behavior appears to be the same for both the Moto Z and Pixel XL.  While there aren't many misses (usually around 4-10 during the high CPU / IO period), the older VR services has a consistent 0 misses during that same period over many tests.\nI've also seen more vsync misses in other Daydream apps, and even in the Daydream Home application.\nLet me know if there's anything else I can help debug.. @jdduke Let me know if you'd to have the APK that I am testing with.. Sure thing. Check your email. . @jdduke, David's description of the behavior sounds like the behavior I see. It's just that I was looking at the HUD to confirm why I was seeing those frame drops. If I disable the HUD, the \"discomfort\" that I mentioned above manifests as the \"sticky\" head when it's particularly bad (more than 1-2 frame drops). Sometimes it's more minor and only results in single frame drop flicker. . @sigmaxipi Do you mean the beta Android 8.0 Oreo update for the S8? Though @davidcox70 appears to be running Android 7.0 and also did mention his issue seems to go away when he reverts to the older Google VR Services - which is also the behavior I see on my Moto Z (Android 7) and Pixel XL (Android 8).. @sigmaxipi Does the new configuration change only apply to Exynos-based Daydream phones? Or is it possible this could also affect Qualcomm devices? If it's only the Exynos chipset, then maybe we should create a specific ticket for that, since this original ticket is sounding like a different underlying issue but just happens to manifest the same behavior.\nAlso, would you be able to provide any details on what the Exynos configuration change actually is? I'm just curious. Thanks.. ",
    "Grief": "@jdduke it was opened earlier than #484 but whatever. ",
    "TheDeveloperGuy": "@nathanmartz Thanks! My content is being rendered and lens corrected etc. already, so I could use the GVR rendering to display my content, without any distortion or anything else done to it, right?\nThe GVR head-tracking is vastly superior to any kind of built-in orientation tracking on Android, so I'd like to use it.. ",
    "nlebeck": "Hi Philip, re-binding the texture in the onDrawEye method fixed the problem. Documentation of that behavior would be great. Thanks!. ",
    "mug797": "Thanks for the super quick response. :-)\nWill I need to turn off timewarp (disable async reprojection) to do this? From what I understand, for every vsync google vr sdk will do timewarp on the submitted frame correct? For which it will use the headpose passed in the submit call of the frame?\nThanks again.. ",
    "leocavalcante": "Samsung S8\nSDK v1.30.0. ",
    "LoSealL": "@jdduke Got a same issue, where error message came out as: \n\nError:Exception thrown while executing model rule: BaseComponentModelPlugin.Rules#createVariantData(ModelMap, ModelMap, TaskManager) > afterEach()\nConsult IDE log for more details (Help | Show Log). I can build the project successfully now.\nWith\n- gvr-android-sdk v1.120.0\n- Android Studio 3.0.1\n- gradle 4.1\n- com.android.tools.build:gradle-experimental:0.11.1\n\nSome issues came from connection timeout while resolving dependencies.. ",
    "deepuprs": "Any Solution for this?\nI am facing same issue.. This issue happens in below setup.\nAndroid Studio v3.0.1\ngvr-android-sdk v1.120.0\nbuild.gradle ==> classpath 'com.android.tools.build:gradle-experimental:0.11.1\ngradle/wrapper/gradle-wrapper.properties ==> distributionUrl=https\\://services.gradle.org/distributions/gradle-4.1-all.zip\nIt got resolved after downgrading the gradle version to:\nbuild.gradle ==> classpath 'com.android.tools.build:gradle-experimental:0.9.3\ngradle/wrapper/gradle-wrapper.properties ==> distributionUrl=https\\://services.gradle.org/distributions/gradle-3.3-all.zip. ",
    "Adam-VisualVocal": "Thanks, but that only works on the Pixel phones. On the Samsung Galaxy S8 series there is no setting to reduce flicker as far as I know. Because some OEMs aren\u2019t exposing this setting, we need an API to control it programmatically.\nMaybe some phones have problems with motion blur but nobody on my team has ever noticed it on the Pixel or S8 when in VR so why default to low persistence? It only makes the display dim and flickery for 100% of the people I've shown this to.\nWhen I do an A/B comparison for people they always prefer the less flicker setting (low persistence turned off). Being stuck in low persistence mode with no way to disable it on some phones like the S8 is a killer.\n. For the moment, ours is a Cardboard app so we're using a range of viewers. Yes, the flicker is visible without a viewer but it's very visible with a viewer as well. Our app is used to view architectural renders, which frequently are done in shades of grey. Unfortunately, those shades tend to accentuate the flicker even more.\nThanks for asking Samsung to do something about exposing the setting. That'll help. I'm still not thrilled about having to show a pop up window asking \"Is your display flickering? If yes, then navigate to this place on a Pixel phone or that place on a Samsung and change the setting from this to that.\" It really would be better if we could put a toggle directly into our app and also be able to control the default setting.. Is there a way to still use Cardboard in stereo without enabling VR?. Very interesting. Thanks for that. I'll have to see if I can use that in Unity.. No. The best we've been able to do is just direct our customers to the display settings on the phone and ask them to switch the \"When device is in VR\" setting to \"Reduce flicker\" instead of the default \"Reduce blur\". That's not ideal obviously and it only works if the phone actually exposes that setting. Pixel phones do and I think Samsung phones do too but I don't know about the other Daydream-capable phones out there.. Hi Jared,\nMy company makes a VR business communication app aimed at architecture and construction and we bundle a specific VR viewer with it. Like this: http://www.visualvocal.com/\nWe recognize the importance of not automatically overriding the user's selected VR viewer. I totally get that. However, we'd really like to make it easy for our customers to configure our app to use the bundled viewer via a prompt and button that we show at startup. Something like, \"Tap here to use the bundled viewer. [OK]\". Right now the best we can do is dump them into the Android VR Settings UI which can be a bit bewildering for a first-time user.\nWhat about introducing a new permission that allows apps to set the viewer? (e.g. CONFIGURE_VR_VIEWER) That would mostly protect against malicious apps but would allow a better user experience for business apps like Visual Vocal.\nThanks,\nAdam. Hi Nathan,\nWe do set the default viewer and that's fine for some customers. However, we've found that the viewer is already set right out of the factory for some phones like the Samsung Galaxy 8 series and the original Pixel. To test, just factory reset a Pixel or S8 and try to call gvr_set_default_viewer_profile and it'll return false.\nWe also have trouble with people who have Daydream headsets. Any time their phone gets within NFC distance of the Daydream headset the phone automatically switches to Daydream. Then we have to send them to the VR Settings UI to switch back. It'd be so much nicer for them if we could just let them mash a button to switch back to our viewer.\nThanks,\nAdam. Hi Jared,\nThanks, I'll take what I can get. :-) I think that would help streamline our user experience but only if the following assumptions are true:\n\ngvr_set_default_viewer_profile would succeed even on factory fresh/reset Daydream phones. However, it's hard to see how it could without the customer upgrading to the latest Google VR Services. Even then, I figure it would only succeed if the user hadn't already chosen another headset.\nCalling gvr_set_default_viewer_profile would result in that viewer being added to the \"Recent\" list in the GVR Services UI.\n\nAm I correct?\nAlso, I don't see the \"Recent\" list in Google VR Services 1.10.172754103 (latest from Play Store). Is that something you'll be releasing in the near future?\nThanks,\nAdam. Our app is written in Unity so we're using the Unity SDK, That limits us a bit, of course, although I'm not totally above calling into the version of the Android SDK packaged with the Unity SDK. However, it looks like GvrView isn't included with nor exposed by the Unity SDK unfortunately.\nRegarding HeadMountedDisplayManager, I've stopped trying to use it. Since it's not bundled into the Unity SDK using it wasn't going to be possible without some scary hacks. ;-). Hi Nathan,\nWe do use SetViewerProfile but unfortunately we've found that the original Pixel and the Samsung Galaxy S8 both come from the factory with a viewer already paired. Perhaps this applies to all Daydream phones but I'm not sure.\nThanks,\nAdam. I have version 1.9 which says February 12. I'm not being offered anything more recent though.\n\n. ",
    "dorcatty": "Hello Adam, I got the same issue with some low cost android OEM system. Do you have any idea about how to solve this 'low persistence' with GVR SDK ? thanks . @Adam-VisualVocal thanks a lot for your tips. My case is different than yours. We are looking for some low cost Android phones with 'low persistence' enabled to run some GVR scenes. However, when we tested with Huawei P20, there's no 'low persistence' option in the OEM system.  Do you think we can disable this function manually or from Unity3D? While testing with the same GVR scene, our Samsung S9++ works well, we dont have the motion sickness at all. \n. ",
    "davidcox70": "I was wondering if there is an update on this issue? I started to encounter \"sticky\" head tracking with an ongoing Unity / Google DayDream app project, tested on a Galaxy S8.  I further found that the DayDream home environment similarly suffered from \"sticky\" head tracking where it hadn't done so previously. \nI found that if I uninstalled all updates from Google VR Services (1.10.172754103), which dropped it back to version 1.6x, motion smoothness returned in my app, albeit now incompatible with DayDream due to the roll back.\nAm I correct to be waiting for a fix for Google VR Services or is there something I have missed?\nThanks for your help.\nDC. Hi Guys - thanks for the responses.\nThe symptoms are that as you turn your head, the motion is not smooth because an occasional single frame does not seem to be rendered correctly with regard to the viewing angle. It feels like the view has jumped to a slightly different angle for a single frame, causing a momentary break in the smooth motion. I suspect what I am seeing is a frame rendered out of sequence. Imagine watching a sequence that went frame 1,2,3,4,3,6,7. I come to this suspicious because if I move my head left/right, the \"jump\" is horizontal. If I move my head up down, the jump is vertical. No jumps are apparent in a static scene without head motion.\nThe frequency of this anomaly is that a frame will be \"dropped\" between every couple of seconds, through to several times a second. It is commonplace to see it from the start.\nI have noticed the symptoms in an app I am developing in Unity, but also the Day Dream home environment and even the \"blue mountain-scape\" initial Day Dream scene.\nAdditionally, there are much less frequent occurrences where the head tracking appears to freeze for up to 1/2 second (although usually for less time). At such times, the scene rotates with the head movement (i.e. the scene is locked to the head turn without a viewing angle change).\nThese behaviours seems to have been introduced in the last couple of weeks as I did not experience any problems prior. I note that Google VR Services was updated on October 19th, so perhaps this is relevant. As I mentioned, uninstalling all updates for Google VR Services, which drops it back to version 1.6x, does allow my app to run smoothly.\nMy test device is a Samsung Galaxy S8 Model SM-G950F\nAndroid Version 7.0\nKernel 4.4.13-12050265\nDaydream version 1.10.170912063\nGoogle VR Services Version: 1.10.172754103\nThanks for your thoughts about this.\nDC\n. @sigmaxipi  Thanks for investigating. I can confirm that when the performance HUD is enabled, the \"flash\" frames are replaced by red frames (and corresponding lines on the time display), indicating that they are indeed the result of VMisses.\nI thought I started to see it before 1st November, but I could be wrong. I was in a period of completing a game and seeing how far I could push additional graphics before it caused performance issues, so perhaps any earlier issues were self-induced. . ",
    "markqvist": "I'm a thinking that this started before november 1st as well. I remember I first noticed it in a WebVR photo viewer I'm working on, but shrugged it off for a while, since I figured it was just something local on the phone I was testing with. It wasn't until a few days ago that I noticed the issue was present on all Exynos S8 devices I had.\nHaving just cleared the data for Google VR Services seems to have helped in some apps, and the home screen, but not all. Chrome in VR is for example still exhibiting the issue very heavily.. ",
    "diegobez": "Having the same issues. A Samsung Exynos s8, performance monitoring on, and a lot of vsync misses at Daydream Home. ( lots of red stripes ).. ",
    "benvrakas": "as of today the problem persists exactly as described. i am able to get smooth performance on older versions of GVR, but with the currently available versions of daydream and gvr, i experience massive stuttering caused by up to 6 dropped frames every second. any fix in sight?\nGalaxy S8 exynos (g950F)\nproject alice rom, stock kernel (debloated rom) \nandroid 7.1.1 . @jdduke I have done as you asked.. ",
    "xxXFalvorSaviorXxx": "Same issue on my Galaxy Note 8 (Exynos variant).\nDaydream is literally unusable because the jittering causes severe discomfort. \nThe performance Monitor also shows several VSync misses on Daydream Home and several other applications. . @jdduke Can confirm, its fixed on my Galaxy S8 and Note 8 Exynos. Runs totally fine now in most apps!\nThere are exceptions like the \"Daydream Elements\" app with occasional stutters, although its much better than before.  . ",
    "gtaadicto": "I still have the jitter and a lot of missed frames on my exynos note8 on android 7.1.1.\nThe daydream version is 1.13.180130063 and google vr services 1.13.185188193\nAltspace VR and Chrome WebVR are still unusable. \nWhat can I do?. ",
    "netkawai": "I mistakenly posted the wrong log portion.\nI saw the log again.\n10-14 08:23:06.751 19477-19477/? E/dalvikvm: Could not find class 'android.util.Range', referenced from method ckn.\n10-14 08:23:06.756 19477-19477/? E/AndroidRuntime: FATAL EXCEPTION: main\n                                                   Process: com.google.vr.vrcore, PID: 19477\n                                                   java.lang.NoClassDefFoundError: android.util.Range\n                                                       at ckn.(PG:61)\n                                                       at com.google.vr.vrcore.common.VrCoreSdkService.onCreate(PG:8)\n                                                       at android.app.ActivityThread.handleCreateService(ActivityThread.java:2821)\n                                                       at android.app.ActivityThread.access$1900(ActivityThread.java:175)\n                                                       at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1390)\n                                                       at android.os.Handler.dispatchMessage(Handler.java:102)\n                                                       at android.os.Looper.loop(Looper.java:146)\n                                                       at android.app.ActivityThread.main(ActivityThread.java:5602)\n                                                       at java.lang.reflect.Method.invokeNative(Native Method)\n                                                       at java.lang.reflect.Method.invoke(Method.java:515)\n                                                       at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1283)\n                                                       at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1099)\n                                                       at dalvik.system.NativeStart.main(Native Method)\ncom.google.vr.vrcore.common.VrCoreSdkService.onCreate called android.util.Range class which added in API Level 21, even though this is very simple API but does not exist in API Level 19.. ",
    "kush7d": "What is the status of this situation?. ",
    "liquid8d": "I was able to test this again and I am no longer having this issue. Not sure if a fix was implemented, but this is likely a different controller emulator version, unity version, updated controller firmware, etc. than originally reported.. ",
    "riadhnet": "the exemple doesn't show how to add any element on top of the full screen , you just mentioned the simple without responding to the issue , i don't think this should be closed . @sigmaxipi  Would this work for non daydream compatible phone? Just like VrVideoView?\nOn Feb 26, 2018 11:58 PM, \"SxP\" notifications@github.com wrote:\n\n@riadhnet https://github.com/riadhnet , see\nhttps://developers.google.com/vr/android/samples/video360 for\ninformation. The second screenshot shows a floating UI in VR.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/googlevr/gvr-android-sdk/issues/488#issuecomment-368681590,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ADTFUQ4hUqjQvg61JcfodpKwHlmyHBgwks5tYzchgaJpZM4QIuli\n.\n. \n",
    "fernandojsg": "I was able to reproduce the same issue on a S8. ",
    "aleyooop": "Basic congo from sample, some other vids, it's all the same. For example, on xiaomi redmi 4 pro fullscreen stereo switching works perfect every time, but we have to use samsung, so how to handle that?. ",
    "nikolas1802": "How do you fix this issue?. ",
    "ethanlee27": "I'm facing the same issue while using version 1.120.0 ,\nI've tested asus zenphone 3, nexus 5X will show black screen on 1.120.0,  but version 1.40.0 works fine. samsung S7 edge is good on 1.120.0.\nAny update?. ",
    "enginegl": "@jdduke thanks, uiMode resolves the problem, but only for VrActivity. So, we need to add this flag for both of activities to achieve desired behaviour.. ",
    "aclockworkkelly": "Hi,\nThanks for reporting this. In order to better track this down, I'd appreciate it if you could provide me with a little more information.\nCould you attach the offending file, and perhaps past in the function calls you are making to gvr audio?\nCheers,\nIan. ",
    "njudit8": "Hi @jdduke, \nGoogle VR Services version 1.10.172754103\nGoogle VR SDK  v1.101.0\nThanks.. Updating to the latest version of Google VR Services has still not resolved the issue.\nAny suggestions?. @Carlos-CR Thanks! For some reason, changing the resolution to WQHD solved the issue. \n@jdduke  Although the bug does not appear on WQHD anymore, it is still present on lower resolutions. This is highly problematic on S7, due to another bug (switching to a lower resolution, even WQHD is shown as the set resolution).\nYes, same problem with the SDK sample, and updating to the latest release did not help.. ",
    "guoyuanzhuang": "Thanks 666. android model: HuaWei honor8, Version: 7.1\nlaunch logs:\n01-11 12:36:00.562 5831-5831/? I/art: Late-enabling -Xcheck:jni\n01-11 12:36:00.562 5831-5831/? I/art: Reinit property: dalvik.vm.checkjni= false\n01-11 12:36:00.572 5831-5831/com.gameobject.vr D/ActivityThread: ActivityThread,attachApplication\n01-11 12:36:00.753 5831-5831/com.gameobject.vr I/InstantRun: starting instant run server: is main process\n01-11 12:36:00.754 5831-5831/com.gameobject.vr V/InstantRun: Starting server socket listening for package com.gameobject.vr on android.net.LocalSocketAddress@f5f9bd8\n01-11 12:36:00.754 5831-5831/com.gameobject.vr V/InstantRun: Started server for package com.gameobject.vr\n01-11 12:36:00.776 5831-5831/com.gameobject.vr I/HwCust: Constructor found for class android.app.HwCustActivityImpl\n01-11 12:36:00.776 5831-5831/com.gameobject.vr D/HwCust: Create obj success use class android.app.HwCustActivityImpl\n01-11 12:36:00.779 5831-5831/com.gameobject.vr V/HwPolicyFactory: : success to get AllImpl object and return....\n01-11 12:36:00.781 5831-5831/com.gameobject.vr I/HwCust: Constructor found for class android.app.HwCustHwWallpaperManagerImpl\n01-11 12:36:00.781 5831-5831/com.gameobject.vr D/HwCust: Create obj success use class android.app.HwCustHwWallpaperManagerImpl\n01-11 12:36:00.785 5831-5831/com.gameobject.vr V/HwWidgetFactory: : successes to get AllImpl object and return....\n01-11 12:36:00.787 5831-5831/com.gameobject.vr V/ActivityThread: ActivityThread,callActivityOnCreate\n01-11 12:36:00.801 5831-5831/com.gameobject.vr E/Unity: Unable to find main\n01-11 12:36:00.820 5831-5831/com.gameobject.vr D/HwSensorManager: HwSensorManager version: 1.0.0\n01-11 12:36:00.841 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.23, mControlPoint1y = 0.06, mControlPoint2x = 0.09, mControlPoint2y = 0.97\n01-11 12:36:00.842 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.6, mControlPoint1y = 0.9, mControlPoint2x = 0.8, mControlPoint2y = 1.0\n01-11 12:36:00.842 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.23, mControlPoint1y = 0.06, mControlPoint2x = 0.09, mControlPoint2y = 0.97\n01-11 12:36:00.842 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.6, mControlPoint1y = 0.9, mControlPoint2x = 0.8, mControlPoint2y = 1.0\n01-11 12:36:00.848 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.23, mControlPoint1y = 0.06, mControlPoint2x = 0.09, mControlPoint2y = 0.97\n01-11 12:36:00.849 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.6, mControlPoint1y = 0.9, mControlPoint2x = 0.8, mControlPoint2y = 1.0\n01-11 12:36:00.849 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.23, mControlPoint1y = 0.06, mControlPoint2x = 0.09, mControlPoint2y = 0.97\n01-11 12:36:00.849 5831-5831/com.gameobject.vr D/CubicBezierInterpolator: CubicBezierInterpolator  mControlPoint1x = 0.6, mControlPoint1y = 0.9, mControlPoint2x = 0.8, mControlPoint2y = 1.0\n01-11 12:36:00.857 5831-5831/com.gameobject.vr D/HwRTBlurUtils: check blur style for HwPhoneWindow-, themeResId : 0x010302d7, context : android.view.ContextThemeWrapper@5a66fb4, Nhwext : 0, get Blur : disable with , null\n01-11 12:36:00.866 5831-5831/com.gameobject.vr I/HwPointEventFilter: do not support AFT because of no config\n01-11 12:36:00.881 5831-5831/com.gameobject.vr D/HwRTBlurUtils: check blur style for HwPhoneWindow-, themeResId : 0x7f070004, context : com.gameobject.vr.UnityPlayerActivity@ba7ee9e, Nhwext : 0, get Blur : disable with , null\n01-11 12:36:00.881 5831-5831/com.gameobject.vr D/HwRTBlurUtils: check blur style for HwPhoneWindow-, themeResId : 0x7f070004, context : com.gameobject.vr.UnityPlayerActivity@ba7ee9e, Nhwext : 0, get Blur : disable with , null\n01-11 12:36:00.882 5831-5831/com.gameobject.vr D/ActivityThread: add activity client record, r= ActivityRecord{d68ed7f token=android.os.BinderProxy@487f797 {com.gameobject.vr/com.gameobject.vr.UnityPlayerActivity}} token= android.os.BinderProxy@487f797\n01-11 12:36:00.889 5831-5831/com.gameobject.vr I/HwPointEventFilter: do not support AFT because of no config\n01-11 12:36:00.894 5831-5831/com.gameobject.vr I/ActivityManager_activity: Resuming ActivityRecord{d68ed7f token=android.os.BinderProxy@487f797 {com.gameobject.vr/com.gameobject.vr.UnityPlayerActivity}} with isForward=true,forwardBitChanged=false onlyLocalRequest=false\n01-11 12:36:00.928 5831-5858/com.gameobject.vr I/OpenGLRenderer: Initialized EGL, version 1.4\n01-11 12:36:00.928 5831-5858/com.gameobject.vr D/OpenGLRenderer: Swap behavior 1\n01-11 12:36:00.936 5831-5858/com.gameobject.vr W/linker: /vendor/lib64/libhwuibp.so: unused DT entry: type 0xf arg 0xe3a\n01-11 12:36:00.937 5831-5858/com.gameobject.vr D/OpenGLRenderer: loaded so path=libhwuibp.so handle=0x3a675548d769b4f5\n01-11 12:36:00.940 5831-5858/com.gameobject.vr D/mali_winsys: EGLint new_window_surface(egl_winsys_display*, void*, EGLSurface, EGLConfig, egl_winsys_surface**, egl_color_buffer_format*, EGLBoolean) returns 0x3000\n01-11 12:36:00.959 5831-5858/com.gameobject.vr D/mali_winsys: EGLint new_window_surface(egl_winsys_display*, void*, EGLSurface, EGLConfig, egl_winsys_surface**, egl_color_buffer_format*, EGLBoolean) returns 0x3000\n01-11 12:36:00.972 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 240518168576\n01-11 12:36:00.975 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 8864812498944\n01-11 12:36:00.975 5831-5858/com.gameobject.vr D/HwuiUseBinaryProgram: Key: 8864812498944 has not found in mBinaryEntries, Compile it.\n01-11 12:36:00.976 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 8830452760579\n01-11 12:36:00.976 5831-5858/com.gameobject.vr D/HwuiUseBinaryProgram: Key: 8830452760579 has not found in mBinaryEntries, Compile it.\n01-11 12:36:00.991 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 0\n01-11 12:36:01.005 5831-5831/com.gameobject.vr I/ActivityManager_activity: Reporting idle of ActivityRecord{d68ed7f token=android.os.BinderProxy@487f797 {com.gameobject.vr/com.gameobject.vr.UnityPlayerActivity}} finished=false\nThe APP displays the dialog: Failure to Initialize! Your hardware does not support this application, sorry!  Click OK to exit APP\n```\n01-11 12:49:50.121 5831-5831/com.gameobject.vr I/hwaps: JNI_OnLoad\n01-11 12:49:50.215 5831-5831/com.gameobject.vr V/AudioManager: playSoundEffect   effectType: 0\n01-11 12:49:50.215 5831-5831/com.gameobject.vr V/AudioManager: querySoundEffectsEnabled...\n01-11 12:49:50.215 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 68719476736\n01-11 12:49:50.307 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 8899177480260\n01-11 12:49:50.307 5831-5858/com.gameobject.vr D/HwuiUseBinaryProgram: Key: 8899177480260 has not found in mBinaryEntries, Compile it.\n01-11 12:49:50.328 5831-5858/com.gameobject.vr E/OpenGLRenderer: allen debug liyu Key: 103084458052\n01-11 12:49:52.575 5831-5831/com.gameobject.vr W/Unity: Not running Google VR from an Activity; Ignoring execution request...\n01-11 12:49:52.577 5831-5831/com.gameobject.vr D/AndroidRuntime: Shutting down VM\n01-11 12:49:52.579 5831-5831/com.gameobject.vr E/AndroidRuntime: FATAL EXCEPTION: main\n                                                                 Process: com.gameobject.vr, PID: 5831\n                                                                 java.lang.Error: FATAL EXCEPTION [main]\n                                                                 Unity version     : 5.6.5f1\n                                                                 Device model      : HUAWEI PRA-AL00\n                                                                 Device fingerprint: HONOR/PRA-AL00/HWPRA-H:7.0/HONORPRA-AL00/C00B183:user/release-keys\n                                                             Caused by: java.lang.RuntimeException: Unable to destroy activity {com.gameobject.vr/com.gameobject.vr.UnityPlayerActivity}: java.lang.NullPointerException: Attempt to invoke virtual method 'boolean android.os.Handler.sendMessage(android.os.Message)' on a null object reference\n                                                                 at android.app.ActivityThread.performDestroyActivity(ActivityThread.java:4398)\n                                                                 at android.app.ActivityThread.handleDestroyActivity(ActivityThread.java:4417)\n                                                                 at android.app.ActivityThread.-wrap6(ActivityThread.java)\n                                                                 at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1629)\n                                                                 at android.os.Handler.dispatchMessage(Handler.java:105)\n                                                                 at android.os.Looper.loop(Looper.java:156)\n                                                                 at android.app.ActivityThread.main(ActivityThread.java:6523)\n                                                                 at java.lang.reflect.Method.invoke(Native Method)\n                                                                 at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:941)\n                                                                 at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:831)\n                                                              Caused by: java.lang.NullPointerException: Attempt to invoke virtual method 'boolean android.os.Handler.sendMessage(android.os.Message)' on a null object reference\n                                                                 at android.os.Message.sendToTarget(Message.java:421)\n                                                                 at com.unity3d.player.UnityPlayer$c.a(Unknown Source)\n                                                                 at com.unity3d.player.UnityPlayer$c.a(Unknown Source)\n                                                                 at com.unity3d.player.UnityPlayer.quit(Unknown Source)\n                                                                 at com.gameobject.vr.UnityPlayerActivity.onDestroy(UnityPlayerActivity.java:44)\n                                                                 at android.app.Activity.performDestroy(Activity.java:7136)\n                                                                 at android.app.Instrumentation.callActivityOnDestroy(Instrumentation.java:1158)\n                                                                 at android.app.ActivityThread.performDestroyActivity(ActivityThread.java:4385)\n                                                                 at android.app.ActivityThread.handleDestroyActivity(ActivityThread.java:4417)\u00a0\n                                                                 at android.app.ActivityThread.-wrap6(ActivityThread.java)\u00a0\n                                                                 at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1629)\u00a0\n                                                                 at android.os.Handler.dispatchMessage(Handler.java:105)\u00a0\n                                                                 at android.os.Looper.loop(Looper.java:156)\u00a0\n                                                                 at android.app.ActivityThread.main(ActivityThread.java:6523)\u00a0\n                                                                 at java.lang.reflect.Method.invoke(Native Method)\u00a0\n                                                                 at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:941)\u00a0\n                                                                 at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:831)\n\n01-11 12:49:52.582 5831-5831/com.gameobject.vr I/Process: Sending signal. PID: 5831 SIG: 9\ngradle config:\napply plugin: 'com.android.application'\n// GENERATED BY UNITY. REMOVE THIS COMMENT TO PREVENT OVERWRITING WHEN EXPORTING AGAIN\nbuildscript {\n    repositories {\n        jcenter()\n        google()\n    }\ndependencies {\n    classpath 'com.android.tools.build:gradle:3.0.0'\n}\n\n}\nallprojects {\n   repositories {\n       jcenter()\n       google()\n       maven { url \"https://jitpack.io\" }\n      flatDir {\n        dirs 'libs'\n      }\n   }\n}\ndependencies {\n    compile fileTree(dir: 'libs', include: ['.jar'])\n    / Google VR */\n    implementation 'com.google.vr:sdk-panowidget:1.101.0'\n    implementation 'com.google.vr:sdk-videowidget:1.101.0'\n}\nandroid {\n    compileSdkVersion 25\n    buildToolsVersion '26.0.2'\ndefaultConfig {\n    targetSdkVersion 25\n    applicationId 'com.gameobject.vr'\n}\n\nlintOptions {\n    abortOnError false\n}\n\naaptOptions {\n    noCompress '.unity3d', '.ress', '.resource', '.obb'\n}\n\n\nbuildTypes {\n    debug {\n        jniDebuggable true\n    }\n    release {\n        // Set minifyEnabled to true if you want to run ProGuard on your project\n        minifyEnabled false\n        proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-unity.txt'\n\n    }\n}\n\n}\n```\nBefore I think it is Android gvr and unity gvr conflict problem, After I tried removing unity gvr, the project is still not working properly, I continue to try to remove Android gvr, the project is normal,I now doubt the problem between Android gvr and unity,I do not know what to do? thanks for your help. Supplementary problems:\nhttps://github.com/guoyuanzhuang/unity_android_demo\nThis is a very common Android project I exported from unity, which does not rely on any gvr correlation in the unity project. It is normal to run directly, but after joining gvr in the Android project, the problem arises.\n. ",
    "franckos": "Same problem here\n@jdduke Did you succed on repackage gvr-common without conflicting classes?\nWould you be able to send the resulting aar file btw?\nThks in advance. ",
    "ramonaharrison": "Is there a target date for the release that will remove this conflict?. ",
    "pnemonic78": "I signed it!\n. ",
    "reklof": "Thanks, attached the log\nlog.txt\n. ",
    "rickardeklof": "To give you some more information, Googles flagship phone Pixel2 XL is the only phone so far that exhibit serious issues with the rendering. The following three issues are only prevalent on Pixel2 XL. No other phone exhibits these issues.\nNOTE: Only drawing the mesh without using GVR works flawlessly on Google Pixel 2 XL. Only when using both together, the following issues appear:\n\n\nOnly drawing small part of the mesh\n\n\n\nCorruption of normals in some parts of mesh (the banded lines are also incorrect, but less bad than the rest)\n\n\n\nCorrupted normals in in banded lines (same as in 2 above)\n\n\n\nThe Xiaomi A1 exhibits the issue below:\n\nStrange colors on parts of the mesh\n\n\n. @jdduke Thanks for the support. We are using the NDK version. Started out from the treasurehunt-ndk sample. I can send you the files you need, just send me an email to send to. rickard dot eklof at techleaf dot se.. ",
    "leapfrog-santosh": "@sigmaxipi : Thank you. This stackoverflow answer can be used for properly selecting views with controller . My bad, there is VrEventListener to handle that. Sorry.. ",
    "ptran-gpfw": "Hi @jdduke, regarding your comment:\n\nMost x86 devices can consume the native arm libraries that we ship.\n\nIs this a general Android feature? An x86 Android device like a Chromebook could run an Android app that is packaged with only arm libs?. On Samsung Note 8 (US, SM-N950U1, Android v7.1.1), I still observe this with release 1.130.0.\n\n03-21 17:02:20.243 12067-15854/smarty W/native: orientation_filter.cc:399 SensorFusion: Mag sample is too old: 0.00494385\n\n(@jdduke). ",
    "nyankosoft": "I am having an issue that looks similar to this. My environment is this:\nOS: Ubuntu 16.04 LTS 64-bit\nAndroid Studio: 3.0.1\nTo elaborate a little more, the errors sjfricke posted (jni.h/asset_manager.h missing) happen on my computer when I run './gradlew build' from the terminal. When I build the project from Android Studio by selecting Build -> Make Project, it causes errors saying headers such as android/log.h and EGL/egl.h are missing. I ran the find command on all of these 4 headers and all of them exist in the SDK's 'ndk-bundle/sysroot/usr/include' directory.\nNDK settings on my PC should be good; when I create a sample hello world NDK project using the Android Studio, it builds apks files without any problem and they work on my Moto G5 Plus just fine.\nAs the NDK treasurehunt sample is the one I need, I extracted it and copied their source files and other library files onto a functioning hello world NDK project, then edited the build.gradle so that treasurehunt source files are compiled and linked (see below). After some troubleshooting, my rip-off copy of NDK treasurehunt demo now runs on my Moto. So the answer should be somewhere in the differences between the original Google VR SDK's treasurehunt and my rip-off version.\nhttps://github.com/nyankosoft/nyanko-ndk-treasurehunt\n. SDK Manager says my NDK is version 16.1.4479499, so if this is the NDK version you are referring to, yes, this is probably the cause. Personally, I've got the sample I needed (ndk treasurehunt demo) working by adapting it to my current NDK 16.1, so I'm leaning toward developing the situation more with it, but thanks anyway.\n\n. ",
    "cversek": "Thanks for the info.  The system update might also explain why my stimuli brightness mysteriously doubled overnight.  Yeah, low persistent mode is a real thorn in my side.  The fact that you guys let us turn it off was a major motivator for me to switch away from GearVR.  Giving power back to the developers is totally the way to spur innovation in this largely entertainment driven platform.  In the meantime I guess I can rollback the system or learn how to make custom builds.. Just wanted to get confirmation on this:  you weren't suggesting that developers could already change Settings.System.SCREEN_BRIGHTNESS_FOR_VR in Android O?  If you were, then maybe some help is needed for this novice Android dev.  I upgraded my API to 27, but  I get this compiler error Error:(280, 70) error: cannot find symbol variable SCREEN_BRIGHTNESS_FOR_VR.  . So, I've been reading up on hidden Settings, seems like the developer can possibly change these with some hoop jumping.  Although my naive attempt:\njava\nSettings.System.putInt(cResolver, \"screen_brightness_for_vr\", newBrightness);\ncrashed my app:\nE/AndroidRuntime: FATAL EXCEPTION: main\nProcess: com.neurofieldz.template, PID: 21130\njava.lang.RuntimeException: Unable to start activity ComponentInfo{com.neurofieldz.template/com.neurofieldz.template.TemplateActivity}: java.lang.IllegalArgumentException: You cannot keep your settings in the secure settings.\nat android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2778)\n at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2856)\nat android.app.ActivityThread.-wrap11(Unknown Source:0)\nat android.app.ActivityThread$H.handleMessage(ActivityThread.java:1589)\nat android.os.Handler.dispatchMessage(Handler.java:106)\nat android.os.Looper.loop(Looper.java:164)\nat android.app.ActivityThread.main(ActivityThread.java:6494)\nat java.lang.reflect.Method.invoke(Native Method)\nat com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:438)\nat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:807)\nCaused by: java.lang.IllegalArgumentException: You cannot keep your settings in the secure settings.\nat android.database.DatabaseUtils.readExceptionFromParcel(DatabaseUtils.java:165)\nat android.database.DatabaseUtils.readExceptionFromParcel(DatabaseUtils.java:135)\n at android.content.ContentProviderProxy.call(ContentProviderNative.java:651)\nat android.provider.Settings$NameValueCache.putStringForUser(Settings.java:1851)\nat android.provider.Settings$System.putStringForUser(Settings.java:2273)\nat android.provider.Settings$System.putIntForUser(Settings.java:2378)\nat android.provider.Settings$System.putInt(Settings.java:2372)\nAny help?  I am highly motivated to get this implementation working and don't care about publishing on the app store.\n. My Pixel 2XL device is running Android 8.1 and I'm currently building my app for API 27.   I'm already scaling my asset brightness but the low end of the scale is still too bright.  From my understanding on the Pixel 2 OLED display the overall screen brightness setting is implemented by PWM around 240Hz - this should work for our app and allow much more brightness variation on the low end.  \nYes, disabling low persistence is a user controlled setting, but we are our own users so to speak (anyway I imagine this can be toggled programmatically with WRITE_SETTINGS permission).  The system will be configured for our special purposes and we will not be distributing through the app store.  With that in mind, is building a custom android SDK a reasonable choice?  Or how about accessing hidden APIs via Java reflection and what can we get away with using the most promiscuous permissions?. Hi again,\n  We just got a hold of a Pixel 3 and are testing our app with low-persistence turned off.  (We have \"Reduce Flicker\" set ON.)  We are running Android 9.0.  When going into VR mode the white screen brightness reduces from are 630lux to around 290lux, so there is considerably less range than on our Pixel2XL running Android 8, where we get up to around 680lux at the screen surface.  Any update about whether developer or user settings can override this limitation in Android P? . ",
    "cynicer": "I'm just facing the same problem. What the hell, why is this (still) a hidden API?. ",
    "damianMolinski": "Thanks for response,\nThis is exactly what i was looking for.  . ",
    "btelman96": "As I believe I am having the same issue, I will post this here, but this could be a different issue.\nI am having this issue only for Non-stereo mode on devices that support daydream headsets. Cardboard only devices are fine, with or without google vr services. VR Mode works correctly on all devices.\nI have tested this on Pixel, Moto Z, Asus Zenfone AR, Galaxy S8, Pixel XL 2, and all have this issue. I am also using same code, but rotations work just fine on devices that do not support daydream. Setting headset to cardboard device does not change this, but disabling GoogleVr services fixes it. using eye.getEyeView() does not seem to change the issue.\nTesting on Nexus 6P, Galaxy S7, LG G3 shows correct rotation. Also Disabled google vr services and noticed that rotation worked normally again on devices that support daydream.\nThe next two charts are converted to degrees and the device barely moved during running the app\nheadTransform.getEulerAngles(orientation, 0) produces:\nGoogleVR Version | pitch | yaw | roll\n-- | -- | -- | --\nDisabled | -32.36363219 | -0.08164681402 | -89.84365264\nUp To Date | -32.3754211 | 0.1750127252 | 0.1752110408\nand eye.getEyeView() still is sideways and produces:\nGoogleVR Version | pitch | yaw | roll\n-- | -- | -- | --\nDisabled | 0.1126451873 | 57.29562925 | -0.06896442005\nUp To Date | 57.29498721 | -0.2629954468 | 0.1474197081\nOrientation is locked to landscape in the manifest.\nAll samples appear to work correctly on devices.\nupdating from com.google.vr:sdk-base: 1.101.0 to 1.120.0 has no change.\nI am using StereoRenderer for mono playback as well, so that may be the issue, but not sure yet. Is there a preferred solution I should be using to not see this for daydream and still keep non-daydream devices functioning the same?\nIf you need more info, let me know. I am unable to link to the code, but may be able to try to create a demo project that is close. Upon initial testing, adding the GvrView.onResume seems to fix it for me. I will report back on Monday after testing on more devices. Works fine now on both daydream and non-daydream.\nEdit: No devices show this issue now after having it added. ",
    "SPGB": "@btelman96 that seems to be what I am experiencing as well. I believe something in Google VR Services 1.13 is the culprit as I am only seeing the issue after upgrading. \nI've been using headTransform to track head position for awhile now, so I am not sure why it would suddenly rotate 90 degrees. @sigmaxipi I could record a video but I'm not sure how helpful it would be, it just looks like normal video playback but rotated.. @jdduke Calling GvrView.onResume() solves the issue for me.\nWithin video playback I allow the user to swap between mono and stereo view modes, so it's worth noting that I have to call .onResume() after each switch as well.. ",
    "shauntc": "I'm experiencing the same issue as far as I can tell.\nOur app bundles both Cardboard and Daydream versions (open in Daydream and get the 3d/Daydream interface, open via app drawer get 2d interface + Cardboard). The strait daydream version works as intended and has the correct head orientation on all devices I've tested. The 2d/Cardboard (which renders from almost the same code path as the 3d/daydream experience) on Daydream ready devices (tested on the Pixel XL and Pixel 2 XL) gets incorrect head orientation (like above) but on non-daydream devices gets the correct head orientation (tested device had Google VR Services 1.13 exactly the same as the Pixel 2 XL tested). \nUninstalling Google VR Services updates fixes this issue on the device I tested it on (Pixel 2 XL).\nWe use the Google VR C++ wrapper api to get the head orientation and a custom 3d engine for rendering\nOur path to get orientation used in rendering:\ngvr_mat4f head_space = m_pGvrApi->GetHeadSpaceFromStartSpaceTransform(m_targetTime);\ngvr_mat4f head_neck = m_pGvrApi->ApplyNeckModel(head_space, 1.0f);\ngvr_mat4f leftEye = MatrixMul(m_pGvrApi->GetEyeFromHeadMatrix(GVR_LEFT_EYE), head_neck);\ngvr_mat4f rightEye = MatrixMul(m_pGvrApi->GetEyeFromHeadMatrix(GVR_RIGHT_EYE), head_neck);. @jdduke We're getting this inside a GvrLayout rendering stereo\nHere's an internal release of one of our apps: https://drive.google.com/file/d/1Nu_PtfA49Iy4jo-IRjctxeO9STuAEnFW/view?usp=sharing\nJust tap through the menus till it brings up a mono view (which is just controlled by touch), in the bottom right there is a button to switch to Stereo view, which is where you will see the problem. \nYou can also open the same app in Daydream mode through the daydream app and see that it works correctly there\nI'll have my eye on this tomorrow so if you need any other details, let me know. adding .onResume() fixed it for us \u2705\nThanks @jdduke . ",
    "Zanfas": "Okay thank you a lot for your quick answer and your advices. Would you be interrested in a feedback if i get any result ?\n. Okay so using the video360, i've been able to do some planar projection by changing two parameters in the sample (the field of view). Yet, the result was not great and i found a few days ago a solution to display normal stereoscopic videos by using a GvrView and a custom implementation of StereoRenderer.\nThe cause of my problem was that i did not understand how the Google VR SDK works and how the renderring was done but now it is fine.\nThank you again for your attention and your advices. ",
    "carlyonj": "Doing that gives me the error \nDuplicate zip entry [classes.jar:com/google/android/aidl/BaseProxy.class]\nwhich is probably because arCore and vr use this.\nI am including arCore from library I am including in my app as an aar and the vr is only from the above 3 implementations.\nimplementation (name:'djv16', ext:'aar') implementation 'com.google.ar:core:1.0.0'. ",
    "anokta": "Hi,\nThe GVR audio engine currently does not support playback through a URL directly, i.e., local file path is required to play (preload or stream) the audio file.. ",
    "bluemarvin": "It is a native app using the GVR SDK directly. I just tried to verify that 1.130 was the cause but now I can reproduce on 1.120 as well. Something must have changed in my app but I don't see anything obvious. I've tried adding android:windowSoftInputMode=\"stateAlwaysHidden\" to the activity with no effect. So I guess while upgrading to 1.130 is not the issue the fact that the soft keyboard is covering the VR window is still an issue.\n. One additional data point: My app application can switch between a Launcher activity and a Daydream activity. If I switch back and forth once, the soft keyboard seems to stop showing in VR mode when giving focus to a text edit view.. For anyone else that run into this issue. TextView.setShowSoftInputOnFocus(false) seems to work.. ",
    "fanrenyi": "on my mobile\uff0cMeiZu, Rom is FlyMe\uff0cSDK sample (SimplePanoWidget) work bad, it black screen when first load, the  the SDK sample (SimpleVideoWidget) work OK. VrWidgetView as a item off RecycleView, There is a probability of this ANR. ",
    "dkshin": "Thank you!!\nI used this code!\n```\nOrientation orientation = new Orientation(headRotation[0], headRotation[1], headRotation[2], headRotation[3]);\norientation.toRotationMatrix(modelReticle);\nMatrix.multiplyMM(modelViewProjectionMatrix, 0, viewProjectionMatrix, 0, modelReticle, 0);\n```\n. ",
    "dragoono": "For those who are interested in the solution:\nThere is an Option Flag at \npanoOptions = new Options();\npanoOptions.inputType = Options.TYPE_MONO;\npanoWidgetView.loadImageFromBitmap(bitmap, panoOptions);\nOptions.TYPE_MONO works well for my videos and photos . ",
    "Consti10": "The description of \"SPGD\" matches perfectly my problem \"the world shifts into what looks like portrait mode and Looking vertically around the world will move horizontally (and vice versa).\"\nThough there is one big difference: I am not using (and cannot use) the GvrView api. instead, I am using GvrLayout and installing a custom OpenGL View via mGvrLayout.setPresentationView(mGLView14Stereo);\n@1 I am using a ZTE Axon 7. Tested it on a Nexus 5X, too. Same problem (couldnt test the Daydream video texture on it though, of course)\n@2 Activity orientation is set to SCREEN_ORIENTATION_LANDSCAPE both via XML and java in onResume.\n@3 can't tell. But the sudden change in the orientation is already a while ago and possibly already occured in february (only now as I am using the same renderer in Daydream Timewarp mode- which suddenly rearranged the scene) I opened the issue.\nMay it be me installing a custom view in the GvrLayout ? Since that is the only other difference between Vertex displacement distortion correction mode and Daydream Timewarp mode.\nOH MAN: calling \nmGvrLayout.onPause(); and \"resume\" actually re-inverted it.\nI was doing this:\nmGvrLayout.getGvrApi().pauseTracking(); and \"resume\"\nThis fixes it partially. Why partially ? Calling onPause() and onResume() on my gvr layout causes it to crash sometimes when using my custom OpenGL view  (which is doing front buffer rendering with vertex displacement distortion correction, so definitely not common). I will have a look into that and maybe open a new issue on that.\nBut in conclusion: Thanks jdduke, calling onPause() and onResume() on the GvrLayout instance instead of  on the gvrApi instance fixed this problem. \n. 10136-10136 V: BoostFramework() : mPerf = com.qualcomm.qti.Performance@d6e8ba7\n--------- beginning of system\n\n10136-10136 D: fontPath: \n10136-10136 W: commandlineflags.cc:1503 Ignoring RegisterValidateFunction() for flag pointer 0x7f6ec1f688: no flag found at that address\n10136-10136 D: Fetched params from VrParamsProvider: allow_dynamic_java_library_loading: true\n    allow_dynamic_library_loading: true\n    allow_vrcore_compositing: false\n    allow_vrcore_head_tracking: false\n    async_reprojection_config <\n      additional_ahardwarebuffer_usage: 268435456\n      back_rgb16_with_bgr16: true\n      black_boost: 0\n      display_latency_micros: 900\n      flags: 16\n      strips_per_frame: 2\n      vsync_grace_period_micros: 0\n    >\n    cpu_late_latching_enabled: false\n    daydream_image_alignment: 3\n    dim_ui_layer: true\n    disallow_multiview: false\n    enable_forced_tracking_compat: false\n    screen_capture_config <\n      allow_casting: false\n      allow_screen_record: false\n      allow_screenshot: false\n    >\n    touch_overlay_enabled: false\n    use_device_idle_detection: true\n    use_direct_mode_sensors: false\n    use_magnetometer_in_sensor_fusion: true\n    use_online_magnetometer_calibration: false\n    use_stationary_bias_correction: false\n    use_system_clock_for_sensor_timestamps: false\n10136-10136 D: ignored Vulkan layer search path /data/app/com.google.vr.vrcore-1/lib/arm64:/data/app/com.google.vr.vrcore-1/base.apk!/lib/arm64-v8a for namespace 0x7f88810160\n10136-10136 W: getBasePackageName in Asset, index=3, return 'com.google.vr.vrcore'\n10136-10136 W: commandlineflags.cc:1503 Ignoring RegisterValidateFunction() for flag pointer 0x7f69e38828: no flag found at that address\n10136-10136 I: [vr/gvr/capi/src/gvr_core_api_loader_android.cc:182] Successfully loaded GVR library version 1.140.0 from VrCore (target was 1.140.0).\n10136-10136 I: [vr/gvr/capi/src/gvr.cc:103] Initialized GVR version 1.140.0\n10136-10193 D: No Network Security Config specified, using platform default\n10136-10193 I: RegisterTcmMonitor from: com.android.okhttp.TcmIdleTimerMonitor\n10136-10136 I: Successfully loaded GvrLayout from VrCore.\n10136-10136 I: GLThreadManager instance created\n10136-10136 V: BoostFramework() : mPerf = com.qualcomm.qti.Performance@536b66d\n    BoostFramework() : mPerf = com.qualcomm.qti.Performance@92f12a2\n10136-10202 I: Noticed surfaceView surface lost tid=4158\n10136-10136 I: Repro enabled:false\n10136-10136 D: fontPath: \n10136-10136 I: onResume tid=4158\n10136-10136 I: Repro enabled:false\n10136-10182 E: void android::uirenderer::renderthread::CanvasContext::setSurface(android::Surface *) to create EGLSurface constantin.fpv_vr.wifibroadcast/constantin.fpv_vr.activities.Activity_Stereo\n10136-10202 I: Noticed surfaceView surface acquired tid=4158\n10136-10202 D: MSAA Level:4\n10136-10202 I: Noticing that we want render notification tid=4158\n10136-10202 W: egl createSurface\n10136-10202 D: GLSurfaceViewEGL14 MODE:MODE_NORMAL\n10136-10202 W: onEGLContextCreated()\n10136-10202 V: Priority set to -16 in GLRendererStereo\n10136-10207 V: Priority set to -16 in VideoPlayerN VideoReceiver\n10136-10207 V: SetSocketTimeout error\n10136-10208 V: Priority set to -2 in TelRN WB\n10136-10208 V: SetSocketTimeout error\n10136-10202 W: onSurfaceSizeChanged()\n10136-10202 V: already stopped\n    circularRefreshT stopped\n    circularRefreshT started\n10136-10209 V: Priority set to -2 in TextElements\n10136-10202 I: Sending render notification tid=4158\n10136-10136 I: onPause tid=4158\n    onPause waiting for mPaused.\n10136-10202 I: mPaused is now true. tid=4158\n    Releasing EGL surface because paused tid=4158\n10136-10202 I: Releasing EGL context because paused tid=4158\n10136-10202 W: onEGLContextDestroyed()\n10136-10202 I: GL14 del video start\n10136-10202 I: GL14 del video stop\n    GL14 release start\n    GL14 release stop\n10136-10202 V: circularRefreshT stopped\n10136-10136 D: fontPath: \n10136-10136 I: onResume tid=4158\n10136-10136 I: onResume waiting for !mPaused.\n10136-10202 I: mPaused is now false. tid=4158\n10136-10202 D: MSAA Level:4\n10136-10202 W: egl createSurface\n10136-10202 D: GLSurfaceViewEGL14 MODE:MODE_NORMAL\n10136-10202 W: onEGLContextCreated()\n10136-10202 V: Priority set to -16 in GLRendererStereo\n10136-10212 V: Priority set to -16 in VideoPlayerN VideoReceiver\n10136-10212 V: SetSocketTimeout error\n10136-10213 V: Priority set to -2 in TelRN WB\n10136-10213 V: SetSocketTimeout error\n10136-10136 I: Repro enabled:false\n10136-10136 I: onPause tid=4158\n    onPause waiting for mPaused.\n10136-10202 W: onSurfaceSizeChanged()\n10136-10202 V: already stopped\n    circularRefreshT stopped\n    circularRefreshT started\n10136-10214 V: Priority set to -2 in TextElements\n10136-10202 I: mPaused is now true. tid=4158\n    Releasing EGL surface because paused tid=4158\n10136-10202 I: Releasing EGL context because paused tid=4158\n10136-10202 W: onEGLContextDestroyed()\n10136-10202 I: GL14 del video start\n10136-10202 I: GL14 del video stop\n10136-10202 I: GL14 release start\n    GL14 release stop\n10136-10202 V: circularRefreshT stopped\n10136-10136 D: fontPath: \n10136-10136 I: onResume tid=4158\n10136-10136 I: onResume waiting for !mPaused.\n10136-10202 I: mPaused is now false. tid=4158\n10136-10202 D: MSAA Level:4\n10136-10202 W: egl createSurface\n10136-10202 D: GLSurfaceViewEGL14 MODE:MODE_NORMAL\n10136-10202 W: onEGLContextCreated()\n10136-10136 I: Repro enabled:false\n10136-10215 V: Priority set to -16 in VideoPlayerN VideoReceiver\n10136-10202 V: Priority set to -16 in GLRendererStereo\n10136-10215 V: SetSocketTimeout error\n10136-10216 V: Priority set to -2 in TelRN WB\n10136-10216 V: SetSocketTimeout error\n10136-10182 D: endAllActiveAnimators on 0x7f6dfb0800 (RippleDrawable) with handle 0x7f6dfb19c0\n10136-10202 W: onSurfaceSizeChanged()\n10136-10202 V: already stopped\n    circularRefreshT stopped\n    circularRefreshT started\n10136-10220 V: Priority set to -2 in TextElements\n10136-10202 V: OpenGL FPS:54.617676\n10136-10202 V: OpenGL FPS:59.850374\n10136-10202 V: OpenGL FPS:59.410884\n10136-10202 V: OpenGL FPS:59.970015\n10136-10202 V: OpenGL FPS:59.880240 .... I continued debugging around this one issue and came to the root of the problem (I assume) :\nCalling onPause/onResume on the GvrLayout results in 2 unnecessary changes in the activity state.\nE.g while not interacting with the phone in any way after opening the activity via a button on resume() in the activity is actually called 3 times !. I investigated the n of onResume() calls depending on \"skip vr entries\" and which headset !!! is set\nSkip vr entry screens not enabled:\nCardboard headset: onResume() called once (how it should be)\nDaydream view headset: I am unable to use a daydream headset with vertex displacement distortion correction, because the \"entry screen\" doesn't allow me (\"incompatible app: This cardboard application is not compatible with daydream headsets\"). Well, it actually is, but how can I tell gvr that ? \nSkip VR entry screens enabled:\nCardboard headset:  onResume() called once (how it should be) again\nDaydream headset: onResume() called 3 times. So to solve the issue I just needed to be able to tell gvr that my app is compatible with a daydream headset (as long as you don't mind the cromatic aberation, it does the distortion correction also for daydream headsets, and has lower video latency than when using async reprojection). I see. Wouldn't actually clarify my app as a \"Daydream app\" but I would like my users to be able to use it with a \"Daydream headset\". Currently you have to enable the \"skip vr entry screens\" to use my (and probably also all cardboard apps) with a daydream headset.  It would be nice to have some java gvrApi call to basically say \"hey, I am not an daydream app but would like to use the daydream headset as a normal VR headset.\nMy app is for FPV (first person view) aerial drone flight. There latency of the video feed matters the most. \n Therefore I developed a custom front buffer renderer that supports vertex displacement distortion correction & has <20ms input-to-output latency.\nThat was actually 2 years ago. Back then there was no support for a video texture running on the async reprojection thread in Daydream.. For reference: only adding the above didn't change anything, I also had to add <action android:name=\"android.intent.action.MAIN\" /> to my activity. e.g. \n<activity\n            android:name=\".activities.AStereo\"\n            android:screenOrientation=\"landscape\">\n            <intent-filter>\n                <action android:name=\"android.intent.action.MAIN\" />\n                <category android:name=\"com.google.intent.category.DAYDREAM\" />\n            </intent-filter>\n        </activity>\nThis is a bit in contrast with my Apps workflow, which manages settings, establishing a connection to the aircraft usw in 2D (normal Android App UI)  and only enters VR via a button if requested.\nSo the user shouldn't be able to start the VR activity from \"Daydream home\" but with these settings he can.\nBut now I am stuck at the \"controller pairing\" screen ?\nThe problem I am seeing here is that this activity is not a \"Daydream activity\" because it breaks with the basic daydream principles like \"always have a controller for navigation, usw\" , it just wants to use the daydream headset as a normal VR headset.\nSo going down this route might not be ideal and might introduce more problems. Any other idea ?. > You can prevent the Activity from appearing in the Daydream VR launcher by marking it with android:exported=\"false\".\nThanks that worked as expected.\n\nDoes your app not use the Cardboard trigger at all? We're considering adding support for a Daydream app declaring \"optional\" controller support, which would avoid the controller connection UI when entering VR. Would that work for you?\n\nNo, I'm not using it. That would be great. How long will it be until that's possible ?\n\nNote that that would still interrupt your Activity to show the 2D transition screen.\n\nI can get rid of that using mGvrLayout.getUiLayout().setTransitionViewEnabled(false); \nNo, it does not cause other problems than the redundant GL context creation.  (At least no problems that weren't my fault, I had tied the lifecycle of almost all my threads to the context creation/deletion and therefore experienced  multithreading issues. I already fixed that.).  Nonetheless, documenting this behaviour would be great. It took me quite a while to figure it out.\n. Looks good. I'l have an eye on it.  . Hello,\nNow that I have updated my native files to 1.6 I was not able to reproduce the issue. (when setting the version in build.gradle lower than in the cpp headers)\nBut I noticed the malfunction on the s6 when it was the other way around:\nSo I went back in my archive:\n1.14 in the headers and 1.5 in gradle\nand this is basically the error:\nJNI DETECTED ERROR IN APPLICATION: jmethodID was NULL\nin call to CallStaticVoidMethodV\n    art/runtime/java_vm_ext.cc:470]     from long com.google.vr.ndk.base.GvrApi.nativeCreate(java.lang.ClassLoader, android.content.Context, long, int, int, float, float, com.google.vr.ndk.base.GvrApi$PoseTracker)\nI arises when instantiating my gvr layout\nBut only on s6 and not on zte. I installed cradboard and googlevr services on both devices (I first thought that would solve the issue).\nI also found some more missing jni methods when looking for the issue.\nIt would be cool if you added a warning / failure that already gets thrown inside gradle (if it is possible) when the versions in the headers and build.gradle are not the same. \nBut until then I will just learn from my mistakes and make sure to update the .so / .h files via extractndkXXX whenever i update the versions inside build.gradle\n. btw, this is not totally on-topic but while 1.16 is released on github i only find 1.15 in android studio \nimplementation 'com.google.vr:sdk-base:1.150.0'\nshould be ...1.160.0 but didnt have any issues with that yet. I use this code to generate mipmaps on my NON_DAYDREAM, ONLY GVR application to generate mipmaps. Maybe it works also for you:\nglHint(GL_GENERATE_MIPMAP_HINT,GL_NICEST);\n    glGenerateMipmap(GL_TEXTURE_2D);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER,\n                    GL_LINEAR_MIPMAP_LINEAR);\n    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER,\n                    GL_LINEAR);\nI remember me using GL_LINEAR_MIPMAP_LINEAR for GL_TEXTURE_MAG_FILTER . Took me hours to find the bug.. ",
    "gcalero": "Hi everyone, this may help anyone else. I'm working on an app that renders using a C++ engine so I get the GvrApi and pass it to C++. I DON'T use GvrLayout. The key to fix this issue in my case was forward onPause() and onResume to the DisplaySynchronizer object used to build the GvrApi.. ",
    "bjmiao": "go to #193 . ",
    "OAkyildiz": "Hello,\nDo you have any updates in this? Or which version of the API doesn't cause that?. I my case it is org.ros.android_core:android_15:0.2.0, I might fork it and update its deps. It is quite outdated. \nEDIT: Turns out switching to vr.sdk I did not remove the lib .jars incldued as dependencies for cardboard SDK\n. ",
    "jifang": "Google VR Services version 1.15.196855678\nGoogle VR SDK v1.140.0. ",
    "t-bashir-uk": "Thanks for fixing it.. ",
    "HyowonHwang": "Is there any sample code for this issue, please? I am also looking for this feature of 360 sample.. ",
    "Harsh2098": "Thanks !\n. ",
    "bell-one": "Well.. maybe I have problem with get total transform data,\nI just use orientation data with gearvr framework on my project, \nand with this, I can't get position information\nSo I just want to use googlevr transform information directly but with this \nI checked treasure hunter example and there, get headtransform with stereorender interface\nby overiding onNewFrame..\nshould I change my class to exnteds Gvrview implements some render interface?\nor is there any way to get headtransform without these?. ",
    "ewang6359": "Thanks, Consti10. We confirmed this is (line for line) how we are generating our mips as well. Neither the generated mips nor the embedded levels from a KTX seem to be getting used for our Daydream app. It's really odd.... ",
    "StarStep": "Hi, I'm using the vr360 project, how would you rotate the mesh from VrVideoActivity? @sigmaxipi \nI tried with gvrView.setRotationY(45) but it rotates the View .-. and not the sphere. Uh cool, will try to implement ASAP and will post back. But wouldn't it be better to change directly the viewProjectionMatrix / sensor data like in the MonoscopicView? @sigmaxipi . For the moment implemented the rotation inside VrVideoActivity.java within onDrawEye function.\nProbably not the best performance wise but works, maybe later on will search for a better solution.\nOf course if you already have better implementions, maybe share them \ud83d\ude01 \n@Override\npublic void onDrawEye(Eye eye) {\n     Matrix.multiplyMM(viewProjectionMatrix, 0, eye.getPerspective(Z_NEAR, Z_FAR), 0, eye.getEyeView(), 0);\n     Matrix.rotateM(viewProjectionMatrix, 0, my_offset_value, 0, 1, 0);\n     scene.glDrawFrame(viewProjectionMatrix, eye.getType());\n}. Yeah, you got a point. Luckily this is exactly what I need for the moment \ud83d\udc4d \nWill surely take it consideration for future developments, thanks sigmaxipi!. Thanks you for the help. Yep, i tried to look at that code and tried adding\n```\npublic void myPause() {\n        try {\n            mediaLoader.pause();\n        } catch (Exception e) { Log.d(TAG, \"Error while trying mediaLoader.pause();\");  };\n   try {\n        mediaLoader.mediaPlayer.pause();\n    } catch (Exception e) { Log.d(TAG, \"Error while trying mediaLoader.mediaPlayer.pause();\"); };\n\n   try {\n        (new MediaLoader(this)).mediaPlayer.pause();\n    } catch (Exception e) { Log.d(TAG, \"Error while trying mediaLoader.pause();\"); };\n}\n\n``\nand to run that function I'm using(new VrVideoActivity()).myPause();If you need more info you can find **the repo** here: https://github.com/StarStep/cordova-vr-help\nGVR: cordova-vr-help/platforms/android/app/src/main/java/com/thevrplugin/cordovapluginvrplayer/\n. Finally got it to work by declaring as static the MediaLoaderpublic static MediaLoader mediaLoader;`\nand then I were able to interact with the player like so\npublic static void myPause() {\n    mediaLoader.mediaPlayer.pause();\n}. Uh, seems like the audio wont play while streaming... gonna find out why.. Yeah, will definitly try it once I got spare time, at the moment it's not a must have for our project \ud83d\udc4d.\n",
    "nkovacs": "Same issue with the LG G7:\n\n. ",
    "iv777": "Same issue with the mi a2 lite - aspect 19:9\n\n. ",
    "MikhailAMD": "Yes, I figured out a simple correction. But you may consider to change documentation which currently states: \n\"Gets the position and rotation from start space to head space.  The head space is a space where the head is at the origin and faces the -Z direction.\" \nTo something like:\n\"Gets transformation matrix that converts coordinates from start space to head space\" \nThanks\n. ",
    "savadmv": "How can i use the video360 sample  to Display 360 image . ",
    "michaeltheory": "I guess I didn't scour enough :) Thank you! . Sorry, trying to use this with Kotlin and struggling a bit with Value.\nprivate val value = Value()\n....\ngvrView.gvrApi.currentProperties.get(Properties.PropertyType.TRACKING_FLOOR_HEIGHT, value)\nLog.d(\"GVR\", value.asFloat().toString())\nThat seems to prevent rendering with logs like Missed vsync by 36444us (CPU load is too high)\nAm I using it wrong?. Thanks for that. It looks like the code is pretty much the same. My code is never actually getting past the .get line, as the float value is never logged. I am calling it every frame.\nI'll try a few things including moving that code into a Java class . Finally got a chance to try this again, I found the issue. If you're using Kotlin, you must use the full Java syntax of gvrView.getGvrApi().getCurrentProperties() even though Android Studio will warn you to change it to gvrView.gvrApi.currentProperties. That makes sense. This is the first time I've seen that happen, but from my end I'm all good. ",
    "virtualguest": "The Cardboard app to scan the QR code no longer functions on Android. We've tested on Galaxy  S7 and S9 using 15+ QR codes. All return a 'Unrecognised QR code' error. The Cardboard QR scans work on iOS, though.. > This is fixed in v1.9 of the Cardboard app which is currently rolling out to production. This should be fixed by Wednesday.\nFantastic, great to hear. Thanks!. ",
    "cmdr2": "@sigmaxipi Thanks, I've submitted a PR with a fix for the issue. It required an update for the Firebase library, and needed to replace Google URL Shortener API with Firebase Dynamic Links. Works fine on my local system now. Hopefully it'll help get the system back online soon. https://github.com/google/wwgc/pull/5\n@virtualguest The QR code scanner worked for me last week (HTC One M8), but I would suggest filing a separate issue, to avoid confusion with this one (this issue is for QR code generator not working).. ",
    "AlphaCircle": "Hello sigmaxipi,\nThanks for your answer. I did what you said to me. That works for me.  Just in case, I removed the directory of \".gradle\" in my home where all the caches exist. \nThanks again for your quick help.. ",
    "legendvijay": "Does gvrAudioEngine support mp3 files non spatial audio ?\nIf yes how should i play it ?. I got it. its working now. . It need mono audio only. Not accepting stereo.. I gone through the exoplayer. Where there is no support for setheadposition() and enableroomeffects() for reverbs. But it has update orientation() Only.\n. ",
    "TheBricktop": "Ive figured it out myself, with the new update for GVRservices something went sideways, all i had to do was uninstall the services completetly from my phone and then install it again.\nWay to go, add it to the FAQ or sth.. ",
    "BakytzhanAkzhol": "Hello. It's my fault. Older budget phones will not be able to run high quality videos. I lowered the video transfer rate from 10mb/s to 3 Mb/s using the \"FormatFactory\" program.. This question can be closed.. "
}