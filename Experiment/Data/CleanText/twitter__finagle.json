{
    "mariusae": "mid air collision!  wilhelm is forward porting it.  thanks!\n\u00bb git pull https://github.com/dhelder/finagle.git thrift-0.5.0\nremote: Counting objects: 44, done.\nremote: Compressing objects: 100% (16/16), done.\nremote: Total 23 (delta 9), reused 0 (delta 0)\nUnpacking objects: 100% (23/23), done.\nFrom https://github.com/dhelder/finagle\n- branch            thrift-0.5.0 -> FETCH_HEAD\n  Auto-merging project/build/Project.scala\n  Merge made by recursive.\n  project/build/Project.scala                        |    2 +-\n  .../com/twitter/finagle/thrift/ThriftCodec.scala   |   10 +++++-----\n  2 files changed, 6 insertions(+), 6 deletions(-)\n  \u00bb sbt test\n  [info] Recompiling project definition...\n  [info]    Source analysis: 1 new/modified, 0 indirectly invalidated, 0 removed.\n  [info] Building project finagle 1.0 against Scala 2.8.1\n  [info]    using Project with sbt 0.7.4 and Scala 2.7.7\n  [info] \n  [info] == compile ==\n  [info]   Source analysis: 9 new/modified, 33 indirectly invalidated, 2 removed.\n  [info] Compiling main sources...\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpClient.scala:8: RuntimeEnvironment is not a member of com.twitter.ostrich\n  [error] import com.twitter.ostrich.RuntimeEnvironment\n  [error]        ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpClient.scala:12: not found: type RuntimeEnvironment\n  [error]     val runtime = new RuntimeEnvironment(getClass)\n  [error]                       ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpClient.scala:14: type Config is not a member of package com.twitter.ostrich\n  [error]     val config = new ostrich.Config {\n  [error]                              ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpClient.scala:20: type mismatch;\n  [error]  found   : AnyRef{def telnetPort: Int; def httpBacklog: Int; def httpPort: Int; def jmxPackage: object None}\n  [error]  required: net.lag.configgy.ConfigMap\n  [error]     ostrich.ServiceTracker.startAdmin(config, runtime)\n  [error]                                       ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpServer.scala:14: RuntimeEnvironment is not a member of com.twitter.ostrich\n  [error] import com.twitter.ostrich.RuntimeEnvironment\n  [error]        ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpServer.scala:27: not found: type RuntimeEnvironment\n  [error]     val runtime = new RuntimeEnvironment(getClass)\n  [error]                       ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpServer.scala:29: type Config is not a member of package com.twitter.ostrich\n  [error]     val config = new ostrich.Config {\n  [error]                              ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/test/HttpServer.scala:37: type mismatch;\n  [error]  found   : AnyRef{def telnetPort: Int; def httpBacklog: Int; def httpPort: Int; def jmxPackage: object None}\n  [error]  required: net.lag.configgy.ConfigMap\n  [error]     ostrich.ServiceTracker.startAdmin(config, runtime)\n  [error]                                       ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/thrift/ThriftCodec.scala:24: wrong number of type arguments for org.apache.thrift.TBase, should be 1\n  [error] class ThriftCallA <: TBase[, ], R <: TBase[, ]\n  [error]                                           ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/thrift/ThriftCodec.scala:75: wrong number of type arguments for org.apache.thrift.TBase, should be 1\n  [error] case class ThriftReply[R <: TBase[, ]](\n  [error]                             ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/thrift/ThriftCodec.scala:79: wrong number of type arguments for org.apache.thrift.TBase, should be 1\n  [error] class ThriftCallFactory[A <: TBase[, ], R <: TBase[, ]](\n  [error]                              ^\n  [error] /Users/marius/twttr/finagle/src/main/scala/com/twitter/finagle/thrift/ThriftCodec.scala:79: wrong number of type arguments for org.apache.thrift.TBase, should be 1\n  [error] class ThriftCallFactory[A <: TBase[, ], R <: TBase[, ]](\n  [error]                                                ^\n  [error] 19 errors found\n. i like it.  Netty already provides the replaying functionality (special framebuffer w/ exception), and a decoder for it:\nhttp://docs.jboss.org/netty/3.1/api/org/jboss/netty/handler/codec/replay/ReplayingDecoder.html\nmind just re-using that instead?\n. LGTM--merging.\n. this should be fixed in 1.1.10 \u2014 could you verify?  thanks, marius.\n. thanks for the stack trace.  i was able to reproduce & fix.\nhttps://github.com/twitter/finagle/commit/80a0794967441dd2a03b7800fc6971079b3ad850\nthis is now included in the 1.1.11 release.\n. ok, cool.  1.1.11 squashed the NIO worker threads, but i still need to refcount the timer thread.\ni'll fix this on monday.\n. this should be resolved in 1.1.15.\nlet me know.\n. LGTM\n. LGTM\n. i pushed this.\n. there's a race between maybeLifeTimeExpire and the completion of the underlying request: maybeLifetimeExpire can fire, and between maybeExpire() and expired = true, the request can complete, leaving didExpire() uncalled.\n. i've added you to the twitter team.  you should be able to push now\n. LGTM!\n. LGTM!\n. This is done.\n. the README has since been rewritten\n. i think this is no longer the case. i was able to build the current master just fine outside of Twitter's environment.\n. this is now fixed.\n. pulled, thanks!\n. can you include:\n1. the builder code for the client\n2. how your invoke it?\nthese exceptions should never happen if you just use .build().\n. the outlined usage seems correct to me.\nwhich version of finagle are you using?\nalso: are you keeping stats (through .reportTo)? the counters/gauges/metrics would be handy.\nalso: when these errors occur, are there any other concurrent exceptions?\np.s. there should be no difference between using .build() and calling .service() on your factory -- except that you only get retries with .build and not .buildFactory.\n. another thing that would help me with trying to reproduce this is: approximate failure rate of requests, latency of requests and request concurrency.\n. re: the WriteExceptions-- these are annoying but harmless. a change is being introduced very soon that quenches these.\nit's interesting that you're canceling the Futures.\nproper cancellation support in finagle was introduced in 1.7.3. i can also think of at least one condition under which 1.6.x would fail on cancellation (i also rewrote Future cancellation completely in the meantime, to avoid exactly these kinds of bugs).\ncould you upgrade to 1.7.3 and see if the problem persists?\n. great. the WriteExceptions you are seeing are likely valid, too -- i'm adding some code shortly that will quench a class of exceptions that get logged, but shouldn't be.\n. should be this week\n. It should not be public.\n. fixed in 1.7.5\n. this is just a case of finagle being too verbose -- i'm landing a fix for this today or tomorrow\n. host validation was added in ebe2fcfa548c4ccb145c8d5b3257a071e513b50d\n. fixed: thanks!\n. please make the change in the internal (birdcage) repo.\n. Thanks!\n. thanks!\n. yikes! i guess i never tested the server side of this :-/\n. just fix the tiny style nit, then i'll merge.\n. thanks!\n. great, thanks!\n. great, thanks!\n. yeah, we're not quite ready for 2.9 yet. for pure Scala, it's pretty simple. however, there have been some significant changes in the way certain types are represented, which is causing some issues for Java compatibility. these changes were introduced in 2.8.2 as well, so even to go that far, we'll have to tackle them.\ni have an internal branch that does compile (util, finagle -- we build all of these as part of one source tree, so changes like this are easier to make), but i can't promise anything before a few weeks hence.\n. We have been publishing 2.9.1 releases for a while now. The maven artifacts are suffixed with \"_2.9.1\". E.g.\n\"com.twitter\" % \"finagle-core_2.9.1\" % \"1.9.12\"\n. I'm working on getting those branches to sync with github, too. Watch this space in a few days.\n. we're publishing 2.9.1  artifacts now (and have been for a while).\n. thanks!\n. yep.  the sbt plugin simply invokes the finagle thrift compiler here.\nthis is a modified apache thrift compiler with the finagle bindings. we're hoping to make this a lot easier in the near future.\n. Done: http://search.maven.org/#search%7Cga%7C1%7Cfinagle\n. hello\u2014 you must use our fork of the thrift compiler. it's at:\nhttps://github.com/mariusaeriksen/thrift-0.5.0-finagle\n. Thanks!\n. This should be fixed.\n. thanks!\n. thanks!\n. it's comforting that our implementation matched verbatim!\n. thanks!\n. thanks!\n. this has been fixed internally, and i'll make a code push today together with the release.\n. This should be resolved now.\n. thanks!\n. Finagle only builds with sbt 0.7.x. Note that this doesn't mean you have to use it in your projects -- it's only required to compile finagle itself.\nFurthermore we publish binary artifacts so you needn't compile it yourself if you don't want.\nI'll add some shell scripts to the finagle source (as well as util) to make it self-bootstrapping so that you don't need to install sbt yourself.\n. Sure-- there's no real reason scala bootstrapper can't use sbt 0.11-- standard project and friends are ported.\n. @jponge they're on our own maven repo: http://maven.twttr.com/. I just realized that this is in fact not documented. I'm going to bring this up to date tomorrow. I'm also working on getting us published to sonatype.\n. Finagle builds by default with sbt11 now.  ./sbt test\n. It sounds like perhaps you're using the 2.8.1 artifacts? 2.9.1 are published with the \"_2.9.1\" suffix, thus you need:\n\"com.twitter\" % \"finagle-core_2.9.1\" % ...\netc.\n. @danielschonfeld just did. sorry about the delay!\n. This question was answered on the mailing list:\n\nYou're encountering a problem due to the asymmetry of the String codec \u2014 which is really just a toy codec used as a minimal example for codec construction: it expects requests to be terminated with a newline, but the server codec strips the delimiter. So if you modify your proxy service a little, adding a newline to the request:\nval proxyService = new Service[String, String] {\n  def apply(request: String) = {\n    println(\"I'm router, I received request message:\" + request)\n    client(request+\"\\n\").onSuccess {\n      result => println(\"Router received result asynchronously: \"\n    ...\neverything should work.\nNote that a well-designed codec will almost always have the property that a proxy in finagle can simply be implemented by doing:\nval client = ClientBuilder().codec(Blah())....build()\n  val server = ServerBuilder().codec(Blah())....build(client)\nAnother note on your code: you shouldn't release the client in the server, lest you wish to server only one request.\n. Thanks!\n. This should all be resolved. Finagle should build with\n\n./sbt test\n. This works.\n. Please use sbt11 to build finagle open source.\n. Is this particular protocol (code32, length32, message) used by somebody else, or is it your own? If not, it  would be nice to build more room for extensibility (eg. to ship trace ids) from the start. In thrift we do an upgrade dance, but that's only to maintain backwards compatibility.\nAlso, it would be nice to build a protobuf compiler plugin to generate Future-full bindings as well.\n. I want to merge this, but we need to put some more work in. My biggest concern so far is the actual protocol: does it comply to some other widely-used one, or is it a custom one of yours? If it's a custom one, I think we should figure out a way to make it more extensible for features like tracing.\nI'm willing to merge this in so that we can work on it, but without publishing it yet. How does that sound?\n. (Another thing that would be nice to support is multiplexing.\n. I'm going to merge this, but not publish it yet-- this way we can work on it to get it up to shape!\n. It's merged! I'll write my thoughts about a protocol in an email. Are you subscribed to the finaglers group?\n. Yep, I was confused.\n. Thanks!\n. This should be fixed.\n. Finagle now builds fine with sbt11, and on scala 2.9.x\n. Thanks!\n. Thanks!\n. Thanks!\n. I tried to reproduce it; I could get it hang a couple of times. I can't get it to hang any longer. When it happened it was hanging in connection establishment. It seems that the api.authorize.net has very high variability in resolution-- so that might be an issue. Anyway, I'm going to keep trying (I now have added debug code to give me a better idea of what's going on by setting a low tcp connect timeout and seeing what's reported).\n. Is this still an issue?\n. That's right. These probably refer to the version of within that takes an implicit\n. oh. that's .. unfortunate.\ni'll fix this; thanks!\n. This is fixed.\n. Thanks!\n. Thanks!\nYikes, this is an ugly bit of Synchronized* in Scala-- might consider a more explicit approach, too.\n. I'm not sure it should. Connection management should be disassociated from request management.\n. The problem is that services are request oriented, but service factories are connection oriented\u2014mixing the two is going to cause resource exhaustion like this.\nThere is a solution to your problem, however, and that's to modify the codec to ensure that proper connection management is applied: a connection is given back to the pool only after it has been released. (We're currently enforcing correctness by ensuring clients are used just once, which is a kludge\u2014finagle-stream was originally designed for \"infinite\" streams).\n. Something like this would probably do:\n``` scala\ndiff --git a/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/Stream.scala b/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/Stream.scala\nindex 9341534..f720aed 100644\n--- a/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/Stream.scala\n+++ b/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/Stream.scala\n@@ -1,17 +1,46 @@\n package com.twitter.finagle.stream\n+import com.twitter.concurrent.Channel\n+import com.twitter.finagle.ServiceNotAvailableException\n+import com.twitter.finagle.{\n+  Codec, CodecFactory, Service, ServiceFactory, ServiceProxy, TooManyConcurrentRequestsException}\n+import com.twitter.util.{Future, Promise}\n import java.util.concurrent.atomic.AtomicBoolean\n-\n import org.jboss.netty.channel.{ChannelPipelineFactory, Channels}\n import org.jboss.netty.handler.codec.http.{\n-  HttpServerCodec, HttpClientCodec, HttpRequest, HttpResponse}\n+  HttpClientCodec, HttpRequest, HttpResponse, HttpServerCodec}\n-import com.twitter.concurrent.Channel\n-import com.twitter.util.Future\n+/*\n+ /\n+private[stream] class DelayedReleaseService(self: Service[HttpRequest, StreamResponse])\n+  extends ServiceProxyHttpRequest, StreamResponse\n+{\n+  @volatile var done: Future[Unit] = Future.Done\n-import com.twitter.finagle.{\n-  Codec, CodecFactory, Service, ServiceProxy, ServiceFactory}\n-import com.twitter.finagle.ServiceNotAvailableException\n+  override def apply(req: HttpRequest) = {\n+    if (!done.isDefined)\n+      Future.exception(new TooManyConcurrentRequestsException)\n+    else {\n+      val p = new Promise[Unit]\n+      done = p\n+      self(req) map { res =>\n+        new StreamResponse {\n+          def httpResponse = res.httpResponse\n+          def messages = res.messages\n+          def error = res.error\n+          def release() {\n+            p.setValue(())\n+            res.release()\n+          }\n+        }\n+      } onFailure { _ => p.setValue(()) }\n+    }\n+  }\n+\n+  override def release() {\n+    done ensure self.release()\n+  }\n+}\nobject Stream {\n   def apply(): Stream = new Stream()\n@@ -42,24 +71,11 @@ class Stream extends CodecFactory[HttpRequest, StreamResponse] {\n           pipeline\n         }\n       }\n-      override def prepareConnFactory(\n-        underlying: ServiceFactory[HttpRequest, StreamResponse]\n-      ): ServiceFactory[HttpRequest, StreamResponse] =\n-        underlying map { service => new UseOnceService(service) }\n-    }\n-  }\n-\n-  private class UseOnceService(underlying: Service[HttpRequest, StreamResponse])\n-    extends ServiceProxyHttpRequest, StreamResponse\n-  {\n-    private[this] val used = new AtomicBoolean(false)\n\noverride def apply(request: HttpRequest) = {\nif (used.compareAndSet(false, true)) underlying(request) else {\nFuture.exception(new ServiceNotAvailableException)\n}\noverride def prepareServiceFactory(\nunderlying: ServiceFactory[HttpRequest, StreamResponse]\n): ServiceFactory[HttpRequest, StreamResponse] = \nunderlying map(new DelayedReleaseService(_))\n     }\n-\noverride def isAvailable = !used.get && underlying.isAvailable\n   }\n }\ndiff --git a/finagle/finagle-stream/src/test/scala/com/twitter/finagle/stream/EndToEndSpec.scala b/finagle/finagle-stream/src/test/scala/com/twitter/finagle/stream/EndToEndSpec.scala\nindex 8fe948c..0dc074c 100644\n--- a/finagle/finagle-stream/src/test/scala/com/twitter/finagle/stream/EndToEndSpec.scala\n+++ b/finagle/finagle-stream/src/test/scala/com/twitter/finagle/stream/EndToEndSpec.scala\n@@ -4,7 +4,7 @@ import com.twitter.concurrent.\n import com.twitter.conversions.time.\n import com.twitter.finagle.builder.{ClientBuilder, ServerBuilder}\n import com.twitter.finagle.{\nServiceNotAvailableException, ClientCodecConfig, SimpleFilter, Service}\nTooManyConcurrentRequestsException, ClientCodecConfig, SimpleFilter, Service}\n import com.twitter.util._\n import java.net.InetSocketAddress\n import java.nio.charset.Charset\n@@ -108,7 +108,7 @@ class EndToEndSpec extends SpecificationWithJUnit {\n       \"the client does not admit concurrent requests\" in {\n         val clientRes = client(httpRequest)(1.second)\n         client(httpRequest).poll must beLike {\ncase Some(Throw(_: ServiceNotAvailableException)) => true\ncase Some(Throw(_: TooManyConcurrentRequestsException)) => true\n         }\n       }\n```\n. I'm pushing something similar to this change internally, so it should appear on GitHub in a few days.\n. Done in 686dae852a8b5\n. I've merged this manually in c39bb8c0\n. Hey, sorry about this! I'm working on pushing out a permanent fix for these build divergences that happen from time to time.\n. Should be Monday a.m.\u2014I have the build working internally, but need to polish it a little before pushing it out.\n. (Btw: this is already done and pushed to util)\n. This is now pushed to finagle; it builds well now, with sbt11.\n. This is somewhat interesting\u2014I'm a bit split about what to do exactly. You can always get the behavior you want by sequencing syncs; but it seems like serialization of messages is desirable generally. I think, however, that the correct solution is to sequence these explicitly: don't wait for the next upstream until the previous syncd.\n. Fixed with 919fd54392b035389937e7a8e67d9565b6f381d6. Thanks!\n. I think doing something like this,\n\n``` scala\ndiff --git a/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/HttpDechunker.scala b/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/HttpDechunker.scala\nindex 52faaa6..fb7c7e9 100644\n--- a/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/HttpDechunker.scala\n+++ b/finagle/finagle-stream/src/main/scala/com/twitter/finagle/stream/HttpDechunker.scala\n@@ -40,11 +40,13 @@ class HttpDechunker extends BrokerChannelHandler {\n       if (chunk.isLast) {\n         ch.close()\n\n\nsendOf andThen error(err, EOF)\nsendOf.sync() ensure error(err, EOF)\n           } else {\n             ch.setReadable(false)\nsendOf andThen ch.setReadable(true)\nread(ch, out, err, close)\nsendOf.sync() ensure {\nch.setReadable(true)\nread(ch, out, err, close)\n}\n           }\n```\n\nis a bit simpler, doesn't involve the use of a Future, and makes the sequencing more explicit.\n. Pretty much any Spec, eg.: https://github.com/twitter/finagle/blob/master/finagle-native/src/test/scala/com/twitter/finagle/ssl/SslSpec.scala\nNote that it is a class (not an object) and mixes in SpecificationWithJUnit not Specification\n. And yes, please remove the additional case in EndToEnd. Thanks!\n. Looks great! I'm going to cherry pick in the other commit.\n. I had to add the following build dep. Did you forget to add it?\n``` scala\ndiff --git a/project/Build.scala b/project/Build.scala\nindex d7923d4..752f011 100644\n--- a/project/Build.scala\n+++ b/project/Build.scala\n@@ -206,7 +206,7 @@ object Finagle extends Build {\n       sharedSettings\n   ).settings(\n     name := \"finagle-stream\"\n-  ).dependsOn(finagleCore, finagleKestrel)\n+  ).dependsOn(finagleCore, finagleKestrel, finagleTest % \"test\")\nlazy val finagleThrift = Project(\n     id = \"finagle-thrift\",\n```\n. Pushed: 919fd54392b035389937e7a8e67d9565b6f381d6\n. You need to use the 2.9.1 version of finagle. In sbt, you do this with \"crosspaths\", so your dependency should look like this:\nlibraryDependencies += \"com.twitter\" %% \"finagle\" % \"3.0.0\"\nNote the double %%\n. This is due to using 2.8 artifacts with scala 2.9\n. I'm going to pull this into the internal repo\u2013should appear here soon.\n. We've merged it; just haven't pushed yet. I've been on vacation so pushes haven't happened in a little while. I'm going to get someone to do it.\n* commit ec764afdc105d2f785570191acb6f12e87edc6a4\n| Author: Chris Birchall <>\n| Date:   Thu Jun 14 14:51:13 2012 -0700\n| \n|     finagle-redis: switch from Int to Long for representing Redis integers\n|     Redis supports 64 bit signed integers (as stated in the docs, e.g. for the INCRBY command), and so Redis integers should be represented by Long rather than Int.\n|     \n|     Here is an example of a Redis exchange that is currently not possible using the finagle-redis client:\n|     \n|     redis 127.0.0.1:6379> SET foo 1\n|     OK\n|     redis 127.0.0.1:6379> INCRBY foo 1000000000000000000\n|     (integer) 1000000000000000001\n|     In order to support this I've switched from Int to Long in the following places:\n|     \n|     INCRBY, DECRBY command arguments\n|     Integer replies\n|     Unfortunately this switch from Int to Long means a breaking change in the API, but it should be very easy for users to fix their client code.\n|     \n|     Signed-off-by: Anirudh Srinivas <anirudhs@twitter.com>\n|     \n|     RB_ID=70910 (https://reviewboard.twitter.biz/r/70910)\n|\n. 32a1aa8e1456782817f498f3cf5236d6db223764\n. I think this accomplishes it without checking versions:\ncut -f2 -d'=' | awk '{print $1}'\n. I've pulled this internally, should make it out here within the day.\n. hey George\u2014I'm currently on vacation and will have a look when I get back (in ~1 week)\n. I think I was referring to the POM :-)\nMy chief objection to making finagle-protobuf truly first class at this point is that I'd really like to separate the encoding from the protocol. There are some upcoming changes in finagle-thrift which will make it a very appealing (and generic) RPC transport, upon which we can use protocol buffers, thrift, whatever.\nI'll probably factor that out into something called \"finagle-rpc\"\n. This is done: finagle-mux. As an example of adapting Mux to Thrift, see finagle-thriftmux\n. @george-vacariuc how do you feel about closing this, and porting just the serialization code to use Mux instead? I promise, it is much better.\n. finagle-thriftmux is a simple implementation showing how to compose an RPC system on top of Mux.\n. > Also on a side note, I've been looking at thriftmux and the fact that the client and server builders aren't compatible with mux and I'm starting to wonder if anyone has used the mux transport in production.\nThe intention is to use the new-style APIs; ClientBuilders and ServerBuilders are not going to be provided for new protocols. @roanta has a change coming\u2014it should hit github very soon\u2014which allows the same kind of customization with the new APIs.\n. This was disabled temporarily because of a scala 2.8 dependency diamond issue. It's re-enabled internally, and works well. I'm going to push this to GitHub momentarily.\n. I assume what you mean is: what happens when the client sends an invalid message? That's really protocol specific. Generically we cannot do anything other than close the connection, but some protocols may have support for returning errors in such scenarios.\n. Some general comments from my review:\n- try to use ChannelBuffers throughout as they make it easier to optimize away allocations &c.; especially for down the road\n- make sure you test the frame decoder for fragmented packets\n- it would be great to have package docs that give a brief overview of the protocol, the structure of the code, and links to protocol documentation\n- apply whitespace consistently throughout: if (, // a comment\nNot for now, but possibly a simplification in the future: it would also be possible to use a Dispatcher to do packet defragmentation. In some sense, it's a more natural abstraction: the pipeline codec produces and consumes Packets, and is stateless. The dispatcher consumes and produces requests/responses, and is stateful. Besides a cleaner separation of responsibilities, you also have the full power of composable futures at hand, which makes it possible to write imperative-looking code. You could do stuff like:\n``` scala\nreadPacket() flatMap { packet =>\n  if (fragmented(packet))\n    defrag(packet)\n  else\n    decode(packet)\n}\n```\netc.\n. I\u2019ve pulled this internally; should show up here soon (probably Monday). Not yet published.\n. Thanks! pulled internally, should show up here within a day.\n. I\u2019ve just pushed the fix for this.\n. 517f308a5efd\n. Reopening. Missed that this was in the gh-pages branch.\n. There\u2019s also: JavaLoggerStatsReceiver and SummarizingStatsReceiver\n. @asrinivas or @xiangxin72 \u2014 can either of you take a look?\n. Ah, i beat you to it. I've just submitted this fix internally; should appear here very soon. I had ignored a failing CI job; apologies.\n. This landed, now, with 5c6d67f6\n. Hm. I can't repro the hanging, but I see some tests failing. Looking into this now: it looks like maven and sbt differ with respect to how they package resources for testing.\n. I've pulled this internally, with one small change: use a second constructor instead of a default argument, since this doesn't break the Java API.\n. (It should appear here shortly)\n. Not an issue.\n. We should just adjust the options in sbt. There's no reason this can't run on a 32-bit JVM.\n. @caniszczyk yes. First, we're not actually bundling sbt; the included sbt script is a bootstrapping script. So, in order to build these projects, all that is required is a JRE install. Pretty nice.\nBut more importantly: sbt versioning is really confusing. You might have the simultaneous need of sbts 0.7.x, 0.11.x, 0.12.x. And not only that, sbt will output only cryptic errors if you use one sbt version when you should have used another.\nSimply being able to build finagle with\nsh\n$ ./sbt compile\nis a wonderfully simple thing, in my mind.\n. Thanks! Pulled locally, should show up here whenever hte code review goes through.\n. I think there was a good reason it's not covariant. Let me see if I can dig it up.\n. Note that clusters are being deprecated in favor of Groups: https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/Group.scala\nThese are also invariant:\n\n\n'''Note:''' Groups are invariant because Scala's Sets are. In\nthe case of sets, this is an implementation artifact, and is\nunfortunate, but it's better to keep things simpler and\nconsistent.\n\n\nGiven the fact that this is already a deprecated API, and the inconvenience not so bad, I'm tempted to forgo this change since it would just introduce additional change and complexity for not much benefit at this time.\nDoes that make sense?\n. It is actually automated. The system was unintentionally down for the last week. In steady state, a sync should never take more than a few hours.\n. Thanks; pulled internally.\n. @tsuna:\n\nI like the sources, to essentially help tack on arbitrary annotations on exceptions/failures, but it also means that recipients of the exception will have to sort of inspect the sources for known keys they may care about, and because these are strings they may change and you wouldn't know, etc. Is there a way to retain this general purpose annotation mechanism yet provide a statically typed mechanism for important annotations that we expect to always be there (for instance the remote address of a socket from which an exception originated)?\n\nI think that programmatic inspection will be rare; these will mostly be used for exception reporting and stats. In these cases, we can simply treat some names as special (remoteAddress, clientName) to recover useful provenance information.\n. @bmatheny:\n\nLike @tsuna I also think this is a nice improvement. My feedback would be to consider using a config class (like you do for builders and such) along with Failure. It seems like the list of options could grow beyond retryable and interrupted, and not having to change existing code to support that growth would be nice.\n\nAgreed: I may just make the case class constructor private, to enforce using the \"builder style\".\n. @tsuna:\n\nI think this would be a nice improvement. Do you expect everything to be a Failure or will there be more case classes? I'm curious also as to whether it's better to put retryable and interrupted directly in Failure or to compose traits?\n\nThe main reason for preferring a case class over mixins in this case is that it allows us to treat exceptions like a transformable value, without the need to resort to reflection or code generation tricks. This allows us to push sources and other annotations like \"retryable\" without altering the semantics of the exceptions:\nservice(req) rescue {\n  case f: Failure =>\n    Future.exception(f.withSource(\"mysource\", blah))\n}\n. That should be pretty simple to do .. you'd have to write your own codec, though, probably just based off of finagle-http.\n. We shouldn't allow socksProxy and httpProxy to be defined simultaneously. Both orderings are valid (HTTP then SOCKS, or SOCKS then HTTP), but in practice it's probably an error if used in this way.\nI think that, for now, a simple comment is sufficient: can you add something like the following to the builder options for both the SOCKS & HTTP proxies?\n\nIf this is defined concurrently with (http|socks)Proxy, the order in which they are applied is undefined.\n. Pulled internally; should appear here shortly!\n. Adding this internally now; thanks.\n. Already done. 2.10 artifacts have been published for a little while.\n. scala-bootstrapper isn't really supported. See the Quickstart for details on the dependencies required to build finagle projects.\n. Thanks! Pulling this internally. Should appear soon.\n. Do you continually create and release clients?\n. Okay. That is quite interesting. Any chance you can show me the stack traces for those threads? Do you run with multiple classloaders? In finagle 6, the actual threadpool of IO workers is a singleton.\n. This explains your issues (if you are using custom channel factories).\n\nFinagle has a slightly different contract with channel factories (they are exposed for testing, really; they're not expected to be overridden by users).\nFinagle does not perform lifecycle management on channel factories themselves; instead, it expects the channel factories to be lazy, and relinquish resources when there are no more channels.\n. yes-- finagle 6 introduced these new semantics. I'm curious: why are you supplying your own channel factories?\n. Sorry for the delay. @asrinivas: can you take this one?\n. @asrinivas or @xiangxin72 can you take this?\n. Rachit has pulled this internally; it should show up here soon.\n. We are looking to deprecate these conversions in favor of the explicit callbacks from Netty. We're almost there.\n. Just grep for \"addListener,\" eg.: https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/ssl/SslConnectHandler.scala#L54\n. Ah. Are you creating your own codec? We decided to remove these conversions because they were needed in just a few places.\n. Just curious: how come you closed this? We're thinking about doing slow start in the load balancer, too, but perhaps with a slightly different strategy: do least-loaded on the amount of outstanding request-milliseconds instead of just requests. This can potentially throttle load to cold servers much more quickly than the standard least-loaded.\n. I'm a bit hesitant to add IDE-specific entries to .gitignore. Once you start, where do you stop?\nI'd instead recommend setting up a global gitignore for ignores that are specific to your setup, and not to the project or the build system that's used. This would work on all of your git repositories, so it's probably the right thing to do anyway.\n. We should take those out, then :-)\n. @robstar-nest is correct -- the client is designed to take into account Connection-Close, through the HTTP-specific connection manager.\nIt seems that the current code assumes that the channel is closed (and thus unavailable, and will be thrown away by the pool. I had believed this to always be the case.\nThanks for the detailed report -- I'll see if I can reproduce this tomorrow.\n. Whoops. Nice catch.\nAlternatively, to test the hypothesis, you can perform the same test, but use the regular (not Rich*) http codec.\n. Hi mark thanks for the repro; I'll have a look at this early next week.\n. I'll have a look at this later today, but: regardless of the outcome, there's always a race here, and it seems prudent to handle it in your application regardless.\n. (Also: can you tell me which version of Finagle this is on? There has been some recent changes to HTTP connection management, specifically around draining.)\n. Hey I'm not going to get to this today anyhow; I got caught up in a few other things. I should get to it by the end of the week. \n. @laurencer Do you set any retries in your clients?\n. @robstar-nest I'm not able to reproduce the error:\n```\n% goal! run\n(using ~/.pantsrc expansion: pants goal --no-colors run /Users/marius/src/b/.local/finagle167_robstar)\n pants() wrapper is obsolete and will be removed in a future release. See http://pantsbuild.github.io/build_files.html \n14:02:44 00:00 [main]\n               See a report at: http://localhost:53954/run/pants_run_2014_11_03_14_02_44_641\n14:02:44 00:00   [bootstrap]\n14:02:45 00:01   [setup]\n14:02:45 00:01     [parse]\n               Executing tasks in goals: bootstrap -> imports -> gen -> check-exclusives -> resolve -> compile -> resources -> run\n14:02:45 00:01   [bootstrap]\n14:02:45 00:01     [bootstrap-jvm-tools]\n14:02:45 00:01   [imports]\n14:02:45 00:01     [ivy-imports]\n14:02:45 00:01   [gen]\n14:02:45 00:01     [idl-fetch]\n14:02:45 00:01     [idl-extract]\n14:02:45 00:01     [thrift]\n14:02:45 00:01     [scrooge]\n14:02:45 00:01     [protoc]\n14:02:45 00:01     [antlr]\n14:02:45 00:01     [ragel]\n14:02:45 00:01     [jaxb]\n14:02:45 00:01     [aapt]\n14:02:45 00:01     [lessc]\n14:02:45 00:01     [requirejs]\n14:02:45 00:01     [rtl]\n14:02:45 00:01     [thriftstore_dml_gen]\n14:02:45 00:01   [check-exclusives]\n14:02:45 00:01     [check-exclusives]\n14:02:45 00:01   [resolve]\n14:02:45 00:01     [ivy]\n14:02:45 00:01   [compile]\n14:02:45 00:01     [jvm]\n14:02:45 00:01       [jvm-compilers]\n14:02:45 00:01         [find-deleted-sources]\n14:02:46 00:02         [prepare-analysis]\n14:02:46 00:02         [cache]\n14:02:46 00:02           [check].\n               ScalaCompile will read from local artifact cache at /Users/marius/src/b/.pants.d/buildcache/ScalaCompile\n               ScalaCompile will read from remote artifact cache at https://build.twitter.biz/buildcache/1.0/ScalaCompile\n                     No cached artifacts for 1 target.\n                     Invalidated 1 target containing 1 payload file.\n14:02:47 00:03         [partition-analysis]\n                     Compiling a partition containing 1 source in 1 target.\n14:02:47 00:03         [compile]\n14:02:47 00:03           [zinc]\n                         [info] Compiling 1 Scala source to /Users/marius/src/b/.pants.d/compile/jvm/scala/classes...\n                         [warn] /Users/marius/src/b/.local/finagle167_robstar/httpserver.scala:20: method setHeader in trait HttpMessageProxy is deprecated: deprecated in netty\n                         [warn]       if (closeConnections) resp.setHeader(HttpHeaderNames.CONNECTION, \"close\")\n                         [warn]                                  ^\n                         [warn] /Users/marius/src/b/.local/finagle167_robstar/httpserver.scala:52: method get in class Future is deprecated: Use Await.result\n                         [warn]     print(r.get())\n                         [warn]             ^\n                         [warn] /Users/marius/src/b/.local/finagle167_robstar/httpserver.scala:57: method release in class Service is deprecated: Use close() instead\n                         [warn]   okClient.release()\n                         [warn]            ^\n                         [warn] three warnings found\n                         [info] Compile success at Nov 3, 2014 2:02:48 PM [1.369s]\n14:02:48 00:04         [update-upstream-analysis]\n14:02:49 00:05         [find-missing-dependencies]\n14:02:49 00:05           [map_sources]\n14:02:49 00:05           [map_classes]\n14:02:49 00:05           [map_jars]\n14:02:49 00:05           [scan_deps]\n14:02:49 00:05         [trim-downstream-analysis]\n14:02:49 00:05     [checkstyle]\n14:02:49 00:05   [resources]\n14:02:49 00:05     [prepare]\n14:02:49 00:05     [buildprops]\n                   Injecting generated build.properties SyntheticAddress(/Users/marius/src/b/.pants.d/resources/buildprops/.local.finagle167_robstar.finagle167_robstar:build-props) for binary BuildFileAddress(/Users/marius/src/b/.local/finagle167_robstar/BUILD, finagle167_robstar)\n14:02:50 00:06     [args-apt]\n14:02:50 00:06   [run]\n14:02:50 00:06     [python-run]\n14:02:50 00:06     [jvm-run]\n14:02:50 00:06       [run]\nOur http server will NOT close connections\nNov 03, 2014 2:02:52 PM com.twitter.finagle.Init$ apply\nWARNING: Finagle's build.properties not found\nNov 03, 2014 2:02:52 PM com.twitter.finagle.Init$ apply\nINFO: Finagle version ? (rev=?) built at ?\nGiving server a few seconds to spin up.\nProbing:\n........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\nexiting.\n           Waiting for foreground workers to finish.\n           SUCCESS\n\n% \n```\n. @mccv I've looked at & tried locally your repro. A few questions: it seems that the way this is constructed is inherently racy? Since you're parking a thread while waiting for it to close, it's likely that the same connection will have another request queued by the time the thread is ready to wake from sleep. So, it's not a surprise that there'd be quite a few failed requests. (Or am I missing something?)\n. @laurencer Can you describe your scenario in a bit more detail? What kinds of errors do you get?\n. @robstar-nest and the one that actually have --close!\n```\n% \"\" goa\n     goal! run --run-jvm-run-args=--close\n(using ~/.pantsrc expansion: pants goal --no-colors run /Users/marius/src/b/.local/finagle167_robstar --run-jvm-run-args=--close)\n pants() wrapper is obsolete and will be removed in a future release. See http://pantsbuild.github.io/build_files.html \n14:16:30 00:00 [main]\n               See a report at: http://localhost:53954/run/pants_run_2014_11_03_14_16_30_508\n14:16:31 00:01   [bootstrap]\n14:16:31 00:01   [setup]\n14:16:31 00:01     [parse]\n               Executing tasks in goals: bootstrap -> imports -> gen -> check-exclusives -> resolve -> compile -> resources -> run\n14:16:31 00:01   [bootstrap]\n14:16:31 00:01     [bootstrap-jvm-tools]\n14:16:31 00:01   [imports]\n14:16:31 00:01     [ivy-imports]\n14:16:31 00:01   [gen]\n14:16:31 00:01     [idl-fetch]\n14:16:31 00:01     [idl-extract]\n14:16:31 00:01     [thrift]\n14:16:31 00:01     [scrooge]\n14:16:31 00:01     [protoc]\n14:16:31 00:01     [antlr]\n14:16:31 00:01     [ragel]\n14:16:32 00:02     [jaxb]\n14:16:32 00:02     [aapt]\n14:16:32 00:02     [lessc]\n14:16:32 00:02     [requirejs]\n14:16:32 00:02     [rtl]\n14:16:32 00:02     [thriftstore_dml_gen]\n14:16:32 00:02   [check-exclusives]\n14:16:32 00:02     [check-exclusives]\n14:16:32 00:02   [resolve]\n14:16:32 00:02     [ivy]\n14:16:32 00:02   [compile]\n14:16:32 00:02     [jvm]\n14:16:32 00:02       [jvm-compilers]\n14:16:32 00:02     [checkstyle]\n14:16:32 00:02   [resources]\n14:16:32 00:02     [prepare]\n14:16:32 00:02     [buildprops]\n                   Injecting generated build.properties SyntheticAddress(/Users/marius/src/b/.pants.d/resources/buildprops/.local.finagle167_robstar.finagle167_robstar:build-props) for binary BuildFileAddress(/Users/marius/src/b/.local/finagle167_robstar/BUILD, finagle167_robstar)\n14:16:32 00:02     [args-apt]\n14:16:32 00:02   [run]\n14:16:32 00:02     [python-run]\n14:16:32 00:02     [jvm-run]\n14:16:32 00:02       [run]\nOur http server will close connections\nNov 03, 2014 2:16:34 PM com.twitter.finagle.Init$ apply\nWARNING: Finagle's build.properties not found\nNov 03, 2014 2:16:34 PM com.twitter.finagle.Init$ apply\nINFO: Finagle version ? (rev=?) built at ?\nGiving server a few seconds to spin up.\nProbing:\n........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\nexiting.\n           SUCCESS\n\n% \n``\n. @robstar-nest @mccv there has been quite a lot of activity -- e.g. to add full streaming support -- in finagle-http in recent times; it's possible that fixing this was a side effect of this. I've looked through the logs but cannot find anything that seems directly related.\n. @mccv The latter. If there is budget to do so, (i.e.hostConnectionLImit` isn't violated), the pool will create a new connection, otherwise it will wait for the next connection to be returned from to the pool.\n. @mccv @robstar-nest are we good to close this?\n. A proposed API: make SSL transports a special type, with retrievable certificates. Listeners can then match on this:\ntransport match {\n  case SSLTransport(cert) => \u2026\n  case _ => \u2026\n}\n. > Correct me if i'm wrong though, but a null stats receiver seems a bit useless though? I'm new to finagle but i'm curious why anyone would want to use it?\nThis is an example of the null object pattern; it means that we can treat stats receives uniformly throughout--it just so happens that some of them (NullStatsReceivers) are no-ops.\n. @rstrickland: Would you mind clarifying some things?\nThe exception is presumably seen at the \u201ctop-level\u201d service? I.e. in\nval f = service(request)\nf is what exhibits the exception.\nIn the code you\u2019ve shared with me, you configure retries \u2014 presumably retries are active at the time you are experiencing this error as well?\n. Okay thanks. That gives me enough to try to simulate the error.\n. @rstrickland Do you always use the service (from ClientBuilder.build) directly? Or do you also use it via ServiceFactory?\n. @rstrickland Do you know if these clients are using TLS or not?\n. @rstrickland Can you do me a favor? Would you be able to try finagle 6.5.2? (Latest release).\nSecond, do you know if there are any entries like the following: \u201cException propagated to the root monitor!\u201d in your logs?\nThe only way I can make sense of your stack trace is that an exception was thrown in a respond block which propagates. Now, finagle monitors all such exceptions and logs the above message, but a somewhat recent change means that such exceptions aren\u2019t propagated anymore (they never should\u2019ve been).\nIf this is what\u2019s happening, then you\u2019ll get a proper error (the exception thrown in respond) and the connection state won\u2019t be faulty (subsequent requests should continue to work).\n. I think they are binary compatible, but no promises. If that doesn\u2019t work out I can nudge the Cassie maintainers to provide an updated artifact :-)\n. Great, thanks! Let me know.\n. Re: reproducing the edge case -- to trigger the issue requires a specific ordering of events which is probably difficult to do synthetically.\nRe: 6.5.0 yes that's new enough. \n. The problem is that it depends on the connection behavior of the server as well. For example, how a server chooses to close an HTTP connection once the result is served. It also depends on which thread ends up executing the respond block which throws an exception (for example if it has been chained with other actions).\nThe totality of the situation would be very difficult to reproduce in a closed setting.\n. Did you have a chance to try this out?\n. Sounds good.\n. Perhaps something involving a bird in an engine room?\n. How about some sort of fast bird (or a more cuddly animal), perhaps mechanized, with a big helmet on? We want to emphasize: fast, safe.\n. More generally, we hope to remove the thrift dependency altogether.\n. It should be pretty simple to adopt to the new APIs. \n. (This is really cool btw.)\n. I think we just want this to be part of the inet! resolver.\n. +1, this looks great.\nWe should consider doing a few things:\n- limit the total amount of permissible concurrency;\n- have resolution timeouts (will thread interruption work here?).\nIn the long term, we might consider implementing our own DNS resolver (I think that there was a Netty summer-of-code project for this -- @trustin?) so that we can respect the upstream TTLs, etc. But, I know that anything involving \"your own DNS resolver\" is tantamount to famous last words.\n. I think this -- as a mechanism -- is obsoleted by Stack?\n. You're right. I did not read this carefully. But, I think this issue is overly broad, and at the same time oddly prescriptive. (E.g. 'dynamically choosing between heuristics' etc.; I think that a model like what is proposed in NOTSLOW provides a simpler -- though not necessarily correct -- framework for thinking about these things.)\n. (The comment here is more about whether something like this fits in an \"issue\" or an RFC; usually I think of these as more concrete -- the approach of having dynamic controllers pick heuristics may very well be a good one.)\n. @hgavert The Future API has remained remarkably stable actually; Future.within has, to my recollection, always been \u201cthe way\u201d to apply a timeout to a Future.\n. This seems fine. I know that ab sometimes is a bit funny with connection management. Does it tell you anything more specific?\n. Woah, this is awesome. Thank you @p-antoine \n. Looks good modulo the Updater usage.\n. LGTM :thumbsup: \nAlso, take it or leave it, but perhaps a more straightforward implementation of the update loop might be:\ndef update() = \n  futurePool { resolve } before Future.sleep(...) before update()\nbut, again, take it or leave it.\n. :thumbsup: \n. :+1: \n. @luciferous we should document carefully what the http client/server does and doesn't do.\nAlso, we're not going to change behavior from underneath the user--new behavior would be introduced as an option, or as a new API altogether.\n. This is a good start, but why stop here? I really think that the result of an Ask is a Learning, so, the type variables should be: Service[Ask, Learning]. \nThis also teaches an important life lesson: an ask today equals a Future[Learning]\n. @travisbrown Those headings are admittedly outdated. They probably should be named Customer ask/Business Plan/Business Case/\n. This can easily be done through an external combinator, and even be combined with syntax enrichment. I'm not convinced it's useful enough to warrant inclusion in the standard Service trait.\n. I think the right thing to do here is, in effect, not use InetSocketAddr subclasses directly, but rather create our own wrapper type, ideally a sealed ADT.\n. Could you elaborate on why you can't use the default load balancing configuration?\n\nTo me, idea of Service <-> ServiceFactory translations throughout req/resp processing pipeline seems to be a mistake.\n\nCan you elaborate? This is very much by design--load balancing occurs over sessions and not requests, as many protocols require this.\n. Hi @scf37, thanks for the details! Some replies inline:\n\nGiven Var[Set[Service]], create Service that balances that set. This task is too complex - you'll need to wrap/unwrap service factories and configure pools to keep underlying services opened.\n...\nBalancers need better isolation from what they balance. It looks like right now balancer client must call ServiceFactory.close() to indicate he is done with that connection/session/request so it can be returned to balancer's pool. Why not provide abstraction that can both work with Service and ServiceFactory and both with one-time and persistent connections? So programmer do not need to protect Balancer pool services from being really closed 'by design'.\n\nWhat you're describing is almost exactly the current design, it's just that that generic API  is ServiceFactory! All a ServiceFactory is is a way to produce a service, and to give it back. For example, ServiceFactory.const gives you a ServiceFactory that just uses a single service. In your case, \nval services: Var[Set[Service[..]]] = ...\nval factories: Var[Set[ServiceFactory[..]]] = services.map(svcs => svcs.map(ServiceFactory.const))\nThat's really all there's to it.\n\nEntire Stack implementation looks like typed dependency injection framework. While it allows to combine, re-combine and configure any part, it requires additional code to insert even simple filter w/o parameters. Also, combined Stack is hard to inspect and modify: What filters are in? What parameters do they have? What parameters are set? Can Stack type contain information on every element it contains?\n\nYou're totally right. This is still an \"expert level\" API. The idea behind Stack is to treat Finagle's Stack as any other collection, which you can transform, inspect, instantiate, etc... I think the idea is very solid, but the implementation is still a little cumbersome and difficult to use. This is something the team at Twitter is actively working on improving.\n. So, there are pretty deep-seated assumptions inside of Finagle that service clusters are homogenous, that they are equivalent from the point of view of the application.\nIf you have application semantics that violate this assumption, it should be built on top of the services (or service factories) that are given to you by Finagle, as suggested by @vkostyukov and @roanta.\nMoreover, Finagle makes this pretty simple, due to the uniform nature of its abstractions.\n. @mosesn the problem is that it's an application level optimization; the trick is used to get more up-to-date reads from the underlying system. Compare with, e.g., the optimizations presented by aperture itself which is more about resource conservation and load balancing.\n. @mosesn but shard management is built on top of the standard finagle stack.\n. yep, you're right. i killed it.\n. for both of these, you can use map:\nprivate[this] var idleTimeTask = maxIdleTime map { idleTime => timer.schedule(idleTime.fromNow) { maybeIdleExpire() }) }\netc.\n. use camelCase naming convention (forceExpire)\n. (after that, looks good, please merge!)\n. just drop the 2.8.0-- we don't do cross builds anyway (and i'm not aware of anyone that does\u2026)\n. s/release/release()/g here -- it has side effects.\n. very nice.\n. consistent styling: no whitespace between '(' and 'tokens', '0' and ')'\n. might be cleaner as:\ntokens.headOption match {\n  case None => NoOp()\n  case Some(NOT_FOUND) => NotFound()\n  case Some(STORED) => Stored()\n  \u2026\n. given that this could be arbitrary data, do we want to do a hex dump instead? (ChannelBuffers.hexDump(commandName))\n. ditto.\n. um. this is wrong :-(\n. prefer invocation syntax:\nengineFactory()\n. whoops-- this broke the kestrel client.\n. please use com.twitter.finagle for package namespaces -- for consistency with the rest of finagle.\n. you're going to have to back out the README changes before I can merge: perhaps put your README text in finagle-protobuf/README.md instead?\n. SSL contexts shouldn't be reused across connections, see ed7efcd.\nSo it's probably more appropriate to pass in factories directly.\n. fix the weird indentation: prefer\n.. val defaultSSLContext: SSLContext = {\n  val ctx = ...\n  ctx.init(..)\n  ctx\n}\n. let's keep this commented out for the time being\u2014 i do'nt want to publish artifacts just yet.\n. I'd like to avoid having timeouts like this in the test. It is not very reliable. (The rest of specs in this file have pretty bad style wrt this, too). Perhaps you can test receive ordering explicitly?\nscala\nval of = Offer.choose(clientRes.messages map(Some(_)), clientRes.errors map { _ => None })\nof.syncWait() must beSome(\"1\".getBytes)\nof.syncWait() must beSome(\"2\".getBytes)\nof.syncWait() must beNone\n. style: use // comments except for scala docs.\n. style:\nscala\nclass AuthenticationProxy(\n    underlying: ServiceFactory[Request, Result], \n    username: String, \n    password: String,\n    database: Option[String]) \n  extends ServiceFactoryProxy(underlying) {\n. private[this] val ..\n. style: using x = x stutters a lot, try instead\nscala\ndef makeLoginReq(sg: ServerGreeting) = \n  LoginRequest(username, password, database, sg.serverCap, sg.salt)\n. here it\u2019s a little difficult to keep track of the scope of the futures and flatMaps. it might help to separate out concerns a little, and flatten things out eg.:\n``` scala\ndef acceptGreeting(res: Result) = sg match {\n  case sg: ServersGreeting if sg.serverCap.has(Capability.protocol41) =>\n    Future.value(())\n  case sg: ServersGreeting =>\n    Future.exception(Incomatib..)\n  case v =>\n    Future.exception(new Exception(\"invalid reply type %s\".format(v.getClass.getName))\n}\ndef acceptLogin(res: Result) = res match {\n ...\n}\n// Then the login sequence is very explicit, and flattened by using a\n// for comprehension.\ndef apply(conn: ClientConnection) = for {\n  service <- self(conn)\n  sg <- service(greet)\n  _ <- acceptGreeting(sg)\n  res <- service(makeLoginReq(sg))\n  _ <- acceptLogin(res)\n} yield service\n``\n. It does: Endianess is Netty (and in Java generally) is handled by the underlyingChannelBuffer. So to do this \u201cproperly\u201d you could either demand a little endianChannelBufferfactory, or override theLengthFieldBasedFrameDecoder` and wrap the incoming buffer with one that is little endian.\nHowever, this is so trivial, that it\u2019s both simpler and clearer to do it \u201cmanually\u201d as you have done.\nBut remove the comment I think :-)\n. whitespace: if (\n. spurious println\n. btw-- if you want to retain the debugging information here -- it's often useful -- you should probably either (1) use logging at a debug level, or (2) pass a debug flag into the codec constructor.\n. You'll need to save the reader index here so that it is restored next time. See the FrameDecoder example\n. When tuples aren't natural, use sequence the statements instead. While correct, it isn't obvious to the reader that the order is br.readInt24, br.readByte).\nAlso, since these are side-effecting, they should be furnished with ()'s:\nscala\nval length = br.readInt24()\nval seq = br.readByte()\n. spurious statement?\n. spurious?\n. define toChannelBuffer instead, which would allow the implementation to avoid extra copies.\n. let's measure first, cut later. i'd like to focus on correctness and clarity first, then performance later -- and of course to make sure that the codec isn't structured in a way that wouldn't allow us to squeeze all the performance we can out of it later.\n. idiomatic to use traits: sealed trait State\n. volatiles on same line: @volatile private[this] var ..\n. whitespace\nscala\n// Do ...\n. this is mysterious to the reader: comment on this behavior. also you probably did mean:  buffer.readableBytes? are there valid packets that are fewer than 5 bytes?\n. consistent naming (what is the decoder doing?): DefraggingPackets\n. This suggests that the decoder is not separable from the encoder. Perhaps you should just conflate them in the code? It would avoid this extra decoding step and make the code clearer, I think.\n. I think this would be clearer if it were split into more states. Right now there seems to be a lot of mutually exclusive configurations of PacketDefragger. Here's a suggestion based on my very primitive understanding of the protocol: depending on the type of the result set, there may be one or two set of packets that are to be decoded. First simplification: I think the Option in the sets are redundant. It's only None whenever there is no data, so use Nil instead to represent this state? Second it seems that you expect a number of packet sets; 0, 1, or 2, and that their order, but not their position is relevant (this understanding may not be accurate). So it seems that what you really want to arrive at is a Seq[Seq[Packet]]\nscala\ncase class Defragging(\n  expected: Int,\n  packets: Seq[Seq[Packet]]\n)\nThen your transitions look like\nDefragging(2, Nil)\nafter EOF for the first set\nDefragging(1, Seq(Seq(first, set, of, packets)))\n...\ndoes that make sense? My intuition is that this approach would simplify greatly.\n. (though i do agree-- this seems likely to be a hotspot)\n. these should all have ()s since they modify state (offset)\n. (for future performance optimization) - we should try to use ChannelBuffers as much as possible throughout as it allows us to reduce the amount of copying we do.\n. i'm sure the protocol has something to say about this, right?  probably it's even configurable? :-(\n. Constants should start with UpperCase -- this is actually not only a matter of style, but the pattern matching does not bind uppercase names, so it allows you to match against constants without further ado. And I also believe the optimizer only folds UppercaseConstants.\n. comment on what this constant is, or better yet, name it.\n. constants are Capitalized\n. any reason to not use a case class?\n. case class?\n. `new' not needed.\n. I agree with Sam -- let's not include this in the API. Let's make it pure SQL. There are many other approaches to building queries, including DSLs that exploit type safety -- but those can and should be built on top of finagle-mysql\n. then we can make room when they come :)\n. version needs update.\n. ditto for these.\n. explicitly annotate return type here.\n. for all public interfaces here: include return types. it serves both as (in code) documentation and it also fixes the types, which is important; otherwise refinement types may be exposed unintentionally, causing API conflicts later:\nhttp://twitter.github.com/effectivescala/#Types%20and%20Generics-Return%20type%20annotations\n. love this.  we'll move it under finagle-example when it's ready for prime time.\n. very nice. FOR LATER: i think we could improve this a bit further by embedding expectOK and defragDecoder into the state as well; but let\u2019s leave it as-is for now.  (I find it much easier to understand than the previous version)\n. The reader will be curious as to why you wouldn\u2019t just use a ChannelBuffer (why didn\u2019t you?)\n. for side effecting methods like this, convention dicatates the use of {}:\nscala\ndef bindParameters() { hasNewParams = false }\notherwise it\u2019s difficult to discern whether you mean to do do the assignment, or if it\u2019s a bug and you instead meant:\nscala\ndef bindParameters() = hasNewParams == false\n. it might make sense to name \"valueOf\" -> \"apply\".\nby convention in scala, maps use that for their keys, then you can access columns thus:\nscala\nval row: Row\nrow(\"theColumn\")\n. since this parameter expansion technique is currently unsafe; can we drop this feature alltogether until we figure out a better way?  we could simply require the user to provide fully expanded parameter lists for now?\n. Let's make this package name httpproxy so it doesn't collide with finagle-http.\n. Ah yes. The code here was actually correct, but didn\u2019t behave well for size=2.\nWhat\u2019s being changed, effectively, is sampling with replacement instead of without. I agree this is probably better.\nThe comments need to be changed, though. Something like \u201cpick a random node with which we can swap n\u201d since we are no longer picking from the shrunk heap.\n. strange style: arguments should be on the same line as the opening brace.\ntry\nfactory flatMap { _ =>\n  didRun = true\n  Future.exception(exc)\n}\n. not needed.\nalso, please put all the imports in one group\n. no space between tokens & braces.\n```\n  IntegrationBase {\n\u2026\ntest(\u201c\u2026\u201d) {\n```\nand so forth.\n. weird argument formatting\n. weird indentation.\n. weird indentation\n. This is a bit of an overkill. I think it'd be simpler & clearer with more boring code:\nval ttl = Security.getProperty(\"networkaddress.cache.ttl\")\nif (ttl == null) defaultTtl\nelse ttl.toInt.seconds max minttl min maxTtl\n. (Also, is there ever any chance this string is not an integer, and .toInt could throw?)\n. futurePool { parseHosts }\nto make it syntactically clear that this is a call-by-name\n. the newly introduced fields should all be marked private\n. don't construct the array every time -- factor it out\n. this would fail in another thread, and the error would not propagate back. shouldn't result in an Addr.Failed?\nbetter yet, pre-parse hostPorts, to do input validation on bind\n. I think that in this case, it's a lot clearer to use standard constructs.\n```\nval d = try {\n  val ttl = java.security.AccessController.doPrivileged(\n    new PrivilegedActionString {\n      def run(): String = Security.getProperty(\"networkaddress.cache.ttl\")\n    }\n  )\n  ttl.toInt.seconds\n} catch {\n  case NonFatal(exc) => Duration.Top\n}\nif (!d.isFinite)\n  log...\n```\n. Should we have some reasonable bounds on TTL?\n. This is more appropriately called 'resolveHostPorts' or some such.\n. This isn't really a valid destination address, right? What does it mean?\n. TimerTask is itself a Closable, just return it directly.\n. This address does not make sense to me.\n. This could run into a problem if the DNS resolution takes a long time. (This can happen -- what are the timeouts used here?).\nIn this case, you could have several DNS updates piling up (and one thread allocated for each).\nI suggest you use com.twitter.finagle.util.Updater or something similar to manage this.\n. I still think we should set a minimum TTL here. (Maybe 1 second?)\n. (Note that small TTLs exacerbate the problem I pointed out below.)\n. We don't use syntax highlighting in our docs; make it just \n::\n<tab>code..\nfor consistency.\n. Not to mention possible for files that could not fit in memory, or for infinite streams. \n. Can we fix this before committing these docs?\n. Personally I find the exact opposite. But I realize I'm in the minority there.\n. @luciferous right. we should make it work with the new-style APIs.\n. It's a separate issue. The most important thing is to keep things consistent. If you're passionate about colors, then create a separate change for that which changes all examples\n(I'll be against it, but I suspect I'll lose out.)\n. While technically correct, I don't think \"fixed length\" is quite the right phrase here. Usually that implies it is fixed across all requests. (E.g. in protocols, we talk about 'fixed-width' fields)\nMaybe instead say something like: \".. encountered so far are simple request-response services\"\n(Or, ideally something even better!)\n. Another term for this is .. \"fully buffered\", but that might be a little too jargony.\n. I think it's important to highlight the fact that the interface doesn't change -- it's valid, and encouraged(!) to use the byte stream interface even if you're aggregating chunks.\nPresumably this is the only option in the new http codec and the user won't have any choice in chunk aggregation.\n. more generally: the notion of a 'chunk' is a rather implementation specific thing; the important thing is byte streams.  (and, again, ideally this would work -- and i think can be made to work even in today's netty -- with large messages that aren't actually chunked. AFAIK, netty can synthesize chunks for these.)\n. Reader.writable() does have this property as well; the Future[Unit] from write() isn't satisfied until the previous write has been fully read.\n. and i don't think we should even guarantee this in Finagle.\n. Of course in practice, you'd just use com.twitter.io.InputStreamReader, which you should probably note.\n. why not just finished ensure { h.close() }  (no .unit)\n. This isn't quite going to work since the update itself is asynchronous (you ferry it off to a future pool).\nSimply moving the updater to inside the future pool invocation should be sufficient.\n. it's a little confusing to treat comments in this way.  how about using '%'? \n. ",
    "dhelder": "Sure.\nI'm thinking of reworking ThriftServerCodec into ThriftFramedDecoder and ThriftFramedEncoder.  And likewise for ThriftUnframedServerCodec.  I think this will work if I move seqid into ThriftCall.\n. Nm - no code review support on github.\n. Thanks for the patch!\nRequest/Response wraps around Netty HttpRequest/HttpResponse.  Looks like DefaultHttpRequest has a decent toString, so I think the real problem is we aren't proxying it.  I'll take a look later this week.\n. Interpret the value as a long...\n. I can't think a reason to keep the Int version.  Could it just be changed to incr(key: String, delta: Long)?\n. ",
    "stuhood": "https://gist.github.com/806609\n. I think the 1.1.10 release is causing other problems. With or without our custom Protocol shim, we're getting: https://gist.github.com/808398 ... on the first request.\n. The problem from 1.1.10 is fixed, but I'm still seeing the original issue with 1.1.11: I've updated this gist https://gist.github.com/806609 with the new stack trace I see after exit. In particular, there is one thread in some Netty code for \"HashedWheelTimer\" that looks suspicious.\n. Sorry, don't know how this got closed: as the last comment indicates, it is still a problem.\n. Indeed it is! Thank you very much Marius.\n. @PatrickOsborne: Would you mind updating this pull request, or opening a new one with your implementation? We might as well begin the review process while we wait for that fix. Also, I don't think the fix actually blocks landing the patch?\n. Maybe something playful about \"smuggling\" packets?\n. Please make sure you've considered sharded cases, where someone will have hundreds/thousands mysql clients open, each with 3-5 hosts.\n. ",
    "olix0r": "+1, modulo that comment\n. @mosesn i understand your concerns but do you really think people are going to use finagle without this change?  i'd consider this a serious blocker to widespread FOSS adoption.\n. @nshkrob perhaps Service[Ask, Learning] best captures this?\n. Http.newService(String) takes a Resolver string which is not strictly a hostname.  Due to the way that naming works in finagle, it's tricky for the client to know what the \"host\" header should be.  Perhaps it makes sense to configure this via the client's Stack?  Or add special helper builders on the Http object?\n. Erroring will needlessly break all sorts of services that aren't strictly\nrfc compliant.  Finagle is a transport layer and imo shouldn't be too\nfinicky about this sort of thing.  Adding extra opt-in helpers to build\nhttp/1.1 compliant clients is a fine idea, and I understand that the\nsupport burden for this is high, so I think logging warnings is a good\ncompromise.  But please, don't make finagle enforce somewhat arbitrary\npolicy if the application doesn't require it.\n\nOliver Gould ver@buoyant.io\n. Specifically: is this a 'residual' path or is this something else?\nIf I recall correctly, this path should only consist of the unbound residual path components (and not the bound path), while the id field (if it is a path) should identify the bound path.\n. I had a feeling this was my fault.  I'll submit a PR to clarify the docs.  Thanks.\n. Fixes #376 \n. Sorry, it was in there just without the words 'problem' and 'solution'\n(otherwise the content was the same).  Will keep this in mind next time.\nOn Tue, May 5, 2015 at 12:48 PM, Moses Nakamura notifications@github.com\nwrote:\n\nFor future reference, it would be rad if you included the Problem /\nSolution / Result in the commit message directly, since we just snarf your\ncommit message in directly with a signed-off-by message.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/378#issuecomment-99253473.\n\n\nOliver Gould ver@buoyant.io\n. sorry i haven't popped stack back to this yet.  i can address this tomorrow\n. I added a note about why residual paths are even a thing. Let me know if it needs more clarification.\n. actually, this should be on twitter-server instead. sorry for the noise.\n. https://github.com/twitter/twitter-server/issues/26\n. per discussion with @mariusae \n. also, i should point out that this obviously can't be type-safe end-to-end; and this is Okay. Today, we have no assurances with regard to the protocol of a named service and so we can't differentiate i.e. http and thrift interfaces at the name-level.  So this at least isn't a regression feature-wise, though we can encounter runtime cast exceptions.\n@mosesn I added a ServiceNamer trait that makes it easy to build Service-backed namers. I don't think it's necessary to wire this through the Resolver interface unless there's a compelling reason.\n. @roanta consider the following:\nLet's say I have a program--zoo--that exposes exposes an http\nendpoint /api/birds; and satisfying these requests requires a\ndownstream client to a service--/s/birds.\nWe may typically run zoo with a base dtab like:\n/s => /$/io.bouyant.sd\n/s/birds may be served by a downstream service, but it may also be\nserved from directly within the process (e.g. by an in-memory buffer).\nThis situation may arise when migrating functionality between\nprocesses (e.g. decomposing a service) or mocking downstream\nclients. In these cases, we want these requests routed in-process with\na dentry like:\n/s/birds => /$/io.buoyant.birds.local\nThe workaround today is to have zoo bind to an ephemeral port and\ncontrol redirects to that ephemeral port:\n/localPort => /$/inet/127.1\n/s/birds => /localPort$/${birdsPort}\nHowever, this approach incurs a full serialization roundtrip.  The\nproposed change allows us to bypass the entire networking stack for\nlocal requests.\n. @mosesn made it invariant.  It could vary to let subclasses maintain Service-type flexibility but I think this isn't a concern practically.\n. Please excuse my flip-flopping on this (got confused by multiple branches ;/ ).  I think this change is desirable.  Note that I chose not to use AnnotatingTracingFilter since this is such a thin tracing layer.\n. nudge. :wave: \n. Sorry.  Yes, I still think this change is useful (we've just worked around it internally for the time being so i lost focus).  Let me rebase and address kevin's issue.\n. @mosesn hey-- it's been a few months so i don't have 100% of my then-context in my now-brain, but I believe that this is because we don't have an annotation that makes sense in the failure case...\n. To put this another way: what annotation should be emitted when the service fails?\n. I believe it's the case that if the server is actually going to respond with a message--for instance, a 5xx--then this service call actually succeeds with the result rather than an exception.  The exceptional case typically results in some connection loss or some such (perhaps mux handles this?  but this should be at the very top of the server stack so that there are no 'rescue' handlers installed above it.\nIn any case, I was trying to avoid introducing new annotation types.\n. @mosesn yeah, I think I agree with you.  I can look into this approach.\n. So, I'm okay with this being private[finagle], but I also want some agreement that the API won't break or that this won't just disappear one release.  Making this public gives me a slightly warmer feeling in this regard.\nBasically, I'm doing some Naming/BindingFactory-type things outside of finagle clients (for a very good reason, I assure you); and I need this functionality to avoid needless work.  For the time being I've just whole-hog copy/pasted ServiceFactoryCache (and DynNameFactory and NameTreeFactory) into my project.  This is okay, I suppose, but I'd also like the benefit of any bugfixes/improvements twitter makes in this space.\nAll in all, I'm fine with whatever you folks feel most comfortable supporting.\n. I mean... isn't that just an argument against API stability in general?  \"We may break this at any time and you'll have to figure out how not to be broken?\"  If you want the ability to break this API in a minor release, I'll just copy the code now.\n. @kevinoliver I understand. I suppose I'm just trying to register my interest in/dependency on this part of finagle.  If there are changes to these modules, I'd love to be involved in the discussion or at least aware of the changes before they land. To be clear: I'm absolutely not against API changes, though I am trying to avoid surprises (especially ones that are so deep/fundamental), and because finagle isn't developed in the open, it's hard to know what to expect.\nSo this PR is really trying to tease out:\n- do you foresee these APIs changing anytime soon?\n- if they do change, how can we do this in a non-surprising manner?  \"develop will just change\" is a bit scary to me.  Because we are feeding changes back into finagle, I suspect we'll be building against develop in the very near future...\n. @kevinoliver perhaps a finagle-dev list?  The finaglers list is fairly user-focused; but it might be nice to have a forum for discussing changes to internals. This may be too heavyweight for now considering that the list of people who care about this nitty-gritty level of detail is pretttty small.  It's not urgent, just something to keep an eye on if it actually causes problems.  (I'm of course open to other suggestions for lightweight synchronization on code changes).\nThanks for humoring me!\n. thanks! \ud83d\udc0b\n. I've done some further debugging on this.  I am fairly sure that the second request is sent onto the same Transport (connection) as the first request, and so it cannot be processed until the first request completes (i.e. the response stream is closed).\nI believe the desired behavior is that a new connection should be initiated if all connections are busy...\n. OK!  Here's the culprit:\n```\nclass FactoryToServiceReq, Rep\n  extends Service[Req, Rep]\n{\n  def apply(request: Req): Future[Rep] =\n    factory().flatMap { service =>\n      service(request).ensure {\n        service.close()\n      }\n    }\noverride def close(deadline: Time): Future[Unit] = factory.close(deadline)\n  override def status: Status = factory.status\n}\n```\nThe endpoint's service is closed after the response is received even though the streaming response continues.  CachingPool marks this endpoint as reusable once close() is called, and so on the second request the busy connection is returned.\nI'm not sure how best to fix this -- ideas?\n. @dschobel that sounds promising.  But I think @mosesn is right here:\nIf I close a client during shutdown, (e.g. via closeOnExit(client)) clients with active streaming requests won't close until their streams are complete?  In SSE-style APIs, this may be a long time.  The graceful shutdown case applies to other sorts of resource management (like Var.async).\nIf we implement this as a FactoryToService replacement, close may still be invoked by users and it will do the right thing, but the connection will not be freed until a stream is complete.\nI am starting to get that sense that we're swimming up-stream (:godmode:) by trying to shoehorn streaming into the existing APIs...  I'm very curious about how a streaming-oriented system looks.\n. Proof of concept DelayedReleaseFactoryToService here: https://github.com/twitter/finagle/commit/e3fa6a47293dcc21a57354d8aa6cbf2a863f4d05#diff-5f6ad7c5ae8bec95a7173f8ad10cf515R37\nI still need to wire this into the Stack before this is ready for real review...\n. On second thought: I don't think it's actually possible to close() a service that's wrapped in FactoryToService, anyway: https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/Service.scala#L262.  So perhaps it is enough to simply insert a DelayedReleaseService wrapper into Stack below this FactoryToService...\nThis is all pretty confusing...\n. Furthermore (from StackClient):\n*  * `Role.prepFactory` is a hook used to inject codec-specific\n     *    behavior; it is used in the HTTP codec to avoid closing a\n     *    service while a chunked response is being read. It must\n     *    appear below `FactoryToService` so that services are not\n     *    prematurely closed by `FactoryToService`.\nBut Http.Client.stack does not replace prepFactory.  This should be a fairly straightforward fix (forthcoming).\n. There is more polishing to be done on this branch before it should be merged, but I wanted to socialize an early sketch of this idea before investing time in it.\n. > NB that we can already do /http/1.1/* => /h with /http/1.1 => /h\nI don't think that's right.  Given a name /http/1.1/GET/host/resource:\n- /http/1.1 => /h produces /h/GET/host/resource\n- /http/1.1/* => /h produces /h/host/resource\n. @atollena i can probably reuse some code between the two implementations -- i opted to copy/paste to prove it, but I'll spend a little time polishing it and adding docs later today.\n. I understand trepidation around a change like this. How should we proceed?\n. @atollena If we're all good with this, could you please merge this internally?\n. Added a note to CHANGES\n. Fixed decodePath nit\n. comments fixed, rebased against develop. @atollena \n. fixed \"grammer\" nit and CHANGES\n. As I understand it the situation is as follows:\n1. The client sends a request.\n2. The server responds properly.\n3. The client receives the response.\n4. The server closes the connection.\n5. The client never closes its side of the connection, leaving it in CLOSE_WAIT.\nRunning @mritman's test program locally, I was able to confirm that the server sockets end up in FIN_WAIT_2 and the client sockets end up in CLOSE_WAIT.  I have attempted to reproduce this in a finagle test: https://github.com/twitter/finagle/compare/develop...BuoyantIO:ver/test-streaming-disconnects#diff-84324cdca2db122c30fa0be6887261a2R126\nIf the disconnect were received during the lifetime of a request, the transport would be torn down properly.  I am still trying to determine how the client should receive notification of remote connection teardown outside of the request lifecycle...  Perhaps this can't be determined until another operation (read or write) occurs on the transport?  I'll try to dive deeper with that test to figure out what's going on.\n. @mosesn You can't close a Service today(!) because FactoryToService ignores closes.  If you're actually managing your own connections, you are likely using the ServiceFactory interface (via newClient), where none of this applies.\n. Updated per feedback\n. Added DelayedRelease to the prepConn phase as well so that it is more in line with the logic in http/Codec.scala\n. Furthermore, there's an additional test failure:\n```\n\u001b[0m[\u001b[0minfo\u001b[0m] \u001b[0m\u001b[31m- bind locally  FAILED \u001b[0m\u001b[0m\nMar 18, 2016 9:59:35 PM javax.jmdns.impl.DNSIncoming readAnswer\nSEVERE: Could not find record class. domain:  type: TYPE_IGNORE index 0\ndns[response,10.128.0.117:5353, length=166, id=0x0, flags=0x8400:r:aa, answers=2\nanswers:\n    [Pointer@283659667 type: TYPE_PTR index 12, class: CLASS_IN index 1, name: _finagle._tcp.local. ttl: '3599/3600' alias: 'foo/0/6341._finagle._tcp.local.']\n    [Service@614366872 type: TYPE_SRV index 33, class: CLASS_IN index 1-unique, name: foo/0/6341._finagle._tcp.local. ttl: '3599/3600' server: 'gce-a40bf156-785c-4b92-b182-c6d23f4cad71-c-tr.ci-prod-5-internal\u001a+\u0010\u0001\u000e\u0010\u0001\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf.:0']]\n    answer:        [Pointer@283659667 type: TYPE_PTR index 12, class: CLASS_IN index 1, name: _finagle._tcp.local. ttl: '3599/3600' alias: 'foo/0/6341._finagle._tcp.local.']\n    answer:        [Service@614366872 type: TYPE_SRV index 33, class: CLASS_IN index 1-unique, name: foo/0/6341._finagle._tcp.local. ttl: '3599/3600' server: 'gce-a40bf156-785c-4b92-b182-c6d23f4cad71-c-tr.ci-prod-5-internal\u001a+\u0010\u0001\u000e\u0010\u0001\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf\u00cf\u00bf.:0']\n   0: 0000840000000003 00000000085f6669 6e61676c65045f74 6370056c6f63616c     ........ ....._fi nagle._t cp.local\n  20: 00000c000100000e 10000d0a666f6f2f 302f36333431c00c c02b002180010000     ........ ....foo/ 0/6341.. .+.!....\n  40: 0e10005500000000 00004c7465737469 6e672d6763652d61 343062663135362d     ...U.... ..Ltesti ng-gce-a 40bf156-\n  60: 373835632d346239 322d623138322d63 3664323366346361 6437312d632d7472     785c-4b9 2-b182-c 6d23f4ca d71-c-tr\n  80: 617669732d63692d 70726f642d352d69 6e7465726e616cc0 1ac02b0010800100     avis-ci- prod-5-i nternal. ..+.....\n  a0: 000e10000100                                                            ......\n\u001b[0m[\u001b[0minfo\u001b[0m] \u001b[0m\u001b[31m  The code passed to eventually never returned normally. Attempted 43 times over 5.108177565999999 seconds. (MDNSTest.scala:45)\u001b[0m\u001b[0m\n```\nHowever, this test is already marked as flaky!  I have no idea why/how it's running in CI, since -DSKIP_FLAKY=1 is specified in project/Build.scala.\n. It turns out that SKIP_FLAKY wasn't actually being applied previously.  While javaOptions in Test := Seq(\"-DSKIP_FLAKY=1\") was set in Build.scala, this wasn't being taken into effect because tests were running in sbt's process.  By setting fork in Test := true, we ensure that a new process is created with the appropriate system properties.\n. Alright, I've spent a bunch (way too much) time trying to get the build to be green.\nThe main problem is that the scala-2.10 builds just OOMs.  The scala-2.11 build would OOM if I hadn't completely disabled thriftmux's EndToEndTest in CI.\nI could really use some help at this point.  If that can't happen, I suppose we should just disable external CI for these projects.\nI would really really like to keep external CI for finagle, since it is infinitely helpful to get this feedback on Pull Requests.  As it is, though, we're training people to ignore the results of CI since it inevitably fails.\n. @dschobel sounds good! i'll drop those tags\n. \ud83d\ude0d \n. cc @mosesn \n. @mosesn indeed it does...\n. This branch looks right to me, but it fails (which either means there's still a bug or the tests are bad...)\n[info] StreamingTest:\n[info] - client: request stream fails on write *** FAILED ***\n[info]   com.twitter.finagle.ChannelWriteException: com.twitter.finagle.ChannelClosedException: null at remote address: /0.0.0.0:62345. Remote Info: Not Available from service: client. Remote Info: Upstream Address: Not Available, Upstream Client Id: Not Available, Downstream Address: /0.0.0.0:62345, Downstream Client Id: client, Trace Id: bbee79fcb6d28fea.bbee79fcb6d28fea<:bbee79fcb6d28fea\n[info]   at com.twitter.finagle.NoStacktrace(Unknown Source)\n[info]   ...\n[info]   Cause: com.twitter.finagle.ChannelClosedException: null at remote address: /0.0.0.0:62345. Remote Info: Not Available\n[info]   at com.twitter.finagle.NoStacktrace(Unknown Source)\n[info]   ...\n[info]   Cause: java.nio.channels.ClosedChannelException:\n[info]   at org.jboss.netty.channel.socket.nio.AbstractNioWorker.cleanUpWriteBuffer(AbstractNioWorker.java:433)\n[info]   at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:128)\n[info]   at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:84)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:292)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:254)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:292)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:254)\n[info]   ...\n[info] - client: response stream fails on read *** FAILED ***\n[info]   com.twitter.finagle.ChannelWriteException: com.twitter.finagle.ChannelClosedException: null at remote address: /0.0.0.0:62347. Remote Info: Not Available from service: client. Remote Info: Upstream Address: Not Available, Upstream Client Id: Not Available, Downstream Address: /0.0.0.0:62347, Downstream Client Id: client, Trace Id: bbee79fcb6d28fea.bbee79fcb6d28fea<:bbee79fcb6d28fea\n[info]   at com.twitter.finagle.NoStacktrace(Unknown Source)\n[info]   ...\n[info]   Cause: com.twitter.finagle.ChannelClosedException: null at remote address: /0.0.0.0:62347. Remote Info: Not Available\n[info]   at com.twitter.finagle.NoStacktrace(Unknown Source)\n[info]   ...\n[info]   Cause: java.nio.channels.ClosedChannelException:\n[info]   at org.jboss.netty.channel.socket.nio.AbstractNioWorker.cleanUpWriteBuffer(AbstractNioWorker.java:433)\n[info]   at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:128)\n[info]   at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:84)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:292)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:254)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:292)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:254)\n[info]   ...\n[info] - client: server disconnect on pending response should fail request\n[info] - client: client closes transport after server disconnects\n[info] - client: fail request writer *** FAILED ***\n[info]   $anon.this.res2.isDefined was true (StreamingTest.scala:146)\n[info] - client: discard respond reader *** FAILED ***\n[info]   com.twitter.finagle.ChannelWriteException: com.twitter.finagle.ChannelClosedException: null at remote address: /0.0.0.0:62553. Remote Info: Not Available from service: client. Remote Info: Upstream Address: Not Available, Upstream Client Id: Not Available, Downstream Address: /0.0.0.0:62553, Downstream Client Id: client, Trace Id: bbee79fcb6d28fea.bbee79fcb6d28fea<:bbee79fcb6d28fea\n[info]   at com.twitter.finagle.NoStacktrace(Unknown Source)\n[info]   ...\n[info]   Cause: com.twitter.finagle.ChannelClosedException: null at remote address: /0.0.0.0:62553. Remote Info: Not Available\n[info]   at com.twitter.finagle.NoStacktrace(Unknown Source)\n[info]   ...\n[info]   Cause: java.nio.channels.ClosedChannelException:\n[info]   at org.jboss.netty.channel.socket.nio.AbstractNioWorker.cleanUpWriteBuffer(AbstractNioWorker.java:433)\n[info]   at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:128)\n[info]   at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:84)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:292)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:254)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n[info]   at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.writeRequested(SimpleChannelHandler.java:292)\n[info]   at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:254)\n[info]   ...\n[info] - server: request stream fails read\n[info] - server: response stream fails write\n[info] - server: fail response writer\n[info] - server: fail request reader\n[info] - end-to-end: client may process multiple streaming requests simultaneously\n[info] ScalaTest\n[info] Run completed in 3 seconds, 443 milliseconds.\n[info] Total number of tests run: 11\n[info] Suites: completed 1, aborted 0\n[info] Tests: succeeded 7, failed 4, canceled 0, ignored 0, pending 0\n[info] *** 4 TESTS FAILED ***\nThese failures originate in assertSecondRequestOk.\n. https://github.com/twitter/finagle/pull/487/commits/61f193a62d9154377d40c6fe6da1659a0132dca2 appears to break these tests.\nSpecifically, the following:\nscala\n  def connect(addr: SocketAddress, mod: Modifier, name: String = \"client\") = {\n    val fac = ClientBuilder()\n      .codec(new Custom(mod, identity))\n      .hosts(Seq(addr.asInstanceOf[InetSocketAddress]))\n      .hostConnectionLimit(1)\n      .name(name)\n      .buildFactory()\n    await(fac()\n  }\nThis obtains a single connection such that when the transport fails, subsequent requests fail.\nTests pass when this is changed to:\nscala\n  def connect(addr: SocketAddress, mod: Modifier, name: String = \"client\") =\n    ClientBuilder()\n      .codec(new Custom(mod, identity))\n      .hosts(Seq(addr.asInstanceOf[InetSocketAddress]))\n      .hostConnectionLimit(1)\n      .name(name)\n      .build()\n. Yep, the client: server disconnect on pending response should fail request test times out because the response is never triggered.  I could change this to attempt a write after its closed, but maybe that test isn't particularly useful.\n. @mosesn is it because the read() fails on the response?\nI've changed it as follows and the test now passes:\n``` scala\ntest(\"client: server disconnect on pending response should fail request\") {\n    val failure = new Promise[Unit]\n    val service = Service.mk[Request, Response] { req =>\n      failure.setDone()\n      Future.never\n    }\n    val server = startServer(service, closingTransport(failure))\n    val client = connect(server.boundAddress, identity)\nval resF = client(get(\"/\"))\nintercept[ChannelClosedException] { await(resF) }\n\nawait(client.close())\nawait(server.close())\n\n}\n```\n. @mosesn but now i'm confused -- how is this at all functionally different than:\n``` scala\n  test(\"client: server disconnect on pending response should fail request\") {\n    val failure = new Promise[Unit]\n    val service = Service.mk[Request, Response] { req =>\n      Future.never\n    }\n    val server = startServer(service, closingTransport(failure))\n    val client = connect(server.boundAddress, identity)\nval resF = client(get(\"/\"))\nfailure.setDone()\nintercept[ChannelClosedException] { await(resF) }\n\nawait(client.close())\nawait(server.close())\n\n}\n```\nI assume that failure is being satisfied before the server processes the request -- why does this timeout but the other mode, where the server fully receives the request, fails?\n. cc @atollena @edma2 @mosesn \nI'll update docs, etc, if this is seems useful.\nThis is something that I've implemented in various clients so that we can have comments in our stored dtabs.  It seems useful to just put this into the Dtab syntax directly...\n. rebased against new develop.  Added CHANGES and documentation in Names.rst.  Let me know if additional documentation would be helpful.\n. It appears that this behavior may occur when /admin/metrics.json hasn't been read from in over a minute?\nsh\n:; function fetch_count(){ curl -s \"$HOST:9990/admin/metrics.json\" |jq -M '.[\"rt/out/dst/id/io.l5d.k8s/default/http/word/request_latency_ms.count\"]' }\n:; sleep 300 ; while true ; do fetch_count ; sleep 1 ; done\n55093\n315\n153\n117\n102\n543\n23\n35\n23\n26\n26\n26\n26\n26\n26\nThis is surprising behavior!  What's the thought process behind it?  I think it would be helpful to have this behavior documented in the guide. (I don't understand it well enough yet to write try to do this).\nUltimately, it seems the behavior should be determined by the client and not by the server.  I.e. I don't think I should have to choose between Metrics StatsReceiver and ImmediateMetricsStatsReceiver in code.  Rather, the requester of stats should determine what view of the data is needed.\nThat said, it still seems very surprising behavior for metrics latching to occur only when metrics are requested and not at some fixed interval...\n. @mosesn ah yes, that behavior documented in that ticket sounds correct -- I get secondly data for as many seconds as minutes I have not requested metrics!  This sounds like a bug.\nOutside of that bug, I'll try to formulate a better idea on how I'd want this to work.\n. Am I right about this?\n. Nevermind, I think I'm wrong about this.\n. @yokoshin i put together a proof of concept test for your change.  Please review and let me know if it looks right.\n. updated test\n. I had a similar use case recently, and @mosesn suggested that the aperture load balancer could be used with maxEffort = Int.MaxValue (see https://github.com/BuoyantIO/linkerd/pull/300).  This should cause all traffic to be sent to a single endpoint as long as that endpoint is available. When it is no longer available another endpoint in the load balancing pool will be used.\n. it seemed surprising that polling is started by the factory regardless of whether it builds anything. i can back it out, though.\n. nudge.  I copied this functionality into linkerd to start playing with it, and it seems like something we definitely want.  I got the impression from Gitter that there might be some reticence to a change like this.  From my point of view: this will be a no-op change to anyone who isn't setting a response classifier.  For those setting response classifiers that return RetryableFailure, I assume this is actually the behavior they would want by returning such a response classification?\n. @kevinoliver no worries, thanks for the update\n. Great feedback, @kevinoliver. Thanks.\nA couple clarifications:\n- RetryFilter isn't on the stack by default (that's okay, just making sure I'm not missing it somewhere).\n- How do multiple retry modules interact with RetryBudgets?  I assume they should share retry budgets so that retries in either place are counted -- but the lower one would have to be wrapped in a WithdrawOnlyRetryBudget?\n. @mosesn That's fair, though it gets hard to reason about if these features are spread around...\nFor context, linkerd uses several stacks to model features at different phases of routing. We'd want this type of retry to be instrumented in the highest (logical name) stack, while the requeues should probably be down in the lowest (concrete client) stack.\nAs I understand it I should pursue this as:\n- Change RetryFilter (and not RequeueFilter) to use a ResponseClassifier\n- Change ClientBuilder.newService (and not newClient) to install a RetryFilter module at the top of the stack.\n  - Since ClientBuilder.newService already replaces the requeue filter with Retries.moduleWithRetryPolicy -- that does not count withdrawls when a retry policy is set, the RetryFilter module should count with drawls.\nThen, linkerd may reuse these stack modules in slightly different locations.\n. There's a bit of a overlap/mismatch between Retries.Policy and, ResponseClassifiers, and RetryFilter:\nRetries.Policy only considers a Try[Nothing]:\nscala\nobject Retries {\n  ...\n  private[twitter] case class Policy(retryPolicy: RetryPolicy[Try[Nothing]]) {\n    def mk(): (Policy, Stack.Param[Policy]) =\n      (this, Policy.param)\n  }\n}\nwhereas RetryFilter uses a policy on (Req, Try[Req])\nscala\nclass RetryFilter[Req, Rep](\n    retryPolicy: RetryPolicy[(Req, Try[Rep])],\n    timer: Timer,\n    statsReceiver: StatsReceiver,\n    retryBudget: RetryBudget)\n  extends Filter[Req, Rep, Req, Rep] {\nand ResponseClassifier matches simply on ReqRep:\nscala\n  type ResponseClassifier = PartialFunction[ReqRep, ResponseClass]\nFurthemore, Retries.Budget provides requeueBackoffs:\n``` scala\n  case class Budget(\n      retryBudget: RetryBudget,\n      requeueBackoffs: Stream[Duration] = Budget.emptyBackoffSchedule) {\n    def this(retryBudget: RetryBudget) =\n      this(retryBudget, Budget.emptyBackoffSchedule)\ndef mk(): (Budget, Stack.Param[Budget]) =\n  (this, Budget)\n\n}\n```\nwhich duplicates backoff configuration as specified in RetryPolicy...\nWhy are there so many ways of expressing essentially the same configuration?  Is it really practical that someone would want to have disjoint policies between requeues and retries?  Certainly the budgets should be accounted together... wouldn't it be desirable to consider backoffs together as well?  I.e. if a request is retried and then requeued -- I would expect this to consume two backoffs from the stream and not one backoff from two streams.\nWhat's the motivation for separating retry and requeue policies? It seems that it will make it much harder to construct a coherent retry policy.\n. I see that moduleWithRetryPolicy (which is configured in ClientBuilderClient.newService) applies a RetryExceptionsFilter around the RequeueFilter:\n``` scala\n  private[finagle] def moduleWithRetryPolicy[Req, Rep]: Stackable[ServiceFactory[Req, Rep]] =\n    new Stack.Module5[\n      Stats,\n      Budget,\n      Policy,\n      HighResTimer,\n      ServiceFactory[Req, Rep]\n    ] {\n      def role: Stack.Role = Retries.Role\n  def description: String =\n    \"Retries requests, at the service application level, that have been rejected \" +\n      \"or meet the application-configured retry policy for transport level failures.\"\n\n  def make(\n    statsP: param.Stats,\n    budgetP: Budget,\n    policyP: Policy,\n    timerP: HighResTimer,\n    next: ServiceFactory[Req, Rep]\n  ): ServiceFactory[Req, Rep] = {\n    val statsRecv = statsP.statsReceiver\n    val scoped = statsRecv.scope(\"retries\")\n    val requeues = scoped.counter(\"requeues\")\n    val retryBudget = budgetP.retryBudget\n    val retryPolicy = policyP.retryPolicy\n\n    val filters =\n      if (retryPolicy eq RetryPolicy.Never) {\n        newRequeueFilter(\n          retryBudget,\n          budgetP.requeueBackoffs,\n          withdrawsOnly = false,\n          scoped,\n          timerP.timer,\n          next\n        )\n      } else {\n        val retryFilter = new RetryExceptionsFilter[Req, Rep](\n          retryPolicy, timerP.timer, statsRecv, retryBudget)\n        // note that we wrap the budget, since the retry filter wraps this\n        val requeueFilter = newRequeueFilter(\n          retryBudget,\n          budgetP.requeueBackoffs,\n          withdrawsOnly = true,\n          scoped,\n          timerP.timer,\n          next\n        )\n        retryFilter.andThen(requeueFilter)\n      }\n\n    svcFactory(retryBudget, filters, scoped, requeues, next)\n  }\n}\n\n```\nI suppose that this could be changed to use a RetryPolicy that is built around a ResponseClassifier.\nStill, I'm unclear on the overlap between requeue and retry backoffs.\n. That does help clarify backoffs, thanks.\n. I'm still a bit stuck on this.\nI tried changing Retries.Policy to take a RetryPolicy[ReqRep] instead of a RetryPolicy[Try[Nothing]].  Then, we could set a RetryPolicy on the stack with:\n``` scala\ndef classified(backoffs: Stream[Duration], classifier: ResponseClassifier): RetryPolicy[ReqRep] =\n    new RetryPolicy[ReqRep] {\n      def apply(input: ReqRep): Option[(Duration, RetryPolicy[ReqRep])] =\n        classifier.applyOrElse(reqrep, ResponseClassifier.Default) match {\n          case ResponseClass.RetryableFailure =>\n            backoffs match {\n              case howlong #:: rest => Some((howlong, classified(rest, classifier)))\n              case _ => None\n            }\n          case _ => None\n        }\n    }\n/*\n   * Converts a RetryPolicy[ReqRep] to a RetryPolicy[(Req, Try[Rep])].\n   /\n  private[finagle] def convertReqRepPolicyReq, Rep: RetryPolicy[(Req, Try[Rep])] =\n    new RetryPolicy[(Req, Try[Rep])] {\n      def apply(input: (Req, Try[Rep])): Option[(Duration, RetryPolicy[(Req, Try[Rep])])] = {\n        val (req, rep) = input\n        policy(ReqRep(req, rep)) match {\n          case Some((howlong, nextPolicy)) => Some((howlong, convertReqRepPolicy(nextPolicy)))\n          case None => None\n        }\n      }\n    }\n```\nThen, I would change Retries.moduleWithRetryPolicy to install a RetryFilter instead of a RetryExceptionsFilter.\nI thought this approach would be equitable, since Retries.Policy is private[twitter], however ClientBuilder exposes a retryPolicy(rp: RetryPolicy[Try[Nothing]]).  Furthermore, it seems undesirable that this RetryPolicy is distinct from the ResponseClassifier on the stack -- we'd want a way to unify these...  We could introduce a new stack module, e.g. Retries.moduleWithClassifier, that installs the proper retryFilter based on the response classifier, though it would need a new parameter type to provide the backoff stream.  Having both Retry.Policy(backoff, policy) and Retry.Backoff(backoff) veers into a redundant, confusing world.\nAt this point, I'm satisfied that I can introduce classification-based retries to linkerd properly using RetryFilter.\nI could use some guidance, however, on where to cut this feature in finagle, if at all.\nI believe that such an application-specific should/could reside in a separate stack role entirely -- the question comes to reconciling RetryPolicy and ResponseClassifier. Such a stack module could consume a generic RetryPolicy[ReqRep] (or RetryPolicy[(Req, Try[Rep])]), but I'm not sure how to reconcile that with the existing Retries.Policy. How do we expose this without having conflicting ways to configure retries.  I assume we don't want to break the public ClientBuilder API due to this change? I'm happy to spend more time on this if this is a desired feature and I can get a clearer sense of how this should be configured. Otherwise, I may just put this down.\n. Unrelated aside:\nis RetryPolicy.backoff safe?\nscala\n  def backoff[A](\n    backoffs: Stream[Duration]\n  )(shouldRetry: PartialFunction[A, Boolean]): RetryPolicy[A] =\n    RetryPolicy { e =>\n      if (shouldRetry.applyOrElse(e, AlwaysFalse)) {\n        backoffs match {\n          case howlong #:: rest =>\n            // XXX this can blow the stack, right?\n            Some((howlong, backoff(rest)(shouldRetry)))\n          case _ =>\n            None\n        }\n      } else {\n        None\n      }\n    }\nIt seems to be recursive in a way that can blow the stack.  Is the assumption here that retries are constrained by some maximum number less than the max stack size?  Should this be enforced---or at least documented?\n. @mosesn Thanks -- super helpful.  I'll share what we do in linkerd and we can spend some more time thinking about how to integrate this sort of thing into finagle.\n. linkerd's implementation of a ResponseClassifier-backed RetryFilter: https://github.com/BuoyantIO/linkerd/pull/403\n. Hm... While this allows some of my tests to pass, others fail:\nWARNING: ChannelStatsHandler caught an exception\njava.lang.NullPointerException\n    at com.twitter.finagle.netty4.channel.ChannelStatsHandler.channelInactive(ChannelStatsHandler.scala:104)\n    at io.netty.channel.ChannelHandlerInvokerUtil.invokeChannelInactiveNow(ChannelHandlerInvokerUtil.java:56)\n    at io.netty.channel.DefaultChannelHandlerInvoker.invokeChannelInactive(DefaultChannelHandlerInvoker.java:93)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:342)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:124)\n    at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:1060)\n    at io.netty.channel.AbstractChannel$AbstractUnsafe$7.run(AbstractChannel.java:747)\n    at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:339)\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:373)\n    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:742)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at com.twitter.finagle.util.ProxyThreadFactory$$anonfun$newProxiedRunnable$1$$anon$1.run(ProxyThreadFactory.scala:19)\n    at java.lang.Thread.run(Thread.java:745)\nfails at:\n``` scala\noverride def channelInactive(ctx: ChannelHandlerContext) {\n    closeChans.incr()\n    val channelStats = ctx.attr(ConnectionStatsKey).get\nconnectionReceivedBytes.add(channelStats.bytesRead.get)\n\n```\n. good news is the rest of my end-to-end tests pass when i don't check connection stats...  i'll dig into this a bit today\n. This isn't particularly tested, etc. Happy to polish more if this change is helpful.\n. What I've observed is that the lifecycle (for an http/1.0 request) appears to be:\n1. write\n2. channelActive\n3. channelRead\n4. close\n5. channelInactive\nThe write blows up because it tries to access ctx.attr(ConnectionStatsKey) before channelActive is called, and then channelInactive is called, which may also throw an exception once it tries to access the ctx.\ncc @dschobel \n. I believe that there are additional conditions (errors) where channelInactive may be called without channelActive being called -- I'll address that if I can reproduce.\n. (btw, @dschobel, updated)\n. minor fixup of tests -- it was hard to reproduce the null case fully in tests (because of mocks and whatnot). @dschobel \n. sorry, I think this is something I only ever saw out of sbt run (and i haven't run it this way recently)..  It's relatively minor and probably not worth spending time on. Closing.\n. It's not exactly that straightforward, since in linkerd we don't have a single place where we just list all of our client params (it's composed over several layers of configuration).  But, basically:\nStackClient.defaultParams +\n  FailFastFactory.FailFast(false) +\n  param.Stats(DefaultStatsReceiver.scope(\"rt\")) +\n  FinagleHttp.param.Streaming(true) +\n  ProtocolLibrary(\"http\") +\n  Netty4Impl\nFurthermore, we have configured a RetryBudget, etc.\n. The next thing I want to do is to only enable netty4 on the serverside of this linkerd instance to confirm that it's not at all related to the netty4 client...\n. this appears to be unrelated. will follow up if i can isolate this to netty4\n. Thanks, that's good to know. I was able to reproduce this on netty3 as well -- I think our load tester gets a little too connection-happy in some configurations.\n. linkerd has a build script for CI'ing against the develop branch that may be helpful: https://github.com/BuoyantIO/linkerd/blob/master/ci/twitter-develop.sh\n. This is an RFC -- I assume there's some reason why these were installed on the dispatcher and not on the stack, but I thought a PR might be the best way to discuss this.\n. I'm still trying to sort through a few things I'd like to do as a part of this change:\n- I'd like to move Dtab-encoding out of the dispatcher and into the stack\n- I think there's a minor problem with retries and dtab-encoding: if a request with Dtab overrides is retried, an error will be logged because Dtab-local headers will be present on the request when retried.\n- I don't yet understand how this should interact with clients ClientBuilder -- currently the Http codec installs context filters. It appears that, for example, ClientBuilder only ever uses StackClient.newStack and never Http.Client.stack, and so we have to replicate customizations from http's stack into http's codec...\n. OK, at this point I've moved the http client dispatcher's Dtab behavior into a DtabFilter.Injector class and added this into the client context module.  Similarly, I've deprecated the (pre-httpx) DtabFilter.Finagle in favor of DtabFilter.Extractor, which is installed via the server context module.\nStill needs CHANGES update. What else?\nThoughts?\n. In one of the test, I see that out of about 60K total requests, with ~6.5K server-disconnects, we observe ~550 ChannelClosedExceptions (exceptions caused by 8.5% of disconnects).\n. It looks like ConnectionManager is supposed to handle this:\nscala\n  def observeResponse(response: Response, onFinish: Future[Unit]): Unit = synchronized {\n    if ((!response.isChunked && response.contentLength.isEmpty) || !response.isKeepAlive) isKeepAlive = false\n   ...\nMessage.isKeepAlive checks Connection: close.\nI'm going to look at HttpTransport to see if it's possible that write() occurs before the read operation completes? or something like that?\n. Interestingly, it appears that netty4 does not exhibit this behavior and netty3 does.  I'll run more tests to confirm this.\n. i've added debug logging to com.twitter.finagle.http.codec.ConnectionManager and I see something interesting:\nscala\n    if (debug && !isKeepAlive)\n     println(s\"ConnectionManager.observeMessage($message) alive=$isKeepAlive streams=$activeStreams idle=$isIdle close=${shouldClose}\")\nin netty3:\n\nConnectionManager.observeMessage(Response(\"HTTP/1.1 Status(400)\")) alive=false streams=1 idle=false close=false\n\nin netty4:\n\nConnectionManager.observeMessage(Response(\"HTTP/1.1 Status(400)\")) alive=false streams=0 idle=true close=true\n\nI'm wondering if there are differences in the way that onFinish is satisfied between implementations (such that activeStreams is decremented differently).\nSurpisingly, Netty3StreamTransport seems to satisfy onFinish immediately:\nscala\n  private[this] val readFn: NettyOut => Future[Multi[Out]] = {\n    case res if !res.isChunked =>\n      val reader = BufReader(ChannelBufferBuf.Owned(res.getContent))\n      Future.value(Multi(mkMessage(res, reader), Future.Done))\nSo maybe there  is something else at play...\n. Indeed, onFinish.isDefined is false in netty3 and is true in netty4.  This causes the connection manager to indicate that the connection should not be closed immediately in netty3.\n. It appears that the response:\nHTTP/1.1 400 Bad Request\nConnection: close\nis marked as chunked(!).\nWhile a request with an explicit content-length is correctly marked as not chunked:\nHTTP/1.1 400 Bad Request\nConnection: close\nContent-length: 0\nThe problem is not exhibited when explicitly setting a content-length.  From Netty3StreamTransport:\nscala\n  private[this] val readFn: NettyOut => Future[Multi[Out]] = {\n    case res if !res.isChunked =>\n      val reader = BufReader(ChannelBufferBuf.Owned(res.getContent))\n      Future.value(Multi(mkMessage(res, reader), Future.Done))\n    case res =>\n      val coll: Reader with Future[Unit] = Transport.collate(transport, readChunk)\n      Future.value(Multi(mkMessage(res, coll), coll))\n  }\nWhen chunked is false, onFinish=Future.Done, and so ConnectionManager marks the request as shouldClose immediately.  In the chunked case, onFinish is not satisfied until the body is exhausted, and so shouldClose is false until this condition is met.  I believe that new requests may enter the connection between this response and the chunked response being fully read.\nSo, this problem is exhibited with chunked responses on which Connection: close is set (as is the case in the original ticket).\n. And I've reproduced this problem in netty4, so it's not limited to a single netty version.  My guess is that netty4 doesn't treat\nHTTP/1.1 400 Bad Request\nConnection: close\nas a chunked message and so it did not exhibit this error.\nWhen forcibly setting a chunked response with Connection: close, I can reproduce this problem in either netty version.\n. I added debug logging to HttpTransport to report on read(), write() and status:\nIssuing the the request:\n\ntransport.status = Open\ntransport.write()\n\nreceiving the response:\n\ntransport.reading\ntransport.read(onFinish.isDefined=false)\n\nresponse.isKeepAlive is false beecause Connection: close was set, but shouldClose is false because isIdle is false because the response stream has not ended yet...\n\nResponse(\"HTTP/1.1 Status(400)\") alive=false streams=1 idle=false close=false finished=false\n\nSomething checks the transport's status after the response is satisfied. The status is reported as Open because the response chunk's onFuture hasn't been satisfied:\n\ntransport.status = Open\ntransport.status = Open\ntransport.status = Open\n\nThen, read's onFinish is satisfied (indicating the chunk response is complete).\n\ntransport.read: finished\n\nThen, another request is immediately written on the transport:\n\ntransport.write()\ntransport.reading\ntransport.status = Closed\ntransport.status = Closed\n\nFinally, we observe the connection closed exception after the write is attempted:\n\nE 0617 21:30:02.255 THREAD72: service failure\ncom.twitter.finagle.ChannelClosedException: Connection reset by peer at remote address: /127.0.0.1:8080 from service: 0.0.0.0/4141. Remote Info: Upstream Address: /127.0.0.1:51654, Upstream Client Id: Not Available, Downstream Address: /127.0.0.1:8080, Downstream Client Id: #/io.l5d.fs/ugly, Trace Id: 7c3d9122adfd0926.a041f45e3a33e464<:7c3d9122adfd0926\n. I think I understand the issue now:\n\nWe have a client stack somewhat like the following:\n- ...\n- FactoryToService\n- ...\n- WatermarkPool\n- CachingPool\n- ...\n- HttpClientDispatcher\n  - HttpTransport\n    - ConnectionManager\nWhen a response is read in the HttpTransport, it is passed through ConnectionManager.observeResponse(rep, onFinish). The response has Connection: close and Transfer-encoding: chunked, and so the ConnectionManager is set with isKeepAlive = false and activeStreams = 1 (and so ConnectionManager.shouldClose returns false).\nThe HttpClient dispatcher essentially works as follows:\n``` scala\ndef apply(req: Req): Future[Rep] = {\n  val p = new Promise[Rep]\nsemaphore.acquire().respond {\n    case Return(permit) =>\n      dispatch(req, p).respond {\n        case t@Throw() =>\n          p.updateIfEmpty(t.cast[Rep])\n          permit.release()\n        case Return() =>\n          permit.release()\n      }\n    case t@Throw(_) =>\n      p.update(t.cast[Rep])\n  }\np\n}\ndef dispatch(req: Request, rep: Promise[Response]) = {\n  ...\n  Future.join(Seq(\n    trans.write(req),\n    trans.read().flatMap {\n      ...\n      case Multi(res, readFinished) =>\n        p.updateIfEmpty(Return(res))\n        readFinished\n    }\n  ))...\n```\nThere are two important events that occur when handling a response:\nFirst, the response promise is satisfied.  This causes FactoryToService to close the underlying service:\nscala\n  def apply(request: Req): Future[Rep] =\n    factory().flatMap { service =>\n      service(request).ensure {\n        service.close()\n      }\n    }\nWhen FactoryToService calls service.close(), CachingPool.WrappedService.close() checks the status of the underlying transport. This status check reports Open because  ConnectionManager.shouldClose returns false (because readFinished hasn't been satisfied yet), and the service is returned to CachingPool's cache.\nAt this point, a new request is received by the client and a ServiceFactory is acquired from the CachingPool. Unfortunately, the caching pool returns the same service factory that's currently being used to complete the initial response---the one that's about to close. The http client dispatcher tries to dispatch the request, but it cannot do so until the dispatcher's semaphore is released (and so it waits on acquire()).\nThen, the initial response's readFinished future is satisfied and the client dispatcher releases the semaphore, allowing the second request to be dispatched & written. By then, the server has already town down the connection, and writing the second request fails with a ConnectionClosedException.\nSo, the root of the problem is that FactoryToService closes the service once the response is satisfied and before the response stream has finished.  We wouldn't see this problem if close() was called after the response stream was finished, but there doesn't appear to be an API for receiving this notification outside of the dispatcher.\nAnother option is to change the ConnectionManager/Dispatcher to indicate status as Closed as soon the response is observed. I'm unsure of the implications of indicating that the Dispatcher is Closed while it's still processing a stream, but I'm concerned that this may cause the stream to be torn down prematurely.\n. This is an issue with linkerd -- I inserted a FactoryToService without a DelayedReleaseService under it. Inserting DelayedReleaseService fixes this issue. :tmyk:\n. Reopening to discuss another (seemingly related) issue.\nAdding a DelayedFactoryService under FactoryToService does indeed appear to fix this issue.  However, when I test this configuration against Netty4, I still observe connection closed errors (though at a much lower frequency than before). Here's what I think is happening:\nWe have a stack like:\n- FactoryToService\n- DelayedReleaseService\n- ...\n- CachingPool\n- ...\n- HttpClientDispatcher\n  - HttpTransport\n    - netty4.ChannelTransport\n    - ConnectionManager\nSometimes the server responds with a message that has\nConnection: close\nTransfer-encoding: chunked\nUsually, the client handles this properly such that:\n- The response is received on the transport\n- ConnectionManager observes the responses, marking isKeepAlive=false. activeStreams is set to 1 since the response has not completed yet.\n- FactoryToService begins closing the underlying service\n- DelayedReleaseService prevents the underlying service from closing until the response is complete\n- The response body is read.\n- The ConnectionManager is updated, marking activeStreams=0 so that shouldClose returns true.\n- DelayedReleaseService observes the stream completion and closes the underlying service\n- CachingPool checks the status of the underlying service which is Closed, and the transport is torn down.\nHowever, sometimes we observe the following:\n- The response is received on the transport\n- ConnectionManager observes the responses, marking isKeepAlive=false. activeStreams is set to 1 since the response has not completed yet.\n- FactoryToService begins closing the underlying service\n- DelayedReleaseService prevents the underlying service from closing until the response is complete\n- The response body is read.\n- DelayedReleaseService observes the stream completion and closes the underlying service\n- CachingPool checks the status of the underlying service which is Open (because ConnectionManager has not updated yet), and the transport is returned to CachingPool.\n- A new request is processed, and provisions the cached transport from CachingPool.\n- The ConnectionManager is updated, marking activeStreams=0 so that shouldClose returns true, but it's already too late because the transport is not checked.\nSo, I think it's possible that DelayedReleaseService observes that the stream has been completed and closes the service before the ConnectionManager has observed this event.\nDelayedReleaseService wraps responses so that a promise is satisfied when the reader observes a stream termination.\nConnectionManager uses the future returned from from:\nscala\n  def copyToWriter[A](\n    trans: Transport[_, A],\n    writer: Writer\n   )(eos: A => Boolean)(chunkOfA: A => Buf): Future[Unit] =\n    trans.read().flatMap { a: A =>\n      val chunk = chunkOfA(a)\n      val writeF =\n        if (!chunk.isEmpty) writer.write(chunk)\n        else Future.Done\n      if (eos(a))\n        writeF\n      else\n        writeF.before(copyToWriter(trans, writer)(eos)(chunkOfA))\n    }\nSo, I think this means that a reader's read promise may be satisfied before a writer's write-promise is?\nI'm not sure why this race only appears to manifest with Netty4. Netty3's copyToWriter looks like:\nscala\n def copyToWriter[A](trans: Transport[_, A], w: Writer)\n                     (f: A => Future[Option[Buf]]): Future[Unit] = {\n    trans.read().flatMap(f).flatMap {\n      case None => Future.Done\n      case Some(buf) => w.write(buf) before copyToWriter(trans, w)(f)\n    }\n  }\nThis seems ~equivalent and I'm not sure how/if this could change ordering semantics.\n. It does appear that Reader.writable() may satisfy read promises before write promises are satisfied:\n``` scala\n    def close() =\n      ...\n        case Reading(_, p) =>\n          state = Eof\n          p.update(Return.None)\n          Future.Done\n...\n\ndef write(buf: Buf) =\n  ...\n    case Reading(n, p) =>\n      // pending reader has enough space for the full write\n      state = Idle\n      p.setValue(Some(buf))\n      Future.Done\n\n```\nI think that this could cause DelayedReleaseService to observe end-of-stream before HttpTransport.\n. It seems that a minor change to Transport.collate resolves this:\n``` patch\ndiff --git a/finagle-netty4-http/src/main/scala/com/twitter/finagle/netty4/http/StreamTransports.scala b/finagle-netty4-http/src/main/scala/com/twitter/finagle/netty4/http/StreamTransports.scala\nindex b806424..ee139aa 100644\n--- a/finagle-netty4-http/src/main/scala/com/twitter/finagle/netty4/http/StreamTransports.scala\n+++ b/finagle-netty4-http/src/main/scala/com/twitter/finagle/netty4/http/StreamTransports.scala\n@@ -48,10 +48,16 @@ private[http] object StreamTransports {\n   )(eos: A => Boolean): Reader with Future[Unit] = new Promise[Unit] with Reader {\n     private[this] val rw = Reader.writable()\n\nbecome(copyToWriter(trans, rw)(eos)(chunkOfA).respond {\ncase Throw(t) => rw.fail(t)\ncase Return(_) => rw.close()\n})\nval f = copyToWriter(trans, rw)(eos)(chunkOfA)\nforwardInterruptsTo(f)\nf.respond {\ncase r@Throw(t) =>\nupdateIfEmpty(r)\nrw.fail(t)\ncase r@Return(_) =>\nupdateIfEmpty(r)\nrw.close()\n\n}\ndef read(n: Int): Future[Option[Buf]] = rw.read(n)\n\n\n```\nThis causes the collation future to be satisfied before the reader is closed, so that the transport may observe the state before other readers do.  I'll test this a bit longer and, if the error does not appear, submit a PR\n. @roanta interesting!  @adleong and I were just discussing how #518 is scheduler-dependent and more of a hack than a fix... I'm interested in improving this, but, if it's amenable to you, I think I'd prefer to ship the hack while we sort out what the proper solution looks like.\n. This seemed like the simplest fix to me, but I'm open to alternate approaches to resolving this race condition.\n. merged https://github.com/twitter/finagle/commit/caa4da809a754c8327be2433fb7ef90e2d289422\n. @mosesn test added, commit reworded\n. Is there a reason why this has to be implemented in finagle-http?  Couldn't this be its own library that implements the proper filters?  It seems onerous for finagle-http to take on a dependency on opentracing (or any tracing implementation, for that matter).\n. There are a number of minor improvements to flow control, but I'm especially interested in picking up https://github.com/netty/netty/pull/5324.\n. It looks like 4.1.3.Final is being released today, which has another fix that I need.  Should I update this PR with 4.1.3? Submit another PR?\n. I'm unsure how to unit test this... open to ideas.\n. Fair enough -- I suppose the alternative is to have my pipeline block the connect future from firing until the channel goes active?  Or, alternatively, buffer outbound messages until the state is active? Any suggestions?\n. @vkostyukov thanks for the explanation. I'm unclear on one thing, though:\nSuppose we use a Netty4Transporter that returns a future that is satisfied on connect; and then we use a buffering channel adapter that prevents writes on the transport from succeeding until some later state is initialized.  So, normally the following happens:\n1. Connection established.\n2. Write req0, buffering.\n3. Session established.\n4. buffered writes are flushed.\nIf step 3 fails, we fail all of the requests that were buffered.  I assume these are considered requeuable? It's not immediately obvious to me where this is handled...\nIt seems that by changing a Transporter to not return a Transport until the session is active, this problem could be avoided as session establishment errors would be treated as connection failures...\n. Cool. Thanks for helping me understand this.\n. @vkostyukov thanks for the pointer! this is exactly what I was looking for.\nIt appears that CancelledConnectionException is raised on buffered requests -- are these requests considered to be retryable? Does the RequeueFilter handle failed connections like this?\n. @mosesn That's a good point, thanks. I think the problem is that HttpTransport doesn't try to close itself after the stream finishes. Patch incoming.\n. rebased, fixed nits\n. thanks, @nepthar. Let me know if there's any context i can provide to make it a clearer (this is all pretty subtle).\nBasically: we (already) track whether a connection should be closed in ConnectionManager---there's a ConnectionManager for each HttpTransport.  HttpTransport can't use onFinish to determine when to check the connection for closure since the ConnectionManager may not be updated (there's a race between callbacks on onFinish).  So, we have to introduce a Promise on the connection manager so that HttpTransport can be informed that the connection manager views the connection as ready to be closed...  Whew! Easy, right? ;p\n. MOCKIIIIIIITOOOOOOOOOOOO!!!!!\nSorry about that, working on a fix.\n. Thanks for merging!\nIt looks like this just missed the cut for 6.38.0, but #549 is a show-stopper for linkerd. It would be hugely helpful (we can ship linkerd's grpc support) to get this into a stable release in the near future (hopefully days and not weeks?).  Let me know if there's someone I should particularly nice to...\n. (repeating what I said in Gitter for the benefit of others)\n@samstarling you are correct that this PR fixes the issue you observe. I am told that 6.39 will be released in the next ~week including this fix.\n. Furthermore, the only way to configure a CA cert with a client is to build a java SSLContext, which can't be used in conjunction with netty's SslContext...\nAre there concrete plans to address this already? The current state of things is pretty unusable for anything but trivial client tls configurations. I think we'd be willing to take this on if it's worthwhile for us to do so.. @ryanoneill that's great news! thanks.  let us know if there's anything we can do to help it along.. Out of curiosity: will this new type unify Netty3 and Netty4 tls configuration? or is the plan to just let Netty3 drift off to sea?. @ryanoneill My initial goal is only trust management.\nWe'd like to support client certs as well, but that's secondary.. Thanks for the clarification.  Some more questions:\nRe: SslClientConfiguration, how do you foresee configuration being composed from multiple sources.  I have some protocol-specific client that knows what protocols need to be supported independently of the details of verification.  It seems desirable to just simply do something like:\nparams = clientParams +\n  ApplicationProtocols(\"h2\")\n(like any other protocol-specific configuration).  hostname and trustCredentials, on the other hand, is likely to be configured separately in some endpoint-specific way (and not protocol-specific). It seems a bit awkward for these bound into one type (though I haven't read enough of the code to see how these things are actually used).  Any thoughts on how to set something like ApplicationProtocols as its own parameter (i.e. I'd want to set that on our H2 client, and i don't have enough of the other details to fill out a full SslClientConfiguration statically).\nIt is important that we be able to use an alternate crypto provider (boringssl). The netty docs indicate that the TrustManagerFactory api can only be used to configure the JDK provider.  I suspect that you have similar needs.  Is this all copacetic?. I think there are several distinct components of TLS configuration that can change independently and are typically set by different things:\n- TLS transport configuration: configures TLS itself including: Protocol, Ciphers, timeouts\n- Remote verification: Controls how a client trusts a server's identity\n- Local credentialing: Controls how a client provides its own identity to a server\n- Post-handshake application protocols: Controls the post-tls wire protocol\nApplication protocols are basically always to be set the same for all clients in a protocol, and should be able to be configured statically for the protocol (for example, here).  Local credentialing may, for instance, be configured for each process, and remote verification configured for each client.\nI think it would be simpler for people like me (who have configuration frameworks over finagle) if these can be changed independently. With a monolithic config object, levels of indirection have to be introduced to augment configured policy.. 1. Generally the \"getFoo\" names aren't used in Scala due to the Uniform Access Principal. You can simply implement def foo (and def foo_= for a setter).\n2. It seems that general header access of the form def headers: Seq[(String, String)] is desirable; and then things like from can simply be implemented on top of it like:\ndef from: Seq[MailingAddress] = headers collect { case (\"From\", addr) => MailingAddress(addr) }\n. I was hoping bound and unbound were the operative words and residual was simply an adjective.  Basically, given a path like /s/buoyant/proxy/s/svc/app/path/to/resource, a Namer may only bind a prefix like /s/buoyant/proxy and leave the residual path, /s/svc/app/path/to/resource to be bound later (i.e. by the proxy).  When the proxy binds the remaining name, it may only bind /s/svc/app, leaving /path/to/resource to be handled by the application in whatever way it deems fit.\nI'll try to figure out the best way to fit this into the docs.\n. nothing.  copy-pasta. will remove.\n. There is no such Annotation type as WireSendError, and I was trying to minimize the scope of this change--it would cause changes on the zipkin thrift struct, etc.  Furthermore, this wouldn't really be a \"wire send error\"--exceptions here would typically indicate some exception thrown somewhere on the server; and as it is, these exceptions are traced elsewhere in the stack.\n. When you say \"val'd up function\" you mean:\nscala\nval showElem: Buf => String = ...\n?\n. used on L69\n. updated both Path and Prefix to use dotted style\n. Yeah, I can revert this.  DelayedReleaseResponse seemed like a nice utility to have outside of this implementation, but now that I'm no longer using it in two places it seems best to merge back..\n. prepConn seems to be orthogonal:\nscala\n    val prepConn = new Stack.ModuleParams[ServiceFactory[Req, Rep]] {\n      override def parameters: Seq[Stack.Param[_]] = Nil\n      override val role = StackClient.Role.prepConn\n      override val description = \"Connection preparation phase as defined by a Codec\"\n      def make(ps: Stack.Params, next: ServiceFactory[Req, Rep]) = {\n        val Stats(stats) = ps[Stats]\n        val underlying = codec.prepareConnFactory(next, ps)\n        new ServiceFactoryProxy(underlying) {\n          val stat = stats.stat(\"codec_connection_preparation_latency_ms\")\n          override def apply(conn: ClientConnection) = {\n            val begin = Time.now\n            super.apply(conn) ensure {\n              stat.add((Time.now - begin).inMilliseconds)\n            }\n          }\n        }\n      }\n    }\nLet's leave this for another change, if at all\n. Oh, interesting. finagle-http's codec does install DelayedReleaseService in the prepConn:\n``` scala\n  override def prepareConnFactory(\n    underlying: ServiceFactory[Request, Response],\n    params: Stack.Params\n  ): ServiceFactory[Request, Response] =\n    // Note: This is a horrible hack to ensure that close() calls from\n    // ExpiringService do not propagate until all chunks have been read\n    // Waiting on CSL-915 for a proper fix.\n    underlying.map { u =>\n      val filters =\n        new ClientContextFilter[Request, Response].andThenIf(!_streaming ->\n          new PayloadSizeFilter[Request, Response](\n            params[param.Stats].statsReceiver, _.content.length, _.content.length\n          )\n        )\n\n      filters.andThen(new DelayedReleaseService(u))\n    }\n\n```\nPerhaps we should install DelayedRelease.module in prepConn as well?\n. Oh, oh, sorry.  I thought you were referring to prefixFailure -- I'll remove decodePath\n. I was just trying to keep this totally in line with Path api.  I can omit them if you think that would be better\n. you can't have /* or */ in a javadoc, since it messes with comment structure.  This renders as /foo/*/bar/baz in rendered javadocs.\nhttp://stackoverflow.com/questions/631817/how-to-quote-in-javadocs\n. good catch, I'll remove the dupe slash\n. @mosesn told me that the def incurs an unnecessary allocation!\n. oopsie!\n. As illustrated in the test case, /#foo names are safe. The comment character has to be found in the context of whitespace and not in a name. eatWhitespace isn't called while processing names.\nRe: character, ; is meaningful as a delimiter which Is problematic:\n/goo => /car ; comment\n          | /cab ;\nDoesn't work.\nI'm open to other suggestions but # seems like a natural comment char.\n. The test name, histogram snapshot respects refresh window, seemed appropriate...  i'll split it out if that's clearer, though.\n. oops!\n. i believe that this happens if there are errors in the write() call (which precedes channelActive in clients)\n. I just commented out for the purposes of discussion. As I mentioned earlier, I think that this error reporting should be removed, since it does not play well with retries.\n. Good idea! I didn't know about request.ctx -- let me know what you think.\n. this is the important part\n. It might be preferable to implement a com.twitter.tracing.Tracer that's backed by io.opentracing.Tracer -- this way all of finagle's built-in annotations will be automatically integrated, without requiring duplication.  This also would make the opentracing backend auto-loadable as a plugin at runtime.\n. This is intentional.  Requests are mutable, and so I want to capture the keepalive state before the request is dispatched to a service that may, for instance, remove the Connection header to send it somewhere else.\n. heh. think i copied this style from elsewhere in finagle because it surprised me. happy to standardize on new Promise ;)\n. alternatively, we could track this as a single pendingResponses field (much like activeStreams).  I suppose this would be slightly better as it has no hope of overflowing\n. @mosesn I don't quite understand... pendingResponses is always incremented in observeRequest and always decremented in observeResponse.  Isn't pendingResponses an accurate name? Is there a situation where a response is observed before a request?\n. ",
    "wanli": "You are right. maybeExpire() could take callback functions from the caller,\nbut that seems more complicated than necessary. Or we can simply pass a flag\n\"force_expire\" to maybeExpire() to always set expire to true.\nOn Mon, Mar 21, 2011 at 2:24 PM, mariusaeriksen \nreply@reply.github.comwrote:\n\nthere's a race between maybeLifeTimeExpire and the completion of the\nunderlying request: maybeLifetimeExpire can fire, and between\nmaybeExpire() and expired = true, the request can complete, leaving\ndidExpire() uncalled.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/11#issuecomment-900383\n. thanks. pushed.\n\nOn Tue, Mar 22, 2011 at 5:17 PM, mariusaeriksen \nreply@reply.github.comwrote:\n\ni've added you to the twitter team.  you should be able to push now\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/11#issuecomment-905638\n. good question. the idea is to allow the current request to finish. The next request will get a exception. \n    if (expired) {\n      return Future.exception(\n        new WriteException(new ChannelClosedException))\n    }\n\nWilhelm, is it required to release the connection?\n. On Mon, Mar 21, 2011 at 11:21 AM, arya \nreply@reply.github.comwrote:\n\n\n@@ -37,6 +51,19 @@ class ExpiringService[Req, Rep](\n     }\nif (justExpired) didExpire()\n-    justExpired\n-  }\n  +\n-  private[this] def maybeIdleExpire() {\n-    if (maybeExpire()) cancelLifeTimer()\n-  }\n  +\n-  private[this] def maybeLifeTimeExpire() {\n-    if (maybeExpire()) {\n-      cancelIdleTimer()\n-    } else {\n-      expired = true\n\nIf it enters this else, does it ever release the underlying connection? Or\nis that not a requirement?\n\nYou are right -- I think this change will fix that:\nhttps://github.com/wanli/finagle/commit/a2d0b26b4a9169de242a7771327deea4d265745b#commitcomment-309679\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/11/files#r10453\n. this is much better. fixed.\n\nOn Mon, Mar 21, 2011 at 2:11 PM, mariusaeriksen \nreply@reply.github.comwrote:\n\n\n\nSome(timer.schedule(maxIdleTime.fromNow) { maybeExpire() })\nprivate[this] var idleTimeTask: Option[com.twitter.util.TimerTask] =\nmaxIdleTime match {\ncase Some(idleTime: Duration) =>\nSome(timer.schedule(idleTime.fromNow) { maybeIdleExpire() })\ncase _ =>\nNone\n}\n  +\nprivate[this] var lifeTimeTask: Option[com.twitter.util.TimerTask] =\nmaxLifeTime match {\ncase Some(lifeTime: Duration) =>\nSome(timer.schedule(lifeTime.fromNow) { maybeLifeTimeExpire() })\ncase _ =>\nNone\n}\n\n\nfor both of these, you can use map:\nprivate[this] var idleTimeTask = maxIdleTime map { idleTime =>\ntimer.schedule(idleTime.fromNow) { maybeIdleExpire() }) }\netc.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/11/files#r10552\n. Fixed and pushed to origin. But I don't have write access to twitter/finagle\nto merge.\n\nOn Tue, Mar 22, 2011 at 9:25 AM, mariusaeriksen \nreply@reply.github.comwrote:\n\n\n\nprivate[this] def maybeExpire() = {\nprivate[this] def maybeExpire(force_expire: Boolean) = {\n\n\n(after that, looks good, please merge!)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/11/files#r10829\n. \n",
    "fizx": "For a while, a 2.8.1 build of specs didn't exist.  We could/should fix this.  Patch welcome ;)\n. ",
    "stevej": "We couldn't rely on %% to give us the semantics we wanted in a multi-versioned world so we relied on hard-coding versions of Scala.\nWe don't think there's a bad interaction between scala 2.8.1 and the version of specs we're using, this is just an accident of history.\nOne of us will clean it up unless some nice person on the internet gives us a patch first.\n. I'm working on moving this to finagle-core and adding tests today.\n. While writing a unit test suite, I ended up hardening RoundRobin a bit. Most of the test scenarios were originally borrowed from P2CBalancerTest.\nI also added a type constraint to DistributorT#This to enforce by the compiler what we had been expecting users to do by convention.\nsbt needs wider access permissions for some of the traits/classes in the loadbalancer package in order to compile and run their tests. This is probably not an issue with your own build system, just with the open source release.\n. I am totally fine with those changes. (please remember to change Simluation which calls Balancer.rr)\nupdog is good. I'll inform the office about this change.\n. @fwbrasil They're only problems in that they're being deoptimized. The documentation is slight and I don't spend a lot of time digging around OpenJDK so please let me know if I'm wrong here but my understanding is that deoptimization means jitted native code is being ejected from the code cache and the bytecode interpreter is being used for that method until the jitter kicks in again. It's possible these are side-exits but that would surprise me.\nAnd no, I don't see any explicit log lines about methods being too large to be inlined.\n@kevinoliver I did a spot check of some of the util methods and most aren't being re-optimized later.\n(The first number in time in millis since the process started)\n/Users/stevej/jit_watcher_086% cat jitwatcher_print.log |grep \"com.twitter.util.Promise::link\"\n  47234  783             com.twitter.util.Promise::link (508 bytes)\n1461433  783             com.twitter.util.Promise::link (508 bytes)   made not entrant\n1461732 2289             com.twitter.util.Promise::link (508 bytes)\n1475537  783             com.twitter.util.Promise::link (508 bytes)   made zombie\n2849690 2289             com.twitter.util.Promise::link (508 bytes)   made not entrant\n2849889 2329             com.twitter.util.Promise::link (508 bytes)\n3048233 2329             com.twitter.util.Promise::link (508 bytes)   made not entrant\n3048385 2333             com.twitter.util.Promise::link (508 bytes)\n3322357 2289             com.twitter.util.Promise::link (508 bytes)   made zombie\n3327810 2329             com.twitter.util.Promise::link (508 bytes)   made zombie\n/Users/stevej/jit_watcher_086% grep \"com.twitter.util.Promise::updateIfEmpty\" jitwatcher_print.log\n  44835  647             com.twitter.util.Promise::updateIfEmpty (252 bytes)\n1968729  647             com.twitter.util.Promise::updateIfEmpty (252 bytes)   made not entrant\n1968835 2305             com.twitter.util.Promise::updateIfEmpty (252 bytes)\n2319234  647             com.twitter.util.Promise::updateIfEmpty (252 bytes)   made zombie\n/Users/stevej/jit_watcher_086% grep \"com.twitter.util.Promise::continue\" jitwatcher_print.log\n  44629  633             com.twitter.util.Promise::continue (423 bytes)\n  50226  633             com.twitter.util.Promise::continue (423 bytes)   made not entrant\n  51229  949             com.twitter.util.Promise::continue (423 bytes)\n  52031  633             com.twitter.util.Promise::continue (423 bytes)   made zombie\n 189924  949             com.twitter.util.Promise::continue (423 bytes)   made not entrant\n 191023 2076             com.twitter.util.Promise::continue (423 bytes)\n 202127  949             com.twitter.util.Promise::continue (423 bytes)   made zombie\n 301036 2076             com.twitter.util.Promise::continue (423 bytes)   made not entrant\n 301133 2229             com.twitter.util.Promise::continue (423 bytes)\n 501840 2076             com.twitter.util.Promise::continue (423 bytes)   made zombie\n1006535 2229             com.twitter.util.Promise::continue (423 bytes)   made not entrant\n1006633 2254             com.twitter.util.Promise::continue (423 bytes)\n1174634 2229             com.twitter.util.Promise::continue (423 bytes)   made zombie\n/Users/stevej/jit_watcher_086% grep \"com.twitter.util.Promise::forwardInterruptsTo\" jitwatcher_print.log\n  44435  626             com.twitter.util.Promise::forwardInterruptsTo (280 bytes)\n 712438  626             com.twitter.util.Promise::forwardInterruptsTo (280 bytes)   made not entrant\n 712532 2246             com.twitter.util.Promise::forwardInterruptsTo (280 bytes)\n 952933  626             com.twitter.util.Promise::forwardInterruptsTo (280 bytes)   made zombie\n/Users/stevej/jit_watcher_086% grep \"com.twitter.util.Promise::setInterruptHandler\" jitwatcher_print.log\n  67826 1275             com.twitter.util.Promise::setInterruptHandler (280 bytes)\n1461433 1275             com.twitter.util.Promise::setInterruptHandler (280 bytes)   made not entrant\n1475537 1275             com.twitter.util.Promise::setInterruptHandler (280 bytes)   made zombie\nI just wanted to bring this to your attention. If you're not concerned or if I'm mistaken on what this means, I'm ok with closing this ticket.. I went ahead and put the whole -XX:+PrintCompilation log into a secret gist.\nhttps://gist.github.com/stevej/569e917fddef919b6ae29369f00e92ec. @christhalinger Thank you for the followup (and especially for clarifying my misunderstanding of the -TieredCompilation flag), can you tell me if the deoptimizations I mentioned in the comment above (https://github.com/twitter/finagle/issues/588#issuecomment-283411421 ) match the pattern you're warning against? They seem to be getting deoptimized and recompiled numerous times.\n(Update: actually, you said you already scanned the logfile so I'll withdraw my comment. Thanks again!). Ok, I've updated this paragraph to describe the data (median, stddev, max) instead.\n. Sure, I can move it and improve the scaladoc to match what you'd expect from something in finagle-core. I'm surprised you have a serious use case for Round Robin that isn't better served by almost any other choice currently in finagle. Would you also want it exposed easily as Balancers.rr?\n. I went ahead and set it to 5 which is the default in Balancers. Based on your comment, I'd ideally set it to the size of the vector but I don't have access to that here. Maybe activity.values.size? That doesn't seem totally right to me.\n. That's a good question, I cribbed this method from P2CBalancerTest and marius wrote this comment in 1179a23b. I mean, it seems fine to me.\n. If I rebuild, will the Closed node still be in the list? If yes, then rebuilding is not an effective strategy here. The lifecycle for the list of nodes is not entirely clear to me. \nIf a rebuild is the wrong choice here, I can either partition the list or move the index forward one and keep trying but I'll need some way to signal that all nodes are down in that case or else we'll spin forever. I could also do what I've done here (find any node ready to serve traffic) and the index will be updated on the next call and not set sawDown to true.\n. Ok, I'm now partitioning into down and up Vectors and triggering rebuild if a member of either should be moved. That's a lot nicer and separates concerns neatly. If somebody really needs a consistent ring across rebuilds, I think it's best if they add that when they have specific requirements.\nI killed that comment about the mean calculation not being \"quite right\"\n. thanks, removed App.\n. Thanks, I changed that.\n. this is now gone due to the other change you suggested.\n. I'm digging into whether vector.size is efficient.\n. Vector.size looks efficient, it is integer subtraction.\nhttps://github.com/scala/scala/blob/2.11.x/src/library/scala/collection/immutable/Vector.scala#L81\n(def size = length is found in SeqLike.scala)\n. the convention of the other balancers is to make these protected. I don't know why that choice was made but it's not strictly required so I've reverted back to default access modifiers for RoundRobinBalancer\n. noted in the comment now.\n. ",
    "jorgeortiz85": "You can get around this by creating a \"specsVersion\" variable and matching on the Scala version.\nSee: https://github.com/foursquare/rogue/blob/master/project/build/RogueProject.scala#L19\n```\nlazy val specsVersion = buildScalaVersion match {\n  case \"2.8.0\" => \"1.6.5\"\n  case _       => \"1.6.8\"\n}\nval specs = \"org.scala-tools.testing\" %% \"specs\"          % specsVersion      % \"test\" withSources()\n```\n. ",
    "sclasen": "Looks like using  ClientBuilder.buildFactory() and  ServiceFactory.service fix this.\nShould that be reflected in the samples?\n. Ok will do, thanks.\n. Bumped it to 1.7.4 since I saw that was latest...been banging on the app and so far so good.  \nNow only seeing the odd WriteException, and valid/expected occurrences of TimedoutRequestException and CancelledRequestException \nWill close the issue tomorow if behavior stays consistent, thanks for your help!\n. +1 on this, we would like push stuff to central that uses finagle and twitter-util but that's not allowed since finagle and twitter-util arent there themselves\n. ",
    "ticktock": "I actually have also seen these using ServiceFactory too, so maybe its just a coding error? \nI see the TooManyConcurrentRequestsException is grouped with the \"API Misuse\" exceptions. What would cause this to be thrown?\nI changed some of my code and most of them disappeared, but they still occur very sporadically.\nthe client builder is  \nvar builder = ClientBuilder()\n  .codec(Http(_maxRequestSize = 100.megabytes, _maxResponseSize = 100.megabyte))\n  .sendBufferSize(1048576)\n  .recvBufferSize(1048576)\n  .hosts(new InetSocketAddress(host, port))\n  .hostConnectionLimit(Integer.MAX_VALUE)\n  .hostConnectionMaxIdleTime(5.seconds)\n  .retries(1)\n  .name(host)\nif (ssl) (builder = builder.tlsWithoutValidation())\nThe general usage pattern is \n```\nval nearClient:ServiceFactory[HttpRequest, HttpResponse] = ...\nval farClient:ServiceFactory[HttpRequest, HttpResponse] = ...\nval req = new DefaultHttpRequest(...) \nnearClient.service(req).flatMap {\n      nearResp =>{\n          if(nearResponse.../accepatble/){\n                Future.value(nearResp)\n          } else {\n               farClient.service(req).flatMap{\n                      farResp =>{\n                          if(farResp.../acceptable/){\n                                val put = new DefaultHttpRequest(....)\n                                put.setContent(farResp.getContent.duplicate)\n                                nearClient.service(put).onSuccess(...).onFailure(...).onCancellation(...)  \n                          }\n                          Future.value(farResp)\n                      }           \n                }\n         }\n     } \n}\n```\n. Thanks for the usage tips, I am on 1.6.2\nIn the course of introducing the stats reciever, or some other code change today, I seem to have made the TooManyConcurrentRequestsExceptions go away, so it seems it may have been an error on my part.\nThe only thing I am seeing now are a few WriteExceptions now and again, followed by this log message, which actually comes from netty SimpleChannelHandler.\nchannel: EXCEPTION, please implement com.twitter.finagle.http.ClientConnectionManager.exceptionCaught() for proper handling.\nchannel: java.net.ConnectException: connection timed out \nchannel:     at   org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processConnectTimeout(NioClientSocketPipelineSink.java:371)\nThe exceptions I was and am now seeing were all coming from load generated by a test harness written using finagle, modeled after the Stress example, with concurrency of 16 and pushing 32k requests through.\nI will keep banging on the app and see if I can get the TooManyConcurrentRequestsExceptions...if I dont have any luck in the next day or 2, Ill close the issue\n. Actually just saw a few TooManyConcurrentRequestsExceptions.  I will get the stats together for you.\nI guess i should mention that on top of the general pattern I showed above, there is parallel request processing going on too, \nof the form\n```\n  val futures: List[Future[HttpResponse]]] = clientPairs.map {\n      _ match {\n           case (nearClient, farClient) => doRequestMentionedAbove(nearClient,farClient,...)\n      }\n  }\nval (first, rest) = Future.select(futures).get\n  rest.foreach(_.cancel)\n```\nNot sure if this gives any further hints...\n. Ok all good with no more TooManyConcurrentRequestsExceptions. Is there a target release number/date for the WriteException supression?\n. ",
    "mosesn": "We can now use ResponseClassifiers to choose whether to handle different successes or failures as failures or not, so I think we can mark this one as fixed.\n. @george-vacariuc any update on porting this to mux?\n. ok, keep us posted.  thanks!\n. And now it has been merged back into github.\n. @george-vacariuc we've been thinking about how it's a huge pain that finagle keeps changing underneath your feet so it's hard to merge in finagle-protobuf.  We've also been putting similar projects under the finagle organization.  What do you think about the idea of making finagle-protobuf its own project under the finagle org, so that it doesn't have to go through the same stringent code review process?  We can also make you an owner of the project, so you'll be able to merge pull requests etc yourself, which makes the most sense since you're the expert on finagle-protobuf.\nWe'll still be happy to consult on finagle-protobuf, but we won't have to end up in these sinkholes where nothing gets done.\nThoughts?\n. @george-vacariuc any update from your compliance folks?\n. I'm trying to compile just finagle-zipkin, so that I can include it in another project like so:\nlibraryDependencies += \"com.twitter\" %% \"finagle-zipkin\" \"1.0-SNAPSHOT\"\nand then fetch it from my local repository.  If I try to publish-local using the original build files, I get all of finagle in my local repo, which is not what I want.  Also, the reason I am trying to publish-local in the first place instead of fetching from twttr is that I ran into problems with compatibility that I'm betting are because finagle-zipkin isn't cross-compiled on twttr.\n. I am working with a slightly hacked version of finagle that is current up to 3.0.0.  Since the API for finagle hasn't changed since then, it seemed like it would be fine as long as I compiled it to the same version of scala.  The only problem is that finagle-zipkin didn't exist back in the day.\n. are you saying that I can find a ZipkinTracer in finagle-b3?\n. I don't know what all of the changes are, I'll talk to someone who does and see what's up.  In the mean time, do you know why I can't find scribe.ServiceToClient?  It seems to be something that your thrift can do, based on https://github.com/twitter/finagle/issues/45, but it can't be done with scrooge, as far as I can tell.\n. Is sbt-thrift compatible with build.sbt?\n. Alright, good to know.  I'm working on getting us upgraded to what's current, so probably at least one of these will pan out.  Thanks for the help!\n. Cool, I get it now.\n. going to review this internally first, sorry for the mispull.\n. Hopefully in a few days.  A big change was just made to finagle-redis, and I need to update these commands to make it work with the new scheme.  However, finagle currently doesn't build, so I can't work on it.  In the mean time, feel free to clone the tumblr repository, which already has these commands.  You can publish-local, and then build using that.\n. @zhanggl this pull request is now up to date with the rest of finagle, tested, and should work properly.  I hope it's useful to you!\n. @anirudh This PR is ready to rock!  Please give it a lookover, I think it's pretty good right now.\n. sweet, when should I expect to see this in master?\n. @abbaspour can you use ./sbt make-pom?\n. If you assign it to me, I'll fix this when I get some free time.\n. @mariusaeriksen this compiles, but it fails a bunch of tests, and then hangs.  can you repro?\n. This was fixed.\n. This change is very similar to #252 which will be merged shortly.  Closing for now, thanks for kicking this off!\n. @wishoping this is a very old issue, but were you able to solve your problem?\n. Great, thanks for moving quickly on this.\n. @ivankelly we're planning on migrating to 0.10.0 shortly, so we won't have to be on our fork anymore.  I expect it to be within less than a month.\nIn the mean time, I believe that you can edit the libthrift JAR on your end to add the NOTICE file.  Alternatively, you can instead exclude our fork of libthrift, and depend explicitly on vanilla libthrift-0.5.0.\nSorry for the oversight, and thanks for pointing it out to us.. @ivankelly isn't the NOTICE that it needs https://github.com/apache/thrift/blob/master/NOTICE ?\nWhen you say\n\nyou distribute the derived work, you must also distribute the NOTICE from the original work\n\nI interpret that as, when you distribute the twitter JAR, you need the NOTICE from apache thrift.\nIf that doesn't work for you, how would you feel about waiting for ~ a month for us to sort out the 0.10.0 stuff?  It's almost ready to go but we want to wait to do the cutover until after the holidays.. Sounds good, sorry I don't have a better answer for you :/.  We'll make sure to get the 0.10.0 stuff going in a timely manner.. This was implemented and rolled out a long time ago.  We're migrating to Failure lazily.  cc @roanta \n. Alright, I made a pull request, the api changed slightly, I described the change in my PR.  Changed to logException.\n. This is now in the finagle docs.  Thanks for the bug report!\n. No problem, happy to contribute.\n. @infinity0 this isn't on our roadmap to provide out of the box with finagle.  Were you able to implement a codec to do it?\n. Seems like this probably dropped off of @infinity0's radar, closing the ticket for now since it's not part of our plans.\n. @roanta tells me that this has been merged internally.  I think that only up until twitter/finagle@a51ec07 was merged internally.  I pushed to this branch, forgetting that it hadn't been pushed back into the open source repo.\nI'm not sure what to do in this situation.  Should I revert twitter/finagle@a2df331 on this branch?  I have a new branch with a new pull request in #154.\n. thanks!\n. I don't know.  I'll talk to someone more knowledgeable on my team.\n. I talked to some team members, and they point out that is a pretty useful point to be able to inject arbitrary code.  It's not an especially concerning vector for attack, but it's fairly useful to be able to do things like collect data about connection churn, etc.  From the point of view that it could be used for plenty of things other than just session variables, I think it makes sense to keep it a function.\n. What are our next steps with this PR?  Does it need to be restarted from scratch to work with the new api?\n. sounds good!\n. @hellokangning if you use a new version of finagle, you won't have to depend on maven.twttr.com at all.  see this blog post for more details.\n0: https://finagle.github.io/blog/2016/11/29/central-libthrift/. @ponkin @roymax \nAre you still able to repro this issue?\n. If you run into this problem again, please let us know.\n. finagle now has a build.properties again.\n. The documentation in the user guide has improved significantly.  I'm going to mark this as fixed.\nhttp://twitter.github.io/finagle/guide/Clients.html\n. Looks like this bug was fixed.  Marking this issue as done.\n. There are descriptions in the scaladocs.\n. Looks like this is a confusing API in finagle-http.  We're planning on simplifying the Request and Response APIs, so hopefully that will improve matters here.  I think this works as expected though, so I'm going to close this issue.\n. I think so?  Have you done this by any chance :P\n. End of next week is fine, I don't think anyone needs this more urgently than you do (and if they do, they can run their own tests :P)\n. Looks like you should be able to call Transport.peerCertificate on the serverside.\nI don't think it's officially deprecated yet, but we're gently encouraging folks to use the finagle-6 style APIs.\n. Have you tried calling Transport.peerCertificate?  Or is your question about how to invoke the method?  Transport is an object, so it's available globally.\nThe actual code would look like:\nscala\nval cert = Transport.peerCertificate\n. It doesn't expose many things this way, but it does for a few things, like Traces.  It's a context that gets threaded through your execution context when you do things like Future#map.  Most users don't ever need to use the Local mechanism directly (we consider it an expert feature), so we don't document it explicitly.  It should \"just work\" in the majority of cases.\n. Rad, then I'll mark it as solved :]\n. HttpDechunker is kaput!  Thanks for the bug report.\n. HttpDechunker no longer exists, so I'm going to close this PR.\n. This was merged.\n. @astubbs it seems like this PR is dead?  did you find a work-around?\n. Closing for now.  Please reopen if you run into this problem again.\n. I might be misunderstanding, but wouldn't a Filter fit your needs?  Something like LoggingFilter seems like it solves this specific problem.\n. Take a look at Http LoggingFilter, confusingly also named LoggingFilter (for historical reasons) :)\nFilters are designed to be composed in the way that you're describing, filter andThen service.  Here are some docs that might be useful.\n. @astubbs revisiting this now--when I answered your question before I wasn't a part of the finagle team, so I have better insight into what's going on now.\nFinagle prefers stats to logging because at the throughput that most finagle services get, logging to disk on the hot path would end up making your computer do a lot more work.  It's often harder to interpret logs than it is to interpret stats, and stats are much cheaper to add than logs.  ClientBuilder has a feature which turns on a ChannelSnooper and very heavy channel-level logging for debugging, but we probably don't want to add logs to the hot path which will be used in production.\nA separate repo is the right place to put your contribution, thanks!\n. @romemore we implemented @stevegury's suggestion, let us know if you run into any more problems!\n. @mkhq, could you get the SRANDMEMBER object be able to handle the optional parameter properly instead of just getOrElse-ing?  We should be able to accept after that.\n. Yes, that is what I mean.\n. Ok, I changed back initialCommands.  Do you prefer omitting initialCommands so that people don't have confusing behavior when starting the console?\n. I think this is a solid starter issue.  We might be able to rehydrate #191, add a test and merge it in.\n. We ended up solving a similar problem recently.  We solved it with this commit.  @eric do you think that will solve your problem?\n. @eric haven't heard from you lately, so I'm going to close this PR for now.  If you run into more problems, please let us know and we can reopen it.\n. Here we're just forcing everyone to UTC, so it doesn't matter what the client's original timezone was.  I don't think I understand your question.\n. Oh, it occurs to me that what I linked to wasn't the entire thing.  The first commit was here.  I'll try to get the person worked on it in here to talk with you.\n. Bummer, thanks for the update.\n. This was merged a month ago, thanks!\n. Merged.  Thanks for the contribution!\n. I think we fixed this problem.  No longer seems to hang.\n. I think this has been fixed.  Can you still repro?\n. 99% sure this has been fixed.  See here.  Closing for now, please let me know if you run into this problem again.\n. +1\n. Nope, we're working on pulling it in internally.  I'll keep you posted.\n. This has been pulled internally, it should show up in a little while.  Thanks for your submission :+1: \n. Hey, we really appreciate your contribution.  Unfortunately, it actually turned out that we had another patch in the works which needed to be shipped and subsumed this, which you can find at https://github.com/twitter/finagle/commit/a0b273029fc2086c49b94624f89953b3b5ddfcdf.  The good news is that part of shipping that commit was widely testing it in production, so we are pretty confident in it.  Thanks again for your contribution! :revolving_hearts:\n. Yep, it's on the roadmap.  We work closely with the netty team, and hope to be able to spend some time to get it done soon.  In the mean time, if you want to try it out yourself, there has been a lot of work done recently to decouple finagle from netty 3.  I would suggest taking a look at DefaultClient and DefaultServer.\n. Might as well do it after the migration is done so people with the same\nquestion as you know that it's on our radar.\nOn Tue, Oct 1, 2013 at 12:07 AM, Yuta Okamoto notifications@github.comwrote:\n\nThanks for your fast reply. I'm looking forward to the new version. I will\nsee the suggested codes.\nDo you want to close this issue now or when the migration is done?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/issues/204#issuecomment-25429474\n.\n. @ernieKovak thanks for the heads up.  Twitter keeps track of vulnerabilities that appear in any lib we depend upon, and make sure to upgrade if there's a problem.  Happily, finagle doesn't use any of the netty websockets stuff, and we're on netty 3.9.4, so the version of netty we're on has had the fix for a long time.  When we upgrade to netty 4, we'll upgrade to the latest version, so we won't have to worry about bugs in netty 4.0.19.\n. @eshelestovich one thing that helps us here is that netty 3 is in a different namespace from netty 4, so finagle-core can still depend on netty 3 but use netty 4 under the hood.\n. Hi @drozzy, sorry you've had trouble with this.  As @nshkrob mentioned, you can use maven.twttr.com in the mean time.  Note that it uses ssl now, so you'll want to go to https://maven.twttr.com/org/apache/thrift/libthrift/0.5.0/\n. This is a duplicate of https://github.com/twitter/finagle/issues/133, so I'm going to close this ticket.  Unfortunately, it's still a low priority internally to fix this.\n. I like the idea here, but Clusters are deprecated.  It doesn't make sense to add a new one right now.  Can you get these to work with the Name api?\n. @agleyzer Not sure if you're still interested in this problem, but I just stumbled on this ticket again.  I think @mariusaeriksen is right that this shouldn't be special behavior, this should just be the way that the InetResolver works all the time.  Do you still have the bandwidth to make this happen?\n. @agleyzer that solution looks great.  Would you mind if @jdanbrown refashioned it to be the default for \"inet!\"?\n. Awesome.  @jdanbrown let me know if you need any help.\n. @agleyzer @jdanbrown looks like this fell through the cracks, do either of you have the bandwidth to take this on?\n. Sure, if you want to take it on, we'd be glad to take your PR.  None of us at twitter has the bandwidth to do it, so it will have to be community driven.\n. #282 implemented this, so I'm going to close this PR.  Thanks to @jixu and @agleyzer for this super cool feature!\n. We're working with @george-vacariuc to make sure it follows current best practices.  You can follow progress here.  If you want to use it in its current incarnation, you can also build it locally.\n\nIn the future, you will probably get a faster response if you ask a question on our google group, finaglers.  It's also a good source of information on questions like this.\n. This looks great.  Could you add a test so that we can make sure this doesn't happen again in the future?\n. Looks good to me!  Thanks for the contribution, I'll see about getting it merged in.  There's a little more process that it has to go through on our side, I'll close the PR after we've pulled it internally.\n. This was merged internally, should show up soon :)\n. @anttipoi your test project doesn't compile for me locally.\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=utf8\n[INFO] Scanning for projects...\n[INFO]\n[INFO] ------------------------------------------------------------------------\n[INFO] Building ftest 1.0-SNAPSHOT\n[INFO] ------------------------------------------------------------------------\nDownloading: http://artifactory.local.twitter.com/repo/org/scala-tools/maven-scala-plugin/2.15.2/maven-scala-plugin-2.15.2.pom\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD FAILURE\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 2.746 s\n[INFO] Finished at: 2015-02-04T14:59:34-05:00\n[INFO] Final Memory: 7M/123M\n[INFO] ------------------------------------------------------------------------\n[ERROR] Plugin org.scala-tools:maven-scala-plugin:2.15.2 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.scala-tools:maven-scala-plugin:jar:2.15.2: Could not transfer artifact org.scala-tools:maven-scala-plugin:pom:2.15.2 from/to Twitter (http://artifactory.local.twitter.com/repo): hostname in certificate didn't match: <artifactory.local.twitter.com> != <*.twitter.biz> OR <*.twitter.biz> OR <twitter.biz> -> [Help 1]\n[ERROR]\n[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.\n[ERROR] Re-run Maven using the -X switch to enable full debug logging.\n[ERROR]\n[ERROR] For more information about the errors and possible solutions, please read the following articles:\n[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/PluginResolutionException\nAre you still running into this problem?\n. Ah, good luck!\n. This has since been fixed.  Thanks!\n. Oops, I got confused, didn't realize this was in a comment.  I'll get this pulled internally.\n. This has been merged internally, you'll see it up here in a little while.\n. Good point!  Can you make a PR?\n. Looks great!  Any reason you chose 6.7.1 instead of 6.7.4?\n. The README will no longer reference a specific finagle version, so I'm going to close this PR for now.  Thanks for contributing!\n. Hey @jeffreyolchovy, sorry we're only getting to this now, I don't really have the expertise to handle this, I'm going to find someone who knows more about http to take a look at this. \n. I think @jeffreyolchovy's patch fixes this, closing this for now.  Please reopen if there are still issues.\n. Looks like you've done a pretty thorough analysis!  We'd love to get a PR for this.\n. I'll try to make time to take a stab at it this weekend.  I'll keep you posted.\n. Netty is now on 3.8.0.Final.\n. This was merged internally.\n. I think this has been fixed.  Thanks for the bug report!\n. This was merged.\n. @softprops it turns out it's a huge pain to get historic tags.  I'm going to start manually adding tags going forward though.\n. this is a dup, I got confused by github's UI.\nhttps://github.com/twitter/finagle/issues/224\n. I might be misunderstanding--I don't think the RFC proposes a mechanism, outside of a few utilities for constructing heuristics.\nI'm hoping that Stack will be able to be used as a tool for reducing the surface area of our APIs, but there's more work to make them truly configuration-less.\nOn the other hand, NOTSLOW might obsolete this API, if it turns out that every variety of remaining configuration can be rephrased as meeting an SLO.  I'm not sure whether or not that's the case.\n. I think you're right.  If I have a chance to sit down with this problem again, I'll probably close this issue/RFC combo in favor of just a prescriptive issue here, and then publish a separate RFC to the external finaglers list.  Internally, the wiki seems like a good place for it, but it's a little more complicated externally.  Maybe it would make sense to stick RFCs and a roadmap into the user guide.\n. This was merged internally, thanks for the PR!\n. This is in the external repo.  Thanks for the contribution!\n. Sorry, accidental close.\nYeah, we have ReferenceCountingFilter for the client side, but it's not correct for the server side, because the Service on the client side encapsulates the entire request end to end, but on the server side, the Service is just shelled out to by the Server.  We can try adding something to the Pipeline to detect when all of the bytes for all of the requests have left the Channel.  That might work.  We could increment a counter for when a request comes in and decrement when the response goes out, or when the connection gets closed / dropped.\n. Why have you turned off failFast?  FailFast is designed to handle exactly\nthis behavior (more specifically, rolling restarts).\nOn Thu, Dec 5, 2013 at 7:51 AM, yaniv3007 notifications@github.com wrote:\n\nI am using finagle client to connect with remote server. I am using it\nlike this:\nvar builder = ClientBuilder()\n.codec(RichHttpRequest http://Http(.maxResponseSize(20.megabytes)))\n.hosts(hostStr)\n.hostConnectionLimit(20) // max number of connections at a time to a host\n.tcpConnectTimeout(1.second) // max time to spend establishing a TCP\nconnection\n.requestTimeout(requestTimeout)\n.retries(2) // (1) per-request retries\n.failFast(false)\nThe scenario:\nSend requests to remote server - everything is ok\nNow shutdown server\nSend new request to server - got exception -> it is ok\nNow start server.\nSend new request -> getting com.twitter.finagle.ChannelClosedException:\nChannelException at remote address:\nNo recovery, no retires.\nI need to close the server and start it again.\nPlease advice.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/issues/228\n.\n. Which server is giving you the ChannelClosedException?  Here's what I'm imagining\n\nClient -> Server A -> Server B\nServer B shuts down\nServer A gets back a Future.exception\nServer B starts back up\nServer A can never connect to B again, even though B has recovered.\nIs that correct?  I think I would understand better if you attached a gist showing how to repro.\n. Up to date docs can be found at the finagle user guide.  We'll add a note to the finagle README that it's out of date, but we're not going to remove it yet because the user guide doesn't quite have parity.  We'd love to get some pull requests for better docs though!\n. oops, closed accidentally.  reopening until the note actually shows up on the README.\n. This was merged a while ago, thanks!\n. This was merged, thanks for the contribution!\n. There's an issue in our tooling which is making it hard for us to publish to http://maven.twttr.com right now (we only want to do it when we know we can do it securely) so right now we're only publishing externally to maven central.  Is that what you're looking for?\n. Would you mind if we moved this question to the google group too?  This is a question that we answer a lot internally, but I'm now realizing that we haven't published broadly outside.\n. @eric would you mind if we moved this question to the finaglers google group?  I think other people on the google group would also be interested in the response.\n. It's going through the internal review process right now.  We'll keep you posted.\n. This has been pushed.\n. This was merged, thanks for the contribution!\n. Thanks for the PR!  However, I think this is a duplicate of #237.\n. Roger.\n. Whoops, my mistake, there are actually two index.htmls.  This updates a different link than the commit I linked to.  This is not a duplicate.  Merging this internally now.\n. This has been merged internally.  We'll close this when it's publicly available.  Thanks for the PR!\n. This was merged.  Thanks again for your contribution!\n. This got merged, thanks for the bug report!\n. More discussion on the finaglers list serv.\n. We still don't have a great solution for this, but this ticket is mostly a red herring.  I'm going to close it for now.  Thanks for the great discussion, @azenkov!\n. @jdanbrown @luciferous Just wanted to follow up on this patch.  What's the latest status?\n. We'd be happy to accept a pull request--I think the right solution might be to use InetAddress.getLoopBackAddress(), but it's java 7 only, and we still need to support java 6.\n. @wenfengzhuo are you still running into this problem?  Since this is so old, I'm going to close this for now, but feel free to reopen if this is still causing you trouble.\n. Looks like a bug to me!  I'd be happy to see a patch of this.  Let me know if you want guidance on how to proceed.\n. Please take a look at our CONTRIBUTING file, which provides a starting point.  Also, in your pull request, please format your PR so that it is structured  \nMotivations:\ndetails here  \nModifications:\ndetails here  \nResults:\ndetails here  \nLike it is in this commit.\nAs far as the actual work, I'd recommend adding those two tests that you have in your issue report to the redis tests in finagle, and keep working on them until they pass.  The error message points to this line which makes it seem like it's an error message from redis, so we're probably passing it something bad.\ndoRequest is where we actually make the request, so it might be worth adding some logging around there while you're debugging to check exactly what bytes we're sending over the wire, and why redis isn't happy.  You can also use redis monitor to see what the server acknowledges, if you're running against a live server.  The code where we encode the redis protocol is mostly in the Hashes file.\nLet me know if you need help getting finagle building or testing on your local machine.  Happy hacking!  I'm excited to add you to the contributors list.\n. fixed by #245 \n. Would love to see fixes for those too! Good catch.\nOn Feb 24, 2014 11:37 PM, \"zhanggl\" notifications@github.com wrote:\n\nAlso, please note that many other commands with StrictValueCommand have\nthe same issue, among which are Set, GetSet, PSetEx, SetEx, SetNx, etc.\ntrait StrictValueCommand extends ValueCommand {\n  RequireClientProtocol(value != null && value.readableBytes > 0,\n    \"Found unexpected empty value\")}\nPlease let me know if I can do anything.\n\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/245#issuecomment-35974314\n.\n. @zhanggl removing StrictValueCommand sounds good to me.  Actually, removing everything in https://github.com/twitter/finagle/blob/master/finagle-redis/src/main/scala/com/twitter/finagle/redis/protocol/commands/CommandTypes.scala is probably fine.  However, it massively explodes the scope of this PR.  Maybe we should leave this one for now and do the other ones in other PRs?\n. Alright, I'm happy with this.  I'm going to put it through internal review and see what happens.  Thanks for your submission!  I'll let you know the results of internal review soon.\n. This was merged internally, and should show up on github shortly.  Thanks!  Let me know if you want help with the other CommandTypes.\n. @zhanggl no need to wait, the two changes aren't dependent.  feel free to put up a new PR whenever you like.\n\nIt looks like the it rethrows the throwable.  I'm not certain I understand the issue that you're running into, could you elaborate?\n. Improving the error messages sounds like a good idea to me.\nI think that we do abort the computation--isn't that what happens when we throw in the section you linked me to before?  It doesn't look to me like we continue processing.  Could you explain in what circumstances we can continue processing?\n. Alright, seems like that might be another bug.  Let me know what you find.\n. Although it's OK to do these two pull requests concurrently, it will be confusing if we try to apply the same commits again.  We shouldn't have to repeat commits.  Could you make a new pull request which doesn't include the repeat commits?  One way of doing this would be to make a patch that includes only the changes from ad2d291 and applying that to the current master branch and making that the branch for 246.\nCould you also elaborate on the results of this change and what precisely the modifications entail?\n. Got it.  Good idea.\n. Good sleuthing!  Let me make sure we're on the same page.\nOk, from a high level view:\n1.  If a redis client receives bad data, it closes the connection\n2.  After it closes the connection, it tries to interpret the rest of the bad data, but it should treat it as unrecoverable.\n3.  Redis can be pipelined, so this means that closing the connection when multiple requests are in flight should fail those requests too.\nI'm not certain that overriding the cleanup behavior is the easiest way to fix this.  I'll pull in @trustin and get some expert advice.\n. @zhanggl sorry this fell through the cracks!  Is this still a problem for you?  Do you want to tackle it?\n. Could you add some NaggatiSpec tests?  Other than that, and a few other small changes, looks good!\n. @sonnes, I just wanted to follow up.  Were you able to find the time to make the changes?\n. @sonnes could you merge master?  I think after you cover @roanta's change and merge master, we can merge it in.\n. @sonnes ping! Just want to make sure this doesn't fall through the cracks.\n. @sonnes I did it for you, working on getting it merged in.  Thanks for the contribution!\n. @sonnes OK, in internal review, a couple questions were raised.\nA.  Could you add a test for this?   Maybe replacing the DefaultTracer with some sort of InMemoryTracer (like we do for StatsReceiver) and testing that the traces are properly recorded.\nB.  You shouldn't need to add the Trace.recordServiceName(clientName), in theory we should already be collecting that information.  Have you found that's not the case?\n. OK, I'll close the PR for now, thanks for helping with this!\n. This was merged a while ago, thanks!  Closing the issue.\n. @kt3k this looks great!  I have a few questions though: can we refactor this to run in parallel?  Can we use the sbt launcher that we package with finagle?  Can we test against openjdk{6,7}, and scala 2.10.3 as well?\nIt's odd that finagle-http fails, could you elaborate on why it fails?  It's known that finagle-memcached is flaky, although we typically see it succeed most of the time.  Are the travis-ci boxes underpowered?\n. Hmm, it's bad that tests don't pass with 2.10.3.  I'll dig into it, thanks.  Otherwise, looks good to me!\n. This was merged!  Thanks for the contribution.\n. I'm going to merge this via our internal review mechanism.  If anyone has any questions, feel free to comment on this PR.\n. Thanks @tonymeng, we'll merge it internally.  It should soon show up publicly.\n. This was merged.  I'll close the ticket after it makes it to github.\n. Thanks, this will be merged shortly!\n. This was merged, I'll close the ticket after it makes it to github.\n. Thanks for following up!\n. Sorry it took us so long to get back to you, this fell through the cracks.  I don't know why that would be the case, it sounds like a bug to me.  Could you write a test that demonstrates this?\n. @rodrigodealer are you still seeing this behavior?\n. :+1: \n. Whoops, good catch!\n. Ok, I have it up for review internally, I'll try to get it into the next release\n. This was fixed a while ago. Thanks again for pointing it out!\nhttps://github.com/twitter/finagle/commit/38b334f431916ef5ca0765f4db588a945a47874e\n. Happy to take contributions!\n. Sounds good to me!\n. @mmollaverdi is this still a problem for you?\n. oh lol.  Looks like I reviewed it, but forgot there was an issue attached.  Closing now, as it had a happy ending :smile_cat: \n. Hi @MasseGuillaume we're aware of the issue--we're cutting a new version of finagle shortly, which should fix the bug.  I'll follow up and close this ticket once the new release is out.\n. If you're blocked by this, you can use the previous version of finagle, which should compile properly.\n. The current code should compile fine.  Marking this issue as closed, thanks for the bug report!\n. shipit\n@bmdhacks \n. This has been merged.  Thanks for your contribution!\n. Yes, we used finagle to make a redis server.  Try ServerBuilder with the redis codec.\n. NB: not every redis command is supported yet.  However, we accept pull requests :+1: \n. This has been merged internally, it will show up in the github repository shortly.  Thanks for the contribution!\n. It's on github!\n. Thanks for the contribution!  Could you also add a test to ClientSpec and ClientServerIntegrationSpec?\n. How did you test with 2.11, by the way?  I don't think we've published a good 2.11 yet.  Did you do a publish-local on util?\n. I think so, not sure what happened with that.\n. This looks good, let me get another person to take a look too.  Also, just a heads-up: if you're going to do a ton of redis commands, it will probably make sense to break it up into a bunch of different PRs so we can review as you go along.\n. This has been merged internally, it should show up in the github repo sometime next week.  Thanks for the contribution!\n. It's on github!\n. OK, I'm going to try to merge this in as is.  If you could continue your work in a different branch, that would be great.  If I run into trouble merging it, I'll let you know.\n. @p-antoine just a note: scalatest has a special === that is a little richer than the regular ==.\nThis means that if you write assert(actual === expected) you'll get more useful information out of the test if it fails than if you just call ==.  I'll change it for these tests, just something to remember for later.\n. OK, we decided there was enough meat in the review that it would be easier to discuss on github.  I made a PR against your branch which fixes some build stuff and changes == to ===, which will be a good start in revising your branch.\n. @p-antoine re indentation: we indent two spaces for pretty much everything.  When in doubt, look around the code base, or the CONTRIBUTING.md.  We typically follow effective scala.  Where effective scala doesn't elaborate, we usually follow the scala style guide.\n. @bmdhacks I think TestLogger is in the util change, not in the finagle change, no?\n. This was merged in, woo!  You da :bomb:!\n. That sounds great!  Can you update this issue when you know which project you want to work on?\n. whoops, good catch!\n. Would you like to make a pull request?  I don't have domain-specific knowledge in memcached, but I'll try to get someone from the cache team to make sure it's OK.\n. Yes, make a pull request.  I'll chase someone down to take a look at it.  Thanks!\n. This was fixed ages ago :100:.  Thanks @lerouxrgd!\n. This has been published to github.  Thanks for your PR!\n. Yeah, would definitely love to merge it in!\n. Thanks a lot for tackling this in https://github.com/twitter/finagle/pull/383 @timxzl!\n. I think I'm missing some context here.  Could you follow the commit style guide from CONTRIBUTING.md so I can better understand the problem, solution, result?\n. LGTM\n. This was merged in, thanks!\n82ea6a8e693c01b67c2ab5b0a4787592c2a88778\n. How can we update the version automatically, or else educate our users to choose their own version?\n. :+1: LGTM\n. Why would a Response object not go through a server dispatcher?\n. @JustinTulloss ahh!  To elaborate, ServerDispatcher is the abstraction which intermediates between Service[Req, Rep] and the representation on the wire.  Every server has a ServerDispatcher on the inside.  Have you found experimentally that that server doesn't set content lengths when your curl it?\n. @senthilnest do you think you'll get a chance to take a look at #300 anytime soon?\n. who owns the google analytics for this?\n. LGTM\n. LGTM\n. LGTM for travisbrown@ac3852df11550abdc17ca6c5cba4793d3347bc15\n. @fwbrasil it turns out that this is a binary incompatible change, and we won't be able to do it until we do a major version bump.  Although we had merged it in, we had to revert it.\n. @fwbrasil we've stopped following semver so religiously, so I think we'd be happy to merge this in.  you think it's still worth doing?\n. Works for me.  Thanks!\n. Would the activate framework guy who's using finagle-mysql fit?\n. LGTM\n. Could you follow the commit message guidelines from the CONTRIBUTING.md file?\n. This generally looks quite good.  Could you add a test?\n. @jixu I replied inline about what I think the right way to do the ttl is.\nI'm not sure about testing, other than just trying it locally.  @mariusaeriksen @bmdhacks @jdanbrown  do you have any ideas for how we could go about testing it?\n. LGTM other than the small fixes I suggested.  Thanks, this looks great!\n. LGTM\n. still LGTM\n. A lot of us have been on vacation, which has made it harder to get things merged.  We'll look into it in the next few days.\n. Thanks for being patient :bicyclist:\n. Looks good to me!  Thanks a ton for doing this :+1: \n. Let me know if there's anything you want help with here.  Happy to help.\n. No worries!  I've appointed you the czar of finagle-redis 2.11-ification, so proceed at your own pace.\n. Sounds good to me.\n. Keys already provides a package namespace, maybe just call it\nClientIntegrationTest.Scala?\nLooks good otherwise. We might want to consider rearranging finagle-redis\nto match the package organization style here.\nOn Jul 4, 2014 4:31 PM, \"Jeffrey N. Davis\" notifications@github.com wrote:\n\nAlright @mosesn https://github.com/mosesn , now I do need some help (\nor most likely a slap ). The last two commits show the completed outline of\nhow I would finish this out. Here's a picture of the folder outline =>\n[image: screen shot 2014-07-04 at 3 26 04 pm]\nhttps://cloud.githubusercontent.com/assets/1630235/3484885/b39b7336-03b9-11e4-8496-7f8eb912b790.png\nI'm not gonna lie, I kinda hate the name\nKeyClientServerIntegrationSuite.scala because it feels so Captain Java\nEnterprise~y Dev. Also, the future file\nServerClientServerIntegrationSuite.scala is causing me to rethink my\nprofession and haven't even written it yet.\nThoughts on the finalized outline? Naming suggestions?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/283#issuecomment-48068968.\n. I typically only look at command line output of tests when there's a failure, in which case they'll provide a stacktrace, which will have the full class name (with the packages).  I think it's probably OK.  Do you have another use case for parsing the class names?\n. @penland365 is there anything we can do to unblock you from this?  Happy to help!\n. No need to apologize, thanks for keeping us in the loop.  Take your time.  Don't hurry on our account, just wanted to make sure it hadn't fallen off your radar.  Hope work gets less crazy :smile_cat:\n. For tests which are named things like Finagle_Suite or Finagle_Test, let's just drop the finagle bit.  We already know they're finagle because they're in the finagle package.\n\nThe other thing is, sorry I didn't talk to you about this before, but I just noticed that you've been taking every assert and pulling it apart into three lines (actual/expected/assert).  I think this is actually less readable, and since none of the vals is being reused, we don't end up with the lessening of cognitive load of being able to see how different bits fit together.  Could you change that back?\n. Yep, inlined asserts looks great.  One last thing though, could you add the RunWith(JUnitRunner) annotation back in to the tests?  We use junit for running our tests, and it won't be able to pick them up without the annotation.\n. @luciferous are you still interested in working on this?  if not, I might ransack it for a quick explanation on how to use the Reader + Writer apis.\n. @luciferous I'm not on guru duty anymore, but I might check in with this week's guru to see if they're interested in doing it.  Thanks!\n. LGTM\n. This looks generally good, but there are a few pieces that seem like they might fit better in the dispatcher than where they are right now.  I'd be interested in seeing some more end to end tests.  The testing could definitely be a little more thorough.\nHowever, most of my suggestions are nitpicks.  In general, this looks quite good!  Great job. :+1:\n. Oh yeah, this LGTM by the way.  I'd be happy to see this get merged.\n. This finally graduated to the finagle organization, and can be found here: https://github.com/finagle/finagle-smtp\n. I don't think it would work, because you're creating a service which speak TBinaryProtocol, instead of the twitter variety of thrift.  If you follow the way that it's done on the scrooge website, it should work.\nHowever, there's a small bug at the end of the page.  Instead of writing Thrift.newIface[BinaryService[Future]] it's fine to just use the type of Bar.ServiceToClient (which is Bar.FutureIface, or something similar).\nThis will use twitter thrift out of the box, which should solve your problem.  I'm going to close this ticket for now, but please reopen if this doesn't work for you.\n. LGTM!  Two nitpicks:\nA.  We like to have our commits be in a specific style, described in the CONTRIBUTING file.\nB.  We typically sort our import lists alphabetically so we can scan them faster to see if we've missed something.\nOther than that, the only thing is let's make sure we don't step on each other's toes.  I made an issue to track it.\n. It would be great if you could reorder the imports.  If your new commit message does it, that's fine.  We just have to be able to choose one of your commits for attribution--the rest will be squashed.\n. Oh, could you also rename your file and class from CookieMapSpec to CookieMapTest?  I think that's the last style nit.\n. This has been merged in, and we've cut a release for it, but we're having trouble publishing because of something on our end.  :closed_lock_with_key:\nSorry, we're looking into it!\n. It's yours!\n. Excellent!  Noted.\n. For @rlazoti, anything!\n. Boom!  Only finagle-native is left now.\n. And all gone.  Thanks!\n. Forgot to mention before, if you're working with mocks, please use MockitoSugar.  I've updated the list of guidelines to reflect this too.\n. Yeah, let's convert them too.  We can remove it after we've actually deleted it.\n. @caniszczyk I've been keeping the description of the issue up to date.  We need to review @bajohns' PRs, and then the only ones that are left are finagle-redis (mostly done) and finagle-kestrel (unsure of status).\n. It's not--we still have more work we can do on our end, don't worry about it :panda_face:\n. Sounds like a plan!  Thanks for following up.\n. Actually, if you folks are rip-roaring to go, it would be great to get started on scrooge and ostrich, which are both dependencies of finagle.  The other thing that needs to be done is to actually turn on 2.11 support for finagle.  We can't do it properly until we're totally off of specs, but we can start off by just making a branch where we remove the specs bits and make sure everything else compiles, and all of our dependencies are OK.\nAny interest?\n. Oh hey, you're right!  Looks like @dhelder removed specs from scrooge already, nice!\nFor scrooge, we need to update dependencies, but finagle is one of the dependencies (finagle depends on scrooge-core, scrooge-runtime depends on finagle, it's a mess but luckily not a cyclic dependency).\nWe'll also need to update scrooge-core to cross-publish against 2.11, and it would be great to rename all of the Spec.scala files to Test.scala, and similarly rename the tests.\n. Rad!  Happy to help if you run into any issues.\n. My instinct is delete it, but file an issue to test that script properly (or else delete it).  @mariusaeriksen looks like you were the one to remove it, do you have an opinion either way?\n. Ahh, that's a good point. I'll look into it, thanks for the heads up.\n. OK, as far as I can tell, the dependency on util-eval is necessary for now.  I'll see if I can deprecate it, but the fastest we'll be able to get off will be with a major release.\nOn the other hand, scala-json is not necessary.  We can probably replace it with jackson + scala sugar.\nIn the mean time, we don't need to publish finagle-ostrich4 against 2.11, and only finagle-example and finagle-stress depend on finagle-ostrich4, so I think we'll be OK.\n. @rlazoti can you tackle removing the dependency on scala-json?  Or are you already busy enough with the specs => scalatest work?\n. Rad!  Very exciting.  I'll see what we can do about deprecating the bits that depend on util-eval.\n. @rlazoti https://github.com/twitter/twitter-server/blob/master/src/main/scala/com/twitter/server/util/JsonConverter.scala#L9 might be useful for inspiration.\n. Yeah, I agree with @p-antoine.  It will be easier to merge this in piecemeal anyway. :musical_score: \n. @mauricio all of the finagle pieces are owned right now, but if you want to help contribute, twitter-server could use some love, just to check that all the tests pass with 2.11.\n. @p-antoine I'm planning on deprecating the bits that remote it--I have a review up internally to do it, but still need to do a couple tests before removing it.  Frankly, it's not going to happen super quickly.  I think for the short term, the best plan will be to not build projects that depend on ostrich against 2.11.\n. I think this is on me right now, I need to test out my ostrich removing util-eval change.  I think @travisbrown is working on publishing the bits of finagle which don't depend on ostrich for 2.11, but not sure how that's progressing.\n. @alexflav23 this is sort of dumb, but I have an ostrich branch which deprecates util-eval, but don't want to merge it in until I'm sure it's usable and doesn't break everything.  However, I've been too busy to try it out.  If I pushed it to github, could you stand up a trivial ostrich server with some basic stats and test it out?\n. Hi @fringedgentian, there aren't any direct blockers for finagle-memcached specifically.  You should be able to publish it for yourself.  However, we're not publishing finagle to 2.11 in general yet because it still has transitive dependencies on util-eval, which will not be ported to 2.11.\n. in defense of @penland365 it has actually been merged internally, we just need to publish and push the code to github.  There's a problem with our ssh keys that we're trying to sort out.  I'll try to figure out what still needs to be done.\n. Yeah, that sounds promising.  We'll probably publish our first 2.11 util in the next couple weeks.\n. Hey @bajohns this looks great!  Unfortunately, I've been snowed in work-wise, and haven't had a chance to take a look at this yet.  It's still on my plate, but it will take a little while to get to it.  Sorry! :grimacing:\n. LGTM other than a couple style nits.  The context class vs. OneInstancePerTest thing is up to you--I prefer having a single paradigm across finagle, and OneInstancePerTest is only used twelve times in finagle, but it does make the code cleaner, so maybe we'll want to investigate just using OneInstancePerTest across the board in the future.\n. This is looking pretty awesome, thanks a ton!  :+1:\nLGTM\n. That would be rad, it would probably help minimize conflicts too.  Could you make a new PR though, so the history for this branch is still one to reason about?\n. We're in the process of doing it today! :tophat: \n. Leaving the mockito bits in is fine.  Could you refactor to use org.scalatest.mock.MockitoSugar?  I'll update the coordination issue to also mention that.\n. LGTM!  This is awesome.\n. @alexflav23 have you tried it on any specific tests?  My impression is that scalatest already runs suites in parallel by default, so I don't understand where the speedup would be coming from.  However, I'm definitely interested in work to make tests go faster, so if you find experimentally that it works well, we would be happy to see it.\nMaybe we should take this discussion off of this PR and move it either to an issue or to the mailing list?\n. LGTM\n. Hmm, yeah, it's a very weird failure.  It hasn't happened historically, though.  My guess is it's just flaky.\nLGTM\n. Looks great!  Just had a few comments.  Thanks for digging into this.\n. LGTM\n. Hey @kashif, do you need anything from us to help you out?  Happy to help :+1:\n. No problem, always glad to see new people getting involved in the community :neckbeard:\n. It looks like the problem you're running into is that trimList isn't working properly.  Maybe it would make sense to parse the number before calling trimList, and then you can pass a value based on that to trimList?  The key there will be that you need to make sure that you at least have a number parameter, but that should be fairly simple.\n. @kashif howdy, looks like this fell through the cracks.  Is there anything else you need some help with?\n. @kashif still happy to help if you have any further questions :+1: \n. I think there's a bug in the parser where it always delimits on ' ' instead of treating stuff between quotes specially.  I'll take a closer look.\n. @kashif I threw together something that should be an OK first approximation.  I haven't tested it at all, so it may take some tweaking, but this patch should generally explain how to go about fixing the bug.\nhttps://github.com/mosesn/finagle/compare/support-string-split.patch\nEDIT: Actually, this is totally broken on inspection, I'll patch it with a fix in a minute.\n. ugh ok now it should work (although it's still totally untested)\nNB: it doesn't handle quotes in the middle of a quoted area, you can't escape quotes, you can't have more than one space.\n. @kashif did you have a chance to try it?\n. Can you push your stuff to this branch so I can try it out myself?\n. OK, I made a pull request against your branch.  I had confused the semantics of filter / filterNot.  It should be fine now.\nhttps://github.com/kashif/finagle/pull/1\n. @kashif howdy, do you need any help from me?\n. @kashif hey, I just wanted to check in.  Is this something you're still interested in working on?\n. @kashif I think https://github.com/twitter/finagle/pull/383 solves the same problem, so I'm going to close this ticket once that merges in.  Thanks for your work on this PR\u2013I'd be happy to work with you again in the future if you want to take another stab at a PR for finagle!\n. LGTM, thanks for looking into this :koala: \n. LGTM\n. @takc923 thanks for the bug report!  Just a heads up, for future reference, if you're doing http streaming, you probably want to use our regular http streaming, rather than finagle-stream.  finagle-stream has slightly weird semantics, such as exposing the http streaming chunks to its end users.  If you want generic http streaming, it's better to just use raw finagle-http.\n. cc @luciferous is this familiar?  did you have to fix this for http streaming?\n. @jbripley this is really useful feedback!  Could you post it on that PR?  The reason why we made a PR was so that we could get this kind of feedback from open source contributors.\n. LGTM\n. LGTM\n. Rad, we'll merge this in after you address Steve's comments :] I'm really excited about this!\n. @bajohns just wanted to make sure this didn't get lost in the shuffle :+1: \n. Interesting.  So it looks like you have a cycle in your directories (unless I'm misunderstanding).  Would you like something where it remembers the paths of where symlinks have sent it and doesn't follow the symlink if it's familiar?\n. Jesus christ I hope not.  I figured you had put that on your classpath?  What does it look like from here: https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/util/LoadService.scala ?\n. OK, I guess if folks setting / as cwd is a real thing, we should maybe exclude /sys explicitly?  @revisiond, @groestl would one of you like to make a pull request?\n. I think #351 fixes this, but please reopen if you have further problems!\n. LGTM\n@chrisphelps, glad to hear you're an adopter!  How do you guys use finagle?\n. @vargasbo could you keep this in alphabetic order?  Also, I'm curious, how do you use finagle?\nThanks!\n. lovely, thanks!\nLGTM\n. LGTM!  By the way, how do you guys use finagle?\n. LGTM\n. By the way, how do you folks use finagle?\n. LGTM\n. LGTM\n. @akwangho sorry for the delay in reading the review.  Since your review, we've unfortunately had to rewrite some of the finagle history, and your patch doesn't merge anymore.  Your old patch should still apply, could you try it again?  Really sorry about the trouble.\n. LGTM\n. This made it into develop, thanks!\n. No, it exists in a mostly-complete state internally as a google doc, but I got pulled off on other things before I can finish.  lmk if you want to see it.\n. Maybe just a day or two?  If you want to tackle it that would be rad.\n. Hmm, I think I might be able to handle this myself actually, since github exposes a patch file for each commit.  I'll try using https://github.com/orrsella/finagle/commit/e2c3521a567ba9bc2c27dc4a5d5a265c2f350614.patch and report back.\n. This made it in too!\n. Finally made it in!  https://github.com/twitter/finagle/commit/bed163eb630fe18a38770d114eb273695712cf96\n. @orrsella sorry for the delay.  We unfortunately had to change our history slightly, and this doesn't merge anymore.  Could you make a patch and apply it to the new master?  Really sorry for the inconvenience.\n. Yeah, I should be able to handle this myself.  I'll report back.\n. Hey, this was finally merged internally.  We're having a problem with pushing stuff to github, but it should appear in the next week or two on the develop branch.  Thanks for the contribution!\n. @jixu I don't see why not.  Do you want to take a stab?\n. Rad, let us know if you have any questions.\n. We've started publishing nightly builds to a branch called \"develop\" so I think that we can do a little better by using them instead of master.  However, it's definitely an issue that master doesn't compile, and we'll look into it.\nCould you check out the develop branch in util, ostrich, and finagle, change their versions to $VERSION-SNAPSHOT (ie 6.22.1-SNAPSHOT) and run publish-local on all of them except for finagle?  Keep in mind that you'll have to change their version in their sbt files, and also their version in the sbt files that depend on them.\nIf you could then make a branch based on the changes you've made in the develop branch, that would be great.\n. This is in develop.  Thanks!\n. LGTM.  @penland365 how are you using finagle?\n. This made it into the develop branch, thanks!\n. Very cool!  Have you been doing any zero-copy stuff with finagle?  I'd be very curious if you're able to share.  Could you also update the \"messageReceived\" method to support FileRegion?\n. @trustin could you weigh in?  I don't think I understand netty well enough to review this.\n@whiter4bbit I thought part of the idea was that if you received a request, you could zero-copy that request elsewhere.  It sounds like there's something I'm missing, is there some documentation or code I should read?  I tried googling for information about netty + FileRegion, but didn't come up with anything that could help me understand it.\n. @whiter4bbit I just wanted to make sure this PR didn't get lost between the cracks.\n. Thanks!\n. @penland365 I think you're right that they're not, but we unfortunately use the junitrunner, not the scalatest runner or the sbt runner, so we're not really able to take advantage of scalatest tags.\nMaybe we should just add TODOs with all of the ignores?\n. LGTM\n. @hliu20 could you describe your test environment?  And what kind of work are you doing in your myRPCFunction?  Are you just sleeping or busy-waiting?\n. @hliu20 We have many machines which are running in production today, with much, much more than 5 concurrent requests, so I suspect there is something going on in your code or your environment.  If you have more information, I'm happy to help, but there's not a ton we can go on from this.  I'm closing this for now, feel free to reopen if you want to revisit.\n. It doesn't have a limit, but because finagle is asynchronous, you're sending many, many, many requests to the server, and because redis is pipelined, it's all through one tcp connection.  Each thread has to keep track of every request that it has been sent so far, so basically you're turning finagle into a queue where you put things in faster than you can take them out.\nNote that it only prints when the server responds, so you're limited by both how fast your client can read responses off the wire (impacted by GC), and how fast the server can respond.\n. Yeah, looks like it should link here instead: https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/tracing/TraceInitializerFilter.scala.  Good catch!  Would you like to make a PR?\n. Hmm, can you try this: ./sbt 'project finagle-doc' make-site?  We only need to run unidoc for generating scaladoc\u2013it might be a windows compat problem, since we mostly develop on OSX.\n. LGTM\n. @luciferous could you weigh in?  I don't know what our policy is on this.\n. Hey, didn't want this to get lost.\n@vicentealencar were you able to try what @luciferous suggested?\n. LGTM\n. LGTM, but this is a pretty big change, and I don't think we have the bandwidth to cutover everyone to use the new API.  Maybe make another module that people can depend on?  Obviously we'll need to do this for finagle-httpx also.  Maybe finagle-http-ask and finagle-httpx-ask?  That way we can slowly phase out finagle-http{,x} without causing too much trouble.\n. LGTM\n. Sorry, could you follow the problem / solution / result guidelines in CONTRIBUTED.md?  I don't think I quite understand where you're coming from with this review.\n. I don't understand \"so when we call ThriftClientBufferedCodec.get() it actually returns ThriftClientFramedCodec\".\nThriftClientBufferedCodec doesn't have a get method yet, so there's no way you could call it today.\nWhat does the get() method get you that you can't use apply() for?\n. So I checked out the bytecode, in case I might have missed something, but it seems pretty unambiguous.\nmnakamura@tw-mbp13-mnakamura \u2b80 ~ \u2b80 javap -classpath ~/.m2/repository/com/twitter/finagle-thrift_2.10/6.21.0/finagle-thrift_2.10-6.21.0.jar com.twitter.finagle.thrift.ThriftClientFramedCodec\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=utf8\nCompiled from \"ThriftClientFramedCodec.scala\"\npublic class com.twitter.finagle.thrift.ThriftClientFramedCodec implements com.twitter.finagle.Codec<com.twitter.finagle.thrift.ThriftClientRequest, byte[]> {\n  public static scala.Option<com.twitter.finagle.thrift.ClientId> apply$default$1();\n  public static boolean $lessinit$greater$default$4();\n  public static scala.Option<com.twitter.finagle.thrift.ClientId> $lessinit$greater$default$3();\n  public static com.twitter.finagle.thrift.ThriftClientFramedCodecFactory get();\n  public static com.twitter.finagle.thrift.ThriftClientFramedCodecFactory apply(scala.Option<com.twitter.finagle.thrift.ClientId>);\n  public com.twitter.finagle.ServiceFactory<com.twitter.finagle.thrift.ThriftClientRequest, byte[]> prepareServiceFactory(com.twitter.finagle.ServiceFactory<com.twitter.finagle.thrift.ThriftClientRequest, byte[]>);\n  public com.twitter.finagle.transport.Transport<java.lang.Object, java.lang.Object> newClientTransport(org.jboss.netty.channel.Channel, com.twitter.finagle.stats.StatsReceiver);\n  public com.twitter.finagle.Service<com.twitter.finagle.thrift.ThriftClientRequest, byte[]> newClientDispatcher(com.twitter.finagle.transport.Transport<java.lang.Object, java.lang.Object>);\n  public com.twitter.util.Closable newServerDispatcher(com.twitter.finagle.transport.Transport<java.lang.Object, java.lang.Object>, com.twitter.finagle.Service<com.twitter.finagle.thrift.ThriftClientRequest, byte[]>);\n  public boolean failFastOk();\n  public org.jboss.netty.channel.ChannelPipelineFactory pipelineFactory();\n  public com.twitter.finagle.ServiceFactory<com.twitter.finagle.thrift.ThriftClientRequest, byte[]> prepareConnFactory(com.twitter.finagle.ServiceFactory<com.twitter.finagle.thrift.ThriftClientRequest, byte[]>);\n  public com.twitter.finagle.thrift.ThriftClientFramedCodec(org.apache.thrift.protocol.TProtocolFactory, com.twitter.finagle.ClientCodecConfig, scala.Option<com.twitter.finagle.thrift.ClientId>, boolean);\n}\n mnakamura@tw-mbp13-mnakamura \u2b80 ~ \u2b80 javap -classpath ~/.m2/repository/com/twitter/finagle-thrift_2.10/6.21.0/finagle-thrift_2.10-6.21.0.jar com.twitter.finagle.thrift.ThriftClientBufferedCodec\nPicked up JAVA_TOOL_OPTIONS: -Dfile.encoding=utf8\nCompiled from \"ThriftClientBufferedCodec.scala\"\npublic class com.twitter.finagle.thrift.ThriftClientBufferedCodec extends com.twitter.finagle.thrift.ThriftClientFramedCodec {\n  public final org.apache.thrift.protocol.TProtocolFactory com$twitter$finagle$thrift$ThriftClientBufferedCodec$$protocolFactory;\n  public static com.twitter.finagle.thrift.ThriftClientBufferedCodecFactory apply(org.apache.thrift.protocol.TProtocolFactory);\n  public static com.twitter.finagle.thrift.ThriftClientBufferedCodecFactory apply();\n  public org.jboss.netty.channel.ChannelPipelineFactory pipelineFactory();\n  public com.twitter.finagle.thrift.ThriftClientBufferedCodec(org.apache.thrift.protocol.TProtocolFactory, com.twitter.finagle.ClientCodecConfig);\n}\nThere is no get method on ThriftClientBufferedCodec, so I think the reason why it returned the ThriftClientFramedCodec was because your code wasn't able to compile.\nUsing apply seems fine to me.  What was the problem you ran into with apply?\n. Oh god, that's horrible.  I had totally forgotten you inherit static methods in java.  OK, LGTM.  Could you add a comment that the problem is that because an object's methods get added as static forwarders on the class that it's a companion of, and static methods are inherited, this must be done so that you don't accidentally inherit get from ThriftClientFramedCodec?\nIt might make sense to add a test too.\n. Sorry, you're right, we screwed up.  It made it into the util changelog but I didn't think to document it in the finagle one too.\nI'll add it to the finagle ChangeLog too.\n. If you're curious, here's the commit:\nhttps://github.com/twitter/finagle/commit/acf28ac5f805a73fac8ea8aa6f0f0d2189b1aea8\nand in util:\nhttps://github.com/twitter/util/commit/55e0cfb938ec000e0cc75546a7f45e0af46a55b5\n. For future reference, if you're looking for a commit for a file that has disappeared, you can examine\ngit log $DIR\nwhere $DIR is the directory of the file that was removed, to narrow down the commits you look through.  Our commit messages tend to have much more context than our changelogs, so if you're curious about what exactly happened, and why, they're the right place to look.\n. Happy to accept pull requests!  As you can probably guess, you're the first folks I've talked to who have made all deps intransitive, so you're breaking new ground.\n. Hmm, neat!  I have to say though, I wonder if maybe this would make more sense as just a set of Bijections?  Then we'll also get things like \n```\nimplicit val dateToTime: Bijection[Date, Time] = ...\nimplicit val timeStampToTime: Bijection[Timestamp, Time] = ...\nTimestamp((Time.now - 5.minutes) - Time.zero).as[Date]\n```\nWe would have to add bijection-core as a dep, but that seems not so bad.\n. LGTM\n. Oh, his has actually been merged already internally, but we've been having trouble with pushing the internal version to github. I'll just close this ticket though.  Good looking out!\n. Sounds like a plan!  Please let us know if you need any help.\n. @kristofa is this something you're still thinking about?\n. woot!  thanks so much!  *<(\u3002\u2283\u2267\u2200\u2266)\u2283\n. Thanks for tackling this @kristofa !\n. Rad, can you make a PR?\n. Let's just use SslHandler's multi-arg constructor.  I agree with @vkostyukov that it should be configurable.\n. @vkostyukov I think it would be nice to have the TimeoutFactory timeout be able to interrupt the ssl handshake, but I agree that it's not urgent.  I think we shouldn't do anything until we run into a problem with it.\n. We're just going to use a default timeout in TLS in netty 4 to simplify this, so I'm going to mark this as closed.  Please feel free to reopen it if you'd like to rediscuss this!. :+1: to don't worry about it and just don't let tests share state.\n. LGTM\n. I think the ssl handshake section is already part the service acquisition timeout, but the hook to fail isn't setup.  I think you're right that regular service acquisition timeout should fail the ssl handshake.  Do you think you might have a use case for setting an explicitly fast ssl handshake timeout?  If not, then we should do what you suggested.\n@dschobel there's precedence for having connectTimeout (cf tcpConnectTimeout) so I think that making it simpler and more consistent is useful enough to risk breaking someone who was relying on existing behavior.\n. Yeah, I'd rather not pass it as a param to netty that way.  Could we use the finagle interruption mechanism to interrupt it instead?  We know the interrupt will come already, we just don't have anything hooked up actually cancel it after the interrupt is sent.\n. Although the Netty3Transporter does cancel the ChannelFuture, it doesn't get propagated to the handshake properly.  My impression is that if we add cancelling the handshake to the onCancellation, it will be correct.\nCould you elaborate on what you mean by \"But it neither can nor should expect the clients to handle the connection timeouts themselves\".  I'm not sure I understand.\n. I think we should say that's a bug in FailFastFactory then.  It seems reasonable to me that we interrupt the previous failfast connection attempt when we start a new one.  Otherwise, if we really end up hanging somewhere in here, we can leak memory.\nIt shouldn't have to be the Transporter's job to handle connection timeouts.  I think trying as hard as we can until we receive an explicit interruption is a completely reasonable way to go about doing it.  If folks never set a connectTimeout, no need to kill it, and we can just try forever.\n. Hmm, yeah, you're right.  I thought that the retry was out of band, but clearly it's not.  Maybe we should move the retries out of band and also interrupt the old ones?\nMy point is that we already have what you described, in TimeoutFactory.  It's just too high up for FailFastFactory to take advantage of.\n. As far as I can tell, the current behavior of FailFastFactory (and I need to sit down and spend some time with it, I might be totally off) is that it shoots off a connection attempt, and once it fails, we start waiting a specified backoff time before shooting off another.\nIf instead of waiting for it to fail, we just start waiting the backoff time before sending another request, we can use the backoff time as both backoff and timeout.\n. @tonyd3 why not use the Client constructor directly?\nhttps://github.com/twitter/finagle/blob/master/finagle-redis/src/main/scala/com/twitter/finagle/redis/Client.scala#L31\n. Sorry, I don't understand what you're saying.  I don't think there's a difference between using the Client constructor directly and the method you're proposing.  Isn't the method you're proposing invoking the redis.Client constructor?\n. @tonyd3 I don't think you really addressed my problem.\nLet me be more precise.  The API you've added is exactly the same as using the constructor directly.  It doesn't seem to be easier to use, and it doesn't solve the problem you think it does.  Using the RedisClient.newService gives you the PipeliningDispatcher because it uses a different StackClient than the ClientBuilder.  What your method does is wrap a Service in a redis.Client, which we already have an API for.\n. You can't use the ClientBuilder if you want the PipelinedDispatcher right now.  The part that you're missing is that the RedisClientWrapper's \"DefaultClient\" section is never used.  redis.Client is a global object, and you're just directly passing the ClientBuilder created instance to that global instance.  I think if you go and look at the piece of code you're invoking it will be more clear why it's not using any of the DefaultClient methods.\nAs an aside, DefaultClient is not really used anymore, although we still have a few protocols that are still on it.  StackClient is the way forward (for one thing it is much more easily configurable).\n. :+1: \n. This seems reasonable, but maybe the right way to do this is with a GlobalFlag?\n. LGTM except for a few final nits.\n. I think it's not quite ready, but very close!\n. The if (ignoredPaths.isDefined) thing is still unnecessary, but if you feel strongly about it, I don't want to block this PR.  :+1: otherwise.\n. I'm not sure what we should do here.  The problem is that finagle has a few tests where it depends on the JVM setting java.net.preferIPv4Stack=true.  It might be that it's better to make sure that that's set than to change localhost to 127.0.0.1, at least until we have time to upgrade all of the tests to support ipv6 (in particular, memcached has trouble with ipv6).\n. :ship: :it: \n. Sorry, github doesn't send an update when you change the description, so I think we were all waiting for you to update the description, not knowing that you already had!  Sorry about that.  We'll get to it shortly.\n. @Eilie whoops, sorry, thought I replied to this.  I followed up with @jroper in that thread, looks pretty straightforward, happy to accept a PR, please let us know if you have any questions!\n. LGTM!  What do you use finagle for?\n. LGTM, but let's document that if you switch threads, things on the new thread will not be traced.\n. Can add a commit message that conforms to https://github.com/twitter/finagle/blob/master/CONTRIBUTING.md#style?  That would be awesome!  LGTM otherwise.\n. From a high level, I'm not sure how I feel about this approach.  We want to keep our APIs java friendly in general, and implicits are typically not the easiest way to do it.  With that said, it's definitely a cool API in scala.\nMaybe the right thing is to separate this out into a separate API for scala, but not get rid of the old java API?  This also has the benefit of not breaking API/ABI compatibility.\nI'm also not sure I'm in love with the Parameter API.  I might be misunderstanding, but it seems like the path to upgrade from Any => Parameter is to import the Parameter.wrap method into scope, and then hope that clients used Seq literals?  That seems awfully fragile, and necessary implicit methods don't make for the easiest to use or understand code.\n. I definitely agree typesafety is worth it, and I definitely want this PR to make it in, but I'm not sure if this is its final form or if it has some more evolving to do.  With that said, I also want to make sure we have a good java compat story, so if we're dropping the old API, we should at least add some java compatibility tests.\n. Sorry, where exactly does it find the implicit here?  I don't understand.  Also, that doesn't address my concern is that since the API we're dealing with is Seq[Any], if someone has already created a Seq[Any], and then tries to pass it in separately, it will break.\nWhen you say transparent, do you mean source compatible?\n. OK, so to recap: the path to upgrade from Any => Parameter is to make sure the Parameter.wrap method is in scope, which will then update any literal Seqs automatically.  If anyone isn't using a literal Seq (ie even val x: Seq[Any] = Seq(3, 4, 5, \"OK\") is no good) then they will need to make code changes to do this.  If they pass those arguments through a few places, they will have to make multiple code changes.\nIf we're forcing folks to change their code anyway, maybe we can do better?  My impression is that prepared statements require a specific set of parameters, which have types that are known in advance.  Can we require that they are the right types, beyond just that they are parameter types?\n. OK, I understand now.  Even if we don't import Parameter explicitly, because it's the type that we're trying to convert to, scala tries to find an implicit conversion in its companion object.  Very neat!\n``` scala\nscala> import com.twitter.finagle.exp.mysql.ExecuteRequest\nimport com.twitter.finagle.exp.mysql.ExecuteRequest\nscala> ExecuteRequest(3, IndexedSeq(3, \"hello\"))\nres0: com.twitter.finagle.exp.mysql.ExecuteRequest = com.twitter.finagle.exp.mysql.ExecuteRequest@6a734dd1\n```\nWith that said, I still think we can do better.  When we make a prepared statement, we know that we want to fill in the gaps in the prepared statements with things of a precise type.  For example, we might know that we need a String, an Int, and a Boolean.  In the proposed Parameters api, we can enforce that we get valid mysql Parameters, but not the number, the specific type, or the order.\nCould we do something like:\n``` scala\nobject TupledParameters[A] {\n  implicit def 1tupleA : Parameter: TupledParameters[(A)] = ???\n  implicit def 2tupleA : Parameter, B : Parameter: TupledParameters[(A, B)] = ???\n}\nclass ExecuteRequestA : TupledParameters { ... }\ntrait PreparedStatement {\n  def applyA : TupledParameters: Future[Result]\n}\n```\n?\n. @roanta we can do better by declaring in prepare what the types we need are, like how @missingfaktor described it.  Then we can enforce it at compile-time, sort of like with string interpolation.\n@missingfaktor since we're breaking ABI compat, I'd rather just do it all in one fell swoop.  I don't think it's that much extra work to add the type parameter to the prepare call site in the API, and I'd be willing to do the migration for twitter.  I think it'll be easier to only have to do one migration rather than two (although it would definitely be a bigger migration than just the one that's proposed right now).\nOh yeah, the Value is a good use of the variance.  Good call.\nAnyway, I think this review looks fine, but I have a strong preference for the CanBeParameter tuples.  I'm not going to block this review though.\n. Could you paste the stack trace?  I think the bug is that https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/util/LoadService.scala#L115 should have a second argument, \"UTF-8\", but a stack trace would help nail it down.\nhttps://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/util/LoadService.scala#L180 is a possible candidate too.\n. Could you elaborate on why you think ISO8859-1 is a better choice?  And how do you feel about making a PR fixing this?\n. I don't think this will work for variable-length UTF-8 characters.  I don't think it will work for GBK when a GBK character is two bytes either.  I think the simplest way forward is to just keep it UTF-8, and require that all of the files that finagle uses be in UTF-8.\nWhat do you think?\n. @tianxiao-ma the overlap between ISO8859-1 00 => 7F, is ASCII.  UTF-8 also encodes 00 => 7F the same way.  As far as I can tell, GBK 00 => 7F is not ASCII, so ISO8859-1 is inappropriate, unless UTF-8 is also appropriate.\nLooking at #366 it looks like the file you're trying to read is in UTF-8.  Could you elaborate on your problem?  I'm not sure that I understand it.\n. Right, but just because an exception doesn't throw doesn't mean it will be correct or meaningful.\nNB: java also requires that these files be in UTF-8.\n\nA service provider is identified by placing a provider-configuration file in the resource directory META-INF/services. The file's name is the fully-qualified binary name of the service's type. The file contains a list of fully-qualified binary names of concrete provider classes, one per line. Space and tab characters surrounding each name, as well as blank lines, are ignored. The comment character is '#' ('\\u0023', NUMBER SIGN); on each line all characters following the first comment character are ignored. The file must be encoded in UTF-8.\n\nhttps://docs.oracle.com/javase/7/docs/api/java/util/ServiceLoader.html\n. Yes!  I think your change is great, except that we should use UTF-8 instead of ISO8859-1.\n. @tianxiao-ma Could you elaborate?  Finagle exports files in UTF-8 and java requires that they be in UTF-8 too.  If you put them in something that's not UTF-8 then you're breaking the contract with java and finagle.\n. I absolutely agree!  I think you should change this pull request to use UTF-8 instead of ISO8859-1.  How does that sound?\n. LGTM.  Thanks for the PR!\n. @fwbrasil I think we already added support for transactions in the develop branch.\nDoes that look like it takes care of your concerns?\n. LGTM, but I'm curious about what the ApertureBalancerFactory doesn't expose that you want to twiddle.\n. What do you mean by max effort?\n. Do you have transitive dependencies turned off?  The finagle stats receiver was moved into the util-stats module.  I'm not sure about what your problem with the mdns object is.\nWhich branch of finagle are you running tests from?\n. I think this was a transitive dependencies problem, and there hasn't been a response in over a year, so I'm going to assume we solved @ncardozo's problem and close this ticket.\n. Aw man, I didn't know you had left NYC!  Well, I'm sure Montreal is happy to have you :+1: let us know if you have any questions about finagle, we're happy to help!  I'm looking forward to seeing you around.\n. Awesome!  What do you guys use finagle for?\n. Cool, glad to hear it.\n. Good catch!  Could you make a quick PR to update the docs?\n. Right, @olix0r's concern is what I'm worried about.  We could do a reverse DNS lookup, but it's not necessarily obvious what we should do for multiple ip addresses, especially if they end up having different hosts.  We also depend upon the assumption that you can explicitly set your host for ClientBuilder#tls.\nThe slightly tricky thing about @olix0r's solution is that since the version of the protocol that you're speaking is dependent on the request, not on the client, it's difficult to know in advance whether the client needs to be able to set a hostname or not.\nMaybe we could log loudly when you send a request which doesn't conform to the HTTP protocol?\n. Maybe?  But it means we need to add special logic\u2013do we want to do it only for inet! when there's only one host, or do we want to guess if there's more than one host, do we want to strip http:// prefixes, how precise do the host headers have to be, can we send prefix.twitter.com if we really mean twitter.com, etc.  It seems like a huge headache to support, when we can (and in my opinion, should) push it back to the user, who should know the name of the virtual host anyway.\n. :+1: to high level DSL that addresses these concerns.  Not 100% sure that should be in finagle proper, might be a separate wrapper (finch-like maybe?).  For example, I doubt that it's really all that common that you want to switch between http versions, and then we could require more information at client creation or compilation time.\n. LGTM\n. For future reference, it would be rad if you included the Problem / Solution / Result in the commit message directly, since we just snarf your commit message in directly with a signed-off-by message.\n. No worries!\n. lgtm\n. Sorry it took so long to get back to you!  @SDHM I'm not sure I understand what the problem you ran into was.  Do you remember what was happening here?\n. Don't have enough information to reproduce, so I'm going to close this for now.  If someone runs into this again, feel free to reopen!\n. Thanks a ton for this review!  I'm very excited about the new features, and I think we'll be able to merge this in with a little polishing.\nSorry for the delay, I'm on vacation with limited internet access.  Could you merge against develop instead of master by any chance?  There are a few changes which I think we've already done, like changing curl to include --location.\nA few general notes on style: we usually just indent two spaces wherever you need to do indentation, no need for indenting to the beginning parenthesis.  When we push an argument to the next line, every argument should get its own line.  Only symbolic operators should use infix style without \".\".  If you're making a note in the // style, no need to prefix with \"NOTE\".  Don't mention authorship\u2013git already encodes it, so we can find it with git blame if we need it.  Please keep import lines sorted\u2013if they're not sorted, and you change imports, please sort them.\nFrom a high level standpoint though, your approach looks correct.  :+1: \n. @timxzl sorry it took so long for us to look at this.  it looks good to me!\n. Historically we've often used Filters for solving this kind of problem. NB: this Service acts like a special kind of Filter, which only mutates input, not output, like:\nscala\ntrait ServiceFilter[Req, SvcRep, FilterRep](first: Service[Req, Rep]) extends Filter[Req, FilterRep, SvcRep, FilterRep] {\n  def apply(req: Req, second: Service[SvcRep, FilterRep]): Future[FilterRep] =\n    first(req).flatMap(second)\n}\nThe one difference is that we need to early-bind FilterRep.  Most folks don't have that many clients with different types (thrift services which talk to an enormous number of endpoints / other services being a notable exception), and we could provide an API which works for most use cases via:\nscala\nclass Service[Req, Rep] {\n  ...\n  def toFilter[Out]: Filter[Req, Out, Rep, Out] = new ServiceFilter[Req, Out, Rep, Out](this)\n}\nI think keeping Filters and flatMap as the base tools of composition is powerful, and I'm hesitant to allow new combinators too quickly.\n. Could you elaborate on what you don't like about the Filter approach?\n. @raelg I'm a little hesitant to do add just anything for the sake of small improvement in concision.  I feel like a lot of the power of the Service abstraction is how simple it is, and increasing the surface area means that finagle ends up even more difficult to learn, and Service becomes more difficult to reason about.\nI'm not sure I buy the readability argument\u2013since Filters are the base unit of composition, it seems to me like it's more readable.\n@luciferous I'm having trouble getting behind 1. because it means map in a totally different way than map normally works, but I can buy it if I just call it prologue or something different in my head.\n1. is true, this is why we normally use SimpleFilter.\n2.  is also a good point, especially if we end up ever wanting to structure a filter / service chain as a DAG that gets compiled later\nOK, I'm slowly getting sold, but can we have a few other folks weigh in?  I'm curious what @roanta and @mariusae think, since they have the most context.\n. We maybe shouldn't use andThen or compose because Service is-a Function, and the overloading with something semantically different could get confusing.  Getting back to the point, is this useful enough to merit inclusion in Service specifically?\n. Thanks for the contribution!\nCan we add a test?  How have you tested this?\n. LGTM\n. NoSuchMethodError is a common error when there's a version mismatch, or there's a caching problem for your artifacts.  Sorry it took so long to get back to you!  I hope you were able to solve your problem.\n. libthrift 0.5.1 isn't in maven central, so make sure http://maven.twttr.com is on your list of resolvers.\n. @travisbrown also, we shouldn't need libthrift for finagle-http, afaik.\n. :shipit:\n. Wow, I had no idea allmychanges existed, very cool!  Now that someone is actually consuming the rst, it would be neat to validate that it's right.  It looks fine on the site you linked to, did you fix that manually?  It's correct rst, right?  It's just that it's not semantically correct.\n. @kevints as you point out, this is something you can turn on with a system property, so I'm not sure it's something finagle should set a default for.  I'm going to close this ticket for now, but please reopen if I missed something!\n. Are you planning on adding a new Resolver in a future PR?\nI'm a little worried about adding all of these different kinds of SocketAddress (like the Weighted one we added before) because I think we have some code which looks explicitly for InetSocketAddress.  Since the SocketAddress interface is so thin, does it make sense to start providing typeclasses for the extra behavior that we want from some SocketAddresses?  (I actually don't know what we're looking for).\nFrom a quick search around:\n``` scala\n moses@Mosess-MacBook-Air \u2b80 ~/projects/finagle \u2b80 \u2b60 master \u2b80 ag ': InetSocketAddress =>' ./finagle-core\nfinagle-core/src/main/scala/com/twitter/finagle/builder/ClientBuilder.scala\n642:      case inet: InetSocketAddress => Ssl.client(hostname, inet.getPort)\n655:      case inet: InetSocketAddress => Ssl.client(sslContext, inet.getHostName, inet.getPort)\n666:      case inet: InetSocketAddress => Ssl.client(sslContext, hostname.getOrElse(inet.getHostName), inet.getPort)\n676:      case inet: InetSocketAddress => Ssl.clientWithoutCertificateValidation(inet.getHostName, inet.getPort)\nfinagle-core/src/main/scala/com/twitter/finagle/Codec.scala\n122:    case ia: InetSocketAddress => ia\nfinagle-core/src/main/scala/com/twitter/finagle/dispatch/ClientDispatcher.scala\n19:    case ia: InetSocketAddress => ia\nfinagle-core/src/main/scala/com/twitter/finagle/tracing/DestinationTracing.scala\n21:            case ia: InetSocketAddress =>\n27:            case ia: InetSocketAddress =>\n66:      case ia: InetSocketAddress =>\nfinagle-core/src/main/scala/com/twitter/finagle/WeightedSocketAddress.scala\n35:      case sa: InetSocketAddress => Some(sa, weight)\n```\nNone of these is relevant for the ServiceFactorySocketAddress, but a few could be relevant for the WeightedSocketAddress.\n. @mariusae yeah, I think you're right.  I'll file a ticket internally.\n:shipit: this looks fine to me, although I still don't love the implicit cast.\n. Can you add a test?  LGTM though.\n. LGTM\n. BtreeClient is something twitter-specific, I believe.  I'm not sure where else Btrees in redis exist, and I don't think anyone at twitter uses finagle-redis anymore.  Maybe we should just delete the btree support?  If anyone wants to revive it, it will still be in the git commit history.\n. We have a cache proxy which we speak thrift to instead.  I don't know the details / rationale, I haven't used it personally.\n. OK, I'm going to try to fix up the style nits myself so we can get this in (since this has taken so long).  Thanks @mkhq!\n. @mkhq thanks for the update!  Let me know if there's anything I can do to help.\n. @mkhq do you mind holding off on working on this for a little while?  we're doing a major refactor of finagle-redis, and I'm worried about your work accidentally getting lost in it.  it should land in ~ a week.\n. @mkhq thanks for waiting!  We've made the changes to redis, so it should be in a pretty reasonable state now.  Thanks for your patience! \ud83d\ude80\n. Yeah, squashing would be rad.  I can do a code review when you feel like it's ready \ud83d\udc4d \n. A new PR works for me, thanks so much!\n. @olix0r hey, sorry I didn't ask this before, but what's the backstory behind using a custom filter instead of AnnotatingTracingFilter?\n. Hmm, many of our protocols are still sending responses over the wire when we see a failure though, right?  Like we still say ServerSend on the server side.\n. Yeah, I'm not sure.  But if it sends back an http 5xx, or a mux TErr, it seems reasonable to still emit a wiresend.\n. Hmm, my impression was that this filter is on the server's service, ie the application-level behavior.  So the dispatcher will invoke the service (with this filter in it) and then will make a decision based on invoking this service.  Maybe this isn't really the right layer if we want to claim that we only write this trace after writing to the wire.\nDispatching looks something like:\nscala\nread().flatMap { req: Req => svc(req) }.flatMap { rep: Rep => write(rep) }\nso we would actually want to trace that we've written to the wire after the dispatcher writes successfully, but with this filter it would do it before we write it.  So maybe instead of adding this filter, we should have something that modifies dispatchers instead.\n. Looks like https://github.com/twitter/finagle/pull/463 is probably the way forward here, so I'm closing this PR for now.\n. Hi @ken57, thanks for filing the issue!  Yeah, that's very strange, we should fix that.  Sorry it took us so long to get back to you about this.\n. Ah, good catch!  I'll mark it as fixed.  Thanks @niw!\n. I think the assumption with using raw sbt was that you have sbt installed on your machine.  Instead of using ||, it's probably fine to just make the examples use ./sbt by default.\n. Thanks for the contribution :]\n. LGTM\n. @tomzhang if you want to build against the develop branch, you should check out util and also do a publish-local against its develop branch.  We often publish changes in util snapshot and then consume them immediately in finagle snapshot, so we do this so that we don't break the build.\nInstead of making this change, do you think you could improve the documentation to make this clear?  We mention it in the CONTRIBUTING.md file, but it sounds like it wasn't clear enough.\n. Is this in-scope for finagle?  finagle-http is such a weird mishmash of things that it is probably in-scope for finagle-http, but it would be nice to start reining in the http API and separating things out into a separate utility library.\nWith that said, this sounds like a cool idea in general.  It might be useful to take a look at dispatch too to see what worked / didn't work in that DSL.\nAlso, what's an http monad?\n. I'm going to close this feature request for now, since I'm not sure that this is in-scope for finagle right now.  Since this ticket was filed, @jeremyrsmith published featherbed which I think solves a similar problem.  We can revisit this in the future if simplifying the http Request and Response types doesn't help.\n. LGTM except for a couple nits\n. Yes, it is designed to be used by many threads.  In general, the finagle public API is threadsafe unless it explicitly says otherwise.\n. Have you tested this to make sure it solves the problem?\n. :+1: shipit\n. Nah, seems reasonable.  Do you want to make a PR against Daniel's branch?  The one caveat is that because we're going to squash this into one commit, only he would get the authorship credit for the change.\n. :+1: \n. That seems reasonable, although it seems weird to me that the ruby thrift implementation would be fine to just make it unsigned instead of failing.\nCan we continue generating [0, 2^64] but then subtract 2^63 to preserve the full size of the ids?\n. Can you add a trailing slash for consistency?  Also, y u no TLS???\n. @3thinkthendoit can you publish-local the twitter/util project?  If you want to build off of stable versions, you can compile from master, which should only be a little behind develop.  You can find more details here.\n. LGTM\n. LGTM\n. @3thinkthendoit the patch landed a while ago, so this should work now.  Please let us know if you run into any trouble with it!\n. @scf37 One of the advantages of open source software is that you're using software (like load balancers) that have been tested extensively by other companies, including at scale.  Could you elaborate on why you don't want to use any of the load balancers that we already provide?\nThe ServiceFactory / Service abstraction generally works well for us, although there are a few places where we reconvert from Service to ServiceFactory, which I agree can be confusing.  We're working on smoothing it out.\n. > Given Var[Set[Service]], create Service that balances that set. This task is too complex - you'll need to wrap/unwrap service factories and configure pools to keep underlying services opened.\nWhy do you want to do this?  The point of having StackClient is so that you don't have to do this.  Connections pools keep persistent connections, so there's no reason you have to do this manually.\n\nEntire Stack implementation looks like typed dependency injection framework. While it allows to combine, re-combine and configure any part, it requires additional code to insert even simple filter w/o parameters. Also, combined Stack is hard to inspect and modify: What filters are in? What parameters do they have? What parameters are set? Can Stack type contain information on every element it contains?\n\nIf you have to modify the Stack, either you're doing something incorrectly, or we should probably support your use case in StackClient.  It's probably not the API you should be using, and we tried to put warning in the API docs.  See \"Note: Stacks are advanced and sometimes subtle. For expert use only!\".\nWith that said, Stack is pretty easy to inspect.  It has a nice Stack#toString implementation.\nYes, and in fact we do expose all of this data.  If you use twitter-server, you can hit /admin/registry.json and it explains every level of the stack and how each level has been configured.\n\nBalancers need better isolation from what they balance. It looks like right now balancer client must call ServiceFactory.close() to indicate he is done with that connection/session/request so it can be returned to balancer's pool. Why not provide abstraction that can both work with Service and ServiceFactory and both with one-time and persistent connections? So programmer do not need to protect Balancer pool services from being really closed 'by design'.\n\nWe do, they're connection pools. See WatermarkPool, SingletonPool, DefaultPool, etc.  When the LoadBalancer says, \"close this session\" it means, \"I no longer need this connection, so somebody else can use it.\"  It doesn't mean it cuts the connection.  Finagle doesn't natively support any protocols where you cut the connection, so if you're seeing this behavior with StackClient, without modifying the Stack, I'd be very surprised.\n\nStack needs better toString and ability to enumerate available properties for every attached module. May be more. I was thinking of possibility to make Stack-s by combining traits so we get something typed in the end... Or may be something else.\n\nI think the toString method might actually do do what you want it to do.  Could you elaborate on what you expect it to do versus what you want it to do?\n\nClientBuilder/ServerBuilder are great. Really.They list all available configuration in single interface so one can see what they do, what they don't do and what can be configured. So they are ideal for novices (give me something working but configurable) and experts looking for typical stack.\n\nWe're aware of the problem with the finagle 6 APIs, and working on fixing it.\n\nWhat I love in Finagle most is that it is (mostly) composable. It \"don't want it - just don't use it\" ideology. So I'd love to see better support for building finagle pipelines from scratch or predefined parts (like dam balancers with dam pooling and dam wrappers)\n\nWe've been thinking about this, but I'd be very curious about your use case.\n@scf37 it feels like you're coming into the project first to criticize it, and it might be more productive if you come in first to try to understand it.  For example, a lot of these questions where you misunderstood what finagle was doing could have been framed as something like, \"I don't understand why it seems like load balancers cut the underlying connections after they're done, but we also have connection pools\u2013those seem contradictory.  What am I missing?\"\nMy main gripe is that it feels like you're on the attack in our open source community, and I don't want to feel like I have to defend myself against folks who are really on the same side as me\u2013it sounds like you also want to make finagle better, which is great!  But I feel like we could work on making our interactions feel more like a collaboration and less like a battle.\n. OK, thanks for explaining your rationale.  I think we do want to make it possible to construct your own Stacks, but it's unlikely that we're going to put a lot of effort into making it easy.  Our focus is on making the common path easy, and the build-from-scratch path possible.  But if there are simple ways of making the build-from-scratch path better without hurting the common path, of course we'd be happy to hear about them.\nIf you want information on parameters, right now you can get it from TwitterServer's /admin/registry.json.  We don't expose that in Stack#toString yet, but happy to accept a pull request.\n. I'm closing this ticket, since it's more feedback than a well-formed issue.  The issues that @scf37 raised are something we've been thinking about, and down the line, we would like to improve the expert-level API.\n. LGTM\n. LGTM, except for a nit.  Glad to hear you're using it!\n. Rad, thanks!\n. @zfy0701 I think we already have this in the generated code.  Could you take a look and see if your code was generated with them?\n. Oh, I understand now.  Happy to accept this here if you can avoid reallocating new stats and counters on every request, but if you can't do it with this API, let's put it in the scrooge generated code, like with the client.\n. LGTM\n. LGTM!\n. LGTM except for comment, will try to get more eyes on this.\n. :+1: \n. This was merged internally, thanks for your patience!  I'll update this ticket again when we publish it to the develop branch.\n. LGTM!\n. could you follow the instructions from the CONTRIBUTING guide?  It could also be useful to update the CHANGES file to note the bugfix.\nSo this is a little tricky because it's concurrent.  This means that we could get weird orderings, and makes it difficult to be efficient.\nIn particular, what we're concerned about is:\nt1: queue.remove()\nt2: queue.remove()\nt1: queue.touch()\nyour proposed solution fixes it so that instead it looks like:\nt1: queue.remove()\nt2: queue.remove()\nt1: queue.touch(); queue.remove()\nthis can also manifest as:\nt1: queue.remove(); queue.touch()\nt2: queue.remove()\nt1: queue.remove()\nwe can do somewhat better, by guarding on if the connection has been closed already.\nscala\nif (!c.onClose.isDefined) {\n  queue.touch(c)\n  if (c.onClose.isDefined) {\n    queue.remove(c)\n  }\n}\nso that in this case, the common case interleaving should be:\nt1: queue.remove()\nt2: queue.remove()\nand the much less common case should be:\nt1: queue.remove()\nt2: queue.remove()\nt1: queue.touch(); queue.remove()\nWe must allow this race if we don't want to add additional synchronization, because onClose is racy\u2013we could read that onClose is not defined, but then onClose could fire and remove it.  But it means it only happens in that extreme race condition.\n. CHANGES and commit message look great, thanks!  Just one last fix.\n. Actually, it occurs to me that it would be nice to add a test for this case.\n. @gpoulin do you think you'll have an opportunity to take a look sometime?  no rush :smile_cat: \n. @gpoulin just wanted to check in if you think you'll have any more time to work on finishing this?\n. @gpoulin this is 99% of the way there, so we're going to pull it in and try to add a test on our end.  thanks so much!\n. So it looks like IdleConnectionFilter is no longer used in finagle, so I'm going to close this PR and delete the class.  Please let me know if you still need it for some reason!\n. This looks great, thanks!\n. still LGTM :+1: \n. @cocodrino we don't have support for it right now, but we'd be happy to work with you to add it :+1: \n. @cocodrino we've since added support for this here: https://github.com/twitter/finagle/blob/develop/finagle-redis/src/main/scala/com/twitter/finagle/redis/exp/SubscribeClient.scala\n. h/t @thirstycrow =)\n. @lukiano what are you trying to do more generally?  It sounds like you're trying to write from a Reader into a Writer, which we have tooling for: https://github.com/twitter/util/blob/develop/util-core/src/main/scala/com/twitter/io/Reader.scala#L351-L360\n. It shouldn't deadlock.  write is asynchronous, so your thread can continue to do other work.  If you could send a blocked stack trace, that would be great.\nWith that said, why are you using the Transport directly?  And how even did you get your hands on the Transport?  You shouldn't be doing this\u2013it's not safe to write directly to the Transport, and ReaderUtils is marked private because this is not a public API.  If this is a patch to finagle-http, I'd be happy to take a look at it though :+1:.\n. @lukiano I think @roanta is right, I'd suggest reading his comment again.  Note that finagle is asynchronous, not synchronous.  Have you tried what he suggested?\nAlso, how did you get a Reader.Writable?  finagle http should only expose Writer with Closable to you.  I think we'd be able to better help you if you explained to us what you were doing.\n. @lukiano were you able to solve your problem?\n. Very cool, thanks for the update!\n. We generally use SimpleFilter[Req, Rep] as a helper class, not as a marker (since you can use Filter[Req, Rep, Req, Rep] directly as a marker), so I'd say it's a toss up.  It feels like it's an implementation detail when something is a SimpleFilter or not.\n. @spockz we purposefully renamed RetryFilter from RetryingFilter so we've already broken backcompat.  Any place where you used a type of SimpleFilter can be replaced with a Filter, so I think we should be pretty safe :+1: \n. @fab-soundcloud good catch!  Unfortunately, we don't have a ton of bandwidth right now, but we'd love to shepherd your PR through :+1: \n. @mehmetgunturkun it looks like I can only assign it to committers, but feel free to start working on it!  I'll just mark it as \"in progress\".  Thanks, and welcome to the project!. Hi @chandra-cd could you paste the full stack trace?\n. @chandra-cd did you have a chance to look more deeply into this?\n. Glad to hear it!  Unfortunately, we don't have the bandwidth to test every version of mysql.  Out of curiosity, which version of mysql didn't work, and which one are you using now?\n. Thanks!  Good to know.\n. LGTM\n. Actually, would you mind changing your commit message to be prefixed with finagle-core:\n. @thirstycrow it's not on our roadmap right now, but we'd be happy to help you with your pull request! :+1: \n. <3\n. Both of these were merged in, so I'm going to close this ticket.  Thanks so much @thirstycrow !\n. Wow, this review is awesome!  :+1: I'll try to get someone from the cache team over on our side to take a look at it too.\nOne thing I'm wondering about, should we provide sentinel-specific tooling?  For example, should we provide a read-only sentinel Service abstraction, where you can read from anybody, but only write to the master?\nAlso, is probably out of scope, but the way that the AUTH command is implemented is that it only checks for one client, which was fine because we previously only wanted to connect to one redis instance, but if a few redises can be treated as the same, it might make sense to treat them as a regular cluster\u2013if that's the case, authentication should be treated specially, like it is in mysql, so that it happens as part of a handshake, instead of requiring that users do it themselves.\n. Thanks @mahakp!  Let's get this out the door, we can do more work with adding native clustering support after we merge this in.  Thanks for your patience @thirstycrow!\n. This was merged internally.  Thanks for your patience!\n. Again, really appreciate your patience with us @thirstycrow.  Now in develop: https://github.com/twitter/finagle/commit/238f98dfb126700d71c221186a71a4a026b4dd45\n. LGTM, can you format your commit message like so:\n```\nProblem\nHere is my problem.\nSolution\nHere is my solution\nResult\nHere is my result\n```\nYou can see an example here (without result, which was obvious): https://github.com/twitter/finagle/commit/e45fd2ab87c248989d3f7937c98c0f77f95f8a27\n. not a problem!  your commit message was pretty good already ;) LGTM\n. finagle isn't on this version of thrift yet\u2013I think it should be safe though, since in the worst case, we can simply stop using a given feature if it's causing trouble, and I'm pretty sure it's backwards compatible.  I'll try to get some more eyes on this.\n. We use 0.5.0 in JVM-land. Thanks!\n. @cyphactor do you think you'll have a chance to take a look at this?\n. Yeah, let's merge this in.  I'm not sure if there's anyone else at twitter who has more context anymore, but I'll ask around.\n. Merged to develop here: https://github.com/twitter/finagle/commit/31da47473a049b14a3360a6c34e3897c3d170a7b thanks so much!  Sorry for the delay.\n. LGTM from a high level, let's hammer out the details!\n. This is looking pretty good!\n. LGTM!  I'll try to get some more eyes on it too.\n. I don't super love this approach (I'd rather expose an actual streaming abstraction) but given finagle's poor streaming support right now, this is probably our best bet.\nThe only other way I can think of doing this would be to mark the redis command a sealed trait, and check whether it's a subscription-style or non-subscription-style command.\n. this looks fine to me, but I think we might want to put this in an experimental package (like com.twitter.finagle.redis.exp), because I think we should change the model away from the the handlers one when we make StackClient a little more flexible (in the next few months, hopefully).\nI think a reasonable list of TODOs for redis is:\n1.  Stop using the mutable subscription clients once we have better streaming support\u2013hand back a Closable AsyncStream.\n2.  Clarify connection pooling for \"reserved\" connections vs \"shared\" connections.\n3.  Remove extra finagle client stuff we don't need anymore\n4.  Provide tooling for sharding (eg a \"subscribe\" method that scatter-gathers automatically).\n5.  Support transactions\n. Actually, now that I think about it, one way we could simplify this would be if we provided a method that lets you choose whether you want the pipelined connection pool or the non-pipelined one when constructing a client.  Then you could use the pipelined connection pool for shared work (like get, set), and the non-pipelined one for reserved work (like transactions, subscriptions).  It's somewhat manual, but  it would get the job done, as long as we make sure not to close the returned service until we unsubscribe.\n. We should keep the Redis.client.newRichClient style instead of Redis.newRichClient style, because that's the style throughout the rest of finagle.\nWhat do you think about using the same transaction API as we have in mysql?\ndef transaction[T](f: Client => Future[T]): Future[T]\nOtherwise, sounds good.\n. thanks @mahakp!  Let's get this out the door, thanks for being so patient @thirstycrow.  You don't have to make any changes, the notes I just made were so for myself.\n. Sorry, ended up in jury duty last week, trying again to merge this internally.\n. This was finally merged internally.  Thanks for your patience!\n. @thirstycrow thanks for being patient with us!  it's finally in develop.  https://github.com/twitter/finagle/commit/b6bc1601bdb6bbe8fda8c9c193b540166fa48fb4\n. LGTM in general (caveat lector: I consulted on the final design, so I'm biased :P)\nCould you add a test?  Also, could you wrap the server dispatchers you care about in a few protocols to demonstrate?  I think the relevant ones will be http, thrift, at least.  mux if you can get away with it.\n. Steve!  How's it going?  Are you using finagle at netflix?\n. LGTM\n. ahh, nice!  looking forward to your visit :+1: \n. Would it be possible to use longs here instead of doubles?  I haven't looked at this part too closely, so I'm not sure what we use the fractional bits for.\n. This was merged in here: https://github.com/twitter/finagle/commit/9a5d4af4ed5d36f314962797636d8bfc9381b95a thanks!\n. @futureskywei what do you think the fix will be?  would you like to submit a PR?\n. @futureskywei hmm, well netty 4 has a lot of breaking changes, so we're doing it piecemeal.  What do you think we can do in the mean time?  maybe we should add a null check?\n. Hmm, maybe this isn't the right solution.  It looks like \"version\" is a reserved name for cookies.  See RFC2109.  Maybe the right thing to do is to rename your version cookie name to something else?\n. I think this is works as expected, so I'm going to close this ticket.  @futureskywei please let us know what you ended up doing!\n. LGTM\n. What you're running into is that when we signal an interruption to the Future that's going to return a result from a remote server, it considers that a request to discard the work, so it cuts the connection.  We use tearing down a connection in http to signal to the server that we no longer care about the work.  If you don't have to tear down the connection, I would recommend not interrupting the request.  Instead of Future#raiseWithin, for example, you can take a look at Future#within.  Another option would be to mask the future explicitly, which you can do with Future#masked.\nWe're currently looking into http2 support, where we'll be able to use http2 interrupts to avoid having to tear down the connection to signal to the remote server we no longer care about the work, but that's a few months down the line.  If you control the remote servers, you can also consider using thriftmux instead, where we already support this functionality.\nOne other option is to choose your timeouts less aggressively, or to use BackupRequestFilter.  If you're doing 3K QPS and need to tear down more than a few connections per second, it might be worth looking into why that is and trying to fix that.\n. I'm going to close this ticket, since we can't really do better on http/1.1\n. LGTM, but it would be nice to use zk2 instead of zk, which is what we use internally, and we think it's more reliable.  I'll get some folks to come take a look at your usage :+1: \n. LGTM except for a couple nits.  Sorry for the delay, github doesn't tell us when you merge in a new commit.\n. LGTM, thanks!\n. @sunnykaka this was merged internally, thanks for the contribution!  :fire: \n. This made it to develop here: https://github.com/twitter/finagle/commit/766f38974663b80509f7d19ae9263c659b11d8a6.  Really appreciate the PR!  :fire: \n. hey, would you mind adding a commit where the first line of the commit message is the title of this RB, prefixed with finagle-http:?\n. LGTM except for a few nits.\n. LGTM\n. Welcome, @dy8000!  Check out the CONTRIBUTING.md guide, which describes how to build the project.  If you just want to try building it, I'd suggest going to the master branch, which will use the stable versions in maven central.  If you want to contribute back, I'd encourage you to follow the instructions to check out the dependent repositories.  The develop branch has the newest code, which may depend on changes in other repositories.\nAlso, if you're having trouble getting set up, feel free to jump into our gitter channel, or to ask a question on the mailing list!\n. @dy8000 sorry to hear you're having trouble.  However, the good news is that sbt is the community standard in scala, so it'll be worth it for you to learn sbt.\nWhat are the dependency problems you're running into?\n. LGTM\n. Sorry for the delay in reviewing, it fell off my radar!  Does this need to be configurable?  Or can we make it private[finagle]?\nThinking about it more, @kevinoliver do you think it would make sense to have a TransactionContext object that lives for the space of a request, that can be updated at any time during that request?  We already have the TLS peer certificate, which should be available during this entire time too (although really it's SessionContext, not TransactionContext).\nThis looks good, I wonder if we can replace the layers of our protocol implementations where we get the trace id out of the request and call Trace.letId with this param.\n. @penland365 let us know if you need any help on this!\n. @penland365 I thought we had agreed that you were going to remove the responseToTraceId bit?\n. @penland365 just wanted to check in.  how's it going?\n. Good point!  Would you like to make a PR?\n. LGTM\n. merged here: https://github.com/twitter/finagle/commit/563264de172b3443a75b3edd2fb1b06b07e34e22  thanks again!\n. Hey @leonmaia, do you think you'll have a chance to get to this sometime this week?  No rush if you're busy \ud83d\ude00\n. No worries, just wanted to make sure it didn't fall off your plate.\n. @luciferous yes.  HttpMessageProxy extends Proxy, which makes the netty Message methods available.\n. @olix0r do you know which FactoryToService is closing it?\n. Looks like this one: https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/client/StackClient.scala#L272\nThinking about it more, we should be able to suppress actually putting it back into the pool until after the stream has finished being read.  This is a little naughty because if you manage your connection pools yourself, this might be surprising behavior, for example if you're trying to tear down a client in the middle of receiving a response.\nAnother option is to change the way that this FactoryToService works for http, so that it waits until the response has finished being written.  The trick here is that this specific FactoryToService will need to be given its own role so that it can be specified differently from other FactoryToService modules.\n. @dschobel @olix0r I think you can close the service directly if you're managing it manually if you use Client#newClient, not Client#newService, since none of the FactoryToServices will be applied.\nedit: implementation here: https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/client/StackClient.scala#L528-L553\n. NB that we can already do /http/1.1/* => /h with /http/1.1 => /h.  LGTM\u2013my main concern was that it would complicate precedence, but it looks like it won't because we removed the \"longest delegation wins\" rule.\nThis sort of tacitly admits that names aren't really strictly hierarchical\u2013path parts are more like tags.  If we're OK with this (which it sounds like is useful in production) then we should make sure that we're still happy with dtabs in general.\n. Ah, I see, you're right of course.\n. LGTM, except for one nit.\n. @olix0r also, can you add a note in CHANGES?\n. :+1: pulling it in\nedit: wrong PR, whoops\n. @mritman, very interesting!  I'd like to take a look too, hoping to check it out this weekend if folks haven't already figured it out by then.\n. @luciferous isn't this an inherent race condition in the protocol?  if a stream is chunk-encoded and ends the transfer by closing the connection, it's indistinguishable from the remote dying.  wouldn't a \"correct\" implementation of this API signal to the reader, \"we don't know whether the server died or is finished\"?\n. @luciferous actually, it looks like it doesn't matter if the server's responses are chunked or not . . . weird.\n. @olix0r I found a race condition in your first test, seems to work OK after fixing that.  taking a look at the second one now.\n. @olix0r and I think that ChannelTransport closes itself, which is why your proxy never detected a close.  I've added the commit which no longer uses the proxy to my PR, so both tests should now pass.\n. @spockz @mritman I'm beginning to think that @luciferous is right that this is a case of a difficult to use API, although it looks like there are a few bugs too.  Since your server is sending a chunk-encoded response, you need to use the response.reader to parse it.  The CLOSE_WAITs seem to disappear when I change to reading the entire reader explicitly and discarding it.\nA couple open questions:\n1.  why isn't it sufficient to read the entire reader?\n2.  why isn't it sufficient to discard the entire reader?\n3.  why isn't it sufficient for the server to cut the connection?\nMy suspicion is that the reader constitutes  a read handle, and that we don't want to cut the read handle prematurely, so that it can still read whatever is in its socket buffer, so 3 makes sense, but 1 and 2 less so.\nI think it's also a bug that content / getContentString don't actually drain the reader.  The intent is to avoid blocking on io, but I think we should instead make it clear that getContent is only safe to call on unchunked content, or when you don't mind if you block.\n@luciferous what do you think?\n@mritman @spockz For what it's worth, if you control your remote servers, the remote server closing the socket should be an edge case, not the normal one.  Tcp sessions are not light, and you'll entail significantly GC pressure if you're constantly tearing down tcp sessions.  With that said, we absolutely want to get to the bottom of these bugs, so we appreciate you finding the minimization, since we know that it will happen occasionally even with servers you control, and that some servers you don't control may do weird things. :sparkles: :+1: \n. @mritman @spockz I've made a PR here: https://github.com/mritman/finagle-not-closing-sockets/pull/1 please let me know what you think!\n. @spockz yeah, it returns what is already received.  I think this is confusing, but it's potentially also confusing to change a call that doesn't block to one that does . . . I agree that it would be nice if responses that were chunked didn't have a content / getContentString, but it's difficult to change the API of Request, since it's one of the APIs that people use the most.\nYeah, it might be worth pursuing having finagle try to read what's in the socketbuffer into memory.  I think that should be safe, although I'm not sure if it might be make us run into weird problems if a remote host has sent us more bytes that we want to copy into the JVM.\n. OK, I dug into finagle streaming clients some more, and I now think that the two main problems were not getting to the end of the read stream, and timing out without getting to the end of the read stream.  Note that if our Await.result fails, then we never assign the new response to the response variable, so if it opens a read handle, we will never have the opportunity to discard the read handle.\nI no longer think that there's a bug where you need to drain AND discard.  I think it worked because it slowed down the operation, and not because of an underlying bug.\n@mritman @spockz I'm convinced that there isn't a bug, but the API is difficult to use.  We'll be working to make it simpler.  Do you think it's OK to close the ticket?\n. @mritman it can be handled by the user of the finagle API\u2013almost none of our users use the Await.result API because most of our users use the asynchronous API, not the blocking one.  It's easy to deadlock if you use the blocking one and you're using finagle clients as well as servers, so we advise strongly against it.  It's much simpler to reason about if you're using future transformations.  I've included an example of how you might describe this behavior asynchronously lower down.\nah, the problem is with the Await.result(service.apply(request)), not in the Await.result(Reader.readAll(reader)) section.\n1 / 2.  Please note that any use of Await.result is blocking, regardless of whether you set the timeout or not.  The only case in which it's not is if you set a timeout of 0.  You should not use Await.result if you can avoid it.  It's better to use future transformations.  If you want to time something out, you can use Future#within or Future#raiseWithin.\nReader.readAll buffers the entire message, so you should only use it if you don't need your response streamed to you.  Otherwise it's preferable to use normal Reader#read(Int).  You can set a timeout on the read with Future#within or Future#raiseWithin and if it fails either of those timeouts, you can then discard it.  Here is one way that would be safe:\nval rep = service(request)\nrep.raiseWithin(20.milliseconds).flatMap { response =>\n  Reader.readAll(response.reader).raiseWithin(20.milliseconds).onFailure { timeout: TimeoutException => response.reader.discard() }\n}.onFailure { _ =>\n  rep.onSuccess { response => response.response.discard() }\n}\n1.  If you're using the Reader#read API directly, it will return you a Future[Option[Buf]].  When the future is satisfied, if it's satisfied with a None, you know that you're reached the EOF and you can stop reading.\n2.  You only need to make sure you call response.reader.discard() if you know you're no longer going to need the read handle and you haven't reached the end of the stream, or the stream hasn't failed (timeouts don't count).  In other cases, the stream will take care of itself.\nAs far as docs go, we know that streaming is a weak part of our documentation.  This ticket is convincing us that we should change the Request / Response API too, so we're probably going to change the API to be easier to use, and then document it.  It might make sense to document safe use of Reader first though, since that's probably not going to change that significantly.  I'm going to close this ticket, but I've opened ticket #488 to improve documentation of Reader.\nThanks for bearing with us as we figured out what was going on in your snippet!\n. Yes, it looks like netty doesn't have support for it, I've filed a ticket with them https://github.com/netty/netty/issues/4970.\nWith that said, since what you're trying to accomplish is to add support on the server-side, maybe it makes more sense to carefully craft a unit test that you can use to verify it works rather than to add general client-side support?  If you decide you also need it on the client-side, then we can go down that road later.\n. :+1: sounds like a good plan, thanks!\n. Looks like google changed their behavior slightly.  We should update the quickstart to reflect this.\nWe can fix this issue by:\n1.  Pointing to twitter.com instead of google.com\n2.  Changing the test command to be curl -D - -H \"Host: twitter.com\" localhost:8080\nI'm marking this as a starter issue since I think this would be a great way for someone to get started with playing around with finagle.\n. Fixed here: https://github.com/twitter/finagle/commit/a60909d4996ff87d016187fe4abf2f899d466e75 !\n. LGTM, just a few nits, thanks!\n. @nrinaudo if the test throws an exception we have bigger fish to fry :wink:.  internally, we can't merge in code that makes our tests fail, and the tests will get torn down at the end of the day, so resource consumption isn't that bad.\n. LGTM\n. We merged this internally, it should show  up on the develop branch on Monday.  Thanks!\n. @nrinaudo boom: https://github.com/twitter/finagle/commit/7b5eaaebf4a9b7c11808207af51bd3001f0ef609  thanks so much!\n. Nope, still doesn't work :(\n. looks good to me too!\n. just a few more nits.   thanks so much, I think it's really close.\n. LGTM\n. @stevej some feedback I've gotten so far internally:\nCan we change the metric name to round_robin instead of rr?\nCan we change the method name to roundRobin instead of rr?\nCan we change the name of the updown variable to updog?\nIf you're OK with these changes, I can make them and merge it in, if not we can talk about it and figure something out :)\ncc @kevinoliver @dschobel \n. This was merged internally, thanks so much for the contribution!\n. @stevej this hit the develop branch today!  https://github.com/twitter/finagle/commit/fc6452179168db49797ae620fafe1f70206b9aaf  Really appreciate you working with us to get it in, this will be really useful for us too. :100: :sparkling_heart: \n. LGTM with the caveat that this won't let folks who are managing their connection manually close them the way they would expect, but that's probably OK.\n. @olix0r oh, I see, because if your FactoryToServices aren't installed you don't have to worry about FactoryToService.  I get it now, thanks!\n. LGTM\n. @anupamaggarwal we ship an sbt with finagle to avoid these exact problems :).  Can you try using the one in the root of the finagle directory?  For what it's worth, we use 0.13.9 ourselves, so there might be something else going on though.\n. @anupamaggarwal no worries!  If you have any more finagle questions, feel free to drop into the gitter or to ask a question on the mailing list, which is the finaglers google group.\n. :ship: :it: \n. LGTM\n. Thanks, made it into develop here: https://github.com/twitter/finagle/commit/21a1ba9cbfc8ae1106d024d3681cece5495dfc8a !\n. Does this need the two patches I added here: https://github.com/mosesn/finagle/commits/mnakamura/test-streaming-disconnects ?\n. @olix0r that patch seems to be nonsense.  I don't understand it, or why either of us thought it was a good idea (you seem to have merged it in here: https://github.com/BuoyantIO/finagle/pull/3/files.  Trying to find the original on my hard drive in case github did something funny here.\n. Nope, github is correct, that commit is just a bunch of nonsense.  I'll try to figure out what I was thinking about again.\n. OK I just have no idea what that commit was supposed to do, but I think the test might not be right now that I'm thinking about it.  If the client succeeds in writing all of its bytes to the wire, it won't realize that the remote has closed the connection until it next tries to write over the connection, so that test is inherently racy.\n. The good news is that I figured out what that patch was supposed to do!  The FactoryToService'd client is lazy, so it hasn't tried to establish a connection on creation.  My concern was that when we made a request, we could still be establishing a connection when we cut the connection.\n. @olix0r it seems like adding a promise that you satisfy when the request has been received, and awaiting that promise also fixes the test.\n. OK, now that I think about it more, I'm confused.  Why does this fix it?  Why would the server never receiving the request mean that we should time out?\n. OK, so thinking about it more (and adding a bunch of printlns), I think that the problem is that the client says it has successfully established a connection when the kernel finishes the handshake, and the server might not have called accept and assigned a transport yet.  So there's a race between failure being set to done and calling the modifier we pass to the startServer.\nThe smallest diff I've found that can fix the test is removing the if (failure.isDefined) which seems pretty compelling.\n. Thaaaaaaanks @olix0r \n. Made it to develop here: https://github.com/twitter/finagle/commit/4488767656c64e6ad67c4eff4099739c18579b2d thanks!\n. @liyichao thanks for the bug report!  Which thrift client are you using?  Is it the one in go?\n. Hmm, that's interesting.  finagle has been pegged to thrift 0.5.1 for a long time, I wonder if this might be a problem?  Can thrift 0.9.1 clients talk to thrift 0.5.1 servers?\n. LGTM\n. 1.  Expected behavior is that they're only changed minutely.\n2.  Hmm, maybe.\nThere are a few weirdnesses:\nWe're using System.currentTimeMillis instead of System.nanoTime for measuring a duration: https://github.com/twitter/twitter-server/blob/a569edc24aca5935389d8ae498aa5abdb05cdcc1/src/main/scala/com/twitter/server/util/MetricSource.scala#L21\nWe update secondly in MetricSource:\nhttps://github.com/twitter/twitter-server/blob/a569edc24aca5935389d8ae498aa5abdb05cdcc1/src/main/scala/com/twitter/server/util/MetricSource.scala#L19\nWe also use System.currentTimeMillis instead of System.nanoTime for measuring a duration here:\nhttps://github.com/twitter/finagle/blob/develop/finagle-stats/src/main/scala/com/twitter/finagle/stats/MetricsBucketedHistogram.scala#L73\nWe assume that a metric will be queried at least minutely for every minute after it starts.  If you don't, we will snapshot as often as you want until you catch up (I suspect this is the problem you're running into).\nhttps://github.com/twitter/finagle/blob/develop/finagle-stats/src/main/scala/com/twitter/finagle/stats/MetricsBucketedHistogram.scala#L73-L75\n@yokoshin pointed this behavior out on this thread, and we've been playing around with a few ideas for how to improve this: https://github.com/twitter/twitter-server/issues/33.  Would love your feedback.\n. Jinx!  Let's move discussion to the TwitterServer thread.\n. You already fixed this here https://github.com/twitter/finagle/pull/495 so I'm going to close this ticket.  Thanks for the contribution @olix0r!\n. LGTM\n. LGTM except for a nit in the test\n. LGTM\n. I think it would be useful.  A few people have asked about it, so clearly there's a use for it.\n. @mariusae I don't think sticky sessions violate this, as long as it's an optimization.  If each remote host responds the same way, except that it can provide better information if it knows what it last gave the peer, that will work too.\nConsider the case where you care about the members of a given set (say, service discovery).  The contract clients and servers have is that a client connects to a single server, and then it gets a full copy of the members.  On subsequent updates, the server can now choose whether to give it diffs or a full copy.  It doesn't violate the assumption that service clusters are homogeneous, and the client doesn't care that it had to keep talking to the same server to get the diffs.  It's purely an optimization.\nWe may want to do this if we start backing a server like this with a wily name, and want to be able to fail over to another such server using wily.\nWith that said, it does break requeues, but aperture of size one does too until failure accrual kicks in, so this seems harmless.\n. @mariusae this seems OK to me\u2013the same way that finagle-memcached assumes that you'll talk to shards as if they're shards, and not as if they're replicas.\nIf we end up in a future where finagle is more modular, we will be able to swap out the load balancer for a sticky session chooser, and choose to layer sharding on top.  You can imagine a cache client which also has a small fixed-size in-memory cache that the shard can choose to update with hot keys.\nWith that said, from talking to folks who are using aperture of size one, and @johanstenberg92, it sounds like none of them actually need naming, which is the only reason to put this at the load balancing layer, as far as I can tell, so we're going to close this ticket.\n. @mariusae sort of?  it's basically an implementation detail today.  the API we expose is the same regular finagle protocol one, and we will probably move shard management into the normal stack so that we can use names.\n. I have a couple questions about your commit message.  What exactly do you mean by \"strong eventual consistency\".  Are you referring to read-your-writes consistency?  Delayed-t consistency?\nThe nodes are still identical replicas, right?  The only difference is that you want to be pegged to a single remote peer if possible, which makes it easier for a server to maintain state for a given client.\n. This is a good first draft, thanks for the PR!  I'll see if I can get a potential user internally to take a look too.\n. cc @olix0r who cares about this too.\n. Eventual consistency is still not well defined.  Unless it's OK that remote servers sometimes don't have the data you just wrote, it sounds like what you want is read-your-writes consistency.  If that's the case, your data server needs to ensure that it writes to a replicated log, and tells clients the position of the write in the replicated log, so that it can ensure that when it reconnect to another data node, that the other node is caught up to that position in the replicated log.\nWhen we get to that layer, this load balancer is not going to be the right tool.  You will have to do what you're describing where you use the ServiceFactory directly, so that you can have special behavior when you switch nodes.\nDoes that sound right?\n. Yeah, from talking to other users who want sticky sessions, it looks like their use cases are also satisfied by using the ServiceFactory directly.  We probably don't want to add this until we're sure we have a use case where we need the load balancer to own this.\n. @yukw777 it doesn't seem like \n``` scala\nclass DeadlockFilter[Req, Rep] extends SimpleFilter[Req, Rep] {\ndef apply(request: Req, service: Service[Req, Rep]): Future[Rep] = new Resp\n}\n```\nshould even compile, since it returns a Rep, instead of a Future[Rep].  Is it possible that you're blocking on the response and then rewrapping in a future, instead of transforming the asynchronous response?\n. No, there is no way to reset the reader.  This is intentional, so that servers can stream requests that are bigger than they can fully buffer.  But this should also not block.  bodyBytes will just be empty.\n. What do you mean by hang?  Do you mean the do something never executes?  From your code, it looks like it's because you haven't written anything to the response's reader, but you also haven't terminated it, so it assumes that it might still send bytes through it.  So I think that's a feature.\n. @yukw777 I'm so sorry, I missed your response!  I'm trying it out now.  This might be a bug.\n. @yukw777 OK, so I tried it in the repl, and I think your code is right except for one small thing, which is that close will not be satisfied until what is written has been fully read.\nHere's the result of playing around in the repl.\n``` scala\nscala> import com.twitter.finagle.http.Response\nimport com.twitter.finagle.http.Response\nscala> import com.twitter.util.Await\nimport com.twitter.util.Await\nscala> val resp = Response()\nresp: com.twitter.finagle.http.Response = Response(\"HTTP/1.1 Status(200)\")\nscala> resp.close()\nres0: com.twitter.util.Future[Unit] = Promise@464042769(state=Waiting(null,List()))\nscala> res0\nres1: com.twitter.util.Future[Unit] = Promise@464042769(state=Waiting(null,List()))\nscala> import com.twitter.io.Reader\nimport com.twitter.io.Reader\nscala> Reader.readAll(resp.reader)\nres2: com.twitter.util.Future[com.twitter.io.Buf] = Promise@92341597(state=Done(Return(com.twitter.io.Buf$NoopBuf@811c9dc5)))\nscala> res2.onSuccess { buf => println(buf.isEmpty) }\ntrue\nres3: com.twitter.util.Future[com.twitter.io.Buf] = Future@595450727(depth=1,parent=Promise@92341597(state=Done(Return(com.twitter.io.Buf$NoopBuf@811c9dc5))))\nscala> res0\nres4: com.twitter.util.Future[Unit] = Promise@464042769(state=Done(Return(())))\n```\nSo I think it works, but your flatMap closure was never executed because it couldn't be executed until after close was satisfied, and close couldn't be satisfied until after the flatMap closure was run!\nHopefully this answers your question.  I'm closing this ticket for now, but please reopen if you have more questions.\n. @tindzk I think we've answered your question.  If you decide your filter is general-purpose enough, please feel free to make a PR, and we can look at whether we want to add it to finagle!  I'm closing this ticket for now, but please feel free to reopen it if you have more questions or you want to talk more about building this kind of filter.\n. @lukiano yah, we were thinking about how to implement pooled ByteBufs, we were thinking we could use PhantomReferences?  What do you think?\n. @lukiano but what if we want to read it again, or we don't want to finish reading it?\n. LGTM\n. LGTM\n. This was merged in a while ago =) https://github.com/twitter/finagle/commit/dd5736a31f44ce145aed6327586504e75fda753c\n. Yeah, maybe we should keep RetryFilter in ClientBuilder, and add the improvement there?  @olix0r we've been exploring using ClientBuilder as a tool for configuring application-level logic, and keeping finagle transport / session-only.\n. RetryPolicy construction is safe because it's lazy\u2013it requires that you have the failure in hand before constructing the next one.  We usually pop back up the stack before using it again, so we don't go deeper in the stack.\nI agree that we don't want to break the ClientBuilder API.  I think it's worth noting that RetryFilter does what you want already without having to use ReqRep, as long as you do it outside of the finagle stack.\nI don't really know what the right thing to do with this is.  It seems tricky that we want to be able to use application-layer information to inform session-layer decisions.  I think we don't know the right balance yet.\n. We ended up deciding that this wasn't the right way forward.  We may come up with richer application-level tools in the future, but for now we don't want to add this to finagle.  If you're curious about this anyway, @olix0r's solution is how you should do it.\n. @jeffreyolchovy yeah, we ran into that too.  filed a ticket in the scala issue tracker here: https://issues.scala-lang.org/browse/SI-9871 and it's being worked on here: https://github.com/scala/scala-dev/issues/157\nwe'd love some help with poking the bijection people to start supporting 2.12\u2013I don't know if any of them are still at Twitter.  jackson we're waiting on the same thing as in the ostrich ticket.\ngood to hear it won't require any source changes in finagle!  and thanks so much for digging into this.\n. @jeffreyolchovy bad news, there's a scala bug that's preventing us from upgrading now.  https://issues.scala-lang.org/browse/SI-9871\nI'm not sure what we can do until that gets resolved.  @SethTisue do you know if there's anything we can do to work around this in the mean time?. Update on this\u2013we ended up having to make a pretty painful breaking change in finagle to work around the scalac backwards incompatibility, since the scala team introduced new semantics in 2.12 that unbreaking our backwards incompatibility would have made backwards incompatible.  Subsequently, we ran into several more compiler bugs, so @jcrossley ended up tackling it, and has migrated finagle to 2.12!  Yay!!  Marking this one as closed.  Thanks for your help, @jeffreyolchovy!. LGTM\n. Removing \"ship it\" label temporarily until you have more confidence in it.\n. LGTM\n. Merged here: https://github.com/twitter/finagle/commit/6b277536a49fb6c4a40032c7e03635c45bc0479b thanks!\n. Landed in develop!  https://github.com/twitter/finagle/commit/1b67f5562aac076de32b544229ce30e42a477285\n. @mateor we want develop to be the default branch because it has the latest code, so I'm not sure we want to switch the default to be master.  Do you think we could improve the documentation to make this more clear?  In general, our assumption is that people who want to build the project want to do it because they are contributing, so they want the latest version.\n. OK, let's mark the remediation item here as \"Add a Build section to the README\" and it should encourage people to build off of master.  I'm going to mark this as a starter ticket for now.  Thanks for filing a ticket!\n. @mateor that's fair.  we would like to have a tool which makes it easier to set up the various dependent repositories, maybe a dbuild setup, but we haven't had the bandwidth to set it up.  maybe if we actually get that set up, we'll be able to switch the default to master.  the other alternative we've been looking at is publishing SNAPSHOT builds to maven central so that the develop branch builds, but we also haven't had the opportunity to do that yet.\n. @adriancole for what it's worth, scrooge-generator-tests are only tests, and nothing else has a dependency on finagle, but we're aware it's a pain point.  I think this would be better if we had a tool which handled this for you.\n. It looks like we made a command for this particular purpose: ./sbt +scrooge-publish-local/publishLocal should work, I think.\n. Looks like we treat it specially because it can only be published against 2.10 (since it's a plugin).\n./sbt ++2.10.6 scrooge-generator/publishLocal scrooge-sbt-plugin/publishLocal\n. Welcome!  Do you mind if I ask how you use finagle?\n. Great, I'm so glad the model is useful for you!\n. This was merged to develop here: https://github.com/twitter/finagle/commit/330acc5245c7e627066d60b75aba1f536093df4f thanks so much!\n. This looks good to me.  @sveinnfannar could you add a note to CHANGES?\n@sveinnfannar what do you think about splitting this up into a few PRs? when we merge it internally, it's all going to be squashed, and I think it would be nice to have separate commits for each piece.  ie, the first PR would be HEAD => First Milestone, second commit would be HEAD => First Milestone => Second Milestone, etc, and for the first patch I would grab HEAD => First Milestone, second patch I would grab First Milestone => Second Milestone, etc.\nI would say this first milestone is pretty close to being ready to ship.\nI would also suggest breaking out the Scribe stuff to a separate module at some point in time if possible, but it's much less necessary than the work you've outlined so far.\n. Hmm, I thought the service-loading bit was in finagle-zipkin, but if it's somewhere else then I see what you mean.  Should actually be fine this way, imo.\n. LGTM except for @kevinoliver's fixes\n. This seems reasonable to me.  I can't think of any reason why it shouldn't work this way.\n. For now, target new features for StackClient and don't worry about it.  We're planning on getting rid of Codecs, so the new API will be to pass a StackClient into ClientBuilder#stack, where it should work properly.\nGood catch with dtabs.  That should only be a problem with http, right?\n. Looks like the work here has moved to openzipkin/zipkin-finagle#1 so I'm going to close this PR.  Pretty excited about this change folks!\n. @kristofa this was published to develop https://github.com/twitter/finagle/commit/5c8862984b9f01e6863459d8bba4f548981b2629, and we're working on a release now.  thanks for the contribution!\n. OK, so it sounds like that's it?  We should add some extra state to ConnectionManager to keep track of whether we've ever seen an isKeepAlive that's false?\n. whoops lol.  can we add a test for this?  also, do you mind prefixing your commit title with finagle-http2:?\n. LGTM, thanks @olix0r!\n. Hey @olix0r thanks for the contribution!  Your commit hit develop here: https://github.com/twitter/finagle/commit/6b64687dd92c1830127c81e660ac06375863524f\n. This is a cool proof of concept, thanks for showing it off!\nAs @olix0r mentioned, finagle has an interface, Tracer which is supposed to be a generic API for tracing.  My understanding is that it's similar in intent to opentracing-api, where they're intended to provide a facade where a user can swap out the implementation.  With that said, when we were designing it, it was with zipkin / dapper-style tracing in mind, and we didn't have as many different use cases as opentracing has thought about, so my guess is that OpenTracing is more flexible.\nSo we're presented with a couple reasonable ways forward:\n1.  Rewrite all tracing in finagle to be against opentracing-api, not against Tracer.  We provide an opentracing-api \"implementation\" which shells out to the Tracer facade in the mean time.\n2.  Provide a Tracer \u201cimplementation\u201d which shells out to the opentracing-api, that users can inject to take advantage of opentracing-api.\nOne thing to note is that all of these are preliminary steps, and choosing one of these steps doesn\u2019t mean that we\u2019ll never change our mind and do the other, or that one isn\u2019t a first step in order to achieve the other.\nWe have a few key goals here that we have achieved with our existing tracer implementation and we want to preserve in the new world, and a few design restrictions we have for our (and our users\u2019) sanity.\n1.  Tracing should work in your service automatically.  You might need to provide an implementation (we do this via service-loading today) and a remote location so we know where to send the spans, but it should ~just work~.  Users adding tracing individually to their service will not work for us.\n2.  Clients should be able to recursively propagate flags which can be interpreted uniformly across a company, and these should be usable to decide what is done with a span.  My understanding is that this should be easy to do with opentracing-api because you can send arbitrary metadata.\n3.  If a service receives a request, and because of that, sends a request, those dependent requests should be linked to the original request.  This property should be maintained even in an asynchronous context, as long as you\u2019re using twitter\u2019s typical asynchronous primitives.\n4.  We need to provide our users with a lightweight migration strategy.  Either this means we don\u2019t change the protocol over the wire, or we ensure that we\u2019re backwards compatible on the client-side and server-side.  After we\u2019re moved over, we can get rid of the old protocol, but it would be a slow process.\n5.  Zipkin still needs to work with whatever solution we come up with.\nWithin these constraints, we have a decent amount of leeway, and we don\u2019t have a strong preference one way or another.  We understand that you\u2019re time limited, so even just moving us directionally the right way would be appreciated.\nAnyway, we\u2019re really pumped about this contribution, and look forward to working together to come up with a good solution here!\n. Thanks for submitting the PR!  We should make a decision about where we want to stick this behavior, and what we want finagle-http to enforce on behalf of its users.\nI think that you're right that finagle should make it easy to follow the spec.  With that said, we need to make sure it's at least bugwards migration compatible.  For example, if your service is depending upon being able to do something that doesn't follow the spec, it would be nice to provide a clear migration to spec-compatibility for them.  This might be as simple as making validation optional.  Netty does this all the time, see validateHeaders\nI think in the long-run we probably want to disallow constructing requests that are illegal, or configuring requests in an illegal way.  This will improve the user experience, since you'll fail when you do the illegal thing, rather than when you send the bad object into the client.  In the mean time, would it make sense to make request / response validation into a new filter?  This way, if folks decide that they really can't live with this behavior, they can simply remove the filter themselves.  It also separates concerns neatly, where the HttpServerDispatcher stays (mostly) just state machine stuff.\n. @monkey-mas \ud83d\udc4d  that makes a lot of sense to me.\n. LGTM at a high level.  Can you also add a note to finagle/CHANGES?  I think this is worth calling out for our users.\n. @monkey-mas sorry for the delay, haven't had a chance to take a look this week.  but I haven't forgotten about you!\n. @monkey-mas good catch with that comment.  maybe the first step is to fix netty's content compressor?  then we can make the rest of these changes more safely.\n. @bryce-anderson that seems reasonable to me, provided we advertise the change in CHANGES\n. @monkey-mas sorry, we dropped the ball on this!  I'm going to see if I can get this over the goalpost and merge it in.  Will keep you posted!. this is failing in really strange ways.  I think the messiness of finagle's HTTP compliance stuff is catching up to us.  I'm going to keep on trying to make it work, but might have to give up if it takes too much time.  If you have some time to look at this again, I'd be happy to send you what I've done so far.. @monkey-mas I ended up undoing most of my changes since they didn't seem to be helping.  I'm not sure where the issue is, but I've merged against master and made a PR: https://github.com/monkey-mas/finagle/pull/1. Good sleuthing!  I would love to know why content length is being set to 0, but I'm OK with pulling this in before we know.  @bryce-anderson what do you think?. LGTM, what's the main improvement here?\n. If you could update this one that would be rad\n. @olix0r I'm on guru duty this week, so I'm going to take a stab at doing the upgrade.  will keep you posted.\n. @olix0r this was merged internally, but we just missed the boat on the github sync.  might do another one later this week.  thanks!\n. This made it to develop here: https://github.com/twitter/finagle/commit/f320909985c5756eb48d612d99abaed939765066  thanks for the contribution!\n. @spockz I'm going to close this, since netty 4 is quickly becoming the default.  I don't think we're going to get a ton of value out of porting this back to netty 3 anymore.  If you want to revisit it, feel free to reopen!. @maheshkelkar fixed this in https://github.com/twitter/finagle/pull/527, thanks a ton!!!\n. @olix0r I don't think we want to do this.  The problem is that the netty state machine doesn't require that writes happen after the entire connection setup has started, so it's not a safe assumption to make.  Given that, it simplifies matters not to encode that assumption into finagle, since it's valid for netty handlers not to assume this, and we want to be able to use netty handlers.\n. Yeah, we buffer outbound messages until the state is active.  See BufferingChannelOutboundHandler.\n. @olix0r yeah, it's a tradeoff between clarifying where failures happen in finagle and following typical netty paradigms.  maybe we could write a generic test suite for netty handlers that we can use to demonstrate we're resilient against this kind of failure, and then add this patch back on?  idk, this is the tradeoff we've chosen right now, but it's not necessarily the right one (or immutable).\n. @cryptoque \ud83d\udc4d . Hey @maheshkelkar thanks for the contribution!  This made it to develop here: https://github.com/twitter/finagle/commit/f0d0b642c2b43f7e11cb014ab2f137ddfe459d70 \u2728\ud83d\udc9e\n. LGTM except for a comment\n. Thanks for the PR!  This made it in here: https://github.com/twitter/finagle/commit/cd04959b5005b01b9842c3f4d39fc1cef92ff32b\n. @spockz I think this is expected behavior.  When the loadbalancer marks all nodes as unhealthy, it just tries one.  The reason why you see \"failed fast\" is because \"failed fast\" happens when we can't even establish a tcp connection to the remote host, and the load balancer has picked that node as the one to send load to.  When something has triggered failure accrual, we still have the tcp connection, it's just that it has not had a good track-record success rate wise.  In general, our clients maximize success rate, which is why they're optimistic.\nWe're investigating cluster-wide overload prevention, so that if the overall cluster doesn't look too healthy it can shed load, but it doesn't exist yet.\n. @spockz we typically set alerts on low success rate using the metrics we export.  would that work for your use case?\n. @spockz I'm going to mark this as closed, since I think we answered your question?  please ping us on gitter if you still have questions.\n. @olix0r we already have logic to do this in ConnectionManager and HttpTransport.  If that doesn't work, can we fix it there instead of adding it here?\n. @olix0r oh, hmm.  I guess because connection pools close client dispatchers with bad statuses?  yeah, I guess server dispatchers should do this too.\n. ahhhh, I had forgotten that we couldn't rely on connection pools to close.  LGTM\n@nepthar please take another look \ud83d\ude3a\n. @lucascs great to hear you're using finagle!  do you mind if I ask what you're using it for?\n. @lucascs very cool.  would love to see an open source version of the kafka codec if you end up doing it!  this was merged to develop here: https://github.com/twitter/finagle/commit/ca5827c1760c3cf7b2efd02a29fb318567958e40\n. @clumsy do you mind making a small reproduction case?  Would love to reproduce it locally so it's simpler for us to investigate.\n. @clumsy hmm, looks like it should be pretty simple.  I think just adding a string to a set here.\nDo you mind taking a stab at it?  None of us can test it, since we don't have windows machines.  It's a pretty minimal use of scala.\n. We can probably help you with compiling it.  finagle comes with everything you need, so it should be pretty straightforward.  We need you to try compiling it so we can make sure it's fixed on your platform!\n. that's something we do to make it easier to make changes across repositories.  if you can emulate bash on windows, we recently made a shell script that makes it easier to build multiple projects using sbt: https://github.com/twitter/dodo.  another thing you can try is building off of the master branch, or changing the code temporarily to depend on stable versions, instead of snapshot versions.\n. @clumsy added this back here: https://github.com/twitter/finagle/commit/e649e9ebea74da741deda2ff9b41361ed19e2e46 thanks!. Looks good to me.  Have you had the chance to test it yet?\n. @clumsy any update on this? we unfortunately can't test it ourselves since we don't have a ton of windows boxes.\n. LGTM\n. @adriancole sounds like a good idea to me!  do you mind moving this issue to the twitter/util project though?  GlobalFlag is part of util-app, not finagle.\n. Why are you changing the garbage collector?\n. Not being able to allocate because old gen is too fragmented makes me think it would trigger a full GC before OOM-ing.  Does it really OOM first?\n. @rklancer oh, interesting.  so what you're wondering is if we could write bytes into the Reader as they're received, rather than buffer them?  I think the long and short of it is that we use netty as our underlying http implementation, and netty takes http messages with a content-length header and fully buffers them, so it's simply not possible while using the common netty types.  Part of the reason why we use netty's implementation is because it's battle-hardened, so we're pretty confident in it.  We could consider reimplementing http in finagle, but it's an enormous undertaking, and seems to have limited benefits.\nHttpChunkAggregator is a no-op in the non-streaming case because it only acts on chunked http.\nIn general, I think content-length is intended to be used for fully-buffered http requests, and chunked transfer encoding is intended to be used for streaming, and that's how finagle uses them.  So I'm not sure there's a ton we can do on our end.\n. Oh, I see!  That's a good idea.  Yeah, as long as netty4 supports it, and you're down to implement it in both of them, I think we'd be OK with adding it.\n. Works for me.  I'll mark it as a community / starter ticket in the mean time in case someone wants to pick it up.\n. works for me!  :shipit: \n. I think this is more of a question than an issue, so I'm going to close this ticket, since it seems to have been answered?  If I'm mistaken, please reopen!. Sure, that seems reasonable to me.. @mkhq have you had a chance to take another look at this?. @reikje do you mind telling us about your use case?  why are you doing so many DNS resolutions?\n. @reikje it sounds like the event stream represents a service discovery endpoint.  you shouldn't have to create a new finagle client on each request\u2013finagle clients are designed to work well with service discovery endpoints.  Have you considered making a Resolver that your finagle client can use?\n. @thirstycrow sorry for the delay, this looks good to me!  I'll see if I can merge it in.. @thirstycrow it's gonna be a bit longer, we need to get legal to sign off on copying the code from Apache Thrift in.. @thirstycrow sorry for the delay, our lawyers finally got back to us.  this was merged in! https://github.com/twitter/finagle/commit/b9cb4883ce35e4f5a88c37d0fc4eeb507ddda0a0. @asheshambasta which version of scala are you running?  Please make sure you're on 2.11, we no longer support 2.10 as of 6.36.0.\n. @asheshambasta if you would like to make a PR, we would appreciate it!\n. LGTM except for one  nit.  Thanks!\n. @jpgneves sorry for the delay, LGTM!  I'm going to see if I can pull this in.. @jpgneves I'm renaming PATTERN to MATCH per https://github.com/twitter/finagle/pull/587/files. @jpgneves this merged in here: https://github.com/twitter/finagle/commit/1b373df466407605c0c145def10a1ddc2738d002 thanks for the contribution!. Relatedly, http/1.0 requests have a hard time too.\n. LGTM\n. @doronl the maven-finagle-thrift-plugin is really old, and unfortunately, also really dead.  It never supported windows, and even when we supported it, we just told people to use a VM if you really had to build on windows.  If you're really dedicated to windows, you might have better luck switching to scrooge, which is not deprecated, and has a maven plugin, and there will at least be a small chance that it will work for you.\nIt might be better to ask the pinterest/secor folks for advice here?  Closing for now, please reopen if you have more questions.\n. @adriancole what's the expected migration strategy?  use a zipkin which writes all 128 bits, but only uses 64, then when everyone is switched over, cut over?\n. @adriancole fixed this back in #553, thanks!. OK, I think we should keep it simple and just use substring for now.  If we find subsequently that this is a problem, we can fix it later.\n. LGTM\n. @spockz we're still working on merging it internally.  We're hoping to get it in tomorrow.  Thanks for checking in!\n. made it to develop here: https://github.com/twitter/finagle/commit/2b65e4187aacc0f7a08f04692854a8d3b1e50c31.  thanks for the PR!\n. @mayflaver finagle-http supports streaming requests and responses, and finagle-http2 will soon support streamed http/2.  We are considering adding streaming support to mux as well.  Hope that answers your question, please reopen if you have more questions!\n. @vigneshwaranr would you like to take a stab at this?  It might look something like having an option on the Http client that lets you set the host header for requests if it hasn't been set yet.. @justinpermar try making a Stack module beneath the load balancer.  The load balancer injects the address of the remote peer into Stack.Params, so you should be able to use that.\nAlso, can you elaborate on why you need this ability?  Host headers typically refer to the virtual host, and since we typically load balance over remote peers in a cluster that are all the same, they typically share a virtual host.. @justinpermar my question is why you need a different host header per endpoint.  Is there a single virtual host which represents everything in your remote cluster?  For example, if I talk to google.com, I always set my host header as google.com, even though I might choose a specific IP address to talk to.\nI'm wondering if maybe you could set the host header yourself, instead of relying on finagle doing it on your behalf after load balancing.. @justinpermar yeah, the tricky thing is that curl and other HTTP tools can infer the host header because they assume you pass a URL.  Finagle doesn't assume that, and indeed many users just resolve IP addresses from zookeeper (or similar).  We could potentially add an HTTP-specific configuration method as a helper, something like Http.client.withHostHeader(\"twitter.com\") but then the downside would be that if you dump the request before you pass it to the client, it doesn't actually reflect what it will look like when it's sent.\nThe RequestBuilder API is intended to address this problem, but it's pretty limited in what it checks, since HTTP is such a complicated protocol.. @dreverri no, that will work fine.  This issue is specifically for when you want a different host header for different remote peers in the same loadbalancer.. Sounds good to me!. @jimschubert would you be interested in taking a stab at it?. @jimschubert sounds good to me!. LGTM.  @vkostyukov what do you think?  it's not great that this exposes a netty3 API, but I'm also not sure if it's worth it to build a background thread into finagle to call this for netty3 on behalf of the user.  part of it depends on how much longer we expect we'll have to support netty3.\n. @spockz I think your test is incorrect.  note that service(Request()) has already finished because it's synchronous.  I think it behaves correctly.\n. @jamesyang124 I think you opened this PR by mistake, so I'm going to close it.  Glad to see you're curious about finagle though!. @allquantor you should be able to fix your problem by following @taylorleese's instructions, so I'm going to close this for now.. @iwag hmm, interesting.  it looks like we misinterpret a mysql response, so our protocol implementation isn't quite right.  what do you think about taking a stab at this?. @iwag I'd suggest looking at where we get the UnderflowException in the stack trace, then trace back through the stack trace to figure out where we make a bad assumption about what the mysql protocol will return to us.  It looks like the mysql ClientDispatcher might be a good place to look?  Thanks!  Please let me know if you have any more questions about it.. @spockz we already only deserialize only once in thrift.  this is enforced by DeserializeCtx.  it might make sense to try to raise DeserializeCtx to finagle-core if it will be useful for http too.\n0: https://github.com/twitter/finagle/blob/develop/finagle-thrift/src/main/scala/com/twitter/finagle/thrift/DeserializeCtx.scala#L29-L41. @spockz I was going through old issues and saw this one was still open.  how do you think we should proceed?. @spockz you should be able to use normal call-back mechanisms.  For example, you could have the call-back satisfy a future.  I'm going to close this ticket for now since it seems like you have a solution\u2013if you decide you think it's worth contributing back, please make a PR!  Feel free to reopen if there's more to discuss.. I googled that error, and it looks like you run into that when you try to run a git command but you're not in a git repository. I don't think ./sbt has any git commands (as far as I know), and besides, finagle is a git repository if you downloaded it from GitHub. I think you might have something weird going on on your end.\nas an aside, I don't know what server you expect to run with run-main, since finagle is a library. \nwhat are you trying to do?. @scf37 it's not retried.  The distinction is that if a request is failed for a reason that makes it eligible for automatic retrying (like it gets nacked) then it gets a fresh request timeout.\nWould you like to make a PR to help clarify this?. Looks good, but remove the bit about response classification.  Finagle doesn't use response classification to decide whether to retry stuff, so you will still have to retry it manually (response classification is only for circuit breaking and stats).. Well, a RetryFilter, not a TimeoutFilter, but yes.  We're working on tooling to improve this, so it's in the pipeline.. Yes, we put RetryFilters over everything.  Although you say, \"over the loadbalancer\" we typically don't encourage users at Twitter to inject filters directly into the stack, so it would also be over naming.\nNo, RetryPolicies can be fine-grained, so we make our RetryPolicies handle different kind of exceptions appropriately.  We are planning on using FailureFlags for exceptions finagle exports, but that's only to simplify parsing exceptions from finagle\u2013you can make whatever kinds of exceptions you want, since you know what kind of complexity you want to handle.. @scf37 so . . . ready to make a PR? =). Instead of changing RetryFilter to RetryExceptionsFilter, can you instead change the type parameter of RetryPolicy?. @spockz have you had a chance to take another look at this?. @nodrunkdriving we have a few projects that we update in sync, so we depend on snapshot versions of them so that they still build even when we break an API.  Scrooge is one of them.  We have an explanation of how to fix it here.  The short version is that you need to publish scrooge-sbt-plugin locally to get finagle-thrift to build.  If you don't want to go through this rigamarole, you can try changing the version that it depends on to stable scrooge version and see if it still builds.\nI'm going to close this issue for now, but please reopen if you still have problems.\n0: https://github.com/twitter/finagle/blob/develop/CONTRIBUTING.md#building-dependencies. Thanks @mkhq!. Thanks for the PR!  From googling around, it looks like there might have been a change in behavior at some point in time: https://redis.io/topics/sentinel-old.  Do you know if there's a way that we can support both the old behavior and the new behavior?  Sorry, I'm not familiar with the way this API has changed, so you'll have to bear with me.. @thirstycrow you might be interested in this PR.. OK, so if I understand this correctly, the server sends the client a list of properties, which used to include  \"pending-commands\" but now includes \"link-pending-commands\".  Is that right?  Maybe we should use the name \"link-pending-commands\" but check for properties by both names, and use whichever we find first (starting with link-pending-commands).  what do you think?  that might look like:\nval linkedPendingCommands = props.get(\"link-pending-commands\").getOrElse(props.get(\"pending-commands\")).toInt. This looks good, I think we can merge this soon.  I wonder what other clients do.  Do you know?. @rogern NoClassDefFound often indicates that there's a classpath mismatch.  Can you check that you only have one version of util-core on your classpath, and that it's the one that finagle-http 6.42.0 depends on?. Thanks for the bug report!  My guess would be that we should wrap service(request) in a try/catch block in StatsFilter.  @reikje do you want to take a stab at this?. LGTM, do you mind editing your commit message to include the Problem / Solution you have in your description?. Hi @bachateraconfuego, we don't support that, but people have added support for postgres, so it might be worth looking into doing something similar for h2.  finagle-mysql isn't built on top of jdbc, but you can make a jdbc client participate neatly in the finagle ecosystem by wrapping calls to the client with a FuturePool.\n0: https://github.com/finagle/finagle-postgres. @koshelev do you mind changing the commit message to the\n```\nfinagle-core: Delay service instantiation till TLS handshake finished\nProblem\n....\nSolution\n....\nResult\n....\n```\nstyle?. looks great, thanks for the PR!. LGTM from my perspective, but @ryanoneill is the ultimate authority here. @herberteuler I'm not sure that this simplifies things.  Reader is an API for byte streaming.  If you don't need to stream bytes (ie you provide a buf via request.content = content), then it's not chunked, if you do need to stream bytes, it's chunked.\nWhy does your finch server care whether it's chunked or not?  If you read the contents of the POST with Reader.readAll(msg.reader) then you won't get 404s anymore.  You could alternatively disable streaming on your server, and finagle would dechunk the message on your behalf.. @herberteuler glad we could help!. Welcome!  Do you mind sharing how you use finagle?. @DanielCharczynski thanks for the bug report.  Would you be interested in taking a stab at fixing this?  I'd be happy to work with you on it =). @DanielCharczynski hmm, good sleuthing.  As a side note, we're switching finagle over to netty4, does this problem still pop up when you're using the netty4 version of finagle?. For now let's leniently read, we can switch to writing 1|0 in a couple releases.  We need to give folks time to upgrade so that we don't break tracing for finagle services that aren't redeployed frequently.. This was fixed here: https://github.com/twitter/finagle/commit/a6de338c0ffb0e7b6924f326cd0feac0bc9dad0a thanks!. @mehmetgunturkun I like that, :shipit: . @mehmetgunturkun no need for a full review, but do you mind posting your work in a gist?  I'm a bit curious.. @mehmetgunturkun ah, I see what you mean.  LGTM then.. @mehmetgunturkun this was merged in util https://github.com/twitter/util/commit/94ab01fc7a568f5bdcb14f032ccb17ed313eb187, so you should be able to take advantage of it now.  thanks for your patience!. @mehmetgunturkun you don't have to wait for the new release.  the instructions in CONTRIBUTING are for using the tip of util develop branch.. LGTM, thanks for the PR!. @adriancole this was merged in here: https://github.com/twitter/util/commit/93a88444c597841e0a514538b2381b14ddbcf687 thanks for the PR!. Whoops, yeah!  My bad, sorry.. This smells like a bug.  We had a big change after 6.42.0 https://github.com/twitter/finagle/commit/7594d414299fabc93565c0dab6d3cc74832b84c4 although we haven't run into any problems with it locally, it probably broke something with the way that you use it.  Can you try running with the JVM option -Djavax.net.debug=all so you can dump which part of the handshake is having a hard time?  Also, if you can make a reproduction case, that would be really useful!\nIn the mean time, maybe we can find a work-around for you?  Does it work better if you use one of these two APIs instead: https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/param/ServerTransportParams.scala#L21-L33 ?. @ghershfield do you have to configure your tls with its own sslEngine?  What about only passing an SslConfiguration instead?\n@ryanoneill it looks like several people have been tripped up by this . . . we should probably make the exception message more clear here.. @ghershfield now it looks like an SSL failure.  I googled it, and it looks like it means that the server doesn't have the right information for the given client?\nhttps://stackoverflow.com/questions/15076820/java-sslhandshakeexception-no-cipher-suites-in-common. @ghershfield I think we're just shelling out to the java implementation here, so there's not a ton we can do.  If you read the stack overflow link I sent you, it's not necessarily a cipher suites issue\u2013the exception is sort of crummy.  Can you try debugging it like a normal SSL issue and turn on java's verbose SSL logs?. @ghershfield that's still the right way to do it.  How did you fix your earlier problem with the \"cipher suites\" error message?  Can you check that you haven't switched to a different thread (in a non-finagle-y way) before calling Transport.peerCertificate?  If you do it in the service you pass to the finagle server it should work.. @wei-hai I don't think this is in scope for the finagle project itself, but finagle is intentionally extensible so that you can add this yourself.  The linkerd project, which is built on top of finagle, has done this here.  I would encourage you to make your own finagle-influxdb project, like [finagle-metrics][1] and that way other people can benefit from your work!  The linkerd stuff looks like a good start, although you would probably want to supply your own StatsReceiver.  I'm going to close this ticket for now, but please let us know if you have any further questions.\n[1]: https://github.com/rlazoti/finagle-metrics. @omerzach oh, interesting, what kind of grpc?  I don't think anyone has finagle speaking the grpc protocol yet except for linkerd right now.  Are you planning on using our h2 clients and interpreting the protobuf/thrift directly?  Would you be interesting in helping to contribute some grpc-compat stuff if you run into any issues?. @yzb808 did this cause you an issue in finagle?. @iyogi thanks for the report! have you actually detected any memory leaks?. @iyogi maybe I don't understand what's happening.  You can't rely on the JVM shutting down to shutdown all of the threads?. @iyogi it doesn't sound to me like this is a memory leak, but for what it's worth, we don't expect you to use finagle as a servlet.  You might be better served by using finagle as a server.  I'm going to close this ticket for now, but we can revisit if you continue to have problems.. wow, this is seriously cool!  thanks so much for tackling this.. @matsu-chara this was merged internally, but because of an internal breaking API change, it's not safe to publish right now, so I'm going to leave this ticket open.  Thanks for your contribution!. @matsu-chara this finally made it to github, thanks!  https://github.com/twitter/finagle/commit/0fd63b01b646a0a04147dedc4e7568ff1e0c9fb4. @chenhj NoClassDefFound means that there's a class that your code needs, but it can't find it.  This typically happens when your project transitively depends on more than one version of a library.  For example, imagine that you're building project A, which depends on lib X, and project B, which also depends on lib X.  However, project B was built against an older version of lib X, which used to have a class, but which it no longer exports.\nA => B => X (version 1)\nA => X (version 2)\nThen when it runs, A makes a call into B, which tries to make a call into X, but because the project now uses the newer version instead of the older version, it can't find the class it needs.\nI would encourage you to use sbt-dependency-graph to see which versions of finagle you're depending on transitively, and ensure that every library you use uses the same version of finagle-http.\nThis isn't a finagle-specific problem, and you may find it with other libraries like guava or scalactic in the future.  I'm going to close this ticket, but please feel free to reach out if you have other concerns.. We should increase the priority of this. . . I don't know why our travisci tests are passing, it seems to fail locally.. @anatolydwnld we've published a new version of finagle.  Can you try finagle 7.1.0?. @mkhq yeah, a new branch/PR would be great, if you can.  Sorry for the delay!. @justinhj yep, there's a note in the README that explains you should peek in the CONTRIBUTING.md doc, or you can build from stable versions by switching to the 'master' branch.. @crispywalrus ah, I see now.  We'll get right on that, thanks!. @spockz can you use SslClientConfiguration instead of supplying your own SslContext?. @spockz I don't think SslContext exposes an API for ALPN, so you might have to configure it yourself.  What certificate format do you use?\nFor what it's worth, I think the long-term plan is to try to move off of SslContext, but as you've mentioned, we don't have feature parity yet.  Maybe the right thing is to rebrand it as, \"raw tls\" instead of a first class finagle supported way of doing it.\ncc @ryanoneill. @spockz maybe instead of KeyStore and TrustStore directly, we could take Certificates?  @ryanoneill wdyt?. Sorry for dropping the ball on this @spockz.  I think exposing an API where we take Certificates directly is worth looking into, I'll talk to @ryanoneill and see what he thinks.. Thanks @lvc!  I'm going to close this ticket for now, but it's very interesting, and thanks for sharing it.. @doismellburning thanks, I'm pulling this internally, I'll close this ticket once it has been pushed back to open source =). @doismellburning this merged, thanks! https://github.com/twitter/finagle/commit/ade45cf58451f6e372665ac27476d50c5c5d34c9. @drcimux this seems to be related to play, not to finagle.  please file a ticket there instead.. Unfortunately, we need to keep scalatest parity with the version of scalatest that twitter uses, so I don't think we can accept this PR.  Scala 2.12.x and sbt are OK because we don't run either of those internally (scala 2.12.x is a work in progress).  However, thanks for the reviews!  Keep 'em coming.. @DanielCharczynski how do you configure your client, and which version of finagle are you using?  We have some behavior in finagle to re-resolve periodically, so I think it should handle the use case you're describing.  https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/InetResolver.scala#L133-L154. @DanielCharczynski it looks like we first added this functionality in 6.20.0, but we've changed our implementation quite a bit, so you might be running into an old bug.\nUnfortunately, we're not going to publish any future releases to be JDK7 compatible, so we can't fix your problem.  Are you planning on switching to JDK8 soon?  If not, your best bet might be to fork a current branch of finagle, remove the JDK8-only APIs and publish it yourself for JDK7.\nI'm going to close this ticket for now, but please let us know if you can reproduce this issue in a current finagle version.\n0: https://github.com/twitter/finagle/commit/1c06105a446994f314773de3713c8d98ebcab482#diff-db7b87f0a4106332436d9699a49b9486. We talked about this in #678, but for anyone who's following along at home, this is a work in progress, and is much more work than we thought it would be.. @sullis is there an sbt 1.0.4 feature you'd like to use?  we prefer to keep our sbt versions in sync, so if there isn't anything you need, we might not want to upgrade this immediately.. @utkarshcmu awesome!  do you mind sharing how you use it?. @spockz is this something you're still interested in?  It sounds like you want to use braces similarly to how linkerd uses braces.. I think the tricky thing here is propagation.  If some services respect curlies and some don't, propagating dtabs will be a mess.\n@spockz going back to the original thing you were trying to get done, .newService(\"/endpoint/host/method/pathTemplate\") looks like a fine format, and doesn't seem to have curlies.  What's the issue you ran into with this? It seems to me like you should be able to use it with the existing ourResolver.. @spockz how about using scala string interpolation?  we could do something like:\ndtab\"apis.com:GET:/accounts/{id}/transactions\". @spockz cool!  can you try it out and get back to us?  I'm going to close this ticket for now, but if it doesn't work out, we can reopen it.. @cricket007 part of it was that it wasn't released when we started, but the bigger piece is that thrift 0.10.0 was stable for a long time, and we don't know what issues 0.11.0 will have.  we figured it made more sense to wait and see for a few months whether they rush to get a patched version before immediately moving to the latest and greatest.\nIf you go to maven central or the badge in the finagle README, you can see when libraries have been published most recently.  We've recently switched our versioning to be YY.month.0, so the most recently published version across both scrooge and finagle was 18.3.0, and the next one will be 18.4.0.  We don't control libthrift, so we can't synchronize that one.\nYep, you'll want to wait until 18.4.0 if you want to use libthrift 0.10.x.. @politrons my guess would be that only Grizzly validates that the request has a Host header by default.  I'm going to close this issue, since I think your question has been answered, but please feel free to open a new one or continue this thread if you have more questions.. @adriancole we're going to talk to folks internally about whether we can move off the scribe transport immediately, or if we'd have to figure out some kind of support strategy for scribe.. @adriancole would changing the name to \"finagle-zipkin-scribe\" and adding some documentation fit what you're looking for?  It seems like unnecessary work for us to add our own http tracer implementation when zipkin-finagle already has one.. OK, so to be clear on what your concern is:\n\nfinagle users today default to finagle-zipkin because it sounds like the \"right thing\".\nfinagle-zipkin uses the scribe transport, which means that you feel like you should continue supporting scribe, even though it's a burden to maintain it.\nyou want to stop supporting scribe, but you first want finagle-zipkin to no longer seem like \"the right thing\".\n\nIs that right?. @adriancole it looks like in the short term, we can rename finagle-zipkin to finagle-zipkin-scribe, and we'll update our docs to refer to zipkin-finagle.  In the long term we'll migrate off of it and delete finagle-zipkin-scribe.  When that happens, we'll either supply a new transport that's whatever twitter is using internally, or we'll stop exporting our own Tracing facade and will migrate to a common facade, like opentracing or zipkin-reporter.  Does that seem reasonable?. I think we'd be open to a community contributed finagle-zipkin-http if we had a commitment from the community to help support it, although it seems a bit redundant, given that zipkin-finagle http already exists.  Would you be willing to commit to reviewing PRs that come in for finagle-zipkin-http?  You've been helpful with reviewing other zipkin-related PRs, so I don't think this would be a big shift.\nOK, that's good feedback.  We haven't looked too seriously at any of this stuff.  I'll mention census in our internal ticket.\nWe've renamed finagle-zipkin to finagle-zipkin-scribe, so the next step is to change the docs to mention zipkin-finagle.. Works for me, thanks for following up!. @politrons Http.Http2 is actually a set of params, so you need to use Http.client.configuredParams(Http.Http2) instead.. @heartsucker this seems suspicious . . .\n[warn] ==== public: tried\n[warn]   https://repo1.maven.org/maven2/org/scalaz/scalaz-concurrent_2.12/7.2.16/scalaz-concurrent_2.12-7.2.16.jar\nWhen I follow this link, it seems to work.  Sometimes folks who are behind the GFW have issues with this?  Is it possible you're behind a firewall?\nFor what it's worth, we don't depend directly on scalaz-concurrent, so it's probably either sbt or a plugin that's pulling it in.  If this still doesn't work, the next step might be to figure out what's pulling it in.. @heartsucker thanks for the PR!  Unfortunately, we've tried updating the netty 3 version, and we ran into some issues around the way that cookie behavior changed.  We're in the process of moving finagle to a point where we'll have parity in behavior in netty 4, but it will still take a bit more time.  cc @jcrossley who knows more about this stuff.\nIn terms of updating the netty 4 version, we're nervous about changing the netty 4 version while we're gaining confidence in our http/2 implementation, since codec-http2 is still in flux.  So we've frozen the netty 4 version for the next few weeks, until we have more time to really nail it and get a decent number of services running http/2 in a production environment.\nI'm sorry the CVE-2015-2156 mitigation has taken so long, we're chugging away at it though!. @heartsucker sounds like a plan.  Thanks for bearing with us!. Hmm, interesting.  It looks like it's intentional that we don't mark the handshake as \"finished\" here, but clearly you should be able to access the peer certificate so you can validate it.  I'll ask around to try to better understand what the intent here is, I agree that this seems wrong. cc @ryanoneill \n0: https://github.com/twitter/finagle/blob/559ae4ad3eb6bae4c2f885fb3149b492c6bf46a0/finagle-netty4/src/main/scala/com/twitter/finagle/netty4/ssl/server/SslServerVerificationHandler.scala. @iPlessmann from talking to @ryanoneill it sounds like SSLPeerUnverifiedException indicates that the client might not be passing you certificates.  The way to indicate that we hard fail when that happens is to pass a clientAuth parameter of ClientAuth.Needed in SslServerConfiguration.  Can you try that out so we can check whether you're actually passing the certs?  For what it's worth, internally we do inspect the certificates during the SslSessionVerification step, so it should be possible for you to do it too.. I think this is working as intended, so I'm going to close this for now until we get more information.. @politrons where have you looked so far?  We have documentation both for scrooge and for [finagle][1].  If you've already looked at these, could you elaborate on what you're missing?\n[1]: https://twitter.github.io/finagle/guide/. @politrons which documentation is for an older version of scrooge?  the one I linked you to should be current.\nWe link to scrooge in finagle under the \"protocols\" section, here: https://twitter.github.io/finagle/guide/Protocols.html?highlight=scrooge.  Please feel free to open a pull request if you have ideas for how we could improve the documentation.\nWe don't currently have a thrift streaming implementation, in large part because the thrift protocol doesn't support streaming.  We're looking into different possible implementations though.  How are you intending to use thrift streaming?. I'm not a grpc expert, but my understanding is that grpc's thrift is actually sending thrift messages over HTTP/2, speaking a grpc-specific protocol.  We don't support that protocol today, although we might support it in the future.  Thrift in general doesn't support streaming, so I think you may have a difficult time migrating off of grpc without supporting two clients for a little while.\nIf you want to use scala, but also want to continue using the grpc thrift protocol, scala typically makes it easy to call java from scala, so I would encourage you to continue using grpc-java, and call it from scala.\nIf you wanted to use finagle's HTTP/2 implementation to speak with a grpc remote peer, there are a few possible complications.  The one that would probably be the largest impediment is that our HTTP implementation doesn't support HTTP trailers.  Trailers were considered fringe before grpc (as an example, browsers don't support HTTP trailers), and we haven't had a chance to implement them since grpc became popular.. @politrons from the javadoc:\n\nThrown if an application tries to call a specified method of a class (either static or instance), and that class no longer has a definition of that method.\nNormally, this error is caught by the compiler; this error can only occur at run time if the definition of a class has incompatibly changed.\n\nSometimes this happens if you're trying to use two libraries that are incompatible.  Make sure you're using the same version of scrooge and finagle, and that you haven't cached anything that you compiled with an older version of finagle.\n0: https://docs.oracle.com/javase/7/docs/api/java/lang/NoSuchMethodError.html. It seems like you have questions about two parts of the behavior:\n\nlatchPeriod isn't respected, it just uses a minute every time\nWhy start with an empty snapshot?\n\n1 is clearly a bug, but I think that 2 is expected behavior.  We expect that metrics collection happens periodically, and that this is a latched metric.  If we used a current histogram, then you might get a weird result if it was near the beginning of incrementing it, while it still didn't have very many samples.  Hence, we use a snapshot histogram from the previous minute.  This presents us with the question, what do we do with the first one?  In favor of consistency, we decided to use the previous minute's snapshot, which is implicitly the empty histogram.\nI think we've discussed documenting it better\u2013I thought we had, but if you couldn't find it in the documentation, it sounds like we haven't done a good enough job of it!  Do you mind making a PR to help us make this clearer?. I see, we used to have a StatsReceiver for that purpose called ImmediateMetricsStatsReceiver https://github.com/twitter/finagle/blob/4f47e6b8ae4a14b1ebb4c6cb78bb4ffbe4a7e165/finagle-stats/src/main/scala/com/twitter/finagle/stats/ImmediateMetricsStatsReceiver.scala\nWe've replaced it with an ImmediateMetricsHistogram, which you can hook up with Metrics.createDetached and MetricsStatsReceiver.  However, you do need to thread the MetricsSR through to your clients and servers, since it's no longer the default stats receiver.. Thanks for the PR, this looks great!  Let's continue the discussion on the initial ticket, sorry I've been slow in responding, I've been caught up in other stuff.. @samschlegel this is bizarre.  It looks like we're requeueing your request every time.  Your success and failure metrics reflect that everything is succeeding?  Can you try removing the RequeueFilter from the stack and see if you still have this issue?. @adleong I think this is an issue with your certs, not with finagle.  buoyant.io has let's encrypt certs, which may be too fancy for your JVM.  Check out this stackoverflow page: https://stackoverflow.com/questions/34110426/does-java-support-lets-encrypt-certificates. @jdreyesp from the error NotSslRecordException it smells like curl is sending a non-TLS HTTP message.  Can you try changing your scheme in your curl to be https://localhost:8080?\n0: https://netty.io/4.0/api/io/netty/handler/ssl/NotSslRecordException.html. @jdreyesp I'm not sure I understand why you want to suppress this warning, which seems useful to me.  You can't consume the server without TLS, so I don't know why your clients are trying so hard to do it.  Can you elaborate on your use case?. I see.  You could reduce the log level for this specific component until everything migrates over in your logging configuration (like logback, or jul), but I think the better solution might be to serve traffic for both HTTP and HTTPS, and then cut the HTTP port later.  This may simplify your migration story too, since clients won't need to figure out how to speak TLS immediately.. @jdreyesp shouldn't it be logged under com.twitter.finagle.netty4.channel.ChannelStatsHandler?  that's the name we create the logger under in ChannelStatsHandler.  https://github.com/twitter/finagle/blob/develop/finagle-netty4/src/main/scala/com/twitter/finagle/netty4/channel/ChannelStatsHandler.scala#L16. Thanks @Prahathess-Rengasamy-ck, we'll look into upgrading.  Unfortunately, we can't just upgrade finagle because internally, twitter uses a monorepo, and we'll have to upgrade all at once.  We'll keep you posted in the mean time as we investigate.. @Prahathess-Rengasamy-ck sorry for the long silence, I've been hacking on this for a while, I think it's pretty close to being ready.  I would expect it to land in the next two weeks (I'm on vacation next week).. Just landed, sorry for the delay @Prahathess-Rengasamy-ck https://github.com/twitter/finagle/commit/9b9523d0982869496dd8f4bfaba28afc855a2498. @hongikeam just wanted to ping you in case you missed Kevin's question.  also, do you mind updating the commit message to match the Problem / Solution / Result format?. Looks good to me, we'll merge it in, thanks!. looks good to me, thanks!. @jimmycasey merged here: https://github.com/twitter/finagle/commit/f5d6342f9ebcd0a9c7fa7365138b40e23a1ce3ec thanks!. Thanks for filing a ticket @adriancole, do you know if there's someone from the zipkin community who uses finagle and would be interested in tackling this?  I think it would be a good first issue.. @gpevnev we only depend on netty3 for cookie behavior, which we're swapping out for netty4 soon, so we're hoping to get rid of the dependency altogether instead of maintaining it.  Can you exclude finagle-netty3's transitive netty dependency?  I would guess it's still compatible since we use a pretty small subset of the overall API.. eek, good catch.  I think the bug is that https://github.com/twitter/finagle/blob/develop/finagle-http/src/main/scala/com/twitter/finagle/http/filter/ClientNackFilter.scala#L34 should set set instead of add.  Do you want to tackle it?  If you're busy, we can grab it.. does seem to have fixed the issue, closing for now. @acidghost this seems pretty reasonable to me.  let me see if I can pull in our local expert too.  would you be interested in making this PR if we approve it?. @acidghost alright, go for it!. To elaborate on @jcohen's problem, his topology looks like A => B => C, and sees the exception on B.  This is when A cuts the connection to B, but the exception says that the downstream was C.  It should instead report that the downstream was B.. for completeness, we should probably make count an Option.\n. I argued in the opposite direction so it's closer to the actual redis API, which takes count as an optional parameter.\nfrom SRANDMEMBER\n\"Return value\nBulk reply: without the additional count argument the command returns a Bulk Reply with the randomly selected element, or nil when key does not exist. Multi-bulk reply: when the additional count argument is passed the command returns an array of elements, or an empty array when key does not exist.\"\n. nitpick: you only need one set of parentheses here\n. has the error message changed in a more recent version of redis?  which version of redis are you testing against?  we might want to change this test to be a little more resilient against this kind of change.\n. fix indentation\n. Does this need to be special cased? It looks like the behavior is identical in these two cases.\n. For now, let's change it so that it doesn't check for an exact string match, and we can add a TODO or FIXME to fix it.  Ideally we'll also specify that you must have a more modern version of redis than X installed to test, but let's not get ahead of ourselves on this review.\n. The internet at my home just cut out, so I'm having trouble verifying why.\nCould you explain briefly? Seems like it should be fine.\nOn Feb 24, 2014 10:34 PM, \"zhanggl\" notifications@github.com wrote:\n\nIn\nfinagle-redis/src/main/scala/com/twitter/finagle/redis/protocol/Reply.scala:\n\nRequireServerProtocol.safe {\n   NumberFormat.toInt(line)\n } match {\n-      case empty if empty < 1 => emit(EmptyBulkReply())\n-      case empty if empty < 0 => emit(EmptyBulkReply())\n-      case 0 => //Here we got an empty string: '$0\\r\\n\\r\\n' -> '\"\"'\n\nI'm afraid it is. A readBytes(replySz) with replySz=0 will cause an\nException to be thrown.\n\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/245/files#r10023324\n.\n. I was able to try it locally, and it seems to work fine.  Can you try removing the 0 case again?\n. this is pretty nitpicky, but could you remove the whitespace at the end of this line?\n. To keep the api consistent, this should return an immutable Set.\n. please make sure your lines are < 100 characters long\n. This comment seems to suggest that it will throw an exception if we try to query a key where there isn't a Set, but the tests contradict that.\n. It won't throw an exception if the values included in the keys Seq are empty, I think.\n. style nit: avoid postfix operators.  ReplyFormat.toChannelBuffers(messages).toSet is more legible.\n. Ah, when you said the values of the key, I thought you meant if the Sets that the keys are pointing to are empty, not the key string.  It's a bug in finagle-redis that they throw though, is that something that we can stick in this commit to fix, or do you think it would end up being a bigger task?  I think it might be clearer to say, \"If any of the keys passed as params are empty, this will throw.\"\n. Only one space after the *\n. I think this is implicit.  If you think it's useful to point out in the scaladocs that users can find more details in the redis protocol documentation, let's just stick it in a package.scala file.\n. should be: Move(key, db)\n. Let's drop it then. :metal:\n. this indentation is still weird.\n. @p-antoine do you know the answer to evnm's question?\n. maybe better to remove the part about asking them to contact us--it's very low friction to submit a pull request.\n. rather than \"feel free to\", might as well change this to \"please\" while we're in here.\n. I think it would be more appropriate for these to be in your global gitignore, rather than the finagle one.\n. Why does this return a Seq[Byte] instead of a ChannelBuffer?\n. both of them, thanks\n. Yes--our netty 3 is showing :) However, there's not much we can do today.  Every other redis endpoint returns ChannelBuffers.  In the long run, we're going to move them all over to c.t.io.Buf, but until then, I think it's best to be consistent. :musical_score:\n. Assuming by \"those endpoints\" you mean the ones that return Seq[Byte], since changing all of the existing ones to Buf would be a breaking change and will require a lot of coordination.\n. is this true?  I thought it would run easy_install for you to install sphinx.\n. I think we can simplify this by just using a defaultTtl and the networkaddress.cache.ttl.  \n\nI think a reasonable default is Duration.Top.\n. we already have most of this behavior in InetSocketAddressUtill.  Maybe just change InetSocketAddressUtil to use getAllByName in parseHosts?\n. we can use timer.schedule(ttl) { fn } here.\n. this looks like a memory leak, and a timer task leak.  could we schedule this when the Var is observed and destroy it when the observation is closed?\n. could you add scaladocs here?\n. scaladocs?\n. idiomatically, this is just varAddr() = Addr.Bound(addrs)\n. maybe make this use log.log(Level.WARNING, \"failed to resolve hosts\", ex)\n. Oh, whoops, I thought the default in java was to cache forever.\nMy impression is that the way the cache works is that it checks whether it was last checked within networkaddress.cache.ttl, and if it was, it won't update.  DefaultTimer.twitter is a netty hashedwheeltimer with granularity of 10ms, so it's expected lag is 5ms, so my guess is that we'll have a lag of 5ms, but will otherwise get dns updates as fast as you specify in your security.\nHow about:\nscala\nTry(Option(Security.getProperty(\"networkaddress.cache.ttl\"))) match {\n  case Throw(exc: SecurityException) => \n    log.error(Level.WARNING, \"security permissions block us from checking ttl, dns caching turned off, change networkaddress.cache.ttl property permissions to enable proper finagle caching\", exc)\n    -1\n  case Return(None) => // not sure if this is possible\n  case Return(Some(value)) => value\n}\nIf I'm reading InetAddress correctly, it sounds like there will always be a value set for networkaddress.cache.ttl.\nI think it's easier to reason about by just using networkaddress.cache.ttl.  We can't get dns information faster than networkaddress.cache.ttl so it would necessarily be a slower DNS lookup--this seems potentially useful for people who want to turn off caching by setting it as 0, but not useful otherwise.\n. Basically, the problem is that after I've scheduled this, it will sit around on the timer forever, even if I no longer care about these InetSocketAddresses.  Imagine that I have a web crawler which takes hostnames and crawls them.  Every time I do a DNS lookup of a hostname to begin crawling, I add a task to the timer to be executed again and again.  It would be better if the tasks could be removed from the timer when they are no longer used.\n. I looked into what java does for this case, and it looks like it uses a PrivilegedAction to check, and doesn't try/catch on SecurityException (either it's impossible in a Privileged action or they're content to crash the process).  Maybe we should follow suit?  We could also pick a ttl, but it seems tricky to do that in a smart way when we don't know what java is going to be using.\nI'm OK with not protecting against the pathological case.  That's why Var.sampled should not be used on a hot path when getting a value from Var.  It should be fine as long as we include a comment.\n. make this parseHosts() since it's not purely functional.\n. maybe we should move this parsing stuff into InetSocketAddressUtils?  It seems like we're repeating ourselves.\n. this seems cleaner as case (host, port) =>\n. drop the trailing space\n. @jdanbrown let me know if I got it wrong, but I think that we agreed that the right way to do this was:\n``` scala\nval t = Try(Option(java.security.AccessController.doPrivileged(\n  new PrivilegedActionString {\n    def run(): String = Security.getProperty(\"networkaddress.cache.ttl\")\n)) map { s => s.toInt })\nt match {\n  case Throw(exc: NumberFormatException) => \n    // log something like: \"DNS cache refresh turned off\"\n    Duration.Top\n  case Return(None) =>\n    // log something like: \"DNS cache refresh turned off\"\n    Duration.Top\n  case Return(Some(value)) => value.seconds\n}\n``\n. this will only do something when there's a change, and there will never be a change.  how about instead usingVar.sampledto check that addrs is what you expect it to be?\n. Ahh, I see, because changes is a wrapper around observe.  Yes, that makes sense.  However, I think we should useVar.sampleanyway, because it communicates our intent more clearly.\n. We don't need to leak the implementation details here.  Something along the lines of, \"Binds to the specified hostnames, and refreshes the DNS information periodically\" would be better.\n. this also belongs inInetSocketAddressUtil`.\n. actually, it occurs to me that we should handle the -1 (never refresh) case by just not making a timer task.\n. Since this is the way that the jdk learns about its cache ttl, I don't know that it would make sense to have an upper bound on the ttl (since it can't possibly have changed before the upper bound).  A lower bound would probably be reasonable--a TTL of 0 won't work well with our current system.\n. One second is implicitly a minimum TTL with this API, because we turn 0s into Duration.Top.\n. Good catch!  Yes, that would be better.\n. Could you use the ssl-enabled version url to your website?\n. instead of calling an init method, the style we typically use is to either make a Context class that we construct and import members from, or make a wrapper method that can do the construction for us.  this means that we don't have to worry about sharing objects.\nFor example:\n``` scala\nclass Ctx {\n  val input = ...\n}\nval ctx = new Ctx()\nimport ctx._\n```\nor\n``` scala\ndef exec(fn: Input => Unit) {\n...\n}\nexec { input =>\n}\n```\n. could you change this file back to the way it was before?  I'm not sure why you changed it.\n. Do these all need to be combined into the same suite?  Maybe it would make sense to just split them up.\n. Since you broke up this test into different little parts, let's separate each class into its own file.\n. remove this\n. separate files\n. maybe remove the suite?\n. the preferred style is to wrap these up in a Context object, and import the context into the test.\na la\n``` scala\nclass Ctx {\n  val valu1 = mock[Value]\n  ...\n}\nval ctx = new Ctx\nimport ctx._\n...\n```\nThis makes it easier to reason about the tests since we know they aren't sharing any state.\n. instead of BeforeAndAfter, let's just use the context class style here, since we're not consuming any resources.\n. this is unused\n. let's not share this state between tests.  let's use the Context class style.\n. context class\n. looks like you can get table-driven property checks in scalatest too\nhttp://www.scalatest.org/user_guide/table_driven_property_checks\n. why is this line commented out?\n. this is missing an assert\n. Ahh, I see.  It ended up being a lot of whitespace changes, so thanks for changing it back :+1:\n. Right--I'm pointing out that this whitespace change is trivial and can be reverted, since nothing else has been changed in the file.\n. Ahh, I see, my mistake. :+1:\n. Haha, I literally told him the opposite.  I like having a Context class because it makes it clear that you're not sharing any mutable state.  Why do you think it would cause a test failure?\n. sort imports alphabetically please (within the same line it's OK to be unordered)\n. Please add an explicit return type annotation.  All public methods should have explicit return types.  In this case, Unit.\n. we don't use this style elsewhere in finagle, please just indent by two spaces rather than aligning.\n. in general, we use 0-arity methods without parentheses if it acts like a field.  build() doesn't act anything like a field, so let's use parens.\n. please indent two spaces in these kinds of blocks.\n. this should match the indentation level of the line that started the block.\n. log these instead of just sending them to stdout.\n. also there isn't a guarantee that it will be printed before the future returns, since it might buffer.\n. Please make all of these line lengths < 100 characters.\n. Why only plaintext?  What kinds of restrictions are there?\n. add a link to EmailMessage.scala.\n. add a link.\n. fix indentation to just two spaces, instead of aligned.  should look like:\nscala\nval email = EmailBuilder()\n  .sender....\n. Why does it return Future.Done on an error?  Wouldn't you expect it to return a failed Future?\n. Is this RFC the best resource to learn about smtp?  Might be useful to include general resources to help n00bs get started.\n. \"every next try\" => \"every subsequent try\".\n. It's a little messy to use the inline linking, might be easier to read the raw file if you use the 0 linking instead.\n. I think this should be log.error.  ditto a few lines up.\n. My impression of these styles of logging is that you need to format the string to be ready to get arguments, \u00e0 la \"Error processing request: %s\", info.\n. \"but does not send greeting to it\" => \"but does not return a greeting\"\n\"without that\" => \"without it\".\nBy incorrect, do you mean malformed?\n. What kind of closing?  If I send a kill -9, presumably it won't send a quit command.\n. The way this works has changed slightly--right now, StackClient is the new way of doing this.  I know you're near the end of your summer, so you might not have time to change this, but might be worth looking and seeing if switching over is simple.\n. we don't need to know it's implemented with a DefaultClient, it's an implementation detail.\n. sort imports\n. this comment probably goes without saying.\n. is it OK to send many of these?  it seems like it would be easy for many threads to try to close this service many times.\n. return type\n. return type\n. return type\n. add a space before the {, this line is > 100 characters.\n. I'm not sure this is the right layer to have this at.  Maybe it would make more sense in your dispatcher?  Then you wouldn't entail a new allocation every time you requested a new connection.\n. instead of flatMap  { ... Future.value(x) } just do map { ... x }\n. We don't need to describe what it doesn't do, describing what it does is sufficient.  However, for my edification, could you explain how you chose to just return a Future.Done?  Is the reply in the smtp spec anemic?\n. return type annotation\n. map instead of flatMap\n. not sure this is in the right location.  I don't know SMTP that well, is there any reason why we wouldn't want to start a connection with this?  maybe it should just be in the dispatcher?\n. indentation, switch over to two spaces.  Also, put the from: Seq[String] on the next line.\n. please switch from snake_case to camelCase.\n. put the end paren on the next line.\n. */ should be on the next line.\n\"Constructs\" might be more clear than \"composes\".\n. Let's collapse EmailBuilder and Payload.  I don't see a clear benefit here to separating our data and our behavior.\n. looks like we don't do any validation on email addresses.  this is probably worth documenting somewhere, or else adding a TODO.\n. camelCase instead of snake_case.\n. add parens\n. we don't assume anything is null by default, why do we assume date might be null?  if it's OK to not set it, let's make it an Option.\n. return type annotation\n. return type annotation\n. in idiomatic scala, we usually use Options for optional arguments.\n. two spaces indentation\n. fix indentation\n. add return type\n. line length\n. return type annotation\n. fix indentation\n. add return type annotation.  is there any reason to not just make this a val?  presumably both of these calls are cheap/free.\n. this would also make sense as a val.\n. syntactically correct according to what?\n. elaborate on the issue in your assertion.\n. mention the kinds of exceptions that you will throw if it's not syntactically correct.\n. I think String has a nonEmpty method on RichString.\n. This might also be more idiomatic if you destructured it like this:\nscala\nval arr: Array[String] // we've already checked it's of length 2\nval Array(first, second) = arr\n. either filterNot or nonEmpty.  also you can combine your filter and map in a collect.\n. add return type annotation.\n. should we make this final?  or can you imagine a case in which you might want to override it?\n. since this is one expression, we can remove the {} if you want, but it's just a stylistic thing.\n. is proper capitalization part of the spec?\n. rm {}\n. Time.now is more idiomatic in finagle-y code.  Is that hard to use here for some reason?\n. should be def toString(): String = cmd.  since cmd and toString are the same, maybe you should just make rename the argument to Request toString?  or do you think that would be confusing.\n. sort imports\n. indentation, put a space before the {.\n. getClass.getName is more explicit.\n. what defines correctness?\n. private[this] or scala will generate an accessor method.\n. read definitely doesn't act like a field, let's add parens.\n. since we never use unit, maybe just use before instead of flatMap?\n. maybe this should be FINE or TRACE.  this seems like a lot to log at INFO, although maybe because it's email you expect it to be lower throughput?\n. given that this is totally synchronous, maybe this should return Unit instead of Future[Unit]?\n. before\n. I can guarantee you that signal will be Future.Unit.  Is that correct behavior?  If it is, let's inline this.\n. there's a ton of duplicated code here, which doesn't seem strictly necessary.  let's also unalign this, we don't use that style elsewhere in finagle.\n. sort imports\n. sort imports\n. Thinking about this more, what's the point of separating EmailMessage from EmailBuilder.\n. richmsg => richMsg\n. fix indentation\n. sort imports\n. flatMap { _ => Future.Done }\nis isomorphic to\n.unit\n. Actually, in this case you can just use Future.join.\n. no need to break this up onto a few lines.  just one line is fine.\n. @roanta @mariusaeriksen thoughts?  how does this fit in with the new exception hierarchy?\n. this is a nop, since info === content.\n. we can move this into an object.  no need to put it in the case class.\n. uh, ignore this, I see the issue now.\n. let's put this next to UnspecifiedReply, since they're related.\n. this line is > 100 characters\n. sort lines\n. this line is > 100 characters\n. does this need to be at the netty layer?  it will be a little messy if we want to swap out a different backend (like netty 4)\n. camelCase, not snake_case.\n. this is the same as before, DRY please.\n. incredibly similar to the ones that came before.  I bet you can make this more clear and concise.\n. Standart => Standard\n. wrap this in an Option and we can just match on it.\n. what other type can this be?\n. we can use destructuring to do this more concisely.  do we want to do some validation here to avoid an array out of bounds issue?\n. add return type annotation\n. why is this ascii?\n. sort lines\n. sort lines\n. sort imports\n. indent these by two spaces.\n. let's use MockitoSugar (from scalatest) instead of MockitoStubs (from specs).\n. why is this commented out?\n. OK, the docs make it sound like it returns Future.Done regardless.  Can you fix the docs?\n. Why does smtp have so many different replies?  Or does it only have one success reply per command?  Do replies add granularity to success?\n. Hurk, how long do SMTP sessions last?  Do we start an SMTP session with a tcp connection and tear it down when we turn down the SMTP session, or do we set it up / tear it down with the request?\n. No need, just document the contract.\n. Can we make EmailBuilder an implementation of EmailMessage then?\n. OK, let's just change this to def toString(): String then.\n. no, I can just wait for the next release.\n. what I'm saying is that there's no point in saving signal off into a val.  this code is equivalent to:\nscala\ndecodeReply(rp, p)\np onFailure {\n ...\n}\nFuture.Done\nThis also makes it more clear that decodeReply is mutating, and doesn't return anything interesting.  Once we're no longer using the return value, it's much more natural to make decodeReply return Unit, which is also semantically more correct since it's not actually asynchronous.\n. should this be ascii?\n. OK, I got confused because you use utf8 elsewhere in the codebase.  I commented on the bit where you use utf8.\n. I might be misreading, but it looks like it doesn't specify case in the section you linked to, and in the section on synctactic notation they say that if it's in quotes, that means that it's case insensitive.  Is there something I'm missing?\n. OK, sounds good to me.\n. no, it's fine.  just use filterNot instead of filter.\n. So I think by default, finagle will hold open a tcp connection until you actually shut down the client.  From what you said about the length of smtp sessions, it sounds like that's correct behavior, no?  Or is the problem that you are destroying the client and not seeing the request be sent?  We also might have to sequence service(Request.Quit) and service.close(deadline).\n. Got it.  Seems like it would be useful for implementors, but not useful for users of a client library.\n. I don't think service(Request.Quit) before service.close(deadline) will work, because we want to close even if we can't Quit properly, but maybe ensure would be the right semantic.  Can you use wireshark and check that the tcp connection is actually being torn down when you expect it to be torn down?\n. NB:\n   This specification uses the Augmented Backus-Naur Form (ABNF)\n   [RFC5234] notation for the formal definitions of the syntax of\n   messages.  Characters will be specified either by a decimal value\n   (e.g., the value %d65 for uppercase A and %d97 for lowercase A) or by\n   a case-insensitive literal value enclosed in quotation marks (e.g.,\n   \"A\" for either uppercase or lowercase A).\"\n. I don't love the style of OneInstancePerTest, it's not particularly idiomatic scalatest.  Generally we just make a context class and import its contents in each test.  By sticking to one style, it's easier for us to reason about different tests, and by having tightly scoped context classes, we can have more sophisticated fixtures if we have a big test suite, for example.\n. probably don't want to share this between tests\n. maybe make a context class?\n. fix indentation\n. I don't like this style, but probably not worth changing, since you don't need to change it for any other reason.\n. you could move these into a context class.\n. let's not share these between tests.\n. I don't think this is threadsafe?  let's not share it between tests.\n. Weird, it works for me.  Does it work for you from master?  Which sbt are you using, the provided one?  How are you running the test?\n. oooh, I see now, they were implicitly skipped before because of this.  OK, carry on :+1:\n. instead of do it or not do it, can we do test vs. ignore, so that it appears in the log output and we're at least reminded that there's all of this stuff we've disabled?\n. context class?\n. don't transform them to lowercase, just make sure they can handle headers case-insensitively :+1: \n. thinking about java compatibility, default arguments make this really hard to use from java.  I think it's fine to keep these, but could you make a couple other nice builder methods that can be used from java?  Maybe something that doesn't take any arguments.\n. where does this trailing underscore syntax come from?  is this an smtp thing?  why does this take varargs String where setFrom takes Seq[String]?\n. I'm not sure EmailBuilder is the right name for this anymore, since we never call build on it.  How about DefaultEmail?\n. Wait, I thought you were saying that it wasn't behaving properly in the dispatcher?  I think I got confused as to what was going on . . . I was trying to reply to a message you posted that said, \n\nYes, when testing with SMTP server stub and looking at its logs, I found out that this request is not actually sent from dispatcher, so I sought the way to enforce service(Request.Quit) before service.close(deadline)\n\nbut I couldn't find the actual message (github swallowed it maybe) so I just put it here.\nIs the behavior correct now then?\n. another way of doing this would be to use an extractor, then you can keep the more natural case style.  just a style choice though, it's up to you.\n. thinking about this more, I think this is incorrect.  we don't want to close the connection when we close this service, we just want to relinquish the connection so that it can be used elsewhere.  this should definitely be moved into the dispatcher.\n. right--if you do service(Quit) ensure service.close(deadline) I think that will have the correct behavior, since it will wait for a response before tearing down the connection.  the two tcp connections will race to tear down, but I think that's OK.\n. Have you tried what I suggested about service(Quit) ensure { service.close }?  Did that have the same behavior?\n. Sorry, I'm having trouble reasoning about the dispatcher code without seeing it.  Could you link me to a branch which has the quit in the dispatcher?\n. let's make sure the test output similarly reminds you to run them manually.\n. ditto here\n. let's keep in the commented out test, but instead of commenting it out, just ignore it.\n. we never seem to use this.  let's remove it.\n. yep\n. can you add a return type here?  public methods should be annotated (it's OK not to fix up the rest of the file).\n. these should be Mapper, not Mapeer\n. can we add an explicit annotation here?\n. Instead of a String-flavored Flag, this should be a Seq[String] flavored flag.  That way you don't need to read the code to guess how to parse it.\n. instead of making this mutable and adding a method in LoadService to update it, let's just add ignoredPaths directly when we declare ignoredPackages.\n. seems like you wanted to expose this for testing, but we could instead make ignoredPackages a method, or else add a private[util] method version of ignoredPackages.\n. please keep imports sorted\n. the if statement isn't necessary.  we can just add ignoredPaths without checking.\n. keep imports sorted\n. Yeah, my guess is that it's very inexpensive.  If it starts being a bottleneck, we can work on it.\n. Could you paste the test you wrote?\n. I don't know ruby, so please be patient with me :)\nIt looks like this is sticking the stack into a thread-local variable.  Is our guarantee for ruby tracing that you won't ever switch threads?\n. instead of locally blocks, can we just separate these out into clearly named tests?  that will help us understand what a test failure means if it happens.\n. please keep imports sorted\n. please keep line length < 100.\nif you need to do this sanitization for every request, you should disallow creation otherwise.  does this need to be here though?  could we just put it in the constructor of ExecuteRequest?\n. imo let's keep this a case class.  why does it need to change?\n. prefer ps.foreach\n. feel free to ignore: maybe simpler as\nscala\nparameters.map(_.size).sum\n. how about we make this return BufferWriter, like the writeX methods in BufferWriter?\n. this doesn't seem to need to take an argument.\n. prefer bytes.length, doesn't create an extra allocation\n. please add type annotations to public methods (here and elsewhere)\n. oh, I see, you need it for disambiguating between TinyBlob, etc.  Is that correct behavior?  Will mysql be OK if you pass it mismatched kinds of blobs?\n. prefer bytes.length\n. why provide a fallback case here but not in typeCode?\n. is silence the correct behavior here?\nwhat about nulls?\n. why do you want this variance annotation?\n. prefer factory().flatMap\n. can we make this a generic instead?\n. can we return a BufferWriter instead?\n. instead of the _ prefixed things, can we rename the variables?\n. right, the style has changed.  since you're changing the line, could you please fix it?  we're changing the style lazily, so we ask that folks fix style as they change code.\n. Almost all of the parameter types are very specific types that can't be subclasses, like Int.  What is it useful for?\n. I meant NullParameters, but yes, you're right that it looks like this is how they're done elsewhere too.  Strange!\n. prefer consistency over existing behavior imo\n. I think consistency is better here.  If we're going to change the write* style methods, let's do them all at once.  Having some of them which follow one convention, and others that follow another is a bummer.  Also, this matches the way that the java.nio.Buffer methods work, so it's not unprecedented.\n. maybe just keep a private[this] val sanitized = .... on the case class?\n. yes, this is cleaner imo.\n. My concern is what happens after a ruby server gets a request.  Is it ever legal to have something like:\nt1: receives a request\nt1: makes a request to a different server\nt1: does some different work\nt1: puts some work on a different thread, t2\nt2: on behalf of t1, makes a request to a different server\n... etc.\nIn this case, they should all logically be part of the same Trace, but if we are storing these as thread-locals, then they won't come along by default when we switch threads.\n. We handle it by requiring that you use twitter's util libraries if you switch thread in java, but it won't be so simple in ruby.  I think for now we should just document the behavior, and then we can deal with it later if you actually need it.  Explicitly passing the trace data will probably be fine as a first approximation.\nGrabbing a global mutex would require that you only serve one request at a time, which seems like it defeats the purpose.\n. s/finable thrift/finagle\nNo need to specify thrift\ns/saftey/safety\n. Instead of one long line, could you truncate at 80 characters?\n. I'm not sure this makes sense from a user perspective.  Most folks reading the README probably don't care terribly about the design decision, and probably care more about how to use it.  If you want to document the design decision, probably best to do that in the code.  Could we keep the README just focusing on what is a valid use of tracing?\n. do we ever define what residual means?\n. er, to be more precise, I don't know what a residual path is.  Can we add a description of what a residual path is, and what it might be used for?\n. I'm a little dubious that this makes it easier to read.  Maybe just keep it \"SCRIPT EXISTS\", here and below.\n. maybe add SCRIPTLOAD etc here too?\n. rm NOTE\nrm by timxzl\n. ditto\n. ditto\n. ditto\n. ditto\n. since we need to do this so many places, is there a way to help get it done generically?\n. sort imports\n. rm NOTE\nrm by timzxl\n. rm NOTE\nrm by timxzl\nmaybe just have an @param which explains what f does\n. rm NOTE\nrm by timxzl\n. ditto\n. feel free to ignore: I think this would be cleaner to return a Closable instead of () => Unit, which more explicitly points out that there's a resource that needs closing, rather than that some mutation needs to be done, which is more generic.\n. feel free to ignore: I think these functions read better as just unit, long, bool, etc.  unit.orElse(long) seems just as clear as handleUnit.orElse(handleLong) but less verbose.\n. rm NOTE\n. Do you mean \"call-by-name\"?\nI'm not sure that I follow your reasoning, especially since I think call-by-name is implemented the same way under the hood as what we're doing now.\n. s/explicity/explicit\n. rm NOTE\n. when would this happen?\n. can we make everything the end-user doesn't need to use directly private[this]?\n. rm NOTE\n. I'm not sure that I love this API.  Maybe it would be better to expose a Reply, and then provide typeclasses to make casting easy?  I think\nscala\nclient.eval(script, keys, argv).map(_.cast[Unit])\nmakes it more clear that we're not type-checking this result for you, and you must do it yourself.\n. either inline this or rm the comment.  no reason to duplicate the logic.\n. rm NOTE\nif you expect end-users to want to know this, make this scaladoc.  not everyone reads the code, but most folks read scaladoc.\n. put this on the previous line\n. might as well duplicate this comment for flush, load, etc.\n. why is only this one a ScriptCommand?  should the others ones be too?\n. sort lines\n. don't import Await.result directly, just import Await.\n. please don't use MustMatchers unless you get something really cool out of it, in scalatest 2.x the assert macro means we can get really good error messages easily out of assert.\n. handleUnit.orElse(retryOnNoScript....)\n. buffers.map(bufferToString)\n. s.map(stringToBuffer)\n. no need for braces for a single expression\n. pairs.map(...)\n. rm\n. indentation, here and below\n. scripts.map(SHA1hex)\n. assert(!result(client.scriptExists(sha1s: _*)).reduce(_ || _))\n. assert\n. assert(x == y)\n. indent\n. indentation\n. assert\n. indent\n. assert\n. indent\n. revert please\n. merge into develop\n. s/ )/)\n. s/ )/)\n. s/ )/)\n. s/ )/)\n. s/ )/)\n. Hmm, that's a good point. I feel like it's OK to start exposing Reply here, especially if we comment clearly how we expect folks to use it.\n. this line is very long, can we chop it up?\n. let's explicitly return ): Unit = {\n. instead of turning these into strings, why not just keep them Files?  Java supports rich equality / hashCode for them, so they also allow things like checking if two pathnames are the same on case-insensitive filesystems.\n. Could you elaborate?\n. what do the variance annotations buy us here?\n. since these generics are erased, this is implicitly a cast.  could we instead make it:\nscala\n  case ServiceFactorySocketAddress(sf: ServiceFactory[_, _]) => sf.asInstanceOf[ServiceFactory[Req, Rep]]\nso that the cast becomes explicit?\n. can we either verify that the transporter isn't called, or change the name of this test?\n. You should be able to set it as a java flag (ie -Dcom.myproject.flag=3).\n. I think it's fine to just add an explanation.\n. no need for triple equals, == is fine.  scalatest 2.x has an assert macro that's the :bomb: \n. git doesn't require that the cloned directory be named finagle, maybe we should say the root directory of the finagle repository?\n. this is still the case, but I won't block this if you feel really strongly about it.\n. for consistency, could you change this to http://www.despegar.com/?\n. also, could you put this line about the DICE line so we can stay in alphabetic order?\n. could you make this https and add a trailing slash?\n. could you add a trailing slash here for consistency?\n. for consistency, could you https and add a trailing slash?\n. for what it's worth, scoping new stats receivers, and creating new counters should never be done on the hot path unless it's impossible to know the name of the counter until runtime.  since we know the names in advance, we can do better.\n. actually, since we no longer expose netty types in the public finagle API, how about we change this to http.Response?\n. sorry, I should have been more clear.  could we change the return type to http.Response?  HttpResponse is a netty3 type, and finagle no longer exposes netty3 types in the public API, since we're trying to switch to netty4.  So the change here will look like:\nscala\ndef fetchUrl(url: String): Future[http.Response]\ndef fetchUrlWithRetry(url: String): Future[http.Response] =...\nDoes that make more sense?\n. is it worth even supplying this case?  how frequently is identity used?\n. we can skip some of the boilerplate with ServiceFactoryProxy, and then override apply.\n. ah, I see, the type parameters are wrong to use factory directly.  :+1: \nwe could cast the factory (since we only need the type parameters to work for apply, but I don't think it's worth it.\n. yeah, it seems unlikely that it matters.  :+1: \n. oh god.  thanks for doing this, this is crazy.  could you add a comment as to why we need this?\n. should be queuing\n. ditto\n. because only one parent can be specified, this is necessarily a tree, right?  maybe more clear to specify a latency tree.\n. sorry, should have caught this before, this should be \"sr\", I think\n. I think this should be if (!c.onClose.isDefined)\n. please don't add these (I think these are eclipse files?) can you instead add these to your global gitignore?\n. can you add these methods to BaseClient instead of Client, to be consistent with the regular style here?\n. if this is optional, let's make this Option[ChannelBuffer] instead?\n. could you mention the values that the parameters can be?  if you don't think it's appropriate to paste it, could you link to the relevant documentation on the redis website?\n. in what cases does it return an EmptyBulkReply?  can we just return Future[ChannelBuffer]?\n. could you add a return type annotation here?  I can guess, but it's nice to have it spelled out.\n. could you instead use the finagle 6 API to construct this?  that way we get to use pipelining, etc.\n. scaladoc? in particular, props must have a role-reported key, or this will throw.\n. feel free to ignore: may call this fromMap or fromProperties?\n. why make these all lazy?  these are all cheap operations, let's strict 'em.\n. I don't think this needs to be fully qualified.\n. sort imports, please\n. let's prefer Seq over List\n. let's prefer masters.map { here\n. since this needs to be Strings eventually, can we take Seq[String] as an argument and use ReplyFormat.toString instead of ReplyFormat.toChannelBuffer?\n. names.map {\n. is it possible that there's no master, for example if the master just died and the dead master has been detected, but leader election hasn't finished yet?\n. s/ckquorum/ckQuorum\n. feel free to ignore: unless you use InetSocketAddress.createUnresolved this will entail a DNS resolution.  Maybe it would be simpler to require that users specify a host and port separately?\n. could you follow the style here and and put these commands in Command.scala?  That way folks only need to look one place to see all the implemented commands.\n. merge me\n. why doesn't this match up with the command?\n. case object?\n. string interpolate?\n. could you add a timeout to the Await.ready?  it's a pain when something hangs and we don't have a timeout on it.\n. rm println\n. use parens\u2013this isn't an accessor by any means\n. github shows that this line is gone, but I'm not sure how that could be possible . . . weird.\n. timeout\n. actually, I think I was just selecting it and it seemed reddish.  nvm.  seems fine now.\n. prefer == since scalatest 2.x the assert macro is dope\n. timeout (and for all other Awaits in this file)\n. == (here and elsewhere)\n. case classes with no parameters were deprecated, so we should find some kind of solution to this\u2013if it really bothers you to put them under the same object (I think it's fine) we can rename the object in this case.\n. yes, that's a good idea\n. So the main places where this command are used seem to be in stats and tracing.  Do you want them to appear as \"SENTINEL\" or \"MASTER\" or \"SENTINEL MASTER\"?  In Config, it seems that we chose \"CONFIG\".\n. Daemonize is already true by default in the finagle 6 API.\nthere's  no need to configure DefaultPool in the finagle 6 API because it uses the pipelining pool, so there will only ever be one outstanding connection anyway.\nLGTM otherwise!\n. yep, you're right, I was confused.\n. that seems even sillier than case class with no constructor args.  how about you leave it this way and we'll change it when we change the other case classes with no constructor args.\n. maybe, \"signals that the work was never done, so it's safe to reenqueue\"?\n. let's also add a strongly-worded warning that if you're just trying not to be overwhelmed, you almost certainly want to use RequestSemaphoreFilter instead, because RequestMeterFilter doesn't work well with \"real\" resources that are sometimes faster or slower (like a service that you're depending on that sometimes slows when it takes bursty traffic).  this is better for resources that are artificially bounded, like a rate-limited API.\n. use mocktimer instead\n. Time.withCurrentTimeFrozen is useful for manipulating time here\n. Time.withCurrentTimeFrozen\n. Time.withCurrentTimeFrozen\n. it might make sense not to mark it as rejected if you get an IllegalArgumentException, or a CancellationException?  Probably only RejectedExecutionException should be marked as rejected.\n. now that I think about it, how about we don't make permits configurable?  the point of having a permits argument in await is for folks who want to sometimes await on a different number of permits\u2013since we always await on the same number, it's fine to just pick 1, imo.\n. suppose you're talking to the foursquare API.  they can handle more traffic than you're throwing at them, but as a policy, they have a ratelimit of N / second.  so you want to rate limit in order to protect them\u2013if you were talking to a service that you owned, it could be that you want to send them traffic as fast as they can handle it, but within reason, ie not more than fifty concurrent requests.  in the foursquare example, they're artificially throttling\u2013in the example of your service, it will be able to speed up or slow down as your service is fast or slow.\n. NB it hangs at Await.result(svc(2)) which is a blocking call.  You need to advance it before that.\n. Well, you wouldn't want to retry it if it had been cancelled or you had passed in bad arguments.  Failure is also mostly used for signaling inside of finagle, so not sure what wrapping in Failure buys you.\n. So the way that AsyncMeter works is that it allows burst through at a time\u2013if you examine the first future, it has already been satisfied.  So only the second one is waiting, which means that there is only one waiter.  It would be incorrect for it to throw.  If instead you do:\nscala\nval timer = new MockTimer\nTime.withCurrentTimeFrozen { ctl =>\n  val meter = AsyncMeter.newMeter(1, 1 second, 1)(timer)\n  val f1 = meter.await(1)\n  assert(f1.isDone)\n  val f2 = meter.await(1)\n  assert(!f2.isDefined)\n  val f3 = meter.await(1)\n  assert(f3.isDefined)\n  intercept[RejectedExecutionException] { Await.result(f3, 5.seconds) }\n  ctl.advance(1.second)\n  timer.tick()\n  assert(f2.isDone)\n}\nIn fact, we have tests like this for AsyncMeter already.\n. Let's be precise here: \"Requests that cannot be enqueued to await a permit are failed immediately\"\n. .andThen(echoSvc) here and elsewhere (infix style is only for symbolic operators)\n. feel free to ignore: AsyncMeter.perSecond(1, 1) here and elsewhere\n. ffti: maybe cleaner as:\nscala\nintercept[RejectedExecutionException] {\n  throw failure.getCause\n}\n. this should go at the bottom of the imports, so that they're in alphabetical sorted order\n. never used\n. let's write this as {Future, Time}\n. merge me!\n. sort imports\n. ffti: no need to nest these, we can make this top-level\n. I think the style is Subscribe, no?\n. should be Subscribe client\n. instead of onSuccess, should we use ensure here instead?\n. let's use close and Closable here instead.\n. let's not expose this publicly: private[this]?\n. don't love imports in the middle of the file.  can we put these at the top?\n. private[this]?\n. ditto\n. be explicit here about the type you're returning: : Unit = {.  Are you sure you don't want to return : Future[Unit]?\n. the timer should be configurable\n. let's pass a useful string to IllegalArgumentException, here and elsewhere\n. why do we not want to do anything here?\n. should be val\n. let's move this closer to the implementation\u2013I had to do quite a bit of looking to find it.  also, let's not call it SubscribeListener, since we use Listeners for things that listen for connections and then respond to requests (ie Netty3Listener).  This is similar, but not exactly the same thing.  Maybe call it something different?  Handler?\n. could you document why we need a special subscription client, here and elsewhere?  presumably it's because finagle doesn't have native support for object-streaming-style computation.  it's also worth noting that if instead of a Service[Req, Rep] we had a Client that could return a Closable AsyncStream, that would probably be better, and it's something we should probably target as we try to retool finagle to support more streaming work.\n. actually, do we need a separate client at this layer?  could we type it at the other client layer?\n. these maps need to be synchronized, or else support concurrent access (\u00e0 la ConcurrentHashMap)\u2013as it is, it's not threadsafe.\n. does this mean that dispatchers must be discarded after each use?\n. can we add a test to check that we're behaving correctly here?  it would be a bummer to just silently keep using the old listener.\n. could you mention in CHANGES that you've added support for pubsub, and also that you're changing these APIs?\n. hmmm, would you be OK with doing it at construction-time?  or do you think it's important to be able to do it request-time?\n. why parameterize A?\n. looks like In is never used?\n. .onSuccess {\n. s/ServerDispather/ServerDispatcher\n. \"A wrapper type\" isn't terribly descriptive.  How about something like:\n\"Wraps a ServerDispatcher, adding annotations when a request is read from the wire, and later is written to the wire.\"\n. let's also be clear about what kinds of ServerDispatchers it can wrap.  this is only OK for RPC, right?\n. why not keep this protected?\n. finagle-redis was an external contribution, so it uses a slightly different style.  we usually try to adhere to the scala style guide, although we have a few different rules, which aren't all published externally unfortunately.  probably best to follow the style of finagle-redis here, so just ignore my comment.\n. good point :+1: \n. my understanding is that we need a redis client when we create the rich subscribe client with all the fancy subscription methods, but I think we might be able to still use a regular redis client, and might not need the special subscribe redis client.\n. ahh, I see. could you add a comment?\n. yes, RB_ID is only for internal changes.\n. OK, let me be more precise.  There are at least three models of request / response interactions that we're considering in finagle right now.  We support two of them, byte streaming (over http) and object RPC today, and we're considering support for a third, which would be object streaming.\nAnnotationServerDispatcher is appropriate for object RPC (we have everything we need as soon as we write the first byte to the wire), but it's probably not appropriate for either object streaming or byte streaming.\n. We can't make it private[dispatch] because we have ServerDispatchers outside of the dispatch package.  Let's make it public and call it a day\u2013I don't think scala has the ability to say, \"let subclasses fiddle with this method on other instances of this type\".\n. could we still use clients of the same type, and just document this?\n. Don't we already have that problem today in that someone could call two subscribe commands?  Seems like we need to document it anyway (shrug)\n. I think the right way of doing this would be to keep using the same redis protocol, but ensure that if a connection is subscribed to, then it can't be used for pipelining, and vice versa.  This way we actually can share the client between subscription and normal operations.\nThis will also be generally useful because we need to support this behavior for redis transactions too.\n. Yes, transactions are unrelated to subscription, except in that when you're in a transaction, you can't use that connection for anything else, the same way that you can't use a subscription connection for anything else.\nIf we changed the connection pool API slightly, so that it was something like:\n``` scala\ntrait ReservingPool[Req, Rep] {\n  // nobody else will use this connection until it's marked as no longer needed (ie closed)\n  def reserve(): Service[Req, Rep]\n// may be reused\n  def get(): Service[Req, Rep]\n}\n```\nThen we could use it with redis and be guaranteed of not violating the protocol.\n1.  When you say we are not replied when we issue an unsubscribe command, but we will receive an acknowledgment, do you mean the TCP ack, or does redis also provide an acknowledgment?  This seems pretty doable\u2013we can have something which doesn't mark the reserved connection as \"closed\" until after we've received the acknowledgment.\n2.  Yeah, we have tools like this for memcached (see the sharded multiget) but I'm a little hesitant to start building sharding into our clients.  It might make sense to make sharding helpers at first so that it's easy for folks to make sharders that work for their use case.  In the long run, it would be nice to have a toolkit that we can hook into any protocol that we need to shard manually (redis, mysql, memcached) but for now it probably makes sense to just make little custom helpers.\nAnother thing to consider is that a lot of the tooling finagle has is around naming, and balancing between hosts.  This isn't something that we can do in something like redis, because we only rarely consider different hosts to be the same (ie in redis cluster mode).\nIt might make sense to see what we can do to simplify the redis client by stripping the parts we don't need.\nwe should be able to remove:\nboth of the FactoryToService\nBindingFactory\nAddrMetadataExtraction\nLoadbalancing\nFailFast\nFailureAccrual\nDtabStatsFilter\nAnyway, most of these are out of scope.  We should just set them as TODOs for future work.\n. oh, I see now.  we would need two kinds of reusable connections, one for subscriptions, and one for regular (non-transaction) redis.  but this should still be doable.\n. this should be on the previous line, and let's wrap ex => in NonFatal(ex) =>\n. shouldn't we check at some point in time that this loop has finished?  let's return Future[Unit] here.\n. let's flatMap here instead.\n. it's idiomatic to use foreach for side-effects.\n. should we fail the promise if we fail the write?\n. hmm, interesting.  I guess it depends on the implementation\u2013the downside is that if you send the parts of a transaction eagerly instead of lazily, then if some of the work is nontrivial, like sending a big request, you don't delay it until the last moment.  especially since finagle typically moves IO to a different thread, this would be a bummer.\n. my concern is that we have no way of checking if it hangs forever and leaks memory.  admittedly it's probably not terribly likely.\n. I think it's a valid use case to close but still be reading in the transport though.  Well, we can keep it this way for now, and fix it if it causes a problem.\n. would you mind using a finagle 6-style client?  This instead becomes:\nscala\nHttp\n  .client\n  .withSessionPool.maxSize(10)\n  .newService(ServiceProvider.buildConsumerPath(EchoServer.servicePath), \"http-client\")\nThe new version of finagle that supports the with-style parameters should be released later this week.\n. Ditto here:\nscala\nHttp.server.withLabel(\"echoserver\").serve(\":8080\", new EchoServer)\n. Yep, we adhere to the comment style here: https://twitter.github.io/effectivescala/#Formatting-Comments\n. can you just put all of this on one line? we typically don't wrap until 100 columns.\n. can you break this up into separate tests for each thing you're testing?  ie, \"matches unknown\" \"matches informational\" etc.\n. why test this?  null isn't a valid input, is it?  if it is, we should instead accept an Option[Status], imo.\n. s/convience/convenience\n. Right, but my impression is that in scala we typically assume that null is not a valid argument to pass.  If an instance might be null, it's up to the user to use it safely.  If that weren't the case, we would need to null-check every argument ever.\nWe could make the argument that there's no harm in adding a test for null, but since folks often look at tests as example code, I'd be worried that this will end up being cargo-culted.\n. this should be Some(status), I think.\n. Ah, we typically only use Option in finagle when we're using an API that can definitely return null sometimes.  We treat Option like the Nullable annotation in findbugs\u2013if it's not marked Option, it definitely exists.\n. let's add parens for this function so it's clear that it's a function, and not an accessor.\n. my suspicion is that we can do a little bit better than this by using a conventional serial pool (like DefaultPool) but we can make this optimization in the future.\n. rm this line\n. this doesn't use ServerDispatcherInitializer, as far as I can tell.  let's not make it a constructor parameter until the layer where we need it.\n. let's not do this kind of special spacing\n. ditto\n. do responses often have the trace id embedded in them?\n. Could you elaborate on your use case?  Will it ever be a different trace id than the one in the request?\n. please sort your imports\n. love to see these imports \ud83d\ude3b\n. twitter style guide on scaladoc:\n/**\n * Blah blah blah\n * @blah blah blah\n */\nhere's an example: https://github.com/twitter/util/blob/develop/util-core/src/main/scala/com/twitter/util/Future.scala#L16-L20\n. wrap at 80 columns please https://github.com/twitter/finagle/blob/develop/CONTRIBUTING.md#style\n. feel free to ignore: the short name we use for address is usually addr\n. can you add a timeout to Await.result so this won't hang even if we regress while developing?\n. feel free to ignore: I'd just spin up a new client and server for the test if I were you, and then we don't have to worry about spinning it down in an afterAll, we can just do it directly in the test.\n. ffti: if statement may be more clear here.\n. unused, we can rm it\n. Let's avoid the scala.Any name conflict if possible\n. can we make this a val'd up function?  as it is, we're entailing an allocation when we placeholder syntax the method right now.\n. How about showElems.mkString(\"/\") here?\n. How about showElems.mkString(\",\") here?\n. can we move the . to be in front?  that's the typical style we use inf inagle\n. do you mind sorting your imports?\n. dots in front :+1: \n. :+1: yeah, our style has evolved since we first started adding end to end tests, but we typically make these kinds of style fixes lazily.\n. how would you feel about moving this into finagle-core?  we have a few use cases which could use this for real.\n. ffti: use a counter and decrement on close?\nedit: thinking about it more, that wouldn't work with garbage collection :(\n. Why use P2C with a constant cost per-node?  There's no benefit, right?  RoundRobin is very simple, it probably adds about as much complexity as P2C with constant cost per-node, and it seems easier to reason about.\n. The RoundRobin implementation is simple enough that I don't think it significantly complicates things.  I'll ask someone from search to take a look.  Happy to merge this in as-is.\n. yes\n. do these need to be protected val?  do we have to specify a visibility for them, or is it OK to be default / private?\n. we don't use them for balancing, but they could be useful for metrics, since they're used to calculate load on a service.  maybe worth mentioning that the stats we export for \"load\" is not right.\nhttps://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/loadbalancer/Balancer.scala#L94-L96\n. ffti: cache up.size?  I'm not sure if vector.size is efficient.\n. we don't reassign node, let's make this a val\n. I don't think having multiple exit points for this method makes it easier to read.\nrewriting it to avoid multiple exits:\nscala\nif (up.isEmpty) failingNode(emptyException)\nelse {\n  val node = up(chooseNext())\n  node.status match {\n    case Status.Open => node\n    case _ => up.find(_.isAvailable).getOrElse(failingNode(emptyException)\n  }\n}\nseems just as clear to me.\n. do we need App here?  looks like we need it in p2c because we parse flags, but since we don't here, we shouldn't need it.\n. of which file?\nedit: I am pretty sure you removed the only usage of it in finagle-http.\n$ ag decodePath ./finagle-http\nfinagle-http/src/main/scala/com/twitter/finagle/http/codec/HttpDtab.scala\n50:  private def decodePath(b64path: String): Try[Path] =\n201:          path <- decodePath(msg.headerMap(prefix))\n. We need to fix this elsewhere too\u2013TwitterServer is failing because of this.\n. ya\n. maybe add a note that # must be preceded by a space or must be the first thing in a line?\n. break this off into its own test?\n. I don't mind the test name, but I don't like tests that are too long.  it makes it hard to tell what has broken when a test fails, and it's harder to tell what a test is trying to do when you read the code.\n. please motivate here\n. do these all need to be public fields?\n. you never satisfy this promise\n. make these vals instead of defs if they're never updated.  please also add type annotations.\n. function literals should have spaces at the beginning and the end, like so: { node => node.isAvailable }.  I'm also personally allergic to using placeholder syntax with curly braces, but feel free to ignore that nit.\n. because this isn't synchronized, we may not see updates to currentNode.  you should either mark it volatile or synchronize the read.\n. please check that load balancer status is the best of its constituent nodes\n. I don't think the TrafficDistributor reorders nodes, so everyone will start on the same node if their host list or service discovery gives them the nodes in the same order.\n. check status instead, imo.  it's more clear\u2013isAvailable was a mistake.\n. since this is written in an imperative style anyway, let's go whole hog.  let's use multiple exits, which will simplify the code.\n``` scala\nvar idx = 0\nwhile (idx < nodes.size) {\n  if (nodes(idx).isAvailable) {\n    currentNode = idx\n    return nodes(idx)\n  }\n  idx += 1\n}\nfailingNode(emptyException)\n```\n. This synchronized block is either at the wrong point, or we should check whether status is open again.  Even if someone else beats us in the race here, we're still going to do all of this work as soon as they they let go of the lock.\nSome alternatives:\n1. double check the condition.\n2. expand the synchronized block to include the original status check (I agree with your assessment that it's not the best tbh)\n3.  use a regular java Lock instance so you can tryLock and if you fail to acquire the lock, busywait by recursing.\n. it's not clear to me that incrementing the index is the right approach here, because I don't think the traffic distributor reorders nodes.  if clients are evenly distributed across remote peers but one peer goes down, suddenly the subsequent peer will get double the traffic.  for example:\nnode 2 still alive:\n[(node 1, clients 5), (node 2, clients 5), (node 3, clients 5)]\nnode 2 dies:\n[(node 1, clients 5), (node 3, clients 10)]\nwhich seems like the wrong behavior.  let's either randomize on node down or ensure that the traffic distributor will reorder for us.\n. this counter is never used\n. let's also add a note that if many nodes go down, and then later are revived, but the old nodes never go down, there's no mechanism to later move load back to the revived nodes.\n. please add a test to check that it behaves correctly if traffic distributor hands you the same nodes as everyone else in the same order.\n. why let maxEffort be configurable?  don't we check all of the nodes anyway?\n. the way this is phrased means that it won't ever go back and recheck nodes that have been marked busy or dead.\n. please add a test that checks that adding a new node to the cluster doesn't change which node is stuck to.\n. this doesn't preserve currentNode so we might end up choosing a completely different currentNode.\n. this isn't actually empty, right?  it's that everyone is dead.  instead of failing we typically just pick one in that case, because we're optimistic =)\n. also this val seems unused, as far as I can tell.\n. indentation\n. indentation\n. add a note that this is where we're sticky too.\n. please add a test that checks that if a node is marked dead, it can later be marked alive again.\n. we need to close the response here to see an EOF\n. rm println plx\n. ffti: I like to make eta expansion explicit so that I feel bad about the allocation, but it's your call.\n. rm println\n. rm println\n. I don't think we need this anymore, since we have the new Filter now.  What do you think?\n. How about ComplianceFilter, and that way we can continue to stick things in here if we decide to put in more changes?  For example, we could consider moving the content length setting in HttpServerDispatcher here.\n. doing this silently makes it sort of difficult for our users.  we should probably either fail or log loudly (at least WARNING level).\n. we prefer to avoid infix-style now, so if you could make this service(request).map { rep => that would be appreciated \ud83d\ude00\n. ditto here\n. why extend HeadFilter here?\n. could you add a test for this filter too?  end to end tests are rad, but for finding new bugs quickly, nothing beats a tightly scoped unit test =)\n. Oof, this doesn't feel like it's easy to know.  I guess this is something that users must set?  I guess it's better to just not modify the content length in this case.\n. can you add a comment somewhere here that explains why it must be public so we don't make it private again?\n. I'm sort of confused.  what is this overriding?  maxThriftBufferSize?\n. It might be better to phrase this as \"we no longer support 2.10\" since we plan on adding 2.12 support when it comes out (which is hopefully soon).\n. since ConnectionManager can be used for both clients and servers, this might be better phrased as pending and we should add a note that for servers it goes negative instead of positive.\n. Can we also document the purpose of both activeStreams and pending?\n. Ohhhhh . . . yeah, you're right.  Ignore me.\n. ffti: c.isDigit\n. why not keep doing this, but only use the last characters?\n. in scala, we usually use if (length <= 16) spanId else spanId.substring(length - 16) as the ternary operator.\n. just two spaces please.\n. we typically drop braces for single exprs.\n. I don't think we want to have non-idempotent configuration methods on StackClients.  How about instead inserting a nop \"http stats\" module into the Http stack and then replacing it here?\nIt might also be useful to look at our design principles for configuration methods for StackClients.\nhttp://twitter.github.io/finagle/guide/Configuration.html#design-principles\n. @vkostyukov I think you're right we don't need it here.\n. this doesn't memoize the counter, it will call statusReceiver every time.  note that the underlying and created maps are both immutable.\n. I don't follow.  MemoizedSR decorates another SR, right?  Wouldn't that solve the problem here?  Why not just wrap the underlying SR with a MemoizedSR in the StatsFilter?\n. Oh geez, it might not be open source.  Let me check if I just got the name wrong or if we haven't open sourced it yet.\n. lol double whammy.  @spockz let's go ahead with your original plan and just use a map.\n. instead of appending to an existing test, can you add a new test?\n. I think if you don't mention times(1) it implies exactly once.\n. please use ==, instead of ===.  scalatest has an assert macro which does the right thing here.\n. feel free to ignore: please add a timeout\u2013we no longer use Await.result in our tests to avoid deadlocks.\n. 5 seconds is fine.\n. ah, when I wrote \"we no longer use Await.result\" I meant unbounded Await.result.\n. cols < 100 please\n. cols < 100 please\n. please de-comment SwitchingProtocols\n. please de-comment SwitchingProtocols\n. please de-comment switching protocols\n. I have a preference for small tests, do you mind structuring this differently so that the test clause is inside of the loop?  We can get around the duplicate names by string interpolating into the name of the test.\n. does this need the NoBodyMessage feature?  or can we make this a regular test?\n. cols <= 100 please\n. cols <= 100 please\n. cols <= 100 please\n. cols <= 100 please\n. cols <= 100 please\n. my suspicion is that this fails for ClientFailUpgradeTest because the client starts having issued an upgrade message, so it's expecting a 101 in response.  When it gets a 101, it expects upgrade headers, and netty will throw an exception if you don't have them.  I don't know how the finagle client behaves in that scenario.  Do the tests work if you remove the 101 test from ClientFailUpgradeTest?  Could we restructure the tests to use \"featureImplemented\" to decide whether to include 101 or not instead of just turning them off for CFUT?\n. cols <= 100 please\n. I have the same feedback as before about the structure of these tests.\n. do you mind if we use the https url instead?. we use CamelCase for constants, can you change this to Timeout?  an alternative would be to add an await method:\nscala\ndef await[A](a: Future[A]): A = Await.result(a, 5.seconds). can you add a comment that explains why we do this?. also, maybe we should call this linkPendingCommands  since that's its name going forward?  should be OK to break the API if you add a note to the CHANGES file.. can you also add a note that this is a breaking API change?  we've renamed pendingCommands to linkPendingCommands.. ah, good point!  works for me.. please keep all of the imports sorted alphabetically. let's scope the try/catch block more narrowly.  I think we want to be able to reuse the behavior from the rest of the method, so how about we convert a service(request) that throws an exception into one that returns a failed future?  we could make this instead be\n```scala\nval result = try {\n  service(request)\n}  catch { case NonFatal(e) => \n  Future.exception(e)\n}\nresult.respond { ...\n```\nwhat do you think?. instead of adding all of this extra machinery to the getService method, we should just inline a new service.. it would be nice to validate that pending actually increments.  how about adding a new filter in between StatsFilter and the service that throws the exception that checks that pending is 1.0?. sorry, do you mind sorting these with everything else?  as in, com comes before java, java comes before scala, etc.. instead of chain, simply: statsFilter.andThen(service). this is unused. rm newline please. can we also assert that this is failed?. spacing here should be:\nif (sslHandler != null) {. should be:\nif (future.isSuccess) {. we should make sure we handle non-success cases (interrupt, failure) gracefully here.\nalso, is it possible this will hang?  if I remember correctly, the sslhandler has a default timeout of 10 seconds?  is that right?. no space between }).. no space between (new GenericFutureListener[NettyFuture[Channel]] {. please sort the java.* with the rest of the imports.  we don't treat any imports specially.. indentation for classes should be like\ncase class ClassName(\n    arg1: Arg1,\n    arg2: Arg2)\nso that each argument is indented by four spaces.. do you mind using a match instead of a fold here?  I think it's a bit more legible.. I think we're missing a + here, so I don't think the label will be applied.. please add a timeout to the Await, so that if we introduce a regression the test doesn't hang.. can we test what happens when the ssl handshake doesn't finish successfully?. how about making a class Ctx and shoving this server in there?  that way we can write our tests like:\ntest(\"some test stuff\") {\n  val ctx = new Ctx()\n  import ctx._\n  server.blahblahblah()\n  ....\n}\nand each test will have its own server, but we can write it as if the server was some shared resource.. shouldn't this be on the apply method, not the object?. these should be styled like:\n/**\n *\n */. this won't work for longs bigger than 2^63, right?  should we add a field to LongValue that we're encoding an unsigned long in a signed long?  or add a new type, UnsignedLong?. can we add a test for a long that's bigger than what scala can fit into a long?. that would be perfect =). well, unsigned longs have the same number of bits as signed longs, they're just encoded differently, so we could conceivably encode them as signed longs in scala.  it's just a design decision.  I don't think it would make sense to make them LongLongs, since we know it can't be most of the numbers in LongLongs.  yeah, it would be nice to use isUnsigned for all of the types that could be unsigned.. not exactly.  suppose mysql wants to return an unsigned long of 9223372036854775808 (as we talked about below).  \"9223372036854775808\".toLong fails.  How do we do this properly?  Note that mysql will consider it a long, not a longlong.. @mehmetgunturkun I don't think that's the case.  The column should be able to be unsigned long.  Note that 9223372036854775808 fits in 8 bytes if you're using unsigned longs.. yes, there's a Long type, that's the field that we match on in this code.  although reading more, I think it's actually 4 bytes, not 8 bytes.  but I'm really starting to think that all of the numeric values that we get out of mysql, we should annotate whether they're unsigned or not.. sounds good to me!. can we add a comment as to why we're doing this?. we can merge ones where it doesn't matter if it's signed or not. that would be rad, but I think if you add the helper method you described, that will document it well enough.. s/,and/, and. It's usually pretty unusual and baseDtab changes this late in the game.  how about we keep baseDtab a field until someone needs it?. cols < 100. cols < 100. cols < 100. cols < 100. cols < 100. cols < 100. I think this needs to be async, and we need to wait on removing the handler until we have a result from the verification.  should we add a test for this?. ditto on needing to be async. cols < 100. ffti: I would prefer this to be parentheses because it's not a call-by-name param, but I don't feel strongly.. cols < 100. cols < 100. cols < 100. cols < 100. cols < 100. cols < 100. Future.True. I think this will just hang if it fails now?  can you add a test and make sure that's not the case?  we should do some kind of connection clean-up or error propagation on failure.  same on the server-side.. ",
    "bmatheny": "Since I wasn't bright and didn't create a branch, I'm closing this and will submit new pull request from a branch (with the nit fixes).\n. Updated in #33\n. No worries, thanks for being so responsive.\n. Style fixes, etc taken care of.\n. There is a pull request currently open on twitter/util (https://github.com/twitter/util/pull/8) for working towards making util 2.9 compatible. IIRC, some code changes needed to be made to FutureSpec (and others) for util to work with 2.9. There is also an Ostrich 2.9 pull request, if you're wanting to include Ostrich.\n. Hah, you were too fast Marius. Closing.\n. Like @tsuna I also think this is a nice improvement. My feedback would be to consider using a config class (like you do for builders and such) along with Failure. It seems like the list of options could grow beyond retryable and interrupted, and not having to change existing code to support that growth would be nice.\n. Works for me. Updated and pushed.\n. Updated and pushed.\n. Also updated.\n. Oh crap, sorry about that. Let me fix it up quickly.\n. ",
    "ijuma": "Scala 2.9.x is not binary compatible with Scala 2.8.x so errors like this are bound to happen unless you recompile with Scala 2.9.x. Did you recompile with Scala 2.9.x?\n. ",
    "mkhq": "Thanks for the quick reply, i used the libraries from maven.twttr.com which are 2.8.x\nI tried rebuilding for 2.9.1 from HEAD. But the tests for twitter.util.logging/core does not succeed with specs-1.6.9-SNAPSHOT (I updated Project.scala for both finagle and util since required for 2.9.1). One error when running the tests for util-core is\n[error] Could not create an instance of com.twitter.util.FutureSpec\n[error] \n[error]   0\n[error] \n[error]   org.specs.util.Classes$class.createInstanceFor(Classes.scala:85)\n[error]   org.specs.util.Classes$.createInstanceFor(Classes.scala:29)\n[error]   org.specs.util.Classes$class.create(Classes.scala:40)\n[error]   org.specs.util.Classes$.create(Classes.scala:29)\n[error]   org.specs.runner.TestInterfaceRunner.run(TestInterfaceRunner.scala:55)\n[error]   sbt.TestRunner.run(TestFramework.scala:53)\n[error]   sbt.TestRunner.runTest$1(TestFramework.scala:67)\n[error]   sbt.TestRunner.run(TestFramework.scala:76)\n[error]   sbt.TestFramework$$anonfun$10$$anonfun$apply$11.runTest$2(TestFramework.scala:194)\n[error]   sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)\n[error]   sbt.TestFramework$$anonfun$10$$anonfun$apply$11$$anonfun$apply$12.apply(TestFramework.scala:205)\n[error]   sbt.NamedTestTask.run(TestFramework.scala:92)\n[error]   sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)\n[error]   sbt.ScalaProject$$anonfun$sbt$ScalaProject$$toTask$1.apply(ScalaProject.scala:193)\n[error]   sbt.TaskManager$Task.invoke(TaskManager.scala:62)\n[error]   sbt.impl.RunTask.doRun$1(RunTask.scala:77)\n[error]   sbt.impl.RunTask.runTask(RunTask.scala:85)\n[error]   sbt.impl.RunTask.sbt$impl$RunTask$$runIfNotRoot(RunTask.scala:60)\n[error]   sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)\n[error]   sbt.impl.RunTask$$anonfun$runTasksExceptRoot$2.apply(RunTask.scala:48)\n[error]   sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)\n[error]   sbt.Distributor$Run$Worker$$anonfun$2.apply(ParallelRunner.scala:131)\n[error]   sbt.Control$.trapUnit(Control.scala:19)\n[error]   sbt.Distributor$Run$Worker.run(ParallelRunner.scala:131)\nI'm leaving this for now and stay with 2.8.x. Did you have any luck building with 2.9.x? \n. Should I fix anything else before this can be merged?\n. @mosesn just to clarify, with properly, do you mean that I should pass the Option[Int] down to the SRandMember case class and make sure that the SRANDMEMBER command is sent to Redis without the count parameter when count is None? Without the count parameter, SRANDMEMBER returns a normal BulkReply which should be handled in addition to the MBulkReply.\n. @mosesn @stevegury I've updated to make the count argument pass through to the SRandMember class where the redis command is generated. It adds the count as a parameter when defined.\n. Hey, thanks for taking a look at this. I removed the Btree integration tests and all tests should work now.\n@mosesn, may I ask if you are not using finagle-redis, how are you accessing redis from scala?\n. @mosesn sorry didnt fix above earlier, added a commit with the fixes. There are some conflicts with develop now, will take a look.\n. @mosesn Merged in develop and updated a couple of things to the latest code base, e.g. PubSub was contributed with two integration test suites. Several of the tests are failing when running it:test, so trying to solve that.\n. @mosesn, Submitted another commit, there are still a couple of unresolved issues:\n- Each test suite must be run using testOnly, otherwise most tests fail with when trying to write to a slave. This is due to the cluster setup, but didn't look in depth yet.\n- The PubSub tests fail with timeouts.\n- Most of the sentinel tests fail with java.util.NoSuchElementException: key not found: pending-commands\n- Any tests involving null fails since they expect a ClientError and not a null pointer exception. Commands extending the StrictKeysCommand implements a def key: Seq[ChannelBuffer]-method. This method is called by a validate method when an instance of the command is created and directly accesses the command parameter which triggers a NPE since the test sends in a null for the parameter.\n. @mosesn sure, no problem. The current state of this is 7 failing tests, mostly due to NPE instead of ClientError.\n. @mosesn merged in latest develop, all tests should work now after removing the Server related tests. A short summary:\n- Run integration tests using it:test\n- Tested using Redis 3.2\n- Removed btree and topology tests since this is not part of the official release\n- Fixed scans by replacing PATTERN with MATCH\n- Updated the expected DUMP results, seems this differs between versions.\n- Fixed a bug when running sentinel tests, not all servers shutdown correctly\n- Fixed sentinel protocol to use link-pending-commands instead of pending-commands\nIf this looks ok, should I squash the commits?\n. @mosesn Feel free to look at the code. Squashing is a bit messy since I've merged in develop a couple of times. One alternative to fix the history is to create a new PR and close this one. Do you have any suggestions?\n. @mosesn Created a new PR https://github.com/twitter/finagle/pull/543\n. Ping @mosesn \n. @nepthar sure, ill rebase and will also check your earlier comment, thanks!. @nepthar @luliu Hey, it was more than I expected so didnt finish yet. Does it make sense to make a separate PR for the PATTERN -> MATCH fix?. @nepthar @luliu Added a new PR #587 that replaces PATTERN with MATCH. Tested against redis 3.2.6.. @mosesn will open a new PR, this code is too outdated. @mosesn updated and tried the await function approach, works fine. . @Mura-Mi would it be possible to move the integration tests into finagle-redis/src/it? All redis integration tests were moved there recently. Run in sbt with it:test.. @yannick-polius Is this PR replaced by https://github.com/twitter/finagle/commit/d32d123665fab5bada54a653029d60a88a29b1a6 ?. Note that some of the integration tests rely on twitter internal modifications to redis and will fail if started with the public redis server.. Note that this PR includes #642 . @vkostyukov Thanks for the review! I'll fix the visibility of ClusterClient.\nIn the meantime I've been working on another PR for transparently handling cluster slot redirect and management. Will try to submit soonish. . @bryce-anderson Hey, I already merged in develop in the branch so rebase+squash would be a bit of a mess. Should I create a new branch/PR?. Ping @mosesn . @mosesn Replaced by https://github.com/twitter/finagle/pull/668. @bryce-anderson no worries :) I didnt have time to fix it until now. This depends on #642 and #645.. Closing this and will create a new PR with redirect client support.. @mosesn See https://github.com/twitter/finagle/pull/645 for previous discussion.. @ryanoneill thanks, sounds good \ud83d\udc4d  Just a note on running the integration tests, the cluster protocol was introduced in Redis 3.2. I've tested it against Redis 4.x (and 3.x) and it worked fine.. updated the code to make count an option and adapted the tests\n. Its an assumption from the protocol: https://redis.io/topics/protocol#bulk-string-reply. ",
    "elliottneilclark": "Any chance of getting those branches (util and finagle I think are the needed for this) pushed to github even if it can't be merged into master for a while ?  2.9.1's been pretty stable for us.\n. ",
    "senthilnest": "Any idea as to when we might be able to play with a 2.9 version of finagle?\n. I should have some time over the weekend to get this done.\nThanks\n-Senthil.\n. LGTM\n. ",
    "lgiorda": "pretty please?\n. thanks!\n. ",
    "jrudolph": "+1 at having everything necessary to create packages like those published in github\n. Is this fix already in the last release?\n. ",
    "robey": "probably \"sbt publish-release\" should do a \"git push --tags origin && git push --tags github\" automatically.\nit prints out a nagging message about this during publish-release, but that usually gets lost in the noise, and is forgotten by almost every single project (including mine).\n. ",
    "naaman": "+1\n. ",
    "jsuereth": "+1   IF you need help setting this up, let me know.  I'll make a pull request.  We get a lot of requests for twitter utilities on maven central.\n. ",
    "raymondtay": "+1\n. ",
    "mslinn": "+1\n. ",
    "viktorklang": "+1\n. :checkered_flag:\n. ",
    "seanparsons": "This would be really useful, I support this.\n. ",
    "mitch000001": "+1\n. ",
    "fride": "+1\n. ",
    "seratch": "+1\n. ",
    "ericacm": "+1\n. ",
    "gourlaysama": "+1\n. ",
    "svraghavan": "+1\n. I am also facing the same issue. Any idea when this will be fixed. Thanks for looking into this.\n. ",
    "dacr": "+1\n. ",
    "benhardy": "+1\n. ",
    "tototoshi": "+1\n. ",
    "jbrechtel": "+1\n. ",
    "kxbmap": "+1\n. ",
    "gakuzzzz": "+1\n. ",
    "shinobu-aoki": "+1\n. ",
    "weihsiu": "+1\n. ",
    "tonit": "+1\n. ",
    "przemek-pokrywka": "+1\n. ",
    "efemelar": "+1\n. ",
    "ornicar": "+1\n. ",
    "eugener": "+1\n. ",
    "malexejev": "+1\n. ",
    "alekseiko": "+100500\n. ",
    "hmanon": "+1\n. ",
    "caniszczyk": ":shipit:\n. Funny, I've actually been working on this today too...\nhttps://travis-ci.org/caniszczyk/finagle/builds/3746169\n. I believe there's an issue of Travis not supporting 64bit VMs so we're dead in the water ATM\n. @mariusaeriksen, is there a reason we should even bundle SBT?\nI think it's reasonable to expect people to have it installed locally.\n. FYI, I enabled Travis CI on the repo now.\n. @radustoenescu can you reference this issue when working on the GSOC project?\n. Someone mentioned \"coffee filters\" as an idea.\n. Thanks everyone for your input, I will start the contest this week and we can go over submissions while we narrow things down.\n. The contest has started:\nhttp://99designs.com/logo-design/contests/logo-finagle-254061/welcome\nThere will be a few days of submissions as we get to whittle them down based on our likes.\nIf you have anymore ideas on what the Finagle logo should look like, let me know.\n. You can take a peak at the current set of designs:\nhttp://99designs.com/logo-design/contests/logo-finagle-254061\nAnything stand out that folks like?\n. Been lost the last thirty minutes looking at steampunk birds, this one is amazing:\nhttp://cdn.designcontest.com/images/twitter-all-stars/steampunk_512x512.png\n. Quick poll here for people who want to help narrow down potential designs:\nhttp://99designs.com/logo-design/vote-oxdzrx\n. Another vote to finalize the designers for the next round of iteration:\nhttp://99designs.com/logo-design/vote-js23nd\n. After voting, these two designs/designers stuck out:\nhttp://99designs.com/logo-design/contests/logo-finagle-254061/entries/61\nhttp://99designs.com/logo-design/contests/logo-finagle-254061/entries/64\nIs everyone comfortable moving forward with those two designers to have them battle it out for the final design?\n. We finalized our designers and are now experimenting with some more designs:\nhttp://99designs.com/logo-design/vote-rvz15k\nPlease comment on each design, it really helps the designers. We will keep iterating and in another poll or two, call for the final vote. Thanks for everyones help!\n. Ok, here's the final poll to select the logo and designer to work with:\nhttp://99designs.com/logo-design/vote-m6nvce\nWe will have an opportunity to slightly tweak the final logo selected so keep that in mind when you're writing the reviews for the logo in the poll.\n. The voting is done and we went with this one:\nhttps://twitter.com/finagle/status/394137210489823232\nThank you to everyone who participated in the voting process.\n. @mosesn can you look at this if you have time or figure out how we can push our respective release tags to GitHub?\n. This has been improved: https://github.com/twitter/finagle/releases\n. @mosesn @travisbrown @selvin now that GSOC is closing up, what can we do to make sure this code gets merged or survives in the github.com/finagle project? Rumor on the street was that @selvin or someone was interested in taking ownership :)\n. @mosesn any idea what's left with this one?\n. Reopening after chatting with @travisbrown, we'll wait until this actually shows up publicly\n. Would just say \"Finagle Adopters\" and include Twitter in the list and link to https://blog.twitter.com/2011/finagle-a-protocol-agnostic-rpc-system\n. maybe an an \"Adopters\" section... list about 5 and then link to the full ADOPTERS.md :)?\n. yes, can someone fix this?\n. ",
    "hogelog": ":+1:\n. ",
    "mccue": "Try again in a minute\n. ",
    "tsuna": "Anyone?  :)\n. @chochos The Spy memcached client looks pretty good, I should test it if I can find some free time.\nI looked at its code briefly and it doesn't seem to support what I'm adding to Finagle either.  It uses the Ruby-way to find a server (the code is in their ArrayModNodeLocator.java).  So either way I'd need to patch that project too.\n. I hesitated to proxy the method entirely, but decided not to because Netty's toString method is returning something on multiple lines, which doesn't play well with logging.\n2011-11-06 19:03:20,626 ERROR [New I/O server worker #1-1] ParseRequest: Unexpected exception when parsing DefaultHttpRequest(chunked: false)\nGET /foo HTTP/1.1\nUser-Agent: curl/7.21.4 (universal-apple-darwin11.0) libcurl/7.21.4 OpenSSL/0.9.8r zlib/1.2.5\nHost: localhost:1042\nAccept: */*\nCookie: foo=42; bc=1\n. I think this would be a nice improvement.  Do you expect everything to be a Failure or will there be more case classes?  I'm curious also as to whether it's better to put retryable and interrupted directly in Failure or to compose traits?\nI like the sources, to essentially help tack on arbitrary annotations on exceptions/failures, but it also means that recipients of the exception will have to sort of inspect the sources for known keys they may care about, and because these are strings they may change and you wouldn't know, etc.  Is there a way to retain this general purpose annotation mechanism yet provide a statically typed mechanism for important annotations that we expect to always be there (for instance the remote address of a socket from which an exception originated)?\n. Combining ideas a bit: A bird whose nest is a coffee filter, maybe with some plumbing visible in/around the nest.\n. Are you saying this just because you want to mark this constructor as @deprecated?\nedit: Or because you don't want this constructor at all?\nedit2: OK sorry for being slow today.  I pushed an updated patch at tsuna/finagle@33b03e44cc9dcc549a2c71016baa1e78c748144c\n. ",
    "chochos": "Wouldn't it be better to use the Spy memcached client? It's written in Java so no native dependencies needed...\n. ",
    "karussell": "ok, the dependencies finagle-core and finagle-http works:\n<dependency>\n        <groupId>com.twitter</groupId>\n        <artifactId>finagle-core</artifactId>\n        <version>1.9.6</version>                       \n    </dependency>\n  <dependency>\n        <groupId>com.twitter</groupId>\n        <artifactId>finagle-http</artifactId>\n        <version>1.9.6</version>                       \n    </dependency>\nI would still recommend to document that :)\n. ",
    "jluxenberg": "Here's a failing test case. Seems to have something to do with using a POST and then a GET:\n```\npackage test\nimport com.twitter.finagle.{Service, SimpleFilter}\nimport org.jboss.netty.handler.codec.http.\nimport org.jboss.netty.handler.codec.http.HttpResponseStatus.\nimport org.jboss.netty.handler.codec.http.HttpVersion.HTTP_1_1\nimport org.jboss.netty.buffer.ChannelBuffers.copiedBuffer\nimport org.jboss.netty.util.CharsetUtil.UTF_8\nimport com.twitter.util.Future\nimport java.net.InetSocketAddress\nimport com.twitter.finagle.builder.{Server, ServerBuilder, ClientBuilder}\nimport com.twitter.finagle.http.Http\nimport com.twitter.conversions.time._\nobject Test {\n  def main(args: Array[String]) {\nval client: Service[HttpRequest, HttpResponse] = ClientBuilder()\n  .codec(Http())\n  .hosts(\"www.google.com:443\")\n  .hostConnectionLimit(1)\n  .tlsWithoutValidation()\n  .build()\n\nval postReq = new DefaultHttpRequest(\n  HttpVersion.HTTP_1_1, HttpMethod.POST, \"/\")\nval getReq = new DefaultHttpRequest(\n  HttpVersion.HTTP_1_1, HttpMethod.GET, \"/\")\n\nprintln(\"start\")\ntry {\n  println(client(postReq).get(5.seconds).get.getContent().toString(java.nio.charset.Charset.forName(\"UTF-8\")))\n  println(client(getReq).get(5.seconds).get.getContent().toString(java.nio.charset.Charset.forName(\"UTF-8\")))\n} finally {\n  client.release()\n}\nprintln(\"finished\")\n\n}\n}\n```\n. Fixed https://github.com/twitter/finagle/commit/928945ca072248dfbbb5ad82bf26fdcafd6911d5\n. ",
    "arya": "looks good, thanks for the changees!\n. This method can be removed since it is replaced by the FIND_SPACE implementation.\n. If it enters this else, does it ever release the underlying connection? Or is that not a requirement?\n. please follow the same pattern as KetamClientBuilder for this\n. why not Nil?\n. why not Nil\n. why do you need the empty check?\n. ",
    "okapies": "I guess this issue seems to be resolved on https://github.com/twitter/finagle/commit/b884c1fdb9396b5dde1c4b07b9abb9694d44976e by implementing Cluster#ready.\n. Thank you for your careful reply. I understand your idea and close this request.\nI'm ashamed to say that I didn't know the Set is invariant before. I found a discussion about Scala's Sets on Stack Overflow.\nhttp://stackoverflow.com/questions/676615/why-is-scalas-immutable-set-not-covariant-in-its-type\n. Thanks for your fast reply. I'm looking forward to the new version. I will see the suggested codes.\nDo you want to close this issue now or when the migration is done?\n. ",
    "gopalrajpurohit": "I can't seem to find getContentAsync method in Java.\n. ",
    "zeitgeist": "quick workaround when you are using Twitter's finagle-thrift_2.9.1: put this into your build.sbt:\n\"thrift\" % \"libthrift\" % \"0.5.0\" from \"http://maven.twttr.com/org/apache/thrift/libthrift/0.5.0/libthrift-0.5.0.jar\",\n. ",
    "ryanking": "Did you run an update to get all your dependencies?\n. Which version of scala is you project using?\n. ",
    "danielschonfeld": "If all there is to an update is 'sbt update' from outside the finagle-example directory, then yes I did.\n. I've tried to reclone the git repo and recompiled.  Seems to be working fine now....\n. if you are using SBT 0.11.0 go to project/build.properties and change sbt.version=0.11.0\n. Once you do that, the projects/plugings/Plugins.scala file becomes obsolete as the new SBT doesn't use these classes anymore.\nFrom there on... even afer ones adds the correct resolvers and dependencies in the build.sbt file - I am lost as to how to get it to compile against SBT 0.11.0 and Scala 2.8.1\nFirst compilation error (I am now referring to searchbird, but finagle-example exhibits similar problems):\nClient.scala:4: value thrift is not a member of package com.twitter.finagle\n[error] import com.twitter.finagle.thrift.ThriftClientFramedCodec\nAnd so on....\n. I'm very new to scala myself and it's been hell with SBT and with Twitter showing a very promising framework but it not compiling with the latest and greatest in the scala world.  I wish one of them authors would chime in here...\nThere is a way to downgrade and compile perfectly.  Just download sbt 0.7.4:\nhttp://code.google.com/p/simple-build-tool/downloads/detail?name=sbt-launch-0.7.4.jar&can=2&q=\nreset any changes you've made to this finagle cloning of yours and make a quick script to launch sbt\n!/bin/bash\njava -Xmx512M -jar dirname $0/sbt-launch-0.7.4.jar \"$@\"\n. Is there any chance those scripts could be integrated into scala-bootstrapper gem?  \nIt would be nice to have the ability to use that boilerplate Service/Client structure and be able to compile our code on SBT 0.11.0 and Scala 2.8.1...\nThanks so much!\n. @mariusaeriksen - left you an email at your @monkey.org email... could you please reply to me there?\n. ",
    "jponge": "It doesn't work with either 0.11.0 or 0.11.2 (the version that I have through Homebrew).\nIt looks like the project definition cannot be compiled, both update / reload fail:\n[info] Compiling 1 Scala source to /Users/jponge/Code/finagle/project/plugins/target/scala-2.9.1/sbt-0.11.0/classes...\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:3: not found: type PluginDefinition\n[error] class Plugins(info: ProjectInfo) extends PluginDefinition(info) {\n[error]                                          ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:3: not found: type ProjectInfo\n[error] class Plugins(info: ProjectInfo) extends PluginDefinition(info) {\n[error]                     ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:3: too many arguments for constructor Object: ()java.lang.Object\n[error] class Plugins(info: ProjectInfo) extends PluginDefinition(info) {\n[error]              ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:4: jcl is not a member of scala.collection\n[error]   import scala.collection.jcl\n[error]          ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:5: not found: value jcl\n[error]   val environment = jcl.Map(System.getenv())\n[error]                     ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:15: value repositories is not a member of AnyRef with ScalaObject\n[error]     super.repositories ++ Seq(\"twitter.com\" at \"http://maven.twttr.com/\")\n[error]           ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:19: sbt.FileRepository does not take parameters\n[error]       Seq(Resolver.defaultLocal(None)) ++ repositories\n[error]                                ^\n[error] /Users/jponge/Code/finagle/project/plugins/Plugins.scala:21: value ivyRepositories is not a member of AnyRef with ScalaObject\n[error]       super.ivyRepositories\n[error]             ^\n[error] 8 errors found\n[error] {file:/Users/jponge/Code/finagle/project/plugins/}default-0bfec2/compile:compile: Compilation failed\n. I would just love to play with Finagle, not fight with SBT, the so-called \"Simple\" Build Tool :-)\nIsn't there a way out bar downgrading SBT?\n. It works with sbt-0.7.4 downloaded and launched locally.\n@mariusaeriksen => you mentioned that you publish binaries, but I couldn't find any mention of those... or are they available on Maven Central?\n. @SamPeng87 @mariusaeriksen said that they push to http://maven.twttr.com/ and I see that the GItHub page has been updated to reflect this.\n. ",
    "SamPeng87": "@mariusaeriksen you say will publish binary artifacts .where are this?\nI want use finagle to my project.i have same program,and build one day don't success...:(\nthank you very much.\n. @jponge thanks your help...but,have one question..I don't know use maven..:(\n. why don't fiex this issues?\nonly one test error,can't package finagle-http\n. ",
    "rshelley": "For anyone else also looking for the binaries, they are in com/twitter, not com.twitter:\nhttp://maven.twttr.com/com/twitter/\nAs a side note, I don't see any reference on the GitHub homepage to binaries, binary, library or maven.twttr.com.\n. ",
    "sodabrew": "If you'd like to to get a Scala 2.9.1, SBT 0.11.2, Thrift 0.8.0, Finagle 3.0.0 stack, a working example is in the README here:\nhttps://github.com/twitter/sbt-scrooge/tree/sbt11\n. For the code you have above, you must change your Scala version to 2.7.\nIf you'd like to to get a Scala 2.9.1, SBT 0.11.2, Thrift 0.8.0, Finagle 3.0.0 stack, a working example is in the README here:\nhttps://github.com/twitter/sbt-scrooge/tree/sbt11\n. If you'd like to to get a Scala 2.9.1, SBT 0.11.2, Thrift 0.8.0, Finagle 3.0.0 stack, a working example is in the README here:\nhttps://github.com/twitter/sbt-scrooge/tree/sbt11\n. ",
    "Vadi": "There is a difference in using sbt and ./sbt \nGo back to school,Vadi!\n. ",
    "zhupan": "Thank you, marlus. \n. ",
    "george-vacariuc": "These are good thoughts, thank you. We will continue to contribute our\nimprovements and welcome suggestions.\nOn Wed, Feb 29, 2012 at 10:53 AM, marius a. eriksen\nreply@reply.github.com\nwrote:\n\nIs this particular protocol (code32, length32, message) used by somebody else, or is it your own? If not, it \u00a0would be nice to build more room for extensibility (eg. to ship trace ids) from the start. In thrift we do an upgrade dance, but that's only to maintain backwards compatibility.\nAlso, it would be nice to build a protobuf compiler plugin to generate Future-full bindings as well.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/68#issuecomment-4242911\n. Marius,\n\nWhen Google open sourced Protobuf they did not also open source the\nRPC protocol they use internally, they apparently considered it to be\na competitive advantage. There are quite a few attempts to do RPC with\nprotobuf (http://code.google.com/p/protobuf/wiki/ThirdPartyAddOns)\nbut none of them has the elegance of the Finagle framework, so we\nstarted creating a protocol for it.\nI am definitely open to suggestions others learned from Thrift that we\ncan apply to create a reasonably good Protobuf based protocol.\nOf course I would like to move relatively fast to add the minimum to\nmake it extensible so that others can start using it and contribute.\nPlease let me know what you think the next steps should be.\nThanks,\nGeorge\nOn Fri, Mar 2, 2012 at 2:11 PM, marius a. eriksen\nreply@reply.github.com\nwrote:\n\nI want to merge this, but we need to put some more work in. My biggest concern so far is the actual protocol: does it comply to some other widely-used one, or is it a custom one of yours? If it's a custom one, I think we should figure out a way to make it more extensible for features like tracing.\nI'm willing to merge this in so that we can work on it, but without publishing it yet. How does that sound?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/68#issuecomment-4294163\n. That's great Markus, I just joined the finaglers google group. I look\nforward to your suggestions. Have a good weekend.\n\nGeorge\nOn Fri, Mar 2, 2012 at 3:06 PM, marius a. eriksen\nreply@reply.github.com\nwrote:\n\nIt's merged! I'll write my thoughts about a protocol in an email. Are you subscribed to the finaglers group?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/68#issuecomment-4294975\n. Hi Marius,\n\nI sent a pull request for updates on finagle-protobuf. Also I moved the\nrepo to the Tendril's company account.\nWe're pretty happy with Finagle thus far, and we'll add support for tracing\nrather soon. We also have a implementation for Serversets based on Netflix\nx-discovery and ZooKeeper that has no dependencies on Thrift but I'm not\nsure if that fits inside Finagle.\nThanks,\nGeorge\nOn Fri, Mar 2, 2012 at 3:06 PM, marius a. eriksen <\nreply@reply.github.com\n\nwrote:\nIt's merged! I'll write my thoughts about a protocol in an email. Are you\nsubscribed to the finaglers group?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/68#issuecomment-4294975\n. Hey Marius,\n\nI noticed one of your comments in the finagle-protobuf module\n\"finagle-protobuf:\nkill POM; seems\ndefunct.https://github.com/twitter/finagle/commit/a3dd155c53507c5c5fc6651d2a75243994d738bb\".\nWe have been using this protocol in production for months, and it has been\nworking great for us and we did not need to make any updates.\nThe one thing I will need to add is a better wiki page.\nGeorge\nOn Fri, Jul 6, 2012 at 1:47 AM, marius a. eriksen <\nreply@reply.github.com\n\nwrote:\nhey George\u2014I'm currently on vacation and will have a look when I get back\n(in ~1 week)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/91#issuecomment-6799208\n. @mariusaeriksen we definitely want to keep in step with the framework, let me see how I can slip this into our backlog. Thanks for the heads up.\n. @mosesn unfortunately, at this time, I do not have the bandwidth to do the porting.\n. Moses, that's a good idea. I will check with our compliance people if\nthey're ok with me working on this and I will follow up with you in the\nnext week or so.\n\nOn Wed, Aug 13, 2014 at 12:00 PM, Moses Nakamura notifications@github.com\nwrote:\n\n@george-vacariuc https://github.com/george-vacariuc we've been thinking\nabout how it's a huge pain that finagle keeps changing underneath your feet\nso it's hard to merge in finagle-protobuf. We've also been putting similar\nprojects under the finagle [organization][0]. What do you think about the\nidea of making finagle-protobuf its own project under the finagle org, so\nthat it doesn't have to go through the same stringent code review process?\nWe can also make you an owner of the project, so you'll be able to merge\npull requests etc yourself, which makes the most sense since you're the\nexpert on finagle-protobuf.\nWe'll still be happy to consult on finagle-protobuf, but we won't have to\nend up in these sinkholes where nothing gets done.\nThoughts?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/91#issuecomment-52085936.\n. Hey Moses,\n\nPlease accept my apologies for having not followed up; unfortunately I will\nnot be able to contribute to the project.\n--George\nOn Mon, Dec 29, 2014 at 10:48 AM, Moses Nakamura notifications@github.com\nwrote:\n\n@george-vacariuc https://github.com/george-vacariuc any update from\nyour compliance folks?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/91#issuecomment-68279689.\n. Done.\n. Done, thanks.\n. That is fine, please comment that after you pull. It would be difficult to\ncomment that section on my fork as we build that artifact.\n\nOn another note, I've seen a few posts where people are interested to\ncontribute to Finagle but are confused about sbt and eclipse. I checked in\nnon intrusive support to eclipsify finagle-core with \"sbt eclipse\". I think\nit would be beneficial to pull and include a note on the main Finagle\nReadme. I believe the easier for someone to get the project open in an IDE\nthe more likely they will become interested in contributing.\nOn Mon, Apr 23, 2012 at 5:12 PM, marius a. eriksen <\nreply@reply.github.com\n\nwrote:\n\nval protobufProject = project(\n     \"finagle-protobuf\", \"finagle-protobuf\",\n     new ProtobufProject(_), coreProject)\n-*/\n\nlet's keep this commented out for the time being\u2014 i do'nt want to publish\nartifacts just yet.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/81/files#r723757\n. \n",
    "tootedom": "\n\nSSL contexts shouldn't be reused across connections, see ed7efcd.\nSo it's probably more appropriate to pass in factories directly.\n\n\nAh yes.  Isn't it the SSLEngine that can't be reused, rather than the SSLContext itself though?  \nI've updated the request with a04aecb ; so that the SSLEngine is created each time; from the SSLContext passed to the ClientBuilder.\n. Hi there,\nSorry about the formatting, does 2d51c0bc look any better?\nCheers\n/dom\n. ",
    "fbettag": "Dear Benjamin,\ncould you share your hackery? ;) I'd really need it. Thanks!\n. ",
    "devinus": "Thanks for looking into it. Like I said, I can reproduce it in my project as soon as I switch my dependencies in build.sbt from 2.0.1 to 3.0.0 and see it work when I move back to 2.0.1. Same code, and in my case it hangs forever. ;_;\n. What confuses me about it being intermittent is that the manual HTTP request works every time.\n. ",
    "stephenjudkins": "It appears that activeHandlers.toArray returns an Array that contains a \"null\". I assume there is a race between activeHandlers -= channelHandler in L629 and toArray.\nIt appears that neither toArray nor copyToArray are synchronized in SynchronizedSet. Replacing this with either toList (which is synchronized) or manually synchronizing on activeHandlers should address this issue.\n. I have a fix above. Feel totally free to use it or throw it out if it's not appropriate.\nI'm curious how one would go about testing this.\n. (Please let me know if there is a better venue to discuss this)\nIf that's the case, perhaps you can offer a suggestion on how to better solve our problem:\nWe're using Finagle as a proxy server between slow clients and a relatively fast S3 backend. Using the non-streaming HTTP client can use an unreasonable amount of memory waiting for clients. As far as I can tell from examples, most other codecs simply let you compose a Server and a Service in order to have a transparent proxy. A Service closes the socket immediately after the response is formed, thus stopping the delivery of any further chunks. Thus, we use ServiceFactory since we need to keep the stream open until release is called. However, the factory runs out of slots since when the Server calls release on the StreamResponse, the client doesn't get released. Here's our stopgap solution:\n```\nobject StreamClosingFilter extends Filter[HttpRequest, StreamResponse, HttpRequest, StreamResponse] {\n  def apply(request: HttpRequest, service: Service[HttpRequest, StreamResponse]) = {\n    service(request) map { response =>\n      new StreamResponse {\n        def httpResponse = response.httpResponse\n    def messages = response.messages\n\n    def error = response.error\n\n    def release() {\n      service.release()\n      response.release()\n    }\n  }\n}\n\n}\n}\n```\nThis fixes our issue, but seems kludgy and is tied to the StreamResponse interface. What other solutions would you propose?\n. Thanks for the explanation, and for pushing the fix.\n. It seems I was mistaken about what's going on here. Please disregard this; sorry for any trouble.\n. That is a much simpler solution to the main problem. I've updated the pull request to use it.\n. See above commit for deterministic test. Is this a reasonable approach?\n. I don't know what you mean by JUnit style unittests. Can you point me to an example in Finagle I should emulate? Should I just switch superclass to org.specs.SpecificationWithJUnit?\nAlso, should I remove the additional case in EndToEndSpec?\n. I've made those changes, and merged in master. I'm assuming it's ready for merge?\nI've also rebased these changes to https://github.com/stephenjudkins/finagle/commit/d62455e6f84d40ccd6e0dac3b21c2876b802997e. Pick your poison on which one you'd like.\n. Yes, it looks like I forgot to add it. Sorry about that one. I was switching between SBT 0.7 and 0.11 branches so it got lost in the confusion.\n. I don't like it either, but the above solution doesn't test the bug that was fixed. If I revert the changes in HttpDechunker, the current test fails. However, your suggested test passes in either case.\nThe issue isn't that the EOF is sent to error before the last message is sent to messages, it's that it's sent before the last message is received and synced from messages. Thus, selecting between messages and error will most often select messages first. What we want to ensure is that EOF is not sent to error until the last message in messages has been synced.\nWe can verify whether the dechunker has sent the second message to messages, but we can't verify whether it's quiescent, or getting ready to immediately send EOF to error. The 1-second wait verifies to a high degree of certainty (absent a huge GC pause) that the dechunker is, in fact, waiting to send EOF until after the last message is synced.\nIf you're opposed to this solution, the only real alternative I can think of is unit-testing HttpDechunker without IO or an executor. If we remove threads from the equation, we can be sure that all side-effects from sending a message have occurred when we send the original message. Would you like me to write this test? Or do you have any other suggestions?\n. ",
    "leothekim": "I am also running into this compile error. Is there a specific tag or branch to checkout to build a working release?\n. ",
    "uzoice": "2.9.1\n. test environments \uff1a windows 7 (64),java version \"1.7.0_03\" (64) , scala version 2.9.[1|2]\n Ubuntu 11.10  (64),java version \"1.7.0_03\" (64) , scala version 2.9.[1|2]\n. thank you\n. ",
    "cb372": "Thanks!\n. I just noticed that this was not actually merged in. \nWas this a deliberate decision (should I fix something?), or did it just slip through the cracks?\n. OK, thanks for the update.\nDon't worry, no rush :)\n. ",
    "slyphon": "ah, good point, lemme just adjust that there\n. awesome! :)\nOn Thu, Jun 14, 2012 at 4:47 PM, marius a. eriksen\nreply@reply.github.com\nwrote:\n\nI've pulled this internally, should make it out here within the day.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/88#issuecomment-6340034\n. \n",
    "pankajmi": "Somehow it doesn't build in old finagle project. If I clone in new folder, then it builds properly.\nMay something related to backward compatibility of sbt.\n. ",
    "stevegury": "It's due to old remaining sbt files.\nUse:\nrm -rf project/plugins\nor better:\ngit clean -fdx\n. Closing, this has been fixed in finagle 6+.\n. I just verified that the jar \"http://maven.twttr.com/com/twitter/sbt-thrift2_2.9.1_0.11.2/0.0.1/sbt-thrift2-0.0.1.jar\" is present.\nSo you should try again and it must work now.\n. Thank you!\nI\u2019m pulling this in internally, should show up here soon.\n. I was waiting for a change on the line 185, like @benpence mentioned.\nAfter that, I will pull this commit into the internal repo, and it will appear a little bit after on the github repo.\n. I pulled this internally.\nYou should show it soon in the github repo\n. Thanks!\nI pulled this internally, should show up here soon.\n. Thanks!\nI pulled this internally.\n. Thank you James for fixing this.\nI pulled this internally, it will be merged in the github repo soon (a couple of days).\n. You have to use sbt to build finagle, see the README at https://github.com/twitter/finagle.\npom.xml are used internally and are not compatible with the github repo.\n. You don't need the poms, look at:\nhttps://github.com/mpeltonen/sbt-idea (IntelliJ)\nhttps://github.com/typesafehub/sbteclipse (eclipse)\n. You have to use sbt to build finagle, see the README at https://github.com/twitter/finagle.\npom.xml are used internally and are not compatible with the github repo.\n. As there's no open source contributor, I think you should send this review to the internal repo.\n. A StatsReceiver is not really a logger, there is the logger() method (See [Client/Server]Builder) if you want to use a logger.\nIf you want to have something more meaningful, you should pass a StatsReceiver and have a \"ConsolePoller\" or something which poll the StatsReceiver and log stats in the console, but there is the Ostrich integration which provide more than that and exposed stats in a Http server.\nSo I don't things this class should be part of finagle.\n. Sure, you can use this for debugging your application, but I don't think it make sense to put this in finagle.\nWe try to reduce complexity in finagle as fas as we can, and we avoid adding new feature unless it make sense for a significant part of the users.\nAnyway, thank you for contributing.\n. I think it's Netty related not finagle related.\nCould you please open a Netty bug instead.\n. Yes it was a mistake, we already added the imports back in our internal repo.\nYou should see the change on the next sync of the repositories (in a few days).\n. See my comment on issue 134.\nI leave the pull request open, if someone need the fix in the meantime.\n. Thank you for your help.\n. it depends a lot, but I would say between a few days to a few weeks.\nFor info: last sync of finagle repo was done 9 days ago.\n. We didn't implement the thrift http transport in finagle, but I remember reading on the mailing-list someone willing to do so.\nhttps://groups.google.com/forum/#!topic/finaglers/eil9AM9wOn0/discussion\nHis first attempt:\nhttps://gist.github.com/4551987\n. I pulled this internally, you will see your commit soon in this repo.\nThanks\n. Thanks!\nI pulled this internally, it will show up here soon.\n. Thanks!\nI pulled this internally, it will show up here soon.\n. Hey Moses,\nSorry for the delay, I retrieve this internally.\nThanks.\n. Sorry for the delay again.\nWe would be happy to see your pull request on this.\nNo need to bump the minor, if you leave the old LogFormatter in com.twitter.finagle.http.filter, there shouldn't be any API breakage.\nI agree with the rest of your proposition, maybe should you use logException instead of logError (I'm fine with both).\n. Closing, the fix is in our internal repo, it should show up here soon.\n. com.twitter.common.zookeeper#server-set;1.0.23 is publicly available here http://maven.twttr.com/com/twitter/common/zookeeper/server-set/1.0.23/\nIt should be resolved by the resolver \"twitter-repo\" defined here: https://github.com/twitter/finagle/blob/master/project/Build.scala#L33\nDid you change anything in the sbt configuration?\n. Right now the doc is unclear about that, I'll fix that.\nThanks for the report\n. I pulled this internally, it'll show up on Github soon.\nThank you for doing that and sorry for the delay, the next time I'll be faster.\n. This is in our internal repo, it should show up here soon.\n. Your bugfix was integrated to the internal repo, we just need to synchronize the internal repo with the Github's one.\n(It will be done this week)\n. Yeah, It will be a 6.4.0 actually.\n. Closing, it's now in master.\n. @dadrox @ForceRs can you show us your server configuration?\n. Can you share the code of your finagle client with us?\nDo you specify a custom ChannelFactory?\n. Can you motivate your choice of a CachedThreadPool instead of a FixedThreadPool?\nUnless for good reason, I would recommend to simply let finagle create (and share) the ChannelFactory.\n. Closing, it's now in master.\n. I agree, we will do the change.\n. @roanta has a local branch where he improved the client.\nWe'll continue to work on it internally and this PR will become obsolete when we'll sync the github repo.\n. Closing, It's now in master.\n. maven is used internally, we used sbt to build the open source version of finagle (with _2.9.2 and _2.10 at the end).\nWe recently tried to remove the need to list maven.twttr.com as a repo and push finagle in maven central, but apparently there's still bugs in this release.\nWe try to fix that in the next release, in the meantime can you list maven.twttr.com as a repo in your project?\n. Your changes in the pom.xml won't fix the problem, because the finagle in Sonatype is built with sbt.\nI'm not a maven expert, but maybe adding the same fix in the sbt project file could solve the problem with transitive dependencies not present in Sonatype.\nhttps://github.com/twitter/finagle/blob/master/project/Build.scala#L65\nWhat do you think about that?\nIn the next version, we'll try to move all dependencies in maven central (or use the latest ones present in maven central).\n. We use maven internally to build finagle and other projects that depend on it.\nThose poms are just the one that we use to build finagle. Actually this github repo is a subtree of a bigger repo that we have internally (you saw reference to \"../../\" in the poms). Actually we should really remove the poms from this Github repo to avoid confusion.\nFYI: we'll migrate the build tools to pants in a (near?) future.\nhttps://github.com/twitter/commons\n. I pulled your pull-request internally.\nIt's in the internal big repo I was speaking about, and your commit will appear here on the next sync (in a few days).\nThank you for your contribution.\n. I saw that the callstack reference scrooge:\ncom.twitter.scrooge.FinagleThriftClient$class.encodeRequest(FinagleThriftClient.scala:22)\nIt may be related to the fact that you exclude the latest scrooge (3.4.0) in favor of an old one (3.0.8).\nWhy don't you use the latest version?\n. I think that this release of finagle-zipkin is buggy, it shouldn't have a dependency on a SNAPSHOT version.\nWhere do you pull finagle-zipkin? (maven.twttr.com or maven central)\n. You can have a look at the old documentation as well: https://github.com/twitter/finagle/#finagle-developer-guide-december-15-2011-draft\nAnd we will try to improve the documentation.\nThank you for your suggestion.\n. Closing, it's now in master.\n. @delitescere sorry for the absence of updates, but this has been unprioritized on our side, but we would gladly accept pull request (and/or give guidance about that).\n. We can introduced a new object representing the \"end of connection\".\nUnfortunately this change would require a version bump (at least minor) because it would make the code not backward compatible.\nWould you like to submit a pull request?\n. Obsolete, closing.\n. Thanks for the pull request, we are pulling this internally (it will show up here soon).\n. It's now in master, closing.\n. Thanks, I've pulled this internally.\nAs it introduced a behavior change, I will run some tests before merging it into master.\n. I think you can directly use default from java.\ncf. https://github.com/astubbs/finagle/blob/d889dcd0560f2cf2e470dccc3f9bc5c1d02878d0/finagle-zipkin/src/main/scala/com/twitter/finagle/zipkin/thrift/ZipkinTracer.scala#L14\n. default is a public val (See line 14), from java you should see this as a method with no argument that return a Tracer.\n. Ah right.\nI'm fine with adding a new method for java people, but def mk() is ambiguous with def mk(host: String = Host().getHostName,\n         port: Int = Host().getPort,\n         statsReceiver: StatsReceiver = NullStatsReceiver,\n         sampleRate: Float = Sampler.DefaultSampleRate\n  ) because of the default parameters.\nWhat about def get() ?\n. I think actually that we should change the comment instead of the behavior:\nEg: the pattern \"foo/bar\" ONLY matches this path: \"foo/bar\"\n. Sorry for the delay, it seems good, I just add a comment about the API.\nI'll merge it, as soon as you update the signature.\n. It looks good to me, we will pull this internally, it will show up here (Github) soon.\n. I agree with you about everything except the initialCommands (we shouldn't touch to that).\n. Yeah, people have different usage of the console, I don't think it's a good idea to impose some initial commands.\nAnd I prefer to keep the sbt definition as simple as possible (it's already quite complex).\nThank you for doing that, I pull this change internally, it will show up here soon.\n. Thank you for contributing.\nCould you add a test + making the change backward compatible please.\nThx\n. Keeping the same API/ABI.\nIn that example, you introduce a new parameter in the ReadMessage case class, so adding a default value should be nice or even better defining a companion object with an apply method that keep the same binary interface (2 parameters).\n. We have other usages of this class in other codebases.\nI'm still would like to have a test for the abort behavior.\n. Can you merge master?\nWe'll review and test that internally.\n. Why not having finagle client(s) directly speaking to those servers and setting up an HAProxy only used by your PHP clients?\n. It looks good, I pulling that internally, it should show up here soon.\nI'm curious, did you change your loadbalancing strategy?\nIf yes, which algorithm did you use?\n. > Do you roll quickly? slowly?\nIt depends of the service, but I would say that we do rolling-restart with a rate of: restart <10% of the fleet, wait until the success rate recover and continue with the next batch.\nServers that are freshly restarted are slower than older ones (for various reasons like JITing, empty caches, classloading...), and, depending on the service, it is sometimes problematic. Currently some services are doing some warm-up initialization, but the true solution for that would be to improve the LoadBalancer strategy.\nWith this new loadbalancing strategy, do you have any impact on the p95 or p99 of your request latency?\n. I just want to close this issue, but I would like to continue this conversation on finaglers@googlegroups.com if you don't mind.\nYour changes have been merged in master (Issue #196 is merged as well internally)\n. It looks good, I'm pulling this internally, it will show up here soon.\nThank you for your fix.\n. I think you're right, would you mind submit a pull request?\n. I think it's a case of tests pollution, if you run the tests independently everything is fine.\nWe'll have a look at that.\n. Actually this has already been fixed (cf. https://github.com/twitter/finagle/pull/180), it will show up here on the next release of finagle.\n. No, we don't have an ETA for this.\n. Glad to see you're contributing to the finagle community!\nHowever, I think that it would make more sense to keep feature separate for now. Our team is very small, and we unfortunately cannot afford to maintain every pull request with big new features that we receive. I think that making this a separate library that integrates well with finagle is the best way forward.\n. That's still something that we want to do, but that's not our main priority right now.\n. We are already testing the Netty 3.8 internally, it will be available here soon.\n. Actually someone is already working on that right now, it should be available very soon.\n. Looks good, I'm pulling this internally for reviews by the redis team.\nThanks for the contribution!\n. Fixed internally, it should show up here soon.\nWe also accept pull request :-)\n. This plugin hasn't been ported to sbt 0.13 yet.\nUse the sbt script https://github.com/twitter/finagle/blob/master/sbt in\nthe root of the finagle repository to compile it.\n\nSteve\nOn Sun, Nov 10, 2013 at 8:22 AM, Rajesh Koilpillai <notifications@github.com\n\nwrote:\n[warn]\nhttp://repo1.maven.org/maven2/com/twitter/scrooge-sbt-plugin_2.9.2_0.13/3.7.0/scrooge-sbt-plugin-3.7.0.pom\n[info] Resolving org.fusesource.jansi#jansi;1.4 ...\n[warn] ::::::::::::::::::::::::::::::::::::::::::::::\n[warn] :: UNRESOLVED DEPENDENCIES ::\n[warn] ::::::::::::::::::::::::::::::::::::::::::::::\n[warn] :: com.typesafe.sbt#sbt-site;0.6.2: not found\n[warn] :: com.twitter#scrooge-sbt-plugin;3.7.0: not found\n[warn] ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]\n[warn] Note: Some unresolved dependencies have extra attributes. Check\nthat these dependencies exist with the requested attributes.\n[warn] com.typesafe.sbt:sbt-site:0.6.2 (sbtVersion=0.13,\nscalaVersion=2.9.2)\n[warn] com.twitter:scrooge-sbt-plugin:3.7.0 (sbtVersion=0.13,\nscalaVersion=2.9.2)\n[warn]\nsbt.ResolveException: unresolved dependency:\ncom.typesafe.sbt#sbt-site;0.6.2: not found\nunresolved dependency: com.twitter#scrooge-sbt-plugin;3.7.0: not found\nat sbt.IvyActions$.sbt$IvyActions$$resolve(IvyActions.scala:213)\nat sbt.IvyActions$$anonfun$update$1.apply(IvyActions.scala:122)\nat sbt.IvyActions$$anonfun$update$1.apply(IvyActions.scala:121)\nat sbt.IvySbt$Module$$anonfun$withModule$1.apply(Ivy.scala:116)\nat sbt.IvySbt$Module$$anonfun$withModule$1.apply(Ivy.scala:116)\nat sbt.IvySbt$$anonfun$withIvy$1.apply(Ivy.scala:104)\nat sbt.IvySbt.sbt$IvySbt$$action$1(Ivy.scala:51)\nat sbt.IvySbt$$anon$3.call(Ivy.scala:60)\nat xsbt.boot.Locks$GlobalLock.withChannel$1(Locks.scala:98)\nat\nxsbt.boot.Locks$GlobalLock.xsbt$boot$Locks$GlobalLock$$withChannelRetries$1(Locks.scala:81)\nat\nxsbt.boot.Locks$GlobalLock$$anonfun$withFileLock$1.apply(Locks.scala:102)\nat xsbt.boot.Using$.withResource(Using.scala:11)\nat xsbt.boot.Using$.apply(Using.scala:10)\nat xsbt.boot.Locks$GlobalLock.ignoringDeadlockAvoided(Locks.scala:62)\nat xsbt.boot.Locks$GlobalLock.withLock(Locks.scala:52)\nat xsbt.boot.Locks$.apply0(Locks.scala:31)\nat xsbt.boot.Locks$.apply(Locks.scala:28)\nat sbt.IvySbt.withDefaultLogger(Ivy.scala:60)\nat sbt.IvySbt.withIvy(Ivy.scala:101)\nat sbt.IvySbt.withIvy(Ivy.scala:97)\nat sbt.IvySbt$Module.withModule(Ivy.scala:116)\nat sbt.IvyActions$.update(IvyActions.scala:121)\nat\nsbt.Classpaths$$anonfun$sbt$Classpaths$$work$1$1.apply(Defaults.scala:1144)\nat\nsbt.Classpaths$$anonfun$sbt$Classpaths$$work$1$1.apply(Defaults.scala:1142)\nat\nsbt.Classpaths$$anonfun$doWork$1$1$$anonfun$73.apply(Defaults.scala:1165)\nat\nsbt.Classpaths$$anonfun$doWork$1$1$$anonfun$73.apply(Defaults.scala:1163)\nat sbt.Tracked$$anonfun$lastOutput$1.apply(Tracked.scala:35)\nat sbt.Classpaths$$anonfun$doWork$1$1.apply(Defaults.scala:1167)\nat sbt.Classpaths$$anonfun$doWork$1$1.apply(Defaults.scala:1162)\nat sbt.Tracked$$anonfun$inputChanged$1.apply(Tracked.scala:45)\nat sbt.Classpaths$.cachedUpdate(Defaults.scala:1170)\nat sbt.Classpaths$$anonfun$updateTask$1.apply(Defaults.scala:1135)\nat sbt.Classpaths$$anonfun$updateTask$1.apply(Defaults.scala:1113)\nat scala.Function1$$anonfun$compose$1.apply(Function1.scala:47)\nat sbt.$tilde$greater$$anonfun$$u2219$1.apply(TypeFunctions.scala:42)\nat sbt.std.Transform$$anon$4.work(System.scala:64)\nat sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)\nat sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:237)\nat sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:18)\nat sbt.Execute.work(Execute.scala:244)\nat sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)\nat sbt.Execute$$anonfun$submit$1.apply(Execute.scala:237)\nat\nsbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:160)\nat sbt.CompletionService$$anon$2.call(CompletionService.scala:30)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\nat java.util.concurrent.FutureTask.run(FutureTask.java:166)\nat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\nat java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)\nat java.util.concurrent.FutureTask.run(FutureTask.java:166)\nat\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\nat\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\nat java.lang.Thread.run(Thread.java:679)\nerror sbt.ResolveException: unresolved dependency:\ncom.typesafe.sbt#sbt-site;0.6.2: not found\n[error] unresolved dependency: com.twitter#scrooge-sbt-plugin;3.7.0: not\nfound\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/issues/220\n.\n. This looks good, pulling this internally.\nThanks!\n. You can use tcpview (http://technet.microsoft.com/en-us/sysinternals/bb897437) to check if the server is correctly binding the port. It's also possible that you may need certain privileges to bind a port on a non local address, you should try to run the server \"run as administrator\".\n. Thanks @jdanbrown for the great bug report (bonus point for the repro code).\nWe'll have a look at that.\n. @roanta can you comment on that?\n. It looks good to me too.\nI'm merging it internally in our repo, it should be available here in a few days.\n\nThank you @zhanggl for your contributions!\n. Wow, thank you for doing that!\nIn addition to Moses comments, it seems that one of the finagle-mux tests is failing, maybe you should exclude it as well.\n. It looks good to me too!\nI'm pulling the change internally, thank you for your contribution!\n. Two questions:\n- Can you give paste the code of your ScorerService?\n- Are you doing blocking IO in your code?\nA jstack of your process could really help us here, and ideally a dump of the stats too (add .reportTo(<...>) to your ServerBuilder)\n. Hey @lerouxrgd, thank you for your contribution.\nI'll ask our memcache \"in-house expert\" to validate the change before merging the commit.\n. Ok it has been merged internally, it will show up here on the next sync.\nThank you for your contribution.\n. LGTM\n. LGTM\n. @penland365 please do, then I'll take care of pulling this PR internally.\nThank you for your contribution.\n. @penland365 I just merge your change internally, it should be part of the next sync with Github.\n(I'll close the bug when it's on Github)\n. LGTM\n. LGTM\n. LGTM\nI'm pulling this internally, it will show up here soon.\nThanks for the contribution.\n. LGTM!\n. For the record, I'm pulling this internally.\n. It does look better!\nI'm pulling this internally, you should see it on Github soon.\n. The code LGTM, please fix the few points @evnm mentioned and we'll pull this internally.\n. LGTM\nI'm pulling this internally, it should be on Github soon.\nThank you for your contribution.\n. LGTM\n. LGTM\n. LGTM, I'm pulling this internally for more testing.\nIt should show up here soon.\nThank you for your contribution!\n. Other than a few code style changes, it looks good to me.\n. LGTM\n. LGTM!\n@sprsquish I'll pull this internally today.\n. LGTM\n. LGTM\n. LGTM\n. LGTM, I'm pulling this internally.\n. LGTM\n. LGTM\n. LGTM\n. Sounds reasonable as well to me, please add a simple test so that we won't regress this feature (that we won't use at Twitter).\n. Not a big deal about master/develop branch, nobody touched the RetryingFilter class!\n@spockz Your change LGTM, I'm pulling it internally.\n. @mosesn I think it's better to be explicit in the code, rather than relying on the JVM settings.\n(I think we still have time before switching to ipv6.)\n. LGTM, could you copy please copy the description (Problem/Solution...) from #329 here?\n. LGTM\n. LGTM\n. Hi guys!\nNo we're not using Finagle, however I needed a load balancing algorithm and reused this one for another project. Then I found this (minor) bug.\nI should swing by TwitterHQ sometime next year to say hi.\n. After a night of reflexion I realized that Int.MaxValue/2 is not enough.\nBecause we measure the latency in nanoseconds, it only represents a penalty of (Int.MaxValue / 2) / 1e9 ~= 1.07 second.\nChoosing a bigger Penalty (e.g. Long.MaxValue >> 16 ~= 140737 seconds or 39 hours) fixes the problem and also works well with potentially extremely latent systems.\n. Unfortunately, I don't think so. \nThe EWMA algorithm uses an exponential to adjust the fact that the time-serie is non-evenly distributed.\nMaking cost a long (or an integer) would just move the problem of precision in the computation of cost, leading to rounding errors.\n. I didn't go the extra mile with writing a unit-test, but one possible solution would be to load balance requests across two latent servers and to check that the load is perfectly distributed (adding a counter on the Service or something).\nIndeed with only two hosts, the P2C should behave like LeastLoaded (or JSQ) and the penalty shouldn't perturb the balancing.\n. private[this] val fService = factory.apply()\n2 comments:\n- use private[this] by default\n- The lazy feature here is not very useful\n. You should also create/update the pom.xml\n. We should recommend to use Scrooge instead https://github.com/twitter/scrooge\nWe will deprecate the custom thrift compiler in favor of Scrooge.\n. We use scrooge in birdcage but not yet in science (the migration should happen in a very near future).\nAnd yes, you need to mention that sbt use a plugin that call scrooge to compile thrift files. \nThe latest plugin has only been release for sbt 0.11.2 \n(usually it's not a problem because we provide a sbt script that download the proper version, \nsee https://github.com/twitter/finagle/blob/master/sbt)\n. I would write something like that:\n\"\"\"\nTo create a Finagle Thrift service, you just need to implement an Interface generated for Finagle by Scrooge. Scrooge is Thrift code generator similar to the standard Thrift compiler, the main difference is that the Interface expose asynchronous methods compatible with Finagle.\n- If you are using sbt to build your project, there is a plugin sbt-scrooge that will automatically compile IDL for you. Beware that Twitter has moved out from sbt, so the latest release version of this plugin is only compatible with sbt 0.11.2\n- If you are using maven, there is a maven pluggin \"maven-finagle-thrift-plugin\" that do the same thing.\n  \"\"\"\nWhat do you think?\n. The source of the maven-finagle-thrift-plugin is in the internal repo \"birdcage\" in the maven-plugins directory, we currently use the version 0.0.5\nIt seems that it is not yet open sourced, you should talk to tools team about that.\n. It would be more scala idiomatic to use the apply() method\n.codec(Http())\nLike here:\nhttps://github.com/twitter/finagle/blob/master/finagle-example/src/main/scala/com/twitter/finagle/example/http/HttpServer.scala#L78\n. ditto\n. ditto\n. ditto\n. I don't think we should have this parameter.\n. Yes I realized that after hitting enter.\nIt would be nice if we could have a consistent test without exposing this internal details, let me think about that.\n. What about passing rng as a paramter:\nrng: Random = new Random\n. I would change the type of count to Int and change the default value to 1.\n. I take my comment back, I agree with @mosesn .\n. There's no need for a Context class, you should just run the code inside Context before executing the test.\n(I think this is the cause of the test failure on TravisCI)\n. You can remove that.\n. ditto.\n. The CertChainOutput that you create at line 56 will fail because you never create this context (never execute the constructor to be precise).\nIn general, I agree with you, but here you don't share anything with the instance of Context, you're just counting on the side effect of creating an instance.\n. You read me correctly.\nThe block in the class should be ran before initializing CertChainOutput.\n. I would prefer having a standard class with members instead of default constructor arguments.\n. ditto here\n. ditto\n. I would like to see a more advanced test.\ne.g. ignore \"com.twitter.finagle.util\" and try to load all the instances of LoadServiceRandomInterface, the result Seq should be empty\n. I think I see why it doesn't work.\nWe are caching the classes meta-data per classloader, and LoadService has already scanned the classpath in a previous test.\nMaybe adding a method to flush the cache (private to the package) or setting a new Classloader would solve the problem.\n. ",
    "asrinivas": "Hey @s-garg, take a look at the recent changes to finagle-redis, @mosesn recently added a bunch of set and list commands. If you have additional commands to add, please open a new pull request. Thanks!\n. Hey @mosesn, this has been pulled internally. Thanks!\n. I just submitted a fix to our internal repo, should appear here soon\n. I have pulled this internally, should appear here soon\n. Hey Moses, I'll take a look at this today.\n. We pulled this internally, should appear here soon. Thanks!\n. Thanks for the patch! Your change should appear here soon.\n. Hey @mosesn, I just pulled this internally, the change should appear here soon. Thanks!\n. Hey @liamstewart, thanks for the PR! One suggestion, why not make zAdd take in a Seq[ZMembers] or members: ZMembers* vs the current score and member parameters? We have to create the intermediary ZMember objects anyways.\n. Fair enough. I've pulled this for internal review, should appear here soon.\n. Thanks for the PR! I have pulled this internally, should appear here soon.\n. Thanks! Pulled this internally, should appear here soon.\n. lgtm, after you address Moses' comments!\n. lgtm!\n. lgtm!\n. lgtm!\n. lgtm\n. Could you add comments in a similar style to the other functions? And could you also add some test cases in ClientSpec.scala for the new commands?\n. Thanks! For the ClientSpec, you need to have the redis binary installed for it to run\n. ",
    "mkochco": "Hi Marius,\nWhat's the status of your efforts around generalizing finagle-thrift ( i.e. finagle-rpc )?\nThanks,\nMark\n. ",
    "PatrickOsborne": "Hi @mosesn,\nWe are interested in moving forward with finagle-protobuf and we have some bandwidth to make it happen.  One of our biggest motivators is a desire to utilize zipkin for distributed tracing of our finagle protobuf services.   I've taken a look at the mux transport and it appears to provide the tracing support we desire.  Is there a simple example, or maybe some tests, that show a simple implementation on top of the mux transport?  Any help would be much appreciated.\nThanks,\nPatrick\n. Thanks for the responses.  The mux protocol documentation has been helpful.\nI've been making a bit of progress sorting out the thriftmux implementation and what a protobuf implementation may look like.\nI have a question about ClientBuilder and ServerBuilder, are those classes intended only for non-mux implementations?  or am I missing something there.   Is there a similar mux mechanism to config the clients and servers?\nThanks,\nPatrick\n. Thanks, the FAQs are very helpful.\nWhat about adding a tracer to client and/or server?  We are in need of distributed tracing and our hoping to use Zipkin in that effort with the new protobuf built on mux.\n-- Patrick\n. Our company has tried to push our version back to Finagle but we got some pushback because it was not built on the mux transport (which wasn't complete at the time).  So other than building the functionality yourself, you may need to wait till we get our new version complete and pushed back to the open source community.\nIf you have some experience with protoc plugins for generating Java code that would be very useful to producing a canonical Finagle / Protobuf interface.  See my post on the protobuf google group here:\nhttps://groups.google.com/forum/#!topic/protobuf/fnKqCcT9NXo\nCheers,\nPatrick\n. Hi All,\nI have built a basic protobuf implementation on the mux transport and it turned out to be fairly easy using thriftmux for some inspiration.\nI'm now working on getting the tracing to work with the new implementation.  I have added Tracers to the DefaultClient and DefaultServer created with the mux transporter but the service name and method name aren't filled in.  So it looks like I need to call something like: \nTrace.recordRpcname(serviceName, methodName)\nafter the TracingFilter executes and pushes the Tracer and sets up the trace id.  But I'm not sure how best to insert this call into client and server instances.\nI've read through much of the thriftmux implementation and I have been unable to find how it is done there.  Is thriftmux recording the service name and method name somehow that I am missing?\nIt does look like in the DefaultServer the 'prepare' field (ServiceFactory) could be used to record the rpc information.  Is that correct?  Or is there a better place to do that?\nOn the client side, I haven't found some sort of hook to use yet.  Is there something in DefaultClient I can use?  or maybe the ClientDispatcher?\nThanks for the help,\nPatrick.\n. Thanks for the quick response.\nMy thinking is that the mux transport has no way of knowing what the service name and method name should be.  So that is why I was looking for some sort of hook in the client and server to provide the information.\nAlso on a side note, I've been looking at thriftmux and the fact that the client and server builders aren't compatible with mux and I'm starting to wonder if anyone has used the mux transport in production.\nIs mux just experimental at this point or is it production ready?\nThanks again,\nPatrick\n. Thanks Marius.  I understand not using the builders with the new protocols.  In the meantime I've passed the tracer into the default client and server.\nThe driver behind us moving the protobuf implementation to mux is so that we can hook up Zipkin for distributed tracing in production.  So I have two primary concerns:\n- getting the tracing working with the service and method names\n- and knowing that the mux transport is production ready\nDo you have some thoughts on that?\nThanks,\nPatrick\n. Great.  Thanks for the info.  If I can help with the mux code let me know.\nI'm working on integrating the protobuf mux implementation with our existing services to see how the implementation shakes out.  I'll let you know if I see any other issues.\n. Hi @bmdhacks, \nDo you have an update on the rpc service name and method name issue with the mux transport?  \nShould I open an issue?\nThanks,\nPatrick\n. Is there an update on the mux tracing issue?  Should I open an issue?\nThanks,\nPatrick\n. what is the timeframe for the tracing fix?\n-- Patrick\n. using sbt to build is fine, but it would be nice to have the parent POM when I'm reading the code through my IDE.\n. ",
    "bmdhacks": "Not so much.  Mux is still pretty new in Finagle.  The only current\nimplementation is thriftmux.  I agree though that protobuf+mux would be an\nextremely useful protocol.\nOn Wed, Mar 19, 2014 at 8:40 AM, Patrick Osborne\nnotifications@github.comwrote:\n\nHi @mosesn https://github.com/mosesn,\nWe are interested in moving forward with finagle-protobuf and we have some\nbandwidth to make it happen. One of our biggest motivators is a desire to\nutilize zipkin for distributed tracing of our finagle protobuf services.\nI've taken a look at the mux transport and it appears to provide the\ntracing support we desire. Is there a simple example, or maybe some tests,\nthat show a simple implementation on top of the mux transport? Any help\nwould be much appreciated.\nThanks,\nPatrick\n\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/91#issuecomment-38065964\n.\n. That being said, you might look at the api docs:\nhttp://twitter.github.io/finagle/docs/#com.twitter.finagle.mux.package\n\nOn Wed, Mar 19, 2014 at 10:14 AM, Brian Degenhardt bmd@twitter.com wrote:\n\nNot so much.  Mux is still pretty new in Finagle.  The only current\nimplementation is thriftmux.  I agree though that protobuf+mux would be an\nextremely useful protocol.\nOn Wed, Mar 19, 2014 at 8:40 AM, Patrick Osborne <notifications@github.com\n\nwrote:\nHi @mosesn https://github.com/mosesn,\nWe are interested in moving forward with finagle-protobuf and we have\nsome bandwidth to make it happen. One of our biggest motivators is a desire\nto utilize zipkin for distributed tracing of our finagle protobuf services.\nI've taken a look at the mux transport and it appears to provide the\ntracing support we desire. Is there a simple example, or maybe some tests,\nthat show a simple implementation on top of the mux transport? Any help\nwould be much appreciated.\nThanks,\nPatrick\n\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/91#issuecomment-38065964\n.\n. I'm willing to bet that recordRpcname is not called in mux and that's a bug.  Lemme look into it some more.\n. Both of these issues are huge focusses for the finagle team at twitter, and we're actively responding to any issues that arise with them.  I'm not promising it's all bug-free, but we're extra-responsive on this stuff this quarter.  You're on the cutting edge, but I don't think you're too experimental to be in production.\n. It's fixed internally, we're just working on getting a release out with the code.\n. We'll have something up within a week\n. Ok, the mux tracing fix is now pushed\n. We're about to remove all poms from finagle and only have sbt for building.  Maintaining three build systems is not sustainable.\n. What about making the twitter bird a cog, surrounded by three gears that mesh with it?\nTake the twitter logo imposed on a radial plane.  Then re-project it to a flat projection, find the inverse, map back to radial and you get a gear that fits the bird.\n. It's on our list of things to do, but we haven't committed it to the schedule.\n. There's some trickiness with the backport of http headers from netty 4 that collides with our headers map in finagle.  If you want to take a look at it, we'd appreciate it.\n. Thanks for the submission.  We're testing this along with upgrading to 0.12.3 right now and will keep you posted when we commit.\n. Thanks, we just pushed finagle 6.10.0 so it might take a while to see it in github, but I committed it to our internal repo.\n. Woah, sorry for the lag.  Lemme work on this.\n. This is committed internally.  We're working on getting a release out soon which will push the change to github.  Thanks!\n. Thanks for the submission!\n. It's merged internally and will be in our next push.\n. Wouldn't the whole bundle get cleaned up when the DefaultClient is non-reachable from gc roots?\n. I don't think you need to finalize them because the close trait is just an interface, we don't actually have open OS handles that really need closing.  But hey, if you have a heap dump that proves me wrong, that's cool.  I'm pretty sure though that the whole nest of Name+DefaultClient will go away when the client is closed/gc'd\n. https://gist.github.com/bmdhacks/3100043c69478b9f7c57\n\n\nThis should fix it.  I'm working on getting this into our internal repo and it should be published shortly.\n. Thanks for the contribution!  Looking this over now...\n. This is committed internally, should be mirrored to github in a day or two\n. pulled internally but just missed the 6.15.0 release\n. This is amazing!  Give us a week or so to merge it, but we love this!\n. Yeah, it looks like nobody has complained about the breaking change of TestLogger but I still have to go fix all the usages of it in the twitter codebase before I can commit this.  I'm hoping to get some time this week to do that, I'll keep you posted thanks!\n. Oh, sorry, I thought I was commenting on the util PR.  Let me work on this.\n. Nope I've done it.  Still working on getting this to pass twitter internal unit tests... gimme a few days.  Thanks for your patience.\n. LGTM, having a missing Host header violates HTTP 1.1 anyways, so this is more than just Apache Proxy Server.\n. lgtm but we might get interesting results if somebody tries to publish a local copy\n. This is committed internally and should be mirrored to github sometime this week.  Thanks for the PR!\n. This is an excellent pull-ask\n. ",
    "roanta": "The builders aren't compatible with mux, but we're working on making them more general so that should change in the near future. However, a lot of the current builder knobs become meaningless with protocols like mux [1]. Because of this, the new apis were designed to a be a bit more rigid and protocol implementors are expected to provide sensible defaults (ex. [2]). \n[1] http://twitter.github.io/finagle/guide/FAQ.html#mux-specific-faq\n[2] http://twitter.github.io/finagle/guide/FAQ.html#how-do-i-change-my-timeouts-in-the-finagle-6-apis\n. I've pulled this in along with https://github.com/twitter/finagle/pull/154. Should sync into the public repo shortly. Thanks!\n. Should be available in the public repo soon. Thanks!\n. Are all session variables set via a \"SET key=value\" query? If so, I think it would be better to take a map containing session vars rather than a function.\n. Okay, that makes sense. I am currently working on moving the mysql client to use the finagle 6 api and I suspect that it will change the implementation of this. I'll get back to you on this soon.\n. It should be auto generated, but It seems that we are missing the resource generator for this in sbt. I'll look into adding this.\n. Sorry for the delay, this seems reasonable to me. I'll pull it internally.\n. Thanks for pointing this out. Unfortunately, the jars are already published. We will make sure we adhere closer to semver in the future.\n. According to the mysql documentation[1], values for TIMESTAMP columns are converted from your mysql server time_zone to UTC for storage and from UTC to the time_zone for retrieval.\n[1] http://dev.mysql.com/doc/refman/5.5/en/time-zone-support.html\n. Okay, so it seems the issue is that the java.sql.Timestamp object doesn't encode a timezone and finagle-mysql is using a Calendar object, which does assume a timezone, to serialize the Timestamp.\nTry setting your timezone using java.util.TimeZone#setDefault.\n. The serialization happens behind the scenes and isn't exposed, I think this is best. You're probably right though, we might want more granular control here. Maybe Timezones can be encoded with a Timestamp into a new composed object.\n. I'm not sure this is the direction I would go with this. If you are convinced that connection level granularity for timezones is what we want, I think a better approach would be to auto-negotiate the timezone when a connection is established.\nAlso, I don't want to associate the Client with one connection, even though it is the case now, this is something that will likely change. We actually have a PR internally that changes the Client (and would be incompatible with this change). Do you mind if we revisit this later?\n. Hey Eric, I was looking over this patch and trying to reason about the api. How would a user interact with the abort broker? The ReadHandle interface doesn't expose a method to do so. What am I missing?\n. Ah, right. Thanks for the clarification.\n. Sorry, this fell off our radar! Thanks for checking up. It's currently in review process internally, and we're waiting for some more feedback before merging it in. We'll keep you updated.\n. Doesn't seem related to this patch.\n. Thanks Greg, I pulled this internally should sync with the public repo soon.\n. merged internally, should sync up here next release.\n. After chatting with @sprsquish, I think we should thread through the service name in the filter and use it for tracing.\n@sonnes Would mind updating the pr?\n. It looks like this patch is slightly out of sync with our internal master. Let's temporarily put this on hold until next week when we will likely sync github with our internal repo.\n. LGTM\n. lgtm\n. This landed in https://github.com/twitter/finagle/commit/18a8387e6c1157595c77447f9942e46fed39c8a3\n. lgtm!\n. Thanks for the PR! This is very cool!\n@mosesn I haven't tried it out, but I'm under the impression that this change should be transparent and the translation from Any => Parameter should \"just work\". At least the changes to the unit tests suggest this.\nre: java API. The original API isn't very Java friendly to begin with. We could always offer a parallel java API that passes the implicits explicitly. I think the type safety is definitely worth the compromise.\n. Just some minor nits, this looks great to me! I think we should pull it in.\n\nFor example, we might know that we need a String, an Int, and a Boolean\n\n@mosesn That information is only available at runtime. I think this is the best we can do with the info we have. We would need some sort of schema annotation along with code gen to do what your describing at compile time.\n. I see, annotating at the prepare call site may be enough. I agree with @missingfaktor that we should pursue this incrementally and this is a good first step.\n@missingfaktor re: the variance annotation. Can we instead expand the CanBeParameter[Value] into separate instance of CanBeParameter? I really think this is more correct (both for Value and other parameter types moving forward).\n. @missingfaktor I don't see any good reason to hide the representation of Value. It's not really an ADT; there's nothing abstract about it. We can't do anything interesting without exposing it's representations. But maybe I'm missing something.\nSupport Option[_] seems like a good idea, but are you sure that -A will give us what we want?\n```\nscala> trait CanBeParameter[-A]\ndefined trait CanBeParameter\nscala> def wrapA: CanBeParameter = ???\nwrap: A(implicit evidence$1: CanBeParameter[A])Nothing\nscala> implicit val stringCanBe = new CanBeParameter[String] {}\nstringCanBe: CanBeParameter[String] = $anon$1@4f913b29\nscala> wrap(\"hello\")\nscala.NotImplementedError: an implementation is missing\n...\nscala> wrap(Some(\"hello\"))\n:11: error: could not find implicit value for evidence parameter of type \nCanBeParameter[Some[String]]\n          wrap(Some(\"hello\"))\n``\n. I see, that's neat! Unless anyone else has anymore comments, I'll work to pull this in this week.\n. We merged this internally, it should show up in thedevelop` branch shortly!\nNote: We added  def unsafeWrap(value: Any): Parameter to the Parameter companion object to ease migration for some of our services. They had rich wrappers around finagle-mysql that required changing their types all the way through. I imagine this might help others with the migration too.\n. Unfortunately, we just missed the 6.25 release. I don't have an exact ETA when we will do the next release, but we're trying to release more frequently.\nre: unsafeWrap it just pattern matches on the value and preserves the previous behavior where unknown params are logged and written as sql null. \n. I would say it's production ready; we have teams using it in production at twitter.\nWhat kind of difficulties have you guys run into? Is it mostly related to the bare API?\n. I think this should be configurable via the Balancers object now.\nhttps://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/loadbalancer/Balancers.scala#L117\n. Thanks for the patch @timxzl \u2013 it was merged: https://github.com/twitter/finagle/commit/18a8387e6c1157595c77447f9942e46fed39c8a3\n. @olix0r The problem statement doesn't explain why/how this would be useful. Can you please add more details about the motivation for this?\n. @olix0r cool, this seems like a nice patch.\n. Hey, sorry about the regression.\nCan you try the following and let me know if it fixes your issue:\n```\nimport com.twitter.finagle.loadbalancer.ConcurrentLoadBalancerFactory\nval redisClient = Redis.client\n   .configured(ConcurrentLoadBalancerFactory.Param(numConnections = 1))\n   .newRichClient(address)\n```\n. Thanks! A silly mistake on our part. I'll push a patch through and it should be fixed in the next release.\n. Ship it!\n. The reader is driven by the writer, but as Moses pointed out it's all async. I suspect you are perceiving a deadlock because you aren't closing the writer which signals an EOF for the response. Here is some example code that imitates the arrangement in http server dispatcher: https://gist.github.com/roanta/f148a81a7ae53b73ea3c\nSorry that we don't have better docs for this!\n. Thanks for the PR Steve! I'll pull this in internally.\n. How did you test this btw? Do you think it's feasible to add a unit test?\n. LGTM\n. Just a minor nit, otherwise LGTM. Thanks so much for the great contribution!\n. Nice! Thanks for taking the time to do this. \nLGTM, just a few questions.\n. The referenced patch should actually fix the issue you're describing, it was a bug in 6.33.0. Please try to upgrade to 6.34.0 which contains this fix.\n. I agree with @vkostyukov, why can't we build this on top of a client using the ServiceFactory API? That's the intended use case.\n. Thanks! This was merged and landed: https://github.com/twitter/finagle/commit/989edc58084fa01b6e6557ff5b6adda594ba469f\n. Thanks @olix0r! This was merged and landed in https://github.com/twitter/finagle/commit/ce4ab7ffd917104efe333b58d1409df00aa4b408\n. Does ConnectionManager affect the status of the respective Service? Could there be a race where the Service is put back in the connection pool and reused before ConnectionManager closes the connection?\n. @olix0r nice sleuthing.\nOne thing to consider is that this (and the n3 impl) rely on the implementation details of the scheduler to ensure that the closures are ordered correctly. @dschobel and I were looking into this and we agreed that it might be nice to explore doing away with DelayedReleaseService and reconciling outstanding streams in the pool. We could change the status of the service to Busy via ConnectionManager and defer on the decision to close or put it back into the pool until it changes. This would be a bigger change, but I think it would make the code much easier to understand and reason about. If it's not something you're interested in exploring, I'm okay with the scheduler coupling since its effectively what we had before.\n. @olix0r that works for me. I'll work towards pulling in #518. Thanks again for digging into this.\n. @maheshkelkar Thanks for the detailed bug report! I think you're right and we should transition to ProbeClosed in onServiceAcquisitionFailure. Would you like to submit at PR for this?\n. FailureAccrualFactory and FailFastFactory both operate per session, so there should be one instance per memcached host that your client talks to. Your observations sound like correct behavior to me given the respective hosts are actually down and your client has concurrent requests.\n. > Are you suggesting that we have 1 FailureAccrualFactory per thread? i.e. we have a session per thread?\nNot per-thread, Finagle multiplexes sessions over threads. Each session that your client connects to gets a new FailureAccrualFactory or FailFastFactory (if enabled). Take a look at http://twitter.github.io/finagle/guide/Clients.html -- the branching after the load balancer represents the per-sessions stack.\n\nI see 4 FailureAccrualFactory instances for localhost:11212, whether I configure FailFastFactory or not.\n\nWhere are you seeing four? You might want to see how many nodes the client's load balancer sees, it should help clarify: https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/loadbalancer/Balancer.scala#L97. One thing to note is that \"localhost\" can resolve to multiple network interfaces which are treated as separate endpoints by the client.\n\nwhy don't I see this on the very first attempt, when all 10 ops goto active node localhost:11211\n\nI'm not sure I understand what you mean. What behavior are you referring to?\n\nwhy do we not use auto-triggering for probing, instead of wasting a request\n\nWe have circuit breakers in Finagle that work out-of-band of requests, but they require protocol support (e.g. https://github.com/twitter/finagle/blob/develop/finagle-mux/src/main/scala/com/twitter/finagle/mux/ThresholdFailureDetector.scala). FailureAccrualFactory is designed to be protocol agnostic and in-band with requests which has its advantages.\n\nif we fail the request, why not attept it again over the different memcached node (I wonder if this can be controlled by retry)\n\nThis is generally the behavior with other Finagle clients (the load balancer guarantees to avoid Busy nodes). However, the memcached is special client that is partitioned so Finagle doesn't have as much freedom (https://github.com/twitter/finagle/blob/develop/finagle-memcached/src/main/scala/com/twitter/finagle/Memcached.scala#L82-L87).\n. I see what's happening here. We replicate, and load balance over, a single endpoint to avoid head-of-line blocking when we pipeline memcached [1]. The problem is that we create a FailureAccrualFactory for each replica even though they share the same endpoint address. This would definitely make it less effective. Try setting the parameter connectionsPerEndpoint to 1 to verify we get the behavior we want w.r.t to FailureAccrualFactory [2].\nI'm not yet sure what the appropriate fix is for this, let me think about it a bit more. In the meantime, let's fix the probe state issue since its orthogonal.\n[1] https://github.com/twitter/finagle/blob/develop/finagle-memcached/src/main/scala/com/twitter/finagle/Memcached.scala#L187-L196\n[2] https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/param/ConcurrentLoadBalancingParams.scala#L28\n. lgtm! It will show up in the develop branch after we merge it in internally. Our release cadence isn't set in stone, but I would estimate that the next release will be in a month or so.\nThanks again for the contribution!\n. Yes, we'll make sure it gets in before the next release. Thanks!\n. Something to note is that the client stack already attempts to avoid nodes that are performing poorly relative the rest of the server set. It does this via prioritizing the least latent endpoints and via circuit breakers. Have you found both of those mechanism to be insufficient in these cases? Maybe you can try to tune the circuit breakers to be more aggressive. For example, failure accrual can now keep track of a target SR and close the circuit when it is out of SLA.. The SR failure accrual policy [1][2] is still experimental, so there isn't a with* style API for it. Instead, you have to use configured on the client:\n$protocol.client\n   .configured(FailureAccrualFactory.Param(FailureAccrualPolicy.successRate(...)))\nYou can also configure a response classifier [3] to take into account responses that look successful to finagle (i.e. are a Return), but really represent an application failure. This should help with the issue you described where the load balancer favors hosts that respond quickly with failures.\n[1] https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/service/FailureAccrualFactory.scala#L129\n[2] https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/service/exp/FailureAccrualPolicy.scala#L122\n[3] https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/param/CommonParams.scala#L46\n. The reason it's initially set to 1 is because the finagle client uses close to signal the release of a session/connection. This allows the underlying pool implementations to interpret it and act accordingly.\nFor example, a common [1] way to use a client:\nclient().flatMap { service => \n   service(req).ensure { \n       service.close() \n   }\n}\nIf the close here would actually tear down the session, the client would churn through resources.\n[1] https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/Service.scala#L293-L310 . The additional close is more likely to come from tearing down the client entirely (i.e. calling close on the client):\nhttps://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/pool/SingletonPool.scala#L187-L188. This means that your client is interrupting requests (usually because timeouts are triggering) and the interrupt is propagating to the server [1].\n[1] https://twitter.github.io/finagle/guide/FAQ.html#what-are-cancelledrequestexception-and-cancelledconnectionexception. Hi @komsit37! Thanks for the detailed report and repro.\nIt seems to me that a reasonable solution would be to move the creation of those stats inside the cursor method (specifically, as part of the CursoredStatement instance). Would you be interested in providing a patch for this?. For prepared queries, the '?' are just expanded and the replacement happens on the server. This allows for calling prepare(\"select * from table where id in (?)\", 1 to 10) as opposed to prepare(\"select * from table where id in (?,?,?,?...\", 1 to 10)\nFor regular queries, the parameters have to be replaced. This also allows for cleaner client apis that don't require StringBuilders and String concatenation to build a sql statement.\n. In some cases, they are not separable. I don't think it would be a problem to conflate them especially since the encoder is so simple.\n. I was wondering where all the set* methods went for Dates. I'll change these methods to use Calendar instead.\n. Is this also the same as server_language sent during handshaking?\n. Yes, this can be solved by precomputing the size the parameters will take and using 1 buffer writer. This would eliminate the copying and the object creation.\nIn retrospect, I am not sure how I reasoned that all this object creation was okay.\n. As in, a rogue library that has a malicious toString method?\nWe can completely remove it but the problem of sql injection is still there if the a user builds their own sql statement.\n. Agreed. I visited the idea of having this just wrap a netty ChannelBuffer, but I remember running into a lot of issues. It could have been my lack of experience of working with netty Buffers / nio Buffers.\n. That makes sense. I agree it would need more work to be more robust and safe. But if you don't think it is worth having we can scrap it and let the user explicitly build the queries. \n. I wanted to leave room for different implementations.\n. case class it is.\n. Why is it so important to make private members private to the instance?\nAlso, my reasoning for the lazy val here was allowing the creating of a client without doing the connection leg work until the user actually used the client. A replacement for having an explicit 'connect()' method. \n. I read the spec wrong. This of course managed to work because I haven't dealt with string lengths that don't fit into a unsigned byte. I'll fix it to use the length coded binary.\n. Is there an upper bound on the length of a string? Can I assume that the size will never need to be represented with 8 bytes?\n. I need to find a better way to represent corrupt data. From what I understand, it isn't idiomatic to throw exceptions that are not future encoded within Finagle.\n. I've implemented your suggestions. Removing the noise caused by wrapping the sets in Option[...] and not passing around the decoder in the Defragging class cleaned up the code a lot.\nThe changes actually reduced the amount of cases by 1, but I think it did result in more understandable code. \n. It seems like the SQL Time type is more accurately represented by a duration because time can also be negative. Unless I am missing something, the current Connector/J driver does not support negative Time. It will throw a SQLException if you try to getTime with a negative time value in the database because it uses java.sql.Time to represent SQL Time.\nEDIT: java.sql.Time also doesn't support hour values greater than 24.\nIs this behavior we want to mimic? Or are we actually interested in negative Time values?\n. There are several reason why I thought it would be better to wrap ChannelBuffer and provide a separate interface.\n1. Each time a user intends to read from a MySQL packet, a ChannelBuffer needs to be created with the correct ByteOrder. It just seemed more naturally to offer an interface specific to the codec that assures this.\n2. There are specific methods that a ChannelBuffer doesn't offer and are at the core of the protocol (readLengthCodedString/Bytes and writeLengthCodedString/Bytes). This could have easily been offered as a method in a an object ex. Buffer.readLengthCodedString(c: ChannelBuffer). Again, I thought it would be more naturally to provide this as part of an interface.\n. try something like:\nVar.async[Addr](Addr.Bound(parseHosts)) { u =>\n  timer.schedule(...) { \n    futurePool(parseHosts) onSuccess { addrs =>\n      u() = Addr.Bound(addrs)\n    } onFailure { ... }\n  }\n}\n. @jixu This was part of InetSocketAddressUtil.parseHosts as a special case to allow servers to use ephemeral ports with the \":*\" syntax. It's not needed for clients.\n. I'm not sure we should have the variance either. Even if we have a X <: Y relationship, we should still be forced to think about how that serializes into a Parameter (e.g. sizeOf, typeCode, etc. are likely to be different).\n. It probably wasn't the best idea to derive the blob type from the size of the array, but we should revisit this separately. I think retaining current behavior is a good idea!\n@mosesn The blobs are length encoded, but they still need to match your schema. I suspect mysql will complain otherwise.\n. Some scaladoc that briefly explains what Parameter is would be nice. Note, that all usage of Parameter should be via CanBeParameter.\n. Would it make sense to seal this? Or is it not possible because we instantiate it anonymously in wrap?\n. style nit: our scaladoc blocks are closed with */ instead of **/\n. style nit, drop params to new line:\ndef apply(\n   stmtId: Int,\n   ...\n): ExecuteRequest = ...\n. As @mosesn mentioned, we recently added this internally and it's available as part of the develop branch.\nNote though, this may have surprising results. Because of how the mysql client operates on the this ServiceFactory you aren't guaranteed exclusivity to this Service (i.e. connection in this case). You need to override the Service#close method to completely control its lifecycle. Take a look at how we implemented it in the develop branch.\n. It seems like we've dropped this behavior? Do we need to lift exceptions in build to Futures?\n. It's not really relevant if this is between data centers or not. I'm not sure if it was, looking at some notes from steve gury who collected the data, it just says \"distribution of ping latency on some remote server\". If we want more control over the distribution we can eventually synthesize the latency in Simulation to fit a pre-defined distribution.\n. I think Moses is referring to a few systems that want to optimize for equity (and have other means of detecting and mitigating the effects of unhealthy nodes). Although I don't think we need round-robin for that. We could use P2C with a constant cost per-node. I would actually vote for keeping this here.\n. The only benefit is having fewer implementations to maintain. I'd just prefer waiting to promote it into core until we are sure that it solves the use cases you have in mind.\n. Sounds good to me if @stevej is up for it.\n. latency or endpoint status.\n. whoops, just saw that you added it to the implementation.\n. why do we need to rebuild if we find a down node?\n. How so? Seems correct to me.\n. I think it's vestigial from when the balancers supported weights.\n. Yes, the status != open node will still be in the list as written. Rebuild only signals to the Balancer trait to schedule a call to your distributors rebuild method (with the same nodes). It is effectively like calling new Distributor(vector) but it is serialized with other updates from the dynamic Activity[Seq[Nodes]].\nWe should do something similar to what we do in P2C. Partition the nodes into up and down and rebuild if you see a down node in up or a node has recovered in down. If we need to, we should be able to maintain a consistent ring across rebuilds by sorting the nodes via the token field. \n. Let's split this up, it makes it clearer and easier to debug:\nval probeStat = statsReceiver.counters.get(List(\"probes\"))\nassert(probeStat.isDefined && probeStat.get >= 1)\n. This comment isn't giving the reader any additional information, I think we can drop it.\n. \"The result of the subsequent request will determine...\"\n. Is this used?\n. is this unused?. I like them explicit too, tbh.. do we still need this case? I think the Distributor should just do the right thing.. Are we sure this is getting rid of (or calling close on) the empty balancer? Can we validate this by adding a hook to the Balancer close method in Ctx?. ",
    "justinrmiller": "So what's the best option for protobufs w/finagle at the moment?\nThanks,\nJustin\n. Ah thanks for the response. Funny thing, I run into this problem locally (OS X, Mavericks, 10.9) but not when I deploy it to a linux vm, so I figure it's just a configuration issue. I can hit ~6k requests per second for minutes and it runs just fine.\nI'm not really doing any blocking in an IO sense, but I am doing a model computation (scoring) that can take up to 50 ms (generally) to 250 ms (worst case). \nI can't paste or upload any code as it's closed source for now (the model scoring code) but I can probably open source the core of the service itself and include a sleep in the request for the same period of time it takes to score.\n. Gist of jstack output from process after it's reached ~16384 requests: https://gist.github.com/justinrmiller/9902480\n. After testing this out on a few linux instances, I'm pretty sure this is an OS X config issue. I do 90% of my development under OS X and run everything on Linux VMs, so not being able to load test locally (over 16k/requests in a short period), isn't a big deal. I'm going to go ahead and close this, if you guys want me to investigate further feel free to re-open and I'll try to get more debugging data, etc.\n. ",
    "travisbrown": "For the record, after a conversation with @chrisphelps yesterday I rebased this PR against develop and split finagle-protobuf out into its own project in the Finagle org. It's likely that we'll remove the subproject from this repository, and once that happens I'll close this PR.\n. finagle-protobuf is now a stand-alone project in the Finagle organization and has been removed as a subproject here.\n. Hi @abbaspour\u2014see this Finagle blog post for a much more up-to-date and detailed outline of the upgrade plan.\n. Now published to GitHub.\n. Now published to GitHub.\n. I'm not sure we need tooling for this, but maybe it could go on a release checklist.\nYou're right, though\u2014we need a better solution for keeping versions in documentation up to date. I've changed this starter issue to include only the GitHub URL change, which is a one-time fix. \n. Yes\u2014this commit fixes the version updating issue, and this PR fixes the domain name (but still needs to be pulled internally; I'm taking care of that now).\n. Yep, just shipit-ed\u2014thanks @dschobel.\n. Fixed by #338 (thanks, @bmckown, @vkostyukov).\n. Fixed in #300 (committed here).\n. Yep, but we can filter hosts in the analytics interface, so I'm not too worried about it (for example for Pants this tracking code isn't in the theme, so we're actually tracking both internal and GitHub-hosted traffic).\nIt may also be the case that the new Google Analytics script does this filtering for us, since you now specify the host\u2014I haven't confirmed yet.\n. It's a Twitter OSS account (also used for other GitHub Pages sites). I'll be incorporating stats into the new monthly Finagle reports, and you can let me know if you'd like more detail.\n. Now published to GitHub.\n. I had to install manually on both a new MPB and a personal machine running Arch, so I figured it was worth pointing out. I'll check on if / when sbt-site should do the install automatically and add a note about that if necessary.\n. Now published to GitHub.\n. We're thinking of this list as only for confirmed uses of Finagle in production\u2014I'll check with Fl\u00e1vio and see if his organization fits in that category.\nWe're also planning to revamp the \"related projects\" list\u2014where Activate definitely belongs\u2014but that work is a little less urgent than getting the adopters list up, and will be part of an upcoming round of doc restructuring across Util and a couple of other projects.\n. Now published to GitHub.\n. Now on GitHub\u2014thanks, @jixu (and everyone else for review)!\n. Now in develop (see also #331).\n. This is now on GitHub\u2014thanks, @zhangxiao!\n. This is now on GitHub!\n. @dnatic09 I'll post an update today.\n. I'm sorry for the delays\u2014there are some complications and other things keep coming up that make it difficult to make this a priority. I can promise to spend some time with it this week.\nfinagle-core and finagle-thrift at least only need a few small changes and it should be possible to publish 2.11 builds with the next Finagle release. A couple of other subprojects will take longer (e.g. finagle-ostrich), and the rest are somewhere in the middle. Are there particular subprojects that are priorities for you, @c089?\n. Okay, quick update\u2014we're planning a release of Finagle and associated projects this week with 2.11 builds for twitter-server and all but five Finagle subprojects (finagle-redis and the ones that depend on Ostrich).\nI've got Finatra running on 2.11 locally, and the necessary changes are pretty small, but I can't promise when they'll be available in a release.\n. Another update: the changes that allow us to publish 2.11 builds for almost everything (not finagle-redis, finagle-ostrich4, finagle-stress, or finagle-example) have been merged internally, but they made it in too late yesterday for us to get a release out.\nI'm waiting on review for additional changes that will allow us to publish util-eval, scala-json, ostrich, finagle-ostrich4, and finagle-stress for 2.11, but all tests are passing and there's no ABI breakage, so it shouldn't be too long.  Thanks much to @rlazoti for the Ostrich test migration work that made this part much easier than it would have been otherwise.\n. In case you missed it: 2.11 builds were published last week for everything but finagle-redis, finagle-ostrich4, finagle-stress, and finagle-example. I'm working on pushing these stragglers through this week, but they may not be available until after the holidays (I'll close this issue when they're out). There's also some initial work by @c089 here on putting together a 2.11 release for Finatra.\nThanks to everyone who put in so much work to make this possible (and thanks to everyone in general for your patience)!\n. Quick note: it's now possible to build finagle-ostrich4 locally for 2.11 by running +publish-local on the develop branches of util, ostrich, and finagle (in that order). Releases are coming soon, but I don't have a definite timeline yet.\n. Hi @hgfischer. Most subprojects have been published for 2.11, and everything except finagle-redis is available in the develop branch, which means they've been updated internally and will be available in the next release. finagle-redis is done but is not yet merged internally (it's a big changeset).\n. @dnatic09 Yep, Ostrich has been updated for 2.11 internally and is just waiting for the next release.\n. @beenokle The migration to ScalaTest is done and is available in the develop branch, and finagle-redis_2.11 will be in the next release (which is likely to be out this week or next).\n. This is now on GitHub\u2014thanks, Adam!\n. Thanks, Kevin\u2014beat me to this. Would you also want to add a link to any blog posts that mention how you're using Finagle? This is the one I know of.\n. This is now on GitHub. Thanks, @stantonk!\n. Now on GitHub.\n. Now on GitHub\u2014thanks, @rlazoti!\n. Now on GitHub, thanks @soboko!\n. Now on GitHub.\n. Now on GitHub, thanks @jbripley!\n. Now on GitHub.\n. If we used .. parsed-literal:: and embedded the build files directly in the RST source instead of importing we could use the |version| substitution here instead of having to keep track of updating it manually with each release.\nI understand why we use .. includecode:: for Scala code, but these files are small enough and keeping them in sync (or letting them get stale) is annoying enough that I think there's a case for plopping them right in the documentation.\n. Small correction: I just tried this and we'd want |release| instead of |version|, since for some reason the latter is 6.20, not 6.20.0.\n. @financeCoding Thanks! We'll need .. parsed-literal:: instead of just ::, though, since the substitution won't be processed in an ordinary code block. Let's wait to see about what the rest of the team says, though\u2014we might just go with your original correction.\nThanks also for noticing this in the first place!\n. @financeCoding Great, thanks. I'm checking now to make sure we can make this work with our internal documentation system\u2014I'll keep you posted.\n. Hey @financeCoding, it turns out that getting our internal documentation system to pass in the version info in the same way as sbt-site is a little tricky, and it doesn't really make sense to pull in your original fix, since by the time it's synced back to here (i.e. with the next release) it'll be out of date again.\nSorry about the run-around on this, and thanks for bringing it to our attention! I'm closing this PR but I've created an internal issue, and we'll get it fixed in the next release.\n. Now on GitHub, thanks again @bpfoster!\n. This is up! Thanks again, @p-antoine, this is awesome.\n. This is now on GitHub\u2014thanks again, @bajohns!\n. Fixed in #312 (committed here).\n. LGTM :thumbsup:\n. Thanks, @chrisphelps\u2014this has been merged internally and will be up here soon.\n. This is now on GitHub, thanks again!\n. This is now on GitHub. Thanks again, @andi5!\n. This is merged internally and will show up here with the next release. Thanks, @vargasbo!\n. This is up now!\n. :+1:, thanks @jbripley!\n. This has been merged internally and will show up here soon. Thanks again, @jbripley!\n. Ah, actually this is up now!\n. This has been merged internally and will be up before too long.\n. This has arrived\u2014thanks, @azenkov!\n. See build results here.\n. Now up.\n. Thanks much @rodrigopr! (and here's some context for everyone else).\n. Take a look at this recent Finaglers thread. fetchUrl doesn't currently support HTTPS, and Http.fetchUrl(\"https://...\") isn't ever likely to work (you'll need something like .client.withTls(...)\u2014which will work now, although not with the handy fetchUrl method), so this is a bug in the documentation.\n. I've just created a reminder to myself (#324) that the FAQ needs to be edited, and since that issue is more specific about the problem, I'd vote for closing this one. Thanks for catching this, @dlwh.\n. Thanks, @penland365!\n. I'll be pulling this in for internal testing and some more review, but any comments are welcome.\n. Superseded by #331.\n. This is #330 rebased and PR'd against develop.\n. Now in develop.\n. I thought we decided no punctuation on the \"Problem\" / \"Solution\" / \"Result\" headers in the commit message? Please consult CONTRIBUTING.md in the future @olix0r.\n. The entire Finagle team set aside today to discuss this change, and after a lot of debate we've decided to close this PR as wont-fix. Sorry @olix0r. If you feel the need to create a more pragmatically-focused Finagle fork, we can talk about whether the Finagle organization would be an appropriate place to host it.\n. Thanks @takei-shg! This is great to see!\n. Now available in the develop branch!\n. :+1:, thanks! Will be pulling this internally today.\n. Now in the develop branch.\n. Hi, @csaltos\u2014it's great to see this, and thanks also for the examples you've been working on. I'll be pulling this internally today, but we'd also love to hear more about how you're using Finagle at Talenteca.\n. Now in the develop branch.\n. For reference, this change is being discussed on Finaglers. Thanks @spockz!\n. (Note that in general it's best to submit pull requests against the develop branch, but in this case it's not a big deal.)\n. @spockz Ah, sorry!\u2014thought that had been updated, but now that you mention it it may have just been discussed in this announcement. We'll get it fixed asap.\n. Merged.\n. @charithe This is really great. There have been some changes to our workflow (see my updates to the documentation in #356) and to finagle-redis specifically (#331) that mean that this will need to be rebased against the develop branch and have its tests migrated from Specs to ScalaTest. I've taken the liberty of doing both of those things in my fork here, and if you want to grab those two commits and submit a new PR against develop, we should be able to move this forward more quickly.\nTwo other small points: I've also moved the commands out of the c.t.f.r.protocol.commands package directly into c.t.f.r.protocol. This is kind of confusing since the package structure doesn't match the directory structure, but Scala doesn't require that, and this is the convention the other commands follow, so it makes sense to be consistent.\nI've also only added stubs for the integration tests with basic tests for PFADD. Ideally these would be more fleshed out.\n. There's no reason you should have been aware of the PR with the doc changes\u2014it's our fault that's it's not up already. About the new error: Finagle depends on Twitter Util, and at the moment you'll need to publish it locally by cloning the repo, checking out the develop branch, and running ./sbt +publishLocal. Over the past few months the way that we publish and consume Finagle and Util internally has changed, and we're still working out the best way to handle publishing here, but this inconvenience should be unnecessary very soon.\n. Thanks again, @charithe, this is awesome, and after the minor changes I've suggested above the integration tests look good and pass on my machine. Sorry about the inconveniences in the contribution process\u2014we're working to get them ironed out.\nTwo questions: Are you using Finagle in production? How crucial is support for these command to you? We're planning a 6.25.0 release soon (tomorrow, I hope) and we could probably hold off until this PR has been reviewed and tested internally if it's a blocker for you.\n. Okay, I'm pulling this inside. Thanks all.\n. This has been merged internally, so it'll make it into the next release. I'll close this PR when the commit gets synced to GitHub. Thanks again, @charithe!\n. This is now available in the develop branch on GitHub (but not yet in a public release).\n. I'm pulling this internally\u2014thanks @kachayev!\n. Now on GitHub\u2014thanks!\n. Mind using HTTPS? Otherwise :+1:, thanks! (and for reference this is a follow-up to this PR).\n. I've pulled this internally, and it should be up with the sync on Monday.\n. Okay, this is merged internally and I'll close this PR with the next sync to the develop branch. Thanks again @keeth!\n. Now on GitHub\u2014thanks!\n. @jamescway \n- Yep, this will be tested and merged internally (see the contributing guide for details).\n- In general that's the new recommendation, but this rebases cleanly so I wouldn't worry about it.\n- All the Finagle modules are published together, and releases are currently pretty far apart (the last was in December), but we're hoping to tighten up the cycle.\n. Thanks @n8han!\n. I'm pulling this in to be merged.\n. Now on GitHub.\n. Thanks @zdavep!\n. I'm pulling this in to be merged\u2014thanks again.\n. Now on GitHub.\n. Thanks, @note!\u2014I'll pull this in to be merged today.\n. Is this ready to go except for the typo, @dschobel, @olix0r? If so I can just pull it in and add the fix before internal review.\n. Not sure if this is missing commits or something, but please the contributing guide for info about how to submit a PR. Thanks!\n. @luciferous I'm not too worried about the input and output mapping functions\u2014if someone really wants these, they're probably open to something like a Cats or Scalaz dependency, and providing a Profunctor[Service] instance will give them lmap and rmap. Adding these to Service would just make things more complicated.\nIt would be nice to have a clean way to compose two services\u2014we've wanted this in a few places in Finch, for example. I'd personally like to see compose and andThen with reasonable signatures on Service:\nscala\ndef andThen[Rep1](f: Service[Rep, Rep1]): Service[Req, Rep1]\ndef compose[Req1](f: Service[Req1, Req]): Service[Req1, Rep]\nIt's not possible to add these via Cats's Compose (at least at the moment), since the syntax for Compose uses the same names, and the compiler won't look past the methods that are actually on Service.\nI don't feel terribly strongly about this, though. We could easily add aliases in ComposeOps that wouldn't collide with the methods on Service. Leaving the Service API as it is and letting people who want improvements make them via type classes and enrichment seems reasonable to me.\n. @raelg The problem is that since Service extends Function1, there are two different ways to think about composition. Viewing Service[I, O] as just a function I => Future[O], you can compose it with other functions that return an I or take a Future[O]. Viewing it as a service, you want to be able to compose Service[A, B] and Service[B, C].\nThe current andThen and compose methods support the first kind of composition, and therefore aren't very useful (to my way of thinking, at least), but they come from Function1, so they can't be deprecated away. We could overload these method names to provide the more meaningful kind of composition as well, but as @mosesn says, that would be kind of confusing.\n. For what it's worth I started a little project a couple of months ago that provides category and profunctor instances (from cats) for Service, and last night I implemented an idea that I've been wanting to try for a while that makes it possible to use enrichment methods even if they collide with methods on the original type. This means you get lmap and rmap for the price of an implicit class wrapping, with compose and andThen (for services, not functions) only adding a small extra syntactic cost.\nAll these things are pretty straightforwardly available to people who really want to use them, which is probably an argument for not meddling with Service.\n. I've merged these changes over in the new stand-alone finagle-swift project\u2014thanks, @rojanu.\n. Thanks @gitter-badger but we'll handle this.\n. Since you're in the develop branch, you'll need to be sure to publish Util and Scrooge locally first. In a quick experiment that fixes the issue for me.\nWhat you're seeing (and that I can replicate by deleting this dependency from my Ivy cache) is unexpected, though\u2014I'll take a look asap.\n. @matthewmichihara I'm glad that helped! I'd like to leave this issue open until we figure out why that resolution step was failing, though. As @mosesn says, you need to have maven.twttr.com in your resolvers, but since you're trying to build a Finagle subproject that was already done for you.\n. Thanks for taking care of this, @mkhq, and sorry for the delay in responding. It looks good to me, although I think we'll need to exclude BtreeClientIntegrationSuite.\n@penland365, any thoughts?\n. @spockz We're planning to add an HTTP client DSL to Finch that would mirror the request reader and encoding and decoding abstractions, but there's no definite timeline for that work.\n. Looks good to me, @spockz, but do you mind alphabetizing?\n(Also for future reference, you don't necessarily need the full three-section commit message for self-explanatory additions like this.)\n. Sorry about the delay, @spockz\u2014I've just pulled this in to be merged.\n. Merged in 167d9a3e4c0903d8fb3d6f84487a1c5a0bb50d45. Thanks @spockz!\n. Thanks, @tarossi! I've pulled this in to be merged.\n. Merged in 1dc81418793fdb6a122bfd36ec7fbf3a9facb333, thanks!\n. Thanks, @rodrickbrown! I've pulled this in to be merged.\nDo you mind sharing how you're using Finagle (what protocols, etc.)?\n. Merged in 93ec79134426c0859717517704021aeab1985489, thanks @rodrickbrown!\n. Pulling this in to be merged.\n. Merged.\n. Some additional context from the Finch room:\n\nWe are using Finch on video streaming platform\nwe implemented a service that returns live transmission details based on users location\n\nThanks, @amartinsn!\n. I'm pulling this in to be merged\u2014should be up on Monday.\n. Merged\u2014thanks again!\n. How about I link it to @finagle\u2014then we cover people with GitHub accounts and people with Twitter accounts, and I'm happy to handle more traffic there (at least for now).\n. Is there a reason these MySQL tests are rearranged here? Could you undo (and move to a separate pull request if intentional) to keep this focused on the SMTP work? Thanks!\n. It'd be better to keep this example out of the project proper (and definitely out of the root of the com.twitter.finagle package). The best place at the moment would be finagle-example, but I'll follow up over email about other ideas.\n. It's worth noting that onFailure takes a Function, not a PartialFunction, so this will blow up for any exceptions that don't match here.\n. Can you clarify the intention here? I'm not sure what you'd be handling.\n. Also, is there a reason you're explicitly returning Future[Unit] here? The inferred return type of res would be Future[Reply], and the Future[Unit] return type only works because of Scala's value discarding, which is frequently very confusing.\n. The indentation is a little confusing here\u2014can you align definitions at the same level?\n. One more\u2014could you clarify where send comes from here, since without context it's not entirely clear that it's a Service? It looks like a method, and we don't want to send users digging for something they're not going to find.\n. These should be defs?\n. Can you motivate the class hierarchy here a bit? Seems odd to me to have Reply as a subtype of UnspecifiedReply.\n. After some conversation on this end it sounds like we should just move this to finagle-example for now.\n. I'm not sure you need to show multiple ways of handling failure here (although it certainly doesn't hurt!). My question was more about the fact that you know res has succeeded if you get to this point\u2014you've either handled the errors in the preceding onFailure or you've blown up with a MatchError.\n. Hi @luciferous, yes\u2014I'm talking to @mosesn about some additions to this paragraph, and am hoping to get them written up tomorrow.\n. I guess we probably should, although once the new round of releases comes out it shouldn't be necessary for a while, and once we've started publishing snapshots it'll be unnecessary for good. I could go either way.\n. Yes, we're not currently running the finagle-redis integration tests in Pants. This @Ignore has no effect on the SBT build, but these tests are also excluded by default in Build.scala.\nIt would be nice to have them run as proper integration tests in SBT. I've just created an issue to track this.\n. Yes, this is consistent with how other finagle-redis commands work. It'd be nice to clean up the API, but in my view that can wait until we spin this off into its own project in the Finagle org (and we don't have a definite timeline for that).\n. Looks unnecessary to me as well, but it's in all the other *Commands.scala files, too.\nThere's a fair amount of noise and historical baggage in finagle-redis, and since it's more or less in maintenance mode until we move it to the Finagle org it's been a relatively low priority. So we have to decide between 1) doing the right thing here and being inconsistent, 2) cleaning up all instances of this at once, or 3) leaving it as is. I'm fine with either 1) or 3), but think 2) should happen in a new PR if at all.\n. I'm nitpicking here, but maybe we could go with the A0, value0 convention since _ is already so massively overloaded in Scala? I'm not sure there's precedent for either convention in Finagle right now.\n. ",
    "chrisphelps": "Thanks, @travisbrown \n. @mosesn We use finagle-protobuf to implement an RPC service-oriented architecture backing our entire platform. We're keenly following the progress on Mux to see how that affects the evolution of our usage of finagle. \n. ",
    "johanoskarsson": "Hey @mosesn,\nFirst off, thanks for looking into Zipkin.\nI'm not sure I get what you're trying to do. Is there a reason the original build files (Project.scala, build.sbt and plugins.sbt) don't work for you?\n. Aha, I see. Are there parts of finagle-zipkin you need but you don't need finagle-core and finagle-thrift? If there's a good reason to split that up further to make it easier we can consider it. For finagle-zipkin as a whole to function it needs finagle-thrift in order to send the data to the Zipkin collectors.\n. I can't remember exact versions but it's possible that it was called finagle-b3 back then. It's basically the same, we had to rename the project before open sourcing Zipkin.\n. You can find the equivalent in there. finagle-b3 has something called BigBrotherBirdTracer, that was the name for ZipkinTracer before. It might have some small differences though, such as it uses a different Scribe category. I assume it's not possible for you to contribute your Finagle changes and upgrade to the latest version?\n. I believe that stuff is part of the generated code that sbt-thrift creates.\n. To be honest I don't know. I think it might be easier to just use finagle-b3 until you upgrade and either change the category there or just change the zipkin collector config to allow the b3 collector: var categories: Set[String] = Set(\"b3\") or similar.\n. ",
    "franklinhu": "The span ID on the client and the server should be the same since a span is supposed to quantify one specific method call between a client and a service. Separate method calls, however, should have unique span IDs.\n. ",
    "spullara": "I would like to see benchmarks against the normal MySQL driver as part of this effort. For performance, memory usage and CPU usage.\n. println--\n. println--\n. I'm concerned that this code is too functional at such a low level. I can imagine it being a hotspot. Obviously we will see when we do performance testing but usually you want C-like code when doing operations like this one to avoid a lot of CPU and memory overhead.\n. I'm surprised there is no reference to the charset here. I think this only works if the server and client are both in the same one?\n. This definitely needs a reference to the charset encoding.\n. String.format is very inefficient. I suggest using a StringBuilder.\nEdit: On second thought you might use a Calendar object instead that doesn't require us to format and then parse a string to get a timestamp.\n. Again using Calendar here?\n. Need an explicit charset. I suggest that we require UTF-8 on both sides.\n. Making a new buffer, and a new writer per parameter seems pretty expensive. Can we refactor this to use a single buffer? Also, it generates multiple copies per parameter.\n. More copies.\n. I'm not sure if we can assume that error codes and messages are in ASCII.\n. Does this regular expression work if I have ? within quotes? I also don't know why we are doing the replacement rather than leaving it to the server? This seems pretty dangerous.\n. I would like this to not be in the API at all. It is very difficult to get this right such that you don't introduce SQL injection attacks like the current implementation allows.\n. If user data is ever passed to this method it is vulnerable. Also, it\nhas a bug related to ? appearing in the query in a string value. If we\ncan't make the method safe for user data and have it work in the\npresence of non-interpolated strings I would rather have it be more\nobvious in the code that calls MySQL that they are constructing the\nquery by hand rather than it looking like a safe prepared statement\ncall.\nOn Jul 23, 2012, at 12:25 PM, Ruben Oanta\nreply@reply.github.com\nwrote:\n\n\n\ndef flatten(params: Seq[Any]): Seq[Any] = params flatMap {\ncase p: Product => flatten(p.productIterator.toSeq)\ncase i: Iterable[_] => flatten(i.toSeq)\ncase x => Seq(x)\n}\n  +\n/**\n* Replace each wildcard instance in sql with the output from\n* running f(param(i))\n*/\nprivate def replace(sql: String, params: Seq[Any], f: Any => String): String = {\nif(params.isEmpty) {\nreturn sql\n}\n  +\nval matcher = Query.wildcard.matcher(sql)\n\n\nAs in, a rogue library that has a malicious toString method?\nWe can completely remove it but the problem of sql injection is still there if the a user builds their own sql statement.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/98/files#r1218606\n. It sounds to me then that we need a well tested way of doing prepared statement encoding client side. In order to support this, the MySQL driver appears to have a SQL parser along with all the escaping rules once the context of the ? is well understood through parsing.\n\nhttp://www.docjar.com/html/api/com/mysql/jdbc/PreparedStatement.java.html\n@jeremycole The other possibility is more carefully monitoring server side prepared statement usage. Which one do you think is more doable?\nMarius' idea of using a DSL to generate them might also serve the same purpose without having to parse statements but you would still need to do proper escaping of values.\n. ",
    "sonjake": "Those classes were removed and that file was deleted but maybe not\npropagated yet. Feel free to ignore it.\nSorry!\nOn Thu, Aug 9, 2012 at 12:56 PM, Matt Brown notifications@github.comwrote:\n\nHi, when I try to compile the whole project or just finagle-benchmark on\nit's own, I get the following errors in TaskTrackingtimer.scala because\nneither of com.twitter.finagle.util.{CountingTimer, TaskTrackingTimer} can\nbe found.\n[error]\n/Users/matt.brown/oss_projects/finagle/finagle-benchmark/src/main/scala/com/twitter/finagle/benchmark/TaskTrackingTimer.scala:5:\nCountingTimer is not a member of com.twitter.finagle.util\n[error] import com.twitter.finagle.util.{CountingTimer, TaskTrackingTimer}\n[error] ^\n[error]\n/Users/matt.brown/oss_projects/finagle/finagle-benchmark/src/main/scala/com/twitter/finagle/benchmark/TaskTrackingTimer.scala:26:\nnot found: type TaskTrackingTimer\n[error] val timer = new TaskTrackingTimer(new FakeTimer)\n[error] ^\n[error]\n/Users/matt.brown/oss_projects/finagle/finagle-benchmark/src/main/scala/com/twitter/finagle/benchmark/TaskTrackingTimer.scala:47:\nnot found: type CountingTimer\n[error] val timer = new CountingTimer(new FakeTimer)\n[error] ^\n[error] three errors found\n[error]\n{file:/Users/matt.brown/oss_projects/finagle/}finagle-benchmark/compile:compile:\nCompilation failed\n[error] Total time: 6 s, completed Aug 9, 2012 3:54:47 PM\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/issues/101.\n. We can take holistic approach here and synergize until we reach consensus. I'll touch base with our internal stakeholders and cycle back.\n. \n",
    "mattnworb": "thanks for the fast turnaround! errors all gone now.\n. ",
    "mef51": "wrong... repo... \n. ",
    "isnotinvain": "Bump!\nI say ship it! What's the next step?\n. Whichever is currently preferred should go in the docs I think. Do we currently use scrooge?\n. I didn't know there is a maven plugin. Let's add that to the sample maven\nfile too.\nOn Aug 29, 2012 8:30 AM, \"Steve Gury\" notifications@github.com wrote:\n\nIn README.md:\n\n@@ -182,6 +182,8 @@ Apache Thrift is a binary communication protocol that defines available methods\n       string hi();\n     }\n+To create a Finagle Thrift service, you must use the custom Thrift compiler. It will generate, in addition to the regular Thrift Iface interface, a ServiceIface interface that wraps all return values in a Future, which is required by Finagle.\n\nI would write something like that:\n\"\"\"\nTo create a Finagle Thrift service, you just need to implement an\nInterface generated for Finagle by Scroogehttps://github.com/twitter/scrooge.\nScrooge https://github.com/twitter/scrooge is Thrift code generator\nsimilar to the standard Thrift compiler http://thrift.apache.org, the\nmain difference is that the Interface expose asynchronous methods\ncompatible with Finagle.\n- If you are using sbt to build your project, there is a plugin\n  sbt-scrooge https://github.com/twitter/sbt-scrooge that will\n  automatically compile IDL for you. Beware that Twitter has moved out from\n  sbt, so the latest release version of this plugin is only compatible with\n  sbt 0.11.2\n- If you are using maven, there is a maven pluggin\n  \"maven-finagle-thrift-plugin\" that do the same thing. \"\"\"\nWhat do you think?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/105/files#r1486589.\n. +1 / Ship It! for @benpence's latest revision. It is clear and accurate regardless of whether maven-finagle-thrift-plugin is open sourced yet (the binaries are available right?)\n\n@stevegury We can work on open sourcing maven-finagle-thrift-plugin separately.\n. ",
    "zhanggl": "I am wondering when will these commits be merged to finagle-redis, because I really need these missing redis commands.\n. Thanks @mosesn , Good Job!\n. I'd love to. Please tell me how to do that.\n2014\u00c4\u00ea2\u00d4\u00c224\u00c8\u00d5 \u00c9\u00cf\u00ce\u00e76:10\u00d3\u00da \"Moses Nakamura\" notifications@github.com\u00d0\u00b4\u00b5\u00c0\u00a3\u00ba\nLooks like a bug to me! I'd be happy to see a patch of this. Let me know if\nyou want guidance on how to proceed.\n\u00a1\u00aa\nReply to this email directly or view it on\nGitHubhttps://github.com/twitter/finagle/issues/244#issuecomment-35845511\n.\n. Got it. I already have a finagle local env for testing. And I currently are\nreading the source codes.\nLooks like it's the empty string being incorrectly encoded to \"$-1\\r\\n\"\nwhich should be \"$0\\r\\n\\r\\n\".\nAnyway, I am in. And glad to be part of this.\n 2014\u00c4\u00ea2\u00d4\u00c224\u00c8\u00d5 \u00c9\u00cf\u00ce\u00e711:18\u00d3\u00da \"Moses Nakamura\" notifications@github.com\u00d0\u00b4\u00b5\u00c0\u00a3\u00ba\n\nPlease take a look at our CONTRIBUTINGhttps://github.com/twitter/finagle/blob/master/CONTRIBUTING.mdfile, which provides a starting point. Also, in your pull request, please\nformat your PR so that it is structured\nMotivations:\ndetails here\nModifications:\ndetails here\nResults:\ndetails here\nLike it is in this commithttps://github.com/twitter/finagle/commit/92052389af5006ad2bd7e6aa68ae205e5a81ecb6\n.\nAs far as the actual work, I'd recommend adding those two tests that you\nhave in your issue report to the redis tests in finagle, and keep working\non them until they pass. The error message points to this linehttps://github.com/twitter/finagle/blob/master/finagle-redis/src/main/scala/com/twitter/finagle/redis/Client.scala#L102which makes it seem like it's an error message from redis, so we're\nprobably passing it something bad.\ndoRequesthttps://github.com/twitter/finagle/blob/master/finagle-redis/src/main/scala/com/twitter/finagle/redis/Client.scala#L100is where we actually make the request, so it might be worth adding some\nlogging around there while you're debugging to check exactly what bytes\nwe're sending over the wire, and why redis isn't happy. You can also use\nredis monitor http://redis.io/commands/MONITOR to see what the server\nacknowledges, if you're running against a live server. The code where we\nencode the redis protocol is mostly in the Hasheshttps://github.com/twitter/finagle/blob/master/finagle-redis/src/main/scala/com/twitter/finagle/redis/protocol/commands/Hashes.scalafile.\nLet me know if you need help getting finagle building or testing on your\nlocal machine. Happy hacking! I'm excited to add you to the contributorshttps://github.com/twitter/finagle/graphs/contributorslist.\n\u00a1\u00aa\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/issues/244#issuecomment-35854829\n.\n. Also, please note that many other commands with StrictValueCommand have the same issue, among which are Set, GetSet, PSetEx, SetEx, SetNx, etc.\n\n``` scala\ntrait StrictValueCommand extends ValueCommand {\n  RequireClientProtocol(value != null && value.readableBytes > 0,\n    \"Found unexpected empty value\")\n}\n```\nPlease let me know if I can do anything.\n. Since I do not know much about the big picture, shall we just update StrictValueCommand as the following snippet. Or should remove the mixin of StrictValueCommand from all related commands?\ntrait StrictValueCommand extends ValueCommand {\n  RequireClientProtocol(value != null ~~&&~~ ~~value~~.~~readableBytes~~ ~~> 0~~,\n    \"Found unexpected empty value\")\n}\n. @mosesn Totally agree with you. One thing at a time.\n. Great! Thanks! I learned a lot.\nI'd love to do more. Really enjoy it.\n. @mosesn \nI've just faced and fixed the same issue with MBULK_REPLY.  See ad2d2912e9a2e2c6116238dfe0da8ec489002381\nMaybe should wait for my last PR to show up here before I submit this one(I'm still on the same branch).\n. Also, this reset thing here on a Throwable being caught costs me a lot to finally figure out the strange behavior(A HGetAll command gets a unexpected BulkReply response). \nWould it make sense to let the Throwable popup to the upper layer instead of returning undesirable replies?\n. scala\n  /**\n   * Helper function for passing a command to the service\n   */\n  private[redis] def doRequest[T](cmd: Command)(handler: PartialFunction[Reply, Future[T]]) =\n    service(cmd) flatMap (handler orElse {\n      case ErrorReply(message)  => Future.exception(new ServerError(message))\n      case _                    => Future.exception(new IllegalStateException)\n    })\nI think we should give some meaningful messages to users like => Future.exception(new IllegalStateException(\"Unknown response format received from the server\")) which helps when debugging a problem.\nAnd, upon an exception when decoding raw data from Netty, would it be better to abort the decoding operation and discard un-handled data rather than wasting computation resources to construct an useless reply which would most likely to be discarded later on by users?\n. Given a MBULK input \n```\n*4\n$3\nbar\n$0\n$3\nfoo\n$3\nmoo\n```\nwe end up with a BULK_REPLY(\"foo\") result, which should not have happened if the whole operation was aborted when processing the empty line before reaching foo.\nIt looks like after the stage = firstStage reset, we started over again and treated the left data as BULK_REPLY. I haven't check the implementation details yet.\n. ad2d291 does depend on changes in ca3b856 to pass all the tests: \n1. BulkReply needs to be changed to allow having empty message be encoded and decoded\n2. The WRONGTYPE error message thing\nI will say that let's just wait for #245 to be finally merged in master.\n. Out-of-date. see #251 \n. @mosesn \nSorry for the delay, please check it out.\n. Great. Thanks.\nI'll check other redis commands for the same issue when my time is available.\n. Yes, It did. My test redis version is 2.8.1\n. From the Redis 2.8 release notes:\n\nMigrating from 2.6 to 2.8\nRedis 2.6 is mostly a strict subset of 2.8. However there are a few things\nthat you should be aware of:\nThe following commands changed behavior:\n- SORT with ALPHA now sorts according to local collation locale if no STORE\n    option is used.\n- ZADD/ZINCRBY are now able to accept a bigger range of values as valid\n    scores, that is, all the values you may end having as a result of\n    calling ZINCRBY multiple times.\n- Many errors are now prefixed by a more specific error code instead of\nthe generic -ERR, for example -WRONGTYPE, -NOAUTH, ...\n\nShould this be OK?\nscala\n      \"key command on incorrect data type\" in {\n        val txResult = Await.result(client.transaction(Seq(HSet(foo, boo, moo),\n          Get(foo), HDel(foo, Seq(boo)))))\n        txResult.toList must beLike {\n          case Seq(IntegerReply(1),\n            ErrorReply(\"WRONGTYPE Operation against a key holding the wrong kind of value\"),\n            IntegerReply(1)) => true\n          case Seq(IntegerReply(1),\n            ErrorReply(\"ERR Operation against a key holding the wrong kind of value\"),\n            IntegerReply(1)) => true\n          case _ => false\n        } \n      }\nOr we have to check the test server version accordingly?\n. I'm afraid it is. A readBytes(replySz) with replySz=0 will cause an Exception to be thrown.\n. Yeah, it works now. And I can't remember why it didn't\nWill just remove it.\n. ",
    "abbaspour": "please leave poms for those using IDE. \n. not as mature.\n. Christmas is approaching @trustin :)\n. ",
    "shijinkui": "\u4e0d\u8d1f\u8d23\u4efb\u7684twitter\u5f00\u53d1\n. ok\uff0cthat force us to use sbt :( \n. ",
    "lahosken": "According to Google Translate, the issue is \"maven-finagle-thrift-plugin version: 0.0.5 Not be found\" (plus some insults).\n. I wish you good luck getting this answered at http://stackoverflow.com/questions/14134882/how-to-group-sbt-application-conf-settings-for-different-apps-is-this-possible . It looks like you're using spray instead of finagle, so I'm closing this issue. (updated w/correct link, eek.)\n. ",
    "rstrickland": "That's fine.  I did this as a result of a suggestion made on the Google group for Zipkin.  I personally find it useful for debugging, and in fact it revealed a conflicting version issue with SLF4J that would obviously have remained hidden using a logger.  It's also helpful if you want to eliminate the Ostrich dependency and just see the raw output.\n. Yes retries are active using the default of 3.\n. We always use the ClientBuilder.\n. This one is not using TLS.\n. Actually yes, we are getting a handful of these (about 0.005% of requests produce this), and this would be one thing our mock server doesn't emulate.  So that would make sense.\n. Regarding moving up to 6.5.2, we would love to, but we're using Cassie which depends on 6.3.  Do you know if the versions are binary compatible?\n. Ok I will do a little testing tomorrow and see if I can just drop in 6.5.2.\n. I haven't tested with 6.5.2 yet, but I updated our mock to emulate the exception that bubbles up to the root monitor.  I was able to send 400k messages without error (other than the exception which occurs 0.1% of the time) using the same configuration that's in production.  I was hoping I could simply handle this edge case as a triage measure, but I'm not convinced it's the root cause.  I am uneasy about upgrading Finagle without extensive testing, because all of our services use Finagle for inter-process communication.\n. I noticed this morning that Cassie's newest release uses 6.5.0.  Is it reasonable to assume that the fix in question would be in that version?  I switched our client back to the Apache client as an immediate triage (which seems to be working fine), because I really want to be able to replicate the issue before trying another production fix.  If you have any other theories I can check out, I'm happy to do so; I'd much prefer to use Finagle across the board.\n. So what I hear you saying is that an upgrade to 6.5.0 will theoretically fix the issue, but there's no way to know for sure without deploying to production?  If the unhandled exception puts the client in this state in our production system, why would it not do the same in our test system?\n. It's on our short-term backlog.  We had to prioritize getting a major release out the door first, but this is a high priority item for us.  I'll let you know when we have testing results.\n. ",
    "eirslett": "Speaking of the devil! :+1: \nStrange... what happens if you make Travis build it with maven instead of sbt? If that's relevant?\n. https://travis-ci.org/eirslett/finagle/builds/3761932\n[info] Loading project definition from /home/travis/builds/eirslett/finagle/project\n19[info] Updating {file:/home/travis/builds/eirslett/finagle/project/}default-d291f6...\n20[info] Resolving com.twitter#sbt-package-dist;1.0.5 ...\n21[warn]    module not found: com.twitter#sbt-package-dist;1.0.5\n. bmdhacks +1\nI like the idea about a mechanized bird.\nhttp://www.thisiscolossal.com/wp-content/uploads/2013/06/swallows-2.jpg\n. What about a 2-second Finagle jingle (audio clip) that plays every time you start a Finagle service? (+ of course every time you read the online documentation)\n^^\n. How about a bird that wears steampunk goggles? https://www.google.no/search?q=steampunk+goggles&tbm=isch\n. You can easily use libthrift 0.9.2 with finagle, no problem. As long as you use the Java generator. (Unless you hit an edge-case.) Just override the version you get from finagle.\n. You can use sbt and exclude the version of libthrift that finagle gives you. And then you must include your own version instead. (0.9.2?)\nUse the latest version of the scrooge sbt plugin. Then it should just work - I think... (at least it worked for me)\n. Too bad the sbt plugin isn't published... but it's only one file, you could simply copy-paste it directly into your project:\nhttps://github.com/twitter/scrooge/blob/develop/scrooge-sbt-plugin/src/main/scala/com/twitter/ScroogeSBT.scala\n. exactly. And add the scrooge-generator dependencies etc. to project/plugins.sbt.\n. I saw this was fixed in 4aaf8db. Thanks! :-)\n. bump\n. Is this running in production anywhere yet? (Or isn't that possible?)\n. Nice! :-D\n. ",
    "evnm": "Better late than never.\n. The deprecation storm has settled and the Name/Var[Addr] API is the outcome. I think it's safe to assume that it's stable enough to build upon. ZkResolver is still written in terms of Group because no one's had time to migrate StabilizingGroup to the Var[Addr] world.\nA DnsResolver would provide a function def bind(arg: String): Var[Addr]. See twitter-server's FlagResolver class for a simple example.\n. Technically the deadline given to Closable.close is advisory, so it's not guaranteed that it's adhered to all the way down the stack. That being said, it would be nice if we could wait until either readq is empty or the duration is expired within ChannelTransport.close(Time). It's not clear how you'd cleanly do this though, given the lack of asynchronous Netty Channel APIs.\n. This issue should have been taken care of by this commit. Here a bit of backstory from the internal code review:\n\nReports indicate that Finagle servers fail to drain themselves before tearing down connections on invocation of server.close(deadline). I initially followed the scent of a TODO comment in DefaultServer [1], but the culprit instead turned out to be race condition in GenSerialServerDispatcher. If a concurrent invocation of dispatcher.close was interleaved between dispatching a request and state being checked for idleness (i.e. between the two lines marked in [2]), the request would be rejected, the transport closed, and upstream success rates affected.\nThis issue is fixed by allowing requests to be handled when state is either Idle or Draining instead of just Idle. There's no multivariate comparison operation on AtomicReferences, so I unfortunately had to explicitly synchronize on state. Note that we still only want to compareAndSet when state is Idle.\n[1] https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/server/DefaultServer.scala#L168\n[2] https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/dispatch/ServerDispatcher.scala#L39-40\n. Am I correct in assuming that you're capping your service at four concurrent requests because of the large request size? If your servers can take it, this problem may be alleviated by increasing your request concurrency.\n\nBarring that, you could try composing your own RequestSemaphoreFilter around your service rather than relying on the one baked into com.twitter.finagle.server.DefaultServer. By default DefaultServer creates a semaphore with no maximum number of waiters, which I suspect is leading to your blowout of pending requests.\nIf ServerBuilder.maxConcurrentRequests isn't set, then a RequestSemaphoreFilter isn't used. Instead, try building a filter with a realistic number set for the maxWaiters argument to AsyncSemaphore. This should stop requests from backing up, but note that it will result in RejectedExecutionExceptions being returned by the service in cases of excess request buildup.\n. Could you format the patch into a single commit diffed against Finagle master, please? The patch generated by GitHub isn't playing nicely with git am since each patch is diffed against a different SHA.\n. We suspect this is being caused by some Windows firewall or permissions issue. These examples work just fine elsewhere.\n. LGTM\n. The Thrift.newIface API uses reflection to create a client using whichever interface is available (e.g. ServiceIface uses stubs generated by Apache Thrift, FutureIface uses Scrooge 3). ClientIds are provided by the TTwitter upgraded Thrift protocol, so are not compatible with Apache Thrift.\n. LGTM. Just some dumb style nits.\n. Thanks for doing this!\n. May I ask in what capacity you're using Finagle?\n. Cool! Thank you for the detailed description. I'm curious how much heavy lifting was required to get Scrooge working with the newer version of Thrift. Good luck with open sourcing and with the new job. :)\nIn the meantime, this change LGTM.\n. Thanks for reporting, Ben. Mailing list discussion for background: https://groups.google.com/forum/#!topic/finaglers/qfE-UAko1xc\n. I merged this change in our internal repo. It should appear on GitHub upon the next library release. Thanks!\n. Thanks, Kevin.\n. Why do we issue a request after calling .close()?\n. omit parens around \"foo\"\n. SkepticalClusterFilter? Shouldn't these be NonShrinkingCluster?\n. Capitalize Helper, here and elsewhere in the newly-migrated tests. And maybe make it an object, in which case all of the vals become defs.\n. There seem to be a number of cases like this where braces aren't padded by spaces. We typically leave a single space after opening and before closing braces:\n... { case i if i % s == 0 => i * 2 }\nCan you fix cases like this so that they match the style of the rest of finagle and util, please?\n. These sections don't appear to actually be changed, but rather indented two characters. Can you revert them to the proper indentation, please?\n. Rm these extra empty newlines.\n. Let's name this file/test ClientTest. As far as I can tell, the \"ClusterClient\" terminology in test case names is arbitrary.\nEDIT: Nevermind, I see what you did here. Good idea to split up what was formerly ClientSpec into multiple files.\n. Fix indentation of these Scaladoc lines.\n. ditto scaladoc indentation\n. ditto\n. you get the idea :)\n. I realize this was in the Specs version, but renamed imports are typically put first before normal by-name ones.\nimport com.twitter.finagle.memcached.protocol.{\n  Error => MemcacheError, ClientError, NonexistentCommand, ServerError}\n. Rm the ** while we're in here.\n. ditto\n. Empty newline before this test, please.\n. Rm this extra line.\n. Only two spaces of indentation within this class.\n. space after the if\n. Why skip these tests?\n. This indentation's a bit weird. Let's use:\ncase class MyStreamResponse(\n  httpResponse: HttpResponse,\n  messages: Offer[ChannelBuffer],\n  error: Offer[Throwable]\n) extends StreamResponse {\n. Class header on one line, since it's less than 100 chars.\n. Same class header style as above.\n. Space between ) and {, here and below\n. Same class header style as above.\n. def thriftToBuffer(\n  method: String,\n  `type`: Byte,\n  seqid: Int,\n  message: { def write(p: TProtocol) }\n): ChannelBuffer = {\n. ",
    "zuercher": "Have you tried using ZookeeperServerSetCluster from finagle-serversets? (See https://github.com/twitter/finagle/blob/master/finagle-serversets/src/main/scala/com/twitter/finagle/zookeeper/ZookeeperServerSetCluster.scala)\nThen you can create the ReadHandle with something like:\nMultiReader.newBuilder(cluster, queueName)\n    .clientBuilder(factory)\n    .retryBackoffs(backoffs, timer)\n    .build()\nwhere queueName, factory, backoffs, and timer are all from your existing code. Well, backoffs need to be converted into a scala Stream, which you can see an example of here: https://github.com/twitter/finagle/blob/master/finagle-kestrel/src/main/java/com/twitter/finagle/kestrel/java/ClientBase.java#L68\nI think the will eliminate most of the complexity in your code. The zookeeper cluster read handle should survive an empty serverset and pick up with new hosts when they appear.\n. Given these imports:\nimport com.twitter.util.Duration;\nimport com.twitter.finagle.builder.ClientBuilder;\nimport com.twitter.finagle.builder.ClientConfig;\nimport com.twitter.finagle.kestrel.protocol.Command;\nimport com.twitter.finagle.kestrel.protocol.Kestrel;\nimport com.twitter.finagle.kestrel.protocol.Response;\nimport java.util.concurrent.TimeUnit;\nimport scala.runtime.Nothing$;\nThis compiles:\nClientBuilder<Command, Response, Nothing$, ClientConfig.Yes, ClientConfig.Yes> factory =  null;\nfactory = ClientBuilder\n    .get()\n    .codec(Kestrel.get())\n    .logger(java.util.logging.Logger.getLogger(\"debug\"))\n    .tcpConnectTimeout(Duration.fromTimeUnit(5, TimeUnit.SECONDS))\n    .hostConnectionLimit(1);\n(Assumes finagle-kestrel, finagle-core, util-core, util-logging and scala-library are on the classpath.)\nNote that the cluster argument must be removed -- you are meant to pass a partially completed ClientBuilder to the MultiReader. The MultiReader will handle using your ClientBuilder to create Client instances as necessary.\nSetting hostConnectionLimit > 1 has no effect: the MultiReader will only ever issue a single request per kestrel host.\nAs far as Stream.empty() vs null goes: using Stream.empty seems to compile without any issues, so perhaps that's more an issue with Eclipse. Explicitly casting it to Stream might help. Also, it's the invocation of backoffs.call() that is marked as throwing a checked exception. You could wrap that with an exception handler that produces an empty Iterator and then pass the resulting Iterator to JavaConversions.asScalaIterator, removing the need to call Stream.empty altogether.\n. ",
    "wishoping": "Thank you for your help! \nI tried with your advice. \nBut I met some problem with code ... \nBelow code is new version ... \nZookeeperServerSetCluster serverSetCluster = new ZookeeperServerSetCluster(curServerSet);\n```\n    final JavaTimer timer = new JavaTimer();\n    final Callable> backoffs = Backoff.toJava(\n            Backoff\n            .exponential(\n                    // 100ms initial backoff\n                    Duration.fromTimeUnit(100, TimeUnit.MILLISECONDS),\n                    // multiplier\n                    2)\n                    // fail after 10 tries\n                    .take(10));\nFunction0<Stream<Duration>> backoffsFunction = new com.twitter.util.Function0<Stream<Duration>>() {\n      public Stream<Duration> apply() {\n        try {\n          return JavaConversions.asScalaIterator(backoffs.call()).toStream();\n        } catch (Exception e) {\n          return null;\n        }\n      }\n    };\n\nClientBuilder<Command, Response, Nothing$, Yes, Yes> factory =  null;\nfactory = ClientBuilder\n    .get()\n    .codec(Kestrel.get())\n    .logger(java.util.logging.Logger.getLogger(\"debug\"))\n    .cluster(serverSetCluster)\n    .tcpConnectTimeout(Duration.fromTimeUnit(5, TimeUnit.SECONDS))\n    .hostConnectionLimit(10);\n\nMultiReader.newBuilder(serverSetCluster, queueName)\n    .clientBuilder(factory)\n    .retryBackoffs(backoffsFunction, timer)\n    .build();\n\n```\nbut factory variable is not valid. I got a compile error.\nfactory = ClientBuilder\n            .get()\n            .codec(Kestrel.get())\n            .logger(java.util.logging.Logger.getLogger(\"debug\"))\n            .cluster(serverSetCluster)\n            .tcpConnectTimeout(Duration.fromTimeUnit(5, TimeUnit.SECONDS))\n            .hostConnectionLimit(10);\nreturns  \"ClientBuilder\" Type ... so I can't adjust that code...\nand Stream function also has a problem... \nFunction0> backoffsFunction = new com.twitter.util.Function0>() {\n              public Stream apply() {\n                try {\n                  return JavaConversions.asScalaIterator(backoffs.call()).toStream();\n                } catch (Exception e) {\n                  return null;\n                }\n              }\n            };\nWhen catch a exception original reference code use \"return Stream.empty()\" But my eclipse show up compile error, \"ambiguous use\"... So I temporarily use return null... \nIf you don't mind, please help me one more..T.T\nThank you for your help in advance~\n. ",
    "itissid": "I see version 0.5.0 for libthrift in the pom. That seems really old. Is it safe to upgrade?\n. ",
    "astubbs": "158 wow, messy.\nSo why is finagle-thrift using such an old version of thrift?\n. Sorry, can you elaborate?\nOn 27/06/2013, at 12:05 PM, Steve Gury notifications@github.com wrote:\nI think you can directly use default from java.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/twitter/finagle/pull/181#issuecomment-20133084\n.\n. As in, call .tracer(ZipkinTracer.default()) ?\nOn 27 June 2013 13:15, Steve Gury notifications@github.com wrote:\n\ndefault is a public val (See line 14), from java you should see this as a\nmethod with no argument that return a Tracer.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/181#issuecomment-20140390\n.\n. I can see ZipkinTracer.default from a Scala perspective, but in java it is\nas above..\n\nOn 27 June 2013 15:01, Antony Stubbs antony.stubbs@gmail.com wrote:\n\nAs in, call .tracer(ZipkinTracer.default()) ?\nOn 27 June 2013 13:15, Steve Gury notifications@github.com wrote:\n\ndefault is a public val (See line 14), from java you should see this as\na method with no argument that return a Tracer.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/181#issuecomment-20140390\n.\n. Why not be up front with it and call it mkJava? It's not like it's doing something different than mk, as to give it a separate name?\nThe Akka model for java compatibility which I used for a year was really nice. Seems there's  few places where finagle could be improved in this regards. \nCorrect me if i'm wrong though, but a null stats receiver seems a bit useless though? I'm new to finagle but i'm curious why anyone would want to use it?\n. I can probably guess what a logging filter is, but I don't think I should have to be aware that I have to install one, in order to prevent exceptions from being silently swallowed, even if I have a high logging level turned on?\n. Are there any examples on how to use LoggingFilter? I see it's abstract, not sure how to plug it in. Got this far:\n\n\nService filteredService = new LoggingFilter().andThen(myService); but that errors because it's abstract.\n. P.s. I can't mix it in because I'm using a scrooge generated service plus it's java.\n. So you disagree that I handled exceptions should always be logged at a high\nenough level regardless of attached filters? It kind of violates the\nprinciple of least surprise...\nOn 27/06/2013, at 5:10 PM, Moses Nakamura notifications@github.com wrote:\nTake a look at Http\nLoggingFilterhttps://github.com/twitter/finagle/blob/master/finagle-http/src/main/scala/com/twitter/finagle/http/filter/LoggingFilter.scala,\nconfusingly also named LoggingFilter (for historical reasons) :)\nFilters are designed to be composed in the way that you're describing,\nfilter andThen service. Here are\nsomehttps://github.com/twitter/finagle#Building%20a%20Robust%20Server\ndocs http://twitter.github.io/finagle/guide/ServicesAndFilters.html that\nmight be useful.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/twitter/finagle/pull/182#issuecomment-20155161\n.\n. That's some crazy work just to log unhandled exceptions.\nOn 27/06/2013, at 5:10 PM, Moses Nakamura notifications@github.com wrote:\nTake a look at Http\nLoggingFilterhttps://github.com/twitter/finagle/blob/master/finagle-http/src/main/scala/com/twitter/finagle/http/filter/LoggingFilter.scala,\nconfusingly also named LoggingFilter (for historical reasons) :)\nFilters are designed to be composed in the way that you're describing,\nfilter andThen service. Here are\nsomehttps://github.com/twitter/finagle#Building%20a%20Robust%20Server\ndocs http://twitter.github.io/finagle/guide/ServicesAndFilters.html that\nmight be useful.\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/twitter/finagle/pull/182#issuecomment-20155161\n.\n. Plus, you can't really use trait's from Java:\nhttp://stackoverflow.com/questions/7637752/using-scala-traits-with-implemented-methods-in-java\n. I'll look at making our own logging filter that uses slf4j that doesn't extend logging filter. If i were to push it up, where would be appropriate? finagle-contributions module perhaps? separate repo?\n. Something like:\n```\n@Slf4j\npublic class Slf4jLoggingFilter extends SimpleFilter {\n@Override\npublic Future<byte[]> apply(byte[] request, Service<byte[], byte[]> service) {\n    Future<byte[]> future = service.apply(request);\n    future.handle(new Function<Throwable, byte[]>() {\n        @Override\n        public byte[] apply(Throwable throwable) {\n            if (throwable != null) {\n                log.error(throwable.getMessage(), throwable);\n            }\n            return null; // no result\n        }\n    });\n    return future;\n\n}\n\n}\n```\n. ",
    "sritchie": "We're stuck on 0.5.0 internally at Twitter, and probably won't be moving any time soon.\n. ",
    "jduan": "Are there any updates? The last update was almost a year ago. Thanks!. @ryanking thank you for the update anyway!. ",
    "ryanoneill": "Hi @jduan, not really much of an update here. We are still on the 0.5.x branch internally. It would be a very large undertaking to migrate everyone internally. Perhaps some day, but we're not actively working on it at the moment.. Also @chandra-cd, what version of mysql you are using? I was able to run the example successfully using the version that I already had installed, but I would like to try to test with a similar environment. Thanks.\n. Sorry @chandra-cd, unfortunately so far I have been unable to reproduce this issue. I was able to try with the same version of MySql (5.5.33)  (different os) but did not encounter the same issues. Please let us know if you're able to find out anything more. Thanks.\n. Hi @amartinsn, this has been submitted internally. We will close out the pull request when it's been pushed back to GitHub from our internal codebase. Thanks again.\n. Going to try to merge this in internally.\n. Hi @lightyang. This PR has been merged into our internal codebase. I'll close out this PR once it's been synced back to GitHub, which should happen by early next week. Thanks again.\n. Your commit has been pushed back out to GitHub as part of the Finagle develop branch https://github.com/twitter/finagle/commit/97c4e6910f15292ad8c7881a8f2a0af6c5f9b561\nI am going to close this pull request now.\nThanks again for the contribution.\n. @bryce-anderson shipped this internally.\n. Hi @jbkt, this pull request has been merged internally, and will be pushed back out to GitHub by (at the latest) sometime early next week. Thanks for the contribution and thanks for using Finagle. \n. Hi @morazow, thanks for the report.\nI was under the impression that using the IgnorantTrustManager in finagle-core does work in most cases, but will look into this further when I have an opportunity. We currently have a test in finagle-native which uses it and is currently passing. My guess is that there is something different about the server you are running, that our Finagle server is not mimicking.\nCurrently, we are in the process of overhauling our TLS code and making it uniform throughout Finagle on Netty 3 and Netty 4. Our version for Netty 4 today uses Netty to build SSLEngine's and so for insecure clients is using their InsecureTrustManagerFactory. Netty's InsecureTrustManagerFactory looks very similar to our IgnorantTrustManager, so I'm concerned about fixing this code in Finagle running Netty 3 and then immediately not having it work anymore when we revamp and switch things to Netty 4. So I'd like to make sure I understand what the exact problem is and how to reproduce it so we can fix it now, and make sure it's fixed when we move forward.\nSo, if you can answer any of the following questions, that would help:\n1. Do you know what type of web server the backend is using?\n2. Do you know what cipher is used by the connection when it's successful?\n3. Do you know what signature algorithm the certificate is using? - You can find this by saving the cert to a file and running \"openssl x509 -in filename.crt -text\" on it and looking through the output.\n4. Does the code still work if you replace the random parameter of sslContext.init with null?\ncontext.init(null, Array(new IgnorantTrustManager()), null)\ninstead of\ncontext.init(null, Array(new IgnorantTrustManager()), new java.security.SecureRandom())\nThanks. Much appreciated for any information you can provide. \nRyan\n. @morazow Thanks for the update. Apparently, @kevinoliver found an issue that was filed on the Netty project with the same issue today. That's a good sign for being able to get this fixed for both.\n. I've made a change for this issue in this commit. Going to consider this issue resolved. Thanks @morazow for reporting it.\n. Hi @knightpop, thanks for the report. I checked this out with the versions you specified (finatra 2.6.0, finagle 6.40.0, util 6.39.0),  and I see the same issue that you do. Our apologies for that.\nA few days ago though we released updated versions of these libraries (finatra 2.7.0, finagle 6.41.0, util 6.40.0), and I confirmed with those versions that this same issue no longer exists. . @olix0r You should be able to do this once all my stuff has shipped (which it's started too, for preliminaries check out util-security). \nThe next commit will include SslClientEngineFactory in finagle-core. That is a generic trait which can be extended, of which one extension is Netty4ClientEngineFactory, which uses Netty 4's SslContextBuilder and can pass in the ApplicationProtocols specified in the SslClientConfiguration into the engine factory, which in turn passes them into the SslContextBuilder. \nCipherSuites will be similarly supported for all engines. Timeouts are not at the moment, but we could revisit soon afterwards, and I would also like to close this long outstanding issue. \nWhen my changes are complete, TlsConfig will go away, and the params will be much closer to how Finagle running Netty3 works today. There will be a ClientEngine param which requires an instance of SslClientEngineFactory, a ClientConfiguration param which requires an instance of SslClientConfiguration, and a ClientVerifier param, which will allow the replacement and the eventual removal of SessionVerifier.\nIf our ClientEngineFactory didn't work for you at that point, then you'd also be able to construct your own and use that instead. Thanks for your patience on this. Sorry for the headaches.. Just to clarify, when you say a CA cert with a client, are you talking about using the CA cert for trusting a certificate from the server, or in using a chain of certificates for configuration for key management. \nExample:\nRoot CA -> Intermediate CA -> Client Cert / Server Cert\nAre you talking about configuring the client with \n([Root CA,] Intermediate CA, Client Cert) so that multiple certs are sent by the client for client authentication or using the Intermediate cert for trust management?. You would then want an SslClientConfiguration that uses TrustCredentials.CertCollection. \nThat file should contain multiple certificates that you would like to trust. With the Netty4ClientEngineFactory for instance, that file gets sent to the builder.trustManager for the client. \nFor what will be our current 'default' engine factory, that file is used by X509TrustManagerFactory to create a TrustManager which is used by a Java SSLContext.\nHope that gives a clearer picture of the direction where things are headed.\nClient certs will be supported too as part of this. It's one of the reasons we are making large changes here. So a Finagle server will be able to want/need a client certificate, and the client will be able to send it.. Just saw your previous question. These changes will unify Netty 3 and Netty 4 SSL/TLS configuration. You would also be able to use the Netty4ClientEngineFactory or Netty4ServerEngineFactory with a Finagle client/server running Netty3. You would want to do that if you're still using Netty 3, want client authentication, and you want to use netty-tcnative. \nMy work is independent of our move to get everything in Finagle working on Netty 4, hence the ability to use this piece of Netty 4 with Finagle running Netty 3.. I think I understand your first question. My current thinking is that it might be best for you to refactor our Netty4ClientEngineFactory to work also for your needs, and have the \"h2\" part stick with the engine factory in this case, and leave the applicationProtocols section of the SslClientConfiguration as Unspecified. I'm open to further ideas once you can see the items in place.\nYeah, the TrustManagerFactory/TrustManager code will only be used by us with a different SslClientEngineFactory, not the Netty4ClientEngineFactory. The Netty4ClientEngineFactory will use a File, specifically for the reason you mentioned.. If you can elaborate further on endpoint-specific vs not protocol-specific that might help. . Within another week or so you should be able to see what this code looks like and then we can talk again about what does and doesn't work for you.. We are in the process of doing the OSS release for Finagle 6.42.0 now. \nMy changes will all be public in 6.43.0. You can see what some of them look like by looking on the develop branch now. The stack parameters for Netty 3 and Netty 4 both will be unified and be changed internally (and on develop) hopefully next week. The additional parameter for verification (which is what would allow setting the other parameters that Oliver was talking about) should be added soon after. . Thank you for the contribution @mkhq. I've put this up for review internally. Once it's submitted internally, it will get pushed back out to GitHub on the develop branch sometime soon after. At that point I'll close this PR.. Thanks again for the contribution @mkhq. This has been pushed back out to GitHub in commit https://github.com/twitter/finagle/commit/894a7b04a49c9e3698156281944747513fb3bec6. Hi @davoclavo, thanks for the contribution. Much appreciated.. Hi @koshelev, thank you for the pull request. I wanted to let you know that I have looked at the code, and am going to ask for you to make some changes. I am currently thinking about how to fit this within the structure of not only where the code is now, but where it's going as well. I should have a better answer for you with concrete things to change tomorrow (Friday). Thanks.. Hi @koshelev, sorry for the long delay. I'm going to take another look now and see how we can best incorporate this.. There's a lot of great work here, thank you. I sincerely apologize for the delay. I hadn't looked much into SNI Matching on the server side within Netty before, so I had some items to look into. \nSome of the changes included in this PR have already made it into Finagle which is great, so thank you. I have some suggestions on how to make further changes which would allow us to accept this PR as part of Finagle. If you're interested in working through them, that's great. If not, I'll probably continue this on as time permits with you getting the credit for it.\nIn this version, Netty4SniHandler is extending SniHandler, which requires a mapping of type AsyncMapping[String, SslContext]. This value is passed in via the Finagle stack param that you added which also turns this functionality on. \nWe prefer to limit the exposure of Netty specific types in Finagle APIs, especially after the amount of effort required to update from Netty 3 to Netty 4 in Finagle. Also, this uses Netty's SslContext, which we don't expose and only use contained within Netty4ClientEngineFactory and Netty4ServerEngineFactory. \nIf we use Netty's SniHandler, we're locked into using that AsyncMapping[String, SslContext], which I think is a non-starter for us. After looking at the implementation of SniHandler though, I think we can make everything work well by instead extending AbstractSniHandler. AbstractSniHandler does all of the protocol work, and it would also allow us to use our own types there.\nI would prefer if the mapping were along the lines of Map[String, SslServerConfiguration], and then Netty4SniHandler used the Netty4ServerEngineFactory along with the specific SslServerConfiguration to create an Engine that's used with the SslHandler. That would be more in line with how engine creation and configuration works in Finagle today.\nWe can then expand on that in the future beyond Map[String, SslServerConfiguration] to incorporate different SslServerEngineFactory values if necessary.\nWould that work for you for what you're trying to do? Let me know your thoughts when you have an opportunity. Thanks again.\n. @koshelev Hope you're enjoying your vacation! Glad to hear that you're interested in pursuing this.. @koshelev I'm going to take another look at this now. Thanks for following up.. @koshelev I have not, I'm sorry. I'm going to take a thorough look now.. @adleong I believe we reached an impasse because of the nature of how this specific implementation needed to use Futures to call off machine to retrieve certificates and keys based on the SNI host. I don't think that fits in well with how the current implementation of Finagle's and Netty's connection APIs work and Finagle's SSL/TLS configurations. \nI would still like to see SNI support added to Finagle as it would certainly be useful for folks. However, internally we don't have a strong need for it because our internal certificates are not based on hostnames. So, it's not something we're planning on prioritizing.. @mehmetgunturkun FYI, I've put up that change for review internally. It required some additional changes to finagle/finagle-netty4 but should be (hopefully) shipped later today.. @mehmetgunturkun yes, via AbstractByteBufByteReader. https://github.com/twitter/finagle/commit/e62c326aebd6475cbe4c05ced54c880886d35eba. You are correct @adriancole. Think Moses meant to post this one. https://github.com/twitter/finagle/commit/a6de338c0ffb0e7b6924f326cd0feac0bc9dad0a. Hi @anatolydwnld. \nI completely agree with your assessment of how difficult it is to extract a peer's certificate. It's something @bryce-anderson and I have discussed recently. The Transport.peerCertificate code has been there for quite some time. So, it hasn't been removed, but we also realize that it's less than ideal. Changing it is on the list, but not currently prioritized. \nSince you are looking to get at this information, do you have opinions on what you feel like would be a better API for retrieving it? From my perspective, when this is changed, I would like folks to have access to a few more values from the SSLSession as well. In particular Id, as that is one that has been specifically asked about in the past.. Hi @wpK, \nI don't believe we have any current plans here, but thanks for letting us know that you would like to use this feature. Is this something that you would be interested in working on and adding to finagle-mysql via a pull request?\nThanks, Ryan. Hi @joeyb, thank you for the pull request. I'm going to have someone who is a little more familiar with the code than I am review it.. Hi @iyogi, with the next release of Finagle, which should happen sometime this month, you'll be able to specify your own SslClientSessionVerifier as part of your SSL/TLS setup. This would allow you to verify the hostname as you see fit, instead of getting rejected by the HostnameVerifier.\nSince it's not published yet, I'll link to our develop branch, which contains the most recent changes. See ClientTransportParams for details.\n. Thanks @ryanb93, I will pull this in.. @ksilin Not as of yet, but I do expect us to add this at some point within the next few months.. Hey folks, wanted to update this issue. Movement is happening here. We have a working prototype and are starting to ship some of the necessary changes to make this a reality. I would expect it to be available for use in the January Finagle release, or depending on the timing, at the latest February.. Regarding taking certificates directly, it's something we investigated, but decided against, at least for now. The issue is not about the certificate, but about the associate private key. Having a Finagle stack param which contains a PrivateKey leads us to too many places where it can be exposed accidentally through logging or admin registry access. We don't have a business case for it internally at the moment either, so we haven't discussed it any further. \n'I need to verify whether that works for us for clients'. Verifiers do work on the client as well. \nWith regards to OCSP, it's not something we use internally with Finagle and we don't have plans to use it in the near future either. Can you provide me with a better idea of how you would normally configure OCSP?. Apologies for the delay. I'm starting to understand the picture here. \nOur plans for supporting JDK9 externally aren't set in stone yet. Internally, it looks like we're moving directly from 8 to a higher version (11?) when it's ready. We've gotten reports both internally and externally and have fixed a few issues recently.\nTo have the combination of features that you're looking for (Java's SSLContext, OCSP, ALPN (which as you mentioned for Java comes in JDK9)), you'll need to write your own SslClientEngineFactory. It should be almost identical to the SslContextClientEngineFactory but just needs the ability to set the ApplicationProtocols in the same way we're now setting hostname verification.\n. @spockz That seems reasonable to me, especially considering that Netty made modifications to allow those to work with netty-tcnative.. Hi @glassorio, thanks for the report. I'll look into getting this fixed up again.. Hi @mkhq, thanks for the pull request. I'll get someone who knows finagle-redis better than me to take a look soon.. Sorry, my mistake. I now see the context from the other issue / pull request. I'm going to put this up for review internally and run against our existing internal code. Thanks.. Hi @DieBauer, thanks for reporting. This is definitely a bug. I was able to easily reproduce this given your steps. Is this something you would be interested in trying to fix via a pull request?\n. Oops, sorry I missed it. :). I've been chatting with @bryce-anderson about this offline. \nFrom my perspective, it's important that client.hashCode terminates, especially in the case of a properly constructed Finagle client / server. We do use hashCode internally and I'm surprised we haven't run into this before.\nHowever, I'm not sold on comparing the equality of clients though, considering we have StackParams which take arguments that can have non-terminating hashCode values, as in this example. I do believe this is an appropriate fix too given the situation.\n. Thanks for the PR. I will work on getting this pulled in internally and reviewed.. Hi @DieBauer, \nThanks again for the pull request. This has been submitted internally and pushed back out to GitHub as commit https://github.com/twitter/finagle/commit/88e7bea9bf29bc5fed3207782bf82b25bf869c4a. @adleong seems like the PR associated with this issue was committed in https://github.com/twitter/finagle/commit/9deb18b45415b0961c7ca26b44ce967d6f73a18e so I'm going to close out this issue.. Closing this issue as Finagle has been on version 4.1.28 for a bit. . I had a branch which addressed this specific exception a few months back, but decided against shipping it at the time, as I wasn't sure that where I was dealing with the exception was appropriate in all cases. I'll probably take another stab at this as time allows. At the very least we should be able to suppress the stack trace, as @spockz suggests. . Hi @xerial. Cool framework you've built. I will get this submitted internally and let you know when it's synced back out to GitHub. Thanks.. Thanks for the report @corhere. Would you be interested in sending a pull request to fix this?. @acidghost Thanks for asking. CHANGELOG entries are not necessary for the examples.. Resolved via pull request.. Thanks for reporting this @gpoulin. Sorry for the lack of response here. I will try to look into this sometime this week.. @gpoulin I started looking into this a little bit yesterday. If you are able to share more about your specific scenario (e.g. what protocol that client is using) that would be helpful to try to reproduce. Thanks.. Hi @acidghost. This is a very reasonable change, and I think it improves the existing functionality. We didn't make it Future-based originally because we didn't need the functionality based on how our credentials and authorization metadata are distributed internally. \nMy only request here would be to try to do the client side as well at the same time. I would like the two APIs to stay in sync. Thanks.. Thank you for submitting a pull request, @acidghost. Your commit was submitted and pushed back out to GitHub here. . Please change to use the Netty4ServerEngineFactory instead. Something along the lines of\nval config = SslServerConfiguration(\n  keyCredentials = KeyCredentials.CertAndKey(new File(serverCert.cert()), new File(serverCert.key()),\n  trustCredentials = TrustCredentials.CertCollection(new File(clientCert.cert()),\n  clientAuth = ClientAuth.Needed)\n.... You should be able to just use the Client Configuration here. Something like ...\n.withTransport.tls(SslClientConfiguration(\n  keyCredentials = KeyCredentials.CertAndKey(new File(clientCert.cert()), new File(clientCert.key())),\n  trustCredentials = TrustCredentials.CertCollection(new File(serverCert.cert())))\nand you could optionally include the Netty4SslClientEngineFactory as the second parameter.. Undo this change please. If you would like to add this outside the context of this pull request, we can discuss it in a separate PR.. Undo this change please. If you would like to add this outside the context of this pull request, we can discuss it in a separate PR.. Undo this change please. If you would like to add this outside the context of this pull request, we can discuss it in a separate PR.. Undo this change please. If you would like to add this outside the context of this pull request, we can discuss it in a separate PR.. Please move this to a file named SniSupport.scala in the same directory.. For mapping, I believe we should use Option[Map[String, SslServerConfiguration]] instead.\nNone means the parameter is off.\nSome(sniMapping) is a mapping from hostnames to SslServerConfigurations. Remove. implicit val param: Stack.Param[SniSupport] = Stack.Param(SniSupport(None)). private[ssl]. Remove.     private[this] def addSniHandler(\n      channel: Channel,\n      factory: SslServerEngineFactory,\n      sniMapping: Map[String, SslServerConfiguration]\n    ): Unit = {\n      ...\n    }.     val SniSupport(mapping) = params[SniSupport]\nmapping match {\n  case Some(sniMapping) =>\n    addSniHandler(ch, factory, sniMapping)\n  case None => \n    ...\n}. Please make this Future => NettyFuture. Since it's the Twitter codebase, Future within it almost always means Twitter Future.. mapping: Map[String, SslServerConfiguration]. promise.setSuccess(mapping.get(hostname)).     keyCredentials = KeyCredentials.CertAndKey(serverCert.certificate(), serverCert.privateKey()),\ntrustCredentials = TrustCredentials.CertCollection(clientCert.certificate()). SniSupport(Some(serverCerts.mapValues(mkConfig))). Change mkClient to just take hostname: String instead of hostname: Option[String] here, so that it's not necessary to calling hostname.get later.. 30 seconds seems much too long, please reduce.. This test failed for me until I removed the newline.. Please change from 300 seconds to something more reasonable.. Please sort the imports.. +1. Please sort imports.. +1. Remove blank line.. Considering that there are already specific Java compatibility classes (*Config.java), is it still an issue to name it `KeyCredentials.KeyManagerFactory`?. +1. Remove blank line.. Same. Remove extra blank line above the scaladoc definition.. It's a good question. This was written before native engines supported TrustManagerFactor[ies]. Part of the comment is now wrong.. Remove blank line.. TrustManagerFactory. How about leaving this comment as 'TrustCredentials.Unspecified does not change the builder.'. I think we'll want to eventually change this, but it shouldn't need to happen in the same review.. I'm not sure how many certs are generally in a KeyManagerFactory when it's used. I'm on the fence about whether it's worth adding.\n\nMy understanding is that you would need to do the following:\n1. Create a KeyManager from the KeyManagerFactory. kmf.getInstance(algorithm)\n2. Get the aliases\n2a. For client certs, get the client aliases. km.getClientAliases(algorithm)\n2b. For server certs, get the server aliases, km.getServerAliases(algorithm)\n3. For each alias, call km.getCertificateChain and verify each set.. KeyManagerFactory. Can you separate this out into a separate TrustManagerFactory test?. KeyManagerFactory. Remove blank line.. Remove. Can you add a test for this to SslConfigurationsTest?. getTrustManagers and checkTrustCredentialsNotSupported seem to be missing necessary changes.. Remove the '@see' line.. Please update to the renamed version.. Thanks. Please undo the spacing change here.. Please move the '=>' back near the closing parenthesis.. Please undo the spacing change.. Please move the '=>' back near the closing parenthesis.. Remove. I think it's ok to not do this.. Can you add a note to the comments for this method that indicates that unlike Cert/Key Cert/Key/Chain, that using KeyManagerFactory does not ensure that the certificates contained within the KeyManagerFactory are not expired.. Can you add a note to the comments for this method that indicates that unlike Cert/Key Cert/Key/Chain, that using KeyManagerFactory does not ensure that the certificates contained within the KeyManagerFactory are not expired.. TBH, I'm not sure which is better, but I'd prefer it to be consistent for now.. Mind updating this note. I think we would prefer folks now to return a Future.exception instead of throwing one.. Future.True here and other places where you have Future.value(true). We generally use Future.respond in code within Finagle as opposed to Future.onSuccess and Future.onFailure, especially when there is code for both branches. Would you mind switching this review to use Future.respond instead?. Future.False to go along with Future.True.. +1 pending writes will get written while the client is still trying to determine whether the remote peer is authorized.. Looks like the server side code here waits for the successful result of sessionVerifier, but we should have a test for this nonetheless.. Can we make this:\naddress match {\n    case Address.Inet(isa, _) if !isa.isUnresolved => Future.True\n    case _ => Future.False\n}. Thank you for switching this! \ud83d\ude04 . Thanks for asking. For us it would look like ...\n\ndef apply(\n    address: Address,\n    config: SslServerConfiguration,\n    session: SSLSession\n): Future[Boolean] = {\n   // More Here\n}. The `respond` within the `verifySession` method looks correct, but the one outside of it is not. There it's fine to use `onSuccess` in this instance:\n\n...\nverifySession(session, ctx).onSuccess { _ => \n    if (on...setDone()) {\n      ...\n      ctx.pipeline.remove(self) ...\n   }\n}\n....\n",
    "ivankelly": "There's a licensing problem with using com.twitter.libthrift-0.5.0-7.\nThis is a derived work of apache libthrift, thus falls under the ASLv2. Clause 4(d) states that when you distribute the derived work, you must also distribute the NOTICE from the original work. Twitter libthrift does not do this, which put it in violation of the license.\nWhat's more, anyone who pulls in finagle and redistributes in binary form with dependencies will also be in violation (which is my problem). Could the twitter libthrift source be made available, or at least the NOTICE added to the jar.. > I believe that you can edit the libthrift JAR on your end to add the NOTICE file.\nI don't have the notice file though. The modified libthrift contains changes which are presumably copyrighted to twitter, so it's twitter that would have to provide the NOTICE.\n\nAlternatively, you can instead exclude our fork of libthrift, and depend explicitly on vanilla libthrift-0.5.0.\n\nIsn't there some concurrency bug though, which was the whole reason for the fork?\n\nSorry for the oversight, and thanks for pointing it out to us.\n\nNo worries. This stuff is very easy to overlook.. @mosesn if one were to put the thrift NOTICE directly into the jar, it would be assigning the copyright of the modifications twitter made to the ASF, which while I'm sure it's fine, is a little weird. Anyhow, this isn't a big deal. Marking libthrift as ASLv2 in my project for now, and as it's a ASF project, it'll be covered by the projects own NOTICE.\nAnyhow, as I said, no big deal, especially with the upgrade to 0.10. Thanks for the response.. ",
    "stefanlance": "Closing this since we upgraded to libthrift-0.10.0 as of https://github.com/twitter/finagle/commit/61c7a71182866250e53f9731c46f31dde28d464c.. The integration tests have a Pants target as of https://github.com/twitter/finagle/commit/0f96f6ca3b6d0ad7dba4233af43b80a9abe19ce3 but they don't yet run in Travis.. I think this is because the client doesn't have the CLIENT_MULTI_RESULTS flag. Looking into whether we can add it to the client's list of base capability flags.. This should be fixed as of SHA https://github.com/twitter/finagle/commit/a734b2565080ea9cf333aed926a47a152052ce3e.. I'm unable to reproduce this with Finagle 18.8.0 and MySQL 8.0.12. @iwag Are you still seeing this issue?. Sorry, wasn't passing the max connections flag. I see this error locally.. We're working on a patch.. This should be resolved as of https://github.com/twitter/finagle/commit/89484ecc216b94ac1dcdfadc16d9f179ccf3c345.. Closing this since we upgraded to libthrift-0.10.0 as of https://github.com/twitter/finagle/commit/61c7a71182866250e53f9731c46f31dde28d464c.. A patch is in progress.. This should be fixed with https://github.com/twitter/finagle/commit/6f8adbfe90a6573de98b0653223d4fd0b6c4a4ed.. Closing since a fix was merged in https://github.com/twitter/finagle/commit/0c39217724c2c701b2b7f46932ee5869a997c061.. Hi @zhangandyhui. You might find it helpful to take a look at the Thrift Client and Server examples in finagle-example.. Thanks @Axxiss. I think I agree that it is in milliseconds. I'll have this reviewed and merged internally.. Thanks again, @Axxiss. This has been merged in https://github.com/twitter/finagle/commit/942fb33a5454a28702c52bae46321712fea41c13.. Hi @shakhovv. Thanks for the ticket. I'm able to reproduce this exception locally with the test you've provided. What's curious is that I don't see the exception in the pubsub integration tests. I'll look into this.. I see this with Redis 3.2.12 as well as Redis 4.0.10.. Hi @hussain21j. I took another look at this recently and the reason the pubsub integration tests work is that the servers they spin up don't require authentication. I think the test @shakhovv posted fails because a new service is created when the client tries to send the subscribe command, and this service has not yet authenticated. The call graph I'm looking at is in SubscribeClient: subscribe calls retry calls doRequest calls RedisPool.forSubscription calls factory.newService.\nAs far as I can tell, the SubscribeClient isn't allowed to send Auth requests as written. This makes authenticating subscriptions a bit tricky.\nUnfortunately work on finagle-redis hasn't been internally prioritized as of late so I'm unsure when a fix will be merged but I'll try to dig in some more. Of course feel free to submit a PR if you find a fix.. I have a proof of concept for a patch. We can authenticate before we send the subscribe command in SubscribeDispatcher.apply and handle the case of receiving a StatusReply (authentication successful) in SubscriptionManager.onMessage. The fix isn't this simple because it requires some extra machinery that will store the password provided on the first Auth command and pass it to SubscribeDispatcher.apply, but in theory this is possible.. The problem with the above approach is that it requires storing and passing around the password between the client and the subscribe dispatcher. Here are some other ideas:\n\nAllow a password to be passed to the Subscribe command. This isn't ideal since it's not how vanilla redis clients interact with the server, but I think it would suffice as a workaround.\nLook into why the Subscribe command creates a new service and check if we can get away without doing so. (The new service is what requires re-authenticating.)\n\nAs I mentioned earlier we aren't prioritizing work on finagle-redis internally and we've decided to not fix this unless it gets more attention. Hopefully there's enough detail here so that a motivated external user can pick up from here and submit a patch, if desired.. Thanks @komsit37. We're working on a fix for this.. This should be resolved as of https://github.com/twitter/finagle/commit/c404078f4d2ae1dbbbe5799a2aa554fd216b09dd.. ",
    "esiegel": "Just doing my part. Typically, how out of sync are your repos?\n. @mariusaeriksen that's good to hear that usually there isn't much of a time gap.  Thanks for the info.\n. ",
    "trevex": "Thanks,\nI am having a look at it.\n. ",
    "infinity0": "Sorry, I was unclear in my bug report. I'm depending on finagle-stream in my own code, and according to the instructions in finagle's README.md I only need to add some libraryDependencies. I have added the http://maven.twttr.com resolver now and everything works. Perhaps you could update the README to reflect this?\n. BTW I appreciate this functionality may not be needed within Twitter, Inc. but it would definitely be useful outside for the reasons I mentioned. If pointed in the right direction, I'm happy to try to implement this myself.\n. @coops how is your progress on this? I found https://github.com/twitter/finagle/tree/master/finagle-stream/src/main/scala/com/twitter/finagle/stream but I think we should be more generic and not HTTP-specific (as most of the packages in that class unfortunately are), since other protocols like SMTP/XMPP will need similar functionality.\n. Ah, this is a different from what I had in mind. This pull request allows a finagle client to connect through some existing HTTP/HTTPS proxy. I can see why you mentioned the socks proxy now, since it is analogous.\nBy contrast, what I meant by this bug report, was to implement a HTTP/HTTPS proxy server using finagle. In other words, the finagle receives the CONNECT request, opens a TCP connection to the indicated host, sends an OK respone back, then switches the Transport into being a tunnel for the duplex TLS streams.\n. ",
    "sprsquish": "Cooper is currently working on this as well: https://twitter.com/cooperb/status/307570973983522816\nMaybe you could combine efforts.\n. Thanks for the report. A fix is on the way.\n. fixed here: cf8a063e63e7d7358702245e1cbe91b3972e5ed9\n. Committed: ca527193673108745e8e88c2ea9308549ff2f5cf\n. Please merge master and resubmit. I tried pulling this internally and ran into merge conflicts with what we had. Those changes are now in GitHub's master.\n. Ah.. this is my bad. I got this mixed up with util. I'll push the changes for finagle later today.\n. Here's what I see when I try to apply the patch:\n```\n../patch:17: trailing whitespace.\nimport com.twitter.finagle.dispatch.ExpiringServerDispatcher\n../patch:35: trailing whitespace.\n    val channelMaxLifeTime = config.hostConnectionMaxLifeTime getOrElse Duration.Top\n../patch:63: trailing whitespace.\n    val listeningServer = server.serve(config.bindTo, factory)\n../patch:112: trailing whitespace.\n * This Codec is a newline (\\n) delimited line-based protocol. Here we re-use existing\n../patch:172: trailing whitespace.\n      // Issue a request which is NOT newline-delimited. Server should close connection\nChecking patch finagle-core/src/main/scala/com/twitter/finagle/builder/ServerBuilder.scala...\nerror: while searching for:\n      tracer = tracer\n    )\nval listeningServer = server.serve(config.bindTo, serviceFactory)\nval closed = new AtomicBoolean(false)\n\nif (!config.daemon) ExitGuard.guard()\n\nerror: patch failed: finagle-core/src/main/scala/com/twitter/finagle/builder/ServerBuilder.scala:464\nerror: finagle-core/src/main/scala/com/twitter/finagle/builder/ServerBuilder.scala: patch does not apply\nChecking patch finagle-core/src/main/scala/com/twitter/finagle/netty3/server.scala...\nChecking patch finagle-core/src/test/scala/com/twitter/finagle/builder/ServerChannelConfigurationSpec.scala...\n```\n. The tool basically pulls the patch from github and uses git-am:\nwget https://github.com/twitter/finagle/pull/168.patch\ngit am -s 168.patch\n. Pulled internally. Thank you.\n. I'm getting errors in the tests. Do you see these when you run them?\n[error] x IdleConnectionFilter should\n[info]   + count connections\n[info]   + refuse connection if above highWaterMark\n[info]   + try to close an idle connection if above lowerWaterMark\n[error]   x don't close connections not yet answered by the server (long processing requests)\n[error]     null (LinearSeqOptimized.scala:135)\n[error]     scala.collection.LinearSeqOptimized$class.last(LinearSeqOptimized.scala:135)\n[error]     scala.collection.immutable.List.last(List.scala:76)\n[error]     com.twitter.collection.BucketGenerationalQueue.collect(GenerationalQueue.scala:144)\n[error]     com.twitter.finagle.channel.IdleConnectionFilter.closeIdleConnections(IdleConnectionFilter.scala:80)\n[error]     com.twitter.finagle.channel.IdleConnectionFilterSpec$$anonfun$1$$anonfun$apply$20$$anonfun$apply$22.apply(IdleConnectionFilterSpec.scala:89)\n[error]     com.twitter.finagle.channel.IdleConnectionFilterSpec$$anonfun$1$$anonfun$apply$20$$anonfun$apply$22.apply(IdleConnectionFilterSpec.scala:66)\n[error]     com.twitter.util.Time$.withTimeFunction(Time.scala:347)\n[error]     com.twitter.finagle.channel.IdleConnectionFilterSpec$$anonfun$1$$anonfun$apply$20.apply(IdleConnectionFilterSpec.scala:66)\n[error]     com.twitter.finagle.channel.IdleConnectionFilterSpec$$anonfun$1$$anonfun$apply$20.apply(IdleConnectionFilterSpec.scala:64)\nThis one used to block infinitely so I added timeouts to the latch and Awaits so I could get something out of it.\nerror] x Finagle client should\n[error]   x handle pending request after a host is deleted from cluster\n[error]     1.seconds (CountDownLatch.scala:13)\n[error]     com.twitter.util.CountDownLatch.within(CountDownLatch.scala:13)\n[error]     com.twitter.finagle.builder.EndToEndSpec$$anonfun$1$$anonfun$apply$4.apply(EndToEndSpec.scala:37)\n[error]     com.twitter.finagle.builder.EndToEndSpec$$anonfun$1$$anonfun$apply$4.apply(EndToEndSpec.scala:12)\n. Yea.. I have a fix for the null exception that augments that PR. It checks that the list isn't empty after doing the compaction. The EndToEndSpec is a new error though. The first request doesn't ever make it to the service. It blocks here: https://github.com/twitter/finagle/blob/master/finagle-core/src/test/scala/com/twitter/finagle/builder/EndToEndSpec.scala#L36\n. Perfect. Thanks!\n. This has been merged to master internally. It'll go out in the next release, most likely next week. Thanks again!\n. Looks like Windows' firewall is probably blocking the port.\n. I don't know much about debugging on Windows. Do you know if the server is binding to the right interface? \n. That's the interface the client is trying to connect to, but what is the server binding to? On linux you can use the lsof utility to see what's bound to what. Is there something like that for Windows?\n. @mosesn the server still needs to be able to bind to the external address. \nI'm not sure why Windows would block that. Are there tools for inspecting the network stack on Windows?\n. This is the first I'm hearing of a flag called SamplingKnown. Where are you seeing that in the documentation?\n. Right. But it shouldn't need to take it into account as whether or not the sampling is known is encoded in TraceId.sampled. \nHow are you sending TraceIds over the wire? If you've rolled something outside of finagle, you'll need to set TraceId.sampled based on SamplingKnown.\n. Aaaahh. Okay. I see what you're saying now. The first clause in isActivelyTracing looks for sampled == Some(false) and flags == 0, but it's possible now to have sampled == Some(false) and flags == 2L. In which case the the sample is taken when it shouldn't be.\n. LGTM\n@mosesn do you mind pulling this in?\n. ",
    "coops": "this week. probably tomorrow.\ni'm implementing it in a similar fashion to the socks proxy support, so it'll be protocol-generic.\n. pull request:\nhttps://github.com/twitter/finagle/pull/148\n. sorry, I broke this by doing a small refactor and relying on the tests.\n. hey guys, i don't think my bugfix commit made it in. it was https://github.com/foursquare/finagle/commit/b77229e0ab4dd8ce5e466b9fd736ebf20b473299 \n. cool, thanks. are you planning to cut a 6.3.1 at the same time?\n. burn 1 2 dis\n. i don't know netty well enough to say. if we change this behavior we should also change it in SocksConnectHandler.scala, which i cribbed it from.\n. ",
    "roymax": "how to use scala-bootstrapper with finagle-6.2.1 and scala 2.10?\n. hi stevegury,\ni checked finagle-zipkin pom.xml again, dependency is 2.4.1 but not 3.4.0 \n<dependency>\n      <groupId>com.twitter</groupId>\n      <artifactId>scrooge-runtime</artifactId>\n      <version>2.4.1-SNAPSHOT</version>\n    </dependency>\nscrooge(3.0.8) is the latest version at https://github.com/twitter/scrooge/ and i can't find the scrooge 3.4.0 version.\n. sorry\uff0cscrooge-runtime version is 2.4.0 and isn't 2.4.1-SNAPSHOT\ni'm  removed exclude(\"com.twitter\",\"scrooge-runtime\") and it is the same problem.\nhere is dependency via sbt dependency-graph\n[info] com.twitter:ask_2.9.1:1.0.0-SNAPSHOT [S]\n[info]   +-ch.qos.logback:logback-classic:1.0.11\n[info]   | +-ch.qos.logback:logback-core:1.0.11\n[info]   | +-org.slf4j:slf4j-api:1.7.4\n[info]   |\n[info]   +-com.oracle:ojdbc14:10.2.0.4.0\n[info]   +-com.twitter:finagle-core:6.3.0 [S]\n[info]   | +-com.twitter:util-collection:6.3.0 [S]\n[info]   | | +-com.google.code.findbugs:jsr305:1.3.9\n[info]   | | +-com.google.guava:guava:13.0\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | +-commons-collections:commons-collections:3.2.1\n[info]   | |\n[info]   | +-com.twitter:util-core:6.3.0 [S]\n[info]   | +-com.twitter:util-hashing:6.3.0 [S]\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | |\n[info]   | +-com.twitter:util-jvm:6.3.0 [S]\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | |\n[info]   | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | |\n[info]   | +-io.netty:netty:3.5.12.Final\n[info]   |\n[info]   +-com.twitter:finagle-ostrich4:6.3.0 [S]\n[info]   | +-com.twitter:finagle-core:6.3.0 [S]\n[info]   | | +-com.twitter:util-collection:6.3.0 [S]\n[info]   | | | +-com.google.code.findbugs:jsr305:1.3.9\n[info]   | | | +-com.google.guava:guava:13.0\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | +-commons-collections:commons-collections:3.2.1\n[info]   | | |\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | +-com.twitter:util-hashing:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-jvm:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-io.netty:netty:3.5.12.Final\n[info]   | |\n[info]   | +-com.twitter:finagle-http:6.3.0 [S]\n[info]   | | +-com.twitter:finagle-core:6.3.0 [S]\n[info]   | | | +-com.twitter:util-collection:6.3.0 [S]\n[info]   | | | | +-com.google.code.findbugs:jsr305:1.3.9\n[info]   | | | | +-com.google.guava:guava:13.0\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | | +-commons-collections:commons-collections:3.2.1\n[info]   | | | |\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | +-com.twitter:util-hashing:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-jvm:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | | |\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-io.netty:netty:3.5.12.Final\n[info]   | | |\n[info]   | | +-com.twitter:util-codec:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | +-commons-codec:commons-codec:1.5\n[info]   | | |\n[info]   | | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-commons-lang:commons-lang:2.6\n[info]   | |\n[info]   | +-com.twitter:ostrich:9.1.0 [S]\n[info]   |   +-com.twitter:scala-json:3.0.1 [S]\n[info]   |   +-com.twitter:util-core:6.1.0 (evicted by: 6.3.0)\n[info]   |   +-com.twitter:util-eval:6.1.0 [S]\n[info]   |   | +-com.twitter:util-core:6.1.0 (evicted by: 6.3.0)\n[info]   |   | +-org.scala-lang:scala-compiler:2.9.1 [S]\n[info]   |   |\n[info]   |   +-com.twitter:util-jvm:6.1.0 (evicted by: 6.3.0)\n[info]   |   +-com.twitter:util-logging:6.1.0 (evicted by: 6.3.0)\n[info]   |\n[info]   +-com.twitter:finagle-thrift:6.3.0 [S]\n[info]   | +-com.twitter:finagle-core:6.3.0 [S]\n[info]   | | +-com.twitter:util-collection:6.3.0 [S]\n[info]   | | | +-com.google.code.findbugs:jsr305:1.3.9\n[info]   | | | +-com.google.guava:guava:13.0\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | +-commons-collections:commons-collections:3.2.1\n[info]   | | |\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | +-com.twitter:util-hashing:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-jvm:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-io.netty:netty:3.5.12.Final\n[info]   | |\n[info]   | +-org.apache.thrift:libthrift:0.5.0\n[info]   |   +-commons-lang:commons-lang:2.5 (evicted by: 2.6)\n[info]   |\n[info]   +-com.twitter:finagle-zipkin:6.3.0 [S]\n[info]   | +-com.twitter:finagle-core:6.3.0 [S]\n[info]   | | +-com.twitter:util-collection:6.3.0 [S]\n[info]   | | | +-com.google.code.findbugs:jsr305:1.3.9\n[info]   | | | +-com.google.guava:guava:13.0\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | +-commons-collections:commons-collections:3.2.1\n[info]   | | |\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | +-com.twitter:util-hashing:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-jvm:6.3.0 [S]\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | |\n[info]   | | +-io.netty:netty:3.5.12.Final\n[info]   | |\n[info]   | +-com.twitter:finagle-thrift:6.3.0 [S]\n[info]   | | +-com.twitter:finagle-core:6.3.0 [S]\n[info]   | | | +-com.twitter:util-collection:6.3.0 [S]\n[info]   | | | | +-com.google.code.findbugs:jsr305:1.3.9\n[info]   | | | | +-com.google.guava:guava:13.0\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | | +-commons-collections:commons-collections:3.2.1\n[info]   | | | |\n[info]   | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | +-com.twitter:util-hashing:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-jvm:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-com.twitter:util-logging:6.3.0 [S]\n[info]   | | | | +-com.twitter:util-app:6.3.0 [S]\n[info]   | | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | | |\n[info]   | | | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | | |\n[info]   | | | +-io.netty:netty:3.5.12.Final\n[info]   | | |\n[info]   | | +-org.apache.thrift:libthrift:0.5.0\n[info]   | |   +-commons-lang:commons-lang:2.5 (evicted by: 2.6)\n[info]   | |\n[info]   | +-com.twitter:scrooge-runtime:2.4.0 (evicted by: 3.0.8)\n[info]   | +-com.twitter:util-codec:6.3.0 [S]\n[info]   | | +-com.twitter:util-core:6.3.0 [S]\n[info]   | | +-commons-codec:commons-codec:1.5\n[info]   | |\n[info]   | +-org.apache.thrift:libthrift:0.5.0\n[info]   |   +-commons-lang:commons-lang:2.5 (evicted by: 2.6)\n[info]   |\n[info]   +-com.twitter:scrooge-generator:3.0.8\n[info]   +-com.twitter:scrooge-runtime:3.0.8 [S]\n[info]   | +-com.twitter:util-codec_2.9.2:6.1.0 [S]\n[info]   |   +-com.twitter:util-core_2.9.2:6.1.0 [S]\n[info]   |   +-commons-codec:commons-codec:1.5\n[info]   |\n[info]   +-org.scala-lang:jline:2.9.1\n[info]     +-org.fusesource.jansi:jansi:1.4\n[info]\n[info] Note: The graph was estimated to be too big to display (> 15 nodes). Use `dependency-graph --force` to force graph display.\n. ",
    "ForceRs": "We were running 3.3.0 for over a year and then updated to 3.6.2 and the New I/O Worker leak started to occur.  We tried 3.6.5, but no luck.  Reverted to 3.3.0 and all is fine again.\n. What exactly are you asking for?  I am not a Netty guru by any stretch.  In fact, I did not write any of the code that deals with it.  Sorry -- we do not even use finagle; I may have posted this it he wrong spot.  Saw the Netty (New I/O worker #) reference and just echoed the error being reported.\nWe are running Apache Tomcat/7.0.34.\n. ",
    "dadrox": "We are running java 6, tomcat 6 & 7 (depending on the host), scala 2.9.2.\nWe use finagle for all of our http clients and memcached client. No server configuration at all.\nFinagle 5.2.0 was the last version that worked for us. We have that in production.\nWhen I tried to upgrade to finagle 6.2.0, our server would get an OOME after an hour or so due to a large number of \"New I/O worker #*\" threads suddenly being created and never stopping.\nWith finagle 6.2.1 we see that behavior right away.\n. No. The clients have server lifecycle.\n. Sure. Here's a representative one:\n\"New I/O  worker #108\" - Thread t@143\n   java.lang.Thread.State: RUNNABLE\n    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:210)\n    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)\n    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)\n    - locked <4848ab42> (a sun.nio.ch.Util$2)\n    - locked <55e43d51> (a java.util.Collections$UnmodifiableSet)\n    - locked <1d77d3f2> (a sun.nio.ch.EPollSelectorImpl)\n    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)\n    at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:244)\n    at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:35)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:102)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n    at java.lang.Thread.run(Thread.java:662)\nIt really looks like a netty bug to me...\n. @pk11 Unfortunately, that didn't work. Thanks for the link, though.\nI still ended up with ~450 \"New I/O Worker\" threads after about ten minutes, before killing it.\n. As a matter of fact, we sometimes specify a custom ChannelFactory for communication with backend services that can be extremely slow. Like so:\ndef newChannelFactory(name: String) = new NioClientSocketChannelFactory(\n            Executors.newCachedThreadPool(new NamedPoolThreadFactory(name + \"-FinagleClientBoss\")),\n            Executors.newCachedThreadPool(new NamedPoolThreadFactory(name + \"-FinagleClientIO\")))\nI'll see if I can work up a small program that reproduces the problem we're having.\n. Did the handling of them change wildy since finagle 5.2.0?\nWe've been using them for about 6 months without issue. And we handle the lifecycle of them directly.\n. Most likely a misunderstanding of their intent.\nWe had issues with back end systems that were taking very long times to respond (> 10 seconds), which ended up causing other requests to timeout before even getting a chance to execute.\nOur system was originally purely synchronous. Since then we've moved to Futures almost everywhere and have introduced circuit breakers.\nI'll take a look at removing all of our custom channel factories and trying my tests again.\n. That wasn't it.\nI took out all usages of a custom ChannelFactory and we still get creation of those threads sprialling out of control.\nAfter one minute of load I end up with almost 300 live threads like this:\n\"New I/O  worker #200\" - Thread t@501\n   java.lang.Thread.State: RUNNABLE\n    at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)\n    at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:210)\n    at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:65)\n    at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:69)\n    - locked <4c95af5f> (a sun.nio.ch.Util$2)\n    - locked <162281e0> (a java.util.Collections$UnmodifiableSet)\n    - locked <5a5c3b81> (a sun.nio.ch.EPollSelectorImpl)\n    at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:80)\n    at org.jboss.netty.channel.socket.nio.SelectorUtil.select(SelectorUtil.java:64)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:244)\n    at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:35)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:102)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n    at java.lang.Thread.run(Thread.java:662)\nI'm going to close this. It really looks like a netty issue rather than a finagle issue.\nThanks for your help!\n. @ravigour I believe the original problem in this issue was due to a bug (introduced by adding aggressive deadlock avoidance) in Netty 3.5.5.Final, which has since been fixed.\nI honestly can't remember which version fixed this.\nfinagle 6.4.1 depends on netty 3.5.12.Final, so you might try updating to that.\nWe're using finagle 6.22.0 (netty 3.9.4.Final) today, which works great.\nAs a guideline, the number of New I/O worker # threads in your system should be 2 * number of cores on your machine.\n. ",
    "pk11": "@dadrox perhaps related to the epoll issue mentioned here http://netty.io/news/2012/09/06/3-5-7-final.html?\n. ",
    "ravigour": "I Found there are multiple  New I/O worker #*\" threads in my application . \nI am sending 5 async call to a resp API , and found 101 NEW I/O threds in my application . \nWaited for some 20 min , but the threads are not reclaimed .\nafter running the same reuest 10 timeas found 1204   New I/O worker Threads . and then Tomcat got crashed .\ncan you please let me know how to resolve the issue ?\n. ",
    "KeithFrost": "By the way, it now seems to me that ChannelBuffers.wrappedBuffer could be used in lieu of ChannelBuffers.copiedBuffer in this patch, by analogy with other examples of usage in the same file.\n. ",
    "luciferous": "I believe we're not going to tackle this in finagle-stream. HTTP streaming should be using finagle-http/x with streaming enabled.\n. What's the issue here? decodeString consumes the HttpMessage and will mutate it. It has to in order to guarantee the return type.\n. I don't like the API and how it's been communicated. It's not unreasonable that you're surprised, however, can I understand a little more about how you're intending to use encode/decodeString?\n. It's been two years so I'm going to assume it worked for him.\n. Still in progress. This isn't really an issue, so I'm going to close it.\n. ~~rep.reader.discard seems fine, but it also seems reasonable for an onFailure handler to invoke fail. I'm not sure which to go with~~ (edit: rep.reader doesn't have fail so we're left with discard). We're currently working on a similar issue encompassing this patch. I think the desired behavior is to interrupt streaming immediately and not wait for the next trans.write before invoking discard, something like:\n``` scala\nval p = new Promise[Unit]\nval f = trans.write(rep) before streamChunks(rep.reader)\np setInterruptHandler { case intr => rep.reader.discard() }\np\n```\nWhat do you think?\n. 1. Try writing a test for transport closure before the dispatch and another after the dispatch. You'll see why setInterruptHandler is also needed.\n2. Sorry I think I left out a p.become.\n. Yes, it's here: https://github.com/twitter/finagle/blob/92052389af5006ad2bd7e6aa68ae205e5a81ecb6/finagle-http/src/main/scala/com/twitter/finagle/http/codec/HttpServerDispatcher.scala#L62.\n. Hi Senthil, thanks for raising this issue!\nI'm seeing that we do in fact set Content-Length for the Response in the server dispatcher, but not for the Request. Weird. This seems unintentional, as you suggested. If you feel up to it, you can patch this part of the client dispatcher which handles the Request and I'll pull in your changes. Your test looks good too. Would you mind moving it into finagle.http.EndToEndTest too?\nThanks and let me know if you run into any trouble.\n. If I understand correctly there's an ambiguous case when message.contentString.length=0, should we have content-length: 0 or omit the content-length header. Is that correct? If so, it may be useful to solve partially: for the ambiguous case, we'll keep the current behavior i.e., omit the content-length header; but for the case where there is certainly content, we'll add a content-length header, e.g. where req: Request:\nscala\nif (!req.isChunked && !HttpHeaders.isContentLengthSet(req)) {\n  val clen = req.getContent().readableBytes\n  if (clen > 0) HttpHeaders.setContentLength(req, clen)\n}\nThoughts, comments, etc?\n. This sounds like a bug.\n. Working on a fix this week. Thanks for being patient, everybody. Please accept this eggplant as thanks :eggplant:.\n. Please review: #300 \n. I'll have a look this week.\n. @jbripley There's an example HTTP streaming client and server in finagle/finagle-example.\n(Sorry for such a delayed reply.)\n. @mosesn I didn't have enough time to work on this last week. Don't let me delay you, if you're wanting to ransack for Reader + Writer stuff, do it. Also, there's an old gist about Streaming that was a WIP, please take a look: https://gist.github.com/luciferous/76dc78e225ebb80ae3db.\n. @kashif How's this coming along? Anything we can do to assist?\n. lgtm too\n. Yes, finagle stream has this problem. We are waiting on review of RB=416353.\n. @takc923 Is there a reason for not using finagle-http instead?\n. @jbripley Thanks for that, I'll incorporate your updates. I understand the confusion about the Readers. You don't need to implement one yourself. I think initially we thought that people would need to, but now it looks like using the Writer directly is best. I'll see what I can do to make it clearer in the PR.\nBut to answer your question quickly here, this is what you'd need to do to set up a streaming client connected to localhost on port 3000.\n``` scala\nimport com.twitter.finagle.builder.\nimport com.twitter.finagle.http.\nimport com.twitter.util._\nval client =\n  ClientBuilder()\n    .codec(RichHttpRequest)\n    .dest(\"localhost:3000\")\n    .hostConnectionLimit(1)\n    .build()\n```\nThen to use the client:\n``` scala\nimport com.twitter.io._\nclient(Request(\"/foo/bar\")) flatMap { response =>\n  println(\"Got response: \" + response)\n  response.reader.read(Int.MaxValue) flatMap {\n    case None => Future.Done\n    case Some(buf) =>\n      println(\"Read whatever was available: \" + buf.length)\n      Reader.readAll(response.reader) flatMap { remainder =>\n        println(\"Read to the end: \" + remainder.length)\n        Future.Done\n      }\n  }\n}\n```\nI think from your suggestion, it seems I should update the doc with more standalone examples.\n. @takc923 This fix for this issue should be made public shortly, so you can continue to use finagle-stream if you want. However, I recommend using finagle-http directly. The way finagle-stream uses HTTP is wrong, and I plan to merge it into the HTTP module in the future. Can you describe why you need finagle-stream over finagle-http?\n. @takc923 no problem :eggplant:\n@jbripley Yes! This is in the works. This is in fact what's holding up the stream docs.\n. Http.client.withStreaming(enabled = true) has been supported for a few months now.\n. Thanks @rodrigopr, looks good to me too :+1: \n. What happened with this, did it get merged?\n. No rush, but would be nice to get it merged. How much more work on it you think?\n. sgtm\n. Are we good to close this?\n. The original issue has been resolved.\n. is this closable?\n. The client dispatcher should set the content length for requests. See HttpClientDispatcher.scala#39. If it's not being set, then that's a bug.\n@vicentealencar is this consistent with what you're seeing?\nrequest.contentLength is misleading,  it's actually a convenience method to view the content length header, have a look at the definition. We don't manage this header each time the content is modified, however we do set it in the dispatcher, but we may not even do that in the future. finagle-http is moving towards a more \"raw\" API, which could mean header management such as this may become the responsibility of the user.\n. @mariusae thanks for clarification, yes\n@vicentealencar it seems reasonable to change MockRequest to make it more convenient to do testing, however, if we change MockRequest in this way, will this test still be testing what we expected it to? In your example, this will mean that MockRequest will pass tests, but Request will perhaps be missing a critical header outside of test usage. I think what we should look at is why the requests are being rejected by the server, can you verify that the content-length header is missing from the dispatched requests?\n. I think this issue is resolved, feel free to reopen if not.\n. @sirmax put some work into this, but it looks like we still need to address a few things. From his comments on the closed PR:\n\n\nIn this PR I tried to fix #345 by adding an SSL-specific configuration parameter. Later we concluded it was not a good idea.\n@mosesn was against re-using Transporter.ConnectTimeout for SSL, and he's probably right. It would be more like a workaround hack than a proper fix.\nThe proper fix should be somewhere around FailFastFactory. I can't yet pinpoint where exactly it should be.\n. @sirmax How's this coming along? Can we help with anything?\n. Closing this PR and updating #345 with @sirmax's last comment.\n. @LithiumTD Thanks for all the work so far. Is this ready to merge yet, @mosesn @stevegury? It looks like there are still some issues outstanding, but it also seems like we're nearly at the finish line.\n\n\nAnything else other than the following?\n1. sort imports\n2. don't need to check for ignoredPaths.isDefined\n3. @LithiumTD's questions about usage of GlobalFlags and the specifications for a test\n. @LithiumTD you can set the GlobalFlag with ignoredPackages.let. I might be misunderstanding your question because you seem to have used it correctly a few comments above.\n. Yes, that's the correct way to use it. The flag is bound to the value only within the let block. Can you describe how this doesn't work for your use case?\n. I think I'm missing why you can't use regular JVM flags, you don't need a \"full fledged TwitterApp\" to use them.\n. @dschobel @mosesn Where are with this?\n. Hi @kristofa we're working on something right now to fix the Travis builds.\n. Looks good to me too.\n. Closed by 65eb49ddb548f3748438c445012fd09e2ae1373b\n. looks good!\n. The release is imminent, but at least a week away.\n. LGTM\n. @mosesn https://github.com/twitter/finagle/pull/370/files#diff-427d6c5f1956c47f025da1ba514f27d4R110\n. @roanta thoughts\n. @roanta That seems correct.\n. I agree with @mosesn about pushing it back to the user.\nI think we should just fix the docs for now, but also provide a more convenient high level DSL which addresses these concerns.\n. @dschobel This is a slippery slope. If we take on responsibility for guaranteeing the validity of the requests sent, then should we also set Content-Type if there isn't one (not that we could even know this)? Or failing HTTP/1.0 requests with Connection: keep-alive? Or ensuring that the Content-Length actually matches the length of the message content? Or...?\n. @dschobel I'm not denying the existence of the problem, I think we should build this, but it should be separate.\n(And since we're observing signs, consider what it means that there are so many frameworks.)\n. Thank you!\n. Closed by de6c058d25a840098e8cd99e9075609315aa7c6e\n. I'm not saying this is a bad idea, but in your example, could a plain\nFuture.flatMap work?\ndef jsonService(model: JsonModel): Response = { ... }\nval myService = importantService.flatMap(jsonService)\nOn Jun 15, 2015 1:47 AM, \"raelg\" notifications@github.com wrote:\n\nHi,\nI think the following method is missing from the Service class, which will\nenable straight-forward chained service calls.\ndef andThenRep2 : Service[Req, Rep2] = {\n    new Service[Req, Rep2] {\n      override def apply(request: Req): Future[Rep2] = {\n        Service.this.apply(request).flatMap{ rep =>\n          service.apply(rep)\n        }\n      }\n    }\n  }\ne.g, this will enable the following service hierarchy:\nval importantService: Service[Request, JsonModel] = {...} // invokes the service and returns a JsonModel val jsonService: Service[JsonModel, Response] = {...} // converts the JsonModel to a valid responseval myService: Service[Request, Response] = importantService andThen jsonService\nThis simplifies the responsibility and testability of each service, while\nenabling reuse.\nThis would also enable a Service to be positioned before a Filter, as in\nthe example below:\ne.g,\nval importantService: Service[Request, [Option[JsonModel]] = {...} // invokes the service and returns a optional JsonModel val optionalMapperFilter: Filter[Option[JsonModel], Response, JsonModel, Response]  = {..} // unrwap the option and returns 404 if None, or invoke the service with the value otherwise val jsonService: Service[JsonModel, Response] = {...} // convert the JsonModel to a valid responseval myService: Service[Request, Response] = importantService andThen (optionalMapperFilter andThen jsonService)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/385.\n. FWIW I agree with @raelg, but I only have abstract reasons for why I want it. @raelg may have a concrete use case, which might be nice to know about, and why he thinks Filters are not ideal.\n\nMy reasons:\n1. We already have map[Req1](f: Req1 => Req): Service[Req1, Rep] which adapts the input type of the Service. It maintains symmetry if we have some way of also mapping the output type.\n2. Four type parameters means Filters can be quite complicated.\n3. Mapping just the output shrinks the scope of effects, which might be nice, e.g. we know that a composition of Service.andThen(b => c) will never retry the Service dispatch; the closure doesn't have access to it. We don't have this guarantee with Filter.\nOh, one more thing. The ability to compose to the right (i.e. adapt the output type) completes the Profunctor instance for Service.\n. @mosesn I just spoke with Travis, and I think maybe I should clarify a little what I'm looking for, then people can critique it as they feel is right.\nSo we have a map already in Service, and this corresponds to a contravariant map which adapts the Service's request type. This map is poorly named, imo, but maybe it made sense at one time. It's misleading for those familiar with map expecting it to adapt the output (response) type.\n```\ntrait Service {\n  // This is the contravariant map, which is already defined in Service.\n  def mapReq1: Service[Req1, Rep]\n// This is the covariant map, which we don't have.\n  def rmapRep1: Service[Req, Rep1]\n}\n```\n@mosesn I wasn't very clear before on the map I was talking about \u2013 I'm talking about rmap, which works exactly like how every other map works, no?\n@mariusae yeah, I don't know how useful it is either, maybe @raelg can compel with his use case.\n@travisbrown What do you think of this?:\ndef andThen[Rep1](f: Rep => Future[Rep1]): Service[Req, Rep1]\n. @vkostyukov right we'd call it something else\n. This is an interesting suggestion, thanks @kevints. We can prioritize this against the list of things we're working on internally, but if you're waiting on this it might be faster for us to work together with you on a PR.\n. @olix0r I don't think there's harm in having a verbose problem statement. If there's no objection, maybe we can update the problem statement with the information in your last comment.\n. FWIW I didn't see @scf37's comments as an attack. I thought the amount of detail in them demonstrated understanding and that a lot of thought (and usage) went into them.\n. Passed:\ncd finagle; ./sbt 'project finagle-core' test\ncd finagle; ./sbt 'project finagle-http' test\ncd twitter-server; ./sbt test\nBenchmark looks too good to be true, though. Let me know how it goes.\n. What's the type of the stream? Is that Process[Task, Bytevector]?\n. Ok, you said you have toBuf: Bytevector => Buf and toFuture: Task ~> Future. So we can get quite far with:\nval process: Process[Task, Bytevector]\nval vectors: Process[Future, Bytevector] = process.translate(toFuture)\nval bufs: Process[Future, Buf] = process.map(toBuf)\nLike Process[Future, Buf], Reader is an effectful stream of Bufs where each step can run Future effects. I can think of two ways to do this.\n(Beware: pseudocode below.)\n- Run bufs each step writing to a Writable.\ndef reader(bufs: Process[Future, Buf]): Reader = {\n  val writable = Reader.writable()\n  val writeSink: Process[Future, Unit] = sink.lift(writable.write)\n  (bufs to writeSink).run before writable.close()\n  writable\n}\n- Wrap the Process in a Reader interface. Implement read by a pattern-match on process.step and if it emits, return the result. Reassign the process to the next one given by the continuation.\n. Yes, if DelayedReleaseService is not part of the stack then that's the problem. In our tests we were using ClientBuilder, so quite possibly that's why we missed it.\nAnd yeah, it's all pretty confusing.\nA stream-oriented system requires services to know about the life time of their requests and response. I forget the API, but @mariusae had some idea (I think he called it Meta) like:\n```\ntrait Streaming[T] {\n  def onComplete: Future[Unit]\n}\nabstract class Service[Req: Streaming, Rep: Streaming] { ... }\n```\nThen everywhere service is used, needs to consult onComplete to determine if the service has finished processing its request and response.\n. This bit from ClientBuilder is missing from ctf.Http.scala: https://github.com/twitter/finagle/blame/develop/finagle-core/src/main/scala/com/twitter/finagle/builder/ClientBuilder.scala#L1171\n. Hi @mritman, the HTTP client should be managing connections correctly whether closed locally or remotely even when interrupted during a read or write. We test these properties quite exhaustively in https://github.com/twitter/finagle/blob/develop/finagle-http/src/test/scala/com/twitter/finagle/http/StreamingTest.scala (see the tests around line 80). I'll have to experiment with your example, but I didn't see anything out of the ordinary while testing in REPL: https://gist.github.com/luciferous/8f98fd3367af7d2aa7ef. tcpdump output seems reasonable too: http://pastie.org/private/tbiuuafiory7jsm2e9v0xg.\n. Try replacing your Tomcat server with the following:\nshell\nwhile true; do printf 'HTTP/1.1 403 Forbidden\\r\\nServer: test\\r\\n\\r\\n'|nc -l 8080; done\nYou'll see the connections are closing. Also try a Finagle HTTP server:\n``` scala\nimport com.twitter.finagle.http.{Http=>, }\nimport com.twitter.finagle.{Http, Service}\nimport com.twitter.util.{Await, Future}\nval forbidden = new Service[Request, Response] {\n  def apply(req: Request): Future[Response] = {\n    val res = Response()\n    res.status = Status.Forbidden\n    Future.value(res)\n  }\n}\nHttp.serve(\":8080\", forbidden)\n```\nThese connections are also closing, but they don't close as fast. My lsof output showed the connection count hovering around 50.\nSeems to me like the Tomcat server is the issue?\n. Ah I'm setting up the server wrongly. I need to make the server send a chunk encoded response.\nshell\nwhile true; do printf 'HTTP/1.1 403 Forbidden\\r\\nServer: test\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n1\\r\\na\\r\\n0\\r\\n\\r\\n'|nc -l 8080; done\nThe lsof count hovers around 50 again. The connections do get cleared, so it doesn't sound like a leak to me. What do you think? For curiosity's sake I also tried the Finagle server again with streaming enabled:\nscala\nval forbidden = new Service[Request, Response] {\n  def apply(req: Request): Future[Response] =\n    Future.value(Response(Version.Http11, Status.Forbidden, Reader.fromBuf(Buf.Utf8(\"a\"))))\n}\nHttp.server.withStreaming(enabled=true).serve(\":8080\", forbidden)\nI saw the same thing with lsof lines hovering around 50. The strangest thing I'm seeing is that a lot of the requests are timing out, so maybe that's worth looking into. But I don't think there's a connection leak.\n. @mritman that's reasonable. I'm really suspicious of the timeouts. I think looking into why they're happening is a good place to start.\n. So, it turns out this has a really simple explanation. Because we set up the client with withStreaming(true) it means the response received will be chunked encoded (depending on how Netty reads it from the socket). This means that before Finagle can consider a response \"done\", you have to drain the reader fully or discard it.\nAdd response.reader().discard(); and you'll see the issue go away.\nI remember being bitten by this before too, once or twice. There's definitely room to improve the API/UX here. Sorry about that.\n. And, if you weren't seeing it with the 200 OK, it might have been because the HTTP response didn't contain a body, and therefore an empty reader.\n. The clients do close if the server closes. See above where I tried to reproduce with servers that close. But the tomcat one seems to keep the connection open.\n. @spockz Raise your timeout (e.g. 1 second) and you'll see the CLOSE_WAIT disappear. With the 20ms timeout does the number of CLOSE_WAIT grow? I see it hovering at ~20 connections.\n. @spockz Regarding the 200 OK case, it really depends on how Netty reads it from the socket. If the whole request fits into the first read, Netty doesn't chunk-encode it.\n. LGTM\n. Hi @dziemba, thanks for reporting! This probably won't make it into the next release, but definitely in the one after. (It takes us a few days to test a Netty upgrade.). This looks good to me.\nI'm not sure how I feel about the name, but I can't think of something better right now. Also, I wonder if it's reasonable to invert this API, i.e., when withStreaming(true) we ALWAYS stream the message body, and add a parameter where if the message is under this size then we buffer it. What do you think?\n// Always streams message bodies, but if we know the\n// Content-Length is under 128KB, then we fully buffer.\nHttp.withStreaming(true, 128.kilobytes). I think let's go ahead with the Http.*.withStreaming(true, 128.kilobytes) API and note the behavioral change in CHANGELOG.rst.\n@vkostyukov's suggestion of minChunkSize sounds good.. Thanks for filing this issue @szysas, we'll be taking a look.. @szysas By any chance, are you using Drv.newVose directly?. @szysas Looks like this was introduced in #742.\nBefore it, we intercepted empty weight classes so that we never passed Nil into the constructor of a Distributor.\nThe patch introduces a change where now we attempt to never emit empty weight classes from partition, but this is where the bug is. We add a special case balancer, but then remove it in a subsequent update.\nThis should be fixed in the next release.. Closed by 2133620e9a18a42300da97984df7aeaeb29c6199.. @szysas Keep us posted if you manage to test this with your service.. Sure.\nIn the future are we looking to colorize? It's a much nicer read.\n. I'll add that.\n. I'm not clear on this, what are you referring to?\n. Ok, I'll look into that.\n. I'm happy to decolorize this branch, but if we're writing documentation for wide distribution, is it reasonable that we should want to optimize its presentation for the majority?\n. I think this makes sense, but is a little confusing to me. Is there a larger, more in depth section we can link to, maybe the Metrics?\n. is this ignore intentional?\n. ignore?\n. scaladoc @throws?\n(side: is this how we do things in finagle-redis, otherwise I'd prefer Try/Option)\n. scaladoc @throws?\n(side: is this how we do things in finagle-redis, otherwise I'd prefer Try/Option)\n. Any way to make this implicit class and drop the implicitConversion import?\n. What I mean is:\nscala\nimplicit class Wrap[A0](val value0: A0) extends AnyVal {\n  def asParam(implicit evidence0: CanBeParameter[A0]): Parameter =\n    if (value0 == null) {\n      NullParameter\n    } else {\n      new Parameter {\n        type A = A0\n        def value: A = value0\n        def evidence: CanBeParameter[A] = evidence0\n      }\n    }\n}\nEDIT:\nSeems like my suggestion is incompatible with null (error: value asParam is not a member of Null), maybe this is a hint that we're doing something wrong here.\nSpoke with @roanta and he seems ok with this, so I'll defer to him.\n. @missingfaktor Thank you. This is good work.\n. > how frequently is identity used?\nthis will be difficult for me to determine. would you rather i left it out? it supports this neat equality:\n(filter andThen identity) eq filter\n(identity andThen filter) eq filter\n. either i'm not sure how to do this, or it doesn't actually improve the boiler plate as you imagine. don't i still need to create a new ServiceFactory[ReqIn, RepOut] to pass into the ServiceFactoryProxy?\n. We are safe because of Service.rescue in the andThen which takes a Service argument.\n. I'm surprised this works \u2013 I thought finagle-http API was Netty free. Is this about Java subverting Scala access modifiers?\n. What do you think of adding this to StreamingTest.scala?\n. Do you also need prepConn?\nI was going to propose making these changes look more like ClientBuilder, e.g.:\nval clientStack = {\n      val stack0 = stack\n        .replace(StackClient.Role.prepConn, prepConn)\n        .replace(StackClient.Role.prepFactory, (next: ServiceFactory[Req, Rep]) =>\n        codec.prepareServiceFactory(next))\nBut I think I like your way better, because it means less reliance on Codec.\n. Leaving prepConn out will mean HTTP clients built using Stack and ClientBuilder be different \u2013 see: https://github.com/twitter/finagle/blob/develop/finagle-http/src/main/scala/com/twitter/finagle/http/Codec.scala#L154.\nThis comment is more for posterity than recommending the work be done in this PR. Eventually, I think we should reconcile the gap.\n. Right, the relevant (to this issue) difference between Stack and ClientBuilder clients is that ClientBuilder has access to the codec, via which it can inject codec-specific logic as prepConn and prepFactory. In the HTTP codec, this is implemented as DelayedReleaseService wrapping.\n. fingers crossed\n. Let's go with minChunkSize for now, if we think of something better during the review we can always change it.. Given a client Http.client.withStreaming(true, minChunkSize = 128.kilobytes), what does it do when it receives a response from the server with Content-Length: 512KB?\nDoes it mean that given loop,\ndef loop: Future[Unit] =\n  response.reader.flatMap {\n    case Some(buf) => go(buf).before { loop }\n    case None => Future.Done\n  }\n, go(buf) will ALWAYS receive a buf where buf.length >= 128.kilobytes (as the name minChunkSize implies)? Or should it mean go(buf) will always receive a buf where buf.length <= 128.kilobytes (a la socket short reads)?\nAlso, what happens if the server responds with Transfer-Encoding: chunked, no Content-Length, and sends chunks that are only 4.kilobytes, e.g.:\n```\nTransfer-Encoding: chunked\n4096\\r\\n\n[...4096 chars...]\\r\\n\n```\nDo we buffer these 4KB chunks into 128KB chunks for the client?. > First of all, I don't think there's flatMap method on Reader, you likely missed the call to read in you code.\n@edio Yes, that correct, sorry for any confusion.\n\nIDK if my understanding is correct, but this is exactly my concern with the name minChunkSize.\n\n@edio Mine too.\n\nI'm trying to understand your reasoning and I'm still not sure why you don't like the name. It does what it says it does (for messages with known length - is this part a concern?).\n\n@vkostyukov It's confusing because calling Reader.read can return chunks larger than minChunkSize.\nSorry, I know I changed my mind on the name \ud83d\ude05. What if we called it bufferSize? Then:\n1. bufferSize = 0: no buffer, Reader.read emits exactly what comes out of the Netty pipeline\n2. bufferSize = 128.kilobytes: buffer up to 128.kilobytes; Reader.read will ALWAYS return buf where buf.length <= 128.kilobytes\n3. We also note that this parameter doesn't apply to the \"write\" path, i.e. when the user does a writer.write(buf), buf.length is unrestricted here.. I don't have any better ideas. aggregateIfLessThan works for me.. OK, I'm not sure I follow, but hopefully some test/docs will clarify. I'll think about it more too.. Thinking more about this, an 8KB default may be a reasonable default here. What do people think?. \ud83d\udc4d\nAlso what do you think of using AggregateIfLessThan.aggregateIfLessThan.default instead of zero. I think I prefer if we prioritize Http.withStreaming parameters over the maxRequestSize, i.e. maxRequestSize is ignored when aggregateIfLessThan > 0. It changes behavior, but I'm concerned about complicating configuration for the user. To me, this seems to be a good default.\nActually, I wonder if we can make a bolder change and ignore maxRequestSize when Http.streaming is enabled.. Sounds good.. ",
    "mergeconflict": "Oh. Evidently there is a org.apache.thrift#libthrift;0.5.0 in the repository at maven.twttr.com. Not sure how this artifact differs from org.apache.hadoop#libthrift;0.5.0 hosted at Sonatype and Maven Central, but whatever.\n. Opened pull request #160.\n. > We recently tried to remove the need to list maven.twttr.com as a repo and push finagle in maven central, but apparently there's still bugs in this release.\nWell, finagle is readily available from Sonatype, which SBT knows about by default. No issue there, and pushing to central won't change anything. The problem is that some of finagle's dependencies are not. See my comment here: https://github.com/twitter/finagle/issues/158#issuecomment-16252180\n\nWe try to fix that in the next release, in the meantime can you list maven.twttr.com as a repo in your project?\n\nOf course, easily. But I figured I'd offer a fix for the POMs instead.\n. Yep, you're right. I've updated the pull request.\nI'm curious: I assumed those poms were there for sbt to publish, but seems not... What are they used for?\n. ",
    "hellokangning": "resolvers += \"Twitter maven\" at \"http://maven.twttr.com/\"\nworks well.\nHowever, the following does NOT work.\nresolvers += \"Twitter maven\" at \"http://maven.twttr.com\". ",
    "ponkin": "I have the same issue.\n. ",
    "avdv": "OK, good.\nDo you have a pointer to some code or Netty docs? Looking at the Netty API pages all I can see is the generic operationComplete callback function of ChannelFutureListener. Thanks!\n. Oh, you meant the standard Netty operationComplete method of ChannelFutureListener. I thought there had been some new mechanism added to handle specific completion cases in Netty.\nActually, I'm (solely) using those conversions from finagle in order to avoid this boilerplate code, like, creating a new ChannelFutureListener, implementing the operationComplete method, et cetera.\nBut thanks, anyway!\n. No, actually my use case is a lot simpler than that.\nI'm using the unfiltered-netty{,-server} library (https://github.com/unfiltered/unfiltered) to implement a reliable HTTP PUT Service, with file locking and nio FileRegion transfers. Knowing about the com.twitter.util.Future class I wanted to write up something along the lines for Netty myself but figured finagle must have something equivalent already... Right I was. ;-)\nSo, as intimated before, I'm only using finagle's conversions as a convenience. Stumbling over this nuance of disbalance in the code just made me wonder. No big deal, actually, I can just rip it out and adjust the code for my needs. Thanks again!\n. ",
    "wonlay": "steve told me we're using birdcage finagle for early development, and gave me some tips on testing dev version of finagle on my services.\nI have another (i think is better) implementation in birdcage, and my testing server has been running good during the weekend, will do a final clean up and send a reviewboard early next week.\n. ",
    "Andrei-Pozolotin": "there is already plenty of \"IDE-specific entries\" :-)\nsee https://github.com/twitter/finagle/blob/master/.gitignore\ni.e intellij\n.idea\n*.iml\n. no, you should change your mind\n. ",
    "mjparrott": "+1 - this would be useful. There is good info here: http://twitter.github.io/finagle/guide/Clients.html but links to the specifics would be nice.\n. ",
    "robstar-nest": "it looks like the gist isn't working for some, so here's the scala file:\n```\nimport com.twitter.util.Future\nimport com.twitter.finagle.{Service => FinagleService}\nimport com.twitter.finagle.builder.{ServerBuilder, ClientBuilder}\nimport com.twitter.finagle.http.{RichHttp, Http, Request, Response}\nimport java.net.InetSocketAddress\nimport org.jboss.netty.handler.codec.http.HttpResponseStatus\nimport org.jboss.netty.handler.codec.http.HttpHeaders.{Names => HttpHeaderNames}\nobject Demo extends App {\nval closeConnections: Boolean = args contains \"--close\"\nprintln(\"Our http server %s close connections\".format(if (closeConnections) \"will\" else \"will NOT\"))\n  val okService = new FinagleService[Request, Response] {\n    def apply(req: Request): Future[Response] = {\n      val resp = req.response\n      resp.contentString = \"ok\"\n      if (closeConnections) resp.setHeader(HttpHeaderNames.CONNECTION, \"close\")\n      Future.value(resp)\n    }\n  }\nval okServer = ServerBuilder()\n    .codec(RichHttpRequest)\n    .bindTo(new InetSocketAddress(9876))\n    .name(\"okServer\")\n    .build(okService)\nprintln(\"Giving server a few seconds to spin up.\")\n  Thread.sleep(3000)\nval okClient = ClientBuilder()\n    .codec(RichHttpRequest)\n    .hosts(\"localhost:9876\")\n    .hostConnectionLimit(1)\n    .build()\ndef probe(): Future[Boolean] = okClient(Request(\"/\")).map { resp =>\n    resp.status == HttpResponseStatus.OK\n  }\nprintln(\"Probing:\")\n  for (i <- 1 to 5000) {\n    val r = probe() map { _ match {\n      case true => \".\"\n      case false => \"X\"\n    }} rescue {\n      case e => Future.value(\"E\")\n    }\n    print(r.get())\n  }\n  println()\nprintln(\"exiting.\")\n  okClient.release()\n  okServer.close()\n}\n```\nand here's the build.sbt\n```\nname := \"demo\"\nversion := \"0.0.1\"\nscalaVersion := \"2.9.2\"\nlibraryDependencies += \"com.twitter\" %% \"finagle-http\" % \"6.4.0\"\n```\n. It feels like sometime after the response is received and before the connection is put back in the pool, the underlying netty layer is \"surprising\" finagle with the TCP connection-close, causing finagle to abort the request (even though it is already complete)\n. Thanks for the Http.fetchUrl tip! Very helpful for getting unblocked on what i'm working on right now.\nIt seems like a bug for the connection to be returned to the pool if the server responded with \"Connection: close\". Finagle should let ConnectionManager decide whether the connection is reusable, right?\n. But it does know. That's the point of a ConnectionManager, isn't it? Knowing, for a given protocol, what the state of a connection is, including whether it is capable of handling more requests? In HTTP, when a client receives \"Connection: close\" header, it knows that it will not be able to send more requests on that connection; why ignore that?\n. I guess i'm just not seeing how these classes, which look at HTTP headers and/or are in the http.codec package, can be said to be protocol-agnostic. Maybe we're talking about different connection managers?\n- https://github.com/twitter/finagle/blob/master/finagle-http/src/main/scala/com/twitter/finagle/http/codec/ConnectionManager.scala ,\n- https://github.com/twitter/finagle/blob/master/finagle-http/src/main/scala/com/twitter/finagle/http/codec/ClientConnectionManager.scala , and\n- http://docs.jboss.org/netty/3.2/api/org/jboss/netty/handler/codec/http/HttpHeaders.html#isKeepAlive(org.jboss.netty.handler.codec.http.HttpMessage)\n. I haven't had a chance to try the patch yet, but changing the client to plain Http() didn't help:\n```\n  val okClient = ClientBuilder()\n    .codec(Http())\n    .hosts(\"localhost:9876\")\n    .hostConnectionLimit(1)\n    .build()\ndef probe(): Future[Boolean] = okClient(Request(\"/\")).map { resp =>\n    resp.getStatus == HttpResponseStatus.OK\n  }\n```\n. Thanks!\n. ",
    "raofu": "I think the exception is caused by the following sequence of events\n1. Netty sees the reply from the server. The request future is satisfied and the connection is returned back to the connection pool.\n2. The next request gets the connection from the connection pool.\n3. Netty closes the channel.\n4. The request returns a ChannelClosedException.\nIf the order of 2 and 3 is reversed, a new connection will be opened for the next request and the request will be successfully served.\nI tried to disable the connection pool logic in the source code (currently this is not configurable through ClientBuilder) and all requests are successful. If you know the connection is going to be closed after a request, you can use Http.fetchUrl instead (see https://github.com/twitter/finagle/blob/master/finagle-http/src/main/scala/com/twitter/finagle/Http.scala#L12).\n. No, I don't think this is a bug. The reply and connection close are sent as two separate events. The connection management logic tries to reuse the connection when the reply is received and it does not know the connection is going to be closed. As I described earlier, the issue happens when Finagle sees the connection close event after the connection has already been reused.\n. No, the connection management is protocol agnostic. If Finagle knows the connection is going to be closed when it sees the reply, yes, it can do the right thing and avoid reusing the connection. The problem is that reply and connection close are two separate events and a connection can be reused in beween. In the uncommon case that the server is going to close the connection after a request you can configure the client not to use connection pool.\n. @robstar-nest I am sorry that I did not know there is a ConnectionManager in finagle-http. The problem is that RichHttp was not correctly wired with the right dispatcher. Please try this patch (https://gist.github.com/raofu/5632920) and let me know if it works for you. Thanks for the detailed report and sorry about the confusion I caused earlier!\n. I tried plain Http() and did get a few ChannelCloseExceptions (significantly less than RichHttp though). I will look into this and get back to you.\n. I tried the test again on my desktop with client/server in the same process and client/server on difference processes and could not reproduce the ChannelCloseException. Now I only see the exception once every a few runs on my macbook. It seems to be a test environment issue rather than a Finagle issue at this point.\n. It looks like a netty issue to me. @trustin, can you help take a look?\n\nscala> import org.jboss.netty.handler.codec.http._\nimport org.jboss.netty.handler.codec.http._\nscala> import com.google.common.base.Charsets\nimport com.google.common.base.Charsets\nscala> import org.jboss.netty.buffer.{ChannelBuffer, ChannelBuffers}\nimport org.jboss.netty.buffer.{ChannelBuffer, ChannelBuffers}\nscala> import org.jboss.netty.handler.codec.embedder.DecoderEmbedder\nimport org.jboss.netty.handler.codec.embedder.DecoderEmbedder\nscala> val decoder = new DecoderEmbedder(new HttpResponseDecoder)\ndecoder: org.jboss.netty.handler.codec.embedder.DecoderEmbedder[Nothing] = org.jboss.netty.handler.codec.embedder.DecoderEmbedder@765cfd1d\nscala> val rep = \"\"\"HTTP/1.1 200 OK\n     | \n     | \"\"\"\nrep: java.lang.String = \n\"HTTP/1.1 200 OK\n\"\nscala> decoder.offer(ChannelBuffers.wrappedBuffer(rep.getBytes(Charsets.UTF_8)))\nres1: Boolean = true\nscala> val httpResponse = decoder.poll().asInstanceOf[HttpResponse]\nhttpResponse: org.jboss.netty.handler.codec.http.HttpResponse = \nDefaultHttpResponse(chunked: true)\nHTTP/1.1 200 OK\n\n. Should this moved to messageReceived? I thank super.channelConnected should be called after the response for the HTTP CONNECT request is received.\n. ",
    "mccv": "Bumping this one. The general problem seems to be that the backing connection pool for HTTP doesn't eject connections that close. So if the following occurs\n1. Obtain an HTTP client\n2. Make a request to an HTTP server with Connection: keep-alive\n3. Server responds with Connection: keep-alive header\n4. The connection is closed\n5. Make a second request\n6. ConnectionClosed exception from the pool\nThis\nhttps://gist.github.com/mccv/d9fdf7b85ea332962f87\nHas a repro case.\nI understand that there could be races where the connection gets closed and this should be handled gracefully on the client side, but it seems like ejecting closed connections from the pool is still the right thing to do.\n. The sleep was intentional to exacerbate the behavior. The \"bug\" we encountered was inherently racy. Looking through our code it appears that the issue here has indeed been fixed, and other issues we were running into were connection pool configuration issues.\nAs an aside, are requests queued per connection, or at the pool level and then dispatched to connections when they free up?\n. ",
    "jameslyo-nest": "Any update on this issue?\n. ",
    "laurencer": "Any progress on this? I'm getting stuck with this issue too when trying to make a large number of requests to a service.\n. ",
    "maddalab": "Please take a look at the log on the branch from which I have create the pull request [1]. All the changes here were on top of the commit that was on twitter/finagle/master/HEAD\nI do not think the changes you have in you internal repository are reflected in on Github's master\n[1] https://github.com/maddalab/finagle/commits/updates\n. For completeness, I merged into your github/master\nhttps://github.com/m2mad/finagle/pull/1\n. Erm, I should say, merged into master on a new fork of the repository .. much better.\n. fwiw, I tried this again since you last change was 4 days back. I did not see any changes pushed to master that would cause a conflict with this pull request, the pull request below confirms it. Let me know if you need assistance reviewing the change or any matters in that respect which might be preventing you from moving ahead at this time.\nhttps://github.com/m2mad/finagle/pull/1\n. I got rid of the trailing white space errors/warnings that you see.\nOn ServerBuilder , I am not certain how you are generating and/or applying the patch, but if it is of any help, here is how the automatically merged pull requests looks like [1]. The patch tool is generating context for the patch and there is a change in the code that is being used a context. This is an issue with the patch tooling and not a merge conflict. It is fairly straight forward to address manually (as a hack), you can take a look at the diff and do it. iIf you wan to do it using the tooling send me some instructions on the way have generated the patch, how you are applying the patch and I will give it a try.\n[1] https://github.com/m2mad/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/builder/ServerBuilder.scala#L476\n. I guess there is a difference between how git applies patches vs how it applies changes sets. You can do the equivalent of what I have done below.\n(a) Add a remote to my github clone of finagle in your local git repo\ngit remote add other git@github.com:maddalab/finagle.git\n(b) Fetch the remote\ngit fetch other\nThis should show you the branch other/updates\n(c) Merge the branch\ngit merge other/updates\n(d) Verify that I am not sneaking in any changes other that those in this pull request ;-)\nI will take a look at the patching later during the weekend.\n```\ntbm:workspace bhaskar$ git clone git@github.com:twitter/finagle.git tf\nCloning into 'tf'...\nremote: Counting objects: 40802, done.\nremote: Compressing objects: 100% (17616/17616), done.\nremote: Total 40802 (delta 12910), reused 39550 (delta 11706)\nReceiving objects: 100% (40802/40802), 11.26 MiB | 3.70 MiB/s, done.\nResolving deltas: 100% (12910/12910), done.\ntbm:workspace bhaskar$ cd tf/\ntbm:tf bhaskar$ git branch\n master\ntbm:tf bhaskar$ git remote -v\norigin  git@github.com:twitter/finagle.git (fetch)\norigin  git@github.com:twitter/finagle.git (push)\ntbm:tf bhaskar$ git remote add local file:///Users/bhaskar/workspace/self-finagle\ntbm:tf bhaskar$ git remote -v\nlocal   file:///Users/bhaskar/workspace/self-finagle (fetch)\nlocal   file:///Users/bhaskar/workspace/self-finagle (push)\norigin  git@github.com:twitter/finagle.git (fetch)\norigin  git@github.com:twitter/finagle.git (push)\ntbm:tf bhaskar$ git fetch\ntbm:tf bhaskar$ git fetch local\nremote: Counting objects: 935, done.\nremote: Compressing objects: 100% (210/210), done.\nremote: Total 616 (delta 228), reused 595 (delta 219)\nReceiving objects: 100% (616/616), 76.73 KiB, done.\nResolving deltas: 100% (228/228), completed with 74 local objects.\nFrom file:///Users/bhaskar/workspace/self-finagle\n * [new branch]      master     -> local/master\n * [new branch]      updates    -> local/updates\n  tbm:tf bhaskar$ git merge local/master\nAuto-merging finagle-core/src/main/scala/com/twitter/finagle/builder/ServerBuilder.scala\nMerge made by the 'recursive' strategy.\n .../twitter/finagle/builder/ServerBuilder.scala    |   24 ++++-\n .../finagle/channel/IdleConnectionFilter.scala     |   20 +++-\n .../scala/com/twitter/finagle/netty3/server.scala  |    6 --\n .../builder/ServerChannelConfigurationSpec.scala   |  110 ++++++++++++++++++++\n .../twitter/finagle/example/echo/StringCodec.scala |   19 ++--\n .../com/twitter/finagle/redis/protocol/Codec.scala |    3 +-\n .../twitter/finagle/redis/protocol/Command.scala   |    6 ++\n .../finagle/redis/protocol/commands/Misc.scala     |   66 +++++++++++-\n .../redis/protocol/commands/SortedSets.scala       |   47 +++++----\n .../twitter/finagle/redis/util/Conversions.scala   |    2 +-\n .../com/twitter/finagle/redis/NaggatiSpec.scala    |   17 ++-\n 11 files changed, 269 insertions(+), 51 deletions(-)\n create mode 100644 finagle-core/src/test/scala/com/twitter/finagle/builder/ServerChannelConfigurationSpec.scala\ntbm:tf bhaskar$ cd\ntbm:~ bhaskar$ cd workspace/self-finagle/\ntbm:self-finagle bhaskar$ git branch\n  master\n updates\ntbm:self-finagle bhaskar$ git status\nOn branch updates\nnothing to commit (working directory clean)\ntbm:self-finagle bhaskar$ git remote -v\norigin  git@github.com:maddalab/finagle.git (fetch)\norigin  git@github.com:maddalab/finagle.git (push)\ntbm:self-finagle bhaskar$ git push origin updates\nEverything up-to-date\n```\n. Closing this pull request as i messed up attempting to get the right patch, will create a new one later.\n. @sprsquish fyi, this replaced the pull request we were having trouble with earlier. Thank you.\n. For completeness, verified applying the patch locally\ntbm:myfinagle bhaskar$ curl -O https://github.com/twitter/finagle/pull/172.patch\n      % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                     Dload  Upload   Total   Spent    Left  Speed\n    100 21606  100 21606    0     0  55789      0 --:--:-- --:--:-- --:--:-- 93532\n    tbm:myfinagle bhaskar$ git am -s 172.patch \n    Applying: The ServerBuilder API in finagle provides options for specifying settings (a) channelMaxLifeTime (b) channelMaxIdleDuration and (c) OpenConnectionsThresholds.\n    Applying: Do not rely the service request completing to add a connection to the queue. This fails the trivial case of just opening connections initially on startup\n    /Users/bhaskar/workspace/myfinagle/.git/rebase-apply/patch:16: trailing whitespace.\n          super.apply(c) \n    warning: 1 line adds whitespace errors.\n    Applying: Dont forget to remove the connection from the queue\n    /Users/bhaskar/workspace/myfinagle/.git/rebase-apply/patch:23: trailing whitespace.\n    /**\n    /Users/bhaskar/workspace/myfinagle/.git/rebase-apply/patch:32: trailing whitespace.\n      private[channel] def closeIdleConnections() = \n    warning: 2 lines add whitespace errors.\n    Applying: Fix another issue with ICF.\n    Applying: Add a counter to track the number of closed connections\n    Applying: squelch trailing ws\n    tbm:myfinagle bhaskar$ \n. I will take a look in a bit (~2/3 hrs). I did build and run the test. Recall I mention a change in BGQ twitter/util that I had pushed earlier. I have built and installed twitter/util into my ivy2 cache locally. If you have time you can verify that.\n. If it is of any use. https://github.com/twitter/util/pull/64\n. Yes, that one is me, I did not include another commit that had to go with this push request when I was trying to sort out the patching stuff, at the internal branch here has quite a few other changes. I clearly did not run the tests when I redid the pull request for the patch issue. Sorry about that.\nThe spec is not using the StringCodec that it thinks it is using. I had defined a new StringCodec for the new spec I added ServerChannelConfigurationSpec and the StringCodec from that class is hiding the one EndToEndSpec wants to use.\nThe new one I defined does not include the logic to introduce a new line. You can do a quick test and add a new line \"123\\n\" in EndToEndSpec or rename the StringCodec in ServerChannelConfigurationSpec to ServerChannelConfigurationCodec. Once again sorry, let me know how you would like me to fix it or if you are good with the rename or adding a newline.\n. [info] + Finagle client should\n[info]   + handle pending request after a host is deleted from cluster\n[info]   + queue requests while waiting for cluster to initialize\nRenamed StringCodec in ServerChannelConfigurationSpec to ServerChannelConfigCodec.\nLet me know if I can help further.\n. ",
    "liamstewart": "Actually, I'm don't really the way I implemented it as it gets ugly when you have a sequence of (score, member) to insert. Either an overloaded version zAdd(key: ChannelBuffer, members: Seq[(JDouble, ChannelBuffer)]) or a zAddMulti method (even though it doesn't correspond directly to a redis ZADDMULTI command) would be nicer.\n. Thanks!\n. Thanks for the feedback. I'll make changes and look at and end to end test and then poke this PR.\n. PTAL\nAlso added a withAttemptProtocolUpgrade method to the Thrift.Client class.\n. Thanks, @vkostyukov. I've taken a look at the new develop branch and rebased my PR. I've made some changes to the way the protocol upgrade attempt is handled to better work with the preparer (so that actions in the preparer that don't involve upgrading the connection, such as your new payload size stats filter and the connection validation filter, are not skipped). This simplifies the code that uses the preparer quite a bit.\n. Updated, though I left the new with methods named with(No)?AttemptProtocolUpgrade as that keeps them consistent with their corresponding stack parameter.\n. My intent with the changes to ThriftClient(Buffered|Framed)Codec(Factory) was to provide a way for client code that was still using the builder interface with .codec(...) to make use of the new option. I'm more than happy to remove all of them if you guys are ok limiting control of the new feature to with-methods / Stack API - that seems to be the case - can you confirm?\n. ",
    "stravadeploy": "I think that score + member is more consistent with the rest of the API and requiring ZMember elements is one more conversion that all client code will have to do. My preference is also to avoid breaking changes so I'm leading towards zAddMulti(key: ChannelBuffer, members: Seq[(JDouble, ChannelBuffer)])\n. ",
    "jdanbrown": "Here's my full dep tree under finagle-core:\n[INFO] |  +- com.twitter:finagle-http_2.9.2:jar:6.4.1:compile\n[INFO] |  |  +- com.twitter:finagle-core_2.9.2:jar:6.4.1:compile\n[INFO] |  |  |  +- io.netty:netty:jar:3.5.12.Final:compile\n[INFO] |  |  |  +- com.twitter:util-app_2.9.2:jar:6.3.5:compile\n[INFO] |  |  |  +- com.twitter:util-core_2.9.2:jar:6.3.5:compile\n[INFO] |  |  |  +- com.twitter:util-collection_2.9.2:jar:6.3.5:compile\n[INFO] |  |  |  |  \\- commons-collections:commons-collections:jar:3.2.1:compile\n[INFO] |  |  |  +- com.twitter:util-hashing_2.9.2:jar:6.3.5:compile\n[INFO] |  |  |  \\- com.twitter:util-jvm_2.9.2:jar:6.3.5:compile\n[INFO] |  |  +- com.twitter:util-codec_2.9.2:jar:6.3.5:compile\n[INFO] |  |  +- com.twitter:util-logging_2.9.2:jar:6.3.5:compile\n[INFO] |  |  \\- commons-lang:commons-lang:jar:2.6:compile\n. Haven't thought about this issue in a couple years, but reading back over it I think that \"consumes the HttpMessage\", if that's intentional, is a surprising behavior.\n. I don't remember well at this point, but I vaguely remember trying to copy Requests, maybe for tests, and seeing if Response.decodeString(rep.encodeString) would accomplish that, and then ultimately concluding that Requests weren't meant to be copied and finding a different approach.\n. How about reuse java.nio.channels.ClosedChannelException? I'll submit a pull request with that and we can change it if you think it'd be better to introduce a new exception object.\n. Rather, I'll use com.twitter.finagle.ChannelClosedException instead of java.nio.channels.ClosedChannelException.\n. Submitted PR #179.\n. @mosesn We keep getting bit by inet! resolved names failing to track DNS names that change over time (e.g. AWS ELBs), so I'd be interested in working this into the inet! resolver if no one is tackling it yet.\nWhat's the best approach?\n1. Stick with Name.Bound(Var[Addr]) (Resolver.eval + InetResolver.bind) and periodically push DNS changes to the Var. This would require periodically re-resolving the hostname on a Timer, which seems like it might be overly complicated.\n2. Add some kind of \"bind-on-demand\" state in Addr so that DNS resolution happens on each request. Is this even possible?\u2014looking at DefaultClient.newStack0 my guess is that it needs the push behavior in (1)...\n. @mosesn @agleyzer @jixu Yeah, sorry, I dropped the ball on this. I still intend to do it eventually, but @jixu feel free to jump on it sooner if you want. Either way, I'll follow up here before I spend much time on it to make sure I'm not racing with someone else.\n. I'd love to, but the naggati stuff is still a bit opaque to me. I was hoping someone on your end could knock that out instead. ;)\nIf you guys don't have cycles for it then I could figure out how naggati works and make a PR, but probably not for another week or two.\n. PR submitted: https://github.com/twitter/finagle/pull/218. Closing this issue in favor of that one.\n. (Updated description)\n. Great, thanks @stevegury!\n. Hmm, I think I don't understand:\n1. In my patch, discard will be invoked in two cases: (a) via an r.read failure if rep.writer.fail is called, (b) via a trans.write failure if trans fails, e.g. closed socket. What's the undesirable behavior in there, and how could we do better?\n2. In your code sketch, p and f aren't related\u2014did you mean for them to be? e.g. p never actually fulfills.\n. @luciferous Did you guys finish the fix you mentioned in your initial reply?\n. @luciferous Great, thanks. 92052389af5006ad2bd7e6aa68ae205e5a81ecb6 clearly subsumes and improves upon the small patch in this PR:\ndiff\n-        trans.write(rep) before streamChunks(rep.reader)\n+        trans.write(rep) before streamChunks(rep.reader) onFailure { _ => rep.reader.discard }\ndiff\n-        trans.write(rep) before streamChunks(rep.reader)\n+        val p = new Promise[Unit]\n+        val f = trans.write(rep) before streamChunks(rep.reader)\n+        // This awkwardness is unfortunate but necessary for now as you may be\n+        // interrupted in the middle of a write, or when there otherwise isn\u2019t\n+        // an outstanding read (e.g. read-write race).\n+        p.become(f onFailure { _ => rep.reader.discard() })\n+        p setInterruptHandler { case _ => rep.reader.discard() }\n+        p\n@mosesn Closing as subsumed by 92052389af5006ad2bd7e6aa68ae205e5a81ecb6.\n. Thanks @trustin, swapping in io.netty:netty:3.8.1.Final fixes this on my end:\n``` sh\n$ curl -s localhost:8000/chunked-empty -HAccept-Encoding:gzip | gunzip | cat -v; echo\n$ curl -s localhost:8000/chunked-empty -HAccept-Encoding:gzip | cat -v; echo\n^_M-^K^H^@^@^@^@^@^@^@^C^@^@^@^@^@^@^@^@^@\n$ curl -i --raw -s localhost:8000/chunked-empty -HAccept-Encoding:gzip | cat -v; echo\nHTTP/1.1 200 OK^M\nContent-Encoding: gzip^M\nTransfer-Encoding: chunked^M\n^M\n14^M\n^_M-^K^H^@^@^@^@^@^@^@^C^@^@^@^@^@^@^@^@^@^M\n0^M\n^M\n``\n.arg.toString(charset)will always work, right ([javadoc](http://netty.io/3.6/api/org/jboss/netty/buffer/ChannelBuffer.html#toString%28java.nio.charset.Charset%29%29)? Is your first branch just to avoid a few function calls?\n. How about something finite and small instead ofDuration.Top` for the default cache ttl? I think caching forever is a surprising default behavior in the setting of web services where dns names are typically used to (a) hide IPs that change over time and (b) load balance across multiple IPs at any fixed point in time. For example, a search for \"java dns cache\" primarily turns up instances of people asking \"how do I turn off java dns caching?\".\nMaybe we could do something more inline with the dns caching behavior already present in java.net.InetAddress? I think that would provide the least surprising overall behavior.\n- http://docs.oracle.com/javase/6/docs/api/java/net/InetAddress.html \u2192 \"InetAddress Caching\"\n  - If security manager then cache successful lookups forever\n  - If no security manager then cache successful lookups for a finite period\n  - Regardless of security manager, always cache failed lookups for a \"very short\" finite period\n  - Override above default behaviors with networkaddress.cache.ttl and networkaddress.cache.negative.ttl\n. On second thought, the second part of my comment above isn't a good idea: the jvm is already caching dns resolutions for us, so we shouldn't try to \"replicate\" any of it.\nOne odd behavior above: if we reuse networkaddress.cache.ttl, then we effectively increase the user-requested cache ttl by 1-2x, since we're composing two independent timed processes. Is that desired? If not, would it be good enough to set a fixed, small ttl like 10.seconds and leave it at that? Or maybe expose a new config to override it instead of piggybacking on networkaddress.cache.ttl?\n. - Caching forever was the default in java 5, but they changed it in java 6.\n- Yeah, I think I agree that reusing networkaddress.cache.ttl is simpler overall than introducing another config param.\n- What would be the effect of your Throw(exc: SecurityException) ... \"dns caching turned off\" ... -1 case? If we do nothing then we're back to the cache-forever behavior since our api to the client is a sticky Var[Addr].\n- As for the \"odd behavior\", consider this:\n  - Thread 1 calls java.net.InetAddress.getByName(\"foo\") repeatedly, as fast as possible\n  - Thread 2 makes a val v = InetResolver.bind(\"foo\") and observes v: Var[Addr] as fast as possible\nThread 1 will cause the InetAddress cache to refresh its entry for \"foo\" every networkaddress.cache.ttl. Relative to this periodic process, the timer updating v will start its own periodic process at some offset d, also with period networkaddress.cache.ttl. So whenever thread 2 observes v, the freshness of its observations will always be within [d, d + networkaddress.cache.ttl] instead of [0, networkaddress.cache.ttl].\nNow, this case seems pathological, and [d, d + networkaddress.cache.ttl] amount of freshness is probably acceptable anyway, but since we're creating our own timed process over a timed cache we should be aware of it.\n. Sgtm.\nRe SecurityException: Note that if we don't pick a ttl (= timer period) then we're stuck with caching forever, which is the opposite of your \"dns caching turned off\" message above\u2014it would need to instead say something like \"dns cache refresh turned off\".\n. @mosesn lgtm!\n. ",
    "danielpcox": "How would this allow an RPC method implementation access to the client cert, say in a custom Filter?\n. I ask because I have the same requirement as @bpfoster, and I was interested in contributing this improvement. I'm having some trouble figuring out the flow, though.\n. Does this commit on develop: https://github.com/twitter/finagle/commit/3d6f236f and the fact that Thrift RPC is now supported over TLS close this issue?\n. Not yet, but it's on my list. :) I'll give it a shot next week and let you know.\n. Make that the next three weeks... I'm pretty distracted at the moment. @mosesn would you be able to try it out? At the moment, I expect to be able to circle back around and confirm that this solves our problems by the end of next week, but anybody with some time to kill right now could pull develop and try extracting a client certificate over TLS via Thrift and HTTP.\nI think you'd just have to write a little demo ping server that uses TLS and grabs some attribute out of the client cert, and then write a client to connect to it with any certificate.\n. OK, I'm finally getting around to this now. I think I'm misunderstanding something fundamental, though. How do I actually get ahold of the Transport from inside a service's request handler? How can I do anything with the client's incoming certificate information so as to affect the response?\nAlso, as an aside, is the builder pattern deprecated now? I've been operating under the assumption that it's the idiomatic way to construct a Finagle client or server, but maybe there's no way to do what I want to with a ServerBuilder?\n. I'm sorry Moses, I still don't understand. How do I get a handle on the Transport object from within a server implementation? I've read all the documentation and I still only know how to do the most common things. I'm implementing a Thrift IDL-defined interface, and I don't see how the transport object could be injected at this point.\n. How can something available globally present me with the certificate for an individual request like this? Is it a thread-local binding or something? How can that be safe? Is each request handled by a single thread and vice-versa, and then all local-bindings cleared for the next request to be processed on that thread?\nThis must be the key thing I was missing. Does finagle expose many things this way? Is this in the documentation somewhere and I just missed it?\n. Transport.peerCertificate seems to be None at this point in my server implementation. Am I doing anything obviously wrong here? https://github.com/DecipherNow/finagle-tls/blob/master/src/main/scala/com/twitter/finagle/example/tls/TLSServer.scala#L23\nThanks Moses for your patience.\n. Thank you @bpfoster, I really appreciate this. Moses helped me earlier today with the new API, and my experiments are here: https://github.com/DecipherNow/finagle-tls/blob/new-api/src/main/scala/com/twitter/finagle/example/tls/TLSServer.scala\nThe certificate is expired... That explains why the client was hanging. Bah. I forked this project from someone else and didn't check how old it was.\nI'll try to catch up to you tomorrow. :) Thanks again.\n. All right, I was able to confirm that these changes provide access to the client certificate with the right incantations, though I was never able to get it working with the new API. I'll file a separate issue about that.\n. I will be today. Just have to figure out how to build Finagle first. :)\n. Yes. Hallelujah. I can confirm that this fix allows me to use the new Finagle 6 APIs to\na) do Thrift RPC over TLS and\nb) extract the client certificate from the Transport to allow for PKI-based client authentication.\nExamples of these miracles are here: https://github.com/DecipherNow/finagle-tls/tree/new-api\nObviously at the moment they require a manual publishM2 of this finagle-thrift fork to use.\n. Sure, though it's crunch-time on another project so it'll have to wait until Monday.\n. ",
    "mbk": ":+1: form me on this. It would also allow for easy SSL debugging on the \"higher\" layer, i.e. catching handshake exceptions, wrap them in json, and send them back.\n. ",
    "delitescere": "Ping?\n. ",
    "bpfoster": "@stevegury I'd like to start revisiting this.  I can see how to retrieve the certificate from within a ChannelHandler, but am not finding a clean way to get it to the service/filter layer.  Do you think anyone could provide some guidance on that?\n. @danielpcox \n- The big issue is the tls() method in Finagle does not expose a way to configure the engine to want or need client authentication.  The default is for neither, so the server will never even prompt the client to present a certificate.  You're going to need to create your own engine and use newSslEngine() instead of tls(), and specify whether you want or need client auth in the engine.  For example:\nval server = ServerBuilder()\n      .codec(ThriftServerFramedCodec())\n      .newSslEngine(() => {\n          val engine: SSLEngine = createSslContext().createSSLEngine()\n          engine.setNeedClientAuth(true)\n          engine\n       })\n      .bindTo(new InetSocketAddress(8080))\n      .name(\"TLSServer\").build(service)\nThe finagle native OpenSSL bindings don't currently support specifying client auth modes, so I ended up creating a javax.net.ssl.SSLContext (similar to the Client) to get an SSLEngine.  In theory performance may be worse than via native.\n- Your sample certificate has expired so I couldn't get a successful handshake with it.  Generating a new one worked.\nWith those 2 in mind, I was able to then run your code and get back what looks like a good response:\nBeautifulDogResponse(O=Internet Widgits Pty Ltd,ST=Some-State,C=AU,true)\n- When you move off the old API, I believe you can configure TLS similar to\nThrift.server.configured(Transport.TLSServerEngine(Some(ssl.newEngine)))\n. Great, thanks Steve!\n. ",
    "eric": ":+1:\n. The problem I see is that I have my mysql server time_zone set to UTC, but it's being sent by finagle as local.\u00a0\nIt seems to me I would need a way to specify what timezone the server is in.\nOn Mon, Aug 5, 2013 at 10:15 AM, Ruben Oanta notifications@github.com\nwrote:\n\nAccording to the mysql documentation[1], values for TIMESTAMP columns are converted from your mysql server time_zone to UTC for storage and from UTC to the time_zone for retrieval.\n[1] http://dev.mysql.com/doc/refman/5.5/en/time-zone-support.html\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/issues/190#issuecomment-22121105\n. Correct.\n\nI believe it would be helpful to be able to pass the TimeZone I want into Calendar.getInstance() so the timezone of the JVM process doesn't have to match the MySQL server.\n. Yeah, I was definitely having trouble figuring out how I would get the info through all of the serialization stuff. I'll investigate the composite object thing.\nI think over-all, the correct solution is to set a timezone for the connection \u2014 it isn't something that is going to vary from one Timestamp object to the next and having to create composite objects every time you pass it to finagle-mysql seems like a poor interface.\n. I realized it would be really easy to add an (optional) TimeZone parameter to the constructor for Client and then that can be passed from Client.execute() to the ExecuteRequest constructor.\nThis would provide a simple way to have a connection-wide timezone specified and allow writeParameter() to have access to the TimeZone.\nDoes this sound reasonable to you? If so, I'll put together a pull request.\n. @roanta: Please let me know if https://github.com/twitter/finagle/pull/191 is a direction you would endorse.\n. Looks like this would work great to solve the problem. I\u2019m not using finagle anymore but I\u2019m glad this has a solution. \ud83c\udf89. The auto-negotiation is interesting... I'll look into that.\nI would argue that the timezone is related to the \"connection specification\", so I still think the Client is a reasonable place to specify the timezone to use for the data type.\n. I've temporarily resorted to using this hack to get the datetime written in UTC: CONVERT_TZ(FROM_UNIXTIME(?), @@session.time_zone, '+0:00')\n. Could you give me more detail as to how that solves the problem?\nPart of the issue is that a datetime in MySQL has no attached timezone, so without knowing the timezone the client that inserted the record intended to use, or without knowing what the timezone of the server is, how can we know what to use here?\n. Well, in ActiveRecord (in ruby), for instance, you can specify what timezone you would like all of your dates to be specified in.\nNow, it is obviously A Good Idea to always pick UTC, but it certainly isn't a requirement. So, if someone had not picked UTC, this wouldn't be giving them the right result.\nSo it seems to me that there would need to be a setting on either the connection or the statement that said, \"This is the timezone I want you to think of the dates and times as being in\".\n. Sorry, I ended up not having time to circle back on this and have moved to just using JDBC. \n. Could you clarify what you mean by making it backward compatible?\n. This case class is only created internally and passed to clients. I don't believe there would be any reason or way to use it outside of this.\nWould this be sufficient?\nscala\ncase class ReadMessage(bytes: ChannelBuffer, ack: Offer[Unit], abort: Offer[Unit] = Offer.const(Unit))\n. It doesn't appear there are any \"integration\" tests against a real kestrel server or ones that test ReadMessage.ack() from ConnectedClient.read().\nCould you give me some guidance for how to test this?\n. Any way we could get this merged?\n. Done.\n. It is actually exposed by the ReadHandle via the ReadMessage class. This gives the receiver of a message the ability to additionally call readMessage.abort.sync() to the already provided readMessage.ack.sync().\n. Let me know if there's anything else I can clarify about this.\n. Thanks! It will be nice to get rid of Yet Another Hack in my codebase once this is shipped. :)\n. Thanks.\n. Thanks! Is there an ETA on that release?\n. That'll work great. I was confused what the authoritative place to look was.\u00a0\nThanks for the quick response!\nOn Wed, Jan 1, 2014 at 7:19 AM, Moses Nakamura notifications@github.com\nwrote:\n\nThere's an issue in our tooling which is making it hard for us to publish to [http://maven.twttr.com] right now (we only want to do it when we know we can do it securely) so right now we're only publishing externally to [maven central][0].  Is that what you're looking for?\n[0]: http://search.maven.org/#search%7Cga%7C1%7Cfinagle-mysql\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/issues/233#issuecomment-31424343\n. Sounds good.\n\nOn Wed, Jan 1, 2014 at 4:09 PM, Moses Nakamura notifications@github.com\nwrote:\n\nWould you mind if we moved this question to the google group too?  This is a question that we answer a lot internally, but I'm now realizing that we haven't published broadly outside.\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/issues/234#issuecomment-31433381\n. Sent.\n. https://groups.google.com/d/topic/finaglers/-DeO4SJB9No/discussion\n. No problem.\n\nOn Wed, Jan 1, 2014 at 4:08 PM, Moses Nakamura notifications@github.com\nwrote:\n\n@eric would you mind if we moved this question to the finaglers google group?  I think other people on the google group would also be interested in the response.\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/issues/235#issuecomment-31433362\n. Sent.\n. https://groups.google.com/d/topic/finaglers/eCVRLmQy-Dw/discussion\n. \n",
    "vkostyukov": "I'm pretty sure this is about finagle-zookeeper. So we can probably close this.\n. @daqulazhang it's still in progress, but the first Netty 4 bits are already here. The Netty 4 work is on track and we except to finish finagle-core in Q1 2016 so we could move to work on protocols (Mux and HTTP will probably be first).\n. I decided to update this epic thread.\nAs of Finagle 6.42, it's now possible to switch the underlying transport implementation over to Netty 4 for all supported protocols. See more details in this blog post.. Given finagle-redis is now like 99% new code (due to N4 migration), I think it's no longer an issue. Please, let us know if you still experience this problem with the most recent Finagle version.. @travisbrown Is this closable?\n. Let me try to cherry-pick this for the internal review.\n. Oh. Just re-read @mosesn's comment. Okay, how about to close this one and file an internal ticket to keep an eye on this?\n. Okay. I've created an internal issue to track the progress on tihs. Closing it now.\n. @mosesn, see details here https://github.com/finagle/finch/pull/116.\n. @luciferous @dschobel haven't we fixed this already (internally)?\n. I'm talking about commits: https://github.com/twitter/finagle/commit/d9276f9ecbb53737da9d6c513198693816e1be40 and https://github.com/twitter/finagle/commit/e2f4187d050e1a51aa9cf849427c6fb04d909fdd.\n. Thanks @dschobel! Let's close it then.\n. @olix0r since you're here, can you also replace c.t.u.Future with scala.concurrent.Future?\n. Very interesting. We can add timeout to Netty3TransporterTLSConfig and override it with stack param. See examples here. The default might be 10s.\n. @sirmax how is it going with handshake timeout? Just let us know if you need any help with that.\n. @sirmax you may have a look at this test. It also tests the SslHandler behaviour so you can use it as a start point.\n. I'm working on TLS/SSL support in finagle-netty4 and I remembered this thread. Wanted to make sure I'm not missing the handshake timeout problem @sirmax discovered a year ago.\nHere is my understanding of the things (I read carefully through #346 twice).\n1. The default handshake timeout is 10 seconds in Netty 4, which is good\n2. We don't want to reuse ConnectTimeout param for this since the handshake should be considered a part of session acquisition, rather then TCP connection establishment\n3. In my current implementation, we also delay the connect promise satisfaction until we've done the handshake. We shouldn't worry about connect timeout applied here since it will be applied onto an underlying promise that corresponds to an actual TCP connect.\n4. My take is that the handshake timeout should be enforced via TimeoutFactory (disabled by default) and I'm not sure we need finer grained timeout here given that default 10 seconds one will prevent FailFact factory from stalls\nSorry if it wasn't clear, but I was trying to make a conclusion that we probably don't need to do anything else here for Netty 4 implementation. Please, let me know if you feel opposite.\n. Thanks @mosesn! I think so too! Actually, while rethinking this, I realized that there is a resource leak in the current implementation for Netty 4 - going to fix that today. \n. This is odd that the neighbor test is failing. Let's hear from TravisCI.\n. I wrote that neighbor and totally forgot about assertions. In that case this \"fix\" with when(engine.isInboundDone) thenReturn true is correct since the test is assuming that SSL engine is closed (which I was trying to configure in the mock engine).\nRegarding the new test (the one that tests timeout). I think we shouldn't reuse that engine here since you don't actually sends anything to it. I would suggest to move the origin SSL engine inside the neighbor tests (+ new mock configuration on isInboundDone) and create a new and super simple one (like val engine = mock[SSLEngine]) in the new test. \nDoes it sounds reasonable?\n. :+1: Looks good to me.\n. Hi @sirmax and all!\nI think that @sirmax is right and we might want to reuse Transporter.ConnectTimeout param instead of introducing a new (implementation-specific) one. \nFor now, this param is used in Netty3Transported and propagates to Channel options via hash-map:\nscala\no += \"connectTimeoutMillis\" -> ((connectTimeout + compensation).inMilliseconds: java.lang.Long)\nThat's being said, it's totally safe to reuse it in SslHandler since at the moment of SSL handshake channel is already connected.\nWhat do you think?\n. This has been merged internally. Thanks @spockz! You contribution will show up here on the next sync cycle.\n. :+1: \n. :+1: \n. It search in a companion object Parameter.  \nRe Seq[Any]: It's a good concern. It seems to me that it's not possible to convert Seq[Any] into Seq[Parameter] since the type information is lost. Although, It might be fixed by replacing Seq[Any] with Seq[Parameter] in user's code: val seq: Seq[Parameter] = Seq(1, \"foo\", bool).\n. I believe we can close this already (fix is here https://github.com/twitter/finagle/commit/aad73448b74f9f98b487c8dbd376dcb134927d9d).\n. For now, Finch doesn't do anything special about consuming HTTP (Finagle) services. But there is a ticket for this, which is planned for 0.8.0 release.\n. @raelg what you can also do is to use the \"pimp my library\" pattern to wrap the andThen function with implicit class like this.\n. @luciferous I'm not sure we would be able to add andThen[Rep1](f: Req => Future[Rep1]) since service already extends Req => Future[Rep], which provides andThen[B](f: Future[Rep] => B). Both functions take the same argument type: Function1[A, B], so we can't override it due to type erasure.\nPerhaps, I'm missing something. Correct me if I'm wrong.\nIsn't contrvariant map called comap?\n. :+1: for andThen and compose. I would vote for adding these functions into the Service trait (as well as deprecating map).\n. @mosesn since we have tests now, can we mark it shipable?\n. I'm pulling this to review internally. Will close the PR once it's merged.\n. This has been merged internally. Thanks @thirstycrow!\n. I'm pulling this internally. Will close this PR once it's merged.\n. This has been merged internally (and will show up here very soon). Thanks @svetlyak40wt!\n. This has been merged internally (by @luciferous). Thanks @olix0r!\n. :+1: Thanks @tonyd3!\n. @tonyd3 any progress with the test? Let us know if we can help here.\n. Thanks @tonyd3! Looks great!\n. Nice! I'm pulling this for the internal review.\n. This has been merged internally. Thanks @tonyd3!\n. @olix0r, do you think we should mention this in CHNAGES?\n. The context is here.\n. I belive it was fixed here so closing it. Thanks @mallman for reporting!\n. :+1: \nThank you @amartinsn!\n. This has been merged in this commit. Thanks @andrestc!\n. Thank you @arnarthor! Some context from the Finch Gitter channel.\n. I'm pulling this internally. Will close this PR once the change make it to the develop branch.\n. This has been merged internally. Thanks @arnarthor!\n. @luciferous I'm pulling this internally. Will close this PR once it's merged. Thanks! This is a solid work.\n. Woot! We've merged this internally and it's already on Github. Thanks a lot @luciferous!\n. Thanks @zfy0701! I'm pulling this internally.\n. Hey @zfy0701!\nAny chance we can test this? I run this PR throght the sandbox and I can see a couple of failed tests internally. Basically, it crashes on cons => cons.newInstance(newArgs: _*) with \"Wrong number of arguments\". \nDo you think we can test this for both cases: w/o new constructor and w/ new constructor?\n. Thanks @zfy0701! I'm happy to pull this again! Will update this PR once it passes or not passes the internal tests.\n. This made it to the develop branch: https://github.com/twitter/finagle/commit/d2453314d0a9411a20c82d83cd9eebbfc7fd3288\n. Thanks @matteobanerjee! That's really cool to see you use Finagle. Mind sharing some details on how do you use it?\n. I'm pulling this internally. Will close this PR once it's merged. Thanks @matteobanerjee!\n. This was merged internally. Thanks again @matteobanerjee!\n. Thanks @adriancole! I'm pulling this internallly. Will close this PR once it's merged.\n. This has been merged internally. Thanks again @adriancole!\n. Hey @adriancole. Just wanted to mention that we've made quite a simple change your original patch before merging it. We used doc comments /** intead of simple comments /* so Scrooge can pick them up.\n. Thanks @ldematte!\n. Thanks @Saisi! LGTM.\n. :+1: \n. I'm pulling this internally. Will close this PR once it's merged.\n. This has been merged internally. Thanks @spockz!\n. Thank you @esamson!\n. I'm pulling this internally. This close this PR once it's merged. Thanks again @esamson!\n. This was merged internally.\n. @liamstewart thanks for the PR!\nYesterday, I merged a patch that adds Stack.Params argument to the Codec.prepareConnFactory so you won't need to propagate your boolean flag all the way down. That patch will be synced on Monday. Let's wait for it and than rebase this PR - it should be simplified a lot.\n. Thanks @liamstewart! It looks better, but I think there is still a room for improvement. Let's not propagate our new param all over the stack: codec constructor -> prepare connection.Thrift client preparer has a function prepare that takes params so you can extract your new param from there.\n. Awesome! :+1: \nThanks a ton @liamstewart!\n. Yeah, I think it might be closed now. Thanks @nrinaudo for fixing this!\n. @nrinaudo In what position do you insert HttpContentDecompressor? My take would be to put it right after HttpChunkAggregator. I looked through the implementation of HttpContentDecompressor and it looks like it should handle streaming requests just fine.\nI'm not sure what do you mean by messageReceiver isn't called. Do you mean HttpContentDecompressor doesn't work if the incoming message isn't encoded?\n. I guess we can close this now. Thanks again @nrinaudo!\n. @bmorganatlas @jabley Sorry for the delayed response. Any chance you wish to open a PR with s/www.google.com:80/google.com if that fixes the issue for you?\n. Looks great! Thanks @nrinaudo!\n. @zhao141 Are you looking for server-side or client-side examples?\n. You can take a look at the finagle-ouath2 project that provides sever-side OAuth2 support for Fiinagle services. There is also a complete example in the Finch repository.\n. Feel free to swing by a Finagle room on Gitter and ping us there is you still have questions.\n. > @vkostyukov have we addressed this in the recent Reader work?\nYes, we now have:\n\nDocs for readers: https://github.com/twitter/util/commit/f069921af3a986bb74afca01c0e370dfe2dca4cc\nDocs for writers: https://github.com/twitter/util/commit/0d183b77e43cd2160ec1bfc2c1f348341989a1cc\nDocs for pipes: https://github.com/twitter/util/commit/1d6e539ecd41afb844c9c946b071b367b05c0fd2. But, there is still plans to add more docs with regards to Request/Response types and their streams (readers and writers).. Nice catch! Thanks @samstarling!\n. This was merged internally and will show up here on Monday. Thanks for the contribution, @samstarling!\n. Thanks a lot for sharing this @johanstenberg92, this is really interesting!\n\nI wonder if having a tiny wrapper around ServiceFactory returned from $Ptotocol.newClient would allow you to achieve that. When you ask for a client (newClient: ServiceFactory) not a service (newService: Service), it provides you more fine grained control over the underlying session (represented as a Service), which maps to a concrete replica and concrete connection. So basically you can create one and used it until status != open so you can recreate that and use again.\nHope that's not complete non-sense.\n. Hello @tindzk! It's really great to hear you're migrating to Finagle. \nI'm actually the person who is fully responsible for that multipart API we have today. So let me give some insights on why it works that way. First of all, sorry if that API was churn to use, but the trade off was made intentionally.\nThis is the second iteration of the multipart API and as you can see it's still under exp package, which indicates that we're not sure it's good enough to be widely adopted. Originally this API was introduced when we're migrating internally from Netty types to Finagle types to unblock ourselves for Netty 4 migration. At that time, Finagle didn't support multipart requests so people used Netty API directly and we decided to wrap it with out own thing to 1) migrate people away 2) make sure we didn't break anything by providing almost 1-to-1 mapping between API and keeping the behaviour unchanged.\nWe have an internal ticket to track the progress on redesigning this API and making that more useful and safe (and support streaming?), but it's not in the top of our backlog right now (Netty 4 migration is).\nHope that helps. Welcome to the Finagle community!\n. I think you can use RequestBuilder.buildFormPost(mutipart = true) for that. See FileElement for adding file uploads.\n. Multipart request streaming is also tricky in Finagle (because of both streaming and multipart are tricky in Finagle). Although, if you're feeling like build multipart request from scratch (not using RequestBuilder) it's possible to do something like:\nscala\nval reader: Reader = Reader.fromFile(new File(\"upload.txt\"))\nval req: Request = Request(Version.Http11, Method.Post, \"/\", reader)\nBut you have to take care about the \"multipart\" part of this request (put content types, boundaries, etc).\n. @adriancole, @kevinoliver,\nYes, \"com.github.finagle\" (and perhaps \"io.github.finagle\") is Maven group id we use for community projects (including Finch, finagle-postgres, etc). What we usually do is to create a new project with appropriate ownership. Next step is to file a ticket to Sonatype and ask them for an access from your personal account to one of those group ids. The rest of the magic primary depends on your imagination. I recall Travis was trying to standardize the way we publish community project, but I don't think it went anywhere. So basically you set up sbt/Maven project and publish things manually (on demand). In most of the cases, it's nothing more than just sbt +publishSigned.\nI'd probably vote for hosting this project under the Finagle org and I'm happy to help with all the setup, but I can totally understand if you decide to go with OpenZipkin org instead.\n. I've never seen that we've handled that Connection: close header in Finagle. I guess we just ignore it right now? Looks like there is a window between receiving a response with Connection: close and channelInactive event in the pipeline, in which we see ChannelClosedException.\n. Hey @monkey-mas! We had to revert this temporary (see b5cbb3e2ef23c82f30dbff6479c834048992e6fe) for some internal reasons. We'll put it back as soon as we can. Stay tuned and thanks again - this is a solid piece of work!. Hi @monkey-mas! I'm trying to put your work back where it belongs. Will update this thread when it's merged in.. It's merged (see f8208cd202fb98b2b071d53e8882457c4b4af208)!. Thanks @spockz for the bug report!\nWe do that for N4 but haven't had a chance to backport that to N3. You're more than welcome to do that and I'm happy to assist you with that. Any chance you want to take a stab and wire in Transporter.HttpProxyTo stack param in N3?\n. @spockz How is it going? Is there anything we can help with?\n. @Ashald you'd need to add a dependency to finagle-netty4-http and switch your client over to N4 IO transport. Something like\n``` scala\nimport com.twitter.finagle.Http\nimport com.twitter.finagle.netty4.http.exp.Netty4Impl\nHttp.client\n  .configured(NettyImpl)\n  .withTransport.httpProxyTo(\"google.com\")\n  .newService(\"my-local-http-cluster\")\n``\n. Please also note that N4 implementation should be considered experimental for now. We're still in the process of gaining confidence in it. That's why it'sexp.\n. So theAwait.result()never returns? Something has to be returned from the call - either a value or exception.\n. Also if you don't use TLS/SSL you don't actually need TCP tunneling (don't need N4) and can simply send HTTP messages with properHostheader to your proxy server.\n. _I think_ If transport/pipeline requires to perform upgrade/handshake/whatever, it should be responsible for buffering writes on its own. For example, Netty'sSslHandlerworks this way. We adopted that idea (with some changes) in HTTP proxy handshake (seeHttpConnectHandler`) / SOCKS proxy handshake / SSL handshake. Basically, we buffer writes from the handlers before and also delays the connect promise so the Finagle transport is not established. The reasons we do that are:\n- want to make sure, for example, SSL handshake exception fails the connect promise, not the request one;\n- want to make sure we don't send much traffic to a client that might potentially fail the session/handshake;\n. Just wanted to make sure I'm not missing something here (quite likely I do).\n@olix0r The scenario you're describing is exactly what ConnectPromiseDelayListenners is supposed to solve - we do not satisfy transport promise until we've performed all the handshakes (established the session). This works today for HTTP/Socks proxy and TLS/SSL.\nAs I understand we're talking about http2 upgrade/preface? My take is if we need to make sure http2 session is established before accepting traffic, we should do the similar thing we do for SSL/HTTP & SOCKS proxies - in an ad-hoc way delay the connect promise. \n. @olix0r The idea is that if we fail those writes we also fail the connect promise, which means a channel was never active. We only buffer writes from the channel handlers before/above - not from a Finagle client. That said, all those writers are somehow part of the session handshake (initiated by a pipeline). Failing them means failing the connect promise, which will be converted into a Failure.rejected and will be retried by the Retries module.\n. Technically, we only need buffering to protect ourselves from other handlers that can write on channelActive or handlerAdded (eg: SslHndler). We know for sure that Finagle won't write until the connect promise is satisfied so we never buffer users requests.\n. \ud83d\udea2 \ud83c\uddee\ud83c\uddf9 \n. Thanks @asheshambasta! I'm pulling this internally. Will close this PR when it's merged.\n. It's merged internally. Will show up on Github this Monday. Thanks @asheshambasta!\n. Thanks @bryce-anderson!\nSorry for the silence on this, @jpgneves!\nWe're in the middle of massive refactoring of finagle-redis as part of our bigger effort to bring N4 support in here. The encoding part is done and merged internally (I think, will show up here on Github quite soon). The decoding part is the one requires more attention.\nI'm going to work on decoding this week. I'd recommend not rebasing anything yet, but rather wait until we finish all the dirty work.\nI will keep this thread updated with the progress.\n. Thank you @jpgneves! I think is ready to go alive - we're not planning to touch any encoding-related parts in finagle-redis. Once you rebase you branch against current master, we'll pull that internally.. \ud83d\udc4d \nThanks for looking into this, @olix0r!\n. I'm pulling this internally. Thanks @olix0r! Will ping you here when it's merged.\n. @spockz I don't know about scoping. On one hand, it's reasonable and that's what we do for mux (having a mux scope). On the other hand, we don't scope for HTTP and we already have some HTTP-specific metrics. So I prefer us to be consistent and either\n1. Do not scope new metrics\n2. Scope new metrics and move old metrics under http/\nIt's quite clear that it's hard to go the second road here since it breaks the API (will likely break both internal and external dashboards). So I vote for 1.\n. Thanks @vazyzy!\nYeah, we're actually thinking about it at this very moment. Besides the Host header, there are other places where finagle-http is not completely specs-compliant. Good news - we have some ideas in mind on how to make it better (and explicit!), but that's part of a larger discussion. One way or another, this kind of concerns should be applied generically, not matter how a request was build (using the RequestBuilder or just Request).\nHistorically, we used HTTP dispatcher to fill the missing gaps, but now we're thinking about separating those concerns (making a separate spec-compliant stack module).\n. Reposting (from Gitter) my question here.\nIs it still a bug though? netty/netty#663 is closed and Trustin mentions something between the lines: \u201cIt's not a bug in Netty but a bug in JDK unfortunately. \u201c Maybe it's fixed already in Java 7?\n. @kevinoliver Works for me!\n. I think it's no longer an issue (given our current SSL API). Please, let us know if you still experiencing troubles configuring TLS/SSL clients/servers.. Thanks @daviddenton for the report! I'll be looking into that this week.. I have an update on this. Seems like there is a problem in Scalac 2.12 w.r.t. to how it compiles this piece of code. Difference in the stack-traces between 2.12- and 2.11-compiled threads lead me to that file. I was trying to figure out what exactly is different between 2.11 and 2.12 but wasn't able to do that yet.\nAnyways, there is some good news. Just by running some weird experiments I figure how we could workaround this. TL;DR we need to move those closures (starting with Awaitable.*) out of the class initialization path. Doing this made the warning disappear.\nWe're thinking about doing a February release so I want to go ahead and apply my workaround such that we make sure to fix this in the upcoming release. In the meantime, I will try to figure out how to reduce the reproducer case so I can report that as a scalac bug.\nAs a side note. This warning blocks the very first client/server initialization for 10 seconds. I think we should consider this a bug and a blocker for 2.12 adoption in Finagle.\n. The workaround I've been talking about has been merged (225c86ddf04723d0346fcd7a76bfa547aaefd39f). I'm going to close this ticket but keep the internal one until the reproducer for Scalac is ready.\nThanks @daviddenton for the report!. I think @bryce-anderson is going to release Finagle this week.. Just an update on this: I made the reproducer (https://github.com/vkostyukov/scala-2-12-1-and-runnable-bug) and filled a scalac bug (https://issues.scala-lang.org/browse/SI-10169).. Thanks a lot @b-hoyt! I'm pulling this internally. Will close this PR once it's merged in.. This has been merged internally and is already synced with Github. Thanks again @b-hoyt!. This was merged in (https://github.com/twitter/finagle/commit/e89eacba5471456a86db3177a2540c85424c08bc). Thanks @tomas-edwardsson!. Fixed by #595.. Thanks @reikje! This has been merged in (6e3306d9c2d2e0649b1c8a6572775d689f41e488).. This was merged in (cf4c0f5a42f32da057b04211895f519ffc2f3abc). Thanks @zaneli!. This has been merged in (3b8feb37f65018123a82b9c019a1825714675353). Thanks @davoclavo!. Thanks @koshelev! As I mentioned on Gitter, I like your idea about changing peerCertificate on N4 transport from val to def. Any chance you want to open a PR?. Oh I see. So we won't propagate that further. That's a bummer. Seems like having that connect delay handler on a server-side is our only option. What do you think @koshelev?. /I think/ it should just work even though it was written with the client-side use case in mind. All the things in SslHandler and in the pipeline (at that stage) should be symmetric for client and server. I'd say let's try it. @koshelev Do you want to volunteer and open a PR?. Perfect! Thanks a lot @koshelev!. You're right. There is no notion of connect-promise on the server-side. Although, /I think/ we can delay either channelInit or channelActive on a child pipeline in order to make sure this server bridge (essentially, a channel transport) thing is created only when the handshake is complete.\nIt seems like we do a similar thing for Netty 3. There we are delaying the channelConnected event, which is equivalent to channelActive in Netty 4.. Fixed in #603.. I'm pulling this internally. Will comment here when it's merged in.. This has been merged in (46e83fcd2efa770755a4dc4d7e27cc3514ee65a0). Thanks @matsu-chara!. Omg. Pulling this internally.. This has been merged (1e0b86593bd6b66ee5a92155e22759ebd9fd63be). Thanks @zaneli!. Thanks a lot @koshelev! I appreciate your patience going through the review and I really like your final solution. Really nice work!\nLet me get somebody else from the team to take a look.. @mosesn Do you mind taking a final look? It seems like your approval is the last one needed.. I'm pulling this internally. Will reply here when it's merged.. This has been merged (96f38130d432c683b561e6ddca0347c61c7bcb24). Thanks @zaneli!. I'm pulling this internally.. This has been merged in (0114a84edd8097b788f55aa728910ea0d178db14). Thanks @matsu-chara!. Thanks @matsu-chara!. @Mura-Mi Thanks for working on this! I still think we don't need to use Java types directly. Also, please, don't use BufToString. Try Buf.Utf8() extractor instead. Other than that, this looks good to me. . I think this is correct. Although this changes the metric location people might be altering on / monitoring (I honestly doubt that though). That said, I think it's fine to merge it but let's wait what others think about that.. I think this is awesome! Thanks @matsu-chara!. Can you try removing \"com.twitter\"%\"finagle-http_2.11\"%\"6.35.0\" from your build file?. Closing this as it's not a problem on the most recent Finagle. @codeape Feel free to reopen should you reproduce it on Finagle 7.. Thanks for letting us know, @ryanb93! Any chance you can share just a little bit of details on how you use Finagle (protocols, versions, etc)? We'd extremally appreciate it.. Thanks, @ryanb93! You might consider opening a similar PR against Finatra as well.. This is merged in b4e73eef3d93487284173a4f884e06c307ff1749. Thanks @ryanb93!. I think this is now fixed by 2fa89b52798f57250fa22a6be3ff62551f02207d.. Thanks for the issue, @teodor-pripoae!\nI have to figure out how TLS works with MySql, I guess. Do you know if MySql negotiates TLS connections via its handshake message? If so, I don't think it's supported in Finagle. Right now, we can only support TLS connections that start with SSL handshake (there is no machinery to upgrade an existing connection to become TLS).\nHowever, we're working on something similar for Mux right now. Hopefully, some of that work can be ported over for MySql.. > I added couple of tests to cover cases we discussed. Sorry for all those force pushes.\n\n@vkostyukov, github says, there's still some change requested by you, but I looked through all the threads, and seems, that everything is covered. Did I miss something?\nLet me know, if you want me to squash the changes.\n\nAgain, thanks a ton for following through this! You don't need to squash - we'll do that on our end.\nOne thing I believe we should change before proceeding is set a default value to 5.mb (the current default), instead of 0.. This was merged internally and made it back to Github: a3094f37478bde2ae599d4f45f8ce3631cce14a5\nThank you again @edio!. > IDK if that's too late to fix. In any case, that's nothing critical I guess.\nDon't worry about that. It's not a big deal.. Merged in 21664df3700257de3165511c2625d232c399322b.. Thanks @masahitojp! I will pull this internally.. This was merged in ce8a52ca2a2be6b9f8c096f8f71f71692e34703f. \n@masahitojp Any chance you want to open similar PRs against other Twitter's OSS projects? Util, Finatra, Twitter-Server, Scrooge?. I looked at the failed assert:\njava\n  assert !inNetBuf.hasRemaining() || engine.isInboundDone();\nI'm not sure if we run the tests with assertion enabled. So, could you please add the following configuration to the mock engine:\njava\nwhen(engine.isInboundDone) thenReturn true\nand check the sbt +test locally?\n. Does it actually need _root_ prefix? Seems to me just java.lang should work fine.\n. I see. Sorry, I don't really know this code well. Thanks for the explanation Travis! In this case we definitely should \"follow the style\" at least in this PR.\n. Why do we need this evidence here? Can we propagate it via closure? Something like this:\n``` scala\ntrait Parameter {\n  type A\n  def value: A\n  def writeTo(writer: BufferWritter): Unit\n}\nobject Parameter {\n  implicit def wrap_A(implicit _evidence: CanBeParameter[_A]): Parameter = new Paramter {\n    type A = _A\n    def value: A = _value\n    def writeTo(writer: BufferWritter): Unit = {\n      _evidence.write(writer, value)\n    }\n  }\n}\n```\nMy point is that we don't really need to carry that evidance in the parameter.\n. My opinion is that we probably want to keep the API surface as small as possible. And also, once you have an instance of Parameter you don't need an evidence that it can be parameter, since it's already it :)\nAs far as I know it's a common practice do not store evidences but wrap them into a closure. Although, it's probably just a nitpick. Feel free to ignore.\n. I believe the style is tokens.tail.map {}.mkString(\" \").\n. And why the empty tokens considered as a special case? Nil.mkString(\" \") will produce a \"\" string as expected.\n. Right. Just use drop(1) then.\n. Perhaps renaming this module to clientModule to make things symmetric? Should be safe to do since it's package-private for [finagle].\n. How about to rename it just Unknown? We already have prefix Status so Status.UnknownStats feels redundant.\n. Why we still need this?\n. I don't think we need _attemptProtocolUpgrade anymore.\n. Why we need to extract AttemptProtocolUpgrade from params and pass it separately? Preparer already takes params so you can extract them later.\n. We don't need it here - preparer has it already through params.\n. Just extract your new param here.\n. Oh, you're right. I was thinking we can add method to a client builder attemptProtocolUpgrade, but realized that it's Thrift-specific. We're planing to remove all the codecs from Finagle in the nearest future (we even have a ticket for that and it's planed to a next tech-debt sprint) so I'm not 100% sure we need to add new functionality there. Let me chat with people to see what they think. I'll get back to you. Thanks, this is a solid work!\n. Okay. I chatted with people at the team. Let's drop the codec support for now and only add stack param available via the with-method.\n. Let's name that withNoProtocolUpgrade as per item 2 in design principles. But please, leave the stack param as is.\n. Let's make that private[finagle] by analogy with DelayedReleaseService.\n. What do you think about moving DelayedReleaseResponse.apply here as def private[this]? This would not only reduce the diff, but would allow as to access latch directly (w/o passing a closure) so we can save those 8 bytes per closure allocation on each chunked request.\n. Super nice catch! Thanks!\n. ffti: NettyFuture[Any] and GenericFutureListener[Any] should work as well.\nI have an internal patch that also fixes that but it's been soaking for review for a long time so I'm totally fine to merge this in.\n. Ah that's interesting! I guess you're right and we should totally ratain those objects.\nWhat do you think about fixing ChannelTransport to do ReferenceCountUtil.ratain(msg) before offering the message into AsyncQueue, instead of introducing a new handler here?\n. Do we need this val? I don't see we use it anywhere.\n. FWIF, I'm voting for a single variable here (activeRequests or pendingResponses).\n. There is noFailFast on Client/Server (it's a client builder thing). We use with-prefixed methods here instead. And it's totally fine to have with-API w/o an argument (we do that all the time). See Design Principles for the with-API (item number 2).\n. Also, please no ().\n. I honestly don't think we still need this Req <: Request type-param. I think we've done this before to support something we called \"rich http\" (which is now just finagle-http). Please, correct me if I'm wrong. /cc @mosesn @dschobel @roanta \n. Please, capitalize HTTP.\n. Please, capitalize HTTP.\n. I think you can avoid defining a new type by just passing an identity function as a stack module - it should be implicitly converted. We do that in a bunch of places.\n. I still don't think you need this type-param.\nPlease, note that it has nothing to do with your custom HTTP types (either for request or response) since at that point they should be lifted to something Finagle can work with (i.e., c.t.f.http.Request and c.t.f.http.Response).\nBy the same reason, StatsFilter doesn't need a type param Req, but we can't remove it yet (an API break) so let's keep it (filter) as is, but remove the type-param on a module.\n. I think you should be fine. There is an implicit conversion from A => A function to Stackable[A].\n. Can you rebase your branch. I think it's called body in master.. Is there a way to make it a separate channel handler? I guess my question is can we \"delay\" channel init?. Oh I think we can delay channelRegistered then given that channelInit is just a fancy version of it. What do you think?. I guess when we'll actually delay the ChannelTransport creation, the peer certificate will be available at the moment this constructor fires and yet I still think it should be def, not val.  I like this more by two reasons.\n\nI'd imagine that sessions could be renegitoated so having def means we could get the latest peer certificate if that happens.\nThis would reduce the memory footprint for each channel-transport (each connection).. Exactly! Although, I don't understand why we'd need to touch ServerBridge. It's a ChannelInitialize right now that essentially an InboundHanlder that will receive channelRegistered (or channelInit in the ChannelInitializer case) as any other handler.. Oh interesting. It looks like we change the isRegistered flag on a channel before firing the channelRegistered event. You're totally right. We should probably change server bridge to be just ChannelInboundHandler. Is that what you had in mind?. How do you know it never happens? This looks pretty reasonable to me. As far as I remember, the handshake is initiated on either channelActive or handlerAdded. Here you're attaching the handshake listener on channelRegistered, but it shouldn't matter and the listener should be fired when the handshake is done anyway.\n\nMaybe just make it a pure ChannelHandler and override (and delay) channelActive instead?. Interesting. I'm pretty sure SslHandler should work just fine with auto-read is disabled. Maybe it's b/c we're not issuing an initial read given that ChannelTransport is not instantiated? If so I think it's a bug in Netty and we should file a ticket about that. As a workaround in your \"delay\" handler you can issue a read manually.. Oh yeah, absolutely. And if it doesn't it's a bug.. Sweet! Just let us know once you update this PR so we can have another look.. Maybe put it in its own file? Also rename SslConnectHandler to SslClientConectHandler?. I guess we can't issue this read on channelRegistred?. Let's just do ctx.channelRegistered.. Why we need this? If that's to prevent init to be called maybe we should just rebrand it as a plain InboundChannelHandler to be explicit about what we want?. Also, please do ctx.read() instead.. I'm still not sure why we need this. Also, how does channelInit work given that it's now ChannelInboundHandlerAdapter and not ChannelInitializer?\nHow do you feel about creating a channel transport on channelActive (in this server bridge) and delaying the channelActive event instead, in your new SslServerConnectHandler?. Both of these seem generally useful. Maybe we should move them under ByteReader, where we have O(1) get? . Why this has to be Java Long?. Why using Java Doubles?. You can inline Buf.Utf8(lon) in this pattern matching to get the string out of BulkReply(lon). This way, you won't need to call  BufToString later.. Similar question about JDouble.. Please inline Buf.Utf8() extractor here.. I'd prefer this w/o nulls. Also why JDouble?. Please, inline Buf.Utf8() extractor instead.. What do you think about GeoUnit.Meter, GeoUnit.Mile, etc?. How do we know \\n follows \\r? I don't see a check for that.. What about the client side? Here is how it looks today:\n// 8 KB is the size of the maxChunkSize parameter used in netty3,\n       // which is where it stops attempting to aggregate messages that lack\n       // a 'Transfer-Encoding: chunked' header.\n       fn(\"fixedLenAggregator\", new FixedLengthMessageAggregator(8.kilobytes)). Maybe keep using a single StorageUnit parameter and set it to min between the two on the call-site?. Thinking about this more, it seems we shouldn't probably use the maxRequestSize here at all and just introduce a separate parameter for it instead.\nI like @luciferous' suggestion. And I would go with minChunkSize as a parameter name.\nHttp.server.withStreaming(true, minChunkSize = 128.kb). I think we should change the client-side too as, otherwise, Http.client.withStreaming(true, 128.kb) would mean the minChunkSize is silently ignored.. Oh you're right. I miss-remembered that withStreaming  configuration API is shared between client and server. I think that's fine then. It's ok not to be symmetric there (looks like we never were).\nPerhaps wait for more people to chime in w.r.t. client-side configuration. \ud83d\udc4d from me for just changing a server for now.. It seems to me what no matter how we name it, there is still some buffering happens (at least today) for messages with known Content-Length. We can surely document what minChunkSize applies to. I'd imagine, setting minChunkSize = 0 would effectively mean \"no buffering\". I'm trying to understand your reasoning and I'm still not sure why you don't like the name. It does what it says it does (for messages with known length - is this part a concern?).. Okay, I'm convinced. Sorry for the confusion, I think I mis-understood what FixedLengthMessageAggregator does. bufferSize seems reasonable but, still, could be interpreted as \"buffer my chunks pls\".\nPerhaps something as verbose as aggregateIfLessThan = 128.kb.. What's the difference between HTTP chunk and chunk? What's so special about HTTP chunk besides being an N bytes?. I think this could be improved. Perhaps:\n\"The maxContentLength determines when to aggregate chunks and when to bypass the message as is. Only sufficiently small messages (smaller than maxContentLength) are aggregated.\". I understand your reasoning now, thanks for taking time to explain!\nMaybe \"not to be confused with chunks as in Transfer-Encoding: chunked\" would make this easier to grok?. One interesting thing is, from what I read, Netty never really cares how chunks are formatted on the wire (think HEX prefix w/ a chunk size) and just shoves whatever is available (think part of an actual chunk) into the pipeline.. As we have little to no control over how Netty decodes HTTP streams, we usually just refer to a chunk (HTTP chunk to be precise) as whatever Netty gives us in HttpContent.\nAlso, I appreciate your patience with this. I'm really excited about this PR!. @bryce-anderson and I are talked about this. It seems like we need to keep maxRequestSize in place as it's also get passed to a supper class, FinagleHttpObjectAggregator, which in turn, takes care about handling oversized messages (think HTTP 413). Changing this param to a different value, for example 128kb, means your HTTP server would be returning 413 on each payload bigger than 128kb.\nWe really need two different parameters here. One for the super-class (object aggregator), one for aggregate-if-less-then.. Let's make it a separate method. Java doesn't understand default arguments.. Oh the shouldAggregate check. Yeah, I think you're right.\nMaybe it's worth mentioning in the scaladoc for withStreaming method that aggregateIfLessThan could be replaced with maxRequestSize if the later is smaller.\nAlso, what do you think about omitting the handler all-together if maxContentLength is zero?. Yeah, I'm with you on the understanding front. What I mean is, when users configure withStreaming(true, 10.mb) they expect fixed-length messages up to 10mb to be aggregated. Yet, as we take min between max-request-size and aggregate-if-less-than`, we actually cap it at 5mb (max-request-size default). Let's just document that we take the minimum between the two.\nAlso, really good point about messages w/o bodies that still needs to be \"aggregated\".. I don't think we should ignore it. There is PayloadSizeFilter that would reject payloads bigger than a max-size so it doesn't really make sense to aggregate more than that anyway.. Yes, I like 8kb.. I like all of those names but I'm still in the \"we should group this new config with withStreaming\" camp. As the new value only takes affect when streaming is enabled, we might want to keep them together (one configuration entry and perhaps one stack param).\nActually I think fixedLengthStreamedAfter is pretty cool and could make a good pair for enabled:\nscala\nwithStreaming(enabled = true, fixedLengthStreamedAfter = 64.kb). Oh yeah, sorry I if I wasn't clear. Basically we're trying to ensure our APIs are accessible from Java which, unfortunately, means saying no to default arguments.. Love these docs! Ty!. @luciferous talked about using 8k for a default value here. I liked that at first but maybe we're better off preserving the current \"default\" behavior and using 5.mb as a value?. @edio This thread.. ",
    "sirmax": "Oh, I wasn't suggesting un-releasing 6.5.2 \u2014 what's done is done. You might want though to re-release it as 6.6.0 and promote this formally correct version, but the choice is up to you of course. \nI don't think this issue needs to stay open \u2014 it has served its \"notification\" purpose. I'm closing it.\n. I can, eventually. But it could take some time to make a proper PR with tests and stuff.\nBTW @mosesn, what solution to this problem would you prefer? A timeout in Netty's SslHandler or in Finagle's SslConnectHandler? A fixed 10s timeout or a configurable one?\n. @vkostyukov, sorry guys, I'm yet to find a time for this :( Tomorrow maybe.\nAs for the help, hint me on testing this thing, please. I thought about creating a pipeline and checking whether the SslHandler is properly configured, but maybe you have a better idea.\n. Two things to note:\n- I have a \"neighbour\" test crashing in SBT on assertion in Netty (and had it crashing prior to the fix):\n- should close the channel if the remote peer closed TLS session *** FAILED ***\n      java.lang.AssertionError:\n      at org.jboss.netty.handler.ssl.SslHandler.decode(SslHandler.java:853)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:425)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n      at com.twitter.finagle.netty3.Netty3TransporterTest$$anonfun$1$$anonfun$apply$mcV$sp$12$$anonfun$apply$mcV$sp$13.apply$mcV$sp(Netty3TransporterTest.scala:234)\nIn IDEA's runner it is green. I didn't investigate it further.\n- SslHandler requires a timer. I used DefaultTimer as the rest of the Netty3Transporter does, but it probably would be better to use the one from com.twitter.finagle.param.Timer.\n. Yup, when(engine.isInboundDone) thenReturn true fixes it. However I'm not entirely happy with such mocking, because it might break some yet-to-be-written tests in an unexpected way.\nWhat's out options here:\n- Add this mock anyway with a comment regarding the possible errors for those who might want to reuse it.\n- Write a conditional mock that would return true only when some (but what exactly?) condition is met. Downside \u2013 this would get ugly immediately.\n- Do nothing and make a mental notice that the tests should be run with assertions disabled.\nSo, WDYT?\n. @vkostyukov:\n\nI would suggest to move the origin SSL engine inside the neighbor tests (+ new mock configuration on isInboundDone) and create a new and super simple one (like val engine = mock[SSLEngine]) in the new test.\nDoes it sounds reasonable?\n\nIt does. I've updated the PR accordingly.\n. @dschobel, reformatted, added a CHANGES entry. Couldn't use named args with SslHandler since it's Java, added val startTls = false instead.\n. You know, guys, there is one thing that bothers me. \nA handshake may be considered as a part of the connection process \u2013 both Netty's SslHandler and Finagle's own SslConnectHandler actually delay \"connected\" event propagation until the handshake is done. Thus it may have sense to cover the handshake with Transporter.ConnectTimeout instead of adding an implementation specific param.\nMaybe instead of setting up timeouts in SslHandler and other places, might the need appear, Finagle should handle the connection timeout itself? It would bring a small overhead of course, and is a bit trickier, but maybe this it the right way?\n. Hi guys!\nFirst of all I'm sorry for going silent for so long. Been pretty busy :(\n@vkostyukov just to clarify, do you suggest reusing Transporter.ConnectTimeout for SSL handshake timeout?\nWhile this would be, probably, the easiest thing to do, it would effectively double the timeout. For me personally this is not a problem at all, but I can't speak for all the Finagle users out there, so it is your choice to make.\n. @mosesn I don't quite get it.\nNetty3Transporter already does the interrupt handling [1]. But it neither can nor should expect the clients to handle the connection timeouts themselves.\nI see two possible ways to deal with timeouts:\n1. Somehow configure netty's handlers to close the channel when the timeout happens.\n2. Do not use netty timeouts, instead add a timeout to one of the methods that return Future[Transport[In, Out]].\nWe've started with the first one, and it does not seem right :) Now I think I'd prefer the second one. While it adds a small overhead, it results in a predictable uniform timeout behaviour, agnostic to the pipeline configuration. In fact since ConnectTimeout parameter is defined on the Transporter abstraction, the timeout handler may be written as a helper function that can be used in any Transporter implementation, be it a netty-based or not.\n[1] https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/netty3/Netty3Transporter.scala#L50\n. @mosesn in your previous comment you've said \"We know the interrupt will come already\". I interpreted this as an assumption, that there is always some other code outside of the Netty3Transporter that eventually interrupts the connection, thus we just need to handle interrupts properly.\nBut the problem is this is not always true. In #345 I mentioned FailFastFactory getting stuck indefinitely, waiting for the connection to succeed or fail, and not sending any interrupts.\nAnd regarding \"nor should expect the clients to handle the connection timeouts themselves\", I mean it is the Transporter's responsibility to handle connection timeouts one way or another.\nHope this makes some sense :)\n. > interrupt the previous failfast connection attempt when we start a new one\nBut the thing is FailFastFactory does not start a new connection until the previous attempt succeeds or fails. So no memleaks here, just a completely broken service :)\nAnd I'm not sure it is good idea to make something else responsible for connection timeouts. \u2026Perhaps we can make a ServiceFactory proxy that interrupts connection attempts just like the TimeoutFilter interrupts requests to the underlying Service, but would it be more robust and easier to use?\n. Oh wow! I've completely overlooked the TimeoutFactory. Now everything you said about FailFastFactory being broken makes much more sense. I feel really dumb right now.\nCould you, please, elaborate on \"move the retries out of band and also interrupt the old ones\"?\n. Hi @luciferous! Frankly speaking this is not coming along at all \u2013 I'm out of spare time :(\nI think we'd better close this PR and just keep #345 open until someone fixes it. Here's why:\n- In this PR I tried to fix #345 by adding an SSL-specific configuration parameter. Later we concluded it was not a good idea.\n- @mosesn was against re-using Transporter.ConnectTimeout for SSL, and he's probably right. It would be more like a workaround hack than a proper fix.\n- The proper fix should be somewhere around FailFastFactory. I can't yet pinpoint where exactly it should be.\n. AccessController.doPrivileged may throw AccessControlException in some configurations. I suggest catching it here. Not catching it will render InetResolver unusable in those configurations. \nI'm not sure other parts of Finagle would work correctly in restricted environments, but let's not add +1 point of failure :)\n. Personally no, I don't have such experience. But it seemed odd to me that one can safely elevate permissions, so I googled \"AccessController.doPrivileged AccessControlException\" and found a some cases when it does happen. One was a sandboxed applet, another had a security manager installed with restrictive permissions.\nIn the doc on AccessController itself there is a passage which hints that things may go wrong:\n\nIf that caller's domain has the specified permission, no further checking is done and checkPermission returns quietly, indicating that the requested access is allowed. If that domain does not have the specified permission, an exception is thrown, as usual.\n. \n",
    "vtatai": "@mosesn I will take a stab at it, hopefully will be able to get some progress.. ",
    "mkantor": "Unless I'm misunderstanding it looks like this was solved way back in 2014 with 4258d70f60c956e6c6f361f84d84ef1a6e2b38dc.. ",
    "kevinoliver": "As noted above, this was fixed back in 2014.. Not exactly the answer you may be looking for, but I recommend using http://github.com/twitter/hbc as a hosebird client.\n. This has been merged internally, thanks!\n. lgtm. I'll take this over and should get it applied internally.\n. Ok this has been merged locally. Should land on the develop branch soon. Thanks for the patch.\n. lgtm. i'll get this applied locally.\n. Thanks.\nThis has been merged locally. Once we get our github push issue sorted out, it'll show up on the develop branch. \n. @LithiumTD just one minor naming fix and then i'll merge this in.\n. Great, thanks. I'll try to get this merged in today or tomorrow.\n. Ok this is merged in but just missed this week's push to the develop branch. Thanks again for the contribution.\n. lgtm\n. Thanks! This was fixed on the develop branch \u2014 https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/filter/MaskCancelFilter.scala\nHopefully we will do a release in the next couple weeks.\n. @tianxiao-ma after the small requested change, i'm happy to merge this in. \n. Ok this is now merged locally and should make it to the develop branch soon. Thanks @tianxiao-ma.\n. In the future, the mailing list would be a better place for these sorts of questions.\nIn this case, it looks like you did not upgrade your util dependency at the same time. I believe the matching version is 6.24.0.\n. Thanks for your patience. Our team doesn't have a lot of redis expertise, and thus the delay. It may still take some time until we get to it.\n. thanks. i'll get this pulled this in locally. fwiw, i probably need to modify the patch so that our pants build system knows about this resource, but it should be a minor change and you'll get full credit for the patch.\n. Ok, well even with sbt this test fails locally for me:\n```\n[info]  1 TEST FAILED \n[error] Failed: Total 182, Failed 1, Errors 0, Passed 181\n[error] Failed tests:\n[error]     com.twitter.finagle.thrift.EndToEndTest\n[error] (finagle-thrift/test:test) sbt.TestsFailedException: Tests unsuccessful\n[error] Total time: 10 s, completed Sep 14, 2015 10:20:31 AM\n\nSep 14, 2015 10:20:32 AM org.jboss.netty.channel.socket.nio.AbstractNioSelector\nWARNING: Failed to initialize an accepted socket.\njava.lang.IllegalArgumentException: requirement failed: Failed to run command 'openssl pkcs12 -export -password pass:FKWBQLFWRKIUTHSLSOXMEVIX -in /var/folders/7m/zdymhkzn7tqb798sk_ld6mjc0000gn/T/temp8021341077388431901dir/FKWBQLFWRKIU.pem -out /var/folders/7m/zdymhkzn7tqb798sk_ld6mjc0000gn/T/temp8021341077388431901dir/FKWBQLFWRKIU.p12'\n    at scala.Predef$.require(Predef.scala:233)\n    at com.twitter.finagle.ssl.Shell$.run(Util.scala:7)\n    at com.twitter.finagle.ssl.PEMEncodedKeyManager$.makeKeystore(PEMEncodedKeyManager.scala:79)\n    at com.twitter.finagle.ssl.PEMEncodedKeyManager$.apply(PEMEncodedKeyManager.scala:30)\n    at com.twitter.finagle.ssl.JSSE$.com$twitter$finagle$ssl$JSSE$$makeContext$1(JSSE.scala:42)\n    at com.twitter.finagle.ssl.JSSE$$anonfun$1.apply(JSSE.scala:59)\n    at com.twitter.finagle.ssl.JSSE$$anonfun$1.apply(JSSE.scala:59)\n    at scala.collection.mutable.MapLike$class.getOrElseUpdate(MapLike.scala:189)\n    at scala.collection.mutable.AbstractMap.getOrElseUpdate(Map.scala:91)\n    at com.twitter.finagle.ssl.JSSE$.server(JSSE.scala:57)\n    at com.twitter.finagle.ssl.Ssl$$anonfun$server$1.apply(Ssl.scala:49)\n    at com.twitter.finagle.ssl.Ssl$$anonfun$server$1.apply(Ssl.scala:45)\n    at scala.Option.getOrElse(Option.scala:120)\n    at com.twitter.finagle.ssl.Ssl$.server(Ssl.scala:45)\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17$$anonfun$mkThriftTlsServer$1$1.apply(EndToEndTest.scala:292)\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17$$anonfun$mkThriftTlsServer$1$1.apply(EndToEndTest.scala:292)\n    at com.twitter.finagle.netty3.Netty3Listener$.addTlsToPipeline(Netty3Listener.scala:101)\n    at com.twitter.finagle.netty3.Netty3Listener$$anon$4$$anonfun$getPipeline$3.apply(Netty3Listener.scala:302)\n    at com.twitter.finagle.netty3.Netty3Listener$$anon$4$$anonfun$getPipeline$3.apply(Netty3Listener.scala:301)\n    at scala.Option$WithFilter.foreach(Option.scala:208)\n    at com.twitter.finagle.netty3.Netty3Listener$$anon$4.getPipeline(Netty3Listener.scala:301)\n    at org.jboss.netty.channel.socket.nio.NioServerBoss.registerAcceptedChannel(NioServerBoss.java:134)\n    at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:104)\n    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n    at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n\nSep 14, 2015 10:20:33 AM org.jboss.netty.channel.socket.nio.AbstractNioSelector\nWARNING: Failed to initialize an accepted socket.\njava.lang.NullPointerException\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17$SslFile$2$.(EndToEndTest.scala:284)\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17.com$twitter$finagle$thrift$EndToEndTest$$anonfun$$SslFile$1$lzycompute(EndToEndTest.scala:283)\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17.com$twitter$finagle$thrift$EndToEndTest$$anonfun$$SslFile$1(EndToEndTest.scala:283)\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17$$anonfun$mkThriftTlsServer$1$1.apply(EndToEndTest.scala:292)\n    at com.twitter.finagle.thrift.EndToEndTest$$anonfun$17$$anonfun$mkThriftTlsServer$1$1.apply(EndToEndTest.scala:292)\n    at com.twitter.finagle.netty3.Netty3Listener$.addTlsToPipeline(Netty3Listener.scala:101)\n    at com.twitter.finagle.netty3.Netty3Listener$$anon$4$$anonfun$getPipeline$3.apply(Netty3Listener.scala:302)\n    at com.twitter.finagle.netty3.Netty3Listener$$anon$4$$anonfun$getPipeline$3.apply(Netty3Listener.scala:301)\n    at scala.Option$WithFilter.foreach(Option.scala:208)\n    at com.twitter.finagle.netty3.Netty3Listener$$anon$4.getPipeline(Netty3Listener.scala:301)\n    at org.jboss.netty.channel.socket.nio.NioServerBoss.registerAcceptedChannel(NioServerBoss.java:134)\n    at org.jboss.netty.channel.socket.nio.NioServerBoss.process(NioServerBoss.java:104)\n    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n    at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n```\n. thanks! don't think i'd've figured that one out...\ni'm a bit bogged down right now, but hopefully i can get back to this by the end of the week.\n. Ok this is merged in. Should show up on the develop branch on Monday.\nThanks again!\n. @olix0r its not obvious that this is a generally useful construct for end-users. Could you elaborate more on the use case?\nA middle ground might be to mark if private[finagle] which would allow users to use it at their own risk by putting their code into com.twitter.finagle.\n. There wasn't general consensus that this should be public, and I generally prefer less public API support.\nLets do this as private[finagle] and we can try to remember to not destroy/mutilate it.\n. @olix0r a project can choose to keep all APIs frozen and rarely if ever modify them and of course that has downsides as well. The JDK is a good example of this and for the most part do a great job on it. But it leads to much slow release cycles and keeping broken APIs for a long time (forever so far). I highly doubt you are proposing that.\nWe try our best to keep public API stable and document it when we do break them. For things where we are less certain about their APIs we want to have more flexibility in modifying them. This is when we use the package private visibility modifiers and put APIs into the exp package. \nIts a balance or course and I hope we are doing a decent job on it.\n. I think @atollena and @jaked would best to answer your first question.\nAnd regarding the latter we don't have any great mechanism for it today :/ Do you or anyone else have any ideas given how development works on this project?\n. I like the idea of a finagle-dev@ list. (+@travisbrown)\n. thanks for the patch. it'd be good if some other folks who know finagle-zipkin chime in \u2014 cc @bmdhacks \ncan you add a note in finagle/CHANGES to the next release's \"Breaking API Changes\" section?\n. looks good to me. i think someone else should take a look before we merge this in.\n. Hi @3thinkthendoit sorry for the delay. @tonyd3 has a patch for this that should land soon that lets Java users call configured.\nYou'll be able to do:\n.configured(new Tracer(com.twitter.finagle.tracing.DefaultTracer.get()).mk())\nAnd take a look at StackParamCompilationTest for how to use the others.\n. woah :+1: \n. This got fixed a little while back. See this unit test for an example.\n. looks good to me too. thanks @cyphactor \n. :ship: \n. @olix0r just two small things.\n. lgtm, i'll try to get this pulled in.\n. Thanks for your patience with the holidays. This patch got merged in late today and should show up on the develop branch next Monday.\n. :ship: thanks i'll get this pulled in.\n. @siggy ok this just got merged in and'll show up on develop this Monday. thanks again.\n. :ship: \n. this will be a nice addition. thanks.\n. lgtm @spockz once you cleanup the scaladoc style.\n. @penland365 i'll try to take a look today\n. @penland365 it doesn't apply cleanly to develop anymore.\n. Ok, I've skimmed through it and I think the concept seems reasonable.\nMy main concern which can be easily fixed \u2014 there is a good amount of API breaks. I think we can avoid that by having forwarding methods and constructors.\nThere is are a bunch of style nitpicks that we can visit later.\nAnd don't sell yourself short \u2014 this is worthy of a new feature in finagle/CHANGES.\n. @adriancole seems reasonable. It'd probably need a bit of work because finagle-zipkin brings in the thrift tracer via service loading.\nTo do it in a backwards compatible manner, I think that implies moving most of everything in finagle-zipkin into a finagle-zipkin-core and then leaving the service loader in finagle-zipkin. Then you can add a new module finagle-zipkin-http that depends on finagle-zipkin-core and finagle-http and adds this tracer.\nBut maybe I'm jumping to conclusions with regards to what you are thinking from the service loader aspect.\n. Ok. So if since it needs configuration, this can be done manually as you mentioned \u2014 DefaultTracer.self = YourHttpTracerThatYouveConfigured. Another approach is to use service loading plus flags (e.g. System properties). \nI would defer to you and your users on how you'd prefer to do it. I suspect the former is simpler for most though.\nKafka sounds like it would be similar, there'd be a new finagle-zipkin-kafka module, and it could be configured in whatever fashion is desired.\n. > Thanks for the idea. Do you literally mean System.getProperty or Twitter\n\nflags? Do you have an example inside finagle somewhere of someone\nidiomatically using flags for a service loader implementation? I'm happy to\nwrite this, just curious the idiomatic way.\n\nI think a c.t.app.GlobalFlag is fine. In practice users can pass a value for the GlobalFlag via a System.property so it works and you also get the command-line documentation from flags. finagle-stats does this \u2014 it comes in via server loader and then some of its configuration is done via flags. See useCounterDeltas for example.\nRe @kristofa's comments \u2014 explicit configuration is nice. I think @adriancole is probably also correct that it won't catch everything, but I think it practice its close to everything.\n. Thanks for the patch, @liamstewart. I like the idea of it. I'll try to take a look in the next few days.\n. > Testing. Where / how would be the right way to test this inside finagle?\nTypically we'd test this sort of thing in c.t.f.thrift.EndToEndTest. I think you can write a test that verifies a few things:\n- client has no conn prep time stats\n- server doesn't see a ClientId\n\nImplementation of avoiding the protocol upgrade in the Thrift.Client object. Right now, I switch in the preparer method - stats on prepare latency disappear (which I think is right). It seems like it would be nice to have the stack method just not do any replacement, but it doesn't have access to params.\n\nNot sure I understand your question or what you are looking for here.\n. @liamstewart i won't have time to look at this for a little while, hopefully someone else will get to it.\n. I believe that comes from scrooge generated code from scribe.thrift[1] idl.\n[1]\nhttps://github.com/twitter/finagle/blob/develop/finagle-zipkin/src/main/thrift/scribe.thrift#L29\nOn Fri, Feb 19, 2016 at 12:51 AM, dy8000 notifications@github.com wrote:\n\nI have an identical project, one using maven to manage dependencies and it\nis fine running the latest production version of all finagle libs found in\nmaven.\nI migrated to gradle using the identical dependencies and now a runtime\nerror complaining zipkin lib not found. I suspect gradle is doing something\nto optimize versions of transitive dependencies. Can anyone point me which\nlib in maven need to be included to avoid the error. thanks\njava.lang.NoClassDefFoundError:\ncom/twitter/finagle/zipkin/thriftscala/LogEntry$\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer$$anonfun$createLogEntries$1.apply(RawZipkinTracer.scala:180)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer$$anonfun$createLogEntries$1.apply(RawZipkinTracer.scala:176)\nat scala.collection.immutable.List.foreach(List.scala:381)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer.createLogEntries(RawZipkinTracer.scala:176)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer.logSpans(RawZipkinTracer.scala:196)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer$$anonfun$3.apply(RawZipkinTracer.scala:108)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer$$anonfun$3.apply(RawZipkinTracer.scala:108)\nat\ncom.twitter.finagle.zipkin.thrift.DeadlineSpanMap.update(DeadlineSpanMap.scala:51)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer.annotate(RawZipkinTracer.scala:310)\nat\ncom.twitter.finagle.zipkin.thrift.RawZipkinTracer.record(RawZipkinTracer.scala:229)\nat\ncom.twitter.finagle.zipkin.thrift.SamplingTracer.record(ZipkinTracer.scala:199)\nat com.twitter.finagle.tracing.DefaultTracer$.record(Tracer.scala:146)\nat\ncom.twitter.finagle.tracing.Trace$$anonfun$uncheckedRecord$1.apply(Trace.scala:266)\nat\ncom.twitter.finagle.tracing.Trace$$anonfun$uncheckedRecord$1.apply(Trace.scala:266)\nat scala.collection.immutable.List.foreach(List.scala:381)\nat com.twitter.finagle.tracing.Trace$.uncheckedRecord(Trace.scala:266)\nat com.twitter.finagle.trrace$.record(Trace.scala:312)\nat\ncom.twitter.finagle.tracing.AnnotatingTracingFilter$$anonfun$apply$4.apply(TraceInitializerFilter.scala:156)\nat\ncom.twitter.finagle.tracing.AnnotatingTracingFilter$$anonfun$apply$4.apply(TraceInitializerFilter.scala:150)\nat com.twitter.util.Promise$Monitored.apply(Promise.scala:85)\nat com.twitter.util.Promise$Monitored.apply(Promise.scala:76)\nat com.twitter.util.Promise$$anon$1.run(Promise.scala:381)\nat\ncom.twitter.concurrent.LocalScheduler$Activation.run(Scheduler.scala:178)\nat\ncom.twitter.concurrent.LocalScheduler$Activation.submit(Scheduler.scala:136)\nat com.twitter.concurrent.LocalScheduler.submit(Scheduler.scala:207)\nat com.twitter.concurrent.Scheduler$.submit(Scheduler.scala:92)\nat com.twitter.util.Promise.runq(Promise.scala:350)\nat com.twitter.util.Promise.updateIfEmpty(Promise.scala:721)\nat com.twitter.util.Promise.update(Promise.scala:694)\nat com.twitter.util.Promise.setValue(Promise.scala:670)\nat com.twitter.concurrent.AsyncQueue.offer(AsyncQueue.scala:111)\nat\ncom.twitter.finagle.netty3.transport.ChannelTransport.handleUpstream(ChannelTransport.scala:55)\nat\norg.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\nat\norg.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\nat\norg.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108)\nat\norg.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\nat\norg.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\nat\norg.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\nat\norg.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)\nat\norg.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\nat\norg.jboss.netty.channel.DefaultChaeline.sendUpstream(DefaultChannelPipeline.java:564)\nat\norg.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\nat org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\nat\norg.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)\nat\norg.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)\nat\norg.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)\nat\norg.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\nat\norg.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:92)\nat\norg.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\nat\norg.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\nat\norg.jboss.netty.channel.SimpleChannelHandler.messageReceived(SimpleChannelHandler.java:142)\nat\ncom.twitter.finagle.netty3.channel.ChannelStatsHandler.messageReceived(ChannelStatsHandler.scala:68)\nat\norg.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)\nat\norg.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\nat\norg.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\nat\norg.jboss.netty.channel.SimpleChannelHandler.messageReceived(SimpleChannelHandler.java:142)\nat\ncom.twitter.finagle.netty3.channel.ChannelRequestStatsHandler.messageReceived(ChannelRequestStatsHandler.scala:32)\nat\norg.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)\nat\norg.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\nat\norg.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\nat org.jboss.netty.channel.ChannelsssageReceived(Channels.java:268)\nat org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\nat org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\nat\norg.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\nat\norg.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\nat\norg.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\nat org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\nat\norg.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\nat\norg.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\nat\njava.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\nat\njava.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\nat java.lang.Thread.run(Thread.java:745)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/468.\n\n\nKevin Oliver | Twitter, Inc | follow me: @kevino http://twitter.com/kevino\n. Does Http.server.withCompressionLevel work for you? (Looks like we could\nuse some scaladoc on that method and the others in Http.server to explain\nwhat they do).\nI think it gets wired into c.t.f.http.Codec which in turn wires up\nnetty's HttpContentCompressor for a server.\nOn Wed, Feb 24, 2016 at 12:33 AM, Adrian Cole notifications@github.com\nwrote:\n\nCan (gzip) decompression be added for http servers?\nThe _decompressionEnabled flag and similar threw me for a loop, as it\nseems to be placed on Http, but only implemented on the client. It is not\nobvious how to affect the netty pipeline to add server support for this,\nwithout changing finagle classes directly.\nIf there's a way to hook into the netty pipeline to add this (without\nchanging finagle classes), that'd work for me, too.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/469.\n\n\nKevin Oliver | Twitter, Inc | follow me: @kevino http://twitter.com/kevino\n. Derp, reading fail on my part.\nLooks like it is not wired up but could be done in a similar fashion.\n. @leonmaia this is great \u2014 thanks! i just have a few small fixes i'd like to see applied and then would be happy to pull this in.\n. @leonmaia lgtm i'll work on getting this merged in now. thanks!\n. Just merged this locally. Should show up on the develop branch this Monday. Thanks again.\n. I haven't read the diff yet, but one consideration is how this changes iteration of existing keys. Specifically, if you had a user that did Map.add(\"UP\", \"X\") and then iterated over the keys, they'd now see \"up\" instead of \"UP\". \nI think that could in turn break users who need to look at all the headers to calculate a signature, for example in OAuth 1.1.\n. I can't think of a way to do merge on read, but maybe you have ideas.\n. @grandbora this looks like a good approach. i think its worthy of a note in CHANGES under the \"Runtime Behavior Changes\" section, if you could add that as well. or you could call it a \"Bug Fix\" \u2014 either way is fine.\n. thanks @grandbora. working on pulling this in locally. looks like there is some usage of the mutable map constructor so it may take some time.\n. This just landed in develop with commit https://github.com/twitter/finagle/commit/603c0226029f8cc9da2ea628e793e80a91c170ef\nThanks for the contribution @grandbora.\n. Is this the same issue as in #469? If so, a PR implementing it would be great (cc @adriancole)\n. Ugh looks like this was submitted in 81894c2c and we messed up on preserving the commit info. \ud83d\udc4e\n. sg, thanks.\n. @vkostyukov have we addressed this in the recent Reader work?. Thanks, I'm closing this as we aren't working off this ticket directly.. This was merged in 4d6dfc1\n. lgtm @olix0r \n. looks like this landed in 186f7a42f but we messed up and lost the commit info :( \napologies.\n. @yukw777 mind leaving a unit test that reproduces along with a stacktrace showing the deadlock?\nFor what its worth, we do this pretty regularly in Finagle's filters. TimeoutFilter returning a Future.exception is a smallish example.\n. My recommendation is to create a \"Follow Redirects\" Filter and then compose\nit with your client.\nIf you think it is general purpose enough and others could use it, create a\nPR adding it to com.twitter.finagle.http.filter.\nOn Tue, Apr 26, 2016 at 3:44 AM, Tim Nieradzik notifications@github.com\nwrote:\n\nAn endpoint that I am requesting may redirect to another page, of which I\nneed to access the data stream. I ended up with the following code:\nclient(request).flatMap { response =>\n  if (response.status != Status.Found) Future.value(response)\n  else {\n    val newRequest = RequestBuilder().url(response.location.get).buildGet()\n    val newClient = Http.client.newService(newRequest.host.get + \":80\")\n    newClient(newRequest)\n  }\n}.map(_.reader)\nCould we introduce an option to automatically follow redirects?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/500\n\n\nKevin Oliver | Twitter, Inc | follow me: @kevino http://twitter.com/kevino\n. I understand the need for the change in StackServer. I'm not sure I see why the change is necessary in MkJvmFilter.\n. yeah, i'm not a fan of side-effects from constructors either. wanted to make sure i understood the change. i'm fine leaving it as is.\n. \ud83d\udea2 \n. @olix0r i personally haven't had time to look. hoping to by the end of the week. \n. RequeueFilter is intended for nacks and these retries are usually going to not be that. \ni think this type of code belongs in RetryFilter instead.\n. or barring that, we could consider adding a new filter that has this behavior and sits after requeues.\n. > RetryFilter isn't on the stack by default (that's okay, just making sure I'm not missing it somewhere).\nyeah, i think this would need to change for Stack-based clients and perhaps slight modifications to ClientBuilder as well.\n\nHow do multiple retry modules interact with RetryBudgets? I assume they should share retry budgets so that retries in either place are counted -- but the lower one would have to be wrapped in a WithdrawOnlyRetryBudget?\n\nby default, they share a budget and yeah the withdrawals need to be coordinated \u2014 this is all handled in the Retries code today. i'd recommend trying to keep the logic there if you want to keep sane.\nit might be good to make sure others are on board with this direction (@mosesn @dschobel @roanta) before we go too deep here.\n. Requeues are meant to handle known-to-be-safe failures in a transparent manner. The initial assumption was that there should not be any backoffs between failures. That is not always a valid assumption depending on cluster topology and flexibility was given to allow customization. I think its reasonable to question if that original assumption is worth the potential risk.\nAs for why the backoffs should be separate, that part makes sense to me. You may want an exponential backoff for application failures while something else may be appropriate for a nack. Ultimately I think you should be able to share them across if you choose to. \nHope that helps clarify.\n. I think we've made this quite a bit better since this issue was opened. The contributing section of README.md points you to CONTRIBUTING.md which in turn has the instructions for building the dependencies. That part is now a 1-liner: curl -s https://raw.githubusercontent.com/twitter/dodo/develop/bin/build | bash -s -- --no-test finagle.\nClosing this as I believe we've addressed the issues. Thanks for the feedback.\n. @sveinnfannar yeah we'll add the RB_ID, thanks. i'll try to take a look today as well.\n. @sveinnfannar this is great. my comments are all superficial and should be easy to patch up.\n. my pleasure. let me know when its ready for another look.\n. @sveinnfannar ok looking good to me. mind fixing this round and pinging when its good?\n. cool @sveinnfannar looks good now. i'll work on getting this merged in. thanks.\n. hmm @sveinnfannar i'm running into some conflicts applying the commits locally. do you mind rebasing on develop and then squashing these down to a single commit?\n. ok, this one has decent sized work on our end to get it integrated. i'll keep at it but it may take a few days.\n. @sveinnfannar i made good progress on this today and should get it merged in by the end of the week.\n. alrighty! got this merged in locally and should show up on the develop branch this coming monday.\nthanks for contribution.\n. @sveinnfannar been busy for the past few days, hoping to take a look at this in the next few days.\n. @sveinnfannar apologies for the delay in getting to this. looks good though. i don't have too much in the way of comments.\none question re the client dependency \u2014 how do kafka clients work for other versions of servers? and what will happen for users on other versions of the client?\n. So we've discussed this a bit over here and our preference is for this to be a repo in the finagle organization. This gives you full autonomy over the project and lets us stay focused on the core protocols that we use.\n. \ud83d\udc4d  @sveinnfannar \n@adriancole releases and so on would be owned by the project's owners (perhaps you and @sveinnfannar to start?)\n. @adriancole to be honest I don't know how this works. @vkostyukov has finch there and @samn has finagle-clojure and as far as I know they do their own releases. Maybe one or both can comment. Not sure what concerns you have with regards to automation.\nAnother option is to not use the Finagle organization! \n. > The only downside is that people using finagle will have to look at\n\nthe OpenZipkin repo for zipkin integration as opposed to the Finagle\none. This implies at least a README change in finagle-zipkin here (in finagle's repo) so that people can be directed accordingly.\n\n@adriancole If you go this route, that seems reasonable to me.\n. @virusdave none of the core committers are working on this. but we are motivated to help get patches in if you or anyone else is interested in picking this up.. (echo of what @mosesn said)\n. @spockz yeah, it seems reasonable to me that on the state change an event would fire. You you could do what you wish with that in the application layer. What are you thinking the events should look like?\n. ok i think i misunderstood what you were looking for. let me see if i can get up to speed.\nfirst, are we talking about the case when all memcached nodes have been marked down via failure accrual (which happens to use response classification)? if so, do you want a callback or different behavior? or something else?\nif not, what situation are you discussing?\n. @spockz i'm not convinced we want to have different behaviors. to be explicit, prior to response classification failure accrual was not only responding to connection errors. timeouts and other network issues also would be included.\nwhat i'm hearing is that you'd like to have a different behavior in the LB when no nodes are Status.Open. today this is not configurable but perhaps it should be. i have a patch that should show up on develop this Monday that doesn't change this, but it cleans this code up in the Distributors and would make it easier to change. \ni'd be open to a patch that makes the behavior configurable when no nodes are Open. this is something we've discussed internally as well but we were fine with the current default. that said i'm not sure you'll get the level of control you are asking for \u2014 where you want different behavior based on how they got marked busy.\n. FailedFastException is only used by FailFastFactory which indicates connection failures. whereas FailureAccrualFactory is used to change the status of a node to Busy which is used by the load balancer to route traffic around it. in other words, it doesn't return exceptions directly.\ni think you are talking about the case when all nodes are marked Busy via FailureAccrualFactory. in that case, finagle's load balancer optimistically try to send traffic. if thats the case, i think you want to open a PR that allows you to change that load balancer's behavior to return a FailedFastException or perhaps something slightly different.\n. lgtm too.\n. This was merged back in 5c6f9167723c40e24485a98039ec9cf61a258732\n. Agreed about the conflation. You'd be fine writing a SamplingTracerreplacement without that code, including the serialization. Running without it with only impact devs who want to use event tracing with this replacement and that could always be addressed separately.\n. seems like a useful feature. what happens if more than one Start nests? would it help to take an identifier?. @edma2 or @atollena may have thoughts about this.\n. @reikje i think a PR would move things forward. looks like @edma2 suggested injecting the FuturePool to use as a parameter to a new InetResolver.apply method. this should be easy to do in a backwards compatible way.. This got resolved in #579 thanks again.. @thirstycrow this sounds nice and I know there have been teams here at Twitter who would like something like this (they've worked around it in a different way, but I can't recall the details).\nI'll try to take a look at your change this week.\n. also, apologies for the delay in reviewing. it got lost in my inbox.\n. > I'm not quite familiar with the SHA thing. Could you add it before merging this pull request? The libthrift code is copied exactly from the 0.9.1 tag\na link to that tag works perfectly for me. the idea is just to help future devs track down exactly where the code originated from.\n. the default service addition is nice. thanks.\n. this lgtm. be good to have another set of eyes on it.\n. +@mosesn \nSeems like a reasonable approach to me. \n. lgtm too. i'll get this merged.\n. This got merged locally and should make it out to develop in today's push. Thanks @adriancole.\n. Merged in f8e76124d1b5f344176b79697b5c911e2c8f44fc\n. Not against creating a module for it but I'm not sure we want this module in the default stack for Http, so you'll still need to decide where to place it. Alternatively, since I think you'll want this at the beginning of the chain (so that it sees the final responses and total time) you could also  this Filter on top: new http.filter.StatsFilter(..).andThen(Http.client.newService)\n. Ah. Yeah, that reason makes sense to me too. Feel like putting together a PR?\n. @spockz I think #557 addressed this so I'm closing it. Please reopen if I got that wrong.. @vkostyukov \"It's quite clear that it's hard to go the second road here since it breaks the API (will likely break both internal and external dashboards). So I vote for 1.\"\nThis could be done for only users of the module which is new and therefore not a breaking change.\nI kinda like the scoping under http, but don't feel strongly.\n. lgtm!\n. lgtm.\n. working on getting this merged.\n. Alrighty this is merged and'll show up on the develop branch this Monday. Thanks again!\n. @vazyzy, yeah this is a surprise for new users and a pothole in terms of ease-of-use. \n+@vkostyukov, @bryce-anderson, @mosesn who've been talking about this and some related issues.\n. This new Netty PR might be relevant and also has the wonderful title of\n\"InsecureTrustManagerFactory is sometimes not insecure enough\".\nhttps://github.com/netty/netty/issues/5910\nOn Tue, Oct 11, 2016 at 12:59 AM, m.orazow notifications@github.com wrote:\n\nHello @ryanoneill https://github.com/ryanoneill,\nYes, I would love to help!\nCurrently, unfortunately I do not know the answers for your first three\nquestions. I will do my best to get answers for them.\nMeanwhile, I checked the last one with null and it worked without any\nproblems.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/561#issuecomment-252839984,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAVMXSCrhrGsKzUMkyVAA0rp_IhG1211ks5qy0HbgaJpZM4KS5Gr\n.\n\n\nKevin Oliver | Twitter, Inc | follow me: @kevino http://twitter.com/kevino\n. @adriancole What approach are other systems taking here? Its not obvious to me what the tradeoffs are between those two choices.\n. @vkostyukov @mosesn I think we should expose this Netty 3 API. It would go away once Netty 3 goes away.\n. thanks, this was merged internally.. @spockz re #1, this approach was discussed as an alternative design for response classification but we decided against it for two reasons. 1, it meant users had to do \"data modeling\" for their failures. 2, it would be a significant change for existing code to use response classification, and thus a barrier to adoption.\nre #3, i see the appeal of exposing the failure accrual to the application. not sure whether or not to pursue this, but a sketch might be something like:\n\nreplace the failure accrual module in the stack with a tweaked failure accrual module that adds a local context for you to callback in with the results for the right node instead of using the response classifier to make the decision on a req/rep.\nin application code, pull that context out after your business logic and call successful/failed on it.\n\nyou might also want to remove the success rate stats and do it in application code as well. this is  already doable now for you.. Looks like you found a way to work around the issue.. > We're working on tooling to improve this, so it's in the pipeline.\nIf you're interested, take a look at MethodBuilder. Its a work in progress, but if you look at the withRetry and withTimeout methods you can get a feel for where its going.. > ResponseClassifier only used by StatsFilter and FailureAccrualFactory\nfor now, yes.\n\nthe only built-in retries are RequeueFilter which retries only 'safe' network failures (and this can not be changed). RequeueFilter uses context.Retries to propagate some data over request... I didn't get how it is used though.\n\nRequeues can be removed from your client. Something like \nval client = Http.client\nclient.withStack(client.stack.remove(Retries.Role))\nThe Retries context is used to give the backend additional context as it is sent over the wire for HTTP and Mux. For example, a backend could decide to deprioritize retries if it chose to.\n\nwithRetryBudget/withRetryBackoff is only for RequeueFilter and, therefore, only for retrying safe network failures. Thus in real application will always be two retry filters - one for network-level retries and another for application-level retries, if applicable\n\nIf you put your own RetryFilter on top of the client, you can share this budget. And yes, there will be two RetryFilters.\n\nbalancers ignore individual response errors and make their decisions only on service status set by FailureAccrualFactory\n\nNot only the status set by failure accrual, but you are correct that they directly account for response errors.\n\npossible Thrift/ThriftMux response are:\n-- response payload\n-- exception declared in thrift schema\n-- Failure(Rejected, NonRetryable) - other flags are not propagated. Tests show that Interrupted is not propagated as well which makes me wonder.\n-- TApplicationException for any other server-side exception\n\nThat looks right to me for ThriftMux. I'm not sure about other failure flags and would have to look at the code. I'm not sure if we have anywhere to encode the failure flags for Thrift responses.\n. +@roanta \nSome brief comments on this:\n The benefits need to outweigh the costs. \n We should be able quantify probabilities for various cluster sizes. For example, given 3 retries and a backend of size (5, 10, 20, 100), what are the odds?\n* Internally, we are moving towards using aperture as the default load balancer and as such we are more likely to see the same node selected for retries.. @stevej thanks. I am not an expert in print compilation, but some light web searching shows that \"made not entrant\" and \"made zombie\" are for deoptimization. I would think the method be optimized again later, but I'm not certain.\nI'm not sure how you are thinking to proceed here. We <3 optimizations. Do you have any concrete changes in mind that would help performance?\n. Thanks @simontoens I forwarded it along to folks who should have more knowledge in this area. @ernstae i think so, if you can drive it forward.. lgtm too. thanks for the patch, @koshelev . thanks again,\nhttps://github.com/twitter/finagle/commit/1ea5da7c51625dae461bd5a118bf9ae2b3aebaff. ooops! thanks for the fix.. merged in 48d9e52b18192460ea2d5bd9984f4e574c4938aa\nt/y!. merged in 154b3dc830adaf06a4e0e8bee847db5c6ad31769. this got merged in 477476dcc5dd36a5eebe51a307b5b7f9e67be8c5\nthanks again!. @DanielCharczynski i've been able to reproduce the issue with a Netty 3 client. as you noted, they come from Netty3Transporter.FireChannelClosedLater and netty3.transport.ChannelTransport.fail.\nhowever for a Netty 4 client i an unable to get the ChannelStatsHandler.channelInactive to fire twice. . @DanielCharczynski we've added protection for both Netty3 and Netty4 (https://github.com/twitter/finagle/commit/ed86a005c8f0486cefc23bf3453355fe56384bc0). Let me know if this fixes your problem. Thanks!. Closing this based on the fix plus lack of new reports.. The implementations here have changed quite a bit since this ticket was filed.. cool. cla-bot works. closing this.. @adleong i believe it is intentional. note the scaladoc commentary.\nwhile working on MethodBuilder i had a need for a similar construct but chose to implement RefcountedClosable instead. \nthat said, maybe there's a bug or another issue? a unit test showing a leak might help illuminate.. Thanks @omerzach this is merged in https://github.com/twitter/finagle/commit/8ea728af2857ff2c2149aad4b0d595c27c8c1cf7. @Mura-Mi thanks for the patch/feature! gonna try to find someone who knows finagle-redis better than i to take a look at this. . cc @dschobel . take a look at ResponseClassifierCompilationTest.java.\nif you are a java user, we strive for full compatibility, though we sometimes miss things \u2014 please let us know when we do. the *CompilationTest classes will often help point you in the right direction.. I believe this is now possible.. Thanks again @wpK \nThis got merged in https://github.com/twitter/finagle/commit/fae2e69d81faeef7cf0dee0340cb4ec27d2bcf10. Ooof. So quick things first, neither of which will solve your problem \u2014\n1. Because ClientBuilder is immutable, your call to failFast is ignored since you don't use the result of it. This is not a memory leak, just may be a separate application configuration issue for you.\n2. You should only need to use Request.close if you are doing streaming writes, and from your example, that does not appear to be the case.\nAs for what your memory leak is\u2026 nothing jumps out to me. I think we'll need some more details or clues to proceed. One suggestion is to capture the jmap -histo of the process as it leaks memory. \n. I would not expect to see that many Stack.Nodes. They are part of constructing a Finagle client (and server) and shouldn't number that many...\nMy guess is that you are creating a good number of clients, likely via ClientBuilder.build, and missed calling Service.close (or ServiceFactory.close) on them \u2014 causing the leak.. @lvc thanks for the report.\ncouple of questions:\n\nare these numbers good or bad? do you have a link to some context/color/opinions?\ni see that the tool supports scala but couldn't find details on the support. does it understand scala's visibility modifiers? in other words, we treat code scoped to private[finagle] as non-public API and don't bother with release notes for those sorts of changes.\n. One other thing to note if you want retries, you need to let Finagle know that it is ok. The reason is that Finagle does not know your application level behavior out of the box and cannot know whether or not retrying that request is safe. Good news is that you can tell Finagle about this using ResponseClassifiers. . > What is the reason that retry on this exception is not set by default?\n\nwe can't know what the application behavior is for any particular request. lets say that this request increments a counter in a database table then gets killed. that is not safe to retry. \nwe choose to use safe defaults. \nbut maybe your request is idempotent and is safe. in that case, you can let finagle know.. @adriancole yeah i think there's a good chance. we can try to get it merged in and then it'll go out in the december release.. Thanks for the report @heartsucker. Seems like it's worth updating to Netty 3.10.3 from 3.10.1. \ncc @isabelmartin @jcrossley . cc @mosesn . i think @ryanoneill got busy on some other work. we'll find someone else to take a look. thanks for your patience.. > i think @ryanoneill got busy on some other work. we'll find someone else to take a look. thanks for your patience.\nit me.\nworking on getting this pulled in, apologies for the delay and thanks for your patience.. This got merged in https://github.com/twitter/finagle/commit/86b151bf641534304c9c9102d93e1e8e3ea9348a\nThanks again @mkhq.. @spockz can you explain the motivation for wanting braces?. so, my best guess to why braces aren't allowed, is that we wanted to be conservative in what we accepted. i'm not opposed to changing that restriction, but we'd want @adleong to be amenable to the patch. or perhaps we can come up with a different approach that works for both?. Ah bummer. We should patch scala_school.\nCan you try following the instructions at CONTRIBUTING?. merged in https://github.com/twitter/finagle/commit/2c17f19bf5965926e9fe94eaf790855726564ab0\nthanks for the patch @GEverding . Hi @kaqqao,\nI think you need to change how you implement backoffAt. Check out it's scaladocs for an example of how to break after a certain number of attempts.. glad that worked out!\n\nI'm now missing the point of the SimpleRetryPolicy constructor argument, but that's less important.\n\nit allows the class to be immutable. \nin practice, you should always use the no-args constructor, and the 1-arg one should be private to the class.. Thanks for the patch. This got merged in https://github.com/twitter/finagle/commit/54c6f2728c2ed6e091909b447e362f04ab6fe81e. An update \u2014 we are working on moving to 4.1.28. Don't want to jinx it, but the early tests are looking good.. @samschlegel any more info here? We've never seen this behavior.. Thanks for following up @baybatu that sounds like expected behavior.. @jdreyesp did you find out if another location is also logging this message? I only see it happening from this logger. \nOne possible gotcha is that the classname for objects has a trailing dollar sign \u2014 \"com.twitter.finagle.netty4.channel.ChannelStatsHandler$\".. Yeah, I see. And I think your more general point stands \u2014 we probably should not be logging at warning level for bad user input.. Fwiw, I think we're like some help to fix this as it isn't an issue right now for us. Any chance you'd be interested in starting to work on it? I'm sure we can find you help if you get the ball rolling with a PR.. @zhangandyhui hopefully the examples helped.. Thanks again @spockz this got merged in https://github.com/twitter/finagle/commit/c0efc7759c64d99d14ca9244dab1b4f064f59782. Looks like MySQL is returning the aggregate as a new decimal. It should work if you switch to using Row.bigDecimalOrNull from longOrZero.. @zackangelo thanks. can you add a note about this being a breaking change to Transport.Option in CHANGES? . > does this introduce a compile-time breaking change? the new argument added to Transport.Options has a default value, so I don't think it'll break any existing code.\nunfortunately for Java users it is a break. this is why we add \"telescoping\" methods for this sort of API evolution.. i think being backwards compatible is about as easy as adding a changelog note. so, lets add the extra method.. merged this in https://github.com/twitter/finagle/commit/0316ac8940f056b86e3d5463ba63b6033a539886 \nthanks again @zackangelo . this certainly looks like a bug to me. is there a way that you've tested it?. Nice find.\nLooks to me like LoadBalancerFactory is not using the right constructor for NoBrokersAvailableException. \nThat said, even if we capture the right value at construction time, those values could change after that. \nMy inclination is to evolve NoBrokersAvailableException.getMessage to allow those values to be read from Dtab.base and Dtab.local unless they have been set.\nAre you interested in working on a PR to fix this?. It'd be a bigger API change. A compromise might be to add a new constructor to NoBrokersAvailableException where baseDtab and localDtab are Function1's.\n```\nclass NoBrokersAvailableExeption(\n  val name: String, \n  baseDtabFn: () => Dtab,\n  localDtabFn: () => Dtab\n) extends ...\n// backwards compatibility constructor\n  def this(name: String, baseDtab: Dtab, localDtab: Dtab) =\n    this(name, () => baseDtab, () => localDtab)\ndef this(name: String) =\n    this(name, () => Dtab.base, () => Dtab.local)\ndef baseDtab: Dtab = baseDtabFn()\n  def localDtab: Dtab = localDtabFn()\n...\n. merged in 8e3b1cb4893cce389fd61243215ae382b8a14e05\nthank you @sboobna . Thanks for the report and great repro @dadjeibaah \n@adleong I think the issue is that we are managing state (newBalancer) in 2 places. A few lines above where you pointed and also in partition. I think we want it to only be handled in partition. \nI'll take a crack a fix. . @dadjeibaah yeah its more complicated than i'd thought and hoped.... fixed in 21664df3700257de3165511c2625d232c399322b. This got included in the upgrade to 4.1.31 in 8e0f4b868c34259350fb0def2e7fee5d3d77fece. Thanks again @chrisbenincasa this got merged back in ba578c1445b2e241687ad3c89eec4f3d93431a76 and was included in the 18.12 release.. This approach seems reasonable. I'd like to see some unit tests before going forward.. Ah, yep another instance of this. Just like #757 . \nI think same sort of solution noted there could work here as well.. Ah. I suspect there may be other issues like this as haven't designed for that type of deployment model.\nThis might require a patch to create a flag that allows you to opt-out of this behavior.. Interesting. Would an API for shutting it down suffice? It may need some reworking along with the API.... should we mention what you need to do in order to build off of util as well?\n. ok, lets leave it as is.\n. same.\n. apologies. didn't realize the Source api doesn't expose that.\ni'll try to get this merged in soon.\n. do you mind making this flag's name more specific? \nright now its \"com.twitter.finagle.util.ignoredPaths\" which is a bit opaque for my tastes. perhaps \"com.twitter.finagle.util.loadServiceIgnoredPaths\" ?\n. .onSuccess \ncan you lift this function into a member to avoid an allocation on every filter.apply?\n. i generally prefer leaving the fields, but no big deal.\ncan you explicitly state that this field number cannot be reused?\n. the top of this file states:\n/**\n * Autogenerated by Thrift\n *\n * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING\n */\nyour changes seem fine to me, so i just want to bring this up.\n. i think this should go around line 28\n. nit pull the paren up to the prev line\n. s/ServerDispatherAnnotator/ServerDispatcherAnnotator/\n. s/Dipatcher/Dispatcher/\n. this and handle don't actually override anything. we only use override for overriding implementations, not when its only an interface.\n. same comment re overrides here\n. in order to avoid the closure allocation on every call, we can store it in a member variable.\n```\nprivate[this] val RecordWireSend: Unit => Unit = \n  _ => Trace.record(Annotation.WireSend) \n...\ndispatcher.handle(rep).onSuccess(RecordWireSed)\n``\n. minor style notes:\n- -1 indent for the scaladoc block please.\n- pull the(dispatcher: ServerDispatcher[Req, Rep, Out])` up to the prev line.\n. please add scaladoc for what this is for and that it defaults to on.\n. this is a breaking API change so it should be listed in CHANGES.\n. leave this next version out please. our release tooling automatically bumps the 6.x to the next version when its release time.\n. nit: space before the {\n. mind adding trivial scaladoc to these public objects? can be as simple as:\n/** Matches when the status code is between 100\u2013199. */\n. sorry to nitpick: but our style used for scaladoc is 1 less indent on *s.\n/**\n * ...\n * ...\n */\n. mind linking to the docs since this is a bit opaque. something like:\n@see The [[https://twitter.github.io/finagle/guide/Protocols.html?highlight=Twitter-upgraded#thrift user guide]] for details on Twitter-upgrade Thrift.\n. for backwards compatibility with java users (who don't get the benefits of default arguments) can you add it as forwarding method instead:\n```\ndef apply(protocolFactory: TProtocolFactory) =\n  apply(protocolFactory, true)\ndef apply(protocolFactory: TProtocolFactory, _attemptProtocolUpgrade: Boolean) =\n  ...\n```\nalso, since you are editing, can you add return types?\n. similar deal here. \nadd:\ndef this(protocolFactory: TProtocolFactory) = \n  this(protocolFactory, true)\n. and here too.\n. and here.\n. rename x to enabled.\n. and here.\n. can we mark this private final? good to have good code hygiene even in sample code.\n. same private final here too.\n. s/Finagle/Filter/\n. feel free to ignore, but i prefer not teaching people to log, so can we omit this line?\n. bummer that we don't have a nicer java API for Stopwatch. i'll try to address that for the future.\nthat said, you should capture the Elapsed from calling start(). then call apply() inside the map function below.\n. private final here too please.\n. the default encoding will be the platform if unspecified, so we should use c.t.io.Charsets.UsAscii i believe.\n. nitpick: use private[this]\n. style nit: add a space after yield\n. do you think we should document that these will return the keys in a normalized form (here and below)?\n. hmm i realize why you left it, but i think its a bit deceptive to the end-user. given that they pass in a mutable map, there is likely some expectation that their modifications to the map are reflected in this HeaderMap. but they won't.\nthis is a big enough change in behavior that i think we should at a minimum mark this as deprecated, and strongly consider breaking the API by removing the constructor.\n. yeah, you're right.\n. please either deprecate or remove. as mentioned, i think this API is too weird now.\n. what does this do to dtabs using #s?\n. i saw the test case after i commented.\nseems reasonable to me, but i'll defer to others working more closely on dtabs.\n. please don't reformat \u2014 we follow the standard scala style guide: http://docs.scala-lang.org/style/declarations\n. lets not give a default argument since we do not need to keep backwards compat for package private changes.\n. fyi merge conflict?\n. moving the package is a breaking change. i think its probably worth it, but please note these in the \"Breaking\" section of CHANGES.\n. can you update the comment, as this isn't tied to scribe anymore, right?\n. since you are modifying this file, if you don't mind making the world ever so slightly better, can you annotate this with the return type?\n. ditto re return type annotation\n. ditto re return type annotation\n. ditto re return type annotation\n. ditto re return type annotation\n. ditto re return type annotation\n. ditto re breaking change.\n. and likewise for the other public classes in this file\n. the pants build file also has a dep on util-app and util-core. util-core should def be added here. if this doesn't have a direct util-app dependency, then can you remove from the pants build file? (or vice-versa add it here).\n. thanks for doing all the pants build files! above and beyond what's exepcted! \ud83d\udcaf \n. indeed you did! apologies for the noise.\n. it should, but its not appropriate for this commit.\n. this moved up, you should remove this one.\n. lets leave the indentation as it was for the constructor params\n. ditto re formatting\n. s/set/list/\n. its good to call out that the value must be [0.0 - 1.0]\n. can we minimize visibility?\n. rm override since its abstract in the base class\n. we try to hoist function literals into member variables to avoid allocations at runtime.\nso this would be:\nprivate[this] val onSendFailure: Throwable => Unit = \n  e => errorReceiver.counter(e.getClass.getName).incr()\n. feel free to ignore: is there a decent guess at an initial size? even if its wrong, i suspect it'll be better than 0.\n. feel free to ignore: in finagle-thrift we have Protocols.binaryFactory which has stats and does some optimizations.\n. new Promise[Unit] or Promise[Unit]() please\n. did you consider withHttpStats as a name? cc @vkostyukov (here and below)\n. i know we haven't always done a good job in the past, but i'd like to have public methods and members have type annotations.\nval role: Stack.Role = ...\n. omit \"Register\"?\n. lets leave these hashrockets unaligned\n. omit override.\n. style nitpick: move the ): Iface = { down to the next line, indented to the same as the def.\n. lets do some scaladocs for these new multiplex methods.\n. mind omitting this and forcing these clients to specify a label? its for their own good ;)\n. can you reduce the visibility?\n. style nit, format for multi line class declarations:\nclass MyName(\n    arg1: Type1,\n    ...)\n  extends ... {\n. can you reduce visibility?\n. might be helpful to chain the Throw's exception in the failure case\n. why do we need to support both this and thriftFinagleServiceFunctionMap? (mind leaving a comment in the code as a response?)\n. should probably only catch NonFatal's:\ncase NonFatal(e) => Future.exception(e)\n. ditto re NonFatal\n. for public methods, annotate with the return type\n. explain why would you use this? i'm guessing its when you have a client that is talking to a multiplexed backend service?\n. i guess we aren't consistent. lets leave as is.\n. lets add a sub heading explaining that they come from this Filter.\n. for consistency with the rest of the file:\ns/Metric/A histogram/\n. ditto\n. nit: we omit override for abstract methods\n. lets add a basic unit test that verifies these work as expected. something like a request populates at least one of the stats. same for the server side.\n. @mosesn you got the name wrong and its not OSS-ed \ud83d\ude2d \n. sorry, should've noticed previously, please add that these two histograms are in milliseconds.\n. nit: include the type : TraceId128 for public members. nit: is this a stray whitespace addition?. another nit: space after if. can you include bytes.length in the failure? it can be helpful for debugging. something like:\nThrow(new IllegalArgumentException(\"Expected 32 or 40 bytes, was: \" + bytes.length)). same nit re space after if. same nit with whitespace after if. feel free to ignore, but i think you can tighten it up:\nvar nextLong = rng.nextLong()\nwhile (nextLong == 0L) {\n  nextLong = rng.nextLong()\n}. seems good, especially about avoiding the reverse dns lookup.\ni'll see about getting this merged.. i think the naming pattern in this file would make this method be called \"keyManagerFactory.. perhaps a similar comment here on naming, but i defer to @ryanoneill . lets fill this comment in.. same sentiment here on the name. style nit: please revert lining up of the=>`s (here and below). same here for scaladoc and naming.. how can we answer this?. how hard is this? \ni defer to @ryanoneill . nitpick: the indentation on the else block looks like it needs +2\n. is this a no brokers available exception? can we test for that instead of any Exception? (same in the test below). ",
    "jcrossley": "Hi Eric, I'm just wrapping up a pull request related to this issue. DATETIME types are interpreted as UTC in the TimestampValue extractor. If you'd like to have them treated as another timezone, you could write your own extractor for a RawValue. There isn't currently a way to specify a different timezone.\n. I looked over your pull request, Eric. Perhaps you could add a test to verify the desired behaviour?\n. We've done some further poking of the bijection folks; once that's in I think we'll be able to start 2.12-ification in earnest. @jeffreyolchovy are you still interested?\n. @jeffreyolchovy that's great to hear, thank you! Will let you know once the bijection upgrade lands.\n. LGTM\n. Hey @spockz ! I tried to merge in your request but  ran into a couple small issues. Fixing those up now and will have it in by the end of the day, thanks!\n. All done, @spockz ! This has been merged internally and will go out with the next release :)\n. Thanks @codecov-io ! This has been merged internally and will go out in next month's release.. @chrisbenincasa all of our finagle clients are set up to handle one response per one request, and it seems that for these transaction requests, that one-one mapping no longer holds, hence the mismatched requests/reponse pairs, and the ClassCastException. There currently aren't any plans to fix this behavior, but please feel free to submit a PR!. Hey @chenhj ! I see you're missing a comma after the quill import:\n\"com.twitter\" % \"jsr166e\" % \"1.1.0\",\n  \"io.getquill\" % \"quill-finagle-mysql_2.11\" % \"1.3.0\"\n   \"com.twitter\" %% \"finagle-mysql\" % \"6.45.0\",. Hi Oscar! I recall this issue, and it was fixed in a more recent Finagle. I see you're on 6.30; can you update to the latest, 6.45? https://github.com/twitter/finagle/tree/finagle-6.45.0. @jimschubert thanks! I'm going to pull this in internally and will let you know once it's merged.. @jimschubert This has been merged internally and will go out with the next release. Thank you for the contribution!. ",
    "johnsonma": "Thanks, stevegury.  I was thinking using that way.\n. ",
    "slackhappy": "The only algorithm I've tried so far is a very simple \"choose randomly\" algorithm, and not at scale.  I'll try some more, but I wanted to make sure adding a configurable load balancer to the client builder was going to be a viable approach.\nThe scenario that I am concerned with is this: ~100 clients talking to ~5 hosts which part of a ZookeeperServerSetCluster.\nIn particular, I'm concerned with what happens when there is a relatively high concurrency level of requests on each client (each client is applying load to each host most of the time), and some new host gets dynamically added to the server set.\nMore generally, I thought it would be interesting to try out different algorithms or techniques for passing load information in the case where each client only sees a tiny picture of the host's world.\nI'm interested to hear if you guys have run into (and conquered) this problem at twitter.  I just sent a post about this to finaglers: https://groups.google.com/forum/#!topic/finaglers/35DJTu2Z058\nOutside of my own problem domain, it seems like there has been a bit of interest on the list for a configurable balancer.\n. Following up, I back-ported this pull request into a fork of finagle 6.3.0 (which we are currently using in production), and I implemented a very simple random load balancer using the factory:\nhttps://gist.github.com/slackhappy/6595751\nWe are using this balancer in one case in production, and it seems to perform well.  The overall load between the servers in this case is about as balanced as it was before, and we can slowly roll out a new version of the server without the clients pegging it with requests the moment it is discovered in zookeeper.\nSome details about this particular use:\n-  128 clients\n-  48 servers\n-  ~420 reqs/s total\n-  p50: 150ms p99: 800ms  (over all request types to these servers)\n-  client discovers hosts using ZK ServerSets\nHere is an example of a roll using the the random load  balancer:\nEach line is the number of requests per second to a particular server.\n\nHere is the request distribution at steady state:\n\nWe haven't seen a noticeable difference in the request distribution compared to using the HeapBalancer in this particular client/server configuration.\nFor now, we still use the HeapBalancer when we have a low number of destination servers, because the thundering herd effect is less dramatic compared to the steady state load when the number of destination servers is low.\nHow do you roll in a new version of a service at twitter?  Do you have a similar scenario to this one?  Do you roll quickly? slowly? Do you use a message queue?\n. No noticeable impact on p95 or p99 for us, surprisingly, though the numbers are a bit old at this point, so they have suffered from some loss of precision.\n. My goal is to make sure that the tests are deterministic.  Without adding some predictability to the rng, the test will fail randomly, which can be a frustrating experience.  I could do this another way. Do you have a preference?\n. Thanks for the explanation.  I fixed the comment.  Let me know if you want me to change the rng seeding mechanism to something else.\n. sounds good, updated.\n. ",
    "gsoltis": "I'm currently in the middle of switching a large application to netty 4 and worked around this by switching to only heap buffers, which includes switching netty's empty buffer instance to be on the heap. If I work out all of the other issues that come up, I'll likely go back and see what it would take to re-enable direct buffers, in which case I'd be happy to submit a pull request. Unfortunately, I can't really commit to doing it in any sort of timeframe.\n. Submitted pull request: https://github.com/twitter/finagle/pull/203\n. Just noticed CI build failed on this. Looks like it may not be set up properly? Or is it some error in my patch?\n. Ah, yeah, I think that would be better. I'll update the patch.\n. Hi @trustin, I'm in the process of making these changes, but I had a question. I understand not making the slice in the put() case (the write methods) if we don't have to, it avoids an object allocation. But I'm not sure what you mean about the get() / read methods. \nUnless I'm misunderstanding, in readEncryptedData for example, calling\nbuffer.limit(bioRead);\n dst.put(buffer);\naccomplishes the same as:\nbuffer.limit(bioRead);\nbuffer.get(dst.array(), dst.position(), bioRead);\ndst.position(dst.position() + bioRead);\nwhen dst is a HeapByteBuffer, but the former works for both heap buffers and direct buffers. Is your concern for the overhead of the extra method call? \n. I've updated the patch according to my last comment, I'm happy to update more if need be.\n. Would anyone have any interest in extending build.xml to produce a sources jar? We're doing this internally to make debugging easier, I can add it to the patch if it would be generally useful.\n. Any thoughts on merging this?\n. Awesome, thanks!\nOn Thu, Oct 24, 2013 at 10:17 AM, Ruben Oanta notifications@github.comwrote:\n\nThanks Greg, I pulled this internally should sync with the public repo\nsoon.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/twitter/finagle/pull/203#issuecomment-27011523\n.\n. \n",
    "rlazoti": "@mosesn done! ;)\n. should I fix anything else?\n. is finagle-memcached available? If it's, I can take it.\n. I am also available to help anyone in a pinch! :smiley: \n. @mosesn I can take ostrich project. :wink: \n. Guys, I am working on ostrich repo and I found a completely commented test (https://github.com/twitter/ostrich/blob/master/src/test/scala/com/twitter/ostrich/stats/JsonStatsFetcherSpec.scala). Should I convert it or I could just delete that test?\n. @mosesn sure, I can do that! \nI'm going to finish the specs to scalatest conversion tomorrow.\n. Thanks @p-antoine!\nI'm going to add your updates into my branch. :+1: \nShould I send a PR with 6.20.0 util-eval's version even that it won't compile?\n. @p-antoine yeap! you are right. :) \nI am currently working to replace scala-json with jackson.\n. @p-antoine, you're right. :)\nI think my work on ostrich is done.\nPlease, let me know if there's something more I can do to help you with this issue.\n. I've just added a new line between the if statement and the test case:\nscala\nif (!Option(System.getProperty(\"SKIP_FLAKY\")).isDefined) \n  test(\"add and remove\") {\nBut I'll change this back. :)\n. I didn't remove this line, it's probably a white space change. :smile: \n. You're right. I've just reverted this file back. :innocent: \n. Thanks! :+1: \n. done! :)\n. ",
    "tdyas": "Need advice on how to restrict the Thrift dependencies to just test mode.\n. ",
    "trustin": "Thanks a lot for the pull request, @gsoltis!  It looks good all in all, but we could make it even better.\nI would recomend to check if the buffer has an array:\nif (src.hasArray()) {\n    buffer.put(src.array(), src.position(), len); \n} else {\n    buffer.put((ByteBuffer)src.slice().limit(len));\n}\nAlso, it would be better not creating a new slice in favor of just keeping the old position and limit and reset to them after buffer.put(...):\nif (src.hasArray()) {\n    buffer.put(src.array(), src.position(), len); // same as before\n} else {\n    int pos = src.position();\n    int lim = src.limit();\n    src.limit(len);\n    buffer.put(src);\n    src.position(pos).limit(lim);\n}\nSame applies to the 2nd and 3rd changes that call 'buffer.get(...)'.\n. Looks great to me.  @roanta, care to merge?\n. We did not say we successfully migrated to Netty 4.  Migration is in progress.\n. No worries. Thanks for staying tuned :-)\n. My wild guess is this Christmas. It's a little bit more complicated because Finagle exposes Netty 3 types in its public API. Complex migration path is ahead of us.\n. Yeah, Netty has an asynchronous DNS resolution facility which came from last year's GSoC.  It has not been merged yet because it needs some clean-up.  Will let you know once it's ready to go.\n. I thought it's just matter of replacing most header access calls with headers().*(). Let me know if you need any help on this.\nSent from a mobile device.\nhttps://twitter.com/trustin\nhttps://twitter.com/trustin_ko\nhttps://twitter.com/netty_project\n-----Original Message-----\nFrom: Brian Degenhardt notifications@github.com\nTo: twitter/finagle finagle@noreply.github.com\nSent: \ud1a0, 09 11\uc6d4 2013 7:40 \uc624\uc804\nSubject: Re: [finagle] Update Netty from 3.7.0 to 3.8.0 (#217)\nThere's some trickiness with the backport of http headers from netty 4 that collides with our headers map in finagle.  If you want to take a look at it, we'd appreciate it.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/issues/217#issuecomment-28104054\n. I vaguely guess this might be related with weak/strong host models in Windows:\nhttp://stackoverflow.com/questions/12818970/socket-bind-then-connect-on-ms-loopback-nic\nhttp://technet.microsoft.com/en-us/magazine/2007.09.cableguy.aspx\nCould you run the netsh command in the StackOverflow answer to enable weak host model to see if this is the cause?\n. The problem is that the Redis decoder implementation's decode() method does not discard the unrecoverable data from the buffer when it fails, leaving the window open for this bug.  I would modify the decode() method like the following:\n``` java\nprivate boolean badStream;\nvoid decode(...) {\n    if (badStream) {\n        buf.skipBytes(buf.readableBytes());\n        return;\n    }\n    boolean success = false;\n    try {\n        ... decode ...\n        success = true;\n    } finally {\n        if (!success) {\n            badStream = true;\n        }\n    }\n}\n```\n. It's a bug in Netty 3.8.0.Final.  Fix has been committed: netty/netty@2f93089fe8c1f350819a7e2f34d782af46314aae Let me release 3.8.1.Final today.\n. Wrong project. Sorry!\n. This pull request itself looks good to me.\nHowever, I think it's not a good idea to increase the counters at writeRequested(), because it only tells us when a write operation has been requested, not when the write operation has been actually fulfilled.\nI would recommend overriding SimpleChannelUpstreamHandler.writeComplete() and get the number of written bytes via WriteCompletionEvent.getWrittenAmount().\n. Looks good to me, but probably someone at Twitter will take a look again.\n. It's not a PR to be precise though :-) Will try to send a PR soon. \n. I would do this:\nif (arg.hasArray) {\n  new String(arg.array, arg.arrayOffset, arg.readableBytes, charset)\n} else {\n  arg.toString(charset)\n}\n. Yeah, arg.toString(charset) will always work. However, the first branch should be faster due to less object allocations.\n. ",
    "sslavic": "+1\n. ",
    "sscarduzio": "In Twitter Engineering Blog there's a post from October 2013 by Trustin Lee (Netty project maintainer and Twitter employee) saying that they successfully migrated to Netty4.\nhttps://blog.twitter.com/2013/netty-4-at-twitter-reduced-gc-overhead\nNow, 7 months later,  Finagle is still based on Netty 3.\nI'm not sure if the open source version is lagging behind or Twitter decided to roll back for some reason.\n. Sorry, my bad, the article only said the migration was in progress. In fact a more recent article says Finagle needed (needs?) some refactoring before upgrading to Netty 4. I will definitely stay tuned :+1: \nhttps://blog.twitter.com/2014/netty-at-twitter-with-finagle\n. Brilliant, I just managed to build a basic server. Thank you very much! :+1: \n. +1\n. ",
    "magro": "Is there a rough ETA?\n. Ok, thanks!\n. ",
    "ernieKovak": "Note: there's a DoS vulnerabliity in Netty through version 4.0.19...\nhttp://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-0193\n. ",
    "note": "Any news on this subject?\n. Should not http client be responsible for setting Host header if no such header found in the request? If you decide that not then it is not a problem for me to submit a quick PR for updating docs.\n. I see that it's broader topic, so created a tiny PR with doc update just not to confuse users (I really spend more than hour on this)\n. ",
    "dschobel": "@note no new developments, work is still actively underway internally but we've intentionally taken the longer path of removing netty types from our protocols' public api to make future upgrades easier.\n. @eshelestovich we have implementations of most of our protcols on netty4 but the dependency on netty3 will be there for a little while longer as we clean up internals. There is no public api that depends on netty3 however.\n. @travisbrown I just posted #338 internally\n. merged in https://github.com/twitter/finagle/commit/7ac1d9e1bafdf80f982c25926adb08a2972e6053\n. merged in https://github.com/twitter/finagle/commit/1cc5d1db72c85005d15288da0ffd8b8730a9ffd8\n. @vkostyukov yes, those commits will fix the case that @vicentealencar describes in his 1/19 comment.\nHere's our test-case finagle/http/EndToEndTest.scala.\nIt's now true for all finagle http client dispatchers that every http request which a) has a message body b) is dispatched c) is not a chunked-transfer will have a defined content-length header.\n. merged in https://github.com/twitter/finagle/commit/cce4c90a88e1d95e17749a642fafda109bfb305a\n. @teodimoff the core issue is that \"Request\" / \"Response\" are technical jargon which are practically meaningless in the real world. I like this change since finagle shouldn't require a formal CS background to use and enjoy.\n. this has been merged internally and will show up in the next time the develop branch syncs. thanks for the contribution @bmckown !\n. merged in https://github.com/twitter/finagle/commit/b0673b0aab11eb701a6cb777a41a73e5f61a8175\n. merged in https://github.com/twitter/finagle/commit/392e3ed01d0c7e78cd5de8a999861e68e0b045c3. thanks @tonyd3 \n. merged in https://github.com/twitter/finagle/commit/27aa087dc93dc635265905a09debbdc39ff2076f. thanks for the contribution @tonyd3.\n. this is looking good, can you add a note to the runtime behavior changes section of CHANGES covering the new default timeout?\n. I think if we had no existing clients it would be the right thing to do but expanding the scope of Transporter.ConnectTimeout to cover those additional twelve packet transmissions of ssl handshake would likely break clients applying tight timeouts tuned against the existing narrower scope. I think it\u2019s better to keep this as an expert knob that maps directly to the netty param, as written.\n. merged in https://github.com/twitter/finagle/commit/24d6e3e307c814410278ceca20c6ff5f7caeb161 thanks @spockz \n. @spockz were you using finagle's sbt wrapper to run your tests?\nI think hard-coding 127.0.0.1 is fine because it is easily greppable but I'm curious how users are running into cases where preferIPv4Stack isn't defined.\n. LGTM, I think this should still come in if it makes people's lives easier since the cost to maintain is a grep run.\n. @luciferous still lgtm\n. LGTM\n. Having our client add the header sounds like a good change since the RFC is unambiguous about the presence of this header, even with an empty value.\nIt\u2019s hard to imagine a user not wanting the Host header to be set other than testing malformed requests in which case they can explicitly unset it.\n. If the resolver inserts the host value in the Metadata map of the Addrs it emits and we install a http filter that sets the header, that would at least solve the case where we create a new service instance with a fully qualified url, no?\n. @mosesn Is dispatching a known bad request in the hopes of a fully qualified request uri and a permissive http server going to be less surprising to users than trying to fix the request? I think the user is rolling the dice in either case and with the latter you at least have a valid request object. Maybe the right answer is to fail bad requests before dispatching (which is what finatra does).\n. @luciferous maybe that's why all the api frameworks on top of finagle build their own request builder libs? it might be a sign  :)\n. okay, I buy that it shouldn't be part of the protocol impl.\n. closing since the doc fix has merged. thanks @note.\n. LGTM, thanks @note!\n. merged in https://github.com/twitter/finagle/commit/e058eeec0c194aab0fbf701da984c7942793750d\n. routed to #traffic, stand by\n. yep, that's the fix, it's up for review internally now so no need for a PR\n. pulling in, thanks for the docs!\n. I'd like it better if we included @olix0r's description of residual paths but I think the posted version is still an improvement for experts/people who know the jargon so I'm happy to have it land.\n. lgtm modulo typo\n. Consensus seems to be that no one feels strongly that this belongs in Service, if no one objects I'll close this.\n. @VELVETDETH we're in the middle of publishing the 6.26 artifacts but there is a lag between the docsite being updated and the binaries being released so sorry for the confusion.\nIn the mean time you can still use 6.25.0 of the finagle-* packages and all of the quickstart docs should still run.\n. @VELVETDETH let's keep it open until the binaries are released since it's a legitimate issue. I'll take a look at the release process to see if we can hold docsite publication until after the binaries are available going forward.\n. 6.26.0 has been published and the example works again.\n. :ship:\n. @svetlyak40wt unfortunately we're not set up to merge PRs directly via github, they have to go through twitter's internal repo which gets synced out every Monday.\ndetails: https://github.com/twitter/finagle/blob/develop/CONTRIBUTING.md \n. @svetlyak40wt if it gets merged internally this week it'll show up in the develop branch on Monday so the only variable is the bandwidth of the team to pull it in (but we're usually good about clearing out all PRs that have passed review every week).\n. LGTM and +1 for adding test coverage.\n. lgtm after style fix\n. just style nits, LGTM, merges cleanly and integration tests pass\n. @olix0r do you still want this? if so, @tw-ngreen can you give it a review? I think you've probably got the most relevant experience from our side.\n. posted internally, thanks for your patience @olix0r \n. @lfcj are you still interested in working on the open issues in this PR?\n. closing this until we hear back.\n. we can address docs in a separate PR.\n. rename is finished, closing.\n. merged in 96e91a9b629edb408052cdfa5323ae6507e2a257. thanks @olix0r.\n. lgtm, I'll bring it in if we can get one more owner to review /cc @roanta @bmdhacks @mosesn \n. this has been merged internally and will sync out to the develop branch on Monday, thanks for the contribution @adriancole!\n. LGTM, very nice!\n. lgtm\n. thanks for the patch, it just merged internally, expect it in develop on Monday.\n. lgtm.\n. merged in 5dbcbd1b614de1b57c589404fef4e5d14cbfa4a8 \nthanks @amartinsn \n. @Saisi this has been merged internally and will sync to github on Monday. thanks for the contribution!\n. this was merged internally and will sync to github on Monday. thanks for the contribution @daviddenton \n. The non-stack http codec mixes DelayedServiceFactory in at the top and bottom of the client stack to suppress closes on the service until the reader is finished or failed which does the trick of keeping the caching pool from putting a streaming session in the cache.\nShould just be a matter of doing the same in the stack http client I think. \n@olix0r / @siggy  do you want to take a stab at it?\nIn the meantime, I tried the repro and confirmed that client builder doesn't have the issue if you need a workaround.\n. yeah you can't close the singleton session because it's managed automatically by FtS so I don't think we're losing anything by adding DelayedReleaseService to the http client stack and tying the session lifecycle to the response stream.\n. merged in 1ff06d07e1e53589d828a96238adb6d5fc4db562. thanks @olix0r \n. thanks @adleong, @cacoco fixed the nits locally on liam's version and is currently bringing it in\n. lgtm, thanks for the new lb!\n. lgtm after vladimir's DelayedRelease visibility suggestion. \nthanks @olix0r / @siggy, that was a bad broken window.\n. this landed in d928ba5f01175e1ab8e1eebbaa5d461252a6f2c4. thanks @olix0r / @siggy \n. @olix0r thanks for taking a stab at this, I'm happy to land this as-is, we can have someone on our side look into the OOM for thriftmux's end to end test and the FailFastFactoryTest flakiness. I'll try to get some more eyes on this and pull it in.\nedit: mind dropping the thriftmux + finagle-core flaky tagging? we'll look into why those only seem to flake on travis and not twtr ci on our side.\n. thanks @olix0r. merged the build cache + timeouts + split up tests. \nI could repro the OOMs at a rate of 1 in 500 on pants so we'll keep an eye on that but this should get the build green-ish, bordering on a chartreuse.\n. I'll fix up the attribution, sorry about that @olix0r \n. landed again in 7f06de3c17a50e550a99cc78e994ee3be4615f23\n. thanks, lgtm\n. merged in 3a80b7138b005702c5227214764927a846757a26. thanks\n. lgtm\n. thanks @lukiano, can you add a unit test for the casting bug and updating the git commit to follow https://github.com/twitter/finagle/blob/develop/CONTRIBUTING.md ?\nTaking a step back from the question of the reference leak this patches for pipelines that let undecoded buffers through, I don't think letting netty bytebufs leak into the finagle layer of transports and dispatchers is something we should encourage so I'd rather install a terminal bytebuf 2 com.twitter.util.Buf handler and then ask protocol implementors who want to use bytebufs and the netty convenience classes to build their protocols in a channel handler. \nThat lets us sequester the netty types to the pipeline and nudges people towards using buf and gaining the benefit of not being tied to a specific version of netty.\n. > About your second paragraph, this isn't just ByteBuf, but actual Netty messages (HttpContent and inheritance) which also extends ByteBufHolder, which itself extends ReferenceCounted, so we can call retain()\n\nRelated, eventually this will need to be improved to support pooled ByteBufs\n\n@lukiano thinking about it a bit more, since this never releases buffers it's not usable with the pooled allocator unless the protocol implementation copies every buffer, in which case, why use the pooled allocator?\nIt seems like it would be safer and less confusing to let netty's leak detectors blow up early if someone tries to use the pooled allocator rather than force that constraint on protocol implementors.\nAs @mosesn says,  there are options for making pooled work without copying but that will be a bigger effort.\n. @lukiano ~~okay I was missing that unpooled buffers can be freed and disabling the leak detection code doesn't stop it from being a runtime exception to access its contents.~~\n~~I wrote two tests for the listener and the transporter with no protocol implementation and the listener's buffers hit finagle space with refCnt == 1 which seems correct.~~\n~~There is a bug on the transporter side~~  edit: The bug is in ChannelTransport's SimpleChannelHandler instance which auto-releases its buffers and will cause a runtime failure if the protocol implementation doesn't explicitly retain them.\nTurning off auto-release in the ChannelTransport emits buffers with refCnt == 1 for both the listener and the handler so that's our fix.\nLet me know if you want to fix it up or whittle this review down to just the shutdown fix.\n. thanks @lukiano, I'm merging it internally. it will sync out to the develop branch on Monday/Tuesday.\n. merged in 2f1786b4658c60a0f22dafc83b0cdfcccba5619d. thanks @lukiano\n. looking at AbstractChannel they guard firing channelInactive with wasActive && !isActive()) so the netty contract seems to be the sane one that a channel needs to become active before it can become inactive.\nI would start by confirming that nothing else in the client pipeline is swallowing the channelActive message.\nwe should have all handlers in the default pipeline covered in com.twitter.finagle.netty4.channel.HandlerEventTest which tests that they're not swallowing messages but it's possible we missed one.\n. oh I think I know what this is... we had a change a few weeks ago so that the transport promise is satisfied outside the pipeline which means that you can see writes before channel active fires. handlers that assume writes come after channel active and rely on the latter to init state will do what you're seeing. \nWe moved the init logic in all of ours handlers to handlerAdded but looks like we missed one...\n@olix0r can you move  the NPE'ing state's init code  (just ctx.attr(ConnectionStatsKey).set(ChannelStats(new AtomicLong(0), new AtomicLong(0))) I think) into handlerAdded and see if that doesn't fix it?\n. can you add a test case or update the existing ones so that writes happen before channelActive?\n. lgtm otherwise\n. we turn off leak detection because we leak every inbound buffer into application code and let the GC handle it so the leak isn't a surprise, but the detector shouldn't be jibber jabbering either.\nhttps://github.com/twitter/finagle/blob/develop/finagle-netty4/src/main/scala/com/twitter/finagle/netty4/package.scala#L40\ncan you post your client/server config to reproduce?\nhere are tests covering our ref-count assumptions: https://github.com/twitter/finagle/commit/3cd9acb69a518524eb8d6d6f6a7fe2d55aaa8f98\n. @olix0r are you still seeing this?\n. can you paste the full client config?\n. yeah that assert is wrong, the logic is there to sanity check against fixed length messages falling into the transport collating case but only accounts for chunked transfer encoding and misses non-identity content encodings.\nI'll fix it up. Thanks for the report.\n. fix landed internally and will sync out on Monday.\n. fwiw I load tested finagle http on n3 vs n4 in a http benchmark and both versions started refusing connections at the highest levels of concurrency\n. thanks for the patch, one question about traces lower in the stack, otherwise just nits.\n. We still need to guard the traceRpc call with isActivelyTracing so I think\na comment on the previous version is fine.\nOn Wed, Jun 22, 2016 at 1:03 PM, Kristof Adriaenssens \nnotifications@github.com wrote:\n\n@dschobel https://github.com/dschobel I updated the code to submit the\nrpc name (command name) before dispatching the request.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/pull/516#issuecomment-227860137, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe/AADkATbGYTscu24bO2JoT_s0D50WxXV5ks5qOZUQgaJpZM4I0Dkv\n.\n. @kristofa ah good point, I didn't see the isTracing guard in record. anyway, I'm happy with this as-is. thanks again for the patch. \n\nlgtm\n. @kristofa it's been posted internally for review so I expect it'll merge and get synced out on Monday.\n. lgtm. I think this is the clearest fix for the subtle rat's nest that we built from deferring close and trying to sequence these side effects.\n. I think it's worth running these traces past our jvm team for a professional opinion. It shouldn't take long for them to verify whether it's worth digging into more deeply.. thanks Steve, I'll file a ticket and report back.\nOn Mar 1, 2017 12:21, \"Steve Jenson\" notifications@github.com wrote:\n\nI went ahead and put the whole -XX:+PrintCompilation log into a secret\ngist.\nhttps://gist.github.com/stevej/569e917fddef919b6ae29369f00e92ec\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/588#issuecomment-283441359,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AADkAfTiCseiVpVq5bnPI0DCrH2POxFbks5rhcU6gaJpZM4MO8J_\n.\n. thanks @christhalinger, calling this one done. thanks for the scrutiny @stevej. we're happy to have you!. thanks for the pr @plaflamme, lgtm big picture. I'm curious what your use case is if you don't mind saying.. @plaflamme looks like it was a flaky run. I'm merging the pr internally and I'll report back if it reappears.. merged in affced891e62428e156f31e2c14dd32121404582, thanks again for the pr @plaflamme . @crispywalrus sorry about that, this should be fixed now. https://github.com/twitter/finagle/commit/5f34657bff3e6a8ab9bf2f4f48b8cca734a039c6 moved finagle-netty4 to 4.1.28.\n\nfinagle-netty3 remains vulnerable to the CVE but I think it'll be a race between our killing it off entirely and that version getting bumped again.. There's an example of configuring client-side SPNEGO in finagle's test suite\n\nPlease let me know if that doesn't answer your question.\n. @Alterrien agreed it could use more / better docs. I think we have an internal ticket for more docs already but if not I'll file one. Thanks for the feedback.. I know you didn't add it but the 'case' keyword isn't needed so do you mind cleaning it up while you're here?\n. can you please reformat per http://docs.scala-lang.org/style/indentation.html so that the line doesn't exceed ~100 chars?\nalso, can you use named params to give that boolean literal some context?\n. not necessary but if you're feeling ambitious... you could write a test case covering the symptom you describe in https://github.com/twitter/finagle/issues/345, specifically, a hung ssl handshake causing the channel to get stuck in the connecting state and showing how this new timeout closes the channel.\n. *during\n. s/are^2/are/\n. no postfix ops please\n. pretty sure it's spelled Buoy\u00e1nt\n. sort please\n. : Unit =\n. can you break this method up w/ one param per line as in:\ndef lotsOfArgs(\n  number: Option[String],\n  typeOfPhone: String\n  hoursOfAvailability: Range = 9.to(12)\n)\n. we can just pass the block to foreach without the parens\n. no parens for map\n. This filter still allocates on each request. Can you pull the onSuccess closure into a val outside the apply?\n. so unfortunately this doesn't do the trick because the method will be eta-expanded into a function value on each request and that costs an allocation. anything but a function value burns us. I'll fix it up locally if that's cool with you.\n. please add a short timeout to this await to pre-empt indefinitely blocking tests.\n. bikeshed: AttemptTTwitterUpgrade is more informative imo\n. this is sufficient I think but if you're feeling motivated, the upgrade request will show up in tracing as well so we could verify that disabling upgrades yields 1 fewer request trace.\n. private[this] for currentNode please\n. why expend this much effort as opposed to a single scan over the nodes and getting to the rebuild sooner?\n. this is up for review internally so I'll fix it there.\n. can you reproduce channelInactive firing when channelActive didn't?\n. doesn't sequencing this request dispatch before the rpc trace below leave the trace out of order with regards to any tracing lower in the stack?\n. no infix notation please.\n. ditto, no infix\n. pulling this trace call into a function literal shaves an allocation on the request path\n. Step #3 represents the rest of the client stack and we have no guarantees\nthat there's no tracing happening there so ideally we'd do the request\nlevel tracing before dispatching the request through the rest of the stack.\nI'm okay with leaving it as-is but can you leave a comment that this\nimplementation assumes no further tracing lower in the stack?\nOn Fri, Jun 17, 2016 at 1:04 AM, Kristof Adriaenssens \nnotifications@github.com wrote:\n\nIn finagle-memcached/src/main/scala/com/twitter/finagle/Memcached.scala\nhttps://github.com/twitter/finagle/pull/516#discussion_r67473223:\n\n}\n}\n-  class Filter(tracer: Tracer) extends SimpleFilter[Command, Response] {\n-    def apply(command: Command, service: Service[Command, Response]): Future[Response] =\n-      Trace.letTracerAndNextId(tracer) {\n-        val response = service(command)\n-  object TracingFilter extends SimpleFilter[Command, Response] {\n-    def apply(command: Command, service: Service[Command, Response]) = {\n-      val response = service(command)\n\nI think we are fine with these changes.\nThe order in which tracing events happen for memcached with this commit in\nplace:\n1. Initialize span (TraceInitializerFilter part of StackClient)\n2. Add Client Send annotation (AnnotatingTracingFilter set-up in\n   MemcachedTracingFilter.Module)\n3. Execute memcached request\n4. Add cache hit/miss annotations based on memcached response\n   (MemcachedTracingFilter)\n5. Add Client Received annotation (AnnotatingTracingFilter set-up in\n   MemcachedTracingFilter.Module)\nWe can only add the cache hit/miss annotations once we got the response.\nThe important change is that the memcached annotations are submitted in\nbetween the cs / cr annotations. The Client Received annotation should be\nthe last annotation that gets submitted because it indicates the span is\ncomplete and ready to send off to back-end.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/pull/516/files/67af7342d082c4408f125b8d15cf68a394506b2a#r67473223,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AADkAZf67j9RBSfbjaWWpioBOLc6H9-Dks5qMlUDgaJpZM4I0Dkv\n.\n. Sorry I should have been more specific, the hit/miss annotations are fine, the issue is sequencing Trace.recordRpc(command.name) in line 47 after potential tracing lower in the stack. It seems like we'd want the cache command name to be traced before the remainder for the stack which is dispatching the command.\n. please add some docs. please add some docs. I wonder if we shouldn't just mark dispatch as final and leave pipeline as the extension point since sequencing responses is fundamental to pipelining. wdyt?. final ? we can always open it up later if the need arises. ditto, final?. log can stay private I believe. I think this one can be private as well. docs please. rm space please. ditto, no space. even though finagle-netty3 isn't going to be around much longer, we should mention that this option is netty4 specific. does SO_REUSEPORT make sense on the client side?\n\nthe ci logs (https://travis-ci.org/twitter/finagle/jobs/416903070) show a lot of instances of\nWARNING: Unknown channel option 'io.netty.channel.unix.UnixChannelOption#SO_REUSEPORT' for channel '[id: 0xae222ddf]' and I'm wondering whether it's because we're using it on the client side or whether we need to guard the setting so that we don't spam people's logs\n. both sound like the right call to me.. ",
    "futurely": "That's how Google's gRPC avoids exposing netty in the public API.\n. ",
    "daqulazhang": "I'm wonderring is this netty4 integration work done?\n. ",
    "eshelestovich": "Any updates on this, folks ? As far as I can see, latest finagle-core_2.11:6.39.0 still depends on netty-3.10.1.Final.\n. ",
    "mgargenta": "http://99designs.com/logo-design/contests/logo-finagle-254061/entries/64 is easier to read. The \"F\" in the other one is not obvious, in my mind.\n. ",
    "antonlindstrom": "Are there any recent plans on upgrading the libthrift dependency?\nThanks!\n. ",
    "itszero": "Looks like libthrift-0.5.0 disappeared on maven.org. Could we bump up the priority a little bit?\n. ",
    "nshkrob": "Upgrading to a recent libthrift version would involve some work for us internally, so it's not a priority at the moment.\nIn the meantime, you can use the http://maven.twttr.com to get libthrift-0.5.0: \nhttp://maven.twttr.com/org/apache/thrift/libthrift/0.5.0/\n. This is useful, but you should also include the service name into the service field, e.g. service = \"mysql.\" + serviceName.\nYou'll have to pass serviceName into MysqlTracing, like what finagle/http/Codec and finagle/thrift/ThriftClientFramedCodec do.\n@sprsquish, what do you think? We are a bit inconsistent in how we set it in e.g. MemcachedTracingFilter.\n. Looks good to me.\nIn most cases, there is just one mysql database in the system, so this will be good enough.\n. I'm going to wait for a green build, but shouldn't you also replace Response with Answer?\n. LGTM, I've pulled this internally. Should show up here in a few days. Thanks!\n. Sure, let me look into that.\n. @jamescway Done. Let me know if that doesn't work for you.\n. I've pulled this internally. It should show up here within a week. Thanks for the patch!\n. Makes sense. Can you add a simple unit test, e.g. by setting the Stats param and checking for stats?\n. It would be definitely useful as a reference and as a test for this, thanks! @mosesn we can pull the test separately I think.\n. I don't think this belongs in a README. This is already explained in the comment below. Remove this file altogether?\n(A README file should give an idea of what this code is doing and how it should be used)\n. ",
    "MayiTiny": "I found that it have a conflict between libthrift0.8.0(in storm) and libthrift0.5.0(in finagle). But I must use both storm and finagle for some reason.I see there is still no schedule to upgrade or remove thrift dependency.\nSo I upgrade thrift dependency to 0.8 and change the thrift file which generated by scrooge manually.\nIt works well at present. \nI hope it can work continuous...\n. ",
    "taylorleese": "Upgrading libthrift is on the long-term radar. There are some logistics that need to be sorted out first.\n. @dschobel Not to be confused with :ship: :it: or :sheep: :it:.\n. @3thinkthendoit Closing this since it's already been asked on the google group. https://groups.google.com/forum/#!topic/finaglers/SaYvZI8nFZ8\n. :sheep: :it: \n. @hoondori If you have any additional questions please use the Finaglers group. https://groups.google.com/forum/#!forum/finaglers\n. @kevinoliver We should probably make this same change in twitter server, scrooge, and finatra as well to keep things consistent.\n. @penland365 Please update the description to follow the suggested format.\n. @dy8000 Any chance you are missing a dependency on finagle-thrift? It looks like DeserializeCtx isn't on your classpath.\n. @dy8000 DeserializeCtx isn't included in 6.31, but it is in the latest 6.33. Try using the latest 6.33 for your various finagle dependencies, 6.32 for util, and 4.5 for Scrooge. See our recent blog post here.\n. Can we resolve this based on #478 or is there something else I'm missing here?\n. @tindzk Also, take a look at Finatra or Finch since you're moving from akka-http. They are both built on top of Finagle and Twitter Server.\n. Related:\n- https://github.com/twitter/util/issues/162\n- https://github.com/twitter/scrooge/issues/236\n. We're going to want the SSL changes as well (https://github.com/netty/netty/pull/5439 and https://github.com/netty/netty/pull/5380). /cc @ryanoneill \n. What (if anything) needs to be done for this to also work with ThriftMux?\n. This isn't published yet, but please see https://github.com/finagle/finagle.github.io/pull/24. Also, see the notes in https://github.com/twitter/finagle/releases/tag/version-6.40.0.. This should probably be sealed as well.\n. Probably should add sealed here as well.\n. This is going to use the platform's default charset when constructing the string. I'm not sure if this is an actual problem in this scenario or not, but it would likely be best to make it explicit (e.g. UTF-8).\n. code\nclient.reset().ensure(singleton.close())\n. Supports => Support\n. Let's add an explicit return type here.\n. Use .flatMap and add a return type to the method please.\n. Add return type.\n. Add return type.\n. Add return type.\n. Add return type.\n. Add return types here and below.\n. Do we really need this to be curried?\n. On the off chance somebody passes in a null Status it would be nice if this were Option(status) here rather than Some(status). Same comment applies to line 45.\n. I had commented that it should be Option(status) in case it was null by some chance. That's what I usually do stylistically out of paranoia, but not a huge deal either way.\n. This should match line 77 to be consistent. I prefer Option, but I may be the only one so consistency is more important.\n. Any reason not to use container based builds for Finatra, T-S, Scrooge, and util as well?\n. @kevinoliver @mosesn Should we move this to the stack equivalent?\n. FFTI, but could add a return type here.\n. FFTI but could add a return type.\n. I have the same question as @mosesn. What's the verdict here?\n. ",
    "drozzy": "With all due respect, how is this not a priority? The dependency has disappeared off the maven altogether (try that - gives you an error):\nhttp://mvnrepository.com/artifact/org.apache.thrift/libthrift/0.5.0\nI am trying to install scrooge-core 4.2.0 and finagle-thrift_2.11\" % 6.30.0 but this is really making the whole thing impossible.\n. @mosesn Thanks, I think I'll use the jar after all. Seems like a hack though :-)\n@eirslett Forgive me, but I don't think I know what you mean... I'm going to use the scrooge sbt plugin.\n. @eirslett But scrooge-sbt-plugin requires Scala 2.10, while scrooge-core is available for Scala 2.11... :( This is like solving a detective mystery :-)\nP.S.: Do you know how I can find version \"3.18.1\" of scrooge-sbt-plugin in the https://oss.sonatype.org/content/groups/public/\nI'm thinking of modifying the scala dependency....\nP.S.S: I think I'll post this on scrooge issues board... https://github.com/twitter/scrooge/issues/212\n. @eirslett So here is a stupid question... where would I copy it? Into project/ScroogeSBT.scala?\n. ",
    "agleyzer": "I've looked at ZkResolver to see how to implement a similar DnsResolver, but it uses a Group internally and there's a comment about taking that out as well (I understand Groups are deprecated too). I wonder if my best strategy is to wait until the dust settles and then take another look? Or am I barking up the wrong tree?\n. Thanks for your response, but I am still a bit confused where my DNS stuff would fit in this brave new world... On one hand, it could be used as a poor man's ZK, with multiple machines resolving the same hostname, so that's why I looked at the ZkResolver, but then we can also have a Name implementation, something like this: https://gist.github.com/agleyzer/7363353. What would you guys prefer? \n. @mosesn sorry I just noticed your question. I might have some bandwidth next week.\n@jdanbrown I ended up writing a subclass for Name with periodic changes: https://gist.github.com/agleyzer/7363353, it's been in use for a while, no complains so far.\n. @mosesn @jdanbrown you are welcome to use that code, I am glad to be of any help\n. I might have some free time later in July but have no problem if someone\ngets there sooner.\nOn Wed, Jun 11, 2014 at 10:30 AM, Moses Nakamura notifications@github.com\nwrote:\n\nSure, if you want to take it on, we'd be glad to take your PR. None of us\nat twitter has the bandwidth to do it, so it will have to be community\ndriven.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/207#issuecomment-45748854.\n. \n",
    "jixu": "@mosesn , we are using the DNS Resolver written by @agleyzer in our product, and it works well. Can I know what is the progress to support automatically DNS resolving in finagle? I can help on issue if @agleyzer doesn't have time.\n. @mosesn I have created a pull request for this issue:\nhttps://github.com/twitter/finagle/pull/282\nPlease help to review when you have time.\n. Hi bmdhacks. Will you help to merge it?\n. Cool. Thanks Brian and Moses.\n. Sure, I will\n. @mosesn I've added a new commit and fixed the issues you and @mariusaeriksen commented.\nQuestions:\n1. Any conclusion about how to set the ttl? Using a default of 10 seconds or cache forever?\n2. I've added a test to test naive case of InetResolver. Any clue how I can test the changing addresses behind a host?\n. @mosesn I updated again. Please take a look.\n. @mosesn @mariusaeriksen  updated:)\n. @mosesn @roanta @mariusaeriksen\n I removed \":*\" syntax check and used Updater to update dns-resolution now.\n. @mosesn @mariusaeriksen Any idea about this updated PR?\n. @mariusaeriksen I got your point that async resolving returns immediately and Updater won't queue anything in that scenario. I updated the code to put Updater inside futurePool, and please help to check if this PR looks ok now. Thanks.\n. @mariusaeriksen I understand the way of \"resolve->sleep->resolve->...\" you proposed. But considering resolution may take long time sometimes, I think this way doesn't follow the TTL setup exactly. So I would like to use Updater instead of this way to do periodically background DNS resolution. Tell me if my idea is not correct.\n. @mosesn @mariusaeriksen Will this be merged?\n. Sure, thanks.\n. No problem~\n. Are we going to support https for fetchURL API?\n. @mosesn I would like to take a look and will give an update later:)\n. @mosesn It seems the package cannot be generated due to some dependency issue now. \nIt should be caused by \"com.twitter#ostrich_2.10;9.6.1\" cannot be found in mvn repository:\n  error sbt.ResolveException: unresolved dependency: com.twitter#ostrich_2.10;9.6.1: not found\nCan you help to fix it?\nNow I cannot do \"sbt package\" locally.\n. Thanks for the review. I think I can change the code to align all the comments by tomorrow. \nBut for this comment, I am not very sure about the problem(memory leak and timer task leak). Can you help to explain more on this? Any example code in existing code base will definitely help me.\nThanks.\n. Ok, I got your point. So what is the proper way to get notified when observation is closed?\nI looked at the code here:https://github.com/twitter/util/blob/master/util-core/src/main/scala/com/twitter/util/Var.scala#L414-L418,\nbut I didn't get the point how I can register timerTask.close().\n. Thank you @roanta .\nI've tested using Var.async and it works fine now.\n. From my testing, it seems the \"assert\" is executed and means there is a change.\nLooking at the code here: https://github.com/twitter/util/blob/master/util-core/src/main/scala/com/twitter/util/Var.scala#L214,\nthe value will always be published each time the event is observed.\nIf I understand something wrong, please point out.\n. This is I came up to align the behavior of \"InetSocketAddressUtil.parseHosts\". I also don't know the scienario of this case.\n. Ok, I will remove this line from here.\n. @mariusaeriksen Do you mean we should use com.twitter.finagle.util.Updater to prevent duplicated DNS resolution on one host?\nAny examples I can refer to create the Updater?\n. Agree that we have 1 second as minimum implicitly.\n. From the doc: http://docs.oracle.com/javase/7/docs/api/java/security/AccessController.html#doPrivileged(java.security.PrivilegedAction)\nAccessController.doPrivileged may only throws NullPointerException\n@sirmax Do you have any experience that AccessControlException is thrown?\n. ok, I think I got the same page which described the possibility of throwing out \"AccessControlException\" and I agree that it should be caught.\nAnyway, I will catch any exception from that \"Try\" and turn off DNS cache refresh if exception is thrown.\n. ",
    "pwigle": "Of course there should be a test, sorry about that. I verified that the test did fail without my patch. \nThe test depends on this file, which is used to test the Announcer. I don't see a big problem with that, unless the tests for Announcer is removed.\n. ",
    "anttipoi": "I'm sorry, I've long since moved to other projects. \nWe ended up giving up on finagle (not just for this reason).\n. ",
    "chamblin": "Awesome, thanks\n. ",
    "ngocdaothanh": "Hey, I didn't know about 6.7.4!!!\nhttps://github.com/twitter/finagle/blob/master/CHANGES\nI will change and resend pull request.\n. Thanks.\nI intend to do the update and send pull request, but since you are already doing that, it's better you finish it.\n. Yes. I'm developing Xitrum (https://github.com/ngocdaothanh/xitrum), which is based on Netty too. I'm seeing warnings like below when updating Xitrum:\n[warn] /Users/ngoc/src/xitrum/src/main/scala/xitrum/I18n.scala:18: method getHeader in trait HttpMessage is deprecated: see corresponding Javadoc for more information.\n[warn]     val header = request.getHeader(Names.ACCEPT_LANGUAGE)\n[warn]                          ^\n[warn] /Users/ngoc/src/xitrum/src/main/scala/xitrum/action/Net.scala:54: method getHeader in trait HttpMessage is deprecated: see corresponding Javadoc for more information.\n[warn]       val xForwardedFor = request.getHeader(\"X-Forwarded-For\")\n[warn]                                   ^\n[warn] /Users/ngoc/src/xitrum/src/main/scala/xitrum/action/Net.scala:89: method getHeader in trait HttpMessage is deprecated: see corresponding Javadoc for more information.\n[warn]         val xForwardedProto = request.getHeader(\"X-Forwarded-Proto\")\nhttp://netty.io/3.8/api/org/jboss/netty/handler/codec/http/HttpMessage.html#getHeader(java.lang.String)\n. Please see this pull request (there's also commit about README):\nhttps://github.com/twitter/finagle/pull/214\n. Does Twitter plan to update Netty from 3.x to 4.x soon? About when?\n. ",
    "jeffreyolchovy": "This routine was updated four months ago to also allow param parsing during PUT operations (https://github.com/twitter/finagle/commit/0e81b6781c23b73dca627e546c8e1ce35adcd6ee), however, it may be useful to allow parsing and retrieval of params during any arbitrary HTTP method unless that method is explicitly forbidden from containing an entity-body by the HTTP spec. I believe TRACE is the only method that explicitly forbids an entity-body [1, 2]; but parsing the params on, say, a GET request, is, in my opinion, questionable. However, I'd leave it up to the library user to decide whether on not they want their server to access the entity-body regardless of the type of request.\n[1] http://www.w3.org/Protocols/rfc2616/rfc2616-sec9.html#sec9.8\n[2] An interesting discussion regarding whether or not the DELETE method should contain an entity-body http://stackoverflow.com/a/299696\n. @mosesn let me know if you still want any outside help with this. when i locally hacked around with ostrich to complete my dependencies to attempt a trial 2.12 upgrade for finagle there didn't seem to be many necessary finagle source changes.\noff the top of my head, iirc, most things centered around dependencies:\n- upgrade jackson version to one that supports 2.12 (i.e. for jackson scala module)\n- twitter bijection needs to support 2.12 for finagle-memcached\nhowever, the main issue that i noted was compilation of 2.12 barks with an ambiguous reference to overloaded definition for the compose operators on Filter:\n[error] both method andThen in class Filter of type (f: Req => com.twitter.util.Future[Rep])Req => com.twitter.util.Future[Rep]\n[error] and  method andThen in class Filter of type (service: com.twitter.finagle.Service[Req,Rep])com.twitter.finagle.Service[Req,Rep]\n[error] match argument types (com.twitter.finagle.Service[Req,Rep]) and expected result type com.twitter.finagle.Service[Req,Rep]\n[error]         service => filters.andThen(service)\nhopefully, resolving this one will not need an API change, but I think decisions like this are best left to you guys :)\nanyway, this was back at the end of May, so maybe all is moot and a non-issue now, but like i said, let me know if you'd like an outside set of hands on this.\n. Sure. Myself and a few other @Tapad engineers would like to contribute toward the effort :)\n. I'll start revisiting this weekend so that our team members are ready to contribute early next week.. Ah yeah.. Definitely a blocker unless you want to refactor a bunch of core code.... ",
    "softprops": "+1\n. the latest in your public repo is only 6.5.0 btw \n. scratch that I see there's newer releases on maven central\n. Without additional context, perhaps you can define a package level type alias\nscala\ntype Argument[Ask, Learning] = Service[Ask, Learning]\nFor which you could derive concrete instances of Strawmen.\n. ",
    "Sebruck": "Thanks for the replies!\nHow do you handle this at twitter? Is there any best practice to shutdown a finagle server (considering the server.close problem)?\n. ",
    "yaniv3007": "Thanks for the reply. \nIt was just a try I turned it off and I am still getting the same.\n. Hi,\nThanks you for the reply. It appears that the request itself was wrong (something in the deserialize). This caused to the channelClosedexception we got. I am closing the issue.\n. ",
    "hgavert": "It would be great if the user guide would have a chapter about timing out futures. I haven't found any other documentation that would mention them. It seems that the twitter future API has just gone through larger rewrite and the changes are not really documented anywhere.\n. ",
    "supine": "Ah, doc/src/sphinx/index.rst would be the source file for site/index.html\nIn that case you should regenerate it and commit that as it's still broken at http://twitter.github.io/finagle/\n. ",
    "gianm": "I don't think there are finalizers in place that close stuff, so I don't think so. Even if they exist, though, I'd think that Closables on the dest Var[Addr] should get called when the Service is closed, instead of having to wait for finalization.\n. My problem is that I'm using Var.async to create Vars that encapsulate external resources and need cleaning up. The \"update\" method starts a Curator PathChildrenCache and returns a Closable that closes the cache. What I see is that even when the client Service is closed, the Closable never gets called and so the cache never stops and the Curator structures don't get cleaned up. (In my case the Curator client belongs to the Resolver, not the Var, so it persists for the life of the program even though the Vars often don't.)\nCode is something like:\n``` scala\nimport com.twitter.finagle.builder.ClientBuilder\nimport com.twitter.finagle.http.Http\nimport com.twitter.finagle.{Addr, Resolver}\nimport com.twitter.util.{Await, Future, Time, Closable, Var}\nimport java.net.InetSocketAddress\nobject hey\n{\n  def main(args: Array[String]) {\n    val client = ClientBuilder().codec(Http()).hostConnectionLimit(1).dest(\"hey!what\").build()\n    Await.ready(client.close())\n  }\n}\nclass HeyResolver extends Resolver\n{\n  override val scheme = \"hey\"\noverride def bind(arg: String) = Var.asyncAddr\n      new Closable {\n        override def close(deadline: Time) = {\n          println(\"Closing!\")\n          Future.Done\n        }\n      }\n  }\n}\n```\nSo I'd expect \"Closing!\" to happen when the Service is closed, but it doesn't. I also don't think a GC would help-- PathChildrenCaches need to be closed and not just thrown away.\n. ",
    "azenkov": "Thank you, Evan!\nLooks like the problem I have sits a little deeper than RequestSemaphoreFilter. Even when I limit the number of connections like this \nServerBuilder.openConnectionsThresholds(new OpenConnectionsThresholds(4, 10, Duration.apply(100, TimeUnit.MILLISECONDS)))\nI still receive the OOM during stress tests. I kept profiling and it looks like IdleConnectionFilter is only applied after the socket is accepted and request is read from the network. In my case a server received thousands of big requests and is unable to provide backpressure to clients since all of those connections are accepted and read by netty/finagle into RAM which is crashing the server. I was wondering if there is a way out of such situations when I need to prevent requests from being read from the network. \n. We are Java-only shop and have our distributed search service written on top of lucene. We use finagle to implement communication layer within the cluster and remote access to it. Also for a bunch of auxiliary services like task distribution, deleted tweets tracking etc.\n. ",
    "wenfengzhuo": "I have close all windows firewall. Here is my configuration.\n\n. Yes, the interface is correct(Local Area Network: [MyDomain]/192.168.1.130:5233) . I never used Finagle in Windows before, just recently I setup the ENV to Windows, and the situation happens.\n. The server log suggests that it binds to the interface which is the same with the one client connects. Now I found that when I use loopbackaddress(127.0.0.1), client works fine. And when the server bind the LAN Address(192.168..), the client did not work.\n. It's easy to get lookbackaddress whether you are using Java7 or Java6 (brute force to find it). But my concern is whether Finagle is able to startup in LAN on Windows Platform.\n. ",
    "sonnes": "@nshkrob Yes. I think it should be like this - \nrequest match {\n      case QueryRequest(sqlStatement) => {\n        Trace.recordRpcname(\"mysql\",\"query\")\n        Trace.recordBinary(\"query\", sqlStatement)\n      }\n      case PrepareRequest(sqlStatement) => {\n        Trace.recordRpcname(\"mysql\",\"prepare\")\n        Trace.recordBinary(\"prepare\", sqlStatement)\n      }\n      // TODO: save the prepared statement and put it in the executed request trace\n      case ExecuteRequest(ps, flags, iterationCount) => {\n        Trace.recordRpcname(\"mysql\",\"execute\")\n        Trace.recordBinary(\"execute\", \"?\")\n      }\n      case CloseRequest(ps) => {\n        Trace.recordRpcname(\"mysql\",\"close\")\n        Trace.recordBinary(\"close\", \"?\")\n      }\n      case _ => {\n        Trace.recordRpcname(\"mysql\", request.getClass.getName)\n        Trace.record(\"mysql.\" + request.getClass.getName)\n      }\n    }\nI didn't want to remove the original author's code, so as to not break their assumptions. \nAlso for 'Mysql' client, isn't the service name constant, unless the same Mysql client can be used to connect to different database/service. \nIs there are scenario where the same client will be used for for other SQL services?\n. @stuhood I do not know about sharding on mysql very well. But if it's just the server host address & port. That case is already covered by the ServerAddr annotations. The server address shows up in the mysql span. \n\nThough, they show up as 'unknown' spans under mysql. I haven't spent time to find the source of these annotations in the code. Let me fix that as well. \n@roanta will update the PR. will push the final changes along with the fix for the server addr. I should be able to spend time on this in a day or two. \n. @mosesn  Sorry about the delay. Got lost and forgot about this PR. \nI have updated MySQL client as well to allow custom names for the client. This I believe should take care of cases where multiple clients are used in the same application. \nI still couldn't find the source of the 'Unknown' spans (https://github.com/twitter/finagle/pull/250#issuecomment-37321429). \nWhat I have noticed is when am sampling 100% requests, these 'unknown' spans are added to the trace few minutes after the trace shows up on the UI. I think it's a case of repetitive tracing. \n. Sorry about the delay, again. \nI have updated the filter to remove the deprecated tracing methods and removed the additional methods I added in the MySql client. \nThe latest code had changes that allow setting a label while initialising the client. The tracing filter now uses the label identifier from client \nClient init looks like this:\nlazy val sqlClient = Mysql\n      .withCredentials(Config.db.user,Config.db.pass)\n      .withDatabase(Config.db.name)\n      .newRichClient(Config.db.url,\"nodestoremysql\")\n. @evnm let me do that. \n. @mosesn I am currently not working on our finagle stack. I won't able to\nmake time to work on tests for the traces. If this is not a priority fix,\nyou can close this pull request. I will revisit the mysql tracing and send\nin a new patch with tests once am free.\nIn the new finagle version, the old tracing methods were deprecated. So\nwhile updating the methods, I added the record client name call,\nreplicating the behaviour of the tracing filter in finagle-redis.\nOn 13 May 2014 23:31, \"Moses Nakamura\" notifications@github.com wrote:\n@sonnes https://github.com/sonnes OK, in internal review, a couple\nquestions were raised.\nA. Could you add a test for this? Maybe replacing the DefaultTracer with\nsome sort of InMemoryTracer (like we do for StatsReceiver) and testing that\nthe traces are properly recorded.\nB. You shouldn't need to add the Trace.recordServiceName(clientName), in\ntheory we should already be collecting that information. Have you found\nthat's not the case?\n\u2014\nReply to this email directly or view it on\nGitHubhttps://github.com/twitter/finagle/pull/250#issuecomment-42990016\n.\n. ",
    "kt3k": "Thanks for the feedbacks!\n@mosesn \n\nCan we use the sbt launcher that we package with finagle?\n\nAt first I thought it's not possible but after some observation, I found the workaround, so I will change to use sbt-launcher. (The problem was default $SBT_OPTS of travis-ci environment.)\n\nCan we test against openjdk{6,7}, and scala 2.10.3 as well?\n\nI tried some of thoses environments ( like https://travis-ci.org/kt3k/finagle/builds/20784616 ).\nWith scala 2.10.3, the build dependency doesn't resolve and no tests run. (The error is sbt.ResolveException: unresolved dependency: org.scala-tools.testing#specs_2.10.3;1.6.9: not found)\nAnd with openjdk{6,7}, in addition to finagle-http and finagle-memcached, finagle-native doesn't pass.\nIf we add a conditional line like:\nif [ \"$TRAVIS_JDK_VERSION\" = \"oraclejdk7\" ]; then ./sbt ++$TRAVIS_SCALA_VERSION finagle-native; fi\nthen it will pass with openjdk{6,7} probably.\n\nIt's odd that finagle-http fails, could you elaborate on why it fails? It's known that finagle-memcached is flaky, although we typically see it succeed most of the time. Are the travis-ci boxes underpowered?\n\nSorry, for now I have no idea about that.\n@stevegury\nOk. I'll do it.\nThanks!\n. Thank you for the reviews!\n. ",
    "imatespl": "I am on linux and I make sure iptables stop,what can cause this\uff1f\n. ",
    "tonymeng": "thanks @mosesn :)\n. ",
    "rodrigodealer": "No, it's working fine now.\n. Can finagle-redis be merged? \n. @penland365 No problem, ping us when you have any news about finagle-redis. Thank you for your work.\n. :shipit: :heart: \n. ",
    "mmollaverdi": "OK, working on it right now.\nI was initially thinking of refactoring the clearContent() method in Message class to set the content-length header to 0 every time this method is called. But then I realized that the method is also called from Head Filter where you would want the content to be empty but the content-length header to be set based on the actual content which would be returned in response to a GET request.\nSo I'm going to only refactor the ExceptionFilter class.\nHow does that sound?\n. No, I made a pull request to fix it a while ago and it got merged.\nhttps://github.com/twitter/finagle/pull/266\n. :+1: \n. ",
    "MasseGuillaume": "Great I was thinking migrating finagle and scrooge to 2.11\n. ",
    "penland365": "Hi all -\nIf you're hacking off this, you can jump back to\nshell\ngit rev-parse HEAD\n491598bd698e7e1cda1481442078707c0795be41\nI got a successful compile / test.  That's the commit just prior to the this one https://github.com/twitter/finagle/commit/9f3d3de1fb80ecb552b933664c27ffffbc4276c0 which introduced the LocalScheduler for thread-local tasks.  It's only a few weeks back.\n. Yeah, I didn't test against 2.11.0, my apologies for stating that.  When I was in Build.scala I had set this\nscala\n  crossScalaVersions := Seq(\"2.9.2\", \"2.10.0\", \"2.11.0\")\nIn anticipation of testing 2.11.0 but never got to it.  I had it written down in my notes but hadn't gone back to correct it.\n. Just notice this while in Build.scala\nscala\n  testOptions in Test := Seq(Tests.Filter {\n      case \"com.twitter.finagle.redis.protocol.integration.ClientServerIntegrationSpec\" => true //false\n      case \"com.twitter.finagle.redis.integration.ClientSpec\" => true // false\n      case \"com.twitter.finagle.redis.integration.BtreeClientSpec\" => false\n      case \"com.twitter.finagle.redis.integration.ClientServerIntegrationSpec\" => true // false\n      case _ => true\n    })\nThat first Spec com.twitter.finagle.redis.protocol.integration.ClientServerIntegrationSpec doesn't appear to exist anymore.  Is it OK to yank it?  It's not life or death, but did cause me a few minutes of confusion when this\nbash\n  sbt test-only com.twitter.finagle.redis.protocol.integration.ClientServerIntegrationSpec\nwas giving me zilch.\n. API replaced for the DUMP command as requested.  :cactus: , because it's hot in Dallas today.\n. @mosesn Would you like me to merge in Friday's push to my branch or just leave it be?\n. @stevegury done. Thanks!\n. Thanks @stevegury , @mosesn for the code reviews.  Y'all make it easy to contribute.\nClosing.\n. Thanks @mosesn .  Sorry for the radio silence on this one - I got pulled into something at work that had to be finished before the quarter wrapped up.  I'm grinding on this today and over the holiday weekend.  I'll definitely ping you at some point for some guidance on this.\n. Is it alright if I roll one command into this ongoing PR?  The command is a simple one, FLUSHALL .\n\nDelete all the keys of all the existing databases, not just the currently selected one. This command \nnever fails.\n\nI'm running into several areas in the refactor where tests are fouling due to unstated preconditions / postconditions.  Right now I'm doing something like this when the client loaner is returned:\nscala\nval dbs = List(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\ndbs.foreach( db => {\n  Await.result(client(Select(db)))\n  Await.result(client(FlushDB))\n}\nI can leave it as is for right now if you want to keep any new Commands out of the PR.\n. Alright @mosesn , now I do need some help ( or most likely a slap ).  The last two commits show the completed outline of how I would finish this out.  Here's a picture of the folder outline =>\n\nI'm not gonna lie, I kinda hate the name KeyClientServerIntegrationSuite.scala because it feels so Captain Java Enterprise~y Dev.  Also, the future file ServerClientServerIntegrationSuite.scala is causing me to rethink my profession and I haven't even written it yet.\nThoughts on the finalized outline?  Naming suggestions?\n. FLUSHALL command added in the latest commit.\n. I like that naming, though it does leave something to be desired when reading the test output on the command line - it just shows two different ClientServerIntegrationTest, and you'd have to break out your context clues to determine which file it's actually in.  Maybe that's OK, maybe we want to be more specific?\n. Spent 15 minutes thinking about it and the answer is nope.  Any report and/or command line output is going to print the fully qualified class name, which I hadn't thought about originally.\nI'm in the middle of the LIST commands, then I'll change the names of the tests to lineup w/ this new schema.\nThanks @mosesn for talking it through with me . . . w/ stuff like this that's half the battle.\n. @mosesn My apologies, It's been crazy at work recently.  I wish I had a better excuse than \"there's only so much code my brain can process\" in a week, but I don't.  I'm going to grind on this this this weekend and hopefully have it wrapped up soon so I can unblock anyone working on redis related stuff.\nThank y'all for your patience.\n. Hey, look, actual code!  The whole mess of current LIST tests has been refactored this evening . . . one of the things that's really apparent while doing this is that some commands don't have the test coverage I thought they did when I first looked at those three huge scary files.\n. Sure thing on both those.  I'm currently in the middle of teasing apart the SET commands - I'll rewrite it in the updated style and push those specifically to make sure it fits.\nOn the multi-line test, I think I got started on that when I was trying to tease apart a few tests I didn't understand originally.  I do think you're right though, it's too much boilerplate and too little readability.\n. Found time => I'm back.  @mosesn , this last commit reflects ( I think ) your desire to collapse the assertions into one line.  This last commit was the Set commands.  Can you look at:\n1. test/scala/com/twitter/finagle/redis/wip/commands/set/SetClientIntegrationSuite.scala\n2. test/scala/com/twitter/finagle/redis/wip/commands/set/SetClientServerIntegrationSuite.scala\n3. test/scala/com/twitter/finagle/redis/wip/commands/set/SetCodecSuite.scala\nAnd let me know if that's the O.K. style?  If it is, I'll go back and and swap out my original assertions.\n. I hope to have finagle-redis finished up by the end of the weekend - Monday.  My apologies if this is holding anyone up!\n. I'll be taking on finagle-redis at the end of this month - I'll have the bandwidth around the holidays. Test migration needs to be completed ( by me ), and then the testing of 2.11. \n. @ckampfe @rodrigodealer You can blame me for that - I bit off too large of a change when we did the port to scalatest and the PR is bit of handful for the internal team. The dev work has been completed, but finding the time to actual get \"All the Things\":tm: done has been a challenge. \n. A thousand thanks for taking my partially finished transition and pushing it over the finish line.  I made a cursory glance over it and it looks good - save my one random import formatting question.\nOne question on the @Ignore integration tests - are those easily removed when testing in certain scenarios, i.e. => ./sbt testIntegration? \n. @dschobel In fairness to @mkhq , most of those style nits were introduced by me last year when I was still trying to get a handle on writing proper Scala.\n. This implementation isn't going to work as is => we're wrapping a type that never gets called externally ( just noticed this on test ). I didn't realize the state was managed internally. We're calling handle and dispatcher internally from here on GenSerialServerDispatcher and here on Mux. So even if we wrap the type, the original Dispatcher handle and dispatcher methods are what will be called.\n. This yak has turned into something much larger than I first though. I've pushed a change that does annotate anything that subclass GenSerialServerDispatcher, and should be able to be mix-in to any other Dispatcher class that extends ServerDispatcher ( like hopefully mux ).\nHowever, while trying to test this I kept failing to get a Trace to record. That would be because of this commit where we are specifically clearing local before entering the Dispatch loop. Since we don't know the TraceId right now at the Dispatcher level, this is going to need some additional work before it's ready to go. \n. Superseded by #463 \n. Ooooof, sorry, this was supposed to opened against my personal fork for record keeping.\n. This is an ongoing attempted solution to #401 - @mosesn has been very kind in helping me along w/ this. Any issues / faults w/ this PR are definitely mine. \nIf this solution looks workable, there are additional changes that need to be made to finagle-stream finagle-memcache finagle-thrift. The hope with this PR is that those changes are pretty painless.\nI needed additional feedback before attempting finagle-mux.\n. I went ahead and updated protocol except for Mux - memcache / stream / thrift / SPDY were pretty easy to change given the current extension point.\n. nudge\n:wave: \n. Thanks @kevinoliver ! I merged in the most recent develop pushes - I sorted too many Scala Imports. I'm currently going through the process of updating / building / publishing Util and Scrooge to make sure the merge worked fully.\nLoading this back into my memory banks, the other issue to me was around the TraceInitializerFilter - for servers, this becomes a bit superfluous since Tracing is initialized at the Dispatcher level instead. I wasn't sure what the best way to address this was.\n. Had a bad merge in http/Codec.scala that's been fixed, and I made the changes @mosesn requested. \nNo worries at all on the delay! \n. \nSo, @mosesn @kevinoliver , what do ya'll need from me next on this? I haven't made it private[finagle] yet ( wasn't sure if that was a request or not, but it seems reasonable to me ). I have updated the style nits. Given that there has been a new push on develop, I'll get those new changes merged in this afternoon.\n. Just pushed a fresh merge \ud83d\udc4d . It should be up to date w/ latest develop.\n. I'm not biased in any direction here - from looking through the *Command.scala files for guidance, I saw what seemed to be a bit of a mixed bag on the scaladocs.  There was one usage of @see but it wasn't consistent.\nMe personally, I figure if someone is using a redis driver they know what the Redis Command is, so I would simply do something like this\nscala\n   /**\n    * Move key from the currently selected database to the specified destination\n    * database. When key already exists in the destination database, or it does\n    * not exist in the source database, it does nothing.\n    *\n    * @param key, db\n    * @return true if key was moved.\n    *               false if key was not moved for any reason.\n  */\n. OK, do you want both lines relating to vagrant to head into my global gitignore?\nshell\n.vagrant/*\nVagrantfile\nor just the hidden vagrant folder?\n. I was undecided on this and wanted feedback.  Exposing the ChannelBuffer felt a big API~leaky to me, since the DUMP command returns simply a Byte sequence.  However, simply returning a ChannelBuffer does simplify a lot of things.\n. Done\n. Understood - I'll replace those endpoints then update this PR when it's done.\n. Hah, yes, sorry.  I'm not looking for that much work\n. Do we want the triple equals for asserts?\nscala\nassert(cookie.value === \"value\")\nIt gives a more informative error message.  Also, the more you have, the better your equality tests will be.*\n*That's science.  Or javascript.\n. It shouldn't be - that was leftover from a functional attempt to return the same type passed in, and I had just yy the original method definition.\nFixed.\n. Done\n. My desire is to have this only wrap anything that is a sub-type of ServerDispatcher. That would mean mixing in the type on things like finagle-http and finagle-mux, but ( fingers crossed ) that shouldn't entail too much work.\n. Done.\n. If it's protected it's not visible to the AnnotatedServerDispatcher. I went back and forth on this - I'm open to other solutions.\n. Yeah, it's not. Same as above - I had yy that definition from another implementation that was an abstract class that need a Transporter.\nFixed.\n. Done\n. I agree - at the time, I thought it would be beneficial for all clients to know that a ServerDispatcherInitializer was required to properly construct a SeverDispatcher. Coming back to it a month later though, it just feels like extra noise that should be handled in documentation.\nRemoved :+1: \n. Removed, sorry, old habits and what not.\n. Done\n. Honestly? \u00af(\u30c4)/\u00af\nI don't have strong opinions on this at all - we have use cases where we like the Trace id embedded in a response, but I can absolutely see this as being something handled on a per-protocol basis.\n. Yeah, I wasn't thinking clearly here - we use some http services internally that we would like to have the ID embedded, but those would\n- Never have a different ID that than the request\n- Wouldn't be affected by the SerialServerDispatcher anyways\nThinking back to a month ago, I originally envisioned the ServerDispatcherInitializer as a way to tell the Dispatcher whether you wanted any traces returned by making fRep: (a: Any) => TraceId optional. That's probably too cute by half.\n. ",
    "lerouxrgd": "I made the following change :\nhttps://github.com/lerouxrgd/finagle/compare/memcache-gets-get\nAs for me tests seem to work :\n./sbt \"project finagle-memcached\" test\nAs for the connection with MemcacheDB it is now working correctly, ie\nList getBatch = new ArrayList(new String [] {\"a\",\"b\",\"c\",\"d\"});\nMap result = memcachedbClient.get(getBatch).get();\nis correctly transformed into :\nget a b c d\nDo you want me to make a pull request ?\n. Thanks!\n. ",
    "timxzl": "I have a fully functional extension to finagle-redis that supports EVAL, EVALSHA, and other scripting commands. would be happy to share if it's interesting to folks.\n. excellent! I have just created a pull request.\n. @mosesn I have managed to make the pull request 381 pass all the tests on travis CI. feel free to contact me if you find any problem with it.\n. it seems that I may have used a wrong base repo. will close this one and open a new one.\n. thanks @mosesn for such a detailed review! I will change those places according to your comments. I agree with them.\n. thanks a lot to @mosesn 's advices! I have rebased on the develop branch of twitter/finagle, and re-designed the API. Now eval() returns a Future[Reply], and we provide helper methods to cast reply to target types. I have opened a new pull request #383 , and closed this one.\n. @jmoseley no updates since I last submitted. still waiting for some contributor to take a look and (possibly) merge it in.\n. thanks @kevinoliver! take your time, please. don't worry.\n. @mosesn thanks for taking care of it! Feel free to ping me if you want anything from my side.\n. @roanta thanks! I have noticed that early this month. Glad to be of some service to the community!\n. I agree with this approach, and I think that would be clearer. The only concern is that this will expose an internal detail (Reply) to the user, which is not done by any other finagle-redis API before. Do you think that is OK?\n. retryOnNoScript is no longer needed in the re-designed API.\n. ScriptCommand is a command that takes a script as a parameter, such as EVAL and SCRIPT LOAD. ScriptDigestCommand is a command that takes a digest of a script as a parameter, such as EVALSHA and SCRIPT EXISTS. The SCRIPT FLUSH does not take any parameter and is just a Command.\n. ",
    "wozaki": "I'm sorry for lack of context. \nProblem\nCurrently, ClientBuilder#httpProxy doesn't support Apache Proxy Server. \nApache Proxy Server needs the Host Header in HttpRequest.\nWhen we send HttpRequest by the client that called ClientBuilder#httpProxy, HttpConnectHandler sends the CONNECT Request without Host Header first, so we get error from Apache Proxy Server.\nSquid Proxy Server don't need Host Header, but Apache Proxy Server need it.\nSolution\nI have added Host Header to CONNECT Request.\nResult\nWe will use ClientBuilder#httpProxy when using Apache Proxy Server. \n. ",
    "tyleranton": "Is this already being taken care of?\n. Alright, just checking! Thanks.\n. ",
    "tenaciousRas": "was this supposed to fix https://twitter.github.io/finagle/guide/Quickstart.html ?\n. ",
    "jpinner": "This should probably be handled in the Request object when setting a payload and not generically in the codec. From RFC-7230 (RFC-2616 is dead!):\n\"A user agent SHOULD NOT send a Content-Length header field when the request message does not contain a payload body and the method semantics do not anticipate such a body.\"\n. ",
    "JustinTulloss": "Should this also work for a Response object that does not go through a server dispatcher? Why is it set by the dispatcher and not by setContentString and friends?\n. Well, as a naive example, I don't believe that the server in the finagle quickstart guide goes through a server dispatcher.\nhttp://twitter.github.io/finagle/guide/Quickstart.html#a-minimal-http-server\n. Content-Length is not set in that example, but then that's not that surprising as the dispatcher just writes HttpResponses straight through. It only sets the Content-Length header if a Response object is returned from the service.\nEven returning a Response on my own, I'm unable to get the Content-Length header to be set. I will experiment and file a separate bug if appropriate, as this conversation is off-topic for the current bug.\n. ",
    "xinxiang-twitter": "lgtm\n. ",
    "fwbrasil": "@mosesn I'd prefer to close it, I'm not sure if it'd be useful anymore.\n. Nice addition! Can we have tests for it?\n. cc/ @rodolfo42 @missingfaktor @folone\n. @mosesn @roanta Thanks for the feedback, I'll take a look at the develop branch. \nIt is interesting to see that you are working on improving the finagle-mysql module, it has been difficult to use it in our projects. Out of curiosity: do you consider it production ready?\n. \"made not entrant\" and \"made zombie\" don't indicate problems afaik. @stevej are there log lines reporting methods that are hot but can't be inlined because are too large?. > They're only problems in that they're being deoptimized. The documentation is slight and I don't spend a lot of time digging around OpenJDK so please let me know if I'm wrong here but my understanding is that deoptimization means jitted native code is being ejected from the code cache and the bytecode interpreter is being used for that method until the jitter kicks in again.\nThe JIT compiler is a magic black box for me, so I might be wrong, but I think the deoptimization per se doesn't indicate a problem. The JIT compiler optimizes optimistically and then deoptimizes if the assumptions it made don't hold, which should be fine. The problem would be if it can't apply the optimizations again and the code path is hot.\n\n@kevinoliver I did a spot check of some of the util methods and most aren't being re-optimized later.\n\nDoes the log have a reason for why the optimization doesn't happen again? Maybe the code path doesn't become hot again?\nI agree with @dschobel, it's definitely worth digging into the JIT compiler logs. . ",
    "jbripley": "Could this also link to a complete standalone example for using finagle-http with streaming? I'm mostly interested in the client part, but server implementation would be nice as well. As an example, this is the two example projects 1, 2 I looked at to wrap my head around the finagle-stream API.\nLooking through the current document, I find it a confusing mix of describing implementation details, implementing parts required by the implementation/interfaces and a description on how to use finagle-http streaming in practice.\nFor example, I don't quite get what is existing interfaces, if Reader is something you need to implement yourself or if there a prefered Reader implementation already implemented that should be used. And as I alluded to earlier, it also doesn't show a complete standalone example, only solving specific problems with no connecting code in between.\n. @luciferous Is there a complete standalone example for using finagle-http with streaming? I'm mostly interested in the client part, but server implementation would be nice as well.\nI've had a look at finagle-http, but I find it a confusing mix of describing implementation details, implementing parts required by the implementation/interfaces and a desciption on how to use finagle-http in practice.\nFor example, I don't quite get what is existing interfaces, if Reader is something you need to implement yourself or if there a prefered Reader implementation already implemented that should be used. And as I alluded to earlier, it also doesn't show a complete standalone example, only solving specific problems with no connecting code.\n. @mosesn  Sure thing. I added an updated comment, with links to the examples I looked at to understand the finagle-stream API.\n. @luciferous Thanks, I'll have a look at switching over our finagle-stream code to finagle-http.\nAny chance to add support for creating a stream compatible HTTP client from Http.newClient, using a withStream() or something? I've tried to switch all Finagle service/client (redis, memcached, http) creation over to $CODEC.newClient, and I think the HTTP streaming implementation is the only thing I've found where that's not available (for either finagle-stream or finagle-http).\n. @mosesn we build micro-services that expose an HTTP or thrift API using the server parts of finagle-http and finagle-thriftmux. Those micro-services in turn use different finagle clients for memcached, redis, HTTP and thrift to implement their functionality.\n. Yep, I don't really like that syntax either and will fix it. I was just following the rest of the code in the file though :)\n. From reading the code in KeysCommand, it looked like empty key values would throw an exception as well. My unit test seems to indicate that this is true as well.\nI can remove that part of the comment though, if you think it'll only confuse people.\n. Just noticed that the comment should probably read \"any\" instead of \"all\" in the \"if all of the values included in the keys Seq are empty\" part of the comment.\n. I don't feel confident enough about the finagle-redis codebase to get started on that and besides, I would probably want to do that in a separate pull request.\nI'll update the comment as you suggested.\n. ",
    "kristofa": "We enabled streaming for one of our services recently and got our use case working but it took us quite some effort to get it right. Adding more documentation will be useful and appreciated! I'll be happy to help reviewing.\n. Thanks, I can use some help, yes :)\nThe problem is that the MemcachedTraceInitializer filter is registered in the TraceInitializerFilter.role. The next filter in the chain is the ClientTracingFilter which submits cs, cr annotations. After the ClientTracingFilter ends the span by submitting cr annotation the MemcachedTraceInitializer filter still submits cache hit/miss annotations.\nSo the obvious way to go I guess is to replace the current ClientTracingFilter with an updated Memcached filter which combines submitting cs, cr annotations and cache hit/misses.\nThis does not sound too complicated but the problem is that I don't see a way to do this using the current Memcached clients. The Memcached clients don't seem to use StackClient and they only seem to allow overriding the Trace Initializer?\nAny thoughts or suggestions would be really helpful. Thanks!\n. See #354 \n. I'll revisit this soon. I'll check if the issue is still present in Finagle 6.35.0 and if so I'll submit a new pr.\n. Pull request #516 reviewed.\n. Because the memcached client still is implemented using ClientBuilder and is not a StdStackClient this change involved supporting overriding ClientTracingFilter.role instead of TraceInitializerFilter.role which was already supported.  Also overriding TraceInitializerFilter.role was supported both in Codec and in DefaultClient constructor.  I decided to update Codec to allow overriding any 'role' and deprecating the old method for overriding TraceInitializerFilter.role.\nIf you guys are fine with this change I can add an additional commit to also fix the memcachedx client.\n. I don't know why Github keeps indicating the build is still in progress. When looking at Travis you see the builds are completed however only 1 of the 3 jobs finished successful.  The 2 failed jobs seem to have failed for reasons not related to my change.  The Oracle jdk 7 one succeeded. Any input? \n. @luciferous Thanks for letting me know!\n. Since finagle-memcached is deprecated in favour of finagle-memcachedx as of release 6.26 I'll close this and have a look at finagle-memcachedx.\n. @adriancole Thanks for taking this up and moving http and kafka support in Finagle!\nAt SoundCloud we have wrapper classes for building Finagle servers and clients. These thin wrappers deal with configuration like settings up the tracer. So instead of relying on service loading or overriding the DefaultTracer we explicitly set the tracer we use like this:\nHttp.server\n      .configured(param.Tracer(tracer))\n      ...\n. @mosesn 2nd attempt to fixing #343.\n. \nThis screenshot from zipkin-web shows the behavior of the original code. While the memcached 'get' operation didn't even take 1ms the duration of the span ends up being more than 32 seconds because the span is submitted a 2nd time (finagle.flush annotation).\nI tested the fix I submit here using a test with a local memcached and zipkin set-up.\n. @dschobel I updated the code to submit the rpc name (command name) before dispatching the request.\n. Inside 'traceRpc' there is a verification using 'isActivelyTracing' before submitting the annotation. \nBut we should have no tracing further down the stack with memcached anyway so I reverted to previous version and added a comment as you suggested.\n. @dschobel Thanks for reviewing! I hope this gets merged as it will make our trace overviews usable again.\n. I'm happy that I'm able to contribute. Thanks for open sourcing such a great software project! \n. I think we are fine with these changes.\nThe order in which tracing events happen for memcached with this commit in place:\n1. Initialize span (TraceInitializerFilter part of StackClient)\n2. Add Client Send annotation (AnnotatingTracingFilter set-up in MemcachedTracingFilter.Module)\n3. Execute memcached request\n4. Add cache hit/miss annotations based on memcached response (MemcachedTracingFilter)\n5. Add Client Received annotation (AnnotatingTracingFilter set-up in MemcachedTracingFilter.Module)\nWe can only add the cache hit/miss annotations once we got the response. The important change is that the memcached annotations are submitted in between the cs / cr annotations. The Client Received annotation should be the last annotation that gets submitted because it indicates the span is complete and ready to send off to back-end.\n. I certainly want to add a comment but I would like to understand the problem. \nWhat could happen is that additional tracing annotations are added lower in the memcached client stack but I don't see why this would give a problem with adding the cache hit/miss annotations on the way out? \nThank you for the quick feedback!\n. ",
    "argha-c": "Indeed, as @kristofa mentions, it'd be nice to improve the documentation here. Happy to contribute in any way around this.\n. \ud83d\udc4d  to this issue. I have observed this while writing an integration test using 2 memcached containers, killing one, killing both and them bringing them back up. \nThanks for the detailed report on the findings.\n. ",
    "bryce-anderson": "There hasn't been much activity on this and many parts are no longer valid. Barring any resurgent interest in getting this updated and merged, I'm going to close this at the end of the week.. Closing due to inactivity.. This has gotten pretty stale and there has been no activity for quite a while, so I'm going to close it. If there is revived interest in updating this and getting it merged, feel free to reopen.. Given that it seems decided that this doesn't belong in finagle-http and there hasn't been any activity on this since June 2016, I'm going to close. If there is interest in moving this forward, feel free to reopen it.. Okay @monkey-mas, I have discussed this with @mosesn and there may be another way to get this done in a bugwards compatible way. A lot of the functionality in the HttpServerDispatcher.handle method deals with similar issues to what you're addressing, namely ensuring that the Response is in a conformant state. Perhaps this isn't something that the dispatcher should be concerned with and this could be moved from the HttpServerDispatcher to your ComplianceFilter. \nThis is bugwards compatible in that those who need the older behavior could replace the filter you've made.\nWhat do you think?\n. @monkey-mas, I'm sorry we've been slow on this. We have started to move in the direction needed to incorporate your commit. See https://github.com/twitter/finagle/commit/fa8cef1c30e635366c763ae12de4133133a1f50b\nIf you're interested, perhaps we can get your work into the ResponseConformanceFilter.\n. @monkey-mas, we'd love to have your contribution, you've put a lot of good work into this and I imagine you know the problem domain better than we do at this point (or else we would have this problem to begin with!).\nIn my minds eye, modifying validate is the right solution. @mosesn had some comments on being bugwards compatible. Personally, I don't see much of a case for being bugwards compatible here considering we are potentially committing a protocol violation by sending a body. I would suggest we log such events as errors considering it is certainly an error to generate a 204 or 304 with a body and should be fixed.\n. I'll pull it in and take another look! Sounds like this is further down in the pipeline a bit, so this is more interesting than we'd hoped. :) Excellent sleuthing @monkey-mas.. @monkey-mas, I've looked through your PR and wanted to get your take: it does look like Netty is responsible for the test failures as you've laid out above. How do you want to proceed? In my mind's eye, Netty should probably be fixed, so if you're interested in contributing to that project I think you've got a nice contribution on deck. In the meantime, we could disable the end-to-end tests that are failing due to the client issue.\nWhat do you think?. @monkey-mas, no worries! I'm in the process of merging this in with the end-to-end tests disabled: this works as expected when running a simple telnet session.\nI feel the Netty folks are generally quite receptive to patches that make sure they don't break things, which this seems to be an instance of. They already have similar logic laying around to deal with cases where a body shouldn't exist, for example here. If you ask me, that code would be better off renamed and in the HttpUtil object.. @monkey-mas, after long last, this was merged as commit 1e4252e. Thanks a lot for both your patience and good work! Keep us updated on the status of any Netty PR you submit to address the chunk aggregation issue.. @monkey-mas \ud83d\udc4d\nPlease feel free to ping me in any related Netty issue/PR you file.. Looks like a success to me!\nSee https://codecov.io/gh/twitter/finagle/commit/c22d896385b2e5f626be9937e16d2cc432cc96e0 for stats on commit d349557.\n. Merged internally.\n. @clumsy, are you working on a Windows machine? This bit of code looks like it addresses the same thing.\n. This has been merged internally and merged as commit e649e9ebea74da741deda2ff9b41361ed19e2e46.\nThanks, @clumsy!. @mosesn: CMS is not compacting, so trying to allocate 2GB of contiguous space in a 3GB heap has a good chance of failing. G1, on the other hand, is a compacting collector.\n. It definately OOM's, the two links are the failing project build logs before changing the GC. \nhttps://travis-ci.org/twitter/finagle/jobs/149860894#L6644\nhttps://travis-ci.org/twitter/finagle/jobs/149860894#L6679\n(I believe these are the same error, just reported twice)\nI will admit that I blamed heap fragmentation for the OOM error which is mostly speculation. Perhaps the structure of the heap is to blame?\n. Always cool to see new adopters! If you don't mind sharing, how are you using finagle?\n. @jpgneves, this has obviously sat in queue way too long without reply, and for that, I'm really sorry. It looks like good work, which makes it even worse. \ud83d\ude1e \nThere has been some activity in finagle-redis recently, mot notably commit 792498babeb42. I think it's going to require a few modifications to this PR to get it all ready to merge, if you're still interested.\nAgain, I'm really sorry that this PR slid by for so long with radio silence.\n. @jpgneves, I'm pulling @vkostyukov into the conversation. Vladimir is doing a fair amount of work in this area getting it in better shape so it might be good to coordinate to minimize the number of necessary git merge calls. \ud83d\ude09 \n. It also looks like some of the Travis failures are legitimate and need to be addressed.\n. Hey @vazyzy, I was in the process of merging this internally but ran into a few unexpected issues. We have a number of internal uses that look for a Host header when forming Url's etc that end up breaking when the Host header is the empty string. In theory, this could be fixed, but it's unlikely to happen in the near future.\nWhat is the problem you're trying to solve? As @vkostyukov mentioned above, we are starting to address theses conformance issues using filter stack modules.  See the ResponseConformanceFilter. Would this solve the problem you're trying to address?\n. I'm going to close this since, unfortunately, this approach causes internal problems at Twitter. I think there is a way forward which has been mentioned above which is making the responsibility of request conformance a part of the client and not the request.. I think that it would be nice for the load balancer to set the host header. We don't use the host header much, so this hasn't been a priority for us. That said, I think it would be really good to do as not everyone is so lax with their HTTP.\nI'm sorry I don't have better news for you.\n. @vigneshwaranr, I'm sorry to say that we haven't invested in this yet.. Hi @pikazlou! This seems to be a hot topic. There is already a PR concerning this that you might be interested in: https://github.com/twitter/finagle/pull/521\nWe have just merged some work internally similar to this regarding HEAD requests, but it hasn't synced with github yet. I'll try and poke the PR ticket once the sync has happened. It should provide a better foundation for cleaning up some of the conformance issues in finagle.\nI'm going to close this ticket as a duplicate of the PR mentioned above. If you feel that this is different in some manner, feel free to reopen it. Feel free to continue the discussion there if necessary.\n. Right now, I don't think there is a solution. That is part of the motivation for #521. Part of getting us on that direction was done in this commit: https://github.com/twitter/finagle/commit/fa8cef1c30e635366c763ae12de4133133a1f50b\nI hope that we can build on that.\n. Done: https://rubygems.org/gems/finagle-thrift/versions/1.4.2\n. Great news! Thanks for the PR, we'll get this merged internally.\n. @fnouama, this has been merged internally and should sync to github within a few days.\nThanks again!\n. Hi @leesf! I noticed in your example you're using an Await.result call, which is notorious for causing issues. It may not be the root problem since you're doing it in separate threads but it can be hard to be sure. Is that how your application code is setup?. Good news @reikje, this has been merged internally and has now landed as commit 9df664a. Thanks for the PR!. See other thread.. This has been merged as 9fa0dafb59080f5e600e0d00f3012a8ac66a5216. Thanks for the PR @koshelev!. I'm closing this because it's been inactive for nearly a year. From the history, it looks like it was really close and may be worth picking back up. If that is the case, feel free to reopen this and get it merged with develop.. @mehmetgunturkun, I wouldn't worry about small delta in codecov: it can be a bit flaky. I'll take a quick look and see about merging this!. @mehmetgunturkun, I have some bad news: we have a few problems. First one is simple: we need a CanBeParameter instance for BigInt.\nSecond one is not so simple, but not too hard. With your change, most int *Value types are now widened if the DB schema is an unsigned integer type. For example what was a LongValue may be now represented as a BigIntValue if the DB schema says the column is an unsigned long long. This causes things like below to fail:\nscala\n// Will result in a MatchError\n// terrible idea, but it happens and only fails at runtime. :(\nval LongValue(foo) = row(\"foo\").get\nA workaround for this is to make consideration of signedness configurable with a default of off. In my minds eye you just need to add a flag to the Row implementations and in the match statements do something like this:\nscala\nfield.fieldType match {\n...\ncase Type.Long if considerSign && field.isSigned => \n...\nWhat do you think?. @mehmetgunturkun I think Type.LongLong is correct.. @mehmetgunturkun, it would be great to see the code. Ultimately this will probably be something that gets set during client construction with a stack Param.. @mehmetgunturkun hard to say for sure without more details, but I don't understand why you would be changing readMediumLE to readIntLE. From the looks of things, there are a few place in this PR where we satisfy an Int24 with readIntLE which seems wrong: won't that consume 4 bytes when we only want to consume 3?. @mehmetgunturkun, hows it going on this?. @mehmetgunturkun this has been merged internally and we're just waiting for the github sync process to publish it. Good news is that it should also make it out into pending finagle release.. Closed by 598acc5416798d37e4c796ab115cbda9a34fb787. Thanks again, @mehmetgunturkun.. @Mura-Mi, are you still interested in getting this merged? This looks pretty close, but there appears to be a few outstanding comments.. This has been merged as commit 7d5f269. Thanks for the PR, and we'll try to get the follow-ups reviewed soon.. Sure enough: by using Http.Client() instead of initializing Http first it starts with Http.Client which then begins Http which uses uninitialized fields on Http.Client resulting in nulls. This can be fixed by making Client.stack and Client.params lazy or a defs.. Depends on your stance on API's: you don't need to since you can use Http.client.copy(..) or the helper methods to do more directed configuration changes, but there is no reason not to have an open constructor function in case someone wants to simply replace the stack or params (or both).\nIMO, the root of the problem is the use of eager evaluation in the object fields: I think we're just being too stingy with allocations by trying to cache the base case and it bit this time.. Looks good to me, but this is honestly the first time I've looked at redis technology so I'm far from an expert. If we can get another set of eyes or two, I think it's ready to go. Ping @vkostyukov, who I believe knows more than I do about this protocol implementation.. @mkhq, perhaps you're already going to do this, but it would be helpful if you could rebase+squash the PR when you push the commit for visibility. (It makes it easier to merge internally, but its not a show stopper). @mkhq, I'm really sorry I didn't see your previous ping: a lot of things got lost in my inbox during that time period.. Merge as commit ac30be3a5aa68e25f8d0ee287fe6f692c2b0e14e. Thanks!. Merged as commit 80149d9. Thanks again @sullis!. Merged as SHA 753b721. Thanks @sullis!. This PR looks legit, but I'm having an internal tug of war where part of me thinks that the backoffs are material to equality of a Budget. On the other hand, it's not fantastic if it never terminates/OOM's on you.\nAs a more general question, is this just to serve the issue you raised, https://github.com/twitter/finagle/issues/669, or is it important in and of itself? In my mind's eye, its hard to justify a client having such a deep notion of equality/hashCode since a lot of the data inside is dynamically generated and highly unlikely to be truly equal to any other client. I would personally advocate for the Http.Client (and other clients) having equals and hashCode defined as instance equality/hashcode. Would that solve your problem?. It seems I've gotten my terminology a bit twisted. Http.client isn't so much a client as a client factory, and it does kind of make sense to have equality and hashCode there since it is arguably just configuration data, and configurations seem reasonable to compare.\nI was arguing for defining equality and hashcode as you've laid out at the end, but I may walk it back. I still think that the equality of Budget should probably consider the backoffs, but that would entail trying to detect cycles in the Stream which is not great.\nI'm actually okay with this as is but more feedback would be helpful.\nAnd thanks for the PR!\n. Closed via a376dc91f7cbec1276ee5114cd89b9e9a50bac69.. Just a wild guess, but try adding a host header.\nOn Feb 10, 2018 3:47 AM, \"politrons\" notifications@github.com wrote:\n\nOne line summary of the issue here.\nExpected behavior\nWhen I do an http request to Grizzly server using this code\nval client: Service[Request, Response] = Http.newService(\"localhost:8080\")\nval request = http.Request(http.Method.Get, \"/hello_server\")\nReturn a 400 Bad request. But using this one works\nval client: Service[Request, Response] = Http.newService(\"localhost:8080\")\nval request = RequestBuilder()\n.url(new URL(\"http://localhost:8080/hello_server\"))\n.buildGet()\nAny idea why?.\nThe funny thing is, that the first code against another finagle Http\nserver or Vertx server works fine, it\u00b4s failing only against Grizzly.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/674, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACz9mhOLx8Kjc5-5N7VJx9iLrOKJZoz9ks5tTXPZgaJpZM4SA4xl\n.\n. We're in the process of checking the latest release. I'm hopeful we'll have\nit done by the next oss release.\n\nOn Tue, Jul 17, 2018, 5:22 PM Alex Leong notifications@github.com wrote:\n\nHey @mosesn https://github.com/mosesn, is the netty4 version still\nfrozen? We'd really like to pick up a bug fix from Netty 4.1.17\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/pull/678#issuecomment-405758996, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACz9mhGhhVL1G-Blr5mHLmJRyWA8tY8Nks5uHnHEgaJpZM4SN00y\n.\n. Merged as 6c02812036ebf0036a0f34275796fda4ea083248. Thanks!. Merged as 60187e275dfe75dbb81ae1a8e6e4e2f86430196d. Thanks!. Served its purpose. Closing.. I wrote this bug so I can put up a patch. Thanks for reporting it @red1ynx.. This should be fixed by commit b49a29790293bb157e943a3c783c7d34062bfabe. Thanks for the bug report @red1ynx!. This was merged as ac17b4574068dca. Thanks for the PR!. @dadjeibaah, your patch looks pretty solid to me. Do you want to put it up as a PR?. Thanks @dadjeibaah! I'll try to take a look this afternoon.. This should make it out in the December release, likely the first part of dec.. I'm not sure if I agree with this change in log level since the library is modifying the users input on the their behalf. If you're explicitly performing non-compliant behavior maybe the right solution is to change the log level of that logger alone in your application?\n\nI'd also be interested in more opinions.. @dadjeibaah, I had speculated they were related. \ud83d\ude04 We'd love a PR for 739. Thanks for your help!. @adleong, seems like a bug. Are you interested in digging into it?. @dadjeibaah, it looks like you've run into https://github.com/netty/netty/pull/6862.. This was merged as ba578c1445b2e241687ad3c89eec4f3d93431a76. Thanks for the PR!. Hi @remi-thieblin-ck, thanks for the PR! Unfortunately we're still working through some internal issues to upgrading this, but we're 99% there.\nA few tickets to read for some background info:\nhttps://github.com/twitter/finagle/issues/665\nhttps://github.com/twitter/finagle/pull/678. Hi @monkey-mas, I'm new to this code so feel free to let me know if what follows is incorrect!\nI don't think that handle(res: Response) is called multiple times: it's responsible for writing the message to the wire so if it's called multiple times we're in big trouble. I do think you're right in that its going to be called after all the filters so in its current form, its a problem.\nIt sounds like the problem is accommodating people sending a 204 with a body. In the case of people sending a 204 without a body, the content-length header gets set to 0. Maybe what we can do is have handle look for a 204 response with a content-length: 0 header, and strip those from the response? That will make 'legit' 204 responses legal by rfc 7230, and give your filter a way to signal that the header should be stripped.\nTo make this happen, the single if statement on 96 (old) might turn into:\n``` scala\nrep.contentLength match {\n  case Some(0) if rep.status == Status.NoContent =>\n    rep.headers.remove(Fields.ContentLength)\ncase Some(_) => // NOOP: don't perturb explicitly set content lengths other than 204 with length 0.  \ncase None =>\n    rep.contentLength = rep.content.length\n}\n```\nThere might be a cleaner way to implement that logic.\nThe filter would then set the content-length headers for Status(304), set it to 0 for Status(204), and strip away the bodies.\n. TLDR: I've had some more time to think about it, and I'm not certain of an easy solution.\n\nUmm.. I think Content-Length header field is not set to 0 for a 204 response when there's no message-body. (But I think it's correct that the header field is added when we explicitly send a message-body, which is our problem here.)\nMore exactly, in the case of a 204 response with no body, rep.contentLength is None and rep.content.length is 0 I suppose.\n\nSorry, its not clear to me if we agree. I believe at a Response with an empty body will get assigned a content length header of length 0. I haven't added tags to the handle function to check, but a raw Response should not be chunked and will not have a defined contentLength, so line 97 (on master, maybe this is the source of our confusion) should set the content-length to 0 on a 204 response without a body.\nI don't think this can be solved only in the compliance Filter, there needs to be some coupling because, as is, the content-length is going to be set for non-chunked bodies regardless of status code. I personally would hate to make the HttpServerDispatcher aware of a single Filter, that just doesn't seem fair to the other filters. \ud83d\ude04  That suggests to me (and we should get @mosesn's opinion in light of what we've found) that this isn't actually a job for a filter. This feels more like the things that are getting delegated to the netty pipeline such as RespondToExpectContinue. \n. I would definately wayt for @mosesn to chime in before going down the netty pipeline route. As a preview, I'll give my understanding of it. The code at https://github.com/twitter/finagle/blob/develop/finagle-http/src/main/scala/com/twitter/finagle/http/Codec.scala#L307 gives an example of how the RespondToExpectContinue handler works, but it is an UpstreamHandler (I believe that corresponds to InboundHandler in netty4). The DownstreamHandler works essentially the same but in the other direction. In my minds eye, the DownstreamHandler intercepts the HttpResponse and drops the body and requisite headers.\nOne thing that occurs to me is that streaming responses (chunked) don't appear to be addressed in this commit. The way streaming responses are rendered appears more complex and might make using the netty pipeline more tricky, if even possible. For example, In the case of a 304 or 204 I doubt that we want to use the Reader, and instead we would want to discard it. I don't think that is a possibility, at least in the place I pointed you to above.\n. Could we remove the default and be explicit? Its private code so I don't see any reason to be ergonomic about it.\n. This is more of a question than a concern, but is an empty Host header meaningful and/or legal per the spec? Adding a link to any relevant RFC would be a good touch, if it exists.\n. I really like that you've added a timeout: it seems it has been omitted from the other test cases in the suite.\n. Reads a little strange to me. Maybe \".. Both rules are enforced even if users intentionally add body data or the header field for these responses.\" Maybe add something about logging violations as an error.\n. We are trying to phase out usage of netty types in our HTTP model so could we do a length check instead? Something like if (rep.length > 0) { would be good. That has the added benefit of avoiding the ambiguity of equality in Java (eg, does != mean reference equality here? I don't know...).\n. ffti: might be useful to say how many bytes were in the body. Then again, maybe not. \ud83d\ude09 \n. This doesn't cover the case of 1xx status codes that are not 100-Continue. Could we be inclusive of the whole range?\n. This has the same 1xx problem as above.\nMaybe this is worth it, maybe its not, but it seems to me that this pattern match could be reused with a special case for NotModified. Eg\nscala\nprivate def mustNotHaveLengthHeader(status: Status) = \n  status != NotModified && mostNotIncludeMessageBody(status)\nMaybe that is getting too convoluted, so use discretion with that suggestion.\n. Try to use .headerMap to remove netty types from the testing. It's also nice not to look for null in scala code. There are a few more instances of this below as well.\n. This could be response.length which is shorter and avoids netty types. A few more instances of this below.\n. I think we need a plan for dealing with chunked responses as well.\n. @monkey-mas: you make tests conditional like this:\nscala\ntestIfImplemented(FeatureName)(\"name\"){ assert(true) }\nand you set what tests are implemented using the functions like this one: https://github.com/twitter/finagle/blob/develop/finagle-http2/src/test/scala/com/twitter/finagle/http2/EndToEndTest.scala#L46.\nI think you already know how to define a feature flag.\n. Thanks for the clarification; this looks correct to me. By adding a link, I meant adding it as a code comment close to this logic in case others are interested in reading the spec in the future.\n. Could you add a test that verifies that the Host header isn't overwritten if its already present?\n. I know this spec is inconsistent in this regard, but could you add a timeout to this Await.result call?. The timing here is a bit tight and might introduce some flakyness in this test case. Have you seen our Time api that allows you to manipulate the current time? See Time.withCurrentTimeFrozen etc. It's what we commonly use in finagle tests to introduce some determanistic behavior for things that deal in Time and seems like it should be useful here.. I think the issue there is that InetResolver doesn't have a way to pass in a Timer and thus cannot use a MockTimer. It could be added as another constructor param, though that might not be worth it.. Since we're not actually using the magic time features, maybe the Time.withCurrentTimeFrozen( isn't necessary. Sorry for the misdirection.\nRegarding the latch, the addr.changes.toFuture call causes the polling event to get canceled after the Future resolves, so it never ticks a second time.  Do something to the tune of\nscala\naddr.changes.filter(_ != Addr.Pending).respond(addr => println(s\"Address: $addr\"))\nadjust your latch to 2, and the test should complete.. Fun fact: this has been broken for a while: we should not be reading a 4 byte int for the Int24 type, but only 3 https://dev.mysql.com/doc/refman/5.7/en/integer-types.html. This isn't a problem with this PR per say, just what we've been doing wrong for a while now.. I agree with @nepthar: I think a throw is fine in this case, although I don't know where that exception will surface off hand. Also, I think you need to make sure you write exactly 8 bytes and right now you will write less in the majority of cases:\nscala\nscala> BigInt(10).toByteArray\nres1: Array[Byte] = Array(10) // only one byte!. Sure, that or just pad with 0's via .writeByte(0x0).. Type.Int24 and TypeInt24 if signed need to call reader.readMediumLE() and reader.readUnsignedMediumLE(), respectively.. I think we need to reverse the order of the bytes we read out of byteArray: the BigInt.toByteArray method returns the bytes in big-endian order.. You're going to need to make an way to configure the Client to operate in 'support unsigned' mode. This will entail making a Stack.Param and threading the boolean all the way through. Which will be a bit of a pain, but it is what it is. I'd remove the default argument for the Row constructors since you're always going to have to pass it up from a higher level anyway.\nStack.Params can be a little convoluted at times (all times, really), so look at the HTTP implementation for an example here. The basic idea is to put typed 'params' (Stack.Param[T]) into a map where the stored items are typed based on the key (the T) and all params have a default.\nIt can then be configured using the pattern:\nscala\nclient.configured(SupportUnsignedInts(true))\n  .whatever(..)\n  .newService(..). Can we gate the size of the array to 32 if !traceId.traceIdHigh.isDefined. Otherwise, even if services are using the 64-bit trace-ids, they will need to have received this patch in order to support tracing.. Can we make a named case class to return these SpanId's instead of using a Tuple2? I would have expected the low bytes to come first, but it's just a state of mind thing so giving it a name would make it unambiguous.. Can you use the if / else block to form the whole SpanId instead of just the substring? That would make the match below unnecessary.. Why not Option[SpanId] instead of Long? Looks like your putting a Some(SpanId(0L)) into the TraceId.apply below due to this (same in Trace.scala). Is this the only situations where you would expect to find a SpanId of 0? If so, lets do _traceIdHigh -> traceIdHigh and remove the method: I know that case class is pretty hairy at this point but I'd prefer the generated unapply method to yield as accurate results as possible.. See comment above about removing this and just using the constructor param.. Not part of your change, but it's really disappointing that this is essentially a duplicate of TraceId.deserialize other than the bytes representation the function receives. Other than we cache a 40 byte thread-local Array[Byte] in this method, we could trivially forward it to the TraceId.deserialize function. \ud83d\ude1e This should be fixed later.. Do we ever feel that we're going to have even more bytes? If the protocol supports evolving by appending more fields, it would make sense to just ensure we have enough bytes but not care if there are extra at the tail that we don't understand. That said, I hope 128-bit is enough.. See comment above in Id.scala.. I'm not an expert, and this isn't part of this change, but I recall a comment by @adriancole saying that a span-id of 0 is not valid, but it's possible that this rng.nextLong() could give us a 0. Is that only true in the high bits?. An aside: this is so close to being id.copy(spanId = spanId) but I'm worried about the subtle differences in def traceId etc.. Also an aside,  but I'm surprised we don't have a TraceId.Empty instance laying about.. Treq is dead to us: its only used for backward compatibility so I don't think a TODO is necessary. A note that we're not going to support 128-bit trace id's in Treq is enough. If someone upgrades, which they'd need to do to support the 128-bit trace id's anyway, they are going to be using Tdispatch/Rdispatch which should get 128-bit via this PR. \nSomeone should correct me if this is not right.. Can we do this as part of this PR? Outside of Twitter, thrift is the most heavily used RPC protocol, so it would be a shame to not have it.. I agree that the naming is now confusing at best, but don't think its something that should be addressed in this PR. If we want to take the easy route out of this, how about SpanId128. Might want to rename the method as well, since it seems (at least to me, happy to hear why I'm wrong) that we're really dealing in span-ids.. For simplicity, I'd vote for looping while nextLong == 0. Another alternative, but one that is probably more work and not worth it, is \nvar spanId = ThreadLocalRandom.current().nextLong(Long.MinValue, Long.MaxValue - 1)\nif (0l <= spanId) {\n  spanId += 1\n}\nFWIW, it's still not clear to me whether 0 is even illegal.. We use old thrift, libthrift-0.5. \u2639\ufe0f . Maybe forward this to the named method:\nsuggestion\n        .withStreaming(enabled). Stray?. ",
    "selvin": "I see that this build failure is not a result of these proposed code changes\nerror sbt.ResolveException: unresolved dependency: com.twitter#util-core_2.9.2;6.18.0: not found\nat https://travis-ci.org/twitter/finagle/jobs/28439637\nand http://mvnrepository.com/artifact/com.twitter/util-core_2.9.2 does not have 6.18.0\nAny ideas on how to proceed?\n. leave a blank line above\ncomment text starts with a space after the '//'\nhere and everywhere\n. isn't it necessary to block? otherwise this thread ends and since all other threads are daemon threads, the program exits shortly thereafter\n. I think this section should be moved to the top (as the first sub-section of Usage) as this is what the typical use case will be\n. prefer to do log.error(...) instead of println(...)\n. log.error(...) instead of a println(...)\n. this text doesn't seem to align (perhaps indicates presence of a hard-tab)\nprefer to use all spaces in your code and no hard-tabs\n. Surprised to see email-headers are missing:\nhttp://tools.ietf.org/html/rfc2076\nhttp://kb.mediatemple.net/questions/892/Understanding+an+email+header\nAs a first step, it might be enough to offer headers as Seq[String]\n. ",
    "suncelesta": "Finally, everything seems passing, so I'll appreciate any feedback. I've also added cc, bcc and reply-to support - but still without attachments. \n. I added more comments and modified README, so now it should be more clear.\n. Thank you for all the comments! I've made some changes and updated README, so you can check it out.\n. I believe it was accidental due to a bug somewhere. Thanks for noticing, I must have missed that.\n. send and Future[Unit] come from Example.scala, where it all was copied from. I can make it more general.\n. This is just another way to handle errors. Should I comment that explicitly?\n. I intended UnspecifiedReply to be a 'protoreply', not classified yet, which is formed during decoding, and Reply to be a supertype for all final reply classes. Since final replies have the same characteristics as a protoreply, except they are classified, I made Reply a suptype of UnspecifiedReply.\nI will talk with my mentors on this matter and try to resolve such issues.\n. It seems I should clarify that these are two separate pieces of code, not a single program part.\n. That was what I meant, I just supposed that in practice the program would probably not end like this, but have something else done in background.\n. It doesn't. It returns Future.done in case of success. In case of failure it returns the first encountered error wrapped in a Future.\n. The logic behind this is such: you either send the email successfully, or there is some error that prevents it to be sent. The request type here is an email, not an SMTP command. Which of the many replies SMTP server sent during the mail session should be chosen to represent success in this case? Furthermore, even if you take 250 reply when mail data is accepted, it's still the only one to be expected in case of success, so is there any point in keeping that information?\n. A hello request identifies the client, and the RFC recommends that SMTP sessions are started with it. It can be moved to the connection phase in the dispatcher, though.\n. If you mean that email addresses should be checked to look like user@domain.com, this is done when constructing MailingAddress'es from them. I can add this type of requirement here too.\n. This was meant to be used for the possibility of integration with other email libraries, e.g. preparing email payload in javamail and sending it through finagle-smtp.\n. I do think that would be confusing. Also, this is an intuitive hint that cmd is precisely the text command that will be sent to SMTP server.\n. I changed that when I was working on the more complete version, should I also make changes here?\n. It is indeed correct, since dispatch() method returns Future[Unit], and this signal is returned by it. \n. It is used as a return value in dispatch() method (see the comment there).\n. Because the default charset for SMTP is 7-bit ASCII. This version doesn't implement any extensions dealing with 8-bit and binary data, it is to be in the next one.\n. I thought about making a wrapper for this library in the beginning but decided not to do that yet, so I commented this out and forgot to clean, sorry.\n. The problem is, when I put this in the dispatcher, nothing is actually sent at the end of the session. And the quit request must be sent before closing the connection.\n. The success replies to different commands usually have different informational strings, so for each command there is actually a specific success reply. Not all of them even have the same reply code. However, the email can be sent only if all the commands succeed. (Here, if one of the recepients is not accepted, the session is aborted, and the error pertained to that recipient is returned; for more flexibility there is Smtp client).\n. The first case. The session lasts until quit command is sent (and then the server closes the connection) or some connection error occurs.\n. isEmpty() here is the method of MailingAddress, not String, but I can add nonEmpty() too, if it seems necessary.\n. If we wanted to implement it the other way (constructing headers from fields, as there is access for fields and no access for headers - as far as I can remember, this is the case with javamail, for example), we would need to override it. Actually, it is much less cumbersome to make EmailBuilder an implementation of EmailMessage this way. \nHere collecting fields from headers is just more general, I think.\n. Yes, it is. For example: originator fields\n. Yes, when testing with SMTP server stub and looking at its logs, I found out that this request is not actually sent from dispatcher, so I sought the way to enforce service(Request.Quit) before service.close(deadline).\n. The definition of From field is this:\n   from            =   \"From:\" mailbox-list CRLF\nI understand it so that the name of this field should start with a capital letter.\n. OK, after some thought, I agree that it can be in dispatcher.\n. Yes, I must have missed that one, thanks.\n. OK, I believe you're right. I will transform all the headers to lowercase, then.\n. Done, you can check it.\n. According to wireshark:\n1. QUIT is sent\n2. Server responds\n3. Server closes connection\n4. Client closes connection\nSeems like what should be expected.\n. It is just to not confuse with methods from EmailMessage, but to allow composing email fields naturally, like to_(addr1, addr2). \nAs for varargs - I supposed that methods like setFrom should be used more like a way to prepend or remove addresses, so it didn't make much sense for them to take varargs.\n. I found out that I also forgot to change Example this way, I'll fix that.\n. Oh, sorry, I thought you were asking to check the behavior it has right\nnow, not with sending QUIT in the dispatcher. I'll check the latter, but I\ncan say that the server doesn't receive the request in that case, because\nin its logs the connection is torn down by client and QUIT isn't received.\n2014-08-11 18:45 GMT+04:00 Moses Nakamura notifications@github.com:\n\nIn finagle-smtp/src/main/scala/com/twitter/finagle/Smtp.scala:\n\n\n* Constructs an SMTP client.\n*\n* Upon closing the connection this client sends QUIT command;\n* it also performs dot stuffing.\n*/\noverride def newClient(dest: Name, label: String): ServiceFactory[Request, Reply] = {\n  +\nval quitOnCloseClient = {\nnew ServiceFactoryProxyRequest, Reply {\noverride def apply(conn: ClientConnection): Future[ServiceProxy[Request, Reply]] = {\nself.apply(conn) map { service =>\nval quitOnClose = new ServiceProxyRequest, Reply {\noverride def close(deadline: Time): Future[Unit] = {\nif (service.isAvailable)\nservice(Request.Quit)\nservice.close(deadline)\n\n\nWait, I thought you were saying that it wasn't behaving properly in the\ndispatcher? I think I got confused as to what was going on . . . I was\ntrying to reply to a message you posted that said,\nYes, when testing with SMTP server stub and looking at its logs, I found\nout that this request is not actually sent from dispatcher, so I sought the\nway to enforce service(Request.Quit) before service.close(deadline)\nbut I couldn't find the actual message (github swallowed it maybe) so I\njust put it here.\nIs the behavior correct now then?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/287/files#r16056704.\n\n\n\u0421 \u0443\u0432\u0430\u0436\u0435\u043d\u0438\u0435\u043c,\n\u0412\u0430\u043b\u0435\u0440\u0438\u044f \u0414\u044b\u043c\u0431\u0438\u0446\u043a\u0430\u044f\n. Ok, I've tried to use wireshark with QUIT sent in dispatcher, and it shows that the request is indeed not sent. The connection is just closed without even attempting to send it. Maybe I'm just doing it wrong? It appeared to me that I should override close(deadline: Time) method - is it right?\n. It's what I've recently pushed (look below), and it has correct behavior.\n. And in dispatcher the behavior is still incorrect when using ensure.\n. Here is what you suggested, I believe. Correct me if I misunderstood, I may have lost track of thought here.\n. Ok, I've created a new branch. Here are the changes for you to review.\n. ",
    "ZxMYS": "I dont have FutureIface. Instead I have ServiceIface, will the latter one work?\n. ",
    "adamdecaf": "Ah, my bad about the commit message. I must have missed that before. Should I go ahead and amend the commit? Also, do you want me to re-order the imports?\n. Alright, I fixed the ordering and my second commit should follow the guidelines. Thanks!\n. How's that?\n. I can grab finagle-http. \n. Looks easy enough. I got it.\n. Alright, MockitoSugar has been added. \n. Is that test failure something local to the server it ran on? I don't get that locally.\n. Updated, does it look better now?\n. Updated the PR.\n. Alright, I'll switch it over to that style.\n. Just to make sure I'm reading this right you're saying to just run the code in Context, rather then newing up the class? Shouldn't the block in the class be ran upon instantiation?\n. ",
    "bajohns": "I can take finagle-thrift and finagle-stream. \n. Hey @alexflav23 - my changes were merged and released publicly Oct 15th.  \nThanks again to @mosesn, @stevegury, @bmdhacks and @travisbrown for moving the changes through.\n. Hey @mosesn - would you mind updating the package status above?  I know finagle-thrift and finagle-stream are done and based on this thread it looks like finagle-kestrel is also done.\nThanks!  cc @travisbrown \n. Perhaps this is already known - but finagle master isn't build-able right now due to Ostrich 9.6.1 not being published.  Can you push that to github and publish?\nSorry to pile on with requests!  And thank you for updating the other packages for 2.11!\n[warn] ==== public: tried\n[warn]   http://repo1.maven.org/maven2/com/twitter/ostrich_2.10/9.6.1/ostrich_2.10-9.6.1.pom\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]  ::          UNRESOLVED DEPENDENCIES         ::\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]  :: com.twitter#ostrich_2.10;9.6.1: not found\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n. Thank you @travisbrown and all the others who pushed this forward.  This is an important step forward for many of us who depend on finagle.\ncc @mosesn @stevegury @bmdhacks \n. @mosesn - In issue #290 you mentioned testing 2.11.x compatibility but I have not seen a published 2.11 version of twitter/util.  \nShould I use falone/util - and publish-local - to test 2.11?\n. @mosesn - I completed the specs -> scalatest conversion for finagle-thrift and finagle-stream.\nPlease let me know any feedback you may have so I can rebase the work into a set of final commits that conform to the commit standard.\nLastly, I came across two issues that I would like some more input on:\n1)  finagle-thrift has test functionality in ThriftTest.scala that seems useful and is marked flaky.  I uncommented parts of it and migrated it to checking an environment variable to determine whether to run or not. Based on other tests, this looks like the new convention for dealing with tests that have intermittent failures.  Please see this commit: https://github.com/bajohns/finagle/commit/1531023e44d86200522c2aeb56e9252c992e9acb\n2) I have not found a good solution to replace the specs2 matcher must beLike.  It is used a number of times in finagle-thrift and in a nested fashion in finagle-stream specs scalatest .  Please let me know if you have other methods for migrating that construct.\n. Hey @mosesn, no rush I see there is a lot of activity around these change sets.  Thanks for all your work to accept contributions!\n. @evnm  - Thanks for reviewing.  All comments handling in next commit: https://github.com/bajohns/finagle/commit/255983d5fbbc95880d77c60340ece7d0521eb9aa\n. Looks like the build failed only for artifact resolution.  Rebuild should clear it out.\n[error] (finagle-commons-stats/*:update) sbt.ResolveException: download failed: com.google.inject#guice;3.0!guice.jar\n[error] Total time: 11 s, completed Aug 4, 2014 2:04:13 AM\n. I am going to take care of the feedback this weekend.  I am more than willing to convert the tests from OneInstancePerTest to the context object - this would make the changeset larger.  The specs default behavior is OneInstancePerTest-like so the shortest path forward was OIPT.  \nUnless I hear otherwise - I will do the work to migrate this from OIPT -> Context object pattern.\n. @mosesn - finished reviewing your feedback.  Please confirm that my changes meet your expectations.  \nRe: ignore showing up for flaky - here is the test output https://gist.github.com/bajohns/e1a03cad4b401ae5fd83\n. Great to hear - would you like me to squash commits down to a single?  That was my plan to conform to the commit message standard.\n. Took care of feedback from @evnm  \nI will create a final pull request based on these commits.\n. Squashed and rebased against current master - the complete work in one commit is here: https://github.com/twitter/finagle/pull/308\n. Looks like the other was used for internal merge. Closing this. \nThanks again @mosesn and @evnm\n. This pull-request contains a body of work which was reviewed by @mosesn  and @evnm  here: https://github.com/twitter/finagle/pull/291\n. Hey @mosesn, Thanks for the ping - this did get lost in the shuffle. \nGiven that the feedback was small I committed by amending.  Please let me know if this version works better re: comments from @stevegury \n. @evnm  - These are skipped because they break.  I am unclear whether they should be deleted or left to pass later (with future dtab work).  \nPlease advise.  Failures output here: https://gist.github.com/bajohns/7f9c4db337164e6a0faf\n. Let me see if I can make a function that combines test/ignore and observes SKIP_FLAKY.  This should be possible\n. ",
    "chester89": "Can I take a shot at finagle-kestrel?\n. What should I do with tests marked as deprecated? Should I convert them too?\n. Guys, finagle-kestrel is on me, I apologise for not reporting for so long.\nWhat I managed to do is to port 99% of the code to ScalaTest, and it does compile - but many tests fail because I somehow screwed up asserts on collections. \nLet me post the code I have tomorrow - and may be someone can help me finish it.\n. Send a PR with what I've got.\n. great! will do\n2014-08-15 18:29 GMT+04:00 Pierre-Antoine Ganaye notifications@github.com:\n\n@chester89 https://github.com/chester89 I've converted all tests except\nReadHandleSpec take a look\nhttps://github.com/p-antoine/finagle/tree/master/finagle-kestrel/src/test/scala/com/twitter/finagle/kestrel\neverything works.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/290#issuecomment-52311801.\n\n\n\u0421 \u0443\u0432\u0430\u0436\u0435\u043d\u0438\u0435\u043c,\n\u0427\u0435\u0440\u043c\u0451\u043d\u043d\u043e\u0432 \u0413\u043b\u0435\u0431,\n\u0442\u0435\u043b. (916) 314-9324\n. @p-antoine just to clarify - as you've ported the code, you're making the PR later, right? \n. I'd prefer you finish it, since you're MUCH closer to the result\n. Guess I can close than one\n. ",
    "elbiczel": "I'll start working on scrooge-core early next week. Is there a separate\nissue for scrooge?\n2014-08-15 17:39 GMT+02:00 Moses Nakamura notifications@github.com:\n\nOh hey, you're right! Looks like @dhelder https://github.com/dhelder\nremoved specs from scrooge already, nice!\nFor scrooge, we need to update dependencies, but finagle is one of the\ndependencies (finagle depends on scrooge-core, scrooge-runtime depends on\nfinagle, it's a mess but luckily not a cyclic dependency).\nWe'll also need to update scrooge-core to cross-publish against 2.11, and\nit would be great to rename all of the Spec.scala files to Test.scala,\nand similarly rename the tests.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/290#issuecomment-52320210.\n. \n",
    "WamBamBoozle": "\ndeprecating the bits that depend on util-eval\n\nwill util-eval be deprecated? Will it not be supported in scala 2.11?\nOn Sat, Aug 23, 2014 at 10:02 PM, Moses Nakamura notifications@github.com\nwrote:\n\nRad! Very exciting. I'll see what we can do about deprecating the bits\nthat depend on util-eval.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/issues/290#issuecomment-53178603.\n. \n",
    "mauricio": "Hello everyone, I'm unsure of what's missing here? Which projects still need someone to pick them up?\n. ",
    "alexflav23": "@bajohns @mosesn Any news or upgrades? We would happily offer more man power as we have a whole family of products, all running atop Finagle, that are waiting for this release.\n. @p-antoine Happy to help with any util-eval or ostrich changes as much as possible, let me know if there's anything I can do.\n. @mosesn I'm very happy to help out with the testing, I'm sure we can easily do that and share stats!\n. @mosesn Being equally excited about the complete move to ScalaTest for Finagle, I keep wondering if there is any argument against using AsyncAssertions to asynchronously wait for results and ScalaTest support for running individual specs in parallel.\nIs there any interop or legacy concern to consider? The outcome would be a massive drop in total test time(> 60%).\n. @mosesn Makes perfect sense, I will continue this on the mailing list. The speed up comes from running every spec(not every file) in parallel and not blocking for results. Examples to come on the mailing list.\n. ",
    "dnatic09": "Great news and work by the contributors.  I look forward to using Ostrich in 2.11.\n. Any chance there has been an update to the 2.11 effort?\n. @travisbrown  thanks for your time and contributions!\n. I know there are a few people on here waiting for Ostrich to run under 2.11.\n. @travisbrown , is Ostrich 2.11 on the roadmap too?\n. ",
    "fringedgentian": "@mosesn  Hello! I am upgrading our app that uses finagle-memcached to Scala 2.11 and I just wanted to see if I am missing something or it isn't quite ready for that yet?  (looks like not ready according to this thread)\n. ",
    "c089": "Sorry to bug you folks but this issue hasn't seen an update in weeks. Any specific issues I could help with by investing some development time?\n. @travisbrown thanks for getting back on this, appreciated. Personally I'm waiting on finatra, which in turn depends on finagle-http.\n. ",
    "kelf": "We are waiting patiently for thrift/core.  Really appreciate all the hard work. \n. ",
    "StefanGheorghiu": "We've also been waiting for half a year. The only library preventing us from migrating to 2.11. Please-please-please...\n. ",
    "folone": "Great news, thank you folks!\n. @mosesn That does look very interesting, will look into that. I'll mark this PR as WIP in the meantime.\n. @mosesn I've opened a PR in the bijection project: https://github.com/twitter/bijection/pull/197.\nClosing this one.\n. that's right, sorry for that. fix is coming in a sec.\n. ",
    "hgfischer": "Hello,\nI would like to know the status of the remaining packages/modules that needs to be updated to Scala 2.11.\ncheers\n. ",
    "ckampfe": "Any movement on finagle-redis?\n. @penland365 @mosesn no worries at all and sincere thanks for your hard work. Was just curious!\n. ",
    "csaltos": "Thank you @penland365 and @mosesn for your work. Looking forward for finagle-redis for Scala 2.11.\n. Hi @travisbrown and @mosesn thank you for your messages and support.\nTwo weeks ago we rolled out our first Finagle microservice at Talenteca. We decide to begin with a simple service like our URL shrinker tool (talenteca.com -> tltk.co), so we migrate from Spray/JSON to Finagle/Thrift and it's working amazingly great !! ... we are suporting 10 times more concurrent connections and the memory usage drops a lot too. The CPU usage increased but that's OK for us, actually we like to keep our CPUs hot, AWS does not charge us extra for CPU high usage !! ;) :)\nToday, as I write you these lines our second Finagle microservice is being rolled out at Talenteca. We decide to migrate a more ambitious server and we choose our newsletter service to migrate, so we are migrating from Spray/JSON to Finagle/Thrift and this time we also are adding Finagle/Redis for the newsletter subscription/unsubscription features. Once again the performance improves a lot and beyond of that the code is very clean and straightforward, we love that, it's truly a joy.\nFinagle is an excellent software and we decide to migrate all of our Spray/JSON services to Finagle/Thrift in these coming months and the new backend developments we have we are going to do it directly with Finagle.\nI will let you know how is the roll out of today going, so wish us good luck !! ;) :)\nOnce again thanks for your support and for Finagle, thank you for sharing and make Finagle available Open Source.\n. ",
    "davydkov": "@penland365 @mosesn Hey guys, are there any updates on finagle-redis?\n. ",
    "maciejjaskowski": "Any chances for this PR being merged ?\n. ",
    "stantonk": "@travisbrown updated the commit\n. cool, thanks @travisbrown \n. yup, added\n. ",
    "kashif": "great thanks! @mosesn I am learning how to write tests at the moment and the way to wrap and unwrap the codec. I will let you know in a day or two of any issues I am having...\nThanks again!\n. ok @mosesn can you kindly help me a bit... I get a\n...\nEVAL Expected 3 elements, found 7 (Command.scala:9)\n...\nfailure which means I am not parsing the command properly. The script's EVAL is a bit special since it take in a script as a string followed by numkeys number of keys and then the args... so not sure how to parse that? Any idea? Thanks!\n. ah damn so sorry... will rebase and have a look\n. thanks @mosesn  I have a question: how to I escape the quotes when wraping and unwraping strings?\nThe EVAL command needs a string as its script:\neval \"return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}\" 2 key1 key2 first second\nbut when parsing it, I get an error since it thinks that \"return  is the first argument... \n. @mosesn ah great I will try it out after dinner thank you!\n. @mosesn I seem to now get an error:\n...\n[error]         x EVAL\n[error]           Unsupported command:  (Command.scala:270)\n[error]           com.twitter.finagle.redis.protocol.Commands$$anonfun$doMatch$2.apply(Command.scala:270)\n...\nwhich might suggest that the parsing is now setting the command to just empty?\n. all the stuff i have done till now is pushed here... I just added in your patch and tried to run the test:\n$ ./sbt finagle-redis/test\n...\n. great that works! I will now add the rest of the SCRIPT commands\n. ",
    "soboko": "Sure, we're using it in all of the JVM-based backend services for our\nconsumer product. We use a mix of Scala and Java. We adopted Finagle when\nwe replatformed this product in early 2013.\nOur services are Thrift-based and we use Thrift 0.9.1. We've had to modify\nscrooge a bit to support that version of Thrift. We make use of server sets\nas well and we've written a nodejs integration for that since we have some\nnodejs services as well.\nI'm trying to convince the company to open source these. Wish me luck on\nthat - I only have a week left before I move to a new job :)\nOn Aug 1, 2014, at 20:08, Evan Meagher notifications@github.com wrote:\nMay I ask in what capacity you're using Finagle?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/297#issuecomment-50952385.\n. ",
    "takc923": "Sorry, above \"Steps to reproduce\" is wrong (I didn't know the order of main list wasn't fixed).\nCorrect \"Steps to reproduce\" is here\n1. sbt \"project finagle-example\" \"run-main com.twitter.finagle.example.stream.StreamServer\"\n2. curl http://localhost:8080/ from another terminal and Control-c to disconnect.\n. @luciferous Now I'm using older version finagle-stream, and this issue prevent to upgrade finagle. If this will be resolved, I wait it and upgrade. However if it is difficult to resolve, I try to use finagle-http directly.\n. @luciferous I just didn't want to take time to modify my code to use finagle-http. However It seems better to do it. I consider using finagle-http directly. Thanks for your advice!\n. ",
    "adam-singer": "@mosesn found another nit in documentation. Adding to this PR. \n. @travisbrown done\n. @travisbrown np, I can squash the commits if this is to be accepted. \n. ",
    "groestl": "I'm actually puzzled what LoadService is trying to find in the /sys filesystem (which probably is an edge case for every directory traversing algorithm). Is LoadService touching the whole /?\n. ",
    "jdneumeyer77": "I encountered a similar problem after upgrading to 6.22. When starting tomcat with \"service\" command, i.e. service tomcat7 start, the war would hang at initializing finagle. Producing a threaddump, I found a similar stacktrace as OP. However, when using /etc/init.d/tomcat7 start; it would not hang. Service sets the current working directory to '/'; so, it would hit /sys and get stuck in '/sys' loop (pcspkr for me...). The daemon init.d scripts would use whatever directory you're currently in. Running the init.d script from '/' will cause the same problem.\n. ",
    "andi5": "It is part of com.twitter.finagle.tracing.Flags, marked with \"Reserved for future use to encode sampling behavior, currently encoded explicitly in TraceId.sampled (Option[Boolean]).\"\nStill, it is used in com.twitter.finagle.tracing.TraceId.serialize and put into the bytes array.\n. We are using thrift services, pretty standard Twitter code. Say, TraceId.serialize sends flags == 2 (SamplingKnown, but not Sampled). TraceContext.handle will read the flags and set sampled correctly, but it also keeps the flags (2) in the new TraceId instance. Now, Trace.isActivelyTracing seems to mismatch, as flags (2) != 0.\n. Sorry, did not have the time to provide a patch or test fixture, but wanted to have it reported.\n. Should fix #310 \n. ",
    "vargasbo": "Followed the breadcrumbs :) I need to implement an api stream for clients on play framework (scala,  websockets). I've used GNIP api before and like how the client side worked. Wanted to mimic that work for my clients plus a few more enhancements. Investigating I found a code snippet that mention finagle. Code was very clean and the rest is history.\n. ",
    "akwangho": "@mosesn The new patch works for me. Thank you!\n. ",
    "orrsella": "@mosesn No worries. Let me know if you want me to do anything.\n. ",
    "dlwh": "Thanks!\n. I'd say close when http://twitter.github.io/finagle/guide/FAQ.html#how-do-i-configure-clients-and-servers-with-finagle-6-apis no longer uses https://twitter.com/ as an example.\n. ",
    "whiter4bbit": "yes, I think, I can share example bit later, regarding messageReceived - this method invoked during upstream handling (for incoming message) and can never be FileRegion, sinceFileRegion can just transfer data to WritableByteChannel, but not read from 'readable' one.\n. was out of time, I will try to 're-implement things in way that @trustin proposed\n. Created new PR: https://github.com/twitter/finagle/pull/355\n. any progress on this?\n. ",
    "raultang": "new Thread(new Runnable {\n    override def run(): Unit = {\n      val client : Client = Redis.newRichClient(\"192.168.0.96:6379\")\n      while(true) {\n        client.get(StringToChannelBuffer(\"111\")).onSuccess( response => {\n          println(CBToString(response.get))\n        }).onFailure( error => {\n          println(error.getMessage)\n        })\n//        TimeUnit.MILLISECONDS.sleep(1)\n      }\n    }\n  }).start();\nThis will block after several times print , is it really have limit there and how to configure?\n. All right, it is because GC is full , seems client use quit a lot memory.\n. ",
    "alexandrnikitin": "With pleasure :bowtie:\nPushed to https://github.com/alexandrnikitin/finagle/tree/issue333_docs_brokenlink\nBut I get the following error while doing unidoc step, not sure what's it:\n[info] Generating Scala API documentation for main sources to C:\\Users\\a.nikitin\\Documents\\Projects\\\ncontribution\\finagle\\target\\scala-2.10\\unidoc...\n[error] C:\\Users\\a.nikitin\\Documents\\Projects\\contribution\\finagle\\finagle-kestrelx\\target\\scala-2.1\n0\\src_managed\\main\\com\\twitter\\finagle\\kestrel\\net\\lag\\kestrel\\thriftscala\\Item.scala:23: Item is al\nready defined as object Item\n[error] object Item extends ThriftStructCodec3[Item] {\n[error]        ^\n. Fixed by #334 \n. ",
    "vicentealencar": "@luciferous thank you for responding. What I am actually trying to do is to use the Request object along with an endpoint instance in test cases. E.g.:\nscala\nval service = endpoint.toService\nval request = Request(\"/books\")\nrequest.method = Method.Post\nrequest.content = copiedBuffer(s\"\"\"{\"title\": \"hello world\"}\"\"\", UTF_8)\nrequest.setContentTypeJson\n// requests always got rejected without the line of code below\n// request.contentLength = request.length\nAwait.result(service(request)).status shouldBe Status.Ok\nBy applying the Request object we get a MockRequest back, which inherits from the Request abstract class. Given that MockRequest was created for testing purposes, would it make sense for the content-length header to be automatically set in MockRequest instances (instead of setting it automatically in all Messages instances as I initially proposed)?\nIt just took me a long time to figure this out and I thought we might want to avoid others from going through it.\n. Guys, sorry I didn't follow up on this. I will try out what @luciferous suggested and will follow up.\n. ",
    "blackicewei": "I merged this. \n. LGTM.  @zfy0701, can you resolve Moses's comment? I will pull it in afterwards.\n. ",
    "teodimoff": "Guys, whats wrong with Request, Response types?\n. ",
    "tonyd3": "Problem\nThriftClientBufferedCodec class extends ThriftClientBufferedCodec, so when we call ThriftClientBufferedCodec.get() it actually returns ThriftClientFramedCodec\nSolution\nImplement get function in the ThriftClientBufferedCodec object so that it returns ThriftClientBufferedCodec.\nResult\nYou should be able to call ThriftClientBufferedCodec.get() and return a correct value, which is very useful for Java development.\n. I actually haven't tried it in scala, but in java here is the problem I encountered. \nClientBuilder.get().codec(ThriftClientFramedCodec.get())\nThis give me the correct codec.\nbut when I tried \nClientBuilder.get().codec(ThriftClientBufferedCodec.get()) \nit actually uses the get function in the ThriftClientFramedCodec object because the get function doesn't exist in ThriftClientFramedCodec. The apply() function works and returns the correct codec, and that's what I have now. \nI haven't tested if it's the same issue in scala, but I guess even if it is, it doesn't come up because people never call the get function.\n. ThriftClientBufferedCodec extends ThriftClientFramedCodec. So since ThriftClientBufferedCodec doesn't have it's own get function, ThriftClientBufferedCodec.get() calls its parent's get(), which returns an instance of ThriftClientFramedCodec.\n. ping, any updates on this change?\n. Thanks Kevin!\n. Thanks!\n. The reason why was I wanted to use RedisClient was because of it extends DefaultClient, which has a custom endpointer. I can of course re-write that wrapper, but I thought It would be helpful to have it in the finagle code.\n. For context, check this thread. https://groups.google.com/forum/#!topic/finaglers/7CZkQOemhp4\nThe last comment, Sanjay's is what I'm trying to solve. We use the old client builder api because we can customize it better. The problem is that the built client won't have the pipeline, as mentioned in Marius' comment. We want to integrate the built client with pipelining provided in RedisClient. Right now, internally we basically duplicate the code provided in RedisClient and RedisTransporter. Ideally we'd like to be able to just call RedisClient.newRichClient(someService), and get the same result.\n. I think we're probably missing something really obvious. I was wondering if you can advise on how to convert the following code snippet to use the new finagle api. \nJava Code:\n``` java\n  public static ClientBuilder<\n      Command, Reply, ClientConfig.Yes, ClientConfig.Yes, ClientConfig.Yes> redisStubBuilder(\n      String name, ServerSpec serverSpec) {\nfinal ClientBuilder<Command, Reply, ClientConfig.Yes, ClientConfig.Yes, ClientConfig.Yes>\n    builder = ClientBuilder.get()\n    .codec(Redis.get())\n    .hostConnectionLimit(redisConnectionsPerHost.value())\n    .dest(serverSpec.toFinagleString())\n    .name(sanitizeName(name))\n    .failFast(useFailFastByDefault.value())\n    .retries(redisDefaultRetries.value())\n    .tcpConnectTimeout(Duration.apply(5, TimeUnit.SECONDS))\n    .timeout(finagleDurationFromAirliftDuration(redisTimeout.value()))\n    .reportHostStats(defaultFinagleStatsReceiver)\n    .reportTo(varzAndFinagleStatsReceiver)\n    .logger(logger);\n\nreturn builder;\n\n}\npublic static Client redisClient(String name, ServerSpec serverSpec){\n    Service client = ClientBuilder.safeBuild(redisStubBuilder(name, serverSpec));\n    return RedisClientWrapper.newFinagleRedisClient(client);\n  }\n```\nour Scala Wrapper:\n``` scala\ntrait FinagleRedisClient { self: Client[Command, Reply] =>\n  def newFinagleRedisClient(raw: Service[Command, Reply]): com.twitter.finagle.redis.Client =\n    com.twitter.finagle.redis.Client(raw)\n}\nobject RedisTransporter extends Netty3TransporterCommand, Reply\nobject RedisClientWrapper extends DefaultClientCommand, Reply)\n  .configured(MaskCancelFilter.Param(true))\n  .serveIface(\"0.0.0.0:\" + port, serviceClass)\n. created against the wrong branch.\n. In this case, just max effort. \n. @vkostyukov just a busy day dealing with some other stuff, will get to it tonight or tomorrow.\n. added test\n. updated\n. Done\n. I think calling tokens.tail on an empty seq throws an UnsupportedOperationException(\"empty.tail\")\n. Done\n. ",
    "fommil": "I'm just amazed that you have this many stats packages...\ncom.twitter finagle-commons-stats_{scala_version_base} {finagle_version}\ncom.twitter finagle-stats_{scala_version_base} {finagle_version}\ncom.twitter util-stats_{scala_version_base} {twitter_version}\ncom.twitter.common stat 0.0.39\ncom.twitter.common stats 0.0.98\ncom.twitter.common stats-util 0.0.49\ncom.twitter.common stats-provider 0.0.66\ncom.twitter.common stat-registry 0.0.35\nit really did cost me most of the day to work this out. I wish that the responsibility of resolving these things lay firmly with the person who choose to go intransitive in the first place. But, alas....\n. I think our biggest problem this time around was the commit that changed how the ServiceLoader worked. By aggressively loading things on startup, it dramatically increases the number of jars that are required for a minimal intransitive setup. We got stung big time. This probably isn't even an issue for people using transitive dependencies because everything is already there (all several hundred MB of it :stuck_out_tongue: )\n. I'd rather bash the intransitive advocates over the head with a big stick\n. ",
    "williamboxhall": "Nice one @folone ! Also agree Bijections could be nice too\n. ",
    "mrvisser": "I've just found Travis' ScalaTest conversion seems to address this as well https://github.com/twitter/finagle/pull/331 but it's not clear the timeline on that. Would recommend just closing this PR without merge in favor of not delaying his w/ more merge conflicts.\n. ",
    "takei-shg": "Thx, @travisbrown !!\n. ",
    "LithiumTD": "Alright, i will modify the code to use the \"GlobalFlag\" instead of the extra method in the LoadService companion object. Will update the pull request asap :)\n. Test added and GlobalFlag used for updating the ignoredPackages. Hope this works for you guys :)\n. Hi,\nThanks for bumping this. There is already a new finagle release and having to custom patch each release is becoming an overhead. We still require this feature and we are simply working around at the moment.\nThanks :)\n. Hi,\nThanks a lot for your response. Besides the questions that i had on how i would actually use the GlobalFlag (which is quite important since it would be pretty lame if we can't use something that we set out to do from the start) and the advanced test that Steve wanted to see for this feature i do not see any problems.\nI will organize the imports and submit the request again but i would be grateful if someone could help me out on how i can programmatically set the GlobalFlag in my application.\nCheers !\n. Yeah i know i used let :) But the problem is that let only stays for statements within the let block. I tested called to some outside code for example placing my application's bind call inside a let. But the let only holds true as long as i have the check inside the class where i used my let. But as soon as it went inside one of the twitter resolvers, the ignoredpackages wasn't what i set it to be anymore. Maybe you could shed some light on this or maybe i am just using it in the wrong way.\n. Alright, so a bit of detail about the problem that we face.\n- We use the thriftmux clients from finagle and use the zkResolver to do our binds.\n- As you know the zkResolver (and others as well) internally call LoadService which then scans our directory structure for the application for possible custom resolvers.\n- We have a really huge FS mounted on one of the folders in our application root where the LoadService gets stuck every time that we tried to do the bind (which didn't cause any problems on local system tests).\n- So now we would like to add that directory as an ignoredPackage (which we currently have by using a custom finagle library with that folder hard-coded in the class)\nProblem is that when i try to use this GlobalFlag solution and place the bind call within a let block, as soon as the control moves out of the class which contains the let block, the ignoredPackages does not reflect what i set in the let block. So i need some means to actually set the GlobalFlag 'globally' for my application. Since we don't use a full fledged TwitterApp, the CL solution would not work out for us. It would be great if you could suggest some alternative to this or correct me if i am using the let in some incorrect manner :)\nCheers !\n. The reason i wanted to avoid using Java system properties or command line flags was because we use this component as a part of a bigger application where this is just included as a jar file. If i did want to add some argument, i would have to get it added on the java start scripts for that application (which involves convincing sysadmins to change something which is never easy :) ). But, i will try it anyway if there isnt another way to get this set programmatically application wide.\nThanks for your help. Will get back to you with an updated patch soon :)\n. Alright guys, I am done with the organizing of imports and rebasing of the branch. Please let me know if there are any further changes required. Also, i managed to place some java system properties in our server code somewhere and it worked like a charm so the fix works out fine for us :)\nCheers !\n. Hmm, i should have seen that comment of yours :)\nLet me just change it real quick then. You did mention it should not have a huge impact on performance.\n. Yeah makes sense :)\nWill get this done right away.\n. This method was done as suggested along with adding of the val for the default ignored packages. We are not sure how much of a performance hit it would be to calculate this as a def on each call but this would definitely ensure no regressions as well as avoid any explicit method calls etc to update them.\n. I tried to run a test with the requirements you specified. For some reason, even though the addition of the package \"com.twitter.finagle.util\" to the list of ignoredPackages used in the browseUri it still seemed to pick up the LoadServiceRandomInterfaceImpl with the LoadService. Perhaps i am missing something here :)\n. test(\"LoadService should ignore packages according to ignoredPaths GlobalFlag\") {\n  ignoredPaths.let(Seq(\"com.twitter.finagle.util\")){\n      assert(LoadServiceLoadServiceRandomInterface.isEmpty)\n   }\n }\nI used a similar LoadService call as done for the Announcer above so i assumed this should ignore things within the package. However it did return an object. I even tried it with directory notation with \"com/twitter/finagle/util/\" with the same result.\n. I suspected it could have been something of that sort so i had commented out all previous tests and ran only the one i wrote but with the same results. Regardless, i would need to look into this and see how i can work around it (probably trying to use the methods you mentioned).\n. Alright, so after further investigation as to why it was not picking up classes as expected based on the ignoredPackages, i tried the new Classloader as Steve suggested but that also yielded the same result.\nI, however, did stumble across some interesting information. Several classes like Resolver, Announcer, LoadServiceMaybeInterface and LoadServiceRandomInterface were actually being picked up from \"META-INF/services/\" and then the getName for those files contained their fully qualified names such as \"com.twitter.finagle.util.LoadServiceRandomInterface\". Therefore, the only way i was able to exclude it from the LoadService scan was to add \"META-INF/services/\" to the ignoredPaths via the GlobalFlag.\nI am not sure if this would be very readable test unless i add some sort of explanation there but if you have any idea as to how i could have a more straightforward test, it would be most appreciated.\nOn a not so related note, i was wondering if you could tell me how i could use the GlobalFlag programmatically in my application. Setting it via command-line args isn't really possible for us since we do not really use this as a complete Twitter App. We directly start up the Thrift/ThriftMux clients and this LoadService is simply a by-product for the scan for Resolvers when we try to do a bind. It would be nice to know if there is some way to set GlobalFlags within the code (besides the let() method).\n. ",
    "gheo21": "Hello, \nWill this pull request get merged? We are facing the same issue. \nThanks!\n. ",
    "spockz": "@travisbrown: The contributing document states to create a pr against master. (https://github.com/twitter/finagle/blob/master/CONTRIBUTING.md)\n. @dschobel, no I was just running it with my local sbt. I that the wrapper uses the prefer IPv4 flag which also should fix the issue.\n. @travisbrown: done and noted. :)\n. Allright, but I think the backwards compatibility argument still holds.\n. @mosesn: Added the commit per request\n. Should we/I add an extra extractor to match on a Response as well? Maybe in a different PR?\n. When running the example application as provided I see \"CLOSE_WAIT\" states as well with lsof -i :8080. Full output here. \nEdit: Also, when just returning a success message I see far less open connections and they don't enter the \"CLOSE_WAIT\" state. Output\nEdit2: When explicitly closing the reader and the message all connections are in a CLOSE_WAIT state, no requests get handled anymore. Output.\nCode:\njava\nresponse = Await.result(service.apply(request), Duration.fromMilliseconds(\nresponse.reader().discard();\nAwait.ready(response.close(), Duration.fromMilliseconds(200));\n. Correct me if I'm wrong, but I think the netcat and Finagle examples don't close the connection whereas the Spring-Boot server closes the connection.\n. How then do you explain these CLOSE_WAIT. I discarded the reader there. Granted I see a lot less connections than without but they are still there. Also the 200 OK responses contained the string \"Good\" and thus there was no empty reader.\n. I can confirm that consuming the whole reader as done in https://github.com/mritman/finagle-not-closing-sockets/pull/1 solves the issue.\n\nI think it's also a bug that content / getContentString don't actually drain the reader. The intent is to avoid blocking on io, but I think we should instead make it clear that getContent is only safe to call on unchunked content, or when you don't mind if you block.\n\nI think it is pretty clear from the signature that it is a blocking call (or that it returns what it already received). Perhaps Response values that are chunked shouldn't have a getContent? In other words, using a Streaming client is a conscious decision of the developer that has to be reflected in which methods he can use?\n\nMy suspicion is that the reader constitutes a read handle, and that we don't want to cut the read handle prematurely, so that it can still read whatever is in its socket buffer, so 3 makes sense, but 1 and 2 less so.\n\nIf we can still read from the socket when the connection is already closed that means that the contents are buffered somewhere on the machine. Thus, it might not be so bad to pull the contents into the finagle layer when the connection is closed. If we do that the connection can be closed without losing data.\n\n@mritman @spockz For what it's worth ..\nI agree with that we should prevent connections to be closed on errors. I'll investigate where these things occur and why. Perhaps there are good reasons for them.\n. Yes @vkostyukov, I'm willing to give it a try. However, this week and weekend is swamped with courses and working at my home. @mosesn linked to a commit in the gitter room. I'll check whether that makes sense tomorrow. (It's a bit later here.)\n. FYI: This is the commit @mosesn mentioned.\n\nhttps://github.com/twitter/finagle/commit/b9b222cb5877b8c4faca755ce9d9f947024ab638#diff-8b7c2f5a15bf6822a18ff662cb633bdcR88\n. I've created a gist with my on-going work. It doesn't compile yet.\n. @vkostyukov I'll try to get my code up today.\n. The code is up in #555. :)\n. @mosesn I understand the need to maximise the success rate. However, we should consider both connection errors and responses classified as errors equal for sake of simplicity and understandability.\nTaking this into account, the current situation is counter intuitive. I would expect that when there are two nodes, where one of which is marked dead, that all traffic should go to the healthy node. \nHowever, and this is tested with 6.34.0 and 6.36.0, in my test, I have one server that returns Forbidden and another that returns 200 OK. The response classifier considers Forbidden to be a failure.\nWhen running the test, I see a log message saying that a node is marked dead. However, I see both servers receiving load after that initial response from the error server. I've seen the following ratios of error/ok responses: 16/84, 3/7, 29/71, 7/93. The log-message makes me expect that the node isn't used anymore as it is marked as dead as do the metrics. However, it still receives messages. (PS: Delaying requests a bit instead of firing all requests at once puts the ratio at the expected 1/99 consistently.)\nMoreover, there should be a way to observe that all your instances are considered dead based on the response classifier because it means your service is broken and you need to act. One can monitor for FailedFastExceptions to see whether there are no instances available to connect with but whether applications are failing on a functional level cannot be observed.\n``` scala\n\"the responseclassifier\" should \"cause traffic to go to the healthy node\" in {\n    val testRequests = 100\n    val failureTolerance = 1\n    val sleepTime = 10L // introducing a bit of delays actually 'fixes' things\nval serverService: Status => Service[Request, Response] = s => Service.mk { _ =>\n  Future.value(Response(Version.Http11, s))\n}\nval server = Http.server.serve(\"127.0.0.1:*\", serverService(Status.Forbidden))\nval server2 = Http.server.serve(\"127.0.0.1:*\", serverService(Status.Ok))\n\nval errorClassifier: ResponseClassifier = {\n  case ReqRep(_, Return(rep: Response)) if rep.status == Status.Forbidden => ResponseClass.NonRetryableFailure\n}\n\nval client = Http.client\n  .withResponseClassifier(errorClassifier)\n  .configured(FailureAccrualFactory.Param(failureTolerance, Duration.fromSeconds(30)))\n  .newService(FinagleUtil.socketsToName(server.boundAddress, server2.boundAddress), \"classifierTestClient\")\n\n\nval responsesFuture: Future[Seq[(Try[Response], com.twitter.finagle.Status)]] =\n  Future.collect(1 to testRequests map { (_: Int) =>\n    Thread.sleep(sleepTime)\n    client(Request(\"http://service/\")).liftToTry.map {\n      (_, client.status)\n    }\n  })\n\nval responses = Await.result(responsesFuture, Duration.fromSeconds(1))\n\nval counts: Map[Status, Int] = responses.groupBy(_._1.get().status).mapValues(_.length)\nprintln(counts)\ncounts(Status.Ok) should be(testRequests - failureTolerance)\ncounts(Status.Forbidden) should be(failureTolerance)\n\n}\n``\n. I would like to be able to act on that information programmatically inside the application, e.g. write to a different kind of log and taking a different functional path or disabling features.\n. @kevinoliver I'm not entirely sure how to listen to those events. Currently, we detect failure of all instances by monitoringFailedFastExceptionand we log those occurrences. I would expect all failures to have the same effect so marking all instances down because of response classification should in my opinion also lead to aFailedFastException`. \n. @kevinoliver Exactly. My use-case was for the HTTP case specifically but I think the behaviour should be the same for all clients of course.\nMy understanding of failure accrual is to detect faulty instances in order to direct load to other, functional, instances. Previously, only connection errors counted for the failure-accrual. In order to compensate for this the Response Classifier was introduced. Now responses that are deemed errors by the response classification, functional errors for my purpose, count as errors towards ignoring an instance as well. This results in successful direction of traffic to instances that don't respond with functional errors.\nNow consider the case that all servers return functional errors. Currently, requests will be sent to those instances and the caller will see the response. This is in contrast with connection errors that will trigger a FailFastException.\nIn my opinion connection failues and responses that are considered failures by the response classification should behave in exactly the same way instead of slightly different in some cases. Therefore, I expect to see FailedFastExceptions when all instances are considered down by the failure accrual.\n. @kevinoliver I think we do agree. I want the behaviour of failure accrual to be equal, so the behaviour of the client should be the same when the node is marked dead because of connection issues and when it is marked dead because of responses marked as failure by the classifier.\nDo you agree?\n. The behaviour is clear. We introduced a filter that checks the status on the underlying service and completes with FailedFastException when that status is unavailable.\n. It doesn't need to be in the stack by default. It's just that I would like to be able to add it through an existing withHttpStats (or similar) on the client. We do add the filter now but I would like to re-use the StatsReceiver from the stack because that is the one that is going to be set anyway. Otherwise, the StatsReceiver has to be passed manually to the StatsFilter which is error prone, on top of being tedious.\n- Alessandro\n\nOn 22 Sep 2016, at 18:26, Kevin Oliver notifications@github.com wrote:\nNot against creating a module for it but I'm not sure we want this module in the default stack for Http, so you'll still need to decide where to place it. Alternatively, since I think you'll want this at the beginning of the chain (so that it sees the final responses and total time) you could also this Filter on top: new http.filter.StatsFilter(..).andThen(Http.client.newService)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @kevinoliver sure, see #557. I've made it so that the stats filter is always pushed pushed on the stack. I am under the impression that that is right place. However, I haven't found a clear description of the order of stacks comparing clients and servers.\n. So, I've added a test-case. It also shows that the stats are directly under the client-label. Should we scope it to http? This would probably be a backwards incompatible change, unless we make it so that it is only prefixed with http when using withHttpStats and not when newing the StatsFilter manually.\n. Should we scope all the stats to start with 'http'? Otherwise we clutter the stats a bit, this will give nice grouping.\n. I went the route @kevinoliver mentioned. The http.filter.StatsFilter itself doesn't add the http scope but the module does.\n. @kevinoliver, do you have any news on this?\n. Great, Thank you @jcrossley!\n. @mosesn yes, the tests pass, on my machine.\n. @mosesn I think you are right. I changed the test to include an actual http server and client and I'm seeing the expected behaviour: the timeout results in a failure that is interrupted.\n. @mosesn that is exactly what I was alluding to in the second pro of solution 1. The issue with that solution that it only works for one transformation. In the SOAP example we parse SOAP but the application then still transforms the contents of the SOAP response and has to check for functional errors.. @mosesn and @kevinoliver: if you believe option 3 to be a viable solution we can try to implement it and use it in our application. And, if we like it, contribute it back.\n\nThe only snag that I see is on how to expose/provide the method that classifies a request/response as a failure. Using Context.Local would mean that the method isn't available before, possibly in a filter, where we set the context. If the FA module sets the context is only available lower down the call chain, right?. @roanta do you have an example on how to configure the target SR?\nIn our case, most of the times, the instances that respond quickest are broken and return errors. Which means that we don't necessarily want to favour the fastest instances. Tuning the failure accrual to be more aggressive (less forgiving) would mean a higher risk of needlessly ignoring an instance and being very trigger happy. Retrying a request to a different node would allow to keep the FA more relaxed.. @mosesn I would like to, however, how are we supposed to use them with certificates that have passwords? We don't use pem files usually, so even if this test works it would be an issue for us.. Downgrading to SslClientConfiguration indeed makes it work. Why is providing the SSLContext not supported anymore? I would expect the behaviour of non-deprecated configuration options to be equivalent.. @mosesn No afaik it doesn't. However, it can be constructed easily from a wide range of certificate formats with and without keys which was very convenient for us.\nWe use a jks with password containing encrypted private/public key pairs in x509 format. Maybe the configuration could work on Keystore and Truststore abstractions instead of direct references to pems?. Any thoughts on this @mosesn and @ryanoneill?. When debugging #679 I noticed there was a way to use .tls() with a SSLContext and a verifier for servers. I need to verify whether that works for us for clients. Also, we are currently using the SSLContext for configuring things like OCSP. Is that still available through the normal Java\u2019s security options or do we need another mechanism?. > 'I need to verify whether that works for us for clients'. Verifiers do work on the client as well.\nI\u2019m aware that verifiers work on the client. We currently use them for san/server hostname checking. I was referring to whether we can configure the client with empty configuration, initialise the engine factory with the SSLContext and add a verifier.\nThe de facto standard in java is to enable OCSP through a -Djavax.security property which exact name eludes me for now. I haven\u2019t gotten around to benchmark and resilience test this. I need to do that because going to http2 means going to OpenSSL bindings which don\u2019t react to the standard Java\u2019s security configuration.\nRelated, ALPN and OCSP-stapling is available in jre9. Are there any plans to support j9? Currently using j9 still leads to some unsupported engine error.\nUpdate:\nJava X509TrustManager\nSystem.setProperty(\"com.sun.net.ssl.checkRevocation\", \"true\");\nSecurity.setProperty(\"ocsp.enable\", \"true\");\nJdk9 OCSP stapling on client and server, slides at the end\n. Using JDK9 creating our own SslContextClientEngineFactory as below does execute and I'm able to connect to our existing http/1.1 servers. (This obviously won't work on JDK8.)\nHowever, pointing the client to http2.akamai.com results in \"This browser is not HTTP/2 enabled.\" when using ApplicationProtocols.Unspecified, and \"com.twitter.finagle.ConnectionFailedException: null at remote address: http2.akamai.com/2a02:26f0:7b:299:0:0:0:2a71:443.\" when I set the ApplcationProtocols to \"h2\". Whereas with the normal JDKClientEngineFactory I get back \"You are using HTTP/2 right now!\", regardless of the protocols I specify. \nAlso, I couldn't figure out how to debug on a h2 enabled finagle server whether I'm receiving a request over h2 or over http/1.1 How can I access that information?\nThis is on Finagle 18.2.0 btw.\n```scala\nfinal class SslContextClientEngineFactory(sslContext: SSLContext) extends SslClientEngineFactory {\ndef apply(address: Address, config: SslClientConfiguration): Engine = {\nval engine = SslClientEngineFactory.createEngine(sslContext, address, config)\nSslClientEngineFactory.configureEngine(engine, config)\nconfig.applicationProtocols match {\n  case ApplicationProtocols.Unspecified => ()\n  case ApplicationProtocols.Supported(appProtocols) =>\n    engine.self.getSSLParameters.setApplicationProtocols(appProtocols.toArray)\n}\nengine\n\n}\n}\n```\nTest code:\n```scala\n        final SslClientConfiguration x = new SslClientConfiguration(Option.empty(),\n            KeyCredentials.Unspecified$.MODULE$,\n            TrustCredentials.Unspecified$.MODULE$,\n            CipherSuites.Unspecified$.MODULE$,\n            ProtocolsConfig.enabled(Arrays.asList(\"TLSv1.2\")),\n            ApplicationProtocols$.MODULE$.fromString(\"http/1.1\"));\n    final Http.Client client2 =\n        com.twitter.finagle.Http.client()\n        .withHttp2()\n        .withTransport().tls(x, JdkClientEngineFactory$.MODULE$); //Force default jdk client\n\n//            .withTransport().tls(x, new SslContextClientEngineFactory(clientSSLContext)); // Always results in http1.1, do I need to do something with the SSLContext as well?\n log.info(HttpCodec.encodeResponseToString(Await.result(client2.newService(\"http2.akamai.com:443\").apply(Request.apply(\"https://http2.akamai.com/\")))));\n``. @ryanoneill The Netty SslContextBuilder supports passing in [KeyManagerFactory](https://netty.io/4.1/api/io/netty/handler/ssl/SslContextBuilder.html#keyManager-javax.net.ssl.KeyManagerFactory-)s and [TrustManagerFactory](https://netty.io/4.1/api/io/netty/handler/ssl/SslContextBuilder.html#trustManager-javax.net.ssl.TrustManagerFactory-). Would you be willing to accept a merge request which extends theKeyCredentialsandTrustCredentialsto be constructed with aKeyManagerFactoryandTrustManagerFactoryrespectively which are then used to call the matching methods ofSslContextBuilderin theNetty4ClientSslConfigurationsandNetty4ServerSslConfigurations?. I'm game for supporting*otherwise. But it seems as if LinkerD also relies on that. I'm actually not seeing how LinkerD relies on{}` not being valid syntax? Isn't LinkerD's path matcher run before Finagles?. > @spockz can you explain the motivation for wanting braces?\nWe are looking up services not by key but by host/method/pathTemplate and this pathTemplate can contain variables. Currently we do .newService(\"ourResolver!host/method/pathTemplate\"), but we want to move to paths so we can do .newService(\"/endpoint/host/method/pathTemplate\"). This is on order for us to be able to override resolutions through Dtab-local headers.. Yes, I\u2019d like this in but haven\u2019t found a way to do it in a compatible way to LinkerD. We are using the curly braces verbatim whereas in LinkerD they are used to mark something replaceable. Using underscores instead of curly braces means changing many of our other systems. Basically the endpoints including he curly braces are used as ids right now so that would be a pain to change.\n@adleong, can you imagine a compatible way?\nOtherwise we could try hooking into the serviceFactory.newService method to rewrite the string... that sounds hacky but preferable to changing all our IDs.. If we could make the parser pluggable we could solve both our issues. We can just eat the curly braces and LinkerD can directly implement the parser instead of relying on parsing to fail. Does this sound feasible?. Whoops. Missed this. Propagation will be a mess regardless of any change. Luckily we have relatively tight control on the used versions.\n\n.. doesn\u2019t seem to have curlies \n\nMy apologies, within our idiom pathTemplate is the template just like in swagger. That means that path parameters are encoded as /mypath/{param}/remainder.  This is what developers use in their newService, e.g. .newService(\u201capis.com:GET:/accounts/{id}/transactions\u201d).\n@mosesn Do you know a way to let developers still use the form above but that we rewrite the string somehow to replace curly path parameters with underscores? The goal is that we can use DTabs to rewrite the name.. @mosesn interesting. I hadn\u2019t thought of that. Our native java users (far majority) could use something like a normalise method. Sounds fair and straightforward. I\u2019ll check with the rest of the team.. Shading netty in Finagle would be beneficial because it allows Finagle to stay on a specific netty version and have the rest of the application use another version of netty.. In addition to making this an info or lower message also consider suppressing the stack trace. It has no added value in this message. . Also there is a typo in finangle, it should be finagle.\n. fixed\n. Done\n. Done\n. No, not really. It was like that because I wanted to write the unapply function like this:\nscala\ndef unapply: Status => Option[Status] =\n  inRange(100,200)\nBut it appears that leads to several compile errors.\n. Good point, fixed.\n. Is there something that automatically formats this way? My auto-layout destroys it back to the layout in the PR. Was this comment style also described somewhere?\n. null isn't a status, therefore, it shouldn't be matched by any of the category matchers.\n. Fine by me. :)\n. Good point, fixed.\n. Good point. I'll also have a look at those principles.\n. Fair enough. I choose enable because there are no arguments passed in. Just like noFailFast.\n. There are other descriptions of modules containing verbs. Why should it be gone here?\n. I've put the type-param in there because the filter itself has it as well and limiting it in the module seemed strange. Additionally, our applications use types that inherit from RequestProxy so we actually like the presence of the type-param in the filter and think the api would be less rich and flexible without it.\n. Done\n. Done\n. Done\n. Done\n. Done\n. You are totally right!\nRegarding the MemoizedStatsReceiver, I don't that would work with custom configured StatsReceivers, right? If the todo was to use the MemoisedStatsReceiver than this MR can be ignored. :)\n. Somehow I looked at the MetricsStatsReceiver instead of the MemoizedStatsReciever. I cannot find a MemoizedStatsReceiver in Finagle. I do find a Memoized in twitter-util, which is used by Finatra. Should we copy that solution to Finagle?\n. Sure\n. Sure\n. Identity is only used in places where stack.replace() is used, not with prepend(), there is no prepend that takes both a role and a function. How do you recommend to do this?\n. Ok. I'll remove it.\n. Yes I was wondering about that. What is commonly used as timeout  value?\n. Done\n. Done\n. Done\n. Done\n. I'm not seeing it. How would we assign a role to the identity function?\n. Calling this class KeyManagerFactory as well makes it clash with the argument type. I'm ambivalent in overriding names like that especially when making it usable from Java which does not have import renaming.. Done. I have not added the test. Depending on how the KeyManagerFactory is constructed the check is already performed there.. Okay. Why don't we use @see?. ",
    "Eilie": "Anyone?\n. ",
    "charithe": "Travis build fails on finagle-common-stats and finagle-stream. finagle-redis builds successfully.\nThe command \"./sbt ++$TRAVIS_SCALA_VERSION finagle-redis/test\" exited with 0\n. Thanks. I wasn't aware of the change to the contribution guide. I will resubmit the PR with the suggested changes.\n. @travisbrown I pulled your branch and added ScalaTest tests for all commands. However, now I can't compile it locally due to a missing dependency: com.twitter#util-core_2.10;6.23.0-SNAPSHOT. Any suggestions?\nNew diff: https://github.com/twitter/finagle/compare/develop...charithe:redis_hyperloglog\n. Travis build fails because com.twitter#util-core_2.10;6.23.0-SNAPSHOT cannot be resolved. All finagle-redis tests pass on my dev machine.\n. Thanks @travisbrown. I fixed all the issues you pointed out.\nWe do use Finagle in production -- quite heavily I might add. When is your next release planned for? This particular piece with HyperLogLog is something I am currently prototyping so if it's going to delay the current release, I can wait until the next release or work off of snapshots.\n. That's great! Thank you.\n. ",
    "kachayev": "@mosesn Just now 4 services are written in Scala/Finagle (and growing): calendars sharing, ACL, load balancer for numerous internal API endpoints, backend for developers portal and public API\n. ",
    "keeth": "Awesome, thanks guys! :metal: \n. ",
    "jamescway": "@mosesn sorry about the delay.  We were testing this change in an integration environment and everything looks good!\n. @mosesn updated with README.md.  Should I make the PR off of develop?\n. @mosesn a few Q's:\n- do u guys merge internally?\n- should I make a PR off of develop?\n- what's the release cycle of finagle-thrift? (seems like not too often)\nsorry to bug :smile: :beers:\n. Ok removed the readme file while preserving the reason for the change in comment and updated commit message (per style guide).  :bowtie:\n. @nshkrob Do you think you guys will be able to do a release of finable-thrift to rubygems.org?\n. @mosesn indeed it is a thread local variable.  I hope I'm understanding your question correctly, I think we are trying to do one trace object per thread.  We were getting race conditions on the stack obj.  I think Ruby does context switching from what I read here, but since its thread local it shouldn't be problem.  Also, we're using jruby so they should be real threads.\n. I see your point, definitely this issue could happen.  A few possible approaches here:\n1.  Thread local - the architecture would require requests to be handled in T1 and if it requires additional work, it would pass the Trace data necessary to T2. \n2. Global - guarded with mutexes synchronized code.  This approach seems like a bit of a band aid and not solving the real problem.\nWhat do you think?\nI will definitely add this to the readme.   Also I'll try rebase the PR on develop with readme.\n. ",
    "ryangreenberg": "Overall changes looks fine to me with the already stated caveat that it won't work in applications that handle multiple requests concurrently in a single thread. We can come up with a solution to that problem when it arrives. Thanks for making this change.\n. ",
    "missingfaktor": "@mosesn @travisbrown @vkostyukov @roanta Thanks a lot for the reviews, guys! I very much appreciate you giving your time for this.\n@mosesn What @roanta said. The changes should be transparent, and would \"just work\". Due to how implicit lookup works in Scala, even additional imports would not be required. Example:\n``` scala\n\nfinagle-mysql/console\n[info] Starting scala interpreter...\n[info]\nWelcome to Scala version 2.10.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_31).\nType in expressions to have them evaluated.\nType :help for more information.\n\nscala> import com.twitter.finagle.exp.mysql.\nimport com.twitter.finagle.exp.mysql.\nscala> def foo(args: Parameter) = args\nfoo: (args: com.twitter.finagle.exp.mysql.Parameter)Seq[com.twitter.finagle.exp.mysql.Parameter]\nscala> foo(3, \"hello\")\nres0: Seq[com.twitter.finagle.exp.mysql.Parameter] = WrappedArray(com.twitter.finagle.exp.mysql.Parameter$$anon$1@152f97f0, com.twitter.finagle.exp.mysql.Parameter$$anon$1@3966c6d0)\nscala> foo(3, \"hello\", 'unsupported_type)\n:12: error: could not find implicit value for parameter evidence0: com.twitter.finagle.exp.mysql.CanBeParameter[Symbol]\n              foo(3, \"hello\", 'unsupported_type)\n                              ^\n```\nAs for Java API, I again have to agree with @roanta. We could have a parallel Java API to make this work, if a Java compat is desirable.\n. > the path to upgrade from Any => Parameter is to make sure the Parameter.wrap method is in scope\nNo. Scala looks in the companion object of Parameter for this conversion automatically, and one has to do nothing to bring the implicit conversion in scope.\n\nIf anyone isn't using a literal Seq (ie even val x: Seq[Any] = Seq(3, 4, 5, \"OK\") is no good) then they will need to make code changes to do this.\n\nYes, though the code change should be fairly minimal.\n\nMy impression is that prepared statements require a specific set of parameters, which have types that are known in advance. Can we require that they are the right types, beyond just that they are parameter types?\n\nI am not sure what you mean. That's exactly what this PR is trying to do: To restrict that only things that can be used a parameter, are. CanBeParameter and Parameter is the machinery used to do it.\n. Hi @mosesn. That would require a change in how you declare queries \u2013 You will have to declare the types of parameters and such with the sql statements. I have been toying with this idea in one of our projects. This is what it looks like (The API is inspired by Doobie, but the underlying mechanism is a lot simpler and is less feature-rich):\n``` scala\nval query: SelectOpt[Project, (String, Int)] = \"\"\"\n  |select * from projects where name = ? and data_sensitivity_level = ?\n\"\"\".stripMargin.selectOpt[Project, (String, Int)]\nquery(\"zob\", 3) // returns Future[Option[Project]]\n```\nThis would look for CanBeParameter evidences for all components of the tuple of parameters. \nAs I said, I am still toying with the idea. It's pretty basic in its current shape.\nIMO the changes I have implemented as part of this PR are a good first step. The users will need some code change but that should be fairly minimal. Later we can try to improve things even further.\n. @roanta I have addressed your review comments in my latest commit.\n. @roanta @mosesn I had to restore the variance annotation. :( In its absence, for instance, a value of type CanBeParameter[Value] cannot be used when a CanBeParameter[StringValue] is needed. (Note that StringValue <: Value.) This leads to errors like the one shown below: \nscala\ncould not find implicit value for parameter evidence0: com.twitter.finagle.exp.mysql.CanBeParameter[com.twitter.finagle.exp.mysql.StringValue]\n. @roanta Splitting CanBeParameter[Value] into separate instances doesn't seem right, because Value is the type constructor here, and StringValue, LongValue etc are simply data constructors. It just happens to be the case that Scala implements ADTs with subtyping, so StringValue etc also become types on their own.\nAlso consider this: When we add a support for Option[_] in future (which I hope we do), we will want the following to just work: \nscala\nclient.prepare(\"...stuff...\").apply(2, 4, Some(\"howdy\"))\n. > @mosesn @missingfaktor I realise this is somewhat off topic, yet I think you may be interested in knowing we have a fully type safe reactive DSL built atop Finagle for MySQL. Have a look here: https://github.com/websudos/morpheus/blob/develop/morpheus-mysql/src/test/scala/com/websudos/morpheus/mysql/query/MySQLUpdateQueryTest.scala. It's not yet production ready, but we'd welcome feedback and contributions.\n@alexflav23 Hi Alex. That seems to take a good deal of inspiration from Rogue and Slick, my two favorite database libraries. Looks pretty great! Thanks for bringing it to notice.\n. @roanta I meant algebraic data type, not abstract data type. Sorry for the confusion.\nSome REPL scribbles to clarify my point about Option[_]:\n``` scala\nscala> trait CBP1[A]\ndefined trait CBP1\nscala> implicit val forString = new CBP1[String] {}\nforString: CBP1[String] = $anon$1@4d591d15\nscala> implicit def forOpt[A : CBP1] = new CBP1[Option[A]] {}\nforOpt: ACBP1[Option[A]]\nscala> def wrapA : CBP1 = ???\nwrap: A(implicit evidence$1: CBP1[A])Nothing\nscala> wrap(Some(\"hello\"))\n:12: error: could not find implicit value for evidence parameter of type CBP1[Some[String]]\n              wrap(Some(\"hello\"))\n                  ^\nscala> trait CBP2[-A]\ndefined trait CBP2\nscala> implicit val forString2 = new CBP2[String] {}\nforString2: CBP2[String] = $anon$1@3b0143d3\nscala> implicit def forOpt2[A : CBP1] = new CBP2[Option[A]] {}\nforOpt2: ACBP2[Option[A]]\nscala> def wrap2A : CBP2 = ???\nwrap2: A(implicit evidence$1: CBP2[A])Nothing\nscala> wrap2(Some(\"hello\"))\nscala.NotImplementedError: an implementation is missing\n  at scala.Predef$.$qmark$qmark$qmark(Predef.scala:225)\n  at .wrap2(:13)\n  ... 33 elided\n```\n. Thank you again @roanta, @mosesn, and others for the reviews! :)\n. @roanta Yay! Thanks for the merge. :fireworks: Any estimate when this might be a part of official release?\nHow does unsafeWrap work? Does it have a registry of all the CanBeParameter instances?\n. @mosesn Good suggestion. Will do.\n. @mosesn Tried removing that line and re-auto-importing. For some reason, IDEA keeps putting it on the same line! Will move it manually and push.\n. @travisbrown I am not sure there is a precedent for either convention in Scala, since it's not a very widely used pattern. But I agree that A0 might be a better convention that _A. Will change.\n. Okay re: line length. \nPutting it in the constructor will be messy because of how Scala does constructors. Every parameter to class is accessible in its entire body, and also it's immutable. We will have something like:\n``` scala\nclass ExecuteRequest(..., params: Seq[Parameter], ...) {\n  val sanitizedParams = sanitize(params)\n// but params is still accessible here, what if we accidentally use that?\n}\n``\n. @mosesn Because of the sanitization that's needed beforehand. With a regular class, I could mark the constructor private. With a case class, I still could do that, but theapplyauto-generated in the companion object will be publicly available, and it cannot even be overridden. \n. Okay.\n. Yes. Also just a tiny bit more expensive. :)\n. @mosesn That seems to give a wrong impression that this is a pure function, which it is not. It's executed purely for its side-effects. And if it's just going to return the same writer at the end, the return doesn't mean much. If a function is side-effecting it should show in its type-signature, don't you think?\n. It does, for byte arrays andValue.\n. @mosesn Good point. I changed it in many places, but missed this one. (In current Finagle MySQL,Array#sizeis more prevalent thanArray#length.\n. @mosesn Okay.\n. @vkostyukov The members ofParameterwill increase with the number of methods inCanBeParameter, and all of them will be pure delegators. What's the value?\n. @mosesn Okay.\n. @mosesnValueis a sealed trait andtypeCodecovers all of the cases explicitly. There is no case that's left out. In case ofsizeOfI am just keeping the existing behavior as-is. \n. @mosesn It's been that way since before.\n. @mosesn I have tried to mirror the existing behavior as faithfully as possible. I think other values are skipped in current implementation too. As fornulls, we are not handling them here. Should they be handled here? Handlingnulls everywhere on a case-by-case basis seems messy, and something to be avoided.\n. @mosesn If I have a custom data typeXsuch thatX <: Y, and there's evidenceCanBeParameter[Y]available, I would want to be able to passX. The fact that it typechecks means such a usage is valid. Why not have the flexibility?\n. @mosesn It wouldn't make sense. It's supposed to be used as an existential type.\n. @mosesn Please refer to my reply to a similar comment before.\n. @mosesn That will expose unsanitized params in the (auto-generated)unapply.\n. Okay, agreed. I will change this.\n. @mosesn Sorry, I am out of my depth here. I have tried to retain the existing behavior here as well.\n. Okay.\n. Okay. I will try making it more explicit at the least, what cases specifically are skipped. :)\n. @mosesn I was thinking this could be useful for custom data types. But @roanta here has raised some very valid points. I will make the type-class invariant.\n. Okay. :)\n. @roanta I usually only usesealedwhen declaring ADTs/GADTs, but using it to prevent extension ofParameter` from outside this unit seems like a great idea. \nAnonymous instantiation is okay as long as it's in the same unit.\n. There are two things here that make that not possible: A conditional inside the wrap, and a type member. implicit classes can be substituted for implicit conversions in most cases, but this isn't one of them.\n. I see. With this, though, the client is burdened with code like following:\nscala\nclient.prepare(\"...\").apply(3.asParam, \"jd\".asParam)\nI think it adds no value and hampers readability.\n. Thanks @luciferous.\n. ",
    "tianxiao-ma": "@mosesn \nsorry, I'm late.\nyes, the problem is the second parameter. And https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/util/LoadService.scala#L93 is hard code 'UTF-8'.\nI think ISO8859-1 is a better default charset for LoadService.\nmy stack track is here.\n``` java\n2015-04-09 18:52:41.565:WARN::Nested in org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'search4realaudit': Invocation of init method failed; nested exception is java.lang.ExceptionInInitializerError:\njava.nio.charset.UnmappableCharacterException: Input length = 2\n    at java.nio.charset.CoderResult.throwException(CoderResult.java:261)\n    at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:319)\nat sun.nio.cs.StreamDecoder.read(StreamDecoder.java:158)\nat java.io.InputStreamReader.read(InputStreamReader.java:167)\nat java.io.BufferedReader.fill(BufferedReader.java:136)\nat java.io.BufferedReader.readLine(BufferedReader.java:299)\nat java.io.BufferedReader.readLine(BufferedReader.java:362)\nat scala.io.BufferedSource$BufferedLineIterator.hasNext(BufferedSource.scala:67)\nat scala.collection.Iterator$class.foreach(Iterator.scala:727)\n\nat scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\nat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)\nat scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:176)\nat scala.collection.mutable.ListBuffer.$plus$plus$eq(ListBuffer.scala:45)\nat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:273)\nat scala.collection.AbstractIterator.to(Iterator.scala:1157)\n\nat scala.collection.TraversableOnce$class.toList(TraversableOnce.scala:257)\nat scala.collection.AbstractIterator.toList(Iterator.scala:1157)\nat com.twitter.finagle.util.ClassPath$$anonfun$browseJar$5$$anonfun$apply$3.apply(LoadService.scala:114)\nat com.twitter.finagle.util.ClassPath$$anonfun$browseJar$5$$anonfun$apply$3.apply(LoadService.scala:111)\nat scala.Option.foreach(Option.scala:236)\n\nat com.twitter.finagle.util.ClassPath$$anonfun$browseJar$5.apply(LoadService.scala:111)\nat com.twitter.finagle.util.ClassPath$$anonfun$browseJar$5.apply(LoadService.scala:107)\nat scala.collection.Iterator$class.foreach(Iterator.scala:727)\nat scala.collection.AbstractIterator.foreach(Iterator.scala:1157)\nat com.twitter.finagle.util.ClassPath$.browseJar(LoadService.scala:107)\nat com.twitter.finagle.util.ClassPath$.browseUri(LoadService.scala:77)\n\n```\nThe data-resolve.xsd file is encoded use UTF-8, and the linux server's default charset I run finagle is GBK, so the exception is throwed.\n. @mosesn \nIt's about how ISO8859-1 do encode and decode. For short,  ISO8859-1 is single-byte fixed length encoding, and GBK or UTF-8 is variable-length encoding. For detail, please see http://stackoverflow.com/questions/7048745/what-is-the-difference-between-utf-8-and-iso-8859-1\nSince the information need by LoadService will just ascii chars, so ISO8859-1 will work. And file's encoded by GBK or UTF-8 can also be read use ISO8859-1, so no exception will throw. \nI will try to make PR.\nEdited:\nI have make a PR, please check @mosesn \n. @mosesn \nrequire that all of the files that finagle uses be in UTF-8 is impossible. My project include some jar which is created by other people, and in these jar, some file will read by finagle's LoadService, like the file I list in #366 .\nISO8859-1 worked, I have try it in my project.\n. @mosesn \nYes,  the file I list in #366 is encoded as UTF-8, but the charset LoadService used to read this file is GBK, so the exception throws. This is because in current implementation, LoadService will use system's default charset to read files, and my system's default charset is GBK.\nWhat is my require is to have a way to change the charset used by LoadService, but in finagle's current version, there is no such way. \nAbout the ISO8859-1 and UTF-8\nThe ISO8859-1 use a one byte fixed-length scheme to encode and decode text, so it can work for any file, since the minimal unit for a file is byte.\nBut UTF-8 or GBK will use different algorithm to encode and decode text, so the file encoded by UTF-8 can't be decoded by GBK. For example, the chinese word \u4e2d\u56fd, UTF-8 may encoded it into 4 bytes, but GBK my encoded it into 5 bytes. So, if we use GBK to read a file it a file which is encoded as UTF-8, a exception will be throw. \n. So,  Can you let LoadService use 'UTF-8' to read these file, not the system's default charset?\n. I think it's need to let developer has a method to set the charset used by LoadService\n. @mosesn \nUse UTF-8 is right, but in current version of LoadService, it will use system default charset to read files. And the system's default charset might not be UTF-8.\nI think you should enforce  LoadService use UTF-8 to read files, like https://github.com/twitter/finagle/blob/master/finagle-core/src/main/scala/com/twitter/finagle/util/LoadService.scala#L93\n. @mosesn \nI have update the pull request, please check it\n. my first successful pull request, thank you all. @mosesn @kevinoliver @dschobel \n. ^_^\n. @kevinoliver can you explain more? how to change?\n. ",
    "n8han": "Thanks guys, happy to be here (Montreal/Fingleland)!\n. ",
    "zdavep": "We've just launched a secure platform (backed by Cassandra) for creating virtual messaging systems (user to user).  We've started small with a single app, but there are plans to use the platform in many more of our internal applications. \n. ",
    "jaked": "It's the residual path. according to @olix0r - 162.days:\nhttps://github.com/twitter/finagle/commit/25a24417\n. ",
    "plancast": "Thanks\n. ",
    "jmoseley": "Is there any update for this PR?\n. OK thanks @timxzl\nOn Jun 10, 2015 5:20 PM, \"timxzl\" notifications@github.com wrote:\n\n@jmoseley https://github.com/jmoseley no updates since I last\nsubmitted. still waiting for some contributor to take a look and (possibly)\nmerge it in.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/twitter/finagle/pull/383#issuecomment-110953448.\n. \n",
    "raelg": "flatMap itself doesn't work, because the method is not defined on the Service trait. I initially used the Filter approach above, but decided that subclassing Service with a new trait with the andThen method is the cleanest, and most composable approach.\nI'm building a microservice with a handful of RESTful JSON end-points, and think this approach fits in nicely with Finagle's functional design. \n. Well, I guess for one, it's slightly less code with my the new service subclass, and personally I think it's more readable. \n. Having used Finagle for a couple of weeks, I'm only familiar with it on the surface level, and it may well be possible my services are too granular and transformation would be more natural in a different layer, especially as each of my routes essentially uses it's own filter chain. \nUsing a Filter to unwrap and short circuit Options does seem like appropriate usage of Filter though (and is easily testable). However, the reason I wouldn't use a Filter to accomplish changing services is since when reading the code, it wouldn't be obvious what the extra Filter did without looking at the implementation, as opposed to the Service#andThen approach. \nI'm not sure I agree with the comment above, as the usage is similar to Scala's Function1#andThen: \nComposes two instances of Function1 in a new Function1, with this function applied first\n. Point taken. It could well be that this is specific to my use-case and anyway adding the implementation has been straight forward enough. I would agree that the current andThen and compose methods confused my initial understanding and approach. \n. ",
    "Gabriel439": "For what it's worth, I'm in favor of this since it's analogous to Haskell's (>=>) operator (specialized to Futures):\nhaskell\n(>=>) :: (a -> Future b) -> (b -> Future c) -> (a -> Future c)\nUnlike flatMap, this operator has the nice property that it is \"compositional\".  Informally, \"compositional\" means that you get back what you put in: two \"Kleisli arrows\" go in, one \"Kleisli arrow\" comes out.  Formally, \"compositional\" means that it is the composition operator in a category (specifically the \"Kleisli category\" for the Future monad).\nflatMap is close to being compositional, but not quite.  The issue is that flatMap requires dealing with two separate types: values of shape Future[B] and values of shape A -> Future[B].  With (>=>) you only have to think in terms of values of type A -> Future[B].\nThis might seem like a minor distinction but from a user's standpoint it means that they don't need to think in terms of Future at all.  They can think purely in terms of Services if they use the (>=>) operator exclusively.  All you would need is a function that promotes a Future to a service with a () input:\n``` haskell\ntype Service a b = a -> Future b\nfromFuture :: Future b -> Service () b\n```\n. ",
    "kumasento": "@dschobel Thanks for your comment, now I understand.\nStill, Finagle rocks\n. Sorry but should I close this issue @dschobel ?\n. ",
    "thirstycrow": "I made this change as a quick fix for the problem to use finagle clients with resin 4 pro container. It works in our scenario. No enough time for testing code at the moment, but I will do it as soon as possible.\n. I sent a pull request for the sentinel support here #443.\n. @mosesn I made some modifications to make it work well with load balancing. Please take a look at the new implementation. And is there anything still need to be done, except merging the subscribe client and the normal client?\n. I moved the subscribe client things into c.t.f.redis.exp. And I hope we can make an agreement on the rich api first. The underlying implementation can be optimized later anyway.\nHere's what I expect it look like:\nCreating a client.\nscala\nval client: RedisRichClient = Redis.newRichClient(hostAndPort) // instead of Redis.client.newRichClient(hostAndPort)\nNormal commands are kept as-is.\nscala\nclient.set(key, value)\nclient.get(key)\nI hope we can subscribe/unsubscribe just like how we use normal commands, hiding the fact that a different connection is used.\nscala\nclient.subscribe(foo, bar)\nclient.unsubscribe(bar)\nTransactions should be done isolated with each other, and with explicit boundaries.\nscala\nclient.transactional { tx =>\n  tx.watch(foo)\n  tx.multi()\n  tx.set(bar, baz)\n  if (someTest()) {\n    tx.commit()\n  } else {\n    tx.discard()\n  }\n}\n'transactional' is defined as following. Hope they are not going to add a TRANSACTIONAL command in the future :)\nscala\ndef transactional: Service[TransactionalClient => Future[T], T]\nSentinels use an almost completely different set of commands, I think we should type it as another class.\n``` scala\nval sentinel: RedisSentinelRichClient = Redis.newSentinelClient(hostAndPort)\nsentinel.masters()\nsentinel.slaves(masterName)\n```\nI don't have ideas about how to do it with redis cluster yet.\n. @mosesn Sorry for late reply, I didn't get much spare time last week.\nI finished the rich client part with the latest commits. Please give a review on it.\nIt seems it's finagle-redis that is using a different style than the rest. I checked finagle-http and finagle-mysql, and they are using the Protocol.newRichClient style. So I changed to this style in the new code.\n. Fixed the coding style issues. And since SubscribeCommand now subclasses Command instead of RedisMessage, there is no need to use Encoder[RedisMessage], so I changed it back.\n. @kevinoliver I'm not quite familiar with the SHA thing. Could you add it before merging this pull request? The libthrift code is copied exactly from the 0.9.1 tag\nI added a param to specify a default service\uff0cso the server can be upgraded to use mutiplexing, and still be compatible with the old clients.\nscala\nval server = Thrift.server.serveIfaces(\n  address, serviceMap, defaultService = Some(\"extendedEcho\"))\n. @taylorleese I think there's nothing special needs to be done to work with ThriftMux, which does not depend on the details of how a thrift message is encoded.\n. The concerning here is about symbolic link.\n. Assume we have a test.jar, which references dot/test.jar by the Class-Path manifest attribute, where dot is a symbolic link to the current directory. In this case, test.jar will be processed repeatedly, because test.jar is not equal to dot/test.jar as File objects, and dot/test.jar is not equals to dot/dot/test.jar, ...\nThere may never be such a case in real systems, but generally speaking, compare files by canonical path is a safer option.\n. They were in BaseClient. I moved them to Client, because they are not available in sentinel and/or cluster mode.\n. EmptyBulkReply is returned when the section is unknown to the redis server.\n. It always returns something about the master, including its status, unless it is removed. In that case, an exception will be thrown.\n. \"MASTER\" is a subcommand of \"SENTINEL\"\n. It is to avoid long running tests without any feedback. Shall I replace it with logging?\n. I think it better not put them together.\n```\ncase class SentinelMasters() extends Sentinel(SentinelMasters.channelBuffer, Nil)\nobject SentinelMasters extends SentinelHelper {\n  val command = \"MASTERS\"\n  def apply(args: Seq[Array[Byte]]): SentinelMasters = {\n    new SentinelMasters()\n  }\n}\n```\n. These are subcommands of \"SENTINEL\", which is added in Command.scala. I followed the \"CONFIG\" command's style here.\n. Is it ok with the following piece of code?\ndef apply(host: String): SentinelClient = {\n  val client = com.twitter.finagle.Redis.client\n  SentinelClient(\n    client\n      .configured(client.params[DefaultPool.Param].copy(high = 1))\n      // Daemonize is private to the builder package.\n      // Is there another way to set this? Or can we just ignore it?\n      // .configured(client.params[Daemonize](true))\n      .newService(host))\n}\n. ```\nabstract class Config(sub: ChannelBuffer, args: Seq[ChannelBuffer]) extends Command {\n  // I think you're mentioning this one.\n  def command = Commands.CONFIG\n  def toChannelBuffer = RedisCodec.toUnifiedFormat(Seq(CommandBytes.CONFIG, sub) ++ args)\n}\ncase class ConfigResetStat() extends Config(sub = ConfigResetStat.channelBuffer, args = Seq())\nobject ConfigResetStat extends ConfigHelper {\n  // rather than this one.\n  val command = \"RESETSTAT\" // <-- Where is it used?\n  def apply(args: Seq[Array[Byte]]): ConfigResetStat = new ConfigResetStat()\n}\n```\n. They both have a \"command\" property, with different values. Instead of using a different name, can we just use a dummy param?\n```\ncase class SentinelMasters(dummy: Int = 0) extends Sentinel(SentinelMasters.channelBuffer, Nil)\nobject SentinelMasters extends SentinelHelper {\n  val command = \"MASTERS\"\n  def apply(args: Seq[Array[Byte]]): SentinelMasters = {\n    new SentinelMasters()\n  }\n}\n```\n. It looks strange to put the listener here in the command, but I don't know how to pass it to the dispatcher at construction time.\n. Upper case is used in CommandBytes, so I followed the same style here. MessageBytes is used only in SubscribeClient, so I made it private, and it would be safe to rename them later.\nBTW: Sometimes, I find it hard to decide the case the name of a val should be in. What are the conventions are you follow in twitter?\n. Why should we register a handler, if the subscription is not succeeded?\n. I found during testing that the acknowledgement message may come after messages for the subscribed channel. So the handlers are registered when the subscription request is sent successfully, instead of waiting for the acknowledgement messages. I added some comments in the code to make it look better.\n. All commands created by the same SubscribeClient instance carries the same listener, which is the SubscribeClient instance itself. It would be better if the SubscribeClient can be passed as a constructor argument for the dispatcher.\n. I don't quite understand what you mean.\n. Updated. I don't figure out what a 'RB_ID' is, so I did not add them, is that ok?\n. It is necessary because when a client enters the pub/sub state, it can no longer issue commands other than the (un)subscribe ones, until it exits from the pub/sub state. We have to create two clients if we want to use pub/sub and still be able to access the data. I added some comments for this on c.t.f.redis.SubscribeClient.\n. Comments add on c.t.f.redis.SubscribeClient\n. In that case, we'll have to keep track of the client state, and prevent users from issuing ordinary commands to a pub/sub client by throwing IllegalStateException. I think it's better to keep them separate for type safety.\n. That's not the same. We may subscribe multiple times, but it will not change the way how we communicate with the server. In the subscribe mode, there's no correspondence between the outgoing and incoming messages, while in the ordinary mode, the outgoing and incoming messages are in one-by-one correspondence (so pipelining works). I think it's more appropriate to consider them two different protocols, despite that they encode messages in the same manner. I agree that we should provider more documentations. So, how about we pull up Redis.Subscribe, rename it to RedisSubscribe, add some methods to create rich subscribe clients, and document the designing considerations in its scaladoc? We could also add a README for finagle-redis to provide some get-started examples.\n. Could you give some details about the transaction affairs? I thought it had no relation with the subscribe commands, but I'm not pretty sure on that.\n. Some more thoughts on adding subscribe support to the existing pipelining client:\n1. It is hard to tell whether a client has quit from pub/sub mode successfully, because we are not replied when we issue an unsubscribe command. When we issued  an unsubscribe command to the last channel/pattern we currently subscribed to, we have to wait until the acknowledgement message for this command arrived, before we can confidently say that it is safe to send normal commands. But during the waiting gap, it is possible that some other subscribe command are issued. So, the acknowledgement message carries some information about the pub/sub status at the time it was sent out from the server, which may not still be true when it is received by the client. To solve this problem, we'll have to provide some special unsubscribe command, so that when it is issued, the client put itself into a temporally-unavailable state, and reject any more command, neither normal nor subscribe, until it receives the unsubscribe acknowledgement.\n2. We cannot manage the client pub/sub status transparently with sharding. We'll have to provider sharders specifically designed for redis, to keep track all of the pub/sub status of the underlying shards.\n. Subscription is more complicated than transactions. Consider the following scenario:\n```\nsend: subscribe foo      <-- The client subscribes to a channel,\nrecv: subscribe foo 1    <-- and receives an acknowledgement like this. The\n                             number at the end is the number of channels the\n                             client subscribed to. The client will exit from\n                             pub/sub mode, when it drops down to 0.\nsend: unsubscribe foo    <-- Not interested in this channel any more.\nsend: subscribe bar      <-- Another subscription, before the acknowledgement\n                             message arrives.\nrecv: unsubscribe foo 0  <-- It's not safe to reuse this connection. :(\nrecv: subscribe bar 1\n```\n. I think it's ok to share the same connection among all subscribers, and share another for all regular uses. And perhaps we can also use the for-regular-use connection for transactions, if we make sure that all commands for the same transaction will be sent with a single write (by buffering the commands involved in a transaction in a client-side thread-local buffer, and sending them all together only when a EXEC command is issued)\n. Yes, you're right. And another thing I failed to take into account is the WATCH command. It's not part of the transaction, but affects the transaction result. So, we're gonna need individual connections for each concurrent transactions.\n. I think it's not necessary. We do the work in the onFailure callback.\n. It may be better to check it at somewhere underlying, in the transport, perhaps.\n. It seems that the current TransactionalClient implementation is not thread safe for the same reason - WATCH's are no guaranteed to use the same connection as the transaction is going to use.\n. ",
    "matthewmichihara": "ah didn't see the Util/Scrooge instructions. Working for me now, thanks!\n. ",
    "cevaris": "Had this issue as well.\nThis seems to fix the finagle dependencies issue.\n```\nUtil\ngit clone https://github.com/twitter/util\ncd util\n./sbt +publishLocal\nOstrich\ngit clone https://github.com/twitter/ostrich\ncd ostrich\n./sbt +publishLocal\n```\nNow you should be able to clone the finagle repo and compile the projects.\n. From looking at the docs and version history it seems I am using the older API's. So going to close this PR. Will open up an issue since the ThriftClient is not working as expected. \n. ",
    "oshev": "@cevaris Thanks, but didn't work for me. :-/\n. ",
    "svetlyak40wt": "Nice. Does somebody have rights to merge this pull request? :)\n. Without this fix, allmychanges have problems which parsing changelog as reStructured file: https://allmychanges.com/p/scala/finagle/\n. @mosesn allmychanges is my pet-project. Feel free to write me any time if you have some ideas related to it.\nIt has few parsers, markdown, rst, html and plain-text (which is able to handle most formats, but in a very restrictive way, for example, it will not handle rst or markdown links, etc). Right now I tuned this package to use plain-text parser for finagle, because rst parser returns 6.26.0 version with empty description.\nLet me explain how it works. Markdown and rst files translate texts into html and then process it with html parser :)\nHtml parser searches h1, h2, h3, h4, h5 headers and if there is something like version number in the text of the header, then saves elements, following this header until a header of the same or higher level will be encountered.\nRight now in the CHANGES 6.26.0 version's header is followed by \"Deprecations\" header of the same level. That causes the problem.\nPlain text parser, works differently. It just looks at each line, and if it is relatively short and has a version number, then this line is considered a version number, and all next lines are saved as description until the next version number will be found.\nThat it.\n. @dschobel so, I just have to wait for a Monday, right?\n. Thank you, Daniel, thank you, Moses!\n. @vkostyukov cool! Thank you!\n. ",
    "nepthar": "New PR - #543. Closing this.. LGTM\n. Well, after your changes, you've ventured in to territory that I'm unfamiliar with, but LGTM! I'll merge it soon.\n. Yup, makes sense, thanks for the overview.\n. Alrighty, I've run in to some NPEs while running finagle-http's tests:\n```\n1) terminate http/1.1 connections without content length(com.twitter.finagle.http.codec.ConnectionManagerTest)\n   java.lang.NullPointerException\n    at com.twitter.util.Promise.become(Promise.scala:736)\n    at com.twitter.util.Promise$Transformer.k(Promise.scala:106)\n    at com.twitter.util.Promise$Transformer.apply(Promise.scala:117)\n    at com.twitter.util.Promise$Transformer.apply(Promise.scala:98)\n    at com.twitter.util.Promise$$anon$1.run(Promise.scala:412)\n    at com.twitter.concurrent.LocalScheduler$Activation.run(Scheduler.scala:201)\n    at com.twitter.concurrent.LocalScheduler$Activation.submit(Scheduler.scala:159)\n    at com.twitter.concurrent.LocalScheduler.submit(Scheduler.scala:239)\n    at com.twitter.concurrent.Scheduler$.submit(Scheduler.scala:107)\n    at com.twitter.util.Promise.runq(Promise.scala:405)\n    at com.twitter.util.Promise.updateIfEmpty(Promise.scala:791)\n    at com.twitter.util.Promise.update(Promise.scala:770)\n    at com.twitter.util.Promise.setValue(Promise.scala:746)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest.perform(ConnectionManagerTest.scala:118)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest$$anonfun$7.apply$mcV$sp(ConnectionManagerTest.scala:142)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest$$anonfun$7.apply(ConnectionManagerTest.scala:142)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest$$anonfun$7.apply(ConnectionManagerTest.scala:142)\n    ...etc\n2) terminate http/1.1 connections with Connection: close(com.twitter.finagle.http.codec.ConnectionManagerTest)\n   java.lang.NullPointerException\n    at com.twitter.util.Promise.become(Promise.scala:736)\n    at com.twitter.util.Promise$Transformer.k(Promise.scala:106)\n    at com.twitter.util.Promise$Transformer.apply(Promise.scala:117)\n    at com.twitter.util.Promise$Transformer.apply(Promise.scala:98)\n    at com.twitter.util.Promise$$anon$1.run(Promise.scala:412)\n    at com.twitter.concurrent.LocalScheduler$Activation.run(Scheduler.scala:201)\n    at com.twitter.concurrent.LocalScheduler$Activation.submit(Scheduler.scala:159)\n    at com.twitter.concurrent.LocalScheduler.submit(Scheduler.scala:239)\n    at com.twitter.concurrent.Scheduler$.submit(Scheduler.scala:107)\n    at com.twitter.util.Promise.runq(Promise.scala:405)\n    at com.twitter.util.Promise.updateIfEmpty(Promise.scala:791)\n    at com.twitter.util.Promise.setDone(Promise.scala:760)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest.perform(ConnectionManagerTest.scala:113)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest$$anonfun$8.apply$mcV$sp(ConnectionManagerTest.scala:150)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest$$anonfun$8.apply(ConnectionManagerTest.scala:150)\n    at com.twitter.finagle.http.codec.ConnectionManagerTest$$anonfun$8.apply(ConnectionManagerTest.scala:150)\n    ... etc\n```\nThese do seem to directly address what you're working on. Can you let me know if you see them as well?\n. Sweet, tests pass internally! Thanks! We're gonna canary before merging and I'll let you know when it lands.\n. We canaried this internally, but had to cut it very short due to reasons (which were not related to this PR). But we haven't forgotten! I'll update soon.\n. I've attempted to pull this in internally, but finagle-redis has moved quite a bit. Would you mind rebasing your changes on the latest in develop? After that, I'll make sure this gets in asap.. @mkhq Have you had the chance to bring this up to date?. @mkhq I always have a preference for smaller, more focused PRs, so that sounds great to me!. @Croyson is this what you're looking for? https://redis.io/commands/select\nFinagle supports the SELECT command.. @sohamsankaran this does sound like something we should be able to do more easily. It would involve modifications to Scrooge.\nThis is something that we'd like to do, but hasn't yet landed on our roadmap. If you'd like to take a stab at a PR, we'd love to help you out/answer any questions that might come up!. @iwag have you had a chance to take a look at this?. A new exception makes a sense to me, or at the very least a note in the exception. (\"Exception in mysql handshake: blah blah\").\nJust so I make sure I understand correctly - occasionally mysql server fails to deliver a properly formed handshake? Is this from some kind of connection failure or something?. Cool. Okay, moving forward with a new exception sounds pretty good to me. Take a look at our docs on how to use FailureFlags. It seems like this failure can be automatically retried, so make sure to flag it Retryable.\nLet me know if you run into any snags. Thanks!. @iwag Any luck with this?. Finagle's internal handling of retries definitely is less consistent than desireable and coming up to speed with it is akin to dealing with seven stages of grief. \nIn fact, we have two different sections of documentations dealing with failed responses - one for users of Finagle and one for developers of Finagle.\nBy the time you see exceptions/errors make it out of Finagle it means that either the retry budget has been exceeded or Finagle was unable to determine that it was safe to retry \"silently\".\nIn short, what you (the user of Finagle) should do is encapsulate your retry logic in a separate RetryFilter via the methods mentioned earlier. Your retry logic should be concerned only with your exceptions and response types.. Now that our documentation for MethodBuilder, I'm going to mark this ticket as resolved. That provides some great guidance around retries.\nFeel free to get in touch if you want to take a stab at making some documentation changes!. @spockz I'm going to close this for bookkeeping reasons. If you feel like working on it again, I'd be more than happy to re-open.. @spockz I'm marking this as closed for now, considering where we are with the aperture rollout & failure accrual stuff.\nFeel free to re-open (is that possible without admin status?) or create a new issue if you'd like to continue the discussion.. @koshelev Have you had a chance to take a look at this recently?. This definitely is a bug, but I think it's a bit more nuanced than handling the QUEUED response. Are you willing to do a bit of debugging? It would be really helpful to see what's going over the wire when this race condition hits.\nQuestions:\n- Does the ClassCastException stack trace eventually point to that casting line in Finagle?\n- Can you also post the NoSuchMethodError stack trace?. Nice detective work!\nIt does indeed look pretty clear cut. I'm not super familiar with redis, but is it also possible to view the server's response to each of those?\nA fix for this is now on our roadmap internally, although I'm uncertain of when it will be finished. The immediate workaround is to allow the transaction to complete before issuing another command:\nclient.transaction(cmds).flatMap { _ => client.mGet(....) }.map { results => ... }\n\nIf you'd like/have time, we're always accepting pull requests! My starting point would be examining RedisPool and seeing what's going on with transactions there.. After doing some digging, I think a PR would be most welcome here. Some notes:\n- This MIGHT be a breaking change for some folks who rely on chunked encoding to just magically happen. ...if they exist :)\n- Do you have an idea of how users will choose to make a chunked vs normal request?. @herberteuler Thanks so much for digging into this. I've also just chatted with @mosesn a bit more about this.\nOur conclusion here is that our lack of documentation should be fixed, and I've created a ticket internally to look into it.\nIn the meantime, can you accomplish what you're setting out to do by setting the content as Moses suggested?. @ghershfield have you had any luck with @mosesn's suggestions?. @Mura-Mi this looks good to me once @vkostyukov's comments about nulls/java types are addressed. Thanks!. Edit - I was not looking at only HTTP dispatchers.. Hi @yzb808, thanks for the report!\nThis looks to me like it lives in Netty's io.netty.buffer, as opposed to Finagle. Perhaps you meant to open a ticket with them?. Hi @yzb808, I'm going to close this ticket for now. If you believe this is a finagle issue and you run into it again, feel free to open an issue again.. Fixed w/ PR #640 . This is an interesting concept. As you point out, our dtab alt behavior is to only use the alt when resolution fails, as opposed to when service creation fails. This is (as far as I can tell) intentional and separate from the way we typically handle these kinds of resiliency things (see circuit breaking, for instance). \n@elecnix have you tested/run your proof of concept?\nIf you folks decide to build out this feature, I think it's important to very carefully think through:\n- What constitutes a \"failure\"? Loss of connectivity to the primary serverset?\n- Once in a failure scenario, how do we return to a healthy state?\nFinally, one more thought - if this sort of functionality is something you're looking to get up and running ASAP, it could be implemented by having two clients - one for the primary and one for the secondary. You could track successes and switch between clusters as necessary.\n@roanta I'd love to hear your thoughts on this, too.\n. Thanks! This merged in 79c9cfd. Merged in 1d42c39. Thanks!. Hi chris, taking a look at this today. @chrisbenincasa Awesome!\nBy the way, when you run your repl tests, could you please copy/paste the commands that you uses to test things into... maybe these comments? I know we don't have an official way of capturing that kind of testing, but at least having them here would be fantastic.. @bryce-anderson I'm re-opening this PR to allow @chrisbenincasa to post his testing REPL logs here. I'll close once they're posted.. I don't think we need to capture, it's only used once.\n. Ah, gotchya!\n. Would you mind adding the TIMEOUT to these Awaits too, since you're modifying this test?\n. nit: Import & use FunSuite directly. This annotation isn't necessary anymore and can be removed.. Can you also add a timeout here?. clump all of the imports together, they can be friends. we use a slightly different style here:\nprivate[this] def addHandlersToPipeline(\n  pipeline: ChannelPipeline,\n  sslHandler: SslHandler,\n  sslConnectHandler: SslServerConnectHandler\n): Unit = {\n\n. Yup: https://github.com/twitter/util/blob/develop/util-core/src/main/scala/com/twitter/io/ByteReader.scala. Some style nits for ya that I missed earlier:\nWe typically leave parens off of these types of methods (both defining and calling) unless they mutate in some way. Since this doesn't, please omit here and in isSigned. Looks like an unfinished comment.\nFun side note, this broke github's syntax highlighting. stray print. stray. Assert that the BigInt being written can indeed fit in 8 bytes. (Unless this is verified somewhere else that I can't see). Yeah, since (AFAICT) BigInt could store values that would be larger than 8 bytes.. haha awesome commit message :)\nSorry, I didn't mean to suggest that a comment was necessary here, only that there was a stray \"/**/\". I think throwing is the way to go. I'd rather have that then write invalid data.\n@bryce-anderson what say you?. Make a case class for (Double, Double, Buf) instead of a tuple for clarity. How about we avoid nulls here and just use Option directly?. Can you create a new named exception for this (can define it somehwere in the file here). I suggest something like:\nclass BigIntTooLongException(size: Int) extends Exception(s\"BigInt is stored as an unsigned long and thus cannot be grater than 8 bytes. Size: $size\". Is this ready to be uncommented now?. Add a link to relevant mysql docs please.. add something like \"for UPDATE and INSERT ... ON DUPLICATE KEY UPDATE type statements\". could you please revert this?. please revert. IMO, this is OK for now. I tried to get some kind of \"state of the union\" view of where tracing is heading and came up with nothing conclusive in 10 minutes - we'd have to do some serious digging to answer this question, I think.. Agreed.. I suggest leaving it as toLong for clarity. I think this would be nice in the scaladoc instead of a comment. Ah sounds like a pain :/\nI'm not too familiar with intellij, but I did some poking around and I found that we have some kind of Twitter scheme for code style here and that I could export it as XML. This is a totally unofficial solution and I'm not gonna guarantee that it will actually format properly, but you're welcome to give it a shot: https://pastebin.com/ZL0UkQ98.. nit - space after if. Overall, nice scaladocs!. Either put what these are for or ditch 'em. No need to have them here empty.. you can remove this annotation as it's no longer needed. no need to \"exclaim\" about these validation remarks. (or the other ones in the file). I think it's worth creating a case class for this return type. should be able to get this behavior with assert(x === y). I think. ffti - we typically use something like def await[T](f: Future[T], 5.seconds): T to save a bit more typing. I've never used this before. This is cool.. ",
    "atollena": "LGTM.\n. @olix0r If we do decide that this isn't useful for BindingFactory anymore or that the interface must change, there will be a note in the change log (and you'll find out soon enough). At that point you can just copy the code to your project.\nSo LGTM.\n. lgtm. I think this is a good addition, but how and when to use wildcard vs leave something as a residual isn't that obvious (moses getting confused backs this up). It would be nice to have an example in the docs. There is quite some duplication between Path and Prefix but I guess you found no easy way to unify them.\n. lgtm.\n. This is merged, thank you Oliver.\n. +1.\n. lgtm, I'm pulling this internally.\n. This was merged and will be in the next release, thanks @olix0r .\n. This is going to be useful for us, thanks for contributing that back.\nlgtm, pending notes in CHANGES and doc changes.\n. lgtm.\n. The number of concurrent DNS resolutions (and thus the number of threads spawned) is bound by a semaphore to a concurrency of 100:\nhttps://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/Resolver.scala#L109\nI could see value in making that more configurable, but presumably this would need to be done via a global flag, since InetResolver is a singleton.\nWe are exploring the use Netty 4 DNS implementation (io.netty.resolver.dns) which would make this implementation obsolete, but in the mean time you could submit a patch to tune the max concurrency level.\n. Why not annotate on failures (with a new WireSendError(error: String)) here and reuse AnnotatingTracingFilter?\nOtherwise LGTM.\n. I'm having trouble interpreting this, what is this supposed to mean? /foo//*//bar/baz?\n. Ha yes! /foo&#47;*&#47;/bar/baz reads as foo/*//bar/baz with a double slash though, no? don't you want /foo&#47;*&#47;bar/baz\n. Also as pointed out by dschoebel it will parse into Prefix(Label(foo),AnyElem,Label(bar),Label(baz))\n. nit: /s => /a | (/b & /c)\n. Good catch. Could we check if the Dtab has already been injected? \nYou could simply add a value in request.ctx for that (or perhaps you have a better idea?).\n. The fact that Dtab headers were silently removed from finagle requests has cost many hours of debugging, I would prefer that we keep it if it's not too hairy.\n. since this is a constant it should be capitalized and go into the companion object.\n. ",
    "codeferret1": "LGTM. Thanks!\n. ",
    "iwag": "the commit to fix is cc891eb?\nI'm really happy to see that \ud83d\ude03 \n. I saw a similar issue.\nIn my case, I didn't call close() method, so mysql's Aborted_clients or Aborted_connects had become the large value and then mysql blocked my clients.\nmysql  -e 'show global status;' | head\nVariable_name   Value\nAborted_clients 5335\nAborted_connects        24950\nYou may want to see 'show global status' if the same issue occurs again!\n. Sure!\nOur team develop search system in our video streaming platform and use finagle for its JSON API server. \nWe have more than 20 API endpoints. The APIs are almost same but have slightly different specifications :weary: Filter and service of finagle are fitted so much for us.  We implement the APIs using filter/service like combining the blocks.\nAs far as I know our company has the most number of Scala engineers/codes in Japan. but most of the teams use Play Framework :stuck_out_tongue:\nAnd I heard other one team in our company is developing something using finagle!\n. further details https://speakerdeck.com/iwag/rewrite-in-finagle \nsorry I have only Japanese slides\n. probably similar issue https://github.com/twitter/finagle/issues/439. Okay \ud83d\ude04  I will try.\nBut I'm not familiar with the implementation. \nDo you have any ideas where I start to do ?\n. @nepthar thanks for reminding me. I forgot to post my idea after digging for that. Anyway, I'm not familiar with MySQL but I suppose this is kind of correct behavior. MySQL Handshake phase fails and then LostSyncException occurs (see the stack trace).  In this case, I set to \"--max-connections=1\" and try hundreds of connections to MySQL server so the server doesn't send correct Handshake packet. \nHowever, this exception is a little confusing, isn't it? How about if making new type of exception? What do you think?. Sounds great! > a note in the exception.\nIt can be small amount of modification. I like it.\nThis is a kind of connection failure. MySQL server refuses to connect because of overcapacity. finagle-mysql seems to be unable to handle a error which occurs in handshake phase.. @smlance Great work! Thanks. ",
    "niw": "My pleasure \ud83d\ude09\n. ",
    "coveralls": "\nChanges Unknown when pulling cce929fd4d9c2fe32b9022e06834820ec6f7ad7c on luciferous:nox into  on twitter:master.\n. ",
    "suls": "I verified this with https://groups.google.com/forum/#!topic/finaglers/g_4i1xpfAJo ..\nWould adding a thrift/TLS test case be overkill?\n. Hi @kevinoliver - and thanks for checking!\nAs you can see in 9464bca43ad8b84a129767d018a58391b4ed74c6 I managed squeeze an additional character in the certificate .. :walking:\nWith eaf64a746ec43e542c4ba330d1db8f836a0a901c I tried to make the test a bit less brittle - StatsReceiver seems to not report a success sometimes when using the someway method ..\n. ",
    "jfeltesse-mdsol": "ok, now I've spent more time testing this through zipkin I can safely close this issue.\nThe confusion was that indeed that generate_id method does make unsigned ints sometimes but afterwards it's converted to an hex string by the SpanId class so no issue in the end.\nI guess the confusion on our end stemmed from the naming and, dare I say, the clunky API where you end up with calls such as trace_id.trace_id.to_s... :sweat: \n. ",
    "wmorgan": "Added!\n(TLS: I know right! Still waiting on our ops org...)\n. Bu\u00f8yant is actually our preference (in honor of Finagle's Norse heritage). But we're fine with whatever.\n. ",
    "3thinkthendoit": "@mosesn  thank you ,I get it.\n. ",
    "adriancole": "NM.. this was against the master branch\n. added note to breaking api changes, too!\n. Thanks!\n. Thanks for the suggestions. All applied. Note, there were more confusion on the other side, so I updated some of the text, particularly on Span and BinaryAnnotation. Might want to have a look again.\n. thx (fixed typo). Hang tight till tomorrow, then I'll tap your shoulder to merge. appreciate the support!\n. @mosesn ok ready to merge. thanks again!\n. thx for the heads up\n. cc @kristofa I know y'all at SoundCloud are using zipkin, though possibly more interested in kafka\n. Thanks for having a look, Kevin.\nso addressing service loader might undo the current hack of\nDefaultTracer.self = HttpZipkinTracer or similar, I guess.\nOne thing about the http tracer is that unlike scribe, there's no\nsensible localhost default.\nIf using service loader, it would need to I suppose resolve a name\nfrom discovery, else they'd still need to explicitly configure it? Or\nmaybe I'm missing something. Let's bear in mind that kafka transport\nwill likely follow.\n. Another approach is to use service loading plus flags (e.g. System\nproperties).\nThanks for the idea. Do you literally mean System.getProperty or Twitter\nflags? Do you have an example inside finagle somewhere of someone\nidiomatically using flags for a service loader implementation? I'm happy to\nwrite this, just curious the idiomatic way.\n\nI would defer to you and your users on how you'd prefer to do it. I\nsuspect the former is simpler for most though.\nYeah it makes it easier although default would probably need to be\nlocalhost (which would be OK for those in dev or forwarding http traffic)\nKafka sounds like it would be similar, there'd be a new\nfinagle-zipkin-kafka module, and it could be configured in whatever fashion\nis desired.\nGotcha. Once I write and get the HTTP one in the right shape for merge,\nKafka should be easy.\n. > At SoundCloud we have wrapper classes for building Finagle servers and\nclients. These thin wrappers deal with configuration like settings up the\ntracer. So instead of relying on service loading or overriding the\nDefaultTracer we explicitly set the tracer we use like this:\nHttp.server\n      .configured(param.Tracer(tracer))\n      ...\nSidebar, but I think failures in finding all the places to do ^^ resulted\nin my discovery of DefaultTracer. Probably I was missing some subtle\nentrypoint that wasn't configured via stack I guess. Sledgehammer, but\nDefaultTracer works for everything :P I suspect the best place to handle\nthis is in the README of the resulting tracer. Ex suggest the stacks\napproach you mentioned (with a fallback of DefaultTracer.self if that\ndoesn't have the intended effect)\n. ps there's some related work about abstracting the reporting function generically here. This would apply to kafka, too, for example: https://github.com/openzipkin/zipkin-java/issues/181\n. FYI, if someone wants to make an interim kafka subtype of RawZipkinTracer, it would look something like this..\n\n``` scala\n--snip--\n  val topic = \"zipkin\"\n  val kafka = \"localhost:9092\"\n  val props: Properties = new Properties\n  props.put(\"bootstrap.servers\", kafka)\n  props.put(\"metadata.broker.list\", kafka)\n  props.put(\"serializer.class\", \"kafka.serializer.DefaultEncoder\")\n  props.put(\"producer.type\", \"sync\")\n  props.put(\"request.required.acks\", \"1\")\n  val producer = new ProducerArray[Byte], Array[Byte]\noverride def logSpans(spans: Seq[Span]): Future[Unit] = {\n    // Write spans to a thrift list used as a keyed message body\n    val zipkinSpans = try {\n      val transport = new TMemoryBuffer(0)\n      val oproto = new TBinaryProtocol(transport)\n      oproto.writeListBegin(new TList(TType.STRUCT, spans.size))\n      spans.map(.toThrift).foreach(.write(oproto))\n      oproto.writeListEnd()\n      transport.getArray\n    } catch {\n      case NonFatal(e) => errorReceiver.counter(e.getClass.getName).incr(); return Future.Unit\n    }\n// send the message off, incrementing counters as needed\ntry {\n  producer.send(new KeyedMessage(topic, zipkinSpans))\n  okCounter.incr()\n} catch {\n  case NonFatal(e) => errorReceiver.counter(e.getClass.getName).incr();\n}\nreturn Future.Unit\n\n}\n```\n. fyi I plan to start on this tomorrow\n. @kevinoliver so here's what I am thinking, which I think is exactly what you said a while back:\nfinagle-zipkin remains the same, basically it holds what we might otherwise call finagle-zipkin-scribe\n- This allows folks to be undisrupted from a service loader POV. ie. they get scribe still with same flags\n- This is changed insofar as it depends on a new module finagle-zipkin-core, which pulls out the non-scribe code\nfinagle-zipkin-http and -kafka hold reporters for each of the transport, as well global flags to control the endpoints, and service loader definitions to enable them\n. Looks like the first wave of this work arrived in master. Thanks for the progress folks!\n. zipkin-finagle has all three transports implemented. please try it out!\nhttps://github.com/openzipkin/zipkin-finagle\nhttps://github.com/openzipkin/zipkin-finagle-example\n. > Does Http.server.withCompressionLevel work for you? (Looks like we could\n\nuse some scaladoc on that method and the others in Http.server to explain\nwhat they do).\nI think it gets wired into c.t.f.http.Codec which in turn wires up\nnetty's HttpContentCompressor for a server.\n\nCompression works, iirc. The question here is about decompression. ex can\nthe netty layer unzip a POST request body.\n. fyi this applies to 6.41.0\nhttp://search.maven.org/#artifactdetails%7Ccom.twitter%7Cfinagle-redis_2.12%7C6.41.0%7Cjar\n. Ran into this myself. I think the problem is that the build instructions aren't rooted here. For example, one shouldn't need to go to scala school or scrooge to figure out how to build finagle. On that note, the instructions in scrooge don't work either due to a cyclic dependency.\nEx. even if you skip tests like below, there's eventually a failure publishing scrooge locally due to a dependency on finagle. And you can't build finagle due to a missing dependency on scrooge.\n``` bash\nafter publishLocal on util, from scrooge, this will eventually fail.\n./sbt \"set test in publishLocal := {}\" publishLocal\n--snip--\n[error] (scrooge-generator-tests/*:update) sbt.ResolveException: unresolved dependency: com.twitter#finagle-thrift_2.11;6.35.0-SNAPSHOT: not found\n```\nI'll try building from master as building from develop seems impractical.\n. > @adriancole https://github.com/adriancole for what it's worth,\n\nscrooge-generator-tests are only tests, and nothing else has a dependency\non finagle, but we're aware it's a pain point. I think this would be better\nif we had a tool which handled this for you.\ndo you know of a syntax to get publishLocal on scrooge to work without it,\nthen? my sbt-fu might be lacking\n. getting closer.. it publishes things, except not scrooge-sbt-plugin, which\nis what finagle's build depends on\n. thanks for looping back. I'll give it a try!\n. works!\n\nOn Tue, Sep 20, 2016 at 9:13 AM, Adrian Cole adrian.f.cole@gmail.com wrote:\n\nthanks for looping back. I'll give it a try!\n. added a couple notes, none of which are important :) carry on. looks like the right path\n. +1 merging the structural changes first makes it an easy merge, and paves\nthe way for multiple transports being reviewed or added independently (ex\nhttp, kafka)\n. ps kafka servers are backwards compatible, but not the other way around\n. @kevinoliver sounds good.. how does mechanics like version bumps/releases occur from there? Is that something the finagle team conduct?\n. thanks. Reason I ask is that we host some projects in openzipkin org (ex\nbrave (java tracer), ruby tracer, go tracer).\n\nIn OpenZipkin org, we have access to sonatype etc via bintray, can do\ntag-driven releases on-demand, change teams etc.\nIn the Finagle org, we'd need to understand what automation, if any, we\nmight be lacking, or additional technology folks might need to learn or\nbecome responsible for.\nCan you elaborate a little on how releases would work if this were in\nFinagle's org?\n. ahh I see. so looking at finch, it appears it is published under the\n\"com.github.finagle\" group id (as opposed to com.twitter).\nhttp://search.maven.org/#search%7Cga%7C1%7Ccom.github.finagle\nThis validates what you mentioned, which is that releases are not\ncoordinated or performed by Twitter folks. In either project, I don't\nsee evidence of tag-driven release automation (ex. push this tag and\nmagically things appear in maven central).\nSince we aren't re-using any automation or inheriting version bump\nefforts (like we would if these transports were in finagle's repo),\nI'd suggest we host this in OpenZipkin's org.\n@sveinnfannar @kristofa @eirslett you game for us creating a repo in\nOpenZipkin for zipkin reporters to finagle?\nWe would publish them under the group id io.zipkin.finagle (and do all\ntransports in the same repo). It is easier for us that way as we don't\nneed to displace time on creating and maintaining a one-off release\nprocess. Also people in the OpenZipkin org are more likely to know the\nnature of zipkin updates I think.\nThe only downside is that people using finagle will have to look at\nthe OpenZipkin repo for zipkin integration as opposed to the Finagle\none. This implies at least a README change in finagle-zipkin here (in\nfinagle's repo) so that people can be directed accordingly.\n. PS I got feedback from gitter from @kristofa that OpenZipkin is preferred, but it doesn't mean the codebase couldn't move to Finagle's at a later time (since it is self-contained).\n. I've opened https://github.com/openzipkin/zipkin-finagle on this topic. If it turns out folks are against using it, we'll just delete it empty. @sveinnfannar you have write access. fyi @abesto\n. please do!\n. cc @sveinnfannar @kevinoliver @mosesn \n. good idea. done!\n. ahh of course. sure.\n. https://github.com/twitter/util/issues/169\n. ps by untested, I mean that there's nothing that shows the intent of the jackson logic apart from this bijection test https://github.com/twitter/finagle/blob/develop/finagle-zipkin-core/src/test/scala/com/twitter/finagle/zipkin/core/SamplingTracerTest.scala#L103\nI'd basically like to write a drop-in replacement of SamplingTracer without having to guess the serialization format this jackson code is trying to create.\n. Thanks for the green light. Good point that these arent really coupled as\nthe event stuff can be added later!\n. cc'ing some zipkin-finagle peeps:\n@mosesn @eirslett @sveinnfannar @kristofa\n. just had a chat with @capitanbatata about this. any thoughts about this proposal (or other ways to make intermediate spans?) it seems a nice and incremental win for those who want to model things like a dao layer.. >\n\nseems like a useful feature. what happens if more than one Start nests?\nwould it help to take an identifier?\nI suspect it would be similar to if multiple ClientSend() were called.\nideally, duplicates would be ignored.\n\nRight now, the status quo for local spans is pretending they are clients,\nso this is a pretty good way to think through things.\ncc @capitanbatata\n. I noticed a finagle tracer port by criteo has LocalOperationStart/Stop\nhttps://github.com/criteo/zipkin4net/tree/master/zipkin4net/Criteo.Profiling.Tracing/Annotation. whatever we do here, we should probably do consistently with other finagle tracer ports like zipkin-js and criteo's tracer cc @wirehead @eirslett @fedj. howdy we are about to merge the second identical implementation of this (after zipkin4net which is also a finagle tracer clone) https://github.com/openzipkin/zipkin-js/pull/156\nLocal tracing\nSometimes you have activity that precedes a remote request that you want to\ncapture in a trace. tracer.local can time an operation, placing a\ncorresponding span ID in scope so that any downstream commands end up in the\nsame trace.\njavascript\nconst result = tracer.local('checkout', () => {\n  return someComputation();\n});\nThis is supported underneath by two signaling annotations:\n``javascript\nfunction LocalOperationStart(name) {\n   this.name = name;\n }\n LocalOperationStart.prototype.toString = function() {\n   returnLocalOperationStart(\"${this.name}\")`;\n };\nclass LocalOperationStop extends SimpleAnnotation {}\n```\nThe first indicates the span name for use. In the recorder, we look at these and simply set span.timestamp/duration accordingly.\nSound like a decent fit for upstream? (here). > @adriancole https://github.com/adriancole what's the expected migration\n\nstrategy? use a zipkin which writes all 128 bits, but only uses 64, then\nwhen everyone is switched over, cut over?\npretty much. There would be a little dancing inside zipkin api when tracers\nsend mixed bits in the same trace, but yeah.\n\nMain thing is the transition design is made to have no impact until 128bit\nids are provisioned and propagated. This change request, is just a\nsafeguard in case some non-finagle callers propagate a 128bit id before\nfinagle is update, or the underlying zipkin one is.\n. https://github.com/twitter/finagle/pull/553 I just converted java to scala.. hope it looks alright.\n. @mosesn here's a summary.. agree the performance stuff is distracting.. I lept to it seeing other performance work in the file.\nInterestingly, there seems to be no performance impact if we just did a substring using the existing RichU64String stuff. If we keep with RichU64String, will just do substring.\nThe better numbers from the code I pasted are the results of attempts to get total overhead (knowing there's often 3 ids to parse, and tickers etc) in microsecond scale. In context, particularly around pulling headers off the wire, it might not be worth it here. lemme know if I should drop the custom id parsing function.\nBenchmark                                   Mode  Cnt   Score   Error   Units\nUtilBenchmarks.lowerHexToUnsignedLong_128  thrpt   15  53.340 \u00b1 1.851  ops/us\nUtilBenchmarks.lowerHexToUnsignedLong_64   thrpt   15  59.829 \u00b1 2.306  ops/us\nUtilBenchmarks.richU64StringToU64Long_128  thrpt   15   2.589 \u00b1 0.071  ops/us\nUtilBenchmarks.richU64StringToU64Long_64   thrpt   15   2.582 \u00b1 0.156  ops/us\n``` java\n  @Benchmark\n  public long richU64StringToU64Long_64() {\n    return new RichU64String(\"48485a3953bb6124\").toU64Long();\n  }\n@Benchmark\n  public long richU64StringToU64Long_128() {\n    String hex128Bits = \"463ac35c9f6413ad48485a3953bb6124\";\n    int length = hex128Bits.length();\n    String lower64Bits = hex128Bits.substring(length - 16, length);\n    return new RichU64String(lower64Bits).toU64Long();\n  }\n--snip-- calling lowerHexToUnsignedLong is uninteresting so not pasted\n```\n. ps looked at the test failures and they look unrelated\n. SGTM change on the way!\n. @mosesn ok much smaller change now\n. thanks for review! (and the tip on ternary. fixed)\n. Thanks for the support!\n. @kevinoliver @mosesn while the timing of implementing this isn't critical, I'd like buy-in on the approach used for binary serialization of TraceId (when 128-bits are in use). This is so that other libraries can update in anticipation of similar updates here.\nThe two most sensible choices seem to be..\n- check length and if 40 read traceIdHigh from position 16 (pushing everything else right 8)\n- check length and if 40 read traceIdHigh from position 32 (leaving everything else where it is now)\n. Brave (who's binary form in cassandra tracing context) uses the former (keep the two halves of the ID next to eachother in byte order). I think this makes most sense, but you do need to guard on length to see if you should read a traceIdHigh or not.\nThe latter was mainly to show two options :) Hypothetically, some demarshaller which works today might work by just choosing not to read the last 8 bytes. That said, it really depends on how the bytes are carried.\n. So I was chatting with @ellispritchard who maintains https://github.com/Financial-Times/tapper, and @fishcakez who is using it in a mixed environment with finagle. Also, I've thought about this a while now.\nI think the following is the best way for binary propagation:\n* check length and if 40 read traceIdHigh from position 32 (leaving everything else where it is now)\nFor others, we'd follow existing approaches that are working well for nearly a year now:\n add traceIdHigh field to trace context carriers, initialized to zero\n encode traceIdHigh as the left-most (high bits) of the X-B3-TraceId header when not zero.\n* for binary, add traceIdHigh as the last 8 bytes (when reading, check-length)\nI'm happy to help with this. Now we've a business case (existing user needing it), seems a good time to start. Sound good?. Thx for the start. Widening X-B3-TraceId seems the most pragmatic start.\nFor binary, we could consider the check length approach of growing thrift\nlater or adopt census (aka dapper2) format though it doesnt send parent ID\nhttps://github.com/census-instrumentation/opencensus-specs/blob/master/encodings/BinaryEncoding.md\n. @jcarres-mdsol fyi I'm pretty sure the zipkin gem will die on long ids until this happens\n. thank you!\n. @kevinoliver @mosesn I was just about to brag on how I have brave working sharing finagle's context in process. Then I realized that finagle is breaking tracing between processes :P\nWhile a workaround is to make an interceptor to rewrite the sampled header when we know downstream is finagle, it would be great to leniently read, or even better switch to 1|0 since most instrumentation use this convention.. cheapest fix is to special case and look for the character '1' as anything else ends up '0' anyway. Perfectly sensible. I will raise a PR for 0|1 tolerant reads\nOn 12 May 2017 12:35 am, \"Moses Nakamura\" notifications@github.com wrote:\n\nFor now let's leniently read, we can switch to writing 1|0 in a couple\nreleases. We need to give folks time to upgrade so that we don't break\ntracing for finagle services that aren't redeployed frequently.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/617#issuecomment-300845700,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAD610aF5DFr3A0SfTAOdcRvxBhogeXeks5r4zjRgaJpZM4NYO45\n.\n. https://github.com/twitter/finagle/pull/619. thanks for championing it\n. thanks for the help getting this in.\n. wrong commit link I think, though\n. The trace ID has cause to consider 128bit, but parent and span ID not. It is not likely at all to get a clash within a trace. Since neither B3 nor its successor TraceContext are on a track to have 128 bit span IDs, I would pull it from this change. For example, if you make span ID 128 bit, it will break and restart a trace on most things I am aware of (like istio, grpc/census and everything in zipkin). Hi, Jim. Great progress\n\nSummary is I think tmux can be separate as there are http-only finagle\nusers. Treat high absent/zero as the same.. ideally you cannot construct\nSome(0). That should simplify interop and also decisions.\n@mosesn other thoughts?\n. PS there's a small change we can consider when generating tracedIdHigh, to support conversion to amazon x-ray trace format. If we did this, we could provision traces that can tunnel through ELBs, fir example.\njava\n  static long nextTraceIdHigh(Random prng) {\n    long epochSeconds = System.currentTimeMillis() / 1000;\n    int random = prng.nextInt();\n    return (epochSeconds & 0xffffffffL) << 32\n        |  (random & 0xffffffffL);\n  }\nSee openzipkin/zipkin#1754. FYI there was at some point a question about other formats. census (dapper, grpc, etc) is piloting a format which may be accepted as a standard (named trace-context), or changed to suit that. It is too early to consider, but anyway it is largely compatible with what is going on with the trace context. https://github.com/census-instrumentation/opencensus-specs/blob/master/encodings/BinaryEncoding.md\nI think of this as a tactical, low-risk change to facilitate 128-bit IDs, and not necessarily a change the world, strategic one. Expect some time next year a plan for the latter, and of course participate between now and then if you can! https://github.com/TraceContext/tracecontext-spec. fyi I think nextTraceIdHigh could easily be done now, and probably should as a lot of sites are running in AWS and this helps make sure we can interop. Is there a technical problem implementing? If so, I can help more than what I pasted.. probably part of my last comment, but I can't see anywhere where we generate a 128-bit trace ID? Looks like this change will propagate, but not create 128-bit IDs. Am I missing something?\nEither here or very soon, we should allow generation of new traces in http with 128-bit trace IDs, possibly based on a flag. When we generate 128-bit IDs, that would be the code that eventually exercises nextTraceIdHigh.. Forgive old-school, but here's a patch I think works!\n```diff\ndiff --git a/finagle-core/src/main/scala/com/twitter/finagle/tracing/Trace.scala b/finagle-core/src/main/scala/com/twitter/finagle/tracing/Trace.scala\nindex bf3287a22..370978cba 100644\n--- a/finagle-core/src/main/scala/com/twitter/finagle/tracing/Trace.scala\n+++ b/finagle-core/src/main/scala/com/twitter/finagle/tracing/Trace.scala\n@@ -6,8 +6,14 @@ import com.twitter.finagle.util.ByteArrays\n import com.twitter.io.Buf\n import com.twitter.util._\n import java.net.InetSocketAddress\n+\n+import com.twitter.app.GlobalFlag\n+\n import scala.util.Random\n+object traceId128Bit extends GlobalFlag(false, \"When true, new root spans will have 128-bit trace IDs. Defaults to false (64-bit).\")\n+\n+\n /*\n  * This is a tracing system similar to Dapper:\n  \n@@ -92,7 +98,8 @@ object Trace {\n   }\nprivate[this] val rng = new Random\n-  private[this] val defaultId = TraceId(None, None, SpanId(rng.nextLong()), None, Flags(), None)\n+  private[this] val defaultId =\n+    TraceId(None, None, SpanId(rng.nextLong()), None, Flags(), if (traceId128Bit()) Some(nextTraceIdHigh()) else None)\n   @volatile private[this] var tracingEnabled = true\nprivate[this] val EmptyTraceCtxFn = () => TraceCtx.empty\n@@ -154,8 +161,10 @@ object Trace {\n     idOption match {\n       case Some(id) =>\n         TraceId(Some(id.traceId), Some(id.spanId), spanId, id.sampled, id.flags, id.traceIdHigh)\n-      case None =>\n-        TraceId(None, None, spanId, None, Flags(), None)\n+      case None => {\n+        val traceIdHigh = if (traceId128Bit()) Some(nextTraceIdHigh()) else None\n+        TraceId(None, None, spanId, None, Flags(), traceIdHigh)\n+      }\n     }\n   }\n@@ -377,4 +386,19 @@ object Trace {\n       }\n     }\n   }\n+\n+  /\n+   * Some tracing systems such as Amazon X-Ray encode the orginal timestamp in\n+   * order enable even partitions in the backend. As sampling only occurs on\n+   * low 64-bits anyway, we encode epoch seconds into high-bits to support\n+   * downstreams who have a timestamp requirement.\n+   \n+   * The 128-bit trace ID (composed of high/low) composes to the following:\n+   * |---- 32 bits for epoch seconds --- | ---- 96 bits for random number --- |\n+   /\n+  def nextTraceIdHigh(): SpanId = {\n+    val epochSeconds = Time.now.sinceEpoch.inSeconds\n+    val random = rng.nextInt()\n+    SpanId((epochSeconds & 0xffffffffL) << 32 | (random & 0xffffffffL))\n+  }\n }\ndiff --git a/finagle-core/src/test/scala/com/twitter/finagle/tracing/TraceTest.scala b/finagle-core/src/test/scala/com/twitter/finagle/tracing/TraceTest.scala\nindex 6484f4dae..cf9b8b131 100644\n--- a/finagle-core/src/test/scala/com/twitter/finagle/tracing/TraceTest.scala\n+++ b/finagle-core/src/test/scala/com/twitter/finagle/tracing/TraceTest.scala\n@@ -401,4 +401,12 @@ class TraceTest extends FunSuite with MockitoSugar with BeforeAndAfter with OneI\n       case rv => fail(s\"Got $rv\")\n     }\n   }\n+\n+  // example from X-Amzn-Trace-Id: Root=1-5759e988-bd862e3fe1be46a994272793;Sampled=1\n+  test(\"Trace.nextTraceIdHigh: encodes epoch seconds\") {\n+    Time.withTimeAt(Time.fromSeconds(1465510280)) { tc => // Thursday, June 9, 2016 10:11:20 PM\n+      val traceIdHigh = Trace.nextTraceIdHigh()\n+      assert(traceIdHigh.toString.startsWith(\"5759e988\")) == true\n+    }\n+\n```\n. Nice work Jim.\nNothing on my side at the moment.. all good. @llinder this when released\nmeans linkerd can do 128bit trace ids (potentially interop with aws.. we\ncan discuss offline this part)\n. Oops I meant @klingperf\n. >\n\nIf 0L isn't converted to None via the getter in Trace, this will allow\npropagation of invalid 128 bit TraceIDs (such as a stringified long which\nis left-padded with 0s). The getter protects against this, with the effect\nof reducing the span to 64 bit. Is that not acceptable, or do you think it\nshould propagate ids with invalid high bits?\nI hadn't changed this because the guard on 0L works similarly to the\nprevious implementation which reduce all 128bit TraceIDs to 64bit, and I\nwas waiting for a response to my previous comment before changing.\nthe TL;DR; is that a trace ID high of zero is the same as a 64-bit ID and\nshould be serialized as a 64-bit one. I understand that it is possible that\nsomeone sent a incoming trace with traceIDHigh as zero, but that's very\nunlikely as this binary marshaling approach is finagle-specific. In other\nwords, the only way a 40byte thing will have a 0L traceIdHigh is some\nclone, which would have to mis-implement what we do here.\n. oops.. we missed a spot.\n\nin TraceInfo.scala, we forgot to serialize the trace id header properly. When you enable traceId128bit, the below doesn't propagate the high bits (sending only half the trace ID)\n```\n  def setClientRequestHeaders(request: Request): Unit = {\n    removeAllHeaders(request.headerMap)\nval traceId = Trace.id\nrequest.headerMap.add(Header.TraceId, traceId.traceId.toString)\nrequest.headerMap.add(Header.SpanId, traceId.spanId.toString)\n\n```\nI think it should be something like\n// if traceIdHigh\n    request.headerMap.add(Header.TraceId, traceId.traceIdHigh.toString + traceId.traceId.toString)\n. >\n\n@adriancole https://github.com/adriancole @jcrossley\nhttps://github.com/jcrossley since this has been merged internally\nalready, what would be the process to add this last piece? Should I open\nanother PR, or can this change just be made internally?\n\n\nI just made one here https://github.com/twitter/finagle/pull/663\n. ps I tested this manually with zipkin-finagle and this change (which enables 128-bit there). Once something like this PR is in, I'll help show folks how to use 128-bit stuff.\nhttps://github.com/openzipkin/zipkin-finagle/pull/39. Any chance this could make it into a release soon? Would be nice considering there are a lot of events happening in the next two weeks.. great. thanks Isabel!\nOn Wed, Nov 29, 2017 at 9:40 AM, Isabel Martin notifications@github.com\nwrote:\n\nThank you @adriancole https://github.com/adriancole! This has been\nmerged in 76b6c9a\nhttps://github.com/twitter/finagle/commit/76b6c9a90e4e08b2b97941266f02786fdb13c9a9\n.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/pull/663#issuecomment-347724187, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAD61wfqYRqSwxc7zFWb_mkBywiOV4nHks5s7LYngaJpZM4QkJDx\n.\n. Hi. There is no working tracer library in finagle except scribe. If there\nwas http then folks who don't depend on non finagle libs (such as\nzipkin-finagle) can operate without using scribe.\n\nPractically speaking, very few know what scribe is or have experience with\ntroubleshooting it. You will find people making remote connections to\nzipkin over scribe as if this is a normal rpc (not a log arch). These\nconnections are not able to take advantage of intermediaries such as https\nproxies etc.\nZipkin server is not written in finagle, and depending on finagle is quite\na large dependency and easy to conflict with other code. Apache libthrift\nisnt a capable impl. The next best is FB swift service, but scribe was\narchived ages ago. This still uses netty 3. The encoding uses an old format\nwhich is itself wrapped in a base64 variant. This has caused compat\nglitches with others.\nKeep in mind I am the only fulltime maintainer of zipkin and volunteers\nusually have no interest in maintaining abandoned tech or dancing around\nconflicts due to it.\nWhen at twitter I understand scribe was still \"good enough\" or too much a\nmountain to move, but if we are honest it is dead arch that yes some use\nbut in no way helps with most folks sites. For the wider ecosystem outside\ntwitter, I ask to get rid of it or at least add a finagle native http\noption by default. A dep literally called zipkin anchors people to keep\nusing scribe and something we can change.\nIf 2018 is too hard even starting towards 2019 would be helpful, looking\nfor some hope here.\nOn 22 Feb 2018 6:25 am, \"Isabel Martin\" notifications@github.com wrote:\n\n@adriancole https://github.com/adriancole Hi, would you mind clarifying\nwhat you're hoping for a bit? As far as I understand it, Finagle doesn't\nuse scribe by default, but you can using the finagle-zipkin module which\nwill use scribe if you choose to depend on it. And if you wouldn't mind\nexplaining, which part of maintaining scribe is burdensome to OpenZipkin?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/675#issuecomment-367497330,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAD61x3fTb6LN3J_Aj30xuhvujSvRv66ks5tXJfjgaJpZM4SJJHB\n.\n. >\n@adriancole https://github.com/adriancole would changing the name to\n\"finagle-zipkin-scribe\" and adding some documentation fit what you're\nlooking for? It seems like unnecessary work for us to add our own http\ntracer implementation when zipkin-finagle already has one.\nI still think people will use this because it comes from the authoritative\nrepo, don't you? How much maintenance are you expecting from the http\nvariant? Is there a way we can help? We've been trying not to rely too much\non your help for things (I've helped with other things in finagle as you\nprobably recall)\n. PS what you mentioned would be an improvement as breaking the artifact\nID can alert folks they should be looking elsewhere. I do think people\nwill still use scribe anyway, because of the mild inconvenience of\nversion skew and different group ID but this could certainly help (and\nis trackable via maven central stats)\n. one clarification: if finagle-zipkin could become the right thing (ie\npackage http transport to let people switch over) this would be ideal.\n\nIf there's only one working transport upstream, even if people know it\nisn't the right thing, they likely will still use it. However, knowing it\nisn't the right thing is an improvement. So yes, if finagle-zipkin must be\nscribe, and only scribe, let's somehoe make it no longer seem like \"the\nright thing\".\n. >\n\n@adriancole https://github.com/adriancole it looks like in the short\nterm, we can rename finagle-zipkin to finagle-zipkin-scribe, and we'll\nupdate our docs to refer to zipkin-finagle.\nok and to be clear you are actively disinterested in an out of the box,\neven if community contributed finagle-zipkin-http?\nIn the long term we'll migrate off of it and delete finagle-zipkin-scribe.\nWhen that happens, we'll either supply a new transport that's whatever\ntwitter is using internally, or we'll stop exporting our own Tracing facade\nand will migrate to a common facade, like opentracing or zipkin-reporter.\nDoes that seem reasonable?\nI don't think ot has anything to do with this unless you are suggesting\nyanking the entire tracing api in finagle, which is overkill for the\ntransport decision IMHO. Reason is that OT does not have a data structure;\nit is a front-end api not an exporter interface like zipkin-reporter is. To\nexport via OT will be a dramatic redo, but also up to you. If you are doing\na complete rewrite you should also consider census which is more RPC in\nnature.\n\nOn Tue, Feb 27, 2018 at 3:50 AM, Moses Nakamura notifications@github.com\nwrote:\n\n@adriancole https://github.com/adriancole it looks like in the short\nterm, we can rename finagle-zipkin to finagle-zipkin-scribe, and we'll\nupdate our docs to refer to zipkin-finagle. In the long term we'll migrate\noff of it and delete finagle-zipkin-scribe. When that happens, we'll either\nsupply a new transport that's whatever twitter is using internally, or\nwe'll stop exporting our own Tracing facade and will migrate to a common\nfacade, like opentracing or zipkin-reporter. Does that seem reasonable?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/675#issuecomment-368627255,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAD6190utMSR-jfeGfQSlwM3k6nOid-Bks5tYwsDgaJpZM4SJJHB\n.\n. >\nI think we'd be open to a community contributed finagle-zipkin-http if we\nhad a commitment from the community to help support it, although it seems a\nbit redundant, given that zipkin-finagle http already exists. Would you be\nwilling to commit to reviewing PRs that come in for finagle-zipkin-http?\nYou've been helpful with reviewing other zipkin-related PRs, so I don't\nthink this would be a big shift.\nIn ideal world I think finagle-zipkin-http doesn't need to exist in, but\npractically speaking as people do download things and used what's pack-in,\nif a pack-in exists and that's only scribe, I hypothesize people will start\ndownloading it (we can look at stats later to see how wrong I am :) ).\n\nIf there was no pack-in, it would be more clear.. it is just where we are.\nHaving a pack-in that is http and works with tech that can consume zipkin\ndata (like jaeger, datadog, google cloud, aws).. that's worth doing\neventhough I have little time. If at some point scribe is removed, then we\ncan also consider removing the http transport (for the zipkin-finagle\nrepo). It is really about this transition period and making sure that we\naren't discouraging a transition. I'll also try to find someone else to\nhelp reviewing this stuff.\n\nOK, that's good feedback. We haven't looked too seriously at any of this\nstuff. I'll mention census in our internal ticket.\n:thumbsup: thanks for listening\nWe've renamed finagle-zipkin to finagle-zipkin-scribe, so the next step is\nto change the docs to mention zipkin-finagle.\nthank you for the help!\n. PS sorry I didn't think about this earlier, but... let's indeed hold\noff on added http here.\n\nHere's why: now that the artifact ID is changed, you should be getting\nmaven central stats about it. If the stats don't change from before\nthe artifact ID change, we could sense the rename isn't helping folks\nfrom resisting the pack-in. We can also cross this with zipkin-finagle\nstats. Presuming you have access, how about we review stats in a few\nmonths to see if there have been any impacts and take it from there?\n. @stevesoundcloud @kristofa @dgarson @lawrencefinn @chemicL @crispywalrus @teodor-pripoae @oskarblom @LarryFinn @umichyiwan sorry for the spam, but are any of you interested in this, or helping with it? If so, Moses can help with stewarding here and I can answer any questions etc.. ps this is related https://github.com/linkerd/linkerd/issues/2114. sure.. maybe like this..\n// don't reuse 4: optional i32 OBSOLETE_duration // how long did the\noperation take? microseconds\n. done\n. will do\n. done\n. Good point. Will update.\n. weird this didn't get caught as a rename..\n. one option is to drop this dep and instead use io.zipkin.java:zipkin:1.0.0 as that includes an implicit codec. In other words change to use the canonical model library.\n. ex in my local workspace, I made this a map of zipkin.Span.Builder.. not required, as such a change is internal-only and could be layered as easily later\n. Is there a META-INF change needed? or is the service loader unaffected by the rename\n. cool basically the extender just needs to implement sendSpans\n. @jcarres-mdsol I think the https://github.com/openzipkin/zipkin-ruby relies on this class, still. lemme know if my adjustment is not idiomatic\n. mainly as I noticed other performance related code in this type. retaining the last chars means a substring, which means another string. you're right, it is far less code to do it that way. wdyt?\n. again, performance related.. the code I pasted benchmarks better. you'll find that isDigit unfolds into quite many things. no problem reverting to RichU64String, if you say go!\n. here's the difference in the java variant:\nif (c >= '0' && c <= '9') {\u2028\nBenchmark                                   Mode  Cnt   Score   Error   Units\nUtilBenchmarks.lowerHexToUnsignedLong_128  thrpt   15  53.386 \u00b1 1.810  ops/us\nUtilBenchmarks.lowerHexToUnsignedLong_64   thrpt   15  57.554 \u00b1 2.446  ops/us\nif (Character.isDigit(c)) {\u2028\nBenchmark                                   Mode  Cnt   Score   Error   Units\nUtilBenchmarks.lowerHexToUnsignedLong_128  thrpt   15  33.529 \u00b1 1.376  ops/us\nUtilBenchmarks.lowerHexToUnsignedLong_64   thrpt   15  33.341 \u00b1 1.120  ops/us\n. For compat maybe better to add another spanid for high bits vs expand spanid to 128. In rest of zipkin we treat lack of traceIDHigh as unset. There's no binary format at the moment, and at some point there will be. However, here I think it is important to remain in \"compat mode\" with 32byte context when there's no traceIdHigh (or it is zero). This allows folks to upgrade more slowly.. if this were a java builder, I would just say something like TraceId.Builder.parseTraceId(String) or similar, which internally sets one of the two. Maybe you could consider making a constructor of TraceId which takes a string form of TraceId and internally does the same?. traceIdHigh is invalid as zero for sure (though using the aws-convertable scheme I mentioned, it is impossible to end up with a zero traceIdHigh unless you are tracing 1970 :) ).. one thing to bear in mind is that negative is needed or else you won't get full random. if trying to avoid 0, you can loop while nextLong == 0. This is unlikely to loop twice. ps I added this check because in the file and noticed we were burning some headers for no benefit.. don't recall if in scala case falls through, but debug implies sampled. so you could also set the sampled header here. ",
    "mallman": "Hi @roanta,\nThanks for helping. I implemented the change you suggested, and my application works as expected. LMK if there's anything else I can do to help debug this issue.\nCheers.\n. Great! Thanks!\n. ",
    "scf37": "@mariusae As for default configuration: Problem is default configuration is large and loosely documented. I do not need just 'balancing', I need to build system that can withstand different kinds of failures within time limits. and therefore I need to understand how balancing/retrying/error classification and handling works. As far as my experience tells me, there is no 'best' configuration - most is a trade-off between load , failure impact and recovery speed. Understanding defaults fully is tough and they could be changed in the future. So I prefer to combine filters manually.\nAs for design. I may be wrong here as I do not know Finagle internals well enough, so...\nRants:\n- Given Var[Set[Service]], create Service that balances that set. This task is too complex - you'll need to wrap/unwrap service factories and configure pools to keep underlying services opened.\n- Entire Stack implementation looks like typed dependency injection framework. While it allows to combine, re-combine and configure any part, it requires additional code to insert even simple filter w/o parameters. Also, combined Stack is hard to inspect and modify: What filters are in? What parameters do they have? What parameters are set? Can Stack type contain information on every element it contains?\nSuggestions:\n- Balancers need better isolation from what they balance. It looks like right now balancer client must call ServiceFactory.close() to indicate he is done with that connection/session/request so it can be returned to balancer's pool. Why not provide abstraction that can both work with Service and ServiceFactory and both with one-time and persistent connections? So programmer do not need to protect Balancer pool services from being really closed 'by design'.\n- Stack needs better toString and ability to enumerate available properties for every attached module. May be more. I was thinking of possibility to make Stack-s by combining traits so we get something typed in the end... Or may be something else.\n- ClientBuilder/ServerBuilder are great. Really.They list all available configuration in single interface so one can see what they do, what they don't do and what can be configured. So they are ideal for novices (give me something working but configurable) and experts looking for typical stack.\n- What I love in Finagle most is that it is (mostly) composable. It \"don't want it - just don't use it\" ideology. So I'd love to see better support for building finagle pipelines from scratch or predefined parts (like dam balancers with dam pooling and dam wrappers)\nPhew. \nI really like Finagle. Both its core ideology and dozens of technological marvels buried deep in the code, teaching valuable lessons on distributed services to anyone persistent enough to find them.\nI still have a lot to learn so take above wall of text lightly, it is just an opinion :-) And, guys, write better documentation! Finagle is much more than \"another simple HTTP client\" or \"low-level HTTP server\" but who knows about that?\n. @mosesn Please do not see this as attack. I'm just providing input so both me and you can learn. It is because negative input is the most helpful - you obviously should be more interested in parts your users aren't happy with while I surely can benefit from maintainer's point of view on Finagle. Collaboration is working together at the same goal - but I'm not there yet, I do not know enough of use cases and maintainer's intentions. So, I try to voice what I see as a problem so, again, you may know what users see a problem while I get your responses for my concerns so I can learn.\nTo summarize, you stand on \"this can be done\" and \"you do not need to use low level APIs like Stack\". While I'm all about \"this is too complex\" and \"I want to control behavior so I want to use low level APIs\"\nOr to say it in other way, I have no interest in framework that \"just works\". I'm interested in ideas, small independent components and their composition. You see, after 5 years with Hibernate/JSF I have no more faith in frameworks :-)\nP.S. Looking again at Stack.toString - still only role name and description is printed.\n. @mosesn I'm not that confident in my english :-)\nThe client request timeout is the maximum amount of time given to a single request\n(if there are retries, they each get a fresh request timeout). The timeout is applied\nonly after a connection has been acquired. That is: it is applied to the interval\nbetween the dispatch of the request and the receipt of the response.\nRequests timed out because of this parameter are not retried by default. \nTo alter this behaviour, mark  [[com.twitter.finagle.IndividualRequestTimeoutException]] as \n[[com.twitter.finagle.service.ResponseClass.RetryableFailure]] in custom \n[[com.twitter.finagle.service.ResponseClassifier]]\nWhat do you think? . So the right way to enable retries on timeout is to wrap built Service[Req, Rep] with another TimeoutFilter or alter Stack manually?. I see...\n- withRetryBudget/withRetryBackoff applies only to internal Finagle errors (networking)\n- ResponseClassifier has to do nothing with retries\n- buil-in retries aka RequeueFilter are designed for network errors and failure propagation via c.t.f.Failure exception\n- There is currently no support for application-level retries based on response classification\nFor example, I have Thrift service that can throw multiple exceptions, some of them retryable and some of them are not. So the right way is to put own RetryFilter over entire stack, including balancer?\nI wonder how do you guys use this internally. Directly throw FailureFlags exception from business logic to signal non-retryable errors (e.g. validation) ?. So, If i get this right:\n- ResponseClassifier only used by StatsFilter and FailureAccrualFactory\n- the only built-in retries are RequeueFilter which retries only 'safe' network failures (and this can not be changed). RequeueFilter uses context.Retries to propagate some data over request... I didn't get how it is used though.\n-  withRetryBudget/withRetryBackoff is only for RequeueFilter and, therefore, only for retrying safe network failures. Thus in real application will always be two retry filters - one for network-level retries and another for application-level retries, if applicable\n- balancers ignore individual response errors and make their decisions only on service status set by FailureAccrualFactory\n- possible Thrift/ThriftMux response are:\n-- response payload\n-- exception declared in thrift schema\n-- Failure(Rejected, NonRetryable) - other flags are not propagated. Tests show that Interrupted is not propagated as well which makes me wonder.\n-- TApplicationException for any other server-side exception\nIs that correct?\n. Failure.Interrupted is converted by ThirftMux to ServerApplicationError. Thus, ThriftMux can also return:\n- ServerError\n- ServerApplicationError\nIt really complicates error handling. Basically, I want error handling to detect at least three error cases:\n- errors that can be retried (e.g. some dependent service is unavailable or overloaded)\n- errors that should not be retried (e.g. validation error)\n- something unknown so it might be a bug (e.g. NPE)\nServerError/ServerApplicationError makes this really complicated. Why not let them implement FailureFlags at least?\nAlso it could be REALLY great to make FailureFlags public so Finagle can properly handle application exceptions, including sending correct failure flags over the wire.\n. ThriftMux connecting to unavailable port returns ChannelWriteException.\nIt seems finagle errors are diverse and unstructured. How do you write RetryPolicy for finagle clients? How do you work with persistent queues in distributed system? When processing a message from persistent queue, you must clearly know whether to consume it, throw it away or put to dead letter queue.. ",
    "amartinsn": "Nice!\n. Nice!!!!\n. Yes, initially it was not configurable. Only did that for testing purposes. Now using MockTimer I might revert that. Ta.\n. Not sure I got the idea of using MockTimer. It proceeds with svc(1) succesfully but when it calls svc(2) it gets stuck on the meter.await(1) part. It hangs forever...\n``` scala\n  test(\"mark dropped requests as rejected\") {\n    val timer = new MockTimer\n    val neverSvc = new Service[Int, Int] {\n      def apply(req: Int) = Future.never\n    }\n    Time.withCurrentTimeFrozen { ctl =>\n      val meter = AsyncMeter.newMeter(1, 1 second, 1)(timer)\n      val svc = new RequestMeterFilter(meter) andThen neverSvc\n      svc(1)\n  val f = intercept[Failure] { Await.result(svc(2)) }\n  assert(f.isFlagged(Failure.Restartable))\n\n  ctl.advance(1 second)\n  timer.tick()\n}\n\n}\n``\n. But we should wrap it in a Failure anyway right? So it can retried? If so,Future.exception(Failure.wrap(noPermit))` would do the trick, right?\n. Didn't get what you mean by \"resources that are artificially bounded\". \n. The idea of this test is to make the meter throw an exception because I'm trying to acquire more than 1 permit within a second, and check the exception type, etc. I've changed it to advance after the first call to meter. I've tried advancing a couple hundred millisecs but it still hangs. Only if I advance 1 sec it stops hanging, but it doesn't behave the way I expect, as it doesn't throw any exception. What am I missing? Thanks... \n``` scala\nval timer = new MockTimer\nTime.withCurrentTimeFrozen { ctl =>\n  val meter = AsyncMeter.newMeter(1, 1 second, 1)(timer)\n  meter.await(1)\nctl.advance(1 second)\n  timer.tick()\nAwait.result(meter.await(1))\n  println(\"done!\")\n}\n```\n. Yes you are right. The client is already controlling the request rate, so if it goes beyond that rate, it should throw an exception. Will change that.\n. Pushed earlier today a new version. \n. Done\n. Done\n. Done\n. Quite liked it! Was looking for a cleaner way of expressing this assertion! Thanks!\n. Done\n. ",
    "andrestc": "Addressed your comment, @mosesn. There were others missing the trailing slash so i added on those too.\n. ",
    "zfy0701": "the generated code you mentioned is just for client code\nthe server side code is at here:\nhttps://github.com/twitter/scrooge/blob/develop/scrooge-generator/src/main/resources/scalagen/finagleServiceFunction.scala#L1\nlet me know if you prefer we add that in generated code.\n. To avoid create stats receiver every time I could add a member variable and let it get initialized the first time it is used.\nHowever I feel unsafe because I didn't feel there is a hard constraint that one filter can be only used for one rpc. \nSo I opened another pull request for scrooge\nhttps://github.com/twitter/scrooge/pull/211\nthanks for reviewing my change!\n. Added comments. Thank you\n. @vkostyukov sorry I just realized I did something wrong (I should cast the newArgs as a Seq[Object]) and I probably didn't run the right set of test to check it.\nI could do manual check on both case, but having automatic test on both version might be hard (I'm really really new to  finagle/scrooge repository).\nAlso it would be great if you could let me know which test is failing.\n. @vkostyukov I found the cause is that I indeed pass one more extra argument for oldArgs, and I'm able to reproduce the problem by running finagle tests, after my this fix, the problem should be no more, could you try pull it again?\n. ",
    "adleong": "This has been merged and will show up in develop soon.\n. This has been merged and will show up in develop soon.\n. This has been merged and will show up in develop soon.\n. This has been merged and will show up in develop soon.\n. I have taken over this pull request here: https://github.com/twitter/finagle/pull/474\n. Thanks, @cacoco!\n. What is the status of this PR?  I'm very excited about SNI support in Finagle, is this still being worked on?. @ryanoneill ^^ ?. Ah I see.  So it's intentional that the underlying session is left open even when all clients have released it?  And the only way to actually tear down the session is to call close an extra time?\nclient().flatMap { service => \n   service(req).ensure { \n       service.close() // release this client's session\n       service.close() // actually tear down the underlying service\n   }\n}. Got it.  Thank you for explaining this to me!. https://github.com/twitter/finagle/commit/3e3ab1926845890687556129133e3540c219c2c1. For what it's worth, Linkerd currently depends on the behavior that { and } are not valid dtab characters:  https://github.com/linkerd/linkerd/blob/master/finagle/buoyant/src/main/scala/com/twitter/finagle/buoyant/PathMatcher.scala#L45. Yes, but if /{foo} is a valid finagle path, that won't be representable anywhere that Linkerd is expecting a path matcher because the segment will be interpreted as a variable capture and not as a literal path segment.  In other words, by allowing more things to be valid finagle paths, we would lose the ability to represent all valid finagle paths.. I don't really have anything to suggest.  Some form of encoding or escaping to encode curly braces as other Path legal characters maybe? \nI don't want to block development but we picked curly braces to use for this purpose specifically because we knew they were not legal Path characters.. Hey @mosesn, is the netty4 version still frozen?  We'd really like to pick up a bug fix from Netty 4.1.17. Thank you!. Ah, yep, this makes total sense.  Thanks, @mosesn!. I suspect the leak might be here: https://github.com/twitter/finagle/blob/develop/finagle-core/src/main/scala/com/twitter/finagle/loadbalancer/TrafficDistributor.scala#L285\nIt looks like when a new Distributor replaces the previous one, the previous one isn't closed.. ",
    "robsonpeixoto": "Thanks \n. I'm a finagle noob. I just get this recursion without the return.\n. Yes @mosesn. And will use the same type of the quickstart.\n. ",
    "matteosb": "Sure, we will probably write a blog post or two in the future.\nFor now I can say that the data/relevance team here at Brigade has adopted Finagle to implement its services, which are either computationally intensive (recommendations) or high volume (event logging). We expose them to a Ruby on Rails web app via Thrift.\n. ",
    "gpoulin": "@mosesn Sorry for the delay. I added comment in the changelog and added our extra verification to make the implementation more performant.\nI read back more in detail the CONTRIBUTING.md and fix my PR accordinly. However, I'm not sure of which part you are referring to. Let me know if there is still issues with this PR.\n. The client is configured with the following configuration:\n```scala\nval stack = com.twitter.finagle.Http.client\n      .configured(DefaultPool.Param(3, 100, 0, 1.second, Int.MaxValue))\n      .configured(ExpiringService.Param(Duration.Top, Duration.Top))\n      .configured(FailFast(false))\n      .withRetryBackoff(Backoff.exponential(1.second, 2).take(5))\n      .withLabel(name)\n      .withTransport.connectTimeout(5.seconds)\n      .withMaxResponseSize(StorageUnit.fromMegabytes(5))\nval resolved = Resolver.eval(url.getAuthority)\nval service = stack.newService(resolved, name)\n```\nWould having CancelledRequestException implements FailureFlags like it was done for ClosedChannelExceptions here prevent the CancelledRequestException from being wrapped in the first place?. ",
    "cocodrino": "@mosesn looks awesome :+1: thank you\n. ",
    "lukiano": "I'm in the process of updating a project from the old finagle-http to the new one (a.k.a. httpx). I used to have some code that wrote directly to the transport like let's say\nscala\n  def writeOld(list: List[org.jboss.netty.handler.codec.http.HttpChunk], transport: Transport[Any, Any]): com.twitter.util.Future[Unit] = {\n    list match {\n      case Nil => com.twitter.util.Future.Done\n      case h :: hs => transport.write(h) flatMap { _ => writeOld(hs, transport) }\n    }\n  }\nand now I'm trying to use the new facilities, writing to the Writable that the Response provides:\nscala\n  def writeNew(list: List[com.twitter.io.Buf], writable: com.twitter.io.Reader.Writable): com.twitter.util.Future[Unit] = {\n    list match {\n      case Nil => com.twitter.util.Future.Done\n      case h :: hs => writable.write(h) flatMap { _ => writeNew(hs, writable) }\n    }\n  }\nHowever, this writable only allows one element at a time, so this writeNew will block until someone starts consuming the Reader (this someone is ReaderUtils.streamChunks in HttpServerDispatcher).\nSince everything is happening on the same thread, I have a deadlock.\nHopefully my issue is now better understood.\n. Let me re-explain with a plain Java analogy:\nYou have a server with plain Java sockets. To write your response you send data to the SocketOutputStream, so it goes back to the client.\nYour Response class could have an OutputStream so consumer of the API write their response there.\nInstead it provides an InputStream (the Reader) and then the server implementation loops to transfer data from the InputStream to the SocketOutputStream (ReaderUtils.streamChunk).\nBut thinking that consumers of the API have data to write to an OutputStream, then you provide a PipedInputStream/PipedOutputStream (Reader.writable). \nThere will be 1 thread with the program logic writing to the OutputStream the Response provides (the PipedOutputStream) and a second thread looping, transferring data from the PipedInputStream to the SocketOutputStream.\nI just say there could be a second approach, where the OutputStream the Response provides is the SocketOutputStream, so only 1 thread is needed.\n. I'll try to find the time to write an implementation and open a PR.\n. StreamServerDispatcher and StreamResponse in the finagle-stream module may be the answer to this concern. Although StreamServerDispatcher is package private and the Stream CodecFactory doesn't seem to be as configurable as the Http CodecFactory.\nEDIT: No, it isn't what I thought. It still loops (this time on an Offer[] instead of a Reader) to transfer data to the Transport.\n. @mosesn I have a stream of data in a Process[Task, Bytevector] where Process is a scalaz-stream class and Bytevector is an immutable byte array / bytebuffer wrapper, from the scodec library. Converting from Bytevector to Buf is easy, from Task to a Twitter Future is also easy. The remaining issue is piping the stream to a reader.\n. Yes, I ended up implementing Reader via traversing the scalaz-stream Process using process.step\nYou can see the code https://github.com/lukiano/finagle-http4s/blob/master/src/main/scala/org/http4s/finagle/ReaderUtils.scala and https://github.com/lukiano/finagle-http4s/blob/master/src/main/scala/org/http4s/finagle/ProcessStepper.scala\n. @dschobel Will do!\nAbout your second paragraph, this isn't just ByteBuf, but actual Netty messages (HttpContent and inheritance) which also extends ByteBufHolder, which itself extends ReferenceCounted, so we can call retain()\nRelated, eventually this will need to be improved to support pooled ByteBufs\n. @mosesn Not sure yet as I'm not entirely familiar with ByteBufs, but was thinking something along the lines of when the Buf readerIndex reaches the end, then release the object.\n. I think the user should be able to choose between non-pooled or pooled buffers. Also they should be able to choose if they are heap or direct based. I think Netty defaults to direct, but in case of Unpooled buffers, maybe heap ones are better as a default.\nIf the user chooses to go in the direct/pooled route, it must be aware of the compromises. These are examples:\n- If there's only one buffer, like a short message, or a chunked message put together via HttpObjectAggregator, then it will be released when the service responds. That is, Future[Response] is completed.\n- If there are chunk of buffers, provided by the com.twitter.io.Reader of the request, each time read(n: Int) is called to get a new chunk, the previous one is released.\nI'm sure there are corner cases. This PR is to make it work with unpooled buffers\n. @dschobel I have updated this PR with the SimpleChannelHandler change, updated the commit messages, and updated the tests to reflect the casting issue.\n. I thought of that as well, but wasn't sure about maybe mixing concerns\n. ",
    "mehmetgunturkun": "Hi @mosesn, I am willing to solve this issue, now working on it. \nShould it be assigned to me?. Hi @mosesn, I guess I solved the issue but before creating a pull request there are several things that I want to ask:\n1. Should I talk to people in gitter.im about the way I solve the issue or these comments will be done in code review before the merger?\n2. In order to understand unsigned part, I used flags in the field data. There was no documentation for bits and their locations per each attribute in mysql side, so I dug into source code and find the bit masks for each attribute. I want to document this process and put a link to that source code so that nobody again needs to do this research. How should I do that?\nP.S. Sorry if I shouldn't have written these into issue\u00e7. Hi @mosesn, get well soon.\nYeah, I do not like checking isSigned in each case too. I though maybe adding this kind of function might help but couldn't be sure:\nval value = getValueForField[Int, Long](str, field)\nval value = getValueForField[Int, Long](reader, field)\nso that isUnsigned check would be only in that function.. Cool, let me change this code into that. Awesome!. Hi @mosesn I tried to do that with the helper function I mentioned\nval value = getValueForField[Int, Long](str, field)\nIt gets too complicated due to the implicit classes, so I guess this is a more clear way to do that, but if you want to see that version I can create another branch for you to review.\n@vkostyukov I added this part of the code to ByteReader, but how should I merge that to this? One idea is to wait for twitter/util to release a new version then upgrade its version in twitter/finagle and remove the duplicated part.. Hi @mosesn here is the link for gist:\nhttps://gist.github.com/mehmetgunturkun/e3f7974819a29bc6cd048eb4366707cc\nCheck StringValueConverter and BinaryValueConverter. @mosesn What about the merge with twitter/util? Are we going to wait for twitter/util to publish changes in ByteReader?. Hi @mosesn Should I wait for new release of twitter/util (probably 6.44.0) to move on to this issue, or is there a quicker way to use develop branch of twitter/util?. @ryanoneill Was the change, you mentioned, related to CopyingByteBufByteReader.scala?. @mosesn I guess I broke something. I just merged develop -> Support_Unsigned_Integer and removed these unnecessary functions, but coverage is decreased. I did sth. wrong?. @bryce-anderson it was a pleasure. @bryce-anderson, I got it, I'm adding that flag.\nFor CanbeParameter what should be the typeCode for BigIntValue, is Type.LongLong ok:\ndef typeCode(param: BigInt) = Type.LongLong\n. Hi @bryce-anderson, sorry for long delay. I have added considerSign flag to Row and take as a parameter in constructors of BinaryEncodedRow and StringEncodedRow, but I am not sure who is going to set this flags.\nBTW, if it is not clear, I can push the current version for you to check.. @bryce-anderson I am trying to merge develop branch into Support_Unsigned_Integer. However, I cannot pass all tests in develop branch. NumericTypeTest.scala fails and when I change readMediumLE to readIntLE, it passes, do you have any idea, why?. @bryce-anderson merged develop to this branch, everything seems to be fine.. Hey, @bryce-anderson that's great news. \nSorry for my inconvenience, I couldn't pay enough attention to the PR these days but it is awesome that it is merged now.\nThanks for your support too.. sth like: 9223372036854775808 (BigInt(Long.MaxValue) + 1)?. I didn't get. Longs bigger than 2^63 has Type.LongLong instead of Type.Long.  Should we use isUnsigned check for Type.LongLongs too?. ok then, just to clarify. I am using isUnsigned for Type.LongLong too and add another test case for that, right?. The thing is in order to store 9223372036854775808 in a column of MySQL Table, that column should be bigint. If the field is bigint then its type is Type.LongLong. Then, I guess adding another value type, let's say, BigIntValue and another function to MysqlBufReader, like readUnsignedLong which is returning a BigInt should solve our problem.. Yeah and if the data type of the column in MySQL, is unsigned long then the type of the field in finagle side is Type.LongLong. \nBTW by saying \n\nThe column should be able to be unsigned long\n\nYou mean BIGINT UNSIGNED, right. Is there a data type long n MySQL?. I think so too because the unsigned logic applies to all numeric values. \nThink about smallint if it is unsigned it can go until 65535 in MySQL side, but we are converting it to Short which has 32767 as a MaxValue.. Hey @mosesn, should I write and send the new version that includes all numerical fields with isUnsigned check?. Yeah sure.. Ok, I thought it might be good to see all cases in discrete.. I assumed that you're talking about isSigned logic, right? If it is, should I write comments for BinaryEncodedRow too?. That helper method might need implicit parameters, is that OK? Some project might have rules likes \"do not use implicits\" so I want to ask.. Sure, it is under twitter/util repo, right?. I have added for debugging actually but left as is, it might be helpful.. You mean remove TODO part (Line 51) or remove comments for unsigned test cases? . Are you suggesting checking the size of the array, to be sure that it is shorter than or equal to 8?. what if it is larger than 8, take first 8 bytes or throw an exception?. Sorry, I miswrote that, message should have been \"a sane comment\"  :). I can create an array of bytes in size of 8 and fill it in little endian order, is that ok?. Yeah, sorry I should have checked that - sending the fix.. Honestly, not sure how to set ignoreUnsigned flag for StringEncodedRow and BinaryEncodedRow.\nclass StringEncodedRow(rawRow: Buf, val fields: IndexedSeq[Field], indexMap: Map[String, Int], val ignoreUnsigned: Boolean = true) extends Row\nclass BinaryEncodedRow(rawRow: Buf, val fields: IndexedSeq[Field], indexMap: Map[String, Int], val ignoreUnsigned: Boolean = true)\nAs you see I set it to true in the constructor, how to set it to false explicitly, especially in a test?. ",
    "chandra-cd": "Ryanoneill,\nThanks for quick reply. We are using MySql 5.5.33 on Amazon EC2 instance. Here is the output that i get when i run the Example.scala from mysql example :+1:  \nINFO: Finagle version 6.30.0 (rev=745578b931893c432e51da623287144e548cc489) built at 20151015-163641\nNov 24, 2015 8:25:37 PM com.twitter.finagle.tracing.DefaultTracer$$anonfun$3 apply\nINFO: Tracer: com.twitter.finagle.zipkin.thrift.SamplingTracer\n1124 20:25:37.322 df402d15b3ff05e1.df402d15b3ff05e1<:df402d15b3ff05e1] ServerAddr(/10.191.5.183:3306)\ncom.twitter.finagle.exp.mysql.LostSyncException: java.lang.IndexOutOfBoundsException: Not enough readable bytes - Need 8, maximum is 0\n1124 20:25:37.362 a63fa3cec01f9ab4.a63fa3cec01f9ab4<:a63fa3cec01f9ab4] ServerAddr(/10.191.5.183:3306)\nChandra\n. I cleaned the project and tried again but now i am getting a different error :\n[info] Running com.twitter.finagle.example.mysql.Example\nNov 24, 2015 8:58:03 PM com.twitter.finagle.Init$$anonfun$1 apply$mcV$sp\nINFO: Finagle version 6.30.0 (rev=745578b931893c432e51da623287144e548cc489) built at 20151124-205603\ncom.twitter.finagle.exp.mysql.LostSyncException: java.lang.IndexOutOfBoundsException: Readable byte limit exceeded: 123\n[success] Total time: 136 s, completed Nov 24, 2015 8:58:05 PM\n. Ryanoneill,\nI was able to run the sample on a new instance of MySql server. Unable understand the reason for error on the other instance. Pythong and Java clients are able to connect but not through finagle.\nChandra\n. iwag,\nThanks for sharing your experience. I did face this issue and have to reset the stats. When i used the other version on MySql it works fine. It looks to  me that there is something different with MySql server on my EC2 server. I tried on my laptop with mysql installed locally and it works.\nI will try to boot a new instance of Ec2 server with MySql and will try to see if this is an issue with a particular instance or with all MySql server on Amazon EC2.\n. mosesn,\nit didn't work for with the version of mysql i was using but we migrated to latest version of MySql and its working.\n. I understand the bandwidth issue. It was not working with 5.5.33 on Amazon linux but works with 5.6 .\n. ",
    "mahakp": "lgtm\n. lgtm\n. ",
    "drewdeponte": "@mosesn I have updated the commit message. Sorry, missed the contribution guide. I was looking within the finagle-thrift directory. I should have popped up to the top level and looked.\n. @mosesn I have updated the commit message to conform to the contribution guide for this PR as well.\nAlso, if there is a particular version of thrift that it should be coupled to. We can lock it to that version or use Pessimistic version constraints (http://guides.rubygems.org/patterns/) to constrain it to only patch updates, or minors and patch updates, etc. I was just not familiar with the particular version it should be paired to so I just used the latest.\n. @mosesn I tried using 0.5.0 and I can't even get build 0.5.0 thrift to build on the latest OS X.\n```\n\u2718 bundle                                                                                                                                                                                               2.3.0 0m add_thrift_dep_to_finagle_thrift_gem 4b2df73 \u2717\nFetching gem metadata from https://rubygems.org/..\nFetching version metadata from https://rubygems.org/.\nResolving dependencies...\nInstalling thrift 0.5.0 (was 0.9.3.0) with native extensions\nGem::Ext::BuildError: ERROR: Failed to build gem native extension.\ncurrent directory: /Users/adeponte/.rbenv/versions/2.3.0/lib/ruby/gems/2.3.0/gems/thrift-0.5.0/ext\n\n/Users/adeponte/.rbenv/versions/2.3.0/bin/ruby -r ./siteconf20160314-70051-71mg0.rb extconf.rb\nchecking for strlcpy() in string.h... yes\ncreating Makefile\nTo see why this extension failed to compile, please check the mkmf.log which can be found here:\n/Users/adeponte/.rbenv/versions/2.3.0/lib/ruby/gems/2.3.0/extensions/x86_64-darwin-15/2.3.0/thrift-0.5.0/mkmf.log\ncurrent directory: /Users/adeponte/.rbenv/versions/2.3.0/lib/ruby/gems/2.3.0/gems/thrift-0.5.0/ext\nmake \"DESTDIR=\" clean\ncurrent directory: /Users/adeponte/.rbenv/versions/2.3.0/lib/ruby/gems/2.3.0/gems/thrift-0.5.0/ext\nmake \"DESTDIR=\"\ncompiling binary_protocol_accelerated.c\ncompiling compact_protocol.c\ncompiling memory_buffer.c\ncompiling protocol.c\ncompiling struct.c\nstruct.c:48:15: error: expected parameter declarator\nextern size_t strlcpy(char , const char , size_t);\n              ^\n/usr/include/secure/_string.h:105:44: note: expanded from macro 'strlcpy'\n  __builtinstrlcpychk (dest, src, len, darwin_obsz (dest))\n                                           ^\n/usr/include/secure/_common.h:39:62: note: expanded from macro '__darwin_obsz'\ndefine __darwin_obsz(object) __builtin_object_size (object, _USE_FORTIFY_LEVEL > 1 ? 1 : 0)\n                                                         ^\n\n/usr/include/secure/_common.h:30:32: note: expanded from macro '_USE_FORTIFY_LEVEL'\ndefine _USE_FORTIFY_LEVEL 2\n                           ^\n\nstruct.c:48:15: error: expected ')'\n/usr/include/secure/_string.h:105:44: note: expanded from macro 'strlcpy'\n  __builtinstrlcpychk (dest, src, len, darwin_obsz (dest))\n                                           ^\n/usr/include/secure/_common.h:39:62: note: expanded from macro '__darwin_obsz'\ndefine __darwin_obsz(object) __builtin_object_size (object, _USE_FORTIFY_LEVEL > 1 ? 1 : 0)\n                                                         ^\n\n/usr/include/secure/_common.h:30:32: note: expanded from macro '_USE_FORTIFY_LEVEL'\ndefine _USE_FORTIFY_LEVEL 2\n                           ^\n\nstruct.c:48:15: note: to match this '('\n/usr/include/secure/_string.h:105:44: note: expanded from macro 'strlcpy'\n  __builtinstrlcpychk (dest, src, len, darwin_obsz (dest))\n                                           ^\n/usr/include/secure/_common.h:39:53: note: expanded from macro '__darwin_obsz'\ndefine __darwin_obsz(object) __builtin_object_size (object, _USE_FORTIFY_LEVEL > 1 ? 1 : 0)\n                                                ^\n\nstruct.c:48:15: error: type specifier missing, defaults to 'int' [-Werror,-Wimplicit-int]\nextern size_t strlcpy(char , const char , size_t);\n              ^\n/usr/include/secure/_string.h:105:44: note: expanded from macro 'strlcpy'\n  __builtinstrlcpychk (dest, src, len, darwin_obsz (dest))\n                                           ^\n/usr/include/secure/_common.h:39:31: note: expanded from macro '__darwin_obsz'\ndefine __darwin_obsz(object) __builtin_object_size (object, _USE_FORTIFY_LEVEL > 1 ? 1 : 0)\n                          ^\n\nstruct.c:48:15: error: conflicting types for '__builtinstrlcpychk'\n/usr/include/secure/_string.h:105:3: note: expanded from macro 'strlcpy'\n  builtinstrlcpychk (dest, src, len, darwin_obsz (dest))\n  ^\nstruct.c:48:15: note: '__builtinstrlcpychk' is a builtin with type 'unsigned long (char , const char , unsigned long, unsigned long)'\n/usr/include/secure/_string.h:105:3: note: expanded from macro 'strlcpy'\n  builtinstrlcpychk (dest, src, len, darwin_obsz (dest))\n  ^\n4 errors generated.\nmake: *** [struct.o] Error 1\nmake failed, exit code 2\nGem files will remain installed in /Users/adeponte/.rbenv/versions/2.3.0/lib/ruby/gems/2.3.0/gems/thrift-0.5.0 for inspection.\nResults logged to /Users/adeponte/.rbenv/versions/2.3.0/lib/ruby/gems/2.3.0/extensions/x86_64-darwin-15/2.3.0/thrift-0.5.0/gem_make.out\nUsing bundler 1.11.2\nAn error occurred while installing thrift (0.5.0), and Bundler cannot continue.\nMake sure that gem install thrift -v '0.5.0' succeeds before bundling.\n``\n. @mosesn I also tried all the released versions between thrift0.5.0and0.9.1` have the same build problem.\nthrift 0.9.2.0 is the first one that builds correctly out of the box, which is second to the most recent release of 0.9.3.0.\nMy vote would be to go with 0.9.3.0 if at all possible. I know you were saying you thought the features it was using were still backwards compatible. Can we get someone to verify that who has more context?\n. cool cool, merge away when you are ready.\n. ",
    "davebarr": "<3\n. ",
    "wilhelmguo": "Upgrade neety version, the new neety has deprecated the CookieDecoder class.\n. Thanks for your reply.Because of involving netty source, I also had not good advice.I have get Cookie like this request.getHttpMessage().headers().get(\"Cookie\") and deal it with myself as my temporary solution,maybe we can implement a decoder method catch NumberFormatException and return the passable cookies.\n. ",
    "chchen": "zk2 only works for the resolution path, right? For announcing, zk is the only supported scheme I think.\n. ",
    "sunnykaka": "Thanks @mosesn , I will use the finagle 6-style api.\n. Hello @chchen , I didn't use zk2 in my project yet.\nI'll try it.\n. Hi @mosesn , I have fix it.\n. ",
    "daviddenton": ":)\n. Nice work @vkostyukov ... looks like it was an interesting one to investigate!!\nIs there a rough date on the next finagle release for 2.12 (early/late Feb)?\nThanks! \n\ud83d\ude00. ",
    "dy8000": "Thanks, finally get to to compile the dev branch. But I only want to clone the master not dev branch, and therefore can use maven repo, and use the examples to start developing. I did clone the master branch separately, but have other dependency problems, when trying : sbt \"project finagle-example\" run . Not being proficient in SBT feel very cripple. In Comparison Maven is simpler to get started. Any advise will appreciate.\n. I've that resolved. I think sbt evicts some libraries. -thanks.\n. I checked.   The dependency has the package. Is this the right version ?    \n<dependency>\n        <groupId>com.twitter</groupId>\n        <artifactId>finagle-thrift_2.10</artifactId>\n        <version>6.31.0</version>\n    </dependency>\n. Just figure out that before you sent out. updated it. no more stack trace. thanks!\n. ",
    "dpnchl": "master branch compilation failed for me with a 'module not found error: com.twitter#scrooge-generator_2.10;4.4.0'.  \nThe workaround I used was to update the 'scrooge-sbt-plugin' version to 4.5.0 in project/plugins.sbt. \n[Note: This is the same 'scrooge-sbt-plugin' version used in the develop branch]\nDetailed stacktrace of the error (for SE indexing)\nbash-4.1$ ./sbt compile\n[info] Loading project definition from /sources/finagle/project\n[info] Updating {file:/sources/finagle/project/}finagle-build...\n[info] Resolving com.twitter#scrooge-generator_2.10;4.4.0 ...\n[warn]  module not found: com.twitter#scrooge-generator_2.10;4.4.0\n[warn] ==== typesafe-ivy-releases: tried\n[warn]   https://repo.typesafe.com/typesafe/ivy-releases/com.twitter/scrooge-generator_2.10/4.4.0/ivys/ivy.xml\n[warn] ==== sbt-plugin-releases: tried\n[warn]   https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.twitter/scrooge-generator_2.10/4.4.0/ivys/ivy.xml\n[warn] ==== local: tried\n[warn]   /.ivy2/local/com.twitter/scrooge-generator_2.10/4.4.0/ivys/ivy.xml\n[warn] ==== public: tried\n[warn]   https://repo1.maven.org/maven2/com/twitter/scrooge-generator_2.10/4.4.0/scrooge-generator_2.10-4.4.0.pom\n[warn] ==== sbt-plugin-releases: tried\n[warn]   https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.twitter/scrooge-generator_2.10/4.4.0/ivys/ivy.xml\n[warn] ==== twitter-repo: tried\n[warn]   https://maven.twttr.com/com/twitter/scrooge-generator_2.10/4.4.0/scrooge-generator_2.10-4.4.0.pom\n[info] Resolving org.fusesource.jansi#jansi;1.4 ...\n[info] downloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.twitter/scrooge-sbt-plugin/scala_2.10/sbt_0.13/4.4.0/jars/scrooge-sbt-plugin.jar ...\n[info]  [SUCCESSFUL ] com.twitter#scrooge-sbt-plugin;4.4.0!scrooge-sbt-plugin.jar (3947ms)\n[info] downloading https://repo1.maven.org/maven2/io/netty/netty/3.6.4.Final/netty-3.6.4.Final.jar ...\n[info]  [SUCCESSFUL ] io.netty#netty;3.6.4.Final!netty.jar(bundle) (858ms)\n[info] downloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...\n[info]  [SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (325ms)\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]  ::          UNRESOLVED DEPENDENCIES         ::\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn]  :: com.twitter#scrooge-generator_2.10;4.4.0: not found\n[warn]  ::::::::::::::::::::::::::::::::::::::::::::::\n[warn] \n[warn]  Note: Unresolved dependencies path:\n[warn]      com.twitter:scrooge-generator_2.10:4.4.0\n[warn]        +- com.twitter:scrooge-sbt-plugin:4.4.0 (sbtVersion=0.13, scalaVersion=2.10) (/sources/finagle/project/plugins.sbt#L6-7)\n[warn]        +- default:finagle-build:0.1-SNAPSHOT (sbtVersion=0.13, scalaVersion=2.10)\nsbt.ResolveException: unresolved dependency: com.twitter#scrooge-generator_2.10;4.4.0: not found\n    at sbt.IvyActions$.sbt$IvyActions$$resolve(IvyActions.scala:294)\n    at sbt.IvyActions$$anonfun$updateEither$1.apply(IvyActions.scala:191)\n    at sbt.IvyActions$$anonfun$updateEither$1.apply(IvyActions.scala:168)\n    at sbt.IvySbt$Module$$anonfun$withModule$1.apply(Ivy.scala:155)\n    at sbt.IvySbt$Module$$anonfun$withModule$1.apply(Ivy.scala:155)\n    at sbt.IvySbt$$anonfun$withIvy$1.apply(Ivy.scala:132)\n    at sbt.IvySbt.sbt$IvySbt$$action$1(Ivy.scala:57)\n    at sbt.IvySbt$$anon$4.call(Ivy.scala:65)\n    at xsbt.boot.Locks$GlobalLock.withChannel$1(Locks.scala:93)\n    at xsbt.boot.Locks$GlobalLock.xsbt$boot$Locks$GlobalLock$$withChannelRetries$1(Locks.scala:78)\n    at xsbt.boot.Locks$GlobalLock$$anonfun$withFileLock$1.apply(Locks.scala:97)\n    at xsbt.boot.Using$.withResource(Using.scala:10)\n    at xsbt.boot.Using$.apply(Using.scala:9)\n    at xsbt.boot.Locks$GlobalLock.ignoringDeadlockAvoided(Locks.scala:58)\n    at xsbt.boot.Locks$GlobalLock.withLock(Locks.scala:48)\n    at xsbt.boot.Locks$.apply0(Locks.scala:31)\n    at xsbt.boot.Locks$.apply(Locks.scala:28)\n    at sbt.IvySbt.withDefaultLogger(Ivy.scala:65)\n    at sbt.IvySbt.withIvy(Ivy.scala:127)\n    at sbt.IvySbt.withIvy(Ivy.scala:124)\n    at sbt.IvySbt$Module.withModule(Ivy.scala:155)\n    at sbt.IvyActions$.updateEither(IvyActions.scala:168)\n    at sbt.Classpaths$$anonfun$sbt$Classpaths$$work$1$1.apply(Defaults.scala:1392)\n    at sbt.Classpaths$$anonfun$sbt$Classpaths$$work$1$1.apply(Defaults.scala:1388)\n    at sbt.Classpaths$$anonfun$doWork$1$1$$anonfun$90.apply(Defaults.scala:1422)\n    at sbt.Classpaths$$anonfun$doWork$1$1$$anonfun$90.apply(Defaults.scala:1420)\n    at sbt.Tracked$$anonfun$lastOutput$1.apply(Tracked.scala:37)\n    at sbt.Classpaths$$anonfun$doWork$1$1.apply(Defaults.scala:1425)\n    at sbt.Classpaths$$anonfun$doWork$1$1.apply(Defaults.scala:1419)\n    at sbt.Tracked$$anonfun$inputChanged$1.apply(Tracked.scala:60)\n    at sbt.Classpaths$.cachedUpdate(Defaults.scala:1442)\n    at sbt.Classpaths$$anonfun$updateTask$1.apply(Defaults.scala:1371)\n    at sbt.Classpaths$$anonfun$updateTask$1.apply(Defaults.scala:1325)\n    at scala.Function1$$anonfun$compose$1.apply(Function1.scala:47)\n    at sbt.$tilde$greater$$anonfun$$u2219$1.apply(TypeFunctions.scala:40)\n    at sbt.std.Transform$$anon$4.work(System.scala:63)\n    at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)\n    at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:226)\n    at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)\n    at sbt.Execute.work(Execute.scala:235)\n    at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)\n    at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:226)\n    at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)\n    at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:262)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n    at java.lang.Thread.run(Thread.java:744)\n[error] (*:update) sbt.ResolveException: unresolved dependency: com.twitter#scrooge-generator_2.10;4.4.0: not found\n. ",
    "fsareshwala": "@penland365 This is a great change. I see it needs a little love so I am going to try and take it over since we're looking for something like this internally as well. I'll fix up the code a bit and submit it -- you'll be the author and I'll be the signer. Thank you for working on this thus far! Great work!\n. ",
    "sveinnfannar": "Hi guys, I started some work on this over the weekend. I just synced with @adriancole and I'll take this over.\n. This diff is too large, I'm going to do some git foo to make it easier to review.\n. Ok I force pushed a change that separates the moving of files from the actual code changes. The PR is now easier to review commit by commit.\n. Thanks for the review @mosesn.\nOk, I'll rename this PR and put the finishes touches on it.\nRegarding breaking out the scribe stuff, do you mean something like having a module named finagle-zipkin-scribe?\nfinagle-zipkin already contains only scribe specific stuff. We could rename it to finagle-zipkin-scribe. Then for backwards compatibility we would have a finagle-zipkin module that just depends on finagle-zipkin-scribe.\nIt would basically only contain a service loader and something like this:\nscala\npackage com.twitter.finagle.zipkin.thrift\n@deprecated(\"Use com.twitter.finagle.zipkin.scribe.ScribeZipkinTracer instead\", \"6.36.0\")\nclass ZipkinTracer(..) extends ScribeZipkinTracer(..)\n. @mosesn I finished some minor tweaks and manual testing so this PR should be ready. The notes in CHANGES still need an RB_ID. Is that something you add internally?\n. @kevinoliver thanks for a thorough code review!\n. @kevinoliver I addressed the comments, can you take another look?\nThe changes are all pretty superficial besides this one: https://github.com/twitter/finagle/pull/513/commits/262614b8e5a6d3d005aeb62aebece1565234ce6f\n. Hi @kevinoliver, I addressed your comments.\nAnd subsequently changed to emacs since IntelliJ kept formatting random code segments like a crazy person. Sorry for all the formatting diffs.\n. @adriancole, I'm putting the finishing touches on the kafka PR, stay tuned :)\n. Yes no problem\n. @kevinoliver done \ud83d\udc4d \n. ok, just ping me on gitter if I can do anything to help\n. Great to hear. Thanks for the help.\n. @mosesn: this PR depends on #513 so the diff is misleading. Is that fine or should I base the PR against the #513 branch? Do you have any suggestions?\n. @adriancole, I used kafka-clients version 0.8.2.2 because that's the version zipkin-collector uses.\nDo you think we should use a newer version since 0.8.2.2? One reason to use a newer version is that 0.8.2.2 is quite old. The downside is that clients cannot be newer than the brokers.\n. @eirslett: no not yet. I plan on productionizing this at Quizup this week.\n. @schrepfler thats a very good point. Here are the pros and cons in my opinion:\nPros:\n- Lot 'o bug fixes, features and stability improvements\nCons:\n-  Kafka clients cannot talk to older clusters so users will have to upgrade their clusters\n- The Zipkin consumer uses 0.8.2.2 and there is a performance impact on 0.10 brokers when dealing with older consumers. However that can be avoided with some configuration if necessary\nAs far as I see there are no compelling reasons to keep backwards compatibility with older versions of kafka. I'm going to change to 0.10.\n. I squashed the commit \"Use kafka-clients-0.10 and use new config options\" into the previous one\n. @kevinoliver I agree, a separate project makes sense.\nI'll get everything set up in a separate repository and transfer the ownership to the finagle organization.\n. Sorry for the radio silence, I've been very busy the couple of days.\nI will start working on this again on Monday.\nBtw @eirslett, I still haven't gotten around to running this in production.\n. yes, it did in my local git diff\n. Yes it should be unaffected.\nMETA-INF/services/com.twitter.finagle.tracing.Tracer in finagle-zipkin points to com.twitter.finagle.zipkin.thrift.SamplingTracer.\n. Very good point. Although I'm going to try keeping the scope of these changes as small as possible. Let's look into it when the rest is done.\n. :$\n. In the breaking section I listed the public classes (and companion objects) affected.:\n\n\nfinagle-zipkin: Moved case classes Span, ZipkinAnnotation,\n  BinaryAnnotation, Endpoint and Sampler to finagle-zipkin-core.\n\n\nhttps://github.com/sveinnfannar/finagle/blob/a7fbf5370dffd88a0d054b9e45ca2ca4b6ee3592/CHANGES#L57..L59\n. good catch \ud83d\udc4d \n. btw, I fixed up the commits so this appears as a rename\n. I replaced c.t.f.zipkin.thrift.SamplingTracer with a SamplingTracer that extends c.t.f.zipkin.core.SamplingTracer with a default constructor. This is because the service loader used to load c.t.f.zipkin.thrift.SamplingTracer.\nNow I realize I can remove c.t.f.zipkin.thrift.SamplingTracer, create a c.t.f.zipkin.thrift.ScribeZipkinTracer and change the service loader to load that instead.\nI'm not familiar with the intricacies service loading, do you think that will break anything?\nActions speak louder than words so maybe this commit explains this better than I do: https://github.com/twitter/finagle/pull/513/commits/262614b8e5a6d3d005aeb62aebece1565234ce6f\n. Gotta run, I'll fix this tomorrow \ud83d\udc4d \n. ",
    "greenrd": "I mean in MapHeaderMap.\n. Will do!\n. Was fixed in 603c0226029f8cc9da2ea628e793e80a91c170ef\n. ",
    "cacoco": "@adleong we've merged this internally on Friday (with the changes Dan suggested) and will be sync'd on the next push to Github (Monday). Thanks.\n. Already merged #467. Thanks!\n. This has been merged internally and should be pushed on the next sync.\n. @mkhq LGTM. We can work on getting this merged.. @sullis sbt 1.0.4 introduces a scala compilation regression that fails for one of our other projects (Scrooge). The regression was patched in 1.0.3 but looks like they didn't apply it to 1.0.4 before releasing. \nThis is the issue: https://github.com/sbt/zinc/issues/127. Merged in dac39f21b121898cd8f905ba61536ad07e62bab5. Thanks!. @AlexITC thanks for the issue. Looks like a dependency issue has been introduced. We'll take a look.. @MohsinBXL thanks for the issue, we'll take a look. It looks that perhaps the URLClassloader can return nulls in the array and it isn't being properly handled. We'll take a look, thanks!. Fix merged in Util: https://github.com/twitter/util/commit/3adca94a9e2b21a702aad619902ce5ef2e29de65. @vsabella in general Finagle is highly sensitive to a specific version of Netty -- the one listed in the build.sbt and is not expected to work with any other version. Updating Netty is generally a large process and not something we would likely accept in a pull request (sorry) as we have to move/fix internal things on occasion. With that, we are actively working to update to Netty 4.1.26 soon. Stay tuned, thanks!. @spockz Finagle originally bled many Netty types through its API and we are still paying the price for that. We are not quite done fully removing Netty types from all Finagle APIs. But that is the eventual goal which would allow for shading. Thanks.. Finagle is developed internally in a monorepo and thus changing a core dependency like Jackson requires updating the entire internal repository so we tend to do these updates ourselves. \nTo make this change, we need to update our internal monorepo all at the same time which are not currently ready to do. But please stay tuned.. If you're OK with it, I'm going to close this issue for now. As we chatted, I would try to add some exclusion rules. Please feel free to re-open or open a new issue if you have problems.. Merged in de668dbc06d71b302bc2918fbd297a614fd698f8. Thanks!. I'm with @mosesn on moving this into finagle-core. I have at least one (major) use-case that would benefit from this and we've been hoping to get this LB for a while. cc @roanta \n. ",
    "leonmaia": "Thanks for the feedback @kevinoliver :)\n@mosesn sure! Sorry for taking so long :) I was very busy last week.\n. I've applied all changes @kevinoliver, please let me know if there's something else. :) \n. @bryce-anderson sure :) We are breaking down a huge monolith into new services to be used both internally and externally (can't give more context than that, unfortunately). I basically chose it because of the great experience that I had before at Globo and other companies :) Thanks for the great work you guys are doing.. ",
    "grandbora": "@kevinoliver thanks for looking into this. You pointed a valid concern. What do you think if I implement the second approach (Merge on read)? Would that be ok?\n. Hey @kevinoliver , I gave it a shot and introduced a slightly more complex logic to work around the problem you described. I updated the pr description and added some tests for backward compatibility. I'd appreciate if you can have a look.\n. I updated the CHANGES accordingly.\n. Yay! Looking forward to use this on prod. Thanks @kevinoliver \n. I was aware of that point, I saw no harm in leaving it to the default because I think as long as it is consistent through out the life cycle of the running app (or most likely within the life cycle of a single request) it should be fine. So that was my reasoning.\nHowever I am no expert on this stuff, so tried to add what you suggested. It didn't work out because it expects a Locale not a Charset. I ended up using Locale.US. If there is a twitter convention for this please let me know.\n. Correct me if I am missing something here. The purpose of the rework was to make sure that we return the original header names, not the normalized ones. There is a test case specifically for that. So behavior here should not change.\n. You have a valid point here. I was going to suggest adding a deprecation here. But I personally prefer breaking the api by removing this constructor. Reasons:\n- there is already an apply method which takes tuples. I would expect that most people are using that over this constructor.\n- this is a pretty easy fix on the users' side. I don't think it worths the trouble of deprecating it.\nLet me know which way you want to go with. Happy to do the changes.\n. Removed https://github.com/twitter/finagle/pull/473/commits/8f01e6bf3b02809cc60b242ea9d6c1aea1640d26\n. ",
    "mritman": "Hi @luciferous, I should note that the problem does not occur when the server sends back a 200 response. I'm interested to hear what you find when testing with my example.\n. I'd also argue that regardless of whether this issue is specific to the use of Tomcat or not, since it's the client's sockets that increasingly end op in CLOSE_WAIT, this is something you'll want to guard against from the side of the client.\n. @luciferous I also noticed the timeouts while testing. If you set the connection pool limit to 1 in my example project and wait for Tomcat to close the connection you'll see that Finagle starts timing out on it. So it looks like Finagle doesn't detect the connection is closed by the server and continues to try to read from it, which is in line with @olix0r's observations.\n. > Note that if our Await.result fails, then we never assign the new response to the response variable, so if it opens a read handle, we will never have the opportunity to discard the read handle.\nSo if this case can't be handled by the user of the Finagle API, I take it it's correctly handled by Finagle itself?\nIs the following understanding of how to use the Finagle client with streaming enabled correct?\nWhen using streaming you either:\n1. use Await.result(Reader$.MODULE$.readAll(response.reader()))); without a timeout, thus blocking\n2. or use it with a timeout but you keep trying until the call returns without timing out.  Await.result(Reader$.MODULE$.readAll(response.reader()), duration));\n3. or you keep reading in a streaming fashion until you encounter the a final chunk of length zero (How to detect this? By inspecting the response? Does the Response class offer a method to check for this?)\n4. or you need to make sure you call response.read().discard().\nNo need to answer my questions specifically, but if you can provide a summary or a link to some documentation on how to correctly use the Finagle client with streaming enabled you can close this ticket as far as I'm concerned.\n. ",
    "nrinaudo": "It absolutely is, you're right. Dont't know how I failed to find it, I'm sorry.\nI might be a bit busy this week but I think I can get something done this weekend. It looks like a 2 lines modifications (@vkostyukov pointed me in the right direction).\n. The problem turns out not to be server side decoding implementation - I have something locally that works fine - but client side encoding, which I'll need at least for testing.\nFrom what I managed to piece together, content encoding in netty must go through HttpContentEncoder, which is implemented in such a way that it must be called in response to a request: if messageReceived isn't called, netty doesn't populate its accepted-encoding list and freaks out when asked to encode content. It thinks it's trying to respond to a non-existing request and throws a scary sounding IllegalStateException(\"cannot send more responses than requests\").\nI could probably hack together a custom implementation of HttpContentEncoder, but before I go down that road, is there a known, clean way of working around that issue? My netty knowledge is next to non-existent, so I might be overlooking something obvious.\n. @vkostyukov Sorry, I wasn't clear. The server side decompression works fine, it's the client side compression that's tricky. The issue I'm having is not with HttpContentDecompressor But HttpContentCompressor.\n. Thanks for taking the time to look into this and to file a much more informed issue than I could have.\nI'll do as you suggest, even though it would definitly make sense to add client side compression support at a later date. I was hoping to piggyback EndToEndTests, but I can simply write a test that sends gzipped content with the appropriate header (if I can set a custom Content-Encoding Header?) and makes sure it's properly decoded server side.\n. Mmm, that wasn't very clever, I just overwrote all my questions with that last commit. Let's start over.\n1. adding a timeout to Await.result: you're absolutely right, and I've updated the code accordingly. I feel I must point out I didn't initially specify a timeout because very few such calls in the tests do set a timeout, and I thought this was the way things were done in Finagle.\n2. spawning a new server for each individual test: I'm fine with that, but what's the recommended pattern for enforcing resource cleanup if an exception if thrown during a test? afterAll has the advantage of being guaranteed to be called, which is why I tend to use if to free resources when I can, can you point me to some idiomatic Finagle code that deals with this issue?\n. @mosesn understood. I've updated the PR accordingly, let me know if you feel anything else is dodgy.\n. This makes sense, but I feel I must point out I failed to do so because EndToEndTest mostly does not specify timeouts - I assumed this was the way things were done in Finagle.\nBy which I do not mean to say I won't fix this problem - I will, you're obviously right - but rather that EndToEndTest might need some work.\n. I'm fine with that, but how do you ensure everything is properly closed down if the test fails? afterAll has the advantage of being executed even if individual tests throw exceptions, which is why I tend to implement resource cleanup that way when I can. What's the proper Finagle pattern for dealing with that?\n. ",
    "bmorganatlas": "I've also run into this issue. I'm not sure what is going on either because rewriting the example Client object to request against google.com gives the expected 302 result.\n. ",
    "jabley": "That doesn't fix the issue for me. Essentially the Proxy is making a request equivalent to:\ncurl -H \"Host: localhost:8080\" http://google.com/\nwhich is why Google returns a 404. I'm not sure how you configure finagle to print out that level of detail, which is why I used Wireshark.\n. ",
    "frank-zg": "server.\n. ",
    "anupamaggarwal": "@mosesn thanks for the response, my bad I should have been more specific and should have filed the issue under scala-bootstrapper.  The problem I am facing is not with compiling finagle but compiling a finagle based service generated using scala-bootstrapper.\n. ",
    "liyichao": "Yeah\uff0cthrift version is 0.9.1\n. Yeah, the program works when zipkin is at 1.25.3 where finagle is at 6.30.0. So, I think the answer is yes.\n. @roanta Thanks, after zipkin upgrading finagle to 6.34.0, the symptom disappears.\n. ",
    "yokoshin": "lgtm @olix0r \n. ",
    "johanstenberg92": "@vkostyukov and @olix0r thanks for replying. I've solved it by creating my own load-balancer.\nWould a PR be interesting to take a look at @vkostyukov? With a new load balancer? Otherwise you are free to close this!\n. @mosesn cool, I'll create a PR in the next 24h and reference this issue, cheers!\n. References issue #496.\n. Thanks @mosesn for the feedback! However @olix0r your comment you stated in the issue (#496) made me think. \nI guess the purpose of using a load balancer is to balance the load of the provided hosts, not to provide some layer of resilience management (even though it naturally does, it's first a load balancer and second a resilience-manager). To evaluate on \"strong eventual consistency\", let's just scratch the word strong and use eventual consistency. \nWith the original Finagle client, I can write a value to my in-memory, eventually consistent database and then when I read it instantly after, the Finagle client has rotated to another host and I can't find my value! If you want to support eventually consistent systems and the use case I just described - should it be done with load balancers such as this PR or is it up to the user of Finagle to write a thin wrapper around the client?\n. Now we are talking about consistency from two different perspectives, you're talking about the client's perspective. Let's focus on the PR - @mosesn do you think this PR is bloaty and it's provided logic should be handled by the Finagle user through e.g. ServiceFactory? Or should I fix it according to your feedback? If we forget about eventual consistency for a moment, I would argue this LB can be useful in testing etc.\n. @mosesn feel free to close this PR and the corresponding issue then! Cheers\n. ",
    "yukw777": "@mosesn Ah sorry, that was a typo. Fixed now.\n. Hmmm. I dug into it more, and I'm starting to think that I might be misunderstanding the problem. Just to verify my suspicion, please see the snippet below.\n// http is a http service of type Service[Request, Response]\n// resp is a chunked transfer encoded http response\ndef readAndDoSomethingWithBody(respFuture: Future[Response]): Future[Response] = {\n  respFuture.flatMap { resp =>\n    Reader.readAll(resp.reader).map {\n      case Buf.Utf8(body) if body == \"something\" => Response()\n      case _ => resp\n    }\n  }\n}\nfor {\n  resp <- readAndDoSomethingWithBody(http(req))\n  bodyBytes <- Reader.readAll(resp.reader)\n} yield {\n  // Do something with resp and bodyBytes\n}\nThis is the jist of the code that caused a deadlock for me. I'm starting to think that the future that is not resolving and causing the deadlock is Reader.readAll, since I'm calling it twice on the same response reader. Is my reasoning correct? If so, is there a way to \"reset\" the reader, or is it forever gone once it's all read?\n. OK, after a lot of digging, the deadlock was caused by this:\nresp = Response()\nReader.readAll(resp.reader).map(do something...)\nBasically, when a Response is not chunked, and you try to readAll its reader, it hangs indefinitely.\nFeature? Bug?\n. That's exactly what I meant.\nSorry to keep asking questions, but I've tried the following code per your suggestion of terminating my response's reader. However, it still hangs!\nval resp = Response()\nAwait.result(\n  resp.close()\n  .flatMap(Unit =>\n    Reader.readAll(resp.reader)\n    .map(buf => println(buf.isEmpty))))\nMaybe this is not the way to terminate the reader?\n. ",
    "tindzk": "Yes, I already saw FileElement. The problem is that content is a Buf and therefore the file will need to be fully loaded into memory. What I am looking for is more of a streaming solution like in scalaj-http.\n. ",
    "clhodapp": "Bijection 0.9.3 with support for 2.12 is on maven central.. ",
    "mateor": "I actually figured it out pretty quickly. The CONTRIBUTING doc seems up to date, although I didn't follow it - I just switched to master. It would be nice to have the Scala School docs work but of course that isn't your project.\nI opened the issue on the chance that you didn't know that a git clone wouldn't compile by default. If it is a considered choice, I think #wontfix is probably okay.\nMy feedback if you keep the 'develop' branch would be to add a 'build' or 'run' section to the README that links to the steps needed to get up and running. I don't usually expect to look in CONTRIBUTING for build instructions, that usually details the review process in my experience.\nI appreciate the reply and that you are doing this development in public in the first place, so thanks!\n. Although I will add, I don't know if I agree with the bias towards potential contributors. Anyone who is going to contribute will have to do a good bit of work/configuration that dominates the time it takes to check out a development branch. I don't know if that convenience is worth the cost of having most people's first experience with Finagle being an error message about missing dependencies.\n. ",
    "schrepfler": "Considering the Kafka collector is pretty recent and there's low need to keep compatibility kept perhaps there's a chance to start with an updated stack and use Kafka 0.10.0.0 from the get-go?\n. ",
    "codecov-io": "Current coverage is 61.70%\n\nNo coverage report found for develop at 9b04fc2.\nPowered by Codecov. Last updated by 9b04fc2...67af734\n. ## Current coverage is 66.31% (diff: 100%)\nMerging #521 into develop will decrease coverage by 1.96%\n\ndiff\n@@            develop       #521   diff @@\n==========================================\n  Files           614        597    -17   \n  Lines         21329      20959   -370   \n  Methods       19739      19385   -354   \n  Messages          0          0          \n  Branches       1445       1409    -36   \n==========================================\n- Hits          14565      13900   -665   \n- Misses         6764       7059   +295   \n  Partials          0          0\n\nPowered by Codecov. Last update 792498b...ddfffc9\n. ## Current coverage is 67.60% (diff: 100%)\nNo coverage report found for develop at e1e7423.\nPowered by Codecov. Last update e1e7423...c22d896\n. ## Current coverage is 67.64% (diff: 100%)\nMerging #537 into develop will not change coverage\n\ndiff\n@@            develop       #537   diff @@\n==========================================\n  Files           570        570          \n  Lines         20680      20680          \n  Methods       19527      19569    +42   \n  Messages          0          0          \n  Branches       1025        983    -42   \n==========================================\n  Hits          13988      13988          \n  Misses         6692       6692          \n  Partials          0          0\n\nPowered by Codecov. Last update 3bd9661...3407b00\n. ## Current coverage is 67.58% (diff: 100%)\nMerging #539 into develop will decrease coverage by 0.05%\n\ndiff\n@@            develop       #539   diff @@\n==========================================\n  Files           570        570          \n  Lines         20680      20680          \n  Methods       19527      19579    +52   \n  Messages          0          0          \n  Branches       1025        973    -52   \n==========================================\n- Hits          13988      13977    -11   \n- Misses         6692       6703    +11   \n  Partials          0          0\n\nPowered by Codecov. Last update 3bd9661...b982735\n. ## Current coverage is 68.48% (diff: 50.00%)\nMerging #543 into develop will increase coverage by 0.81%\n\ndiff\n@@            develop       #543   diff @@\n==========================================\n  Files           575        575          \n  Lines         20831      20832     +1   \n  Methods       19653      19715    +62   \n  Messages          0          0          \n  Branches       1049        988    -61   \n==========================================\n+ Hits          14096      14266   +170   \n+ Misses         6735       6566   -169   \n  Partials          0          0\n\nPowered by Codecov. Last update 6e4d0b3...763095b\n. ## Current coverage is 71.63% (diff: 100%)\nMerging #545 into develop will increase coverage by 4.45%\n\ndiff\n@@            develop       #545   diff @@\n==========================================\n  Files           566        469     -97   \n  Lines         20506      16321   -4185   \n  Methods       18988      15164   -3824   \n  Messages          0          0           \n  Branches       1335       1079    -256   \n==========================================\n- Hits          13775      11691   -2084   \n+ Misses         6731       4630   -2101   \n  Partials          0          0\n\nPowered by Codecov. Last update 00dc4cc...dacb6a4\n. ## Current coverage is 56.60% (diff: 100%)\nMerging #547 into develop will decrease coverage by 10.83%\n\ndiff\n@@            develop       #547   diff @@\n==========================================\n  Files           567        569      +2   \n  Lines         20653      20611     -42   \n  Methods       19515      19492     -23   \n  Messages          0          0           \n  Branches        985       1002     +17   \n==========================================\n- Hits          13927      11666   -2261   \n- Misses         6726       8945   +2219   \n  Partials          0          0\n\nPowered by Codecov. Last update e4a7b20...5a23196\n. # Codecov Report\nMerging #548 into develop will increase coverage by -5.03%.\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #548      +/-\n===========================================\n- Coverage    65.47%   60.45%   -5.03%   \n===========================================\n  Files          627      627            \n  Lines        21438    21451      +13   \n  Branches      1476     1493      +17   \n===========================================\n- Hits         14037    12968    -1069   \n- Misses        7401     8483    +1082\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...twitter/finagle/redis/protocol/commands/Sets.scala | 21.05% <\u00f8> (-9.72%) | :x: |\n| .../com/twitter/finagle/redis/SortedSetCommands.scala | 0% <\u00f8> (\u00f8) | :white_check_mark: |\n| .../scala/com/twitter/finagle/redis/SetCommands.scala | 0% <\u00f8> (\u00f8) | :white_check_mark: |\n| ...r/finagle/redis/protocol/commands/SortedSets.scala | 76.19% <\u00f8> (-4.62%) | :x: |\n| ...a/com/twitter/finagle/redis/protocol/Command.scala | 100% <100%> (\u00f8) | :white_check_mark: |\n| ...ain/scala/com/twitter/finagle/http2/Settings.scala | 0% <\u00f8> (-100%) | :x: |\n| ...ter/finagle/mux/lease/exp/GenerationalRandom.scala | 0% <\u00f8> (-100%) | :x: |\n| ...er/finagle/mux/stats/MuxCancelledCategorizer.scala | 0% <\u00f8> (-100%) | :x: |\n| .../netty4/http/handler/RespondToExpectContinue.scala | 0% <\u00f8> (-100%) | :x: |\n| ...scala/com/twitter/finagle/http2/RefTransport.scala | 0% <\u00f8> (-100%) | :x: |\n| ... and 77 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f9bf976...d6ef1b6. Read the comment docs.. ## Current coverage is 67.62% (diff: 100%)\nMerging #550 into develop will increase coverage by 8.75%\n\ndiff\n@@            develop       #550   diff @@\n==========================================\n  Files           579        569     -10   \n  Lines         21047      20792    -255   \n  Methods       19952      19642    -310   \n  Messages          0          0           \n  Branches       1000       1019     +19   \n==========================================\n+ Hits          12390      14061   +1671   \n+ Misses         8657       6731   -1926   \n  Partials          0          0\n\nPowered by Codecov. Last update 1378455...879e8d1\n. ## Current coverage is 68.24% (diff: 75.00%)\nMerging #557 into develop will increase coverage by 1.06%\n\ndiff\n@@            develop       #557   diff @@\n==========================================\n  Files           566        592    +26   \n  Lines         20506      21172   +666   \n  Methods       18988      19568   +580   \n  Messages          0          0          \n  Branches       1335       1444   +109   \n==========================================\n+ Hits          13775      14448   +673   \n+ Misses         6731       6724     -7   \n  Partials          0          0\n\nPowered by Codecov. Last update 00dc4cc...dae164b\n. ## Current coverage is 67.84% (diff: 75.00%)\nMerging #560 into develop will decrease coverage by 0.01%\n\ndiff\n@@            develop       #560   diff @@\n==========================================\n  Files           625        625          \n  Lines         21371      21378     +7   \n  Methods       19684      19697    +13   \n  Messages          0          0          \n  Branches       1486       1480     -6   \n==========================================\n+ Hits          14501      14503     +2   \n- Misses         6870       6875     +5   \n  Partials          0          0\n\nPowered by Codecov. Last update 53e9885...23a013b\n. ## Current coverage is 62.97% (diff: 100%)\nMerging #568 into develop will decrease coverage by 0.01%\n\ndiff\n@@            develop       #568   diff @@\n==========================================\n  Files           625        625          \n  Lines         21382      21382          \n  Methods       19723      19742    +19   \n  Messages          0          0          \n  Branches       1479       1460    -19   \n==========================================\n- Hits          13468      13465     -3   \n- Misses         7914       7917     +3   \n  Partials          0          0\n\nPowered by Codecov. Last update b8bcc35...65cc8a6\n. ## Current coverage is 68.22% (diff: 100%)\nMerging #574 into develop will increase coverage by 2.74%\n\ndiff\n@@            develop       #574   diff @@\n==========================================\n  Files           627        627          \n  Lines         21438      21438          \n  Methods       19910      19874    -36   \n  Messages          0          0          \n  Branches       1476       1512    +36   \n==========================================\n+ Hits          14037      14626   +589   \n+ Misses         7401       6812   -589   \n  Partials          0          0\n\nPowered by Codecov. Last update f9bf976...3aa5b03. ## Current coverage is 69.69% (diff: 80.00%)\nMerging #579 into develop will increase coverage by 4.89%\n\ndiff\n@@            develop       #579   diff @@\n==========================================\n  Files           629        631      +2   \n  Lines         20624      20608     -16   \n  Methods       19161      19126     -35   \n  Messages          0          0           \n  Branches       1457       1476     +19   \n==========================================\n+ Hits          13364      14363    +999   \n+ Misses         7260       6245   -1015   \n  Partials          0          0\n\nPowered by Codecov. Last update 3d53c09...fac70e5. ## Current coverage is 70.09% (diff: 100%)\nMerging #582 into develop will increase coverage by 0.03%\n\ndiff\n@@            develop       #582   diff @@\n==========================================\n  Files           643        643          \n  Lines         20849      20849          \n  Methods       19409      19402     -7   \n  Messages          0          0          \n  Branches       1434       1441     +7   \n==========================================\n+ Hits          14606      14614     +8   \n+ Misses         6243       6235     -8   \n  Partials          0          0\n\nPowered by Codecov. Last update 1044427...a002c77. # Codecov Report\nMerging #589 into develop will decrease coverage by -0.64%.\nThe diff coverage is 0%.\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #589      +/-\n===========================================\n- Coverage    65.69%   65.05%   -0.64%   \n===========================================\n  Files          594      597       +3   \n  Lines        19339    19374      +35   \n  Branches      1454     1442      -12   \n===========================================\n- Hits         12704    12604     -100   \n- Misses        6635     6770     +135\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...nagle/serverset2/client/apache/ApacheWatcher.scala | 0% <0%> (\u00f8) | :white_check_mark: |\n| ...gle/serverset2/client/apache/ApacheZooKeeper.scala | 0% <0%> (\u00f8) | :white_check_mark: |\n| ...ala/com/twitter/finagle/toggle/NullToggleMap.scala | 33.33% <0%> (-66.67%) | :x: |\n| ...n/scala/com/twitter/finagle/toggle/WriteOnce.scala | 40% <0%> (-60%) | :x: |\n| ...la/com/twitter/finagle/toggle/flag/overrides.scala | 50% <0%> (-50%) | :x: |\n| ...witter/finagle/toggle/ServiceLoadedToggleMap.scala | 50% <0%> (-50%) | :x: |\n| ...n/scala/com/twitter/finagle/toggle/ToggleMap.scala | 41.22% <0%> (-49.62%) | :x: |\n| ...com/twitter/finagle/toggle/StandardToggleMap.scala | 61.11% <0%> (-37.04%) | :x: |\n| ...ala/com/twitter/finagle/toggle/JsonToggleMap.scala | 69.56% <0%> (-30.44%) | :x: |\n| ...main/scala/com/twitter/finagle/toggle/Toggle.scala | 70.45% <0%> (-20.46%) | :x: |\n| ... and 7 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 084bea3...08bb0c3. Read the comment docs.. # Codecov Report\nMerging #591 into develop will increase coverage by 8.45%.\nThe diff coverage is 0%.\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #591      +/-\n===========================================\n+ Coverage    61.36%   69.82%   +8.45%   \n===========================================\n  Files          651      664      +13   \n  Lines        20802    21104     +302   \n  Branches      1456     1497      +41   \n===========================================\n+ Hits         12766    14736    +1970   \n+ Misses        8036     6368    -1668\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ala/com/twitter/finagle/redis/SentinelClient.scala | 0% <0%> (\u00f8) | :white_check_mark: |\n| ...le/netty4/channel/DirectToHeapInboundHandler.scala | 68.42% <0%> (-31.58%) | :x: |\n| ...ain/scala/com/twitter/finagle/netty4/package.scala | 90% <0%> (-10%) | :x: |\n| .../src/main/scala/com/twitter/finagle/util/Rng.scala | 86.36% <0%> (-4.55%) | :x: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 91.17% <0%> (-0.74%) | :x: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 67.5% <0%> (\u00f8) | :white_check_mark: |\n| ...a/com/twitter/finagle/loadbalancer/Balancers.scala | 83.33% <0%> (\u00f8) | :white_check_mark: |\n| ...ala/com/twitter/finagle/loadbalancer/p2c/P2C.scala | 100% <0%> (\u00f8) | :white_check_mark: |\n| ...tter/finagle/loadbalancer/p2c/P2CLeastLoaded.scala | 100% <0%> (\u00f8) | :white_check_mark: |\n| ...src/main/scala/com/twitter/finagle/util/Ring.scala | | |\n| ... and 162 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 40a08a7...8907f00. Read the comment docs.. # Codecov Report\nMerging #592 into develop will increase coverage by 0.06%.\nThe diff coverage is 100%.\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #592      +/-\n===========================================\n+ Coverage    70.44%   70.51%   +0.06%   \n===========================================\n  Files          663      663            \n  Lines        21026    21030       +4   \n  Branches      1460     1458       -2   \n===========================================\n+ Hits         14812    14829      +17   \n+ Misses        6214     6201      -13\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...scala/com/twitter/finagle/server/StackServer.scala | 97.75% <100%> (+0.1%) | :white_check_mark: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 91.17% <0%> (\u00f8) | :white_check_mark: |\n| ...nagle/http2/transport/MultiplexedTransporter.scala | 91.33% <0%> (+0.78%) | :white_check_mark: |\n| .../scala/com/twitter/finagle/mux/ClientSession.scala | 80.2% <0%> (+1.04%) | :white_check_mark: |\n| ...cala/com/twitter/finagle/transport/Transport.scala | 87.65% <0%> (+1.23%) | :white_check_mark: |\n| ...re/src/main/scala/com/twitter/finagle/Server.scala | 78.57% <0%> (+7.14%) | :white_check_mark: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 72.5% <0%> (+10%) | :white_check_mark: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 0ed6ca6...f9cc838. Read the comment docs.. # Codecov Report\nMerging #595 into develop will increase coverage by 0.1%.\nThe diff coverage is 100%.\n\n```diff\n@@            Coverage Diff             @@\ndevelop     #595     +/-\n==========================================\n+ Coverage    71.36%   71.46%   +0.1%   \n==========================================\n  Files          659      659           \n  Lines        20452    20192    -260   \n  Branches      1433     1402     -31   \n==========================================\n- Hits         14595    14430    -165   \n+ Misses        5857     5762     -95\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...cala/com/twitter/finagle/service/StatsFilter.scala | 87.71% <100%> (+0.44%) | :arrow_up: |\n| .../src/main/scala/com/twitter/finagle/Resolver.scala | 68.75% <0%> (-6.25%) | :arrow_down: |\n| ...src/main/scala/com/twitter/finagle/Announcer.scala | 80% <0%> (-4.62%) | :arrow_down: |\n| ...la/com/twitter/finagle/client/ClientRegistry.scala | 93.61% <0%> (-4.26%) | :arrow_down: |\n| ...twitter/finagle/mux/lease/exp/ClockedDrainer.scala | 1.65% <0%> (-2.58%) | :arrow_down: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 63.75% <0%> (-2.5%) | :arrow_down: |\n| ...om/twitter/finagle/http/exp/ServerDispatcher.scala | 69.76% <0%> (-2.33%) | :arrow_down: |\n| ...om/twitter/finagle/dispatch/ServerDispatcher.scala | 82.97% <0%> (-2.13%) | :arrow_down: |\n| ...la/com/twitter/finagle/mux/transport/Message.scala | 92.51% <0%> (-2.03%) | :arrow_down: |\n| .../main/scala/com/twitter/finagle/param/Params.scala | 56% <0%> (-1.7%) | :arrow_down: |\n| ... and 38 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 796ac10...101e9e4. Read the comment docs.. # Codecov Report\nMerging #596 into develop will increase coverage by 0.04%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #596      +/-\n===========================================\n+ Coverage    71.33%   71.38%   +0.04%   \n===========================================\n  Files          659      659            \n  Lines        20452    20452            \n  Branches      1449     1449            \n===========================================\n+ Hits         14590    14599       +9   \n+ Misses        5862     5853       -9\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...com/twitter/finagle/toggle/StandardToggleMap.scala | 98.14% <100%> (\u00f8) | :arrow_up: |\n| .../scala/com/twitter/finagle/mux/ClientSession.scala | 79.16% <0%> (-1.05%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 92.64% <0%> (\u00f8) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 73.75% <0%> (+12.5%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3342456...03abd12. Read the comment docs.. # Codecov Report\nMerging #597 into develop will not change coverage.\nThe diff coverage is n/a.\n\n\n```diff\n@@           Coverage Diff            @@\ndevelop     #597   +/-\n========================================\n  Coverage    71.36%   71.36%         \n========================================\n  Files          659      659         \n  Lines        20451    20451         \n  Branches      1424     1403   -21   \n========================================\n  Hits         14595    14595         \n  Misses        5856     5856\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 71.25% <0%> (\u00f8) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 24ecb7b...fff88bf. Read the comment docs.. # Codecov Report\nMerging #599 into develop will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #599      +/-\n===========================================\n- Coverage    71.39%   71.36%   -0.03%   \n===========================================\n  Files          660      660            \n  Lines        20486    20486            \n  Branches      1424     1396      -28   \n===========================================\n- Hits         14625    14620       -5   \n- Misses        5861     5866       +5\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 70% <0%> (-5%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/Exceptions.scala | 69.84% <0%> (-1.59%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 91.17% <0%> (\u00f8) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 277617e...70767d9. Read the comment docs.. # Codecov Report\nMerging #607 into develop will increase coverage by 0.01%.\nThe diff coverage is 61.33%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #607      +/-\n===========================================\n+ Coverage    67.46%   67.47%   +0.01%   \n===========================================\n  Files          644      645       +1   \n  Lines        21843    21912      +69   \n  Branches      1689     1638      -51   \n===========================================\n+ Hits         14736    14785      +49   \n- Misses        7107     7127      +20\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...finagle/ssl/server/LegacyServerEngineFactory.scala | 40.74% <0%> (-1.57%) | :arrow_down: |\n| .../netty4/ssl/client/Netty4ClientEngineFactory.scala | 91.3% <0%> (-4.16%) | :arrow_down: |\n| ...agle/ssl/server/LegacyKeyServerEngineFactory.scala | 95.83% <0%> (-4.17%) | :arrow_down: |\n| .../netty4/ssl/server/Netty4ServerEngineFactory.scala | 84.21% <0%> (-4.68%) | :arrow_down: |\n| ...la/com/twitter/finagle/ssl/SslConfigurations.scala | 72.91% <0%> (-27.09%) | :arrow_down: |\n| ...r/finagle/netty4/ssl/Netty4SslConfigurations.scala | 76.19% <0%> (-3.81%) | :arrow_down: |\n| ...er/finagle/netty4/transport/ChannelTransport.scala | 98.07% <100%> (\u00f8) | :arrow_up: |\n| ...gle/netty4/ssl/server/Netty4ServerSslHandler.scala | 83.67% <76.47%> (-16.33%) | :arrow_down: |\n| ...r/finagle/netty4/ssl/server/Netty4SniHandler.scala | 86.36% <86.36%> (\u00f8) | |\n| ...inagle/http2/transport/UpgradeRequestHandler.scala | 87.87% <0%> (-6.07%) | :arrow_down: |\n| ... and 7 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 796eca1...88149b1. Read the comment docs.\n. # Codecov Report\nMerging #609 into develop will increase coverage by 0.08%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #609      +/-\n===========================================\n+ Coverage    62.29%   62.37%   +0.08%   \n===========================================\n  Files          662      662            \n  Lines        23498    23498            \n  Branches      1684     1705      +21   \n===========================================\n+ Hits         14639    14658      +19   \n+ Misses        8859     8840      -19\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...tter/finagle/loadbalancer/p2c/P2CLeastLoaded.scala | 100% <\u00f8> (\u00f8) | :arrow_up: |\n| ...scala/com/twitter/finagle/client/StackClient.scala | 100% <\u00f8> (\u00f8) | :arrow_up: |\n| ...twitter/finagle/loadbalancer/p2c/P2CPeakEwma.scala | 100% <\u00f8> (\u00f8) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 70% <0%> (-2.5%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 92.64% <0%> (+1.47%) | :arrow_up: |\n| ...la/com/twitter/finagle/mux/transport/Message.scala | 94.37% <0%> (+6.29%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 80a8ded...0974e46. Read the comment docs.\n. # Codecov Report\nMerging #615 into develop will not change coverage.\nThe diff coverage is n/a.\n\n\n```diff\n@@           Coverage Diff            @@\ndevelop     #615   +/-\n========================================\n  Coverage    38.64%   38.64%         \n========================================\n  Files          398      398         \n  Lines        11995    11995         \n  Branches       921      903   -18   \n========================================\n  Hits          4635     4635         \n  Misses        7360     7360\n```\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update a587454...d69d68b. Read the comment docs.\n. # Codecov Report\nMerging #618 into develop will decrease coverage by 0.17%.\nThe diff coverage is 2.63%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #618      +/-\n===========================================\n- Coverage     68.2%   68.03%   -0.18%   \n===========================================\n  Files          634      634            \n  Lines        21101    21161      +60   \n  Branches      1567     1578      +11   \n===========================================\n+ Hits         14392    14396       +4   \n- Misses        6709     6765      +56\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...c/main/scala/com/twitter/finagle/mysql/Value.scala | 70.29% <\u00f8> (\u00f8) | :arrow_up: |\n| .../main/scala/com/twitter/finagle/mysql/Result.scala | 83.96% <0%> (-8.75%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mysql/Type.scala | 34.61% <0%> (-18.33%) | :arrow_down: |\n| ...src/main/scala/com/twitter/finagle/mysql/Row.scala | 24.59% <3.57%> (-5.41%) | :arrow_down: |\n| ...ala/com/twitter/finagle/mysql/CanBeParameter.scala | 70.83% <9.09%> (-8%) | :arrow_down: |\n| ...c/main/scala/com/twitter/finagle/http/Method.scala | 83.33% <0%> (-4.17%) | :arrow_down: |\n| ...agle/http2/transport/Http2UpgradingTransport.scala | 88.88% <0%> (-3.71%) | :arrow_down: |\n| ...nagle/http2/transport/MultiplexedTransporter.scala | 82.65% <0%> (+0.57%) | :arrow_up: |\n| .../main/scala/com/twitter/finagle/mysql/Client.scala | 60.46% <0%> (+0.94%) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 71.25% <0%> (+1.25%) | :arrow_up: |\n| ... and 1 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1e23d08...5eb03e5. Read the comment docs.\n. # Codecov Report\nMerging #621 into develop will increase coverage by 0.17%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #621      +/-\n===========================================\n+ Coverage    68.11%   68.28%   +0.17%   \n===========================================\n  Files          643      643            \n  Lines        21142    21142            \n  Branches      1541     1555      +14   \n===========================================\n+ Hits         14401    14437      +36   \n+ Misses        6741     6705      -36\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../com/twitter/finagle/mux/transport/MuxFramer.scala | 91.74% <0%> (-1.84%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 92.08% <0%> (-0.72%) | :arrow_down: |\n| ...a/com/twitter/finagle/http2/Http2Transporter.scala | 74.24% <0%> (+1.51%) | :arrow_up: |\n| ...agle/http2/transport/Http2UpgradingTransport.scala | 92.59% <0%> (+3.7%) | :arrow_up: |\n| ...la/com/twitter/finagle/mux/transport/Message.scala | 94.42% <0%> (+6.22%) | :arrow_up: |\n| ...inagle/http2/transport/UpgradeRequestHandler.scala | 93.75% <0%> (+6.25%) | :arrow_up: |\n| ...e/http2/transport/AdapterProxyChannelHandler.scala | 93.54% <0%> (+6.45%) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 75% <0%> (+13.75%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update dd87c62...4a37c40. Read the comment docs.\n. # Codecov Report\nMerging #622 into develop will increase coverage by 0.16%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #622      +/-\n===========================================\n+ Coverage    68.11%   68.28%   +0.16%   \n===========================================\n  Files          643      643            \n  Lines        21142    21142            \n  Branches      1541     1538       -3   \n===========================================\n+ Hits         14401    14436      +35   \n+ Misses        6741     6706      -35\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../com/twitter/finagle/mux/transport/MuxFramer.scala | 91.74% <0%> (-1.84%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 92.08% <0%> (-0.72%) | :arrow_down: |\n| ...a/com/twitter/finagle/http2/Http2Transporter.scala | 74.24% <0%> (+1.51%) | :arrow_up: |\n| ...agle/http2/transport/Http2UpgradingTransport.scala | 92.59% <0%> (+3.7%) | :arrow_up: |\n| ...la/com/twitter/finagle/mux/transport/Message.scala | 94.42% <0%> (+6.22%) | :arrow_up: |\n| ...inagle/http2/transport/UpgradeRequestHandler.scala | 93.75% <0%> (+6.25%) | :arrow_up: |\n| ...e/http2/transport/AdapterProxyChannelHandler.scala | 93.54% <0%> (+6.45%) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 73.75% <0%> (+12.5%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update dd87c62...18703fc. Read the comment docs.\n. # Codecov Report\nMerging #624 into develop will increase coverage by 0.01%.\nThe diff coverage is 76.47%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #624      +/-\n===========================================\n+ Coverage    68.46%   68.47%   +0.01%   \n===========================================\n  Files          643      643            \n  Lines        21140    21145       +5   \n  Branches      1578     1542      -36   \n===========================================\n+ Hits         14474    14480       +6   \n+ Misses        6666     6665       -1\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...cala/com/twitter/finagle/redis/exp/RedisPool.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...dis/src/main/scala/com/twitter/finagle/Redis.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...src/main/scala/com/twitter/finagle/Memcached.scala | 40.35% <100%> (+0.52%) | :arrow_up: |\n| ...witter/finagle/dispatch/PipeliningDispatcher.scala | 88.23% <92.3%> (-2.09%) | :arrow_down: |\n| ...la/com/twitter/finagle/mux/transport/Message.scala | 88.19% <0%> (-6.23%) | :arrow_down: |\n| ...om/twitter/finagle/dispatch/ServerDispatcher.scala | 82.97% <0%> (-2.13%) | :arrow_down: |\n| ...a/com/twitter/finagle/zipkin/core/Annotation.scala | 4.74% <0%> (\u00f8) | :arrow_up: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 92.8% <0%> (+0.71%) | :arrow_up: |\n| ...a/com/twitter/finagle/http2/Http2Transporter.scala | 74.24% <0%> (+1.51%) | :arrow_up: |\n| ...2/transport/RichHttpToHttp2ConnectionHandler.scala | 86.36% <0%> (+2.27%) | :arrow_up: |\n| ... and 5 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 462643f...c0e2d65. Read the comment docs.\n. # Codecov Report\nMerging #631 into develop will decrease coverage by 0.06%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #631      +/-\n===========================================\n- Coverage     68.2%   68.13%   -0.07%   \n===========================================\n  Files          634      634            \n  Lines        21101    21101            \n  Branches      1567     1546      -21   \n===========================================\n- Hits         14392    14378      -14   \n- Misses        6709     6723      +14\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 61.25% <0%> (-8.75%) | :arrow_down: |\n| ...e/http2/transport/AdapterProxyChannelHandler.scala | 85.48% <0%> (-8.07%) | :arrow_down: |\n| ...agle/http2/transport/Http2UpgradingTransport.scala | 88.88% <0%> (-3.71%) | :arrow_down: |\n| ...2/transport/RichHttpToHttp2ConnectionHandler.scala | 84.44% <0%> (-2.23%) | :arrow_down: |\n| .../scala/com/twitter/finagle/mux/ClientSession.scala | 77.65% <0%> (-1.07%) | :arrow_down: |\n| ...nagle/http2/transport/MultiplexedTransporter.scala | 82.65% <0%> (+0.57%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1e23d08...eab068b. Read the comment docs.\n. # Codecov Report\nMerging #645 into develop will decrease coverage by 0.27%.\nThe diff coverage is 6.66%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #645      +/-\n===========================================\n- Coverage    67.46%   67.18%   -0.28%   \n===========================================\n  Files          644      647       +3   \n  Lines        21843    21937      +94   \n  Branches      1689     1672      -17   \n===========================================\n+ Hits         14736    14738       +2   \n- Misses        7107     7199      +92\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../scala/com/twitter/finagle/redis/KeyCommands.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...la/com/twitter/finagle/redis/util/TestServer.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...tter/finagle/redis/protocol/commands/Cluster.scala | 0% <0%> (\u00f8) | |\n| ...la/com/twitter/finagle/redis/ClusterCommands.scala | 0% <0%> (\u00f8) | |\n| ...cala/com/twitter/finagle/redis/ClusterClient.scala | 0% <0%> (\u00f8) | |\n| ...a/com/twitter/finagle/redis/protocol/Command.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ...twitter/finagle/redis/protocol/commands/Keys.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ...a/com/twitter/finagle/http2/Http2Transporter.scala | 72.72% <0%> (-7.58%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 91.36% <0%> (-2.16%) | :arrow_down: |\n| ...la/com/twitter/finagle/netty3/Netty3Listener.scala | 89.39% <0%> (-0.76%) | :arrow_down: |\n| ... and 4 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 796eca1...7384132. Read the comment docs.\n. # Codecov Report\nMerging #648 into develop will increase coverage by 1.78%.\nThe diff coverage is 6.15%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #648      +/-\n===========================================\n+ Coverage    64.13%   65.92%   +1.78%   \n===========================================\n  Files          653      656       +3   \n  Lines        22127    22242     +115   \n  Branches      1655     1661       +6   \n===========================================\n+ Hits         14191    14662     +471   \n+ Misses        7936     7580     -356\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ala/com/twitter/finagle/redis/SentinelClient.scala | 0% <\u00f8> (\u00f8) | :arrow_up: |\n| .../main/scala/com/twitter/finagle/redis/Client.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...la/com/twitter/finagle/redis/ClusterCommands.scala | 0% <0%> (\u00f8) | |\n| ...cala/com/twitter/finagle/redis/ClusterClient.scala | 0% <0%> (\u00f8) | |\n| ...tter/finagle/redis/protocol/commands/Cluster.scala | 0% <0%> (\u00f8) | |\n| .../scala/com/twitter/finagle/redis/KeyCommands.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...dis/src/main/scala/com/twitter/finagle/Redis.scala | 24.32% <0%> (-1.39%) | :arrow_down: |\n| ...la/com/twitter/finagle/redis/util/TestServer.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...twitter/finagle/redis/protocol/commands/Keys.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ...a/com/twitter/finagle/redis/protocol/Command.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ... and 78 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 7d5f269...166f75b. Read the comment docs.\n. # Codecov Report\nMerging #660 into develop will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #660      +/-\n===========================================\n+ Coverage    68.46%   68.47%   +0.01%   \n===========================================\n  Files          699      699            \n  Lines        23135    23134       -1   \n  Branches      1795     1789       -6   \n===========================================\n+ Hits         15839    15841       +2   \n+ Misses        7296     7293       -3\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 63.41% <0%> (-12.2%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 92.59% <0%> (-1.49%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/Exceptions.scala | 65.21% <0%> (-0.38%) | :arrow_down: |\n| ...nagle/http2/transport/MultiplexedTransporter.scala | 77.55% <0%> (+0.51%) | :arrow_up: |\n| .../com/twitter/finagle/mux/transport/MuxFramer.scala | 89.21% <0%> (+1.96%) | :arrow_up: |\n| ...om/twitter/finagle/dispatch/ServerDispatcher.scala | 85.1% <0%> (+2.12%) | :arrow_up: |\n| .../main/scala/com/twitter/finagle/http/Request.scala | 42.39% <0%> (+2.17%) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/http/path/Path.scala | 84.31% <0%> (+3.92%) | :arrow_up: |\n| ...2/transport/RichHttpToHttp2ConnectionHandler.scala | 87.23% <0%> (+4.25%) | :arrow_up: |\n| ...e/http2/transport/AdapterProxyChannelHandler.scala | 93.54% <0%> (+8.06%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3d292b4...38b8417. Read the comment docs.\n. # Codecov Report\nMerging #661 into develop will increase coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #661      +/-\n===========================================\n+ Coverage    68.46%   68.49%   +0.03%   \n===========================================\n  Files          699      699            \n  Lines        23135    23135            \n  Branches      1795     1799       +4   \n===========================================\n+ Hits         15839    15847       +8   \n+ Misses        7296     7288       -8\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 73.17% <0%> (-2.44%) | :arrow_down: |\n| ...nagle/http2/transport/MultiplexedTransporter.scala | 77.55% <0%> (+0.51%) | :arrow_up: |\n| .../com/twitter/finagle/mux/transport/MuxFramer.scala | 89.21% <0%> (+1.96%) | :arrow_up: |\n| .../main/scala/com/twitter/finagle/http/Request.scala | 42.39% <0%> (+2.17%) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/http/path/Path.scala | 84.31% <0%> (+3.92%) | :arrow_up: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 79.06% <0%> (+6.97%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 3d292b4...feca4a5. Read the comment docs.\n. # Codecov Report\nMerging #666 into develop will decrease coverage by 0.1%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #666      +/-\n===========================================\n- Coverage    71.93%   71.83%   -0.11%   \n===========================================\n  Files          707      707            \n  Lines        22543    22543            \n  Branches      1716     1715       -1   \n===========================================\n- Hits         16216    16193      -23   \n- Misses        6327     6350      +23\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...le/http2/transport/PriorKnowledgeTransporter.scala | 57.14% <0%> (-28.58%) | :arrow_down: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 62.19% <0%> (-10.98%) | :arrow_down: |\n| ...inagle/http2/transport/UpgradeRequestHandler.scala | 85.29% <0%> (-5.89%) | :arrow_down: |\n| ...itter/finagle/http2/LoggerPerFrameTypeLogger.scala | 37.03% <0%> (-1.86%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 93.33% <0%> (-0.75%) | :arrow_down: |\n| ...nagle/http2/transport/MultiplexedTransporter.scala | 76% <0%> (-0.5%) | :arrow_down: |\n| ...agle/http2/transport/Http2UpgradingTransport.scala | 92.85% <0%> (+3.57%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d63186f...0631c8a. Read the comment docs.\n. # Codecov Report\nMerging #667 into develop will decrease coverage by <.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #667      +/-\n===========================================\n- Coverage    71.87%   71.86%   -0.01%   \n===========================================\n  Files          711      711            \n  Lines        22781    22781            \n  Branches      1838     1838            \n===========================================\n- Hits         16373    16371       -2   \n- Misses        6408     6410       +2\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 64.63% <0%> (-8.54%) | :arrow_down: |\n| ...nagle/exp/pushsession/PushChannelHandleProxy.scala | 66.66% <0%> (-8.34%) | :arrow_down: |\n| ...er/finagle/mux/exp/pushsession/MessageWriter.scala | 78.2% <0%> (-7.7%) | :arrow_down: |\n| .../exp/pushsession/MuxClientNegotiatingSession.scala | 72.09% <0%> (-4.66%) | :arrow_down: |\n| .../com/twitter/finagle/mux/transport/MuxFramer.scala | 89.21% <0%> (+1.96%) | :arrow_up: |\n| ...om/twitter/finagle/dispatch/ServerDispatcher.scala | 85.1% <0%> (+2.12%) | :arrow_up: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 76.74% <0%> (+4.65%) | :arrow_up: |\n| ...a/com/twitter/finagle/http2/Http2Transporter.scala | 76.97% <0%> (+6.47%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e2a90ba...951a514. Read the comment docs.\n. # Codecov Report\nMerging #668 into develop will decrease coverage by 0.14%.\nThe diff coverage is 6.66%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #668      +/-\n===========================================\n- Coverage    71.73%   71.58%   -0.15%   \n===========================================\n  Files          723      726       +3   \n  Lines        23016    23110      +94   \n  Branches      1812     1847      +35   \n===========================================\n+ Hits         16511    16544      +33   \n- Misses        6505     6566      +61\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...tter/finagle/redis/protocol/commands/Cluster.scala | 0% <0%> (\u00f8) | |\n| .../scala/com/twitter/finagle/redis/KeyCommands.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...la/com/twitter/finagle/redis/ClusterCommands.scala | 0% <0%> (\u00f8) | |\n| ...la/com/twitter/finagle/redis/util/TestServer.scala | 0% <0%> (\u00f8) | :arrow_up: |\n| ...cala/com/twitter/finagle/redis/ClusterClient.scala | 0% <0%> (\u00f8) | |\n| ...a/com/twitter/finagle/redis/protocol/Command.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ...twitter/finagle/redis/protocol/commands/Keys.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ... and 11 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update a205bd2...f1eed12. Read the comment docs.\n. # Codecov Report\nMerging #671 into develop will decrease coverage by 0.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #671      +/-\n===========================================\n- Coverage    72.36%   72.33%   -0.04%   \n===========================================\n  Files          730      730            \n  Lines        23209    23209            \n  Branches      1847     1797      -50   \n===========================================\n- Hits         16796    16788       -8   \n- Misses        6413     6421       +8\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...le/http2/transport/PriorKnowledgeTransporter.scala | 57.14% <0%> (-28.58%) | :arrow_down: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 64.63% <0%> (-6.1%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/mux/Server.scala | 93.33% <0%> (-0.75%) | :arrow_down: |\n| ...a/com/twitter/finagle/http2/Http2Transporter.scala | 78.41% <0%> (+1.43%) | :arrow_up: |\n| ...er/finagle/mux/exp/pushsession/MessageWriter.scala | 85.89% <0%> (+6.41%) | :arrow_up: |\n| ...nagle/exp/pushsession/PushChannelHandleProxy.scala | 91.66% <0%> (+8.33%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 1a77899...b37b0d7. Read the comment docs.\n. # Codecov Report\nMerging #692 into develop will increase coverage by 4.78%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #692      +/-\n===========================================\n+ Coverage    66.31%   71.09%   +4.78%   \n===========================================\n  Files          715      715            \n  Lines        23511    23511            \n  Branches      1869     1859      -10   \n===========================================\n+ Hits         15592    16716    +1124   \n+ Misses        7919     6795    -1124\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...com/twitter/finagle/netty4/ConnectionBuilder.scala | 73.21% <0%> (-3.58%) | :arrow_down: |\n| ...om/twitter/finagle/dispatch/ServerDispatcher.scala | 82.97% <0%> (-2.13%) | :arrow_down: |\n| ...er/finagle/mux/exp/pushsession/MessageWriter.scala | 85.89% <0%> (-1.29%) | :arrow_down: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 73.17% <0%> (-1.22%) | :arrow_down: |\n| ...cala/com/twitter/finagle/transport/Transport.scala | 93.47% <0%> (+1.08%) | :arrow_up: |\n| ...rc/main/scala/com/twitter/finagle/Exceptions.scala | 65.97% <0%> (+2.06%) | :arrow_up: |\n| ...inagle/http2/transport/PriorKnowledgeHandler.scala | 88.37% <0%> (+2.32%) | :arrow_up: |\n| ...twitter/finagle/loadbalancer/EndpointFactory.scala | 77.14% <0%> (+2.85%) | :arrow_up: |\n| ...agle/http2/transport/Http2UpgradingTransport.scala | 93.75% <0%> (+3.12%) | :arrow_up: |\n| ...itter/finagle/http2/LoggerPerFrameTypeLogger.scala | 37.03% <0%> (+3.7%) | :arrow_up: |\n| ... and 84 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 5a4d268...bee5920. Read the comment docs.\n. # Codecov Report\nMerging #710 into develop will decrease coverage by 16.03%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff              @@\ndevelop     #710       +/-\n============================================\n- Coverage    65.38%   49.35%   -16.04%   \n============================================\n  Files          730      412      -318   \n  Lines        23844    12068    -11776   \n  Branches      1901     1012      -889   \n============================================\n- Hits         15591     5956     -9635   \n+ Misses        8253     6112     -2141\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...com/twitter/finagle/ssl/IgnorantTrustManager.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...er/finagle/mux/stats/MuxCancelledCategorizer.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...n/scala/com/twitter/finagle/ssl/CipherSuites.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...ter/finagle/mux/lease/exp/GenerationalRandom.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...nagle/loadbalancer/NoNodesOpenServiceFactory.scala | 0% <0%> (-100%) | :arrow_down: |\n| .../twitter/finagle/netty4/channel/ServerBridge.scala | 0% <0%> (-100%) | :arrow_down: |\n| .../finagle/thrift/ThriftSerialServerDispatcher.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...twitter/finagle/mux/lease/exp/RequestSnooper.scala | 0% <0%> (-100%) | :arrow_down: |\n| .../twitter/finagle/thrift/TTwitterServerFilter.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...om/twitter/finagle/filter/RequestMeterFilter.scala | 0% <0%> (-100%) | :arrow_down: |\n| ... and 592 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update e01f02f...ff47d7a. Read the comment docs.\n. # Codecov Report\nMerging #714 into develop will decrease coverage by 0.02%.\nThe diff coverage is 55.55%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #714      +/-\n===========================================\n- Coverage    70.97%   70.95%   -0.03%   \n===========================================\n  Files          737      737            \n  Lines        24084    24088       +4   \n  Branches      1934     1959      +25   \n===========================================\n- Hits         17094    17092       -2   \n- Misses        6990     6996       +6\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...com/twitter/finagle/netty3/Netty3Transporter.scala | 64.02% <100%> (\u00f8) | :arrow_up: |\n| ...la/com/twitter/finagle/netty3/Netty3Listener.scala | 53.03% <100%> (\u00f8) | :arrow_up: |\n| ...com/twitter/finagle/netty4/ConnectionBuilder.scala | 73.21% <100%> (\u00f8) | :arrow_up: |\n| ...cala/com/twitter/finagle/transport/Transport.scala | 91.48% <33.33%> (-1.99%) | :arrow_down: |\n| ...witter/finagle/netty4/ListeningServerBuilder.scala | 78.78% <33.33%> (-2.47%) | :arrow_down: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 73.91% <0%> (-6.53%) | :arrow_down: |\n| ...om/twitter/finagle/dispatch/ServerDispatcher.scala | 82.97% <0%> (-2.13%) | :arrow_down: |\n| ...er/finagle/loadbalancer/heap/HeapLeastLoaded.scala | 93.47% <0%> (-1.09%) | :arrow_down: |\n| ...nagle/http2/transport/StreamTransportFactory.scala | 79.83% <0%> (+0.4%) | :arrow_up: |\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 66% <0%> (+4%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4c46b80...c2239f9. Read the comment docs.\n. # Codecov Report\nMerging #734 into develop will decrease coverage by 4.76%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #734      +/-\n===========================================\n- Coverage    74.54%   69.78%   -4.77%   \n===========================================\n  Files          661      735      +74   \n  Lines        19977    23435    +3458   \n  Branches      1448     1691     +243   \n===========================================\n+ Hits         14892    16353    +1461   \n- Misses        5085     7082    +1997\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../com/twitter/finagle/thriftmux/MethodBuilder.scala | 0% <0%> (-68.3%) | :arrow_down: |\n| ...hriftmux/service/ThriftMuxResponseClassifier.scala | 34.32% <0%> (-46.27%) | :arrow_down: |\n| ...ain/scala/com/twitter/finagle/tracing/Tracer.scala | 60% <0%> (-40%) | :arrow_down: |\n| ...cala/com/twitter/finagle/thrift/ThriftClient.scala | 0% <0%> (-33.34%) | :arrow_down: |\n| ...src/main/scala/com/twitter/finagle/ThriftMux.scala | 60.26% <0%> (-23.07%) | :arrow_down: |\n| ...witter/finagle/mux/pushsession/MessageWriter.scala | 69.23% <0%> (-17.95%) | :arrow_down: |\n| ...e/thriftmux/pushsession/VanillaThriftSession.scala | 75.32% <0%> (-15.59%) | :arrow_down: |\n| .../twitter/finagle/client/MethodBuilderTimeout.scala | 87.87% <0%> (-12.13%) | :arrow_down: |\n| ...hrift/service/ThriftReqRepServicePerEndpoint.scala | 50% <0%> (-11.54%) | :arrow_down: |\n| ...riftmux/pushsession/MuxDowngradingNegotiator.scala | 78.68% <0%> (-11.48%) | :arrow_down: |\n| ... and 130 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update b66d4fd...1e4dae8. Read the comment docs.\n. # Codecov Report\nMerging #736 into develop will increase coverage by 0.87%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #736      +/-\n===========================================\n+ Coverage    69.63%   70.51%   +0.87%   \n===========================================\n  Files          735      745      +10   \n  Lines        23436    23768     +332   \n  Branches      1732     1752      +20   \n===========================================\n+ Hits         16319    16759     +440   \n+ Misses        7117     7009     -108\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 68.08% <0%> (-6.39%) | :arrow_down: |\n| ...re/src/main/scala/com/twitter/finagle/Filter.scala | 90.09% <0%> (-1.72%) | :arrow_down: |\n| ...ter/finagle/zipkin/thrift/ScribeZipkinTracer.scala | 0% <0%> (\u00f8) | |\n| .../com/twitter/finagle/zipkin/core/TracerCache.scala | 37.5% <0%> (\u00f8) | |\n| ...ala/com/twitter/finagle/zipkin/core/Endpoint.scala | 86.66% <0%> (\u00f8) | |\n| .../twitter/finagle/zipkin/core/DeadlineSpanMap.scala | 94.44% <0%> (\u00f8) | |\n| ...m/twitter/finagle/zipkin/core/SamplingTracer.scala | 85.71% <0%> (\u00f8) | |\n| .../twitter/finagle/zipkin/core/RawZipkinTracer.scala | 68.75% <0%> (\u00f8) | |\n| .../finagle/zipkin/thrift/ScribeRawZipkinTracer.scala | 60% <0%> (\u00f8) | |\n| ...a/com/twitter/finagle/zipkin/core/Annotation.scala | 100% <0%> (\u00f8) | |\n| ... and 34 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update ed5f8d2...fee3c5d. Read the comment docs.\n. # Codecov Report\nMerging #737 into develop will increase coverage by 0.01%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #737      +/-\n===========================================\n+ Coverage    70.39%   70.41%   +0.01%   \n===========================================\n  Files          745      745            \n  Lines        23718    23718            \n  Branches      1723     1707      -16   \n===========================================\n+ Hits         16697    16700       +3   \n+ Misses        7021     7018       -3\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...finagle/http/codec/ResponseConformanceFilter.scala | 95.65% <100%> (\u00f8) | :arrow_up: |\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 52% <0%> (-12%) | :arrow_down: |\n| ...witter/finagle/mux/pushsession/MessageWriter.scala | 87.17% <0%> (-1.29%) | :arrow_down: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 74.46% <0%> (+6.38%) | :arrow_up: |\n| ...le/http2/transport/PriorKnowledgeTransporter.scala | 97.22% <0%> (+11.11%) | :arrow_up: |\n| ...cala/com/twitter/finagle/http2/DeadTransport.scala | 28.57% <0%> (+28.57%) | :arrow_up: |\n| ...n/scala/com/twitter/finagle/http2/Exceptions.scala | 50% <0%> (+50%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d91944b...dc4f8bd. Read the comment docs.\n. # Codecov Report\nMerging #740 into develop will increase coverage by 0.64%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #740      +/-\n===========================================\n+ Coverage    70.43%   71.07%   +0.64%   \n===========================================\n  Files          745      679      -66   \n  Lines        23724    20710    -3014   \n  Branches      1736     1540     -196   \n===========================================\n- Hits         16709    14719    -1990   \n+ Misses        7015     5991    -1024\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...y4/http/handler/FixedLengthMessageAggregator.scala | 95.83% <\u00f8> (\u00f8) | :arrow_up: |\n| ...cala/com/twitter/finagle/netty4/http/package.scala | 95.31% <100%> (+0.15%) | :arrow_up: |\n| ...http/src/main/scala/com/twitter/finagle/Http.scala | 82.45% <100%> (+0.2%) | :arrow_up: |\n| .../scala/com/twitter/finagle/http/param/params.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ...twitter/finagle/mux/lease/exp/RequestSnooper.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...er/finagle/mux/stats/MuxCancelledCategorizer.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...witter/finagle/netty4/decoder/DecoderHandler.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...hreading/EventLoopGroupExecutionDelayTracker.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...ter/finagle/mux/lease/exp/GenerationalRandom.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...om/twitter/finagle/netty4/encoder/BufEncoder.scala | 0% <0%> (-100%) | :arrow_down: |\n| ... and 158 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update f306467...6db98df. Read the comment docs.\n. # Codecov Report\nMerging #742 into develop will decrease coverage by 0.08%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #742      +/-\n===========================================\n- Coverage     70.7%   70.61%   -0.09%   \n===========================================\n  Files          750      752       +2   \n  Lines        24041    24085      +44   \n  Branches      1763     1782      +19   \n===========================================\n+ Hits         16997    17008      +11   \n- Misses        7044     7077      +33\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...tter/finagle/loadbalancer/TrafficDistributor.scala | 97.67% <100%> (+3.48%) | :arrow_up: |\n| .../main/scala/com/twitter/finagle/mux/Response.scala | 42.85% <0%> (-14.29%) | :arrow_down: |\n| ...tter/finagle/stats/NonReentrantReadWriteLock.scala | 88.88% <0%> (-11.12%) | :arrow_down: |\n| .../twitter/finagle/http2/MultiplexCodecBuilder.scala | 79.16% <0%> (-10.84%) | :arrow_down: |\n| ...e/http2/exp/transport/Http2ClientEventMapper.scala | 92.85% <0%> (-7.15%) | :arrow_down: |\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 68% <0%> (-4%) | :arrow_down: |\n| .../mux/pushsession/MuxClientNegotiatingSession.scala | 75.82% <0%> (-2.2%) | :arrow_down: |\n| ...in/scala/com/twitter/finagle/mysql/Handshake.scala | 57.57% <0%> (\u00f8) | :arrow_up: |\n| ...main/scala/com/twitter/finagle/mysql/Request.scala | 84.29% <0%> (\u00f8) | :arrow_up: |\n| ...la/com/twitter/finagle/mysql/RollbackFactory.scala | 94.44% <0%> (\u00f8) | :arrow_up: |\n| ... and 7 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 884a4c5...57827c4. Read the comment docs.\n. # Codecov Report\nMerging #743 into develop will decrease coverage by 0.08%.\nThe diff coverage is 64.49%.\n\n\n```diff\n@@            Coverage Diff             @@\ndevelop    #743      +/-\n==========================================\n- Coverage    70.59%   70.5%   -0.09%   \n==========================================\n  Files          753     755       +2   \n  Lines        24094   24232     +138   \n  Branches      1780    1743      -37   \n==========================================\n+ Hits         17009   17085      +76   \n- Misses        7085    7147      +62\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../main/scala/com/twitter/finagle/redis/Client.scala | 0% <\u00f8> (\u00f8) | :arrow_up: |\n| ...ala/com/twitter/finagle/redis/StreamCommands.scala | 0% <0%> (\u00f8) | |\n| ...a/com/twitter/finagle/redis/protocol/Command.scala | 100% <100%> (\u00f8) | :arrow_up: |\n| ...tter/finagle/redis/protocol/commands/Streams.scala | 98.7% <98.7%> (\u00f8) | |\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 48% <0%> (-16%) | :arrow_down: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 66.66% <0%> (-6.25%) | :arrow_down: |\n| ...nagle/http2/transport/StreamTransportFactory.scala | 80.63% <0%> (-1.19%) | :arrow_down: |\n| ...rc/main/scala/com/twitter/finagle/Exceptions.scala | 66.66% <0%> (-0.99%) | :arrow_down: |\n| ... and 2 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update d30c554...7166212. Read the comment docs.\n. # Codecov Report\nMerging #746 into develop will decrease coverage by 0.02%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #746      +/-\n===========================================\n- Coverage    69.48%   69.45%   -0.03%   \n===========================================\n  Files          764      764            \n  Lines        24354    24354            \n  Branches      1794     1793       -1   \n===========================================\n- Hits         16923    16916       -7   \n- Misses        7431     7438       +7\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 54% <0%> (-12%) | :arrow_down: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 66.66% <0%> (-6.25%) | :arrow_down: |\n| ...om/twitter/finagle/dispatch/ClientDispatcher.scala | 88.23% <0%> (-2.95%) | :arrow_down: |\n| .../http2/transport/Http2NegotiatingTransporter.scala | 94.02% <0%> (+1.49%) | :arrow_up: |\n| ...nagle/netty4/channel/ChannelExceptionHandler.scala | 88.23% <0%> (+11.76%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 8e2958a...9e28ff7. Read the comment docs.\n. # Codecov Report\nMerging #747 into develop will decrease coverage by 2.94%.\nThe diff coverage is 100%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #747      +/-\n===========================================\n- Coverage    69.46%   66.52%   -2.95%   \n===========================================\n  Files          764      757       -7   \n  Lines        24356    24266      -90   \n  Branches      1799     1793       -6   \n===========================================\n- Hits         16920    16143     -777   \n- Misses        7436     8123     +687\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../finagle/ssl/server/SslServerSessionVerifier.scala | 75% <100%> (\u00f8) | :arrow_up: |\n| ...tty4/ssl/server/SslServerVerificationHandler.scala | 78.78% <100%> (+0.66%) | :arrow_up: |\n| ...le/netty3/ssl/client/SslClientConnectHandler.scala | 78.84% <100%> (\u00f8) | :arrow_up: |\n| .../finagle/ssl/client/SslClientSessionVerifier.scala | 75% <100%> (\u00f8) | :arrow_up: |\n| ...tty4/ssl/client/SslClientVerificationHandler.scala | 88.88% <100%> (+0.31%) | :arrow_up: |\n| ...le/netty3/ssl/server/SslServerConnectHandler.scala | 66.66% <100%> (-2.09%) | :arrow_down: |\n| .../twitter/finagle/redis/protocol/StageDecoder.scala | 0% <0%> (-100%) | :arrow_down: |\n| .../finagle/redis/protocol/commands/HyperLogLog.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...a/com/twitter/finagle/redis/protocol/Command.scala | 0% <0%> (-100%) | :arrow_down: |\n| ...twitter/finagle/redis/protocol/commands/Keys.scala | 0% <0%> (-100%) | :arrow_down: |\n| ... and 44 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update bd4c999...1cf32ee. Read the comment docs.\n. # Codecov Report\nMerging #749 into develop will decrease coverage by <.01%.\nThe diff coverage is 13.63%.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #749      +/-\n===========================================\n- Coverage    69.31%   69.31%   -0.01%   \n===========================================\n  Files          765      765            \n  Lines        24397    24419      +22   \n  Branches      1829     1811      -18   \n===========================================\n+ Hits         16911    16925      +14   \n- Misses        7486     7494       +8\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...n/scala/com/twitter/finagle/http/HttpTracing.scala | 91.66% <100%> (+0.75%) | :arrow_up: |\n| ...ain/scala/com/twitter/finagle/http/TraceInfo.scala | 65.67% <9.52%> (-25.64%) | :arrow_down: |\n| .../http2/transport/Http2NegotiatingTransporter.scala | 86.56% <0%> (-5.98%) | :arrow_down: |\n| ...tter/finagle/redis/protocol/commands/Streams.scala | 98.75% <0%> (+1.25%) | :arrow_up: |\n| ...nagle/http2/transport/StreamTransportFactory.scala | 82.14% <0%> (+1.58%) | :arrow_up: |\n| ...com/twitter/finagle/netty4/ConnectionBuilder.scala | 75% <0%> (+1.92%) | :arrow_up: |\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 66% <0%> (+18%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update a423e16...dd85c59. Read the comment docs.\n. # Codecov Report\nMerging #751 into develop will increase coverage by 9.24%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #751      +/-\n===========================================\n+ Coverage    60.13%   69.37%   +9.24%   \n===========================================\n  Files          693      766      +73   \n  Lines        21224    24372    +3148   \n  Branches      1578     1851     +273   \n===========================================\n+ Hits         12762    16908    +4146   \n+ Misses        8462     7464     -998\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...scala/com/twitter/finagle/mysql/param/params.scala | 54.54% <0%> (\u00f8) | |\n| ...itter/finagle/memcached/TwemcacheCacheClient.scala | 0% <0%> (\u00f8) | |\n| ...ala/com/twitter/finagle/mysql/IsolationLevel.scala | 25% <0%> (\u00f8) | |\n| .../com/twitter/finagle/memcached/ClientAdaptor.scala | 0% <0%> (\u00f8) | |\n| ...com/twitter/finagle/memcached/util/AtomicMap.scala | 0% <0%> (\u00f8) | |\n| ...itter/finagle/memcached/protocol/text/Framer.scala | 85% <0%> (\u00f8) | |\n| ...er/finagle/memcached/PoolingReadRepairClient.scala | 0% <0%> (\u00f8) | |\n| ...in/scala/com/twitter/finagle/mysql/Parameter.scala | 63.88% <0%> (\u00f8) | |\n| ...scala/com/twitter/finagle/exception/Reporter.scala | 69.23% <0%> (\u00f8) | |\n| ...m/twitter/finagle/memcached/protocol/Command.scala | 72.72% <0%> (\u00f8) | |\n| ... and 279 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9132d0e...8a2d565. Read the comment docs.\n. # Codecov Report\nMerging #752 into develop will increase coverage by 9.23%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #752      +/-\n===========================================\n+ Coverage    60.13%   69.36%   +9.23%   \n===========================================\n  Files          693      766      +73   \n  Lines        21224    24372    +3148   \n  Branches      1578     1839     +261   \n===========================================\n+ Hits         12762    16905    +4143   \n+ Misses        8462     7467     -995\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| ...scala/com/twitter/finagle/mysql/param/params.scala | 54.54% <0%> (\u00f8) | |\n| ...itter/finagle/memcached/TwemcacheCacheClient.scala | 0% <0%> (\u00f8) | |\n| ...ala/com/twitter/finagle/mysql/IsolationLevel.scala | 25% <0%> (\u00f8) | |\n| .../com/twitter/finagle/memcached/ClientAdaptor.scala | 0% <0%> (\u00f8) | |\n| ...com/twitter/finagle/memcached/util/AtomicMap.scala | 0% <0%> (\u00f8) | |\n| ...itter/finagle/memcached/protocol/text/Framer.scala | 85% <0%> (\u00f8) | |\n| ...er/finagle/memcached/PoolingReadRepairClient.scala | 0% <0%> (\u00f8) | |\n| ...in/scala/com/twitter/finagle/mysql/Parameter.scala | 63.88% <0%> (\u00f8) | |\n| ...scala/com/twitter/finagle/exception/Reporter.scala | 69.23% <0%> (\u00f8) | |\n| ...m/twitter/finagle/memcached/protocol/Command.scala | 72.72% <0%> (\u00f8) | |\n| ... and 280 more | |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 9132d0e...183af90. Read the comment docs.\n. # Codecov Report\nMerging #753 into develop will increase coverage by 0.01%.\nThe diff coverage is n/a.\n\n\n```diff\n@@             Coverage Diff             @@\ndevelop     #753      +/-\n===========================================\n+ Coverage    69.17%   69.18%   +0.01%   \n===========================================\n  Files          767      767            \n  Lines        24386    24386            \n  Branches      1824     1830       +6   \n===========================================\n+ Hits         16869    16872       +3   \n+ Misses        7517     7514       -3\n```\n| Impacted Files | Coverage \u0394 | |\n|---|---|---|\n| .../main/scala/com/twitter/finagle/mux/Response.scala | 42.85% <0%> (-14.29%) | :arrow_down: |\n| ...nagle/netty4/channel/ChannelExceptionHandler.scala | 76.47% <0%> (-11.77%) | :arrow_down: |\n| .../com/twitter/finagle/tracing/BroadcastTracer.scala | 64% <0%> (-4%) | :arrow_down: |\n| ...e/http2/transport/AdapterProxyChannelHandler.scala | 86.51% <0%> (+1.12%) | :arrow_up: |\n| ...2/transport/RichHttpToHttp2ConnectionHandler.scala | 84.9% <0%> (+5.66%) | :arrow_up: |\n| .../http/exp/GenStreamingSerialServerDispatcher.scala | 72.91% <0%> (+6.25%) | :arrow_up: |\n| ...la/com/twitter/finagle/netty4/codec/BufCodec.scala | 92.85% <0%> (+7.14%) | :arrow_up: |\n\nContinue to review full report at Codecov.\n\nLegend - Click here to learn more\n\u0394 = absolute <relative> (impact), \u00f8 = not affected, ? = missing data\nPowered by Codecov. Last update 4588bc1...4b943e4. Read the comment docs.\n. \n",
    "kcamenzind": "\nIt might be preferable to implement a com.twitter.tracing.Tracer that's backed by io.opentracing.Tracer -- this way all of finagle's built-in annotations will be automatically integrated, without requiring duplication.\n\nWhile it would be possible to create an OpenTracing implementation of com.twitter.tracing.Tracer, there are numerous benefits to the approach suggested in this PR. OpenTracing is decoupled from any notion of a TraceId, so implementing it separately would remove inefficiencies of tracking both the TraceId and OpenTracing span across the wire. It also leaves the encoding of trace information up to the tracing implementation, so that finagle wouldn't have to directly depend on any specific format (such as the finagle-http X-B3- headers, finagle-thrift request/response headers, or finagle-mux Treq encoding).\nUsing OpenTracing as a separate tracing pathway also significantly reduces the amount of code needed for its implementation, as well as reducing the complexity of the code that finagle users need to write. This approach does require several new filters that are similar to the ones written for the built-in finagle tracing, but overall this approach leads to a cleaner, more concise, and easier to understand implementation.\n\nIs there a reason why this has to be implemented in finagle-http?\n\nThere's no reason that it has to be in finagle-http; it could definitely be moved though to an finagle-opentracing library (or something of that sort). There are already some http-specific tracing filters in the http codec, which is why I had originally written the opentracing filters there.\n. Hi Moses, thanks for the feedback and ideas! I realize that this first RFC didn't \"just work\" for the user, which needs to be addressed in whichever more complete solution we come up with. Some thoughts about implementation:\nThe core obstacle to including OpenTracing as a finagle tracer is that finagle Tracers pass around TraceIds with the specific traceId-spanId-parentId format, while OpenTracing Tracers rely on the span objects themselves,  which can have any implementation. This is an issue if you're trying to create a new span across the wire because OpenTracing has to have a reference to the parent span object, which it doesn't get with a TraceId. With that being said, I think that there are at least two reasonable implementations that seem relatively straightforward to pursue:\n1. We could add another module to the ServiceBuilder stack that has the role OpenTracing and can be configured to by default do nothing, or if the service is built with an .opentracing(tracer), it uses filters similar to the ones in this RFC to trace requests and send the spans across the wire. The positive of this approach is that it would be simple to implement and would have no compatibility issues with finagle-tracing. The downside to this approach would is that we're adding a completely separate pathway for tracing, which is inefficient and redundant.\n2. Another approach that we could take would be to initialize tracers and then wrap them in a class, (let's call it AnyTracer for now) as follows:\nscala\n   Service: service = new ServiceBuilder\n   . ...\n   .tracer(someFinagleTracer) // backwards compatible\n   .build()\nor\nscala\nService: service = new ServiceBuilder\n    . ...\n    .otTracer(someOpenTracingTracer)\n    .build()\nWhen either tracer(someFinagleTracer) or otTracer(someOpenTracingTracer) is called, finagle will then set the service's tracer to an AnyTracer(someFinagleTracer) or AnyTracer(someOpenTracingTracer), depending on which has been called.\nThe AnyTracer class would essentially allow either the finagle or OpenTracing class to inherit its own methods, while also providing an implementation for the other tracer type's methods. This would allow the tracer to still use finagle's Annotations to record events, but will also allow for sending span objects (via inject and join) across the wire.\nRoughly something like:\n``` scala\nclass AnyTracer(ot: io.opentracing.Tracer) \n    def inject(args):\n        ot.inject(args)\n    def join(args):\n        ot.join(args)\n    def record(Record):\n        // matches records to create and finish spans\n        // and log other key events\n    def letSpan(span: io.opentracing.Span)\nclass AnyTracer(ft: finagle.tracing.Tracer)\n    def inject(args):\n        // marshal the TraceId\n    def join(args):\n        // unmarshal the TraceId\n    def record(Record):\n        ft.record(Record)\n        def letSpan(span: TraceId)\n```\nThe only major difference regarding the filters would be to then call letSpan instead of letTraceId.\nHope this helps!\n. ",
    "bhs": "One related issue with the existing Finagle Tracer architecture is that things like https://github.com/twitter/finagle/pull/515 are even relevant at the Finagle layer (and, for now, they are). With OpenTracing, there can be a Zipkin-Kafka OpenTracing implementation, and \u2014 best of all \u2014 Finagle doesn't need to know a thing about it. :)\nIIUC, the Finagle code at master binds itself tightly to the structure and specific encoding of a TraceId struct. The alternative @kcamenzind suggests in this PR focuses on the semantics of the tracing operations (e.g., defining start times, finish times, logging events in between, and injecting/extracting from the wire format), obviously using the OpenTracing API in the process... if we moved in this direction, Finagle could deprecate and eventually remove the TraceId (which would be encapsulated by an equivalent OpenTracing implementation).\nTL;DR, an approach like the one illustrated here would allow us to remove lots of tracing-related subtlety and complexity from the Finagle codebase while also decoupling it from the encoding and transport concerns of any particular tracing system.\n. A while back, @kcamenzind and I met with @mosesn in person (since we work about 4 blocks from each other) and devised a reasonable plan for this work. Unfortunately, nobody has had time to put that plan into action :)\nHere\u2019s a summary of where we ended up. Others are of course encouraged to chime in with other suggestions/opinions about a path forward as they see fit.\nTo review, Finagle presently has a TraceId concept (which, just to be super clear, is actually an object with a traceId, parentId, spanId, and a sampled bit). That TraceId can be stored in the Finagle context, then in various places Finagle essentially logs against that TraceId.\nIn OpenTracing, this would be modeled a little differently\u2026 rather than placing specific IDs into the Finagle context (via a wrapper object), a single OpenTracing Span would be stored in the context; and the various tracing-specific logging methods would write directly to the OpenTracing Span API (which has a timestamped logging facility of its own).\nIn a final, post-migration state, Finagle would have less code, and there would be no need for interfaces like Record... the core finagle code would just log events to the Span found in the context. This end state would also be even further decoupled from any specific tracing system (e.g., Finagle per se would no longer need to know about things like trace/span/parent ids, or even the sampling bit). So in this respect, the migration seems like a win both for tracing systems and for Finagle.\nThe tricky thing is that it\u2019s a multi-step process assuming we aren\u2019t willing to break existing users of Finagle\u2019s tracing subsystem. Here\u2019s one way that could work:\n1. Support an OT Span in the Finagle context, log to it during the RPC lifecycle (e.g., at https://github.com/twitter/finagle/blob/eddeb3b8552702f7fb2b5d756440552d7ad94947/finagle-core/src/main/scala/com/twitter/finagle/tracing/Tracer.scala#L35), and do Inject and Extract at the process boundaries.\n2. Create some sort of adapter to the OpenTracing Tracer interface that could bridge all of the various Span lifecycle events into the Finagle tracing scheme. I haven\u2019t actually implemented it so I don\u2019t want to overpromise, but my sense from reading the code is that this would be doable without changing existing Finagle tracing implementations.\n3. Having done ^^^, remove the pre-existing Finagle tracing instrumentation (leaving the Span-based instrumentation in place)\n4. Grant some reasonable period for Finagle tracing impls to migrate to something OT-based\n5. \"Someday,\" delete the bridge code from (2) above\nNote that a Zipkin OpenTracing impl on one side of an RPC connection should be able to communicate with a peer running pre-OpenTracing Finagle+Zipkin without issue\u2026 i.e., there are no intended changes to the wire protocols anywhere in this proposal.\nIf anyone is interested in pursuing the path described above, it would be pretty fun code to write, and I'm happy to help out with any OpenTracing orientation/spin-up that's required. @kcamenzind is back at MIT for the school year and I am too swamped (and too unfamiliar with Scala) to do the brunt of the dev work myself.\n. @virusdave from the OpenTracing side, I also know of nobody actively working on this, though agreed that there are a lot of benefits and I would be happy to help orient anyone who wanted to take it on.. ",
    "virusdave": "Anyone actually working on this?  It seems far too useful to ignore.  I wish i had the spare time needed to do it myself.. ",
    "wsargent": "See https://github.com/opentracing-contrib/scala-finagle. ",
    "monkey-mas": "Thanks a lot for your quick and detailed response!\n\nWith that said, we need to make sure it's at least bugwards migration compatible.\n...\nIn the mean time, would it make sense to make request / response validation into a new filter?\n\nYes, I like your idea and strongly agree with it. :)\nWith regard to the actual implementation, we can 1) create a new filter and 2)add it to Http.scala like this so that finagle follows the spec by default and if some users don't like the filter they can just remove it? I might be wrong, please let me know if this is what you meant :)\n. Hi @mosesn,\nI've rebased and updated my commit! Though I think it's ready to be reviewed, one test from finagle-mysql failed... Actually it passes on my local machine.  If this is ok, please review my commits :)\n. Thanks for the review! Except this point, I think the fix commit should be fine. :) I'll squash additional commits into one after everything is ok.\nLooking forward to your feedback! :grinning: \n. @mosesn haha, sure sure. :) Please have a look when you have time and let me know then!\n. @bryce-anderson, cc: @mosesn \nThanks for having a discussion! Yes, I think it sounds nice! :)\n\nPerhaps this isn't something that the dispatcher should be concerned with and this could be moved from the HttpServerDispatcher to your ComplianceFilter.\n\nJust to make sure, do you mean we leave handle's core functionality and move rest of the functionality to ComplianceFilter?\nIf so, I think we need to make two things clear:\n1. which functionality can we move to ComplianceFilter?\n   If I understand your thought correctly, we might move:\n   1. setKeepAlive\n   2. others: e.g., removeContentLength, setTransferEncoding and addContentLength\n  It could be not really good to move these [functionality](https://github.com/twitter/finagle/blob/finagle-6.36.0/finagle-http/src/main/scala/com/twitter/finagle/http/codec/HttpServerDispatcher.scala#L70-L76) if we take the comment into account though???\n\n\ncan we safely achieve it(moving functionality to the filter) and maintain the current finagle's behaviour?\n   I think the biggest reason why we've added the problematic logic to handle is to make sure we apply the changes, such as removing a Content-Length and so on, just before we actually dispatch a response (after applying all filters and so forth)?\n   Based on your idea, ComplianceFilter will take this responsibility? If we can't guarantee that ComplianceFilter is used (just) before handle is called, then we might change finagle's behaviour? I might be wrong but I mean it's not nice if there's a possibility that another filter or functionality, which adds a Content-Length for example, can be called after ComplianceFilter is used to filter a response? (or is this fine?)\n\nWhat do you think?\n. @bryce-anderson Sorry I didn't get back to you. Wooow, great commit! Now it seems way straightforward and easy for us to solve the 204 and 304 issue :). (Maybe just modifying validate(...) would be enought?)\n\nIf you're interested, perhaps we can get your work into the ResponseConformanceFilter.\n\nDo you mean you'd like to finish the issue on your side ASAP? :eyes: (If so, yes please finish it :) I left the PR unsolved for a long time. Sorry about it!) Or I can possibly continue working within this PR? (Yup, I'd be interested in working for it though I'm not sure if my try works but I'll give it a shot by this weekend at the latest.)\n. @mosesn \nMy apologies. Sorry for not handling this PR for a long time.\n\nthis is failing in really strange ways. I think the messiness of finagle's HTTP compliance stuff is catching up to us. I'm going to keep on trying to make it work, but might have to give up if it takes too much time. If you have some time to look at this again, I'd be happy to send you what I've done so far.\n\nHonestly, I've got no idea why it fails. You have some clue, don't you?\nI think I can have some time to fix it. Can you please give me some information you've collected so far?\nIf things go wrong (or if you'd think it's not good to keep doing this stuff), let's close this PR. (Well, that's my fault for keeping the PR open... Sorry again! :)). @mosesn Thanks so much! Let me have a look at it :). @mosesn @bryce-anderson \nOkay I kinda understand our situation. I might be wrong but give me your thoughts please :)\nProblem\nThe current (wierd) problem we have is our response gives us Content-Length: 0 even if we remove it using ResponseConformanceFilter\nActually end-to-end test fails like:\n[info] - response with status code 204 must not have a message body nor Content-Length header field when non-empty body with explicit Content-Length is returned *** FAILED ***\n[info]   Some(0) was not empty (AbstractEndToEndTest.scala:1472)\nBased on the fact that the unit test ResponseConformanceFilterTest passes, I think the filter works properly.\nWhat I've observed so far\nI've done some print-debugging (& stack tracing) and found our code works as follows:\n\n\nBody & Content-Length are set in test code\nNetty3HeaderMap#set(Content-Length , 9) is called\n\n\nBody & Content-Length are both removed using ResponseConformanceFilter\n\n\nBijections#fullResponseToFinagle(res) and Netty3HeaderMap#add(content-length, 0) are called where res is\n  DefaultFullHttpResponse(decodeResult: success, version: HTTP/1.1, content: EmptyByteBufBE)\n  HTTP/1.1 204 No Content\n  content-length: 0)\n\n\nAdditionally, I roughly checked if our code adds the header somewhere, by using git grep 'contentLength' for example, but it seems not.\nBased on this, I think Content-Length: 0 is set when fullResponseToFinagle(...) is called, which ends up with contentLength == Some(0) thus test fails. It could be possible that Netty adds Content-Length: 0 and we have the header in NettyHttp.FullHttpResponse when calling fullResponseToFinagle(...)?\n(Naive) Solution\nWith that said I'm still not 100% for sure how and when Content-Length: 0 is set. If my guess is correct, the header is added after filters are applied to a response. So we can't avoid handling the issue within Bijections like below?\n```diff\n@@ -88,15 +90,21 @@ private[finagle] object Bijections {\n     }\n def fullResponseToFinagle(rep: NettyHttp.FullHttpResponse): FinagleHttp.Response = {\n   val payload = ByteBufAsBuf(rep.content)\n\n\n\nval status = rep.status\nval resp = FinagleHttp.Response(\n     versionToFinagle(rep.protocolVersion),\n-        statusToFinagle(rep.status),\n+        statusToFinagle(status),\n     BufReader(payload)\n   )\nresp.setChunked(false)\n+      if (status.codeClass() == HttpStatusClass.INFORMATIONAL || status == HttpResponseStatus.NO_CONTENT) {\n+        rep.headers().remove(\"Content-Length\")\n+      }\n   writeNettyHeadersToFinagle(rep.headers, resp.headerMap)\n   resp.content = payload\n``. Finally I determined the cause ofContent-Length: 0`. I believe it's set in HttpObjectAggregator#finishAggregation(...) by netty.\n\n\nThe following is the rough sketch of (reversed) execution paths to encounter Content-Length: 0.\n```\n3. Bijections#fullResponseToFinagle(...)\n\n\nUnpoolHttpHandler#channelRead(...)\n\n\nHttpObjectAggregator#finishAggregation(...)\n```\n\n\nAs I've mentioned before, the header's already set to 0 when Bijections#fullResponseToFinagle(...) is executed. Before this, UnpoolHttpHandler#channelRead(ctx: ChannelHandlerContext, msg: Any) is called where msg is something like\nHttpObjectAggregator$AggregatedFullHttpResponse(decodeResult: success, version: HTTP/1.1, content: CompositeByteBuf(ridx: 0, widx: 0, cap: 0, components=0))\nHTTP/1.1 204 No Content\ncontent-length: 0\nAs msg indicates, we've already got content-length: 0. This header is actually appended when HttpObjectAggregator#finishAggregation(FullHttpMessage aggregated) finishes execution. Because we've already removed Content-Length header using ResponseConformanceFilter, aggregated(AggregatedFullHttpResponse) doesn't have the corresponding header at the beginning of the method call. Actually aggregated.message.headers is DefaultHeadersImpl[] (empty). This leads to our unexpected result, i.e., Content-Length is set to String.valueOf(aggregated.content().readableBytes())) where\naggregated.content() == CompositeByteBuf(ridx: 0, widx: 0, cap: 0, components=0)\naggregated.content().readableBytes == (this.writerIndex - this.readerIndex) == 0\nref. readableBytes\nTherefore, aggregated has Content-Length: 0 here.. @bryce-anderson Sorry for my late reply. \n\nIn the meantime, we could disable the end-to-end tests that are failing due to the client issue.\n\nDo you mean we can just merge functionality of handleNoMessageResponse to ResponseConformanceFilter without end-to-end tests? Or should we lock this PR until Netty solves the problem? Either way sounds good to me, let me know your opinion :)\n\nIn my mind's eye, Netty should probably be fixed, so if you're interested in contributing to that project I think you've got a nice contribution on deck.\n\nCool! I'll open a PR related to this issue though I'm not quite sure if Netty community likes the change to follow RFC7230. :(\nAnyway I'll keep you updated! :). @bryce-anderson @mosesn \nActually thanks a lot for your patience and great feedback! It wouldn't be possible without your support :)\nOkay, I'll get started with the aggregation issue. The easiest solution could be to modify the logic of finishAggregation(...) as this should be the last point before an actual response is returned to a client. \nMoreover, some methods can be moved to HttpUtil and refactored like you said. Anyway let's discuss it at Netty's github :). Oops sorry to hear that :( I hope all is well at your end.\n(Anyway thanks for kindly letting me know!). AFAIU, (Http)ServerDispatcher#handle is called after all the filters are applied? In handle(), we add a Content-Length header field with a value of 0 in here. If I understand finagle's behaviour correctly, I think we can't avoid putting the code there?\n(but I have to admit this is not nice though :(\nI might be wrong, please give me your idea :)\n. Yeah, good name! :+1:\nFixed it! \n. Sure. Though I've added a log here in a new commit, (as you suggested) it might be better to just fail here instead of modifying and sending a message? So that users can notice that there's something wrong happening?\n. Done! :grinning:\n. Oops, sorry my bad! Fixed it!\n. Sure, I've added the corresponding test! :D\n. Oops, I think I was wrong. As RFC 7230 section3.3.2 says, if we do want to send a Content-Length header field, we should return the Content-Length value of the cached content which has been returned to a client in a 200 response. I thought a value of Content-Length header field was always 0 as the content of a 304 response is always empty...\nThe following is the citation from the section;\nA server MAY send a Content-Length header field in a 304 (Not Modified) response to a conditional GET request (Section 4.1 of [RFC7232]); a server MUST NOT send Content-Length in such a response unless its field-value equals the decimal number of octets that would have been sent in the payload body of a 200 (OK) response to the same request.\n. > I guess this is something that users must set?\nI think so if users really want to send the header field in a 304 response... I'm not sure how to validate that they've chosen the correct Content-Length value. As the RFC says, if the field-value doesn't equal the decimal number of octets that would have been sent in the payload body of a 200 (OK) response to the same request then we MUST NOT send Content-Length.\n\nI guess it's better to just not modify the content length in this case.\n\nYeah, not modifying is better I suppose so. Will fix it :)\nI feel that things will be more complicated if we start to think about a Content-Length value of a 304 response as I've mentioned. Do you think we could stick to the original problems we had before and hopefully we can find a way to handle the new issue we've found now? What do you think?\n. Fixed it :)\n. Hi @taylorleese  cc: @mosesn ,\nI might be wrong but it seems like handle(res: Reponse) is called multiple times and it's called again after all filters are applied (s.t., even after ComplianceFilter is applied) as I mentioned before. I found this when I debug my commit with sample code like this.\nI think this means a Content-Length is added to a 204 response for example. Suppose we're going to return a 204 response;\n1)we remove a Content-Length and message-body of a 204 response by using ComplianceFilter\n2)but then handle is called and this line adds a Content-Length with a value of 0 to a 204 response as we've already removed a Content-Length in 1) and !rep.contentLength.isDefined holds.\nTo achieve what we want to do, i.e., send a 204 without a Content-Length and message-body for example, we need to have this condition here. The condition checks whether we send a Content-Length or not.\nThis is why I think we still need mayHaveContent. Anyway, I need your help to sort this out. Can you please help me? :)\n. Hi @bryce-anderson,\nThanks for your advice! (and sorry for my late reply!) Well I think I don't fully follow your strategy, can you give me more details please?\n\nI do think you're right in that its going to be called after all the filters so in its current form, its a problem.\n\nThanks for checking it, yeah that's what I expected :)\n\nIt sounds like the problem is accommodating people sending a 204 with a body\n\nDo you mean we don't provide support for removing a body-message of 204 and 304 responses if a body is explicitly sent by users?\n\nIn the case of people sending a 204 without a body, the content-length header gets set to 0\n\nUmm.. I think Content-Length header field is not set to 0 for a 204 response when there's no message-body. (But I think it's correct that the header field is added when we explicitly send a message-body, which is our problem here.)\nMore exactly, in the case of a 204 response with no body, rep.contentLength is None and rep.content.length is 0 I suppose.\nOh BTY, do you assume to use ComplianceFilter (or some filters) to handle the problem? It seems like you tried to solve the problem by just changing the original code at 96 in HttpServerDispatcher? (I thought so cos we don't have to check if a 204 response has contentLength=Some(0) after applying ComplianceFitler.)\n. > Sorry, its not clear to me if we agree. I believe at a Response with an empty body will get assigned a content length header of length 0. I haven't added tags to the handle function to check, but a raw Response should not be chunked and will not have a defined contentLength, so line 97 (on master, maybe this is the source of our confusion) should set the content-length to 0 on a 204 response without a body.\nYes, I understand the code in the same way. Thanks for your explanation! :)  (I was thinking about Content-Length of rep where the code on line 97 is not applied.)\n\nThat suggests to me (and we should get @mosesn's opinion in light of what we've found) that this isn't actually a job for a filter. This feels more like the things that are getting delegated to the netty pipeline such as RespondToExpectContinue. \n\nOkay, so you mean we create a ChannelHandler, like RespondToExpectContinue, instead of using a Filter and give it a responsibility to handle 204 and 304 responses? Correct? Honestly, I'm not familiar with Netty's pipeline and not quite sure how it works in finagle. What sort of high-level solution (or actual implementation) do you have in your mind? (Can you please be more specific?)\n. Do you mean we need a plan to conform to RFC7230#section-3.3.1 probably?\nIt says:\nA server MUST NOT send a Transfer-Encoding header field in any\n   response with a status code of 1xx (Informational) or 204 (No\n   Content).  A server MUST NOT send a Transfer-Encoding header field in\n   any 2xx (Successful) response to a CONNECT request (Section 4.3.6 of\n   [RFC7231]).\nDo you think it's better for us to handle the issue in this PR or another PR?\nWell, my first thought to solve the problem is like this:\n```\nprivate[this] def handleNoMessageResponse(rep: Response): Unit = {\n  // remove message body if necessary\n// remove Content-Length and Transfer-Encoding if necessary\n  if (rep.status != 304 && mustNotIncludeMessageBody(rep.status)) {\n    if (rep.contentLength.isDefined) {\n      rep.headerMap.remove(Fields.ContentLength)\n      log.error(...)\n    }\n    if (rep.isChunked) {\n      rep.headerMap.remove(Fields.TransferEncoding)\n      log.error(...)\n    }\n  }\n}\n```\nWDYT?\n. Okay, I think you mean we need to validate 100 <= status code < 200 for 1xx condition check, correct? I thought it'd be enough to check Continue, SwitchingProtocols and Processing but (if you meant it) yes I think it's reasonable :)\n. Good point, thanks! I fixed the condition to check 1xx codes as well. WDYT?\n. Yeah, you're right. It's nice to have small tests! Hope my modification is what you suggested :)\n. It seems like I misunderstood the concept of Feature. I defined NoBodyMessage to pass some tests in finagle-http2 for example (by ignoring test cases?). What do you think I should've done here? :eyes: \n. Your suspicion sounds reasonable to me. In that case, we might have timeout error or exception?\n\nDo the tests work if you remove the 101 test from ClientFailUpgradeTest?\n\nYup, I think it works without 101 test. Currently, 101 test (finagle-http) also fails for EndToEndTest with the following error:\nSome(0) was not empty (AbstractEndToEndTest.scala:949)\nAbstractEndToEndTest.scala:949\nIt looks like Content-Length has the value of 0, which shouldn't happen like we can see from ResponseConformanceFilterTest...\n@bryce-anderson What do you think about this?\n\nCould we restructure the tests to use \"featureImplemented\" to decide whether to include 101 or not instead of just turning them off for CFUT?\n\nCould you show me some sample code of how to use featureImplemented please? It seems like there's no code using it in finagle? :eyes: \n. ",
    "ashald": "@vkostyukov how that could be done with N4 proxy?\n. @vkostyukov thanks!\nI tried:\n```\nimport com.twitter.util.Await\nimport com.twitter.finagle.Http\nimport com.twitter.finagle.http.{Request, Method}\nimport com.twitter.finagle.netty4.http.exp.Netty4Impl\nval client = Http.client.configured(Netty4Impl).withTransport.httpProxyTo(\"service-available-only-through-proxy.acme.co\", None).newService(\"localhost:4140\")\nval req = Request(Method.Get, \"/\")\nAwait.result(client(req))\n```\nAnd the only thing I got is few log messages:\nSep 12, 2016 12:27:30 PM com.twitter.finagle.netty4.channel.ChannelStatsHandler channelRead\nWARNING: ChannelStatsHandler received non-channelbuffer read\nSep 12, 2016 12:27:30 PM com.twitter.finagle.netty4.channel.ChannelStatsHandler channelRead\nWARNING: ChannelStatsHandler received non-channelbuffer read\nI wonder whether something wrong with my proxy or there is some kind of issue in Finagle Netty4 Proxy module?\n. > So the Await.result() never returns?\nYeah, I waited for ~ 5 mins but didn't get anything. \n\nAlso if you don't use TLS/SSL you don't actually need TCP tunneling (don't need N4) and can simply send HTTP messages with proper Host header to your proxy server.\n\nOK, I think I'll go this way - thanks.\n. ",
    "maheshkelkar": "Hello @roanta, I will submit a PR on Monday. \n. @roanta @argha-c @kevinoliver \nI implemented a simple solution stopProbing that gets executed either we succed, fail or hit an exception. However, what I notice is:\n1. There are 4 instances of FailureAccrualFactory. Not sure why.\n2. After markDeadFor timeout, all 4 objects start probing\n3. If one or more requests arrive at the same time, all one or more objects accept that request, fail and go back to dead state. Now, if requests are sparse, then only 1 request fails, mark all of these objects to dead.\nSo, every 30 seconds, we loose at least 1-4 operations in probing. \nDo we have an option of invoking a probe i.e. self-probe on one of these objects? I thought FailFast does the very same thing. But, if I tried, and it doesnt seem to probe.\n. @roanta. Thanks for the response. \n- Are you suggesting that we have 1 FailureAccrualFactory per thread? i.e. we have a session per thread?\n- I see 4 FailureAccrualFactory instances for localhost:11212, whether I configure FailFastFactory or not.\nBut, thats not the real problem. IMO problem is probing is causing me at least 1 failure after  markDeadFor timeout.\nI wonder:\n- why don't I see this on the very first attempt, when all 10 ops goto active node localhost:11211\n- why do we not use auto-triggering for probing, instead of wasting a request\n- if we fail the request, why not attept it again over the different memcached node (I wonder if this can be controlled by retry)\n. @roanta: Thanks for the response\nHere is the diffs that I am adding for this PR: https://gist.github.com/maheshkelkar/75b87741008adf7d912cd9a36e40c862\n\n\nI see 4 FailureAccrualFactory instances for localhost:11212, whether I configure FailFastFactory or not.\nWhere are you seeing four? \n\n\nI see 4 instances marked dead for localhost:11212. See concurrent_lb_replica with values of 0,1,2,3 at the end.\nD 0714 15:01:38.714 THREAD234 TraceId:a0a70e136dac97d4: FailFastFactory marking connection to \"memcached\" as dead. Remote Address: Inet(localhost/127.0.0.1:11212,Map(concurrent_lb_replica -> 2))\nD 0714 15:01:38.739 THREAD234 TraceId:797cb15c29c1f414: FailFastFactory marking connection to \"memcached\" as dead. Remote Address: Inet(localhost/127.0.0.1:11212,Map(concurrent_lb_replica -> 0))\nD 0714 15:01:38.745 THREAD234 TraceId:b4769a43446a65e5: FailFastFactory marking connection to \"memcached\" as dead. Remote Address: Inet(localhost/127.0.0.1:11212,Map(concurrent_lb_replica -> 1))\nD 0714 15:01:38.750 THREAD234 TraceId:a0a70e136dac97d4: FailFastFactory marking connection to \"memcached\" as dead. Remote Address: Inet(localhost/127.0.0.1:11212,Map(concurrent_lb_replica -> 3))\nAfter 30 seconds i.e. markDeadFor timeout, I see probing started on 4 instances:\nW 0714 15:02:08.726 THREAD200 TraceId:a0a70e136dac97d4: ***FailureAccrualFactory: startProbing for \"\"\nW 0714 15:02:08.748 THREAD200 TraceId:a0a70e136dac97d4: ***FailureAccrualFactory: startProbing for \"\"\nW 0714 15:02:08.748 THREAD200 TraceId:7b2279e7c3c1cace: ***FailureAccrualFactory: startProbing for \"\"\nW 0714 15:02:08.757 THREAD200 TraceId:b4769a43446a65e5: ***FailureAccrualFactory: startProbing for \"\"\n\n\nwhy don't I see this on the very first attempt, when all 10 ops goto active node localhost:11211\nI'm not sure I understand what you mean. What behavior are you referring to?\n\n\nIn this test, I have enabled FailFastFactory. I am executing 10 GET operations every 60 seconds. After 60 seconds, I see 2 requests picked up by 2 of FAF instances and fails. As a result, I think 1-4 concurrent requests may fail every 60 seconds:\nFirst 2 requests received\nD 0714 15:02:41.307 THREAD209 TraceId:b82a8065f1050e8a: Processing: Request(GET, mtp.localhost:9090/les with CustomerId: mtp\nD 0714 15:02:41.307 THREAD210 TraceId:aa3f6e285c203e9a: Processing: Request(GET, mtp.localhost:9090/les with CustomerId: mtp\n2 requests picked up by 2 FailureAccrualFactory instances. Not sure which one. I don't see any FailFastFactory messages either. \nW 0714 15:02:41.308 THREAD209 TraceId:b82a8065f1050e8a: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 15:02:41.308 THREAD210 TraceId:aa3f6e285c203e9a: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 15:02:41.308 THREAD210 TraceId:aa3f6e285c203e9a: ***FailureAccrualFactory: stopProbing for \"\"\nW 0714 15:02:41.308 THREAD209 TraceId:b82a8065f1050e8a: ***FailureAccrualFactory: didFail for \"\"\nW 0714 15:02:41.308 THREAD209 TraceId:b82a8065f1050e8a: ***FailureAccrualFactory: stopProbing for \"\"\nW 0714 15:02:41.309 THREAD209 TraceId:b82a8065f1050e8a: ***FailureAccrualFactory: DEAD for \"\"\nW 0714 15:02:41.308 THREAD210 TraceId:aa3f6e285c203e9a: ***FailureAccrualFactory: didFail for \"\"\nW 0714 15:02:41.309 THREAD209 TraceId:b82a8065f1050e8a: ***FailureAccrualFactory marking connection to \"\" as dead. Remote Address: Failed(com.twitter.finagle.Address$$anon$1: failing)\nW 0714 15:02:41.309 THREAD210 TraceId:aa3f6e285c203e9a: ***FailureAccrualFactory marking connection to \"\" as dead. Remote Address: Failed(com.twitter.finagle.Address$$anon$1: failing)\nW 0714 15:02:41.309 THREAD210 TraceId:aa3f6e285c203e9a: ***FailureAccrualFactory: DEAD for \"\"\nNote that remaining 8 requests are channeled to localhost:11211 and succeeded. I tried configuring the Retry but that didnt work. I mean I didn't any retry occuring, I wonder if its protocol specific\nSessionStores.MemcachedStore(\n          Memcached.client\n            .configured(FailureAccrualFactory.Param(1, () => Duration.fromSeconds(30)))\n            .configured(Memcached.param.EjectFailedHost(true))\n            .configured(FailFastFactory.FailFast(true))\n            .withRetryBudget(RetryBudget.Infinite)\n            .newRichClient(s\"memcached=${hosts}\")))\n. Hi @roanta, thank you. Setting the connectionsPerEndpoint to 1 did solve that problem. And I can clearly see that only 1 FAF instance is used.\nSo I will go ahead committing the PR for this issue. \nI also noted this behavior, that if I try 10 requests at a time, I see some of those numbers (5 in this example below) gets queued to be processed by the failed FAF. And even after marking that FAF instance DEAD, we still go through the queue and eventually failing them.\nNote that in this example 11211 is inactive.\nD 0714 18:07:21.716 THREAD232 TraceId:3217119f247dc776: FailFastFactory marking connection to \"memcached\" as dead. Remote Address: Inet(localhost/127.0.0.1:11211,Map(concurrent_lb_replica -> 0))\nW 0714 18:07:21.719 THREAD232 TraceId:3217119f247dc776: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 18:07:21.720 THREAD232 TraceId:3217119f247dc776: ***FailureAccrualFactory: didFail for \"\"\nW 0714 18:07:21.720 THREAD232 TraceId:3217119f247dc776: ***FailureAccrualFactory: DEAD for \"\"\nW 0714 18:07:21.721 THREAD232 TraceId:3217119f247dc776: ***FailureAccrualFactory marking connection to \"\" as dead. Remote Address: Failed(com.twitter.finagle.Address$$anon$1: failing)\nAt this point the FAF is dead, but we still continue processing requests and failing\nW 0714 18:07:21.726 THREAD232 TraceId:aabdb26547896feb: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:aabdb26547896feb: ***FailureAccrualFactory: didFail for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:cd0eedac5bf41047: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:cd0eedac5bf41047: ***FailureAccrualFactory: didFail for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:41c7e1288d7ccc07: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:41c7e1288d7ccc07: ***FailureAccrualFactory: didFail for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:e66ba0ff875da440: ***FailureAccrualFactory: onServiceAcquisitionFailure for \"\"\nW 0714 18:07:21.726 THREAD232 TraceId:e66ba0ff875da440: ***FailureAccrualFactory: didFail for \"\"\n. @roanta @jcrossley. Updated as per the comments; all the checks have passed. Let me know if this can be merged. \nAlso, please let me know which release and approx when will this show up in the bintray\n. Thank You!\n. @roanta, is there a way to ensure that this change does get merged and doesn't miss the boat for release next month\n. Thank you @mosesn @roanta @jcrossley \n. ",
    "cryptoque": "@adriancole @mosesn  If no one is working on it, i would like to work on this issue. . ",
    "lucascs": "We're using for http clients and considering writing/enhancing a Kafka producer/consumer codec\n. ",
    "clumsy": "@bryce-anderson yes, I'm working on Windows. Looks like the message is different in that case.\nCan this be incorporated into finagle?\nSorry, cannot contribute as I don't use Scala.\n. No problem, it's just I won't be compiling it.\n. @mosesn I knew it wouldn't be simple...\nI tried running via both standalone sbt and from the script.\nKeeps complaining about missing 4.8.0-SNAPHOT of scrooge:\n[warn]  Note: Unresolved dependencies path:\n[warn]          com.twitter:scrooge-sbt-plugin:4.8.0-SNAPSHOT (sbtVersion=0.13, scalaVersion=2.10) (/Users/alexander_jipa/Projects/scala/finagle/project/plugins.sbt#L9-10)\n[warn]            +- default:finagle-build:0.1-SNAPSHOT (sbtVersion=0.13, scalaVersion=2.10)\nsbt.ResolveException: unresolved dependency: com.twitter#scrooge-sbt-plugin;4.8.0-SNAPSHOT: not found\nAfter traversing the fields found Build.scala with funny logic: \n``` scala\n...\n  val suffix = if (branch == \"master\") \"\" else \"-SNAPSHOT\"\nval libVersion = \"6.36.0\" + suffix\n  val utilVersion = \"6.35.0\" + suffix\n  val ostrichVersion = \"9.19.0\" + suffix\n  val scroogeVersion = \"4.8.0\" + suffix\n...\n```\nOnly builds from master branch...\n. Not but soon I will, I'll let you know.\n. ",
    "rklancer": "Thanks for the response @mosesn!\nSo, I'm sold on Netty's battle hardened qualities and I don't expect Finagle to try to work around anything it doesn't support.\nBut ... I guess I'm not convinced that that Netty 3 actually requires buffering the whole http message. If you specify a maxChunkSize in the HttpMessageDecoder which is smaller than the Content-Length, it emits an HttpMessage followed by HttpChunks, just as it does for chunked-transfer encoding (look for the READ_FIXED_LENGTH_CONTENT_AS_CHUNKS state).\nI assume that Finagle is fundamentally capable of accepting this sequence of Netty events (HttpMessage + HttpChunks) and incrementally filling the Reader's underlying buffer--or am I mistaken that this is what it does when it serves a chunked-transfer-encoding request with the streaming option enabled?\nI'd say here that it looks like a simple matter of exposing an option to set a chunk size independently of the request size limit. But I find that, if I manually set the chunk size to less than the uploaded file size (in a debugger), the following hangs:\nReaders.readAll(request.reader()).get();  // pardon the Java\nTaking a closer look, I find that the Netty pipeline emits the HttpMessage and several chunks, but gets closed before the final chunk is emitted. Thus, presumably, the hang. I'm not sure why that would be, but I'm in danger of going down a rathole.\nMy bigger question is, should I continue going down this route? If it turns out to be a simple matter of tweaking the pipeline setup, would Finagle be interested in supporting a use case where streaming + a modest chunk size is used in order to allow proxying of large, but fixed-size, uploads?\nOf course, I know a Netty 4 transition is in the works, so we can't get too deep here.\nMy specific use case is a Finatra server, as mentioned, which on the one hand interacts with other Finagle services, and on the other exposes an HTTP API to our mobile apps. They would send multipart requests with small application/json part and a potentially much larger \"attachment\" which we really just want to forward downstream. So we do have to process the client's request in app code, but buffering the whole client request before sending it downstream seems like it could be a scaling pain point. Especially given that we are talking about mobile clients, so we expect downstream to be able to drain bytes much faster than clients can send them.\nThanks!\n. Thanks! I'm pretty sure Netty 4 supports that (one old comment from the netty mailing lists suggests HttpChunk was renamed to HttpContent in Netty 4 exactly because the name seemed to imply chunked encoding was necessarily being used)\nShould we leave this ticket open? I'm not sure whether or when we would submit a PR. We're discussing a number of different options for the underlying problem and haven't established for sure that it will be a scaling problem.\n. ",
    "edio": "I believe we can close this now. I'd happily contribute to finagle what I can, but we need to be on the same page first.\n\nI think that 2 is expected behavior\n\nI'd like to discuss this if you don't mind.\nI do understand the purpose of the latch, that it lets data to accumulate... \nI'd say, that latch basically creates non-overlapping windows for calculating histograms.\nOne way to look at snapshot behavior, is that calls to snapshot periodically start new windows. If we only look at snapshot from this point of view, the current behavior is consistent, everything is fine.\nBut let's think about snapshot from caller's perspective. A caller is not interested in a creation of some windows, it is interested in getting a snapshot of the current state. And for me as a caller, it looks like at any arbitrary moment of time (except the first call and some following calls), the behavior of snapshot is following:\n if it is the first call outside of some window (simply speaking, first call in a while), a caller gets consistent (1) snapshot that includes the most recent (2)  data.\n following calls get a snapshot that is stale but is not older than latchPeriod (3).\nThis behavior is true for every call except some number of first calls, which always get a stale snapshot - a snapshot of state at application startup. And it doesn't matter when the call is made. If we make a call 1 hr after applications startup, we'll still get an empty histogram.\nThis behavior is not consistent with (1), (2) and (3).\nThat's why I believe, snapshot on the first call should return a snapshot of the data it has accumulated so far, no matter, how much data is there.\nAlternatives I see are\n start a window with the histogram creation. Con: instance may be created long before it starts accumulating any data. So effectively, it is the behavior I proposed above.\n start a window with the first datum that comes to the histogram. Con: minor runtime overhead on adding new data + code complication.\n\nLet's make it more practical (perhaps I should have started from this :) maybe I'm trying to make this code to do something it doesn't intend to do).\nImagine one-off batch task that is executed periodically. We want to collect metrics of every batch and emit them at the end of the batch.\nIf the behavior of snapshot was like I described, we could reuse the code for the purpose and just call snapshot in the end and get a consistent histogram. Right now, we'd need to call snapshot 2 times and the second call should be latchPeriod away from the first one (assuming we fix the bug with latchPeriod being not respected). We could set latchPeriod to 1ns and just make 2 calls in a row, but I hope you'll agree that the behavior is very strange from callers perspective. \nSorry for a long comment :). @mosesn thanks for pointing me to that class. I'll try to use it.\nNow back to the issue of latchPeriod being not respected. Frankly, the more I look at the code, the less I understand it. For example:\n what is the purpose of a \"wiggle room\" of 1 second? :82. Looks like a quick workaround to a very specific issue for a very specific use-case in a very specific environment.\n I do not understand potentially updating nextSnapAfter to the value in the past :84. If I'm not mistaken, this will cause histogram to be (almost) empty occasionally. Consider a test case: last snapshot is made at t0, latchPeriod is 1 minute. We call snapshot 2 times in a row at t0 + 61.seconds and t0+62.seconds. First call will return snapshot with data for 61 seconds and set nextSnapAfter to t0 + 60.seconds. Next call will include data for only 1 second and set nextSnapAfter to t0 + 120.seconds\n* having mutable snapshot to handle recalculations, while returning new instance of immutable snapshot on each call from synchronized block :94\nI'm relatively new to Scala, so maybe I'm missing something. \nAnyway, what do you think about the mentioned issues? Would you be open to consider a PR that fixes both the latchPeriod issue and also all the issues mentioned above? Or would you prefer an isolated fix isntead?. I made this fix as small and as isolated as possible. I see, how this class may be improved in terms of both performance and semantics, I may do this in a different PR if there's interest.. @luciferous \nthanks for a quick feedback.\nI agree, that the API is confusing. My main motivation was backward compatibility, and I'm eager to redo this if compatibility is not an issue.\nIf developers always decide between using content or reader basing on the value returned by isChunked, then it is safe to invert the API. I'd vote for doing this.\nRegardless of whether we invert or not, I like your idea with optional parameter.\n. I fixed review notes.\nI need some time to figure out why tests fail if buffer size for the aggregator is 0.\nI thought, it should work, but apparently I missed something. My guess atm, is that even when we deduced a message length to be zero, netty can still send some content which we attempt to buffer (and since buffer length is 0, aggregator returns error 413).\nOr maybe some tests just have to be adjusted.. I fixed the failing test. The issue was not in the code, but in the test itself. It assumed, that the incoming request is not chunked, hence its reader has all the content already, hence it is safe to read it synchronously.\nDo we want to get back to the parameter name discussion and try to comeup with better name? Or do you think it's good as is? If yes, do you want me to squash all the commits into a single one before you merge?\n. I think, having few e2e tests that test only new mixed behavior are needed. I only tested this manually. I'll add some shortly.. A quick update: I've been busy with other stuff today. Still working on those tests.. I added couple of tests to cover cases we discussed. Sorry for all those force pushes.\n@vkostyukov, github says, there's still some change requested by you, but I looked through all the threads, and seems, that everything is covered. Did I miss something?\nLet me know, if you want me to squash the changes.. Thanks for thorough reviews, folks! It was a pleasure to work on this with you.\n@vkostyukov, I assumed, that the commit message will be set from PR description on squash. First commit message in PR became a bit inaccurate after all the fixes applied:\n\nDefault value for the new parameter is 0 which forces streaming of all messages (changes former behavior).\n\nIDK if that's too late to fix. In any case, that's nothing critical I guess.. I agree. I'm reworking this code right now and came to the same conclusion.\nInitially I wasn't sure, if we can set maxContentLength to 0 and still retain all the features.\nNow I looked more carefully in the code, and it seems, that the only case when we really aggregate something in buf is when there's a HttpMessage with following HttpContent.\nAll other cases only make sure, that the request, when it makes sense, has isChunked set to false and content is available as string or buf.\nI wonder even, if it makes sense to eventually split FixedLengthMessageAggregator so it has more clear purpose: one class should handle actual aggregation,  and the other one should handle all the quirks, like noContentResponse and messages without content-length and trasfer-encoding headers... I had no intention to implement client side, but I'm open doing this if you think we need that. I do not know, however, what is the behavior right now, and what it should be. Would need to investigate.\nminChunkSize is a bit confusing for me.\nIn general, it is confusing, that finagle's chunk is different from http chunk. It took me some time to realize, that Request.isChunked has, strictly speaking, nothing to do with Transfer-Encoding header.\nIf you believe, that for experienced finagle users minChunkSize would clearly mean finagle's chunk, then let's do this name. Otherwise, I, as non-experienced finagle user, would prefer to see the parameter named smthng like streamingThreshold. I implemented your suggestions on the server-side (had to force push \u2014 I noticed that my feature branch been branched from the master).\nI need some time to figure out how exactly the client-side should be changed.. @vkostyukov , just to clarify.\nIt seems that in your last message you assume that we already did changes to API but did not modify pipeline creation code.\nWhile in fact I didn't change the API. Signature of theHttp.client.withStreaming is the same as before this PR: withStreaming(Boolean).  \n\nHttp.client.withStreaming(true, 128.kb) would mean the minChunkSize is silently ignored.\n\nIs this your only concern? Or do you indeed want to change client's behavior?. @luciferous, I don't know the answer, but I'll reply just because I want to understand this too and I hope someone will correct me if I'm wrong.\nFirst of all, I don't think there's flatMap method on Reader, you likely missed the call to read in you code.\nRead requires an argument \u00ad\u2014 number of bytes to read. So given the loop\ndef loop: Future[Unit] = {\n      req.reader.read(128.kilobytes).flatMap {\n        case Some(buf: Buf) => go(buf).before(loop)\n        case None =>  uture.Done\n      }\n    }\n\nresponse Content-Length is <= 128.kilobytes\ngo(buf) will receive buf.length <= 128.kilobytes as soon as whole message is read. The loop will have exactly one iteration.\nresponse Content-length is > 128.kilobytes\ngo(buf) will receive buf of an unknown (to me) size defined by netty pipeline and/or sending party. The loop will have multiple itrations.\nresponse Transfer-Encoding: chunked is set\ngo(buf) will receive buf of an unknown (to me) size defined by netty pipeline and/or sending party. The loop will likely have multiple iterations.\n\nIDK if my understanding is correct, but this is exactly my concern with the name minChunkSize. Although http chunk size (or any chunk size) per se, is not exposed via finagle API, parameter name suggests (at leat to me), that there's some buffering in the middle, and that the consumer of the reader will see the data only after minChunkSize requirement has been met (or on EOF). I'm not pushing for a name change, just trying to be on the same page with you folks.. @vkostyukov, buffering indeed may happen, but not in FixedLengthMessageAggregator.\nAggregator's buffering is all-or-nothing: we either buffer all message into a huge buffer up to maxContentLength or we bypass the aggregator, and emit chunks of data as they arrive from the upstream handlers in pipeline (and in this case minChunkSize does not have any effect).\nSo for example if we have a sufficiently large minChunkSize (say, 128 KiB) that is used as a maxContentLength for FixedLengthMessageAggregator, then the consumer of Request.reader wil actually never read a buffer of size 128*1024. On contrary, 128 KiB will likely be maximal theoretical value the consumer can read.. @luciferous \nsmall clarification\n\nbufferSize = 128.kilobytes: buffer up to 128.kilobytes; Reader.read will ALWAYS return buf where buf.length <= 128.kilobytes\n\nif \n bufferSizez is very small. For example bufferSize == 100.bytes\n request has Transfer-Encoding: chunked or request Content-Length is > 100\nthen Request.reader.read(128.kilobytes.inBytes) will likely read buf with buf.length > 100 (the value will be determined by upstream handlers in netty pipeline)\nif \n bufferSizez is very small. For example bufferSize == 100.bytes\n request does NOT have Transfer-Encoding: chunked and request Content-Length is <= 100\nthen Request.reader.read(128.kilobytes.inBytes) is guaranteed to read buf with buf.length <= 100\nSo, as you see, there are no guarantees at all.\nThis discussion makes me think, that maybe we need couple of tests to demonstrate that behavior, so it is easier to reason about the handler behavior?\nIn the meantime I will make an attempt to improve the scaladoc on the aggregator.. @luciferous , here's my attempt to explain this class. Please let me know if this makes any sense.. I'm not sure, that exactly \"http chunk\" phrase is defined anywhere, but at least what I mean by chunk in the context of HTTP chunked encoding is a part of http message body, enclosed in <content length>\\r\\n and \\r\\n as specified by chunked encoding format.\nIn a request with Transfer-Encoding: chunked and body prefix foobar suffix these are chunks\n\"7\\r\\nprefix \\r\\n\"\n\"7\\r\\nfoobar \\r\\n\"\n\"6\\r\\nsuffix\\r\\n\"\nIn a request without Transfer-Encoding header and body prefix foobar suffix this is the message body that appeared to be grouped into N bytes groups for some reason (f.ex. these parts been transferred in different TCP packets or upstream netty handlers decided to split the body this way)\n\"prefix \"\n\"foobar \"\n\"suffix\"\nAlthough word chunk may mean exactly N bytes, I personally find it highly overloaded in the context of FixedLengthMessageAggregator. This class deals with requests that have Transfer-Encoding: chunked header, and requests that do not have it (logic is different for these cases).\nSo I tried to make this distinction clear. This wording would have helped me a lot, but maybe I'm overcomplicating this.\nIDK, maybe we may try rewording this using terms chunked and chunked-encoded, where chunked means split into N bytes groups, and chunked-encoded means having Transfer-Encoding: chunked header. So then we'll have chunks of a chunked message and chunks of a chunked-encoded message. Not sure, whether it'll help.... That's an interesting find! I didn't know that. Thanks\nMaybe for someone who's more familiar with netty than me, the meaning of chunk is clear and I'm just trying to workaround my ignorance here :smile: . I may be missing something, but I think, we do not need new parameter.\nIf message is bigger than aggregateIfLessThen, then there's nothing to aggregate. Messages fully bypass this handler.\nYour concern would be valid if we used FinagleHttpObjectAggregator, but this class adds additional checks on top of it.\nTo sum up, this class is only doing something in following cases\n message length is known and it is less than maxContentLength\n message length is unknown, but some heuristics allow us to conclude that message size is 0 (and we aggregate only to have request with isChunked == false, so no allocations on buf are needed).\nThere are already some unit tests for the FixedLengthMessageAggregator that demonstrate how it works if maxContentLength is 0. Also all end2end tests now use FixedLengthMessageAggregator with maxContentLength == 0  (and all pass). I can add more tests for other cases, if you have any in mind.\n. > Maybe it's worth mentioning in the scaladoc for withStreaming method that aggregateIfLessThan could be replaced with maxRequestSize if the later is smaller.\nSorry, I'm not sure I follow.\nTo my understanding, maxRequestSize limits request size and in case if streaming is enabled it is enforced by PayloadSizeHandler, not by FixedMessageLengthAggregator.\nIf maxRequestSize < aggregateIfLessThan, then the message should be rejected even before it reaches FixedMessageLengthAggregator. In any case, the behavior remains consistent, and if message length > maxRequestSize, then 413 must be returned regardles of the aggregateIfLessThan.\n\nAlso, what do you think about omitting the handler all-together if maxContentLength is zero?\n\nWe can't omit the handler completely if maxContentLength == 0 because it handles also 2 cases that are not impacted by maxContentLength:\n responses with specific codes that are guaranteed to have 0 length\n requests without Content-Length and without Transfer-Encoding: chunked\nIf we omit this handler, those 2 cases will end up with chunked Request and Response objects.\nThis is not critical perhaps, but this is a change in behavior.\nAnother option might be to split the handler in two handlers: one to handle messages that have body and the other to handle messages that do not have body. So we could omit the first one if aggregateIfLessThan == 0. But frankly, at this stage, I do not see much benefit in this. Once you start thinking about FixedLengthMessage and how we define it (in scaladoc), this handler makes perfect sense as is (at least to me).. > We can't omit the handler completely if maxContentLength == 0 because it handles also 2 cases that are not impacted by maxContentLength:\nOn the other hand, if developer enables streaming, isChunked == true should be expected. IDK, honestly. This is tough API design decision, and I am not sure I have enough exprience with finagle to be leaning towards any of the options.. Ok, I got it now! Will do the fix a bit later today. Hopefully together with some new e2e tests.. I'll take this opportunity to offer once again different name for the property. I promise it's the last time I'm raising this :)\nwithAggregateIfLessThan\ncon: does not suggest in any way, that it is realted to streaming\ncon: while it is very verbose and explicit, it is almost too explicit, delusionally explicit.\nIt explicitly says, what the framework will do. And even mentions some condition. But not all conditions are mentioned. That's why it is delusional.\nFew alternatives\n withStreamingThreshold(64.kilobytes)\npro: suggests that it is related to streaming\npro: threshold is a very general term, I'd decide to read docs to know how behavior changes once threshold is reached and wouldn't be fooled by an overly explicit name\n withStreamingBuffer(64.kilobytes)\npro: suggests that it is realted to streaming\npro: buffer is a very generic term, so I'd probably decide to read docs and wouldn't be fooled by an overly explicit name\ncon: even more delusional than withAggregateIfLessThan\n withContentLengthStreamedAfter(64.kilobytes)\npro: suggest, that it is realted to streaming (if you typed Str in IDE you'd likely see this among suggestions)\npro: suggests that it may be realted to Content-Length (which is the truth, we only aggregate, if there's content-length header). IMO it is the least delusional name.\ncon: not less verbose, than withAggregateIfLessThan, but, imo, much more readable\n withFixedLengthStreamedAfter(64.kilobytes)\npro: related to streaming\npro: suggests, that it is related to fixed length messages\ncon: develop must know what is a fixed length message\ncon: verbose\n* withStreamingAfter(contentLength: StorageUnit)\npro: related to streaming\npro: related to content length\ncon: contentLength is only present in method definition and only in original sources (won't work on decompiled code)\n. Ugh, I misunderstood about separating a method.\nApparently you suggested an overloaded version of withStreaming.... ",
    "fedj": "In zipkin4net, we ended up doing LocalOperationStart and LocalOperationStop for two reasons:\n- It allows to easily nest one operation into another without having to care about the ids in the client code\n- It follows the RPC span pattern having a start and a stop operation\nThe cons were that it's not following directly serialization annotation pattern. We thought that the serialization can easily change whereas APIs are hard to change.\n. ",
    "LiuVII": "Hey guys! Any update on this?. ",
    "luliu": "Hello, just wondering what the status of this PR is.  Would love to get the PATTERN -> MATCH fix.  Thanks :). @mkhq I'll refrain from butting into your process.  :)  As long as it is still being worked on, I'm happy with a \"it's done when it's done\".. ",
    "reikje": "@mosesn it's an application that listens on a event stream that a remote server provides. on the stream we receive notifications containing host:port of slave machines (nodes being added and removed). Before we start listening we receive all current nodes in one go, around 150-200 items. For each we create a finagle.Http.client using the inet!host:port destination, which will internally bind using the InetResolver.\n@atollena Yes I was also thinking global flag. Rx is doing this for instance, except that they use a system property instead of the flag. Regarding the semaphore, there is also this timer which periodically re-resolves using FuturePool.unbounded and is not guarded by the semaphore. I might be wrong here but I think there are scenarios where you can get to more than 100 threads in that pool. Even though under the hood it uses newCachedThreadPool() which will also shrink in size, it would be great to control the size somehow.\n. @mosesn yes that would totally be possible but then I could just write my own InetResolver and use it with myinet! as scheme. The choice not to use a more advanced service discovery is on purpose, we want one Http client per endpoint.\n@edma2 yes an easy fix would be to open up for extension and change package private scope to protected. I can provide a pull request but maybe there is a reason it shouldn't be extendable?\n. This came up again here. Whats the status of this issue, can I help in any way?. Yes will do @mosesn :). Created a pull request: https://github.com/twitter/finagle/pull/595 and also added some notes.. Changes are made @mosesn . fixed. Yes I have seen it, good idea! However, with the current test setup, advancing time isn't really required as inetResolverWithPool.bind will count down the latch one time immediately. In other words pollInterval isn't really used in the test. \nWhat I tried to do, is to test this section which uses pollInterval. However, I didn't manage to have the timer execute in bindHostPortsToAddr. I am not an expert in Var and Addr but my suspicion is that this test setup bypasses the timer:\nval addr = inetResolverWithPool.bind(\"127.0.0.1:80\")\nval f = addr.changes.filter(_ != Addr.Pending).toFuture\n\nI would be happy if you could suggest a different test setup, so that the timer is executed. In that case we could have a CountDownLatch(2) and put Time.withCurrentTimeFrozen to use and as a bonus bump test coverage :)  . True, so let's skip that test then. Out of curiosity, if I set the latch to 2 (remove the timeout in await) and send in a pollInterval, why does that never poll for updates?. Removed Time.withCurrentTimeFrozen. Thanks for the hint regarding addr.changes.. @bryce-anderson changes are made. yes sounds good. gonna add this tomorrow.. no problem, will fix. will do. This is on purpose. If I use andThen then this is already wrapping NonFatal's. Which means that the test wouldn't trigger the problem we are trying to fix.. yes, will add it. ",
    "edma2": "InetResolver has a resolveHost private constructor argument. Another way is to expose that in the public constructor and provide a default in a subclass with a different scheme identifier (e.g. myinet!blah). The benefit of this approach is you don't require any flags which are dependent on a particular resolveHost implementation (such as the private DnsResolver).\n. Let's pass a max concurrency parameter to InetResolver's factory which defaults to a global flag value.\n. contentType.split(';', 2)to handle more than one \";\" in the string.\n. Can replace \"charset\" with just \"_\".\n. I don't see take, drop, ++, etc being used anywhere for prefixes. Any reason to keep them?\n. Keeping it consistent with Path seems reasonable to me. I don't feel strongly about it.\n. \"grammar\"\n. ffti: \ndef showElem(buf: Buf): String\n. wow :confounded: \n. Using a non-dtab character (like ;) for comments would avoid this ambiguity.\n. ",
    "asheshambasta": "@mosesn \nThat was it.\nIt would be helpful to add that here\n. @mosesn https://github.com/twitter/finagle/pull/547\n. ",
    "jpgneves": "@bryce-anderson thanks for the feedback! I will attempt to rebase this branch on develop and get it all cleaned up for a second go Soon(tm). :)\nEDIT: refer to the correct branch name. :)\n. I saw that 6.40 was released with some big-ish changes and I tweaked my branch to reflect those.\nAnything else I should wait for, or are we good to take another look at this?. Done! :). Hi! Sounds good! Thanks for taking a look at this again! :). ",
    "samstarling": "I'm trying to track down some behaviour that changed between v6.35.0 and v6.38.0, and I think this PR might be related. The following code now throws a com.twitter.finagle.ChannelClosedException, rather than the HTTP response. Is there something I need to change?\n/cc @olix0r @vkostyukov \n``` scala\nimport com.twitter.finagle.builder.ClientBuilder\nimport com.twitter.finagle.http.{Http, Method, Request, Version}\nimport com.twitter.util.Await\nval client = ClientBuilder()\n  .codec(Http())\n  .hosts(\"www.google.com:80\")\n  .hostConnectionLimit(25)\n  .build()\nval request = Request(Version.Http11, Method.Get, \"/\")\nrequest.headerMap.add(\"Connection\", \"close\")\nval response = Await.result(client(request))\nresponse.getContentString()\n```\n. ",
    "doronl": "I see, anyway I solved this by executing: sudo mount -o remount,exec /tmp.\nThanks anyway!\nDoron\n. ",
    "morazow": "Hello @ryanoneill,\nYes, I would love to help! \nCurrently, unfortunately I do not know the answers for your first three questions. I will do my best to get answers for them. \nMeanwhile, I checked the last one with null and it worked without any problems.\n. @ryanoneill great! thank you!\n. ",
    "saint1991": "@bryce-anderson \nThank you for your kind reply!\nI opened this issue because HTTP/1.1 obligates us to set Host header.\n Some middleware, e.g. consul, don't accept the request without Host header and return the 400 BadRequest.\nI hope this issue will be resolved in the future, thanks!\n. ",
    "vigneshwaranr": "Is this not resolved yet? It bit me :(. ",
    "justinpermar": "We can't use Finagle with AWS ALB unless this is fixed. It's a blocker for us. I can probably devote time to fixing this if anyone would be kind enough to point me in the right direction.. @mosesn As noted above, HTTP 1.1 spec requires valid Host header. We're making requests with Finagle to AWS ALB, which rejects the requests with 400: https://docs.aws.amazon.com/elasticloadbalancing/latest/application/load-balancer-troubleshooting.html#http-400-issues.. @mosesn Ah I see what you're asking now. Yes, setting the host header is a workaround for our use case (I'm currently in the process of testing our application with a special-case configuration that does just that). But it's very hacky, since I have to set a host header manually for each request instead of letting Finagle just \"do the right thing\". As an aside, curl and other http tools set the host header, so it seems like a good idea that Finagle follows suit.. ",
    "dreverri": "Is there anything wrong with setting the host header via a filter?\n```\ncase class WithHostHeader(host: String) extends SimpleFilter[Request, Response] {\n  override def apply(request: Request, service: Service[Request, Response]): Future[Response] = {\n    request.host = host\n    service(request)\n  }\n}\nWithHostHeader(\"localhost\").andThen(Http.newService(\"localhost\"))\n```. ",
    "taborda": "Hi\nIt would be nice to have this feature. \n@mosesn are you able to give more detail on this please?\n\ntry making a Stack module beneath the load balancer. The load balancer injects the address of the remote peer into Stack.Params, so you should be able to use that.\n\nI would like to give it a try\nThanks\n. ",
    "pikazlou": "@bryce-anderson could you suggest any workaround to avoid ConnectionManager closing connection? I've tried adding \"Content-length\" header inside filter, but it seems ConnectionManager logic is applied before any filtering. So I'm running out of ideas how to solve the issue without forking/patching finagle for my needs.\n. ",
    "jimschubert": "My company uses 128bit trace ids within our tracing system (based on zipkin). My team's stack is exclusively based on top of Finagle (Finatra, finagle-mysql, finagle-redis) and we regularly have colliding ids because of the reduction to Long within Finagle.\nI'd be interested in evaluating the above suggestion when it's ready.. @mosesn I don't have an lot of free time outside of work right now. I can see about allocating time for this at work, but identifying alternatives is low priority on our backlog at the moment. If I can get get the time, I'd love to take a stab at it. I'll let you know here if I can, and I'll hit you up on gitter if I get stuck.. @adriancole @mosesn I took an initial stab at this. I started down the road of adding support for 128-bit SpanID and ParentID, but I think it's overkill. Could you guys check out the linked PR #651 and give feedback?. @adriancole I updated this PR to include an additional span to account for the high bits, rather than extending SpanId support to 128bits. This is definitely a bit cleaner.\nI had some concerns and TODO items.\n\n\nI overloaded TraceId#apply to reduce impact on existing codebases. However, adding the _traceIdHigh parameter to the case class requires an additional parameter for extractors. I had considered explicitly creating a TraceId#unapply to match the old signature, but I thought this may lead to unwanted results. I tend to have only a single extractor per object, and I didn't see any guidelines or clear examples in the code to suggest otherwise.\n\n\nI wasn't sure how to handle the conditional aspects of the additional 8 bytes in different representations of TraceId. For example, in TraceId#toString I only prepend traceIdHigh if it is non-zero. Yet in TraceId#serialize it will always serialize to a byte array of size 40.\n\n\nI'm not familiar with finagle-mux. I was wondering if someone else would pick up adding support for 128bit TraceID propagation there.\n\n\nThis one isn't really a big deal. finagle-http previously relied on SpanId#fromString to parse the TraceID value from the header. To convert a string representing that 128bit TraceID into the low span and high span, I created TraceId#mk128BitTraceId. I didn't really like the name, or that it's only used by finagle-http and living in finagle-core but it makes more sense to me that it lives on the TraceId object.\n\n\nTODO items:\n\ntracing.thrift doesn't seem to generate compilable code using thrift 0.9 or 0.10 with the commands at at the top of the file. I added RequestHeader#trace_id_high at position 11. Is there a custom build of thrift, or instructions somewhere for generating tracing.thrift with the correct output?\n\nTest/update finagle-thrift after tracing.thrift is regenerated and RichRequestHeader is updated.. I think I hit all the pieces of feedback in this except:\n\n\nAdrian's comment about nextTraceIdHigh: it wasn't clear if this was an ask to add to this PR or an aside for future consideration\n\nBryce's comments related to thrift (regenerating and updating RichRequestHeader.scala): I spent some time working on getting thrift 0.5 compiled locally, but stopped after I felt like I was spinning my wheels resolving old dependency matches.\n\nThe PR is blocked on thrift/mux changes since I can't generate tracing.thrift into valid code. I could modify the generated code by hand, but I'd rather not do that and introduce bugs.. @adriancole I don't see any technical reason to not generate traceIdHigh now, especially since current Finagle truncates to a single long if it encounters a 128bit trace id.\nDo you think this is behavior that should be behind a flag?\nI may not be able to get back to that addition for a week, though. So if you want to assist I'd be fine with that as well :D. I think this PR will be blocked until I can work out generating the tracing.thrift changes so 128bit Trace ID support can also be added to thrift logic.. @adriancole thanks for that patch. I've had a lot less free time lately than I anticipated.\nI finally worked out a docker image for Thrift 0.5 (https://hub.docker.com/r/jimschubert/thrift/), and I was able to regenerate compilable code from tracing.thrift. I've added a test for the thriftmux server + Finagle thrift client to validate 128bit TraceID propagation. Please let me know if I missed anything.\nbtw, sorry for the multiple commits and build failures. When I try to run the entire test suite locally, I run out of heap space so I'm relying on the CI outputs. (\u272a\u3268\u272a) . @adriancole thanks for the clarification. I've made that last change, and I think that addresses all the feedback.. @jcrossley sounds good. I appreciate it!. @jcrossley that's awesome. Thanks!. @adriancole @jcrossley since this has been merged internally already, what would be the process to add this last piece? Should I open another PR, or can this change just be made internally?. Mentioning openzipkin/b3-propagation#6 here so it's connected.. I switched over to my open IntelliJ to start looking at a different area of Finagle, unrelated to this PR, and this file was open.  I remembered that these were previously toLong, and here I have changed them to self. I wasn't even thinking about the change when I did this, I was just directly referencing the property rather than the helper method .  Should I go ahead and change these (in Id.scala, IdTest.scala) back to toLong?. I had thought about doing this as well, but I wasn't sure if which would be the correct approach. I'll make the change.. Yeah man. I had copy/pasted the entirety of SpanId to overwrite a previous commit in which I attempted to extend all spans to 128-bit. My IDE settings auto-formatted to these changes on save, and I didn't catch it.  I also didn't catch the differing indent on new methods like apply below. I'll fix these up.\nDo you all have IDE-specific formatting settings shared for IntelliJ?. Thanks. I meant to mark that as another question (conventions for creating one-off case classes like this) but forgot to mention it in the PR.. The reason I did it this way with the special cased 0L, is that systems requiring 128bit traces may be padded with zeros. On my team at Expedia, we hacked the 64bit trace ids to fit our tracing system by transforming the traces generated by Finagle into a UUID with zeroed most significant bits (example: new java.util.UUID(0,traceId)). If the special case is dropped here and not cleaned up via the traceId method, I assumed that would cause problems with allowing a traceIdHigh equal to 0L.\nI may have misunderstood what @adriancole said with 0L being invalid.  To clarify, my understanding was that both of these are invalid:\n0000 0000 0000 0000 0000 0000 0000 0000\n0000 0000 0000 0000 7fff ffff ffff ffff\nIs the second case a valid 128bit identifier? If it is valid, then I agree we should just take the bits as they come and forward them along.\nIt's a little different from the tracing system I'll be integrating with, in which the identifiers are string representations of UUIDs with no constraint on the high 64bits (see haystack-idl).. Was just getting around to this, and remembered a major part of the question. I wanted to call that case class just \"TraceId\", but this is already taken from the case class encapsulating the traceId, parentId, spanId, etc. In other implementations, I think I've seen the current TraceId named things like TraceContext or SpanContext. I had considered a case class namedFullTraceId, but I was concerned this may cause confusion with the existing TraceId type.\nSince a simple \"TraceId\" is already taken, are there any suggestions for naming here?. @bryce-anderson I commented on this in the discussion part of the PR, but it's probably gotten buried. I tried using thrift 0.9 and 0.10 (both installed via homebrew) to regenerate tracing.thrift using the commands at the top of the file, and these resulted in code that wouldn't compile. There were numerous references to apache libs which weren't resolved.  Do you know if there have been manual modifications to the generated files, or if you all are using a modified version of thrift?. ThreadLocalRandom.current().nextLong(1,Long.MaxValue) could provide non-zero positive values, but as I understood it all longs are valid except 0.. My reply to your referenced comment is kinda hidden now. I think this was the last PR feedback, so I wanted to follow up.\nIf 0L isn't converted to None via the getter in Trace, this will allow propagation of invalid 128 bit TraceIDs (such as a stringified long which is left-padded with 0s). The getter protects against this, with the effect of reducing the span to 64 bit.  Is that not acceptable, or do you think it should propagate ids with invalid high bits?\nI hadn't changed this because the guard on 0L works similarly to the previous implementation which reduce all 128bit TraceIDs to 64bit, and I was waiting for a response to my previous comment before changing.\n/cc @adriancole . Yeah man, this IntelliJ setting (as well as format on save) keeps getting reset when I reopen IntelliJ and the change has snuck past me a few times now.\nI'll edit the whitespace changes in vim. Thanks for pointing it out. Sorry about that.. ",
    "francknouama": "No problem. Thanks @bryce-anderson \n. ",
    "herberteuler": "It is indeed not a bug of Netty, my description was not accurate. Unfortunately, this issue still exists in Oracle's jdk 8u77 (the version we are using).\n. Here is the plan.\nChanges to Request and Response creations\nThis is where all user-visible changes exist. I checked the code and found that there was a similar issue in Response as well, so it might be preferable to change both Request and Response.\nThe common use cases include requests/responses (a) without contents, (b) with a single piece of content, and (c) with a (possibly infinite) sequence of contents (aka streaming).\nCase (a) is not affected by this change.\nFor case (b), add a size parameter because it is the user who knows the actual size of the content, otherwise Finagle has to scan to find out, which is wasteful:\n```scala\n// For Request\ndef apply(version: Version, method: Method, uri: String, reader: Reader, size: Int) = ???\n// For Response\ndef apply(version: Version, status: Status, reader: Reader, size: Int) = ???\n```\nThese methods will not set the result message to chunked, but will instead set a proper Content-Length header.\nThe current methods can be reused for case (c) with their behaviors and thus semantics keeping unchanged.\n```scala\n// For Request\ndef apply(version: Version, method: Method, uri: String, reader: Reader) = ???\n// For Response\ndef apply(version: Version, status: Status, reader: Reader) = ???\n```\nChanges to Message\nNow it should be possible to identify a Message with contents by checking it headers. If it contains a Content-Length header or its Transfer-Encoding header contains chunked, then it has content(s). This is packaged as a new method:\nscala\ndef hasContents: Boolean = ???\nChanges to Bijections\nTransformation to Netty 4 requests can be simplified because the request has been set up properly.\nChanges to transports\nFinally, the write methods in transports need to be changed. Currently they are defined as\nscala\n  def write(msg: In): Future[Unit] =\n    transport.write(from[In, NettyIn](msg)).rescue(wrapWriteException).before {\n      if (msg.isChunked) streamChunks(rawTransport, msg.reader) else Future.Done\n    }\nA simple change to if (msg.hasContents) should suffice.. I tested setting content with content_= and it worked. This is a non-issue and will be closed. Thank you for your time and the clarification.. ",
    "yufangong": "Hi @sohamsankaran , thanks for the report! Now you can close the connection by calling\nclient.asClosable.close(). . thanks @koshelev , this change has been merged in 23d13d66d2414cc936d71ccd03d2e897f247b91f. Thanks @zaneli, your change has been merged here: 8fbabf3761c71e0f055315f6ed4fcbdc67bbff6e. @zaneli thanks for the fix, merged in 18ff67c794373a13a5fb01163e251c163df7259c. Thank you @theel0ja for the fix, merged in 0a75ae7df2c3558410bddc5098400f8661621076. Hey @rpless, thanks for letting us know! merged in dbe0165a0289bc04ec1bce5eaa72600044ac43e8. @matsu-chara Thank you! Merged https://github.com/twitter/finagle/commit/dffc7d3a58b340480ab6dce03023a318c4da5bf9. Thank you for your report @glassorio, this is fixed.. @jluehe thank you for the report! We are working on upgrading our libthrift dependency to 0.10.0 now, however, we need to fully test it before merging. We will let you know when it happens. . @Mandar-Shinde Do you mind also updating two other repos so we could keep these consistent?\nThey are Finatra, and Dodo, thank you.\n. Thanks @spockz , this is merged in https://github.com/twitter/finagle/commit/c863ca0b606455d78350588595b3190165efe26b.. \ud83c\udf89 @ben-ng, do you mind sharing how you use it?. DEADEND. @jlawrienyt  Thanks for the reproduce package, I believe this behavior started from 18.6.0, we will look into this issue.. @jlawrienyt Thanks for the report, this should be fixed in 815c05315ff47db151a6433c32bcf421c7e1e940. I'm closing this issue now but feel free to open one if the issue still remains.. Hi @pra527vin , can you provide more info here about the issues you run into? From the QuickStart, I think you could bind the services to different ports.. Thanks for the fix!. Thanks again, this is merged here https://github.com/twitter/finagle/commit/601151639898e19669d312208bf8823e3c941abe.. Let's keep this Status subtitle.. Please add another new line to be consistent with other subtitles.. ",
    "zarinfam": "I have this problem too.. ",
    "leesf": "Hi @bryce-anderson, thanks for replying. The experiment shows that the Await.result not the root of problem, i use the multiGet to get results in batch manner, and it works well.. ",
    "koshelev": "@ryanoneill any progress on this issue? Let me know if there is something I can help with. @bryce-anderson @kevinoliver Thanks for reviewing!. @vkostyukov I'm afraid the solution with changing val to def will not fix the problem completely. This will still be broken. :(. Seems so. On the bright side delaying will have another nice side effect - service factory will not instantiate the service if handshake fails. Kind of DDoS protection.\n@vkostyukov should adding SslConnectHandler to Netty4ServerSslHandler fix the problem or some more involved solution needed?. I will try it tomorrow (it is already midnight here in Berlin). I will open a PR in case it work. If not - I have some time to spend on it.. @vkostyukov Seems like we need different implementation of SslConnectHandler for server. The problem is ChannelInboundHandler receives no connect promise, so we have nothing to delay. I would suggest to change Netty4Listener to add only raw initializer to a pipeline and move the initialization code starting from here into new class ServerSslConnectHandler. It will add marshalling, framing and bridge if handshake succeeds. What do you think?. @vkostyukov Opened PR. Tried solution you proposed. The problem with it is the way Netty4Listener initialises a pipeline - a channel initializer adds more channel initializers. New initializers will be fired immediately . @mosesn Done. PR updated. @vkostyukov thanks a lot for taking time to review the PR and your feedback! Hope to submit next PR next week (in case you are interested in server side SNI support :) ). @nepthar Thanks for the feedback! Updated PR. @ryanoneill Thanks for your feedback! Updated PR. Hi @ryanoneill. Sure, I see the current code in the PR as just a starting point for a discussion and will be happy to improve it. Looking forward to your suggestions!. Hi @ryanoneill, any idea when you will have a time to review this PR?. @ryanoneill Thanks a lot for your feedback! I'm on vacation now and will be able to work on the PR again next week.. @netphar Unfortunately found no time :(. Will try to find time this or next week.. @ryanoneill I finally found some time to work on this PR again. Could you please have a look and let me know WDYT?. @ryanoneill have you had a chance to check the PR?. Not really, if I understand your question correctly. initChannel will be called if channelRegistered event is triggered or a ChannelInitializer is added to a pipeline of a registered channel.. If I understand netty code correctly, it is not necessary for netty4. SslHandler will shutdown SSLEngine and context (and it will close the underlying channel). Yes, default timeout is 10 seconds.. Ok, I believe now I finally understand what do you mean :). So you are suggesting to implement a server SslConnectHandler and delay channelRegistered in it? It should be possible, but we also will have to change ServerBridge to be a handler.. There is not much we can test in case of failed handshake - netty handles everything in case of failure. . Yes, but channelInit also will be called when we add ServerBridge to the pipeline in our case: https://github.com/netty/netty/blob/4.1/transport/src/main/java/io/netty/channel/ChannelInitializer.java#L99. Yes, making server bridge ChannelInboundHandler and moving code from channelInit to channelRegistered. \nCould you help me understand why if I change ServerBridge like this:\nscala\n  def initChannel(ch: Channel): Unit = {\n    val sslHandler = ch.pipeline().get(classOf[SslHandler])\n    if (sslHandler != null) {\n      sslHandler.handshakeFuture().addListener(new GenericFutureListener[NettyFuture[Channel]] {\n        override def operationComplete(future: NettyFuture[Channel]): Unit = {\n          if (future.isSuccess) {\n            val transport: Transport[In, Out] = transportFac(ch)\n            serveTransport(transport)\n          }\n        }\n      })\n    } else {\n      val transport: Transport[In, Out] = transportFac(ch)\n      serveTransport(transport)\n    }\n  }\nhandshake does not happen?. handshake times out when I'm running the test from this PR.  Just to be explicit - the only change I did is also delaying transportFac(ch).\nYes, client initiates handshake on channelActive. @vkostyukov I think I figured it out - we are using backpressure, so channel's auto read is set to false.  Means transportFac(ch) cannot be delayed. Here is an alternate implementation, with a handler deferring the channelRegistered event. As we still need ChannelTransport, it will be added in handlerAdded. As consequence ServerBridge is not sharable any more. What do you think?. Do you mean SslHandler should issue an initial read?. I'm not so convinced :). Why should it, if we explicitly configured channel do not read any data  unless we explicitly tell it to do so. And SslHandler has no idea, if we want to serve the channel or not.\nBut anyway, the workaround you suggested seems to work: https://github.com/koshelev/finagle/commit/282ca2c5f281fabcdaa22495a07d1cfd850628ad. I believe we can't. channelRegistered signals that channel is registered with an EventLoop, channelActive signals that it is possible send and receive data.. Yes, it is to prevent init to be called.\nI also was considering to rebrand it, but after closer look at the sources of ChannelInitializer it seems like we will have to duplicate a lot of its code. So I decided the overriding handlerAdded is lesser of two evils.. OMG, have no idea how it is landed into PR.\nI think it is a good idea! Updated PR. String => TwitterFuture[Option[SslServerConfiguration]] is more flexible, IMO. Option[Map[String, SslServerConfiguration]] implies the mapping is static and keys and certificates are available locally. For instance, it is not true in our case. We have keys and certificates stored in Vault and new servers can be added at any time. That is why I also added https://github.com/twitter/finagle/pull/607/files/61cd8d956037e0efadcb186e48a54790b2c55802#diff-7be4dc145c09c1df2647a7ee1cc8bccd. @ryanoneill WDYT?. ",
    "chintootech": "I am getting the same warnings using scala 2.12.1 and finagle 6.41.0.. ",
    "b-hoyt": "Primarily thrift servers and clients, http clients, dtabs. Trending towards linkerd + grpc to accommodate our polyglot environment.. Thanks @vkostyukov @mosesn and everyone else who contributes to Finagle! The best practices, patterns, and hard-earned experience encoded here are invaluable to anyone aspiring to operate a services architecture. Very fortunate to benefit from this project and look forward to contributing back.. Fixed. ",
    "cookzhang": "thanks  for your reply\uff0cit\u2018s fixed. ",
    "christhalinger": "First, if you are using -XX:-TieredCompilation you are using C2, not C1.\nThe deoptimizations, as already mentioned above, are completely normal and expected.  The methods in question also seem to be recompiled immediately (after some profiling in the interpreter):\n50226  633             com.twitter.util.Promise::continue (423 bytes)   made not entrant\n  51229  949             com.twitter.util.Promise::continue (423 bytes)\nNothing to be worried about.\nYou should worry if a method is deoptimized and recompiled over and over again.  This will lead to a method not be being compiled at all after some time.\nA quick scan of the log file doesn't show anything alarming.  Again, nothing to be worried about.. Answering anyway\ud83d\ude00\nThe deoptimization/recompilation dance would happen two or three orders of magnitude more.. ",
    "simontoens": "Closing this for now until we have a more concrete plan to fix something here.. ",
    "ernstae": "This issue can creep up when there's an underlying network problem. Is there any interest in rekindling this PR to avoid stale ApacheWatcher objects?. ",
    "tomas-edwardsson": "Not sure if considered dirty but we could go with the following:\nimport scala.util.Try\nval pendingCommands: Int =\n      Try(props(\"pending-commands\").toInt).getOrElse(-1)\n    val linkPendingCommands: Int =\n      Try(props(\"link-pending-commands\").toInt).getOrElse(-1)\nI would prefer changing this to Option[Int] but that would be backwards breaking.\nThis way the types would match but the value would be -1. Thoughts?. Scratch that, much simpler with props.getOrElse(\"pending-commands\", \"-1\").toInt. Updated CHANGES file, not sure where the RB_IDs come from so left them as ??????. I agree renaming to linkPendingCommands to better reflect the actual value returned by redis.. Already noted above in Line 112 to 115 under Breaking Changes. ",
    "rogern": "@mosesn Oh, so I need to depend on util-core 6.41.0 when using finagle 6.42.0! I probably missed that in the doc somewhere =) Maybe not so obvious ;)\nI tried to slim down my project as much as possible but still I had quite a few dependencies on util-core since Future class is part of it.. ",
    "zaneli": "Sure.\nI did it and force push.\nWould this be OK?. Oh, exactly.\nI've tried to fix it, and got compile error.\n[error] /Users/zaneli/ws/finagle/finagle-core/src/main/scala/com/twitter/finagle/Dtab.scala:267: @tailrec annotated method contains no recursive calls\n[error]       def apply(s: String): Label = Label(Buf.Utf8(s))\nThis addition seems to be a my mistake.\nI've reverted it.. ",
    "CLAassistant": " Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.Vladimir Koshelev seems not to be a GitHub user. You need a GitHub account to be able to sign the CLA. If you have already a GitHub account, please add the email address used for this commit to your account.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA.. ",
    "torao": "You are welcome. Thank you for developing this awesome OSS.. ",
    "chrisbenincasa": "@nepthar definitely willing to debug. I was not able to reproduce the NoSuchMethodError (I think that was a bug on my end), but I can reproduce the AbstractMethodError consistently. I setup a quick test in the form I described above. Here are some details:\nThe test:\nscala\nit should \"fail\" in {\n  val underlyingClient = client.redisClient\n  val keyVals = List.fill(10)(Buf.Utf8(randomString) -> Buf.Utf8(randomString))\n  val cmds = Seq(\n    MSet(keyVals.toMap)\n  ) ++ keyVals.map { case (k, _) => PExpire(k, 100)  }\n  underlyingClient.transaction(cmds)\n  val fut = underlyingClient.mGet(keyVals.map { case (k, _) => k  }).map(res => {\n    res.foreach(println)\n  })\n  com.twitter.util.Await.result(fut, com.twitter.util.Duration.Top)\n}\nThe breakpoint on QUEUED getting hit:\n\nThe redis monitor output:\n) redis-cli -p 30144 monitor\nOK\n1493925332.472761 [0 172.17.0.1:41410] \"MULTI\"\n1493925332.495212 [0 172.17.0.1:41410] \"MSET\" \"g8iEo\" \"0qHv1\" \"9WpFi\" \"ybjwz\" \"4ydI3\" \"8uRXO\" \"oO29P\" \"rJWKH\" \"Chget\" \"CzTXa\" \"19J6T\" \"JhJAl\" \"jln65\" \"wW5pg\" \"o3w9L\" \"kumUR\" \"OrOfM\" \"36eE2\" \"PLz74\" \"EyYIj\"\n1493925332.495270 [0 172.17.0.1:41410] \"PEXPIRE\" \"o3w9L\" \"100\"\n1493925332.495296 [0 172.17.0.1:41410] \"PEXPIRE\" \"jln65\" \"100\"\n1493925332.495318 [0 172.17.0.1:41410] \"PEXPIRE\" \"g8iEo\" \"100\"\n1493925332.495340 [0 172.17.0.1:41410] \"PEXPIRE\" \"4ydI3\" \"100\"\n1493925332.495362 [0 172.17.0.1:41410] \"PEXPIRE\" \"Chget\" \"100\"\n1493925332.495384 [0 172.17.0.1:41410] \"PEXPIRE\" \"PLz74\" \"100\"\n1493925332.495405 [0 172.17.0.1:41410] \"PEXPIRE\" \"OrOfM\" \"100\"\n1493925332.495428 [0 172.17.0.1:41410] \"PEXPIRE\" \"oO29P\" \"100\"\n1493925332.495450 [0 172.17.0.1:41410] \"PEXPIRE\" \"19J6T\" \"100\"\n1493925332.495471 [0 172.17.0.1:41410] \"PEXPIRE\" \"9WpFi\" \"100\"\n1493925332.495493 [0 172.17.0.1:41410] \"MGET\" \"o3w9L\" \"jln65\" \"g8iEo\" \"4ydI3\" \"Chget\" \"PLz74\" \"OrOfM\" \"oO29P\" \"19J6T\" \"9WpFi\"\n1493925332.495557 [0 172.17.0.1:41410] \"EXEC\"\nTest output:\n[info] - should fail *** FAILED ***\n[info]   java.lang.ClassCastException: scala.runtime.BoxedUnit cannot be cast to scala.collection.Seq\n[info]   at com.curalate.redis.test.RedisTests$$anonfun$1$$anonfun$17.apply(RedisTests.scala:151)\n[info]   at com.twitter.util.Future$$anonfun$map$1$$anonfun$apply$3.apply(Future.scala:1145)\n[info]   at com.twitter.util.Try$.apply(Try.scala:15)\n[info]   at com.twitter.util.Future$.apply(Future.scala:163)\n[info]   at com.twitter.util.Future$$anonfun$map$1.apply(Future.scala:1145)\n[info]   at com.twitter.util.Future$$anonfun$map$1.apply(Future.scala:1144)\n[info]   at com.twitter.util.Promise$Transformer.liftedTree1$1(Promise.scala:107)\n[info]   at com.twitter.util.Promise$Transformer.k(Promise.scala:107)\n[info]   at com.twitter.util.Promise$Transformer.apply(Promise.scala:117)\n[info]   at com.twitter.util.Promise$Transformer.apply(Promise.scala:98)\nThe Redis monitoring output tells the tale, I think. You can see that the MGET executes within the MULTI block, thus returning the QUEUED response. My callback on the MGET function in the code then interprets that response as successful, but the underlying type is not a Seq. \nLet me know what else I can do to help!. @jcrossley I'm not sure I follow -- the single QUEUED response comes from a single MGET request. It's not that the response are mismatched (unless you mean that the eventual result for an MGET issues during a transaction ends up as a part of the response for an EXEC request), but rather that the single QUEUED response is cast opaquely to Unit. In other words, consumers have no way of knowing if the single response is actually the type they expect, if the \"raw\" response from Redis is a QUEUED type. . As a quick follow-up, I'm certainly interested in taking on the change here. Though, I'm curious as to what your opinions are on the correct solution. To some degree, one could argue this is user error for using Redis transactions in a multi-threaded application environment; so you could consider this a sort of error state (maybe a specialized Exception to let the caller handle the QUEUED case?). On the other hand, the response isn't technically an error, so an exception may not fit the bill. . cc OWNERS:\n@dschobel\n@edede\n@koliver\n@mnakamura\n@mpatidar\n@roanta\n@vkostyukov. Awesome, thanks! . @nepthar thanks for the review! On top of the integration spec I've done a fair bit of ad hoc testing using the REPL. I thought of a few more cases I'd like to run through, so I'm doing those now! . Most definitely! I'll get those added here along with the changes you requested. . @nepthar pushed up changes based on your feedback. I'm working on cleaning up the logs from a long REPL session and I'll post that here once I'm finished with that.. Apologies for the delay here - the holiday threw things off for me. I'll post those logs ASAP. . @nepthar here's a session demonstrating XADD, XREAD, XRANGE, XREVRANGE, XLEN, XDEL, and XTRIM.\nhttps://gist.github.com/chrisbenincasa/c672e7b0b410def35481f1aa0ddd0fe7\nLet me know if you'd like to see any more cases! . \ud83d\udc4d ah yup - got in the pattern match mode when I was using them for partial matches with wildcards. . Added descriptions for all of these \ud83d\udc4d . ",
    "rpless": "Thanks @mosesn. We use finagle-http for some of our servers (by way of Finch) and we make heavy use of the http client as well. We're hoping to start pulling in more of the metrics into our existing infrastructure soon as well as potentially experimenting with the tracing mechanism.. ",
    "DanielCharczynski": "I was trying to find why it works in that way and it looks like connections are closed twice in finagle client when server decided to close persistent connection after configured time 30s/60s etc\nIt only happens in case of HTTPS \nThere are two stack traces that decrements counter according to single connection\n\"finagle/netty3-1@5401\" daemon prio=5 tid=0x17 nid=NA runnable\n  java.lang.Thread.State: RUNNABLE\n      at com.twitter.finagle.netty3.channel.ChannelStatsHandler.channelClosed(ChannelStatsHandler.scala:85)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:106)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.channelClosed(SimpleChannelHandler.java:216)\n      at com.twitter.finagle.netty3.channel.ChannelRequestStatsHandler.channelClosed(ChannelRequestStatsHandler.scala:26)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:106)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.channelClosed(SimpleChannelHandler.java:216)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:106)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.cleanup(FrameDecoder.java:493)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.channelClosed(FrameDecoder.java:371)\n      at org.jboss.netty.handler.ssl.SslHandler.channelClosed(SslHandler.java:1659)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:88)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n      at org.jboss.netty.channel.Channels.fireChannelClosed(Channels.java:468)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.close(AbstractNioWorker.java:375)\n      at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:93)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n      at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n      at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n      at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n      at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n      at java.lang.Thread.run(Thread.java:745)\n\n\"finagle/netty3-2@5407\" daemon prio=5 tid=0x18 nid=NA runnable\n  java.lang.Thread.State: RUNNABLE\n      at com.twitter.finagle.netty3.channel.ChannelStatsHandler.channelClosed(ChannelStatsHandler.scala:93)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:106)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.channelClosed(SimpleChannelHandler.java:216)\n      at com.twitter.finagle.netty3.channel.ChannelRequestStatsHandler.channelClosed(ChannelRequestStatsHandler.scala:26)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:106)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.channelClosed(SimpleChannelHandler.java:216)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:106)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.cleanup(FrameDecoder.java:493)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.channelClosed(FrameDecoder.java:371)\n      at org.jboss.netty.handler.ssl.SslHandler.channelClosed(SslHandler.java:1659)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:88)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n      at org.jboss.netty.channel.Channels.fireChannelClosed(Channels.java:468)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.close(AbstractNioWorker.java:375)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.write0(AbstractNioWorker.java:296)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.writeFromUserCode(AbstractNioWorker.java:146)\n      at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:84)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\n      at org.jboss.netty.channel.Channels.write(Channels.java:725)\n      at org.jboss.netty.channel.Channels.write(Channels.java:686)\n      at org.jboss.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:1111)\n      at org.jboss.netty.handler.ssl.SslHandler.closeOutboundAndChannel(SslHandler.java:1492)\n      at org.jboss.netty.handler.ssl.SslHandler.handleDownstream(SslHandler.java:515)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n      at org.jboss.netty.channel.SimpleChannelHandler.closeRequested(SimpleChannelHandler.java:334)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:260)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n      at org.jboss.netty.channel.SimpleChannelHandler.closeRequested(SimpleChannelHandler.java:334)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:260)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n      at org.jboss.netty.channel.SimpleChannelHandler.closeRequested(SimpleChannelHandler.java:334)\n      at com.twitter.finagle.netty3.channel.ChannelStatsHandler.closeRequested(ChannelStatsHandler.scala:77)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleDownstream(SimpleChannelHandler.java:260)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:784)\n      at org.jboss.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54)\n      at org.jboss.netty.handler.codec.http.HttpClientCodec.handleDownstream(HttpClientCodec.java:97)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\n      at org.jboss.netty.channel.Channels.close(Channels.java:812)\n      at com.twitter.finagle.netty3.transport.ChannelTransport.close(ChannelTransport.scala:150)\n      at com.twitter.util.Closable$class.close(Closable.scala:19)\n      at com.twitter.finagle.netty3.transport.ChannelTransport.close(ChannelTransport.scala:13)\n      at com.twitter.finagle.netty3.transport.ChannelTransport.com$twitter$finagle$netty3$transport$ChannelTransport$$fail(ChannelTransport.scala:48)\n      at com.twitter.finagle.netty3.transport.ChannelTransport.handleUpstream(ChannelTransport.scala:84)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.exceptionCaught(SimpleChannelUpstreamHandler.java:153)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.exceptionCaught(SimpleChannelUpstreamHandler.java:153)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.handler.codec.frame.FrameDecoder.exceptionCaught(FrameDecoder.java:377)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n      at org.jboss.netty.handler.codec.http.HttpClientCodec.handleUpstream(HttpClientCodec.java:92)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.exceptionCaught(SimpleChannelHandler.java:156)\n      at com.twitter.finagle.netty3.channel.ChannelStatsHandler.exceptionCaught(ChannelStatsHandler.scala:110)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:130)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.exceptionCaught(SimpleChannelHandler.java:156)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:130)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.channel.SimpleChannelHandler.exceptionCaught(SimpleChannelHandler.java:156)\n      at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:130)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n      at org.jboss.netty.handler.ssl.SslHandler.exceptionCaught(SslHandler.java:627)\n      at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n      at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n      at org.jboss.netty.channel.Channels.fireExceptionCaught(Channels.java:525)\n      at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:74)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n      at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n      at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n      at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n      at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n      at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n      at java.lang.Thread.run(Thread.java:745)\nConnection count =-1\n\n. Strange logic in NioWorker\n```\n      at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:74)\n  at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:93)\n\n```\nboth lines closes the same connection\nand quite interesting behaviour in \nNetty3Transporter\nsslHandler.getSSLEngineInboundCloseFuture.addListener(FireChannelClosedLater). Yes it does. Thanks for quick response\nunfortunately I have to use JVM 7 compatible one - > 6.35.0\nWhich version solve this problem?. Thanks for quick reply Kevin.\nI was able to close many other threads because API allows me to use my own Timers/Executors/etc\nI have problem with last three threads.\nIn this case HighResTimer param is injected implicitly when client is instantiated.\nIt is definitely to early.\nIn such implementation  StackParam[HighResTimer] makes no sense . Thanks for quick reply Kevin.\nI was able to close many other threads because API allows me to use my own Timers/Executors/etc\nI have problem with last three threads.\nIn this case private object is used and I have no access to it.\n. Thanks for quick reply Kevin.\nI was able to close many other threads because API allows me to use my own Timers/Executors/etc\nI have problem with last three threads.\nIn this case Finagle uses Closable.nop but this fires CollectClosables.collectorThread field initialization that starts Timer.\nUnfortunately this field is private and Thread uninterruptible.\nYes API is good. I'm not sure if is is good idea to use while (true)  and catch inside InterruptedException. I suggest to use  while(flag)\n. ",
    "ghershfield": "@mosesn Sorry, I have been chasing other things. I have not had gotten to the possible work around yet. I have attached the log file. \nwrapper-debug.zip\nI did update to the latest Twitter libs ... 7.1.0 etc and still same issue ( which I figured ). . @mosesn I obviously am doing something incorrect. I now have pem files for certs instead of jks. I have tried this:\n```\n  override def configureHttpsServer(server: Http.Server): Http.Server = {\nprintln(\"WOMBAT-HTTPS .... 1\")\nval certFile = new File(\"/tmp/server.localdomain.crt\")\nprintln(\"WOMBAT-HTTPS .... 2\")\nval keyFile = new File(\"/tmp/server.localdomain.key\")\nprintln(\"WOMBAT-HTTPS .... 3\")\n\nval trustedFile = new File(\"/tmp/intermediate.crt\");\nprintln(\"WOMBAT-HTTPS .... 4\")\nval keyCredentials = KeyCredentials.CertKeyAndChain(certFile,keyFile,trustedFile)\nprintln(\"WOMBAT-HTTPS .... 5\")\nval sslConfig = SslServerConfiguration(keyCredentials = keyCredentials)\nprintln(\"WOMBAT-HTTPS .... 6\")\nval sslContext = SSLContext.getInstance(\"TLSv1.2\")\nprintln(\"WOMBAT-HTTPS .... 7\")\nsslContext.init(null,null,null)\nprintln(\"WOMBAT-HTTPS .... 8\")\nval sslEngine = new com.twitter.finagle.ssl.server.SslContextServerEngineFactory(sslContext)\nprintln(\"WOMBAT-HTTPS .... 9\")\nval sslVerifier = com.twitter.finagle.ssl.server.SslServerSessionVerifier.AlwaysValid\nprintln(\"WOMBAT-HTTPS .... 10\")\nserver.withTransport.tls(sslConfig,sslEngine,sslVerifier)\n\n}\n```\nAnd everything starts up fine, but when I attempt to connect I get the following exception: \nINFO   | jvm 1    | 2017/09/18 07:45:49 | com.twitter.finagle.ssl.SslConfigurationException: KeyCredentials.CertKeyAndChain is not supported at this time for SslContextServerEngineFactory\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.ssl.SslConfigurationException$.notSupported(SslConfigurationException.scala:16) ~[finagle-core_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.ssl.SslConfigurations$.checkKeyCredentialsNotSupported(SslConfigurations.scala:133) ~[finagle-core_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.ssl.server.SslContextServerEngineFactory.apply(SslContextServerEngineFactory.scala:26) ~[finagle-core_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.netty4.ssl.server.Netty4ServerSslHandler.$anonfun$initChannel$1(Netty4ServerSslHandler.scala:88) ~[finagle-netty4_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.netty4.ssl.server.Netty4ServerSslHandler.$anonfun$initChannel$1$adapted(Netty4ServerSslHandler.scala:85) ~[finagle-netty4_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at scala.Option.foreach(Option.scala:257) ~[scala-library-2.12.1.jar:na]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.netty4.ssl.server.Netty4ServerSslHandler.initChannel(Netty4ServerSslHandler.scala:85) ~[finagle-netty4_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.ChannelInitializer.initChannel(ChannelInitializer.java:113) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.ChannelInitializer.handlerAdded(ChannelInitializer.java:105) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:605) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.addFirst(DefaultChannelPipeline.java:186) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.addFirst(DefaultChannelPipeline.java:151) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.netty4.channel.Netty4RawServerChannelInitializer.initChannel(Netty4RawServerChannelInitializer.scala:53) [finagle-netty4_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.ChannelInitializer.initChannel(ChannelInitializer.java:113) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.ChannelInitializer.handlerAdded(ChannelInitializer.java:105) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:605) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.addLast(DefaultChannelPipeline.java:234) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.addLast(DefaultChannelPipeline.java:400) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.addLast(DefaultChannelPipeline.java:387) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.netty4.ListeningServerBuilder$$anon$1$$anon$2.initChannel(ListeningServerBuilder.scala:129) [finagle-netty4_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.ChannelInitializer.initChannel(ChannelInitializer.java:113) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.ChannelInitializer.handlerAdded(ChannelInitializer.java:105) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.callHandlerAdded0(DefaultChannelPipeline.java:605) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.access$000(DefaultChannelPipeline.java:45) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline$PendingHandlerAddedTask.execute(DefaultChannelPipeline.java:1395) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.callHandlerAddedForAllHandlers(DefaultChannelPipeline.java:1130) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.DefaultChannelPipeline.invokeHandlerAddedIfNeeded(DefaultChannelPipeline.java:655) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.AbstractChannel$AbstractUnsafe.register0(AbstractChannel.java:506) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.AbstractChannel$AbstractUnsafe.access$200(AbstractChannel.java:419) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.AbstractChannel$AbstractUnsafe$1.run(AbstractChannel.java:478) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163) [netty-common-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:403) [netty-common-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:463) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.14.Final.jar:4.1.14.Final]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_144]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_144]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23) [finagle-core_2.12-7.1.0.jar:7.1.0]\nINFO   | jvm 1    | 2017/09/18 07:45:49 |   at java.lang.Thread.run(Thread.java:748) [na:1.8.0_144]\n. @mosesn \nNew exception. I tried it with and without cipherSuites\n```\n  override def configureHttpsServer(server: Http.Server): Http.Server = {\nprintln(\"WOMBAT-HTTPS .... 1\")\nval certFile = new File(\"/tmp/server.localdomain.crt\")\nprintln(\"WOMBAT-HTTPS .... 2\")\nval keyFile = new File(\"/tmp/server.localdomain.key\")\nprintln(\"WOMBAT-HTTPS .... 3\")\n\nval trustedFile = new File(\"/tmp/intermediate.crt\");\nprintln(\"WOMBAT-HTTPS .... 4\")\nval keyCredentials = KeyCredentials.CertKeyAndChain(certFile,keyFile,trustedFile)\nprintln(\"WOMBAT-HTTPS .... 5\")\nval cipherSuites = CipherSuites.Enabled(Seq(\"TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384\"))\nprintln(\"WOMBAT-HTTPS .... 6\")\nval sslConfig = SslServerConfiguration(\n  keyCredentials = keyCredentials,\n  cipherSuites = cipherSuites)\nprintln(\"WOMBAT-HTTPS .... 8\")\nval sslVerifier = com.twitter.finagle.ssl.server.SslServerSessionVerifier.AlwaysValid\nprintln(\"WOMBAT-HTTPS .... 9\")\nserver.withTransport.tls(sslConfig,\n                         sslVerifier)\n\n}\n```\njvm 1    | io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: no cipher suites in common\njvm 1    |  at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:459) ~[netty-codec-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:265) ~[netty-codec-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1342) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:934) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:134) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459) [netty-transport-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_144]\njvm 1    |  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_144]\njvm 1    |  at com.twitter.finagle.util.BlockingTimeTrackingThreadFactory$$anon$1.run(BlockingTimeTrackingThreadFactory.scala:23) [finagle-core_2.12-7.1.0.jar:7.1.0]\njvm 1    |  at java.lang.Thread.run(Thread.java:748) [na:1.8.0_144]\njvm 1    | Caused by: javax.net.ssl.SSLHandshakeException: no cipher suites in common\njvm 1    |  at sun.security.ssl.Handshaker.checkThrown(Handshaker.java:1478) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.SSLEngineImpl.checkTaskThrown(SSLEngineImpl.java:535) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.SSLEngineImpl.readNetRecord(SSLEngineImpl.java:813) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:781) ~[na:1.8.0_144]\njvm 1    |  at javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:624) ~[na:1.8.0_144]\njvm 1    |  at io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:281) ~[netty-handler-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1215) ~[netty-handler-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1127) ~[netty-handler-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1162) ~[netty-handler-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:489) ~[netty-codec-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:428) ~[netty-codec-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  ... 18 common frames omitted\njvm 1    | Caused by: javax.net.ssl.SSLHandshakeException: no cipher suites in common\njvm 1    |  at sun.security.ssl.Alerts.getSSLException(Alerts.java:192) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.SSLEngineImpl.fatal(SSLEngineImpl.java:1666) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:304) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.Handshaker.fatalSE(Handshaker.java:292) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.ServerHandshaker.chooseCipherSuite(ServerHandshaker.java:1045) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.ServerHandshaker.clientHello(ServerHandshaker.java:741) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.ServerHandshaker.processMessage(ServerHandshaker.java:224) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.Handshaker.processLoop(Handshaker.java:1026) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.Handshaker$1.run(Handshaker.java:966) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.Handshaker$1.run(Handshaker.java:963) ~[na:1.8.0_144]\njvm 1    |  at java.security.AccessController.doPrivileged(Native Method) ~[na:1.8.0_144]\njvm 1    |  at sun.security.ssl.Handshaker$DelegatedTask.run(Handshaker.java:1416) ~[na:1.8.0_144]\njvm 1    |  at io.netty.handler.ssl.SslHandler.runDelegatedTasks(SslHandler.java:1364) ~[netty-handler-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1272) ~[netty-handler-4.1.14.Final.jar:4.1.14.Final]\njvm 1    |  ... 22 common frames omitted. @mosesn I had expected the engine to automatically decide which cipher when not defined. When that failed, I tried what you guys had in your UT. Alas, I was not thinking that I might have provided incorrect information since there are many ciphers. I changed it out to val cipherSuites = CipherSuites.Unspecified and I got the exact same behavior that I was getting with the JKS. IMO it's broken all the way through with respect to 2-way SSL.. @mosesn We were retrieving the Certificate and then the user's DN from com.twitter.finagle.transport.Transport.peerCertificate. This is coming back as None for both jks & pem configurations.\nThe code looks like this:\ncom.twitter.finagle.transport.Transport.peerCertificate.fold(UserAuthentication.set(None)){cert =>\n      val subjectDN = X509CertificateTransformer.translate(cert.getEncoded).getSubjectDN\n      UserAuthentication.set(Some(new UserAuthentication(subjectDN.getName)))\n    }\nLooks to me right now we are getting 2-way connectivity but again this com.twitter.finagle.transport.Transport.peerCertificate no longer returns the cert. \nWhat should I be doing if this is not the correct way to retrieve the certificate now?\n. ",
    "plaflamme": "The use case is a finagle-kafka client which we may be able to contribute at some point. The reason why it needs these changes is mostly because Kafka has a correlation id associated with each request (basically a unique id) which is sent back to clients in the response. This is a dispatching concern, so I wanted to encapsulate that in there.\nThe correlation id is put into the queue along with the promise and is checked when the response comes from the server. It is required to match head of the queue and then simply thrown away.\nIn its current state, it also uses different types between the dispatcher and the transport, but that's probably not strictly necessary, just a nice to have.\nThe configuration of the stall timeout is strictly hygiene (I figured it would be better if it were configurable). So we can drop that commit if it's preferable to minimize the change.. @dschobel Sorry, I had to rebase the original PR because it wasn't off develop.\nI added an additional commit which I hope addresses your concerns.\nIt also enforces correctness of handling the Promise[Rep] which was originally left to extending classes. I think this is an improvement, but it came at the cost of instantiating an extra type in the simple case.\nAlso, an argument to leave dispatch non-final is that Kafka actually has an edge case where one particular request does not get a server response. So it would actually need to override dispatch to avoid enqueuing an item in the queue for those requests.\nAn alternative is to return an Option[T] from pipeline (or some other union type) that dispatch would know not to enqueue (say when it's None), but it seemed like too much of an edge case to add formal support for. Leaving dispatch non-final seemed simpler.. @dschobel I've added a commit with the requested changes. I'll sign the CLA ASAP.. @dschobel @kevinoliver any guidance on how to solve the test failure? Is it a flake?. I hesitated to do that and didn't similar to how apply is not final in GenSerialClientDispatcher. I figured that most use-cases would only need to override pipeline, but potentially more complex ones would need to override dispatch as well. I don't have a strong opinion, either way is fine by me.. ",
    "omerzach": "Our whole API server is built on Finagle through Finch and we use Finagle clients to call out to our own Node microservices via HTTP/REST and to third-party REST APIs. We're also switching some of those microservices to gRPC, so will be getting that set up pretty soon.. ",
    "Mura-Mi": "Thank you for reviewing my pull request. I'm removing the usage of Java primitive numbers and BufToString converter.\nIn TravisCI, latest redis-server is not available so the Geo API Redis integration test fails. I'm trying to install redis-server via apt-package. Is this acceptable?. It's good. I've named like these as described in Redis document, but I'll modify.. ",
    "yannick-polius": "@mkhq @Mura-Mi I had an internal reason to implement a similar PR. My version took a bit from this PR and is on the internal code review. I moved the integration test into finagle-redis/src/it.\nDo we want to decide if we want to use this one or the other code review?. @mkhq yeah we were able to land it with that change.. @mkhq  please see 269e181 for attribution . ",
    "gpevnev": "~Hi, why wouldn't you finally merge it into open-source version? As I am guessing from labels this is already merged internally more than year ago, why would't you do it on github too?~\nStill catching similar problem on finagle-http-18.8.0\ndispatcher.serial.queue_size is already used for a different type of metric\n    at com.codahale.metrics.MetricRegistry.getOrAdd(MetricRegistry.java:431)\n    at com.codahale.metrics.MetricRegistry.gauge(MetricRegistry.java:244). Yes, seems it is just strange concurrency bug, and dispatcher metric is just occasional victim. But it was very strange that it was affecting just this metric.. https://mvnrepository.com/artifact/io.netty/netty/3.10.6.Final. Thanks a lot for answer, will take into account! I think this can be closed for now.. ",
    "yzb808": "thank you very much. ",
    "iyogi": "No. I added this issue based on what we observed in the tomcat log. \n\nSee https://wiki.apache.org/tomcat/MemoryLeakProtection#cclThreadSpawnedByWebApp \nHanging ThreadLocal variables may be a code smell?\n. \n",
    "chenhj": "Thank @vkostyukov  reply, I tried, and the same problem\nThe details of the jar package are as follows\n```\n\ndependencyList\n[info] aopalliance:aopalliance:1.0\n[info] ch.qos.logback:logback-classic:1.1.6\n[info] ch.qos.logback:logback-core:1.1.6\n[info] com.fasterxml.jackson.core:jackson-annotations:2.8.4\n[info] com.fasterxml.jackson.core:jackson-core:2.8.4\n[info] com.fasterxml.jackson.core:jackson-databind:2.8.4\n[info] com.fasterxml.jackson.datatype:jackson-datatype-joda:2.4.4\n[info] com.fasterxml.jackson.module:jackson-module-paranamer:2.8.4\n[info] com.fasterxml.jackson.module:jackson-module-scala_2.11:2.8.4\n[info] com.github.ben-manes.caffeine:caffeine:2.3.4\n[info] com.github.nscala-time:nscala-time_2.11:1.6.0\n[info] com.github.spullara.mustache.java:compiler:0.8.18\n[info] com.google.code.findbugs:jsr305:2.0.1\n[info] com.google.guava:guava:19.0\n[info] com.google.inject:guice:4.1.0\n[info] com.google.inject.extensions:guice-assistedinject:4.0\n[info] com.google.inject.extensions:guice-multibindings:4.0\n[info] com.iheart:ficus_2.11:1.2.3\n[info] com.thoughtworks.paranamer:paranamer:2.8\n[info] com.twitter:finagle-base-http_2.11:6.45.0\n[info] com.twitter:finagle-core_2.11:6.45.0\n[info] com.twitter:finagle-http2_2.11:6.45.0\n[info] com.twitter:finagle-http_2.11:6.45.0\n[info] com.twitter:finagle-mysql_2.11:6.45.0\n[info] com.twitter:finagle-netty4-http_2.11:6.45.0\n[info] com.twitter:finagle-netty4_2.11:6.45.0\n[info] com.twitter:finagle-stats_2.11:6.45.0\n[info] com.twitter:finagle-thrift_2.11:6.45.0\n[info] com.twitter:finagle-toggle_2.11:6.45.0\n[info] com.twitter:finagle-tunable_2.11:6.45.0\n[info] com.twitter:finagle-zipkin-core_2.11:6.45.0\n[info] com.twitter:finagle-zipkin_2.11:6.45.0\n[info] com.twitter:jsr166e:1.1.0\n[info] com.twitter:libthrift:0.5.0-7\n[info] com.twitter:scrooge-core_2.11:4.18.0\n[info] com.twitter:twitter-server_2.11:1.30.0\n[info] com.twitter:util-app_2.11:6.45.0\n[info] com.twitter:util-cache_2.11:6.45.0\n[info] com.twitter:util-codec_2.11:6.45.0\n[info] com.twitter:util-collection_2.11:6.45.0\n[info] com.twitter:util-core_2.11:6.45.0\n[info] com.twitter:util-events_2.11:6.45.0\n[info] com.twitter:util-function_2.11:6.45.0\n[info] com.twitter:util-hashing_2.11:6.45.0\n[info] com.twitter:util-jvm_2.11:6.45.0\n[info] com.twitter:util-lint_2.11:6.45.0\n[info] com.twitter:util-logging_2.11:6.45.0\n[info] com.twitter:util-registry_2.11:6.45.0\n[info] com.twitter:util-security_2.11:6.45.0\n[info] com.twitter:util-stats_2.11:6.45.0\n[info] com.twitter:util-tunable_2.11:6.45.0\n[info] com.twitter.common:base:0.0.116\n[info] com.twitter.common:collections:0.0.111\n[info] com.twitter.common:metrics:0.0.39\n[info] com.twitter.common:quantity:0.0.100\n[info] com.twitter.common:stats-util:0.0.60\n[info] com.twitter.common:util-executor-service-shutdown:0.0.68\n[info] com.twitter.common:util-system-mocks:0.0.105\n[info] com.twitter.finatra:finatra-http_2.11:2.1.6\n[info] com.twitter.finatra:finatra-jackson_2.11:2.1.6\n[info] com.twitter.finatra:finatra-scalap-compiler-deps_2.11:2.0.0\n[info] com.twitter.finatra:finatra-slf4j_2.11:2.1.6\n[info] com.twitter.finatra:finatra-utils_2.11:2.1.6\n[info] com.twitter.inject:inject-app_2.11:2.1.6\n[info] com.twitter.inject:inject-core_2.11:2.1.6\n[info] com.twitter.inject:inject-modules_2.11:2.1.6\n[info] com.twitter.inject:inject-request-scope_2.11:2.1.6\n[info] com.twitter.inject:inject-server_2.11:2.1.6\n[info] com.twitter.inject:inject-utils_2.11:2.1.6\n[info] com.typesafe:config:1.3.1\n[info] com.typesafe.scala-logging:scala-logging_2.11:3.5.0\n[info] commons-codec:commons-codec:1.3\n[info] commons-fileupload:commons-fileupload:1.3.1\n[info] commons-io:commons-io:2.4\n[info] commons-lang:commons-lang:2.6\n[info] commons-logging:commons-logging:1.1.1\n[info] default:finatra-demo_2.11:1.0\n[info] io.getquill:quill-core_2.11:1.3.0\n[info] io.getquill:quill-finagle-mysql_2.11:1.3.0\n[info] io.getquill:quill-sql_2.11:1.3.0\n[info] io.netty:netty:3.10.1.Final\n[info] io.netty:netty-buffer:4.1.10.Final\n[info] io.netty:netty-codec:4.1.10.Final\n[info] io.netty:netty-codec-http:4.1.10.Final\n[info] io.netty:netty-codec-http2:4.1.10.Final\n[info] io.netty:netty-codec-socks:4.1.10.Final\n[info] io.netty:netty-common:4.1.10.Final\n[info] io.netty:netty-handler:4.1.10.Final\n[info] io.netty:netty-handler-proxy:4.1.10.Final\n[info] io.netty:netty-resolver:4.1.10.Final\n[info] io.netty:netty-transport:4.1.10.Final\n[info] io.netty:netty-transport-native-epoll:4.1.10.Final\n[info] javax.inject:javax.inject:1\n[info] javax.servlet:servlet-api:2.5\n[info] joda-time:joda-time:2.9.3\n[info] junit:junit:4.4\n[info] log4j:log4j:1.2.17\n[info] net.codingwell:scala-guice_2.11:4.0.0\n[info] org.apache.httpcomponents:httpclient:4.0.1\n[info] org.apache.httpcomponents:httpcore:4.0.1\n[info] org.apache.thrift:libthrift:0.6.1\n[info] org.clapper:grizzled-slf4j_2.11:1.0.2\n[info] org.joda:joda-convert:1.8\n[info] org.scala-lang:scala-reflect:2.11.11\n[info] org.scala-lang:scalap:2.11.11\n[info] org.scala-lang.modules:scala-async_2.11:0.9.5\n[info] org.scala-lang.modules:scala-parser-combinators_2.11:1.0.4\n[info] org.scalamacros:resetallattrs_2.11:1.0.0\n[info] org.slf4j:jcl-over-slf4j:1.7.7\n[info] org.slf4j:jul-to-slf4j:1.7.7\n[info] org.slf4j:slf4j-api:1.7.21\n[info] org.slf4j:slf4j-log4j12:1.7.16\n```\n\nreStart fail\n```\nfinatra-demo[ERROR] I 0726 02:10:59.201 THREAD1: Finagle version 6.45.0 (rev=fadc80cdd804f2885ebc213964542d5568a4f485) built at 20170609-103047\nfinatra-demo[ERROR] com.google.inject.ProvisionException: Unable to provision, see the following errors:\nfinatra-demo[ERROR] \nfinatra-demo[ERROR] 1) Error injecting constructor, java.lang.NoClassDefFoundError: com/twitter/finagle/http/Method$Get$\nfinatra-demo[ERROR]   at com.twiiter.demo.controller.ExampleController.(ExampleController.scala:12)\nfinatra-demo[ERROR]   at com.twiiter.demo.controller.ExampleController.class(ExampleController.scala:12)\nfinatra-demo[ERROR]   while locating com.twiiter.demo.controller.ExampleController\nfinatra-demo[ERROR] \nfinatra-demo[ERROR] 1 error\nfinatra-demo[ERROR]     at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1028)\nfinatra-demo[ERROR]     at com.google.inject.internal.InjectorImpl.getInstance(InjectorImpl.java:1050)\nfinatra-demo[ERROR]     at com.twitter.inject.Injector.instance(Injector.scala:12)\nfinatra-demo[ERROR]     at com.twitter.finatra.http.routing.HttpRouter.add(HttpRouter.scala:121)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer$.configureHttp(ExampleController.scala:22)\nfinatra-demo[ERROR]     at com.twitter.finatra.http.HttpServer$class.postStartup(HttpServer.scala:34)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer$.postStartup(ExampleController.scala:18)\nfinatra-demo[ERROR]     at com.twitter.inject.app.App$class.main(App.scala:44)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer$.com$twitter$inject$server$TwitterServer$$super$main(ExampleController.scala:18)\nfinatra-demo[ERROR]     at com.twitter.inject.server.TwitterServer$class.main(TwitterServer.scala:72)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer$.main(ExampleController.scala:18)\nfinatra-demo[ERROR]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nfinatra-demo[ERROR]     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nfinatra-demo[ERROR]     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nfinatra-demo[ERROR]     at java.lang.reflect.Method.invoke(Method.java:498)\nfinatra-demo[ERROR]     at com.twitter.app.App$$anonfun$nonExitingMain$3.apply(App.scala:225)\nfinatra-demo[ERROR]     at com.twitter.app.App$$anonfun$nonExitingMain$3.apply(App.scala:224)\nfinatra-demo[ERROR]     at scala.Option.foreach(Option.scala:257)\nfinatra-demo[ERROR]     at com.twitter.app.App$class.nonExitingMain(App.scala:224)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer$.nonExitingMain(ExampleController.scala:18)\nfinatra-demo[ERROR]     at com.twitter.app.App$class.main(App.scala:190)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer$.main(ExampleController.scala:18)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleServer.main(ExampleController.scala)\nfinatra-demo[ERROR]     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nfinatra-demo[ERROR]     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nfinatra-demo[ERROR]     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nfinatra-demo[ERROR]     at java.lang.reflect.Method.invoke(Method.java:498)\nfinatra-demo[ERROR]     at scala.reflect.internal.util.ScalaClassLoader$$anonfun$run$1.apply(ScalaClassLoader.scala:70)\nfinatra-demo[ERROR]     at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)\nfinatra-demo[ERROR]     at scala.reflect.internal.util.ScalaClassLoader$URLClassLoader.asContext(ScalaClassLoader.scala:101)\nfinatra-demo[ERROR]     at scala.reflect.internal.util.ScalaClassLoader$class.run(ScalaClassLoader.scala:70)\nfinatra-demo[ERROR]     at scala.reflect.internal.util.ScalaClassLoader$URLClassLoader.run(ScalaClassLoader.scala:101)\nfinatra-demo[ERROR]     at scala.tools.nsc.CommonRunner$class.run(ObjectRunner.scala:22)\nfinatra-demo[ERROR]     at scala.tools.nsc.ObjectRunner$.run(ObjectRunner.scala:39)\nfinatra-demo[ERROR]     at scala.tools.nsc.CommonRunner$class.runAndCatch(ObjectRunner.scala:29)\nfinatra-demo[ERROR]     at scala.tools.nsc.ObjectRunner$.runAndCatch(ObjectRunner.scala:39)\nfinatra-demo[ERROR]     at scala.tools.nsc.MainGenericRunner.runTarget$1(MainGenericRunner.scala:65)\nfinatra-demo[ERROR]     at scala.tools.nsc.MainGenericRunner.run$1(MainGenericRunner.scala:87)\nfinatra-demo[ERROR]     at scala.tools.nsc.MainGenericRunner.process(MainGenericRunner.scala:98)\nfinatra-demo[ERROR]     at scala.tools.nsc.MainGenericRunner$.main(MainGenericRunner.scala:103)\nfinatra-demo[ERROR]     at scala.tools.nsc.MainGenericRunner.main(MainGenericRunner.scala)\nfinatra-demo[ERROR] Caused by: java.lang.NoClassDefFoundError: com/twitter/finagle/http/Method$Get$\nfinatra-demo[ERROR]     at com.twitter.finatra.http.Controller.(Controller.scala:7)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleController.(ExampleController.scala:12)\nfinatra-demo[ERROR]     at com.twiiter.demo.controller.ExampleController$$FastClassByGuice$$f5bbf722.newInstance()\nfinatra-demo[ERROR]     at com.google.inject.internal.DefaultConstructionProxyFactory$FastClassProxy.newInstance(DefaultConstructionProxyFactory.java:89)\nfinatra-demo[ERROR]     at com.google.inject.internal.ConstructorInjector.provision(ConstructorInjector.java:111)\nfinatra-demo[ERROR]     at com.google.inject.internal.ConstructorInjector.construct(ConstructorInjector.java:90)\nfinatra-demo[ERROR]     at com.google.inject.internal.ConstructorBindingImpl$Factory.get(ConstructorBindingImpl.java:268)\nfinatra-demo[ERROR]     at com.google.inject.internal.ProviderToInternalFactoryAdapter$1.call(ProviderToInternalFactoryAdapter.java:46)\nfinatra-demo[ERROR]     at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1092)\nfinatra-demo[ERROR]     at com.google.inject.internal.ProviderToInternalFactoryAdapter.get(ProviderToInternalFactoryAdapter.java:40)\nfinatra-demo[ERROR]     at com.google.inject.internal.SingletonScope$1.get(SingletonScope.java:194)\nfinatra-demo[ERROR]     at com.google.inject.internal.InternalFactoryToProviderAdapter.get(InternalFactoryToProviderAdapter.java:41)\nfinatra-demo[ERROR]     at com.google.inject.internal.InjectorImpl$2$1.call(InjectorImpl.java:1019)\nfinatra-demo[ERROR]     at com.google.inject.internal.InjectorImpl.callInContext(InjectorImpl.java:1085)\nfinatra-demo[ERROR]     at com.google.inject.internal.InjectorImpl$2.get(InjectorImpl.java:1015)\nfinatra-demo[ERROR]     ... 40 more\nfinatra-demo[ERROR] Caused by: java.lang.ClassNotFoundException: com.twitter.finagle.http.Method$Get$\nfinatra-demo[ERROR]     at java.net.URLClassLoader.findClass(URLClassLoader.java:381)\nfinatra-demo[ERROR]     at java.lang.ClassLoader.loadClass(ClassLoader.java:424)\nfinatra-demo[ERROR]     at java.lang.ClassLoader.loadClass(ClassLoader.java:357)\nfinatra-demo[ERROR]     ... 55 more\nfinatra-demo[ERROR] Exception thrown in main on startup\nfinatra-demo ... finished with exit code 1\n\n```\n. @jcrossley Thank you for your reply. I am missing a comma on the information above. But this is not the real cause of the problem.\nMy project can be compiled normally, but it has been started and an error has occurred,\n. ",
    "wouterd": "Thanks for the pointer. That helped a ton. Not as pretty as when done in Scala, but I've got it working now.. ",
    "wpK": "Sure. I'll send over a pull request shortly.. @nepthar Updated the comments with your suggestions.\n\nWhere will this option be translated to the appropriate connection flag?\n\nNot sure what you mean. Can you elaborate?\nThe flag is changed here and the client can disable the flag like so:\nMysql.client\n  .withCredentials(\"test\", \"test\")\n  .withDatabase(\"test\")\n  .withAffectedRows()\n  .newRichClient(\"localhost:3306\")\nI originally had enableFoundRows(enabled: Boolean) instead of withAffectedRows(). I went with withAffectedRows() which is closer to the the JDBC as seen here (you'll need to search for useAffectedRows.\nIf the methods cause confusion since the internal implementation (in Handshake) is different than the Mysql.client API, I'll make it uniform. Just let me know which one you prefer. Removing withAffectedRows() entirely and just configuring it using Mysql.client.configured(FoundRows(false)) works as well.. ",
    "codeape": "Thank you. I will get back to you as soon as I have tested your solution. Hopefully on Monday :). ",
    "ryanb93": "@vkostyukov we are currently using version 2.11.0 of finatra-http_2.12 as a HTTP client to send requests between services. We're taking advantage of the built in circuit breaker as a replacement for Hystrix, that we would usually use.. ",
    "anatolydwnld": "Is there a valid use case for calling Http.Client() directly? If not maybe the constructor should be marked private[Http]?. Upgrading to 7.1.0 fixes my reproducer. This can probably be closed. Thanks!\nOn Sat, Sep 9, 2017 at 11:03 AM, Moses Nakamura notifications@github.com\nwrote:\n\n@anatolydwnld https://github.com/anatolydwnld we've published a new\nversion of finagle. Can you try finagle 7.1.0?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/644#issuecomment-328282647,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJrHF5BEtw-yFoHhIqB92XoDmIMyust0ks5sgqjEgaJpZM4O410c\n.\n. \n",
    "Eternity-Yarr": "I think i'll post this bug in util project instead. Sorry :). ",
    "teodor-pripoae": "Mysql clients first send a client capabilities packet with SSL flag and the server responds with a server capabilities packet containing SSL flag. Then the client tries to upgrade the connection to SSL if the server supports it. I couldn't find more information about how tls works in mysql.. ",
    "ksilin": "+1 is there any progress on the SSL for MySQL issue? . ",
    "crispywalrus": "@mosesn the underlying issue here is that scrooge-sbt-plugin was literally not published for ANY version of sbt This is kind of a big bug for me and anyone else outside of twitter that uses thrift with finagle.. I see it now, thanks @dschobel!. I've started a PR https://github.com/crispywalrus/finagle/pull/1 to address this .... @adriancole @mosesn this is the result of the last changes to https://github.com/crispywalrus/finagle/pull/1 to add OpenZipkin support to finagle. . ",
    "ptaillard": "@kevinoliver Thanks for your answer.\nLet's dive deeper and give you more details.. @kevinoliver \nWe captured jvm memory using jmap on different times during the application life under traffic (and fix the failfast misconfiguration as you advised it).\nBelow you can see the jmap output (histo and heap).\n\n\nFew minutes after the start of the application:\n1-jmap_heap_start.txt\n1-jmap_histo_start.txt\n\n\nFew hours after the start of the application:\n2-jmap_heap_during_life.txt\n2-jmap_histo_during_life.txt\n\n\nAnd the last one, when the jvm memory and latency issue occured:\n3-jmap_heap_latency_issue_occured.txt\n3-jmap_histo_latency_issue_occured.txt\n\n\nWe noticed that the com.twitter.finagle.Stack$Node instances increased and seems to be not released => On the jmap heap, the Old generation increased as well.\nThat's why we thought it was a memory issue, maybe it could be also a restraint issue.\nThis behaviour is not visible on the old Finagle version 6.2.0.\nEach server send around 30 000 000 requests (30 Millions) by day using Http Finagle client.\nDoes something jump out at you?\nThanks. @kevinoliver Could be this issue? https://finagle.github.io/blog/2016/09/01/block-party/ . Yes you are right @kevinoliver \nMany thanks for your help, we will fix that.. ",
    "elecnix": "Commit 808a935a766c36cc4063cd665dd1a0f5a6c3170e shows a prototype implementing this behavior.. The change was validated in a simple integration test.\nThis implementation relies on the existing circuit breaking. When the circuit \"opens\", the service factory \"closes\", and the Alted service factory picks the next available circuit. Once the circuit breaker starts probing, the Alted factory sends an equivalent request.\nThis is inherently racy. I'm okay with that, but open to suggestions.\nAs a disclaimer, I'm running this change with an unmodified Linkerd. I'll think about the idea of creating two clients, but I doubt that would fit nicely with how they integrate Finagle.. ",
    "glassorio": "I have used the way back machine and found a version of the page where those sections are still there.. ",
    "szysas": "I still would like to understand use case that this exception is thrown, is it only because of timeout (http response did not arrive in time)? In the source code I could only find here, that is related to client: https://github.com/twitter/finagle/blob/143f6f0f83765783808a11f990179d881daecb66/finagle-base-http/src/main/scala/com/twitter/finagle/http/exp/GenStreamingSerialServerDispatcher.scala#L128\nWhat is the reason that retry on this exception is not set by default? (I'm guessing you guys had a good reason). Thanks.\n(BTW, great job with this library). No, not using it.. ",
    "yozhao": "1646.34 failed, this should not be related with my checkin.\n@mosesn linden is xiaomi internal search project, many vertical search in MIUI are based on linden.\n. ",
    "isabelmartin": "Thank you @adriancole! This has been merged in 76b6c9a.. @adriancole Hi, would you mind clarifying what you're hoping for a bit? As far as I understand it, Finagle doesn't use scribe by default, but you can using the finagle-zipkin module which will use scribe if you choose to depend on it. And if you wouldn't mind explaining, which part of maintaining scribe is burdensome to OpenZipkin?. Thanks @edio! This has been merged in 0c39217724c2c701b2b7f46932ee5869a997c061. Thanks Robert! This has been merged in 940809af1a5f1874af0513c9cdca3b1c3b2ce03c. ",
    "sullis": "SBT 1.0.4 fixes a performance issue in SBT 1.0.3\nhttps://developer.lightbend.com/blog/2017-11-27-sbt-1-0-4-hotfix-and-performance-fixes/\n. obsolete\n. ",
    "utkarshcmu": "@mosesn - I am not the right person to answer that but I would say that some of our backend microservices use Finagle.. ",
    "oscar-stripe": "this would be useful to me.\n@ryanoneill any update on when Twitter can review?. ",
    "DieBauer": "Hi @ryanoneill, I'd be interested ;) I tried an initial patch in #670.. @bryce-anderson I feel the same regarding dropping the field in an equality, that is part of the unique instance. \nHowever, comparing infinite things doesn't make sense, it has no meaning. \nAs you mention this is indeed to only cater for the issue I raised. A use-case could be putting clients in a HashMap (requiring a valid/unique hashCode). \nHaving a valid (short-circuited) equals/hashCode on the Client does make sense. And would solve (circumvent) this issue. \nWhat would you suggest is part of the hashCode then? Is ignoring the certain Params a better option than partly checking the equality of 'deeper' params (ie. Budget)?\nYou could as an alternative decide to drop the hashCode/equals class specific implementation (given by the case class) and delegate to super -> java.lang.Object for Budget or the Client, automatically giving you the instance equality. \n. @ryanoneill alright! Let me know if I need to do something on this PR :) . ",
    "jluehe": "Sounds great, @yufangong - thanks for keeping me in the loop!. ",
    "cricket007": "@smlance @yufangong Is there a particular reason Thrift 0.11.0 wasn't used? Other than perhaps it wasn't released at the time you started the upgrades?\nAlso, I'm just starting to look at Finagle for an RPC Thrift use case (in Java and using Maven), and I finding it difficult to line up versions between Scrooge, Finagle-thrift, and libthrift. For example, the Scrooge web page says to add version 4.13.0, but I see that's rather old. I assume all versions of these libraries should closely match? And I'll need to wait until the next release for Thrift 0.10.0 anyway?  \nThanks. ",
    "politrons": "Yeah adding the header or directly adding host in request make it works. Still wondering why with Vertx or Finagle servers are not needed. I think the problem is that you guys have several documentation for older versions of scrooge which are not working anymore with newest finagle versions published.\nIt's feel like scrooge it\u00b4s not part of Finagle project since there's no track of it from the official finagle web page.\nCan I use this question to ask you if there\u00b4s any implementation of Streaming with Thrift + scrooge?. I cannot find where I saw the old documentation. Regarding the streaming we\u00b4re using gRPC using bidirectional StreamObserver to connect some microservices, but I would love it migrate it to Scala. Unfortunately people from Google does not like Scala :( that\u00b4s the reason why I start looking into Thrift. Thanks I\u00b4ll keep in mind, and I will see if it's worth it the migration since if all the generate code by gRPC it\u00b4s already in Java there's nothing to migrate actually.. Yeah it was mixing code from previous version with new one.. ",
    "lelence": "I have the same problem, when I using code like \nval client: Service[Request, Response] = Http.newService(\"localhost:8080\")\nval request = http.Request(http.Method.Get, \"/hello_server\")\nIt's return 400 Bad Request\nwhen I using code like \nval client: Service[Request, Response] = Http.newService(\"localhost:8080\")\nval request = RequestBuilder()\n.url(new URL(\"http://localhost:8080/hello_server\"))\n.buildGet()\nIt will be successed.\nI found something like\nval withHost = config.headers.updated(Fields.Host, Seq(hostValue))  at line 153 on source file 'RequestBuilder'\nso I think, it will be working , add header info like \n`val client: Service[Request, Response] = Http.newService(\"localhost:8080\")\nrequest.headerMap.add(\"Host\", \"localhost:8080\") // add header\nval request = http.Request(http.Method.Get, \"/hello_server\")`\nso it's working, return status 200, \nmybe there is a bug!!!\n. ",
    "heartsucker": "Huh. I'm going to blame that on a crappy corporate network and close this because that sounds like it's probably the cause.. @mosesn Thanks for the quick response. If this collides with current development, feel free to let it dangle until it can be merged in to someone supersedes it. :). ",
    "legopiraat": "@mosesn I've just tried the same thing and i've made sure my client certificate is send by using:\nHttp.client\n.withTransport.tls(sslContext)\n.newService(Config.Http.baseUrl)\nAlso i configured set my server to require ClientAuth i think?: \nHttp.server\n      .withTransport.tls(SslServerConfiguration(clientAuth = ClientAuth.Needed), serverFilter)\nThe session.getPeerCertificateChain still throws the same error.. After some extra digging around i managed to get it working. \nTurns out there is a some extra server configuration needed.\n```\nHttp.server\n      .withTransport.tls(SslServerConfiguration(clientAuth = ClientAuth.Needed), (config: SslServerConfiguration) => {\n  val context: SslContext = SslContextBuilder\n    .forServer(privateKey, password, certificate)\n    .trustManager(trustedCertificate).build()\n\n  val engine = context.newEngine(io.netty.buffer.UnpooledByteBufAllocator.DEFAULT)\n  engine.setNeedClientAuth(true)\n  Engine(engine)\n}, sessionVerifier)\n\n```\nWith this configuration i was able to retrieve the peerCertificates in the sessionVerifier.. ",
    "YikSanChan": "Thank you Kevin, I go into CONTRIBUTING, run curl -s https://raw.githubusercontent.com/twitter/dodo/develop/bin/build | bash -s -- --no-test finagle and solve the issue. Now I can import com.twitter.util.{Await, Future,Promise}. Thanks a lot!. ",
    "yaroot": "finagle-example does not depend on guava in sbt build, but in pants BUILD it does. Looks like been broken since the removal of guava from serversets.. ",
    "KyleU": "@kevinoliver:\n\nfor the former, your best best is to modify the stack. this might sound scarier than it is.\nfor the latter, it sounds like this is thriftmux, if you are using Scrooge to generate your bindings you should be able to use service per endpoint (https://twitter.github.io/scrooge/Finagle.html#serviceperendpoint) and put your filter there.. \n",
    "kaqqao": "Hey @kevinoliver ,\nYou're indeed right! Thanks a bunch for the pointer!\nI'm now missing the point of the SimpleRetryPolicy constructor argument, but that's less important.. ",
    "yorksen": "my mistake, exp is e^n. ",
    "robertpanzer": "Only guessing, but I guess the VM will automatically load all types that appear in a method, that's why it crashes even if the toggle is disabled.\nBy moving the creation of the EpollEventLoopGroup into an own method, that also has only the base type EventLoopGroup in the signature, we can defer loading it until the new method is really invoked.. ",
    "vsabella": "We recently saw this issue when using Finagle clients with Play Framework 2.6.13 - or any one of our other services that forced an upgrade to Netty 4.1.23 but is calling other Finagle services via finagle-thrift .\nI don't mind submitting a patch to Finagle to upgrade to latest Netty, but to avoid similar problems in the future would the group here find it unreasonable to shadow-jar Netty inside of Finagle.\n(TODO: List pros/cons of shadow-jar). ",
    "baybatu": "Hi, I've encountered with this behaviour with 2 REST apis running on localhost. (apigwservice -> customerservice)\nI added ConsoleTracer to Http client and logs are something following:\n1207 18:09:16.264 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] Rpc(POST)\n1207 18:09:16.266 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] BinaryAnnotation(http.uri,/customers)\n1207 18:09:16.266 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] ServiceName(customerservice)\n1207 18:09:16.266 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] BinaryAnnotation(clnt/finagle.version,18.11.0)\n1207 18:09:16.266 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] ClientSend\n1207 18:09:16.266 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] Rpc(POST) # duplication starting\n1207 18:09:16.267 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] BinaryAnnotation(http.uri,/customers)\n1207 18:09:16.267 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] ServiceName(customerservice)\n1207 18:09:16.267 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] BinaryAnnotation(clnt/finagle.version,18.11.0)\n1207 18:09:16.267 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] ClientSend\n1207 18:09:16.350 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] WireSend\n1207 18:09:16.350 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] WireSend\n1207 18:09:16.353 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] ServerAddr(localhost/127.0.0.1:9002)\n1207 18:09:16.353 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] ServerAddr(localhost/127.0.0.1:9002)\n1207 18:09:16.354 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] ClientAddr(/127.0.0.1:60432)\n1207 18:09:16.354 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] ClientAddr(/127.0.0.1:60431)\n1207 18:09:17.500 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] WireRecv\n1207 18:09:17.500 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] WireRecv\n1207 18:09:17.504 0ed23f75c00b1f09.950bf153dfbe4c4d<:0ed23f75c00b1f09] ClientRecv\n1207 18:09:17.504 0ed23f75c00b1f09.ff5814a2e8f40305<:0ed23f75c00b1f09] ClientRecv\nSometimes, apigwservice duplicates requests that sent to customerservice.\n. It seems the duplication requests' cause is Http client's idempotency settings(1.percent). ",
    "jdreyesp": "Hi @mosesn, that's exactly the cause of the issue, if you consume the server through HTTP instead of HTTPS, a big warning log is produced and it cannot be disabled / configured. \nI've been investigating and this is managed by ChannelStatsHandler. It seems like by default, it logs everything that is not a IOException/TimeoutException/Failure to WARNING level:\noverride def exceptionCaught(ctx: ChannelHandlerContext, cause: Throwable): Unit = {\n...\ncase _: IOException => Level.FINE\n        case _: TimeoutException => Level.FINE\n        case f: Failure => f.logLevel\n        case _ => Level.WARNING\n...\nIs there a way to override the ChannelPipeline (managed by netty4) in the server creation to set a custom ChannelStatHandler to avoid this warning? \nThanks in advance!. Hi @mosesn , thanks again for your response. We work as a framework team and we're making a non backward compatible change, updating this Finagle server from non secure to secure. Since this server is being consumed by polling tools (Prometheus in our case) we're expecting a big amount of calls during this re-configuration period. That's why we want to be able to disable this warning, in order not to flood out our logs.\nI was just wondering if there's an easy way to toggle this warnings off for our server.\nThanks. Hi @mosesn !\nThis is not only a migration thing, but in general attackers can try to flood server logs with plain HTTP requests (even if the server is using TLS configuration).\nThis could create performance issues, for example.\nSolving this as disabling finagle logging is not a possibility, since it's logged by com.twitter.finagle and disabling this means disabling the whole finagle logger.\nThanks. Hi @mosesn , that was my first try, but it didn't work. Apparently some class in a higher package level is still throwing this warning.. Hi @mosesn, any updates on this? Thanks. Hi!\nNo, I found it only in the location you mention, but this is also caught in other locations\nIndeed, that avoid the ChannelStatsHandler one (thanks :)), but there's two more, netty related:\n```\n08:53:35.932 [finagle/netty4-1] WARN  com.twitter.finagle - Unhandled exception in connection with /127.0.0.1:58886, shutting down connection | io.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: ....\n08:53:35.932 [finagle/netty4-1] WARN  i.n.channel.DefaultChannelPipeline - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception. | io.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: ...\n```\nI don't want to get rid of com.twitter.finagle nor DefaultChannelPipeline since I see them important to log in other cases. But I don't want to get my log overflooded by HTTP calls.. Fair enough. \nPlease let me know what is your final decision on this in next Finagle version!\nThanks for the support!. ",
    "Prahathess-Rengasamy-ck": "Great thanks\nOn Fri, Aug 17, 2018, 16:42 Moses Nakamura notifications@github.com wrote:\n\n@Prahathess-Rengasamy-ck https://github.com/Prahathess-Rengasamy-ck\nsorry for the long silence, I've been hacking on this for a while, I think\nit's pretty close to being ready. I would expect it to land in the next two\nweeks (I'm on vacation next week).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/twitter/finagle/issues/701#issuecomment-413982821,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AigA5_yvRVE93GhSvlqC2t06mOwENugaks5uRyrLgaJpZM4U0IB2\n.\n. \n",
    "Axxiss": "@smlance For the record, here is where the duration is tracked:\nhttps://github.com/twitter/finagle/blob/911a01cee08852f47385ac7b9d709cf3fc5422a9/finagle-netty4/src/main/scala/com/twitter/finagle/netty4/channel/ChannelStatsHandler.scala#L33-L34\nhttps://github.com/twitter/finagle/blob/911a01cee08852f47385ac7b9d709cf3fc5422a9/finagle-netty4/src/main/scala/com/twitter/finagle/netty4/channel/ChannelStatsHandler.scala#L133. ",
    "hussain21j": "Did any one solve this problem ?. ",
    "amishra123": "I'll be interested to work on this.. ",
    "ben-ng": "Hi @yufangong, I've added a youtube video about how we use Finagle in our search stack.. ",
    "caplan": "The Metrics singleton is public, so I can use that - sorry for the noise.. ",
    "Alterrien": "Hi, I managed to get the code to sort of work (minus kerberos setup on my machine, but that's not Finagle scope). It was my first time being exposed to SPNEGO, so the documentation, specifically what was to fill in as loginContext for the JAASClientSource, was not enough to allow me to use it out of the box. I guess that's more related to knowledge of the SPNEGO protocol and JAAS.\nAnyway, thanks !. ",
    "komsit37": "seems calling transact would create new client repeatedly, which requests new CursorStats metrics every time\nhttps://github.com/twitter/finagle/blob/develop/finagle-mysql/src/main/scala/com/twitter/finagle/mysql/Client.scala#L319. ",
    "moleike": "indeed, thanks!. ",
    "zackangelo": "@dschobel \u267b\ufe0f added some more detail in the comment. @kevinoliver does this introduce a compile-time breaking change? the new argument added to Transport.Options has a default value, so I don't think it'll break any existing code.. @kevinoliver would it be preferable for me to add another apply method on Transport.Options vs documenting a breaking change? . @kevinoliver @dschobel \u267b\ufe0f added alternate constructors/apply methods for Transport.Options and also only added the socket option if native epoll is being used. okay will do!. agree, it should be removed. @dschobel do you want me to just ignore the presence of this setting in ConnectionBuilder? . Actually, along the same lines, would it be preferable if I only add the option if nativeEpoll.enabled is true? . ",
    "hongikeam": "@kevinoliver @mosesn \nsorry i've been busy :(\ni send a transaction twice that will be failed.\nand i'm monitoring in redis-cli.\ncurrent revision\n* server logs\n```\nfirst\nERRO [20180831-16:07:35.993] server-service: com.twitter.finagle.redis.ServerError: EXECABORT Transaction discarded because of previous errors.\nERRO [20180831-16:07:35.993] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:103)\nERRO [20180831-16:07:35.993] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:102)\n...\nsecond\nERRO [20180831-16:08:48.371] server-service: com.twitter.finagle.redis.ServerError: ERR MULTI calls can not be nested\nERRO [20180831-16:08:48.371] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:103)\nERRO [20180831-16:08:48.371] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:102)\n...\n```\n\nredis logs\n```\n\nfirst\n1535699255.942261 [0 127.0.0.1:62377] \"MULTI\"\n1535699255.947154 [0 127.0.0.1:62377] \"EXEC\"\n1535699255.992372 [0 127.0.0.1:62377] \"MULTI\"\n1535699255.992794 [0 127.0.0.1:62377] \"MULTI\"\nsecond\n1535699328.371062 [0 127.0.0.1:62377] \"MULTI\"\n```\nmy revision\n```\nfirst\nERRO [20180831-16:17:25.102] server-service: com.twitter.finagle.redis.ServerError: EXECABORT Transaction discarded because of previous errors.\nERRO [20180831-16:17:25.102] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:103)\nERRO [20180831-16:17:25.102] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:102)\nsecond\nERRO [20180831-16:18:00.401] server-service: com.twitter.finagle.redis.ServerError: EXECABORT Transaction discarded because of previous errors.\nERRO [20180831-16:18:00.401] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:103)\nERRO [20180831-16:18:00.401] server-service:     at com.twitter.finagle.redis.BaseClient$$anonfun$doRequest$1.applyOrElse(Client.scala:102)\n```\n```\nfirst\n1535699845.092552 [0 127.0.0.1:64837] \"MULTI\"\n1535699845.098164 [0 127.0.0.1:64837] \"EXEC\"\n1535699845.101876 [0 127.0.0.1:64837] \"DISCARD\"\n1535699845.102252 [0 127.0.0.1:64837] \"DISCARD\"\nsecond\n1535699880.398286 [0 127.0.0.1:64837] \"MULTI\"\n1535699880.399989 [0 127.0.0.1:64837] \"EXEC\"\n1535699880.401317 [0 127.0.0.1:64837] \"DISCARD\"\n1535699880.401612 [0 127.0.0.1:64837] \"DISCARD\"\n```\nif you looking previous commit (8months ago) then you'll get what is the problem.. ",
    "coduinix": "I think I could work on a PR, but I have one question/alternative approach:\n* Is there a specific reason why the exception is created only once instead of creating an exception each time it encounters the specific situation. E.g. why not pass a () => NoBrokersAvailableException function to the newBalancer method. I think that would be better in terms of: which class should be responsible for mentioning the correct Dtab info in the message? I think it should be the creator of the exception who knows the exact information it worked with.. The suggested compromise makes sense I think. I'll prepare a PR. ",
    "sboobna": "@kevinoliver . @kevinoliver the failures look unrelated to me. @kevinoliver thanks for the approval. What else do I need to do to get this merged in, since there are some unrelated test failures?. ",
    "xerial": "Thanks!. ",
    "acidghost": "@ryanoneill I can open a new PR. Shall I also update the changelog? If so, how should I handle PHAB_ID=# and RB_ID=#?. @mosesn for sure I can try to tackle it! I already have an idea (or at least I think I do) of the parts that need to be changed (com.twitter.finagle.netty4.ssl.server.SslServerVerificationHandler and com.twitter.finagle.netty3.ssl.server.SslServerConnectHandler).. I think everything is in place now. I'm going to work on the missing tests tomorrow (CET timezone). what does the style guide suggests about method declaration? how should I split it to multiple lines?\nIs the following okay?\nscala\ndef apply(\n  address: Address,\n  config: SslServerConfiguration,\n  session: SSLSession): Future[Boolean] =\n{\n  ???\n}. Is the following correct?\n```scala\nprivate[this] def verifySession(session: SSLSession, ctx: ChannelHandlerContext): Future[Boolean] = {\n  sessionVerifier(address, config, session).respond {\n    case Return(verifierResult) =>\n      if (!verifierResult) {\n        fail(\n          SslVerificationFailedException(\n            Some(new Exception(\"Failed client verification\")),\n            inet\n          )\n        )\n        ctx.close()\n      } // if verification is successful, do nothing here\n    case Throw(e) =>\n      fail(SslVerificationFailedException(Some(e), inet))\n  }\n}\noverride def handlerAdded(ctx: ChannelHandlerContext): Unit = {\n  // React on satisfied handshake promise.\n  sslHandler\n    .handshakeFuture()\n    .addListener(new GenericFutureListener[NettyFuture[Channel]] {\n      def operationComplete(f: NettyFuture[Channel]): Unit =\n        if (f.isSuccess) {\n          if (sslHandler.engine.isInboundDone) {\n            // Likely that the server failed to verify the client or the handshake failed in an unexpected way.\n            fail(\n              new SslVerificationFailedException(\n                Some(new Exception(\"Failed server verification\")),\n                inet\n              )\n            )\n          } else {\n            val session = sslHandler.engine().getSession\n            verifySession(session, ctx).respond { _ =>\n              if (onHandshakeComplete.setDone()) {\n                // If the original promise has not yet been satisfied, it can now be marked as successful,\n                // and the SslClientVerificationHandler can be removed from the pipeline. If the promise is\n                // already satisfied, the connection was failed and the failure has already been\n                // propagated to the dispatcher so we don't need to worry about cleaning up the pipeline.\n                ctx.pipeline.remove(self) // drains pending writes when removed\n              }\n            }\n          }\n        } else {\n          // Handshake promise is failed so given SslHandler is going to close the channel we only\n          // need to fail pending writes and the connect promise.\n          fail(f.cause())\n        }\n    })\nsuper.handlerAdded(ctx)\n}\n```. So the logic for the server verifier is correct? I'll try to write a test if so. ",
    "dadjeibaah": "@kevinoliver, I made a first attempt at fixing the bug. Not sure if it's the totally right way to do it but from my understanding, it looks like the partition method needs to handle situations where the endpoints activity is updated with an empty set. The code I have on my branch moves the newBalancer method into partition and creates a CachedBalancer with weight 0 (Not sure if that even makes sense). I will play around with it more to see if I can come up with a better solution.\nDiff can be found here...https://github.com/twitter/finagle/compare/develop...dadjeibaah:develop. @bryce-anderson I can add a PR for review. I just need to work on it a little more to fix some tests that are failing.. @bryce-anderson, I added a PR as a potential fix for this issue, just as a heads up.. Thanks for the feedback @bryce-anderson. It seems the root cause of this issue is https://github.com/twitter/finagle/issues/739 and I think fixing this will avoid us having to make this change. I am going to go ahead and close this PR and create a new PR that addresses #739. I dug into this a little bit more and it appears that this is a bug in Netty's HTTPObjectAggregrator here. It looks like when netty parses a full http message it sets the Content-Length header for that message even when the http message is of type 204 No Content. Based on RFC 7230 3.3.2\n\nA server MUST NOT send a Content-Length header field in any response\n   with a status code of 1xx (Informational) or 204 (No Content).  A\n   server MUST NOT send a Content-Length header field in any 2xx\n   (Successful) response to a CONNECT request (Section 4.3.6 of\n   [RFC7231]).. @roanta I added a test to confirm that close is indeed being called on empty load balancers after there is a change in the address set. PR should be ready for another look.. thanks for catching that!. My manual tests of this branch, or at least looking at the Balancers in loadbalancers.json, indicated that the Balancers were being closed. but I can add your suggestion to verify.. Yes it is, thanks for pointing that out. I will make the suggested change.. \n",
    "jaykhimani": "For which version this is scheduled? . ",
    "dziemba": "If you haven't planned this already and don't have capacity for it, I'm also happy to try this myself and create a PR. We would love to see this in the next finagle release if possible.. Awesome! that works for us too. Thanks!. ",
    "jlawrienyt": "Thanks!. ",
    "pra527vin": "@yufangong \nHttp.server\n      .withAdmissionControl\n      .concurrencyLimit(maxConcurrentRequests = maxRequests, maxWaiters = maxRequestsQueue)\n      .withMaxHeaderSize(new StorageUnit(maxHeaderSize))\n      .withMaxRequestSize(new StorageUnit(maxRequestSize))\n      .withRequestTimeout(30.seconds)\n      .configured(Stats(statsReceiver))\n      .serve(s\"${ServerEnvironment.SERVER_ADDRESS}:${ServerEnvironment.PORT()}\",\n        new Cors.HttpFilter(originPolicy).andThen(kiranaAPI))\n/*\n      * Make Exit happening here.\n      /\n    onExit {\n      server.close()\n    }\nI have configured server like this \nfor two instances with different ports \nAfter first services is started  then second service with different port is gives AddressBindException \nI have cretaed different jar for two server insctances. ",
    "remi-thieblin-ck": "Hi @bryce-anderson , thanks for the reply. I'll close the PR for now.. ",
    "hjz": "Seems sensible to me. I thought it would be an annoyance for current\nusers of incr to change to Long.\nOn Sun, Mar 27, 2011 at 6:57 PM, dhelder\nreply@reply.github.com\nwrote:\n\n\n@@ -279,11 +303,15 @@ trait PartitionedClient extends Client {\n\u00a0 \u00a0def replace(key: String, flags: Int, expiry: Time, value: ChannelBuffer) =\n\u00a0 \u00a0 \u00a0clientOf(key).replace(key, flags, expiry, value)\n- \u00a0def delete(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = clientOf(key).delete(key)\n- \u00a0def incr(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = clientOf(key).incr(key)\n- \u00a0def incr(key: String, delta: Int) = clientOf(key).incr(key, delta)\n- \u00a0def decr(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = clientOf(key).decr(key)\n- \u00a0def decr(key: String, delta: Int) = clientOf(key).decr(key, delta)\n- \u00a0def delete(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = clientOf(key).delete(key)\n- \u00a0def incr(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = clientOf(key).incr(key)\n- \u00a0def incr(key: String, delta: Int) \u00a0 = clientOf(key).incr(key, delta)\n- \u00a0def decr(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 = clientOf(key).decr(key)\n- \u00a0def decr(key: String, delta: Int) \u00a0 = clientOf(key).decr(key, delta)\n- \u00a0def incrl(key: String) \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0= clientOf(key).incrl(key)\n\nI can't think a reason to keep the Int version. \u00a0Could it just be changed to incr(key: String, delta: Long)?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/15/files#r12506\n\n\nJustin Zhu\nTwitter, Application Services\n@hjzhu\n. ",
    "holdenk": "Changed in 8beea2b , thanks :)\n. ",
    "s-garg": "Will do that. I was not able to run ClientSpec.scala.. I will give it\nanother shot.\nSaurabh\nOn Mon, Jul 16, 2012 at 2:36 PM, Anirudh Srinivas\nreply@reply.github.com\nwrote:\n\n\n@@ -348,6 +360,38 @@ class Client(service: Service[Command, Reply]) {\n       case EmptyMBulkReply()    => Future.value(Map())\n     }\n-  def lPush(key: String, value: Array[Byte]): Future[Int] =\n\nCould you add comments in a similar style to the other functions? And could you also add some test cases in ClientSpec.scala for the new commands?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/twitter/finagle/pull/90/files#r1173581\n. \n",
    "darnaut": "It uses the same character set as query results (character_set_results).\n. Also, you need to convert days to hours. I guess using Calendar will solve.\n. The variable is initialized to the charset number sent by the client.\nSee Connection Character Sets and Collations and Character Set for Error Messages for more details.\n. As suggested above, better to enforce UTF-8 both ways.\n. List of character set names and numbers\n. Would be better to refer to capabilities by name.\n. ",
    "jeremycole": "Do I understand correctly that this conflates NULL and empty string by always translating empty string to None? If a legitimate empty string were returned would it result in None and thus be indistinguishable from NULL? That would not be a good thing.\n. Not totally sure I'm following the above conversation, but if we're to use this in production it will need to support some form of prepared statement substitution. Server-side prepared statements are slower for many use cases and much more difficult to resource-manage. It's quite easy to accidentally run the server out of prepared statement handles and then everybody loses. I generally recommend with MySQL Connector/J JDBC driver to always set useServerPrepStmts=false, causing the client-side to always do the substitution.\n. This is not really correct. I would think it better to explicitly case 251 as SQL NULL, and throw an exception for 255, as it implies corrupted data or out of sync client/server, since it's not a valid value. Continuing your read after getting a 255 here would end up with an exception in some other unrelated place.\n. Blank string and SQL NULL should never be conflated.\n. This seems to not actually implement the length-coded string. What am I missing?\n. If it is not readable, then what? Certainly this needs an else and should probably throw an exception of some sort.\n. It's also worth noting that MySQL conflates character sets and collations at the protocol level, so 33 is \"utf8_general_ci\" collation, and you could see many other values here for utf8 character set.\n. There are a lot of other SQL queries which don't return result sets. To avoid confusion it's probably better not to try to list them here.\n. In terms of naming, this is not really correct. Type BIT represents a bitmap of 1 or more bits. It's really an integer type of varying length, and only in the minimal case of BIT/BIT(1) is it potentially a boolean.\n. This is, of course, far too simple. I would argue that regular expression substitution is itself too complex to be part of this library though, and should be delegated to something else.\n. In general I would say to avoid using server-side prepared statements at all. Even if they are perfectly monitored, they are still in very many cases generating 3 round trips (prepare, execute, close) when 1 would suffice (query). In most of our apps that we care about, there would be huge numbers of prepared statements in order to pre-prepare them all (as table name is not an allowed placeholder, and they are mostly sharded into N tables); so the round trip multiplication can't be avoided by pre-preparing all possible statements.\nSo since a good client-side prepared statement handler is necessary, may as well use it everywhere, even when it's not strictly needed.\n. ",
    "benpence": "scrooge worked OK for me. I think it's important that the scrooge docs mention they need sbt v0.11.2 (or is that fixed by sbt-scrooge?). sbt v0.11.3 did not resolve when working against twitter dependencies.\n. \"To create a Finagle Thrift service, Finagle requiers you to generate, in addition to the regular Thrift Iface interface, a ServiceIface interface that wraps all return values in a Future. Use either scrooge or the sbt extension sbt-scrooge to compile your Thrift IDLs.\nNote: scrooge and sbt-scrooge must build with the correct version of sbt.\"\nSomething like this? Or should the scrooge/sbt-scrooge install instructions reference the script instead?\n. \"\"\"\nTo create a Finagle Thrift service, you must implement the ServiceIface Interface that Scrooge (a custom Thrift compiler) generates for your service. Scrooge wraps your service method return values with asynchronous Future objects to be compatible with Finagle.\n- If you are using sbt to build your project, the sbt-scrooge plugin automatically compiles your Thrift IDL. Note: The latest release version of this plugin is only compatible with sbt 0.11.2\n- If you are using maven to manage your project, maven-finagle-thrift-plugin can also compile Thrift IDL for Finagle.\n  \"\"\"\n@stevegury Steve, do you have an official link for the maven plugin? I could only find it under Twitter's maven repos. Sorry, I'm not familiar with maven plugins. Let me know if the revision is OK. I think it's important to specify that the developer must implement ServiceIface and not Iface to make the example clearer.\n@isnotinvain that is a good idea.\n. ",
    "arnarthor": "Sure thing\n. Fixed in  3870599\n. ",
    "gtcampbell": "typo: \"delimeter\" should be \"delimiter\"\n. ",
    "jcarres-mdsol": "I think we are good and this will work properly for us. It will work as expected, will read a string (which comes from the header) and create a SpanId class from it.\n. ",
    "vazyzy": "I already added link to RFC in my commit. Here a quote from it:\nA client MUST send a Host header field in all HTTP/1.1 request\n   messages.  If the target URI includes an authority component, then a\n   client MUST send a field-value for Host that is identical to that\n   authority component, excluding any userinfo subcomponent and its \"@\"\n   delimiter (Section 2.7.1).  If the authority component is missing or\n   undefined for the target URI, then a client MUST send a Host header\n   field with an empty field-value.\nI think better parse a Host from URI like you already do in RequestBuilder. And then we must remove this logic from RequestBuilder to avoid duplications.  But I did not find a way to do it neatly and without changes in public interfaces.\n. ",
    "matsu-chara": "fix example\nhttps://twitter.github.io/finagle/guide/FAQ.html \nold: https://twitter.github.io/finagle/docs/#com.twitter.finagle.CancelledRequestException\nnew: https://twitter.github.io/finagle/docs/com/twitter/finagle/CancelledRequestException. ",
    "iPlessmann": "hello,\nwas this merge? i don't see it on 18.1.0 nor on develop. ",
    "Mandar-Shinde": "@yufangong sure, will do.. "
}