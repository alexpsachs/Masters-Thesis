{
    "kripken": "The em++: command not found is because you need emscripten in your path, if you want to build the js parts. But you don't need it for asm2wasm or wasm-shell.\nThe others are a gcc bug, it turns out. Building with newer gcc, or clang, should avoid those. I haven't been able to find a workaround for older gcc.\n. This is the bug, I'm not sure how to figure out which gcc release that ends up in. But based on the dates, I think at least 5.0.\n. Thanks! I pushed a patch with aborts instead of pure virtual. It does build in gcc now. However it gives an error, which I don't have time to look into right now. (Note that the test suite is currently failing in the spec tests due to upstream spec changes, but a gcc build errors earlier.)\n. After recent changes, gcc seems to build and emit a working shell, so I think we can close this.\n. After @waywardmonkey's first pull and some tweaks, cmake mostly works. The main missing piece is it doesn't invoke emcc to build wasm.js yet.\n. Yeah, it's getting worse. I just pushed a commit to move build.sh to use cmake for everything that it can, which is everything but wasm.js. Hopefully we can figure out the wasm.js bit (tricky part is calling emcc, and not the system compiler), and remove build.sh entirely.\n. This is mostly done, but we still have build-js.sh for building the JS parts. Would be nice if that could be done in cmake as well, but it means invoking out to call a different compiler (emcc) so maybe not. If not, we can close this.\n. Done in wasm.js.\n. I feel like I don't understand the background here. Sure, talking over beers sounds good.\n. Some thoughts before beers, so I don't forget:\nIf the goal is to have a uniform license for the WebAssembly/ projects so they can share code, then that sounds good. However, I don't think the Apache 2 license is the best for our purposes. The two main problems are\n- Apache has a binary attribution clause, which makes it troublesome for code included in build outputs (e.g., the binaryen asm.js => wasm polyfill would ship with the build, and fall under that clause). For example, LLVM is considering moving to Apache, but only with a runtime exception. So I think we would need a runtime exception here as well, and there isn't a standard one, so we'd need to write one and people would need to read it carefully.\n- Apache 2 is not GPL 2 compatible.\nThe MIT license has neither issue and is standard and familiar, which is why I tend to prefer it.\n. Merged per discussion. We do want to add an exception for the attribution issue, but can do that later. For now, it's Apache 2.0 as in all the other WebAssembly/ projects.\n. This is an issue that happens because WebAssembly does not have global variables. The idea is that people use locations in memory to replace them, but that requires interaction with the compiler, so it knows where it can place them.\nFor emscripten, we just reserve 8-1000 for such \"mapped globals\" as we call them, and we know that will be enough room.\nWe could make this work for other asm.js code too. The mapping shows up in mappedGlobals, see https://github.com/WebAssembly/binaryen/blob/master/src/wasm-js.cpp#L199 for how it is used. But asm2wasm needs to be told where it can place them, with nextGlobal and maxGlobal https://github.com/WebAssembly/binaryen/blob/master/src/asm2wasm.h#L275 which by default have the 8-1000 range that works for emscripten.\n. Yes, exactly.\nOut of curiosity, are you trying to convert asm.js from a non-emscripten source?\n. I see. Yes, something like that could work too.\n. Yeah, probably we should. What's annoying though is that we do support it in the shell for spec tests, but supporting it here would require support in other places. I suppose I should refactor the code into somewhere it can be used more generally.\nAlternatively, I am considering a python script that splits up a wast into separate files, and emits a js file with the asserts.\n. Oh, at what level do you do it? Maybe I can reuse that code. I looked here but I guess that's the wrong place?\nWhat can be done for the expected-output files though? It's not clear how to split those since which outputs go to which module in the .wast is not defined.\n. Interesting, thanks for the info. A question about int64 - is the issue that v8-native doesn't have int64 yet, or that you can't represent an int64 outside of the wasm module in normal JS (or something else)?\n. I see, thanks.\nI think for the purposes of wasm2asm testing, I'll have a python script split out the wast into modules + assertions. Then I'll translate the module using wasm2asm, and let python convert the assertions to JS. Then I'll run them and concat the output before comparing to the expected output (which should handle not knowing which parts of the expected output is for which module in a file with more than one).\n. Right, yeah. I was thinking about returning a JS array of [low, high] for testing purposes here. I'm less sure about weird floats, though.\nIt seems we need to address this for polyfill purposes (which is the main goal of wasm2asm), that is, once we have a polyfill, and someone converts a wasm into some JS, and they get a return value that can't be expressed in JS, we need to do something. iow this seems to be a serious problem not just for testing, but for polyfills in real life, it now appears to me.\n. wasm2asm is no longer in development, closing.\n. Thanks!\nBtw, this repo might change license to Apache 2 + runtime exception. Any concerns there? (asking now so I don't need to track people down later)\n. Cool, thanks.\n. Thanks, the issue is that that .wast has ; but comments are actually ;;. That's a bug in s2wasm, fixing now.\n. Fixed.\n. I actually don't know git submodules that well - what do those commands do? I wouldn't want them to pull new changes from those repos, as I need to pull them manually and fix things when they break.\n. I see, thanks. How about creating an update.sh that does this? And perhaps warn from check.py if those directories are not created/up to date?\nOn the other hand, keeping it in build.sh as currently done in this pull is nice for simplicity, it would just work for most people. I guess I don't feel strongly either way.\n. Yeah, we need a proper build system anyhow, so build.sh will be going away, I hope ;)\nSo I'm ok to merge this as-is. Although, the idea of putting the info in the README instead sounds better actually.\n. Thinking some more, let's do both, I'll merge this and add it to the readme.\n. Thanks!\n. I think it's still worth doing the current binary proposal. Then our binary output can be tested with the other tools. And we can track the spec as it changes, continuously over time. It's likely the final spec will not be radically different, and so that way we'll move towards it along with everything else.\n. I did a bunch of work on this, it's in src/wasm-binary.h. It should be most of the code to write the binary format, but it's not complete, and it's written but not compiled or tested.\nI'll get back to this when I can, but if someone wants to work on this, that would be great. Getting it to write the binary format shouldn't be much more work.\n. Pull #100 landed, and there are now wasm-as and wasm-dis tools, that convert to and from the binary format, and they can parse/unparse basic stuff.\nStill TODO is to verify that the spec test suite is converted ok, and runs ok after conversion.\n. Thanks, that was partially-removed debug code.\n. Nice to see this start :)\nLatest Ubuntu LTS has cmake 2.8.12.2, but this file requires 3.0. Could we support that lower version?\n. Ok, cmake runs properly. Running make, it fails on not having -std=c++11 in the command args, I'm not familiar enough with cmake to know where to add that.\nShould we merge this in and iterate, or keep working on this pull? I'm fine either way (if we merge, I'll add a note to the readme that cmake is wip).\n. Cool, merging.\n. Yes, we should remove those. What source code led to them?\n. I see, thanks, looks like for calls and returns we look through the coercions, but for comparisons specifically we don't. Looking into that now.\n. Ok, the issue wasn't comparisons, but rather that we had the look-through logic for |0 but not >>>0. Fixed on master. Thanks again for filing!\n. Forgot to add the issue # in the commit, it was this: 2654fe23914c87afb2dd7340709db2cea5e2b047\n. We can do this in a binaryen pass, then it wouldn't be tied to asm2wasm (but asm2wasm could run it in its optimizations phase).\n. We could write a simple pass that does this, then it would be easy to do testing on it (just run binaryen-shell -offsetize input.wast).\n. Yeah, definitely not valid to do in general at the asm level. But a pass might be nice for testing, as 99% of the changes are valid to do, so e.g. it would give a good picture of binary size changes even with 1% wrong semantics.\n. Is this ninja thing good? Should I be using it? :)\n. Interesting, thanks.\n. Merged and updated the .s test outputs (newline changes).\n. Thanks!\n. lgtm with that fixed.\n. How about putting it in test/?\n. I had somewhat intentionally left AllocatingModule for a side .h, so wasm.h focuses just on the AST and not allocation. But I don't feel strongly about it. What was your thinking here?\n. Ok.\n. How can I run those torture tests locally? Would be good to have them in the repo, perhaps as a submodule, so they can be run together with the rest of the tests.\n. Ok. I think it's best to have tests directly in this repo for fast regression prevention. But maybe it's enough to add tests as we go. I added a functional test now for .int8 and .int16, 6f573309b3ee704eff76068297511934ca13009f\n. Any example? Looking at the test outputs in test/*.wast, nothing obvious pops out.\n. Thanks for the details. Notes:\n- That first block is there because binaryen functions have just a single child Expression for the body, not a list of expressions. So it has to be a block if there is more than one expression. If the .s format allows a list, we could avoid printing the block, I suppose, as an optimization.\n- We emit a topmost block when there is a return value. In the second example, there is a return value but not a branch, so we could remove the name of the block (but not the block itself because of the previous point). Perhaps we could make a pass that finds blocks with names that are never branched to, and un-names them.\n- In unlockfile, we have a return without a value. I can't think of a trivial way to eliminate that one, we would need to see that control flow goes to the right place anyhow, and get rid of the branch; then we can get rid of the block name, and then the entire block. Might need multiple passes here.\n- Looks like we can also \"unfold\" blocks in the last examples, a block is already a list so we can just embed a child block's list in it. Seems like a simple pass.\n. Sorry if I wasn't clear. In the first point, I was saying that the binaryen AST is perhaps not identical to the spec. I discussed this in issues on the spec repo, and in the end it wasn't clear that there was a \"best\" way to represent the AST. For example, the binaryen Function doesn't directly have a list, instead they have a single child, which often is a block (which does have a list). That's why there are some of those blocks.\nI'm interested in those experiments. It should be fairly easy to do them in binaryen, at least I've tried to make it easy. Basically you can write a pass in src/passes/, and then run bin/binaryen-shell and tell it to run that pass. I can document this better if that would help.\n. I wrote RemoveUnusedNames, which removes the name of toplevel (and other blocks) when never branched to.\n. (that's in https://github.com/WebAssembly/binaryen/commit/15043f71f901882203cbaf0d98a6e325ed97f56a and https://github.com/WebAssembly/binaryen/commit/4abf3e03f772348e193f00219da8b2f0baa454ee)\n. I pushed several more commits that should address most of the points raised here. I'd appreciate it if you could take a look at the current output and see if anything looks easily optimizable.\n. How did you test - perhaps you did not run the binaryen optimization passes? On your example (1), when I run\nbin/binaryen-shell -print-after 1.wast -remove-unused-brs -remove-unused-names -merge-blocks\nThen I get\n(func $_zcfree (param $i1 i32) (param $i2 i32)\n    (call $_free\n      (get_local $i2)\n    )\n  )\nThose three passes are run automatically after asm2wasm, so if you tested using that, it should also have worked.\nIf it still doesn't work for you, can you provide the full input and command you are running, and not just the bad output?\n. It's not always safe to merge a named block into a parent unnamed block, since it moves the location of the branch target. I don't see enough in your first example to tell if that's the case there or not.\nFor switch and case, I am not planning to optimize them yet since i think the spec might still change for them. But yes, that should eventually be optimized.\n. The local names should be the same as in asm.js. There, i1 etc. are int32s, while d1 etc. are doubles, etc.\nI agree it might be nice to be zero-based for comparison to the encoded files, but the comparison to the original asm.js would suffer if we rename locals in asm2wasm. Instead, we could write a pass to do that renaming, although it would actually be equivalent to converting to binary and back, so I don't think it's necessary.\n. In particular, we need this for C++ exceptions support.\n. Looks like this is very specific to that cxa_find_matching_catch method, so I fixed this in emscripten. It will now emit cxa_find_matching_catch_X for X the number of arguments, thus avoiding overloading that method.\n. Fixed, thanks for filing.\nThe lack of a parent implies a void return type, since asm.js forces a coercion if there is a return type (even if discarded).\n. As mentioned on irc, all now should pass except for (1) unresolved symbols, which we abort on (maybe we should do something else?), and (2) 930930-1.c.s which pops the same value more than once, looks like a backend bug?\n. Done, https://llvm.org/bugs/show_bug.cgi?id=25938 and added to list.\nI wasn't sure where to find the input source to add to the bug? Is there a link for just that test?\n. Sorry, I just updated this which is causing a conflict.\nBut lgtm with that resolved.\n. I guess I need to re-watch Tron...\n. Error detection improved.\nShould we just special-case $__stack_pointer? Or is that a temporary hack in the backend?\n. I pushed a temporary hack, we can remove it if we want.\n. Looks like it does get rounded as a double, to 18446744073709552000, which could be written as 18446744073709552e3, saving one character. So I guess that asm.js is not fully optimized. And I guess asm2wasm's handling of number conversions keeps the number exactly as it is, even though it should be rounded.\nThis seems technically correct, so not something urgent to fix, but I agree it would be nice to represent numbers concisely in .wast files.\n. Ah, I wasn't aware relocations could be negative. Should be as easy as finding the one or two places that look for '+' and handling things there. I can do it if you prefer.\n. Actually this hits some minor parsing annoyance, let me do this.\n. Done, this should be fixed.\n. I think I'd prefer to check in the files, so that bisection can work without depending on a remote server. What do you think?\n. For that we still need this code, just the fetch part would be in a separate file, that we'd run manually. Similar to updating a git submodule. In fact maybe the tests could be in their own git repo, and this would be a submodule, come to think of it?\n. Yeah, #57 is great, thanks. Next steps sound good.\n. lgtm. Maybe squash it all to one commit when rebasing?\n. (a push -f should work, for any update, including of squashed commits)\n. Very nice, thanks.\nJust one question about that setup.cfg file. lgtm otherwise.\n. lgtm with those fixes\n. Perhaps let's not mention ninja in the command - I assume most users won't have it already installed?\nOtherwise lgtm.\n. I'm ok to mention ninja in a comment later down, of course.\n. Perhaps try to escape your code with 4-backticks (`) before and after?\n. Ok, that makes sense. We have support for parsing emscripten asm.js output, which is a subset of asm.js - it never uses for loops, for example. It should be easy to add this support though, if it would be useful.\n. Ah, out of curiosity, what code backend is this?\n. Interesting, thanks for the info.\nOk, I just added for-loop support. I didn't test it beyond a simple testcase (see the commit), so let me know if you hit any issues\n. Great, thanks for confirming.\n. That doesn't look like valid asm.js? It doesn't have arrays or strings.\nBtw, please use escaping (4 backticks \"\") to make code easier to read.\n. Where is thatwctombfrom? I see it intest/emcc_hello_world.wast, where it is in unoptimized form (there is an optimized version withO2in the name, but it lacks that method - might have been inlined).\n. Thanks!\n. I am leaning towards checking an env var for LLVM. If it's present, we'll assume it's a stock/vanilla LLVM, and use that incheck.py`. Then on travis, we can download an LLVM+clang build from the waterfall and set the env var to find it.\nWe also need emcc, so we can add an emscripten submodule.\nThoughts? @jfbastien \n. But CC and CXX are set for clang or gcc. This would be a secondary compiler.\n. No, I mean, look at .travis. It already uses CC and CXX. We need an additional LLVM build aside from that.\nBut maybe we don't need an env var. I can just make check.py (or update.py?) grab LLVM+clang from the bot, put it in a dir, and use that with emcc. Could that work?\n. Yeah, that sounds reasonable.\n. I don't currently see a need for more.\n. This is all implemented in #112, so we can discuss details there.\n. Thanks, fixed.\nOne possibly tricky issue is ignored return values. Since .s files no longer define imports, we must detect the type implicitly. But if an import has a return type, if might be ignored, in which case we will think it's a void function. Not sure if that's a problem or not. cc  @sunfishcode \n. Oh right, yes, that should be fine. Even if the return value is ignored, it'll still be i32.call, right? Then that's fine, s2wasm reads the type of the call node here.\n. Yes, still changing I think. But also, I think it's valid either way? The tableswitch could always branch to an enclosing block. So that code should be valid in the current spec.\n. Oh right, thanks. Ok, this was actually a bug in the tableswitch logic in general. Fixed now.\n. Oh right, thanks, the default is separate. Fixed now.\n. Thanks again, fixed.\n. Fixed, thanks. Was just a typo in using the proper type in the s2wasm parser.\n. Fixed, thanks.\nInteresting, I guess the spec tests don't have this, otherwise it should have been caught...\n. Hmm no, I do see this in conversions.wast.\nI think the issue is that check.py just runs the spec tests and looks for failed asserts, it doesn't verify that the printed wast is correct.\nAnyhow, we now have testing for this through some of the .s tests.\n. lgtm, assuming check.py passes and @jfbastien.\n. check.py looks good, so just waiting on @jfbastien for feedback. Looks like there is also a merge conflict now though.\n. Perhaps the submodule move is necessary for a later step @sunfishcode has in mind?\nIn any case, @sunfishcode feel free to resolve and merge.\n. Do we still need that experimental submodule for anything, @sunfishcode and @jfbastien ?\n. Right, ok.\n. Overall lgtm. What is \"lkgr\"?\n. Merged together with code to ignore those visibilities in s2wasm, and the test outputs.\n. One more thanks, this is fixed as well. Was some old code that just handled params there, I made it use the new more general logic.\n. Thanks!\n. It's hard for me to understand this report. It would be very helpful if you provided\n1. The input code for this (asm.js if asm2wasm, or something else if some other tool, etc.)\n2. The command used to generate the code\nFor example, without the command, I can't tell if this would have been fixed by LLVM optimizations.\n. lgtm. there is a merge conflict, though.\n@jfbastien , should we wait to merge this for that bot update?\n. Merged.\n. Yes, I think that could easily be optimized in s2wasm. But it does seem like the backend would be the better place. @sunfishcode, is this just not yet optimized, or is there some bigger issue here?\n. Ok, in that case it sounds like there's nothing to be done in binaryen, so closing.\n. Thanks, RemoveUnusedBrs was not handling values. But it definitely can, as you say, I added this now.\n. I don't see if_else with ne as an argument in that output. Just a br with one.\nIt would be very helpful if the testcases were complete, btw - to check this, I had to embed in a file and write some code around it. I might have written something there that makes my result not match yours. It is always better to have the simplest, most direct steps so that I can see what you are seeing.\n. Based on an email testcase, this looks like an issue at the asm.js stage, and has been optimized in emscripten.\n. lgtm, please just rebase to get rid of the merge commit.\nSo what is going to be the procedure for using this? I.e. when will we do a force-update?\n. Got it, thanks.\n. lgtm, but lol, it reports failing checks right now on this pull, even without doing anything?\n. lgtm squashed\n. lgtm. failure looks unrelated.\n. Failure is maybe #10 or #16\n. If that error turns out to be gcc-only, then maybe we are actually hitting a weird gcc bug.\n. lgtm except for that last question about those 2 methods.\n. Can @FUNCTION be simply ignored? what information does it convey?\n. It's not actually disambiguating anything, is it? I guess it's just for clarity? Or is it due to a backend internal thing?\n. Those commits should make all the tests pass.\n. And travis confirms. If my commits lgtm feel free to merge it.\n. I see.\nJust to confirm, it's not possible to have both \"foo\" which is a global, and \"foo@FUNCTION\" which is a function, correct? (Otherwise s2wasm would need to remember where it removed \"@FUNCTION\".)\n. Wait, what does that code do? Run wasm-as on stuff? It's not ready yet! :)\n. No, it aborts on \"hello world\" :)\nI need to do some other refactoring. This pull is mainly to finish getting it building, as I don't want to have a long-term side branch.\n. Actually no, the text as it stands is correct. This tool assembles a .wast (s-expression wasm text format, and eventually the official wasm text format whatever that will be) into a .wasm (binary wasm format, in current v8 proposal).\nIn other words:\n- wasm-as: .wast => .wasm\n- wasm-dis: .wasm => .wast - not yet implemented\nThese are parallel to llvm-as, llvm-dis. They translate between the text and binary formats of the same thing, either LLVM IR or wasm AST.\nOther tools convert to/from external or unofficial formats, like\n- asm2wasm: .asm.js = .wasm (well, right now it emits text, but that should change)\n- s2wasm: LLVM .s => .wasm (again, right now it emits text)\n- etc.\nA sad point of confusion is that .s is LLVM's .s format, while wasm-s-parser stands for wasm-s-expression-parser, which might trip people up. Suggestions for a better name?\n. What is \"CRTP\"?\n. Thanks, got it.\n@mbebenita: this looks very nice to me. But perhaps it can be even better as @jfbastien suggests. I still need to think more on that, but I trust he's right.\n. Also need to update the .s files in tests/dot_s.\n. I pushed a commit that updates s2wasm. It also updates the llvm_autogenerated tests, and the output looks correct to me, so I think this implements what we need here.\nStill to do: update dot_s/ (which I'd rather not do as I'm sure i'll make mistakes) and the torture tests (not sure how we coordinate that).\n. Sounds good. I added an option to run check.py without the torture tests, which is useful locally to see nothing else is broken.\nPerhaps we should actually default to disabling torture, until they are fixed? Then travis will pass.\nOtherwise this looks good to land to me. Unless someone wants to look over my commits here first.\n. Yeah, there was a hack for shared labels, it's removed in that commit.\n. Disabling torture tests for now, I'd like to see if the new tests pass (they pass locally).\n. @jfbastien, are you ok with this merging together with disabling the torture tests for now? (then when they work again, can just update the boolean at the top of check.py)\n. Ok, leaving torture tests on.\n. Got it, thanks. Maybe worth documenting in the readme? Or i guess it's just for us devs, nor regular users.\n. In addition to those updates, I noticed a few bugs and fixes those. There is also now verification of the output of text->binary->text on the initial set of testcases, and it looks pretty good, so this is in fair shape (but not tested on spec test suite yet).\n. Travis is sad.\n. lgtm, nice!\n@jfbastien, did you want to take another look?\n. Cool, merging. We can do improvements as followups.\n. Ok, this is good to go I think.\n. There is now a second route for testing correctness of the LLVM WebAssembly backend, in addition to those s2wasm executions just mentioned. #112 adds testing of the full toolchain path, using emcc + plain vanilla LLVM (downloaded from the wasm waterfall), which compiles C programs and executes them.\nOnce we have libc working (need full byval, vararg etc support in the wasm backend first) then those tests can use normal printf etc. For now, they use emscripten EM_ASM as a hack, but it's already good enough to check that outputs are correct.\n. Yes, this is a current limitation. It was simpler for now, but we should fix this, and will need to fix this in order to handle general binary inputs and not just binaryen's own outputs.\n. More details are needed in bug reports like this, specifically: what input are you providing? What is the output you see, and what is wrong with it? It's usually better to just provide these details in the initial report.\nwasm-as is tested in check.py, with example outputs in test/*.fromBinary. Those have imports which look ok to me.\n. I don't understand how changing the order of those two fields would solve something to do with imports not being named?\n. Bug reports like this would be more useful with details. What error do you see? What platform? Which revision?\nasm2wasm is tested in check.py, which passes - you can see on the travis-ci link on the main binaryen page. It also passes for me locally.\n. I saw the PR for this, let's focus on that and close this issue, to avoid duplication.\n. Thanks, I saw your pull for this #116, lets close this issue and focus on that.\n. @jfbastien: i'm not sure what to do about downloading the waterfall build.\nFirst, it's 160MB - i guess it contains more than just LLVM, which is all I need here? Is there a way to get just LLVM+clang binaries, and just for linux?\nSecond, is this just a normal archive I can unpack with tar -xvf? (I get an error, haven't looked into it yet.)\n. Hmm, the unpack looks fine on travis... perhaps I had a network error when I downloaded the file or something locally. A smaller download might help that I suppose.\n. @jfbastien, @sunfishcode: are there perhaps llvm waterfall links that would contain just a build of latest llvm+clang, for linux?\n. Looks like bot build is 64-bit? Fails to run on my 32-bit machine.\n. Ok, this looks good. This uses vanilla llvm from the waterfall, plus emcc from a submodule, and it can build and run (in node) the wasm-backend programs. @jfbastien , thoughts?\n. Only thing I'm not happy with is that it only works on 64-bit linux.\n. Some improvements, emcc vanilla support no longer requires you to set an env var. Just use a vanilla llvm, and it will use the wasm target automatically.\n. I don't quite understand how your untar works - what is the subdir it expects to find the output in? I tried the name of the target dir, and I tried the name of the subdir inside the tar, and neither work. (I can't test this locally, so I'm relying on travis here, which is making this annoying.)\n. (see travis output for the problem)\n. I tried that, but no luck: https://travis-ci.org/WebAssembly/binaryen/jobs/102881709\nWhen I open that tar locally, I don't see wasm-install. I see llvm-install. But I tried that in a previous push and it didn't work either.\nBtw, I'm not sure why untar needs to be told the temp dir, which is what it fails on? Seems like that's under its own control anyhow? Again, I feel like I don't get the design of that method.\n. Looks like llc and other llvm tools are no longer in the waterfall build? that breaks this pull.\n. Ok. I believe emscripten also needs llvm-link, llvm-as, llvm-dis, llvm-nm, llvm-ar, opt in addition to llc.\n. I still can't get untar() to work. See the last commit. It seems like there are only two options for what to pass there (the target dir I want to emit to, or the base dir of that), and both fail :( What am I missing here?\nIf it is too complicated for us to design untar() and use it in this pull, how about not using it here, merging this, and as a followup finishing untar() and using it in this code?\n. Thanks!\nBut this seems to always unzip that huge archive, though - the code you removed tried to avoid that. My hard drive can't take this much pain on a constant basis :)\nI also think it's worth printing the \"downloading\", since it can take a long time. The user should know what's going on, and not just think it's randomly hanging.\nFinally, the failures on travis are due to \"warning: could not run vanilla LLVM from waterfall: [Errno 2] No such file or directory, looked for clang at /home/travis/build/WebAssembly/binaryen/test/wasm-install/bin/clang\". That looks like an untar failure? The file should be at that location. It's there locally, and on some of the travis results, but not others.\n. I rebased on master and now the error is more consistent. So it might have been that last push to master you did.\nAnyhow, ok, let's go with what I had before. We're trying to do too much at once in this pull, I think. I'll merge that, and we can improve things to use shared code later.\n. But I also need to head out, so later today...\n. Cool, merged.\nSounds good about the smaller size.\n. The current implementation matches the v8 spec document, which I think makes more sense to do. Since we may have multiple such implementations and want to verify them against each other. If we want to change this, let's change the spec first. So I don't think we should do anything here in binaryen currently.\n. Ok good, then let's merge this.\n. Are you sure? My understanding is that we can add an import to the table.\n. Do you mean the implementation, or the spec?\nI believe binaryen does what the spec says (but I could be wrong on that). And I think binaryen should follow the spec and not another implementation (which might have a bug).\ncc @titzer \n. I'm sorry, I still do not understand. There is \"the v8 binary spec\", and there is \"the v8 implementation of that spec\". Which of the two do you mean, when you say \"v8\"?\n. I don't think we should follow the v8 implementation - we should follow the spec (implementations can have bugs, and are not meant to be readable as specs are, etc.). If this is a spec bug, let's fix that. @titzer is already cc'd so lets see what he thinks.\nThe spec uses \"function\" to refer to all types of functions, including imports, in multiple places. That's why I think it's clear it allows imports to be in tables.\n. Thanks, this looks like a good start. You also need to add code to read the value, lower down in visitBreak in the same file. Then the failure on CI should be fixed.\n. Looks perfect, thanks!\n. Can you point me to a specific local where you saw the problem? Otherwise I need to go looking at every single one in search, while you already found the problem.\n. Thanks, now I see. Fixed in 960043a359046b1536c75aeca2f7092e15714d45\n. I guess I'm not sure what \"bit 4\" means. Is it \"the fourth bit\", in which case 1,2,4,8, so 8? Or is there a \"bit 0\" which is 1?\n. Cool, thanks @binji and @JSStats.\n. I assume the movement didn't change anything, and the indentation change likewise? Then lgtm.\n. Well, there are 2 targets - so that part looks right?\nThere is also a default, and this is indeed lost in the binary format. But reading the spec document, I'm not clear on how exactly the default is encoded?\n. @titzer: is it possible that handling of the default in tableswitch is missing in the v8 binary format document?\n. Thanks, now I see. Fixed.\n. Makes sense to me.\n. Thanks, there was some bad global state in the processors. Fixed.\n. Thanks, we forgot to mapLocals if there are params, but no locals. Fixed.\n. I copied those values from the spec, and double-checked them now - they look right to me in binaryen. Perhaps a mistake in sexpr-wasm-prototype? Or the spec changed? @binji \n. Why did the known failures change? Waterfall update?\n. Otherwise looks very nice!\n. No, I just opened an issue about triaging them :)\nIf no one looked into them yet, I guess we can leave figuring out the new passes for proper triage anyhow.\n. The v8 document specifies the condition is at the end, so that's what binaryen is doing.\n. Yeah, those two don't match, but (1) binaryen should usually follow the binary spec, not an implementation of it, and (2) as @sunfishcode, there is reason to believe that what the binary spec says is what should be.\n. Ok, cool, then nothing to do in binaryen, I think we can close this.\n. As discussed in the issue, this change looks wrong from the perspective of the spec doc, which has the condition at the end.\n. I am having a hard time understanding what this does from just the code. Can you please explain the background and what specifically this fixes or adds?\nIn particular, \"Rework\" in the title suggests this is a refactoring, but it looks like more than that?\n. Thanks, that's very helpful.\n. This makes me worried about portability. I just don't know enough about this.\n@jfbastien, what do you think?\n. Btw, llvm has this. Maybe we can take that code?\n. Thanks, fixed.\n. Personally, I don't think there should be a column limit ;) But no strong feelings.\n. This might be fixed by e81ed44795bcb3e3c181177009cb6390d1b0a555 on the binary-spec-tests branch.\n. 1. The fake_return block is due to the binaryen ast not having return. Last I heard there was still some uncertainty about it being in the final spec, so for now we emulate return. If we are sure return is here to stay, I can remove that.\n2. The second block is for simplicity in building the ast. It's optimized away if you run -O, for example. Perhaps we should run the relevant passes automatically in s2wasm?\n3. The last is because the binaryen ast has a single child for loops - to make transforms easier, less redundancy (only one node has a list of children). But it accepts as input the short form of course, and I made it emit the short form as well, so that last one is now gone.\n. 1. Ok, sounds good to add return, then. Done.\n2. That should also fix the toplevel loop.\n3. It did. But wasm-as/wasm-dis changes other stuff too, like names of variables, adding nops for e.g. br values per the spec, etc.\n. Ok, that commit should add support in s2wasm for the new syntax.\n. Fixed alignment power issue.\n. Looks good on travis.\n. Great, looks like we can close this.\n. And it's safe to remove support for .align everywhere - p2align replaced all 3 uses (load/store, functions, globals)?\n. Ok, if it's theoretically valid, I guess it doesn't make sense to remove it from s2wasm.\n. Please add testing for this, a pair of .s and .wast files in test/dot_s/.\n. Great, thanks!\n. \"Think different\"\n. I agree basically all sizes could be LEB128.\nExcept for function sizes - as @JSStats says they may be moved OOL, but even if not, when writing we need to go back and set the size afterwards, and with LEB we don't know how much space to reserve. Not a big deal - the writer could do an extra copy - but the overhead of just using an int32 seems low.\n. I'm also adding the module and base for imports (i.e. name = module.base; name was already present).\n. Also adding the option to export a function by a different name than itself. If exported, we read a second string after the first.\n. Power of 2 memory does not allow memory size 0, which some spec tests need. Making it be power of 2 offset by 1, and \"0\" means actual 0.\n. Well, it was useful to hack things to get full spec test coverage quickly. When there is consensus on the page size approach, we can change to that.\n. Meanwhile I now have the full spec test suite passing through the binary format - that is, each spec test passes after being converted to binary and back - so I don't think I'll need to do any more divergence.\n. Just where I saw a problem. Not sure if that was all of them. We should definitely make sure to look at this eventually.\n. Also added a start section for the new wasm start property.\n. Seems trivial if I understood you properly. Pushed a commit and rebased.\n. This is awesome!\n. Do we need this? Shouldn't aliases be resolved by the backend already?\n. I guess I'm not clear on if this is something we intend to have forever in the .s format? cc @sunfishcode \n. I guess that's ok. Still waiting on @sunfishcode to hear what the plan for aliases in the .s format is.\n. No problem, just wanted to hear what you just said.\n. Yes, patch looks good.\n. lgtm otherwise. please rebase before merge.\n. Link?\n. That doesn't look like a vanilla LLVM error? It's failing to run asm2wasm, because CMake failed so nothing could be built (and asm2wasm is just the first it tries),\n```\n$ cmake . -DCMAKE_C_FLAGS=\"$COMPILER_FLAGS\" -DCMAKE_CXX_FLAGS=\"$COMPILER_FLAGS\"\nCMake Error at /usr/share/cmake-2.8/Modules/CMakeDetermineCXXCompiler.cmake:43 (MESSAGE):\nCould not find compiler set in environment variable CXX:\nclang++-3.6.\n```\nIt seems to happen randomly now and then. Some travis bots are just bad I guess?\n. Yes, but please rebase/squash.\n. I don't think you can redirect a pull on github. Just rebase locally to master and merge.\n. Oh, I didn't notice it wasn't to master. Feel free to cherry-pick the commit onto master.\n. Why are the memcpys necessary?\n. Oh, it's UB? I thought unions were \"the way\" to do it? TIL :)\nIf so, then actually this might be the cause of the weird intermittent bug? We might fix two things at once if you make this use the Literal.reinterpret* methods from wasm.h, and make those methods do a memcpy internally, which they don't right now.\n. Looks good. We can also use that in Literal.reinterpret* as mentioned, I'll do it as a followup.\n. Updated first comment too.\n. Oh, now I see what you mean - those || should be && (only do payload comparison if both are nans). Fixed.\nYes, the spec repo lacks a test for this, or it would have blown up here.\n. Perhaps my confusion was that I assumed that assert_equal did the same as normal wasm semantics. Ok, fixed, and I made assert_equal use the payload.\n. Right, thanks. And is that full bitwise match of every single bit, or is it enough to check the payload + sign bit?\n. Ok, but somehow I don't see it as equivalent to do a full bitwise comparison vs. sign bit + payload - we have a bug somewhere I guess. Specifically, in spec/nan-propagation.wast I see\nCHECKING: (assert_return (invoke f32.reinterpret_i32 (i32.const 0x7f876543)) (f32.const nan:0x76543))\nAnd the printable values are\nseen (f32.const nan:0x76543), expected (f32.const nan:0x76543)\nwhich looks fine, they are the same. But the full bit patterns are\n0x7fc76543 : 0x7f876543\nThe payload mask we are using is 0x3fffff, so their payloads are identical, and their sign bits are identical. But they differ in a bit that is neither the sign bit nor in the payload? What's going on here? :)\n. So what should we do? If any floating-point operation can cause it, then it's ok for it to be there I guess? Or are you saying that there should be no floating-point operations performed on that value?\nAnd what is \"operation\" here - anything that produces a float, like add or load? We do a memcpy in bit_cast and then load the float, so it seems like that would set it, if so. Should we be un-setting it?\n. Thanks, I'll debug to find out where it gets set.\nBut is it truly possible for an implementation to avoid this? Can't some compiler optimization (or lack of one) add a floating-point operation that sets the bit? Are you saying that implementations must unset the bit when they aren't sure their compiled code didn't set it?\n. Sadly no, your fix adds the silent bit to the payload, which makes the test fail properly - now it is testing all the bits. But that still leaves open the question of why the bit is set.\n. Looks tricky to avoid. The bit is set when I have\nfloat   reinterpretf32() { assert(type == WasmType::i32); return bit_cast<float>(i32); }\nbut not when the assert is removed,\nfloat   reinterpretf32() { return bit_cast<float>(i32); }\n(!) I suppose the assert might prevent inlining?\nSince this looks very dependent on compiler behavior, should I just always unset that bit? Or are there cases where it is valid for it to exist?\n. I am, yes.\nSo any compliant implementation that wants to run on x86 must unset the bit all the time? I think we tried to avoid x87 with -msse2 -mfpmath=sse but that's already in our cmake file and it doesn't fix this.\n. This seems to make it quite hard to write a simple wasm interpreter, though? Is that not a concern?\n. I see, thanks.\n. I still don't see how this is possible in a reasonable way. I wrote a patch to store integers in literals, so we pass them around, and we only convert to float when explicitly required. But this is not enough: If the signalling bit is unset, then just bitcasting the integer to a float (@jfbastien's utility uses a memcpy) sets the bit. So just the bitcast in preparation for doing some float operation is already game over.\nThe only options seem to be\n1. Use software floating-point \n2. Manually unset the bit after\n?\n. @sunfishcode: In #171, I still see you doing a bit_cast in getf32 for example, as in https://github.com/WebAssembly/binaryen/commit/c27d465887f41ade685ceda91294796a43c9ed40 . That will still set the signalling bit as mentioned in my last comment, so e.g. doing an f32.abs will set it.\nThere seems to be no way to win here :( unless we do one of options 1 or 2 mentioned above (software floating point, or manually unset the bit), or 3: find a way for bit_cast to not set the signalling bit.\n. Oh, for all the other operations, it's ok if the bit is set? Is it deterministically set, and set in the same way across archs (no difference on 32-bit)?\n. Ok, great, thanks. I'll just convert those three to use bits then.\n. Ok, thanks to @sunfishcode's assistance I think this is now good to go.\n. I talked some more with JF now. We agreed to land this now, and as a followup do a further refactoring as he suggests. Namely,\n1. It should be very rare to get the actual i32 or f32 value etc. Instead, the Literal class would encapsulate things like Literal.sqrt directly.\n2. Then the code e.g. in the interpreter would be a lot cleaner and more C++ey, basically it would call methods on Literal.\n3. And it would also avoid unnecessary returns of values, avoiding the x87 issue as well.\n. Opened #177 for the followup.\n. This isn't done (we'll need a bunch more binary format changes to get the spec tests passing) but I'd like to merge it as I don't want to work too long in a side branch. Anyone want to review?\n. Ok, after a lot more fun here, I have most of the tests running, up to switch.wast (alphabetically).\nThis now has a bunch of fixes elsewhere in the code, so I'd like to merge this ASAP before continuing or taking a break.\n. ...aaand now they all pass.\n. I doubt anyone wants to review this right now, so merging. If there are fixes we can do them as followups.\n. Fixed by your pull request.\n. Nice, thanks!\n. Hmm, why does travis show torture test problems?\n. Ok.\n. No need to squash. But there is a merge conflict.\n. But that assert should never be hit, since we avoid reaching that code if the size is 0. Unless we have a bug and you have a testcase showing it?\n. Good question about testing. It seems like we have to either enable wasm-as to emit unnamed functions, or to have tests with the actual binary format. But as the binary format is still very much undefined and changing, the second option sounds bad.\n. Also fixed, and again I didn't add a test since looks like this will be tested in the spec tests anyhow.\n. Fixed. I didn't add a test since looks like this will be tested in the spec tests anyhow.\n. Thanks, fixed. Our call_indirect code only took into account the reverse order of operands for the call operands and not the target itself.\n. Yeah, I guess we do accept this. Is it disallowed by the spec, though?\n. Thanks. Ok, let's fix this.\nBut first, parsing.h is also used by s2wasm. @sunfishcode, is -+nan a valid value in the .s format?\n. Fixed.\n. I am still totally baffled by the minSize thing. Why it is needed, and why 4096 is a magic number?\n. Sounds good, maybe add a comment with that?\n. One does not just bit_cast into Mordor ;)\nSee #152, when I tried to do this, I got signalling nan bit errors on 32-bit. Still figuring out what to do in that pull.\n. After the recent merge, I think that's no longer relevant?\n. I worry about having runtime decisions on pre or post walking. Perhaps we can have 2 classes?\nPerhaps PreOrPostWalker (or two classes) could reuse the RecursiveWalker?\n. That sounds promising, then it would all be at compile time?\n. Oddly, this broke gcc on my machine (4.8.2), fixed in 6dab47590562df6e542ff3f0c105db138b8f4fd9\n. Closing as this was implemented elsewhere, after being motivated here.\n. Will this output parse ok in the spec interpreter? If yes, then it should already be re-parsable back into binaryen.\nThe AST printing can't avoid printing empty names, because e.g. a break needs to refer by name to somewhere. Unless you mean it would have a number there?\nOverall it sounds fine to\n1. Have a pass that makes all names numeric (strip-names?).\n2. Make the printing emit as concise as possible output that is still spec-compliant when names are numeric.\n. Ok. I hope you don't, though - we parse everything in the spec tests, and it has examples of those things. But yeah, might be something missing.\n. Any updates here?\nI had another thought meanwhile. Maybe not relevant if you're already close to done. But perhaps we should move printing out to a pass, which seems cleaner anyhow. Then we can have a print pass, and a printStripped pass. Or maybe stripping would be an option in a single print pass. That way, printing is entirely encapsulated on the side, and this would require no AST changes.\n. Looks good, however, the travis errors look real. This fails for me locally: bin/binaryen-shell test/spec/func_ptrs.wast\n. Yes, looks like we should have an onError for that.\n. Pull opened for this, closing here.\n. Manual. But you can update their outputs automatically with auto_update_tests.py.\n. I had some more general thoughts about this.\nFirst, since the stack comes after the static allocations, all the size does for us is potentially increase memory. But the program will need more memory anyhow for sbrk/malloc. And probably the memory size should be arriving from the LLVM backend anyhow? @sunfishcode?\nOverall, the program's runtime/startup code might do the following:\n1. Receive info on where static allocations end (staticBump in s2wasm the metadata, the driver can forward it).\n2. Receive the location of the stack pointer (also in the metadata).\n3. Instantiate the wasm module.\n4. Decide where to place the stack, what size to make it, etc. This might be done at runtime, and fits in with making everything as relocatable as possible, which is an idea @jfbastien and I were talking about. It's also how Emscripten does this now.\n5. Write the stack pointer's initial value, chosen in 4, into the stack pointer's location in memory.\n6. It can also set up the rest of what it needs for memory, like sbrk can be right after the stack, etc.\nThis seems more flexible, does less work in s2wasm, and is consistent with Emscripten.\nThoughts?\n. Oh, are you just looking for something temporary to replace that appended code? I'm fine with something for that. But I'm a little worried this will help here but then need to be replaced later with something better, and tests will break during that change, etc.\nIn any case, I think we should be able to support both a simple fixed stack if that's useful for you, and the flexible runtime approach that Emscripten uses. Perhaps the option here could do nothing (except return the location of the stack pointer in metadata) when not set? Then the flexible approach would do that.\n\nMostly I want this to be able to test LLVM independently of all the emscripten machinery, it doesn't have to be the only or final mechanism.\n\nSure. I was saying that I think it makes sense to be consistent with what Emscripten does here, both because the consistency is nice for itself, and also because what Emscripten does is the flexible approach of letting the runtime set this, which should be easy for other things to use as well.\n\nAlso what do you mean by startup code?\n\nI meant the outside JS code. The code that loads the wasm module, connects it to the rest of the world, etc.\n. 1. I think we still need to create the stack pointer, even with this option off, as we do before this pull. The only thing I think this pull's option should add is to create a segment in memory for the stack and to bump the initial and max memory sizes.\n2. Given that, how about calling this option \"create stack\"? Or \"allocate stack\"?\nAs a followup, I think we'll also want a \"set memory sizes\" option to set the initial and max memory sizes, if they aren't arriving from the LLVM backend. I can do that.\n. Hmm, I don't see much harm in always creating the stack pointer itself. Since it's tiny. And trying to optimize it out means the code will never have a stack, but we might need one in linked code (JS today, or other wasm some day).\n. I see your point, yeah.\n. lgtm with that last variable renamed, and squashed.\n. Nice, lgtm. Please just squash before merging.\n. lgtm to merge this for now. but i have no idea what's going on here :)\n. cc @jfbastien and @sunfishcode who maybe can figure this 1337 c++ stuff out out\n. We'll need a followup issue for the interpreter actually calling the start method. I assume the spec repo will get a test for that eventually.\n. As mentioned above, I actually don't even understand what this pull request does. Please explain when you get a chance.\n. This seems confused to me. Maybe it's me that is confused. There is both a _start function, and a startFunction? Your code creates the former and makes it call the latter? And the former is marked as the wasm \"start\"?\nThat seems very convoluted to me. Why not just mark startFunction as the wasm \"start\"?\n. (I'm fine to iterate on this after the merge, but in the future, how about not merging while there are outstanding questions?)\n. I manually pushed the remaining relevant stuff from here to master, after #187 landed.\n. See #196\n. Looks like this duplicates some of #184 which was filed earlier?\n. lgtm if tests pass\n. Passes locally, looks ok on travis. Review comments welcome as usual.\n. There are changes here not in the previous merged pull, like binary format changes.\n. lgtm if check.py passes\n. Good point. Sorry about this.\nMy main problem in fixing it is that I'm not sure how much error handling we want here, nor what is an error we want to handle vs. not. So the line here is fuzzy in my head, not just in the code ;)\n. I guess I don't feel strongly about either of your comments. I'm not sure why a particular rule here is better than another (e.g., why shouldn't fuzzer testcases be able to hit assert?). So I'm happy to go with whatever you all agree to.\n. Works for me locally. If lgty then feel free to squash into yours and merge.\n. Did you get that info from the current build logs? I'm not sure what to read there, I don't see TSAN errors but just it looks like it halts?\n. Weird. Should we just merge this? It's obviously better than the current code.\n. cc @jfbastien \n. Added constiness.\nAlso added a commit with float unaries. todo: binaries..\n. Refactoring complete.\n. Looks ok on travis. Should probably squash though since I have a fix commit at the end.\n. Addressed the review comments.\n. Cool, squashed and pushed.\nI agree more testcases for corner cases would be good. The spec repo already has a lot, but honestly I didn't look carefully to see if they are complete or not. @sunfishcode has been interested in that though I believe.\n. Anyone want to review?\n. Ok, updated for that comment, and merged.\n. Should be good to go now.\n. No comments, so merging.\n. Why are there new failures?\n. Why are they new? I thought the torture test set was fixed? Or are they new to not crash the backend?\n. Thanks!\n. Yes, that should pass.\nDoes the output mention any warnings? (can grep for warning in the output)\nAre all submodules up to date? (git submodule update)\n. Those just mean fewer tests were run. So it's very strange that that fails.\nWhat OS are you on?\n. 64 or 32 bit?\n. That should be ok. And the Travis CI stuff is 64-bit ubuntu as well, and it passes, so I'm puzzled why it fails for you.\nTry very latest master, perhaps, if you haven't already?\n. No, that is just when we change the code in ways that affects test output. What you are seeing appears to be a bug.\nIf it's still a problem after the update, can you create a gist with the file outputs in the breaking test? Then I can compare to what I and the bots get.\n. Can you please add the code files too? It should generate a.wasm.js, and possibly some other files beginning with a.wasm.* (look at the dates).\n. Should be good to go, comments welcome.\n. To fix the unrelated cout/cerr issue, I realized that we don't even need the --print-after|before flags now that we have --print, which is better since you can put it in any order you want. Bonus commit removes them.\n. Also added a commit which overloads in std. This lets us do that one line thing.\n. lgtm aside from that one question, and something seems wrong on travis.\n. The travis problem looks weird, didn't you update that test? I'll try locally.\n. I think it's a stable sort issue, I see the errors locally. I might have a fix, will merge with it if so.\n. Pushed with fix.\nThanks!\n. This bumps the waterfall. @jfbastien, is that ok?\n. Travis says so, and looks good locally.\n. It might be nice to add options for passes, but I don't have a good idea of how to do it. Meanwhile, though, look at the bottom of Print.cpp where we have static RegisterPass<Printer> registerPass(\"print\", \"print in s-expression format\"); - we can register multiple passes in a single file. There could be print-minified for example.\n. Is this still relevant, or should we close it?. Is this a temporary thing? If more permanent, it should be tested.\n. Thanks!\nWe didn't merge that test update yet, I think.\n. This is possible after #211 which fixed switches.\n. Or post-February..? ;)\n. I'd rather not have to support both - it would be a lot of extra code, basically each ast handler would have ifs and multiple code paths.\nSince the wasm spec is moving to postorder, I think we should just land this now, as in any case we have not had interoperability with other tools.\n. @JSStats: there isn't a full postorder spec yet. This just moves us towards that general goal. That's also why it's not complete, as you pointed out. But it passes the full test suite, so it's already a good checkpoint I think.\nI see no reason not to merge this now, since nothing depends on binaryen's binary tools yet? Am I missing something?\n. There have also been preorder and postorder branches in this repo for a while, for experimentation with this. Testing things like decode speed, I also see benefits to postorder, like @titzer (different sizes though, but that's probably due to measurement method).\nThe one downside to postorder (or postorder + something else for control flow) is that it makes the raw binary 1% or so larger, which is expected (since in preorder we an avoid end markers for some control flows). However, testing on real-world code like Poppler and BananaBread, that vanishes and even reverses after gzip (and lzma and others). I don't have a good explanation for that, but it does suggest that code size is not a serious problem for postorder.\n. Ok, merging this in. Its just a small step towards postorder, but since it's a clean refactoring and passes the test suite, and there is consensus to move towards postorder overall, it's helpful to merge it now.\n. This will break tests unless we also update the emscripten submodule. I can do that here.\n. That push should do it. Note I returned BINARYEN to pointing to the root, not the /bin dir, as it was before, I didn't catch that in review.\n. It's likely we'll need additional non-binary tools from binaryen, like script wrappers for JS engines and so forth. And it's consistent with EMSCRIPTEN_ROOT. It's true that LLVM_ROOT is a little different, perhaps that should have been renamed way back.\n. Probably fine, but what version/branch did you use to build it?\n. No, that should be fine, it's what I do.\n. wasm.js only runs pure wasm in an interpreter. And wasm itself doesn't have DOM integration. However, a compiler can allow calling into JS which can them manipulate the DOM (e.g. emscripten does so using EM_ASM blocks).\n. Yes, for now you need to call out of wasm to do DOM stuff, which can be done by calling an import. That's how emscripten does EM_ASM.\n. If it's easy to support that, I think we should. However, the parser was written to support emscripten output, which is easier and faster to parse than general asm.js, and the parser does depend on that. I'm not sure how easy it would be to generalize things.\n. Might be the simplest thing is to manually add a ; there, and there might be a few other minor things you need to fix up.\nBut in general, there is a problem here - asm2wasm assumes emscripten input for other reasons. In particular, wasm does not have globals, but asm.js does, so asm2wasm maps them into memory. But it needs help to know where is a safe place in memory to do so. For that reason, asm2wasm works ok when run in integration with emscripten, but would not work on older emscripten outputs, nor on non-emscripten files. Unless they happen to not have globals.\n. Oops, this is not yet done.\n. Ok, this fixes the issues we saw with memory, @dschuff, @bnjbvr, @lukewagner.\nI also uploaded an updated build of hello world to https://github.com/WebAssembly/build-suite/tree/master/emscripten/hello_world\nAlso a C++ hello world with iostream at https://github.com/WebAssembly/build-suite/tree/master/emscripten/hello_iostream , which is much larger.\n. Working on it in #224, but there is a bunch of stuff in the latest changes, plus I found we weren't doing validation testing 100% correctly, so this might take a bit.\n. Anyone want to review? This updates us to the if-else stage of recent spec changes.\n. Unless it's urgent, how about just implementing rotate? I worry about having multiple branches in flight where some disable core spec tests like i32 or address, we could get into confusing situations.\n. @jfbastien: I apologize for temporarily disabling flake8, but I just can't figure out how to make it work on my script, and it's blocking me.\n. I see no concerns, so merging.\n. We also need something on the other side - the imports in the wast need to match up to the flattened form. We could make a pass for that, or do it in asm2wasm, not sure which is best.\nAlso, because this needs changes to the wast, I don't think it can be only in the v8 code path. iow, either we flatten for everyone, or for noone, if they all use the same wast.\n. Based on offline discussion it sounds like we don't need to flatten anymore, but I think we do still need the v8 part here to find the right object?\n. The commits can be squashed into 1, I think?\nAlso, I don't think we need the wasm.js update - if it's just for .exports, then when I update the emscripten submodule that will just work, as that code won't be bundled into wasm.js anymore.\nSo basically, lgtm with a single commit of 2 changes that add .exports.\n. Sorry, I caused a merge conflict for this. Let me just apply the change myself.\n. Nice!\n. Fixing in that pull.\n. This was fixed by #240.\n. Also fixes exports as in #230.\n. @sunfishcode: this gets us to the stage of running code from the wasm backend. An easy way is just to edit out the ONLY_MY_CODE from check.py, then it will build libc etc., then run check.py --no-torture. When I do that with EMCC_AUTODEBUG=1 in the env, I then get\nwasm trap: final > memory: 4294967280 > 16777204\nlooks like an invalid write of some sort?\n. Btw, why does the .s format have globl and not global?\n. Maybe there was a shortage of \"a\"s in the 70's ;)\n. Should be good to go if anyone wants to review.\n. Yeah, switches get one block per case, so many thousands, easily. The testcase I added is from real-world code with over 33,000.\n. Good to go if anyone wants to review.\n. Another benefit with this is that if the methods specified do not include interpreting, then the wasm.js polyfill stuff is not linked in, which @lukewagner was asking for.\n. Thanks!\n. This found a couple of minor bugs, which should now be fixed.\n. Thanks!\n. That's probably about halfway there, merging the current work.\n. Thanks!\n. What command fails for you? This works for me over here: bin/asm2wasm test/unit.asm.js --debug\n. Interesting. Still surprising, though, I didn't realize that takes a parameter value at all. @jfbastien, what did you intend for --debug?\n. I agree, just one level sounds right. Which part uses more than one? I'm surprised to hear that, but I guess i forgot something.\n. Perhaps your c++ standard library isn't recent enough? Binaryen uses some c++11 features in both the language and the standard library.\nOr, perhaps we need to set c++11 support explicitly for msvc? In the cmake file it looks like we do -std=c++11 for non-windows.\n. Great!\nDo you want to open a PR that adds a link to your tutorial, in the main readme? I think adding it there would make it easy for people to find.\n. Hmm, 200MB suggests this was measured on loading the text format version, not the binary. Load time doesn't matter that much for the text format.\nIt might be useful to profile the load speed of the binary format. If it's too slow, and there's nothing obvious to fix, we could parallelize the function parsing section as wasm is designed for that.\nOverall, though, I haven't had the impression that our binary load times are bad, at least recently, so there might be nothing to fix here. Let's close this, if there are concrete issues measured, we can open new issues.. Is this ready for review?\n. Ok, great. Please comment next time, as github doesn't send notifications on pushes to existing pulls (but it does for comments), so I could have easily missed this.\n. Thanks!\n. Thanks!\n. Ok, that should do it. Reading through the Binary Format document, I don't see anything that we are doing differently (except for postorder).\n. There is probably a better way to write this... I was trying to avoid copy-pasting the unsigned LEB code.\n. Thanks!\n. Hmm first commit is from another wip pull, but it's done i guess, so leaving it in there.\n. A stack trace in a debug build could help some more, I think.\n. I see, thanks. This is a memory growth issue, with how asm2wasm translates the special asm.js memory growth function. Fixed in #266.\n. cc @jfbastien \nfixing windows to work with std:: seems better to me too.\n. An include for cctype has been added.\n. cc @jfbastien who is the resident ninja\nbtw, please squash/rebase the commits to remove the merge commits (git rebase on master should do it, then git push -f to this branch).\n. Looks like we forgot to merge this before, sorry about that. Thanks again!\n. cc @jfbastien \nWe should already notice if you can't run the executable and just warn on that. Is that not enough for you, @sunfishcode? I.e., are you bothered by the warning? Or did the warning not work properly?\nAnother option is to download and build LLVM and clang locally. This might help the VS case that you mention, @rwtolbert. If someone wants to do that work to add it as an option, sounds good to me.\nHowever, keeping the option for downloading the waterfall is crucial: it's the only way we can use Travis CI. And, downloading the linux64 executables works in the common case - my machine, most other devs I know, and the google bots - so I think that's useful.\n. Nice!\n. By more memory do you mean memory growth? I think that's not currently a tested path.\n. Oh, it should be supported ;) I'll look into it now, actually. I just wasn't expecting anyone to try this yet, I wasn't aware browsers had support yet. Even before browsers get there, we should get interpreter support working.\n. Ok, should be fixed now.\n. The asserts are bogus, yeah. Fixing in #282. These just cast and clamp.\n. Is there a way to tell asan to allow some leaks? E.g. the leaks in istring.h are intentional, they need to live until the end of the process lifetime. Using a \"proper\" method of allocation that frees them on shutdown is nice, but adds unnecessary overhead.\n. Working on this in #403.\n. Very nice work, thanks!\nlgtm, no additional comments on top of @jfbastien's.\n. Looks like that streamoff stuff breaks on travis, https://travis-ci.org/WebAssembly/binaryen/jobs/119046057\n. Rebased, fixed last issue, and merged in #287.\n. Yes. (Although in practice, all current uses only send in integers.)\n. Opened #285 for strcpy, but is there something cross-platform for sscanf?\n. Nice, optimizing this makes box2d 2.5% faster in throughput, 2.2% smaller in binary size, and 6% faster in startup. (Startup speed is fairly large since we used an asm.js sequence, which asm2wasm lowered into a block, and blocks are relatively slow to compile.) Numbers are on latest spidermonkey.\n. Great!\nI still see an error, looks like it doesn't find the asm2wasm binary. If the last push to incoming doesn't fix it (it will rebuild binaryen), then maybe something went wrong with the VS upgrade or other changes, and maybe emcc --clear-ports on that bot would help?\n. Why static?\n. Seems risky, though? The default behavior is to place it in the data segment, globally, and you'd rely on optimizations to avoid the loads and also to get rid of allocating it? I did some searching and didn't see recommendations specifically for function scope for this pattern, but maybe I didn't find the right sources?\n. Local enum sounds better to me, I guess. But I don't feel strongly.\n. Yes, wasm.js has a lot of integration with emscripten, that's what it's designed for. Things like i64 don't exist in JS, so it has special code for them, ditto for unaligned reads (which emscripten disallows because of how JS typed arrays work), etc. etc.\nIf you just want to interpret a standalone s-expr file, you should be able to just take the binaryen shell, and build that to JS. I can help out if you want. We could add an s-expr evaller .js to the project.\nHowever: s-exprs are a temporary thing. We will have an official text format before the 1.0 launch of WebAssembly, and it will most likely be very different. Therefore I'm not sure of the value of making it easy for people to learn about s-exprs, if they will need to unlearn that later.\n. Yes, in fact most of the proposals (from months ago to more recently) that I've seen almost all involve a more C-like syntax with curly braces and so forth. So I would not be surprised to see that happen.\nMy inclination is it makes sense for wait for the text format to materialize before providing a sandbox for learning wasm using text. For binary, the issue is that the binary format is still changing quite a bit, e.g. from preorder to postorder around now, and more to come, so I think it's too early for that as well.\nBut I'm open to other thoughts on this, that's just my general feeling.\n. Fair point about this informing discussion. I wrote a PR that adds webidl bindings which let you use binaryen from JS, see #312. That might already be enough for what you want, if not, we can add more bindings.\n. Nice site :)\nYeah, very limited so far - this was just enough to get basics working, to see its in the right direction. Would be nice if we added more to the IDL as necessary.\n. Interesting, I didn't realize that about the standard.\nFor now, I temporarily made emscripten just pin the memset, memmove and memcpy methods. That still leaves the math functions as a problem, and it wastes some code size, but we can optimize later (and it sounds like a valid thing to do in terms of the C standard).\nThe good news is that with that, and the last emscripten update (which has some other wasm backend fixes), I now see \"hello world\" working, using the wasm backend + emscripten + full musl! Next I'll start some larger programs in the test suite.\n. @jfbastien: STR is e.g. emcc tests/hello_libcxx.cpp in emscripten (latest incoming branch, and with vanilla llvm set up as your llvm), which builds this file:\n```\ninclude \nint main() {\n  std::cout << \"hello, world!\" << std::endl;\n}\n```\n. Thanks for the info. So, what are the benefits and downsides to fixing this in the musl headers vs fixing this in the wasm backend?\n. An additional benefit to fixing it in clang might be\n- Consistency with other musl targets (all of which use int for 32-bit, long for 64-bit), less surprises\n. It seems that there are two issues here. Compatibility risk with code not working, which @sunfishcode says he can handle, and upstreamability risk with us not doing the standard musl thing.\nIn both cases, the safe route is to do the stuff musl does in all other backends, and modify the wasm backend. That avoids both types of risk.\nIf we do want to take the riskier path, let's at least get rid of the upstreamability risk now. Because if they don't say \"sure, we'd accept such a new backend even with it differing from the others on that aspect\", then we might end up with them saying \"no\" later, and later it would be harder to change the wasm backend.\n. Thanks, and that fix sounds good to me.\nNot sure though about arch/wasm in the future, for reasons discussed in the past.\n. Fixed size_t in emscripten in https://github.com/kripken/emscripten/commit/72856ea6c255da6a9f56343522d92bea69859fa2\nNow compiling hello_libcxx.cpp (hello world with iostream) crashes in s2wasm, on the line with .int32  _GLOBAL__I_000101@FUNCTION (which surprises it), https://gist.githubusercontent.com/kripken/5a2e32e4e1aa10d206136204583f23ac/raw/01a7ce032a582b99be8c52af5b83e56858b6d2e5/gistfile1.txt\nI don't really understand what the sections etc. mean in .s files, so I have no idea what's going wrong there.\n. Makes sense, yeah. I opened a new issue for ctors specifically, #306, as this one was about new() and I guess we can close it following the size_t fix.\n. @FrancoisChastel you may be seeing a different issue, if you see that error on the latest release (1.38.13). Do you have a testcase showing the issue?. Nice, thanks!\nAre you a member of the wasm community group?\n. Great, thanks again!\n. fixImports in integrateWasmJS in src/js/wasm.js-post.js should do that, I think.\n. Hmm, still seeing a local error when I enable the new tests in this pull. Investigating.\n. Ok, this should be good now, if travis passes.\nThis now adds a bunch of wasm backend tests using full libc normally, in -O0 and -O2. It still keeps the old -O1 -s ONLY_MY_CODE=1 hack that was useful when we couldn't build libc. The existing tests are pretty slim (intentionally, since we couldn't do much more) so I also added a full hello world with printf, that now passes.\nAt this point, it might be useful to start running parts of the emscripten test suite directly, which we can do since it's a submodule here, to avoid test duplication. Perhaps a whitelist of what is known to pass there?\n. Looks good, thanks! Can you please just squash the two commits (then push -f to this same branch)? That way this won't break bisection.\n. Yes, thanks!\n. Looks like this fails on the bots. It can't find a pass, which implies that maybe you aren't linking in all the files under src/passes/ into the binaryen shell, or another tool?\n. Thanks, looks good to me now. But might be good if someone that knows cmake better than me (which is pretty much everyone :) ) could take a look too.\nAlso, please join the community group before we merge, if you haven't already.\n. How about if we have a single binaryen.so shared library, that all the tools would be linked with dynamically? That would be good for other projects using binaryen as well, they would just link with it similarly.\n. Small static libs internally sounds ok, but are you fine with also having a single .so for external projects? e.g. the program in examples/, I'd like it to just link to libbinaryen and not to multiple static libs.\n. Sounds reasonable.\n. Looks nice, thanks. Please just rebase so this can be merged, and also I think you need to join the WebAssembly w3c group.\n. Ok, another solution has landed for this, so I think this can be closed.\n. cc @juj \n. Fair points. Ok, how about if we merge this (should unbreak a bot) and then fix both args as a followup?\n. Good points. However, using asm2wasm and then wasm-as is a lot slower than just asm2wasm that emits binary directly. For unity-size codebases, that can be significant, I measured and asm2wasm is around 10-15% of build time. It could be much less with just binary.\nAs for emcc knowing when to emit binary, we have BINARYEN_METHOD (see docs), and if the user says there \"I want a binary, and to interpret it\", then we can tell asm2wasm to get straight to binary, etc.\n. native-wasm generating a wast is wrong, yeah. The reason it's like that is binaryen doesn't emit a binary that an engine can read. Once engines go postorder, that should change. And then we can make it emit a binary for native-wasm. And yes we'd get rid of spidermonkify.py at that time too (and other hacks if any).\n. Yeah, we should keep the option to use the BINARYEN_SCRIPTS hook to run an external tool to emit binary.\n. This is a duplicate of #608.. We should probably add a test for this, that checks we supply all imports. Perhaps the binaryen interpreter should error if so?\n. I added those asserts to wasm.js. Seems like the right thing to do. If not, we can change later, for now it seems safer to have them in.\n. Merged. @dschuff, wasm backend hello world should now work in v8 with asserting on all imports, please verify if you get a chance.\n. Looking at that failure, the file is this: https://gist.github.com/kripken/9153beda98849f504b04b9bc4f5e38c7 and my guess is the problem is mishandling of irreducible control flow in the wasm backend, as some debugging shows that divergence from correct behavior happens in the highly-irreducible mymemcmp3 method. cc @sunfishcode \n. Although that's just in wasm.js, and it now fails on something else. So that new failure still needs to be investigated.\n. This also refactors a bunch of stuff to make them nicer + easier to bind.\nSee .idl file for what is bound so far. We can add more later.\n. Yes, although if we want to backport to 0xb while working on 0xc, a branch would be nice. But maybe we can start with a tag and see.\nSounds like no concerns with master tracking the next binary format?\n. Emscripten could emit a __dso_handle thing for you, it's in the js libraries. Not sure why it errors here - shouldn't it work like other unimplemented symbols that end up implemented later in js?\n. Oh, ok. Then yes, I guess we need to work around it here.\n. Hmm, squash commits are already allowed in the settings, but the button here doesn't seem to allow them. Weird. Btw, you're already a collaborator on this repo, so you can look at the options too, maybe I missed something there.\nHmm, the \"$\" are the default Name printing method, since that's what wasts like. To avoid them, print x.str, str is the property with the C string.\n. lgtm squashed\n. Good to know, thanks.\n. 1. No strong opinions. But I'm still not sure why fixing the alignment of the stack pointer causes memory to be used, when it wasn't before. Weren't we allocating it before, just unaligned?\n2. I still think that 1 should be 0. Otherwise the first global allocated might be at address 0, which is an aligned address...\n. Yeah, I think 0 should never be an ok address to allocate on, so we start at 1, which gets aligned for the first one to something > 0.\n. I don't follow, what's wrong with 4? 0 is bad because it's the same as nullptr, so it would break comparisons to null.\nEmscripten will set up the stack itself. It emits a little code that writes the var STACKTOP into the memory location for the stack pointer, over here. \n. Sounds good.\n. Actually, we could get externs to work. Do we need them? If it's just this one symbol, it's fine, but if we'll have more we could fix this more properly. Specifically we would allocate them here, send that as metadata, and emscripten would connect those allocated locations to the code for them in a js library.\n. lgtm (squashed if that first commit would break bisection)\n. Added a commit with another walker, which goes in execution order and notes where execution is non linear. This should be a fast way (no constructing a new AST for basic blocks, etc.) to do 80% of a bunch of useful optimizations I'd like to add.\n. Ok, this is mostly done, barring bugs/travis.\nThis adds logic to analyze the effects of code, and uses that + FastExecutionWalker to sink store_local, getting rid of get_locals. See the test diffs, this can be pretty effective.\nThis is useful on asm2wasm output since it doesn't try to do this. Mainly since it hardly affects asm.js code size. But for us, it removes nodes, and is more useful. Also, this was much easier to write on the binaryen AST.\nAside from asm2wasm, this is a generally useful compiler optimization pass, e.g. for the case of a userspace compiler writing some wasm and using binaryen to optimize it before sending to the JS engine.\n. This hit the stack limit on JS engines. I added a derecurseBlocks method which helped work around it. Might be useful elsewhere too. But it makes me think, should our traversals not be recursive? I worry that would make them slower, though.\n. I don't know, it seems like it has to be slower. I guess we should benchmark to be sure. But simple recursion can do things like\nvisitBinary:\n  visit(left)\n  visit(right)\nwhich seems as fast as possible, compared to non-recursive which needs to manage a stack plus state so it knows where to pick up where it left off (i'm returning to the Binary, and now I need to do what?), which needs a lot more branching (which the native execution stack+pc does automatically and efficiently).\nThe issue seems to only happen in JS engines, though. I have not seen it occur natively. We should check on bigger codebases, perhaps. But if this is that JS engines have small native stacks, it would only be an issue for running binaryen when compiled to js/wasm. In which case, there might be another solution (like compiling it in a special mode).\n. lgtm\n. lgtm, nice\n. Process-wise, I'd prefer to not merge this until there is clear consensus the spec is moving this way, is that ok?\n. Cool, just wanted to make sure there are no misunderstandings.\n. This is definitely an area where we need help! Most (all?) of the main devs here are not on windows, and the VS errors are very unclear sometimes, at least to me. The current errors can be seen on the emscripten windows bot, btw (search for \"test_binaryen\"), e.g. here\n. Looks like this broke building on linux on travis.\n. We've had other changes to those lines, perhaps one of them fixed this?\n. I think these windows issues have been fixed, we test windows on the bots now too.. How was that code generated?\n. Ok, asm2wasm is meant to be run just on asm.js. Those files contain normal JS too.\nEven if you manually strip it out, it might not be compatible with asm2wasm's expections, you should run with --separate-asm to get a proper .asm.js file.\nOr, just build with -s BINARYEN=1 and it will run asm2wasm for you.\nI tried to verify that works on those files, but looks like a file is missing,\n```\n./Vectors.h:3:10: fatal error: 'Compatibilty.h' file not found\ninclude \"Compatibilty.h\"\n     ^\n\n1 error generated.\n``\n. In html, things can be more async. You might be running code before it's loaded. If so, building with-s ASSERTIONS=1` should give an error. See this faq entry.\nTo use BINARYEN, best to get latest incoming, as things are moving fast.\n. The main reason I'd prefer the alternative mentioned in kripken/emscripten#4236 is that the total code would be less, and it would be only in one repo (there is also a minor perf benefit as well). That is, adding dynCall in s2wasm should be pretty simple, and then things would just work. We can even write that s2wasm code using the new builder interface.\n. Suboptimal in what sense? Compilation speed? Or convenience of use of API?\n. Got it. Yeah, fair point. I've been thinking we should move Names to be just indices at some point, I just didn't want to do it too early when the compiler was in bad shape (much easier to debug stuff with normal names). But maybe now or soon is a good time. Of course names would still be optional, kept on the side in the module. The one risk factor is keeping that side data thread-safe (so passes can be parallalized).\n. You can try to use the wasm module by itself, but in general, emcc will emit JS as well, and you should run the JS. The JS will load the wasm for you, as well as do things like run c++ global ctors, a filesystem if necessary, etc. etc.\n. The first two chars (66, 67) are \"BC\". Is that file LLVM bitcode perhaps?\n. They should be in binary, we pass that flag, but maybe there's a bug somewhere.\n. The good news is that the -O times are on the order of 1 second for angry bots, which is a very large realistic code base. So perhaps even if this slows things down by a factor of 2, but makes the code better (no need to worry about recursion limits), it might be worth it?\n. The perf numbers are when running natively.\n. Added commit with name changes suggested in comments.\n. I hope these optimizations live for a long time :) asm2wasm will only matter for the next year or so, and hopefully go away, so this is not just for that. In general I think we need good options for people that want to emit a simple IR and compile it to efficient wasm. LLVM can do that, of course, but it's overkill in terms of compile time and code size for many use cases, especially ones running on the client. My hope is binaryen and its optimizer provide a useful option in that space. I'm imagining that the input IR and output IR from this optimizer is the same - wasm - which should allow for especially high efficiency (no multiple IRs to mess with), and it makes sense since wasm is a pretty nice input IR (IMO), and it's our necessary output IR.\nOk, thanks for the review comments, merging this and we can look at those followups later.\n. (In other words, I see asm2wasm as an example of the type of compiler that can benefit from such a tool. asm2wasm will go away, but others could benefit later.)\n. Good to go if anyone wants to review.\n. Also added 2 commits now, remove unnecessary virtual destructor followup, and also fix dyn_cast to follow the naming conventions as dynCast.\n. I like the idea of names being on functions, it solves the parallelism issue. But not sure about how printing nodes would work: if the name info would be on the function, then to print a node, we must know its function. I really hope we can avoid each node having a parent pointer (like e.g. LLVM has). For the module, on the other hand, I was thinking it would be known globally anyhow, as when running functions in parallel they all use the same module. But, I haven't thought this through fully, I'd need to write some code to do that I guess.\n. Ok, after more thought, I do think we can put local names on functions, and turn local names into indices with optional string names.\nI was also thinking we could do the same for other names, like block and br names, but realized that would be bad for compositionality (i.e. adding another block would require changing indices all around). But I think it's fine, the vast majority of names used currently are local names, and we have a plan for that.\n. Yeah, for adding names you can just append. To remove, you can just not use a local, then run the pass the reorders by frequency, which drops unused ones. Whereas for blocks, you'd be in a literally incorrect state for a while. More generally, I think we can consider blocks are part of the AST, and the indexes depend on the AST, while local names do not, they are just a list on the side basically. So indices for locals seems to make sense to me, but not for labels and so forth.\nAbout memory, yes, I think it would best to avoid unnecessary IR nodes, and to reduce the size of existing nodes. I think after this change, we'd be pretty good, as it would reduce set_local and get_local blocks in size by replacing a pointer with a 32-bit offset, and those are the most common nodes. And our other IR nodes are fairly compact already (barring obvious stuff we need to optimize, like we still use std::vector in blocks).\n. This was implemented by that PR, but we forgot to close this.. lgtm, nice, just two minor style nits/questions above.\nBtw, we might want to eventually move that dynCall maker to a more global location, as I suspect other tools might want it eventually. Unless we replace the mechanism before that, I suppose, so let's leave to later.\n. Thanks, looking forward to the PR.\n. Is the problem with printing, or with processing of .s input? A testcase would help. Looking at the binaryen printing and s2wasm code, both seem ok (condition at the end).\n. cc @binji \n. Are you using an old version of s2wasm perhaps? Current s2wasm fails to parse that .s file.\nIf you're using an older s2wasm, before the spec update on the order of select operands, it would explain the error. Like sexpr-wasm that @binji noted, binaryen passes the spec tests, so it has to be correct on this, unless some weird corner case is somehow being hit.\n. Yeah, this should be well-covered with tests throughout the toolchain space now.. Binaryen by itself doesn't set up the stack by default. When using emcc, emcc notes where the stack is stored (first allocated global location, that emcc tells s2wasm), and will write the stack location there, and then things work.\nThere is also a --allocate-stack s2wasm flag that emcc doesn't use, and might help here, not sure.\n. Also improve reorder-locals to drop completely unused locals (which happens now that simplify-locals is so powerful).\n. Yes, we need to do some coordination here.\nlgtm. How about if we land this as follows:\n1. Merge this squashed but without the tests. So no tests are broken.\n2. Land the emscripten side fix (we can't land that first, or emscripten's test suite could be broken).\n3. Make a new PR that pulls in that emscripten + enables the new tests here.\nSound ok?\n. On second thought, that seems like extra work - let's just tolerate some failure on the emscripten side.\nI landed the emscripten PR, so this should pass tests with a submodule update.\n. Yes. I can do that.\n. I'll look at the tsan stuff. I might need help though, I'm not familiar with it. I did verify code runs locally on helgrind and valgrind, though.\nHappy to split out the chrono stuff. But if it looks ok to you, I can just land that on master directly? Or did you want a PR to comment on?\n. Sorry, I didn't understand your answer to my question. I'm happy to do whatever you want for chrono. Do you want a new PR just for it? Or can I just push the chrono stuff to master (just a few lines, seems noncontroversial, I think?)? Either way, this PR can stay for the threads stuff until we figure it out, of course.\n. Added a commit with some check.py cleanup, might help to have more consistent checks on process return codes and logging of stderr, for figuring out the tsan thing.\n. I split out the other 3 commits into separate PRs #344, #345 and #346, I hope that's what you want?\n(Also leaving them here for now for debugging on travis, temporarily.)\n. Ok, this should be good to go. Passes all tests locally and on travis. Also passes valgrind and helgrind locally.\nJust fails the thread-sanitizer test which is not enabled yet, but it fails it in exactly the same way as it fails before this pull - something goes wrong in the torture tests section. That means it passes thread-sanitizer on everything until the torture tests, which is all the passes, etc., which is very good (initial thread-sanitizer failures there helped me fix the last bug). IOW this pull looks fine, there is just the pre-existing thread sanitizer issue.\n. Some thoughts on the unrelated preexisting thread-sanitizer bug are in #348.\n. Ok, I addressed all comments so far except for the main issue, which we are still discussing.\n. Regarding main(), note that the assertion must be checkable also before main() - e.g. IString code can and does occur in a global ctor in some cases.\n. Actually, since for now the thread pool is a singleton, then we don't need to check we are the main thread - just that the thread pool is not running. In the future, if we add other threads than the pool, we'd need to be more careful, but for now, checking the main thread seems overly-paranoid and unnecessary. I added a commit with that.\n. After the last commit, global ctors and the main thread are no longer relevant to this PR (see last comment).\nI agree removing global ctors is a good thing. As a separate issue unrelated to this, let's do it later. (I believe the issue is global IString/Names.)\nAny remaining comments on this PR?\n. Good catch on the comments, fixed.\nI'm ok to wait to merge this until we fix the tsan bot.\n. Rebased.\n. All green, merging.\n. @jfbastien, I think you were interested in this chrono stuff.\n. Thanks! Addressed comments, merging.\n. @sunfishcode: is the debug output from the backend stable? is now a good time to start parsing it as in this PR?\n. Also curious to hear @jfbastien and @dschuff's thoughts as well.\n. Can you please elaborate as to why it would be temporary?\n. Is this still relevant, or can we close it?. Closing due to inactivity.. Looks like the 3 unexpected failures all end in -9, with no stdout and no stderr. Looks like the waterfall harness lets tasks run up to 10 seconds. Perhaps those 3 are pushed over the limit of 10 seconds due to slower execution in thread-sanitizer mode? That would explain things if -9 is the error code when hitting the rlimit quota that the waterfall sets.\nNote that there are other tasks ending in -9 already, marked as known failures - probably infinite loops bugs in the wasm backend, s2wasm, or wasm-interpreter. So this just adds 3 more to that list of bugs to investigate.\nEither way, there isn't any thread-sanitizer output here, so tsan isn't actually finding a proper bug. So either they run out of time as suggested above, or some other difference occurs when running in tsan mode, like using more memory and running out of that. Seems like we need a way to mark \"might fail\" tests in the waterfall, if we don't already, and add those 3 to it? Or a tsan-fail list?\n. Hmm, not sure how to test locally. I just investigated via travis.\n. Hmm, I get clang-3.5: error: unsupported option '-fsanitize=thread', so I guess a special build is needed?\nAnyhow, I don't think we would see something different locally, the travis results look consistent and stable. Unless the issue is timing out, in which cases a local machine faster/slower than travis might differ, of course.\nAnd indeed the issue is timing out: meanwhile I tested adjusting the timeout, and increasing it from 10 seconds to 90 seconds lets the tsan build pass, which confirms the suspicions from before about this being a tsan-is-slow issue. And unsurprisingly, the tsan build takes much more than the others, around 8:30 (vs 6:30 for the normal ones).\nSo one way to fix the tsan bot is to modify the waterfall to increase the timeout. Or add an option to it to increase the currently hardcoded timeout of 10 seconds. Another option is to add the 3 super-slow failing tests to a \"might fail tsan\" list, but maybe that's less nice. Anyhow, I'm ok with any of those.\n. Sure, opened https://github.com/WebAssembly/waterfall/pull/45\n. The investigation here was concluded, closing this PR.\n. Renamed.\n. Thanks!\n. Don't you need to update the waterfall too?\n. Woohoo!\n. Just pulling latest master should be enough.\n. Maybe you forgot to pull into your clone? Or the local copy? fetch isn't enough, it just gets the data into the local upstream/master branch. You also need to do pull or merge or something like that, into your own branches.\n. Added tiny fix for #360.\n. The test output changes are due to local sorting. We sort by # of use, then for pairs with equal usage, we sorted before by the name, and now do it by the original location. So the order changed, but it's valid either way.\n. Depends on #356.\n. Hmm, -pthread is a necessary flag on gcc and clang on linux at least. Maybe not on OS X? Does it need a different flag for a multithreaded program?\n. Thanks, looks like that's correct, it works for me locally on linux. Added a commit to the thread-fixes PR #353.\n. Should be fixed by that PR.\n. Would that make it ignore unused arguments? Seems risky, we might miss other things later.\nUnless we have no other solution for this issue here, but it should be resolved now that on master we add the flag at compile and not link time?\n. Interesting, thanks @adam852. Maybe it would be safer to do the opposite, add the flag only on linux? I don't know cmake that much, but probably there's a way to do that?\n. @adam852: ok, thanks, that sounds good. Do you want to open a PR with that?\n@jfbastien: it does sound good to do what llvm does, but seems like we'd need to import a lot of cmake from there, which makes me worry...\n. Heh, nice, funny this wasn't noticed before!\nCan you please add a little testing, maybe just modify a single number in one of test/*.asm.js to use capital hex format?\n. Great, thanks!\n. Hmm, travis c++ compilers don't like unique_ptr to void*... my local compiler doesn't complain.\n. Good point. Ok, now this adds a bump allocator per thread in a simple way. It still locks, could be much optimized, but since this path is very rare let's leave that for later.\n. An arena might live less than the thread. More specifically, each wasm Module has an arena, and there could be multiple modules, they aren't global structures. After this patch, each module has an arena which might become a list of arenas, one per thread.\n. (But in practice, the optimizer very rarely needs to allocate nodes, instead they can be reused. So the list should not be a hot operation.)\n. Maybe I don't follow, but that sounds more complicated to me, for the following reasons. First, the thread class and thread pool classes would need to understand about arenas. This component interaction would get trickier if we could run multiple thread pools at once, or add additional background threads, etc.\nSecond, I don't follow how you would handle multiple arenas in action at the same time? Or did you mean to avoid that situation by having a singleton arena per thread? But we may have multiple arenas, with different lifetimes, active at once: consider linking 2 modules to another module, each with its own arena. They can't share arenas, as after linking we'd want to erase the first two modules and their arenas, but not the third.\nThe way this PR is written, the arena class is inherently thread-safe, and does not need special support from other components. Each arena instance is a thing that can be used safely no matter if one is single-threaded or not, and there can be any number of arenas active at once, each is entirely self-contained.\nI might not understand your approach yet, though, sorry if the above is based on a misunderstanding.\n. > What I'm suggesting is conceptually very simple. If a work item needs to give back memory, it creates a MixedArena, and when it's finished it gives it back to the creator of the work item, which can do whatever it wants with the memory. In this case it would merge the memory into its own arena.\nBut what if a work item needs to allocate memory in multiple arenas? That is, if the creator of the work item has multiple arenas?\n. (Added more documentation to the MixedArena class.)\n. > Allocate a MixedArena per module, for each work item.\nSure, but how do you coordinate that? A work item would need to know about what modules are active, which is additional interaction and complexity. Right now (and in this PR) work items do not need to know anything about allocation and vice versa. And as work items get more complex (now we have a single thread pool class, later we may have more background threads, multiple pools, etc.), that separation of concerns seems very useful.\n\nIf you're going to lock\n\nThe locks are unnecessary, I just didn't want to bother with optimizations at this early stage, and it's not a perf issue since side threads allocations are extremely rare in the design of the optimizer. But, if the locks bother you, then a lock is only needed to append to the linked list, which happens once per side thread per module (should be negligible). Otherwise, every other operation does not need to lock.\nBut again, in practice, the current code should be fine for now - it only locks on side threads, on which allocations are extremely rare. But, if you prefer, I can do the optimization to only lock when necessary here.\n. Once the locks here are gone, I don't think there is significant loss - main thread is still fast, and for side threads, they allocate far less, and when they do, they just look in the (short) linked list. (Only building the list takes a lock, and it happens once per core and that's it, not once per allocation.) So performance-wise, this should be near-optimal, I think.\nI implemented that now in this PR. I guess I didn't realize how silly the code looked without this optimization ;) Hopefully now it looks less weird. Although I guess now I need atomic operations on next?\nAbout arena per function: each MixedArena has some overhead, and modules can have many small functions, so I worry about having an arena allocator per function. In addition, while currently functions are the basis for parallelism, that might well change in the future (e.g., an operation might be parallel in basic blocks, or it could run parallel threads for the entire function, like a multithreaded register allocator), so I think it's safer to make MixedArena always thread-safe, as in this PR.\n. Thanks! I fixed the atomics.\n\nI wouldn't worry about designing for that case until you actually start doing it.\n\nI agree on basic block parallelism, it's complex and I have no current plans for it. But other kinds of parallelism I can see the use for in the nearer future (like a parallel register allocator, which I'm thinking about). And more generally, binaryen is meant to be a library, which might be used in all sorts of ways. I think that having the core arena class be thread-safe, without support from external components (like the thread pool) is the safest way to do that.\n. > You can mix both approaches too (you know at each allocation point how long something will live), but in the end there's no lock. If there are locks in the allocator you're usually better off with malloc.\nThis PR only locks ~once per thread per allocator, which is generally once per thread per module. In other words, on a 4 core machine, we are talking about 4 locks total for the entire lifetime of that module, through all optimization passes. In other words, the locks are essentially negligible, unless I'm missing something.\n. Let's merge this in for now. It only modifies the MixedArena class in a small way, so it's not limiting future improvements. And it's blocking 2 other PRs (improve-remove-brs and improve-simplify-locals).\nIf you still feel strongly that there is a better approach, then perhaps writing a PR with the alternative might help. When you suggested ideas here, I thought in my head how I would implement them, and the result seemed less good than this PR - but obviously that might be my fault ;) Maybe seeing a concrete implementation that is better would change my mind.\n. Thanks! Ok, now I think I see more clearly what you mean.\nThis does look pretty nice, I admit. It is a bunch more code, though, in particular the interactions between the classes with passing around and merging the allocators. But I can see the argument that the design is clean and might be worth it. So I guess that part could go either way.\nLooks like you're taking a lock a few times per task, which means per function?\nA bigger concern is that you have an allocator per task, which means per function? It seems like that would lead to a great many chunks, at least one per function?\n. I'm not that familiar with lock-free queues, but your main thread and worker threads need to block at some points. Doesn't that imply a mutex and locking? Or busy-wait?\nAh, I missed that about the N*2 tasks maximum. Yes, that would make the number of extra chunks overhead on the order of cores as opposed to functions. Why not N btw?\n. I think in the end at least one of the two, getting tasks and doing allocations, must be coordinated. In your approach it's the tasks, while allocations are trivially lock-free, while on the other hand in mine tasks are trivially lock-free, while allocations must be coordinated.\nNot fully symmetrical, though, it seems like the coordination on tasks requires blocking (spin-wait or a mutex, etc.) while coordination on allocations needs those things only until the allocator has a side allocator per thread, so after O(number of cores) there will never be a need for blocking.\nI guess which is better depends on the usage patterns. I think there may be more tasks than side thread allocations, at least that's my goal (reuse nodes, etc.), but I might be wrong. Or I might be right now but new optimizations we write later might need more allocations and prove me wrong.\nAside from perf, I think your approach is more code, even if I do see the appeal and the design now. And it might require more code later if e.g. a task has more than one allocator (like when linking modules) or changes on the task pool side, because of the interaction between allocation and tasks.\nSo overall I think I still prefer the current approach, but it's close.\n. I suspect this really comes down to differences in perceived complexity. I understand what you say about your approach being more obvious for you. For me, though, passing around allocators seems like unnecessary complexity, and it's simpler to have the allocator itself be thread-safe.\nI admit you might be right that most people might find your approach more obvious. I'm not sure how to measure that. But I think you have more experience with this type of code than me, so you are perhaps more likely to be correct.\n. Doing this better in the 0xb branch.\n. Your proposal sounds good to me.\nIn previous discussion in #292, I ended up pinning the memcpy/memset/memmove methods. After your approach is implemented, we could remove that line in emcc.py.\n\nEven when using LTO (in which case the user code is linked as bitcode) there is a native link step, which includes the native user code, native system libraries, and compiler-rt.\n\nCan't someone doing native development statically link in libc and other system libraries and LTO that? I mean, it can break, but this shows the problem is more general than us, I think? It's just that no one thinks to do it natively? Anyhow, just an academic point I guess.\n. Overall good. Notes:\n1. How about wasm-linker.h? (to match e.g. wasm-builder.h)\n2. LinkerModule => Linker? The name LinkerModule suggests it inherits from Module, which it doesn't.\n3. That Fatal thing could be in support/ perhaps, as we should probably be using something like it elsewhere. I'm ok with that as a followup.\n. In theory we could derive from Module, but I like what you did here better actually - leave linking to a Linker.\nWe can consider changing that later, I suppose, but I think we should use Linker as the name for now - and if we do later make it inherit from Module, we can change the name then.\n. Thanks!\n. lgtm\nAs a followup for myself (unless you or someone else wants to do it), I think it might be nice to put asm_v_wasm* in something like src/asmjs/, and also put the emscripten-optimizer stuff in there.\n. Thank you @brakmic and @jfbastien, we need all the help we can get for Windows :)\n. What is the difference between Linker and LinkerObject?\nAnd what does \"executable\" mean here? Could it be \"module\"?\n. Ok, I get the approach now, thanks.\nCould \"executable\" be \"linkerObject\" then? As in, exe would be renamed to that, getExecutable also, etc.? I am just surprised by the additional concept of execution here.\n. I don't understand, you have LinkerObject exe;, why wouldn't a suitable name be linkerObject in this context? That is, if it's ok for the type, why is it not ok for the instance?\n. So Linker receives a LinkerObject, which wraps a Module? And turns it into another LinkerObject, also wrapping a Module? And the first is a pre-linked thing, while the other is post-link, so it makes sense to call it an \"executable\"? I'm sure I have only 50% at best of that correct :)\n. How about the terms \"linker-input\" and \"linker-output\" instead of \"?\" and \"executable\"?\nRegarding the actual linking part, we need module+module linking anyhow, so I think just reusing that for compiler-rt might be simplest. In particular we'll need module linking for compilers not emitting the .s format, and for general stuff (like llvm-link is used in llvm; although, we don't have relocation info by default like llvm does). On the other hand, if compiler-rt is only a few functions (no memory, no function table, no chance of name collisions on the functions, no complications) then I could see it being simple both ways I guess.\n. Sure, out or output sounds good.\n. Do we still need update.py? I forgot it existed actually, I haven't run it in ages.\n. Ok, opened #385.\n. Looks like that script was out of date. Should be fixed on master now.\n. Which test? All tests pass on the bots, and for me locally.\n. Oh, I think it still passes for the bots and me since our binaryen.js is older. In other words, if binaryen.js is updated, the test needs to be updated with it.\n. Fixed by your PR.\n. Looks like this passes on the bots now, is it ready?\n. Ok great, looks good to me to land. Have you already joined the w3c wasm group? (see here)\n. Excellent, thanks!\n. I think you need to update binaryen.js as well.\n. Looks good, thanks!\n. That was merged so lets merge this.\n. lgtm with those 2 fixed.\n. I landed 2 PRs that might cause merge conflicts here. I checked locally and the diff isn't that bad. I pushed a rebasing to split-build-2 since I already did it anyhow, but feel free to ignore if it's not helpful.\n. Ok, this should be good to go. I rebased now and removed the debug help stuff, and all leaks are gone.\nA bunch of code changed here, but aside from the .travis.yaml change to enable leak checks, it's nothing interesting, just moving to rely on std::unique_ptr etc. to manage memory in more places, and removing some hacks.\n. Merging as this touches so much code, it's a merge collision hazard. Let's do additional comments as followups. @jfbastien: I already addressed the first of your comments, and had some questions about the others.\n@dschuff: about merge vs squash commits, this pr is an example of where i think a merge commit is better. It's lots of tiny separate commits, not worth their own pr, and it's nice to keep them separate for future bisection and readability purposes. Also the merge commit shows the structure (that those commits led up to the commit enabling leak tests now that they pass).\n. lgtm\n. Thanks!\nI guess this was not detected by all the asm2wasm testing and fuzzing since asm2wasm has no native i64s... and the spec tests have i64 loads, but we have different code for them in wasm.js, the memory access must integrate with the JS-accessible heap.\nWe can add a test for the wasm backend, just by adding a cpp and a txt (of the output, and same basename) to wasm_backend/.\n. No problem, I can update that part. I'll push to this PR.\n. Fixed a check.py bug that this hit. Merged.\nThanks again for looking into that bug!\n. In general squashing is nicer, but in this PR for example i think a merge is better, for future reading of the commits - squashing would eliminate some information.\n. Where is that from, btw?\n. Looking into this, I removed the printf and replaced it with direct logging calls, to not involve libc,\n```\ninclude \ninclude \nstruct S1 { unsigned lo:32; unsigned mid:2; unsigned hi:30; };\nstatic struct S1 g_68 = { -1, 0, 0xbbe };\nextern \"C\" void emscripten_autodebug_i32(int32_t x, int32_t y);\nint main() {\n  emscripten_autodebug_i32(0, g_68.lo);\n  emscripten_autodebug_i32(1, g_68.mid);\n  emscripten_autodebug_i32(2, g_68.hi);\n  return 0;\n}\n```\nand that now prints out the 3 elements in that struct. The code the wasm backend emitted looks weird to me,\n(call_import $emscripten_autodebug_i32\n      (get_local $$0)\n      (i32.load offset=1032\n        (get_local $$0)\n      )\n    )\n    (call_import $emscripten_autodebug_i32\n      (i32.const 1)\n      (i32.wrap/i64\n        (i64.and\n          (i64.load32_u offset=1036\n            (get_local $$0)\n          )\n          (i64.const 3)\n        )\n      )\n    )\n    (call_import $emscripten_autodebug_i32\n      (i32.const 2)\n      (i32.wrap/i64\n        (i64.shr_u\n          (i64.load offset=1032 align=4\n            (get_local $$0)\n          )\n          (i64.const 34)\n        )\n      )\n    )\nAnd the data segment is\n(segment 1032 \"\\ff\\ff\\ff\\ff\\f8.\\00\\00\")\nwhich doesn't look right. That is -1 for the first 32 bits, correctly, but then 0xf82e0000 for the other 32 bits, which doesn't look like the bbe I would expect? The .s is the same,\n_ZL4g_68:\n        .int8   255                     # 0xff\n        .int8   255                     # 0xff\n        .int8   255                     # 0xff\n        .int8   255                     # 0xff\n        .int8   251                     # 0xfb\n        .int8   46                      # 0x2e\n        .int8   0                       # 0x0\n        .int8   0                       # 0x0\n        .size   _ZL4g_68, 8\n. Yes, I simplified the middle part to 0.\nOh right, it's shifted by 2. Then that part does look right...\n. Fix in #460.\n. lgtm but one typo\n. I'm not sure that would work on other platforms, though. Might need to cast to int. Perhaps open a PR, and the bots will automatically test that?\n. > There is just one type of number in JS, so I'm assuming overloading constructors on number type is not possible in WebIDL?\nYes, correct.\n\nSo I subclassed Literal instead into i32, f32 & f64 specific classes.\n\nMakes sense, yeah, I think that's the right approach.\n\nI would like to include i64, too. The WebIDL type for a 64-bit integer is long long, but defining long long geti64(); for Literal in the IDL results in src/../glue.cpp:33:1: error: unknown type name 'LongLong' when building binaryen.js. Adding typedef int64_t LongLong; will make it compile, but values below/above the 32-bit range will wrap around, so the conversion to JS number isn't working as it should. Any ideas?\n\nThe error could be fixed in the webidl parser in emscripten (third_party/WebIDL.py).\nThe conversion issue is a real problem though, as JS lacks 64-bit ints. Perhaps an I64Literal should be constructed using i32 low, i32 high, and instead of geti64 we could have geti64Low, geti64high.\n. Perhaps as an option - if it's the default, I worry it would be confusing for users.\n. Our objects contain pointers (that's why manual destruction is necessary), so the downcast is of a pointer, which is valid in C++.\nChanges look good, is this all ready?\n. Ok, this looks good. But actually my last comment worries me: in C and C++ these are passed around by value, but our WebIDL binder wrappers use a pointer. So they must be destroyed manually. That means a lot of extra code, and it's error prone - I think the test itself is missing some?\nThe same is true for Name as well.\nPerhaps we should use the [Value] option that the binder has? It has downsides itself, though (it cannot be used later - we should probably add more assertions in the binder glue for correct usage).\nAnother option is to avoid wrapping value types. Then creating a Const node require a different constructor for each type, and getting the value of a Const node would have the getters we have on Literal here. So basically, this option would mean moving code from the Literal bindings to Const bindings.\nI lean to the latter option, but still not sure. What do you think?\n. Ok, if you don't feel strongly either way, then I think using [Value] is best. As documented that means that when returning such a value it can be used but not held on to over time, as there is storage for one instance globally. That avoids the need for destroy() calls.\n. This has been inactive for a while, do you intend to still work on it, @data-ux ?. Closing due to inactivity.\nI'd like us to improve in this area - we should make it easy to generate optimized wasm using a JS API. Not sure if I'll have time myself though.. I intend to work on a C API next week.\nI'd also like to see a shared library, but I'm not sure how best to do that with cmake, hopefully someone else can help out there.\n. @dschuff, @sunfishcode: the llvm_autogenerated folder has autogenerated tests from llvm, correct? are they just out of date, or does the llvm backend still emit the older form memory_size?\n. @Lichtso: did you manually change these files, or automatically? This should probably be done automatically, and might include other changes as @dschuff says.\nI'm also ok to support both temporarily if that unblocks something.\n. lgtm, except it might be nicer to put that code in support/. Not sure if in bits or safe_integer though?\n. Thanks, lgtm. @jfbastien?\n. lgtm\nTIL about copy_n\n. lgtm\n. No, I haven't thought much about manipulation yet. Hopefully most compilers won't need it? Probably that's too optimistic ;)\nAbout the prefix, how about \"Bin\"? Or any other ideas?\n. > How about BYE :)\nBYE suggests BYOB to me... so, Bring Your own... Expression? ;)\nBut I like the shortening, BYE for BinarYEn. Another option might be BYN?\nProbably too short, but maybe, B_?\n\nKnown would be nice: \"the prefix? It is Known.\"\n\nDefinitely the kind of pun I like, but probably too much for a C API ;)\n. Or maybe BIN?\n. Yeah, maybe the choice is BYN (or Byn?) vs Binaryen. I'm ok with either. If no one chimes up I suppose we can leave it as Binaryen for now.\nMeanwhile I added a kitchen-sink test of the api, which found a few bugs that are now fixed.\n. Ok, let's merge this. We can change the name later if there are opinions about it.\n. nice!\n. I think this is clearer personally, but if more people think otherwise I'm fine to leave it as is.\nInstead, perhaps a comment \"we don't shift more than the actual number of bits\" would be just as good, with the previous code.\n. I may be missing some background here. Why do you want to handle archive files in binaryen?\n. Might be a silly question, but is there just one .a file format? I think I heard that different *NIXes might differ on it. Is it guaranteed to be the same on OS X and Linux, in particular?\n. lgtm except for one style nit\n. This shouldn't be controversial, and is a merge-collision hazard all around, so merging. Comments still welcome of course.\n. @jfbastien: this is failing on ubsan, on\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.9/../../../../include/c++/4.9/bits/stl_tree.h:741:25: runtime error: downcast of address 0x7fffe6af0888 with insufficient space for an object of type '_Rb_tree_node<std::pair<CFG::Block *const, CFG::Block *> >'\n0x7fffe6af0888: note: pointer points here\n ff 7f 00 00  00 00 00 00 00 00 00 00  f0 a4 12 02 00 00 00 00  f0 a4 12 02 00 00 00 00  30 a6 12 02\n              ^\n(e.g. see this log). No stack trace even in a debug build. And that class isn't something I defined, I guess it's part of the STL - so this must be hitting UB inside the STL somewhere? Any tips on how one would debug something like this?\nGuessing that that's a map of Block* to Block*, I looked at all the code using that. There isn't any iteration on them, so no iterator invalidation I can see. Some find()s are done but they look safe too. Weird.\n. Oh wow, thanks @binji! I didn't even think to look for that...\nOk, let's see if ignoring that specific file in ubsan helps.\n. Ok great, adding that stdc++ file to the ubsan list avoids the issue, so this should be good to go.\n. lgtm\n. lgtm too\n. Looks like this broke tests here, and on master.\n. Fix in https://github.com/WebAssembly/binaryen/pull/445\n. lgtm, nice!\n. Thanks!\n. lgtm. might need to coordinate with @mbebenita's #446?\n. Great!\n. cc @adam852 - any idea why your pull had that effect?\n. The specific problem I see without that flag is a runtime abort when I try to use threads,\nterminate called after throwing an instance of 'std::system_error'\n  what():  Enable multithreading to use std::thread: Operation not permitted\nAborted (core dumped)\n. @binji: thanks, that does fix it for me. I updated this PR to do that.\n. lgtm (squashed)\n. Ok, let's get this in, we can iterate later if there are windows issues.\n. Thanks!\n. Before we merge this, have you joined the w3c group?\n. Great, thanks!\n. Thanks, yeah, that was a bug. Not noticed since it's indeed not used yet.\nThe idea though is that it's an optimization. If someone builds wasm and they know block types, they can avoid the scanning that the default finalize method does. So far nothing in the codebase tries to optimize that way.\nFixing in #457.\n. Should be good to go, the travis error looks like a random corrupted download of the waterfall archive.\n. Great, thanks!\n. Yes, i64 support was never added to wasm2asm.\nMeanwhile development on it has stopped, and it was recently removed from testing and then the build. If someone wants to pick it up, though, that's fine.\n. Thanks!\n. This caused some errors on travis.\n. I think you need to rebase on master and push -f to this branch again.\n. I don't see an update here, it still looks like 71a0755 is what's in the branch?\n. Ok, let's close this and focus on that pr.\n. Closing due to inactivity, and the related PR #471 was merged meanwhile.. Not fully, it would be a very hard problem to see i64s that were split into i32s and merge them back together.\nHowever, asm2wasm does do a little optimization here, specifically it turns some of the runtime library code, for i64 division, to use i64 native operations. This saves code size and can make it faster.\nBut the only way to get full optimized i64 usage is to compile i64s directly, which the new wasm backend can do.\n. Looks like this hit a travis error on undefined behavior detection, negating too large a value.\n. Is this still relevant? Closing due to the long period of inactivity, please reopen if necessary.. Address was refactored so I think this is no longer needed.. The alternative PR was merged so I think this is outdated and can be closed.. Negation of unsigned is still unsigned? That sounds odd. Also looks a little odd in the code. No other option here?\n. I agree with @dschuff, if the changes make the code less readable (which might be the case here, I think), maybe disabling a warning might be better.\nedit: cast => case, no pun was intended :)\n. Sounds like disabling warnings was preferred by most of us here, as an alternative.. size_t for 1 and 2 sounds good. For 3, we have Index and Address types that have a 32-bit size, so those should stay, and I guess assigning a size_t to them should be done carefully - why is that happening? - and if it's valid, through a cast, I guess? Maybe a cast function that checks for overflow?\nNeed input from @jfbastien and @dschuff here.\n. @BSalita: are you referring to a specific PR? If we forgot about one (sometimes things get lost, sorry), please comment in it in that PR (which will email us).\n. lgtm\n. lgtm. @BSalita, what do you think?\n. Yes, all those look like correct changes.\n. I think the noncontroversial parts of this PR are where we change to use the right type, and do not add a cast or a macro. That makes the code strictly shorter and more correct. Might make sense to land that stuff first, and leave the rest for a followup? I'm ok either way.\n. I am not convinced those warnings are serious enough to justify clutter in the code.\nIf they are serious, let's try to find a way to fix them that doesn't add clutter (but that might be a longer-term thing).\nBut are they? If the risk is trying to truncate a 64-bit value that doesn't fit in 32 bits, we should do it on external inputs, but on internal data that is assumed valid, I don't think the clutter is worth it. Readability matters more.\n. This has been inactive for a long time, is it still relevant?. Ok. Let's close this for now then with those warnings disabled, we can revisit the general issue later if there is interest.. Looks good, thanks.\nFor a test, can add a unit test for the print pass specifically. Add print.wast and print.txt in tests/passes/. Then the test runner runs the shell on that wast with --print, and verifies the output is the same as in the txt.\n. Or would this be tested by a future spec test? then that's good enough.\n. Seems good enough. If it's untestable via a wast, I'm not worried.\n. Thanks, should be fixed in #499.\n. Fixed by #499.\n. Fixed by #499.\n. Fixed by #499.\n. Ok, these all should be fixed by #499.\nOur validation was indeed pretty poor before, it was basically just enough to pass the spec test suite ;) thanks!\n. Fixed by #499.\n. Fixed by #499.\n. Nice!\nPerhaps we should mention this in the readme?\n. We may convert those void* back to the subtypes though, elsewhere. Is that not a problem? Not sure I understand the UB issue here, sorry...\n. I see, thanks. Interesting, I didn't know that.\nAnother question, is there a benefit to the implicit_cast operation you define here? Couldn't we just write static_cast in those places?\n. static_cast would also check if the pointer is of the wrong type, I think? Or is there less safety somehow?\nIf they are equivalent, I think static_cast is more idiomatic.\n. I guess I'm in favor of static_cast then. But there are bigger C++ experts than me around here like @jfbastien and @dschuff - any thoughts from either of you?\n. These methods are the implementation of the C API? There is no place lower to do the cast?\n. Ok, sounds good. I guess an additional C layer under this C++ might be better, but yeah, seems like overkill.\n@MI3Guy, let's just change those to static_cast, and then this is good to go.\n. Thanks!\n. Thanks, interesting problem. Not sure what to do here. Maybe the two main options are\n1. Consider potentially-trapping operations like div, some of the casts, etc., as having side effects, so the optimizer won't reorder them.\n2. Add an option for imprecise optimizations. asm2wasm already has this. This would be a flag for the optimizer to be able to do things like assume math and conversions do not trap, so if they do, some reordering might occur.\nWhat do you suggest? Is there a standard compiler behavior for stuff like this?\n. Ok, what's a conventional name for such a thing? --fast-math perhaps? Or should it be more specific like --assume-math-cannot-trap?\n. @jfbastien The option would prevent disabling some code reduction optimizations, so it sounds useful. Or do you think it would be rare in practice to see such potentially-trapping operations be movable?\n. I guess you're thinking of LLVM-generated code? But another use case is for a compiler to let Binaryen do optimization for it. It could then say, optimize under this assumption, or not.\n. On more thought, I'd like to generalize this to not just math. For example, it is nice if the optimizer can assume that loads do not trap unless told otherwise.\nHow about --assume-no-implicit-traps? (Implicit, since (unreachable) should still trap even in this case?)\n. #898 tightens our handling of implicit traps, and in particular fixes the issue @titzer warned about in the previous comment here. Also adds more infrastructure that builds on #788 for allowing more detailed handling in the future.. Merging as there are no concerns and there is followup work I'd like to get started on. Comments still very welcome, though; as mentioned before, need advice for how to tune this.\n. Maybe I don't know how to use it... it tells me 50% of time is spent in one method, which I know is the hottest, and doesn't help me much. I'd like to know if that time is spent in the method itself or in the things it calls. I guess that information is lost due to inlining?\n. Indeed preventing inlining seems to help, hmm...\n. Thanks, nice. Ok, that pointed me to a few things, opened #509.\nEasy stuff is probably gone. Bigger question is whether there is a better data structure than sorted vectors for the sets of live locals, which we constantly merge, insert and erase from, and loop to find conflicts. Sorted vectors are good when the total # of locals is high but most lists contain just a few. But I wonder if the total # of locals is small enough, if a bitvector might be faster (merging is just bitwise or, etc., everything is faster, except for iterating, but for small # of locals might be fine).\n. @binji Interesting, thanks. So, looks like you keep livein etc. in PNBitSet which are a vector of bits? So it's very fast to merge, insert, and erase, but how about when you need to iterate - then you need to loop over every single bit (I guess at least in chunks)? Or is there some way to avoid that?\n. Ok, I see how you generate the list of live vars using that algorithm (indeed nicer on SSA...). Do you then use that to generate an interference graph? That's where the iteration over variables would happen. Or do you do some other register allocation method?\n. I see. Yeah, that avoids the interference graph, and then you don't need to iterate on locals. Definitely faster.\nIt also looks like that family of algorithms can do remarkably well. I believe LLVM uses a variant with backtracking, and the method here can only do around 2% better than that. I'd be curious to see what the compile-time difference is, but that's harder to compare.\nMeanwhile I had another optimization idea from this discussion, #516. I also think it could be optimized even further, come to think of it, now that interference is done after liveness as in that pull (bitset for one and sorted vector for the other).\n. Nice! :)\n. Thanks!\n. Still deterministic, we use the same seed for the generators.\n. Thanks!\n. > this didn't require any actual s2wasm change because s2wasm just accepts anything beginning with 'd', so it accepts either \"discard\" or \"drop\".\nThe very definition of \"feature, not a bug\".\n. The tests failed, though? Or was that expected?\n. 1. Didn't you just explain that things would still pass here as we accept both drop and discard?\n2. The errors don't look like drop/discard errors, they look like something else? Namely they look like a bad line at the end, maybe the build you made the update with was before the recent whitespace change we made at your suggestion?\n. @jfbastien , to be sure I get the issue, if I keep using the current merseinne stuff but write my own random permutation generator using it, everything would be ok?\n. And the merseinne generator is a valid URNG, the docs say? So basically I just pass in the generator object instead of an instance of it which is a function - 1 line fix? Or am I missing something?\n. Great.\n. Thanks, fixed.\n. Yes, the code does optimize away some blocks - it goes further than just avoiding unnecessary ones.\nIs this a problem, though? For the second time today, I feel I must say: bug, or... feature? :)\n. Fair enough, agreed.\n. Well, turns out that the last spec tests at the end required a total overhaul of our internal opcodes (so that was a fun few hours). The tests require that we be able to express \"this is an f32.abs, receiving an unreachable-typed input\". We had just an opcode for abs, and used the input to know the type. Anyhow, it's better now, in fact we can probably remove the binary opcodes and use the same ones everywhere.\n. Nice, lgtm too. Just needs a merge conflict fix.\n. lgtm\n. lgtm\n. Not sure what's going wrong, but in general when you run something like clang -emit-llvm --target=wasm32 -S dlmalloc.c then you are compiling using the local system settings. For example, you get the local system headers that define basic types and so forth. That might be messing things up. (When you use emcc to build, it uses portable libc headers and also handles the triple stuff for you.)\n. A downside to this class approach is that Index x and Address y become structs. We rely on compiler opts to make things fast. Did we verify that? I don't worry about Address, because it's rare, but Index is literally everywhere all the time.\nA further downside is that this can cause subtle FFI bugs, e.g. in wasm-js.cpp, we send an Address x into an EM_ASM (which is a varargs function), and when it became a struct it silently started to pass the address of the struct. Wasn't hard to find with bisection, but annoying that there isn't a compiler warning. I can live with that though.\nOn a side note, this does raise the issue of what to do with wasm64 eventually. We should at least plan for it I think. My current thoughts are that it's not worth supporting both wasm32 and 64 in a single build, instead it could be a build-time flag. That way in wasm32 - the more common case by far, I think, for quite some time - we don't have larger data structures, and we don't have runtime checks \"is this wasm32?\" etc. in many places.\n. Yes, agreed, even with wasm32 and 64 in separate builds, the solution could be similar - only the definition of Address and Index would change.\nI'd still like to measure the Index change just to be sure, before landing. I can do it if you want.\n. Performance of running -O (can run with --debug to get timing info) on a large .wast file, like AB or BB.\n. Is this still relevant?. Closing due to inactivity, please reopen if relevant.. Ok.\n. This is obsolete.. Thanks!\n. Before we merge this in, have you joined the w3c group?\n. Correct. We could add support for binary tests here, however, are these perhaps test that make sense to add to the spec repo? I'm not sure. I guess if they are highly specific to bugs in this project, perhaps not, but if they test general things like \"not enough functions provided for what is declared earlier\" then that does seem like a spec repo thing.\n. Ok, great, let's merge this in.\n. Thanks!\n. Nice!\n. Yes, we should fix all these. I haven't made it a priority personally since it needs tests, and tests should arrive eventually in the spec repo, so not urgent to fix before that. However, if anyone wants to fix earlier, that's great of course.\n. Some binging shows this is a known issue with llvm.org sometimes not being available. I guess we can wait to see if it comes back.\n. Until this is resolved I think we should be very cautious about merging code to master.\n. This looks like the cause: LLVM disables apt for now.\n. One option here is to use clang from the waterfall, see #557.\n. overall lgtm\n. Ok, this might be worth the risk then. I opened https://github.com/WebAssembly/waterfall/issues/51 for making the waterfall build sanitizer-enabled.\n. Thanks!\nI'm not aware of a way to force a build. Maybe if logged into travis there is an option in the UI somewhere (I don't have an account though, so not sure).\n. Hmm, I think we need to rebase this on master anyhow, to pick up your pr? I did that now and pushed to here (before it still failed).\n. Looks promising! First sanitizer cmake stage passed.\n. Looks like this is working. It seems to have found a leak in s2wasm code you just added, @dschuff - https://travis-ci.org/WebAssembly/binaryen/jobs/134878503#L2440\n. Looks like renaming the 4 clang builds to \"clang\" marks them properly in the logs, and doesn't interfere with using the \"gcc5\" plugin to make things work (I was worried the name mattered, but looks like it's entirely superficial).\n. Ok, this pr looks good to go to me (assuming this last build fully passes, except for the new memory leak which is a separate issue). @dschuff, lgty?\n. Cool, landed. Thanks again for the help with the waterfall bits!\n. Looks like this is deep inside stdc++ code, perhaps this is something new in your local version of stdc++ that needs to be added to a list of stuff to ignore?\nBased on the stack trace, I also assume it's not specific to that pass, but would occur in any loading of a file in any of the tools, seems like a very broad issue in stdc++.\n. lgtm\n. Wow, that was fast. Is clang really that unstable in development? If this is going to be a problem, we could use an older and more stable build for building, and not the same as for the tests?\n. Thanks, yeah, we definitely shouldn't run out of memory even though the input is invalid. Looks like we allocated a lot of empty strings and got stuck in an infinite loop, when the input isn't valid. Fixing in #571.\n. Thanks!\n. Thanks!\n. Hmm, maybe something is wrong with linking on windows? Yes, please file an issue, that command should pass (and does pass for me on linux, as it must since the test suite tests it, and travis reports green).\n. They should be linked in by cmake, then used by the global constructors. On unix, we need some linking tricks since we use a static library which links in object files on demand, and they don't seem to be demanded (until the global constructor is seen). I don't know much about windows linking, does it also link in object files on demand?\n. I guess I'm not totally opposed to adding a list by name somewhere, but I was hoping avoid it... it's annoying in LLVM that to add a pass you need to edit multiple files with boilerplate.\nPasses are run not just by the shell, but also by asm2wasm for example. It's a general functionality I expect to be used in s2wasm as well eventually.\nHow about just making the library with passes a shared library as opposed to static? That would avoid the link hacks on linux. Would it work on windows?\n. Well, putting all the class definitions of all the passes in pass.h would make it very large. Some of those classes have many functions and properties. And it would sort of kill incremental compilation if adding a single pass means recompiling all the others (since they all include pass.h). But, maybe we can find some solution to all this.\nHowever, what undefined behavior do you refer to? AFAIK we rely on a special linker flag, but everything should be defined. Specifically, we have a static lib with objects that each have a global constructor. The linker flag makes us link in all those objects. Then each's global constructor ensures it is not eliminated. This is exactly the same mechanism LLVM uses to declare commandline arguments, for example, and I was under the impression it is not undefined behavior?\n. I didn't look in a spec for this, but\n1. I have seen this pattern in other projects, like LLVM as mentioned, and I assumed it would be reasonable for them to do, since LLVM tends to make reasonable choices.\n2. The LLVM optimizer will not remove code called by a global constructor. And LLVM tends to use UB to optimize, so when it doesn't usually that's for correctness.\n3. And most importantly, it seems strange to remove code callable by a global constructor. For example a global C++ object whose constructor prints hello world - if we remove that, we no longer print it. So the optimizer would be changing observable behavior. That can't be right, can it? And that behavior is all we depend on here (except for linking actually including the object files, which we need a special flag for on linux).\n. Good points, I guess I'm convinced on the #582 approach.\n. What specific command are you running?\n. Is testsuite the wasm test suite?\nstart.wast in the test suite contains multiple wasm modules, and assert_invalid stuff. It's a format for the test suite, basically. So there isn't a way to run wasm-as on it and get a module. Instead, in check.py we break up such files into individual modules and run binary format tests on them.\n. Sounds good to me, if the changes are minor like these. If we hit a more serious limitation or a need for large-scale changes though, then I think at that point we should give up on vs2013.\n. I'm not too happy with this, was hoping to avoid the LLVM-like create* method which means each new pass needs boilerplate in at least 2 places (passes.h and binaryen-shell.cpp). But we don't seem to have a better solution here.\nExcept for making passes a shared library as opposed to static. Would that not fix the problem on windows?\n. I think what's going on is that that example does not use any passes. So it was fine before - we don't register any, and don't call any. But now you added that header which declares them, and the method calling it exists, so the passes must exist. This means you need to link in src/passes/*.cpp.\nMaybe we can just link the c++ example with libbinaryen.so like we do with the c examples. Right now in check.py we handle the two differently (look for 'example').\nIf this turns out to be messy, we can probably just remove the one c++ example we have. It's not very good, and we added a C api exactly so we'd have a stable api for people. I'd say if it's not easy to link to libbinaryen, let's get rid of it.\n. Merged #593 which contained this + some fixes.\nOne thing not resolved is what I asked about in this PR with the wasm:: stuff.\n. That other PR was merged so I think this one can be closed.. In Emscripten currently,\n1. Nothing is exported by default\n2. The user can add exported functions to the EXPORTED_FUNCTIONS compiler flag\n3. The user can also export functions in source code, using a macro which currently lowers to __attribute__((used))\nThe compiler flag option (2) can just be passed to s2wasm (we do it with other backends).\nFor source code exporting (3), perhaps using visibility makes more sense, as you suggest. Do I understand correctly that we can do that without any breaking changes?\n. @dschuff: in the asm.js backend we hackishly interpret the \"used\" attribute as \"keep this alive, and export it\". We could do the same in the wasm backend and things would just work. Or, the optimal thing is probably a new attribute, __attribute__((export))?\n. retroactive lgtm\n. lgtm\n. wasm-opt should certainly be optional, but the benefit is noticeable already. It shrinks wasm-backend outputs by 3-4%, and could do more if we exported less by this PR.\nThat's for code size. For throughput, the wasm backend emits slower code than asm2wasm+wasm-opt, I believe on all the emscripten benchmark suite (except for one or two of the microbenchmarks where it's the same). I didn't try to run wasm-opt on the wasm backend's output - I think for that to work well, it would need to re-SSA it first. I started to write a PR with a pass for that, but haven't had time to finish it.\n. Do we still need this, or can it be closed?. test.js contains the JS part of the output. You should see the wasm part in test.wasm, etc. So asm2wasm can't work on that, it needs asm.js.\nThere wouldn't be asm.js in this case anyhow, since the wasm backend doesn't emit any. If you build using emscripten's llvm and asm.js backend, with the binaryen flag, then you would get test.asm.js.\n. Yes, -s BINARYEN=1. Same command basically, just without the wasm backend env var.\n. Yes, older probably won't work.\n. The asm.js backend isn't in upstream llvm, you need to use emscripten's \"fastcomp\" fork.\n. (Can just use the emscripten SDK and it gets it all for you, or you can build it manually too.)\n. I agree. Also the name isn't the best. We could have wasm-opt for just running opt, and wasm-test for running the spec tests, perhaps? Or maybe they should all be binaryen-* or bin-*?\n. Also 4) remove the linking hacks we don't need anymore now that passes are registered explicitly\n. make_unique is a c++14 feature - does VS enable it by default? Maybe the fix could be to set c++11 for VS like we do for unix (with -std=c++11) - looks like we don't tell VS the C++ version currently?\n. Sure, but as I said above, make_unique is c++14 and we are a c++11 project. Can we tell VS to do only c++11, as we do for unix?\n. I agree limiting use namespace is good. We avoid it entirely for std for that reason (which is one reason I'm surprised this problem happens on VS), and really just use it for our own namespace wasm.\nThanks for those flags. @juj, what do you think, can we use those, should fix this problem?\n. Well, first I'd like to understand the issue. It seems like the ambiguity requires VS to do two things:\n1. Enable c++14\n2. Do the equivalent of using namespace std\nWithout 1, there is no make_unique in std, and without 2 it isn't in the global namespace. Does VS just have two bugs here?\nIf yes, then we should work around it. Options are\n1. Your wasm:: additions\n2. Add a namespace wasm { .. } scope around all the code in that file (might need to keep just a stub main() outside).\nThe latter seems simpler to me.\n. Ok, thanks. Let's qualify with wasm::make_unique then.\nUnless there's a way for our header (src/support/utilities.h) to detect std::make_unique exists and use that, and only declare ours if necessary? Probably not though.\n. Thanks for reporting, this is actually being discussed right now here - feel free to join the discussion there. We are still trying to figure out what the best solution is.\n. Travis reports Unable to locate package g++-5 which breaks the builds, unrelated to this PR. But it means we don't have any CI working, so it makes merging tricky. I guess we can wait and see if travis fixes it.\n. Added a commit that removes our dependency on g++5. No more test coverage for g++ is the main downside. Also had to add a warning override.\n. Transient travis error went away.\n. The transient error went away, so this is not needed - we didn't need to disable g++5 anyhow.\nThis PR might still be useful in the future if we do need to disable it for some reason.\n. Nice, thanks!\n. What binaryen was used, and in what browser was it tested? Binaryen emits 0xb (the \"found\" result there), and current nightlies should support that, if you have 0xa then perhaps you're on an older nightly?\n. You can use an old tag of binaryen for each of those binary versions. But, it is better to just use the very latest chrome canary or firefox nightly, which support 0xd (the 0d you see in the found versions in those messages).\nClosing this issue as it isn't a problem in binaryen. Perhaps we should document this better somehow though?. Node.js doesn't have wasm support yet. When it gets a recent enough v8 it might work with a flag. Otherwise, you can use trunk builds of v8 or spidermonkey, or use a nightly build of firefox or chrome with a flag.\n. For example, you can get firefox nightly here, and then open about:config and look for a pref with wasm in the name, and turn it on.\n. Instead of running the js file in node, you can run it in a browser by creating an html file that contains a script tag whose source is that js file.\n. Is that with firefox nightly, and with the pref I mentioned?\nIf it is, then something else must be wrong but I have no idea what. You can debug in the source code, search for that error message, then read the code around it, and you will see what it is looking for that it can't find, that leads to the error being printed.\n. @ramiro1234: any updates on this?. Cool, thanks for looking into this - it's becoming a high priority as we get close to stable wasm in browsers. This issue is probably the biggest relatively easy win in compile times, and it avoids some corner cases with really slow compile times (when the wast is ridiculously large).\nAnd yeah, using the file extension is what we want, I agree. Other details sound good too.. Could you please make a PR on github with your changes? That would be more convenient to read.. @ramiro1234, this is getting urgent, so if you don't have time for it there's no problem (and lots of other non-urgent stuff you can contribute to if you want), but in that case we should let someone else do it. I'd like to see this landed in the next week or so.\n. Ah yes, this was in fact done :) wasm-io.h provides those methods.. This was done.. Nice, thanks!\n. On small program probably most of that time is starting up node and compiling the JS. If you want just execution time, it might be best to do it in the program itself: note the time before doing some work, then note it again after and print the difference to see how much passed.\n. Can add the test from the issue to test/dot_s/.\n. Aside from that comment looks good to me.\nMore generally, what is the status of this approach in LLVM? We should wait on things to stabilize there first, if that hasn't already happened.\n. Looks like we were not quoting strings that needed it, and here some function names have () in them for example. Fixing in #619.\nAfter that lands let's check if things work. I don't see an obvious problem in i32/i64 stuff, but it'll be easy to make sure after this is out of the way.\n. The validation errors look correct. The first one is in the function $Ordering::reverse where (local $2 i32), but\n(set_local $2\n                        (i64.const 0)\n                      )\nwhich is wrong - we can't assign an i64 value to an i32-typed local.\nIs that what you sent into the binaryen api? If so then the question is why it validated ok, as it shouldn't.\nOr did you send valid data and it's not being printed correctly?\n. Oh wow, yeah, that's the bug. I just made a trivial testcase for that and it indeed does not show a validation error! :)\nWorking on a fix now.\n. Yeah, we do catch some errors during parsing, stuff that is parsing-specific (like a missing close parentheses). My guess is local type mismatch checks only happens there, which is very wrong of course...\n. Yeah, that was it. Fix in #620.\n. Ok, I logged into appveyor, but I'm not sure where to find the dropdown you mention?\n. Hmm, I logged in with my github account, but I just get sent to what I guess is the dashboard (a big mostly empty page with \"Welcome to your new AppVeyor account!\"\nIf I try to create a new project it asks for more oath permissions (admin access to webhooks etc.) and has a bunch of options there. Is that the right thing?\n. Ok, it might be those extra auths. I granted them now.\nHowever while granting them it said that for the webassembly org in particular I can just ask for access. So I asked for it, it said it emailed the owners.\n. Ok, all that should be ok now. But after I logging in I still get sent straight to the dashboard. Should I just create a new project? When I do that I get https://ci.appveyor.com/project/kripken/binaryen which looks empty\n. Yeah, I thought it might be that earlier so I edited myself to public. That was almost an hour ago but I still don't see the WebAssembly group among my public groups on my profile though...\n@dschuff, maybe you can try to do this? (you have equal collaborator status as I do on this repo) It should just be logging in as per the first comment in this PR, so just a few seconds to see if you don't hit whatever weirdness is blocking me.\n. No, I'm just a collaborator like you, @dschuff. The owners are I guess the WebAssembly group owners that created the repo for us.\n. Ok, I ran into some testing issues but now everything should be good, if someone wants to take a look.\n@lqd, this implements the tracing stuff we were discussing, let me know what you think. If you want to try it some docs are in the .h c api file.\n. Great, looking forward to hearing how it works for you :)\n. Side note, I also added some docs on the wiki for this.\n. Thanks, a fix for the empty array issue is in #631.\n. The one error on the bots looks like a random one, so this should be good to go. @dschuff?\n. Thanks!\n. I can reproduce the problem. I see it in both a native-wasm and interpret-binary build, though, so this isn't specific to wasm support. But it's possible native wasm makes it more likely due to timing.\nThere are so many layers here I don't have a guess as to what is going wrong. I am also not sure it is in fact wrong - does the TCP spec guarantee it in C? And does the websocket spec in the browser? (I have no idea :) )\nI would suggest making a debuggable build (--profiling, for example) and to add some console.logs in relevant places, to start to see what's going wrong. And then hopefully you can find if emscripten's socket code is doing something wrong, or if it is right and therefore you should file a browser bug with the testcase.\n. I tested in firefox nightly.\nOh, I might have misunderstood the testcase, I thought it was sending data, not receiving? (If sending, I wasn't sure it should get an error if the remote host goes away.)\nHeh, yeah, this is wizardry to us too ;) Things like sockets and GL in particular, there's C code, compiled libc, browser APIs, and system APIs that they call. Lots of layers...\nIf you can't figure it out, I would make as standalone, small, and consistent a testcase as you can and file a browser bug, on the different behavior between the browsers.\n. What is the full command that you run? And what is the full debug output (with EMCC_DEBUG=1 in the env)?\n. Oh, am I wrong in believing that all operations on a NaN return false? So NaN == NaN is false while NaN != NaN is true?\n. Ok, thanks. Maybe some day I'll really understand NaNs ;) I'll prepare a PR to return the eq/ne stuff.\n. Yes, this is normal. While node.js does have APIs for local file access, JS environments in general are sandboxed, and cannot do such things. Instead, emscripten generates a virtual file system, see http://kripken.github.io/emscripten-site/docs/getting_started/Tutorial.html?highlight=filesystem#using-files\nEmscripten also has node-specific ways to access local files, see NODEFS. But note that most development effort is on running emscripten code on the web, using web APIs, and not node.\n. There is still some confusion and flux in the spec about what type-less functions' types are and how they work, see https://github.com/WebAssembly/spec/pull/301 and the discussion there. Once that's sorted out we can figure things out here.\nCurrently what happens here is that to emit the binary format we need to create actual types for functions that are not listed as having types in the wast, since the binary format only has actual types. On the way back, we don't try to undo that, as we have no way of knowing if the type was created just for the binary format, or was always there.\n. Have you seen https://github.com/WebAssembly/design/pull/682? That allows importing tables, which means we can have more than one. Although, I'm not sure of the details yet, as it mentions a \"default\" table and it's not clear how the others can be accessed. I assume those details will be clarified when this reaches the spec repo (which it hasn't yet). Also, that PR began more general, similar to what you propose here with multiple internal tables, might be interesting to read the discussion of why the path changed somewhat.\nVery minor implementation note, (table \"bla\" (type $anyfunc) $b $c $d) should probably have $bla as it is an internal name - quotations are for exported names.\n. Let me know if there is specific feedback you're looking for, reading this now I don't see anything odd or wrong.\n. This was described as for feedback only, so I think it can be closed.. You definitely need emscripten incoming for wasm - master is just too old.\nI'm not sure about the v8 version, you need a very recent one there as well.\n. You can see what is passed there in the code, right above that link. Looks like it's an object whose elements are objects, and they are the imports for the wasm module. So something like\n{\n  env: {\n    func: function() { ..}\n  }\n}\nwould let the wasm module import env.func (module is env, property is func).\n. What kind of docs are you looking for?\nDocs for instantiateModule etc. would be on the wasm design repo.\nOtherwise, people don't normally call those low-level APIs, they just compile programs and let the runtime call main for them. Or, if you want to call methods directly from JS, emscripten has some apis for that.\n. > All that I'm trying to do is see how to include compiled C/C++ code with WebAssembly\nSorry, I don't understand what that means? Compiled C/C++ code becomes WebAssembly.\nThat emcc error might be that the emscripten repo is incoming (1.36.5) while the llvm and clang repos are master (1.36.0), or perhaps incoming but without pulling changes. You need to have all three repos on the same branch.\n. And yes, on incoming the compiler will emit code that calls initiantiateModule automatically. You should not need to look inside the code, it should handle all the wasm integration details for you. Just emcc -s BINARYEN=1 [..] should emit some JS and side files that work when you run that JS.\n. lgtm\n. Also has a commit for https://github.com/WebAssembly/spec/pull/301's change to function type sugar.\n. #654 picks in the 301 change. The 314 change is a one-liner that remains here, waiting for the spec repo to land the 0xd branch.\n. I don't think this is needed anymore.\n. Great, thanks. I think this is all correct currently.\n(Looks like I misspoke earlier when I said 0, I meant the end marker, which is indeed 0x0F.)\n. Overall I don't see anything wrong in the code. But what is the goal here? If it's code for experimentation on a side branch that sounds fine, but I don't think this is something we'd want to merge to master unless the wasm spec changed to have multiple tables.\n. I think multiple tables are something to be considered after the MVP, and it's my understanding that all post-MVP features are yet to be figured out. But I could be wrong.\n. I still have the question from before: while the spec has just one table, I'm not sure we should have multiple table support in binaryen.\nIt's ok to prototype future features in binaryen. If they add no maintenance burden, the master branch can be fine. But in this case, it's a significant change, so my tendency is to keep it on a side branch.\n. No clear decision to land or not land here. Let's close this for now. Please reopen if things change or if I got it wrong.. The appveyor CI is not working well, e.g. this. It queues for very long, and then errors on something not related to this PR. cc @jasonwilliams200OK\nSo I am inclined to merge this and not wait on figuring out the appveyor issue? Any concerns?\n. Looks like no objections, so merging. We'll figure out the appveyor thing later (or maybe it'll fix itself?).\n. If ALL THE CODE is synchronous code then it must execute there in the middle, and that measurement approach is valid. The only risk is if you have something async like setTimeout.\n. What is the output with EMCC_DEBUG=1 in the env?\n. Maybe try 4 backticks before and after to escape the logs? Or put them in a gist?\n. Looks like a problem occurs in spidermonkify. It's actually not needed anymore since binaryen emits the same format that browsers accept (until the next milestone change...), so try the same command without the spidermonkify bit.\n. Might be a mismatch in version. Is that with latest emscripten incoming and firefox nightly? And using default versions of binaryen etc.?\nIf yes, then maybe you are hitting a problem we aren't aware of, can you reduce that to as a small a testcase as possible in source form?\n. Not intentional, just that's all that has been done so far. More could be added to binaryen.idl.\n. @JSStats: what you're suggesting sounds more like for the WebAssembly design than for Binaryen? This issue is just for Binaryen responding to a WebAssembly change.\n@dschuff: I agree that trucking on for a while sounds reasonable, but it's not quite that easy. I've been working towards that in the (increasingly misnamed ;) since it's all about stack now) land-drop branch, and it's been quite a lot of work so far. In addition, it looks like we'd need to rewrite our s-expression parser from scratch. If it's indeed the case that this is a significant amount of work, it seems unwise to do it only to likely get rid of it later - so it makes sense to focus on the change in direction now.\n. Yeah, sexpr-wasm-prototype is perfect for that, it has a proper stack-based interpreter in fact. And I think I saw @binji already has a web port so it could be used as a clientside polyfill (if not I'd be happy to help with that).\nI think in the forked-IR path, if we go that route, binaryen might still end up with some wasm import facilities, but they might not be lossless. For example a \"wasm2byn\" could handle patterns that can't work in an AST by introducing new locals (sort of like the project whose name escapes me that translates wasm into LLVM IR in the sense that it's also not meant to be lossless). And of course we can emit wasm, so optimizing wasm to wasm in binaryen might still be useful, although that's an open question.\n. I am leaning more in the forked-IR direction. I considered in more detail the option of rewriting binaryen to use a single stack-based IR, but I just don't think it makes sense. The original design principles still relevant are\n- A single main IR has major simplicity and efficiency benefits.\n- That single main IR should be transformable so we can run optimization passes on it. (Without this requirement, the single main IR could just be the wasm binary format.)\nBut doing those with a stack machine IR seems very hard. On the one hand it's true that some optimizations are easy to write (e.g. removing dead code) while others become possible (stack-machine specific things). But on the other, consider a simple pass that reduces eqz(gt(x, y)) into lte(x, y) (i.e. !(x > y) into x <= y, which is true on integers). Right now in our AST an eqz node has a pointer to the child node. In a stack machine, options are\n- No child pointer. The child is then defined by the location in the array, and might be right before the parent, but also might not be (and even trickier with more than one child).\n  - Optimization passes would therefore need to maintain an expression stack, and every optimization pass would need to consult that data structure for child operations. This might not be so bad when traversing in the natural direction, but anything else (other orders, random access, etc.) become tricky.\n  - Code receiving a pointer to a node must also receive a \"context\" pointer to the array, as the node by itself is no longer enough (in our AST right now, we've intentionally made it so a node pointer is always enough; in fact expressions stand on their own even without knowing the module, which makes function parallelism trivial).\n  - On the other hand, not having a child pointer would make each node smaller, which is a significant upside. But nodes would still need a \"next\" pointer (forming a linked list) if we want it to be efficient to move nodes around, insert them, etc., which seems like a strong requirement. So this would only help when the number of child nodes is >1. Still significant, but less. \n- Have a child pointer. This means\n  - Node sizes strictly increase compared to our current AST, given the \"next\" pointer.\n  - Each modification of the code needs to be updated in two places, the linked list and the child pointers, which adds overhead compared to now and also introduces bug risk.\n. @qwertie: Yes, I was taken by surprise by the stack machine change. And from what I've seen online and off I was the only browser-vendor person that opposed it. And you can see work going on for it (e.g. in the spec repo). So for better or for worse, I think it's safe to assume it's happening, even if nothing is truly final until it lands, is specced, and ships.\n\nthere are AST equivalents for the new stack machine semantics (have you discovered anything in the stack machine that can't be expressed in AST form with a new operator like 'first'?)\n\nYes, a \"first\" can solve the current issues, with some awkwardness, but as discussed above multi-values are almost certain to happen, and \"pick\" and others seem very possible. It's clear the awkwardness for an AST will increase.\n\nBy maintaining an AST form for Wasm code, you maintain knowledge about the two-way isomorphism between AST and stack machine. I think that's just useful knowledge from an academic perspective. It could be useful to other engineers in the future and useful to the computer science field.\n\nI agree and those are some of the reasons I opposed WebAssembly moving to a stack machine. (My main reason is the negative implications for the text format.)\n\nConverting stack-based wasm to an AST is a potentially useful feature to many people.\n\nI agree, and I think we might still support a form of that, but it wouldn't be lossless. For example, a wasm2binaryen tool might use additional locals for stack machine code we can't directly represent.\n\nAre \"virtual\" nodes really uncomfortable in terms of code complexity, or it is mainly uncomfortable psychologically? If it's the latter, I think you'll get used to it after awhile.\n\nI think there is a fundamental issue here. The optimizer currently has some useful principles like\n- AST nodes ~ work. That makes it easier to write optimization passes. In particular, it is obviously the \"right thing\" in most cases to replace some AST nodes with a smaller number of AST nodes.\n- Removing AST nodes is good. And not just individually as implied by the previous point: if optimization passes decrease the number of nodes, we have a good guarantee of repeated optimization reaching a fixed point (sort of like a loss function in gradient descent or a Lyapunov function in differential equations; i.e., we have a monotonically decreasing function in the number of nodes, and it can't decrease forever, so we must halt).\n- The same points also apply when replacing \"work\" with \"code size\", i.e., when optimizing for size over speed.\nNow, there are exceptions to those principles. For example, a block does no work by itself, e.g. (block (block ..) x) is the same as (block .. x). So we lose the \"AST nodes ~ work\" property. But we do still have the principle that decreasing AST nodes is good (for AST size and code size). Another example is that some math operation might be faster with more nodes, like say turning an integer divide by a constant into a sequence of shifts and adds. That violates the first two principles, so the optimizer has to be careful about it. In this case, we can just not do the reverse of that operation, but it does mean we need to keep that in mind when writing additional integer math optimizations. At least, though, the third principle remains in that more AST nodes means more code size, so we clearly know not to do it when optimizing for size.\nThe problem with \"first\" is even trickier in that all three of those principles are no longer true: adding such nodes can reduce output code size and work, but the opposite is true in other cases. So we can't just not do the inverse, and it isn't trivial what to do when optimizing for size, and so all optimization passes that remove or create \"first\"s must be coordinated. Now, of course this isn't an insurmountable problem. But it (and multi-values, and pick, etc.) add complexity and awkwardness to our optimization IR, and not just in a few places. An AST is just not a good 1-to-1 IR for such stack machine code.\n\nIf \"forked-IR\" means \"an AST-based IR that is very similar to, and easily convertible to, the Wasm stack machine, such that arbitrary Wasm stack-machine code can be converted easily to the IR,\"\n\nNo, sorry, the name might be confusing. Forking here means that we diverge from WebAssembly by not adopting the stack machine elements that are awkward in our AST. A better name might be \"only output wasm\", as it implies wasm is only our output format, while the forked IR is our input format, internal IR, binary and text format, etc. But the direction of Binaryen IR => WebAssembly would remain a very easy and fast operation, of course (since we would be pretty much a subset of WebAssembly).\n. > OIC - \"~\" means \"varies proportionally with\". Aka x \u03b1 y...\nYeah, sorry, I should have been more clear.\n\nIt seems to me you can model most of this with a per-node weight [..]\n\nYes, but the issue is that \"first\" would need to have a negative weight in the context of code size. That's already troubling, but in addition, even that isn't true as the weight depends on the surrounding code, it shouldn't be negative in other cases, so it doesn't even have an intrinsically definable weight.\n\nBut local variables do everything we would use pick for, so I think it'll be awhile before they consider that\n\nIt might be a while, but I hope it'll happen at least for the text format: with pick you can avoid oddities like a let variable that can only be used once and in certain places.\n\ndo you know what the decision-making process is?\n\nI don't know that there is anything formal written up. For the informal stuff I'm not sure since I'm not very good at politics ;)\n. Imagine that we want to do a call, set it to a local, a store, and then use the call result (and the store and the call can't be reordered):\n(i32.eqz\n  (first\n    (tee_local $x (call ..))\n    (store ..)\n  )\n)\nvs.\n(set_local $x (call ..))\n(store ..)\n(i32.eqz\n  (get_local $x)\n)\nBoth of those have 5 AST nodes, but the former has one less node in the stack machine output since it doesn't need the get_local.\n. @qwertie: sure, but it can't be zero in other cases, and a specific non-zero value might work in some but not others.\nThe underlying issue is that in a stack machine, it's easy to see the cost of this operator (or rather, what it does, since it doesn't exist there). In an AST an analysis is needed to calculate the cost.\n. At this stage I'd like to propose that we go in the forked-IR, aka \"only output wasm\" direction:\n- The internal IR, our AST, does not change, but it is now called Binaryen IR. In time it will diverge from WebAssembly (e.g. on the stack machine issue) but it will remain a core goal to stay as close as possible (same types, semantics, etc.) and basically to have an IR that trivially compiles to WebAssembly with almost no work because it's practically WebAssembly already.\n- We no longer focus on WebAssembly as an input. It is an output for us, and it is our primary output aside from our internal IR. (But see wasm2byn below.)\n- Our main focus is on supporting compilers to WebAssembly, e.g., asm2wasm, mir2wasm, s2wasm, etc. The more specific goals when supporting such compilers remain unchanged: to make it easy to write a compiler to WebAssembly, to be fast, and to emit good code.\n- The current binary format support we have becomes the Binaryen IR Binary Format, perhaps with suffix .byn (pronounced \"bine\"; see previous discussion).\n- The current s-expression support we have becomes the Binaryen IR Text Format, perhaps with suffix .tyn (pronounced \"tine\"; spelling is parallel to .byn, replacing 'b' for binary with 't' for text). Our own .wast files in the test suite are renamed to the new suffix.\n- asm2wasm => asm2byn, wasm-as => byn-as, wasm-dis => byn-dis, wasm-opt => byn-opt, wasm-shell => byn-shell. No actual change but input and output where relevant are switched from WebAssembly to Binaryen IR.\n- Add a byn2wasm tool that emits WebAssembly. As our current binary format is identical to wasm, we can share almost all that code for now (just have a flag for the divergent points). emcc will call this tool to emit the wasm binary when compiling, etc.\n- wasm.js => byn-emcc.js, this integrates with emcc and allow running Binaryen IR in a compiled interpreter in JS. Useful for toolchain testing, testing the Binaryen IR interpreter (which is important since we use it in the compiler, e.g. --precompute so far), and ensuring our semantics don't diverge too much from WebAssembly. (I previously considered removing this, but changed my mind.)\n- binaryen.js was a standalone wasm interpreter. We no longer input wasm, so we leave that to other tools, and can remove it. (But see wasm2byn below.)\n- s2wasm => s2byn, it would now emit Binaryen IR. Note that s2wasm must track changes in the wasm backend, which for now doesn't emit stack machine code that is a problem for our IR, but if that happens, s2wasm might need to do lossy conversion (see wasm2byn below).\n- We can still run a subset of the wasm spec tests, basically everything but where stack machine notation pops up. This would let us keep coverage on all the rest of the suite, which is very useful for testing our interpreter and keeping our semantics as close as possible to WebAssembly. And it makes sense to keep our text format compatible with .wast files as much as possible anyhow (and as with the binary format almost all the parsing code could be shared).\n- wasm.h, wasm-validation.h and so forth become byn-*.h, etc.\n- Internally, we use the variable name \"wasm\" for a module in various places, that should be renamed to \"module\".\n(Assuming we agree on this proposal, I am of course signing up to do all the above work; but if anyone wants to help that's great.)\nPossible future steps, worth mentioning now since they might influence the discussion:\n- With our own text and binary formats, I think it makes sense to introduce optional basic block + branches support. We have that support in our C and C++ APIs already, in the form of the relooper API and its IR, so this would just reflect that in our IR's text and binary formats. This would be little work. It would help in internal testing as well as external compilers, e.g., right now mir2wasm uses the Binaryen C API with the relooper, and if we add basic blocks to the text and binary formats then it and similar projects could in principle generate one of those formats directly if they prefer. Basically, this would make our IR easy to target for a wide range of compilers: AST-based or CFG based, both would be supported.\n- Introduce a more sophisticated wasm output layer, that can e.g. reorder stack machine code into forms we can't directly represent in our IR. This might be a secondary IR.\n- Introduce a wasm2byn tool that imports WebAssembly. This would not be lossless as we can't represent all WebAssembly directly, so it might e.g. use more locals for some stack machine code, etc. But overall it would be a simple importer to write, and could be useful for various things even without being lossless, like a wasm-to-wasm optimizer, a standalone wasm interpreter, etc. (which would be trivial by just chaining wasm2byn to our byn* tools).\nThoughts?\n. @JSStats: I agree we need a plan for multi-values, and if we don't have a good one then we can't move forward here.\nOne option is to just not add them to our AST. This assumes we can still generate good code without it. I don't know if that's true.\nAnother is to add it to our AST with something like\n(set_local_multi $x $y\n  (multi\n    (..expression to assign to $x..)\n    (..expression to assign to $y..)\n  )\n)\ni.e. multi creates a multiple value, and set_local_multi can destructure it into components and assign them into separate locals. And multiple values can flow through blocks, ifs, and function returns. This seems plausible, but I'm not sure.\n. I definitely don't want to define a new VM or machine format or platform here. The only goal I have in mind is a library that makes compiling to wasm easy, fast, and emits good code. Period.\nAnd I believe an interpreter serves that goal very well:\n- In the --precompute pass, in just a few lines we find stuff the interpreter can run and replace it with the result. This is much, much easier than writing such a pass by hand, and it also has a guarantee of working on all of our IR.\n- This could also be used to remove global ctors by running them at compile time. Emscripten's asm.js optimizer does this now (by running the asm.js in a JS engine!). Compare this to LLVM's GlobalOpt which tries to do the same, but just handles the IR that it was written to handle, and aborts otherwise (e.g. it fails on removing the ctors added in a C++ iostream hello world).\n- A first-class interpreter is also very useful for testing. I've wished many times LLVM's lli worked better than it does.\nAnd we already have a fully-functional interpreter now, so it makes sense to keep it.\nRegarding a binary format: it's useful for the same reasons LLVM has a binary format, it's convenient and fast (in particular it will improve our compile times, unless we write all-in-one tools instead of chaining independent ones). And as with an interpreter, we already have one.\nLinking: I don't feel strongly about this one. On the one hand it could be useful (like llvm-link is useful). But it seems very low priority at best.\nStability: I agree, not a goal. (While in theory it could help compilers targeting us, the burden on us would be far too great.)\nCFG support: You're right that adding this to our IR formats diverges us more from wasm. But:\n- Not by a lot. Literally it's just adding something like (cfg (..block1..) (..) ..). It's not much of a divergence.\n- It's useful. As you said, many compilers want to emit CFGs. Why should they need to use our C API if the IR format would be easier for them?\n- It would also be easier for us for testing, look at the current relooper tests, it's a bunch of ugly C programs using the C API. It would be much nicer to use IR in text form. Just like in LLVM, you want to write tests in IR, you don't want to write C programs using the LLVM C API.\nI'm not happy about diverging from wasm, and would still love to find a way to avoid it. But it does have upsides, like being able to make small but useful additions to our IR formats such as CFG support.\n. Another reason for Binaryen to have its own file format (and not keep using wasm) is that wasm's stack machine pivot causes some issues with unreachable code, namely that adding or removing a branch that alters code reachability can turn wasm code from valid to invalid and vice versa. Details are still being discussed last I heard, but that seems like an annoying property in an object file format (especially when bringing up a new compiler).\nOverall, I think it's fair to say that wasm is focused on what browsers want to consume, while an object file format would have somewhat different objectives in my opinion:\n- Fast to link object files together (O(1) with low constant factor)\n- Fast to \"link\" an object file to a shippable wasm file that browsers can consume\n- As optimizable/LTOable as possible given those constraints (since on the web code size matters more than any other platform by a huge margin)\n- As easy as possible for compilers to emit\n.byn files as described above should be able to achieve those goals (fast linking hasn't changed; \"link\" to wasm is an almost trivial operation since types&semantics are essentially identical; optimizability is pretty good by being AST-based, as evidence we have the current Binaryen IR optimization passes; relatively easy to emit by avoiding stack oddities as mentioned above, and also as discussed earlier we can add CFG support, etc.).\nI had originally thought that the toolchain using raw wasm files for object files was an excellent opportunity for wasm - avoiding an extra format simplifies the ecosystem substantially. And that led to the original Binaryen design. But I think that's just not viable any more, wasm's design is evolving in ways that make sense for browsers but have downsides for toolchains. A single format can't fit all I suppose.\n. Very good points.\nFirst note, I think we should prototype and measure this, and shouldn't decide without that (e.g. converting byn to wasm for linking is a nice idea, but if it adds overhead, it might make sense to implement direct byn linking or something else).\nA second and larger issue: I didn't get into this earlier, but byn files aren't just useful for optimizing. Their being in an AST form which is higher-level than wasm's stack machine makes them more introspectable. In particular, as I've argued for a long time I believe wasm has been going down a bad path in terms of its text format, which I worry might be less usable than e.g. LLVM IR and asm.js. Perhaps a novel wasm text format will help there in the future, but I'm skeptical. And introspectability of object files matters a lot, this is a crucial part of toolchain usability. LLVM got this right pretty early, for example, to its great benefit.\nThat's one reason why I mentioned before that binaryen's byn files could have a parallel tyn text format. That would be AST-based and as it diverges from s-expression format, we could turn it into something nice. We could also evolve byn and tyn files together for their mutual benefit, without being tied down by wasm binary format decisions that are regrettable from a text format viewpoint.\nAgain, the big picture here is that wasm is making something browsers want to consume first and foremost. It's not meant to be an object file format. I believed it would also make a good one in the early days, but optimizability and introspectability make me think it no longer is.\nI do see your points about some people wanting to emit and link raw wasm files. But I'd like to convince you and them not to do that ;) Think about wasm files as a weird browser deployment format, like gzip: every compiled program shipping on the web will be gzipped, but compilers don't gzip, they leave that to a specific tool. Likewise, there is no need for people to emit wasm directly - and it will get harder over time, in particular with layer 1 etc. - we just need to make the tool that generates wasm files super-easy to use like gzip.\nA huge motivation we had in the past for emitting wasm directly was for super-fast linking. But we can get that with byn files too. Given that, and the points above, I don't see much benefit to compilers emitting wasm directly. But, I'm not opposed either; we could just implement all the above and see how the ecosystem evolves.\n. @qwertie \n\nWhere did this name \"byn\" come from\n\nLiterally from shortening binaryen. This is meant to be a binary file format for Binaryen IR. But I think once we experiment with it, it might be a useful object format more generally, we'll see how things evolve.\nAbout the text format, there was discussion in issues and PRs. For example this and this. Also PRs modifying TextFormat.md are relevant, could be more there.\nBut sadly much of the debate was not public. To summarize that, I've been saying that we should consider the text format as part of the wasm design, and not be left to the end; and I've opposed changes to wasm that I believe make it less structured and less of an AST as I believe ASTs are significantly better for text representation. But on both the group went another way.\nAt this point, it was decided as mentioned elsewhere to use a linear list of stack machine instructions for the wasm text format, since there just isn't time to do anything more given the current design of wasm (a stack machine) and the timetable (short). I think that's why your issues have not received responses.\n. I'm not sure what you mean by structured here, but in any case, all I meant was that given wasm's current design as a stack machine, there is really just one natural text format, a simple linear list (plus blocks etc). It's essentially just writing the binary format as text, in its natural order. And it was agreed to have that as the wasm text format, so I don't think anyone is interested to talk about other options. I think that makes sense given where we are at this point (but as mentioned before I did all I could throughout the process to convince people to avoid getting there).\nFor example, code that conceptually does this (and that I wish we could represent as this!),\nif (x == y) {\n  x = 1;\n}\nwill look something like this in the wasm text format:\nget_local y\nget_local x\ni32.eq\nif\n  i32.const 1\n  set_local x\nend\nIf LES is compatible with that, then perhaps it's worth stressing that.\n. Fair points in that post and in discussion today. Maybe I'm signing up for too much work too early by laying out a large plan here. Instead, a more incremental plan might be\n- Keep the current AST as it is, i.e. not follow wasm into full stack machine land.\n- All tools remain as is, i.e. we still have wasm-as, wasm-dis, etc., but, importing wasm in wasm-as is no longer 1-to-1 in all cases (if it encounters overly-stacky code, it might use extra locals or such to fit it into our AST), and importing wasm in s-expression format might have some limitations too.\n- Rephase the project's goals to something in between the current (\"compiler and toolchain library for wasm, i.e. helps do stuff on wasm\") and new proposal (\"compiler library for wasm, helps builds compilers to wasm\"). Not sure exactly where in the middle. On the one hand the loss of 1-1 wasm import means we aren't a fully general wasm library any more. Yet, for practical purposes, maybe we are good enough, or maybe this is a temporary limitation we'll end up fixing (with a second IR as discussed above).\n- I'll do some prototyping of the optimization and object format stuff discussed above, as well as introspectability, and see how that goes before proposing a more elaborate big plan.\n. @JSStats: Regarding multiple values, my perspective is that we can do them in a second IR if that is necessary. But it seems premature to think it will be - wasm isn't adding multiple values based on perf data that I am aware of. It seems possible a compiler emitting wasm without multiple values (perhaps with just simple support for function calls) will still be high-performance.\nRegarding the lossless transform, the implications of it are discussed above in this issue - it means some new AST nodes with awkward semantics that have downsides for the Binaryen optimizer. But if we add a secondary IR at the stack machine level, then it could do multiple value opts if that makes sense, and a lossless import of wasm to that IR would of course be possible.\n. @JSStats: there are examples in the discussion earlier in this issue (e.g. here).\n. @qwertie: interesting, I didn't realize LES could do that. It's too bad your proposal isn't getting more attention, I agree.\nAbout first: It can't have zero weight, e.g. assuming the order of operations allows it we want to do this transform:\n```\n(block\n  (call a)\n  (call b\n    (first\n      (call c)\n      (call d)\n    )\n  )\n  (call e)\n)\n==>\n(block\n  (call a)\n  (call b\n    (call c)\n  )\n  (call d)\n  (call e)\n)\n```\nAs for it having positive weight, the example from before showed it must have the smallest positive weight (as the other nodes it is compared to could be arbitrary), which is a global constraint on the AST and its weight system - are we sure we don't need some other node to have the smallest weight, now and in the future?\nThat leaves a negative weight or something more complicated than a fixed weight. Of course it's doable, but I just don't think the complexity in the main IR is worth it. A secondary IR dedicated to stack machine-style opts would be the natural place for it and related things (multi-values, etc.).\n. I think there are big differences in text usability between those categories:\n1. x86 or ARM assembly is very low-level and has a lot of target specific noise.\n2. JVM and CLR bytecode on the other hand is portable, and also contains higher-level information like objects.\n3. Minified JS (with prettified whitespace) has the benefits of 2, plus (a) structured control flow, (b) nested expressions, and (c) is still a human-readable/writable language, so you can easily hack in new code while debugging it.\nAnd asm.js is somewhere between 2 and 3 (has structured control flow, nested expressions, and hackability; lacks obvious objects).\nSo while I agree we need to keep people's expectations realistic, I think we can be pretty close to what the web currently has (minified JS, asm.js). The wasm MVP isn't going to do that, as it's shipping a linear list of stack machine instructions (somewhere between 1 and 2 - portable like 2, but no objects). And while wasm might get a better text format later, without an AST it will always have to deal with non-AST patterns, which means it's going to be no better than decompiled linear code as in 1 and 2 (decompilers can sometimes do a good job of course, but sometimes they don't) and it's hard to hope it will have hackability as in 3c. So I'd argue that would still be worse than asm.js.\nAnyhow, if in fact wasm gets a better text format later, Binaryen could adopt it as its text format, and just like Binaryen's IR is the AST-friendly subset of wasm stack machine code, Binaryen's text format would be the AST-friendly subset of the new text format. Which would avoid the issues just mentioned and so be comparable to asm.js, but also strictly better than it (no annoying coercions, etc.). We'd also have the option to alter Binaryen IR in ways that help the text format, if we find that makes sense.\n. @qwertie: I actually think the bikeshedding of small syntax stuff (like opcode names as you mentioned) is exactly something they want to avoid. The sentiment seemed to be \"we'll just ship the flat s-expr format of what we have now, there is nothing left to fiddle with, we have no time for that\".\nIf you still want to push LES as an option, I think one possible productive route could be to make a browser addon that shows LES for wasm modules in the developer tools. Seeing it in action could convince people. Especially if your addon receives interest from the developer community.\nAbout that last transform: it's beneficial to do things like it because by removing unnecessary nodes the code is easier for other passes to optimize (the more canonical the representation, the better, passes depend on such conventions). A further reason is that removing nodes makes later optimization passes faster. In fact the Binaryen optimizer does that transform now with blocks, for those reasons.\n. @lukehutch Personally I agree with you - I think it was a mistake for wasm to make this change.\nHowever, the specific arguments about perf are mostly incorrect - it's true that executing a stack machine can be very inefficient compared to a register machine etc., but the goal in wasm isn't to actually execute the code that way - VMs would translate it to something efficient first (optimized machine code in most cases).\nWith that out of the way, as I said, I definitely agree that the stack machine change was a bad idea for the rest of your reasons - code transparency, readability, learnability. And more generally, openness in the wide sense.\nSadly I don't think there is much of a chance to revisit this. The small group of people driving the wasm design are all in agreement on this matter (as you quoted), and everyone is working hard towards shipping. But, if you want to try, then opening an issue on the wasm design repo would be the right place.\n. Yeah, it's true that\n\nThis shows that the stack architecture and its non-optimizing compilers were wasting over half of the power of the underlying hardware.\n\nBut in wasm we are talking about optimizing compilers, and specifically ones using SSA IRs. The wasm stack machine code is translated into the VM's SSA IR, at which point it doesn't matter if it came from a stack machine representation or register machine representation or AST or anything else - it's a bunch of operations on virtual registers in basic blocks in a CFG. Then it can be optimized exactly like the best native compilers do today.\nWe also have perf numbers on wasm running in current VMs - it's very close to native speed. asm.js was already close, and wasm improves on that. So throughput is just not an issue here.\n. The problem is that SSA form is not compact - it's much larger than an AST or stack-based representation.. @rossberg-chromium, that's the current state now, but if as expected wasm ends up adding stacky operations like pick, multiple return values, etc., then the situation for the inverse will worsen, won't it? Or has something changed?. > However, if the fundamental stack-based execution model of wasm is preserved even in the AOT-compiled code, meaning that there is an actual stack machine (beyond the call stack) used to store all intermediate values even in compiled code, then there are enormous efficiency implications. \nAs mentioned above, nothing to worry about: the stack machine representation is converted into standard compiler SSA form and optimized, just like clang or gcc would, into machine code. That is how SpiderMonkey and V8 work right now, so you can benchmark this if you want, no need to speculate. For example, here's emscripten's corrections benchmark:\ntest_corrections (test_benchmark.benchmark) ... \n        clang: mean: 14.877 (+-0.001) secs  median: 14.877  range: 14.876-14.878  (noise: 0.004%)  (3 runs)\n     sm-asmjs: mean: 16.035 (+-0.105) secs  median: 15.961  range: 15.948-16.183  (noise: 0.658%)  (3 runs)   Relative: 1.08 X slower\n      sm-wasm: mean: 15.561 (+-0.210) secs  median: 15.412  range: 15.408-15.857  (noise: 1.348%)  (3 runs)   Relative: 1.05 X slower\nok\nThat shows asm.js being 8% slower than native clang, and wasm is slightly faster, at 5% slower.. Could be those, but it could also be noise - gcc and clang have differences between them too, often much larger. Sometimes one register allocator happens to work better on a particular function, etc.. Nice! How functional is this - can the emscripten test suite exceptions tests pass?\n. Great, thanks.\n. My guess is some local problem happened on your machine, like running out of memory or disk space. Does this happen consistently? Trying a rebuild from scratch might also help.\n. The problem is that wasm % can trap (on corner cases) while asm.js % cannot. But if you build with asm2wasm --imprecise it will ignore the corner cases, and do what you want here.\nI am surprised about that browser error you saw, though. Do you have a testcase + full steps to reproduce?\n. That looks like invalid asm.js. You must coerce on a % because otherwise it can't tell if it's a signed or unsigned operation.\nI didn't realize you were using handwritten asm.js here. asm2wasm is only tested on emscripten output, so it's possible you'll find bugs, although in this case, I'm not sure yet.\n. It would be great if it did work on all asm.js, just I've only had time for emscripten output ;) Fixes for non-emscripten output would be welcome of course.\n. See https://github.com/WebAssembly/design/issues/736 and in particular https://github.com/WebAssembly/design/issues/736#issuecomment-236727305 and https://github.com/WebAssembly/design/issues/736#issuecomment-236964205\n. This is now good to go if anyone wants to review, I added table element offset support too.\n. Thanks @rossberg-chromium.\n. Those commands look ok. What is the error you see in the console?\n. Oh, is the error you see in the console what's in the title? \"Import #0 module=\"env\" function=\"abort\" error: FFI is not an object\"? I missed it the first time I read this.\nThen the error is that the module is trying to import env.abort. But when you instantiate the module, you don't provide any imports.\nBy default emcc will generate a .js file that will instantiate the wasm module and pass it the necessary imports automatically for you.\nInstead, if you want to instantiate it yourself, you can look in the .wast at what it expects. However, you'll need to match the ABI expectations as well, like creating the stack, libc syscall imports if you print etc. In other words, emcc emits wasm files that are not standalone, they are designed to work with the .js file emcc emits for you.\nIn theory a wasm file could be standalone, if you don't use any imports, manage your own stack, etc. and just provide exports that are called from outside. You can try to experiment with this using the ONLY_MY_CODE option to emcc, but it's not much tested yet - the main focus in emscripten has been to get C and C++ programs to \"just work\". Doing that requires some JS, e.g., to print output, to receive input, to handle a virtual filesystem, to render to canvas, etc. But it would be good to improve support for standalone wasm files using ONLY_MY_CODE too.\n. We don't really have a good way to generate a standalone wasm file yet from C or C++. As I said, you can try emcc's ONLY_MY_CODE, but it's not likely to work. This is an area that needs more work. It's just not easy to do, as C and C++ programs tend to need things we can't do in pure wasm right now, like print. But, we could define a new ABI that makes it practical, I think.\nAlternatively, if you're not using C or C++, then you can use binaryen directly to generate code, and then you can generate exactly what you want in terms of imports and exports and code. The mir2wasm project is doing that for Rust, for example.\n. What do you mean \"work with asm.js and wasm\"?\n. And what do you mean by minimal? Something smaller than emcc generates for you?\nAs explained above, we don't have a way to have a truly standalone wasm file, so something smaller than emcc generates isn't yet possible.\nHowever, I am working on dynamic linking of wasm now, and that might be a route to get there. On the linking branch in this repo and binaryen-linking branches in emscripten and emscripten-fastcomp, basic shared modules of wasm are starting to work. We could in fact create a mostly standalone way to load those, with some ABI definitions. Still things to figure out though like the C stack.\n. Maybe take a look at https://github.com/WebAssembly/binaryen/commit/dcebddda8cdea0686e7dcf6cb938b25d79e113b9. That's in the stack branch which hasn't landed yet. We should do whichever is better of the two commits, or combine them.\n. Ok, maybe I'll do that. I was hoping to get all of stack merged sooner rather than later, but that's not how it ended up...\n. In general we've tagged versions and moved to the next version on master, which makes sense since we have a lot of code churn - so putting 0xc features on a side branch would mean either doing all development on 0xc, or a lot of rebasing between the two.\nBut so far I haven't had a need to do anything 0xc specific on master, I've landed globals, tables and memories without breaking support for 0xb. However, that will probably change soon.\n. This looks correct to me. It requires support on the emscripten side too of course, the externs needs to be read as in the asm.js path (also in emscripten.py), and that information sent into the JS compiler (compiler.js) which will then fetch the relevant parts of the JS library for that (and indeed environ is implemented there).\nThe one tricky thing left is to connect the external symbol. What happens in asm.js is that we import a constant, which contains the address. That works basically just as in dynamic linking in fact. In the asm2wasm path, we implement that using an asm.js import which is translated into a \"mapped global\", that we store in .mappedGlobals, but the nicer thing would be to have an actual global as wasm is now getting - see discussion in #675. If we agree to use globals for things like this, it would make this very easy.\n. The stack branch together with emscripten's binaryen-stack branch now support importing the mem init into the asm2wasm output module.\nOne tricky part is that when we use the binaryen fallback modes of asmjs or interpret-asm2wasm, then our input is the side asm.js file. So if a fallback is to be possible, we don't import it and leave it in a side file. Otherwise, we always import it.\n. This commit on the stack branch moves asm2wasm to use wasm globals, and stops using .mappedGlobals files: 261efaa8f11e3a087ad60a0a0000ddb3f8a2c2da\n. This was done.. Thanks!\n. (commits starting with TEMP, FIXME, WIP can be ignored and removed before or after landing)\n. Fuzzing asm2wasm for a while also looks good.\n. There is a parallel binaryen-stack branch in the emscripten repo now, that is meant to work with this. When we merge this we should merge them together.\n. The last asm2wasm fixes here allow the emterpreter to run in wasm.\nIn polyfill testing mode, that means that our program's code is compiled into emterpreter bytecode, which is run in the emterpreter's interpreter, which is compiled from asm.js to wasm, which is run in the polyfill wasm interpreter, which is an interpreter compiled from C++ to asm.js, which is then run in a JS engine. (The meme writes itself.)\n. Any objections to me cleaning this up a little and landing it?\nThe main downside is that the wasm backend and s2wasm stuff would all be disabled on master (since it's not updated yet for 0xc/stack). The upside is that this PR is big, and people are filing bugs on master that are already fixed (e.g. https://github.com/kripken/emscripten/issues/4531).\n. Btw, I ran csmith fuzzing on the asm2wasm path on this branch for 4 days, and found just one minor bug (when running asm2wasm itself compiled to JS, which we do for testing but users would normally run asm2wasm natively, which works ok).\n. Sounds good. I commented in that issue now with one possible quick fix.\n. Rebased, cleaned up a little, and re-enabled spec tests on latest upstream stack branch. This is good to land whenever you are ready.\n. Spec repo now has a PR with the new import/export stuff with a concrete syntax, which differs from the temporary one I guessed here. Added a commit for imports now.\n. @dschuff, ping - are you ok with this landing?\nMeanwhile I did some more parsing work here for upcoming spec repo changes.\n. Yes, in this PR that's disabled. There are the handwritten and autogenerated tests etc. that need to be fixed up, unless you've already done that?\nIf not, what do you think about landing this first?\n. Anyone know why appveyor keeps failing? There isn't a build to check an error on, weird.\n. @dschuff: ping - are you ok to land this? (needs a merge fix which I'll fix, and later on master we can figure out the .s/wasm-backend tests)\n. Ok, rebased and tests passed, merging.\n. Thanks!\nIn build-js.sh, how about using the env var $EMSCRIPTEN? Then people could write emmake build-js.sh which is consistent with general emscripten build instructions (similar to emmake make). I'm also ok with supporting both a commandline parameter and the env var.\n. Something seems to have gone wrong here, travis reports the binaryen.js test now fails.\n. Looks great, I had just one last question about the emcc flags.\nAlso, please join the wasm group before we merge.\n. Nice data. Yeah, that's fairly consistent with other projects I've seen. I'm always surprised how useful duplicate function elimination is, but it seems to help on any large-enough C++ codebase.\nBtw, does build-js.sh work if $EMSCRIPTEN is not defined? It might be nice to not fail in that case if em++ is in the path already.\n. Thanks! Is this ready to land?\n. Great stuff, thanks!\n. lgtm\n. lgtm\n. Thanks, this is great! :)\nCan you please join the working group if you haven't already, before we merge?\n. Excellent, thanks again!\n. The wasm backend doesn't emit fully standalone code. The supported code path is to use emcc to invoke that backend, then it will generate a JS file as well that does all the gluing necessary around the wasm file.\nThe specific glue problem here is that the stack pointer is initialized by code from outside, Without that glue, memory is indeed 0 and decreasing it gives an invalid pointer.\n. Currently yes, but now that wasm has proper globals, the nice thing would be for the wasm backend/s2wasm to use a global for the stack pointer (as asm2wasm now does on the stack branch).\n. Similar logic motivates importing the table as well.\n. Memory and table importing implemented in 6c12d228a11aba93d2b3083fd996ed4f42b214f2 and f5a0be638f27257250f28837843fa0b11b1837d1 on the stack branch.\n. This was done.. I think this would be useful, but the overhead for doing the mirroring is a concern. I know there are automatic systems for this, like e.g. launchpad, but not sure if there is something for github.\n. The error at runtime is\nuncaught exception: Assertion failed: fmod(getNumber(), 1) == 0, at: src/emscripten-optimizer/simple_ast.h,229,getInteger at jsStackTrace@a.out.js:796:12\nSomething we expect to be an integer, is not an integer.\n. ..and this turns out to have been a SpiderMonkey bug, as it did not manifest with --no-ion. It also appears to already be fixed on trunk.\n. Cool.\n. I've never written a browser addon myself, but I hear it's fairly simple and APIs are even similar between browsers. Here are the current firefox docs for example: https://developer.mozilla.org/en-US/Add-ons/WebExtensions/Your_first_WebExtension\nI see your concern that changing punctuation is harder after the spec is done. But there is plenty of time to write an addon and see if the dev community likes it. The spec won't be done for quite a while.\nBinaryen integration would be welcome of course (assuming the usual stuff: it's modular, tested, and maintained). And it can also be a way to show LES in practice and try to get interest. However, I think a browser addon is your best bet, it can reach many more people.\n. I hope addon APIs let you hook into the debugger somehow, but I'm not sure - just need to read the APIs. If not, you could make an addon that inspects wasm script tags from the HTML perhaps. Might be worth looking at related addons that are open source.\nFor parsing a wasm binary, probably someone did write such JS code - but with all the wasm churn I doubt it's up to date. What I would do is write the main part in C++, using say Binaryen, and build it to JS (see binaryen.js in this repo for something related which could be a basis).\n. asm2wasm doesn't use the wasm-s-parser stuff that is failing, so I suspect that is the OptimizeInstructions startup code which parses the list of optimizations. In a debug build the stack trace could show it more clearly.\nIt should basically be parsing src/passes/OptimizeInstructions.wast.processed which is included in the middle of src/passes/OptimizeInstructions.cpp. Is the first file of those modified locally perhaps? If not, maybe some line ending issue on windows?\n. Good find! Yes, I think that's the bug here.\nThe fix is indeed to create it not during startup. Probably in the global scope it could be a pointer set to null, and initialized if not already initialized, in the constructor of OptimizeInstructions. There might need to be thread-safety, though, as multiple such objects can be created (although I believe we currently create them all on the main thread).\n. This should now be fixed. Thanks again for reporting this and finding the problem.\n. Thank you, this is very useful!\nJust 2 tiny comments above before we merge. Also, please join the wasm group if you haven't already.\n. Great, thanks again!\n. Looks like no concerns, merging since I've gotten reports of people hitting these issues. If there are comments later we can address them in followups.\n. At this point, the binaryen optimizer is of comparable power to the asm.js optimizer in emscripten, in fact it often emits better code than it. When I started this PR last week I wasn't sure it was realistic, but I'm happy to have been overly skeptical.\nThis is good for 2 reasons:\n- It means the binaryen optimizer does a good job, since the asm.js optimizer has been enough to get us from naive fastcomp output into something that competes with native. And that's good since the binaryen optimizer can be used as a general wasm last-stage \"minifier\" by anyone shipping wasm.\n- We can disable the asm.js optimizer when in binaryen mode, i.e. instead of fastcomp=>asm.js opts=>asm2wasm=>binaryen opts we can skip the second stage, and the result is still good, and this significantly speeds up compilation times.\nThis isn't quite ready to land though, I'll run more tests and fuzzing. (Not running the asm.js optimizer exposes a lot more code to the binaryen optimizer, which I'm sure will find bugs, and also this PR has a bunch of new opts.)\nThere is a binaryen-opts branch in emscripten for the emscripten changes that correspond to this PR.\n. Ok, this should be good to go. Tests and fuzzing pass after the last commits fix some \"interesting\" issues that turned up.\n. lgtm\n. Is this something you intend to land soon, or keep open for more things?\nI ask because I'll start to work on 0xc changes soon. That might cause merge conflicts, I'm not sure.\n. Cool.\n. Implemented and merged. emcc.py parts are in binaryen-opts branch.\n. Your process looks correct. The next thing to check is to run the browser profiler on the asm.js and wasm cases, and look if there is something obviously different. (Build with --profiling for this.)\nIn general, my guess is that you are hitting something not yet optimized in wasm. Due to how wasm works, it has a slightly different libc, for example. That should show up in the profiler if so.\n. Yeah, I actually did all the import/export stuff I could earlier, before stack merged to 0xc, to try to save time now. But it was still quite a lot left, turns out...\nAnyhow, I did part of the 2nd item from before (wasm.h refactoring), and it finally gets us to pass imports.wast. Now things pass up to labels.wast. I'm not sure what's wrong there yet, so still hard to estimate how much work is left here. But hopefully we can leave of further major refactoring for later.\n. Spec tests now seem to all pass, except for some I disabled like stack.wast and typecheck.wast.\n. Ok, PR with 0xc spec test support, and PR with that 0xc binary support have both landed.\n@dschuff, are you planning to continue work on finishing binary support?\n. This basically done, closing.\n. Yeah, I didn't read the current JS API yet, but you're probably right. Easiest to debug this with functional VMs, I'll look into that when it's feasible (current attempts hit issues in VMs, which I filed and am waiting on).\n. @dschuff: what do you think about landing this? it touches the binary format code a little, I don't want to interfere with your work.\n. lgtm\n. Yeah this is all quite wip, I'll split it out. For fuzzing purposes that patch is helpful so it's here, but it shouldn't be here when this is merged of course.\nBut regarding alias.wast: that's the first test alphabetically that it appears in. The problem is in many other tests too.\n. Actually let me close this PR, I'm seeing a bunch of errors from fuzzing so I'll open a bunch of separate PRs.\n. I did some poking around,\n- Manually adding .result i32 to __exit helps, it then prints out a proper wast when drop validation is ignored. This suggests the wasm backend is emitting it wrong?\n- However, it still doesn't validate properly in memory with drop validation, as the type of the call node is none (and it is dropped, which is wrong). One odd thing there is that the call isn't dropped in the .s file, which maybe it should? Anyhow, somehow s2wasm needs to know the type of the function called and set the type of the call node properly. Perhaps this can be done in a post-pass (asm2wasm does it that way), but explicit drop in the .s file (with the type) would be another way.\n. AutoDrop issue is fixed in #710. Looks like after that I can run the fuzzer on libc++ for a while without finding an issue.\n. This also uncovered a tiny bug with if values in simplify-locals, added a fix.\n. Interesting, I see. Ok, it does look like we need to fix that type checking. I can look into that, I opened the type-check-block-sigs branch for that, initial work shows it shouldn't be too hard. Most of the work was updating tests so far.\nMeanwhile this looks good to land to me, once the type checking is fixed we can remove the hack.\n. @dschuff: Ok, in that branch I have things mostly working with the new type checking. Spec tests all pass. One problem though is that the binary format tests don't work, perhaps related to the hack implemented in this PR? That branch is based off this one, and doesn't alter the hack - is that expected to work?\nIf you have a minute to look at it, build that branch, copy the main module in test/spec/br.wast into a file, then run wasm-as and wasm-dis on it, then wasm-shell on that output, and it gives some errors that it didn't give on the original file before binary.\n. @dschuff: yeah, sounds good to me to merge this. we can figure out the stuff in #717 later.\n. s2wasm was fixed, and I also fixed the issue noted in https://github.com/WebAssembly/binaryen/pull/718#issuecomment-250322593, so this should be good to go now.\n. Yeah, things have changed and that mappedGlobals file is obsolete. spidermonkify is out of date in other words. It is deprecated at this point, in fact, and I removed it from the docs - unless you found somewhere it is still mentioned?\nThe current status is that browsers just got updated to 0xc. But there isn't currently a way to build code to 0xc, and spidermonkify can't help (hacks like spidermonkify only work if spidermonkey can read a text file binaryen emits, but the 0xc changes are just far too big for that workaround). However, binaryen passes the 0xc spec tests so we should be close to being able to emit code that runs in browsers. @dschuff is working on the last binary format pieces.\n. Which version of emscripten is that, and which version of binaryen? Development is going on on emscripten incoming and binaryen master, so if you aren't already there I would try to reproduce the problem there.\n. Ok, then this just isn't stable enough yet, I'm afraid. wasm is changing a lot and binaryen is changing with it. To try to build stuff that works, you should use emscripten incoming, now at 1.36.11. Note though that even with that, native wasm support doesn't work yet (browsers just updated the wasm binary version, and emscripten is not quite up to date yet, but should be soon).\nIn a few months things should be a lot more stable though.\n. This also\n- Prints out if and loop sigs, which was missing and is now necessary.\n- Removes the DSL in OptimizeInstructions (after these type checking changes, using wasm for the DSL became too annoying, not sure what to do there).\n. Finalizing might still matter for code generators other than wasm-s-parser. But maybe that is worth refactoring later into something on the side.\n. Yeah, as discussed in person that's indeed the issue. I'll continue work towards that, with finalize(type) on loop/block/if using a given type (as by the s-parser or binary decoder), while finalize() with no args autodetects the type fully (which is useful in the optimizer, as you said).\n. Ok, this is hopefully good to go. Tests pass locally.\n. In #708 we also saw that the type of exit looks wrong (function type is void, but it has a return statement with a value) - is that an unrelated problem to the one this PR fixes?\nSeparately, can we enable drop validation with this PR? That is, replace the code in src/wasm-validator.h for visitDrop(), which currently checks an env var, with something like\nvoid visitDrop(Drop* curr) {\n  shouldBeTrue(isConcreteWasmType(curr->value->type) || curr->value->type == unreachable, curr, \"can only drop a valid value\");\n}\n. Ok, thanks, lgtm. I'll investigate that drop validation problem.\n. lgtm\n. lgtm\n. Cool, yeah, I'll refactor (I just didn't want to do it if it wasn't useful anywhere else).\n. LegalizeJSInterface is now refactored to a cpp file under passes/.\n. As this isn't .s specific, please also add a test in test/unit.wast or test/kitchen_sink.wast or such (then run ./auto_update_tests.sh and see the test outputs are correct).\n. (oops, hit the wrong button)\nI think it would be good to add a line to a test in test/*.wast, since this was a bug in core printing functionality, and not specific to .s files.\n. > I guess just a tiny function with an i64.store32 in test/unit.wast should do it, right? \nYeah, that should be enough.\n. cc @dschuff who wrote that line\n. I'm ok to wait. @tzik?\n. lgtm\n. Ok, cool.\nYeah, using names is possibly a controversial design decision. But overall:\n- For global objects, names allow the module to be created and optimized in parallel (add a call node to a function not yet existing, for example).\n- Names are interned, so they are fast as pointers to compare. They are sort of like handles, really.\n- With that said, for branch names - the issue here - I agree things are more debatable. I think numbers are too fragile, e.g. br 2 could break if you add a block in the middle. But pointers which you suggested might be interesting to consider (depending on overhead, debuggability, etc.).\n. This has been implemented in that merged PR.\n. I think that was wrong, the true bug here was in dce. According to the current wasm type rules, removing code from a block can change its type, so we must update block types when shortening them in dce.\n. Actually even that seems wrong. It looks like according to the spec interpreter it is not always valid to remove unreachable code (https://github.com/WebAssembly/spec/issues/355#issuecomment-251537806), so we just need to not dce away such code.\nOr perhaps this is a bug in the spec interpreter, but for now I think this makes sense to go in.\n. Also added the fuzzer variant that found this stuff, which just runs random passes on a wast and looks for validation errors.\n. Just to be sure, this is built with latest emscripten incoming branches? lgtm if so.\n. From the trace it looks like you aren't validating the module before optimizing it? That might explain this. We don't validate automatically, normally, as it's a costly operation. It's best to validate when the module is complete, before doing anything with it like optimizing or saving.\n. 1. Looking at the new trace, something seems wrong - there is no call to BinaryenModuleCreate. Is it possible you're not calling it? I doublechecked and our tracing code should emit a call to it if you did (on current binaryen master).\n2. Those wasts do fail validation on binaryen master, e.g. the first hits\n[wasm-validator error in function $__wasm_start] unexpected false: can only drop a valid value, on \n(drop\n  (call $main)\n)\nPerhaps you're not on latest master, and we added that check later?\n. lgtm\n. Wait, why did you add skipping here? Those aren't \"stacky\" tests, there should only be stacky stuff in stack.wast (which we ignore entirely)?\n. The tests look up to date, and yes they have the \"stack\" comment on them, but they were not \"too\" stacky before - I guess that now they are, after removing return arity?\nI'm ok to skip these then, for now, but the proper thing is to move them to stack.wast in https://github.com/WebAssembly/spec/pull/351, and to update our spec tests to that version, so we don't need to skip. But we can do that later (might be more such things?).\n. Thanks, fixed by #742.\n. I tend to agree with @dschuff on maintainability mattering more. However, we should measure all 3 options here before deciding, I think.\nI've been measuring on BananaBread, which is fairly large and realistic. Here's the wast. You can measure on it with bin/wasm-opt [name].wast -O --debug (that prints out timings for each pass. note that it runs other passes too, but it's more realistic that way).\n. Thanks @rongjiecomputer, very interesting data. Ok, looks like the third option - std::lower_bound + std::move + std::move_backward - is the best, as it's both fastest and uses the most standard C++ library functionality.\nYes, LocalSet might spend more time moving. I guess that suggests a different data structure might make sense here (e.g. a bitset), although I did test that in the past, and the overhead wasn't worth it. \n. Is this ready for review?\n. This is great, thanks again!\n. lgtm\n. lgtm, but i'm curious, where in the spec does it specify this?\n. Interesting - we pass that test. So we must be passing it incorrectly somehow I guess.\n. This isn't tested in a native build because VM support is still blocked on other stuff.\n. Note that the test suite coverage I mentioned was using spidermonkey. I just realized that since spidermonkey checks fewer errors than v8, the picture here might change once we can check on v8 as well, as the errors discussed above are exactly the kind on which the engines diverge.\n. @binji: Yeah, question is when the fixup can be done. If it needs to be done after every operation that sounds bad, so one option is it's ok in binaryen IR to not care about it, and handling it when loading/saving wasm.\nBut then: @dschuff, I think that's a good question - do we allow loading and saving IR that isn't true wasm. This wasn't much of an issue before since we diverged by being a subset of wasm, but this divergence would make us a superset.\nNot being able to save and load our IR - which a strict wasm-only checker would cause - sounds bad. So perhaps we should go ahead and do the full split from wasm, creating .byn files that differ from wasm files, etc., as suggested in #663. Maybe we've held off as long as we could on doing that?\n. @JSStats: the main use case for that transform is when you need to add some code that runs first. you might not know if the parent is another block, and it might not be another block anyhow. so creating a new block is a simple and useful thing to do (and later optimizations might get rid of it, if possible).\n. Well, the current status is that I am not aware of asm2wasm problems due to this - we seem to work around the type system corner cases. Test suite passes and fuzzing looks ok. So I guess for now we can ignore it. But when the type system is formally written up, we should look into this more carefully, as I worry running on non-asm2wasm output may hit a problem. Leaving open for that.\n. I also found the memory growth hang issue and fixed that in another commit (CI didn't finish on the first one anyhow so I couldn't merge it, and it's a tiny fix too).\n. There are now binary builds for linux in the sdk, so this should be possible,\nhttps://groups.google.com/forum/#!topic/emscripten-discuss/JCpNkUfaJ_Y\nWould be great if in this repo we could run tests using that (probably can't do the whole suite, but at least a subset).. Experiments in emscripten repo using that: https://github.com/kripken/emscripten/pull/5087. Thanks!\n. I don't know cmake much - does this have observable changes? Does it require people to issue a different cmake command for a debug build than before?\n. Yeah, good idea, we should use the monotonic one.\n. Thanks! Btw, where did you notice this?\n. I see, thanks. Ok good, I just wanted to be sure we weren't missing obvious testing for this (aside from not testing a whole platform ;) I guess).\n. lgtm\n. lgtm too, thanks!\n. Thanks!\n. Good point about layer 1, this would be an obvious win there.\nOk, sounds like it isn't clear what is best to do here currently. Definitely not worth adding much complexity for it then. For now, other PRs made us selectify when optimizing for size, and to not otherwise, which seems to make sense.\nClosing this PR, but maybe we'll want something similar to it some day.\n. Thanks!\n. cc @dschuff who added those tests.\nI think that's right, those are meant to fail. Yes, we could make them silent.\n. @rossberg-chromium: true, we just have a mode that disallows even importing them. we would need to not enable that mode if the import/export is only intended to be linked to another wasm module, of course.\n. lgtm, thanks.\n. lgtm\n. What was the build fix? (I just see one commit here, so I can't tell the diff directly.)\n. Thanks, interesting.\nWe have AddressSanitizer coverage on travis, so it doesn't seem high priority to get valgrind up, but it might be useful. In particular it could be useful to run locally when an issue seems like the kind valgrind can catch.\n. lgtm. what could the benefits be here?\n. Nice.\n. I wasn't sure what kind of API to use for it - it has to interface with the commandline options receiving code (add params to it, etc.). I played around for a while and found nothing that looked nice. But open to suggestions.\n. Well, the function would also need to take some variables by reference (runOptimizationPasses, passOptions) so it can assign their values to them, since we need to store to those variables. That's where it gets messy and I didn't find a nice way to do it.\nMaybe one option is to subclass Option and have those two variables be new properties on it?\n. This isn't enough to get to asm.js yet, the \"loop variable\" hack can do a little more. Still figuring out how best to do something similar.\n. Indeed, very nice!\n. lgtm too.\n. cc @juj \n. Looks ok to me, and I see no objections from @juj.\n. Fixed by that PR.\n. lgtm\n. lgtm, nice.\n. For the commit right before merging this, we should add a binary_0xc tag (like we have for 0xb).\n. What is the issue with binary.wast?\n. lgtm\n. Yeah, it would be interesting to know if cases like those are common. I believe the LLVM inliner has a related heuristic, where it if thinks inlining could get rid of a branch, then it prefers to do it.\n. Does this happen in an -O0 build? If so it could be an optimizer bug, which is the most likely thing.\nIn any case, if this worked previously as wasm, then we should bisect. I can do that, if it's easy to build one of your testcases? Maybe you can set up a repo with just the bitcode, asset files, and a shell script that calls emcc on the bitcode?\n. Ok, #820 fixes that assert. It's possible there is a second problem though, I have no strong reason to assume this was the cause of the other issue you saw.\n. Like the old days, sorry - it's in binaryen master, but I don't update the emscripten version of binaryen before I run all the tests, so it's not there yet.\n. Interesting, thanks. Bisecting this on the repos, it's on\n```\ncdd52f71b2d7e24a7654d46d537c2260a73eaf5c is the first bad commit\ncommit cdd52f71b2d7e24a7654d46d537c2260a73eaf5c\nAuthor: Alon Zakai alonzakai@gmail.com\nDate:   Tue Sep 13 13:55:57 2016 -0700\ndefault PRECISE_F32 to on when compiling to wasm\n\n```\nWhich is interesting, since enabling PRECISE_F32 on asm.js does not change anything...\nAnd in fact disabling PRECISE_F32 for wasm does make things work. So we are doing something wrong with floats, indeed.\nVery strange. I can investigate more, perhaps bisect on the codebase somehow. But maybe this helps your hunch, and you can craft a small testcase?\n. Turns out direct bisecting on two builds is hard, as PRECISE_F32 changes the ABI.\nMaybe we can bisect on the history of oryol - if we go back, does it start working? Or is this an old demo that has not changed in very long?\nAlternatively, we can use shell logging here, if it's feasible to make a shell version of this testcase?\n. Ok, I got autodebug logging working in the browser, and diffed builds with and without PRECISE_F32. The log shows the first differences happens in\n_ZN3glm5tvec3IfLNS_9precisionE0EEC2IjLS1_0EEERKNS0_IT_XT0_EEE\nglm::tvec3<float, (glm::precision)0>::tvec3<unsigned int, (glm::precision)0>(glm::tvec3<unsigned int, (glm::precision)0> const&)\nand indeed it involves f32 operations.\nNow, looking at this fairly short method, the wasts differ only in one using f32s and the other using f64s, and then there are the necessary promotions/demotions to f32 for storing (if we use f64s), etc. So I don't see any bad code being generated. Is it possible the values here are just in the range where f32/f64 differences matter, and the method is sensitive to them? Looks like it loads an i32, converts to f32 or f64, then does the same for another i32 4 bytes after it. It's the second of them where the difference occurs,\n-AD:49319,378846291\n+AD:49319,378846304\n49319 is the id, the value after is the f32 or f64 value. So the difference between the two is indeed fairly small, and could be a rounding difference in f32/f64. Maybe those accumulate?\n. Oh, I was diffing the wrong thing. Diffing f32 vs f64 shows rounding differences that are ok. But diffing asm.js with f32 to wasm with f32 shows the problem: we didn't do fround of unsigned properly. This happens in that same method mentioned above actually. Fix is in #821.\nBuilding with that, looks like the program renders correctly.\nThanks @floooh!\n. Oh, this was specific to asm2wasm, I don't think a spec test could have helped. The spec suite already has tests for both signed and unsigned i32-to-f32 conversions.\n. Actually if we had a wasm to asm.js convertor, then those tests would have found this, by checking round-trips, hmm.\n. It's on incoming now, so getting latest incoming from the SDK should be fine.\n. lgtm\n. Added comprehensive test. The existing test had good double support, but not float.\n. Hmm, looks like some OS X-specific issue I don't understand. First thing I would try, though, is to try to  clone and build binaryen manually yourself using cmake . and then make, instead of letting emcc do it. If that works, maybe emcc is building it wrong somehow. It not, maybe cmake isn't set up properly on your machine?\n. If this recently changed, can you please bisect to find when exactly?\n. I believe under the sdk directory is a directory with a git repo, that you can bisect in. Alternatively, you could just do your own git checkout of the main emscripten repo and bisect on that. Bisecting on current incoming (which breaks) vs Nov 1 (or when it still worked).\n. @juj - this looks like a cmake issue on OS X, which you know a lot about, if you have time please take a look.\n. Thanks @jbajwa, that's very helpful.\nWhat I think is going on here is that that commit makes us use the clang from fastcomp to build. And it seems to not work properly. While when you build binaryen yourself, you are using your machine's system compiler which does work.\nTo verify that theory, if you build binaryen yourself but force fastcomp to be used, does it fail? Can try CC=/home/..path-to-fastcomp../clang CXX=/home/../clang++ LD=/home/../clang++ cmake . and then make, instead of just cmake . and make.\nIf that is the issue, then the solution is for that python script to not use fastcomp's clang. But also we can't use the inherited env, as it may be modified by emmake. So we need to either\n1. Find the system compiler and set that.\n2. Find a way in python to create a subprocess that does not inherit the env, so it does the exact same as if you run in the shell, and so gets the system compiler.\n. Yeah, there are risks either way. But using the system compiler seems safer for now, unless someone else has a better idea. I have a proposed fix in https://github.com/kripken/emscripten/pull/4734, please test if you can (I don't have an OS X machine, so I can't).\n. The proposed fix was merged, and is confirmed to work, so this should now be ok. Please comment/reopen if not.\n. That looks unrelated. We recently changed binaryen's default from trying native support, then interpreting if not, to just using native support. That makes sense since at this point browser support in dev versions is pretty consistent, and including interpreter support can be confusing (when it ends up running, it's slow, and also the build is very big).\nThe link in that error message shows how to turn on interpreting, as it was before, if you want that.\nOtherwise, make sure you have wasm enabled in a browser that supports it.\n. What's on the failing line? What is it trying to instanceof?\nWorth making sure that is very latest chrome canary, as bugs are constantly being fixed. Also I would try it in latest firefox nightly for comparison.\n. Not sure I understand. What are the steps to see the problem?\n. This might be a node.js bug? Or perhaps it depends on the node.js version, which do you have on those two setups?\n. How is the startup time compared to asm.js? If it's worse, then something is wrong. One possibility is that the wasm binary is in a side file, and downloaded separately, so webserver performance matters more - how are you testing?\nThe s2wasm issue is a bug in the wasm backend or s2wasm, can you provide the bitcode file? That should be enough to reproduce the problem.\nThe Memory issue is strange - Firefox and Chrome should be running the same checks. What is TOTAL_MEMORY at compile time? Do you modify memory size during startup, perhaps? And, is this with or without memory growth?\n. > I'm now getting this error: Assertion failed: (!estack.empty()), function operator(), file src/s2wasm.h, line 713.\nSounds like #828 perhaps, which was fixed in upstream LLVM just now.\n\nWe explicitly define TOTAL_MEMORY in the HTML file before running. [..] Memory growth is not enabled. \n\nI see. I think what's happening is that without memory growth, we set the wasm initial and max memory size to TOTAL_MEMORY as seen at compile time. If you set it to something higher at runtime, that surprises the JS engine.\nThe wasm spec bakes the max memory size into the binary, so our only options here are to enable memory growth. If you do that, does it work? If so, we should figure out how to show a better error here.\n. #834 adds a warning with guidance to turn on memory growth for the memory size incompatibility issue.\n. @eska014 \"Are there significant optimizations we're missing out on by enabling memory growth?\"\nFor wasm, not much. It may reserve more memory than it needs, but for a full game engine like Godot I imagine it's fine. And there is no speed downside unlike with asm.js.\n. About the README, it refers to the emscripten wiki page, which mentions the wasm backend isn't stable yet (but I'm ok if people want to update the README too). I updated the wasm backend page to mention that cmake flag.\n. Yeah, can try the binaryen optimizer on s2wasm output, e.g. wasm-opt -Os input.wasm -o output.wasm. I'd be curious to know by how much it helps on your codebase, but currently it probably won't do a lot because the wasm backend's output isn't coordinated with binaryen's optimizer (it's pretty \"final\" - binaryen would need to undo some things to really do serious optimization).. First thing, note that the wasm backend/s2wasm path is not yet stable yet, and we therefore recommend the asm2wasm path.\nFor s2wasm, LLVM 3.9 will not work, it must be the very latest dev version from git/svn. The build from the binaryen test directory, which it fetches from the waterfall, should work.\nNow, that error looks familiar to me - I think I saw it as well, or something like it, when using the waterfall LLVM, which I mentioned to @dschuff. I think I never managed to figure it out, and instead built latest LLVM from source, and then things worked for me. So perhaps try that, but this does sound like a significant bug - I was hoping it was just some weird thing in my local setup, but if you see it too, that's not good...\n. Hmm, this question is about the .s format itself, I think - not sure what is intended there. cc @sunfishcode \nBut reading the code, I don't understand. On Line 25 I see a return, and before it a br_if, so L25 is not unreachable?\n. Does changing things so that that condition ($pop6) is always false (or not always true nor always false) change things? (I ask because I don't think the condition always being true has an effect here - s2wasm doesn't know that, unless you run the optimizer, but s2wasm doesn't.)\n. How about if you change the .s code (to make that condition always false, or variable)?\n. Great.\n. Heh, the subtraction part is a funny typo.\nThanks, fix is in #830.\n. Merged.\n. Ok, how about this: looks like the gcc/clang behavior on native 32-bit is to return MIN_INT in all undefined cases - too big, too small, or nan (seems an odd choice, I wonder why they do that - or maybe it's a hardware thing?). We can make binaryen emit code that does the exact same thing. That would differ from asm.js now, but make us identical to something else important, and it's fast and simple.\nPR code is updated to that. If we decide to go this way, though, it needs test updates (some things change).\n. Actually it's not so simple, gcc and clang have different behaviors when optimizing - undefined behavior and all that. So perhaps it just doesn't matter what we do here?\n. cc @dschuff @sunfishcode @juj, advice on this would be very welcome.\n. Benchmarking this, it is much faster than calling out into JS (3x) as we did before. However, it remains significantly slower than imprecise mode, even 4x in the copy benchmark which hammers on these operations in a tight loop. I guess the function call overhead into the safe div/mod/etc. methods is significant in such a situation.\nWe might remove some of that overhead by inlining (#815), but it could increase code size substantially, so we'd need to do it carefully.\nAnyhow, the good news is that the report that led me to do this was of a 5% slowdown. So the 3x speedup here might reduce that to the 1-2% range, which maybe is negligible.\n. It is trivial to do clamping instead of always the minimum. I did the minimum because that's what x86 does, so most likely for people's code to \"just work\" even if for bad reasons.\nWe could add more options here, but I'd like to not add that complexity.. Superceded by #907. Emscripten branch with corresponding name has a test for this.\n. Will need a binaryen tag update.\n. We'll need to update this wiki page after this: https://github.com/kripken/emscripten/wiki/WebAssembly#binaryen-methods\n. Looks very useful thanks!\n. As a C++ project that uses a lot of std:: functionality, we use std::cerr etc. to print in most places. We should probably change the printfs to do the same - where are they?\nI agree printf can be better for code size, but for code clarity in C++ I think the C++ way is better.\n. I'd be in favor of iostream everywhere, just for code clarity. But if others think otherwise I don't mind the opposite? No strong feelings either way.\nLooks like the tests fail on a python syntax check. Weird, those files weren't changed recently. Perhaps the CI versions of the checking library were updated, so it's testing more? Fix in #841.\n. Thanks, looks great except for one tiny style fix.\nAlthough actually, I see we get that style thing wrong in some other places. So let me merge this, and I'll make a PR with those fixes including this.. lgtm (but should probably wait for @dschuff for the linking-specific stuff?), and nice about the hashing.. > Added some minor optimizations\nThose seem like things the optimizer should do, but looks like it didn't yet, so I wrote #850. With that, you could rely on the optimizer to do it for you if you want.\n. Do other things work with wasm, that don't use SDL?\nIf it's a general issue, make sure your browser supports wasm.\nIf not, is there a stack trace or larger error message perhaps? And which emscripten version is it with?. @qog314: perhaps the problem is you need a more recent emscripten version. The wasm spec changed since then, maybe on something that a small program doesn't hit but an SDL-using one does. I am guessing that is the case because when I run your command on latest emscripten incoming (1.36.14), it does run ok in firefox nighty.. I think that updated you to master, and you need incoming. Specifically, that error shows that it is using BINARYEN, which was an old form, and now we use BINARYEN_ROOT. I think these are the commands you need.. @qog314: worth checking you and that colleague have the same versions of browsers and emscripten. One possible issue is chrome has canary on windows, but not in linux, so linux builds are always delayed.\nAlso worth checking other wasm demos on the web, like one on the main website. That'll help narrow down if it's the browser or the toolchain. Also, can test a build your colleague makes.. Actually, if you are on 1.36.14, then the browser might be at fault. A problem is that I remember now that the main demo website will run earlier versions of wasm binaries (something that is indeed possibly confusing).\nI would create a hello world binary in 1.36.14, then add some debug output in the JS, search for \"no native wasm support\" in the code. It checks for the existence of WebAssembly and some other things, I believe, so you can find out what specifically it is not finding in your browser.. We should also find a way to improve that output when an error occurs.. Possibly the restart made it use a more updated version.. Interesting, perhaps we can just raise that limit, although I wonder why so many names are needed - perhaps something else went wrong. Is this code you can provide publicly perhaps?\nBut yeah, as you saw, that error isn't fatal, so there is a secondary issue you are hitting. Perhaps when building with EMCC_DEBUG=1 in the env it shows a better error? You will see the command being run that fails, so you can run it again yourself and should see the same failure. Then running it in a debugger could give a stack trace that helps figure this out.. Hmm, that is indeed a lot of wasm...\nCan you build binaryen with debug info and without opts? There is a nice cmake way but I forget it, I just edit the CMakeLists to remove the -O2 flag and to remove \"DEBUG\" in  ADD_DEBUG_COMPILE_FLAG(\"-g3\"). And run without multithreading, in the env BINARYEN_CORES=1. Then the stack trace should be good.. About the relooper jump threading limit, I made #847 to increase it, but testing on everything I can find, I don't see anything over 293 (sqlite). So I'm curious what can cause 7,820. Can you say what type of code that is? Is it autogenerated or otherwise special in some way?. Thanks for the info about the codebase. Perhaps those autogenerated C++ files cause so many labels to be needed? Hard to say. Anyhow, we might as well land that PR that raises the limit, I see little downside. A better solution is likely to avoid using names in labels, which @dschuff has mentioned in the past, and which would make this problem go away as well as make inlining simpler. (Another solution might be a more complex Name class with multithreaded insertion, but that sounds dubious.)\nAbout the testSetjmp issue, looks like we handle dependencies for it in library.js, but in theory that might not be enough, if you have a setjmp/longjmp but later in the optimization it gets optimized out but the testSetjmp remains. Hard for me to imagine how to construct such a testcase, but if that's the issue, the fix is simple and worth doing anyhow, https://github.com/kripken/emscripten-fastcomp/pull/160. Does that fix things for you?. Are you using the sdk? then there is a command to get it to check out a branch, and you can get that PR's branch. I don't remember what the command is, but I think the sdk just has a subdirectory with the git checkout, so you can just go there, check out the branch and build, etc.. Heh, yes, the wast is just for debugging. There is an issue open to get rid of it, we should do it soon.\nOk great, thanks for verifying that fixes it.\nThe only thing I'm not totally happy with at this point is that we don't have a testcase for that fix. Maybe we can think of a way to create one somehow. Otherwise, no big deal, the PR is obviously a good change, but without a testcase we don't guard against regressions.. Both of those PRs are now merged.. I can't think of a good test, not worth more effort I guess.\nSince those PRs are merged, I think we can close this.. Overall this looks like a nice improvement. A few notes:\n\npython conventions are test_s2wasm.\nflake8 looks in scripts/, so by moving  code out we reduce coverage. might want to point it to the new locations too.\nI don't follow \"Can run a single test suite without having to add command-line flags and more conditionals\" - what does the new command look like? do you mean you invoke the sub-script directly?. While investigating the output here to be sure nothing changed for the worse, I noticed a tiny refactoring opportunity, added as a commit. No code effects.. What's the story here?. Yes, wasm doesn't have simd yet, so that isn't expected to work.\n\nHow are you generating that code? I'm not sure which clang/opt flags you need, but if you use emcc, it should pass those to those tools for you. You can run it with EMCC_DEBUG=1 in the env to see what flags it passes.. Thanks, PR in #858.. That tutorial does things in a nonstandard and not recommended way. It happens to work on the things in the tutorial, but other stuff likely won't.\nIn general the recommended path is to use emscripten normally, and add the flag -s WASM=1. That is the recommended path. It emits a wasm plus a JS file that provides all the runtime support it needs.\nIf you want only wasm, without JS, then there is still a better way to do it than that tutorial. See the standalone wasm option, it lets you build a wasm that you can write the loading code for yourself. More similar to that tutorial, but it uses the recommended tools. It is not fully stable yet, though, feedback is welcome.. Hmm, that unity file sounds like a release build, so it should have DCE already, so enabling DCE in -O0 wouldn't fix what you see.\nSomething else must be causing unreachable code there. It would be useful to find a testcase we can compile from source that shows the problem, so we can investigate this, it sounds like a bug. Maybe one easy way, if you have a program that checks for such unreachable code, is to run it on the emscripten test suite (anything it finds not in -O0 is a bug).\nA not-great option to paint over the bug could be to manually remove code according to the pattern you mention. But our DCE should be fixing this. Also there isn't an obviously good place to do such an optimization, not until we add a stack machine output layer type thing as discussed in the past.. Yeah, agreed. That's what the DCE pass is supposed to be, so perhaps @sunfishcode found a bug in the pass. Or perhaps AB was compiled with an older and less effective version, or maybe the extra changes done to it over time caused that change (I've seen stacky code in there, for example, which the toolchain would not emit either).\nIf there's a way to get a VM that errors on unreachable code, we could use fuzzing to try to find such a bug.. Yup, already doing that as we speak.... Test suite finished. I verified that\n\nMost tests in -O0 fail with that SM patch.\nWhen enabling DCE in -O0, all tests pass once more.\n\nSo I can't see any bugs in DCE. I suspect the AB issue was due to the special and nonstandard way in which it has been manipulated.\nSo looks like if we need to we can enable DCE in -O0. It makes the asm2wasm phase around 3% slower (tested on libc++), so not too bad if we decide to do this.. @lukewagner What's the benefit to running DCE in -O0 now? I'm not opposed to doing it, I just don't get what we gain from it.\n@sunfishcode If there's a benefit, I lean towards running DCE instead of writing a new pass, just for simplicity, and since 3% slowdown isn't that bad. But I'd measure more carefully first I guess.. By \"other sources\" do you mean \"bugs in binaryen's DCE\"? Or something more fundamental?\nAnd how would the bugs be noticed - would you enable your patch in Firefox too..?. @sunfishcode: Yeah, all that sounds great. The Binaryen part of that was done as discussed above, finding no issues, so I guess you saying it's worth doing the same for other tools? (And this is not connected to the question of enabling DCE in -O0 in Binaryen?). Yeah, thanks.\nI guess the additional question is, should we stop running dce on -O0 (which was added for this)? Probably we should, unless I'm missing something.. Ok, #932.. Yes, thanks @froydnj . There appear to be no concerns, so I'll merge these 3 PRs in tomorrow unless I hear otherwise.. Nice, thanks!. Turns out there is stacky/non-ast code in there, so I added support for that too.. Sure, I opened #868. This is now rebased on that (so it must land later).. Rebased after the PR we depend on landed.. This should be good to land if there are no comments.. We don't create an unnecessary block in that case: blockifyWithName is smart enough to just add a name if the input is already a block without a name (and that would be the case here, as the function body is generated by getMaybeBlock which creates a block if there are multiple statements, but does not name it). So if we already created an explicit block, we reuse it, and if not, then we create one.. If there are no more concerns, I can land this?. lgtm, seems like cleaner code this way anyhow.\nBut that sounds like a compiler bug if it wasn't constructing the static variable properly. Just out of curiosity, which compiler was it with?. It's possible the change makes ASan capable of finding more leaks, because the leaks seem to be a bunch of strings, and not the StringSet itself.\nSee the // XXX leaked comment in the middle of your diff. We allocate there and never free it, since it needs to live til the process exits anyhow. Perhaps we should change that, although we'd need to look at perf.. Is this still active, or should we close it?\n. I think the string is in the (data line, it's just encoded so it doesn't look normal. If you open the wasm (binary) in an editor, though, you will see it.\nFor that assertion, we should be improving it soon, but meanwhile if you can emit HTML instead of JS, it will work (the html will set up the binary for you; alternatively, you can set it up yourself manually).. To emit html, you just call emcc with -o output.html, the suffix tells it what to emit. Not sure where that fits in with rustc though.\nIf all you want is a wasm module that you use directly, and it doesn't need JS integration, and it doesn't need libc or other system libs (which often needs JS, e.g. to print), then you can read the \"standalone wasm\". It has a full example, that maybe you can connect rustc to? But the standalone stuff is experimental, so expect breakage.. @dschuff \nHmm, when I try to use copy_backward as suggested, I get this. I try to specialize that template for the iterator class we have, in src/mixed_arena.h,\nnamespace std {\ntemplate<class T>\nstruct iterator_traits< typename ArenaVector<T>::Iterator > {\n  typedef T value_type;\n};\n} // std\nbut then it complains template parameters not deducible in partial specialization about T. But T can't be a final class yet, as the iterator is over a templated class..? Reading a bunch of stackoverflow posts about related errors and creating custom iterators, I am only getting more confused. Is there something simple I'm missing?\n\nToo bad we don't have a good way to express stacky code in text\n\nYeah, it would be nice if we got around to writing a new parser for the final wasm text format. But wabt works great meanwhile :)\n\nIt might be worth considering adding new IR node like first/reverse-block to avoid having to introduce locals in the future.\n\nAlso agreed, we should consider this. Really depends on how beneficial/common stacky code is.. No difference. It just doesn't like T not being defined, I guess.. So yeah, maybe better to look into full iteration as a followup. Will need someone that knows more C++ wizardry than me ;). That definitely looks like a bug, somehow we miscompiled the param type - none is not valid there. Can you provide the code to reproduce the problem? Or if not perhaps reduce it to a testcase you can provide?. Thanks. I get\nHEAP32\nasm2wasm: /home/alon/Dev/binaryen/src/asm2wasm.h:1347: wasm::Asm2WasmBuilder::processFunction(cashew::Ref)::<lambda(cashew::Ref)>: Assertion `mappedGlobals.find(name) != mappedGlobals.end() ? true : (std::cerr << name.str << '\\n', false)' failed.\nAborted (core dumped)\nand looking in the code, the source of that HEAP32 is in atomics/pthreads code. We should give an error on using that with wasm, because wasm doesn't have support for it yet.\nWhen I strip out the atomics code manually, then I run asm2wasm, the output is free from none, so it looks like that is the cause of the problem you saw.\nDoes your codebase require atomics/pthreads?. I see, ok. Then wasm isn't an option for you yet, pthreads and atomics are on the roadmap but there is no spec or impl yet.\nI opened https://github.com/kripken/emscripten/pull/4849 to show a clear error message for this, sorry for the confusion.\nClosing this issue as the cause is not something we can fix in binaryen.. Thanks, the problem was just the memory wasn't marked as existing. Fix in #871.\nNice how the tracing stuff helps here, as the problem wasn't reproducible without it, this was a pure C API bug.. See the C API header, it describes how it works too. It's also tested in test/example/c-api-kitchen-sink.c so you can see it and its output there: c-api-kitchen-sink.c is the source, c-api-kitchen-sink.txt the output of running it, which contains the executable trace, and c-api-kitchen-sink.txt.txt contains the output of running that trace, so we test that the trace works too.. Interestingly the test found another trivial bug, we weren't deterministically ordering exports from binaries. So travis happened to do a different order than I had locally. Added a fix.. Thanks! Looks like a good start. I'll write a bunch of specific comments, but first one general thing: I don't think we need to add a wasm2wasm tool. Instead, we should use the new ability to read/write wast/wasm in wasm-opt. Then it would do what wasm2wasm does, plus optionally optimize.. Yeah, it was convenient as a demo, it helped to read that code.\nThat's all the comments I have for now.. @ramiro1234: this particular feature is fairly urgent as I mentioned before. if you don't have time to address the comments quickly, I think I should take over. Sorry about that, but lots of other important stuff that is less urgent :). Oh, wow... that's a lot of bad luck! Sorry you went through all that :(\nNo problem about this PR. I'll take it over. Thanks for your work here, the start you did helped me think through how this could be done, and I think I have a good idea now.\n. Yeah, the assertion is switch-related. Hard to tell what's going wrong, though - can you provide the bitcode or .asm.js file, to reproduce the issue?. Thanks, #877 should fix this.. Yes, thanks.. Yeah, we should clean that up. I need to change some things for async compilation too anyhow, so I can do it while doing that.. Ok, that should be fixed by that PR, which merged.. Hmm, can you run it with BINARYEN_PRINT_FULL=1 in the env? (that prints out the types while printing) I think you'll see [i32] (call $panic), because you have BinaryenCall(the_module, \"panic\", operands, 0, 1);, and the last param is the return type, and 1 is i32.\nThe API requires you to set the function type when creating it, and also state the type when creating call nodes to it, because they can be created in parallel. We check that they match at the end, but I suspect after the error that you see, so you see this first.. @binji: oh cool :). No connection to mozilla, \"MIR\" in Rust means \"Middle-level Intermediate Representation\". It's in between a high-level Rust AST and a low-level machine IR.. Also, for the general case of a compiler or IR that wants to compile to wasm, Binaryen has a C API - which is how mir2wasm works in fact. The API tries to be as simple as possible to use. Here are the docs.. Hmm, so what I am guessing happens is that we see that param of that import is used as i32 once, and as unreachable another time. We don't handle such overloading, so it crashes. The problem with that theory is I can't think of how a param could be unreachable - this is asm.js, we can't e.g. do a return instead of a parameter to a function call. So something really weird is happening here.\nIf you can't share the code, I'd try to reduce it - find the function (--debug to asm2wasm will print func names as it works, so the last is the crucial one) and then remove stuff from the function while the bug persists, until you are left with the interesting part.\nIf you can share the code privately, I can do that for you.. Perhaps also print out getFunction()->name to see where the bad call appears. That plus the called function that you already have should pinpoint the failing line. Then you can see how it gets an unreachable for the param. Maybe print out the type to confirm that as well.\n. The emterpreter should be able to do those things. Hopefully it would be fairly straightforward, but I don't remember enough of those details to be sure. Maybe read src/library_async.js and see how other async things are done in the emterpreter, then try to do it for the coroutine methods.. Thanks, I tracked that down to #885, which should fix things for you.. Fixed by that PR landing.. Our asm.js parser isn't very good with error messages, sorry about that.\nHere the problem is that that isn't valid asm.js - the extra { and }; break the rules of how vars work (they must be one after the other, nothing in the middle), and also var X = Y; must have Y equal to zero, not an expression.\nIt would be good to improve our parsers error handling, if someone is interested.. That does look like valid asm.js, yes. How does binaryen handle it?. Hmm, then probably it's a bug in the asm.js parser. It's been tested in asm.js backend output, which doesn't emit unnecessary {, };s as in that code.\nWould be good to fix but I don't know offhand how easy it would be.. Yeah, the rule seems to be \"disallow code until the end of a block, once you see a br or return etc.\", so we could do that more directly in e.g. the binary writing code, pretty easily. Not sure what's better for debugging, downsides either way. For now just using the DCE pass seems simplest.. Oh right, yeah, we could work around it that way too. Simple option too, if we need it.\nLanding as there are no concerns and I'm already getting reports of code failing due to this.. Merging as it's just a test fix for bustage.. Looking in src/library_syscall.js, it appears syscall 221 is fcntl64. That's known to work in general, so something odd must be happening in your case.\nSince it worked in a previous version, perhaps the fastest thing is to just bisect to find where that changed? Another option, if it works in asm.js but not wasm, is these debugging tips: https://github.com/kripken/emscripten/wiki/WebAssembly#debugging. I guess I prefer the suffix, but you probably have a better idea for what is consistent with other tools. If no one else disagrees then let's go with your way.. Updated to do it that way, no influence from the suffix.. Thinking on it some more, I'm less sure I like the tradeoff here.. Overall looks like a nice improvement, thanks.\nIn addition to the comments above, we should verify performance does not regress - the change to use a lambda function is on some hot methods.. Yeah, wasm-opt -O on a not-yet optimized large input is good enough.. Ok. Hmm, we had bigger builds in the build-suite, but they are not updated. Maybe I should test on a Unity build, I have one locally. Is now a good time to check or are changes still landing in this branch?. Ok, tested on Unity, results look fine. lgtm.. Doesn't look like there are any concerns here, merging.. Some error on the bots and locally other.test_binaryen_names fails - posting to remind myself to look at this tomorrow.. This should be good now, if anyone wants to review.. Thanks for the feedback, added a commit with fixes.. Thanks!. As a followup, we should probably change wasm-validator to assert on this. However, doing so naively brings up errors, so let's leave that for later.. > So this bug only affects the implicit function-scope block?\nThat seemed to be the case until I compiled bigger things ;) This fixes hello world, but there is a more complex validation error on hello_libcxx.cpp for example. As I mentioned on email, I don't understand the validation rules, so not sure what to do. But, probably we shouldn't merge this, as maybe the fix should be a more general one.\n\nI guess i was confused about that last time I looked at that too, actually. In the binaryen IR it seems like the function body is not always a block (indicating that it could be implicit) but if it is a block, sometimes it is printed, and sometimes not. And sometimes it has a name, (and therefore can be targeted by breaks). Am I just confused?\n\nBinaryen IR has the function body as an expression - not a list. Similar to loop, if, etc. - the only thing with a list is block.\nWe have an optimization to not print the block, if it's the toplevel of a function, loop or if, as the s-expression format allows them to have lists. PRINT_FULL overrides that, showing the full ast + types.. This is obsoleted by #899.. Wait, does it work after this with only when disabling selectify? the fix should make it just work. or was that a typo in the comment?. Ah, I spoke too soon, I see some errors, still not done on the correctness side.. This also required C API changes, to provide the type of a block.\nSo this was a lot more work than expected, but it does seem to be ok now, nightly fuzzing + test suite appear to pass. The spec tests are still broken though.. Added some more validation improvements. This now seems to pass the spec tests too.\nNote on s2wasm: it has tests that contain typed empty blocks (like (block i32)). Those should not validate. I made it add an unreachable to keep the block valid, but if that is in fact something the wasm backend emits, it sounds like a bug? Or if not, perhaps the test needs to be updated.. In more \"test suite is never enough\" news, tests pass and fuzzing found nothing, but a failure occurred on Unreal. Fix pushed, details in there.. Fuzzing found another bug. I guess this makes sense - this is a large change to the type system, so fallout is to be expected. It'll take a while to stabilize again.\nThe last commit fixes it, but also worries me because it seems to indicate we must handle a lot more corner cases in each pass. We need to find a better approach, I think.. Or maybe I still don't understand the new wasm type system rules. Can someone confirm if this should or should not validate?\n(func $return-block-2 (type $0) (param $x i32) (result i32)\n    (if i32\n      (get_local $x)\n      (block\n        (set_local $x\n          (get_local $x)\n        )\n        (return\n          (get_local $x)\n        )\n      )\n      (i32.const 2)\n    )\n  ). Also whether this should or shouldn't:\n(func $return-block-2 (param $x i32) (result i32)\n    (if i32\n      (get_local $x)\n      (return\n        (block i32\n          (set_local $x (get_local $x))\n          (get_local $x)\n        )\n      )\n      (i32.const 2)\n    )\n  ). And the same two questions with the if replaced by a select (I assume the answers are the same, but just to be sure).. Thanks. Ok, then this is a serious issue. That transform, of\n(return\n  (block i32\n    (set_local $x (get_local $x))\n    (get_local $x)\n  )\n)\ninto\n(block ?\n  (set_local $x (get_local $x))\n  (return\n    (get_local $x)\n  )\n)\nwas previously valid, because in the latter case our type system gives the block type unreachable (since the block ends in a return, and we set ? to none). But now wasm doesn't allow that. (Note that I put ? for the type, because i32 would happen to work, but the problem is the outside context might want f64.)\nThe result is that in our current type system we cannot replace a node in the ast with another node with the same type (unreachable). I think that's a bad property for an optimizing IR, so something needs to change.\nOne option is to change our type system to disallow unreachable as the type of block,if,loop. That seems to be more consistent with wasm, if I understand it correctly? It's a substantial type system change for binaryen though, so it might be a lot of work.\nA downside to doing that change is that it means we can't do the above transformation - it would be disallowed by type system logic as the first has type unreachable and the latter type none - unless we infer the type from the surroundings. In other words, this change would mean that optimizations can't work locally any more, they need to see the surrounding context. That's also a bad property for an optimizing IR.\nInstead, another alternative is to keep the type system as it is, i.e. allow unreachable on block, but fix it up when writing the binary. This is actually what we sort of do now, or try to - we write out unreachable as none. But of course that is far from enough. The question is whether a simple fixup can work here. I don't have a clear picture of that yet. Even if possible, it would mean another divergence of our IR from wasm, which we've tried to avoid (but couldn't always, like the stack machine change).. An alternative I am considering, and would appreciate feedback on, is as follows:\n\nKeep the current binaryen type system as is.\nDocument a new difference between it and wasm: we allow block/if/loops with type unreachable, while wasm doesn't.\nFix things up during read/write of binaries. For example, a block/if/loop that is never exited could be emitted with type none, then an unreachable instruction could be emitted. I believe that wasm type system rules would then see that the block/if/loop is not consumed, so it's fine, while the unreachable is always ok to emit. So we increase code size slightly as a workaround.\nWe could also improve that in some cases, e.g., a block that is never exited could simply not be emitted, only its contents would be. This should be ok as such contents would end in a something unreachable like a return anyhow.\nSlightly complicating this approach is that in the current type system, a block that has a (br) (no value) and ends in a return will have type unreachable - by the property of having the type of the last element. This actually seems inconsistent, since if such a block had a br with a value, it would have that type, and not the type of the last element. Perhaps we should change this, both for consistency and for making the last bullet point simpler. However, I'm not sure how this would interact with other corners of the wasm type system.\n. Superceded by #911.. See test.wast and test.txt for an example of this in use. The superoptimizer suggests the optimization rule (x << 1) << 1 => x << 2.. Well, LLVM is just one thing that can produce wasm. Binaryen's optimizer should be able to optimize any wasm from any compiler, so having a superoptimizer here would benefit all those. Not many exist yet, of course, but hopefully they will.\n\nI also think it's convenient to superoptimize in Binaryen - the technique used here requires the ability to execute code, which is trivial in Binaryen (using the built-in interpreter), but not practical in LLVM.. Ok, running the superoptimizer, it found a bunch of things missing in our optimizer, which I implemented in the 4 linked PRs (details in each one).\nThe total benefits of those PRs:\n * Code size is reduced by mostly around 0.5%, however some codebases benefit more significantly, such as Lua by 1.0%. Unity shrinks by 0.7%.\n * Most benchmarks don't benefit, but there are a few with 0.5%-1.0% speedups, and a few benefit more significantly, notably lua-scimark is 3% faster and bullet is 2% faster.\nThose PRs seem to cover most of what the superoptimizer finds for now - we'll need to improve it to find more, lots of TODOs in the superoptimizer source, it's really very naive so far. Nice that even with such a simple superoptimizer we can find useful improvements.\nAs for this PR itself, for me personally it would be convenient to merge it, but possibly not worth it to increase build times for everyone, it could stay on this side branch. Thoughts?. Let's close this, the optimizations from this are helpful, but probably not much sense in getting the superoptimizer itself in-tree. It can stay in a side branch.. I believe that's not valid asm.js. asm.js can only create arrays on the singleton buffer that arrives from the outside.\nasm2wasm doesn't have much in terms of input validation (it is mostly just tested on emscripten asm.js output), so it misses this problem. But for error checking, you can run it in spidermonkey with -w to check for asm.js validation, which gives this error:\na.js:4:12 warning: asm.js type error: cannot create array view without an asm.js global parameter:\na.js:4:12 warning:     var a = new stdlib.Int32Array(10);. Rebased. Looks like no concerns, merging.. > reify\nDoes this mean emiting a proper wasm type for a block/if/loop when converting to wasm? Or something more?\n\n(brs targeting unreachable-typed nodes are invalid)\n\nDoes this mean that a block has type unreachable if and only if\n\nNo brs target it.\nIts last element has type unreachable?\n\n\nPresumably we want a single pass to propogate unreachability as far as it can go that we run early\n\nI'm not sure I understand what this propagation mechanism is. Would we need to propagate unreachability after each transformation? (I hope not?)\nOn the general approach described in this issue: I think it sounds promising. I've also been moving in the direction of thinking we should keep the unreachable type. I had some different ideas about how to emit proper wasm from such an IR. The ideas are not really complete yet, but something like this: If an unreachable block/if/loop is one that cannot be flowed out of, then it is always valid to \"fix\" things with two unreachable nodes, that is, given this binaryen IR:\n(block U\n  ..code..\n)\nthen it is always valid to emit this wasm:\nblock\n  ..wasm code..\n  unreachable\nend\nunreachable\nThe first extra unreachable makes the block valid, since (a) by assumption it cannot be exited, so it has no brs, and so no brs with a value, and (b) by the same assumption, we cannot actually reach that new unreachable node, so execution will not change; and so it is ok to emit the block in wasm as having no type. (This first unreachable may not be necessary, actually, depending on other type system details.)\nThe second unreachable, as the first, will not change execution, so it is ok to add in that sense. It fixes our main problem, which is that it makes it ok that the block before it has no type, and the unreachable makes the stack polymorphic so it will validate no matter what tries to pop it.\nIf that makes sense so far, then this can actually be taken a step further: again, if an unreachable block is one that cannot be exited, then we can just emit\n..wasm code..\nunreachable\ni.e., don't emit a block at all! Just emit the block contents, then an unreachable. This is valid stacky wasm, I believe.\n(Also in fact the unreachable is probably not needed, since the ..wasm code.. will end with something unreachable anyhow, but that might depend on other type system details.). A shorter way to summarize the last part of my last comment is that, if we allow blocks with unreachable type, and if that means the block is not flowed out of, then we can either (1) emit a proper type based on the outside context, which is what I understood @dschuff's proposal to do - is that correct? - or, (2) emit something like\nblock\n..\nend\nunreachable\nwhich in effect puts a block on the stack, and makes it so it's ok to pop from the stack. So this can be seen as a wasm way to emit an unreachable block. Just instead of having the unreachable type as the block type, it's an extra byte afterwards. (And, while efficiency isn't the main issue here, we don't even need to waste a byte, as I think we can just not emit the block begin and end, it would still be valid stacky wasm, so we actually save a byte.). Seems like overall we are pretty much in agreement here.\n\nSo we could define the validation rule for binary operators to reflect wasm's order dependency in case of unreachable code, or we could keep it symmetric \n\nI think we should keep it symmetric as it currently is, because wasm's asymmetry is only due to the stack machine model (I believe?) and in our AST an asymmetry would be surprising. (Of course DCE makes this kind of a moot point anyhow.)\n\nAdding unreachable and dropping dead code sounds like a good optimization\n\nIs that about my proposal to emit an unreachable block as block [..] end unreachable? If so, it's a side issue that it's an optimization. The main point is that that is the \"natural\" way to emit an unreachable block in wasm, in the sense that it's a simple pattern that always works regardless of context.\nNow, maybe that doesn't matter if we can find the right i32/f32/etc. type for the block during lowering anyhow - if we can, then that's a nice clean solution. But I am not 100% sure we can.\nAnother issue to consider is reading the output back into binaryen. If we emitted block [..] end unreachable as I proposed, then we would recreate the block as none naively, and if we add a type during lowering, then we'd recreate the block as having that type. It would be nice to recreate it as unreachable somehow?. @dschuff:\nWrt symmetry: yeah, I see what you mean. I believe that is currently handled by DCE, though - it should remove all unneeded code including the toplevel add, where possible. So this is a little complexity but it seems worth it.\nWrt finding the right type during lowering for unreachable blocks: Yeah, its those cases like if etc. that worry me. It's not enough to just look up the stack, in general, you may need to look up, reach an if, then go down into the ifs other arm, and so forth.\n\nSpeaking of validation for blocks, IIRC we currently require dropping results of all operands in the list except for the last, correct? In that case it would always be clear what the required type is.\n\nAll operands but the last must be dropped, yes. (But if the last is unreachable, then we need to look at the brs to it to find the block type.)\nWrt round-tripping: yeah, maybe that isn't much different between the two proposals. Workable in either one, I suspect.. > I think for if you don't. If both arms of an if or select are unreachable, then the if is void. If one is unreachable, then its type is the type of the reachable arm. But in that case you wouldn't be inferring the if's type, the type of the if would be i32 already. To find the type of an unreachable block which is the arm of an if you just look at the type of the if containing it, just like any other construct.\nYeah, thinking some more, that does sound right.\n(Except for If both arms of an if or select are unreachable, then the if is void which I assume was a typo, the if might need a type if the parent requires it.)\n\nThinking more about blocks: could say a block has type unreachable if any of its elements is unreachable, and if no br targets it (regardless of its last element).\n\nThat does seem like a good way to define it.\n\nif the type was not void and the last element was not void or unreachable, you'd add an unreachable or drop at the end to make it valid wasm.\n\nI don't think that's necessary? If the block type is i32, and there is a br in the middle, then it shouldn't matter what the last element in the block is, the stack is polymorphic, anything goes.. Exploring this issue, I implemented @dschuff's rule for block types (unreachable iff an element is unreachable, and no breaks), and the simple \"emit unreachables to make stuff work\" approach. I realize we haven't agreed here yet, I just wanted to see how this can work. Here is the diff.\n\nIt appears to achieve the goal: I ran a bunch of tests, all pass in v8. (I am actually not able to test in sm right now, because it has the extra rule of disallowing dead code entirely, and the extra unreachables hit that.)\nImplementing this was simple. The only semi-tricky part was the new type rule for blocks. That hit a few minor things like the relooper fix (was missing a finalize).\nThis makes us fail on the spec tests. I didn't look into it, but it could be the typing change for blocks, which I guess doesn't match wasm anymore. If this is tricky to figure out, and depending on how urgent this is to fix, I think we could consider disabling the spec tests - they were crucial for getting up and running, but now that we have large working test suites, and are diverging more from wasm anyhow, perhaps at some point we can just drop them.\n. Good summary. Yeah, I think 1-8 are exactly what we want here. Earlier on we had hopes of having binaryen use pure wasm, so there wouldn't be two type systems, but we wasm evolved we've diverged. so formally, we do have two now.\n\nAbout unreachable being a type vs an effect, I'm not totally sure I see the difference in our case, but the changes proposed in this issue do make unreachable properly describe an ast node that is not \"reachable\" in the naive sense - you can't get exactly there (you can get out of it, though, if you branch to some outer scope).. This was done in #911 (and followups mentioned above).. (builds on #902 and #904, also inspired by the superoptimizer in #900). And after this the superoptimizer finds little of value, so that's enough for now.. I ended up pushing a bunch more tiny improvements here - once I started noticing these sign/zero-extends, it was hard stop optimizing them out ;) I think now every one that is practically removable is in fact removed, no more work here.. Yeah, we should figure out in kripken/emscripten#4625 how to do it for floats as well. As mentioned there, we need help from cpu people, so we know the optimal thing to emit (I'm not a cpu person :). While debugging fuzz testcases I also fixed mode 2 here, by avoiding pass-debug recursion.. Ok, I made that constant, and now we explicitly track recursion for purposes of avoiding pass-debug when in a sub-pass.. Thanks. Yeah, that's no longer needed, and will probably be removed entirely at some point. Unless we find another use for it.. Thanks, lgtm.. Yeah, makes sense. Looking more carefully, two now fail, return and unreachable, I disabled only them.. So actually it turns out those two spec tests were testing something quite important ;) I had a bug in emitting of ifs with unreachable conditions. Fixed, and re-enabled them, which means all spec tests are back.. I'm now fairly confident this works: 3/4 of the test suite checked so far, all passing; fuzzing for several hours found nothing; and building unity generates a validating wasm (although I can't run it to confirm correctness, hopefully @juj can).. Test suite passes. Fuzzing found 2 issues, one of which which is fixed by that last commit (and was also a bug in sm). The other is a validation error I am still investigating.. Pushed a fix for the remaining fuzz testcases from last night.\nIt's a tiny/obvious fix so I assume lgtms are still in effect, will merge once green.. Ok, cool, thanks. Will merge once green.. @wllang \nI am afraid I must agree with @dschuff that your message is unproductively worded, for example when you say things like\n\nThis is your first and final warning.\n\nIt appears you have issues with the wasm design process as a whole, but this PR is not the right place for them. All Binaryen is, is a technical project that helps us compile to wasm, and all this PR is, is updating the bits Binaryen emits so that browsers will accept it - this is us responding to what browsers tell us to do. Binaryen has no choice in the matter.\n. btw, @dschuff and @jgravelle-google, I can understand if you don't have time/interest to fully review PRs like this and #908, #915, etc., but just wanted to mention that quick general feedback would be appreciated too (like \"seems like the right direction\", or not).. Cool, thanks guys.. This depends on #917 and #918.. This has been refactored a lot, and is hopefully in nice-enough shape to look at more closely. In particular we were discussing using this as a basis for more linking stuff, so let me know how that looks.. Merging, there seem to be no concerns here, and this functionality would have been useful in a recent emscripten mailing list discussion where someone was trying various linking mechanisms.. lgtm, nice. I didn't know that was possible actually.. Thanks @binji, your feedback and the poll results on twitter pointed me towards a more JSey API. I'm mostly done refactoring for that, I'll do another twitter poll after that maybe ;). I found time to debug the test issues here. There were a few typo bugs in the bindings. Everything should be fixed now.. Added initial docs.. Looks like no concerns here, and this just adds new functionality (no risk of breaking existing stuff), so merging.. lgtm.\nOn a side note, I think all those cashew::IStrings should be Names. The IString stuff is an internal detail of how Name works. Unless I am forgetting a reason this code needs those internals.. Thanks, looks even better to me. (lebtm?). There appear to be no concerns for this simple fix, merging.. Looks good, thanks! Before we merge, please join the community group if you haven't already.. Great, thanks again.. Overall looks great, nice work, just the comments issue concerns me here.. 1. Yeah, this applies to both. We may split them up eventually, but actually I am thinking that is less likely, since we now have very fast non-trapping i32 operations (no ffis).\n2. Maybe a little verbose, I agree. We already had makePotentiallyTrappingI32Binary etc., and it seems hard to shorten that (I think we discussed makeUnsafe* at some point, but not clear enough, and makeTrapping* is not accurate), so PotentialTrapMode seems consistent with that.\n3. Yeah, clamp and JS mode do the same for int div/rem, both \"clamp\" div/rem of 0 to 0, the JS default here is good.. Ok, not my first intuition but I can see how that works too, and shorter is nicer.. Ok, how does this look now with the shorter names?. I think https://wasm-stat.us/console has binaries for windows (see \"archive binaries\" step). . I think you need to switch to the 'waterfall' tab, https://wasm-stat.us/waterfall . Then the 'archive binaries' step has a download (looks like it's everything all together, the binaryen binaries are in bin/).. Thanks! I didn't look closely at the code yet, but to verify this works, the binaryen tests can be run with ./check.py  --no-test-waterfall, and emscripten has specific tests for this, ./tests/runner.py other.test_binaryen_debuginfo and ./tests/runner.py  binaryen*.test_demangle_stacks (if you don't already have an emscripten environment set up and don't want to bother just for this, I can run those for you).. The error on travis ci here looks like it's due to the binary size changing in a test. Can run ./auto_update_tests.py to fix that (or just edit the output file manually).. Yeah, that change makes sense. Although perhaps we should print a warning instead of silently ignoring it?. Ok, just some minor comments, overall this looks correct, thanks @pipcet  :)\n@lukewagner: you asked for a ping when we are ready to test this with a VM, this PR should be ready for that.. I agree with @dschuff, we can merge this asap, unless @lukewagner has concerns?. Also optimize pow(x,0.5) into sqrt which wasm has natively.\nProbably a lot more we should do here? Maybe there's a list somewhere.. There seem to be no concerns here, merging.. Fuzzer also found another small related issue with loads, also fixed.. One theory is that the new parallel llvm-nm and linking stuff leads to some nondeterminism in linking (different order could lead to different LLVM temp symbol names). However, that should affect asm.js too, and you say you see no difference there? So sounds like it's not that.\nIf this is binaryen-specific, then you should be able to see the issue with just compiling the final bitcode file. Also possibly with just running the asm2wasm stage on the asm.js. If it just happens there, worth seeing if doing BINARYEN_CORES=1 in the env changes something.. The asm.js file should be output when in debug mode (EMCC_DEBUG in the env). It is saved in the output dir, though, together with the output file(s), not in the temp dir. Perhaps we should save a copy in both?. Nice, thanks. I thought we might need this eventually. Let's just add a test (see the part of check.py with checking wasm-dis on provided binaries... for a test that uses binaries).\nIs that dyninfo stuff documented somewhere btw?. Yeah, wasm-opt doesn't output anything by default. To print text to stdout, though, you can just add --print at the end, which runs the print pass (printing is just a pass).\nAbout dyninfo, there are some docs summarizing some current thinking in that space here: https://github.com/WebAssembly/tool-conventions Your thoughts and plans with dyninfo would be interesting there I think.. I think this may have slipped through the cracks. Is it ready to land?. cc @juj . When @juj is back perhaps he'll have an idea. My only guess is that\nERROR: Repository not found.\nfatal: Could not read from remote repository.\nmight be due to a network error, or disk error? I've never seen it before.. Turned out to be more than one bug here ;) fixes in #940.. Yeah, our error handling could be a lot better - we only really test on fastcomp asm.js output, so that works, but no guarantees otherwise. Would be nice if someone looked into improving the error reporting.. The SDL directory contains SDL1.3, and the SDL2 port in ports contains SDL2.0. Some projects still use 1.3, so we haven't removed support for it.. Is the idea that you'd import one wasm module from another? You'd need to specify a function name then, not an entire wasm module, unless you're suggesting an approach where there is a whole module for each function?\nIn general in the current toolchain, every unsupplied symbol becomes an import from env. Generally people then implement those in JS (using --js-library etc.). For implementation in wasm, that could be done using dynamic linking, e.g. dlopen, which works (but it not optimized).. I don't think I understand yet. Where do you replace \"env\" in your example void custom_logger(int val) __attribute__ ((import, name (\"./custom-logger.wasm\")));?. I see. Yeah, seems like an option to allow customizing the module name for an import makes sense. Curious what other people think.. When I run that command g++ links without an error, but that's when binaryen was built normally, not with BUILD_STATIC_ON. cc @lqd who added that feature.. Oh, I meant to link to a use case before but forgot, https://bugzilla.mozilla.org/show_bug.cgi?id=1347950#c4. Why? And where would you suggest instead?. Sounds ok to me. I don't quite understand how cmake decides to install files - I suppose files in our local bin/ go to /usr/local/bin? So we'd need to create a share directory which installation would copy to /usr/local/share?. When you use emcc with the wasm backend, it will link in system libraries for you, so it would generate the compiled code for that method and link it in statically.\n. Recreating the cfg and re-relooping that was done in #1009.\nWhat is left here is to possibly identify the loop-switch pattern and optimize that as well.. Done in #1049.. Looks like a bug in asyncify in emscripten, when running with asm.js validation it says\na.out.js:5:22736 warning: asm.js type error: '___async' not found in local or asm.js module scope:\nA dependency issue, coroutine create/next don't pull in all of asyncify. Fixed in https://github.com/kripken/emscripten/commit/6b6396e5714b4c4c4c965d6dbc24e673b5f65a2d (although I don't even know if coroutines should work without the other stuff... but this fix can't hurt!).. The idl is used to build binaryen.js, and isn't needed afterwards.. Looks great to me too. Please join the wasm group if you haven't already.. Thanks!. Looks like this replaces loads/stores with calls to imports? Another approach might be to add calls but keep the loads/stores in place, that way the imports don't need to do the actual work, they would just do extra logging or such?. > I think the concern is that if you replace loads and stores with the calls, then the called function must also actually perform the load or store.\nYeah, exactly. And it's possible to get it wrong, e.g. the person writing the called function might forget to handle the offset, or might forget to throw an exception if out of bounds, or might mishandle alignment, etc.\nI'm suggesting something like\n(i32.load ..)\n=>\n(i32.load (call $load-instrumentation ..))\n(here we assume that the function returns its input; saves a temp local)\n. Still working on this? I found I could use something like this for a bug. If you're not I might write something.. Nice, thanks!\nHow about ins => something lengthier like instrument?\nPlease document the arguments to those instrumentation calls, reading the tests, it wasn't obvious to me.. Thanks. Yeah, we can adjust the design later, might want to add the value for store, not sure.. This PR appears to have the last commit that travis has checked (other PRs are not being checked). And the last commit did in fact alter the travis config file (to use trusty) - so perhaps that broke something?. @dschuff: looking in github's settings for binaryen and how travis is set up there, it appears to have your username as the owner there, so perhaps you can see what's wrong? it may be hiding info from me.. Thanks!\nIf you haven't already, please join the wasm community group.\nPerhaps we should bump it to 8MB while we are doing it? That would then be identical to Linux, so things would be more consistent. (Anyone know what the OS X default stack size is?). Thanks!. I think you may be doing things in a more complicated way than necessary. First, native i64 multiplication is present in the default compilation path (asm2wasm), unless it is disabled. Second, even if you switch from asm2wasm to the wasm-backend (which except for testing we don't recommend yet as it isn't stable yet), you can let emcc drive it for you (use EMCC_WASM_BACKEND=1 in the env), you don't need to call s2wasm etc. manually.. Ok, now I see. The extra external call is due to wasm traps, which asm2wasm is careful with by default. You can allow wasm traps, and then it will get rid of all that overhead, https://github.com/kripken/emscripten/wiki/WebAssembly#trap-mode\nAbout the 256 pages issue, I don't understand, do you have a testcase or steps to reproduce?. I don't understand. What is requiring 256 pages - a browser, or emscripten's setup code? If it's a browser bug, which one?\n. I'd guess it doesn't matter much. In a few tests I ran now I see no difference. So we can just remove those.. Oh, right! This was a correctness fix for the interpreter, thanks @binji.\nSo not so easy to remove.... Saves 0.5% of hello_libcxx.cpp size, 0.2% of unity.. Both CIs seem to have stopped working. Anyone know what's going on?. Travis setup looks ok as far as I can tell, just nothing is being run.. Ok, travis is back up, and it found that I had done the multithreading here entirely wrong... Fixed now.. I'd like to land this, but a user reported on the mailing list that it hits a bug on their project. There isn't a reduced testcase, and this passes fuzzing and the test suite, so not sure what to do. Perhaps let's do more fuzzing and testing.. Thanks, good idea. No bugs found with inlining or inlining+optimizing.. Running the new fuzzer on this found a few issues (not in inlining itself, but it uncovered existing bugs), all fixed by #1123, so this should be good to land after that one.. Yeah, fair enough. lgtm.. Yeah, asm2wasm error handling is very limited. We've focused on fastcomp output due to time constraints. But would be great to improve this.. Hmm looks like there's more bustage, that's not enough.... Yeah. I think it is reasonable for wasm-merge to not require those imports, but I'm not sure so I'd like to hear others' thoughts.. Thanks, looks good. Have you joined the community group?. Thanks! Ok, last issue is the failure on travis. I think that's just old breakage we had. If you merge current master in to this branch, it should fix it.. Thanks!\n. Seems ok, but maybe let's not land this until all existing bustage is fixed, so we know it works properly.. We need this update due to the names section changes (other.test_binaryen_names in emscripten). I know little about build systems myself, but this passes travis, works locally for me, and you say it fixes ARM, so unless anyone has concerns, seems ok to merge.. Thanks!. You can't calculate it from a wasm file, it's additional information - that's why it's provided as metadata in addition to the wasm.\nBasically, the wasm file just contains the data, but there is additional space needed for stuff that is either not initialized (like the stack) or initialized to zero. The compiler knows that based on information in the source files, but that information is lost in the wasm. Instead, the metadata tells the rest of emscripten what to do in the JS code that sets things up.\nIn other words, it's not generally possible to emulate a wasm file by itself, it depends on the JS as well. The wasm is not standalone.\nHowever, there is work towards standalone wasm, which does define everything needed in the wasm, see https://github.com/kripken/emscripten/wiki/WebAssembly-Standalone. We do have 2 versions (one handwritten in asm.js, one compiled for when we are not going through asm.js). We should never include both, so something has gone wrong. Please try to create a reduced testcase for this, it's not a known issue.. https://github.com/kripken/emscripten/pull/5299 should fix this. It's not merged yet in emscripten but you can use that branch for now.. That PR was merged, should be fixed now.. Fuzzer found a bug in the coalesce-locals change here. It was kind of a hack anyhow, I rewrote the debugging mechanism to work differently so we don't need it (we assume each debug intrinsic refers to the code after it, the opposite from before; this is better since if we are before we don't get dce'd if the thing the debug info is on is e.g. a return).. Another bug was due to an old obsolete debug info hack, removed it and added a test.. All tests + fuzzing look good, merging. Can do the other possible improvements discussed above later.. @jfbastien: yeah, it would be nice if LLVM did it. however,\n\nDue to LLVM limitations it isn't practical there for technical reasons, which is why compilers like cheerp and emscripten ended up rolling their own solutions.\nDoing it in binaryen means it can help anything compiling to wasm, not just LLVM-based toolchains.. @dschuff @jfbastien: i believe we or some subset of us discussed this in the past in more detail, but I don't remember where so not sure where to find that summary. But the llvm code is here:\n\nhttps://github.com/kripken/emscripten-fastcomp/blob/master/lib/Transforms/Utils/Evaluator.cpp\nI vaguely recall that in the IR generated by libc++'s global ctors for iostream it fails on a bunch of things.\nOverall, the issue is that the Evaluator utility is pretty minimal, it's not close to a full interpreter of LLVM IR, while we do have full interpreter for the other compilers mentioned.\n. @jfbastien: No, that's part of LLVM, it's how the GlobalOpt pass works. that's not out of tree (although I did give you a link to fastcomp, but that's not new code in it - I just couldn't find a better url to link to LLVM code ;) ).\nIn a sense those aren't inherent limitations in LLVM, though, but it does look like it would take a lot of work to have a maintained full interpreter.\n. Yeah, I get that worry. But I want to stress my point 2 from earlier, we need this in binaryen anyhow for output from gcc and other non-LLVM compilers. So I don't think this is an arbitrary choice between \"do it upstream\" or \"do it here\", in which case upstream would be obviously better. We do have good reasons to do it here specifically.. Well, that metric is just one factor to consider.\nOf course I agree that if we hit LLVM bugs we should fix them. It's just that in this PR we happen to have something larger than a few bugs, it's a big chunk of functionality which is just missing in LLVM.\nSo I think we agree on the principles of working with upstream, but in this PR, it makes more sense to do it here since we already have the necessary functionality (a full-fledged supported interpreter, which is what LLVM lacks; when I asked about this, I didn't get encouraging responses from LLVM people). And yes, it's also beneficial to do it here since it helps more projects. It's also beneficial since it's at a lower level (might catch more things)\nYou seem concerned about a dangerous trend, but I don't think such a trend exists. Good to guard against it though.. Isn't this clang taking advantage of undefined behavior?\nI don't think we can do anything in binaryen here. Users can set the trap mode to js or clamp, though, which prevents the trap. (i.e. this now traps by default only because we changed the default trap mode to allow traps).. Specifically, conditional conversions become unconditional when LLVM simplifies the CFG (we run that pass even in -O0 as part of legalization).. Yeah, sorry, see my second comment: it's not clang, it's LLVM's cfg-simplification pass which unconditionalizes it. We do run that in the JS backend, which is why we hit this issue and other backends might not. But isn't simplifying the cfg a valid operation in LLVM at any time? That pass obeys LLVM rules, and LLVM's rules allow unconditionalizing that code because it depends on UB, I believe.. In that case, were we wrong when we said way back that it's ok to make these wasm operations trap, since it's just UB anyhow? To put it another way, you've reached the conclusion that emitting the plain wasm instructions - which might trap - can be wrong in a way that does not involve UB. So compilers can't just emit them even if they are ok with ignoring UB.\nConcretely, here: what can the JS backend do? It seems like it needs to mark that code as having side effects, so that cfg simplification doesn't unconditionalize it. How would we do that? I hope we don't need to add some new intrinsic function for every wasm math operation.. Yeah, looks like we only notice this in the JSBackend because it runs pass for legalization purposes. But in -O1 it would run in both the wasm backend and fastcomp. So this is a general problem. \"Luckily\", in -O1 other opts get in the way on this testcase the problem does not show up.\nBut turns out if we make both of those C variables volatile then those opts don't interfere and in -O1 we do hit the crash in both fastcomp and the wasm backend.. Also seeing this problem on something like input == 0 ? 0 : int(std::fabs(std::log10(input))), where it unconditionally does the log10, fabs, and float-to-int, which can then trap. Might be the same general issue as here, but noting so we remember to check it later.. Overall seems reasonable. We should add a test for this, though. Need to modify check.py and auto_update_tests.py, look for existing tests with asm2wasm, hopefully there's an obvious way to add it there. Maybe similar to how we test the -g flag.. Great, thanks.. Hmm, maybe I don't understand move semantics or how s2wasm works, this hits an error, I presume since we move something we shouldn't be. So not as easy as we hoped.. ping @juj, see question higher up. I believe this has been fixed by #1088, thanks everyone.. (noticed this while running afl, but it wasn't a detected crash). afl found some other issues in dce, added fixes.. Interesting, looks like that test was added 2 months ago, and we haven't updated our spec tests for longer than that. We probably should.... Heh, touch\u00e9.... Yeah, exactly.. Thanks!. It does seem like we don't need to export that method. But perhaps it is there for another reason. I'd use git blame to see who wrote that and cc them here.. Nice, this is definitely worth exploring.\nI think the example output might be missing the set_local in the if?\nConsidering code size, looks like this removes a get_local and changes a select to an if. I believe the get_local is normally 2 bytes (could be more of the LEB for index is over one byte, but very rare), and the if is two bytes more than the select (1 byte for the type and 1 for the ending). So if my calculations are right this would not change code size, but worth measuring.\nConsidering performance, I'm not sure how to read those figures? Is the JS line a pure handwritten JS implementation? And what are the colored bars versus the x's?\nOverall it looks like if this doesn't change code size, then it replaces a set of a local with a branch. Interesting that on chrome that doesn't seem to matter, while on firefox it does. That might suggest that firefox needs to improve its register allocator so that more of those stores become no ops. First thing though, I think it's worth running the emscripten benchmark suite, as it has a bunch of interesting codebases, maybe the picture will be clearer with that data.\nIn general, I don't have a good intuition for whether it's better to have a set or a branch, but this does seem like something that the JS VM backend could do regardless of what we emit. So it's not totally clear what is the best thing for us to emit (if code size differed, I think the argument could have been \"emit the smaller one, and let VMs optimize it\"). cc @sunfishcode \n. About benchmarking, you can run the emscripten benchmarks by doing tests/runner.py benchmark in emscripten. You can edit tests/test_benchmark.py first to pick what you want (e.g. can remove the native benchmarker, pick which js engines, etc.), hopefully the code is clear enough, let me know if not. Output is put in the default temp dir, /tmp/emscripten_temp, so you can look at code size on those benchmarks too. (actually we should probably make it print out the size too...)\nThe reason I stress code size is that it's less ambiguous - almost any code size win is going to be something we want to do by default. Your theory on collapsing multiple assigns saving code size is very interesting I think, for that reason.\nFor perf on the other hand, when it helps some browsers but not others, and so it's not clear what is best, I defer to the browser VM people.\n. To debug this, I'd start with building with -g so the stack trace is more useful. And see these options.. Ok. If you can get a reproducible testcase, please reopen or file another issue.. ubsan notices our intentionally-leaked strings now for some reason, so fixed that too. It does slow us down a little, but less than 1%.. (Depends on #1008 and contains changes from there.). This looks stable now. Sadly it is 6% slower than master (tested on poppler).\nThe core issue is that full and proper handling of unreachable means that any time you remove a branch or alter a type to unreachable, you must recompute types for the entire potentially-affected tree underneath it. Perhaps we should reconsider our options here, but this PR should probably land since it fixes a large amount of fuzz bugs + adds a lot more testing to prevent more.. This is getting out of hand. May need to rethink the entire approach here - it is going to be very hard to actually fix all these issues.. It would be rare in optimized LLVM output, yeah (in principle it could occur after binaryen optimizations make something identical that wasn't before, but I've never seen that). But in non-optimized input or input from some other place than LLVM, it's definitely possible.\nPractically speaking, I noticed this when going over afl-fuzz testcases.\n. Also turns it it happens in our test suite ;). General questions, maybe I don't understand how debug info is meant to work yet:\n\nWhat is the URL?\nLooks like there is both code to write out a separate binary map file, but also read and write inside the binary?. Thanks, but what does \"later map\" mean in all those cases? Is that an expected spec change, or something happening now in the toolchain?. Ok, I think I see, so this emits some map file that is later translated to a full source map by the sourcemapper tool in emscripten? And you're asking if we should do the full translation here?\n\nIf that translation is trivial, it might make sense to duplicate that functionality here, since then the code here would be useful by itself. But I'm not sure how simple it is, what do you think?. Ok, this lgtm. Did anyone else want to take a look?. Looks like no concerns, so merging. Thanks!. Hmm, we don't need those files in emscripten, but what we download is just the github zip of the repo, which includes everything. Maybe we could set up something more sophisticated with just the files we need, but I'm not sure how to do that or how much work it would be.\nAlternatively, we could change the test infrastructure. Right now it encodes the passes for the test in the filename. We could move them to a side file instead perhaps.. This should be fixed now on master.. cc @juj who wrote that code.. I believe this is something @jfbastien suggested a while ago.. Overall looks good.\nHow about wasmBuilder = > builder? That's the name commonly used elsewhere.. Also, what is the plan for testing here?. Oh, if it fixes failing tests, that seems sufficient.. Ok, I think that's the last comment I have here, should be good to merge with that.. The RemoveUnusedModuleElements pass should remove unused function types, but looks like it doesn't yet (it just does functions and globals so far).\nIt would also be a good idea, as you suggest, to remove duplicate function types. Not sure offhand if it's better to add a new pass or maybe rework the one mentioned before into OptimizeModuleElements (that both removes unused ones, and merges duplicates).. Great, thanks!\nAnd very nice work on AssemblyScript btw, great project.. Good idea, I've been meaning to add it to npm but didn't find the time. Not sure how automation would best be done, but worth thinking about - especially if we start updating binaryen.js more frequently, which we should.. Yeah, building LLVM/clang is pretty heavy. But the emsdk has a binary version for linux, which in theory could be used. However, it didn't just work, see https://github.com/kripken/emscripten/pull/5167 and https://github.com/kripken/emscripten/pull/5087 , something needs to be figured out there.\n. cc @juj, I think this came up earlier as well as a suggestion for building the emsdk for linux, but I'm not sure what was decided.. You can set -s ERROR_ON_UNDEFINED_SYMBOLS=1 to make those warnings be errors.. Thanks for filing, and sorry this got forgotten somehow. Fix in https://github.com/WebAssembly/binaryen/pull/1219. That sounds like a version mismatch, using an older binaryen. Perhaps you set BINARYEN to point to an older version in ~/.emscripten? Also, any warnings when you do emcc -v?\nWhen I test 1.37.13 (without any value set for BINARYEN, so it uses the default), it works.. Very odd that it doesn't support thread-local storage. Never seen such an error before.\nSome searching suggests it was a bug in xcode http://textmate.1073791.n5.nabble.com/error-thread-local-storage-is-not-supported-for-the-current-target-td29117.html#a29133. Seems like the best solution, lgtm.. I never know what's best for these things. Worth comparing to LLVM and other projects perhaps? But my intuition is that we should use Fatal() << \"error text\" etc. when we want text to be printed, and WASM_UNREACHABLE() in places where control flow should not reach, like a switch case we know is logically impossible.. Is LLVM not installed where LLVM_ROOT is pointing? The error says it fails to run LLVM tools.\nIt also fails to run node, so need to check that path too. Given so many things are broken, perhaps something went wrong during install? Might be worth trying to reinstall from scratch.. @yurydelendik, do you have time to take a look at this?. Looks like no concerns here, merging.. Merging quickly since this fixes an actually risky bug. Feedback can be addressed in followups.. Looks like the C API (and binaryen.js) don't have a way to parse the s-expression format yet. We can add it if it would be useful.\nNote btw that the text formats that wabt and binaryen parse are not identical. wabts is the official wasm text format, which supports stack machine syntax and so has less structure, while binaryen's text format is closer to a previous version of wasm's text format, without stack machine syntax, and that validates structure fully. For simple things you might not notice a difference though.. Sorry about that, we did a major rewrite of binaryen.js, from the C++ API to C API. This fixed many issues, but the C API itself is not yet complete, so some things regressed as well.. Here's a PR to add text parsing to C API and binaryen.js: #1050. Why did wabt make this change? Is that what the wasm spec requires?. Thanks, lgtm. lgtm. Yeah, this PR gets us pretty close to that. I think we'd just need to add module merging to get what you want. We already have wasm-merge as a tool, it could be refactored into a C API call.. Yeah, it would be good to do this. We will still need JS though even when the compiled code is wasm (for all the integration, exceptions support, etc.). Also, we will still need the asm.js version as well (as some people might be using binaryen.js in their build system, which might use an older node).. lgtm, but I'm not a cmake expert and i'm surprised you can set the compiler to a C compiler and have it work, since we need c++? or if that just sets the c compiler but keeps the default c++ compiler, i'm not sure why this fix fixes it (since you don't say which of the two the flags are applied to). Probably my own lack of knowledge of cmake.. I see, thanks. Yeah, this fix seems best. No C code now, but maybe in the future.. Thanks, it does look like that's a factor here. Disabling that pass makes fannkuch 7.5% faster and 1.2% smaller.. I tested SpiderMonkey and v8.\nWhich I guess raises the question, do any wasm VMs do that type of optimization?. Doing more thorough testing, it looks like disabling lsr removes most of the speed issues with the wasm backend. Without that pass, it's almost always within +-10% of asm2wasm (one exception, lzma, where it is 1.3x slower on sm and 2.5x slower on v8).\nDoing so also helps code size, but it's a very small factor there. Still e.g. 7.5% larger on box2d (or 3.5% larger if we binaryen -O it).\nSo I'd recommend we disable that pass. If that makes sense, would the place to do it be in LLVM, or should we pass the flag to llc from emscripten?. Followup PR: https://github.com/kripken/emscripten/pull/7386. That looks like the main recursive parsing loop. We could solve this by using a stack instead, but that might not be trivial to do (and we would need to measure speed).. In that case it is, but not for others such as\n(if (..condition..)\n  (block\n    (call $abort)\n    (unreachable)\n  )\n)\n(the wasm backend does emit stuff like this, not with a literal if though)\n. Probably not a big deal in size. It's noticeable in hello world because malloc/free use that pattern (and have lots of checks!). But we could modify the malloc/free build args so that it calls llvm_unreachable() (or whatever the intrinsic is for emitting an unreachable). And I guess if it's a size issue anywhere else, the recommendation would be the same?\nAnnotation is an issue, yeah. In theory we could say that binaryen assumes env to be a special import prefix, corresponding to the standard musl etc. libc we compile in right now. Then env.abort means C abort, etc. But not sure how I feel about that. Thoughts?. PR to change dlmalloc aborts to unreachable in https://github.com/kripken/emscripten/pull/5332. It looks like this broke the s2wasm tests. I saw them broken locally, bisected to this commit. Also, it looks like they broke on CI here, it says \"2 of 4 checks passed\"? @sbc100 . Hmm, does changing char to auto on the previous line fix it for you?. I think the recommended way is to define stdin, see http://kripken.github.io/emscripten-site/docs/api_reference/Filesystem-API.html#setting-up-standard-i-o-devices https://stackoverflow.com/questions/32912129/providing-stdin-to-an-emscripten-html-program. Yeah, wasm has those too. See the _signed param to the makeTrapping* methods, we should be handling those.. lgtm, thanks.. Nice!\nI'm not an expert on this stuff, not sure I fully understand how this works. But I have a few questions/notes:\n\nJust to confirm, this doesn't remove any existing testing, and just adds one new test mode? (the others are refactored, but remain, and still run with the same tests?)\nIt sounds like that new job is slower since it does more builds? Do you have a sense of how much? In particular I worry if it's close the timeout (15 minutes on travis, I think?) we might have failed jobs now and then.\nFully built binaries sounds potentially useful, cc @juj. Oh, I realized I can read the travis logs for the builds that just passed. Looks like 5 new builds, 3 of which take >30 minutes, but don't timeout, if I read that correctly?. I see, thanks. Looks good to me. One note is maybe the binary building should be disabled for now, until we decide how to integrate it with our other stuff? Just to not be wasteful, I mean. Maybe it could just be commented out, but left easy to enable.\n\nWould also be good to have other people take a look at this before merging (as I said, this isn't my area of expertise).. Ok, everything sounds good here, I think we can merge this?. Thanks, that all sounds good to me, let's merge this in. I'll add that auth token as a followup in a bit. Other stuff mentioned in the last few comments we can look into as followups as well.\n. Thanks!. Looks like it's on (export \"\" (func 0)) - but what does that mean? How can an export have an empty name?. Looking at this more carefully, the issue is that there is an import starting with a null (0), which we read as the empty string, which conflicts since there was already an empty string before.\nBinaryen export names are currently Names, which are null-terminated. Not sure if it's worth changing that just for this type of obscure testcase.. #1068 makes us show a better error on this case (but does not fix anything).. I improved the message here, to clarify what is valid wasm.. What are shared memories? Is this something new in wasm? Where are they supported?. Thanks, now I understand the context here.. Usually code is around half as fast as native, or better, but some things are currently much slower, like C++ exceptions and SIMD. If the code uses those features, that could be the reason.\nYou can use browser profilers to see what is slow, maybe it will show something.\nAnd if you can create a benchmark showing the issue, please share it here.. The wasm-function problem is because wasm changed the names section format. That should be fixed on firefox nightly and beta, but is still a bug in release.. Nice find!. I am concerned that before we had var Binaryen = which meant that bundling the code inside other JS was possible, and it just added one local var (which may have been non-global). With this PR, we would add a global var. Could we assign just the local var, like before, for the non-module loader mode?\nalso cc @yurydelendik who knows about this stuff. Ok, good points. Let's do it your way.\n. This is still an issue, but I assume not worth fixing in s2wasm since it's going to be replaced by o2wasm.. Looks like no concerns, and this just adds a new pass, merging.. I think we might need some followup work here:\n\nThis PR added a property to loads and stores. We need to make hashing, copying and equality checking work with that. This could be a silent error, so it's worrying.\nThe new atomic expression type needs support for those things as well. Also possible that it needs support in some of the optimization passes. This should cause aborts, so it's less worrying.. Nice, I didn't know that api existed.. This is a confusing thing that we should document better. Wasm has just a Call node, while Binaryen IR has separate Call and CallImport. In this example, it works with module.callImport. Better docs and error reporting in #1081.. Thanks, yeah, that's a typo. Will fix in that PR.. lgtm with that.. lgtm. Good idea, thanks, I didn't know about that. Done.. Thanks!. For reordering, the simplest is probably to add to test/passes/simplify-locals.wast, as that pass focuses on reordering stuff like\n(set_local $x (i32.load (i32.const 1024)))\n(drop (i32.load (i32.const 1024)))\n(drop (get_local $x))\nThe set should be moved to the get normally, so one load crosses the other, but if you make them atomic then it should not. (If just one is atomic, can it be reordered?). lgtm so far (but i would like to review the tests). It splits out multiple modules and then compares the combined results, doesn't it? Multiple modules are used in e.g. the test/passes/duplicate-function-elimination.wast. Maybe I don't understand what you're looking for.\n\nAlso, can't you just add a function (or functions) for this, why a separate module?. Looks like no fundamental concerns here, and I have another PR based on this, so merging. But if my responses above don't make sense to you, let's keep discussing of course.. When I do bin/wasm-opt libc.wast -o libc.wasm on that file, I get\nwasm-as: /home/alon/Dev/binaryen/src/wasm/wasm-binary.cpp:348: uint32_t wasm::WasmBinaryWriter::getFunctionIndex(wasm::Name): Assertion `mappedFunctions.count(name)' failed.\nInvestigating, it is trying to find what to do for $exp. And that function seems to be used in the table, but not imported or defined, so the wasm file looks invalid. How was it created?\n(And what version of binaryen did you use? Odd that you saw another error.). The LLVM optimizer created a switch there,\nswitch i11 %trunc, label %if.end7 [\n    i11 0, label %if.then\n    i11 -1, label %cleanup\n  ]\nWe have heuristics for when to lower an LLVM switch into ifs, looks like they didn't kick in here. Perhaps when optimizing for size we should do it in binaryen?. Fixed by #1502.. Hard to say offhand. Are there any numbers on the expected benefits to code size and/or perf? (the link mentions as motivation what this could allow, but not why allowing those things would help?) It would depend on that I think.. Probably some simple experiment could try to estimate pick's benefits, but to really measure it properly would take some more involved work. Another option that seems simpler is to take a platform that has pick (Java?) and see if it can be disabled/removed there, and how that affects code size.\nOverall though, from a wasm optimizer's point of view, I think the less complexity the better - so we can focus more on fewer things. So all these proposed features sound somewhat concerning.. I think the issue is that optimize()'s second param is by reference, which is changed by the patch. Changing the first, second, third params to be *& makes it work.. Yeah, that's it, thanks. I think this was missed since clang doesn't end up emitting it, but looks like rust can. Fix is in #1106.. Fixed by that PR.. Glad to see interest in working on this :)\nWe should figure out a plan for how this will work - perhaps you've already thought through these points, but these are the issues that stalled the initial work on this:\n\nHandling control flow, wasm allows e.g. a loop inside an if condition, which asm.js does not.\ni64 support.\nEmitting reasonably efficient asm.js code. The first two issues can mostly be fixed up with adding temporary locals, but then we need to optimize those out somehow.\n\nThe good news is that I think (1) can be handled by running the flatten-control-flow pass first; then what is left is much simpler and should map 1:1 to asm.js. And (3) is much less of an issue since the binaryen optimizer is now good enough to optimize away temp locals like that, so all optimization could be done in binaryen, without depending on running an asm.js optimizer.\nAlso the tradeoffs need to be thought out. Sounds like your focus is on offline compilation, while I think it's also useful to have client-side compilation (e.g., a polyfill). That could affect the design here.\nThoughts?\n. The main tradeoff there is compilation speed, I think. But maybe it's not an issue any more, in the past we would have needed to run the slower asm.js optimizer on the asm.js, but now it's probably enough to just run the fast binaryen optimizer before doing the conversion to asm.js. Could be fine on the client.. Test-wise it would be good to (eventually, not necessarily in this PR, depending on when it lands) have some reference tests (i.e., compare the asm.js output to a correct output) and functional tests. For functional tests,\n\nWhen we run the wasm spec tests, we should see that we can wasm2asm each one and run it as asm.js with the same output.\nWhen we run full compiled programs compiled with emcc, we could compile the wasm part into asm.js and see that the program runs as expected.\n\nIt would be good to have both, although the main use case discussed here would be the second of those, so the first might be left for later.. Hmm, STAT nodes only matter for printing of JS, they say where to emit a semicolon, and the asm.js subset is simple enough that I think we'd either be ok without semicolons, or would know trivially where to add them. In other words, we might need to change the asm.js AST => asm.js text code a little, but I'm hoping not much, probably just something like add a semicolon\n\nafter each statement in a block\nafter the if body (and else if there is one)\n\nafter the for/do/while loop body\n. lgtm, thanks.. Thanks for reporting, proposed fix in #1111. This makes it check if the offset condition has any upper bits, in which case it branches to the default. Does the output look ok to you?\n(func $main\n  (local $$0 i64)\n  (local $$x i64)\n  (local $2 i64)\n  (set_local $$x\n   (i64.const 0)\n  )\n  (set_local $$0\n   (get_local $$x)\n  )\n  (block $switch\n   (block $switch-default\n    (block $switch-case\n     (br_table $switch-case $switch-default\n      (i32.wrap/i64\n       (block (result i64)\n        (set_local $2\n         (i64.sub\n          (get_local $$0)\n          (i64.const 9218868437227405312)\n         )\n        )\n        (br_if $switch-default\n         (i32.wrap/i64\n          (i64.shr_u\n           (get_local $2)\n           (i64.const 32)\n          )\n         )\n        )\n        (get_local $2)\n       )\n      )\n     )\n    )\n    (block\n     (call $abort)\n     (br $switch)\n    )\n   )\n   (return)\n  )\n ). To validate, check out and build binaryen manually. Then set the env var BINARYEN to point to the the dir containing binaryen when running emcc.. Hmm, I don't know how rustc works. But if the env var fails, you can edit the ~/.emscripten file to point BINARYEN_ROOT to the dir you have binaryen. (Unless rustc customizes the location of the .emscripten file? Probably it doesn't but I'm not sure.). Thanks for confirming, merged.. This is a corner case I'm not sure what to do with. What's going on is that\n\n\nWe decided to allow wasm traps by default. It's fast to emit a potentially-trapping i32.trunc_u/f64 (what traps here) rather than guard against it trapping.\n\nEnabling safe-heap makes it do some more int/double conversions, and one of them happens to hit this trap (nothing to do with safe-heap, just that it instruments the code in ways that avoid optimizations removing what would otherwise trap). This is bad since it makes safe-heap behave differently than normal mode.\n\nYou can work around this for now by building with -s \"BINARYEN_TRAP_MODE='clamp'\". Maybe we should just enable that to avoid safe-heap trapping, but that changes safe-heap in another way, so I'm not sure what the best solution is.. Meanwhile I documented the issue better on\nhttps://github.com/kripken/emscripten/wiki/WebAssembly#debugging\nNot sure yet what we can do aside from documenting this. A tricky point here that we may want to do something about is the interaction between the two optimizers. What can happen is\n\nThe user builds normally, which means we allow traps in wasm.\nThe user builds in a mode like SAFE_HEAP which enables the asm.js optimizer.\nThe asm.js optimizer assumes JavaScript semantics - no traps - and can do things that depend on that.\nThe code is converted to wasm, where it traps.\n\nSo the problem here is that the asm.js optimizer is unaware of the wasm trap mode. This is rarely an issue as we don't run the asm.js optimizer anymore, aside from special modes like SAFE_HEAP.\nPerhaps when we allow trapping in wasm but are forced to run the asm.js optimizer, we should issue a warning? Or perhaps we should disallow traps in wasm when doing so?. The truncation operation uses >>>, which is an unsigned operation. For example, -1 >>> 0\n =>  4294967295.\n. Yeah, that's a good example of the same issue. I verified -s \"BINARYEN_TRAP_MODE='clamp'\" fixes that as well.. 2 times slower is very bad. @metalpavel, can you maybe create a standalone benchmark of what you are seeing? Or if not, can you profile it and see what's going on? One possibility is that we could add separate flags for clamping different operations, this was proposed in the past but we didn't have data that supported it yet.. Thanks for the benchmark. Some numbers about inlining are in https://github.com/WebAssembly/binaryen/pull/1125 , looks like we can get rid of most of the overhead that way, but not all.. Yes, just adding -s WASM=1 should do that. The only reasons we don't do it now is we want it to work in JS shells even if wasm isn't present (e.g. older node.js), and it means a separate file on the side, as opposed to a single file for everything.. I see, thanks. Ok, then we are indeed emitting bad code in cases of unreachable code like this.. Will be fixed by #1117.. Following the resolution of https://github.com/WebAssembly/wabt/issues/588 , I had to do some more fixing here, so you might want to look at the last commit. It introduces a hack which seems to work well in practice, basically, when the stack has just 1 element, and that element has type unreachable, it leaves it there. This allows reading wasm binaries that are only valid because of the polymorphic stack mode.\nThis is a hack instead of a full, true solution because binaryen binaries aren't really wasm. At some point we may need to diverge the two, as discussed in the past. Here the issue is that we don't have a type-checking stack and a value stack, we have just one stack (of values), and we read from it into an AST. So it's not easy to actually do the full wasm stack stuff.\nProbably there are more issues that this hack doesn't fix, but it seems to fix everything seen so far by fuzzing of binaryen-emitting binaries. So it at least gets us a lot closer to being self-consistent.\n. Yes, looks like a duplicate of that, closing this one.\nI think this is more of an issue now because wasm makes memory growth more useful. Before very few people used memory growth in asm.js, so bugs there went unnoticed.. Let me merge this in since it's blocking another PR. But feedback on the code is as always very welcome.. I don't think it's possible to create problems in wast text files - since we don't parse the stacky stuff. We just parse structured s-expr code, which doesn't run into problems. The only problem is in wasm binaries, which this PR works around.\nAbout round-tripping, actually we already don't have binary round-tripping being identical, also because of unreachable stuff - we emit extra unreachables in some cases, for places we allow unreachable things but wasm doesn't, like blocks and ifs. But it's true that this PR takes us much further in that direction. In practice, I don't think it's too much of a problem - unreachable code won't be run so as an optimizer, binaryen doesn't care about it; and otherwise, when we need the ability to save IR in a lossless manner, we can use wasts (and some day we may add a binaryen IR binary format).\n. Thanks, lgtm.. Looks like something bad happens in binaryen3.test_printf, noting to investigate that further.. If I understand that, it would be slower in some corner cases (values around the absolute size of 1^31, 1^32, due to asymmetry around 0, and depending on signed/unsigned etc.)?. I see. Well, this seems a little tricky, let's leave it for future careful investigation. I think this PR is orthogonal to that, even if it was motivated by it, as there are other use cases for inlining.. Gathering some more data, this actually shrinks code size in most cases, since it just inlines small things without calls or loops etc, and they tend to get optimized well. The one outlier in the benchmark suite is lua, where it increases code size by 1.5%, as it manages to successfully inline many of the little lua helper functions.\nSpeed-wise, no noticeable differences on the benchark suite. This is probably only noticeable in cases where the call overhead is really large, and many apps avoid such things (or the LLVM optimizer helps them avoid them, for apps compiled that way).\nStill, I think this is useful to merge, as it does help significantly on the benchmark at the top of this issue as one example. It basically makes our inlining pass more like a normal inlining pass.. Looks like no major concerns here, merging. Happy to iterate more on names and refactoring later as necessary.. It's possible it's running out of memory on your machine. I'd look at a memory monitor as it runs, see if something odd happens.\nIf that's not it, please try to make a standalone testcase showing the issue (as small as possible, single input file, etc.).. Running this in a debug build in gdb, the crash is because it sees a SIMD type. SIMD is not supported in wasm yet.\nWe should have an error on this in emscripten, but maybe it's not working properly. Did you build with SIMD=1? That matters for what type of error detection should be used.. Yeah, I think that's it - explicit vectorization leads to SIMD being enabled even without the option being specified. Looks like we're missing checks, I opened https://github.com/kripken/emscripten/pull/5462. I'm curious if there's an automatic way to do that. All I can think of offhand is to remove explicit use of SIMD types in the source code, which in some projects is possible with a #define.. It might be worth looking for an LLVM pass that removes SIMD from IR. I haven't heard of one but it seems practical and maybe someone created it.. Aside from those minor comments to fix, looks good.. Hmm, that seems very bad. First thing, can you use git bisect to find the specific changeset that caused this, or is 9a18081 that you mentioned the result of bisection?. Thanks! Ok, looking into this, the breakage is because comparing threads broke in single-threaded mode. Fix in https://github.com/kripken/emscripten/pull/5487. Thanks, nice.\n\nDoes this need to rebuild the .js builds after that infinite recursion fix?\nLet's add a test here.\nLet's open issues on the orthogonal wasm2asm issues, so we don't forget them.. Yeah, test should go under test/binaryen.js/.. Thanks! Yeah, the test will need to be improved as the functionality here gets more useful.. You can use wasm-as to convert a wast file to a wasm file.. There isn't another way that I can think of to get a reference wasm. The best we can do is wasm-as. (If we wanted to add those tests to the main repo, that's what we'd do, run wasm-as and check those in, consider them as references, and then it would protect against regressions later.). Yeah, would be nice to fix this. We don't parse the stacky non-sexp format that wasm changed to, binaryen's text format is basically the previous s-exp format. It would be nice to have a parser able to handle both.. merge-funcs merges identical functions, while the stuff here looks for similar-but-not-identical functions. Or did I misunderstand your question?. @jfbastien: interesting, I don't see that in the main repo, I suppose this was an experiment somewhere else? Do you know where?\n\nI agree it would be good to do this in LLVM if it's practical to do so.\n@achoudhury85: thanks for the data. Makes sense, yeah, 20% does seem unlikely to happen on most codebases. But 3%-5% is still very useful :)\nWould it be practical to measure how important the different pieces of SFE are? I mean, if at full power it's 20%, and you disable handling of different constants, how much worse does it become? And so forth for disabling handling of different functions. (Maybe this could be done with just commenting out a few lines, etc.? If it's very hard then probably not worth it.)\nAnother thought is I wonder if it's important to handle extra code, i.e.\nfunction foo(x, y) {\n  x += y;\n  return x;\n}\nfunction bar(x, y) {\n  x += y;\n  work(); // an extra line\n  return x;\n}\nIt would be easy to handle that (an if instead of an if-else) but it does seem like it would be harder to find such opportunities.. Doing some searching, I found Swift has a similar-functions-merging pass,\nhttps://github.com/apple/swift/blob/master/lib/LLVMPasses/LLVMMergeFunctions.cpp\n@jfbastien, maybe that's what you meant?\nLooks like it handles different constants, but otherwise is a copy-paste of the LLVM one. Apparently in Swift it's common to template on metadata which ends up being pointer constants.\nOverall, I suspect we will want duplicate and similar function elimination in both LLVM and Binaryen because each location is useful in a different way. So the question might be which to improve first. For LLVM,\n\nWe can build on the existing MergeFuncs pass.\nImproving LLVM would help everything using LLVM, not just wasm. For example, it would help native compilation to x86, ARM, etc. (But MergeFuncs appears to be turned off by default in LLVM, so I suspect very few people would benefit? Looks like only Swift has it on.)\nMergeFuncs can be run on LLVM IR, so it can be done when doing LTO.\n\nFor Binaryen,\n\nWe can build on the existing DuplicateFunctionElimination pass.\nImproving Binaryen would help everything using Binaryen, not just LLVM output. For example, it could help gcc, WasmScript, etc.\nDFE can be run on arbitrary wasm, so it can be done after linking wasm once we get that (i.e. when not doing LTO).\n\nI'd say those are mostly even. However, some additional reasons for focusing on Binaryen first are\n\nFaster to run, since it can be parallel like DFE is, which can matter a lot in whole-program passes like this.\nFaster to write, since I'm volunteering to do it, and I know Binaryen a lot better than I know LLVM.\nAlso some concern on Swift having an improved fork of LLVM's MergeFuncs, might need to coordinate with more than one upstream.\n. I think partial match could also be a compile time win, it also causes fewer functions to be optimized. (But of course it does do more work and the functions left are slightly bigger, so it's not obvious either way.). Yeah, I agree inlining probably makes more sense first.. @achoudhury85, @hackcasual: does your current implementation handle just pairs of functions, or also three or more? For three or more this seems less efficient (can't use a simple if-else, and harder to find matches), I'm wondering if it's worth handling that.. Yeah, definitely hashing is crucial here.\n\nThe inefficiency I meant is that switches are less compact (need more blocks + branches in wasm). And if-else gets slow with a long chain.\nThe complexity I meant is what if A is similar to B but also similar to C in another way, you need to pick one. If you consider triple+ matches, this is less simple (decision depends on later funcs).. I see. So if A and B differ just in one location, and A and C also differ just in one, while B and C differ in 2, then you still optimize them all into one function? Make sense for code size, and I guess this pass is focused on that anyhow. (It's not obvious to me that this won't miss some things. The overhead from handling 3 functions in one might be larger than the win - but it does seem like those would be odd corner cases.)\nAbout code size, in wasm an if-else is 4 bytes. If there are no side effects - likely - then we can use a select, just 1 byte. But a switch requires a block and a break for each condition, 5 bytes :( That's already bigger than a constant or a local.... I see, thanks. One thing I didn't fully appreciate til now is that when handling constants, you can avoid ifs - instead of a parameter saying which control flow path to take, the parameter can be the value itself. Also hashing is easy that way, as you said.\nDo you handle arbitrary expressions? Say if two functions differ only in one part where one has a + b and the other has a * b, would you do an if there,\nfunction helper(.., which) {\n  ..\n  .. (which ? a + b : a * b) ..\n  ..\n}\nOr do you not handle that case?\nSame question for extra code, where two functions differ by one having a few extra statements in the middle, optimizable to\nfunction helper(.., which) {\n  ..\n  if (which) {\n    extra();\n    code();\n  }\n  ..\n}\n?\nI am leaning towards trying to support those as well, but it does make things more complex and longer to run.. Got it. And what about a + b vs a * b, did you consider optimizing functions differing only in that?. How do you handle hashing in that case? Do you ignore the operation, so it's a ? b? In that case, I guess you wouldn't match ~a (a unary) with a + b (a binary)?. Got it, thanks, I was just wondering if there was a clever hashing trick I was missing here.. Another thing to consider here is the effect on gzipped size. Has that been measured on the asm.js implementation?\nI would guess this reduces the benefits of gzip but probably doesn't have a negative effect, but would be good to confirm. However, we should probably remeasure on wasm as function order matters. We currently order functions by number of uses, so the index of popular functions is small, but we should also order by similarity for gzip purposes as in that link, and so any measurement would be incomplete before we do that.. Ok, then as a first step here I think we should get the compression-friendly reordering in place. That will allow later SFE measurements to be more valid. I can get to this soon unless someone else wants to.\n. Very interesting data, thanks @achoudhury85!\nLooks like we'll need to be careful here because of those cases where code size is actually increased or gzip size is.\nMy plan is still to get the gzip-optimized reordering in first. I hope this will give us most of the benefits of SFE on gzip size, in which case maybe it's actually not worth doing SFE (given the complexity and risk). More likely there will still be a benefit, and then we can use the gzip-optimization code to help avoid the bad cases where we increase gzip size.. Sorry I haven't had enough time to really focus on this. I did find out a few things in experimentation, writing it out since maybe someone else can get to it before me:\n\nWe should sort by LEB size (how many bytes in the call instruction) and afterwards similarity.\nSimilarity sorting can probably be greedy - pick the most similar for the last function emitted so far.\nSimilarity can take into account only the last 32K of the last function and first 32K of the next function, as that is the gzip window size. Much less would work too, probably. This avoids scanning very large functions.\nThe new tableOfContents attribute in the binary writer makes it easy to look at the byte output of all the functions.\nSimilarity should be done in O(N) time, without comparing every pair of functions, as in big files it's just too slow. One option is to generate a \"fingerprint\" of a sequence of bytes (say, hash each byte, pair, and so forth, and note how many of those hash values we see), and then comparing two fingerprints is pretty efficient..  * Similarity ordering is probably a blocker for enabling function reordering, as reordering by itself improves binary size but often regresses gzip size.. Some more experimentation in https://github.com/WebAssembly/binaryen/commits/func-order. Yeah, same behavior as asm.js for now is best, I think.. Thanks for noticing. Strange, I thought we checked this worked properly when we added it, but I guess not...\n\nLooking quickly now, I don't see anything obviously wrong, and I don't have time to investigate this in depth. Opened #1160 to remove this stage until we can find time to figure this out.. I meant, I thought that the error in the logs that you noticed now wasn't in existence back then. Strange how it was missed...\nThanks, I edited the token now and restarted one of those jobs to see how it works.. Looks like it's working.... Yeah, I should have been clearer. I wasn't sure if those are valid wasm or not - looks like not, based on what you say. But we started to accept them in binaryen as a result of the wasm stack changes. I don't remember the full reasoning back then - maybe we just relaxed validation rules because it seemed simplest - but I think we can do things better with the changes in this PR.. Looking at the spec test issues here more carefully, some just needed to be fixed. They were already fixed upstream, so what might have happened is when we switched to the stack stuff the tests were not yet fixed at that time.. Yeah, binaryen still supports if i32 so I did that for consistency with the tests around it. At some point we should upgrade all the tests (or fork them) and remove the old notation support, probably.. Added a commit to also clean up the \"untaken br\" issue mentioned above. That means that we don't ignore unreachable brs in type checking. Consider\n(block $b\n  (br_if $b (unreachable))\n  (unreachable)\n)\nThen before this change the type of the block would be unreachable (since the br_if is not taken). After this change the type would be none, since has a br referring to it.\nThis gets rid of a bunch of unnecessary complexity (ignoring untaken branches, handling cases where a branch becomes taken or untaken), and complements the other commits in returning us to a more structured type system.. Thinking some more on this, I think the core issue is the type system changes from #903 etc., when we moved to make a block unreachable if any of its children is unreachable. When we made that change we still allowed the annoying case mentioned at the top of this issue,\n(block\n  (unreachable)\n  (i32.const 10)\n)\nThe block has type unreachable despite having a final element which has a concrete type, which is wacky. We probably should have made that not validate back then, and that's basically all this PR does - see the wasm-validator.cpp changes. All the rest of this PR falls out of that.\nThe one slightly odd result from this is that the block in the example should have type i32, while if the last element were (nop) then it would have type unreachable. In other words, there is an asymmetry here between all the concrete types and none, as it is only none that will be turned into an unreachable if there is an unreachable child.\nI think this makes sense to do despite the asymmetry, because in wasm there is already an asymmetry there, (block (unreachable)) can be optionally given a concrete type, ever since wasm moved to block and if signatures. We have always had some unease around that, as the binaryen optimizer could strip the type of (block (result i32) (unreachable)) if it wanted to, while a none type can never be stripped.\nAnd actually the change in this PR makes things better there too, while we could strip the type in that trivial case, we couldn't for\n(block (result i32)\n  (unreachable)\n  (i32.const 10)\n)\nIn other words, requiring the last element to be valid for the type, as this PR enforces, means we can't change types in silly ways like removing the i32 from that block. Furthermore, this is more efficient: when updating the type of a block, if the last element is concrete, we don't need to scan the other children to see if one is unreachable. Finally, this change makes the code simpler and it seems more resilient to fuzzing.\n@dschuff, @jgravelle-google, you suggested the type system change in #903 etc. - thoughts on this change? If you don't have time to do a full review of the code, it would still be helpful to know if you think this direction makes sense or not for the type system.. I think this makes conversion to wasm simpler and better in that we have fewer blocks with type unreachable, which is the tricky one for us since it doesn't exist in wasm. Namely, this PR rules out (block (unreachable) (i32.const 1)) which we need to fix up for wasm by adding another unreachable in and out of the block; after this PR that block would have type i32 anyhow, so it's emitted more efficiently and simply.\n(However, we can't get rid of that unreachable-handling code because we do still have unreachable blocks without a concrete final element, like (block .. (br $somewhere)). So this PR lets us use that code less but it's still needed.)\nI don't think conversion from wasm is affected, since there are no unreachable blocks like that coming from there. I.e., wasm wouldn't tell us to create stuff like (block (unreachable) (i32.const 1)) anyhow, as @binji pointed out. . Thanks! Interesting that the fuzzer didn't find this, I'll need to figure out why.\nFix in d199aafed128cdf52de229aba4cf4c6769929e71 on the fuzz branch. That's waiting on another branch to land first.. Is 3 enough? Have I been typing an extra character all these years?\nedit: turns out yes!. How about initializing those fields in the struct declaration? (Then it's just one place instead of 2, and would work in other users in the future too.). Thanks, yeah, the issue is that infinite loop at the end (which has type unreachable), which was not properly handled by the inliner. By coincidence this bug was reported twice today, and there is already a fix for it in #1154 (the inlining fix there).. Merging this quickly because it fixes a serious bug that reached users a few days ago and was reported twice today (the inlining bug).. The two version numbers are actually independent. Binaryen version_37 is just a tag on binaryen, usually done when it seems stable and a good time for other projects (including emscripten) to update. The idea is to keep binaryen independent of emscripten (which is just one user of binaryen).\nIn emscripten, we update the binaryen port when a new binaryen version is tagged. This is independent of emscripten version changes.\n. I haven't thought that far ;) Open to ideas.. Got it. Then yeah, makes sense to move to 37.0.0. (And maybe someday we'll have a use for the minor numbers, if we have bugfix-only updates etc.; for now each update can change APIs.). Looks like we figured this out, closing.. Yeah, that sounds bad, we should change it. I guess cron jobs is the way to do that?. This has been fuzzed heavily and looks correct. Any concerns?. How about getUnnamedBlockOrSingleton() for getting either a singleton or a block, where the block can't be branched to so we create it without a name, and getBlockOrSingleton() for the case where we can branch to it?. Which logic do you mean is duplicated? if you mean the identical lines in getList and getBlock, it's just a few, and it's simpler that way I think. Otherwise getList could get a parameter, but it would be kind of messy to check it multiple times.\nAbout loops, yeah, the issue is that their branch is backwards. wasm no longer lets them be broken out of - they only have a top label, in other words. getBlock optionally creates a block, which is only a forwards branch. So in loops we getList, and handle the branch to the loop top directly.. I like that, nice. Updated to getBlockOrSingleton(), and the loop-specific getList logic is now inside the loop code, and that name is gone.. That's... very strange. Pass debug mode should never change behavior. It just forces single-threaded mode + extra validation. Perhaps this is because of single-threaded mode, does BINARYEN_CORES=1 cause the same odd result? If so maybe there's a threading bug.. Ok, sounds like it won't block this PR then, but can you make me a standalone testcase of the issue perhaps? I don't fully understand but it sounds like this could be a serious existing bug, so I'd like to investigate.. Thanks, and yeah, you're right, it's related to the optimization and adding order. Turns out we add those trapping functions while translating the functions, and they don't get in the queue t o be optimized. Except if we optimize at the end all together anyhow - if no multithreading - in which case they do.\nMostly we don't need to optimize these methods anyhow, but your testcase actually shows an example of where we do (inlining limit is hit or not hit based on whether we optimized). So seems worth fixing, fix in #1208.. Yeah, merge this first. We'll figure out those followups later.. To add to what @dschuff said: @jirutka, your expertise here is much appreciated, exactly because we don't know much about this ourselves. But I agree with @dschuff that your comment could be read as insulting, please let's avoid that.\n. Hmm yeah, it is rather hackish. But what's a good way to find the wasm-opt binary from inside a C++ source file?\nAlternatively, we can skip those tests if it can't find bin/wasm-opt.. cc @dschuff . I can take a look at the missing optimizer stuff for atomics.. Ok, that is enough for the optimizer to run on that testcase. Good enough for this PR I think.\nOutput looks ok to me, but I don't have a deep understanding of atomics in either asm.js or wasm ;) so I could easily have missed something.\nI haven't tried to actually run code, not sure if there is a wasm impl to test on. The binaryen interpreter doesn't have support either - not sure if we want to add that.. Hmm, on the other hand, this might actually suggest that the opcode table idea might have the same result: smaller binary but larger compressed binary.\nLooks like no objections to merging this?. lgtm, thanks!. lgtm to me too. Was there a particular reason to focus on those methods? It seems like all the pass classes (almost everything in src/passes/*.cpp) could be final too? but maybe they don't have many virtual methods.. Surprising that it's ambiguous on your compiler. Not sure why that is. Anyhow, #1182 should fix it, please confirm (since this is an issue our bots don't see).. Great, thanks for confirming.. Thanks, yeah, I think we just forgot those.\nHave you joined the wasm community group? (we need that to merge). Great, thanks!. Thanks, this looks right. Let's also add a test. You can add to one of the files in test/example, like maybe the kitchen sink test (can search for where it creates a node of this type). Then run ./auto_update_tests.py and it will update the test outputs for you.. Hmm, you can run check and auto-update with --no-test-waterfall to work around that. But it's odd it fails. @dschuff, what's the status of the waterfall - is it expected to work on non-linux platforms?\nDockerfile looks like it might be useful to check in, yeah. Is there a convention for such things, like what directory they go in, etc?\n. Thanks!\nMaybe at some point we should automate these builds in travis. It's too slow though, it more than doubles the build times.... Yes, it's invalid to use an expression twice (x, x), the IR here is a tree. So each node must have exactly one parent. The reason is that when we optimize, we might modify one, and it would be wrong to change things somewhere else. For similar reasons it's not valid to use the same expression twice in different functions.\nI opened #1191 that adds code in validate() to check this, and fix existing bugs in the code. Also some docs to better explain things.. Looks ok to me (but not my area of expertise).. Thanks!. Yeah, that looks like a good fix, we shouldn't use fallthrough that way.. Thanks, yeah, a PR would be great.. Perfect, thanks! Just waiting for CI to finish before merging.. Oh sorry, I didn't notice there were previous comments - they're hidden in the diff view.\n@dschuff, did we ever come to a consensus on that? Looking in the code most have the {,} but I don't remember details of discussion on the topic.. Heh, ok :) Anyhow, I'm not super-invested in this - if most people prefer another convention let's switch (separate from this PR of course).\nBut just for the record (since I'm not sure where else this is documented), my logic is that this is similar to the case of\nif (..) {\n  ..\n} else {\n  ..\n}\nWithout {,} there is a risk of getting things wrong, and switch cases also denote separate code paths like if arms.. Yeah, I agree. Let's just run ./auto_update_tests.py and add that change here.. Yeah, perfect. Thanks again!. cc @tlively . Yeah, it failed locally for me. I think it looks for SpiderMonkey in a hackish way, so it might not find it on your system - probably expects to see mozjs in the path or something like that (in emscripten we have a config file for such paths, but binaryen so far has no \"proper\" solution for finding things).. The emsdk should download binaries for all platforms now, I think. Make sure you are using the latest version of the emsdk. cc @juj . Yeah, those docs look out of date. The main emsdk docs are here, and they mention that you don't need to build from source. I verified now on linux, after downloading the emsdk from that link,\n./emsdk update\n./emsdk install latest\n./emsdk activate latest\nThat downloaded and set up everything, without needing to build from source.\nI also opened a PR to update those docs, https://github.com/WebAssembly/website/pull/107. Looks like no concerns here, merging.. Well, maybe if someone is sure it's valid binary that was emitted as part of a build system, maybe they would want to disable validation. Or maybe we should optimize validation speed ;) It's not even parallelized currently.. Parallelizing validation is probably worth it too since it's noticeable time in compilation, not just when reading (we validate at the end by default, currently). I'll look into it.. The error message should be improved, but this is because SIDE_MODULE, and dynamic linking more generally as well, is not fully optimized. Currently how it works requires us to disable wasm-only mode, and wasm-only mode is necessary for async compilation.\nI thought we had an issue on that, but don't see it. I'll rename this one to that issue, and add it to the dynamic linking project.. Oh, I found it, the name didn't focus on dynamic linking. Closing in favor of https://github.com/kripken/emscripten/issues/5567. Yeah, this is a little weird I guess. Binaryen does some fast validation during reading, like a wasm reader would, but most of the work is done after reading, on the IR. And we validate some internal IR details (like unreachable types being correct, node types not being stale, nodes appearing only once in the IR, etc.), so it's maybe more like LLVM's validation than wasm binary validation in that respect. And those haven't been much optimized - I think there are some places where it might not be linear. So it's both doing more work and not doing it super-efficiently ;)\nFor now, parallelizing is pretty easy to do and gives a big speedup. We should also probably give an option to not validate, like I think LLVM does.\nAnd thanks for those numbers, that's interesting. Seems like binaryen loading is in the right ballpark but still kind of slow. Btw, is all that single-threaded in wabt?\ncc @yurydelendik - @binji's wabt numbers on wasm loading might interest you as you were measuring related things I think.. What do you mean by expression folding?. I see, yeah. Makes sense that takes more work.. Merging fast since this fixes a regression that was just caused.. Re-worked after the landing of #1168. This adds a small api to get the list of added helper trapping functions, and uses that to optimize them.. I guess another option is to use consts and not enums? Anyhow, I don't think it's too bad to do the cast given this API is small and not used everywhere.. Thanks @binji, that does look nicer. I updated it that way.. I don't think we do that now, but I'm not sure we won't want to later, hmm.. Anyhow, I think this is good to land. Not too worried about silent weirdness, we should get a noticeable error if we get that wrong, the logic should be different enough.. Looks like no concerns, merging.. These are global constructor functions, called during startup, yeah. Sounds like the name contains an illegal character, and either the wasm backend or s2wasm doesn't handle that properly? The wasm backend should emit it in a way that is legal in wasm, so probably that's the culprit. Can you provide a testcase (source or bitcode file and full steps to reproduce)?. Thanks. Yeah, this looks like a bug in the wasm backend, so when you can please open a bug there. I verified this works ok with emcc without the wasm backend.. Merging as this blocks other stuff. Feedback still welcome of course.. Is line 288 in pass.cpp the second line of this?\nfor (auto* pass : passes) {\n      if (pass->isFunctionParallel()) { // line 288 on master\n        stack.push_back(pass);\n      } else {\n        flush();\n        pass->run(this, wasm);\n      }\n    }\nVery strange how that could be an invalid pointer.\nAs for the move, it should be valid - the last element is not copied, the range is [first, last) (i.e. does not include the last), http://en.cppreference.com/w/cpp/algorithm/move\nSo in both cases I'm puzzled. Maybe memory corruption somehow? Does VS have something like valgrind perhaps?. valgrind is a linux tool that can detect memory corruptions of various forms. I thought I heard msvc had some memory corruption checks of its own.\nWe've received no other reports of complete breakage on windows, so perhaps this is a recent regression? Might be worth looking further back in the tags til you find one that works, then bisect.. Interesting stuff. Do you want to submit PRs with these fixes, and we can discuss in more detail in those?. Thanks, please open a PR for the move issue. You should join the community group before we merge it.\nGood point about the passRunner issue. Maybe we should change the API there. I can look into that one.. I opened #1234 for the PassRunner issue.\nSide note, it would be good if we found a way to run tests on windows too. Right now our CI only checks that it builds.. Thanks, added to that PR.. Yes.. I don't see an error on current master.\nIf you still see this, maybe find the stack trace in a debugger in a debug build, it could show something interesting.. Which commit is that on master? (local master might be out of date)\nThat line (if (i >= list().size()) looks innocuous. But then maybe the debugger is getting the line wrong.\nDo the core tests pass? ./check.py. Strange. So, that error is in s-expression parsing code, but you are feeding it a binary. Which makes me realize I've tested on a binary I made from that s-expr you provided. So we've tested different things.\nMy guess is that binary you are sending has invalid characters in the first few bytes, so it doens't recognize it as a wasm binary. Then it tries to read it as text, and that fails on that exception. How was that binary created?. Ok, now I see. Looks like wasm2asm only supports s-expression input, and errors on binaries.\nIt's not as simple as just making it accept binary inputs too, that part is easy, the problem is that it assumes the input is text so that it can look for text format assertions and other things. I guess we use that for testing. Maybe we can remove it though?. Oh yeah, we aren't printing the errors, missing the try-catch in wasm2asm. Fix in #1251.\nHow was that text file generated exactly? From clang somehow? It looks invalid, in particular\n(func $main (type 0) (result i32)\n    i32.const 0)\nThat is missing an open paren.\n. Thanks @binji. Ok, that's a known limitation then (we'd like to add a flat text parser in binaryen, but I don't think anyone is focused on that).. Fair point. On the other hand ;; N is a little shorter. I'm ok with either though.. Looks like no strong feelings either way, so let's do it the way wabt does. Consistency is nice.. Thanks, looks good.\nHave you joined the wasm community group?. Great!. Thanks, I can confirm something has gone bad here. I'll investigate.. Fix in #1237.. Fixed by that merged PR.. For some reason flake8 is now showing errors it didn't before (on stuff not changed by this PR). Very strange. I pushed what I think is a fix, but does anyone know why it flake8 would suddenly check more things?. I don't know what's going on with this PR... now the windows machines are showing an error on unchanged code, as if they also just changed to new settings...\nWorse, this doesn't makes sense. It says first may be used initialized, but it's a parameter :-o\ntemplate<typename T, typename... Args>\n  T pickGivenNum(size_t num, T first, Args... args) {\n    if (num == 0) return first;\n    return pickGivenNum<T>(num - 1, args...);\n  }\nC:/projects/binaryen/src/tools/translate-to-fuzz.h: In member function 'wasm::Expression* wasm::TranslateToFuzzReader::makeConst(wasm::WasmType)':\nC:/projects/binaryen/src/tools/translate-to-fuzz.h:1267:5: error: 'first' may be used uninitialized in this function [-Werror=maybe-uninitialized]\n   T pickGivenNum(size_t num, T first, Args... args) {\n     ^~~~~~~~~~~~\n[ 79%] Linking CXX executable bin/wasm-shell.exe\ncc1plus.exe: all warnings being treated as errors. Yeah, gcc on appveyor bot has upgraded from 6.3 to 7.2.\nCould be a gcc bug. I don't see anything in the tracker that looks similar, though :(. Anyhow, there's a better PR for the python stuff, #1239, and I'll look into the new gcc failure separately as well. Merging this PR which is unrelated to those two new failures, and which fixes existing breakage.. Tracking it back through all the callers I don't see anything uninitialized anywhere that could feed into that param. In fact we always pass a constant into it, not even a variable. Very odd.... The only special thing I can see is that makeConst provides a template param, pick<float>(..) instead of all the other places which don't. I pushed a branch to test that theory.. This should now be worked around on master. But leaving this open since we don't understand this bug yet, and it would be good to see if it's something we should file for the compiler. If someone has a windows machine and some time, please see if you can reproduce this.. I gave this another shot and I did manage to reproduce it on my local machine. I reduced it and filed it for gcc: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82800\nClosing as we are not hit by the bug and it's been reported. If it returns (not sure exactly how we worked around it) we can reopen.. Thanks, added, and verified it works.. The CI failures here are the known issues currently being fixed, merging.. Alternatively, maybe it's ok to have it update to new versions, and we'll get further improvements enforced? The fixing is fairly simple each time. I could go either way on this.. Ok, lgtm. Before merging though please merge in latest master to here to see that things pass, as we just merged flake8 fixes (so there's some risk of collision, probably very small though).. Note that s2wasm will be deprecated eventually, as the llvm wasm backend will eventually emit a binary directly. But still worth fixing issues of course.\nDo you have a testcase showing the problem here that we could add to the test suite?. Merging this since it changes non-sensitive code (fuzzing support) and fixes live breakage on master.. Thanks for the quick responses here.. Any thoughts on if we should show this warning about big functions?. Probably a bug in llvm or s2wasm, but maybe the bigger issue is that the plan is to avoid the .s format entirely, so llvm would emit a wasm and binaryen's s2wasm wouldn't be needed.\nThere's been working ongoing towards that, but I'm not sure how close it is - @sbc100 @dschuff ? If it's not far, probably makes sense to wait for that and not fix .s bugs.. What do you think about adding a new API call alongside BinaryenModuleOptimize, something like BinaryenModuleRunPasses which receives a pass or passes to run? This both keeps backwards compatibility and also not all passes are optimization passes (although we do refer to them that way sometimes, but I feel that makes more sense internally than in an official API).. Great, thanks!\n. Hmm, I find this quite useful myself as a developer :) How else would you print out the erroring module? If you add --print after the pass that breaks it, it won't reach the print?\nBut if this is annoying it could be optional.  Perhaps one of the current debug env vars (BINARYEN_PASS_DEBUG, BINARYEN_PRINT_FULL) could cover it, or we could add another.. I see, I was thinking more form the point of view of a commandline tool. Yeah, I agree we should do it the way you propose, by making printing the module optional, and we should make it print the module in the commandline tools like wasm-opt, so the user of those tools doesn't see a change from this PR (while people making their own tools using the C API can choose to print the module or not).. (About env vars and js, emscripten does support getenv, but it isn't hooked up to the actual system env. But in node.js someone could in theory do that.). Overall this looks like the right direction, but the CI errors show that we are printing the module when testing spec/func_ptrs.wast, which suggests it doesn't validate? But that can't be since the test passes. I'd run it locally to see more (maybe there is stderr output that travis is hiding).. Yeah, that's odd - it seems like it should have been printed before too. Anyhow, your fix is the right one, in wasm-shell we actually don't want to print it, it has tests that are supposed to fail, without printing.. Thanks! Although I think by coincidence this may have gotten fixed anyhow through another PR that was just merged (that added a new API for running passes in binaryen.js). On current master do things look ok to you?. Running with EMCC_DEBUG=1 in the env should show more info, including the command that fails.. Does the asm2wasm executable exist at that path there? (Also, are the slashes+reverse slashes ok on windows?)\n. Looks like the parse error on that wast is because the table is defined after the function that depends on it. Perhaps we should make the s-parser look ahead for the table definition, but it currently doesn't.\nYeah, wasm and asm.js semantics are different for indirect calls, so it's not trivial to connect them. One way would be to replace call_indirect with a call to a helper function that picks the right asm.js table based on the index being used. Another option is to standardize on N arguments of type double, and convert to that for all indirect calls (so just one asm.js table). Maybe a better option but I don't see one right now.\nBtw, what are you doing here, for context?. > Is that actual Asm.js semantics or Emscripten semantics that can be thrown away?\nActual asm.js. In asm.js each table has a specific function type. So one table for void (int, float) functions, etc. etc. All the functions in that table have that type, and all calls to that table provide the right types in the arguments. Whereas in wasm, a table can contain a mix of function types, and each call defines the argument types, which are checked at runtime if they match the function that is called from the table.\nSo the difficulty here is to create multiple asm.js tables from a single wasm table.\n. This fixes current breakage, so merging quickly.. This found a few issues so it seems useful, and looks like no concerns, merging.. I'll land this since we have various PRs in flight that could benefit from this additional testing.. I'll take that \\o/ as an lgtm. I tried to compile just that function (replacing gpointer with void*, and adding code to keep that function alive) but I don't see an error, with that command.\nCan you provide the full files necessary to reproduce this crash? The intermediate .asm.js or bitcode file for example.. Very odd about the wasm error message - the validator should emit a complete message. In fact there is a PR that shortens it since it was too long ;) So something is going wrong on your file somehow. Perhaps are you just viewing stdout or stderr and not both, and we emit to the other? If that's not it, can you provide the wasm file, to reproduce the problem?\nIs the wast parsing error looks correct (duplicate import)? If not, please provide the wast too. Note btw that the errors you see on wast and wasm files may differ, as how they are parsed is not identical - wasts are parsed in multiple passes, in particular. So what is a validation error may be a parse error in the other, but ignoring that, what is invalid in one should be invalid in the other, and only then.\nImports are not actually imported when we scan for errors, so it shouldn't matter which files are in your directory - it won't look for Kremlin.wasm when it checks that module.. Thanks for the files. Yeah, both cases look like they are bugs, I'll investigate.. 1. The wast text error is because binaryen's text format assumes all imports share a single namespace. So an imported memory and global with the same name causes a collision. This might be a place where we diverge from the official text format, so it's worth investigating more and perhaps fixing. But we already diverge so much on the text format that this is low priority (that is, we don't claim to have a compatible text format).\n2. The wasm binary error is a serious bug, a type of stack-based code that we didn't handle. Details and fix in #1267. After that PR, we can read the wasm without error, and optimization also works fine, e.g. -Os shrinks the file to around half the original size.\nBtw, what compiler was used to generate these? I don't think I'm familiar with it.. Very interesting, thanks for the info!\nI'm curious about the Low => wasm path that you're adding: since you already had Low => C, and could do C => wasm, what are the main reasons for adding the \"bypass\" route directly to wasm?\nAnother question, looking in the code, I saw the AstToWasm file, which looked like it has most of the compilation logic, but I couldn't figure out how it does the final part, if it compiles to a wasm binary or text?\nAbout data_start, that sounds good, I don't think there's a better way - if each module has its own constant data, then they can receive an imported integer of where to place it, and inform how much space they used etc., and the loader coordinates all that so nothing collides. That's basically how dynamic linking for C/C++ etc. works.\nLet me know if there's more stuff we can help with on the wasm side for this.\n. Makes sense, thanks for the info. Yeah, I think those are reasons we'll see more compilers take a similar path too (although the code size issue may be addressed by emscripten's wasm-standalone path eventually; still, even then if you write your own compiler you can of course do better).\nAbout avoiding optimizations, I guess you'd also avoid running the binaryen optimizer (or another wasm => wasm optimizer) then? Or is there a chance you'd run a subset of those optimizations? I'm not sure how much code size and speed are the focus for you, but I ask because it's a goal for the binaryen optimizer to help a variety of compilers (not just LLVM output).\n\nThe wasm binary / wast generation is done using https://github.com/WebAssembly/spec -- I directly reuse Andreas' library which is also written in OCaml. No extra work for me!\n\nOh, nice :) Heh, I did have a feeling the AST style looked familiar, I should have recognized the spec stuff, and I should have guessed based on the language the compiler's written in too... ;). @prosecco \n\nWhen we compile our code directly from F* to WASM we end up with a 20K file. An emscripten compiled version of Curve25519, as used by Signal Desktop, for example, is over 200KB.\n\nInteresting, I assume that is emscripten normally, not in wasm-standalone mode, i.e., without -s SIDE_MODULE=1? I'd be curious to see a comparison with that flag too, if it's not too much trouble. You would need to write your own js loading code in that case, but the compiled output should only contain your own code, in which case I'd expect it to be smaller than even the F* to wasm's 20K, because it shouldn't have extraneous code, and it has been optimized for size by LLVM and binaryen. (On the other hand, those optimizations might increase code size too, but in -Os or -Oz mode they shouldn't.)\nOf course maybe you don't want to go that route for the other good reasons mentioned. I'm just curious if there is something we could do better for code size that we aren't doing already, in that mode.. That error is from clang, so you will probably see the same error when you use clang to build natively (without emscripten/binaryen). I don't know if it's a bug or not in clang, though.. I believe @dschuff added that because in the wasm spec atomics are unsigned. So we should fix what is generating a signed atomic operation, do you have a testcase?. Yeah, I think what we have now is good. And we do have code that sign-extends as necessary - although not using the new instructions, they do it manually. So the question is in what code path do we not do that, leading to this bug - need a testcase.. What branches are you on? On heapu64 in binaryen and threads-hack in emscripten (+ the 2 line patch in the PR in my last comment), I don't see a failure here.\nOr, maybe can you just provide the .asm.js that fails, + asm2wasm command?. If you've got that already set up, can you provide just the .asm.js file that shows the problem? Or if you need to set it all up from scratch, I can do it.. I got it set up and can reproduce, investigating now.. Bug was that the optimizer sometimes wants to change loads to signed (if it can remove code that way). Fix added to https://github.com/WebAssembly/binaryen/pull/1262. Ok, let's close this then and focus on that other PR.. I don't object, but I also don't fully understand the value of the checked in .s torture tests currently. I assume they'd go away with s2wasm eventually anyhow? Anyhow, as I said, if has value for now, sounds ok to me.. Yeah, the binaryen.js tests weren't run on the bots. I've been working towards that. I just opened #1275 which enables them.. This looks good to land, except for the conflict.. Btw, @dcodeIO, if you haven't seen https://github.com/WebAssembly/host-bindings already then you might be interested in that (maybe relevant to AssemblyScript etc.).. I think the underlying issue here is that wasm is limited in what can be used to decide where to place a segment - that offset can only be a constant, or a get_global. If it could receive an add of a constant and a global, then we could optimize out those zeros.\nUntil wasm adds that, though, the zeros are annoying but they do almost vanish when gzipping, so it's not too bad, I think?. Yes, I think you're right - what we should do is merge the dylink sections of the merged modules. We'd need to handle the case of just one having it, or both. And then we can avoid the zeros.. Yeah, we should probably focus on using references where possible, for those reasons. Makes sense to rename to BinaryenRemoveExportByName as you suggest, too. And modules should provide getFunction which receives a name and returns a reference (I don't think it needs to be getFunctionByName, as there isn't another way to get a function from the module?)\nWe can't always, though, as the IR intentionally is designed to use names in specific places, like when creating functions in parallel - if a calls b and b calls a, and we build them in parallel, we don't have refs to give each other (nor do we have an index, we don't know which index they will have), so we must use names there. So creating a call instruction will receive a name.\nBut otherwise, whenever possible we should use references.. This mostly looks good, but the export parts and the issues you mentioned in the last comment made me read the existing code more carefully, and we have a pre-existing problem, where BinaryenAddExport doesn't receive the kind, and doesn't set a kind on the export it creates. I think that might be because we added it before the ExternalKind stuff was added...\nAnyhow, instead of adding new export code here, could we add a kind to the current export, which would allow exporting the memory?. Memories and tables are singletons for now, but they do have an internal name - really just used for printing, though. So I think it's ok to receive a name parameter for them.. Yeah, I see what you mean. So maybe AddFunctionImport, AddGlobalImport etc. is indeed nicer.. Thanks, yeah, this is good stuff to add. binaryen.js + tests would also be great.. Build looks ok, merging.\nTo recreate the .txt files, you can run ./auto_update_tests.py. Very odd. The auto update script is pretty simple, just runs the commands and saves the output, so not sure how something could go wrong.. lgtm but looks like the spec tests we run need to be updated too.. @dschuff: Well, we sort of gave up on updating them since wasm became a stack machine and things diverged. We definitely can't support a bunch of things in the upstream tests. And we don't claim to support the upstream text format at this point.\nBut the spec tests have been updated with various specific changes, current commit looks like it's from August 27 2017. So we might want to do that for this change.\nAlternatively, do we need to update this, since we still won't be able to support the full upstream text format anyhow?. I believe wasm doesn't have a way to provide names for imports in the binary format, see \"Name Section\" here: http://webassembly.org/docs/binary-encoding/ - it only supports names for modules, functions, and locals, but not imports.. Oh, thanks. Then this is indeed a bug we should fix.. Fix in #1290 . Fixed by that PR.. Good idea, thanks.\nSorry, I already merged one of those 2 PRs since I didn't read this one til later. Would you prefer to merge this in before the remaining one?\nBtw, this will also be useful when we need to use that list more than once, which will be the case when we have a binaryen.wasm.js (binaryen.js but compiled code is wasm) which I've been planning to add, since even node.js LTS now has wasm support.. Why not just run the precompute pass on the whole module? Is there a reason to do it on individual expressions?. I see. One way could be, in JS, to create a module (empty except you would want the global imports), add just that expression in a function, and run the pass on that, then get that function body. We should make doing stuff like that easy anyhow from JS, I think, so this could be a good way to verify that.. I don't see why not, can you elaborate? (Or do you mean you'd need to loop, continuing to work while something is reduced? Yes, that would be necessary.). I see, thanks @rossberg and @jgravelle-google . Multiple memories are pretty far out, there's no roadmap for them that I am aware of. I'd say we can just document this as a current limitation.. Heh, my guess was \"Not For Continuous Integration\" ;) Actual meaning actually makes sense.... API-wise, I think this might make sense, but as in the previous discussion, I think there are competing API concerns. On the one hand a more minimal API is better, and adding a piece of a specific optimization suggests we may want to add many more. (For comparison, I don't think the LLVM C API provides stuff like this.) But on the other hand, maybe this is a common-enough operation, I'm not sure.\nIf we generalize this I'd be a lot more confident. We currently have a way to optimize a module, and maybe we should have a way to optimize an expression by itself, something like\n// Run optimization passes on an expression by itself (only things\n// we can optimize without the context of the module or function).\nvoid BinaryenExpressionOptimize(BinaryenModuleRef module);\nThat would include precompute and a few other passes that are truly independent of the module and the function (like optimize-instructions). Would that work for your use case?. How about adding a new function for this, BinaryenFunctionRunPasses? (I don't care about breaking backwards compatibility on this, but it seems cleaner to me.)\nBtw, is this enough for your use case of optimizing just an expression? We can add that too, but it requires work inside binaryen to add it first. I can do that if you want.. Also would be nice to add BinaryenFunctionOptimize to parallel BinaryenModuleOptimize (i.e., run the default opt passes on a function). Can leave it to later too.. It's true the implementation is almost the same since the function version needs the module anyhow, good point. Maybe internally they can use a shared helper function. For the external API, that's a good question about those options. I guess it depends on whether we expect to have more BinaryenFunction* methods. I suspect yes (get params, change result, etc.). So I am leaning to BinaryenFunctionRunPasses, taking the module as the final param (like RelooperRenderAndDispose).\nAbout the second paragraph, I think that's a general enough thing that I'd like a binaryen utility for it. It should also handle locals etc. properly, so it's not as simple as your use case, but feasible. If that makes sense I can do that later today (unless you want to).. About the general optimize-an-expression thing, as I was writing it I realized it can't be efficient, at least if it tries to handle the general case (you need to do a bunch of copying and scanning, stuff you don't need when you optimize a whole function). So I'm starting to think it's not worth it. Do you have enough for your use case without it?\nAbout the C and JS APIs, I think it's best to let each make sense on its own, they don't need to be a perfect parallel. As you said in the past, we may have other APIs built on top of the C API eventually anyhow.. Merging for those test fixes (and generally there is little interest to review these optimizer changes - let me know if that changes).. I saw that too with recent gcc, and filed an upstream bug.\nIt's tricky to work around, I didn't find a way, except from using older gcc, or clang.. It has an integer type, though, so comparing to a null pointer isn't valid. But if you have time, just trying a bunch of stuff might find something - I gave up eventually, but I might have missed it.. Yeah, it can be 0. It also can't be uninitialized - it's some weird internal bug in gcc, it gets confused by too many templates I guess...\nGood point about the flag. The CMakeLists.txt file is the right place - we should add it, but it should only be for gcc in the versions we know have this bug, and with a TODO to remove it once they fix it. Would be great if you can make a PR with that.. Fair point, maybe we should build by default without it, but then we'd need to test on the bots both with and without it, which is double the time.. Hmm, one remaining topic mentioned above is whether we should built with -Werror or not. Perhaps it should be on for testing, but not on by default for users? Or perhaps it's better to see errors even there and get reports on them?. Makes sense, thanks.. As suggested by @binji in https://github.com/WebAssembly/binaryen/issues/1300#issuecomment-345843868 , turns out there are ways to change this warning for a single file in the source code - that seems optimal.. Great, thanks!. This should be added eventually, yeah, would be great if you want to do it. The relocations stuff is just getting stable now in LLVM, lld, etc., so it made sense to wait for that. But now is a good time.\nWe probably don't want to reimplement full linking in binaryen, but it would probably be useful to support loading/saving relocations. What use case did you have in mind?. Yes, that's what binaryen.js is (in the bin/folder). Some examples of using it in JS appear in tests/binaryen.js.. (That's compiled to asm.js currently, but compiling to wasm would be just changing a flag.). Makes sense to do this. However, wasm switches can only support comparing something to a constant, so only the get_local part could be generalized. (Maybe the eq too, to support ranges?)\nThis might actually already work if you run the rereloop pass, as it reduces to a CFG and recreates control flow. However, I believe the relooper doesn't convert to a switch, only from it, currently. We'd need to investigate if it's better to improve that or to directly match the pattern you wrote.. What is $case_value? Is it (get_local $case-value)? If it's not a constant, it can't be in a br_table, it just has a list of indexes and where to jump to. If the common case isn't a constant, this can't be optimized.\nIn theory nonconstant ones can be optimized by doing some math at runtime, but you don't know the range of the values, so I don't see how.. Oh ok, now I see, thanks. Makes sense.\nPretty simple optimization, I think, I'll get to this later today.. Yes, thanks @jakirkham . I don't think there is a single \"proper\" route, this stuff is still being figured out :) Some options:\nIn general, if your language uses LLVM, you can use the LLVM wasm backend directly to emit wasm for you. Things are still a little unstable there - LLVM+lld are moving to use wasm as object files, see here but that's not 100% done yet. You will need to make various decisions about what to include for your runtime, standard library, create your own JS code to load the wasm, etc. Rust and other languages are in the process of figuring all that out, it's interesting to see how their experiments will go.\nAnother option is to use emscripten (which can wrap around the LLVM wasm backend). That will link in libc and other runtime things for you automatically, generate JS for you, provide WebGL and other web API wrappers, etc. But it's optimized for C and C++, and other languages might want different things (e.g., maybe you don't need the malloc it will automatically provide). We are working to improve that, but C and C++ have been our focus in the past. For a language with needs very similar to C and C++, this could be a good option.\nFinally, some languages are emitting wasm directly, like Go, F, AssemblyScript, Cheerp, etc. You can use various techniques there: write your own wasm emiting code (Go, Cheerp), use a library like the wasm spec interpreter (F) or binaryen (AssemblyScript) etc.\n. There are several separate issues with GC. In the future, wasm will support GC objects directly, so it will integrate with the JS GC.\nBut meanwhile, you can ship your own GC implementation as part of your language runtime. Unity does that for C#, for example, and that's what happens when you run the compiled Lua or Python VMs, etc. A Boehm-style GC should just work, the only tricky thing being roots on the stack.\nSo if you already have your own GC in your runtime, all you need to do to try this is to create an LLVM bitcode file (containing your compiled program + GC and other runtime) and just pass that to emcc. It'll compile the bitcode to wasm+JS.. @ylluminate: yes, emscripten (and the asm.js and wasm backends in LLVM) consider C-like languages, not languages with native GC types (at least for now). But, the GC runtimes for those languages are typically written in C, so you can compile those and use them. That's very different than Opal and GWT and others that compile to JS with GC objects, yes.\n@RX14: For stack roots, one option is to only collect in between browser frames - they need to be short anyhow, as its an event/callback model. And if you call the GC in between frames, when there is nothing on the stack, then you are safe.\nAlternatively, if that's not an option (like a very long computation running in a web worker), a compiler would need to mark the stack manually. In C++ you could use an RAII class for pointers instead of raw pointers, where it writes to memory, etc. Or I've seen cases where the code was compiler-generated anyhow, so they just made the compiler emit writes to memory for stack values. It's probably possible to modify LLVM to do this, I think I heard of someone experimenting with that.\n. I see. Yes, if you always have things on the stack, then you need to manage the stack in a special way. One option is what Go is doing, to manage their entire call stack in linear memory. That's going to add overhead.\nAlternatively, if you have a way to just manage pointers on the stack, that could be efficient, like the RAII option mentioned before.\n. There has been some theoretical discussion of stuff like that (switching stacks, inspecting the stack, etc.), I think motivated by Go for example. But I don't think there's been anything recent. Which I guess is why Go is doing things the way it is. I would guess that if Go doesn't end up with good enough performance, that could motivate adding support for this.. > It's probably possible to modify LLVM to do this [make sure values on the stack are in linear memory, so they can be scanned by a Boehm-style GC]\nWe could do this in binaryen too, I realized. Basically a pass that ensures all i32s are spilled to a linear memory location. Then Boehm GCing would just work.\nLet me know if there's interest in such a pass, should be easy to write.. Yes, current wasm is 32-bit. There are plans for a future wasm64.. What process do you mean? Reading the end of this issue, looks like I proposed writing that stack spilling pass, but it sounded like there wasn't interest from @RX14 to use it?. @ylluminate: ok, let me know if someone's interested to work on this. I'd be happy to help out on the binaryen/emscripten side, with that pass or other stuff.. @ylluminate looks like @juj states the core stack-walking issue there, which is what I think we can experiment with working around using a binaryen pass to manually spill the stack.\nI'm not sure about the runtime errors that are mentioned there. Those are from several months ago, perhaps it's worth trying again now.. @ylluminate Ok, great. I wrote that pass in #1339, should be good enough to experiment with. Let me know how it goes and if I can help.. Good questions. In the end it really depends on what the Crystal community wants from Crystal-on-the-Web.\nFirst, DOM access isn't important in many cases, for example, most Rust-on-the-Web use cases I've seen. People use Rust there so they can write computational code in a language they prefer over JS, and it runs faster. Then they call out to JS and do DOM stuff there if they need that, but often they just create a library from that Rust and then call it from JS to do computation, so the DOM never comes up. I haven't used Crystal much, but from what I see of the language, it should work very well that way.\nIf you do want DOM access as a core feature, emscripten does give you a few ways to make it easy. You can use EM_ASM blocks (would need work on the Crystal side) or JS libraries (would just work) to make it simple to call into JS. Using those and the emscripten runtime support, you can build a DOM access library in Crystal (Emscripten does this for C++ in the embind and WebIDL binder features, for example). The main problem there is you can't collect cycles between the two worlds yet, but otherwise it can work very well.\nIn the farther future, wasm may be able to access the DOM directly. That will likely take years to be designed and rolled out to browsers. Meanwhile, if you implement a DOM library today as in the previous paragraph, you could use the new DOM capabilities as an optimization when they do arrive - they would solve cycles, and would make things faster.. > The main problem there is you can't collect cycles between the two worlds yet, but otherwise it can work very well.\nOverall the issue is JS has a GC, and wasm can have a GC if you use Boehm, but no single GC can see it all. You can only connect the two manually. So cycles of a wasm object using a JS object and that JS object using that wasm object can't be cleaned up (without manually breaking the cycle).\nIn more detail, wasm doesn't have direct access to the JS object world, so if you want wasm to do something to a JS object, you need something like this:\n\nIn JS, a map of integer IDs to JS objects.\nIn wasm, you use the integer IDs (since it can handle integers ok)\nWhen you want wasm to be able to refer to an object, you create an ID for it and put it in that JS map.\nWhen wasm calls JS, it gives the integer to JS. JS looks up the object in the JS map, and can then manipulate it.\n\nSo you must manually \"bind\" an object to an integer ID, and the problem is that you must also \"unbind\" manually as well: as long as the object is in that map, it won't be JS GC'd (unless the entire map can be GC'd).\nYou can do GC using Boehm in the compiled code, and maybe the finalizer for an object can call JS to unbind the integer ID for it. But this does leave the issue of cycles through both compiled code and JS, there is a separate GC for each, and a manual interface for connecting them. That's going to be a problem until wasm gets GC support, probably.\nBtw, do those frameworks need to directly call into the DOM? In Ember for example, they are adding Rust/wasm just for the core VM component there, which doesn't need direct DOM access, as I understand it.. There is a reference types proposal for wasm now, with initial experimental impls in VMs - enough to start experimenting with some DOM interaction, but still far from full GC. See a discussion about using that in AssemblyScript here: https://github.com/AssemblyScript/assemblyscript/issues/89. This PR also includes a fix for a missing finalize on a makeBlock variant, that this happened to uncover.. Looks like no concerns with this new optimization, landing.. Yes, I think none of the commandline tools here support piping in content from stdin. I'm not sure how to implement that in a cross-platform way myself, but hopefully someone can figure it out, would be good to fix this.. That would be great!\nFor the relevant code, look e.g. at src/tools/wasm-opt.cpp, where it does add_positional(\"INFILE\". That's where we prepare to receive the input file as a positional argument (i.e. an argument that has no prefix before it, it's just the filename itself). Somehow we'd need to find a nice way to say that if that isn't specified, then we read it from stdin. If we need support code for that, it could be in src/support/file* perhaps.. I'm not sure. But don't most tools read stdin even without the -, they somehow detect that there is info in stdin and they read it? I honestly have no idea how these things work :). 1: Yes, something like BinaryenModuleAddDebugInfoFilename (with a better name) could return BinaryenFileRef could be the index in Module::debugInfoFileNames.\n2 and 3: I think what you want here is something like BinaryenFunctionAddDebugInfoLocation(Expression*, file#, line#, col#) (again, need better name) which adds to Function::debugLocations. So you'd create the expression first normally, then call this to add the debug info metadata onto that expression.\n4: The names section and/or source map are user sections in the wasm itself, so we could have a variant of BinaryenModuleWrite, BinaryenModuleWriteWithSourceMap which calls setSourceMap. There are some details with the URL there that I don't fully understand, though, but we can ask the author of the code if necessary (yurydelendik).. On 2: debug info can only be added to expressions (function code), so far (and not imports, exports, and other global entities).. We should check if there is a spec test for this. If there isn't, we should add one upstream. If there is and we are missing it because our spec tests are too old, we may need to update them, or add testing for this in another way.. Thanks for the testcases, fix for those two is in #1347\n. Yes, because currently wasm has no stack aside from int/float locals, binaryen doesn't have any explicit C-like stack support yet. So no way to alloca X bytes, etc. That leaves the C-like stack to the program itself to handle, binaryen isn't aware of it. The program itself can use a region of linear memory for the C-like stack, managing the stack pointer as necessary, etc.\nBut I've been thinking we should probably add this at some point, since some optimizations can benefit from it. We use a specific global for the stack pointer, but I think the asm2wasm and wasm backend paths actually give it a different name, so probably we should standardize that. Once that's settled, we can add utilities to binaryen to find stack usage, add allocas, etc. (I'm not sure we'd want to actually add a new alloca to binaryen IR, it could just emit reads/writes to that global, as one option.)\nOne reason I've been thinking of this recently is https://github.com/WebAssembly/binaryen/issues/1312#issuecomment-348409211 where a pass to write locals to the stack was proposed (to support conservative GC, that needs to scan the stack). To make it efficient, we'd probably want to write those locals to the stack, and we'd want a dead store elimination pass that is aware of what stores are to the stack (so that it can eliminate stores not only when something else overwrites them, but also when they are to the stack which is about to be unwound).. Also in this PR: an indentation fix for the help tools show (this tool has a large multi-paragraph comment in its help, to explain the input format, and we didn't handle paragraphs right), and a limited JSON parser (for the input graph format).. Merging, as no concerns with this new tool, and this is necessary for next steps in JS shrinking in emscripten.. Related to #1317, either the spec is missing tests for these things, or we are out of date. So as in that issue, if there isn't one upstream, we should add one. And if there is and we are missing it because our spec tests are too old, we may need to update them, or add testing for this in another way.. cc @dcodeIO . This was disallowed earlier in the wasm spec process, right? I think we just left it that way here. Anyhow, worth fixing.. Or maybe I'm thinking about allowing/disallowing imported functions in tables.. Possible fix in #1326. With these fixes, all the emscripten test suite I've tested appears to pass.. Interesting. I agree we should optimize that use case, however, adding function flags is something I've hoped we can avoid. If we do want to add them, it would be a large effort - they'd need some sort of text format representation, and maybe even binary format as well (which would need to be coordinated either with the wasm tool-conventions project, or force us to really fork the binary format, as has been discussed in the past).\nWhy don't those functions get inlined already? Perhaps we just need to tweak the heuristics? If it's not that simple, we could add a variant pass, InlineAggressively perhaps, which inlines a lot more and focuses on this use case. (If we can't manage that, I think we can look at more radical options like adding flags.)\nMaybe you can provide the wast of that example, for investigation?. > Are you interested in issues like this one? \nDefinitely, yes :) Thanks for filing!\nSo looking at\n(module\n (memory $0 0)\n (export \"test\" (func $test))\n (func $test (param $7 i32) (param $2 i32) (param $4 i32) (result i32)\n  (if (result i32)\n   (tee_local $7\n    (get_local $2)\n   )\n   (i32.rem_s\n    (get_local $4)\n    (i32.const 4)\n   )\n   (get_local $7)\n  )\n )\n)\nThe issue is that the tee_local is \"in the way\" of optimizing it, and -O has no effect. But we can solve that with --flatten --ssa, those flatten out things like tee_local (into sets on a block), and ensure each use has a different name. That's then much more similar to what LLVM would emit. And running --flatten --ssa -O, we get\n(if\n   (get_local $1)\n   (set_local $1\n    (i32.rem_s\n     (get_local $2)\n     (i32.const 4)\n    )\n   )\n  )\n  (get_local $1)\nwhich has indeed managed to remove the tee.\nWe don't run --flatten or --ssa by default, because they enlarge the IR quite a lot, and it's not necessary on what LLVM gives us anyhow. But perhaps we should, at least in -O3 or -Oz? Anyhow, it might make sense for your compiler to run those passes before the main optimizations.. Hmm, that looks wrong, yeah. The order does matter, you must run --flatten --ssa before the normal optimizations. Does your runPasses queue them for later, perhaps? Or maybe somethings going wrong with running them just on the current function, and they apply to the module? Can check in the shell that wasm-opt --flatten --ssa -O does what is expected (if not, that could be a serious bug).\n. That looks correct, so this might be a bug. Do you also see this problem in the shell using wasm-opt? Can you provide the wast file?\n. Thanks, now I see. While in the tiny testcase those passes work, in the full file, ssa has some issues that make it cause those nested tees. That'll need to be optimized (ssa is still experimental), I think it's causing too many long overlapping lifetimes, and we don't currently break those up.\nBut looking at this more closely, perhaps we should optimize it better directly. It looks like coalesce-locals does a poor job on\n(if (result i32)\n      (tee_local $7\n       (get_local $2)\n      )\n      (i32.rem_s\n       (get_local $4)\n       (i32.const 4)\n      )\n      (get_local $7)\n     )\n     [ $7 is never used again, $2 is ]\nIt thinks $7 and $2 can't be merged because their lifetimes overlap, which is technically true, but not actually a problem since on the overlap their values are identical. This definitely seems like something we should optimize. It doesn't seem super-easy, though, we'd need to track values in that pass, and not just lifetimes. An alternative might be to add a pass for this specific thing, which would run before coalesce-locals.. What tracing issue did you hit with BinaryenExpressionClone? I think we'll want that eventually anyhow.. IIUC, the API here has getLoad, getBinary etc., and you need to call it with the right one? How about a single method, getInfo (or some better name), which receives a node of any kind and returns the JSON metadata for it (internally it would get the node id and use that)?. Looks great, thanks!\nAnything left to discuss here before merging?\nOne followup idea I have is to add another field to the JSON infos, that gives their class in JS, so if you get a block's info, you get\n{\n  what: 'block',\n  id: ..\n}\nMaybe what isn't a great name, but seems like this could make looking at the JSON more convenient? Anyhow, something to think about separate from this PR.. Yeah, that makes sense too. I guess it depends on if we want JSON.stringify of these info objects to be self-explanatory, or require the enum lookups. I'm not sure myself.\nAnyhow, let's merge this in, and keep thinking about the other stuff.. Good point, the type field should be handled the same way.\nNot sure what's best for those two fields. Minimal JSON makes sense for efficiency, I suspect, although maybe it doesn't matter much since the strings are going to be internalized anyhow, so they have the same overhead as an integer. And on the other hand, richer JSON, with full string names, seems nicer for people just getting started and for debugging.. Thanks!\nCan you add a test for these? You can add a X.wast and X.2asm.js (the expected output) in test/.. Yeah, in general, anything not valid as JS should be sanitized. We should also eventually add a conflict checking system, so two things don't get sanitized to the same output.. Thinking a bit more about this, maybe we should check on more code. @dcodeIO, can you maybe try more code from your compiler? I've checked on the one testcase from you, plus a bunch from emscripten, but more testing would be good (since this is more of a heuristic than a guarantee). By testing, I mean to run it on some code and see if it improves things or not, say by measuring the binary size, or the output of wasm-opt input.wasm --metrics --merge-locals --metrics (so it prints a diff per element).. This new pass is a default optimization in -O3 and -Oz, but nowhere else, and in particular not in the default level (-Os), yeah.\nThe diff with flatten looks a little odd, we should investigate that before recommending people use flatten I guess.\nOk, thanks, I guess we've tested this all we can. All signs look positive, so I'll merge this. We should optimize the pass for speed eventually, and turn it on in -Os and -O2.. asm2wasm is built to run on asm.js code, not on regular JS code.\nThe code here looks like an emscripten shared module? If you build with -s WASM=1 then it should run asm2wasm on the asm.js part of the output for you. (Or if you want to do it manually, you need to split out the asm.js code, you can see in emcc.py how it does it, I think it calls a tool called tools/separate_asm.py)\n. Thanks! This looks good to me, but I'm not a windows or msvc user - maybe someone else here that knows those can also take a look?. One case we should test on is binaryen3.test_sqlite in emscripten: the merge-locals pass is extremely slow there (dozens of seconds).. I experimented with using a flow analysis, similar to coalesce-locals, in https://github.com/WebAssembly/binaryen/commits/fast-local-graph (see last 3 commits there) but it makes it slower :-o\nThe issue there is probably that we move around maps of index => set of relevant gets. A small_set class could help a lot there, perhaps.. > No JS engine present to run this test with.\nHmm, looks like node and sm bugs limit what vms we run the test on. And testing, it seems like those issues are still active today, so we should leave them...\nFor your local testing, if you have spidermonkey installed locally, you can add it to ~/.emscripten which will run the code in at least the optimized modes of that test (some other tests benefit from it too).\n\nwhich I think means that it ran all the optimizations appropriate to this bug.\n\nYou can verify with EMCC_DEBUG=1 in the env. That will log times for each step, and you should see an asm2wasm step which has the binaryen optimizations. It will also save a .temp.asm.js file - sorry for the confusion about what saves what, perhaps that's somewhat we could improve. (Overall, EM_SAVE_DIR=1 should keep the temp dir alive, but EMCC_DEBUG=1 tells it to emit all temp files.)\n\nInspecting the process tree with tracetree says that about half of that time goes to running opt and about half that time to asm2wasm.\n\nThat's without #1382, I assume? It should improve things substantially at least on sqlite.\n\nSo a smaller representation for LocalGraph::Sets would be a good starting point.\n\nVery interesting analysis, thanks. I think most of it remains valid after #1382 since that core data structure is the same. It may make sense to use an unordered set or a sorted vector or something else, but those also have downsides. Probably we should remeasure after that PR lands.. Oh, and thanks for mentioning tracetree! First I heard of it, looks very useful.. Merging this as the infrastructure is useful for other things already.. Thanks, looks good. Before we merge this, please join the wasm w3c community group https://www.w3.org/community/webassembly/participants. I don't understand it myself, but it's what the WebAssembly group wanted, and this repo is under that org. It may have something to do with the w3c, @jfbastien knows all the details.\n. ping @jfbastien for that legal question.. Well, to my understanding that should be more than sufficient. I'll merge this in Monday unless someone objects.\nThanks for your work and your patience here @krisselden!. The filesystem was \"needed\" because of iostream usage.. Ok, this should fix everything now. Added a wasm.js fix for recent emscripten and testing fixes and improvements (run binaryen.js tests in all engines).\nOne change here is to move binaryen.js to use standard emscripten MODULARIZE (like wasm.js). I needed that because things had broken in non-node.js for some reason. @dcodeIO , I think you wrote that code, is that ok?\nNote that it means we emit Binaryen as a function, so the test suite and users now do Binaryen = Binaryen() to get an instance, since that's what MODULARIZE does by default. We could change that though.\nOne odd thing is that this modified some of the test outputs - what I think are pointer values changed. We should probably remove those from the output, as they will change over time. It might even fail now on the bot given it's using an older emsdk version, we'll see.... About changing the interface, I'm not sure what's best. In MODULARIZE the exported Binaryen is a constructor, and the user needs to do Binaryen = Binaryen() to get an instance. That's awkward in a way, but it does let the user create multiple instances. Although for binaryen that doesn't make sense I guess, so I changed it back now, so it should be the same interface as before.\nAbout the pointer numbers, I guess we can leave them as-is for now, as the tests pass here. But I'm not sure exactly why it's not complaining already, something seems odd.. Ah, I see what's been going wrong... we build -g on the bot, but test the old build... :(. Good, and now it fails as expected on the bot.. And with the last commit it should work, without printing the pointer values that the tests now clean out.\nThis PR should be finished now, assuming tests pass.. I'm not sure how - I've never really understood how require and module loading etc. work, to be honest. But we have tests check for require, for example https://github.com/kripken/emscripten/blob/incoming/tests/test_other.py#L5420. Thanks, I understand better now. Is it standard though to add it to the global object, don't most people use the proper require etc. technique? I think MODULARIZE does the require stuff, but doesn't add to the global (but I'm not sure).\nIn any case, yeah, let's look into this as a general improvement of MODULARIZE. People on the emscripten repo will know more about this than me there.\nOtherwise this looks ok to merge?. Ok, let's merge this in. For followups, let's discuss those two lines in emscripten since it seems like a general thing for modularize?. Hmm, so should we assign the output of Binaryen() to the export? Perhaps this should be an emscripten option, like MODULARIZE_INSTANCE which does modularization and exports an instance instead of a constructor?. Alternatively, maybe there is a use for exporting the constructor, people may want multiple Binaryen instances for some reason? In which case, users should do the instantiation?. In a hypothetical MODULARIZE_INSTANCE mode it would be more efficient not to also allow creating more instances, as a singleton instance could be better optimized by JS engines and packers. But maybe that's not a big deal compared to the benefit?\n. Yeah, singleton instantiation is simpler for a VM. It can see that the code will never be used again and throw it away immediately after it runs, also it can avoid adding type profiling code as it compiles it (except for loops) etc. But, as I said I'm not sure it would matter much here. We should probably err on the side of the nicest API for users.. Looks like #1346 includes code to fix this.. Yeah, thanks for reminding me, I was meaning to get around to this. I think it might be pretty common actually, as many loops start naturally at 0.\nThe tricky issue is that using the zero-init value means the lifetime extends all the way to the beginning of the function, which might be bad in some cases, so this should probably be done after coalescing. #1339 adds some liveness infrastructure that could help here.\n. I extended this to handle redundant sets of values coming from a merge or an arbitrary set. Helps a little bit more on some codebases (mono) but no difference on most.. Fixed a bug that prevented this from optimizing some cases it should.. This should now be complete. I worried for a while about convergence being guaranteed, but ended up being able to write a proof for it. The convergence property is also tested with assertions, and this has been heavily fuzzed.\n  . Looks like the special detection of wasm object files was removed? lgtm, we can land this and do followups separately if that's more convenient.\n. Maybe testing this here is good enough, but might also be useful to also add a test of calling stackAlloc in the emscripten repo. I can do that if you want.. Thanks!\nThere are probably more APIs not fully documented there, it would be good to do a pass over the whole thing if someone has time.. Sadly updating the compiler didn't help. I added a commit to disable just the leak checks in a proper way as suggested above.. It would be good to land this soon, as it blocks some emscripten work. Nothing super-urgent, but if you're deciding which binaryen PR to review, maybe make it this one :). Good question. Actually the mandreel compiler used to emit switches in JS instead of ifs because that was faster on v8, a very long time ago. I suspect though that in wasm this doesn't end up useful enough, and does increase code size. Curious what @sunfishcode thinks.. @dcodeIO \"Maybe, in this specific example, the if could also be replaced by a select\"\nOh right, actually that should already be happening. When I compile your input wast with -O or -Os I get\n(func $test (; 0 ;) (type $i) (param $0 i32) (result i32)\n  (select\n   (get_local $0)\n   (i32.const 0)\n   (get_local $0)\n  )\n )\nBut not in -O2 or -O3. In this case it does seem like select is always preferable, so maybe we should do that. Right now the code just doesn't do this if we aren't optimizing for size.\nBtw, what are you compiling with?\n@binji \nVery interesting! If I read that right (my x86 is rusty) the native compiler outputs are consistently good? While the v8 ones seem to keep the branches? Is it odd that happens even when the input is a select?. The default should be -Os, in which case you should have gotten a select. Can you make a testcase showing the wrong output, I can debug that?. @dcodeIO: thanks, I think I see the problem in that testcase. we run the passes but don't set the opt level. we can fix that in your PR (next on my list to read) if it's not fixed already.\n@sunfishcode @binji I see, thanks.. The leak sanitizer can be ignored, it's unrelated breakage. I need to land something to disable it.. lgtm, however when I run this locally, I get an error. It wants to change things this way:\n```\n$ git diff\ndiff --git a/test/binaryen.js/hello-world.js.txt b/test/binaryen.js/hello-world.js.txt\nindex a2b023d..6441f7e 100644\n--- a/test/binaryen.js/hello-world.js.txt\n+++ b/test/binaryen.js/hello-world.js.txt\n@@ -26,7 +26,7 @@ optimized:\nbinary size: 43\n-[ 'exports' ]\n-[ 'adder' ]\n+\n+adder\nan addition: 42\n```\nI would guess that is a printing difference between node and other shells? or is the output just not updated? (travis is slow for some reason, so i can't compare to the results there). fwiw, I created this repo, and I don't care where it resides. (not that it matters much who created it)\nThe only things I care about are\n\nthe code being useful to as many people as possible, and\nas many people as possible being interested to contribute to it.\n\nMight be useful to know if moving the repo would change things either way for someone.. Thanks!. What compiler is that with?. Very strange, I am literally on the same version,\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\nand latest master works ok.\nAny chance the source was modified, or another compiler was found by cmake? And what revision is this of binaryen?. What was the order? Maybe there is something we can improve here. (Or was it the order of includes with other projects?). I see, yeah, sounds like that's the explanation then. Ok, closing.. Sounds like am s2wasm bug. o2wasm is almost ready to replace it though, maybe ready enough to test on that?\nEither way, it might be nice to have a testcase for the bug so we can verify o2wasm handles it ok when it is ready.. I think it's still in another branch. cc @jgravelle-google . Thanks! Yeah, this is good to do. Done in #1365.\nThis happens on hello world code too (see diff in that PR), it might not be that rare actually, given that 0-x is how we negate ints.... The offset semantics are tricky, actually. Integers wrap, but offsets don't (if the pointer + 20 overflows as a 32-bit int, it throws instead of loading from the wrapped value). Under limited circumstances you can optimize such things, but you need to know more about the pointer $1 here.. The current inlining heuristics are pretty conservative. In -O2 and below we only inline functions with a single use, that guarantees that when we inline them we can remove the original, so it should never be bad for code size. In -O3 we consider inlining functions with multiple uses as well.\nYeah, it seems like a tiny getter like that could be inlined with no code size risk, even with multiple uses. Maybe anything with just a single get_local or a const is safe. I can look into that (unless you want to).. Yeah, exactly, those are the issues here.\nAnother important detail is that we create a block and some new locals when we inline - inline without optimizing to see what that looks like. When we inline+optimize, we can often but not always get rid of those. For example, it depends if there are multiple params with incoming values with side effects, in that case we may need a new local and the block,\n(call $inline-able\n   (call $x)\n   (call $y)\n )\n..\n(func $inline-able (param $x i32) (param $y i32) (result i32)\n  (i32.sub\n    (get_local $y)\n    (get_local $x)\n  )\n)\nIn this case we can't just replace the call with\n(i32.sub\n    (call $y)\n    (call $x)\n  )\nbecause those calls may have side effects and can't be reordered. So we must use a block + local.\nBut a \"getter\" type example, as you said, is safe. If it has just one param or less, and its body is small enough.. Just inlining-optimizing should be enough. But the conditions in the inlining pass check for code size, existence of loops, and some other heuristics, so even if the pass runs it may not inline what you want, maybe that's the issue? If not, do you have a testcase showing the issue?\n(We should also improve those heuristics :) ). Thanks! Yeah, no reason not to do this.. Yes, looks like imports and exports should also be cleared there. We probably just forgot to do that when we added them.. This would help in those cases, as tee_local would be smaller, as you said, and also operations on locals will normally be implemented in registers with a lot less memory reading and writing, so it would be faster.\nBut to optimize this, it seems like the conditions are: the global is only used in one function, and that function will only be called at most once. Which can really only apply to the start method. So this would be fairly rare, I suspect. Still, worth doing.. Yeah, good point. Everything except for the final stores could be optimized using general methods (eventually; we don't have proper PRE or GVN yet). And a final store to a global is something we could work to optimize out (a store to memory is harder because they can trap, so we can't remove one unless we can prove it won't trap).\nI'm not sure how important it is to optimize globals in this way, though. In C/C++ output they are very rare, really only the stack pointer will use one. But maybe in AssemblyScript and others this may be common?. Yeah, exactly. In that example, we can save the loaded value to a local and use it instead of the second load. A gvn pass could do this, and would be a generalization of the currently very simple local-cse and redundant-set-elimination passes.. Sometimes travis jobs just hang, yeah. Just random issues on the bots I guess...\nLooks almost good on the last run, but I think you need to update the js builds.. Surprisingly useful. I see code size reductions of 0.5% on libc++ for example.\nWith more complex analysis we can inline even more, the heuristics are still quite simple.. Hmm, I wonder if there is some difference in startup between C++ and Rust that could cause that? Not sure what it could be, though.\n\nWhat test is it running where that fails?\nIs it possible to get a full stack trace for that assert?\nBuilding with BINARYEN_THREAD_DEBUG (just src/support/threads.cpp needs it) will produce runtime logging that could also help here.\n\nIf it's feasible to bisect to find the bad commit, that could help too (looks like the range is from last september til today).. I have a poor understanding of Rust stack traces, but it looks like\n\n\nRust starts to panic\n\nDuring panicking it starts to run a binaryen test\nThe binaryen test tries to do stuff with threads but hits an assert\n\nIs it possible Rust panicking leaves things in a state where mallocs or other system operations will fail?. > No there are no panics. What you see is machinery to catch a panic and a test setup.\nI see, thanks. As I said, I know very little about Rust :)\n\nI don't know about C++ memory model and concurrency semantics but doesn't this should be wrapped in somekind of mutex?\n\nHmm, good point. The intention was that that should be safe, as the threadpool is only requested from the main thread. However, I see we added asserts in the thread constructors, which get the pool to check if it's running, which run in their own threads ;) lol\nAnother issue is that I think you are running tests in multiple threads? We didn't test that, so we need some more carefulness to handle that properly.\nFixes for both should be in #1377. It should, that's very important even, but it was never tested ;) Our test harness is just not multithreaded. We should probably add a specific test for this.... Thanks, I think I see what's wrong. Fixes in #1389.. Interesting... it looks like on your machine when a c++ unique ptr is destroyed, it first clears the value, then destroys the object. So the workers can't find the pool when they destroy themselves. That actually seems odd since it seems like if it were defined behavior, we'd see the same on all machines, and it only happens on yours, which makes me wonder if it isn't undefined behavior in C++...\nAnyhow, the fix is simple, to not have them go through a global unique_ptr as they currently do, I pushed a refactor with that to that branch (which seems nicer anyhow).\nI'm not able to see that issue though, so I can't verify it fixes what you see, please test it if you can.. Great, thanks!\nI wonder if this depends on the OS somehow, actually (I'm on linux). That is, maybe how processes are torn down is different, and on linux it \"skips\" over the potential issue, while on mac it doesn't.. Hmm, interesting. In that case, this might still be UB after that PR? Although it depends on whether the lifetype of the unique_ptr is identical to that of what it refers to, and whether our ThreadPool and Thread have \"trivial destructors\" in the sense of that link (I'd hope yes, but I'm not sure about the mutexes they use), and probably some other details I really don't understand.... Right, good point, that's all quite bad. isRunning shouldn't be doing all that extra work with the global pointer, it should just directly access running. Fix coming up.. 1. You might need to implement a bunch of things for the imports here - e.g. binaryen uses exceptions so there will be invokes, and it does syscalls to print logging, etc. Not sure it will be practical to do. But could be fun to try :)\n2. You actually can just build with -Os on latest emscripten, you don't need SIDE_MODULE. It should still produce something with the minimal possible imports and exports (thanks to metadce). SIDE_MODULE will bring in some extra overhead, too, like runtime relocations (for memory and the table) which you don't need. And with -Os --closure 1 the generated JS should be pretty minimal, especially compared to the wasm size (blogpost coming on this soon).\n3. A temporary asm.js file is expected, we generate asm.js and then run asm2wasm to get wasm.\n4. That crash is due to libc aliases for globals, possible fix is in https://github.com/kripken/emscripten/commit/dc543e90d4f07230350a5093e2dea32b866f54ae . Yeah, the async startup is an annoying issue. For binaryen.js we can maybe just set BINARYEN_ASYNC_COMPILATION=0 so it is synchronous - browsers have limits there, but hopefully node.js doesn't. Does that work?\n(Otherwise, MODULARIZE provides a promise for this, but it's not clear how to do that with MODULARIZE_INSTANCE...). I think over time the JS side will get simpler, for example when wasm has native C++ exceptions support, we won't need invokes etc.. For the cwd, you can use Module.locateFile to customize where to look. I think that could work, but it would need to check if the file is in the current dir or under bin/ manually I suppose.. Maybe we could use SINGLE_FILE to embed the wasm? Not great for size, though.\nHow about disabling async compilation, does that work in node? (I know it would fail in chrome, but maybe v8 in node.js is more tolerant of sync compilation?). The place where it should call locateFile is here: https://github.com/kripken/emscripten/blob/incoming/src/preamble.js#L1990 maybe some debugging logging around that location can help.. That.. would be very odd if true :) the pre-js goes before the \"prelude\" file which is where the integrate method is.\nIs the pre-js queuing code to happen asynchronously later perhaps?. About the synchronous/asynchronous issues,\n\nDid we check if node.js can handle synchronous compilation? that would be best.\nIs there some way in module loaders to handle this? What i mean is, when you do require() in node.js, is that an async or a sync operation from the perspective of the module being loaded? If node allowed an async callback for the require to complete, that would be really cool...\nIf we can't do either of those things to keep the API synchronous, I think we should consider changing it to be asynchronous everywhere - the asm.js and wasm versions being different seems confusing. But i'm not sure.. Yeah, makes sense overall.\n\nAbout .ready.then(), could it be just .then() like MODULARIZE does now? Or is .ready better for some reason?\nI see that Parcel allows synchronous syntax for loading wasm, by translating it to async at bundling time. We probably don't want to depend on a specific bundler, though, but that would have been nice.... I think the Modularize .then() just looks like a promise, but isn't actually one. This caused some issues in https://github.com/kripken/emscripten/issues/5820 so maybe as discussed there we should change it.\nAnyhow, I don't want to block this PR on all these larger issues. But picking the API (with .ready or not) is maybe something we should figure out before landing. Or at least we should have an idea of a way to change things later without breakage.. Interesting about wabt using .ready too - is that a general convention in the JS space these days? If so, definitely let's do that. . I see. Well, I don't really have strong thoughts on the API one way or another, just trying to keep us consistent with other stuff... :) I'm ok to merge this in unless you think there's more to discuss.\nI am somewhat worried about us already having a non-ready method on MODULARIZE, so maybe it's worth opening an issue on emscripten to discuss what to do more generally there.\n. This was held back by some bizarre breakage - ubsan throws an std::bad_alloc, and the js build starts to abort inside free. Turns out the issue is that having two classes with the name wasm::Action is bad - apparently the linker will merge them silently. That led to memory corruption, even though if the new Action class was not actually run - just being linked in was enough to break things (I guess it was running functions from the new code on objects of the old or vice versa). Sad stuff. Fix should be in https://github.com/WebAssembly/binaryen/pull/1382/commits/e278519833091c46d76b14c8bb0276b414330449 but there is also some chance I am missing something here.\n. Tests look good now, this should be all done.. Looks like no concerns here, merging.. Not sure what you mean - what should we check about the offset? It's just a number, like for loads and stores, I think.. Without optimizations, some default imports may be left in, which are not needed. When I compile your asm.js with optimizations I get this:\n$ bin/asm2wasm a.asm.js -Os\n(module\n (export \"add\" (func $add))\n (export \"square\" (func $add))\n (func $add (; 0 ;) (param $0 i32) (param $1 i32) (result i32)\n  (i32.add\n   (get_local $0)\n   (get_local $1)\n  )\n )\n)\n(Notice that it detected the two functions are identical so it merged them, and it optimized out the return.) So basically just run asm2wasm with -Os (or another optimization level) to get a small minimal output, without anything unnecessary.\nAs to what those imports are, by default we import a memory and a table, and also an offset of where we can use space in them. That is useful for dynamic linking, where multiple modules might use the same memory, each with a different range. But for a case like this, with just pure computation, the memory and table and the offsets are not needed and the optimizer can remove them.\n. Added a refactoring to give workers a direct pointer to the pool, avoiding them using a global variable which was less nice. This should also fix an issue noticed about destruction order of that global in #1376. Yeah, I'll document this better in the final commit here, good point.\nAbout the threadPool being global or not, there are advantages both ways, yeah. I prefer a single global one for a library like binaryen, since threads are a single global resource in a sense. Even if you create multiple modules and optimize them in parallel, you usually only want a number of threads active that is equal to the number of cores, and not potentially the number of cores times the number of modules.. True, but after this PR I think most of that complexity is gone. The one place it's left is that we lock in the get() method, which doesn't seem so bad to me.. Let's merge this in, as it is confirmed to fix all known problems here. We can do further improvements later.. I doubt UBsan will catch this, it's already been present (since we added that test 2 PRs ago) and not detected...\nWe can avoid all this stuff, the only reason the children access the parent is that we try to shut down in an \"orderly\" way, with the parent waiting for child threads to join before stopping. Probably that's not strictly necessary, what's the worst that can happen if the main thread exits before a child thread does?. Yeah, UBSan failed to notice anything.\nMeanwhile I see that ThreadPool doesn't even have a destructor. So we can avoid this UB by just not calling from the worker into the pool to check if it's running.. Hmm, I'm not sure. cc @yurydelendik who might know the answer to the above question?. Thanks, changes look good!\nHow about if we make more of an effort to update docs/binaryen.js.Markdown? It would be good to add to there with each PR like this.. Oh, yeah, another PR is fine.\nRemind me of your other docs, where are they? Maybe we can just link to those, depending on the content.. Thanks. Those look pretty nice. I think we should focus on one set of docs in one place, as right now for example yours are missing Module.set_local (the alias with an _), while the ones in this repo are missing other stuff. I'm fine to go with yours, in which case we should make sure everything documented here is in yours, and we should remove the docs here and add a link in the readme for where to find the docs. Thoughts?. Probably get_local should be the default, since it matches the wast format? Less \"JS-ey\", but still seems slightly better to me.\nIf it's not too hard, we can just constantly sync those two files? Unless there is a difference in content that should exist?. An advantage to not doing it in the wiki is that then it uses the same git history as the code itself, so people can easily see older versions of the docs.. I guess it's fine either way. Long-term if we have many users ;) we may want to move it from the wiki, but the wiki sounds ok for now. Let's just add a link to the wiki and remove the copy that isn't in the wiki.. @jfbastien hmm yeah, it would break demangling. but just if there are duplicate names which seems incorrect anyhow...\n . lgtm as well. Anything left to discuss here, or should we merge it?. I think we might split things out in the future, yeah: a Type might be more specifically either a ValueType or a GCType (sort of like we already have a distinction between concrete types and non).. Thanks for reporting @cuviper , #1401 should fix it.. Oh thanks, sorry I didn't see yours before.. Thanks!. #1400 does this and better.. The issue here is that var k = 10; is not valid asm.js, and asm2wasm assumes the input is valid.\nI agree we should add error messages for code that isn't asm.js, but our parser isn't currently designed in a way that makes that simple. It would be nice though if someone were interested to write a better one, or improve the existing one.. Good point, looks like the spec does allow it. I think that changed at some point, as in early versions it mandated only 0 in the declarations.\nIn that case, it would be nice to support it in asm2wasm. I'm not sure offhand how easy that would be, but I think there are some hardcoded assumptions on 0 in declarations.. To misquote Huxley, a beautiful optimization ruined by an ugly fact. . I like @binji's suggestion to get a \"preview\" first.\nWhat are the effects of this PR? It doesn't look like it adds any tests for incorrect format changes. Does it just change what clang-format does if it is run? Do we not want it to be run automatically somehow?\nStyle-wise, I feel strongly about\n\nIf etc. arms on a new line need curly braces (that one saves me from bugs now and then).\n\nI would prefer but do not feel strongly about\n\nLine length limits. 80 feels much too short to me, personally.\n. Thanks @aheejin, very interesting.\n\nOverall any of the first 3 seem generally ok to me, they are the closest to the current code I think. I'd slightly prefer the LLVM style myself out of those.\nI'd love as much line size as possible, personally. If Rust has 100, maybe that's ok, but I'd like 120 even better ;)\nI'm not worried about changes to git blame - consistent style is worth the extra effort to add a step to look through a widespread style change.\nSo if I understand correctly, if I were to run clang-format in the root dir of this repo, it would update all the files to the proper style? And we'd expect people to do that before creating PRs (or we'd do it ourselves periodically)?. Is PointerAlignment the char* x vs char *x issue?\nYeah, I think we should go with char* (not the LLVM way). That prevents confusion in my experience.. Thanks, lgtm.\nHow should we move forward after this? A followup that applies the style sounds good to me (even though it changes history).. Running this locally, I see it transform\n-        if (j > 0) std::cout << \", \";\n+        if (j > 0)\n+          std::cout << \", \";\nI thought that we were going to allow it to stay on a single line? Or maybe I misunderstood the discussion above.. I see, thanks. Make sense. In that case, we should add { } around those when applying the new style, and never put something (with an else) on the same line.\nBtw, about the attribution issue, I had a silly thought: is there a practical way to run clang-format on just the code a person is already the last modifier of? That is, that clang-format would not change git blame much. Then each person could update their own. This doesn't seem trivial to do, but on the other hand, it seems like a useful thing for projects using clang-format and git, which should be quite a lot - maybe something like that exists?. Yeah, maybe the blame is no big deal either way. In that case, since I likely have most of the blame for bugs in this codebase ;) I could do a commit to update the style. I'd manually fix { } as is necessary as you said @aheejin \nHowever, @sbc100 it sounds like you don't think even that is worth doing? In that case are you suggesting people only use the new format on new code going in?. @sbc100 oh ok, I'll prepare a commit then.\n@aheejin I think there are not too many of those, I'll see if I can do them manually first.. Hmm yes, there are quite a lot of single-line ifs. So would need clang-tidy, which I don't seem to have installed anywhere, is that not part of clang?. Thanks, I opened #1435 with the formatting changes.. This broke CI, flake8 issues on the python changes, e.g. https://travis-ci.org/WebAssembly/binaryen/jobs/341558272. Thanks!. Thanks, opened #1414.. Ran the emscripten test suite and fuzzing, saw no problems.. readBinary receives the actual binary data (as a typed array), not the filename.\nBtw, what is \"wasmx\"?. Interesting, is wasmx a standalone project? Or is it part of something? I never heard of it til now.. Heh, thanks, now I see :). Thanks for submitting this PR. I'm not familiar with snap myself, hopefully someone else here understands what this does and the benefits.. I see things working in Firefox Nightly (62), after enabling the pref. For example, a basic OpenGL app like this works:\n./emcc tests/hello_world_gles.c -s USE_PTHREADS=1 -o a.html. @athei - that's actually just a weird thing with the wasm spec. They require the proper MIME type for streaming support, and simple webservers often don't set it right. That's the case for the simple python webserver, for example. Which did you test on?. (But, when the MIME type is wrong, we fail to stream but still compile it without streaming, so it's not a fatal error, just means things are less efficient.). Hmm, might be good to file an issue there (or in the upstream MIME-handling library) about adding the wasm mimetype.. I'd check if it works in other browsers - if it works in all but Firefox, sounds like a Firefox bug; if it works in none of them, sounds like an emscripten bug.. I can't confirm the bug on Firefox Nightly. Here's what I did:\n./emcc tests/hello_world.c -O2 -o a.html\nCreate .py with\nimport BaseHTTPServer, SimpleHTTPServer\nSimpleHTTPServer.SimpleHTTPRequestHandler.extensions_map['.wasm'] = 'application/wasm'\nhttpd = BaseHTTPServer.HTTPServer(('localhost', 8888), SimpleHTTPServer.SimpleHTTPRequestHandler)\nhttpd.serve_forever()\nRunning python a.py, I browse to http://localhost:8888/a.html. There is no MIME error shown in the console. But if I remove the MIME line from the .py then the error appears as expected.. Hmm sorry, I don't know enough about tracing network stuff.\nAre there simple instructions for running it with your server where you see the problem?. Great, thanks!. This link should work: https://nightly.mozilla.org/. Is that with javascript.options.shared_memory enabled? (Although, when disabled, the error message you get should be different, so it's probably not that.)\nAnd is that on latest emscripten, 1.38.7? (I verified that works now.)\nThe line the error is thrown on may also have useful information - although I'm guessing it's creating the HEAP views or something like that?\nAnyhow, if it's none of those, it may be a Firefox bug on your machine - could be platform specific which would explain why I don't see it.\nBtw, does it work on Chrome canary? If so, I'd file a bug on Firefox.. I'm on Linux (Ubuntu).\n\nAs i mentioned in my first post, i get the error \"TypeError: invalid array type for the operation\" w.r.t. PThread.mainThreadBlock.\n\nThat's a variable, I think - which line that operates on it throws for you? Is it the same as the other poster, something like Atomics.store(HEAPU32, PThread.mainThreadBlock + 116 >> 2, tlsMemory); ? No idea what could cause an error there, though.\nMaybe put up a build that doesn't work you, and I'll test that link over here? If it fails for me too I can debug it.. Those steps look ok to me. At this point I am out of ideas - I'd suggest putting up a build that I can test (as I said, if I see your build fail on my machine, I can then debug it), or you can debug it directly on your machine (I'd add some debug printouts to see what the objects are on that line - then debug backwards to see where they are created).. When I run your build it works as expected for me (although it seems to be built without -s PTHREAD_POOL_SIZE=8 or such - when I build with that, it also runs properly. I don't remember offhand why that pool stuff is needed, but all the examples in the test suite seem to use it).\nSo given that your build fails for you with that error, this does seem like a Firefox bug. If you still see it on current nightly, I'd suggest filing an issue there, https://bugzilla.mozilla.org/. Oh, I may have misunderstood something above, sorry! \n\nThe hang in firefox is, I believe, explained by not having -s PTHREAD_POOL_SIZE=8. I see @Priysha-Aggarwal mentioned that before but I missed it. So that doesn't sound like a firefox bug - instead, we should figure out what's going on with that flag (as I said, all the tests seem to use it; I'm not sure why it doesn't have a default value).\n\nThe [object Uint32Array] is not an integer shared typed array error in node.js is likely because node does not have SharedArrayBuffer support, or something else goes wrong in the creation of the threading code - but regardless, our current threading support can't work in node.js because we require Web Workers, and node doesn't have them. There are some packages on npm that have worker support, but I'm not sure how exactly. So to answer your question: all development so far has gone into getting pthreads working in browsers, it is not expected to work in node.js (but it would be great to get it working there too).. @thomasjammet that sounds like a firefox bug (given the same code works in chrome, and you are on a recent emscripten). I'd suggest filing an issue there, https://bugzilla.mozilla.org/ (the right component is Core::JavaScript Engine, this link might work to get there directly, https://bugzilla.mozilla.org/enter_bug.cgi?format=guided#h=dupes|Core|JavaScript%20Engine ). Could be, yeah. You can add more debug logging around where we create the buffer. That should be the same line in both browsers, and something like new ArrayBuffer(TOTAL_MEMORY) - so it seems odd one browser could have a different type than the other. But perhaps control flow doesn't reach there, like maybe one browser does not detect SAB support earlier on?. lgtm, but looks like flake8 has some style errors that fail the tests.. I don't know flake8 well myself, but I don't know a way. Honestly, I think it's more hassle than it's worth. If you waste more than a little time on this, maybe we should reconsider using it, especially since it's just test support code and not the main project code.... Oh, might be the other flake8 issues just now that affected things? Anyhow, everything looks good.... These changes don't require updates in the existing wasm2asm tests?\n. Looks good, thanks!. lgtm. That could be an asyncify bug, and it doesn't have a maintainer currently. Perhaps see if you can use the emterpreter-async option, which can do most of the same things, and is better supported, https://github.com/kripken/emscripten/wiki/Emterpreter#emterpreter-async-run-synchronous-code\n. From this\nfunction sleep_doWritev(stream, iov, iovcnt){\n  var result = real_doWritev(stream, iov, iovcnt);\n  _emscripten_sleep(2000);\nI am guessing you are calling emscripten_sleep from ordinary JS? That won't work, the emterpreter can pause and resume interpreted code, code it compiled into bytecode itself. It can't pause and resume ordinary JS.\n. Yeah, we'll need to prefix functions and globals, good point. Want to do it here or in a followup?. Sorry, conflicts here are probably from my wasm2asm float32 fix.. Thanks, the nearbyint thing should be fixed by https://github.com/kripken/emscripten/pull/6265. Looks like it was clang-tidy that caused both of those bugs.\n. Probably doens't make sense to do this. I'll leave the branch though if we want to reconsider this in the future.. cc @froydnj . Ok, I think we are all in agreement here, merging.. Sorry, yeah, wasm-reduce is not very portable.\n\n\nI don't know how to replace timeout in a portable way (maybe using threads?).\n\nI'm also not sure how to fix the BINARYEN_ROOT issue, basically the executable needs to find another executable in the same dir as it, is there a way to do that in C++?\n\nI agree it would be good to add checks with better error messages and suggestions in the meanwhile.. Looks good to me. Should we merge this or did you have more thoughts on refactoring?. Ok, cool. Let's merge this. We can always improve things later if we find a good way.. I think the extra return statements would be good to remove, but the optimizer could do that for us, so if it's not easy to do in wasm2asm then we don't need to. But removing those warnings would make seeing the errors easier, though.. > which requires regenerating all the .2asm.js files\nJust wanted to make sure you're aware of auto_update_tests.py, which does that automatically.. Done.. Great, after your last fixes @froydnj this PR is now green!\nAny concerns or should I land this?. cc @yurydelendik . Looks like no concerns, merging.. Overall this looks good and I like the approach with the imports. For the exports, though, I think we should avoid adding a new API like setFunctionName. Instead, we can set the function name before we add the function, which is how this works for the names section (WasmBinaryBuilder::readNames), it sets functions[..]->name. Concretely, when reading exports, it's an exported function I think we can set the function name there.. Is that the spec repo? I do see foward.wast in there. I guess we already have some code to run the spec test suite through wasm2asm? (which I was thinking we'd want eventually, surprised it's already started)\nPerhaps the only thing missing is to add a few lines to ./auto_update_tests.py for updating those, as the inputs are in the spec test repo, but the outputs are in this one.. Last errors look like binaryen.js, which means we need to update the wasm2asm component in the JS port too. If you have emscripten set up ./build-js.sh can do that. If not I can do it for you.. I think the only problem left here might be the merge conflict. I merged in master and rebuilt here and it looks fine. We can just merge that branch in, or you can merge it into here, either way.. I've seen that before, it seemed like a random CI failure. Might be ok after a restart.. Looks good! :). Looks like no concerns here, merging.. I like the idea, nice!\nBot errors might be python style issues, although the last one looks like something else.. It's hitting a problem that looks like a bad merge to me - it's looking for a file that doesn't exist, with a very long name, that we recently added an option to use a numeric name for, #1450. Perhaps in the merge that logic got lost?. Looks good now, thanks!. Binaryen only supports s-expression notation, so that drop should be (drop). Everything else there looks ok I think.. Sorry, I should have been more clear. The drop needs to be in s-expression notation, which means properly nested,\n(drop\n      (call $call (i64.const 200000) (i32.const 0) (i32.const 20) (i32.const 52) (i32.const 4) (i32.const 56) (i32.const 4) ) \n    )\n(There is no stack in s-expression notation, it can't drop something before it.). Sorry about this, it is being discussed in https://github.com/kripken/emscripten/issues/6275 . Hopefully we can fix it soon.. The error handling in asm2wasm is not very good, sorry about that. The issue here is that min/max are float operations in both asm.js and wasm, so doing them on an integer is an error. I opened #1456 with better reporting.. The error should be clear now with that merged. Thanks for filing!. Seems reasonable. Maybe we can simplify this as follows, though: right now we show that logging when either in debug mode or the env var for debug mode was set. I think the env var is enough, so we can remove the debug field from PassOptions. And then verbose mode might be one of the levels of the env var, maybe 1 is non-verbose (same as now but less logging), 2 is verbose (replacing the current 2 mode which seems silly) and 3 which is unchanged (verbose + save files for each pass). Thoughts?. Yeah, this is a tricky area. For emscripten output, this is actually already ok, though: we reserve a bunch of bytes in low memory for temporary use, pointed to by tempDoublePtr. Even without that, it is always safe to use memory locations 0-8 since we disallow them to be used otherwise.\nBut for non-emscripten programs, yeah, this is not valid to do in general. An option might be to do a function call out to JS to do it for us. That has the downside of being slower and requiring us to include some JS support code which I don't think we have needed yet.\n. The main code could be valid asm.js, calling out to normal JS is allowed. So we'd have some asm.js and some support JS on the outside which isn't asm.js.. I'm not very familiar with git attributes, but binary is a macro for -diff -merge -text, it seems. Maybe -text is enough to avoid grepping? (-merge seems like it might have downsides, in that sometimes it does make sense to merge those files instead of treating them as indivisible units like a binary would. -diff seems reasonable for those two.). Also adding proper multithreading for those warnings - they can happen from multiple threads.. I think this is an interesting idea, see previous discussion on the emscripten repo at https://github.com/kripken/emscripten/issues/6155\nOverall, the main issue is with point 1: currently the table is neither imported nor exported, and that turns out to be good for VM optimizations as well as toolchain ones, see last comment in that link.. memoryBase and tableBase are from the dynamic linking conventions. They are basically where the wasm module should place it's memory and table data.\nDYNAMICTOP_PTR is a pointer to where the top of dynamic memory (handled by sbrk) is.\ntempDoublePtr is a pointer to some scratch memory in asm.js - I'm surprised to see that in wasm actually, but the metadce optimizer should eliminate it.\nABORT is whether the program is aborting.\nNaN and Infinity are those JS values, used in asm.js to define them, and should be optimized out for wasm in metadce.\nabortStackOverflow is called to report a stack overflow and halt the program.\nIn general, this stuff isn't well documented because it's not a fixed ABI, and we hope to remove much of it and formalize the rest (in the link at the top there, in part). But that's going to be a long process. Help is welcome there of course.. Those two are identical, aren't they (except for the debug info)? If you use wasm-dis from binaryen it's clearer when it's not in the stacky format. Both have one set and 3 gets.\n. Thanks!\nShould be 1.37.36 now, btw.. Thanks, yeah, the error handling here was not good. Improvements in #1475. Looks good, thanks. Just need to rebuild the js files and update the binaryen.js test (./build-js.sh, ./auto_update_tests.py) for that test failure.. Yeah, I think you're right, it looks valid according to the spec. Binaryen appears to allow it, but wabt errors with\na.wast:6:9: error: initializer expression can only reference an imported global\n@binji, thoughts?. That assertion says the IR it is traversing is not valid. It's not valid enough to even print, so it's hard to show a much better error message than that, but maybe someone else has an idea. (Maybe we should show what is currently on the stack before trying to push null to there? Not sure it would be helpful.)\nFrom the program fragment you posted I'm not sure what might be going wrong, but likely it's something with not providing a parameter somewhere, so it puts null where a valid value should be. Can you post a full program I can run to reproduce the problem?. @pannous it would be good to improve those error messages. Can you maybe create small testcases using binaryen.js that end up showing those errors? That would make fixing them much easier.. Thanks @pannous, proper error handling for getFunctionType etc. is in #1570.\nI'm not sure why the stack trace would be wrong. We need to look into that. I'm making a new JS build now and will try to see.. Regarding the stack trace, when we hit an error the C++ calls exit with an error code, which on node.js will call process.exit, which exits without a stack trace. I added a commit to that PR to change the behavior.. Looks good, but also this makes me think, maybe we should only run optimization passes when optimizing? For now though this seems fine.. Tests don't look fully updated, did you update them after rebuilding the js?. Sorry, I should have been clearer: I meant we should probably consider adding optimization options to wasm2asm. asm2wasm has them - it's common to want to translate and also optimize, and we can pick the right optimization passes that way, too. Anyhow, nothing urgent.. Thanks!. Using wasm-dis implies you converted that text to binary first - how did you do it? Binaryen's wasm-as fails on it (it doesn't support the stacky format without parens, it just supports s-expressions), reporting\n[parse exception: expected list (at 4:4)]Fatal: error in parsing input\nand wabt's wat2wasm fails on the error you mention.. full wabt error:\na.wast:6:5: error: type mismatch in i64.load, expected [i32] but got [i64]\n    i64.load\n    ^^^^^^^^. I see, thanks. Yeah, this is due to binaryen's handling of unreachable code - it just drops unreachable sections instead of trying to parse them, so here it just emits\n(func $0 (; 0 ;) (type $0) (param $var$0 i64) (result i64)\n  (block $label$0 (result i64)\n   (unreachable)\n  )\n )\n(everything after the unreachable is lost).\nI'm not opposed to adding support for error handling in those sections, but it's not a major goal for binaryen to have full support for proper parsing of invalid wasms, in my opinion at least (I care more about optimizing valid ones well).. We run those asserts in general, but we skip the stacky parts of the spec test suite, that's probably where that test is?. Renamed the issue for the more general issue of type-checking unreachable code.. Thanks!. Thanks!. Good idea, cc @dcodeIO . Yeah, we should improve this. It's not quite as simple as this, though:\n\nan i32.add should always be smaller than a call with an additional function index immediate - is this correct?\n\nConsider the case where the function flips the argument order,\n(func $exported_sub (; 0 ;) (type $iii) (param $0 i32) (param $1 i32) (result i32)\n  (i32.sub\n   (get_local $1) ;; second arg first\n   (get_local $0) ;; first arg second\n  )\n )\nIf in addition the arguments passed have side effects, then we need to create a block, assign to a temporary local, etc., so that we keep the side effects in the right order. (Whereas when it's not exported, we know we can remove the function, so even if we need that extra overhead it's going to be worth it for size. And when we do -O3 we don't care about size and focus on reducing the call overhead, so we do inline even if it is exported.)\nIt's tricky to get those things correct. Maybe the simplest thing is to simply inline and measure the size after optimizations, but that's not going to be fast. Alternatively, we could focus on getting simple cases right like this one, maybe that's worth doing - is this common, do you think?. This is the flipping problem: given this,\n(func $small (param $x i32) (param $y i32) (result i32)\n  (i32.sub\n    (get_local $y)\n    (get_local $x)\n  )\n)\n(func $big\n...\n  (call $small\n    (call $first-side-effect)\n    (call $second-side-effect)\n  )\n...\n)\nIf we inline we must keep the order of those two calls the same as before. So we need something like this:\n(func $big\n...\n  (block\n    (set_local $temp_first_side_effect\n      (call $first-side-effect)\n    )\n    (i32.sub\n      (call $second-side-effect)\n      (get_local $temp_first_side_effect)\n    )\n  )\n...\n)\nI can't think of a more efficient way to do that. And it's larger than the call, sadly.. Exactly, yeah. For 2&3 we have EffectAnalyzer so it's easy to see if two arguments can be flipped without problems. For 1, we actually don't have a simple interface for it, no way to abstract \"give me the operands without caring about the node type\". Might be worth doing that first.\nWhat I kind of don't like is that even with that interface, this would be very specific to the case of a function with a single node that has 2 operands (so a binary node or a call etc.). There are going to be more cases of various sorts. So it would be nice to have a very general way to see if an inlining is going to be worth it or not, but that's hard. At the same time, we should handle common cases at least, so I'm not opposed to doing this for this specific case.. @TerrorJack Binaryen validation is very comprehensive, and definitely non-linear. But you should only need it when debugging. Or do we have validation on by default somewhere it shouldn't be, what commands are you issuing?. @TerrorJack I see, thanks. Meanwhile I'm reading the source and it looks like the nonlinear thing I remembered has been optimized, so I'm actually not sure why it's so slow. Maybe you can create a testcase and I'll profile it?. @TerrorJack Thanks, but how do I see the problem with that testcase? Not sure what to run or look for. When I do e.g. wasm-opt --metrics to print out metrics, which also runs the validator, it seems quite fast (0.3 seconds for everything).. Meanwhile I looked into the 0.3 seconds, and most of that is block parsing which is indeed quadratic for no good reason. Fix in #1495, which makes this 10x faster on that testcase.\nIs there a chance you were seeing binary reading times as the slowdown, as opposed to validation? If so, that PR might fix things for you.. Great!\nLet us know if you find anything else is slow.. Binaryen would add to that, yeah. But, being realistic, Binaryen is going to be faster than the WebAssembly VM compiling it to machine code afterwards anyhow. WebAssembly is an intermediate format, so in an environment like qemu slower compilation is unavoidable.\nIn a workload dominated by compilation WebAssembly just might not be good enough, period. On the other hand, for code that is compiled once and run many times, increasing the compile time even significantly shouldn't be too bad - that's why I'm very interested in this. But, what's your use case?\n. I see. My guess is that could be fast enough (but we'd need to measure to be sure, of course).\nHappy to help try this out - I can help writing out the Binaryen integration bits, if you set up a repo. I just don't know where to get started on the qemu side.\nBtw, another option here is to interpret the wasm (using the Binaryen interpreter, or another), to avoid compilation entirely. Then compilation can be done after the function is used enough times, as a JIT optimization, etc. I'm optimistic we can find ways to make this work efficiently.. Regarding the license, that is something we should fix if, if it's a problem.\n@jfbastien, I know the WebAssembly/ projects, like LLVM, were thinking about doing Apache 2 plus exceptions. Looks like those exceptions might help here (QEMU is GPL2). Do you know what the status is there?. @jfbastien Thanks! And to be sure, the wasm projects are going to be licensed in the exact same way as LLVM?\n@atrosinenko \n\nBut isn't changing a license a big problem when there are already 64 contributors?\n\nWell, in practice probably 99% of the code in Binaryen was written by less than 10 people. And I'm pretty sure all of them are very excited about enabling use cases like Qemu (I definitely am), so I think we could dual-license it (say, to add MIT) or some other solution. But it sounds like the LLVM license change will apply here too, in a matter of months, so we may not even need to do that.\nOverall, I encourage you to experiment on this stuff :) We'll make the licensing stuff work out.. I'm happy to drive the conversation. I thought I remembered we had a plan here and/or someone that was focused on this? But I guess we can discuss that in the CG meeting :). Sure. So for Binaryen I see this issue came up in 2015, when we added the initial license, #5 - already there we mentioned needing an exception. I don't see any later discussion. So maybe that is now :)\nWe've also discussed some W3C specific issues in #1358 (joining the community group as a barrier to contributors) but that is orthogonal.\nOutside of Binaryen, the issue came up in the design repo in https://github.com/WebAssembly/design/issues/668 - there it is suggested that wasm projects follow the LLVM license change, and it mentions updates in the future (as at the time the lawyers were still figuring things out, I guess?), but I don't see any later discussion.. > Do I get it right, Binaryen can be used as a library constructing WASM binaries at run-time and even somehow optimize them?\nYes, and that's one of the goals of Binaryen - to make it easy to write not just static compilers, but also JITs. I hope to see it used in places like QEMU and Mono, for example.\nSpecifically, Binaryen has a very simple C API for generating its IR, and then you can tell it to emit wasm from that. Optionally you can also run Binaryen's optimization passes first, which are designed to be fast enough to run in a JIT.\n. I get an out of memory crash in chrome, and on firefox I see an exception thrown, exception thrown: CompileError: at offset 962: unrecognized opcode: c0 0 - is that expected?. I see, thanks. Ok, let's file a bug on chrome for that, yeah. First thing, though, is that an optimized build? I see the binaryen optimizer can shrink that file by 13%, which suggests maybe it's -O0?. I see, thanks. Ok, I can open a bug with that - is it a stable URL?. Thanks! I filed https://bugs.chromium.org/p/v8/issues/detail?id=8907. I agree it's a little weird, yeah. Binaryen follows the wasm spec closely, though, so that optimizing is straightforward - we want one Binaryen IR node to correspond to one wasm node, or as close as possible. So adding a node not in wasm, that we need to expand out, has downsides.. markdown?. Oh, I see. Yeah, that's a good idea I think :). cc @jgravelle-google - I know the main focus is on o2wasm now and we hope to deprecate s2wasm, but the changes here to the shared linking code may be useful regardless of that?. Hmm there is an o2wasm_temp branch here that I see. Maybe that's it?. Thanks @jgravelle-google !\n(Can we delete the o2wasm_temp branch then?). Thanks! I opened #1502 to handle this case (and a few other things I noticed while doing it).\nI should clarify, I don't think it's worth optimizing the fastcomp switch heuristics, as we intend to switch the llvm backend from it. But I think it's worth optimizing stuff like this in a binaryen pass, since it can help other compilers to wasm.\nAlso while that binaryen pass improves overall asm2wasm output, obviously that shouldn't matter for purposes of comparing to the wasm backend for deciding when to switch, i.e. that pass shouldn't make your job harder ;). Thanks @AndrewScheidecker . We can close both after #1502.. Hey @dcodeIO , do you have any interesting code with br_tables in it I could test this on? I'm curious how the heuristics do on code not from LLVM :). Thanks @dcodeIO! Ok, nothing there looks like it should be a problem for this type of heuristic. Of course we can revise it later as needed, but for now I was curious if there was something obvious I was missing after reading too many br_tables from llvm ;). What revision of binaryen is that? That error message appears to have been removed based on git, with a fix, and running current master I can't reproduce the failure on that input.. Ah heh we had a race condition :). Oops, fuzzer found I got a float optimization here wrong. It's not ok to change x * -1 to -x because if x is a nan, it will return x, not -x. Fixed.. I know we've been meaning to deprecate s2wasm in favor of o2wasm, but I'm not sure of the status there. @jgravelle-google @sbc100 ? What should we do with bugs in s2wasm?. The source of such things could be an LLVM phi like\n%op.0 = phi i32 [ 7, %if.then.i29 ], [ 7, %if.then ], [ 6, %freereg.exit ]\nwhere two out of the 3 incoming values are identical. We assign 7 to the variable twice (once in each code path) and sometimes one of the paths was empty aside from that assignment, so it was a singleton expression.. Hmm, I think we can optimize without such hints. Skimming that issue, I see sign-extend type stuff like x << 24 >> 24, which binaryen has a lot of optimizations for. If you find concrete stuff that looks like it should optimize but doesn't, let me know!. Looks good, thanks!. Reasonable question. I'd say that in theory the LLVM WebAssembly backend could do the optimizations Binaryen does, but in practice we do still need Binaryen very much. First, the goals of the projects are different:\n\nNot all compilers use LLVM, many compile directly to wasm (like Go, Cheerp, etc.). Binaryen can improve the output of all compilers to wasm, not just LLVM-using ones.\nThe LLVM wasm backend compiles LLVM IR to wasm, while Binaryen can also read wasm. That makes it convenient in Binaryen to build tools like ctor-eval, metadce, do things like Souper integration, etc.\n\nSecond, the practical optimizations are different as well:\n\nLLVM codegen takes much more memory and is much slower than Binaryen's optimizations, because of how the two are designed. For example, LLVM maintains use lists and so forth - those have big benefits, but they also take memory and time. LLVM is also single-threaded while Binaryen optimizes functions in parallel. This is \"just\" efficiency of the compiler itself, but it can be a big issue when optimizing very large wasm files, and optimizing such files is crucial for code size (whole-program dead code elimination and optimization really helps). Running all of Binaryen's optimizations on a big 10-20MB wasm file takes just seconds, so it can be run frequently as part of a build process.\nThe LLVM wasm backend's internal IRs are less close to wasm than Binaryen's IR is. As a result, some wasm optimizations are harder to do in LLVM, for example the LLVM wasm backend doesn't represent wasm if instructions, so it doesn't emit them and also doesn't do if-specific stuff. It also can't do optimizations like Binaryen's ctor-eval (Binaryen uses its internal wasm interpreter there), etc.. > why don't we make a tool that reads wasm into LLVM IR?\n\nThat might be worth doing! :) See also WAVM. But it would not make sense for some of the examples given, like metadce (LLVM IR is overkill) or ctor-eval (LLVM can't do that).\n\n\nThe LLVM wasm backend's internal IRs are less close to wasm than Binaryen's IR is.\n\nThat's mostly true for now, but for how long? We can represent multi-value in LLVM IR via SSA renaming, but how do we handle it in binaryen IR?\n\nYeah, this might change. And even right now Binaryen IR can't represent some stacky code, as another example.\nOverall my intention is to modify Binaryen IR as necessary to enable generating compact wasm. If something like stacky/multi-return don't allow significant new compactness, I think we just need to update the Binaryen wasm reader/writer code, and not change the IR.\nAbout multi-value, I don't know the answer yet. Possibly it justifies IR changes, but possibly not: For function returns it's not an issue, and for blocks and ifs my data from years ago suggested it was not likely to help much (I counted things like phis, and 1 was by far the most common, and that's already handled in wasm in block/if return values, which Binaryen utilizes).\nFor stacky code, I've been meaning to look into an additional optional IR for Binaryen for it. But I don't think I've seen clear data yet that justifies that effort.\n\n\nIt also can't do optimizations like Binaryen's ctor-eval\n\nIs there a fundamental limitation in LLVM that prevents this? Or is it just that no one has done the work?\n\nIt's somewhat awkward to fit into LLVM, I think. The natural place for such things is on the final executable format, to maximize the chance of the code being runnable, which means wasm (or asm.js for that matter) and not LLVM IR. And an interpreter for wasm seems like an odd thing to add to LLVM.\n(A full interpreter for LLVM IR could help, though, and that is work that in theory could be done.). Heh, I was just working on something related ;) if you do\n--flatten --dfo -O3 --ignore-implicit-traps\non the souper2 branch, you'll get\n(module\n (type $0 (func (param i32 i32) (result i32)))\n (export \"div16_internal\" (func $0))\n (func $0 (; 0 ;) (type $0) (param $0 i32) (param $1 i32) (result i32)\n  (local $2 i32)\n  (i32.add\n   (tee_local $2\n    (i32.div_s\n     (i32.shr_s\n      (i32.shl\n       (get_local $0)\n       (i32.const 16)\n      )\n      (i32.const 16)\n     )\n     (i32.shr_s\n      (i32.shl\n       (get_local $1)\n       (i32.const 16)\n      )\n      (i32.const 16)\n     )\n    )\n   )\n   (get_local $2)\n  )\n )\n)\nWhich looks like what we want here :)\nNote that you need --ignore-implicit-traps as otherwise the div might trap and so can't be removed. Also, those --flatten -dfo are much slower than the main -O3 etc. opts and are still a wip.\nWith that said, though, I wonder if the opposite ABI doesn't make more sense: for each function returning an i16, it may be received in many places. In other words for each return there are multiple more places where the returned value is received. So doing this on the return seems more compact than in each place the value might be received, unless i'm missing something.. That second example should be optimized by the dfo approach, eventually. It's reasonable to expect an optimizer to do that.\nBut given what you say about that ABI issue, it might be worth just writing a special binaryen pass for that. It could actually look at the functions being called to see which returns need to sign-extend (they end up used in operations where the sign actually matters). So no callers would sign-extend, and only returners that need it would do it, which hopefully is just a few. Not too hard to write such a pass, I think.. That would be a type of LTO-like optimization that is exactly what Binaryen should be good at, actually.. @dcodeIO ah, actually I misread your second example. It looks like it subtracts first, then does the sign-extend? That's trickier to optimize, in fact I don't see how it can be.\nMeanwhile I realized we have a local-cse pass that should be able to optimize the first case. Turns out it wasn't good enough though, so I did some rewriting in a branch to fix it, https://github.com/WebAssembly/binaryen/compare/localcse?expand=1 . lgtm, thanks!\nI think we also need to update the docs here? https://github.com/WebAssembly/binaryen/wiki/binaryen.js-API. Oh great, thanks again :). lgtm, thanks. restarted those CI jobs.. Great, thanks!. > implementFunctions should only contain functions that are accessible from outside the module. i.e. those that have been exported. There is no point in adding internal-only functions to this list as they won't be accessible from outside anyway.\nThis is not technically true in emscripten in general - we use implementedFunctions for some other things. However, it is possible none of those things matter for the wasm backend, although that surprises me. Looking in the code, the main relevant use seems to be\n\nA JS library function uses foo.\nfoo was compiled.\nsrc/jsifier.js will add foo to the list of exports from the wasm, so that the JS library function can access it.\n\nAn example of this is malloc being used from JS, but we export malloc by default so that works anyhow. \nI can't think of another example offhand, but there should be test suite coverage. If no tests failed for you, we can comment out that code (jsifier line 228) and run the complete asm2wasm test suite in all modes (including other and browser), it should find breakage.\n\nThis is especially imported with lld where the debug names are demanagled.\n\n:)\n. I pushed a commit to see what breaks, https://github.com/kripken/emscripten/tree/break\nSeeing the breakage might help understand the issue better, I don't remember all of it.... Yeah, I guess for wasm we can't export something from wasm that wasn't exported anyhow. When we see what breaks we'll see what that means I guess.. Interesting... nothing broke. I'll look into this - the commit history suggests we added a test when adding that code, hopefully that helps.. Ah yes, so what happens is we have the deps_info.json infrastructure, used in system_libs.py: if we know a JS library function will need a C function, we must link it in first of all. And at that time we also make sure it is exported. So that jsifier code is redundant, I'll fix that later.\nThe other place we use implementedFunctions is in showing \"unresolved symbol\" warnings - we do that in jsifier.js since at that point we know what C code was linked in (implementedFunctions) and what was provided by JS libraries. Looking in the test suite, this is checked in other, specifically other.test_warn_undefined (and also other.test_circular_libs). Does that pass with the wasm backend with this change?. Great, thanks for checking!. lgtm. Hmm, the current order according to wasm-traversal.cpp:337 is import > function contents (callImport) > table, which is different.\nIn general we didn't document a specific order, but it's possible passes depend on it.... Probably fine to do that (as long as it's tested).. It's true that removing the result would make this example work, but what would the new rules be for when to do so - how would that fit in the current typing rules? I'm not sure offhand how that could be done, and this is tricky stuff with many corner cases I'm afraid...\nIn general, if there isn't a simple fix for something like this, it may just be something we document as a text format difference between binaryen and wat - there are already a few in the list. While we need binary format support to be perfect - that's the point of binaryen :) - the text format is meant to represent our internal IR, which has been diverging from wasm. We may want to just stop claiming to support wat, and instead have our own byn text format as has been discussed before.. I believe the binary writer adds the extra unreachable after the loop. The reason is that Binaryen IR has an unreachable type for loops, but wasm binaries do not. To fix that, after it emits a loop that is unreachable it also emits an unreachable opcode, which ensures we are in an unreachable zone in the binary. And when reading wasm we do the opposite, in effect.\nIt's not clear how to fix this for the text format, though:\n\nA \"proper\" fix would be to remove the unreachable type from the IR. See previous discussions on wasm diverging from Binaryen after wasm became a stack machine and removed unreachable loops, blocks and ifs. The core issue, iirc, is that unreachability makes optimization more easy - you can replace an unreachable loop with a br, and know it is valid because it has the same type, while if the loop has the empty type then it's only clear from the outside context whether the replacement would be ok, which is messy.\nRename Binaryen's current text format \".byt\" (\"binaryen text\"), and add another input and output format, the .wat format. Then Binaryen would have three input/output formats, .wasm, .wat, .byt.\n. We could do that, but we'd also need to make changes in the text input code to handle that, and the bigger issue is that by making such changes the text format would no longer represent Binaryen IR as it currently does. And having a good way to print the internal IR is necessary for debugging and development. So we'd need to support two text formats, .byt and .wat as mentioned before.\n\nI'm not saying that's a bad idea, but it would take some work to do, and I'm not sure it's worth it. How important is it that binaryen can emit the wasm text format correctly?. I see, good point @dcodeIO \nSo, if emitting wasm text is important but reading it is not, then that's not too hard to do, we can make a variant of the --print pass, maybe --print-wat, and internally Print would have a parameter whether to conform to proper wat syntax.\nBefore going down that route, is there anyone else that does care about reading proper wat as well?. @binji \"it wouldn't be too hard to separate some of it out to slim down the library.\"\nYeah, we could make a wabt build with just the binary loading and text printing code included, perhaps? Might be as easy as only specifying those functions in the list of exported functions.\n. Hmm, for some reason the script special-cases wasm2asm and requires that the output file exist (same base name, suffix .2asm.js). We should probably remove that (lines 302-303). For this PR, you can either remove those 2 lines or create an empty file there to work around that.. Sorry, I'm not familiar with that code and it is indeed confusing.\nFor some reason it seems to want to put the test outputs in /test/ (we should probably fix that), so you need to create that file one directory above. And indeed that is where the .2asm.js tests are. Very odd.... So I must apologize again, but the code in this area really needs improvement. Now that I see how much I'll make time to read it and clean it up. It wants the test file under test/wasm2asm but the output file goes in the outer dir. And if you put the test file in the outer dir, it does a lot more with it. tl;dr to fix your test failures here, move just the test file, not the output, into test/wasm2asm.. Worked, thanks!\nAnd sorry again, those testing annoyances are really not how one's first PR should go in any project. I'll look into cleaning that up.. Thanks!\nThe existing rotate generator looks 32-bit specific, yeah - even though the assert at the top suggests it was intended to eventually do more. I don't have a strong opinion on extending that vs adding a new function for the 64-bit case (which seems sufficiently different to make a single function difficult). But the approach of generating helper functions makes sense, I think, if the inline expansion is large as it is here. (The optimizer can inline if it makes sense later on.)\nAnother thing to consider here is that instead of adding a new test, we can enable an existing spec test. I just merged in the helper PR to clean up wasm2asm testing, so this should be simpler now. Looks like the spec test with rotates is i64.wast, though, which contains a million other things. So maybe that doesn't make sense yet. However, you will need to merge master and have the test & output in /test/wasm2asm now.. Thanks!. Let me merge this in quickly as it helps 2 open PRs for wasm2asm.. lgtm, but please merge master and move the test output into test/wasm2asm (as the PR cleaning that up has landed).. Perfect, thanks!. Thanks!\n\nThe return double-wrapping is not necessary. It would be nice to fix that, but low priority probably.\nWe should probably do trunc and other non-asm.js things too. I expect we'll want to deviate from asm.js anyhow in order to do more interesting wasm things - like tables, GC, etc. eventually - so really we should be wasm2js and not wasm2asm.js. In theory an asm.js mode might make sense for speed, but in the long term that might not be important either (as VM optimizations change).\nFor things like nearest that don't have a JS implementation, we'll need helper functions, yeah. Not sure what you mean by \"there's no Math.round\" though?. Cool, let me know if you get stuck on something, maybe I can help.. Nice work!\n\nYeah, seems like we can't expect all NaN tests to pass due to that canonicalization issue. In theory we could have a mode that stores floats in memory all the time, but that sounds very slow and painful.\nSo yeah, we can't just enable that spec test, so let's copy that modified test into the wasm2asm folder.. Do these pass for you locally? I seem to see the same error travis complains about.. What was the problem you found?. I see, thanks.\nThere seems to be overlap between this and #1554. Is one based on top of the other / contain the other? In which order should I read them?. Will land once CI finishes.. lgtm, but see the appveyor errors - I think we want uints there.\nAbout merging passes, yeah, something to think about. For i64-to-i32, I'd say keep it separate from this for modularity. But if there was another opcode very similar to this, maybe we'd want to merge that with this.. This probably needs to merge master after the other PR landed.. Looks like one of the assert tests fails.. If updating node on CI is easy enough, that sounds best.. Great!. Landing quickly as this fixes current breakage on the wasm waterfall.. Thanks @yurydelendik! Added a test like that.\nSource map information is passed through, but it doesn't look quite right. For example the annotation on add shows up in another function, ret. Maybe that bug isn't caused by this PR though, which just moved code around? Or maybe that test is wrong somehow?. Oh, also, I see these warnings, do you know what they mean?\n```\n$bin/wasm-as test/debugInfo.fromasm --source-map=a.map -o a.wasm\n$bin/wasm-opt a.wasm --input-source-map=a.map -o b.wasm --output-source-map=b.map\nskipping debug location info for 138\nskipping debug location info for 153\nskipping debug location info for 191\nskipping debug location info for 223\n$bin/wasm-dis b.wasm --source-map=b.map -o c.wast\nskipping debug location info for 153\nskipping debug location info for 161\nskipping debug location info for 191\nskipping debug location info for 191\nskipping debug location info for 271\n```\n. Let's merge this in for now as the refactoring here should have only upsides, and this has been open for a while after being approved.\nHowever, the test results do look like they show some underlying problem in our source maps support, I opened #1591 so we don't forget that.. @jgravelle-google I thought wasm-linker was used to link in the .a files with libm - stuff that is necessary but was not linked in, as codegen created the dependency. In that sense it sounds just like what we need here, which is to supply a few runtime functions that we find out are needed at a late stage.\nBut maybe it's overkill to use that mechanism, yeah. Were we hoping to just remove it together with s2wasm?. Ok, sounds good about not using wasm-linker then, and just copying functions from the wast.\n@alexcrichton what do you think about my question above regarding splitting this up?. Well, it's a matter of how much discussion is needed. I don't mind many commits in one PR if they are all obvious and just need rubber-stamping. It's many commits + detailed discussion in a single PR that ends up messy.\nThe first commit here does require detailed discussion (maybe mostly done by now?), and I'm not sure of the others - so your call.. Yeah, skimming them they do seem mostly straightforward. So maybe one for the big initial stuff here, then one for all the rest, as you suggested?. lgtm, thanks. There are some big open questions here about optimization but we have to leave them for later.. I hit this again now. At least I remembered how to figure it out ;)\ncc @sbc100, I think you set up the current flake8 stuff?. Ah I should have been more clear, that's what the fuzzing at the end is meant to be: the binaryen fuzzer emits random programs and we'd run them in multiple VMs + through wasm2js, checking for any difference in the output.. Oh, yes, definitely :). Agreed that the order doesn't need to be what was listed above. Once we have enough to run the fuzzer, no reason not to do that immediately, etc.\nRegarding emitting a module or not, one thought I had was not to emit a wasm or ES6 module for just the wasm, but rather emit a complete polyfill for wasm itself. That is, define the WebAssembly object and polyfills of its compilation methods etc. This seems the easiest for integrating into code that loads and uses a module (like for emscripten output), but maybe not for other use cases?. @binji Agreed. So maybe wasm2js could compile into something that looks like a wasm Module, and we'd also have a separate JS file which is a polyfill for the WebAssembly object + APIs, and it would know how to use those objects, and eventually also how to use normal wasm objects and even link them.. When I say \"module-like\" I actually mean more \"binary-like\", in that it would be an input to a WebAssembly.compile* API.. Thinking about optimization in the PRs, it may still be useful to keep an \"inner\" asm.js module that validates. That would let us run an asm.js optimizer on it. That would mean leaving the other non-asm.js code on the outside. Not sure if it's practical, though.\nIf we can't do that, then we need to figure out something else for optimization. Closure compiler and others can do a good job on general code shrinking but may not be as good as an asm.js optimizer for what we emit here. . Thanks, this does look clearer to me now! Although, I'm not sure what you mean by \"duplicating intrinsics\" so I must be missing the important part?. Thanks @alexcrichton for all the work here!. It's an expression representing a wasm \"host\" op, that is, one of the special operations that connect to the host environment. HostOp in wasm.h has a list of the possible operations, which are page_size, current_memory, grow_memory, has_feature. (grow_memory is probably the only one that really matters at this point.)\nGlad to hear about Crystal bindings, btw :). Looks like nameOperand is used for hasfeature (I found that in Print.cpp).\nFor examples of grow_memory etc, you can search in the wasm spec test suite under test/ in https://github.com/WebAssembly/spec The rest of the spec repo should have details on what the host operations mean, but in my experience reading the tests is usually easier.. It depends. As I said, has_feature uses it. If that is necessary, then name is. But I'm not sure if it is.. Was this fixed by that PR?. Also added a line to customize how we exit on fatal errors - instead of letting node call process.exit which exits silently, show a stack trace.. I finally found time to rebase this and fix the test issue. The problem there was that the -g builds on the bots had assertions enabled, which cluttered the output. I removed assertions by default there.. I found a way to work around the test issue, by just disabling the atexit() assertion messages in binaryen.js, instead of disabling all assertions in non-optimized builds.. The builds depend on the compiler too, the emsdk, yeah.\nCurrently we build a debug version on travis and run tests on that, to prevent regressions. A release build takes quite some time but should also be doable in the 50 minutes travis allows us, so perhaps we could set it to publish to github releases. I'm not really sure how github releasees work, but if new tags (for new versions) could trigger such builds being added, that sounds good.. Thanks @xtuc , this sounds doable then.. @dcodeIO how do you handle builds for binaryen.js? In this issue we're considering stopping the bundling in the binaryen repo.. Oh cool! So maybe we can do something like this:\n\nPoint people that want builds to npm. Maybe most people are looking there anyhow :)\nKeep the current debug build tests we have (that is, do a quick debug build of binaryen.js and verify it).\nThe one tricky bit is the rest of the tests, that is, that tested the bundled optimized build. The value there is that (rarely) debug builds miss something. The problem is that if a PR here updates the code, there will not be an optimized build for that on npm. Maybe it's just find to drop this test mode, I am thinking.\nAbout wasm.js, we currently don't test it here actually, but emscripten does. But over there, we can get a tagged build from npm, I think. (Alternatively, we could do a quick debug build and test with that.). @dcodeIO makes sense, yeah, improving the buildbots testing could offset removing tests here.\n\nAnother thing I realized meanwhile is that wasm.js can go away once we finish wasm2js - that is meant to be a drop-in replacement for wasm after all. So we'll need to figure out testing for that anyhow, and can remove wasm.js in the meanwhile.. Is there a way to link directly to binaryen.js builds on npm? Maybe there's an obvious place but I can't seem to find it. I think that would be useful for people that just want the binaryen.js build, without npm (might not be many people, but still).. Thanks for the links @dcodeIO !\nI opened #1609 to stop bundling binaryen.js, and point to those links.\nBtw, do people rely on rawgit and unpkg? At first glance they don't seem to be official products of github or npm, whose content they serve.. And I guess the same question for @xtuc about bundle.run? Just curious how mainstream all these services are.... I see, thanks @xtuc & @dcodeIO \nThat binaryen.js CI error looks like\nerror: failure to process js library \"library.js\": Missing C define TIME_UTC! If you just added it to struct_info.json, you need to ./emcc --clear-cache\nShould be fixed by clearing the cache. I assume the bot uses latest incoming? If it does, might be worth clearing the cache on each run (but will add some time to building libc etc.). Or, getting the latest tagged version would avoid that issue too.. The binaries work on 16.04, this is what we use for emscripten CI on travis: https://github.com/kripken/emscripten/blob/incoming/Dockerfile Also works on circle (also using 16.04).. Thanks @sbc100 !. I'm not sure how to use that playground link - does it have the passes in there somehow? Can I run them there?\nOverall, running the optimizing-inlining pass should do what you want. inlining just inlines, and you need to run opts yourself after, but optimizing-inlining will run function-level opts after inlining into a function, https://github.com/WebAssembly/binaryen/blob/master/src/passes/Inlining.cpp#L365 and those opts should perform constant simplification.\nThat pass is also run by default in -O2 and above, https://github.com/WebAssembly/binaryen/blob/master/src/passes/pass.cpp#L190\nIf that doesn't work right for you, the simplest thing for me to debug would be a .wast file plus the binaryen passes to run on it (either in wasm-opt on the commandline, or binaryen.js commands).\n. I see, thanks.\nSo, first thing, it looks like AssemblyScript is doing the inlining. When I disable opts, I still see the inlining happen.\nSecond, running --precompute-propagate -O3 does optimize it the way you want.\nSo basically, if binaryen did the inlining, it would have run precompute-propagate for you (see first link above). When not inlining, binaryen does run that pass, but late. Perhaps we should add it early as well, but the key information here, that we inlined, is not given to the binaryen optimizer. Therefore, since AssemblyScript does its own inlining, and so it knows about it, I'd recommend it also running precompute-propagate before running the main opts.. @dcodeIO Fair point, yeah, it could just have been written manually. My perspective was skewed because LLVM would have done it, so I didn't realize that, I guess...\nFix in #1581. This passes the emscripten test suite, however, it does make SQLite -O3 significantly slower, the binaryen optimizations phase takes around 30% more time. That's a smaller fraction of the total build time (LLVM opts take a while on SQLite, it's a very difficult testcase), around 15%. And this is a much smaller effect on other codebases. But perhaps we should look into making that pass faster before landing this.. Doesn't seem to be a quick fix there. Anyhow, not sure it's worth holding this general improvement back just for sqlite, which is a pretty rare case, and the regression there is not fatal.. Interesting. I think what's going on here is that the dynamic linking conventions specify that that section needs to be first:\nhttps://github.com/WebAssembly/tool-conventions/blob/master/DynamicLinking.md#the-dylink-section\nand emscripten emits it first, but none of the tools preserve that. It seems like we could either fix the tools, or change the spec to not require it to be first. Changing the spec is probably better, since the reason we required it to be first was make it easy to parse - but wasm added a .customSections API that lets the JS loading code avoid needing to parse the binary.\nSo what I'd recommend here is updating emscripten's JS loading code to use that new API (in src/support.js; can search for that \"must be first\" error message). After doing so, we can just remove the requirement to be first from the spec document.. 1.38.3 upgraded LLVM, so if this was still ok on 1.38.2, then this is caused by a change in upstream LLVM it seems.\nI don't have a windows machine to debug on myself, but this sounds like a debug info issue, so the relevant place might be JSBackend.cpp, specifically emitDebugInfo(), https://github.com/kripken/emscripten-fastcomp/blob/cd96346a22e2bcff45f8605a1798ce59f9068029/lib/Target/JSBackend/JSBackend.cpp#L762 Looks like we never added any escaping there, and just trusted LLVM's.. We don't currently have a pass to do that. It would be interesting to experiment with one, though!\nThe main problem though is stuff on the stack. Converting a big function into separate smaller functions means that any locals need to be stored in linear memory or passed around as extra parameters. That overhead might be worse than the switch overhead, as the switch might not be that bad - it's not a computed goto, but it is a jump table in most VMs.\nIf you don't have stuff on the stack, then this is more likely to help. However, even so, wasm function pointer calls may not be faster than a jump table. Actually the jump table may be better in general, I am told by @sunfishcode . Yeah, in wasm br_table is always dense and simple, and I think VMs always implement it that way - unlike switches in JS where, as you said, browsers had all sorts of heuristics and deopts.\nWould be good to see those measurements on wasm too - some slowdown compared to native is expected, but hopefully not that much.. When I compile that link with -O0, then run binaryen wasm-opt -O3 on that, I get\n(func $foo3 (; 0 ;) (type $3) (param $0 i64) (result i64)\n  (local $1 i64)\n  (i64.add\n   (tee_local $1\n    (i64.shl\n     (get_local $0)\n     (i64.const 1)\n    )\n   )\n   (i64.const 0)\n  )\n )\nwhich looks almost optimal to me (the tee can be removed, which another -O3 does, which we may want to fix).\nIs it possible you're using an older binaryen.js, before recent optimization improvements?. (I think foo3 is the right function to look at in that link - I don't see a test there?). Thanks, now I see test and also I see the problem.\nThat type of code requires flattening for the optimizer to work optimally. When I run --flatten -O3 I get\n(module\n (type $0 (func (param i64) (result i64)))\n (memory $0 1)\n (export \"test\" (func $main/test))\n (export \"expected\" (func $main/test))\n (export \"memory\" (memory $0))\n (func $main/test (; 0 ;) (type $0) (param $0 i64) (result i64)\n  (i64.add\n   (i64.shl\n    (get_local $0)\n    (i64.const 1)\n   )\n   (i64.shr_u\n    (get_local $0)\n    (i64.const 63)\n   )\n  )\n )\n)\nwhich looks optimal, it propagated everything and then merged test and expected.\nIn general, running flatten adds significant overhead, but it can definitely be worth it as you can see here. I've also improve flatten quite a bit recently and it should be ready for general use now. So perhaps we should add an -O4 which does --flatten -O3, what do you think?. @dcodeIO before. I really should write a blogpost about the whole optimizer design, that would explain why. meanwhile though, I'll can have -O4 ready for use soon (maybe today), including local-cse (that fixes https://github.com/WebAssembly/binaryen/issues/1521#issuecomment-385485525 ).. -O4 landed, which fully optimizes this, closing.. @dcodeIO You can pass --optimize-level=4 --shrink-level=2 for example to get something like -Oz plus the extra stuff here - and yeah, that should have benefits over -Oz (I didn't measure yet, though).\nOr, you could manually run --flatten --local-cse -Oz, however, we'll probably add more passes after --local-cse eventually, and using --optimize-level=4 would get them without the user needing to remember to add them.. Interesting point. Maybe the opposite, --llvm that implies LLVM optimized the code already would make more sense, as there's probably a lot of variety in non-LLVM compilers, and just one LLVM? However, that does seem like a pretty specific flag.... Yeah, the code already being fairly optimized is an important part of this. But maybe that's captured by the difference between -O3 and -O4 already, though - higher levels make sense for code that needs more optimization work?\nAnother issue aside from being fairly optimized is how \"flat\" the code is - does it use block and if return values, etc. Flattening helps there. That's something LLVM doesn't do now, but might eventually.\nOverall, I don't care much about the names of options here. We can add more if it helps usability.. @dcodeIO I don't understand, sorry. What is \"other toolchain\"?. I see. Well, overall I'm not sure what's best here, we just need to do more testing. On the one hand, LLVM should not need -O4's flattening, and people don't use levels above -O3 in practice anyhow, so it seemed appropriate to add only in binaryen. But on the other hand, if we test enough maybe we will find cases where it helps LLVM (for example, if binaryen inlines, the code has not been fully optimized by LLVM, so more stuff for us to do).\nAn option might be --flat-opts which would do flattening + flat opts, and then --flat-opts -O3 would  be identical to -O4. -O4 still seems like a nice shorthand though imo.. The Intrinsics stuff was a missing file. Should be fixed in #1600, and also I made it error on undefined symbols in the build, so hopefully we never regress this stuff again :)\nThe other errors about bad_function are, I suspect, from a mismatch with the emcc sdk and the libraries. Make sure you're using latest emcc, and emcc --clear-cache so it rebuilds libc++ which is where those symbols are.. Confirmed to also work by @dcodeIO . Interesting, I thought VMs would be doing this kind of thing. I see this on firefox (on a slow machine):\ndivision by uint64 constant 1e10 (mulh/shift): 2268ms\ndivision by uint64 constant 1e10 (normal): 1260ms\nwhich looks like the opposite of your results.\ncc @sunfishcode - should VMs or binaryen do this, in your opinion?. (In my opinion it would be great if VMs did it - because it lets us ship smaller wasm binaries.). The CI errors might be that seen initialization bug, but I'm not sure.. About windows, that could be a determinism bug - maybe we depend on how linux (where we test) does hashing and sorting. We did fix a bunch of such bugs between different linux c++ STLs, so I'm not aware of any open ones, but I've not tested on windows.. SQLite is a good testcase, yeah. It's also somewhat pathological, though - rare to see such a large interpreter loop. Worth testing, in addition, on something more common like Poppler and Bullet (both large real-world codebases).. Btw, I noticed Binaryen -O3 is very slow on this prolog VM: http://demos.rlaanemets.com/swi-prolog-wasm/dist/swipl-web.wasm I suspect it's also a big interpreter loop like in SQLite, but I didn't investigate in depth. Might be interesting to measure on that as well.. Thanks @vloppin ! Looks good.\n. Thanks!\nA test would be good, yeah. Can maybe add one inside tests/unit.wast.\nHowever, should we not just throw a ParseError on such inputs? Or is it valid to read them as -1?. Sounds good, yes, can add a test to the validator subdir. Looks like you also need to add a line or two for it in run_validator_tests() in check.py.. Thanks @vloppin!\nYeah, more tests would be nice, if possible later.\nFair point about reporting multiple errors. So far we just throw on the first. In text maybe it's feasible to continue after an error - the main focus has been on the wasm binary format, where after any error it's likely nothing else will make sense. But if it's practical to add for text, that could be nice.. Any thoughts on this?\n@dcodeIO maybe?. Cool, thanks for the update @vloppin!. Great, thanks @vloppin!\nI did some more benchmarking now and see only improvements :) Merging.. Oh, oops, that's my fault - it's actually because of https://github.com/kripken/emscripten/pull/6756 , we no longer allow hacks like modifying Module['print'] dynamically. Fix in #1614\nI think we didn't notice it on CI here since it isn't in a tagged version yet - your bot runs incoming, I assume?. Should be fixed now with that PR just merged.. The edit looks like it should work, yeah. Another option is to add a layer of indirection, to define Module.print during startup as a function like this, for example:\nModule['print'] = function(x) { Module['flexiblePrint'](x) };\nModule['flexiblePrint'] = .. ; // and you can modify this later at any time. Exactly, yeah, you can define it, just not change it later (so if you need that extra flexibility, you need to add it yourself).. I replied about the warning in the other issue you filed, https://github.com/kripken/emscripten/issues/6837 In the future, please don't open duplicate issues even in separate repos - unless there's no response for a long time in one ;)\nAbout the second question here: dlopen loads a file from the filesystem, so the shared library should just be a normal file packaged there. Docs for that are here: http://kripken.github.io/emscripten-site/docs/porting/files/packaging_files.html. Good suggestion, I think we should do this. Maybe the only question is when - if optimizing for size, we could check if it helps or not, but even if it helps binary size it may affect gzip size in a surprising way, I never found time to investigate what's going on with inlining local constants, see https://github.com/WebAssembly/binaryen/blob/e601522b1e15e5a2a96578244faca1648021fb2d/src/passes/ConstHoisting.cpp#L18\nOn the other hand, often inlining a constant would help other optimizations later, so maybe it's worth it even then. \nUnless someone else wants to implement this, I can get to it later this week.. Implemented by that PR. Leaving open though as it might be interesting to measure the effects here, and see if we want to gate this on particular optimization options, as a future refinement.. Thanks @dcodeIO!. Yeah, actually the --print-stack-ir pass almost does what you want there. The differences are\n\nIt doesn't print the immediate values of an instruction, so it prints load instead of load offset=4 etc. We could refactor the --print pass to move the immediate value printing into helper functions (so visitLoad would call printLoadContents or such) etc., then call that from the stack IR printing code too.\nIt doesn't add indentation yet. Trivial to add.\nIt prints a numeric index for each instruction. I found that nice for debugging, but we can remove it.\n\nSo if proper stack IR text output would be useful, that should be easy to do..  * Added extra checks in pass-debug mode, to verify that if stack IR should have been thrown out, it was. This should help avoid any confusion with the IR being invalid.\n * Added a comment about the possible future of stack IR as the main IR, depending on optimization results, following some discussion earlier today.. (Added a few commits for fuzzer issues.). In the stack4 branch I did a quick experiment with refactoring the printing code to emit valid wat text when we print stack IR. This turned out to be surprisingly easy, and I did some fuzzing using wabt to read those wat files, and can't find any bugs there. I think that is further support for the stack representation being correct, and also also that this approach can get us quickly to being able to emit valid wat (which has been requested, see e.g. https://github.com/AssemblyScript/assemblyscript/issues/179#issuecomment-408302345 ).. Yeah, we should make sure stuff like that is well-optimized. I think the main mechanism is inlining - small functions like that should be inlined, after which precompute etc. are run, which should give the effect you want? If so then the main thing here would be to improve our inlining rules.. Actually, maybe there is more than just improving the existing inlining rules. Maybe something like the inliner making its decisions using precompute, maybe even running it on potential locations to see if it's worth it.... @MaxGraey Aside from the recursion, I think this could be handled by inlining (possibly with improvements)? The recursion sounds like a harder problem. I'm not sure offhand if that makes more sense in a general-purpose optimizer like binaryen or in the language's compiler. One argument for putting it in the language is that it may have a concept of constexpr, which binaryen and wasm don't (so in binaryen we'd need to try to find out which functions can be recursed into like this).\n(edit: for comparison, I believe the c++ frontend compiler does constexpr computation, not the LLVM optimizer, although I could be wrong). I'm not sure about LLVM, but I don't think there is a constant/pure attribute for functions, http://llvm.org/docs/LangRef.html#function-attributes\nI think it would make sense to start with the non-recursive case, see that we handle that well on examples, improving the inliner as necessary.. @dcodeIO I see what you mean. However, structurally, the precompute pass is function-parallel, which means we run on each function separately, without looking at others. In particular function-parallel passes are safe to run on a function before we've even defined the functions it calls.\nBut you're right that this could fit there - we may want to add a new pass like \"precompute-calls\". However, I'd prefer to first try to see if we can achieve what we want using inlining first, until we get some testcases that inlining can't handle.. Interesting, which compiler do you see a warning on?\nI guess those could be size_t as they are the size of the container there. However, we do have the assumption that the number of total wasm \"things\" fits in Index, and the number of blocks in those containers is bounded by that. . Cool, thanks, merging.. Nice, thanks @axic!. We do already support this optimization for unsigned remainder (rem_u). Is this also true for the signed case? I'm not sure offhand.. Good question, yeah. We should do something. I wonder if just running the --print-stack-ir pass (and capturing stdout) is enough for JS, for now. The reason it might make sense to not add a new C API is that there is some uncertainty here - if we add a proper stacky ir reader, so that we have both a reader and a writer of valid .wat, then maybe we should switch the default reading and writing to .wat format (and if so, then we wouldn't need a new C API). Not sure...\n. Looks like no concerns here, merging.. Thanks @seshness for the great testcase!\nI looked into this. What is going on is that enabling EMULATE_FUNCTION_POINTER_CASTS turns off wasm-only mode. wasm without wasm-only mode means that we emit valid asm.js code, then convert it to wasm. And the problem here is that that asm.js code assumes that the code has asm.js semantics - that's why the js trap mode fixes things.\nOne solution here is to force the js trap mode when not in wasm-only mode. That does add significant overhead, though. Alternatively, we could make this conversion not assume the js trap mode. I'll look into that more, but not sure how easy it would be.. Looking into this some more, there isn't an easy fix. A complicated one is possible, but given this is for non-wasm-only mode, which is less important, and that both wasm-only and non-wasm-only modes will be deprecated anyhow once the LLVM wasm backend is the default, I'm not sure this is worth focusing on.\nInstead, I'd recommend we document that the js trap mode is recommended when in non-wasm-only mode. Maybe we should even suggest it by the compiler if it's not set?. > Will the LLVM wasm backend support, or even need, something like EMULATE_FUNCTION_POINTER_CASTS?\nYes. Wasm just doesn't naturally support a call with the wrong number of arguments, or wrong types. So some emulation must be done, regardless of the backend. The same option should work with both backends.\n\nis there a way to isolate the effect of EMULATE_FUNCTION_POINTER_CASTS\n\nNot easily. However, perhaps with wasm object files, you could compile python into one wasm, run the binaryen pass for emulation there, and compile the rest of the code to another wasm where you don't run it. I suspect we'd need to improve that pass, though, as right now it assumes all indirect calls use the same ABI - not sure offhand how feasible that would be.\nAre you seeing a lot of overhead from this?. Yeah, there isn't a commandline flag for those things, but you can edit src/tools/fuzzing.h and adjust whether to emit atomics (emitAtomics), as well as other things.\nIt would be nice to add commandline options for them all, if someone has the time.. I think we are waiting on the LLVM wasm backend to get SIMD support first. While the asm.js backend has SIMD support, that backend will be deprecated eventually, so it doesn't make sense to do work on SIMD there.\nHowever, we could do the Binaryen work in parallel to the wasm backend, in principle.. Yes, with the binaryen.js port, you can generate programs in Binaryen IR and compile them to wasm, all in JS. See for example this code sample from the test suite: https://github.com/WebAssembly/binaryen/blob/master/test/binaryen.js/hello-world.js\nIf you want to write the programs in C, though, then you need to compile a frontend compiler as well. That's a lot larger, but also an option, see this port: https://github.com/tbfleming/cib. Thanks @jayphelps!. Looks like no concerns, landing.\nAlso I'm working on a blogpost about IR stuff in Binaryen, which will document how this fits in there.. That stuff might make more sense in a specific post or paper about the Binaryen/Souper work. Not sure when that will happen, but hopefully soon.. Also verified that the binaryen* and other tests pass with this change, plus some fuzzing.. The .wast at least looks correct, with\n;;@ a.cpp:5:0\n  (return\n   (i32.const 0)\n  )\n(5 is indeed the line with the return). So something might be going wrong in the later offset computation.\ncc @yurydelendik . Good points about the name. Yeah, DeadArgumentElimination definitely sounds better. Regarding DAE being separate from intraprocedural const propagation, fair point, but for efficiency reasons it's nice to have a single pass do both (avoids doing the heavy scanning operation more than once), so I think it'd be nice to keep it as one, but with a better name.\nThinking about the name IPCP made me realize that we also want to propagate return values, which is super-simple to add to this in a followup. So maybe we can find a good name for a pass that does both IPCP (arguments + return) and DAE. Maybe ICPO (intraprocedural constant optimizations)? Or maybe DAE is more familiar?\n. @MaxGraey I intend to, yeah, it just hasn't been high priority. I could try to get to it sooner, though - have you seen cases where it would help?. @MaxGraey Agreed, yeah. There are some tricky details in that example, though - unless all the calls are inlined (which seems unlikely given $~lib/array/Array<Vec3>#__get is not tiny; the other call, $~lib/array/Array<Vec3>#get:length, does appear to get inlined as expected), then local licm by itself wouldn't be enough, it would also need to be aware that the calls do not modify memory (or if they do, some sort of aliasing guarantees would be needed, which is much more complex).\nAlternatively, optimizing that at the AssemblyScript level could be more direct, since you know a lot more at that language level, you presumably know the inputs do not alias (I think?), etc.\nAnyhow, I do intend to add licm, and I can try to get to it soon, but just mentioning that it won't automatically optimize testcases like that without extra work - naively, we must assume a call can do things that invalidate licm.. Any objections to landing this, with the named changed to DeadArgumentElimination as discussed above?\n@MaxGraey I think I'm mostly done with writing an licm pass, just doing some fuzzing now (which might find I'm not done ;). Interesting, I'll take a look.. Great, thanks! Looks good aside from two tiny comments above, and also I wanted to ask where memasmFunc etc. come from - seems like an odd name, why isn't it just mem?. Sounds good, thanks! lgtm. Looks like some test failures though, maybe need to run the test output updater?. Hmm, sorry about this, looks like those failing tests are recent breakage on master, and unrelated to this PR. But this PR is good to land as soon as we figure that out.. Master should be fixed now - can you please merge it to here?. All green, merging.. It's not quite symmetrical - asm2wasm does actually translate asm.js, and not arbitrary JS. So I think it's ok to leave the current name.. Otherwise, we have a FeatureSet concept at the top of wasm.h, currently with a flag for atomics. Not sure if we intend to add a flag for every new feature, or if mutable global imports in particular - @dschuff, thoughts?\nOther things we'll need here eventually:\n\nwasm-interpreter.h support.\nTests.\nFuzzer support.\nOptimizer support, if we decide it's worth it.. Oh, and about tests: auto_update_tests.py runs the tests and updates their outputs. So you can add a test input, run that script, and then git add and commit the output. Then check.py will check that output is the same when it is run.\n\nFor this feature, we might want to add the spec tests, but we haven't in a while and I'm not sure it's worth the effort. Otherwise, can add test/mutable-global.wast with some code, and then the test suite will convert it to binary and back, so if you run the auto script it will generate an output like test/mutable-global.wast.fromBinary or something like that.. > however I needed to update the testsuite/spec files to pick up mutual global support and in doing so it opened a big old can of worms with incompatibilities\nAh yes, I was worried about that. It might not be worth the effort - I think it would be reasonable instead to just get the relevant mutable global tests directly. Specifically, we can replace the git submodule with just checked-in files (since we've diverged from upstream anyhow) of the current state, then add that one file (assuming it's in a new file).. I agree, this looks like it should be fixed.\nWe don't have a strong policy about breaking changes in the C API. I think it's ok to do for something like this (where there isn't a reasonable alternative), but we should start a Changelog document (like say emscripten has) and mention it there so that people upgrading can easily get a list of breaking changes.. I'm not sure about the example - is it not ok to simply quote that string, which seems to have no \" or \\s? Is the issue that right now we don't quote or parse quotes in the call instructions to a function with a weird name? That is, it seems like in your example, we could write/read this text:\n(func \"$core::ptr::drop_in_place::ha8f9534d58f8a1fd (.llvm.3277592684094598524)\"\n  ..\n)\n(func $caller-of-that\n  (call \"$core::ptr::drop_in_place::ha8f9534d58f8a1fd (.llvm.3277592684094598524)\")\n)\nIf so, then this seems more like an s-expression parsing/emitting bug than binary format? However, it seems like (func \"..\") has a meaning actually, to export it, so perhaps that's not good?\n. For testing, I'd add a weirdText.wast and weirdBinary.wasm in test/, and run ./auto_update_tests.py - that will generate outputs, which include reading and read-writing.\nedit: actually the basename without extension needs to be different between those 2.. Talking on IRC, the approach here seems necessary as (call \"quoted\") is not valid wat, so sounds good.. Makes sense, this PR lgtm, and we can see about other escaping issues in the text format etc. later.. Thanks, looks like the test outputs need to be updated now though.\nAlso please rename tests/complexNames.wasm => tests/complexBinaryNames.wasm and tests/complexNames.wast => tests/complexTextNames.wast, that way it will be clearer which test output is which, as I was trying to say before (sorry if I wasn't clear).. Perfect, thanks @yurydelendik! Last thing, sorry, we had some breakage on master - it's fixed now, can you please merge it in here, so we can see that tests pass?. Thanks @yurydelendik!. Looks like no concerns here, merging.. Sounds good. Yeah, it would be simpler to just have a list of functions and globals, and info inside them saying if they are imports or not.\nOne minor thing to consider here is that unifying Call and CallImport may have implications for the optimizer. Specifically, Binaryen lets you optimize a function by itself (before the module is complete), and having separate Call/CallImport nodes meant that we knew the difference at that time. I don't think there's an actual problem to make this change, but wanted to point it out since I might be missing something.. It's a little subtle - parallel passes are allowed to read global state except for functions. The rationale is that you build the other global state quickly, then start to add functions, and optimize while you add them, so checking the list of functions is the only thing changing and that must not be read.\nThinking more on that, a unified list of functions and function imports does imply that we can't check that list in a parallel pass - so we would actually lose that information (the frontend might know, but can't encode that in the single call node). I suppose we could save it in a data structure on the side. In any case, so far I can't think of a concrete reason we'd actually need that information.\n. Looks like the test failure is in the JS API code - the kitchen sink test fails on [wasm-validator error in module] unexpected false: segment name should be valid, so perhaps the name isn't being passed through properly.. Great, thanks!\nBtw, I'm not opposed to adding new functions like that - just I was surprised it was here, I thought I'd missed something. Can discuss that in a separate issue if you want.. Looks good on travis, and looks good to me too, thanks! But would be good to get confirmation from @pepyakin about the question above?. Thanks @pepyakin! Ok, merging this. The check.py failure looks like something MacOS-specific that is separate from this, that we should an open an issue for.. Personally I don't think it's important for us to support the old names - I think wabt is what most people use for reading wat files, so makes more sense there, while here our text parsing isn't spec-compliant for other reasons anyhow.. About the spec tests, as mentioned in the other PR, I'd be fine to replace the git submodule with just a directory of the files in their current state, then modify them for changes like this. (For the same reason as not supporting the old notation - our text format kind of diverged anyhow; may make sense one day to harmonize them, but really we are focused on the binary format here, and just use spec tests for test purposes.). >  What I'm gonna do is comment out the ones that binaryen does not support, with a comment--sound good?\nYeah, sounds good.\nAnd yeah, you're right about that example - it's pretty weird I think that in wat format you can write (return) or (call) and it uses operands from before. It's basically there for backwards compatibility due to how wasm used to not be a stack machine. Anyhow, yeah, binaryen parses only pure s-expressions, so it is expected that weird stuff like that will parse differently/wrongly.. Do you see the failure locally too?\nIn the past I saw an odd failure in those tests that was fixed by upgrading node. But likely unrelated.\nIt might be best to do a separate PR for \"flattening\" the spec tests, starting with changing nothing but removing the submodule. Then the PR for renaming memory operations would be a lot smaller (just the actual renaming + a few spec test changes) and we could be sure it isn't something that went wrong with the spec test changes.. >  I guess this is the only test which covers this feature, which suggests maybe it should move to core?\nProbably true, yeah - I think we put it there only because of temporary convenience, but core would make more sense.. I think this broke some tests on master currently,\nhttps://api.travis-ci.org/v3/job/422255811/log.txt\nMaybe the lld tests need updating?. Thanks, lgtm.. Looks green, merging.. cc @MaxGraey . Fuzzing didn't find anything new, so I think this is pretty stable now.\nI did see that it can increase code size on fuzz testcases (and, more rarely, on real inputs) due to stuff like this:\n(loop\n  (set_local $x (i32.const 1))\n  ..\n)\n=>\n(set_local $x (i32.const 1))\n(loop\n  ..\n)\nFor a const or a get_local, such an assignment to a local is both very cheap (a copy to another local may be optimized out later), and moving it out may prevent other optimizations (since we have no pass that tries to move code back in to a loop edit well, not by default, precompute-propagate etc. would do it, but are only run on high opt levels). So I made the pass not move such trivial code (sets/tees of consts or gets).. @MaxGraey I think we need to do some investigation before deciding where - did you measure it in both locations?\nMy guess is that we need to run it early, as you said, and in particular that we need to run precompute-propagate (to propagate constants) as well as the standard optimizations after it. But I didn't measure it carefully yet.\n. Doing some quick tests, licm doesn't always help code size (even when done early). But I was looking on fuzz testcases, which is not great - we should look at real-world code.. @MaxGraey I'm not sure what to look for in that first link? How can I tell which passes it runs when I click \"Build\"?\nNote that if you run flatten, you should run all normal opts later. --flatten -O3 for example.\nMeanwhile in my testing, I think it's expected that licm may increase code size. It can move something out of a loop that then requires saving it to a local and loading it, in particular - so it's faster but more verbose. I think maybe the right place is to do it early, but not when optimizing for size (-Os, --shrink-level, etc.). The second output looks like it's not fully optimized - the nops should definitely not be there. Maybe something is going wrong in those links and it's not running the proper opts? Would be good to get a testcase that reproduces in the shell, where it's easy to follow which passes are run.\nOtherwise, in both loops licm can't help much due to the call. Perhaps we should tune the inliner to handle that, but I'm not sure - that would need to be done carefully.\nBut thinking more about the general issue, I think we need good benchmarks here - VMs will do licm themselves (except for baseline compilers or interpreters perhaps), so since licm may increase code size, I am thinking it's generally better not to do it in Binaryen. But if we can find a benchmark showing otherwise, that would be useful.. About those nops, when you wrote\n\n-O4 + flatten + precompute-propagate + licm\n\nDid you mean -O4 is run first? it should be run after the other three.. Thanks! Fixes and details in #1664, turns out there were two issues here (we need to handle ridiculously-large numbers of locals, and we also emitted locals much slower than we needed to).\nI suspect I didn't see this in my own fuzzing since I've focused on crashes, and this happened to hang and not crash because of that slowness.. Thanks! I opened #1666, #1667, #1668 with fixes for most of these. Some, though, are probably not worth fixing:\n\nasm2wasm: Proper input error handling in parsing is very low priority for us there, actually - we mostly care that we can parse asm.js backend output properly (also I am getting pypy JIT parsing to work in the singleton branch), and the main focus of development is not on the asm.js backend in any case. I see one of the crashes there is on an empty input, though, that one seems higher priority, I added a fix.\nwasm-merge: I'm not sure this tool has much of a future, I thought it would be useful, but not sure if anyone is using it. So also not sure if those are worth fixing.\n\nOverall, the highest priority stuff for me is anything that crashes wasm-opt, especially when run with some optimization flags like -O1, -Os, or some combination of specific passes, etc. That would test both our binary reading code and optimizer code, which are crucial.. Looks like that error comes from f109f3cae1cd81db22ba490a4da17a7a4c495047 , #1642 , cc @alexcrichton\nMy guess is that that's a new assert added there, and indeed wasm2js doesn't support non-function imports (that is, globals) yet (edit: wait, that can't be right...). We don't have a test for a module with globals, but looks like the binaryen.js bot does. What does the module it is trying to translate look like?. Oh ok, makes sense now. I see the same error in the native build too.\nI was confused because I thought we did have tests with imports, but I guess that was for wasm2asm, before wasm2js. So for now, need to disable that test on your bot.\n(Also, we should rename the binaryen.js API to be emitJS.). Have you joined the w3c community group? (required for contributors)\nLooks like there are some compilation errors on CI here.. Great, thanks!. Not sure i understand this yet, some initial questions above. But what i do get looks good, thanks.. Actually, I had another thought here - emscripten's EMULATED_FUNCTION_POINTERS (see settings.js for docs) does something very similar in terms of both compacting the table and avoiding unnecessary masks, as it avoids asm.js function tables entirely. That's used for dynamic linking, but I realize that it should work without it too. May be worth seeing how compiling your testcase with that option works before deciding how to proceed here.. I think that's because in dynamic linking we need to know function pointers for dlopen etc. (and currently we use wasm exports as a simple but inefficient way to do that). So we can probably fix this easily by just making that exporting only happen when linking. But maybe I'm forgetting something - let's see what the tests say in https://github.com/kripken/emscripten/pull/7108. That's odd, can you get me the bitcode to test on? I don't see an issue on a few testcases I tried now.. Fixed by #1797. Thanks!. The emscripten test suite passes with this too, so I think this is done aside from any review comments.. Great, thanks @jgravelle-google!. Sorry about that, looking into it.. Makes sense. Another option is to add a single function to set the shared flag, but I think what you suggested is better and more consistent with the current API.. Thanks, a PR sounds great!\nI believe that's right about shared memory, the docs say it needs to define a max size.. Thanks @sunfishcode! For some reason I remembered nondeterminism was possible in simd but forgot about this. So I guess we need to update that test to not depend on nondeterminism in wasm, I'll do that.. Confirmed as fixing that bug.. Sounds good.. After #1687 landed, I think it may make sense to add a bool import parameter to both table and memory. However, we can do that after this PR, either order is fine with me.. I think those errors are expected (it is checking that they appear). The actual error is at the very end of the log,\n```\n[ checking native gcc testcases...]\nbuild:  clang /home/travis/build/WebAssembly/binaryen/test/example/c-api-hello-world.c -c -o example.o -I/home/travis/build/WebAssembly/binaryen/src -g -Linstall/bin/../lib -pthread\nclang-5.0: \u001b[0;1;35mwarning: \u001b[0margument unused during compilation: '-Linstall/bin/../lib' [-Wunused-command-line-argument]\u001b[0m\nIn file included from /home/travis/build/WebAssembly/binaryen/test/example/c-api-hello-world.c:2:\n\u001b[1m/home/travis/build/WebAssembly/binaryen/src/binaryen-c.h:597:144: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1munknown type name 'bool'\u001b[0m\nvoid BinaryenAddMemoryImport(BinaryenModuleRef module, const char internalName, const char externalModuleName, const char externalBaseName, bool shared = false);\n\u001b[0;1;32m                                                                                                                                               ^\n\u001b[0m\u001b[1m/home/travis/build/WebAssembly/binaryen/src/binaryen-c.h:597:158: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1muse of undeclared identifier 'false'\u001b[0m\nvoid BinaryenAddMemoryImport(BinaryenModuleRef module, const char internalName, const char externalModuleName, const char externalBaseName, bool shared = false);\n\u001b[0;1;32m                                                                                                                                                             ^\n\u001b[0m\u001b[1m/home/travis/build/WebAssembly/binaryen/src/binaryen-c.h:625:238: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1munknown type name 'bool'\u001b[0m\nvoid BinaryenSetMemory(BinaryenModuleRef module, BinaryenIndex initial, BinaryenIndex maximum, const char exportName, const char segments, BinaryenExpressionRef segmentOffsets, BinaryenIndex segmentSizes, BinaryenIndex numSegments, bool shared = false);\n\u001b[0;1;32m                                                                                                                                                                                                                                             ^\n\u001b[0m\u001b[1m/home/travis/build/WebAssembly/binaryen/src/binaryen-c.h:625:252: \u001b[0m\u001b[0;1;31merror: \u001b[0m\u001b[1muse of undeclared identifier 'false'\u001b[0m\nvoid BinaryenSetMemory(BinaryenModuleRef module, BinaryenIndex initial, BinaryenIndex maximum, const char* exportName, const char segments, BinaryenExpressionRef segmentOffsets, BinaryenIndex* segmentSizes, BinaryenIndex numSegments, bool shared = false);\n\u001b[0;1;32m                                                                                                                                                                                                                                                           ^\n\u001b[0m4 errors generated.\n```\nLooks like we forgot that bool and false are C++ things, and not present in C. We should use uint8_t and 0 for those.. May also need to update some of those tests, if they use the old API before the change, btw - may see more errors later if so.. Thanks @nidin! Looks good aside from the two comments I just wrote - I think that will fix the test failure (if not, may also need to run ./auto_update_tests.py).. Correct, yes, we should add it to the CHANGELOG.md. As this is all ready to merge, I'll merge it and do that part myself.\nThanks @nidin!. Thanks!\n(sorry for the delay, was on vacation). I think something related came up in one of the PRs. My general thinking is that we should have a BinaryenSetMemory method which receives all the options for the memory, including whether it is imported or not. So you would call that and set the imported parameter to false.. I see your point. I agree that if we have the time then specific getters and setters for each field of the memory and table would be better.. I believe Python 3 is supported in all the tools referenced there, so it may be that just those docs need to be updated. If so, can file an issue or PR here: https://github.com/WebAssembly/website ; otherwise, if you find a tool not fully working with Python 3, please file an issue in that tool's repo.. Very sorry for the delay here - been very busy recently and I missed the email for this somehow.\nLooks good, thanks! If you can, please add a test in a followup PR.. I commented in the duplicate issue https://github.com/kripken/emscripten/issues/7247 that you filed. In the future, please don't open duplicate issues in multiple repos (often the same people just end up getting duplicate emails, and the discussion can end up split, etc.).. Good idea!\nWe probably need help with this, though - I don't think any of the active developers here know how to do that - even the current linux builds were added by someone else (and I'm not sure how they work...).. About the versioning, yeah, there are two - the version_# one is the relevant one, that's the main version. The other number is the corresponding emscripten version.\nI'm not sure how the github key stuff works... it's all very mysterious to me ;)\nHappy to do a call too if that can help.\n. I have no idea how any of this works :) but I trust you two and the code looks reasonable. Were we expecting to see anything special in travis (it looks normal as before)? If all is well there then we can merge this I think.. Cool, thanks @ashleygwilliams! Let's land this then.. Probably we should show an error there, yeah. But I don't think this can work, as browsers don't support over 2GB anyhow?. Sounds good, I opened https://github.com/WebAssembly/binaryen/pull/1702 to fix this here.. Fixed by #1702. Not sure if anyone here knows this stuff well enough to really review it. It seems fine to merge to me if it works.... Thanks @binji!\nI think this is good to go, aside from the comment on the secure key thingie.. I think this is ready to merge except for the actual secure token, which I am hoping someone here knows what to do with? :) (I don't). @alexcrichton I thought you already had push access to this repo, given the work you've already done :) but you should be invited now.. Happy to do it if necessary, sure. I think I don't have any special access to appveyor though, so we'd be equal in its eyes?. Hmm, I don't see any \"WebAssembly\" mention on the appveyor page after signing in. But under projects I see \"Binaryen\"?. Ah, maybe I don't have those permissions then. I see \"export yaml\" but no encryption option...\nSo I guess this needs an actual WebAssembly group admin? @dschuff maybe you can try? (log into appveyor.com with github, then go to the binaryen project, then under settings there should be an \"encrypt\" option). I'm not sure who has the right permissions here. If it's WebAssembly group owners, perhaps just @dschuff and @lukewagner? Maybe one of them has time to look into this.. I realized there is a corner case here: we do not run the legalize-js-interface pass if the user asked to not legalize the JS interface. However, we do still need these functions.\nProbably it's fine for now to just add a FIXME on this, as not legalizing is not really tested much yet (it's basically \"I know what I'm doing, I'll call this wasm just from other wasm, and never from JS\").. Oh right, yeah - it's really part of the JS interface, you don't need those otherwise. So sounds good, no need for a fixme.. The error message mentions a line and column, and I see (i32.eqz) there. The issue is that that is \"stacky\" text format, and binaryen does not support it. Only stuff like\n(i32.eqz\n  (..the input..)\n)\nwork (that is, normal s-expressions, in tree form). See the section on tree structure here. While I do agree that in asm2wasm and llvm wasm backend codegen we can decide to always include or always import those functions (so that binaryen would never add them in that case), binaryen can also be used to legalize a random wasm from somewhere else, and then it is useful to add those methods, as we need some way to pass around the higher bits.\nI've been experimenting with a patch that does something like what I discussed in the other PR:\n\nIf one of the pair (get/set) is present, error - we can't handle a half a pair.\nIf both are imported, use those. This would happen in asm2wasm dynamic linking, and in llvm wasm backend output after that change you mentioned.\nIf both are exported, use those (the internal name may not be the canonical one, but the export must). This would happen in normal asm2wasm and llvm wasm backend output before that change you mentioned earlier.\nOtherwise, create and export those.\n\nIf that sounds ok I can finish it up.. (Or if you prefer to work on it that's fine with me too, of course.). Good point that other users could create those imports. And not creating those here would be simpler. So your approach sounds good.\nWe'll also need to modify emscripten to not define them in asm2wasm.. I can do the emscripten asm2wasm changes if you want, if so let me know.. Re-reading this and other context, I think I did misunderstand you. But I think what I misunderstood might make sense to do :) Specifically,\n\nAlways import getTempRet0/setTempRet0, in all backends and all modes.\nIn this pass here, if the imports exist, use them, otherwise create them (and error if one but not both imports exist).\n\nThis simplifies code generation across the board, I think - we'll have exactly one place where we create those functions, in emscripten JS glue, and no more need to check for other cases.\nIn the past I had some concerns about perf regarding this (we call out to JS), but as I believe you pointed out in a previous issue, these functions are only used for interfacing with JS, and if we're calling out to JS anyhow, it averages out (compiled code calls out to JS to set the temp value, JS only calls into JS to get it).\nPractically speaking, to do this, we'd\n\nChange the emscripten JS glue to always create and import those functions.\nStop creating them in extras.c.\nUpdate fastcomp to use the imports.\nUpdate this pass here to just handle imports (and adding them if necessary).\n\nWhat do you think?\n. Fastcomp also needs a tiny change, yeah, since currently it will only assume they are imported for shared modules. I experimented locally with\nhttps://github.com/kripken/emscripten-fastcomp/commit/064c32740667e54e72565011c7fdc055b2282389\nwhich seems to work (with corresponding changes elsewhere).. See the emscripten tutorial.. iiuc, the article's algorithm 2 is what you are referring to? And it depends on fused multiply-add, which may be added to wasm eventually (\"fma\")?. Thanks @janisozaur!. Merging quickly to fix existing breakage on master.. I think so, using BinaryenModuleRunPasses, can give it those passes (and capture stdout).. A JS API option sounds good. How about a new function, emitStackIR? Internally in src/js/binaryen.js-post.js it can intercept out like emitText and emitAsmjs do.. Yeah, we should remove that comment if we're printing stack IR, agreed.. Thanks for the bug report! The problem is in _module_EndBank, where there is\n$14 = (Atomics_compareExchange(HEAP8, $12>>2,$13,0)|0);\nI opened https://github.com/WebAssembly/binaryen/pull/1720 which fixes this, however, it's possible that the backend is not emitting the right code there - can you provide the source code to that function, to verify?. Great, thanks for confirming!\nLooking at that source, I am guessing vlc_mutex_lock expands into an atomic operation. Hard to tell in the source though - can you provide the bitcode maybe?. Thanks @jakogut!\nOk, the bad news is that I think the backend is doing something wrong here, so that PR does get things compiling but the result may be incorrect if it runs that code. I'll investigate more.. Fixed by that PR landing.\nAbout dynamic linking, that does work but is not much optimized in the current state. We hope to optimize and complete it reasonably soon.. Doing some more testing, it seems this was wrong initially. The way fastcomp emits compareExchange is a little odd, we just need to ignore the shift. Added a comment about that.. Hi @linzj, can you please use escaping, so that the text is more readable? Use three backticks (`) on a line before and a line after all the code to be escaped.. Thanks @linzj, now I can see better.\nI think that running optimization passes there brings us to the same behavior as without -g, that is, the debug info comments ;;@ are gone?\nWhat are you trying to achieve? Sounds like you don't want debug info, maybe just function names? In that case --profiling or --profiling-funcs in emscripten may give what you want.. Ok, then yeah, --profiling-funcs may be what you want. It has no debug info in the JS, and in the wasm it just has function names. For full debug info, -g also has source locations in the wasm text, and -g4 also creates a source map, see emcc --help for details.. Thanks @singpolyma-shopify and @binji, turns out that is in fact the issue. Added support for the new notation in #1725. Great, thanks @dcodeIO!. Measuring (with #1740 to fix alignment), I see on e.g. wasm-opt tanks.wasm -Os we take 5% more emory and 5% more time. Likely that is due to the size increase of the very common Const node, now that the Literal union has a 128-bit value. Anyhow, 5% is what we need to live with for now - perhaps worth adding a TODO on the v128 property to investigate a heap allocation for those as they are rare.. It seemed simpler to have a fixed max alignment, and use that to allocate the chunks. Otherwise each Chunk could have a different type I suppose, but the added complexity seems not worth it (aligning to 16 bytes should be enough for everything ;) - but we do have a static_assert now, for when that eventually changes).. This is blocking some optimization work, landing. But post-commit review would be very welcome of course.. Yeah, the rereloop pass can create those from an arbitrary cfg.. An assert would only happen if not NDEBUG, so this changes the behavior in a release build without asserts (note that our CI only builds release+asserts currently, so we are missing possible compiler failures from a change like this, due to not having a noreturn function there).\nHow about using an assert when it would have an effect, and __builtin_unreachable otherwise? Do you know what LLVM does for unreachable?. Sounds good to have the name the way you did it, but it does change current test outputs so you need to run the auto updater script (./auto_update_tests.py) and commit that to get them to pass.. Actually on second thought, let's keep fuzzing of all features on by default, so make it --no-fuzz-atomics. We'll be adding SIMD soon, and other stuff, and having to flip on a bunch of flags in order to get full coverage is risky since the user might forget one (worse than having too many features for the fuzzed VM, where at least you get an error).. Great!. Really nice work here - very happy to see that autogenerated output which is 100x better than what we had before:). I think it would be ok to do a full string compare once we've gotten to a leaf of the trie. (The bad case is going through all possible strings in the list.). Looks like I don't either - @dschuff probably can though?\nTalking with @tlively I think we want to select \"rolling builds\" and \"only for pull requests\" there.. Huh, we changed it for the fork I do have access to, and it seemed to have worked... so looks like this is fine.. cc @dcodeIO, you may want to take a look at the C and JS API changes. Oh, also please add a test - a new files in tests/passes/minify-imports.wast (and a corresponding .txt output file, either generate manually or by running ./auto_update_tests.py). Odd about those unrelated errors. Does ./check.py pass for you? Maybe our tests just don't run on windows, we only run them on linux here.... That is not possible. Wasm programs can only access JS, which means you can only access the normal Web APIs. You can't do anything you can't do with the browser that JS can't do (except faster).\n. Chrome APIs are available to Chrome extensions, but not to normal web pages. So you can't use them in normal web development, which is what I understood from your first post here, but maybe I was mistaken?\nIn any case, the rule is that if you can do something from JS, you can do it from wasm that calls JS (and yes, embind is one mechanism to do that).\n. Good idea, we should do these!\nIt's not hard to add them. The correct pass is OptimizeInstructions (src/passes/OptimizeInstructions.cpp). Do you want to do it?. @MaxGraey Sounds good, I can get the stuff set up so that it's just a matter of adding the specific rules into that pattern. Take a look at https://github.com/WebAssembly/binaryen/commit/d3e5d4416f1bcb8fe3998db39351be766ba250aa - I added the first rule into combineOr there, and a test in $combine-or. The rest should be straightforward, let me know if you need any help.\n(I realized I need to land a few other things before that commit, so I can't land it right now, but posting this now so you can get started if you want.). @MaxGraey \nYes, for now fork oi2 and work on that, since I might not be able to land it today.\nThat unsigned trick looks valid to me. Maybe leave it for a separate PR afterwards though, so there isn't too much in one?. Comment before last looks good to me.\nLast comment also looks good - as you said in if or select etc. inputs we can flip the arms and avoid != 0 anyhow, but there are cases when it happens elsewhere, so i think it's a good rule to add.. @MaxGraey how are you getting along with these optimizations? Anything I can help with?. Thanks @atrosinenko, fix in #1768. cc @alexcrichton . Thanks @MaxGraey, looking at that benchmark I see some room for improvement, I pushed an additional commit here to run function passes again at the end of -O4. -O4's flattening etc. needs more work by the regular opts to be fixed up.. @dcodeIO might be interesting to run this against your test suite now, and see if there's anything surprising.. @dcodeIO thanks! Nothing looks odd to me there, but it's a little hard to compare total counts. Might be interesting to see the wasm binary sizes before and after, if that's easy to get?. Thanks @dcodeIO, I'm not sure what to look at though? I see libm.optimized.wasm and libm.wasm, when I compare that commit to the previous one... which are the two files of before and after that I should inspect?. Thanks @dcodeIO! One change there is that the new version has no br_tables. Trying to debug this, I went to the previous commit to get libm.wasm and ran -O4 on it, but I don't see the expected result - the br_tables are still there. Am I doing something different than the optimizations you ran?. @dcodeIO and what is the br_table issue that is observable on that testcase? Is it that in older binaryen a br_table was emitted, and no longer is? I tried this PR and some older versions, on -O4, -O3 and -Os, on wasm-opt in the shell, and see no br_tables in any of those outputs, so I must be doing the wrong thing?. That seems odd, since the code for emitting br_table (which has not changed in a long time) says\n// How many br_ifs we need to see to consider doing this\n        const uint32_t MIN_NUM = 3;\nand the testcase has only 2.\nHow can I run exactly what you are running? I'm not sure how to reproduce your build and process (as I said, my process is just to build wasm-opt in the shell and run that).. Ah, I've been running on the one with 2... I didn't read the patch properly, sorry. Looking now.. Ok, the issue is that this PR enables the rereloop pass, and it generates code that isn't a perfect match for the br_table-generating code. I'm not sure how quick it will be to improve that, but in any case, it's likely that for AssemblyScript you don't need the rereloop pass, so for now you can just skip it (and run the other passes in -O4 manually for now).. Eventually the optimizer should be good enough that running rereloop doesn't have downsides. But maybe we just shouldn't merge this PR in until then, I guess.... @tlively sgtm!. >  c-api-kitchen-sink.txt has not been updated. What's the best way to do that?\nRunning ./auto_update_tests.py should update them all, including that one.. For tests, can add in the relevant spec tests in this PR. However, if they use text format stuff we don't support, we may need to think about that.\nFeature flag sounds right, yes.. I don't care either way, though, if someone has an argument for the other way that's ok too.. Thanks @binji , looks like it's SpaceAfterTemplateKeyword. Updated.. Is there a reason to keep around the old behavior? It may be simpler to just remove it?. > Not sure about how friendly we needs to be with asm.js. I can remove that if needed.\nI think we can remove the asm.js requirement myself - as more features are coming in to wasm, that would be less and less practical anyhow. It will also simplify the code.. Thanks @yurydelendik!\nHmm, not sure what to do with the linking section. It's needed for more than debugging so I don't think we can remove it here. However, yeah, that sounds bad that it can contain references to debug sections that we would be removing here. @sbc100 , what do you think?. Addressed feedback.\nI'll open a separate PR to show a warning or an error if the linking section is present.. @sbc100 thanks, good to know. So we almost don't need this then, but it's still useful for non-lld paths (asm2wasm, other compilers perhaps?).. Thanks @MaxGraey! Yeah, this is something we don't do well atm. I experimented with some ideas in a selectify branch, but I'm not sure yet what the right approach is.. Also\n\nSince simplify-locals now emits more set/tee of if-elses, we need to run coalesce-locals again after it, as that pass is the only one that can remove a set with no corresponding get.. fyi @bnjbvr - when this lands you'll need --disable-threads for fuzzing without atomics. Added scarier warning.. Why is this useful - I thought we already handled all the inconsistencies between the two formats in emscripten?. It might be possible to transition asm2wasm to remove underscores - in ASSERTIONS mode we could emit wrappers that emit nice errors if the user forgot one (\"you're calling _main, you should call main\"), so the change might not be too disruptive.. We have an --extract-function pass, so you could do\nEXTRACT=name wasm-opt --extract-function input.wasm -o temp.wasm\nwasm-dis temp.wasm\nWe don't have a way to pass a param to a wasm-opt pass, so we use an env var atm. I'd be in favor of finding a nice way to do that, as then we'd have something that's useful for more things.\n\nWith that said, I'm not strongly opposed to this PR either.. Would regenerating them fix this - is it a bug? I think it might be expected, that is, maybe it's writing to some global memory location. So we'd need to modify the source code too?\nAlternatively, we can maybe just patch those to point to address 0, which is safer and already done in other places in the wasm2js path.. About the name, I see your point. But I think the current name makes sense as describing the broader intention, though, as there may be other things we can do when the runtime is not exited, like not flush standard streams (which we do in emscripten now, but perhaps might do here some day).. Cool, then what about the name? asm2wasm currently uses STACKTOP, but maybe this should be more similar to the wasm conventions, so __stack_init perhaps?. Amusingly this found a bug in wasm-ctor-eval, which only handled the stack going up, but not down. After this change makes us more similar to asm2wasm, the ctor-evaller tried to do more, which hit the bug. The fix is easy though (make it not assume either direction and allow both).. Great, following the new commits they all look good to me. Were all the comments I had before addressed? If so then I didn't find any other comments since, so lgtm as a whole!. Btw, we should add testing for this in test/passes/ (say, one small file for each feature we test on). No need to block on that here though.. lgtm, but see more discussion here: https://github.com/WebAssembly/binaryen/issues/1763#issuecomment-441837248. cc @awtcode. @awtcode LEGALIZE_JS_FFI=0, but see https://github.com/kripken/emscripten/issues/7679\n\nIn my case, I believe the i64 exported functions are not called from JS as well so is there a way to turn off legalization for these functions? Thanks for your help.\n\nI don't understand - what does \"as well\" refer to? (what else could call them aside from JS, that legalization matters for?)\n@dschuff sounds good, followups for your comments are in #1832. @awtcode I understand, thanks. There's nothing special about exports. So if you build with legalization off, it will not legalize those (it will just legalize dynCalls, if there are any).. Probably soon, there is current work on some ABI issues which will include this https://github.com/kripken/emscripten-fastcomp/pull/249 etc.. @dschuff I think that'll be fixed by https://github.com/kripken/emscripten/pull/7661. Interesting, can you share that benchmark?\nIt's possible this is something we need to ask VMs to optimize as opposed to the toolchain. We'd need good benchmarks in that case.. Thanks!\nI see similar results on my machine. The question is then whether the toolchain should do this, or VMs.. We may want this option for that reason, yeah (since some VMs are not that complex). However, in general this is the kind of optimization that VMs should do IMO since\n\nIt increases code size (anything that decreases code size, the toolchain should definitely do!)\nThe VMs can do better since they know the actual # of registers and the cost of reading a global, and so can reason about whether it's worthwhile caching global values.\n\nI'll try to ask some VM people about this.\nWhat's that LLVM-backed wasm project you mention? wavm? Do they cache, or just they get it automatically from representing the globals as LLVM globals + LLVM's gvn?. I looked into this a little, and with little work we should be optimizing this in local-cse and licm, #1840. That covers many common cases, probably. As with licm in general, it shouldn't be on by default, probably, but it's a good option to have.. Yeah, this is a case where binaryen's unreachable type allows things that wasm does not. The loop here has unreachable type.\nFix in #1835 - we were flowing out a value through the block that does not actually flow. Thanks!\n. What should happen is that Binaryen IR has an unreachable type, but when we emit a wasm binary we make sure to produce something that is valid, removing the unreachable type where it appears. It's a potential source for bugs though, yeah - I wonder if we shouldn't reconsider this.. @dschuff yeah, when interned comparisons are just pointer comparisons.\nModified to use a std::array. I wish the , 4 could be avoided, but nothing's perfect ;). @binji good point, thanks, updated to avoid that. Although now it will initialize those names once per function. Probably fine, but no simple way to do something optimal here that I can see.. Are you sure it's not running out of memory? In my experience that's the likely cause for an error with no other details.\nRunning emcc with EMCC_DEBUG=1 in the env might also show something useful. Other things worth trying are running asm2wasm in a debugger or in valgrind.\nIf you can provide your project's code or bitcode, I can investigate it.. Thanks, those input files would allow me to debug this.\nAlso interesting would be the stack trace in a debug build (but with those input files I can probably get that myself, assuming the problem reproduces).. Thanks @crsib! Fix is in #1936\nBtw, I'm curious what codebase is that, if you can say?. Took an hour for the reducer to shrink the test ;) then at 235 bytes it was easy to figure out, just a few minutes.\nInteresting product, thanks for the info.. Also add determinism checks to the fuzzer.. Not missing anything @nth10sd :) We were missing some JS glue code to support some recent fuzzer improvements. Fix in #1843. What's the bad type it sees? (can use wabt to inspect the binary, or a hex editor) Might be SIMD, which you also need to disable if you don't want it.. How about --disable-simd?\nWabt is here: https://github.com/WebAssembly/wabt. The 1.38.x numbering is the emscripten version number. You probably want the other one, yeah, which is binaryen-specific.. Tagged version_62 with this.. Thanks! Fix in #1846, looks like we were not doing aligned allocation properly, as caught by that error.. Updated to 2019.\nStill blocking on windows testing as mentioned above - help!. To test on windows, I found I can just add some ctest testing, which is pretty easy, and it seems to run ok on the CI here.\nProbably we should move more testing and consolidate it with the other tests somehow, but for now this is useful to make sure basics are not broken, which is all we need in this PR.\n. I don't see a false value there - it's just mentioned in the validator message in the sense of \"assertion failed, this was false but should not have been false\"? Unless I'm missing something.\nSeems like the called function, __ZNKSt3__28ios_base6getlocEv, has a single parameter, a this pointer, in the LLVM IR, asm.js, and wasm. So that all looks consistent. How is that function declared in all of those?\nOne possibility is that this is a bug that was fixed since 1.37.33, which is quite old at this point (Feb 2, almost a year). We did have some bugs in that area in the past.. Thanks for the extra info. I think that's what we fixed in https://github.com/WebAssembly/binaryen/pull/1439 , which indeed landed after 1.37.33.\nThere might be some way to work around this in the source code, but updating binaryen is the best thing. If it's hard to update the entire emsdk+binaryen, all you need is to build binaryen master from the time of that PR landing, and replace the asm2wasm and wasm-opt binaries.. Not really. You can tell asm2wasm not to validate with --no-validation, but that won't help - the wasm VM will throw a validation error on loading the wasm file.. Hmm, it's possible you need to rebuild system libraries for that version. ./emcc --clear-cache should make it rebuild them automatically next time.. Oh, also it's possible Unity has some bundled system libraries that need to be linked with the old versions, which is the opposite problem.\n. Emscripten changed the signature of size_t from int to long (or vice versa, I forget), so bitcode needs to be rebuilt with the new types. I think that's the cause of that issue. (They are all 32-bit ints, but get mangled differently.). Perhaps. In that case it should be moved out of ir to the top level. Not sure which is the best place though.. Also added ignoring of \"too many locals\" (VMs have a limit, and some binaryen passes can create enough to reach it, we can just ignore those).. Also remove commandline parsing stuff in fuzz_opt.py, which @tlively realized won't work with the other commandline parsing in test.shared. But we don't need it anyhow - can figure out another solution if we do in the future.. cc @dcodeIO . This is not enough to pass. We also need to remove or rebuild wasm.js. Fix in a moment.. We do still have an interpreter, and it works in binaryen.js. We just got rid of the wasm.js glue which integrated the interpreter with emscripten programs.. Thanks @chicoxyzzy!. Perhaps the parameter to wasm-dis was the contents of the file, and not the filename? (The *asm pattern looks like how a wasm binary should start.) That is, wasm-dis filename.wasm should work, but I don't think we currently support reading the binary from stdin through a pipe or something like that.. Thanks @juj!. Thanks! Fix in #1869.. Thanks! Fix in #1869.. Thanks! Fix in #1869.. Thanks! Fix in #1869.. Thanks! Fix in #1869.. Yeah, it might make sense to special-case this. But we do handle it with --flatten --rereloop -Os, which results in\n(func $0 (; 0 ;) (; has Stack IR ;) (type $0) (param $0 i32) (result i32)\n  (select\n   (i32.const 1)\n   (i32.const 2)\n   (local.get $0)\n  )\n ). Interesting data about the speed!\nGiven that data, and that the select version is smaller in the binary, I think it makes sense we emit it.\n\nIs it make sense using this also for -O3?\n\nYes, it works in both -O3 and -Os, try --flatten --rereloop -O3.. Thanks! Fix in #1874. > Is --strip run by default as part of normal opt builds?\nYes, when no debug or profiling or other metadata is requested by the user.\n\nit's fairly miniscule in size\n\nIt is over 100 bytes, which is small compared to a large wasm I agree, but not all wasms are large, and also it's 100 bytes times every wasm downloaded over the internet, which adds up.\n\nHow about having a separate --strip-producers or --strip-all for testing and for when people really mean to remove the producers?\n\nThis is the key issue, I think. When someone tells emscripten \"optimize my code for size as best you can\" then they do mean to remove any metadata and unnecessary space, which implies removing this section.\nI don't see developers asking for this extra size increase to their binaries. I think you need to convince them of that value if we want this on by default. Meanwhile we can add a flag for the devs that do want to emit this.\n. It still would not fit in with what emcc currently does - when users optimize in emcc, they want the smallest and fastest binary. These new 100 bytes have no practical benefit for the developer, so it's not like a speed/size tradeoff. The consistent behaviour in emcc is to strip them.\nHowever, we are in binaryen here, and some devs may want to keep these, so I'm fine with adding a --strip variant that does not remove this section. However, I don't think emcc would use it by default.. I am open to being convinced about that benefit to the ecosystem, but I don't see it yet. What would that benefit be? (Not that I'm not curious on how used the tools I work on are, but I see that as idle curiosity.)\nLet's discuss this more. For now, I opened https://github.com/emscripten-core/emscripten/pull/7892 to hack the test to pass for the wasm waterfall.\n. I'm not sure I see how useful that is. Yes it's interesting, but we already have a vague notion of how popular the various tools are, and that's more than good enough for prioritization decisions, isn't it?\nIs there precedent for this? Do JS bundlers, for example, bundle some producer info about themselves, which minifiers were used, etc.?. https://github.com/WebAssembly/tool-conventions/issues/93 has a summary of emscripten's current thinking on this. For Binaryen, we don't want to do anything to the producers section by default, but do want it to be possible to optionally remove it. To achieve that, this PR now\n\ncreates a --strip-producers pass that removes that section.\ncreates a --strip-debug pass that removes debug info, same as the old --strip, which is still around but deprecated.\n\nA followup in emscripten will use this pass by default.. I believe this should already be fixed by #1874.. I think those are fixed with https://github.com/WebAssembly/binaryen/pull/1887. Thanks!\nThis looks the same as #1879 (similar stack trace, my wip fix resolves it).. Stack trace is different, but this is also fixed by my wip fix for #1879 (it happens to break later).. This is definitely useful for #7679, and passes the emscripten test suite for me locally. Looks like no concerns, landing.. Thanks! Looks good.\nInteresting that Ruby needs more parameters here. Do you happen to know where in the code it depends on FuncCastEmulation? (just curious since it's rare - only other case I know of is python)\nBefore we merge, have you joined the wasm community group?. Hmm, b8395 is probably just the function that throws the error. I think that data is enough - looks like Ruby does the same as Python, and relies on C undefined behavior with function pointer arguments, making this pass necessary.. As this is a small change to a constant, I think we can merge it, but for future contributions it would be important to finish joining the group.. Thanks! Will be fixed in #1886. I think those are fixed with https://github.com/WebAssembly/binaryen/pull/1887. I switched the pass to the -notee version, which is perhaps a tiny bit faster to run, and is enough for us.\nAlternatively I guess we could maybe write a custom analysis for these locals, just walk the function, note locals assigned to once, etc. That might be better for debugging of O0 code somehow?. I experimented with adding custom logic for this. It basically means tracking set/get pairs in basic blocks, and is actually pretty simple, let me know what you think of the current code in this PR.\nI lean towards this approach, because otherwise running an optimization pass may have bad downsides for debug info in -O0 builds.. Interesting, and I agree this is important and we should support this use case.\nHowever, I'd prefer to not add anything to wasm.h and the core IR. Instead, I'd rather add parameters to passes. That is, I'd like to have a way to not just do (not literally this code, but in spirit) runPass(\"inlining\") but also runPass(\"directed-inlining\", FunctionList(\"name$a\", \"name$b\")), that is, we'd have a variant of inlining that inlines exactly what it was asked, and users can run it with a parameter of those names.\nThis is important for other stuff too (like ExtractFunction, which receives the param through an env var currently...), but we just haven't had a nice enough design idea for it. I think we should focus on fixing that, and then adding this for inlining would be easy.. That seems reasonable, yeah. We can move the core inlining logic into src/ir/inlining.h, use that from the pass (which would keep the logic for deciding where to inline), and add a C API call to the inlining.h method.\nWhy would an error code be necessary for the inliner?\nAnd, why would the user need to remove functions that are no longer necessary - the optimizer can do that automatically? (I think the remove-unsed-module-elements will). Makes sense, although probably we should design the interface so errors are not possible, or are fatal. For example, maybe we want ForceInline(\"name\") which would inline that function into all callsites. It would avoid doing so if that would cause recursion, etc.. Oh wait, the metadata change is unneeded - we do track imports already, as \"externs\". Reverted that part.. Thanks, fix in #1894.. What do you mean by \"creation time\" here?\n\nUnfortunately, it's not possible to make a BinaryenCallInline helper that'd do this at creation time of the function. \n\nWhat do you think about my suggestion from earlier to make the API \"force-inline function X\" which would then inline X into all functions that call it? If that works for your use case, it seems like a nicer API, and it would be a lot faster.. Thanks for the clarification about creation time, now I see.\nAbout the precompute issue, it sounds like doing inlining early, before running the optimizer, would be best for you? Are you saying you don't need binaryen to inline in that case?. That is, it seems like using this PR (or an improved version of it) to inline first thing, and then optimize, would get what you want?. I see, thanks.\nI guess those inlined functions are special - simple enough that simple precomputation turns them into a constant? So they don't have locals, for example?\nOverall, it seems like that's a special case that the AssemblyScript compiler would maybe have to handle itself - those functions being inlined are really like compiler intrinsics, that is, special functions the compiler controls and is aware of.. Thanks, fixed in #1902. Landing to fix urgent breakage.. I don't see a crash on linux, but that might be because linux stacks are 8MB, and I think you're on MacOS, which has smaller ones?\nSo my guess is this is not an infinite recursion, just a very deep one. If so, #1905 should fix it.. Odd that didn't fix it. Can you please try with that PR, does that fix it?. Thanks for checking!. Confirmed to fix #1903, landing.. Landing to fix current breakage.. Ah, I saw this after I opened https://github.com/WebAssembly/binaryen/pull/1908\nOptions seem to be\n\nEmit a warning (what that PR does).\nEmit an error (but sometimes people do want to not output anything, like if just running --metrics).\nDo what llvm-opt does, which is always output (to stdout).\nNot change anything.. Let's go with this, as there seem to be no strong feelings about the other options.. There's an unofficial docker here: https://hub.docker.com/r/trzeci/emscripten/ would be good to have an official one, I agree.. > 1 / (x / x) => NaN\n\nHmm, why? E.g. if x == 1, then 1 / (1 / 1) => 1?. Yes, I think an optional pass could do optimizations like these that are unsafe in general, but valid for some compiler.\nAnother option is to add a pass option, like \"don't care about nan bits\" - then existing passes can check that and behave accordingly. Sort of like the existing --ignore-implicit-traps.. @jgravelle-google, maybe you'd like to review this? no worries if not.. For testing, maybe there's a generic unit test suite for vectors in C++? (quick search doesn't turn much up) Otherwise I can write some tests, but I'm sure it wouldn't be comprehensive.\n(This is tested by being used in the codebase, at least at a functional level.). Makes sense. Ok, added a testcase file with some corner cases with the template parameter being 0, and crossing and uncrossing the boundary between the fixed and flexible storage.. Thanks @binji and @jgravelle-google for the feedback here!. Also added an option --no-fuzz-nans to make it easy to avoid nans when fuzzing (without hacking the source and recompiling).. I think that warning may happen if the wasm uses name section subsections, like the locals subsection. We still need to add support for that. Btw, what compiler created that wasm, do you know?\nTesting on v68, I don't see a crash with -O2 (it successfully shrinks it by around 17%). Do you have a stack trace? Or running valgrind may find something (I don't see anything here).. Interesting. Would a debug build in WSL show a better stack trace? Or does it have limitations? If you can run valgrind in a debug build in WSL that might be especially interesting.. Also may be interesting to see if the test suite passes on WSL (python check.py).. Interesting, thanks, I guess it's not too surprising to see node differences like that between platforms (emscripten's NODERAWFS mode has several open issues on that). I guess our test suite is not fully portable because of that.. Verified to pass emscripten test suite + a bunch of fuzzing.. Yeah, I believe the wasm backend will do this - but it doesn't manage to do it in all cases, due to technical limitations that I don't know much about. In any case, there will be cases that it can't be expected to do, like if binaryen inlines something after llvm.. Thanks, yes, we should use std::unique_ptr for stuff like this. Perhaps you'd like to submit a PR?. Yeah, we may want to make the size of the region customizable. 1024 is just one possibility.\nFor AssemblyScript in particular, perhaps you don't need the pass, though - do you already use load/store offests in all possible places? Or are there places binaryen could optimize for you?. Interesting. Is there ever a case where it is not valid to use a load/store offset in AssemblyScript? In C, the problem is that a program may assume a pointer may overflow, and that that is valid (!). But another language may just say that's undefined behavior, and that it is always safe to do\nload(x + constant)  =>  load(x, offset=constant)\n. Yeah, this may well be undefined behavior. But we've seen real-world code that depends on it, weirdly...\nI'm not sure it's undefined by that paragraph, though. What I think happens is this:\nx = some pointer, say 1000\ny = ptrtoint x\nz = y - 1500 = -500 or rather 0xfffffe0c\nstore it to memory or whatever so the optimizer can't see past this line here\na = z + 1500\nb = inttoptr a (note, equal to x)\nload b\nIf you do the add as an unsigned integer, and overflow it, then you get 1000 as expected. If instead the optimizer did load(b) = load(z + 1500) = load(z, offset=1500) then it would trap.\nIs that undefined behavior in C - is it not valid to do arbitrary intermediate math like that after converting a pointer to an integer, and before converting it back?. Still curious about that UB C question, but merging this PR.. @Warchant - thanks! Have you joined the w3c group, before we merge? https://www.w3.org/community/webassembly/participants. cc @yurydelendik , maybe you have some thoughts?. I think we can do better here, yeah. E.g. most passes use replaceCurrent to replace nodes, so we could make it aware of debug info. Otherwise, yeah, we'd need to add manual debug info copies in the optimizations, where possible. Not sure this is high priority yet, but I imagine once wasm debugging gets better people may care more about this.. Added support for copying debug info in replaceCurrent.. Yes, I landed a PR to fix these, https://github.com/emscripten-core/emscripten/commit/7f7d0d066cdec1d408be96b4dd1fe961b80572e5\nAnd yes, binaryen doesn't know about noinline. To prevent inlining in binaryen, it just needs to be run at -O1 or below.. Some previous relevant discussion: https://github.com/emscripten-core/emscripten/issues/8085. ccing wasm2js/wasm2asm authors for more visibility: @yurydelendik @alexcrichton @dcodeIO @froydnj @tlively . Yeah, we definitely don't want to remove use cases people care about - @dcodeIO, thanks for mentioning that you use this code path.\nHow much do you care about the external API of the JS code emitted? I might want to change it in minor ways. (Aside from that, my plan is to just improve the quality of the JS emitted.). Yeah, a wasm-ish API - almost like a polyfill - is what I was thinking too, heh.. Thanks @alexcrichton, good to know! Yeah, I intend to make this a major focus for myself personally, and it will definitely be a high priority once emscripten depends on it as a fastcomp replacement.\nI'll have to investigate the JS output format issue - for emscripten and AssemblyScript it seems like a \"wasm polyfill\" approach is better, and for you an ES6 module is. Probably we can implement one in terms of the other or something like that.. Thanks @brion, very good points. Yeah, the \"polyfill\" approach does want to affect the global scope. So it seems like building the polyfill as an extra optional layer on top of the other approach is the better way to do.. Good question... cc @binji @tlively . Hmm, good point, I don't think that's intended. The code would need to create a buffer and pass that in. However, this call doesn't have side effects, so it would not be crucial for creating testcases using tracing. Might be best to add a TODO on those lines though.. Great, thanks!. I suppose it could be a pass, true. But it's not something I see as useful by itself. We just need to ensure dynCalls exist in a few places (wasm-emscripten-finalize, and emulate-func-casts), so having it in library code that is just called from those places seems reasonable to me.. I also think it's reasonable for that code to handle the case with existing dynCalls - by not erroring when trying to create them. This doesn't add complexity, and makes the code usable in emulate-func-casts. Maybe there's a downside I'm missing though?. We renamed the tool to wasm2js (since it doesn't emit asm.js, but JS that is mostly like asm.js, but not strictly).. I ended up doing a bunch more work here, as the added locals could increase code size in some cases. Avoiding that is good not just in general but also to avoid needing to update test expectations in emscripten in the negative direction.\nThe PR now has separate commits for:\n\nPropagate a load/store offset even if locals are not in ssa form. This lets us handle a lot more cases, at the potential cost of another local.\nRun multiple iterations in OptimizeAddedConstants. This helps with cases where propagation leads to another propagatable added constant, which can be combined to a single big propagated one.\nOptimize added constants with propagation only if we see we can remove all uses of the original add. The key issue is that if we do both the add and use a load/store offset, we are not saving anything - the add is where the work is (the offset can be 'free' at runtime), and if we have both we are doubling code size.\nCoalesceLocals: run even if we have just 1 var. This was a tiny oversight from a long time ago. While 1 var seems like we can't do anything, we can in fact remove it if we can reuse a no-longer-needed param. This avoids this PR causing a regression on some internal tests.\nAdd a test with deflate from zlib using the wasm backend, which may be good to track these kinds of optimizations.\n. Sounds important - please find the specific commit that changed things, and show me your wasm before any optimizations, and I can investigate it.. Can you get me the wasm file before optimizations? That is, I want to be able to run the earlier and later optimizer, and see the results locally.. Sorry, maybe I wasn't clear. What I need is a wasm file before binaryen optimized it - not before the new optimization change.\n\nI just need that one file. With that, I will run the binaryen optimizer using a build before that commit, and after, and compare and debug that locally.\nIs that file one of those included there? I interpret \"before\" as \"optimized using the binaryen from before\", am I wrong?. Ok, when I run wasm-opt -Os on that wasm file, I do see a change happen on 7e56e5b9eb08a68631d98f6d0d7db2adc2cd8236 which is\n--- v83aa0dc2daf32.wat  2019-03-13 16:37:25.041479549 -0700\n+++ vmaster.wat 2019-03-13 16:38:01.925810726 -0700\n@@ -28,42 +28,41 @@\n      (local.get $0)\n     )\n     (i32.shl\n      (local.get $1)\n      (i32.const 2)\n     )\n    )\n   )\n  )\n  (func $~lib/array/Array<Body>#__get (; 1 ;) (; has Stack IR ;) (type $1) (param $0 i32) (param $1 i32) (result i32)\n-  (local $2 i32)\n   (if (result i32)\n    (i32.lt_u\n     (local.get $1)\n     (i32.shr_u\n      (i32.load\n-      (local.tee $2\n+      (local.tee $0\n        (i32.load\n         (local.get $0)\n        )\n       )\n      )\n      (i32.const 2)\n     )\n    )\n    (i32.load offset=8\n     (i32.add\n      (i32.shl\n       (local.get $1)\n       (i32.const 2)\n      )\n-     (local.get $2)\n+     (local.get $0)\n     )\n    )\n    (unreachable)\n   )\n  )\n  (func $assembly/index/Body#offsetMomentum (; 2 ;) (; has Stack IR ;) (param $0 i32) (param $1 f64) (param $2 f64) (param $3 f64)\n   (f64.store offset=24\n    (local.get $0)\n    (f64.div\n     (f64.neg\nThat looks like a good change, removing an unnecessary local.\nBut it's different than your diff. Perhaps you're running with different optimizations? I need the exact steps to reproduce your build.. Sorry for missing that earlier!\nTesting with -O4, I don't see any difference at all on all the relevant commits.\nIn the past, I think we saw that AssemblyScript had some flags on, like maybe debug info? Flags might alter how optimizations work. . Ok, I bisected this on -O4, and the change happens in 83aa0dc2daf327ed264cc22e51af1a866787a764\nInvestigating this, the change is that we add an extra copy of a local in the loop. That's definitely not good. The reason is we can't identify it properly as a copy yet. I'm actually working on fixing that this week, so hopefully this will go away.\nMeanwhile I don't think we should revert that other change - it's doing something more correct in general, and here as well, but it just happens to get unlucky later when it fails to remove that copy.\n. Updated with a more structured mapping of --pass-arg=KEY:VALUE which is enforced in a central way.\nAlso realized the extract-function pass being improved here can be a lot more useful with the non-extracted functions turned into imports.. Thanks @Ryooooooga!\nAny idea why one of the windows builds is failing here? Maybe just needs to be rerun?. Great, thanks. Looks like the previous errors were just a temporary problem on the bots.. Thanks @brakmic!. Nice, thanks @Ryooooooga!. I see, thanks. lgtm either way.. this new stuff could go in a header of its own, then it could eventually be reused by other tools here.\n. curly braces please, or put it on the same line\n. why did this lose indentation?\n. Oh sure, clang-format is fine. Just wanted to check this wasn't a mistake.\nI'd be fine with clang-format on all the things.\n. Cool.\n. getStr() modifies global state. can just remove the assignment to name.\n. 32 bits is enough, this is an asm.js pointer\n. oh nice, now I know the proper way to do this stuff :)\n. curly braces, or same line (or does clang-format not accept either?)\n. { on same line\n. also { on same line\n. if we must move this for msvc, we'd need to rename it. Perhaps LoopChildChecker?\n. how about printing the symbol itself?\n. Cool.\n. sounds good.\notherwise this lgty?\n. lgtm with curly braces like the one after it\n. i love c++11 lambdas\n. curly braces please, or same line (my one pet peeve... ;)\n. ditto\n. ditto\n. what is this file for? I don't see it used?\n. oh ok, cool\n. typo in update\nlgtm with that fixed\n. why is there still a submodule?\n. no longer plural in both sentences\n. we should still run on those wasts, in their new location?\n. or does that happen lower down and i missed it?\n. Yes, and I see that s2wasm is run on those. However, we previously also ran binaryen-shell on the wasts, to verify that it could parse them, which your code removed.\nThis isn't what the tests were intended for, I suppose, but I did notice that those wasts had a bunch of stuff not in the spec wasts, so it was useful to verify binaryen can parse them.\n. On their wast expected outputs, yes.\n. this might be higher up perhaps?\n. what does ./ do here? is it the same as .?\n. no need, seems ok either way\n. ok\n. this is not right, we can accept either a signed or an unsigned value here. Both fit in a double.\n. emscripten optimizer code (like here) should not access the wasm namespace. if we need to add helpers for here, they should live inside the optimizer directory here\n. ditto, emscripten optimizer code shouldn't access wasm namespace\n. but it can return a negative value?\n. (negative values here)\n. ditto\n. is this right? what if x is negative? or is that intentionally not handled, and we assume the input is valid, I suppose? then perhaps add a comment?\n. oh nice\n. what caused this change?\n. Do you mean places in binaryen? If so then having it in emscripten_optimizer/ seems fine. Or do you mean places in other projects?\n. You mean, it does the right thing while passing the negative values as unsigned (2s complement)?\nSeems very confusing to me personally, as small negative numbers are very natural and common here.\nWhat is the undefined behavior this counters? Perhaps there's another solution?\n. oh ok, got it. nice.\n. the difference is that emscripten_optimizer is also used in emscripten, where it powers the asm.js optimizer. it happens to be useful in binaryen for asm2wasm and wasm2asm, etc., so it's here as well.\nperhaps it could be moved out to a repo of it's own, but that seems kind of overkill.\nbtw, in emscripten the license is MIT - are you ok with dual-licensing your changes, so that they can go there as well?\n. Is the undefined behavior here negating -MAX_INT? I'm also kind of unclear on how this avoids undefined behavior. Is it just that the spec is one-sided?\n. Yes, there was just one (aside from me) to that directory. But the problem isn't symmetrical - MIT is more permissive than Apache, there isn't a problem to include the emscripten code here, just like you can include BSD code in GPL projects, but not vice versa. (Except one can't apply new copyright headers, of course.)\nSure, sounds fine to fix it for now - but in what way? If it's fixing it temporarily in a way that doesn't make code in emscripten_optimizer/ look outside, then then sounds ok.\n. Ok, sounds fine.\n. what's the benefit to forking s into loc and then joining them later?\n. oh, ok.\n. fixed\n. done\n. fixed\n. something seems odd here, but I'm not sure. is there no better way to do this?\n. Yeah, that worries me.\n@jfbastien, thoughts?\n. I don't know... looks clearer to me my way. Do you feel strongly?\n. For the size itself. We fill it in later. I'll add a better comment.\n. v8 binary format document says so :) yes, definitely too small for real-world code.\n. done.\n. depth is a pure debug thing. will add a comment.\n. yes. done.\n. oops, actually can't be const.\n. even for pointers?\n. yes. done.\n. done.\n. hmm, technically yes, but that seems... hacky? :)\n. perhaps worth doing as a general refactoring for IString. But it's used in a bunch of places, so it needs more consideration. followup discussion seems best.\n. hmm, this is a super-common pattern across binaryen - calls to allocator.alloc<T>, returning a pointer. I don't feel auto* adds anything there?\n. need to pass , false to that IString constructor. The second param is \"can I reuse this memory\", and it's optimized for the initial use case of IStrings, which was to intern strings as we go, starting from a large existing buffer of text.\nOr, perhaps we should flip that default. It means we can't merge code to emscripten's optimizer, but maybe that's not too bad at this point.\n. Yes. The idea was that those are coming from a buffer, similar to the original use case. But agreed, that's not good. I'll change that.\n. why did this go away? it checks we print --help with useful info.\n. But this tested the contents of what the user can read when --help is requested. We don't check that anywhere else, do we?\n. Ok, the reason this was tested is that the shell is the most user-facing tool here - I want stuff to break if we make that less useful for people :)\n. why was the U/S moved from after I32 to before the final F32?\n. this one (i32->i64) seems to have been dropped?\n. Oh, I guess it's superceded by I64ConvertSI32 etc.?\n. are these changes just reformatting? I prefer the more concise way things are before, which is consistent with the rest of the file.\n. oh wait, I see, they add the float conversions\n. Please use {,} when the body of the if is on a separate line, for all these.\n. I'm confused by these. In the AST semantics document https://github.com/WebAssembly/design/blob/master/AstSemantics.md we have conversion operations that all convert an int to a float. But these that you added look like they convert to an int?\n. But in the spec, it looks like the way it was, not the way you changed it to?\n. I agree, this should be better. It was a quick hack. We should refactor it eventually (but I don't feel it's urgent).\n. I'm not happy to land something that is just partial work, though - as it seems to make things potentially more confusing. If the design doc says convert ops convert to float, I'd like to not do something else.\n. what is this?\n. why do we need a new field here?\n. is this check and the checks below verifying that each section is seen once?\ni would prefer a more generic approach to this instead of adding a field to wasm.memory, checking sizes, etc. How about an std::set of the seen sections, used in the main section for loop?\n. i think i understand this now, but see comment above about another approach - i don't think we should modify this here.\n. I see. I would be ok then to ignore unknown sections, which should give you what you want here, without hardcoding a nonstandard section.\nWe should print a warning on skipping unknown sections (in debug mode).\n. Oh right, yes, we need sizes to skip.\nOk, how about just replacing the name \"WLL\" with \"other\" or something more generic. That seems fine for now.\n. I'm trying to meet you halfway here.\nI don't think Binaryen should support WLL, because I know nothing about it except for the name, and it is not something that is mainstream in the wasm design process.\nOn the other hand, I am trying to compromise with you, because all you want is to skip a certain section. And since I know skipping sections is something we want anyhow, I suggested that we make this a generic \"unrecognized section\", and it would be skipped.\n. Ok, thanks. I might build on this work then, and add support for these opcodes. I need to first figure out the naming convention question.\n. Ok, I added the missing opcodes on master now.\n. Do you mean you are giving up on this part of the pull request (i..e you intend to address the other comments), or the entire pull request?\n. I'd prefer these on separate lines.\n. for asm2wasm, technically we shouldn't need this - if the code is built with -Oz. The opportunities your pass finds are because the code in the test suite is -O0 or -O2, and that focuses less on code size, and in particular it duplicates blocks, which leads to ssa optimizations not kicking in specifically on return values.\nbut, since -O2 is common, I suppose this does make sense. just writing some thoughts here, not a request to change anything\n. for consistency, i believe we don't have a space in Const * elsewhere (we do write Const *ptr, but not when the type is by itself). but, maybe this convention is better? i don't feel strongly.\n. The current walker logic in the current passes does not require overrided methods to do recursion to their children themselves - why is this different?\n. Ok. I'll add code for this, your patch is helpful as a starting point.\n. Perhaps we should have PreWalker and PostWalker (where the latter replaces WasmWalker), that do strict pre- or post-order walking, and then something more flexible with another name?\n. should use camelCase like in the argument right before it\n. eh?\n. oh ok.\n. Done.\n. Added signbit.\nYes, this code avoids comparing nans, because they always compare false.\n. fixing, thanks.\n. For example, 500 bytes of memory would be 8.97 (log2 gets an integer cast to a float, returns a float). With ceil we get 9. Then in the round trip, we get 512, a little more. But better than 256 which breaks some spec tests.\nint8_t is from the v8 binary format.\n. The design and spec repos do not require a power of 2, and various tests depend on it. Only the v8 binary format does.\n. Yes, if that changes then we can update things here as well.\n. if name is not set, then we are setting that null string here, which is bad.\nwe would have to autogenerate a name earlier, in parallel to the getString.\n. alternatively, we could create the export later down, after we have called addImport/addFunction, which would have set a numeric name.\n. please use a non-shortened link, which is more likely to survive\n. i don't quite get why we need a minimum size?\n. hmm, this can't work, can it? there is an overloading on WasmType and on int32_t, wouldn't the latter always win? why do we even need the explicit one? maybe I'm missing something?\n. Even with explicit, it's still a concern, isn't it? Your c++ is better than mine, but I seem to recall that the type system doesn't differentiate enums from ints. I.e. Literal(2) could be the enum or the int32_t, couldn't it?\nAs all the tests pass, this must be fine currently. I'm just worried :)\n. I don't get it. I asked why we need a minimum size. I'm not sure why it not being aligned is a response to that?\n. 1. But for that, you only need 7 extra bytes. The minimum size here is 1 << 12 = 4096?\n2. Why does it need to be aligned in the first place? All the methods here are designed to work properly even if it isn't?\n. 1. Well, but how does 4096 fix it? Why is that the magic number? :)\n2. Oh, I see. Well, why couldn't they check if &memory[address] were aligned?\n. Thanks, fixed.\n. Yes, let's make this a flag.\n. pointerSize would be more consistent\n. it would actually be more efficient to put the stack at the very end. The reason is that we will have baked constants to globals, and if they are first then they might be smaller than if they are after the stack, which might be a few MB. It's very possible that the stack being first would lead to extra bytes in the LEB128 encoding of those baked constants.\n. I think we plan to allow catchable faults on arbitrary ranges, so we could detect such overflows elsewhere as well. At least that's my recollection here, I could be wrong.\nIn any case the code size different is significant. I don't remember numbers in emscripten, but we switched to this after noticing it was a worthwhile code size win (on JS numbers, but LEB128 would be sort of similar).\n. {,} if body is on another line, please\n. why no cast here like in the unsigned case?\n. placeStackPointer for consistency, please\n. Yeah, either way is fine (same line, or different line but with braces).\nI am just allergic to newlines without braces ;) It's the one thing I feel strongly about in C++ syntax.\n. why?\n. same line, or {,} please\n. in other places with similar things, we create cmd first, then after it we do if condition then append to it etc., I think that's simpler\n. this should be a Name\n. unless i'm missing something, i don't think you need this. you can access wasm.functionsMap[name] to get the Function object for a function name.\n. I don't understand what this addition does. Isn't the start an already existing function? What kind of work do we need to do here?\n. as mentioned earlier, the name seems wrong to me, if (1) we create the stack pointer anyhow, and (2) the stack might be created by a runtime later. Instead, how about --create-stack or --create-stack-segment? The last seems most precise, but maybe long.\n. Or --create-stack-storage?\n. Or --allocate-stack?\n. Heh, I think we just wrote it at the same time ;) Sounds great!\n. please rename this too\n. Seems less natural to me, but whatever :)\n. Sorry, I wasn't asking about that line. I mean this entire part of the diff.\nIOW I have no idea what this pull request actually does, since this is the main part! :)\n. Why doesn't startFunction.is() work..?\n. isn't startFunction null if not used? Then checking is() which checks the pointer is not null would be fine?\nor are you saying startFunction has a valid pointer that points to an empty string?\n. Let me try to be clearer. This line, and the big multiline change under it - lines 1201 to 1236 - are completely unclear to me. Why do they exist? What to they do?\n. But we use Name extensively, for performance reasons. I'd rather use Name for startFunction as well. Is there a reason not to?\n. I'm ok to change the API to make it more idiomatic if you want, let's discuss.\nBut in general I think Name is the right thing for the AST - we know it helps perf hugely there. And anything interfacing with that should be a Name or else we'll have constant weird mismatches of std::string here but Name there. That's what I want to avoid.\n. Thanks, now I see.\nWhy is this in s2wasm? Should'nt the backend do this?\n. yes, see the commit. this was doing a wast=>wast transform. But it's impossible to do when the spec changes - the before state will not parse.\n. hmm actually this and the catch below should be for a third type, a ParseException perhaps? It's not a runtime trap.\n. and I guess I added this line and it's not strictly necessary. but maybe nice for clarity, better than the setting 4 lines above?\n. that's the bits per character, isn't it? on some systems the bits per character might not be 8?\n. There are spec tests for this, yes. But I don't know offhand what they do, just that this passes them ;)\n. No, it's already stored as just bits in the i32. We never store float values directly.\n. Spec test suite has a lot of tests for this. Hopefully it covers all invalid inputs.\n. Hmm yeah, that's wrong. Fixing.\n. darn time and it's slow inexorable march\n. Almost, the order would be wrong. What is really needed is to overload the << operator I suppose, in the std namespace? I'm always wary about doing that...\n. (overload it on some new object, of course, not a call)\n. :( I keep copy-pasting. Should we update all the existing ones too?\n. Ok. I fixed this one meanwhile.\n. why do we need finalize?\n. what is this for?\n. what is special about const, getlocal and setlocal?\n. would be good to split that out into a bugfix with a testcase, then. but surely this would already be tested?\n. Do we need this here? Printer is here so other places can use it, e.g. for debugging. But if this is only used by the user specifying it as a commandline pass, it doesn't need to be here.\n. I'd like to not add things in wasm.h - for example, we moved printing out. Do we need metrics here?\n. Perhaps we should just make this a pass, and allow wasm-as to run passes?\n. Or perhaps we should wait with that for a future refactoring of binaryen-shell that can load and store binaries.\n. Then does #208 require this addition to wasm.h? Could we remove it from here and have it only there, if so? I'd hope we don't need this even there, though.\n. please make it initialMemory in camelCase like the others\n. this and the one after it need to be rounded up, like in s2wasm, don't they?\n. what's this?\n. what changed here?\n. need .exports here too\n. everything looks good except I'm puzzled at these ror and rol methods - where are those provided?\n. got it. perhaps let's move these to src/support/bits.h? lgtm with that.\n. should be Names\n. instead of doing this here and in the other place below, how about doing a loop over globls in fix(), which runs at the very end?\n. Thanks! I should read docs more... ;)\n. Thanks, I missed that.\n. this needs to check for debug\n. literally the same two lines are outside of the if, so how about removing these two and flipping the if condition?\n. ditto\n. Seems ok to add them for future use.\n. It would have just 2 values though, and seem inconsistent with the next param after it, which is a bool?\n. How would accessing the values look?\nThe issue is that e.g. Binary is the name of something else as well, so it needs Flags:: or some other prefix. And Flags:: seems ok to me.\n. Then you'd need two such enums (to avoid mixing them up), and can't write Flags::, though, right? Currently you can write Flags:: and it still avoids mixing them up, I believe.\n. spaces around section\n. the names need quotation marks around them\n. actually let's keep it 1, then plus alignment it will be 16 (or the proper amount)?\n. extra space before allocateStatic\n. Also it will work if there isn't a stack.\n. There isn't a stack in this file, why are we adding memory? Seems like we shouldn't allocate the stack if there isn't one. So something is going wrong.\n. are you sure this gets written to before it's read? I think that's not the case, and we do need this here (for when there is no stack, no globals, etc.).\n. Oh right, sorry. I was reading it wrong.\n. It has not only the visitor, which visits one node, but the walker, which walks a whole AST. And we should add more walkers (pre-order, in order, etc.). \"Traversal\" seems to cover both visiting and walking?\n. indentation looks wrong\nlgtm with that fixed\n. I'm confused, we have lots of stuff in headers, why does this one worry you in particular? It's not a terribly large class.\nOverall I think this header could contain a bunch of traversal algorithms. Most passes would use one of them. We could break them out into many small headers, but I'm not sure of the need for that?\n. And it can't be a c++ file, it has to be a header file?\n. Yeah, this is a class to be derived from.\nYes, in theory they could be in C++ files. Probably we should make a libwasm.o at some point and have the other tools link to it, etc. For now though I don't think compile times are that bad, and it's an easy refactor if we do need it later.\n. I don't think so, the usage pattern is to inherit from the class and to use an instance of that child class, no need for virtual and its overhead.\n. It's a template in the latest patch, yeah - this is a wip pr :)\n. the main loop for non-recursive walking of the AST is here, in walk()\n. the scan() method here implements post-order traversal, for example, by pushing the right jobs to the stack.\n. Any node with multiple operands, basically. What I mean is that if e.g. call_indirect has a value to call and operands, then we traverse in the same order the interpreter would. That means when the spec changes order, as it has, this would change here.\n. Sounds good, changing.\n. std::function is nicer in a way, I agree, but also more generic and hard to optimize (I doubt any compiler would reduce it to a single pointer).\nReturning an expression has the downside that the visit* methods would need to return a value. Many (most?) passes don't need replacing, so it's extra annoying boilerplate, I think.\n. I'm not totally sure, @jfbastien might know. The macro might emit a builtin_unreachable, which may not be quite the same as abort. In particular, abort is guaranteed to execute, while unreachable might be considered undefined behavior and ignored?\n. Nice, thanks. Changing.\n. I tried some more now to get something like this to work. I can't quite seem to find a good way that doesn't have other downsides (like relying on overloading of visit(Expression*) vs visit(Block*), which seems potentially confusing if people forget to downcast), and that compiles ;) Perhaps if we find a good approach here we can do it as a followup.\n. Makes sense, assuming in non-production builds it still aborts? Filed #335 to follow up and fix this across the whole codebase.\n. Yes, just like the others, they can all call replaceCurrent. I'll add a comment.\n. True, and the replacing can \"race\". Perhaps it's best to document as the visit method not being allowed to replace. Another option is to get rid of the generic visit, but it is quite nice for e.g. the Metrics pass. But perhaps there could be a special class with only the generic visitor for that kind of thing? Not sure what's best.\n. Looks like old forgotten code, thanks. Will remove in followup.\n. very minor comment: would it be possible to write {} for the locals argument? would be nice to avoid the extra line to define them before.\n. I think it's a little nicer to nest the makeGetLocal calls in the makeCallIndirect, can avoid the two local variables that way.\n. done.\n. just a cleanup. with the new pass times logging, logging is much more useful, and other excessive logging was drowning it out. removing it, i ended up removing all use of debug in this class, at which point the compiler errors on the property not being used, so I removed the property too, and at that stage, I figured leaving it in comments was silly.\n. hmm, i wasn't familiar with that so I read up on it now. I'm not sure how to use it here - we need it to start its life initialized to false, before any code runs (it might be read by a global ctor), and that class doesn't allow = false?\n. Hmm, I still don't follow. The docs say I can clear it, or set it to true and get the previous value. But how can I just check if it's true or false, without changing it, which we need here? Sorry if this is a stupid question.\n. Ok, cool.\n. this was causing the excessive logging in debug mode. removing it forces removing the property from the class or else the compiler errors on unused property.\n. Me too, every time I have to type all that unique_ptr stuff...\n. I would say TIL but after reading some of those links, I'm even more confused... ;)\n. What do you mean \"main\"? The C main() function? Then we'd need to do this in each tool separately (shell, wasm-as, wasm-dis, asm2wasm, s2wasm, etc.)? That seems... sad. Is there no better way?\n. metrics pass is an example of a pass that wants the new UnifiedExpressionVisitor.\n. Done.\n. The emscripten.h header has an EM_ASM macro that allows inline JS to be written. It's turned into a call to the outside using emscripten_asm_const(), and the runtime then runs the JS that was written there.\nIn wasm, we can't overload on imports, each import has a specific function type. So we convert emscripten_asm_const() into emscripten_asm_const_vii() for example, where vii is the signature (void return, two int params).\nThe pass also saves the JS code itself, which is just a string in the data section. (In theory we could have the backend emit it as metadata so we didn't need to do that part.)\n. why is this test changed? is the wasm backend output changing?\n. Oh, ok.\n. please add a comment here explaining this class\n. i don't like the ad-hoc nature of this function. how about a boolean starting false that is flipped to true when we do any processing, and return that boolean here?\n. I'm still not happy about this. In theory it should call a Module.isEmpty() utility. But even that seems odd...\nIs this actually checking if the module is empty? Or whether it has already been written to?\n. Destructors are unneeded - we allocate in areas, which are destroyed all at once. As a result, arena-allocated classes can't have destructors, as they wouldn't be called. (This causes some leaks currently, which I have a patch in progress for.)\nIn other words, when you don't need something in an arena, just forget about it.\n. please just allocate normally here - while you save some resources in theory, you depend on node sizes.\n. I see. Ok, how about this: in ast_utils.h, there is a nop() method which turns any node into a nop, which is safe since it's the smallest. We can add a reuse() (or some better name) that reuses a node as you are doing here, and is templated on the types being swapped, and has an assert on the size being <=. Then this should be safe to do.\n. And then nop() can just call that method with a conversion to a nop.\nAbout a name, perhaps template <classname OriginalType, classname TargetType>TargetType* convertTo(OriginalType *node)?\nCould be on the same object as nop in that header (unless there's a better idea).\n. If it's the details of how nop currently works, and yours is better, let's move nop to your approach, of course.\n. Or are you saying that can't be done for some reason?\n. I'm fine if we hide the ugliness inside a utility function. Also fine to do it as a followup to this. I can do that if you want.\nI suppose there is no harm in calling a destructor here, which would be a no-op.\n. based on the new location of this header, perhaps this name should include the subdir too?\n. please {} or same line (same line sounds better to me)\n. these should be Name\n. Oh, this is just throwaway code for testing on travis. Just makes the stack traces from leaks nicer to read. I'll remove when this PR is done and the leaks are gone.\n. This declares a destructor? Not sure what the question is?\n. What is the downside of that?\nWhat's a better alternative?\n. fixed.\n. how would this enum be used?\n. I think these serve a webidl-bindings purpose only. So it would be better to not have them in the core wasm.h. file. Perhaps in the same directory as the idl file?\n. typo signe\n. should be maskType, or alternatively we could rewrite this in python ;)\n. although I see this error exists later down in the code too... so can leave for now i guess\n. please only one space between : and {\notherwise lgtm\nbtw, if it's faster for you to do one PR with multiple small changes like this, i'm fine either way\n. Also for changes, but the main reason is that compilers using the C API might not want to use a C header. For example, Rust is not written in C, so it can't execute the C header to get those enum values. Instead it links with C libraries and calls methods on them using the C ABI.\n. Yeah, I can see an argument for varargs. But reasons against are that the LLVM API doesn't use it, and also there are probably ABI corner cases (maximum elements, maybe?).\n. Interesting point. I think you're right and we should probably have both. Although then it seems we'd also want an API to set the size of the basic block before incrementally adding to it (otherwise the vector contents would get reallocated)?\n. Hmm, yeah, we should do that. Also it might save space since it fits in a byte.\nHowever I think this might need to wait, as the gcc in Ubuntu 14.04 LTS has a bug on enum classes with int8_t that I've seen hit. Unless we do int8_t for the storage (no enum class, just plain int8_t) and an enum for the values, and do some casting, which maybe isn't so bad since it's only done internally in wasm.h?\n. That still doesn't help the Rust use case, though? Or did I misunderstand you?\n. Sounds good. First we need to add support for reserving space in arena-allocated arrays, then we could do this.\n. these constants seem odd. maybe add a comment?\n. I see. Yeah, I agree that might be nicer. There is the gcc bug mentioned in another comment on this PR, though, which worries me.\n. *bitwidth\notherwise lgtm\n. space after for\n. same line or {} please\n. what does this mean? perhaps add a comment. in what cases would that var be false and hit this path?\n. {} please\n. same line or {} please. ditto a few lines down\n. space after if\n. what does the return value mean?\n. (also a few more cases later in this file)\n. The indentation in this file looks off in some places, like here. Is it 1 space perhaps? Should be 2?\n. Yeah, i think it's specifically the public and private tags. In all the rest of the codebase they are zero-indented. I guess I'm ok either way (0 or 1), but let's make it consistent with the rest.\n. Sounds good in principle, I haven't used clang-format much myself though. Looking at the options, it seems to have a great deal, but I'm not sure it has enough stuff we currently have and wouldn't force stuff we don't? Or perhaps it's not too bad if not, but I guess i'd like to see the closest style it could emit.\n. Sure, fixing.\n. Hmm, seems more complicated? In particular we need that for the example tests, and if I understand RPATH, it wouldn't help there (since we don't build them in cmake, we intentionally build them in  check.py to simulate what a user would do).\n. A tricky thing with static is that it creates a .a file, and that means it only links in methods as needed. But we allow passes to be added by name, and they are registered by globals (like LLVM does commandline param registration). It looks like that wasn't enough, and the passes were not getting linked in.\nI would have spent more time to investigate that, but anyhow I think many users will want a dynamic library, e.g. Rust.\nIf rpath can fix this, that sounds good, I just have only heard about it in this issue :) How would it fix the check.py-compiled programs? (your link was cmake-specific, unless I misunderstood?)\n. please explain why this is useful\n. & on the type please\n. Oops, thanks, that's obsolete now. I'll remove the comment.\n. perhaps it could be lib/*?\n. Hmm, probably we should change that too, I suppose. Anyhow, doesn't need to be in this PR.\n. how about const and & for the vector?\n. auto* please\n. this is O(N^2), if I am not mistaken?\nsome projects can have tons of tiny functions, so I think we should keep this linear. In e.g. Vacuum.cpp we use a simple skipping pattern,\nint skip = 0;\n    for (int z = 0; ..  ; z++) {\n      if (skip it) {\n        skip++;\n      } else {\n        if (skip > 0) {\n          list[z - skip] = list[z];\n        }\n      }\n    .. after loop, resize if skip > 0\nMaybe we could even make a utility function that does that, and use it here? Or maybe it's too trivial.\n. my const-fu is weak, would that make the pointer const or the object pointed to?\n. indentation looks wrong?\n. I assume that ends up linear time? If so sounds good, much nicer.\n. Cool, thanks.\nOk, I guess writing it either way would be ok with me. We don't modify the functions, but on the other hand it is a little clutter too.\n. Not necessary, but it does add a compiler check that the type here is in fact a pointer. Imagine if root is changed to be a list of some object that is heavy to copy, then this line would error on such a change if it has auto*, but silently be slow without.\n. can't offsets be negative?\n. oh right, there was a proposal, but it's not accepted i guess.\nlgtm\n. auto* also here\n. I think we should have a toAddress utility function that casts a uint64_t to and Address and checks for overflow, as it would be an error here.\nWe do still want uint64_t for those variables, since for wasm64 eventually we won't need that cast. At that point perhaps we'll have toAddress32 and toAddress64?\n. addr should be in the right range here, so there should be no risk of overflow. however, if we have a toAddress utility function that checks for overflow, it would still be a useful assert check here, so as in the other pr I think it makes sense to do.\n. empty line before new namespace please\n. we don't have spaces after operator in other places. but this does look nice. just making sure it's not unintentional.\n. please keep the order as in the enum, so first i32, then i64 stuff, etc.\n. i'd rather not modify wasm.h for this js-required change.\n. what changed here?\n. newline after this typedef please\n. Method sounds good to me since there are going to be multiple uses. Can leave the others for a followup PR, I agree.\nHow about asserting on the right range in the function?\n. Yes, let's add an assert here. But I think its enough to check on the maximum size of the type (a more specific check would require some overhead in getting that information to here).\n. How about defining a JSFriendlyLiteral (with a better name perhaps ;)), and all the webidl bindings would return that? It would be a subclass that adds these convenience methods.\nAlternatively, we can fix this up in JS dynamically (add those methods directly) but that's probably less clean.\n. sadly this gets rid of this comment that i rather liked\n. Oh, too bad. Do you happen to know why?\nNot hard to write our own, I guess.\n. i think python has shutil.rmtree for stuff like this\n. I filed #520 for this.\n. The mapLocals code? It should definitely be executed, unless something very strange has gone wrong. Maybe add a printf to verify it is run?\nThe code looks right to me, curr values there begin at 0 and increase. Unless I'm missing a bug?\n. indentation looks wrong here\n. I'm not sure about the second parameter. It does help in some cases, but we may not always have that information around, and we'd need to write a lot of getFunction()->getNumLocals(). I suggest just asserting on just the size of the type, assert(index <= std::numeric_limits<uint32_t>::max()).\n. Let's do just one parameter for now. For better checks, I think we might find a better option, like a method on the function func->toLocalIndex(i), for example, but let's leave that discussion for later.\n. instead of calling toIndex, we can just use Index as the type of i. I suppose then we'd need toIndex on the size() output? that is still less code clutter though.\nbut I would like to not even have the toIndex on the size() call. The array type could be modified, perhaps?\n. not sure I like a macro here.\nmaybe the bigger question is, do we need this cast? and the next cast after it, int32_t ret = (int32_t)o.size(); - are those strictly necessary? they add code clutter and confusion. i'm not sure i understand why we need them.\n. indentation looks broken here\n. There is another option though, of params being a type that has size() returning Index, instead of an std::vector. (Perhaps an IndexedVector?) Anyhow, just a thought, maybe it's a bad idea, but I also think lots of toIndex calls is bad as well.\nThe only think toIndex saves us from is if the number of params is more than can fit in a 32-bit value? I don't think that risk is worth the cast. I do think the cast is useful when receiving outside input, like when parsing s-expressions. But internally, like here, it feels like just clutter.\n. I agree on not doing more in this PR. Perhaps let's take out the SIZE32LEB then, and later think more on the types in this file?\n. Yes, those two are the relevant types.\n. That is useful, but I think the real question is where a non-32-bit value comes from. It's an array or map, perhaps those types should return 32-bit values anyhow, as mentioned before.\n. if we need this here, don't we need it every single place that we define Index i for a loop etc.? That sounds bad :(\n. I don't understand why this is needed, which suggests I don't understand something important. Both index and numNewLocals are of type Index. Why doesn't this just work without a cast, then?\n. what is ++(int)? shouldn't it be void?\n. this is the only constructor taking a value. does that mean that if we assign a uint32 to this, then it is converted to 64 bits, CheckValid is run, then it is cast to 32?\n. should be checkValid (no caps on C)\n. addr seems the wrong name now this was generalized. maybe value?\n. is there no solution for this? doing std:max or min on Indexes might not be that rare.\n. Interesting, TIL.\n. Why not just make a constructor receiving a uint32_t, though?\n. Nice! thanks @binji \nLet's use that here then?\n. if it's uint64_t, it would use that one, and uint32_t then the other, wouldn't it? We have such multiple constructors on Literal and things seem fine?\n. this wasn't obvious to me what it does, please add a comment\n. no need for the size var, can do it all on the next line\n. can use auto\n. also here\n. @sunfishcode: what's the status of .LBB and Lfunc_end? Looks like this PR has to introduce workarounds for them. Are they gone from .s now? Do we just need to update handwritten tests?\n. Perhaps we should add constructors to Literal for size_t, if that works? And do the same here? Overall Literal and this class have the same problem, so it would be consistent to solve it in the same way.\nI think literal 0 should be ok, if we do what Literal does, which is have a constructor for all [u]int[32|64]_t. int has to be one of those. I'm not sure if size_t is, I guess we can just try it and see (but given I don't think we have warnings on Literal usage, I tend to think it's already doing the right thing).\n. Cool, thanks @sunfishcode.\nOk, @yurydelendik, looks like the right approach to me in this pull. So aside from the comments I noted, lgtm.\n. First thing, thanks for this! :)\nAnd a comment on this line: this should not be possible, ifTrue must always exist. So this assertion is valid, however, the problem is happening at an earlier stage, so we should also add another fix somewhere. Is it possible to get the input that led to this?\n. same question about this, and then next change as well.\n. we read a 32-bit LEB into this, why isn't int32_t enough?\n. this assert could be an assert(ifTrue) on the previous line.\n. This assert could be before the if begins, as it is relevant for both cases.\n. Yes, this should be uint32_t, unsigned. But really, it should be the Index type.\n(In theory it's also bad that we use -1 as an invalid value, but the possibility of all 32 bits being used as function indexes is not practical. Might be worth a TODO note though.)\n. unnecessary comment\n. space after if\n. What is an \"extern type\"? The 4 things above it are actual properties of modules. Is this something for internal use? It seems like it should have a different API and not be alongside those 4. But, I'm not sure yet I even see the need for it - why not just use a function type?\n. I don't think we even need this? This is an implementation detail of llvm/s2wasm, it shouldn't cause additional complexity in wasm.h for all modules generated in all methods. That is, can't llvm/s2wasm just emit a normal function type for this, and use it like a normal function type - why do we need this map?\n. Hmm, I think it should all be in the linker, then.\n. We write gcc and use the gcc5 addon, so that it installs the same gcc5 toolchain in all builds in the matrix. This in particular ensures we install new-enough versions of libstdc++ and so forth, since what works for gcc5 also works for recent clang in terms of c++11+ support. Then, in the last build we actually use gcc5, and in the others, we override to use the waterfall clang.\nJust writing clang here isn't enough, as it uses old clang which does not install what waterfall clang needs. We would need to both write clang and use the clang36 addon, but that's what LLVM broke... Alternatively we could find the specific packages we need instead of using gcc5, however (1) we use gcc5 in the last build anyhow, so this seems simpler, and (2) I have no idea how to find the right packages ;)\n. could be Index (could matter in the future, when wasm64 has 64-bit Index, and the person is building on a 32-bit machine)\n. ditto could be Index\n. hmm, what's going on here? why is this needed now?\n. Ok, cool.\nlgtm\n. Before, if the input code happened to contain a method with this prefix we would get an error when adding the second one to the module. But after this change, it will silently use that existing method as a thunk. There's a chance that would hit a validation error, but also it might not, and cause weird errors.\nHoisting the thunk prefix into a global and checking all input methods do not have that prefix seems safer. (Might also be worth renaming the prefix to something with binaryen in the name, so a conflict is really unlikely.)\nAn alternative might be to run the duplicate-function-elimination pass after s2wasm. It would coalesce all the duplicate thunks. We can do this in just 3 lines of code, but it would add time. But^2, it's a useful pass anyhow, and pretty fast.\n. The optimization wouldn't help correctness, it would just help code size. Is this PR not just addressing code size, did I miss something?\n. I see, ok.\n. let's not make this optional. we don't have it optional in other parallel places.\n. if we need to add the module here, which seems reasonable, then let's get rid of the allocator. we don't need both.\n. Sure. But I'm guessing it's just a few simple errors, so seems simpler to fix them here? But if it's more than that or you're not sure, then I'm ok with a followup to make it mandatory.\n. Could we just use Fatal() here?\n. lgtm aside from that, very nice.\n. hmm, what is special about this location (and the few others)? what does VS need this-> here but not in 99% of the other places this is implicitly used?\n. Yeah, if we go with this PR, then all the PassRegistry stuff can go away too.\n. might be nicer to put this file in src/passes/\n. these have similar names but very different meanings. how about the longer name used below for the second, validateWebConstraints?\n. please add a test for validate=none where something bad does not error\n. we do using namespace wasm, why are these needed? ambiguity somehow I guess? is there some other make_unique in the global namespace?\n. could this be const auto?\n. this seems to copy the data, but I think @sunfishcode said this is an alias, so it should just refer to the same address\n. Even when quoted?\n. Thanks, I didn't realize that. I guess this change makes binaryen accept more s-expressions than the spec, then. On the other hand it was useful for rust code and might be for others. Maybe I'll suggest changing this in the spec repo.\n. indeed, thanks!\n. That would be great, @jasonwilliams200OK :)\n. please put the return on the same line, or use { }\n. Yeah, agreed, we should find a way to make this nicer.\n. Adding a commit for that.\n. Fixed.\n. Added a commit.\n. Yeah, I agree, this can assume passes are valid in release builds.\n. This code is reached when we execute the init statement for the global, which is when we instantiate the module, which is after we fully parse and validate it. That means we can assume the expression is valid, in which case none of these unreachables would be hit. Assuming we don't have a bug in our validation ;)\n. Look at https://github.com/WebAssembly/binaryen/pull/650/files/0dc286f78cd3d5d1f5fd1cb21c16485cd9f2fd1f#diff-33a3856e71772f6165f55c85cb076496R264 , it's actually a stronger check than needed - it only accepts Const (because that's all that is tested currently, and I'm not sure what else will be allowed).\n. I don't think we should add a property to the Function object in wasm.h. That represents a function in wasm in general, while this index is for the specific case of linking code from the wasm backend.\nInstead, the indirect index should be kept in the wasm-linker or s2wasm code.\n. code conventions are indirectIndexes\n. why is this here?\n. I think in c++11 you can just do {} instead of those std::vector<NameType>()s.\n. instead of adding to the table manually, you can do ensureFunctionIndex. perhaps it should be moved from an auto in a method to a proper method on the object.\n. is it really impossible to get a comparison to a function pointer without this? couldn't one compare (void*)17 to nullptr for example? I guess that's a weird thing we don't care about much ;) but i wonder if we shouldn't be totally general.\n. rawName\n. {} or same line\n. if this is wasm-backend specific code, perhaps it should be refactored out, in that .s files might in theory be generated by some other source. But I guess that other source would do the same thing. So maybe the comment can just be reworded to be more general?\n. I see. Perhaps the name of the function can add ForLLVM or such? And clarify in the docs that this is LLVM specific.\n. Fair enough.\n. I'm not sure this is the best approach. As discussed in https://github.com/kripken/emscripten/pull/4469, emcc will export malloc and free, the only reason this doesn't work for wasm is that wasm doesn't have a prefix _. Solving that core issue would probably fix/avoid some other issues as well in the wasm-backend path.\nBut, if we prefer to get this in for now as a workaround and figure things out later, I'm ok with that.\n. Yes, good point, it actually isn't the issue. This does send us in the right direction, though - emcc.py adds those methods to EXPORTED_FUNCTIONS, and that is used throughout emscripten (e.g. when running LLVM opts it makes sure to keep them alive) as well as exporting them from the asm.js module. So what we need is for emscripten to forward EXPORTED_FUNCTIONS to s2wasm (as a new parameter to s2wasm, sent from emscripten.py), and for it to export them from the wasm module, to parallel the asm.js case.\n. I don't think we need to do (1). We just need to handle the prefix difference (either before sending it, or when receiving it).\nI don't think the size of EXPORTED_FUNCTIONS would be a problem in practice. So I don't think we need to add an s2wasm option to read from a file, or we could leave that for later.\nBut if doing the more proper fix would slow you down and you'd prefer to just land this (with a TODO comment) and fix things later, I'm ok with that too, I don't want to hold things up.\n. Ok, this PR looks great now, except that I think this is unnecessary - WebIDL should be able to handle a simple pointer? In fact that's the default behavior, so just removing the [Ref] should make it work.\n. please link to https://github.com/kripken/emscripten/wiki/WebAssembly#testing-native-webassembly-in-browsers which has those chrome instructions plus others.\n. Instead of the pre and post bits to wrap and return the module, you can use emcc's MODULARIZE option. although then the code outside the function must be added after emcc, so maybe not worth it.\n. i'm having a hard time understanding this... what is Symbol? what does the code do with it?\n. these options look different than before. just curious how you picked them? was there a specific benefit to each over plain -Oz?\n. That part makes sense, yeah. I'm more curious about the llvm opts, lto, and duplicate function stuff.\n. the endif and if can be merged into an elif, since they are mutually exclusive.\n. same thing here\n. The headers will include that class, no need for this line.\n. It would be nice to put these methods in their own subnamespace or class, so wasm doesn't get cluttered. see ast_utils.h for some examples, would be nice to be consistent.\n. better to avoid adding bool arguments. could we just call generateMemoryGrowthFunction ourselves outside (if this isn't going to be called from anywhere else anyhow)? or we could add a parallel method on this class, emscriptenMemoryGrowthGlue or emscriptenGlueMemoryGrowth (glue as a verb in the latter ;) that we call from outside?\n. Almost, yeah, but to thread-safely initialize the static variable once, it would take a lock, wouldn't it? This code avoids that (by relying on the fact that we'll reach this on the main thread first).\n. Yeah, maybe you're right. But since this database is I am guessing hot, we should measure first.\n. this commit removes a hack and instead uses a static variable as suggested by @jfbastien in https://github.com/WebAssembly/binaryen/pull/694/files/c24b9f9f6af61abd9ef124837bee41cbba35a8f2#r78034581\n. can use builder.makeDrop\n. lgtm with that change\n. My understanding is that mutable globals can't be imported, as verified by the s-expression tests. So we don't need this field, unless it's for future use? If it is just for future use, then maybe this could wait for future refactoring of wasm.h (in particular I'd like to get rid of the Import class entirely, and then a Global could have an imported flag, and Global already has a mutable field).\n. {,} like the others please\n. I'm also ok to leave this as is though.\n. false is the default anyhow, so no need to set this field in this file? (otherwise for consistency it should be set in wasm-s-parser too, but no need for either)\n. I think you're right, will fix.\n. I saw the angry bots JS file still uses Wasm. Maybe it's wrong though?\n. Hmm, I prefer Kind I think. I'm not sure we need this just for external things, e.g. a function neither imported nor exported still has a \"Function\" kind, and some passes might need that (e.g. I'm planning a globalopt pass which would be in that situation). And the design repo uses both external_kind and kind, but mostly the latter. Finally, Kind is nice and short, and I don't think at risk of colliding with anything, at least that I can think of.\n. Not temporary. I'll add documentation.\n. https://github.com/WebAssembly/binaryen/pull/730\n. GlobalKind sounds like a good idea. Yeah, Table and Memory do fit in here (although globalopt won't do much with them until we have multiple tables and memories). So GlobalKind it is?\n. Ok.\n. Yeah, design repo uses external_kind for the type, but uses kind for the name which is more frequent - and while we are discussing the type here, that they can use kind for the name suggests no conflict.\nGood point about GlobalKind, since there is a Global... so I'm not sure what to do here.\n. Done.\n. I guess ExternalKind is ok, although we might need to add an InternalKind eventually.\n. Yeah, I want to call it Global too, but given Global means a global variable, it's too confusing. We'd need to call Global \"Var\" or something like that, diverging from other repos' conventions.\nModuleValue is a possibility, but I'm not sure. It's not familiar like Global, and things might change (maybe functions aren't just owned by modules some day?).\nExternalKind seems best, it's consistent with the design and wabt repos, and the main downside is we might need to add an InternalKind some day, which isn't the end of the world even if it comes to that.\n. Fixed.\n. imported seems more consistent with the nearby names like exists. If we had isImported, we should have had doesExist.\n. Turns out we already do that later down when we create the import - we mark the table as both imported and existing on consecutive lines. Seems ok that way to me.\n. The constructor sets the max to kMax (indicating a growable table with no maximum). So the initial isn't strictly needed, just the max, but it feels nicer I think to set them both here, clarifying that we start the table at fixed size 0.\n. I think in practice the name doesn't matter since there is only one table/memory, yeah, so ok to leave as is for now.\n. does this check it isn't a directory?\ndid something change in this PR that adds a new directory?\n. at what time would these operations happen?\n. At first I thought it's not urgent to do the better fix, as normally we don't use code from the bin/ dir. But actually this + the emscripten PR makes us use stuff from bin/, like the js glue code file? That means that as I debug it, I'd need to remember to manually do cmake all the time - which sounds error prone and burdensome.\nAnd actually, even having to run make to get the js glue code file to be copied to bin/ seems like a worse developer experience than we have now.\nOverall it seems the old way, of using the js glue from the src dir, etc. and not using more stuff in bin/ is better - except for when creating a distribution, I guess. So doing something special for a distribution might be an alternative?\n. please add {, } for an if body that is not on the same line\n. needs to be indented\n. can be just str, no prefix\n. this looks worrying, if the include is included in multiple files it will conflict at link time\ndo we actually need a static variable here? if we do, we could define it in a single cpp file (i guess wasm.cpp for now, although it would be nice to have wasm-interpreter.cpp eventually)\n. I think wasm-traversal.h would be a more targeted header to include for that.\n. Yeah, these can be contradictory. One option is to have a single \"axis\", 0,1,2,3,s,z, but the downside there is that s,z implicitly suggest something like 2. So it seems nicer to me to have separate opt and shrink levels (with s=1, z=2). That's how emcc does it internally. But if there's a downside we could change that?\n. might as well be bytes == 8, clearer I think\n. this test passes for me before this PR, using the interpreter\n. Hmm, asm2wasm does emit i64.store in printf code, but looks like of only 8 bytes. So yeah, I guess the test should go in the wasm_backend section.\nThat raises another question, when does the wasm backend emit i64.store4 etc.? Thinking about it now, it seems surprising it's much useful. At best it can save a little by replacing i32.store + i32.wrap? And looking in asm2wasm output, I don't see cases of that which could be folded, so I am wondering what the wasm backend is doing differently?\n. Sounds good, let's leave the test here then. I'll make asm2wasm optimize to create that pattern, and then this will be tested that way.\n. Ok #792 now creates i64.store8 in asm2wasm, verified in the output. But it still executes this file ok without this PR... so I'm not seeing this test provide coverage for the issue, but no idea why. Does it depend on something else in the wasm-backend output?\nAnyhow, if this is a hassle to figure out, I guess it's ok to leave it.\n. Yeah, is that not valid for wasts? Seems odd to disallow it.\nAnyhow, I updated the test.\n. Yeah, and with that opt I see it converted to an i64.store8.\nBut anyhow, we can merge this and leave the mystery alone. But you did actually see the fix in this PR fix something for the wasm backend?\n. Oh, I guess it's obvious, the bug was it wrote too many bytes. asm2wasm layout probably happens to have nothing important after those bytes, while wasm-backend does.\n. Yes, but make sure you optimize (e.g. -Os) , as this doesn't happen without opts.\n. Ohhhhhhhh wait a minute, my mistake. I forgot that now my code will run in native VM support, so I wasn't testing the interpreter at all...\nYes, in the interpreter I do see this properly fail before your fix.\n. I guess that makes sense, yeah.\nWe should probably not accept that in the parser, but as we think we should replace the parser anyhow, doesn't seem worth fixing.\n. can we avoid this? we don't do it elsewhere. (I see you mostly capture std::cout to o anyhow, so it shouldn't mess up the code much.)\n. oh, also maybe add to the comment here how to run graphviz to get a picture?\n. doesn't this remove the ability to force colors on with COLORS=1?\n. I see, thank you.\n. endl is actually better as on windows it does the right thing, \\r\\n.\n. perhaps printWrap could get a std::ostream& and write to that, instead of always writing to std::cerr?\n. Interesting, that's new to me too. So yeah, I guess just \\n is best then?\n. how about auto here?\n. If the cashew::IString stuff is related, then it could all be converted to Name, which would be better anyhow.\n. PotentiallyTrapping does sound better, thanks, will do that.. please move the & to the type of the last param (std::string).. this is the new local that was added. why is  this change needed?. Instead of WebAsm, we should use Wasm.. please follow the style conventions in other files. here, the { should be on the same line as the struct.. we don't use m_ for member variables. So this one would be debugInfo, etc.. { on previous line. spaces around >. similarly, spaces around - and below == etc.. how about calling these methods writeText and writeBinary. not sure about this, but perhaps we should tolerate other suffixes, and default them to either text or binary. currently check.py will emit some other suffixes, which I guess we could change, but it might be simpler not to. Defaulting to text would be the simplest, as it's what check.py does.. as before, webasm => wasm. you can use a c++ finally block for the delete. And also, since this class should be able to read and write, so it does general input/output, perhaps we could call it WasmIO.. Or actually, how about a Reader helper class for reading, and Writer class for writing. Also no need for Wasm as a prefix as it's in the namespace already.. isn't this loop what ADD_NONDEBUG_COMPILE_FLAG does? (I don't know cmake well, but superficially it looks similar). if not, maybe a utility function alongside that one?\notherwise lgtm but i know almost nothing about windows.. Thanks, done.. what is using?. indentation looks wrong. ditto about indentation. cool, never seen it before. Good point, yeah: #894.. Yeah, I considered that, but instead I documented this in more detail in the test itself. i.e., we might have just one PRINT_FULL file with multiple small unit tests inside it eventually, with some text describing each one in the file. I prefer that because a filename isn't much room to go into detail. if i'm in the minority though i can change that.. Fair point, I wanted to keep my options open ;) In case we do want multiple files, this would mean we don't need to change anything.\nAnyhow, I don't feel strongly about any of it. If you do, let me know what you'd prefer.. It's needed for abort, this just wasn't noticed before because other locations happened to have the include anyhow, I think.. Yeah, good point, fixing.. Fixing. I worry it will be less efficient, but I guess a modern compiler should be able to do this well.... Sure.. Good point, yeah. Changing to checkDebugInfo which is consistent with other stuff in wasm.h.. Fair points, but which toplevel? Of the object? Or the entire file?. ok, refactored to top level in the file. Yeah, might be a better way. The code is not expected to change much if at all, though, so I think it's maintainable as it is. If it were evolving code definitely it would need to be refactored.. Heh, it's actually the semicolon at the end, \"use asm\";. I'll clarify.. Good point, fixing.. this file is removed because it moved repos a while ago, the copy here was forgotten. removing it now because it contains stuff that refers to the old ffi mechanism, so it could potentially confuse people grepping . I'd rather not do this in wasm.h since it tries to be super-minimal. And it seems like there are dozens of other small functions like that.\nPerhaps we should move Name out of wasm.h, into name.h perhaps? Or support/name.h? In that case, having it in the class sounds ok to me.. kind of the same concern, I'd rather keep this out of wasm.h. How about adding it to a header in ast/, perhaps something like module.h or module_utils.h (i'm not great at naming consistency myself). It should have been done before I think just for cleanliness, yeah, but also I realized that if we walk the initializer expression of a segment, then we are walking an expression which does not have a function. So the current function should be null, to avoid confusion.. Yeah, a walk will set things up, then call all the necessary visitors etc. The visitors do nothing by default and are meant for specific traversals to implement.\n. Yeah, we init it to nullptr. So with this change it should always be in the right state.. Good idea, will make it const.. A problem though is that it means code can't easily be moved around, as we might need to add nested to the name. A concrete example is printing: we might call print as a toplevel thing, in wasm-dis for example (when it prints out the output), but we also call print in other cases, some of which happen to be inside other passes.\nSo I don't think this is optimal either way, as I agree with your criticism of the current code in this PR. However, as this is purely meant for BINARYEN_PASS_DEBUG, a weird debug mode, I am not too worried about cleanliness in this code itself. While adding a nested version means lack of cleanliness outside, which worries me more.\nHowever, perhaps the nested version makes sense for other reasons?. Yeah, maybe the nested versions will want to parallelize sub-passes differently too.. Actually I'm refactored this now, I think the concept of a nested pass runner is an important one, so I'm convinced to go more in the direction you suggested. I propose we have a NestedPassRunner class that handles this, instead of a method (see commit), since I think we'll need the fact it's nested in more places. Thoughts?. I see it could work that way too, but I think we do still want isNested(), as it should be useful elsewhere. An example could be that nested passes do not want to use multiple threads, or have other limits on their parallelization. They may also want to validate differently.\nSplitting up run into doRun and doRunDebug seems like a separate issue. No strong feelings on that, if you think it's important to do here I can do it.. Well, I do like that pretty much all the core AST fits in one header. I think splitting out Name and Literal makes sense - they are more separate - but perhaps not Module, Const, Binary, Export, etc. - i.e. not module and its contents. I suppose that separation is subjective to some extent, though.. Good idea, fixing.. Also good idea, thanks.. Basically, it does seem to make sense to have the information of \"run a set of passes\" vs \"I am a pass, and I want to run some internal passes\". And a nice API for that is \"create a runner for nested passes\".\nI agree if we add another type of pass runner then there could be a problem. I don't see a reason for that, but who knows, yeah.\nInstead, are you suggesting that whether we are nested or not would be a property, and specified in the constructor or such?. Yeah, that suggested PR sounds good.. Ok, good points. I'll add a setIsNested as you suggest, removing the inheritance. Seems clearer and more future-proof.. side note, unrelated to this PR, we should probably clean up these 5 methods into a more proper place. these were self-documenting with the code inline ;) perhaps now we should add a comment saying that try* is like get but returns an empty result if not found, etc?. same here, feels like more comments are needed when the meaning isn't right there. I actually think tryLocalName is pretty clear - it tries to get it instead of just assuming it's there. Just me? :)\nI'm ok with @dschuff's suggestion too.. Yeah, those should have the same name convention I suppose (there is a slight difference in that one checks for optional metadata while the other checks for the existence of something non-optional, but not worth a different name probably).\nI think try is good enough, no need for tryGet. But again, maybe that's just me ;) @dschuff's approach applied here might be getFunctionTypeOrNull which I'm ok with too (verbose, but clear).. Yeah, worth trying that.. convention is nameType etc. for these new vars. we could use it at the end, to compare pos and see it incremented by the right amount? unless I'm missing something. Oh, heh, nice :)\nBtw, is the other code you mention your gcc wasm backend? Are you connecting those in some way, or just using binaryen to inspect the output from gcc?. I see, thanks. I'd be curious to see how the binaryen optimizer works on your output. It's a goal for it to be as general purpose as possible, so testing on more compilers can help.. No, because that's the same as having an empty else arm. So if the condition is not taken, we do reach the outside.. WASM_UNREACHABLE(). stale comment. contents of struct should go on a new line, for consistency with the others. Thanks, yeah, that could be nicer. A refactored this a bit. Should also address the second comment I think.. Probably we can increase it, yeah. The reason I'm being conservative in this PR is that the use case we've seen so far involves small functions, and that we do need to optimize after inlining, so a very big function might make that slow (depends on the function we inline into as well, which isn't measured yet...).. Yeah, this is something LLVM LTO should be able to do. But we can do it much faster ;). Makes sense, updated.. Good point, added a comment.. maybe worth logging something out here and later down? then if it fails on some platform, that might help figure things out. We already have a bunch of logs (Building with etc.) anyhow.. yeah, we could. call imports are rare enough that i doubt it matters, and this is debug info mode after all. what do you think?. To do that properly, we should also refactor the name of those intrinsics, which I notice now is emscripten_debuginfo, but should probably be moved out of asm2wasm.h into debugInfo.h or such and renamed to binaryen_debuginfo (it's in asm2wasm.h now because I prototyped the approach there). Maybe worth doing later.. how about renaming to legalizeJSFFI?. Or maybe legalizeJavaScriptFFI. oops, yeah, that was a copy-paste bug. less amusing imo but sure ;). not for our purposes. adding comments.. Yeah, the whole found stuff was messy. Actually it wasn't needed. I'll remove it which simplifies a bunch, and add more comments, let me know what you think.. But doLoad itself takes a template argument, and also it's a function... can that even work?. I'm not sure I like that better. the current code is ast-ey, it's structured. do you really find it less readable?. Good point, adding now.. Hmm, another option is in the last commit. Gets rid of duplicating the switch, by adding a bunch of new virtual funcs. Maybe that's clearer, what do you think?. I can almost get there,\nstd::vector<char> temp;\n      Builder builder(*wasm);\n      wasm->memory.segments.push_back(\n        Memory::Segment(\n          builder.makeConst(Literal(int32_t(0))),\n          temp\n        )\n      );\nbut the compiler doesn't like me getting rid of temp, it complains about invalid initialization of non-const reference.... Yeah, macros might remove some code, but debugging them can be a nightmare in my experience, for stuff like this.. Makes sense. That's a change to wasm.h, so maybe let's leave that for later work, already quite a lot in this pr.. https://github.com/WebAssembly/binaryen/pull/985. rebased and added this too. does anyone know why mingw is special here?. please add a comment for this. i assume it's that unix stack sizes are normally 8MB but we need to add this for mingw?. I'm not sure, but the reason I am guessing it's mingw-specific is that people have built and used this with vs. At least I think so, I didn't do it myself.... The latter, yeah. This is in the interpreter, and everything it receives must be valid code, so it's an internal compiler error if it isn't.. The main ones do, but some others don't like user sections? I guess those can also appear twice too, so this happens to be ok...\nAnyhow, we should eventually check the order regardless since it's correct, as you say. Meanwhile #995 does @dschuff's optimizations.. I think when we generate the asm.js text, on windows the text-handling python code in windows just emits \\rs automatically. @juj knows more.\nIf there is no danger here, then opening as binary sounds ok, but I don't know enough about windows and text handling there.. In what case is this not valid? Re-reading the code, gNames is the mapping of old to new names, so why wouldn't a name have a mapping entry?. In the binary format code we can assume that the module is valid, so curr->name must be a valid value. What are you trying to achieve here, there might be a better way?. no need to leave the commented-out lines.\nwe will need tests for modules without these imports, in test/merge/. Oh I thought this was merged already. I did this in the followup #995.. it's true we don't catch it, but cleaning up the env var change is nice since the exception might be caught higher up. Yeah, we do clear in the second part of the code in the try, but you're right, that's not enough. Will fix.. Yeah, that might be nicer, will fix.. Currently it's just 1 or -1, yeah. Maybe it's my math background, but +1/-1 is more clear to me than an enum...?. Correct, br_table always has a condition on which it branches.. Good idea, fixing.. Yeah, fixing.. Fair enough, seems equal to me either way, fixing.. Good idea, fixing.. Thinking on this some more, in theory we might want other values than -1/+1. Right now the analysis looks at a single break at a time, but in theory, we could scan an expression and batch the changes into a single change per break target. That actually might be more efficient, as operations might cancel out, i.e. add 2, remove 2, that ends up with 0 and so can just not do anything.\nBut honestly, my bigger reason for finding +1/-1 more natural is just that personally to me, a function that adjusts the number of breaks, and receives the amount, is simpler compared to a function that performs an operation on the number of breaks, where the operation can be \"add\" or \"remove\". I think in that case, I'd prefer two separate methods, addBreak/removeBreak, as sending in the operation seems \"heavy\", in the sense of too much design pattern abstraction (\"this method does an operation; we pass in what operation to be done, and it does the operation\"). Whereas sending in an amount is just an integer to be added, it seems natural to me.\nOverall, I admit this comes down to subjective stuff in the end.. i think space after { and before } is what we have more commonly in the codebase.. what does this do?. if we are emitting binary, and not emitting a binary map, we can drop the debug info, I think? I.e. replace !emitBinary with something like (!emitBinary || !binaryMapFile). i think a more consistent api might be to have, like we have setBinary now (used a few lines above), setBinaryMapFile and setBinaryMapURL methods that we call. then we can avoid calling writeBinary here.. std::unique_ptr. spaces before and after each <<. how about using the operator, i.e. !(other == *this)?. since the tools now emit the source map directly, do we need binarymap here?. so --binarymap-file emits a source map? what i am asking is, should we change the parameter names to --source-map or something similar, if they just emit a source map?\nor am I missing something here? is there still a binary file, with a \"reference\"? if so where is that documented, i don't think i see it in t he design pr?. yes, those names sound good.\nto make sure i understand, the current state is now that we emit just 2 files, the wasm binary (which has a section that has the URL) and the JSON source map file (which that URL should point to)?. looks like this uses some new test output files in the test dir. please also update auto_update_tests.py which should generate all the test output files in the test folder. here and in a few more places, spaces after { and before } would be more consistent with the rest of the code. these are duplicated in two files. i am currently getting rid of most of the existing duplication in #1023. it would be good to do the same thing for these options, however, i understand if you want to land this first and leave the refactoring to followup work.. this looks weird, it used to be the same name, but now it is different. perhaps add a comment, \"if debug info is used, then we want to emit the names section\" (is that correct?). indentation looks wrong here?. if body of if is on another line, please use {,}. indentation looks larger than the 2 it should be. if identation is too big, and need { }. also here and later down, need {}. Hmm, that does sound like a good idea, but when I try it I get\n````\nin-class initialization of static data member \u2018const string wasm::OptimizationOptions::DEFAULT_OPT_PASSES\u2019 of non-literal type\ncall to non-constexpr function\nI tried changing it to a `const char*` but it still complains about\nerror: \u2018constexpr\u2019 needed for in-class initialization of static data member \u2018const char* wasm::OptimizationOptions::DEFAULT_OPT_PASSES\u2019 of non-integral type\n```. Thanks, updated.. Yeah, good point, we'll need more refactoring here. Definitely let's leave for later.. isa.wasmthe right place for this? it should be stored wherecheck.pylooks for it.. I agree, this looks like a necessary C API change. (We should have done it when we changed how block types work.). it's better to instead callfinalize(type)if a type is provided, as it is more efficient. did you figure out where this was needed? it's possibly a bug in emscripten that we should figure out. for backwards compatibility, we could in theory see iftypeis undefined, and set it tononeotherwise. this should happen anyhow since its coerced to an int, but i think it would be nicer to do so explicitly.. Yeah, that looks right.. same question as before, and, is this needed twice?. actually there is something ambiguous here. if type is 0, that means the none type, and we could also callfinalize(none)`. but that means that there is no way for the user to say \"figure out the type\" (the old way) as opposed to \"i am giving you the type\". As the code is written right now, 0 means \"figure out the type\" instead of \"none\".\nI guess we could add an api for making blocks without providing the type. but maybe it's fine to just change this to do finalize(type) regardless of the value of type. Thoughts?. I see, thanks. Sorry for my confusion.. I like the idea of using -1 for the old behavior. Seems low-risk for confusion.. Ok, I investigated that. Needed a little fix in emscripten, https://github.com/kripken/emscripten/pull/5261 . Nothing to block us here.. Oh, except to remove the definitions of __cxa_thread_atexit. Which I guess we can only do once that other PR lands.. How about BinaryenUndefined?. I suggest replacing the -1 with a call to that function.. this should still be unsigned. might require writing uint32_t(-1) if the compiler complains.. Please add a comment here about the new addition, that it is not a core type, but represents \"no type defined / no type passed into the API\" or something like that.. instead of these -1s, let's call the function. please also add another comment about the use of BinaryenUndefined for the last value, and what that means. The assert is redundant, yeah, I'll remove it.. Good idea, refactoring to getCheckedAddress for those, and use atoll.. How about using Fatal() << \"callImport etc.?. the emscripten PR fixing this landed, so this can be removed. same, can be removed now. why not just do FunctionType ret?\n(also maybe rename to test as it isn't returned). I am not sure how I feel about adding this API call. One issue is that we may eventually add getters by name, so this one might collide with the natural name for that one. Perhaps BinaryenGetStructuralFunctionType?\nAnother issue is that while this seems like a nice utility, it could be done by the user of the library that is creating the function types? Generally the binaryen API has been kept pretty minimal, and this feels like an \"extra\" - it's not strictly necessary, in other words. Another option to adding or not adding this might be to add it in a new section of the API (utilities? helpers?).. I see. So if we had an optimizer pass that does this, that would be good enough? Sounds like it would make all this simpler, avoiding adding a new API.\nWe need to add such an optimizer pass anyhow. Should be easy to write. I can do that unless you want to.. We could add an API call to run a pass by name, yeah, right now it's pretty limited to optimize or not. Is that what you mean in the first paragraph?\nOk, I'll add that optimization.\nI might be wrong, but to me it feels like such a getter could be implemented in JS, if we provided enough lower-level functionality, which feels more natural to me. Open to other opinions here though.. PR for that optimization: #1041. Yeah, I'm ok with your suggestion: let's add your API for now, with a note that we'll remove it when there is a better way to do it from JS. BinaryenGetFunctionTypeBySignature sounds good. Let's put it at the end of the API section in the header, under a header \"utilities\" or such.. lgtm with removing the WASM_UNREACHABLE after it, as it is redundant (Fatal halts execution).. Might be worth refactoring that, but get seems too strong a name, since it's checking if something is a result. If it's not a result, it returns none correctly, but it didn't \"get\" that from the input, if you see what I mean.\nMaybe I'm overthinking it, lgtm (for the PR as a whole) either way.. Yeah, I considered this, but the issue is that the js-handling part is very different (since i64s don't exist in js). Given that, I couldn't find a nice way to write this, without having a bunch of extra weird params.. Good idea, added.. why not put it at the end? seems more natural there at first glance, maybe there's something I'm missing?. isShared. I see. lgtm. if this is just for check.py, perhaps we could do some hack in there, just for testing? seems a shame to instrument the official production build for testing.. this statement could use some parentheses, to clarify the order of operations.. doesn't this define Binaryen as a global symbol?. what does this change do?. typos in Atomic. Sorry to go back around on this, but this troubles me. I'd like binaryen.js to \"just work\" in the easiest way for people. That means\n\nIf you include it on your web page or bundle it alongside your JS code, you can just call Binaryen.*, without needing that line of boilerplate.\nIf you use it in a unified module loader context, it works in a consistent way with that approach.\n\nSo I would like to avoid adding this in check.py, and having it in binaryen.js seems natural for 1. Is it impossible to achieve both 1 and 2 at the same time?. I see. Could we fix check.py to use binaryen in the normal way for a CommonJS context? It would be good if the test suite reflected real-world usage.. Hmm, good point, mozjs does not have CommonJS functionality. We could use node.js instead, but it would need a very recent node, we'd need to version-detect, etc. So all that seems out of scope for this PR I guess.. some comments explaining the things done here would help I think. (this is the new error). I'm ok with landing this PR with not all opt passes working yet, we can fix those later. Could we keep this line normal-looking, then, with {} like the others? Or is the return here temporarily necessary?. {, } around if body. Looks like a typo in store here, must be in the Print code?. Right, makes sense. Yeah, I think we should update them all to the { return ReturnType; } form. Could we make all these functions have the return, I believe we decided that was best?\nAlso, please add spaces after { and before }.. cool, lgtm. { on same line as the if. why is this changing from C++ file IO to C file IO?. perhaps these two could go in wasm-printing.h?. unneeded comment?. if there's nothing to validate, these methods can just not be defined?. the style in other places is\ncase 8: {\n  ...\n  break;\n}. oh, i see. sounds good.. why the indentation change?. this is starting to feel rather complicated. perhaps we should rethink the printing code?\ne.g. in llvm I believe they support printing of objects, not pointers, which maybe makes things simpler (so you need to do cerr << *x instead of just x etc.).?. other code uses {, } when body is on another line, also in switch cases. How about just putting it on the same line?. Well, I'm hoping with a larger refactoring we could remove the need for all of this printing code. Perhaps we can leave it for another PR. But iiuc, the issue here is to pass the option of printing the types, then we could have an API like this:\nstd::cerr << FullTypePrinter(expr)\nwhich would print it with the full type. And so we could end up with just cerr << [..] for everything, and without these new templates and function calls? . I'd suggest\ncase i32:\ncase i64:\ncase unreachable: break;\nor\ncase i32:\ncase i64:\ncase unreachable: {\n  break;\n}\nsince both appear elsewhere.. We could do the wrapping in the calls to fail but yeah, maybe that's no better.. I don't understand this well enough. Would an atomic load be marked as having side effects here?. shouldn't this be |=? if it was already marked as atomic, we shouldn't clear the flag. what's the possible implicit trap here? read memory out of bounds I guess?. function name should begin with lower case letter. Index, not size_t. convention elsewhere is { curr->value } (with spaces), I believe. but i don't feel strongly, if we want to standardize on another way that's cool too.. could this be const std::vector<Expression*>& (const and by reference). Nice refactoring, btw. I don't see how this could cause an infinite loop, that's odd. But, this code was actually wrong, there is a fuzz fix in #1095 for it. Let's land that first, it's possible doing this on the fixed code will work. If not, we can investigate the infinite loop there (i.e., might not make sense to debug the infinite loop on code that is being replaced anyhow).. this change to this pass is just to make it correct - it's trying to merge blocks, and it's not valid to do so without removing a value flowing out on the final element (because it becomes a non-final element after the merge).\nit's also worth removing all the unreachable elements, the dce pass does that (this bug was only noticeable by fuzzing this pass directly, without running all opts, where dce would have run). Stuff like (i32.load (unreachable)) i.e., the pointer for the load is unreachable, so the load has type unreachable (like any node with an unreachable child).\n(as before, this is normally removed by dce, but i was fuzzing with dce disabled on purpose). I think the core issue here is that we use the type when we do shouldBeEqual(getWasmTypeSize(type), 8U ...). As a result, when the ptr is unreachable, we don't have anything to compare bytes to, so validateMemBytes can't do anything.\nThis is actually an issue with printing such a load as well, we print (unreachable.load ..) because we don't know what kind of load it is. Perhaps we should add an extra field to loads, so we keep the type they should have separate from the actual type (which depends on the pointer). That would increase the size of every load instruction, though, so I don't know.. Yeah, we could check for 5-byte loads etc. Would still need an explicit unreachable check though. I'll make a PR.. It's similar, but that method is for comparing types. Here the first argument isn't the type, it's a computation based on the type, and it's invalid to do that computation if the type is unreachable (it asserts, as it is not valid to ask for the size of an unreachable type, only concrete types have sizes). these flags are for the entire expression being scanned, including all its children. so readsMemory means that in all our scanning, we found a read of memory, so the whole thing reads memory (somewhere inside it). so if we scan two loads, one atomic and the second non-atomic, the current code would mark them all as not being atomic.. fair point, it could in theory be used to operate on a list with more than Index elements.. was that pushed? i still see e.g. in visitLoad there is {curr->ptr}, without spaces. Makes sense.. based on the discussion, it seems like this should be: if one of the two is atomic, and the other accesses memory (atomically or not, but not sure if both loads and stores?), then return true.. intentionally not enabled?. why do we need the new contained-but-not-equal mode? is equality too much for some test?. & should be on the type, not the var. this looks worse than before - the parens are not needed, and the ; is not strictly needed but is safer to emit. it's actually possible some asm.js compilers depend on the lack of parens and the existence of the ';', I'm not sure - the spec can be read as assuming the very canonical form x = x | 0; (up to whitespace). fixing.. I don't know, a switch seems uglier to me personally..?. sounds better, yeah, adding \"has\". fixing. We took out STAT nodes as an optimization, though. I think we should emit ;s without needing an AST node for them. It should be easy as discussed before, to just emit one after each element in a block (and loop body, and if arms).. Do we need timing information? What is actually used there?. Sounds good.. Oh, I see. Yeah, that's hard to remove. Looks good then, maybe add a comment though to say why we just check for the subset (if there isn't one already).. It's safer to leave extra semicolons in (no semicolons can run into automatic semicolon insertion nonsense in js...). Let's do that, and maybe figure out how to remove then later.. the convention in other code is\nb.makeBinary(\n  xorOp,\n  b.makeGetLocal(0, i32),\n  b.makeBinary(\n    subOp,\n    b.makeGetLocal(0, i32),\n    b.makeConst(Literal(1))\n  )\n);\n(i.e. always nest, and always 2 spaces for nesting)\nalso, when creating a literal, we normally use an explicit type, Literal(int32_t(1)) so there is no ambiguity. however, i suppose there is no ambiguity for int32 constants, even on 64-bit, is that right?. perhaps these should be prefixed? maybe wasm_ctz_i32 etc.?. how about ARRAY_BUFFER, ASM_MODULE?. asm.js doesn't have try, what is this for?. Hmm, yeah, something's not clear here. First, it should abort even when asserts are off, I'll fix that. Second, yeah, seems nicer to return a bool, I'll do that.. Well, it's like Python range() - it's the values up to that, which start at 0, and don't include the end. I'm not sure if getLessThan is clearer, but if you feel strongly I could be convinced.\n. this code might use Builder::addVar. if not on the same line, please use {, } as in the other cases above. what's the issue here, why is older node bad?. I see, thanks. But not sure I fully understand. Do you emit normal JS outside of the asm.js module? Or inside? I didn't see test outputs here, which could have clarified this.. Sort of the reason I like oneIn's terseness is that it's 100% only going to be used in this one self-contained file. Names matter more when they are used across files, I guess is what I'm saying. But if it's too annoying, we can change it. Not sure I like getOneIn, since it's not really \"getting\" that, it's more computing a probability. Maybe it could be oneChanceIn?. That shouldn't be a problem, if imul or fround are not present we polyfill them.\nWhat was the specific error you saw?. I see, thanks. I think we should add tests for this new functionality, see for example #1126 which adds --emit-js-wrapper for the new fuzzer and adds reference tests for that output.. oh, i see. i guess we could either use a polyfill or user newer node. i suspect a polyfill is better since it'll keep our builds faster to not download node (and avoid the risk of that download failing due to a network error etc.). however, maybe we need newer node anyhow for something else?. You could just prepend a few lines of code to the js (in which you emit the asm.js and other code to call into it), in which the polyfill is done (see code here).. Interesting bug. I verified it's in node 0.10.0 but not 0.10.48, so it was fixed during that release.\nOk, I guess it makes sense to use newer node. Did you verify downloading is the best way to do so? Looks like they have options to use newer node (but that might be for node-only projects? not sure).\nAlso please add a comment saying why we need a newer node, with a TODO to remove it (hopefully when travis supports 16.04).. Yeah, it could turn into a memmove. Seems cleaner to write move though, imo.. Done.. I find this stuff confusing so I'm not sure, but this is moving to the left (we get rid of extra padding, we shrink), which these docs say should be move,\n\nWhen moving overlapping ranges, std::move is appropriate when moving to the left (beginning of the destination range is outside the source range) while std::move_backward is appropriate when moving to the right (end of the destination range is outside the source range). . Oh, great. Then no need for a TODO, I think, we might as well use a nice modern node since travis has a proper option for it.. indentation needs some fixing here (2 spaces), and also need {, } around the if and body.\n\na larger issue is that we should probably make a utility method in src/support/file.h for expanding a response file. perhaps we should even do this by default? or have an option on Options that they have this feature or not?. let's add a TODO here, if it's out of scope to fix that in this PR (shouldn't be too hard, but maybe makes sense later). can use auto. also stuff like this that already has the type on the line should be auto*. missing space after ,. let's add a TODO to use RAII for this alloc/free pattern. It checks for both local and global side effects though, so I think the current name is better?. Hmm, not sure I follow. Without adding atomic here, it's possible that we move a load across an atomic load. The load may trap, so if we move it before vs after the atomic load, the atomic synchronization may or may not happen. Are you saying that is something we should work to preserve? Or is there a better example?. I see now, thanks. Fixed. Also the style comment.. Looks like the goal was to see that unreachable code doesn't break us, there was nothing in need of flattening after the unreachable. So the test is still fulfilling that role. Code truly in need of flattening is tested in $9 after this one, and in the wast (text) test for this.. improved, let me know what you think.. Added.. this comment should go one line up to match the function below. i haven't read the spec, how can these trap? seems odd that wait/wake could trap.... or vice versa. how can parent not be an array?. why must it have a local name?. might as well make it == 8. this has to be 4?. name.is() is shorter. also here. this looks very bad. what's going on here?. Fixed, needs to check for timeout too (see below).. It's more specific than that, it also needs a full-featured timeout utility, which e.g. the ARM linux variant on the bots lack. Refactoring this check into a shared location.. Fixed.. Ok.. I see, makes sense.. I think so, wasm only supports 1, 2, 4, and 8 byte sized loads unless something big changed recently that I am unaware of.. We need to figure that out. Instead of adding this hack in the code, how about disabling the wasm2asm test on it? Hacking a test seems better, even if this is temporary. And lets file an issue for that problem.. I meant to put this logic into the utility function read_response_file. That way it's easy for other options to support response files too.. proper else notation should be } else {. Good point, I'll make it consistent throughout, using the more concise form.. I'll add a comment to explain the Load/Store are used as structs to describe the type of load/store to create a function for. But I'm not sure I fully understand the question, what do you mean by \"pull this out to the caller\"?. Oops, yes. Fixing.. Yeah, maybe there should be an option here. But I think to start with that faulting on incorrectly-aligned load/store is best. Also faulting keeps it closer to asm.js which helps with debugging in some cases. So I tend to think an option to ignore this would make more sense farther in the future.. We don't have that information here, but it's an interesting idea. Not easy though since in asm2wasm we do use lower locations for some special things (like mapped globals, before we started to use wasm globals, and I'm not sure there are no remnants of that; another thing is the special tempDoublePtr stuff that emscripten uses to emulate some things). Can investigate in the future.. BINARYAN => BINARYEN. Suffix is like \"Targaryen\" ;). I agree.\nAlso personally I'd prefer bool debug = false; (init in the declaration). But lgtm either way.. I see, nice fix.. this doesn't look right. the previous line checks if name, and so it seems like this line could add a null name to localNames? is the idea to keep the array at the right length? that seems confusing and should at least merit a comment, but i also think nulls in that array are odd, we should avoid that.\nbut more largely, i think this and the method before it addParam should handle missing names identically (instead of one requiring names and the other not). i'd be ok to leave this to a followup though, as I don't know offhand what the best fix is. but my point is that this PR seems to make things worse rather than better - i'm ok with that only if you can commit to the followup soon.. (lgtm with that). Cool, thanks. Yeah, that might be a good option. Let's discuss more in the followup. I'll merge this in now.. this is a clang-specific extension, I guess? it would mean we only build on clang though, how about adding a break; on these lines, would they fix the warning?. Pleaset add another assert here that the name is unique (not already in func->localIndices).. Why even call that method? it will not find the local so it just returns Name::fromInt, I think?\nWe should also guard against colliding with another name, as in theory a previous variable could have a name which is a larger integer. So we could loop on a counter until we find a free one (which should almost never hit the loop).. Yeah, it should be \"unreachable branches\" I guess. I'll do that in a followup.. amusingly this was wrong all along, so the optimization never kicked in (if it did, it would have led to breakage, which is fixed in this PR - we need to call getBlock in places where a branch might occur, like the top of a function). typo in comment, should be 32?. maybe names should be ToInt32 etc., to match the trunc and converts? but maybe not since there are others too.... Agreed, let's do a bulk renaming eventually to the spec names, but not here.. Needs a comment explaining what the pass does. having a pass with a .h file feels wrong to me. a pass should be self-contained. how about a header file with the just the constants etc., probably under ast/?\nfor adding the pass to be run, can use the string name, instead of the class identifier.. why float trap as a name - doesn't this handle int div/rem of 0 also, etc.?. why are test results changing? should this be just a refactoring without functional changes?. we should keep it matching asm2wasm, though? perhaps we should change both . How about making separate passes for the modes: one pass would do the clamp mode, and one would do the JS mode? We can define them all in a single pass cpp file (see e.g. simplify-locals pass which defines 4). Internally it would be a flag inside the pass class.\nThen the users would add the right pass of the 2 (or not add any pass if we allow traps). Might add a little utility function for that in the header.\n. i'm terrible at names, but maybe src/ast/trapping.h, enum is TrapMode?. Hmm, yeah, looks like in big_uint_div_u we manage to optimize more. But I'm not sure this is what we want. I believe what's going on is that we have an unsigned -1 / 2 operation, which precompute happily precomputes, leaving the result. But if this operation required clamping or js-ing, then that precomputing would have been wrong, wouldn't it? For example if it traps, it would be precomputed into a trap.\nInstead, could we run this pass first, before everything else? Probably will need to do that in two places: when optimizing, right before passRunner.add<AutoDrop>(), and when not optimizing, right before passRunner.add<FinalizeCalls>(this).\nSide note, the test result from before this PR could also be optimized with a full constant propagation pass, which we don't have yet. We should probably add that eventually, marked #1172.. Hmm, good points.\n\nRunning it after AutoDrop seems like the right thing, then. Not sure why we would need a separate pass runner? The issue, I think, is that we need to run it right after autodrop both when optimizing and when not, so there are two places to add to, as commented above (but I got the order in those two places wrong, should be after AutoDrop in both).\nHow about having a utility method that creates the helper functions, separate from the pass? That could be called in asm2wasm/s2wasm before creating any functions. Then the pass would only add calls to existing functions, and so would be a pure function-parallel pass. (The one downside is we might add some functions we don't need, but optimization would eliminate those.). It should, yeah, I added a commit with tests for a few more smaller size examples.. from the travis docs it sounds like TRAVIS_TAG is set when it is a tag. could we check for its existence, as opposed to checking it contains 1.*? Because there may be tags which are not of that form, like 2.* some day, but also we have version_* tags now as well.. Yeah, maybe the names aren't the clearest. @jirutka: we have two tags in this repo, the version_* tags which are binaryen version tags, and the v1.*.* which are emscripten version tags (their goal is to make it easy to integrate with emscripten, but they aren't enough by themselves since binaryen can be used without emscripten too).. I agree those two are downsides. But isn't the issue that we must do it that way to maintain the right semantics? Otherwise if the optimizer kicks in before we modify these math operations, it could optimize them incorrectly, as it's not seeing the correct math operations.\n\nOtherwise we'd need to not run the optimizer until we run that pass, which would be substantially slower (we'd need to finish translating all functions before we start to optimize).\nAnother option might be to have some utility code that adds the functions, and also has code to do an individual fixup. And separately we'd have a pass that adds the functions and does a traversal to do all the fixups, using that. So the pass could be 100% self-contained. And asm2wasm would not use that pass, it would call the utility code directly to do the fixups during translation (as it does now, but in a call to shared code), and also call the utility method to add the functions.. Both proposals sound reasonable to me.\nMeanwhile, can we not block this PR on that, and make it not care about the specific name of tags, just whether something is a tag or not?. Hmm you're right, currently Precompute will handle constants and branches, but not traps. But it could handle traps some day, although I guess that's low priority (and the type of trap would be lost, leaving a generic (unreachable)).\nAn issue currently affecting us would be that the side effects might be different (e.g. an FFI into JS should have more side effects than possibly trapping).\nAnyhow, we don't need a specific new test for that I guess, seeing the current test outputs are identical should be enough.. Yeah, exactly - it's reading a \"list context\" in a wasm binary, so it could be a list of instructions, but we do know it can't be branched to.\nIdeas for a better name? :) Maybe getExpressionList or getExpressionOrList?. Yeah. Both can return a block or a single instruction if a block isn't needed. A block might be needed if we branch to it (in getBlock, but not getList where we assume no branches), or if we have more than one instruction.. Sorry, but the more I think about this, I have an uneasy feeling. Something in the design (way back) may have been wrong here.\nHow about changing localNames from a vector to a map (like localIndices)? Then we wouldn't require names to exist, or have these asserts, etc. It would then be fine for some params and some vars to have names while others do not, which seems the simplest design (i.e. no different treatment of params vs vars). In that case we also don't need the loop in addVar, since we don't need to add a name.. Sure, done. Even if I kind of think it's more elegant the other way... ;)\nI wasn't sure about the file name. We seem to use FileName.cpp but file-name.h for other things.... i wonder if it's important to handle moving here? is it for correctness, or to save locals? if just to save locals, we can depend on opts to fix that up later, and this logic could be simpler.. didn't we say we'd avoid using the pass in asm2wasm, and have it call directly to utility methods to do this? to avoid all the issues with having a pass be self-contained, and run at the right time, and all that?\nmaybe I misuderstood what we agreed on.. this will run that pass after the functions have already been (mostly) optimized.. hmm, this used to be inlined, and now it isn't. if this is still the case after the other changes, that's worth investigating.. I think we should care, yeah: if the optimizer works on incorrect code (before clamping was applied) then it doesn't see the right side effects, might precompute incorrectly, etc.\nThe plan 1-4 sounds ok. Hopefully with that the test outputs will be unchanged. (The only change I'd expect to see is that the order of functions might differ, since we add the helper functions themselves at a different time, that's ok of course.). Got it, thanks.. I suppose, but I find the .second notation hard to read myself (a shame it's not .inserted). Is it just me?. please use index instead of idx, i think that's what we use elsewhere.. i think we can do localNames.at(index) which both does the check+returns the value.. Thanks, I like that way, updated.. since the body isn't on the same line, please add {,} for each (see other switches for the convention). why is this test going away?. cool, lgtm. this line is the fix. all the rest is cleanup.. Hmm, maybe, but we have a struct called BreakTarget so that might be confusing. It contains a name and and arity. So maybe breakTargetNames?. Done.. TrappingFunctionGenerator perhaps?. generated seems too generic. maybe trappingFunctions?. please put the returns on the same line, to avoid arguments about {, } ;). instead of ensureGenerated in each expression visitor, can implement doWalkModule, and in it call ensureGenerated() before calling the ancestor doWalkModule.. what are the three binary files added? (test/validator/*.wasm)\n(this isn't the right place for this comment, but it's the closest). is this test changed because now we have a method that converts f32 to int, instead of just f64?\nif so, why is there still usage of ensureDouble to force an f32 to an f64?. Got it.. TrappingFunctionManager?. Yeah, makes sense. How about if I do that in a followup? (I'm trying to change the API as little as possible in this PR). I usually prefer to put the try-catch as close to the possibly-throwing code as possible, but maybe that's more of a dynamic language thing... anyhow, yeah, I doubt it matters here in practice.. oh, is this keeping the old flags for compatibility?. Yeah, I think these are internal implementation details, just between emcc and asm2wasm. So we can remove old stuff.\nBut we will need to land this and the emscripten PRs at the same time, and make sure the emscripten one updates the binaryen tag to a new tag on binaryen after that merge, so it uses the new code immediately.. Not yet. Yeah, worth doing, I'll look into it.. Good idea, my instincts here were wrong.\nShould the opposite of Mutable be NotMutable, or Immutable?. Ok, also a search shows that's more common, updated.. maybe two spaces here?. Thanks, done.. Interesting. I guess when we add those to binaryen we can use them to replace makeSignExt etc.. It is O(N^2), yeah. I can add a utility to do this.. Added a commit with an indexing utility used by both binary emitting and this comment code.. Looks like it is ok to construct that way.. It causes a warning on some compilers, turns out, so I'll leave it as two lines.. Thanks, updated.. Alternatively, maybe they should all be unspecified except Exception: so we preserve the same semantics as before?. Done.. Hmm, but it stopped working (throwing an error).. Looks like static asserts only happen if the code is called. Which is good enough.. Yeah, it is the same as before. I just happened to test a method that wasn't called now and not earlier ;)\nMaybe delegate isn't the best name, but it's also writing a stub for the function with an abort in it, so it's more than the static assert. Maybe \"handle\"? or \"implement\"?. Sure, done.. Can use the second passRunner constructor, which receives passOptions as a second param. That would copy in the features.. we don't strictly need this (can use the constructor as mentioned above, or also do getPassOptions().features =) but I suppose this could be a useful convenience. 32 bits should be enough for all the features? ;). what is this?. i personally think it's clearer to write if (curr->isAtomic) shouldBeTrue(..atomics feature enabled..). Good point, yeah.. Hmm, this does change the semantics, before it would not even check if assertions are off. But I see no downside to making this change, probably better actually.. should return BinaryenExpressionId?. hmm, this was wrong before, AddGlobal should return a global, not an import. Let's fix that here and in the new places it is used in this PR.. comment should say function type. ditto. why do you want to get function types by their index? can't you use their names?. can use just Name, as that's the field name in the code. But the comment might mention it is the internal name.. can also remove the External from these, I think.. I see. For iteration, perhaps another option is something like a JS API that returns an array of the names, and a C API underneath that does something similar (mallocs a list that must later be freed, and returns it)? Just a suggestion, I'm not sure what is best, but overall I'd like to avoid using indexes (as we have names intentionally, and also, the indexes are internal and do not necessarily match the wasm binary indexes, which could be confusing).\nIf you want, you can split this into smaller PRs, as we can land the obvious stuff already, but the areas where the API design isn't yet clear may take longer.. another option is to put these two methods on Binaryen, as they don't need a module to work. So Binaryen.getExpressionId(..). Thoughts?. Returning a JS class for every expression would be more JS-ey, yeah, but I think it's better not to for perf reasons: we have just one (or a few) Module and Relooper instances, but potentially a huge number of expressions, so my intention was to avoid JS allocation for them.\nNot sure I understand your second comment, and first link there is a 404?. Prototypes might be more standard JS, yeah. Could also help perf, not sure.\nWhy do you prefer the raw C API exposed to JS instead of the more JS-ey one? If that's more convenient it would be less work, too, maybe I was wrong that we need more.\n. Got it, thanks for the info.. this could perhaps be more concise, since the return [..] line is almost identical on all these except one. So we could switch on just the add => Module['AtomicRMWAdd'] parts, what do you think?. Not sure what you mean by repeating that section, but maybe I wasn't clear before. This is what I meant, just to remove the duplication in those rmws by changing makeAtomicOps to this: https://gist.github.com/kripken/406fa34ab78a608a3442aaa8b0e77a40\n. Sure.. this fix looks like the line was deleted by mistake before the merge to master somehow. not sure what happened there. we don't print out module contents by default any more. Heh, no problem. Now at least I know what caused that ;). i guess that low/high variants are for calling from JS? worth mentioning that i think.. \"known-to-be-constant\" seems to use \"constant\" as a general property - we should say that the expression passed in must be a captital-C Const node.. maybe emscripten => glueLinker?. why the _ prefixes?. not a big deal, but the Address(0) looks weird here, since we don't mean \"0\" (I think?). If it had a default value, we could avoid writing it here?. I get the symmetry, but having a single export function is nice for conciseness, and we don't strictly need separate ones here. Not sure what's best.. it would be better to use a Builder for these, see e.g. the impl of BinaryenAtomicWait. . this is fine for now I guess, but please add a comment // TODO add feature selection support to C API, as we do need to add that eventually.. this overloading could also work in removeFunction? Could be nice there too as a followup maybe.. Hmm, yeah. But we could eventually do the reverse, maybe: the C API expects a name, so if JS receives a name, pass that through. And if you get a number (a pointer), you can call FunctionGetName (which returns the name, parallel to GetBody), and use that.. Yeah, it wouldn't be optimal.. I don't understand, can you elaborate?. What do you mean by \"inherited from the linked internal element\"? We can inspect the internal element as necessary in the C API implementation code, do you mean something more than that?\nSorry, I feel like I'm not following your line of thought here. What is this arguing for?. I see now, thanks. 2 is what I was thinking of, but I forgot you'd need the extra kind argument. About 3, so far all exports need functionType (functions) or type (globals), and not likely to change any time soon.\nOverall I think this PR (option 1) seems reasonable to go with. Please just fix the conflict before we merge.. Thanks, this looks good. Please just add a comment before this with an explanation and a link to the upstream bug ( https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82800 ).\nAlso, before we merge, have you joined the community group?. The optimize-instructions pass will canonicalize things so a comparison of a const to anything else leaves the const on the right. And it makes sense to run that pass before this one anyhow, I think?. Heh, well, it's an internal optimizer detail. Should probably be documented somehow.. Good point, fixed.. Yeah...\nWhat do you think about changing these to BinaryenTypeInt32, BinaryenTypeUnreachable etc.? We could keep the old ones for backwards compatibility, but I think we can get away with frequent breaking changes, currently.. why is this Object stuff needed?. initializing this to false could be done here, in the definition.. I don't think this should depend on the presence of a memory export - maybe I'm missing something?\nI think it should happen of growth is used, as I see later in the patch, and also the memory has an initial and a max value; if the max is larger than the initial, then growth is possible (from outside - maybe we don't care about that?).. I see what you mean now, yeah, asm.js doesn't allow exporting the memory. However, I think we should just not export the memory - asm.js always imports (and never exports) the memory, no matter what wasm does, so that is always going to be different.\nAbout enforcing the maximum growth, I agree, we can leave that for later.. I see, thanks, then I agree we need to export it and disable \"use asm\".\nHowever, can we not do this if memory growth is disabled? I think it may be common to have a non-memory growth wasm module that exports a memory, and it would be better to not export it so that we can keep \"use asm\" for speed. But, a downside of that is we do something different depending on memory growth. Perhaps we can issue a warning, and/or have an option to ignore a memory export?. maybe add a comment explaining what this new section does? the comments help group things visually.. convention is auto& function (& before space). are these standard constants, or just something internal? if standard, maybe they could go in src/abi/? (just a thought) . does this just write out user sections unmodified, so reading and writing a file will preserve them? If so very good :)\n  . this seems odd. do object files violate wasm validation rules, or do we have excessive checks in binaryen? (is this why we need to know if we are reading an object file?)\n  . this seems confusing - why would it matter if it's an object file? we should explain here. . the lld- prefix is a little confusing to me. Is it suggesting this is a tool to be used with lld? however, other linkers may implement the same conventions, I think? perhaps it could be wasm-link- as the prefix?. could use some more detail here. should the term here be \"wasm object files\" (as other compilers than clang may emit them eventually)?. also more detail here. Ok, this looks great! All ready to merge I think, except for the logging just mentioned, which I don't think I see yet?. we do have wasm- as a prefix for all the other tools in binaryen, is there a reason for this to be an exception? (Alternatively, we were considering renaming them all to byn-)\nHow about wasm-link-metadata and wasm-emscripten-finalize? Neither is great, I know ;) .... I thought it was a strict goal to have wasm object files be proper wasm files, plus some custom segments? Them not validating seems surprising, is that documented in the conventions repo?\nOr is mutable global imports a \"import from future\" feature in the python sense? that's how I understand you @sunfishcode ?. (To be clear, my motivation here is that I really hope we don't need a new \"wasm object file\" mode in binaryen.). I see, thanks. Then I think we should allow mutable global imports instead of adding a mode for object files, unless there is some other reason we need that (I hope not!).. Yeah, and another limit is the function size issue (#1246 is open for that), so maybe we should collect up these limits in a central place. abi doesn't seem entirely right. Maybe web-limitations?. I also can't find a proper reference for it. I figured I'd set the limit to the lower of the two interpretations ;). Yes, mathematically speaking it should be true anyhow, but I think it's nice for clarity, and to prevent future refactorings from breaking stuff.. I added a new enum for both those limitations (still inside wasm-binary header, since I realized this is a binary format limitation only).. Good idea, done.. Oh, sorry, I didn't understand you fully before.\nI kind of prefer it now - with the nice function names, I think it's clear to read. isAOrB() seems kind of excessive, at least to me.. Well yeah, actually I'm convinced now. We do only care about one type of segment at that point (and til the end), so why not have a helper function for it. Added.. Is there an official link for the Web as a whole? . Good point, thanks. I'll fix in a new PR.. have we decided that MODULARIZE_INSTANCE is the way to go here?\nI'm not objecting, just I thought it was still being discussed, but I could be wrong.\nIn any case, is it worth undoing this, this re-doing it all with MODULARIZE_INSTANCE?. there is similar code in auto_update_tests.py.\nwe need to verify that code works in both spidermonkey and node.js. the bots test just one.. maybe there's a way to reuse src/tools/optimization-options.h which has those constants? or to share code with it.. debug info should be off by default, i think.. Alternatively to this API, another option is to just expect people to use the existing RunPasses on inputs like -O etc.  - same as on the console? That could trivially reuse the code from src/tools/optimization-options.h.\nOr, there could be an Optimize() variant with more params.\nThoughts?. Good catch. I can just move this to there I guess, seems safer for future changes.. But nevermind, this didn't fix it anyhow. LSAN is just crashing entirely, not in a way affected by disabling the leak check feature. Pushed a commit to do it the original way again.. Yeah, consistency is important, I agree. But I can open a PR for MODULARIZE_INSTANCE later today, so it shouldn't be long before we can use it. If you don't mind undoing the changes here after that, though, then it doesn't matter either way, I just thought it might be efficient to wait.. True. We should probably do a general refactoring of those defaults, probably into pass.h. I can do that unless you want to.. Yeah, good point about passes depending on the optimize levels too. So I think your API choices in this PR make sense.. this will have a single set of options for all Modules, globally. I guess that's ok, but we should document it.. we could document it here. I think this might not be random actually, the underlying issue is which emscripten version is used, as there was a bug that was just fixed - so using the fix or not leads to the difference.\nBut, with the limiting of long lines (the cause of the bug) on master now, that should be avoided - I hope if you merge in master here all will be well.. At least, that's my best guess as to the cause. It is odd.. Hmm, what's causing that?. Heh, I see. An option is to change the error printing to not emit such things.... What does dominated_by mean?\n\nThat is, this is not the sum of sizes of everything transitively reachable in the call-graph from this function -- it doesn't include transitively reachable children that are also reachable from other exported functions?\n\nCorrect. This computes how much the binary could shrink if we removed the export. And we can't remove things still needed by other things, the optimizer won't break the module.\nBut it's also not just the graph of the things only needed by that export, as removing some things might open up optimization opportunities elsewhere. (For example, removing a function might reduce the number of calls of another function from 2 to 1, which might make it beneficial to inline that single-use function, which it wasn't before.). Yes, exactly. It removes and optimizes.\nYes, calling an exported function is handled - the export itself isn't called, it's the function, so whether the export is removed or not is separate from whether we can remove the function.. I see, thanks. So dominance with the roots R being all the exported functions is equal to \"is kept alive by\".\nBtw, there are 2 other sources of roots, the start function and the table (assuming the table is imported or exported). Would it be useful to show information on those?. Added support for the start function.\n. Something about atexits? That's expected when assertions are on, but not in an optimized build. So we shouldn't see it here, I don't think. Or was it something else?. as this is a pre-js, you can actually just check the ENVIRONMENT_IS_NODE variable. Oh right, the pre-js goes before everything.... adding files to bin/ should be avoided. one option is to clean up those files, but then there's a risk of not reaching the cleanup code. how about copying the js and wasm files into the current dir? if we forget them there, that's less bad than leaving them in the bin dir. Even better would be to do this in a new subdir just for testing, perhaps, like test/temp/.. Depends on the version of clang and gcc. When I run locally in Ubuntu LTS using gcc, it needs that flag.. should this line also check that? or is it valid to not have the URL but have the epilog?. I see, sounds good.. returning a struct has some odd ABI issues in C that I'd rather avoid. instead, how about returning the output size as in BinaryenModuleWrite, and adding a parameter with a pointer to write the source map bytes into?. (looks like this depends on the ABI issues mentioned above, it assumes the output is pointed to by an extra param at the beginning? I'm actually surprised it's not at the end.). Yeah, an API variant that mallocs the buffer internally and returns it, and requires the caller to free it later, would be a good way to solve the 1MB limit. Alternatively the zlib API has a method that can upper bound the size needed for a buffer. That's less easy for us, but maybe there's a way to that, which would be better (avoid malloc, the user might have another preferred allocation method).. Oh, I see. Yeah, we already do depend on those ABI details I guess... no big deal to add this, then.. was this necessary?. I'm not too sure about the name BinaryenModuleToBinary. My inclination is it should be more similar to the existing BinaryenModuleWrite maybe with a suffix that indicates how it differs. BinaryenModuleWriteExtended? BinaryenModuleWrite2?\nAlternatively, maybe BinaryenModuleAllocateAndWrite?. please specify freed manually using free() (as e.g. delete could be used in C++, but shouldn't).. Can be auto.. unsigned => Index (Index is the right size for an element in a wasm module).\n(also some more instances elsewhere). I think you need a loop here, as when appending it might still be something already seen.. please put the & on the type. can use tableSegmentData again here?\nlgtm. Oh, oops, those are wrong too then ;) I'll fix those later.. hmm, why does this manually do the text emitting? ModuleWriter can emit both text and binary.. this is very nice!. remind me, are these invokes translated into js and executed in the test suite? or are they used in some other manner?. I see, thanks. Looks pretty good there.\nEventually, as we discussed yesterday, it would be nice to hook up the wasm test suite (in tests/spec/). I think we want that anyhow, and also it might save writing some of the new i64 tests.. btw, it would be nice to have wasm2asm emit proper function names (same name as in the wasm). Yeah, I think it would help debugging and also reading the testcases.. Maybe we should only do it with -g or something like that?. no need for this, it would be invalid IR if it didn't exist (which should be caught in general IR verification). instead of these 2 lines, can do\nif (auto* const_ = global->init->dynCast<Const>()) {\ndynCast returns the pointer cast to the type you want, or nullptr if it's the wrong type.. same line or { } please. in the 3 cases, the only difference is the actual value, all the rest (makeVar, etc.) is the same. How about in the switch cases just doing the different stuff, and sharing the rest before & after the switch?. 2018 ;). this should be in the wasm namespace (see asm_v_wasm etc.). instead of these 2 lines (and the 3 after them?), how about just \nassert(!name.empty());\n?. for case bodies spanning multiple lines, please use { } (like an if body). I'm not happy about this change, yeah.. what does the i do here?. unnecessary comment?. I'm confused then, what about x86_64? (which is what it seems it should be on my machine, based on the cmake docs). Thanks, now I get it :). I may be misunderstanding this. Why is a temporary needed here? Also, setLow just copies the value in curr->value, which is 64-bit, don't we need to truncate it to get the low bits?. I think I see, thanks. What I believe happens is the lowering was already done, so this node is 32-bit, and the high 32 bits are received in fetchOutParam.\nIf that's right, then you don't need the set_local/get_local (or the block) here, since the low bits are used exactly once, you can just use them directly.. I mean, I believe there is no need for the temporary variable. It could be auto lowBits = curr->value;. I think the original code got the part of receiving the low and high bits right, but it just did an AND operation on them, which your PR fixes, it should indeed be an EQZ of an OR.. I think that's due to an ordering bug, see https://github.com/WebAssembly/binaryen/commit/3572e575322024c49737a25c654437b08c531140 . The issue is that curr->value sets up both the low and high bits, so it needs to execute first before we use either. And in an or the order doesn't matter so we can just flip it.\nBtw, I think it's easier to understand looking at the pass by itself as in that commit, and testing the pass directly, what do you think?. no need for the block here, can just do auto* result = and then the makeUnary. this kind of gets to my point, that when the low bits are just used once, the situation is much simpler - no need for a temp, no need for a block, which makes it shorter to write and at least in my opinion easier to understand.\nbut reading the other cases, i do see your point that in many or most you do need to read the low bits more than once, in which case for consistency maybe it's better for this to be that way too. i don't feel strongly either way, up to you.. While you're here, please change ->_id == Expression::ReturnId to ->is<Return>(). (Also the same happens with Block a few lines above.). Good idea to optimize this!\nCode looks good, but for testing, I think this case here that is now optimized out might be the only case we have for the start function. Please add another module in this test with a non-empty start function, to make sure we test that case too.. Good idea, done.. Heh, fair enough. How about \"justRemoved\"? (since it's about the last iteration, I think \"just\" captures that better. also added a comment). the fix is here, all the rest is the pointer notation stuff. lgtm, but please add a comment here about what this is or how it is used (unless it's documented somewhere else that I missed).. Yeah, if there's a reasonable way to do this with options (instead of an env var) that would be cleaner. The thing is that then we need to add those options to every tool, which is hard to do nicely. optimization-options.h is the closest we have, I guess.. Overall lgtm, nice. But how about in the very first line of these two functions, we do\ncurr->index = indexMap[curr->index];\nunconditionally? Easier to understand that way I think.. { should be on this line. please add a comment here so it's clear this else separates windows from posix. also maybe add a comment here // _WIN32. I'm confused what does thes` indicate in the name? is it plural?\nHow about binaryenBinDir?. how about getBinaryenBinDir?. Thanks, good catch! Fixed.\nWas there a previous discussion of this? In general though we need to cast to signed/unsigned in almost all the operations in this file (e.g. for the signed/unsigned divisions), so not sure it's worth flipping the storage to unsigned or not.. Looks good!\nOnly change I'd like is to please replace build with init, I think that's clearer.. (I mean to change the variable name to initEmitAtomics, not the function name which I just noticed is build... ;) ). these are sort of for future use ;) but may as well remove them until that future happens, if it ever does.... hmm, what was the warning here? (both are unsigned already, so it wasn't that I don't think?)\nThe cast should be to Index (what the function on the left returns, and which represents the proper index size in wasm modules - 32 bit for now).. how about making isFullForced return a bool?. How about changing lowerShU to lowerShift, as now it handles signed as well?. Please run ./auto_update_tests.py and add the output file it creates. That will be used by the test suite going forward.. these appear to already be defined in src/asmjs/shared-constants.h which we could include here. {, } if the if body is one a separate line, please. need to = false these. I suspect the two might need to do different things. At the C level, the rules for conversions are somewhat weird and I don't really understand them, but at the wasm level we do have a very strict definition of what is right, and we should do that. In particular the spec tests should fail if we do not.. 2018 :). copypasta. how about Asm => JS? Less ambiguous.. I don't understand what this does?\nIn general it seems worrying to add a global for some special state, hopefully we can find a better solution.. instead of documenting this as a bug, we can document the i64 lowering pass as requiring flat IR. seems reasonable.\nslightly sad we need to flatten twice, though, in theory that pass could keep the IR flat to avoid it, but whatever.. why are the opt passes run here?. the first unsigned can be auto and the second should not be needed. i don't understand what this does. it returns a name containing low,high? how does that work later?. aborts should be WASM_UNREACHABLE(), although we can leave to later and fix up the other places it needs to be updated.. why did the names change from x => $0? the former seems nicer?. It seems like this doesn't need to be in the i64 lowering pass? It could be directly in wasm2asm (where the global is set), avoiding the global.\n. we should probably have a better name for this, and getTempRet0 is actually almost overlapping too, but honestly I can't think of a better name for both of them, so I guess it's fine for now :). i know almost nothing about docker as well as alpine :) but what do these changes do?. text here needs to be updated. maybe \"js\" instead of \"asm.js\"?. nice, this looks better this way. why wouldn;t this be once per invocation of wasm2asm - it should run this pass only once?. what is special about popcount?. please add a helper function for this in module-utils.h. a function type is not needed - can just set the function's type to Name() (empty). (wasm function types are weird, they made more sense before spec changes made their checks structural and not nominal). the blob could be a separate .wast file which we load using the helpers in wasm-io.h. The only non-obvious thing is getting the file's location, I suppose, so maybe that's a bad idea.. Another option is to #include it at compile time, which could almost work, but it wouldn't be quoted, hmm.... Actually I think we can #include it at compile time, basically just\n```\nconst char *IntrinsicsModule = R\"(\ninclude \"stuff.wast\"\n)\";\n``\nShould be no quoting problem there... I think.. This might be an option: https://stackoverflow.com/questions/410980/include-a-text-file-in-a-c-program-as-a-char/25021520#25021520 (other options in there too). Another option is to use an archive andLinker::linkObject()or::linkArchive()(see example use insrc/tools/s2wasm.cpp). That's probably a more \"proper\" option, but it would mean that wasm2asm would need to be called with a parameter of where to find the file(s). If we expect more stuff to appear here, though, then maybe that's worth considering.. Or maybe we could usewasm-linkerto link even if the file is embedded in the C++. That might be nicer/safer than manually copying the files ourselves, but I'm not sure. I think @dschuff and @jgravelle-google know that code best - thoughts?. is there a reason not to fix this TODO now? maybe i don't understand why it was more convenient to do this way.. please add a helper methodModuleUtils::copyFunction` which copies a function from one module to another.\nif you're not sure what i mean, i could do that as a followup instead.. instead of CallFinder, see src/ir/find_all.h which you can use to get all the Calls.. there was some discussion of options to put this in another file - did none of those pan out?. maybe a sketch of the build instructions could fit in here? just the commands to run perhaps and what they do.. i don't quite understand the interaction between these two passes. it seems like you're saying we need to\n * remove non-js ops, like an i64 div\n * lower i64 ops to i32 ops\n * remove non-js ops again\nwhat is an example of something that needs the last line?. looks like there are only wasm2asm tests here, please add direct tests for the changes to the passes as well. (that might actually help me see why the second iteration of remove-non-js-ops is needed.). I'm somewhat worried about leaving this to a URL, but reading the gist it isn't obvious to me that there's a crucial subset of it that we could paste here.\nPerhaps we could at least have a comment on each function in the wast explaining what it does? Then it we need to recreate it, we will at least have a clear picture of what needs to be in the output.. Thanks, but now I'm not sure I understand the separation between the passes. Why does remove-non-js-ops lower i64.div_s but not i64.ctz? In other words what is the scope of responsibility of the remove-non-js-ops?\nIt seems like the intrinsics module in remove-non-js-ops could include i64.ctz in addition to i64.div_s? I'm not saying it should, just that I'm not clear on why it doesn't.. I see, thanks.\nThis arbitrariness worries me regarding maintaining and improving the code. Let's think some more on this. My current thinking is that we could\n\nLower all i64 instructions in one pass. This needs the temp var logic and all that.\nLower all non-i64 instructions that are non-JS (like f32.copysign) in another. This doesn't need temp vars.\n\nAnd both might need an intrinsics module that implements things we replace, so we might want some shared helper code for them.\nWhat do you think?. Alternatively, the two might just be one pass for all the non-JS stuff. I don't see a reason to only lower i64s and not all non-JS operations, myself.. There is a minor speed downside to running it twice, but I think we can live with it. My concern is that arbitrary design harms maintainability in my experience. For example, if some time from now I want to add another method to be lowered (say, after wasm adds GC or multi-value) then it would be good to have a clear, proper place for it. If there are two equally valid passes, I'd need to understand both passes before making that decision.\nAnother example is if a bug occurs, running the pass twice could make things somewhat more complicated to debug, as the bug could occur in either one. And future additions to either pass might need to take into account that one of them runs twice, etc.\n. How about if we make this a python script instead? (I actually see we have scripts/process_optimize_instructions.py which is sort of similar, too.). 2018. would this work on windows?\n. needs to be updated. is this comment up to date?. actually instead of this condition, please put it in\n```\nifndef NDEBUG\n[..]\nendif\n``\nThat way it will be run in debug builds/when assertions are on.. Cool, I guess if we get reports of problems we can consider other options then.. Unless I'm confused, I think this class is trying to print out valid JS, andNaNis already valid JS? This change seems to make it print valid wasm or C++ perhaps?. Let's move this out of wasm.h/.cpp (in general we keep that header minimal and put things in side util files, but also specifically here, see comments below). this seems like surprising behavior given the name of the name of the function. are non-constant offsets not handled, then?.Module =>Module(remove spaces in type name).{ }if if body not on same line. how aboutenum class NameScope { Global, Local, Label, Max }(then accessed byNameScope::Globaletc)?. please add a comment for this more-complex function. After a minute or so looking at it I'm still lost.... (if so, that seems to make this very wasm2asm specific and not a general utility). Personally I think'` is nicer as it requires fewer keypresses on most keyboards.. I see what you mean now, thanks.\nHowever, as we don't need strict asm.js validation as discussed in #1561, and that the code here is a generic JS printer, I think we should keep things as they were before.. could this be enum class (to avoid adding Max etc. which are pretty generic, to the global namespace)?. please use Fatal() << \"..text..\" for this kind of thing. why is call_indirect different than other calls?. why is store special?. don't we run flatten before this? in flat IR, there can't be side effects. Or was flatten just for the helper passes?. do i understand correct that this emits a name node with arbitrary JS, as a hack to be able to emit arbitrary JS?\nwe probably do want a way to emit such JS, and could use it in more places like the abort() function etc.. Yeah, good point, we need to update the test suite to not require asm.js validation.\nAlso good point that might be a good topic for a separate PR. If so, how about adding FIXME comments on the things that are changed here that that PR will need to undo, like the NaN change? Unless you think you can get to undoing those very quickly?. I see. Reading it carefully now, it looks like we run simplify-locals-notee-nostructure after flattening, which may un-flatten it. However, if we run simplify-locals-nonesting then flatness will be preserved. It sounds like that will make the work here a lot simpler, so it's probably worth doing, especially if we're already flat anyhow. It may also end up fixing a bunch of bugs we'd otherwise only run into later.\nThe potential downside is that in some cases nesting might lead to simpler JS code. But we can probably leave that for JS optimization to do.. I see. And meanwhile I see this already existed before, it was just moved around.\nMy concern is what this might do to optimization possibilities. Does this get emitted alongside the compiled functions? In general, I was thinking that we'd want to run an asm.js optimizer on those, even if the code as a whole is not asm.js. Stuff that is not valid asm.js could be imported from the outside or something like that. Anyhow, if it's just a few specific functions we can probably just special-case them.\nBut this does make me think that perhaps we should not remove asm.js validation as quickly as we were thinking. If it's practical to keep the \"inner\" portion valid asm.js, that would make optimizing it easier.. I think so, yeah.. Not from this specifically, but in general if we move to non-asm.js then the question arises there. I commented to the general planning issue with some thoughts.. No, thanks, I think it's ok for now.. Well, this is a large issue we need to think about. I think we can defer that thinking to later.. Heh, this is a cool idea!\nI like it, but my main concern is perf. In e.g. the diff here, previously we checked the condition and only if it's true do we create a Fatal object and pass it the string etc. But with the change, we always do that work, I think? Doesn't matter in most places, but we'd need to be careful to avoid it in places that are called a lot, like say the validator. But, if this is only for validating user input, maybe this isn't an issue anyhow as those places are in fact not called a lot.. Aside from the checks, though, there is the work of the constructor and the string creation? If we did\nFatalIf(isBad(func->body)) << \"bad function body: \" << *func->body;\nthen it would convert the entire function body to the text format even if it isn't needed?. I'm afraid so, because we run the tests in the root source dir. Probably we should refactor the tests to create a temp dir and run in there, then we could remove a lot of the .gitignore actually.... Yeah, exactly. I'll improve the comment.. Good point, I'll improve this.. please add a comment explaining what this is. I think we need to initialize all blocks's lastSeenIndex here (as opposed to just once when creating the block): we can reach this location for the same index multiple times, and we need to forget previous settings of lastSeenIndex each time we start here (so it is logically the same as seen.clear() from before).\nThat seems like it would add some overhead, we'd need to measure that.\nAlso, given that, I don't think we need to store the index - just a boolean, seen, seems enough. In other words, this would move the seen map into a seen property on each block.. whitespace changes are unnecessary (our convention is if (, space after the if).. { should be on the previous line. after moving that code out, the second part of this if is no longer needed. spaces after ,. while we update this list, maybe worth adding wasm-emscripten-finalize and wasm-link-metadata?. why inline?. This seems to count the number of iterations in the algorithm, but I'm not sure?\nThe term Index in this codebase implies the index of a local, so perhaps another term is better here. iteration?. no space before *. no space between >>. why is this an unordered map, while in OptimizedBlock we use a very different data structure? if the perf aspects justify the difference, please explain in comments why.. Maybe FlowBlock? Seems like this is only used in flow(). Can also move the definition into that function, so the scope makes it clear where it is used.. convention in this codebase is OptimizedBlock* (no space).. convention in this codebase is auto& (no space). it looks like currentBlock only refers to the entry? In that case, perhaps the name could be changed to reflect that (entryFlowBlock perhaps)? Otherwise, this change seems surprising, it makes sense before with entry, but after the check is on the \"current block\" which seems like something not related to the entry.. I see, thanks.\nI meant comments in the source code.\nI am somewhat worried that profiling and making decisions this way might be too tied to the specific things being measured. Probably best to combine this with more general reasoning about things, which can be expressed in a comment in the source, like (random example) // we use an array here because it is unlikely a codebase would have more than 100 items here.. please elaborate on how the iteration number helps us know if we saw a block in the current iteration. how about flowBlocks for the name here?. no space between auto*. no need for space after ( or before ). if I understand correctly, there is a mapping between basic blocks and flow blocks, and this find_if here is finding the proper basic block for the flow block? this is linear in the number of blocks, how about instead creating a mapping once up front, then we just have a hashtable lookup here?. how about a comment here like \"convert the basicBlocks into more efficient flowBlocks for the flow computation\".. Oh cool, good to know.\nFor now I guess it's fine to have the links in both places, but if we think those links might change maybe we should reconsider.. hmm, don't we also need the prefix for bin/binaryen.js on this line as well (and below)?. Ah, reading the docs again I see this is fine as it is, lgtm.. The name of the class, and comment above, are outdated with this change. How about PrecomputingExpressionRunner?. auto* (with *, that ensures it's a pointer type, in the unlikely chance the function is later changed to return something else). Hmm, this optimization is too good, it makes some testcases less interesting ;)\nHow about changing these merge testcase globals to be mutable, so they aren't optimized out?. I think this is the size of sourceMapLocations at the section start? If so, how about calling it sourceMapLocationsSizeAtSectionStart? Or maybe firstSourceMapLocationInSection?. could this and other places be behind if (sourceMap)?. size_t => auto. MaxLEB32Bytes - sizeFieldSize is now used in multiple places (also elsewhere), how about saving it in a local called adjustment or diff or such?. please add a comment explaining why we need this, maybe we store source map locations until the section is placed at its final location (shrinking LEBs may cause changes there). why is this change needed?\nMore generally, reading through the WasmBinaryBuilder's usage of useDebugLocation, I'm not sure I understand it. It seems to only be used locally in WasmBinaryBuilder::readExpression, but set in other locations, like the one added in this patch - are they even needed?. It could be in both places I guess. I like the idea that StackIROptimizer operates on valid input, containing stack IR, and the pass is valid to run if there is or isn't. Yeah, makes sense to add an assert inside StackIROptimizer, I'll add that.. Yeah, it's weird either way I think... it's just awkward to iterate down to 0 on an unsigned number.. Is the crash related to the other changes in this PR? Or is this fix unrelated?. Great, thanks!. I think it's the test runner that is confusing here: when we run tests in /passes/, we run the requested passes plus --print, so we always print at the end (so that the majority of tests don't need to specify --print). For this test we also manually print using --print-stack-ir, so the module appears twice.\n. Yeah, that's better, fixing.. Thanks, changing.. Well, almost, it's just that such descending loops over an unsigned value to 0 are awkward, i >= 0 is always true.. We'd end up with the wrong names, as removing a parameter decreases the indexes of the ones after it, so the names map would need to be updated for those values.\nCould be done, but as this optimization will usually lead to the function being completely reoptimized anyhow, local names will likely be meaningless anyhow (for local coalescing etc.).. Due to wasm declaring the params first, then the other locals. So if we had\n(func $x (param $a i32) (param $b i32) (local $c i32) ..\nThen if we remove the first param $a, which had index 0, there is no way to have a non-param local with that index, as $b must then have index 0.. Yeah, I had initially hoped to use names everywhere, but it just turned out to be too much overhead for locals - so they are numerically indexed.\n(But functions and other global things use names everywhere, which I think has worked out well.). That's shorter, yeah. Matter of opinion, I suppose - I find it harder to read with UINT_MAX, myself.\n. Regarding capitalization, how about Wasm2JS (capitalizing the S as well)?. for reading the file, please include wasm-io.h, and ModuleReader there will read either a binary or a text file automatically for you (see e.g. tools/wasm-opt.cpp).. is preserving the old output just for testing purposes? If so I guess it makes this PR more incremental, but I lean towards just changing to the new JS output, to have less complexity overall. Or are there other benefits I'm missing?. can actually use a c++ template for this and the other constOffset,\ntemplate<typename T>\nstatic uint64_t constOffset(const T& segment) {\n  ... {, } if if body is not on the same line. I think I'm missing something - I see outputs without --only-asmjs-wrapper are included in this PR (which is great!) but I don't see the code to emit them?. I may be missing something, but I don't think the code added to this function is needed - the type of SetGlobal is always none, as it does not return a value.. Seems reasonable to me. Might be nice to eventually think about a union or other cleaner approach, but Imports are not that common, so I'm not worried about it.. Interesting - I think that's a coincidence actually, but a good one here as it pointed out something useful :) What I think is going on is that we forgot an initial value for bool mutable_; (unlike the other fields near it, it doesn't have a default value) - we should set that to bool mutable_ = false;.\nIt's also a good question what we should do for asm.js imports. Yeah, in asm.js they are mutable, and to work around that in wasm we created a mutable global with the initial value of the import, then we just use that global from then on. In theory we could simplify that to use a mutable import, however, I think it would be more complicated than it would be worth since we do want the old form supported too (and also a mutable import may have perf overhead).. Sorry for not being clear. I meant, how about not adding this flag, and only doing the default behavior of emitting the ESM output? That seems like all we really want, and it's simpler to not add an option?. Hmm, yeah - sorry, this is some C++ unpleasantness ;) We are using a template in a template. To fix it, replace ->dynCast with ->template dynCast.\n. Hmm - I think we just run in node.js on the bots anyhow, so spidermonkey not supporting ESM should not be a problem? (although I thought it did..? maybe behind a flag). Oh, I see in the later responses that the issue is that testing ESM is not that easy, so keeping the old mode is convenient for that reason.\nI think testing in node is enough, as I said later down - but if we can't get that to work, then yeah, it does seem reasonable to keep an option to not emit ESM, for now (with a comment explaining why).. Do you mean to skip it, for now? There's no special mechanism, but some of the tests ignore certain inputs by just having a list of those in the python code. For example in the spec tests in check.py,\n# skip checks for some tests\n      if os.path.basename(wast) in ['linking.wast', 'nop.wast', 'stack.wast', 'typecheck.wast', 'unwind.wast']:  # FIXME\n        continue\n. these could be static (no need for inline I don't think). does the binary not have a names section name for this function?. Is debugInfo actually used in that pass? Make sense to have it though for future-proofing I suppose.. What about the case where the name has not arrived from the binary reading code? I think we may still need to escape there.. Specifically, I'm concerned about weird characters in names arriving from the text format, or from the C API.. asm2wasm also does passRunner.add(\"legalize-js-interface\");, like this PR adds.\nI think fixInvokeFunctionNames does something else, it connects to the right invoke names (I think the backend emits other names?), but that's separate from legalizing their types.\nI think it's ok to do that first, then legalization (the order in this PR), as legalization doesn't change the names of functions.. please mention that this is in the C API. Yeah, we should be more consistent. I think we prefer char* funcNames (keep the type all together).. based on irc discussion, I think we still need quoting here - we need to emit something we can parse.\nwe should probably check if we need to quote, as escaping may have removed the problem for us. if not, then we must quote.. maybe add a comment about why we can't just use ModuleReader everywhere, adding \"because we need to process the assertions too\"?. can all this commented-out code be removed?. interesting that the name ended up $1 here - I guess that's a limitation of the s-expression parsing?\n. Hmm, are we escaping both the export and the function name identically? If so then we would be regressing compared to before, as reading and writing a binary won't preserve export names?. Got it, makes sense.. I thought this file was the result of wasm-dis tests/complexNames.wasm, that is, printing out the binary you added to the test suite?\nIf you added both a wast and a wasm, it might be better to give them different names and not just differentiate them by the suffix - can be confusing.. Makes sense, yeah, that's what I was thinking before I saw this comment.\nIn general I'd say if the test suite passes we should be good - we have good coverage of this stuff.. can use strToStack here (see examples above in the same file). Good point, yeah.\nI realized now that we don't need this function, actually - as the one place that needs it uses the existing .eq() calls (which have always been typed). So I removed this confusing function, and added comments to clarify how those other ones work.. why was this added? I think the getXInfo functions are enough, you can get the name that way - otherwise we'd have a great many such small functions to add.. Good point, not sure why I had it this way.\n(I prefer a while as the other option means writing i - 1 in the loop body.). Might be slightly clearer, I agree, but on the other hand it means initializing an extra array of the size of numSetsForIndex, which is of size numLocals * 4 bytes (could be a few K, and this is for each item we try to move out).\nIf this pass were larger or more complicated I'd lean more towards clarity over speed, but as it is I slightly lean towards speed.. Good point, fixing.. Good idea, fixing.. Hmm, wait, this doesn't seem right - as uint8_t it would just be 0 after doing << 16, wouldn't it? I think we want uint32_t here.\nPlease also make sure we have a test that verifies that.. Great, thanks, I think it's less surprising to read that way. lgtm.. How about if the contents are not empty, then note the first item as the null function. If the segment is empty, add it. And the null function can be used later down: instead of checking for _ prefixing, we can compare to the null function. Also we can emit the null function instead of Name() for filling in the gaps (it must be a valid function).. I may be missing something, but this seems like a separate optimization, to get rid of the masking? That is, it could work with or without the above shrinking of the emitted table?\nIf so it may still make sense to combine it under a single option, but we should document it and perhaps change the name.\nTo be careful here, we should verify the mask size is the size of the table.\nAlso, we'd probably want to write a helper function to share this code with the other instance later down (also the 2 preceding lines look identical).. not obvious what the bool means. i think it would be better to check currFunction. but also can assert on endOfFunction.. end of what?. Thanks for the PR!\nOverall I agree it makes sense to use unique_ptrs for stuff like this. However, we use auto* thing = make_unique<Type>() in other places, so we should be consistent one way or the other with the rest of the code. I don't have a strong opinion either way myself.. our code conventions require { and } if the if or if-else bodies are not on the same line.. I agree this is better. For consistency we should do the others as well. I wouldn't be opposed to separate PRs, during which we are not consistent in the middle, but only if we're sure we can get to the other PRs quickly.. If it's to check existence, can we use an std::set of the items, and check if it's there etc.?. Oh ok, then how about startLoc, endLoc?. Plus a comment could help here I think.. Not sure I understand (how can function parsing start before the function?), but can we set currFunction earlier? It seems like that should match whether we are in a function or not, at least I think that was the intention when it was added originally. If not, perhaps we should rename it?. Can we set currFunction here? then we can avoid having isInFunction (and needing to explain why the two are different).\nDoing so means we'd do currFunction = new Function() here, that is, not use the builder, and set the fields as they arrive - but I think that's better than adding isInFunction. we lose several debug locations in this file, is that expected?. Yes, sorry if I wasn't clear before: I am saying we should replace the use of makeFunction at that late point with an early call to new Function, and then assign the fields along the way.\nmakeFunction is just a convenience utility, and in this case here, it's better overall to not use it, since without it we can set currFunction earlier, which simplifies things.. The issue is that ->imported() is on the Function object, not the Call (a Call no longer knows if its target is imported or not). We can get the Function from the module, but in general we allow optimizing functions before all other functions have been added. So if we did that here it would limit when cost.h can be used.\nThat might make sense, however, I think it's not clear we should be increasing the code for an import - yes, there is some extra possible overhead, but the real overhead is in the unseen code in the other function, which we can't estimate.. Yeah, exactly.\nThis particular case here doesn't worry me much for now as it's just for debugInfo builds, where maximal perf isn't that crucial.. Yeah, hard to pick between the two. Happy to change if people prefer the other way.. I think it's ok as it is - regardless of whether a function is defined or imported, if we export it we need to legalize what we export. (And once we create that stub, it's a regular function that will contain a call to the import, which will be legalized as well as necessary.)\nBut good thinking, that's a corner case, and while making sure this was right I noticed we don't have tests for it. And while writing that I hit a minor unrelated issue of not handling exporting the same import twice, so added the test + fixes for that.\n. Good point, yeah, this seems like it could be simplified. I agree it's safer to leave it for later.. Might need to add an include for it. I think it's in src/support/utilities.h.. I think we investigated that and found we couldn't do it in clang-format, and only clang-tidy can fix up such things. But I may be thinking of another notation.. It might make sense to split up into multiple PRs, good point.\nIt might be best to wait for #1678 to land first, before any of this, though - it's another widespread change and the two may have conflicts.\nAbout curr, it's short for \"current\" when there isn't a better name. I don't think it's worth changing as it's very widespread in the codebase.. Thanks, oops, that's a stray debug line I forgot.... No, it's a pre-existing bug (but hit by the new test) - a function may be imported more than once, so if we already created the legalized versions we must reuse those (or we'd error on trying to create functions with the same name).. There's an open PR for mutable globals, but might as well do it here, yeah - the other PR will have a lot of conflicts anyhow, and refactoring it for clarity here is easier with support for mutable globals. (The other PR can add the tests etc.). Yes, thanks.. I like the idea to have separate functions for imported/defined functions/globals, refactoring.. Done.. Done.. Good point, no reason, fixed.. Yes, fixed.. Added a comment - at this point we have transferred the imports, and left nullptrs in their place. So anything left must be a defined function.\nWe can't use iterDefinedFunctions since it would segfault checking if a nullptr is imported. It might be cleaner to just clean up those nullptrs I suppose. I think it's ok with a comment though?. That almost works, but import->name is not part of the shared base class. A template might work but is kind of awkward given the location here. I'd say it's simplest to leave it as is, but maybe we can refactor the base class later to help with this.. Yes, fixing. Basically we just need to clearly error on any import that is not a function and spectest.print.. Done.. Heh, I did this too mechanically to notice that I guess... fixed.. I can just remove those outdated comments - we no longer need to mark \"imported\", as Importables track that in a better way anyhow.. I'm not sure it's worth doing these attempted corrections - seems simpler to just apply the initial and max the user provided. If they are too small, the module won't validate, but that seems less surprising I think. I also don't understand the correction here - numSegments is the number of segments, not the size of memory (also it's not scaled by the page size). As I said above I think we can just drop these corrections.. I don't think the initial needs to be the same as the max - maybe we can just add a boolean to the other function, whether it's imported? That seems simpler overall, and more consistent with #1678 that unified imports and non-imports. But maybe that's a larger issue that this PR.. not obvious what isPresent means, perhaps add a comment?. perhaps it makes sense to inherit from a parent here, as we have two structures with file, line, col?. I'm not sure how these fit together - what does \"record\" mean in the context of printing? (Sounds like it causes side effects, which seems odd for a print operation?). I think we have existing VLQ code? Can we perhaps share it in src/support/ or elsewhere?. iostream will actually not print the shared value here properly - I think because it treats 8-bit ints as chars. Instead, please write int(shared).. same as in the other place. why not auto?. {, } for if bodies on other lines. Is the idea that if the tempRet0 global appears, we must also already have the getter and setter for it, to avoid mixing a getter for one mechanism with another? I think we should also check that if the global does not appear, that neither the getter nor the setter do either.. This doesn't remove an import - it removes a function with that name, whether it's an import or not. Maybe I'm missing something here, but it seems like this tramples any existing function with that name?\nI think it would be safe if both the getter and setter already exist, as long as they appear as a pair. The problem is if there is just one.. I'd prefer to leave it as auto for consistency with the rest of the codebase. But open to discussing changing the style.. Imported functions are just functions, correct. However, these two are not imports, I think? We define get/setTempRet0 in the wasm itself.. Ah yes, for the dynamic library case we import them. So I guess we need to handle the case they are either imports or are not, if they exist.. please don't change the indentation (we don't have a strict length limit here). our style requires {, } if the if body is on another line. please use auto* ptr =. typo, already. If they were imports, we do need to use the imported versions, though (in dynamic linking, we use that so we can share it between multiple wasm modules, without needing to worry about load order - we just define the helpers in JS).\nMaybe the logic should be:\n * If an import or export exists for the getter or the setter, but not both, error.\n * If imports exist for both, use the imports. Assert that no exports existed before.\n * If exports exist for both, use the functions for those exports. Assert on them being defined (not imports).\n * If neither imports nor exports exist, create and export them.\n?. Btw, by coincidence I noticed a bunch of other bugs in this file, for https://github.com/kripken/emscripten/issues/7304 (dynamic linking stuff). Some overlap with this issue actually. I can either wait until this is landed, or I could do it all in one PR, whichever you prefer.. maybe call this ensureImport?. This is not quite right - we may import env.getTempRet0 as $func$17 (if no function names are present). See src/ir/import-utils.h, we have helpers that can look for a function by import module+base.. I think I'm missing something here. I thought what you proposed is that we always import these two helper functions in all cases (shared module or not, asm2wasm or not)? I was convinced to that position.\n. Oh, I thought it was very high, I guess I remembered wrong.... you also need generate-stack-ir before it. it may work without it, if stack IR already exists, which is the case if you ran the right optimizations.. Ah, good question - I was going to say no, that optimization should be done separately, but then there's a problem, if you optimize before, then calling generate here would trample that.\nSo maybe two options to pick from here:\n\nemitStackIR, emitOptimizedStackIR, two separate functions. Stack IR is kind of special so maybe this is justified.\nHave emitStackIR just run print, and not generate. Then the user must previously do either generate or generate,optimize manually. That seems more error-prone I think, so I lean towards option 1.. please add a comment about why this is important here. Hmm yeah, the list is incomplete - I just copied it from the emscripten js minifier code. Which is incomplete too I guess ;)\n\nI think in practice, to get to 4 letters is very unlikely. With three letters you can get to 221,184 minified ids. But, would be worth adding the rest of the words too, I agree.. unrelated tiny cleanup (duplicate removal). unrelated tiny cleanup (make it like the other code paths around it). {, } when if body on another line. Good idea, that is nicer.. might be worth using the constants here?. Not my area of expertise, but I see __m128 in portable vector-using codebases.. Put another way, it's (upTo^2)(n) ;)\n. Yes, but only since we make copies of them all later down.. Fixing.. memInitFile. lastEnd. To make sure I understand, is it that they import a memory with initial size 0 but maximum size big enough for the segments? If so maybe the comment could say \"an initially zero-sized memory\"?. We should enclose both in { } as otherwise bad stuff would happen with this:\nif (..) WASM_UNREACHABLE();. Good idea, fixed. Found a few more in this file too.\n(Honestly beceause pop_back() doesn't return a value I think I just gave up and forgot about it...). Can this be python3 (without .6)?. Please change this to makeUnreachable and add a tiny function doing that, I think it'll make the code as a whole more regular.. same here. i have a vague memory this was needed for some spec test corner case... but since tests pass I guess either you fixed it, or I was wrong :). Good idea about doing it this way.. can use strncmp?. Makes sense, done.. may as well update this to WASM_UNREACHABLE here. seems nicer to put the WASM_UNREACHABLE on this line, instead of after the switch\nhappens a bunch more places below too. WASM_UNREACHABLE. I see. How about putting a WASM_UNREACHABLE in both places, then? Not sure what I prefer better, but the break seems like it could be misread in some cases.. Yeah, not sure which I prefer. |= is less verbose, but I can't help thinking of type conversions there.... Good point, I fixed that and a few similar ones.. for consistency with code style elsewhere, please put this right after the new bool that was added at the top, and format it as\nMinifyImportsAndExports(bool minifyExports) : minifyExports(minifyExports) {}. Please add an assert that neither does the ifFalse in that case. perhaps falseBits to match the line above?. I may be missing something, but shouldn't the out param be a select over either the high bits of the ifTrue or the ifFalse?. sorry, I think I wasn't clear - i think we need the assert in the other code path,\nif (no out param for true) {\n  assert no out param for false\n  return;\n}\nas after the return we'll use both out params, and should notice if one is missing.\nCan also remove the string from the assertion, for consistency with our other asserts.. how about using a select here? it's more parallel to the code being lowered, so eaiser to read I think, and more efficient (although I guess it depends on what we lower it to later). Also it means we don't have issues with side effects (which we don't have due to flattening earlier, but it would be nicer to depend on that as little as we can).. for consistency with other asserts, the text should be in a comment on the same line. however, maybe we should change the others to be like this (later, if we decide so now). I don't feel strongly either way, but we should have a plan.. Instead of crashing, I think it would be better for the pass to ignore such constants, so return false; here would work I believe. Can move the assert text into a TODO comment.. instead of crashing, let's make the reducer ignore such things, and add a TODO of that assertion text.\nTo skip it here, I think just continue will work.. this has to be implemented for any binary read-write tests to pass, I think, does this PR not provide that?. We should implement these ASAP, as the interpreter should be complete. But ok to leave to a later PR if you prefer.. I think we should consider what to do with this function. Perhaps rename it to getBits64, and then a v128 would be an error here.. pretty crucial for debugging, so I'd make this high priority - this PR or quickly after.. can we not just say align <= 16 here? (how does simd alignment work in wasm?). maybe add a TODO here that we should rename the above convert*ToF* methods to trunc*ToF*, since these new methods are their saturating parallels so they should have similar names (but those older methods appear to be poorly named, or rather named the old wasm way).. we more commonly have template< (without a space), by a factor of 5. please change it here. we should also fix the other places, i'll look into that.. The issue may be the tee_local. We may depend on the IR being flat, and tee violates that. Doing the set_local before, and a get for the select condition, should work (if not, let's look more into why, I can help debug).. typo in libraries. Thanks, fixing that way.. our convention elsewhere is features_ (add a _ when necessary). I think this should be \"all\", like wasm-opt?. Tables contain function names, so if we renamed functions we have to update them too.. typo in the\nalso please move this comment to the outside, as it's part of the definition of the method, that we allow the function to not exist.. No problem, yeah, I agree the urgency justified a quick response.. I'd move this even higher - alongside the Renaming comment. This is a \"rename all uses, and also the function if it exists\" method, and not a simple \"rename\" method any more, so we should mention it at the toplevel I think.. actually I think we should just remove demoteToF32. It's not used, there's a demote method which is actually tested, and it has more logic to handle corner cases.\nlgtm with that. Without this it would say that there is an extern \"_STACKTOP\". We don't need that since the special imports are already set up. Also this would be wrong with the _ prefix, so we'd need to fix that if we needed it (but we don't luckily).. Fair point, these are separable things. I split this into 3 commits as suggested, and can land this with rebase-and-merge.. I think it's not obvious what the <16 sizes mean here. from the code I gather it means i16, i32, i64 elements, etc. - perhaps a comment would be good.. i agree the refactoring to move this code here makes sense. after that move though, I think we can remove the Literal from the name.. I suggest the same name change here.. maybe move the careful! comment to a line before this, so talks about all 3 lines. do you need the = {}?. this is not great for nan literals (comparison results will be false). would be good to use the i64 approach from before for those.. we normally use cameCase (so, extractBytes) but I guess this is more standard for this style of C++. I'm fine either way.. i think it would be best for this method to zero out the unused bits in buf, just to be safe.. auto. I'd prefer to indent this by just 2 (so the }; ends up at the bottom), but there is no right way for stuff like this I guess.... oh wow, we had this wrong and it was doing nothing before, heh... nice find.. } else {. I think this can be removed?. Not sure what you mean by raw pointer - of what type? (void*?)\nPerhaps there could be getBits(uint8_t& x) which would write a 1-byte value, and assert the value fits into one byte, and likewise overrides with uint16& etc., but what would be the type for the simd variant, though?. Oh, I'm not a fan of the void* approach... that seems too risky. Overriding for each size would ensure that we write to the proper type, which we'd lose with void*?. numEntriesAdded. { } for if body. this tee violates the flat property of the IR. I think we should preserve it even if we don't depend on that right now. That means just doing a set earlier in the block being created here, and a get here.. I think this and the assert below should be covered by the validator (not in an assert, but also in release builds there).. Well, NaNs can cause some nondeterminism, which makes comparing between VMs hard. But definitely something we can leave for later.. grep indicates they are the norm in this codebase. all places but one, in fact, I'll fix that.. { } around if bodies . why doesn't this optimization work for simd? seems like it could just work, if the Abstract stuff were hooked up - is that the issue?. this part lgtm. Ok, lgtm.. It's also probably fine to not do that optimization for now, if it's not easy to do - benefis are likely small.. The last element is the value that may be flowing out of the block.. And it may be unreachable, consider\n(block\n  (..)\n  (return (i32.const 1))\n)\nThat last element's value is what we want to flow out.. Yes. This optimization would do\n(func $ret (result i32)\n  (block\n    (..)\n    (return (i32.const 1))\n  )\n)\n=>\n(func $ret (result i32)\n  (block (result i32)\n    (..)\n    (i32.const 1) ;; optimized out the return instruction\n  )\n). Yeah, this could use the interning, good point. I'll follow up.. Please add to the comment about the size issue - it does seem like this is a new factor we need to consider here, where precomputing may actually increase the size and be detrimental.. Why is the signature changed here? The downside is that we do tend to use pointers in most places, which means a bunch of extra *, which I think is less readable.. Makes sense, thanks, done.. Good idea, fixing.. Adding.. But I wrote it in 2018, 5 days ago ;). Hmm, I don't think we have a style. I don't feel strongly either way. What does LLVM do, btw?. Thanks, yeah, we should do that too. Adding a commit now.. Added a commit to do it as you suggested.. Yeah, agreed, that's what I added now. It's also nicer to avoid T* x, y confusions with pointers.. I see we pass the global base to both wasm-emscripten-finalize and to lld - is lld doing it in both bitcode linking and wasm object files? If so I can remove the flag to finalize.. We tell lld the size of the stack, but not its absolute location. Instead, finalize adds a wasm import of STACKTOP, and JS sends it over, and then the import gets assigned to the stack pointer lld created (which is mutable, so that way we couldn't assign it directly). This PR changes that, to just hardcode an initial value for the stack pointer, avoiding the import.. Oh, are you saying, lld guesses the location of the stack (right after static allocations), and we can just leave it?\nEven so, that wouldn't be right, as emscripten can add more static allocations after lld (in the JS compiler). Even without that, it seems safest to have one location that decides this stuff (Memory() in emscripten.py) and informs everything else.. i see, thanks. Ok, fixing the comment.. lld's guess at the stack pointer location is incorrect due to static allocations from JS (see my last comment, may have been a race).\nEmscripten won't use the stack from JS, as the wasm controls it - it needs to call into wasm to get the stack pointer and modify it. So it can modify it after the wasm is ready and the program started up.\nGood idea to rename this to --initial-stack-pointer, done.. Yes, emscripten adds more stuff after 3. But it keeps the stack size fixed while doing so, so the initial stack location becomes higher - it pushes up the entire range reserved for the stack, top and bottom.. Yeah. I agree it's a little odd - this file now means \"options for all the tools\". I'll rename.. Yes, that pass will replace the initial set with a single nop. There won't be anything more here since there's just one constant in the whole function.. Hmm, not sure what *curr does for a function. For an AST node, that would print in out. Here it was just printing the pointer until this PR, and now it prints the name (which seems sufficient for debugging to me at least ;) . Thanks, fixing.. BinaryenMemoryCopyId appears to be duplicated?. Do the bulk memory operatoins use the trunc_sat prefix?. I see, thanks. Yeah, let's rename to that then, looks odd otherwise.. Oops, thanks!. Thanks, changing. Although I'm not sure it's useful to add all of those until they are tested, so just adding what is currently used.. 10 pointers on 64-bit would be a multiple of 16, so seems like it should be ok cache-wise, or am I missing something?\nI kind of picked 10 because I didn't see a benchmark advantage to smaller or larger values, and it seems reasonable as a guess for a \"typical\" wasm function body.. Changed to prev.. why is it doing a move of a std::function?. no space after auto. this move also puzzles me a little...?. we use = false; in other places. indentation can be decreased here. also no space after auto, and below. also here. Hmm, good point. In that case it might be nice to change the enum to say static const Index UnsetArity = -1;. Why is it valid to move it, though? In theory a user could pass in a std::function and be surprised by the fact that it is no longer valid afterwards.\nIf the overhead is an issue, we can pass it in by reference, std::function<..>&?. no need for wasm:: here. Looks good aside from this, thanks!. I see. Still, isn't & clearer? We can use it on the external interface as well, to avoid any passing by value (if we think that's high-overhead - is it actually, though?). I don't follow. In the example there,\nBox::Box(const Box & other)\n{\n   // copy the contents of other\n}\nThere is a const ref, and we used that to refer to other. We then create a new Box, copying those fields. We don't hang on to other, we just look at it to initialize the fields of the new Box.\nIn our case here, though, we are not in a constructor like that - we just want to pass around a  std::function from place to place. We could pass around a raw pointer to it, in other words, avoiding any copying at all. I believe that is functionally what happens if all the locations have std::function<..>&.\n. why is this not an error?. perhaps HEAPU8 so these are unsigned?. can we push this check into the ModuleReader logic? Then we wouldn't need to modify the other commandline tools too.. Please add a TODO comment here that we are adding overhead here with an extra copy, and can perhaps optimize things better.. Maybe it'll be a pattern, yeah. But I'm not sure it will be. If it is, we should probably madate it as part of the syntax, so it's no longer arbitrary strings, etc.. I was trying to avoid thinking about a more structured design here, because I didn't have a good idea for one, but yeah, I agree it's a little awkward to stop in the middle too, as this PR does.. Sounds reasonable, lgtm.. would this look in all of binaryen? how about looking just in test/?. ",
    "drom": "Thank you. Yes, it looks like I am using LLVM-3.5 and I probably need to switch to 3.7. As of GCC I am using 4.8. What is the minimum requirement here?\n. In general HEX number parser is looks broken.\n0xa 0xb 0xc 0xd 0xe 0xf -> 10 11 12 13 14 15\n0xA 0xB 0xC 0xD 0xE 0xF -> 5 6 7 8 9 10\n. @kripken I can't see this fix upstream. What should I do to get it?\n. In my fork:\n```\n\ngit remote -v\norigin  git@github.com:drom/binaryen.git (fetch)\norigin  git@github.com:drom/binaryen.git (push)\nupstream        https://github.com/WebAssembly/binaryen.git (fetch)\nupstream        https://github.com/WebAssembly/binaryen.git (push)\ngit fetch upstream\n```\n\nI still see old code.\nFresh clone from https://github.com/WebAssembly/binaryen.git works. Weird.\n. Test would be good. It took me some time fixing my code and then unfixing it ;)\n. I know that I was stupid and I should use asm2wasm to go from asm.js to wast but why wasm-as dies on reasonably small text file. It is still mystery to me ;)\n. Great. It fixes my issue.\n. ../../WebAssembly/binaryen/bin/wasm-as testsuite/start.wast\n. @kripken OK. I understand. I was confused because only 2 tests form the testsuite are consumed by the wasm-as; and the failure reason, and the error message where cryptic. Sort. of. Closing. so.\n. @binji O! great. I gonna try it. Does it use binaryen under the hood?\n. @binji I see. Generated binary code does look way different. So I need to find a way comparing these tools.\n. Agree with @JSStats that first not readable nor native to \"stack machine\" concept. \n. > But rather than simply transliterating the s-expressions syntax, I proposed a more compact representation, something like this:\n\n$y; $x; i32_eq; if {\n    1; set_local $x\n}\n@qwertie in old good Forth it would be:\nforth\n$y $x = if\n  1 to $x\nthen\n. > we've had a lot of lisp fans hanging around here since the beginning, who would no doubt share your intuitions about ASTs, but the switch to a stack machine has suddenly brought a lot of Forth fans out of the woodwork, who might have different opinions about how intuitive stack machines are :)\n\n@dschuff yes, stack machine based bytecode brought me out of the woodwork. And brings some hope that it would be done right this time. Forth does have some valuable 45 year experience dealing with stack machines, and developed robust \"woodworking\" tool set, that worth learning before reinventing it from scratch. IMHO\n. ",
    "cosinusoidally": "Looking at https://gcc.gnu.org/bugzilla/show_bug.cgi?id=51048#c3 it appears that the below patch is sufficient to get wasm-shell to compile on GCC 4.8.2 in Ubuntu 14.04. I haven't run the test suite though.\nLooking at the GCC site it is difficult to tell when the fix was added. Considering the bug report makes no mention of any of the stable branches of GCC, I would assume the fix is not in any stable release of GCC (and probably not available the default system GCC in any current stable version of Ubuntu). To be sure the unit test in would need to be compiled with one of those very recent releases of GCC.\n```\ndiff --git a/src/wasm.h b/src/wasm.h\nindex 0fd014a..8ca8e24 100644\n--- a/src/wasm.h\n+++ b/src/wasm.h\n@@ -1065,27 +1065,27 @@ private:\ntemplate\n struct WasmVisitor {\n-  virtual ReturnType visitBlock(Block curr) = 0;\n-  virtual ReturnType visitIf(If curr) = 0;\n-  virtual ReturnType visitLoop(Loop curr) = 0;\n-  virtual ReturnType visitLabel(Label curr) = 0;\n-  virtual ReturnType visitBreak(Break curr) = 0;\n-  virtual ReturnType visitSwitch(Switch curr) = 0;\n-  virtual ReturnType visitCall(Call curr) = 0;\n-  virtual ReturnType visitCallImport(CallImport curr) = 0;\n-  virtual ReturnType visitCallIndirect(CallIndirect curr) = 0;\n-  virtual ReturnType visitGetLocal(GetLocal curr) = 0;\n-  virtual ReturnType visitSetLocal(SetLocal curr) = 0;\n-  virtual ReturnType visitLoad(Load curr) = 0;\n-  virtual ReturnType visitStore(Store curr) = 0;\n-  virtual ReturnType visitConst(Const curr) = 0;\n-  virtual ReturnType visitUnary(Unary curr) = 0;\n-  virtual ReturnType visitBinary(Binary curr) = 0;\n-  virtual ReturnType visitCompare(Compare curr) = 0;\n-  virtual ReturnType visitConvert(Convert curr) = 0;\n-  virtual ReturnType visitSelect(Select curr) = 0;\n-  virtual ReturnType visitHost(Host curr) = 0;\n-  virtual ReturnType visitNop(Nop curr) = 0;\n+  virtual ReturnType visitBlock(Block curr) { }; \n+  virtual ReturnType visitIf(If curr) { };\n+  virtual ReturnType visitLoop(Loop curr) { };\n+  virtual ReturnType visitLabel(Label curr) { };\n+  virtual ReturnType visitBreak(Break curr) { };\n+  virtual ReturnType visitSwitch(Switch curr) { };\n+  virtual ReturnType visitCall(Call curr) { }; \n+  virtual ReturnType visitCallImport(CallImport curr) { };\n+  virtual ReturnType visitCallIndirect(CallIndirect curr) { };\n+  virtual ReturnType visitGetLocal(GetLocal curr) { };\n+  virtual ReturnType visitSetLocal(SetLocal curr) { };\n+  virtual ReturnType visitLoad(Load curr) { };\n+  virtual ReturnType visitStore(Store curr) { };\n+  virtual ReturnType visitConst(Const curr) { };\n+  virtual ReturnType visitUnary(Unary curr) { };\n+  virtual ReturnType visitBinary(Binary curr) { };\n+  virtual ReturnType visitCompare(Compare curr) { };\n+  virtual ReturnType visitConvert(Convert curr) { };\n+  virtual ReturnType visitSelect(Select curr) { };\n+  virtual ReturnType visitHost(Host curr) { };\n+  virtual ReturnType visitNop(Nop curr) { };\nReturnType visit(Expression *curr) {\n     assert(curr);\n```\n. > So any compliant implementation that wants to run on x86 must unset the bit all the time? I think we tried to avoid x87 with -msse2 -mfpmath=sse but that's already in our cmake file and it doesn't fix this.\nAre you using GCC? If so, does adding -mno-fp-ret-in-387 fix the problem? According to http://stackoverflow.com/questions/22816095/signalling-nan-was-corrupted-when-returning-from-x86-function-flds-fstps-of-x87 the problem is that, according to the x86-32 ABI, floating point numbers are returned in x87 registers (which triggers x87 loads and stores even if you explicitly ask for sse). Using that flag breaks the x86-32 ABI though.\n. ",
    "waywardmonkeys": "I've got a start on this in cmake ... I'll submit a pull request shortly. It isn't complete, but it is a start.\n. No concerns.\n(I already contribute to various Apache2 things and I have contributed to LLVM / LLDB, so ...)\n. If this lands, then we can improve it further ... like cleaning up the source directory structure and having multiple CMakeLists.txt files as is more typical.\nI've built with this on Mac OS X with Ninja, but haven't done anything really with the build products.\n. It would probably work with 2.8.12 and if not, can be made to do so. I just have 3.4 handy here so was conservative.\nTry it out!\n. merge and iterate ... It worked for me having -std=c++11 in the args ... so that must be a later feature that I was using.\nI'm going to be traveling for about 30 hours, starting in about 5 hours.\n. ",
    "svenstaro": "CMake is fine. @waywardmonkeys your changes don't seem to be public yet. Can you push them? I would like to take a look as I'm also interested in working on this.\n. ",
    "mbebenita": "build.sh is not in sync with CMake and fails in several ways. Even after making sure that I compile the same source files as CMake, check.py fails because the support library is not built.\nQuestion is, should we fix build.sh or just drop it all together?\n. Are you referring to the virtual members in the Pass class? I actually tried getting rid of the non-template Pass class, but I couldn't figure out a way to get it working with the PassRunner class, which keeps track of a list of passes in: std::vector<Pass*> passes;. The passes vector needs to hold objects of different parameterized types, and the only way I could get it to work was to introduce a non-templated base class (Pass).\nI haven't written C++ in forever, so I may be missing something obvious.\n. Closing in favor of #103 \n. This is pretty much ready to go.\n. I should add that, although Travis tests pass I am not certain that this is correct. \n. Closing this in favor for #169, will rebase it later if needed.\n. @kripken yah, that's a concern. Could we enable it only for a local debug builds?\n. > This makes me worried about portability\n@kripken speaking of portability, I don't know if it works on Linux. Only tested it on OSX.\n. Stale, and probably not worth the effort. Breaking in the debugger is easy enough.\n. @kripken what's your preference for column limit?\n. @kripken so I couldn't figure out how to pass arguments the constructor of the parameterized base class, so I changed it locally to use template arguments. I'll push that change soon. Also, what if I merge all the visitors in one class and use template parameters to change the behavior?\n. This is stale by now, I'll re-open if necessary later.\n. > Unless you mean it would have a number there?\nSo, if it's a number, it just prints the number without the $ prefix. Sometimes however, in the case of function it wouldn't print anything because the function name is now implicit, and thus empty.\nI think Binaryen may have trouble parsing some AST nodes that don't have names, (imports for instance) so I'd have to fix those cases.\n. K, thanks, I'll look deeper, I just wanted to make sure I'm not way off track.\n. Yes, it would be optional and off by default. Since Binaryen can consume numeric names, I think it makes sense to also generate them (optionally). And yes, we should also fix SM to handle non-numeric names. \n. Yes, it would be nice to move printing to its own pass. I have a patch that\nremoves names in the AST, but binaryen can't interpret the ast correctly\nafterwards. It's only good for printing really. I'll push what I have so\nfar.\nI'm also writing a patch for SpiderMonkey to handle names, which should\nhelp with testing since we would be able to run the spec test suite as is.\nOn Feb 15, 2016 6:09 PM, \"Alon Zakai\" notifications@github.com wrote:\n\nAny updates here?\nI had another thought meanwhile. Maybe not relevant if you're already\nclose to done. But perhaps we should move printing out to a pass, which\nseems cleaner anyhow. Then we can have a print pass, and a printStripped\npass. Or maybe stripping would be an option in a single print pass. That\nway, printing is entirely encapsulated on the side, and this would require\nno AST changes.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/172#issuecomment-184475640\n.\n. @kripken so it fails because an assert is triggered for the following test: https://github.com/WebAssembly/testsuite/blob/master/func_ptrs.wast#L34\n\nShould this be an assert? Or should it just call onError(). I guess before it was failing for a different reason, not the expected reason.\n. I don't know what is going on in Travis. Tests run okay locally, and I updated the .fromasm files using ./auto_update_tests.py.\n. If we add options to passes then I can also add a test case that ensures the compact output is parsed back the same way. I tried this locally and it works, but it would be nice to add this to the testing suite.\n. Metrics from banana bread: https://pastebin.mozilla.org/8860409\nYou can easily add your own by following this example: https://github.com/WebAssembly/binaryen/pull/204/files#diff-34ae3913118ed6b9c570f9c5d6b997b4R49\n. K, so this patch is a bit sloppy. I should remove the name erasing stuff as it's not that important. I was just experimenting with stuff.\n. I removed all the metric stuff and just left the minification code in there.\n. @kripken I split this PR in two PRs, #210 applies the bug fix, and this adds whitespace minification. \n. No, we can close it.. Here's the full list of i32.constants (BananaBread -> emscripten -> binaryen), if anyone wants to play around. i32.const.txt\n. It is. The average size is 3.1871, I guess it's either 2 bytes, or 5 bytes.\n. I marked it as WIP since it's not complete and was just looking for feedback. If this is something we want I can expand on it and wrap everything that writes to the binary file with enter/leaveMetric.\n. Bitrotten, will revive it if needed.\n. Yes, I rebased it on top of your latest changes.\n. @kripken okay, I flipped silly condition.\n. @lukewagner so far, the approach I took looks something like:\nFor each function:\n1. Walk over the body of the function and construct a table of the opcodes that are used and count the occurrences. Opcodes that are more frequent will have lower indices in the opcode table. This doesn't help with compression but it's necessary so we can assign all used opcodes valid indices. Opcodes with immediates are also added to the table (as a pair opcode+immediate), but only if the immediate is lower than some set threshold. \n2. Sort the table by number of occurrences.\n3. Emit function bodies as before, but use the table index instead of the original opcode number. For opcodes with immediates, if the opcode+immediate pair doesn't exist in the opcode table, encode it as before.\n- I don't yet emit the tables themselves, so the results are not really valid ATM.\n- I don't yet handle all opcodes.\n- I don't have a way to limit the table size right now, but luckily it doesn't get too large if I limit the range of immediates.\nResults (bytes, angrybots)\n```\nraw\nbefore: 12381858\nafter:  11402475\ngzip\nbefore: 3972606\nafter:  4166769\nlzma\nbefore: 2584020\nafter:  3132206\n```\nSo far the results are not great. Uncompressed size improves if we use opcode tables, however both gzip and lzma are both worse. Things will be even worse once I actually emit the tables themselves.\nNext steps / ideas:\n1. Support all opcodes.\n2. Emit opcode tables.\n3. Try constructing a single opcode table for the entire file.\n4. Opcode table hierarchy maybe?\n@lukewagner I know you had better results when you last tried this. What was your approach?\nFor reference, the wast I am trying to encode has the following AST node counts:\nbinary         : 740459\n block          : 183453\n break          : 56364\n call           : 166125\n call_import    : 13186\n call_indirect  : 16371\n const          : 924337\n get_local      : 1620040\n if             : 163429\n load           : 470673\n loop           : 17490\n nop            : 2068\n return         : 57224\n set_local      : 580108\n store          : 309300\n switch         : 2093\n unary          : 11946\n. @kripken absolutely. I am just posting this here to open up a discussion on a possible design. \n. Similar work is happening on https://github.com/WebAssembly/binaryen/tree/opcode-table.\n. Great!\n. @kripken this should be ready to go.\n. @kripken are there any more comments that need to be addressed?\n. > Another approach might be to add calls but keep the loads/stores in place, that way the imports don't need to do the actual work, they would just do extra logging or such?\nIs the concern here that it would be more difficult to optimize away the instrumentation at a later point? The current design is quite flexible, but is potentially slower than the one you propose.\nThe size overhead is currently around ~30% (42,886,511 vs 31,012,238 on UE4. I just measured the overall Binaryen optimized .wasm size, not sure how much of it was code vs. data.). I suppose that leaving the loads / stores in there will increase the size further.. > we should make sure we should support putting the instrumentation in early and then optimizing the result\nAre you suggesting that I add an optimization pass that can undo this instrumentation?. Let me push what I have right now, to see if it is sufficient for your needs.. > Please document\nDone. Feel free to adjust the design to fit your needs. I'm not currently working on a project that needs this interface. I have a local cache simulator prototype which I can always adapt to a new API.. I don't know, you need to cast to the SubType so you can dispatch statically. It's a little brittle, for instance you need to make sure you never call member visitXXX methods directly, but through the subtype.\nhttps://github.com/mbebenita/binaryen/commit/e165020f87f807179d27203195843c88fb8afe55#diff-4216e914cacfb0138e16782bc31f67d3R1392\n. If I do this, compilation fails with a linker error. I suppose this is beacause it's not implemented in any of the derived classes.\nUndefined symbols for architecture x86_64:\n  \"wasm::Pass::~Pass()\", referenced from:\n      wasm::MergeBlocks::~MergeBlocks() in MergeBlocks.cpp.o\n      wasm::MergeBlocks::~MergeBlocks() in MergeBlocks.cpp.o\n      non-virtual thunk to wasm::MergeBlocks::~MergeBlocks() in MergeBlocks.cpp.o\n      non-virtual thunk to wasm::MergeBlocks::~MergeBlocks() in MergeBlocks.cpp.o\n      wasm::RemoveUnusedBrs::~RemoveUnusedBrs() in RemoveUnusedBrs.cpp.o\n      wasm::RemoveUnusedBrs::~RemoveUnusedBrs() in RemoveUnusedBrs.cpp.o\n      non-virtual thunk to wasm::RemoveUnusedBrs::~RemoveUnusedBrs() in RemoveUnusedBrs.cpp.o\n      ...\n. Didn't realize C++ got so advanced over the years. If I run clang-format, it will change quite a bit of the file. Perhaps I can submit another PR with a style change, @kripken what do you think?\n. Interesting. Okay, I'll change it here, but I also see other parts of the code that use:\ncase: ...\ndefault: WASM_UNREACHABLE();\nWe should probably address this in another PR.\n. Is this kind of optimization still worth doing in C++?\nAlso, I tried using a range-based for loop, but the tests no longer pass. @kripken do we mutate these vectors while iterating over them?\n. Is there a similar compile option in gcc? Travis (gcc) is failing with:\nerror: control reaches end of non-void function [-Werror=return-type]\n. I've been using clang-format, I'll change the rule.\n. Again, this is what clang-format with the default style does.\n. This is using the PreWalker instead of the usual WasmWalker. The PreWalker gives you finer grained control of where you can insert logic. For example, in visitSwitch I need to do something special after each case node, which is something I can't do using the WasmWalker.\n. You are right about this pass not finding a lot of opportunities. My goal is to have a starting point, for more interesting data-flow type optimizations.\n. Added in #137.\n. Sounds good, although I opted for creating a PreOrPostWalker class and renamed PreWalker to RecursiveWalker, not ideal, but the best name I could think of.\n. We don't :)\n. If I remember correctly, (module(memory ...) doesn't parse unless you stop parsing memory when you see the (.\n. Nothing really, just examples. I should just comment it out.\n. Not really. I can move it out.\n. No, we only need it if it's used. Since I broke up the patch in two PRs, this and #208 which actually uses it, I at least wanted to make sure it's part of the build.\n. The metrics code needs to be interleaved with the serialization code. I don't see how this could be moved to a pass.\n. I'm just following what other files use. If we were to change this, then we should probably update all source files.\n. Is this technically necessary? Or is it more of a style preference? I thought I only need to be careful when dealing with references.\n. Thanks, fixed it.\n. Tried\nauto v = module->functions;\nv.erase(std::remove_if(v.begin(), v.end(), [&](std::unique_ptr<Function> curr) {\n  return analyzer.reachable.count(curr.get()) == 0;\n}), v.end());\nBut I'm getting a few compiler errors related to:\nerror: call to implicitly-deleted copy constructor of 'std::unique_ptr<Function>'\n...\n. Tried const as well, same thing.\n\n(And don't forget to actually erase the removed elements after the call to remove_if. It doesn't actually do that.)\n\nDoesn't v.erase(std::remove_if ... do just that?\n. I found my mistake, I was using: auto v = module->functions; ... instead of auto& v = module->functions; .... This was somehow causing compilation problems further down in the function. Sorry for the noise.\n. Ahh, gotcha.\n. Done.\n. Done.\n. ",
    "dschuff": "If build-js.sh stays as simple as it is, then unlikely to be worth the effort of trying to have multiple toolchains in a single build system configuration. This is especially true since we don't really need to have support for random users running it on a variety of OSes. I'd say we can call this issue fixed since we have CMake and of course update it as needed.\n. This seems working. Do you want me to squash it and just land it on master?\n. This is an improvement; I was thinking yesterday that it might be nice to even be a little bit smarter and detect underflow as well (i.e. if the unsigned value is way at the top of the space it's more likely an underflow than an overflow)\n. OK, addressed the comments. please take another look at the code. I'm still looking at how to update the tests. Are the test cases in dot_s autogenerated, or manual?\n. Mostly I want this to be able to test LLVM independently of all the emscripten machinery, it doesn't have to be the only or final mechanism. But, here are some other thoughts too:\nFirst, of course the stack increases memory. Most programs will still need it. And there's no good way to resize it without mmap (or having it grow upward into a space that can be increased by increasing the entire linear memory). So it will have to be large enough, according to the program's needs.\nThe program will also need heap memory; it would be the job of the allocator to allocate that, and how much it would want initially would be a design decision; presumably it would need to balance the cost of having a large initial size against the (probably large) cost of having to call grow_memory. It doesn't necessarily need to be aware of the stack, although it could.\nAlso what do you mean by startup code?\nIf, for the statically-linked case, you mean wasm code called before main(), then yes that's kind of what I had in mind eventually, but we don't have a mechanism for that yet. nor any common libc startup code (and it would still be nice to be able to test single files without that).\nThe LLVM backend doesn't really have a good idea how much stack would be needed (other than whether it's needed at all), but it is possible to have all the stack info come from the .s file. Previously I was testing locally by appending (or prepending) the following to the .s file:\n``` .data\n        .globl  .stack\n        .type   .stack,@object\n.stack:\n        .zero   4096\n        .size   .stack, 4096\n    .type   __stack_pointer,@object\n\n__stack_pointer:\n        .int32  .stack+4096\n```\nIf we made s2wasm support commons then it would even support linking multiple files.\nI'm fine with making things more dynamic (this is just for a start, for testing things), although I'd rather avoid having things outside the wasm module completely (e.g. in JS startup code).\n. Right,  in other words this isn't a toolchain design proposal, it's just supposed  to be part of the minimal test harness that we're already using for the torture tests, where we don't need a libc or multi-file linking or startup code.\nMaybe we should make the option default to 0 and not create a stack if not set.\nMore broadly, I do think we want a more flexible mechanism than this; something that works for now, and when we get mmap, and when we get dynamic linking.  I think in general I would prefer the stack allocation to be handled inside the wasm module if possible but I'm open to discussion on that, and this probably isn't the place.\nAnyway I'll make the option more optional.\n. Updated, rebased, and squashed.\n. Yeah, I was just thinking about that. I'm fine with keeping that as-is for now.\nIn general though I actually think maybe we don't need to create the stack pointer if there are no references to it in the file. Since we are assuming that this is an already-linked module, if there are no references to the stack pointer, then there need be no stack pointer and no stack.\nSo there are 3 possibilities:\n1) s2wasm should create a stack (specified explicitly by an option), in which case there needs to be a stack pointer.\n2) There are no uses of the stack pointer, in which case there need not be a stack pointer or a stack.\n3) There are uses of the stack pointer but the stack will be allocated by some startup code (i.e. dynamically). This is presumably what we'd use in nontrivial programs in the long run.\nFor case 3, there are a couple of options. \na) s2wasm could determine whether there are any references to the stack pointer and conditionally allocate it. It would be easy to put it at the end after the user variables, but we might prefer to have it before the user variables to keep its address small (which would be slightly less trivial in s2wasm but maybe not so bad).\nb) LLVM could keep track of whether a stack pointer is needed and emit its own .globl (or maybe .common in the future if we want to link .s or ELF files) declaration for the stack pointer. In this case s2wasm wouldn't even need to have any special-casing for the stack pointer at all (although it would still be needed if we wanted to expose the stack pointer address to JS, and it could have special-casing for that purpose).\n. Updated the branch to always generate the pointer as before.\n. WRT creating the stack pointer at all: That's why the dynamic linker would set up the stack in the dynamic linking case. Otherwise if there are no references and we are statically linked, then there can be nothing that uses the stack pointer. (This includes JS, which shouldn't be touching the user stack anyway).\n. OK, --allocate-stack it is.\n. This still has a failure with clz. That is presumably related to JF's change. That change looks right though; i'm investigating.\n. Thanks!\nOn Thu, Feb 4, 2016 at 1:09 AM JF Bastien notifications@github.com wrote:\n\nI squashed and committed.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/180#issuecomment-179721555.\n. Merging based on IRC lgtm\n. Yeah, I'm a little fuzzy myself. I can't see offhand any reason why inlining it should make any difference.\n. @jfbastien If they are templates, don't they just get put into a comdat?\n. @jfbastien @flagxor Any idea why this wouldn't be working?\n. leak suppression worked locally for me when I set that env var. The thing I\nwas confused about was why the travis build of the branch didn't seem to\npick up the extra env var in .travis.yml. We could just land this and see\nwhat happens since the bot is xfail anyway.\n\nOn Fri, Feb 5, 2016 at 1:34 AM JF Bastien notifications@github.com wrote:\n\nHuh that would be nice... Does it work locally? I didn't know about that\noption.\nOoh adding this would be nice too:\nASAN_OPTIONS=\"detect_leaks=1 symbolize=1 external_symbolizer_path=$SRC/third_party/llvm-build/Release+Asserts/bin/llvm-symbolizer\"\n(well, with the right path)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/183#issuecomment-180270857.\n. There are a bunch of new unexpected torture test failures. I'm not sure why; did I miss anything on the binaryen side?\n. All except TSan. Don't know what that's about, but I'm pretty sure this change doesn't cause it.\n. No problem; any particular reason why? I don't have strong feelings about it but I switched it for consistency with LLVM_ROOT and EMSCRIPTEN_ROOT and because I didn't see any particular reason to require that the the binaries live in a directory with a specific name.\n. I think this is right? If you want you can regenerate it locally and make sure my asm output matches yours.\n. incoming branch of emscripten, master branch of binaryen.\n. maybe i should use a release version of emscripten?\n. LGTM, I'll try it out with my local v8 patch and then send a PR for that.\n. This will probably require pinned test/revision updates which I haven't done yet.\n. @JSStats thanks, I didn't see that. I stole a couple of bits from there (although I do prefer the approach of making the page size constant a member of wasm::Memory rather than a preprocessor define).\n. OK, rebased. Alon, do you want to have a look?\n. OK, so I rebased and updated the spec tests (which makes address.wast and traps.wast pass). Now we have the problem that the spec implements rotate and binaryen doesn't. So i32.wast and i64.wast fail. So we can either leave the spec repo where it is and blacklist address and traps, or update it and blacklist i32 and i64. And then of course we can just implement rotate.\n. So, I actually did start that. I can go ahead and finish it.\n. Rebased, sqashed, added rotates.\n. I haven't updated wasm.js yet to avoid conflicting with #225 \n. The object name change was added to V8 this morning, so we don't need that. And yes I think @titzer said he was going to do the namespace change too, so maybe we can just close this and I can keep this locally until the namespace change lands.\n. OK, updated to just the one change that we agreed on now.\n. lgtm\n. looks good, thanks!\n. Updated for initial and max sizes.\n. I just missed this when I added rotates to the interpreter. Should be straightforward.\n. We can't really support running wasm64 code in a 32-bit process, so I don't think values that are supposed to hold linear address indices necessarily need to be 64-bit. Maybe what we really should have is some new type address_t or some thing like that to make it more clear.\n\nActually it's a bit more subtle; the interpreter can't support 64-on-32, but I don't see any reason s2wasm (and maybe asm2wasm?) can't. Either way though, a new type name would be good just for readability.\n. It's actually even worse; IIRC according to the C standard the backend is allowed to generate calls to at least memcpy, memset, and memmove even if the intrinsics are not in the bitcode.\nFor PNaCl we have a 2nd (native) linking stage after LTO and codegen to satisfy memcpy/memset/memmove. (For the math functions, I think we have a separate bitcode library? I forget, I'll have to look). Medium/longer term for wasm, I'd like to have a non-LTO/bitcode linking mode as well, that can serve the same purpose. It can include compiler-rt (and libc/libm or some subset as well; \"normal\" LTO doesn't include libc itself, and therefore doesn't have the same issues we do). Longer term there's also of course dynamic linking.\nIn the short term, I actually wrote an LLVM pass to force memcpy, memset, and memmove to stay in the binary using LLVM's llvm.used mechanism for wasm. Then when I tested it out on emscripten's output I discovered it didn't do anything because those functions were not in the binary in the first place (as you noted, they are in Javascript), so I didn't land the change. But I can do that; we probably do want these in the wasm binary instead of in JS.\n. Interesting. If I manually do something like this in a C file:\nint myfunc(void) __attribute__((section(\".text.__startup\"))); \nit doesn't complain. I'll take a closer look\n. So this also reproduces if you have a function marked __attribute__((constructor)).\nIt's because it emits a bare .int32 into the .init_array section, i.e.\n.section        .init_array,\"aw\",@init_array\n        .p2align        2\n        .int32  myfunc@FUNCTION\nWhereas s2wasm always expects directives like .int32 to be part of an object marked with a .type directive, e.g.\n.type   .L.str,@object          # @.str\n        .section        .rodata.str1.1,\"aMS\",@progbits,1\n.L.str:\n        .asciz  \"Hello, world!\\n\"\n        .size   .L.str, 15\nConstructors that go into .init_array are just pointers to functions, but are not objects with names. Probably we should just add support for raw emission into sections like that.\n. This looks fine. Slightly unrelated but when I try to do builds with my vanilla LLVM, I'm getting errors at wasm instantiation time that a couple of functions (specifically pthread_self and friends) are undefined. They are in the JS module but with the leading underscores. Which part is supposed to fix that up?\n. @shibukawa Do you plan on rebasing this? If not, do you mind if I do that and land it? I have another refactoring that would be much nicer if this were in with it.\n. asm2wasm is something we expect to be invoked by the compiler driver rather than directly by the user, right? So it probably doesn't make a huge difference. Even llvm tools are not consistent on this. llc defaults to text and has a -filetype=<asm|obj> flag. opt defaults to binary and has has -S for text. That would make sense for asm2wasm too I think.\nEventually when the binary format is stabilized we'll want binary output from emscripten by default. But in the near term (where binary formats for V8 may not exactly match SM or Binaryen) I expect for testing that I will want a wast output from emscripten, which I would translate with sexpr-wasm (which I do expect to be kept in lockstep with V8). So we have a bit of weirdness with emscripten, where you'll say you want .js output, but you also get a wasm (or wast) file too. And you can't just use -S with emscripten because for compiler drivers that means you want to stop before linking (i.e. it implies -c). \nSo I might want to say that for now we should leave wast the default, but later (once users can expect to just build something and have it work in all wasm-supporting browsers) make binary the default.\n. Oh, I forgot that the method could specify that. I guess we still have the interesting case that as far as I can tell, the native-wasm method generates a wast (which can then be passed to spidermonkify, right?). Maybe for the native case that's what we want (to get around binary format skew). We can make spidermonkify and sexpr-wasm have a common interface suitable for that purpose and pass either one to emcc.\n. Or, I guess what you are trying to do is get rid of spidermonkify and use asm2wasm's output instead? Maybe we could just have a native-wasm binaryen method, and native-wast, or native-binary vs native-s-expr or something corresponding to the interpret cases.\n. Right, but even once the engines go postorder, I wouldn't expect that e.g. V8 and SM will land the switch to a particular format milestone on the same day. So for me for testing, I would still want a method that behaves just as native-wasm does today... i.e. the Module glue is set up for native wasm, but there's a wast file I can encode with an external tool.\n. Success!\nHello world works.\nI also tried flipping the asm2wasm build on the waterfall to the LLVM backend and most of those tests work too. There are a bunch of new ones that fail too (that work with asm2wasm) but that's probably good news, in that the tests are hitting some corner cases we can fix. I'll have a look on Monday.\n. I need to update the tests before this will work but you can see if you like the code.\n. yeah; I should mention, this hasn't been tested end-to-end yet because once you get past this the link fails because __dso_handle is missing. I plan to fix that in s2wasm's \"linker\" unless you have a better idea.\n. I think the difference is that __dso_handle is a global instead of a function.\n. Hey, can we enable PR squashing in this repo?\n. Added a test. Are the names supposed to have \"$\" in front of them?\n. Removed leading $\n. So, speaking of squashing, the option shows up after you click \"merge pull request\". Then you get the dropdown which says \"confirm squash and merge\".\n. Apparently you can't change the base branch of a PR after you open it (this one was based on the initializer branch because it was WIP), so I opened #317\n. Forked from #316 \n. The current (and previous) behavior is that the stack pointer would always be allocated even if the stack was not allocated. This was because the compiler will always emit references to it if necessary (e.g. in tests like test/llvm_autogenerated/byval.s) without knowing if a stack is going to be allocated or not; and if there was not at least a stack pointer allocated, the test would fail to link. The fact that the tests previously had no memory was a bug. Practically speaking this only affects the binaryen tests because everywhere we actually use s2wasm that I know of, we use the --allocate-stack flag.\nSo, we have a couple of options.\n1. Make the stack pointer only allocated if a stack is being allocated. If we do this we will need to use the --allocate-stack flag for some or all of the binaryen tests. If we really want to have tests with no memory, we'll have to update check.py to use --allocate-stack for only some of the tests.\n2. Make the pointer allocated unconditionally and just accept that all of our tests will have memory.\nI don't particularly care which of those we do; do you have an opinion?\n. Fixing the alignment didn't cause memory to be used, per se.\nI guess another way of describing the previous behavior was that we reserved an address for the stack pointer by bumping nextStatic but we didn't also finish the allocation by also bumping minInitialMemory if there was no stack allocation. So if there were no other statics or anything else that required reserving memory, then no memory would be allocated.\nActually come to think of it, now that the allocation happens here in the function, I don't think we actually need separate variables for nextStatic and minInitialMemory. I'll fix that.\nSo we still have the 2 options of conditionally or unconditionally allocating the stack pointer. I'm leaning toward option 1 (so the program will fail to link if there is a reference to the stack pointer but no stack allocation) and just using --allocate-stack for the llvm-autogenerated tests.\nDo you mean the 0 should be 1, i.e. the first static should be allocated at address 1 (assuming no alignment constraints)? That would mean that nothing could ever be allocated at 0. And practically speaking if there is a stack pointer it would push its address up to 4, wasting the first 4 bytes.\n. OK, I made it so the stack pointer is only allocated when the stack is allocated. For testing we have the hand-created dot_s tests and the llvm_autogenerated tests. For the former I kept it with no stack allocation (none of them use the stack pointer), and for the latter I made the test runner pass the --allocate-stack flag. If you look at the test updates, you'll see that none of the dot_s tests that didn't have any memory before have any memory now, and that some of the llvm_autogenerated tests such as byval.s (which previously had no memory even though they referenced the stack pointer) are now more correct. Also you'll see that making the static base 0 instead of 1 reduced the memory requirements of a lot of tests (obviously they still need a whole page, but the addresses used are smaller).\n. Or wait, are you saying that we should just intentionally disallow anything from being allocated at address 0?\n. But what's the point of disallowing 0 if you can allocate at 4? That's not useful for any purpose I can think of (e.g. catching null pointer derefs).\n. oh, also. It looks like emscripten is not using the --allocate-stack flag, which means the stack pointer appears to be uninitialized in the wast file. I assume it wants to tie it to STACKTOP, where does that happen?\n. Oh, I found it, emscripten assumes that it lives at the --global-base location, which will be true if that location is aligned. So that means that conditionally allocating the stack pointer won't work for emscripten. So I guess we can just go back to option 2 above.\n. Ok. s2wasm now explicitly reserves address 0 (instead of making it depend on getting 1 passed to the constructor for globalBase) and unconditionally allocates the stack pointer. This means that s2wasm will never generate wasts with no memory, but since it's designed to work with LLVM output and LLVM may use the stack pointer anytime, and because emscripten always does its own stack, this seems ok to me.\n. It should be just this one.\n. Squash+merge ftw\n. If we're hitting recursion limits, it probably would be better to just make the default traversal behavior not be recursive. I don't think it would necessarily make things meaningfully slower (you're basically just adding explicit pushing and popping instead of function calls). It might make the default traversal code a bit more complex (it's hard to beat recursive walking for simplicity), but it would be generally useful and probably better (in terms of being understandable) than having a special case like derecurseBlocks.\n. Oops, I pasted the wrong title. The first comment should be\nThis fixes 2 bugs in s2wasm:\n- Handle address-taken aliases (i.e. when they appear in relocations),\n  by lookup up and subsituting the address of the aliasee.\n- Skip whitespace at the top of the scan() loop instead of requiring it\n  to match. When there are multiple alias declarations in a row, th\n  match(\"FUNCTOIN\") at the end of an alias delcaration consumes the\n  whitespace at the beginning of the next line, causing it to fail to\n  match the tab character specified in the match pattern at the top of\n  the loop\n. I tested yesterday and the current master branch compiles for me with VS2015. Good enough to close this?\n. Funny you should mention that, i was just exploring that as we speak. I'm not convinced yet that there will be no need for any changes to emscripten but we'll see. We may consider even doing this in the LLVM wasm backend in the future (perhaps a post-s2wasm future?), or a least some well-defined mechanism for accomplishing the same goal as dyncall.\nSpeaking of wasm builder and Binaryen's IR, it seems suboptimal to require that all locals be named, and GetLocal/SetLocal always use the name of that local. Especially if we want to make the IR and the traversal mechanisms be part of some generic library.\n. Btw we may very well have to revisit the details of this mechanism, when we consider linking, and dynamic linking.\n. In the sense that it can't represent a lot of valid wasm AST (namely, AST with unnamed locals), that users may not want to make up variable names just to use the API, and that variable names take up space in binaries.\n. Probably the IR should reflect the AST semantics, which is that the index is the canonical identifier, but locals can optionally have names as well. E.g. maybe the IR node for a function has a list of names of locals, any of which can be empty. Names only get updated on function creation. The IR node for get_local just has an index. And maybe there are 2 builder methods for get_local, which take an index or a name. Or something like that.\n. https://github.com/WebAssembly/binaryen/pull/337 is partway toward making s2wasm generate dyncall thunks. Mostly it adds some stuff to wasm::Builder and makes S2wasmBuilder use it.\n. Closing in favor of #342 \n. Also, re: Wasm.instantiateModule, that's definitely not the final form of the JS API for WebAssembly, so we haven't documented anything yet.\nTwo other caveats currently about using Binaryen for FF vs Chrome. IIRC the default BINARYEN_METHOD is 'native-wasm,interpret-s-expr' which has the following behaviors:\n1. native-wasm tries to load the wast (not the wasm) natively using Wasm.instantiateModule. This works for Firefox but not for Chrome (Chrome only accepts the binary format).\n2. If that doesn't work, it falls back to interpret-s-expr which runs the wasm interpeter, compiled as an asm.js module. This will work in any browser, but won't be using the native wasm support.\nFor testing with V8, I currently use the 'native-wasm' method only (i.e. the emcc flag is -s 'BINARYEN_METHOD=\"native-wasm\"') but before running, I encode the wast using sexpr-wasm. (if you use the .wasm suffix for this file, you also need to rename foo.wast.mappedGlobals to foo.wasm.mappedGlobals.\n. Is this when running the optimizer compiled for asm.js, or for a native platform?\n. What do you expect the overall lifetime of these components to be (e.g. do you expect it to outlive common use of asm2wasm?)\n. This LGTM if you don't want to try to further simplify all the doVisitFoo\n. Comment copied from the other discussion:\nProbably the IR should reflect the AST semantics, which is that the index is the canonical identifier, but locals can optionally have names as well. E.g. maybe the IR node for a function has a list of names of locals, any of which can be empty. Names only get updated on function creation. The IR node for get_local just has an index. And maybe there are 2 builder methods for get_local, which take an index or a name. Or something like that.\n. (also the state would then be local to a function, rather than global to the module)\n. Aren't there are a lot of the same problems for locals as for block names?\nTo add a local, you can just append to the end of the list. But if you remove one from the middle, what do you do? Probably you'd just leave it there as a tombstone.\nInstead of names or indices you could just make IR data structures for everything, including locals, blocks, etc. (the IR structure would optionally have a name). Then nothing would have an index at all until you wrote it out. Then all IR nodes that refer to other nodes (get_local, br) would just use pointers instead of indices. That might cost more memory than you'd want to pay. \nMaybe best would be just to do both. Everything except locals already has an IR node anyway, right? so pointers to those IR nodes are the way they are represented in the in-memory AST. Then when you write it out you assign indices, break depth, etc. For locals, you could keep using indices and if you deleted one, just leave a sentinel value and re-number before you print or as you go.\n. I guess we'll have to merge https://github.com/kripken/emscripten/pull/4245 and update the emscripten submodule revision before all the tests will work here, correct?\n. OK, binaryen tests passed locally for me. Will see about travis.\n. Binaryen tests pass. I guess now we just need to update the binaryen version in emscripten?\n. LGTM\n. LGTM\n. maybe change the PR name to be more clear? otherwise LGTM\n. wrt libc in LTO, yes, someone could do that (if you take care to disable some libcall optimizations, as we do in PNaCl). And I actually seem to recall someone in LLVM recently improving LTO so that that could be more easily done. It's more or less orthogonal to the problem of calls materializing in the backend though.\n. __cxa_pure_virtual is in this category too; the compiler puts its address in vtables, but there are no references to it from user code. However it comes from libcxxabi rather than compiler-rt, so its handling should be more like whatever exactly we decide to do for memcpy and friends.\n. With https://github.com/kripken/emscripten/pull/4294 landed I'm going to go ahead and close this. There will be more changes to the linking functionality but the blocking problem and proposal is done.\n. LGTM. Should I merge?\n. Good idea for wasm-linker.h, will do. wrt LinkerModule, I actually want to (eventually) have something that does represent a module, which has the extra data necessary to do linking (hence, a linker module). Whether the thing that actually does the linking is a separate class, or just a method on the linker module, I don't know yet. I think LinkerModule actually maybe could derive from Module, but I didn't do that (at least not for this PR) because I haven't checked whether Module is really suitable for deriving from, and I didn't want to change the actual code to much in this PR.\n. Agreed. I'll go ahead and create src/asmjs and we can either add the optimizer stuff as a followon or wait for #302 first.\n. @brakmic Sorry I wasn't clear enough. I did mean alphabetically; it's nothing complicated, it's just organization :) Thanks for the suggested fix!\n. I'm trying to avoid calling anything a module because that's a term already used in the wasm context.\nAlso LinkerObject is like a relocatable object file. It has code (a wasm module) and also metadata needed for linking. Executable is the output of a link (aka a linked executable, not a relocatable object).\n. do you mean to rename \"executable\" to \"linkedObject\" instead of \"linkerObject\"? I don't really want to call it any kind of \"object\" because \"object\" has a particular meaning for compilers and linkers; i.e. it's a relocatable non-linked file.\n. Oh, I see what you mean.\nYou could think of it sort of like ELF files, where the container is the same, but the properties are different according to whether it's an object file or a relocated executable. So the name of exe has significance in that it tries to convey what the output is supposed to be. I guess the question would be is there a better name for linkerObject. I started out with linkerModule but you didn't like that either :)\n. Almost; A LinkerObject has a Module, and a Linker has a LinkerObject (so it starts out with an empty one). An S2WasmBuilder builds up the LinkerObject (and its Module) that you pass to it. So in the current CL, you just pass the Linker's LInkerObject to the builder. After you call Linker::layout() it becomes a ready-to-run executable (but it's still the same object).\nIn this CL that's all there is to it.\nTo handle the actual \"linking\" part, I'm thinking that, (before we do layout and after we determine which extra functions need to be added), I will open a .s file for the appropriate compiler-rt function, construct another S2WasmBuilder and have it also build directly into the Linker's executable (just as with the main executable). This seems preferable to the alternative which is to build a separate module, and then merge them together.\n. Something like \"output object\" would be fine (Concretely, maybe out instead of exe for the short internal name and getOutput instead of getExectuable for the public method?). I'll update this PR for that shortly, and I think that's all that's blocking this PR.\nMore generally, linking of 2 in-memory IR modules (let's call that module merging) as opposed to constructing new functions and objects inside an existing module (let's call that in-place construction) is sort of orthogonal to the origin and format of the files being parsed, and sort of orthogonal to the exact semantics being implemented, i.e. how dependencies are handled, whether and how you support data objects, address-taken functions, name overriding, symbol types (e.g. weak) and visibility, etc. I say \"mostly\" because the choice might affect how easy or complex things are.\ncompiler-rt is a few functions with (I think?) no data objects, no address-taken functions or indirect calls, and few complications and I think it will be simple to make that work. Beyond that I want to consider a little more carefully what kind of semantics we want to implement, and how far to even take this (vs doing a longer-term thing instead).\n. #554 and its counterpart in LLVM are a little bit of a hack. What we really want is a way to explicitly specify the list of functions (with their signatures) that are available for import, which would be available to the final linker at link time. Currently the linker just takes all the undefined functions and turns them into imports, but an import file would allow us to specify the available syscalls and other emscripten-provided imports, as well as allow users to plug in their own, and the signatures would come from the definition rather than the use of the imports.\n. With LLVM r271599 this should be fixed.\n. This has the side effect of sorting the imports by name rather than by order of appearance in the file, but that's fine since it's still deterministic.\n. otherwise lgtm, thanks.\n. OK, thanks for rebasing it. I pushed the commits from split-build-2 back onto split-build so I can keep using this PR. I think it looks right.\n. I addressed the comments (except for Name as noted above); I'm going to go ahead and land this to avoid more conflicts, as I expect to be out of the office until later this afternoon.\n. It looks like this PR resulted in a merge commit. I thought we disabled merge commits and only use sqaushing?\n. It still has memory_size (https://llvm.org/svn/llvm-project/llvm/trunk/lib/Target/WebAssembly/WebAssemblyInstrMemory.td)\nSo we should fix that. I guess the semantics are the same and only the name has changed so that should be simple. More interestingly, I don't know if the llvm_autogenerated tests have been updated recently, so I don't know if re-generating them would also have other changes. But we should probably just go ahead and do it anyway.\n. By the way if this is blocking someone who doesn't want to wait for a fix in LLVM we could always just accept both names temporarily, and then go back to just one when we update the tests.\n. I'll just go ahead and fix LLVM now.\nOn Mon, May 2, 2016 at 10:21 AM Alon Zakai notifications@github.com wrote:\n\n@Lichtso https://github.com/Lichtso: did you manually change these\nfiles, or automatically? This should probably be done automatically, and\nmight include other changes as @dschuff https://github.com/dschuff says.\nI'm also ok to support both temporarily if that unblocks something.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/419#issuecomment-216300686\n. I thought the change to returning pages was done before already? Binaryen is already using pages anyway. (Also the implementation is apparently already called CurrentMemory so the renaming looks like it will only affect s2wasm anyway?)\n. OK, LLVM and clang are fixed as of r268256\n. I think this is actually less nice.... :(\n. its nice -n 20 less foo.txt\n. This seemed like the simplest way to deal with #370. We have a bunch of files from the compiler-rt library, and we want to be able to link in any of them that we need. In other words the semantics are: if there are any undefined references in the output object that are satisfied by a function in an object file from the library, we want to link in that object file. Those are exactly the semantics of archive linking.\nSo there are a couple of possible ways to do that, but putting them in an archive and handling it the \"right\" way seemed like the best. The archive format is pretty simple, especially if you don't need to worry about all the variations.\n\nOther options might be:\n1) Keeping all the compiler-rt .s files separate, and passing a command-line flag for each of them. In this case the linking logic would be the same (very simple), but we'd just have ugly command lines instead of an archive library.\n2) Keeping all the .s files e.g. in a directory and treating that directory like an archive. This would again have the same linking logic, but we'd have to write platform-specific code to enumerate the directory contents to get the files.\n. No, there's a GNU/System V style, a BSD style, and a COFF style, which are similar but slightly different. We only support the GNU format (the commit message says that and a comment in the cpp file says that but I also just added a comment to the header as well). llvm-ar can produce any kind, so my intent is to just have emscripten produce the archive when it produces libc, and force the GNU format.\n. Ah, good catch, thanks.\n. lgtm for a fix to what's there. But agreed that we should use rpath instead.\n. LGTM\n. Should I just pull the equivalent of this into #448 ? doing that would make #448 simpler.\n. merged into #448\n. I also discovered that libbinaryen-c.so depends on libasmjs and other stuff, so if it goes too late on the link line, things break. What we really should do, is link everything into one libbinaryen.so, which can export both the C and C++ APIs and can be used without also having to link all of binaryen's internal libraries manually.\n. OK I folded something like #446 into this, and confirmed that the build works on OSX.\n. Works on Linux and OSX, haven't tested on Windows yet.\n. Can you clarify that this is the static frequency only? Maybe call it \"static call count\" or \"static use count\" or some such?\n. https://github.com/WebAssembly/binaryen/pull/472/\n. Thanks for doing this BTW; I was planning on adding an option to do essentially this for the linker soon anyway :)\n. Another option might be something like #486 \n. If there are warnings that we just don't want to see, maybe we should consider turning them off instead of adding unwanted casts and such?\n. size_t for 1 and 2 are ok with me too. Often variables like that end up getting fed back into e.g. array index operations which means they were getting implicitly promoted back to size_t anyway. And you often want size_t or an unsigned type for loop counters too.\nIMO the general principles should be that types like Address and Index that are properties of the target (i.e. wasm, and could be wasm32 or wasm64) should not have types that depend on the host (i.e. the machine running the interpreter or compiler). E.g. they should not be size_t or int. When we convert we might want overflow checks anyway. In a lot of those cases we could have extra overloads or templates (e.g. U32LEB(size_t) which checks before encoding or casting down).\n. I just found the gcc warning flags -Wconversion and -Wsign-conversion (https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html) which looks pretty similar to the MSVC warnings you are seeing. If we do want to keep these conversion warnings in MSVC (and assumung the actual set of things they warn about overlaps enough), we should enable these on gcc and clang too.\n. Retroactively, this is related to #278\n. On the other hand, warnings are disabled for the posix systems via command line flags. (I don't even know if there are pragmas for that with those compilers, but it's certainly not common practice to use them). So given that I think I'd rather have all the warning disabling going on in one place (CMakeLists.txt) for all platforms.\n. It turns out we even already have warning disabling for Windows in CMakeLists.txt (/wd4146), so this is consistent; I think I'm going to land it.\nIf we have another concrete use case for a global #include, then we can talk about that separately.\n. LGTM\n. Thanks for taking this on!\n. You don't necessarily need to install those. You can always rely on Travis to see what happens with the Linux build. (There's also clang for Windows; I've never tried that though).\n. I agree that we want to treat warnings as errors. I don't necessarily agree that all warnings on all compilers for all platforms must be enabled. I do think that for the most part it's worth getting better type hygiene, and I also think that if we find ourselves doing a lot of static or c-style casting, then maybe we should look for other ways.\n. OK after looking some more, I think we should:\n1. Remove toIndex from this PR\n2. Remove SIZE32LEB from this PR.\n3. Change the constructor of LEB to take a size_t argument as I suggested above (that can be in this PR because it's a pretty trivial change).\n4. Land #537 or something like it in a separate PR.\nIf you do 1 and 2 and optionally 3 for this PR, then it LGTM.\n. It could be if we wanted. In eafc06f8cf2b815d151b67c67086f33b3dae6b8b I disabled the warnings that create all the noise about this. But it still seems like it might be valuable to fix these type issues.. On the other hand, several of the codebases I work with (e.g. LLVM and Chromium) also disable these warnings, so it may not be worth fixing all of these.. LGTM\n. LGTM, thanks!\n. Relevant to the discussion in #491, but I haven't tested this on Windows yet. (Won't be able to until Wednesday). @BSalita if you want to roll this into #491 or another PR yourself, that would be fine too.\n. I think this should be able to replace the uses of toIndex in #491 though, so it would be unfortunate to land all of those parts of 491 just to back them out again....\n. I'm not worried about performance. Optimizers can handle small structs just fine; also even the C ABI specifies that such structs are passed in registers on x86-64 and ARM IIRC. It's quite a common pattern, and the C++ standard is even written to accomodate optimizations like RVO (see e.g. http://en.cppreference.com/w/cpp/language/copy_elision although this class doesn't even have any constructors).\nVarargs is more interesting. We can think if there's a way to improve that.\nEven if we do only need to support wasm32 or wasm64 in a single build, we would want to use the same sources, so the solution may not be any different. Address is already a template, so assuming we clean up all the type assumptions for Address (and Index, although it may or may not change), it might be as simple as making a few other AST types templates.\n. sure; do you mean measure the performance? (performance of what? build, interpreter, both? what's your preferred benchmark for that, anyway?)\n. FWIW I build with clang locally. It's a newer version of clang than Travis has, but between that and the gcc build on Travis I'm not too worried about the coverage. It's a little annoying that the builds are all red, but we can give it a day or 2 and see if it gets fixed.\n. It ought to be pretty straightforward to build the sanitizer code if we want to do that. It would mean that we'd be using bleeding-edge clang, and that bugs in the sanitizer code or the x86 backend could block rolling the waterfall into the binaryen build. But it would let us keep the sanitizer builds and make the bot setup faster to boot.\n. With #559 this should maybe actually work now. Do you know if there's a way to force a travis build other than just pushing a dummy change to the branch or something?\n. Ah, there is a link in travis to restart the build. we'll see what happens.\n. You can log into travis with github oauth. I'm not sure if that's what gives me the link but it seems to work.\n. Yep, let's land it.\n. Yeah, sorry, I was just running this before I left the office and wanted to get it recorded somewhere before I forgot about it. You're right, it doesn't look actionable and it's probably not new.\n. Looks like we have our first winner in the \"upstream LLVM commit breaks binaryen build\" lottery. I'll close this and try another.\n. Well to be fair, the commit that broke it was reverted after 50 minutes. I just happened to pick a really-new build and got unlucky.\n. (but having said that, that sort of thing is not too uncommon.)\n. OK, looks like we have an actual winner with 7268\n. OK, added a few fixes and made validation mandatory.\n. OK, even better idea. Validation is on by default, but can be disabled with a flag to allow for debugging. That way if validation fails we still don't produce an output (and don't overwrite any existing file either).\n. I'm in favor of doing something like #582 rather than making the registration magically use strings.\nRegarding \"whatever LLVM does\":\nLLVM tries to have it both ways, because it does have explicit createFooPass() calls but also tries to have auto-registration by name e.g. for opt. One reason they have the explicit way is because they need to support several different ways of building and linking all the passes (e.g. linking everything into a single DSO, static linking with different archive libraries, etc) and support different platforms, so there ends up being some redundancy. Often you can get away with avoiding some of it for one use case but not for others. I think our use case is actually similar. If we intend for people to use parts of Binaryen in their own projects we have to support a variety of ways of linking, and that means having things more explicit. If we do the extra work to make things work with strings like in LLVM we can support that too, but I don't think it's worth it. I'd vote for just having createFooPass() for each pass and being done with it; it's a little extra boilerplate, but not that much, and it means things will just work. To me, our users are better served by giving them something that will more reliably work and be more tolerant of different environments than saving them a few lines of copy/paste.\nAs for things being defacto standard over ISO.... Well \"whatever LLVM does\" doesn't override ISO, but \"whatever works on the platforms we care about\" does :)\n. I thought we had decided that we only wanted to support VS2015?\n. I don't know if there was a definitive decision, I'll see if I can dig up the discussion. The short version though is that there's a fairly long list of C++11 features that don't work or are buggy in VS2013, and VS2015 has basically complete working C++11 support, so we can just say \"any C++11 feature can be used\" instead of worrying about which ones work on which platforms.\n. @kripken I just posted about the question of whether we should do this at all on #577. In particular I think we want to support both shared and static use cases.\n. Landing this because I have another change stacked on it; I can address additional comments in the next PR.\n. @jfbastien, @sunfishcode, @kripken \n. Ah, I didn't realize that about emscripten currently. That should make things easier since there won't be any expectation of things working without some manual intervention by the user. I agree that for 2) we can just plumb something through to s2wasm. I'm not sure __attribute__((used)) can do what we want for wasm; IIRC it only prevents the function from being omitted/DCEd. If that's the only effect the macro has in asm.js, that would seem to imply that everything is implicitly exported just by virtue of its being in the module?\nFor visibility, I supposed it depends on what you mean by breaking changes. If there is a user who is already depending on the \"everything is exported\" property, then this will break them. But it seems like we still want to not have everything exported, and of course we haven't shipped yet so breaking changes like that should be expected :). Going forward, if someone uses default visibility to cause functions to be exported from their wasm modules, then we will have the question of what that means for dynamic libraries. We might conceivably want to separate the idea of wasm exports (e.g. to the environment) from the idea of DSO/DLL exports.\n. Yeah, JSON seems not-great, for the command line at least. Assuming we do end up requiring or allowing exports to be specified externally to the program sources (e.g. a response file), it might make sense to have something unified with #558. Although for #558 we'd need a way to specify types as well as just names, so maybe something more structured than just a list of names would be needed.\n. We hope to be able to replace s2wasm before too long. But for now I think it would be OK to make s2wasm's behavior match what emcc has for asm2wasm, which sounds like it could mean reducing the exports even more than that. This is something I'd been meaning to do \"sometime\" so if you wanted to pick that up that would be OK. At minimum we need to export functions named on the command line and things marked with EMSCRIPTEN_KEEPALIVE (I think that's what the macro is currently called? We discussed making something like EMSCRIPTEN_EXPORT based on the discussion above but not sure that we actually did). We probably do want to eventually have a visibility-like model but since that probably means exporting more things compared to the current asmjs behavior, switching to that probably wouldn't break things.. Going to land this because I'm going out of town tomorrow, and don't want to leave it around to get stale. Feel free to fix or even revert if there are objections.\n. Ah yeah.... so we've been trying to bring up the remaining emscripten test suite tests for the wasm backend (which exercise a lot of emscripten features and, JS glue, etc) before landing this to see what kind of effect it had. But we are getting close on that, and we are also working on getting support in LLVM for wasm binaries (which will be a bit later), so now might be a good time to start thinking a little more about this as an ABI/convention issue.\n. I think we'd want wasm-opt to be optional, rather than a requirement. the LLVM wasm backend has plenty of optimizations that it inherits from LLVM's target-independent code, so it produces pretty decent code quality. I could certainly imagine that wasm-opt might be able to improve on that, but we haven't done really any meaningful performance work yet.\n. Yeah; as I said we've basically been trying to mature the backend in the face of all the changes to wasm itself (and catch up to JSBackend's several-year head start). There are lots of optimization opportunities still on the table.\n. I think the reason I was holding off on this was to get the rest of the emscripten testsuite passing (which @jgravelle-google has been doing, along with the various general improvements like the libc update). At that point we would be more assured that turning this on wouldn't break anything.\nMore generally I think we still want to do this anyway, but the design for what \"visibility\" means (to the linker and in C++ code) should probably be done in conjunction with the other design conventions e.g. https://github.com/WebAssembly/tool-conventions/blob/master/Linking.md and https://github.com/WebAssembly/tool-conventions/blob/master/DynamicLinking.md \nSo, short answer is, we can probably try rebasing it and turning it on more-or-less as-is shortly. If things are fine for the current emscripten+wasm-backend style of integration, then we should land it. If not, then we can close it and rethink things.. I think it probably makes sense just to have a standalone tool like llvm's opt. It's kind of weird that we use binaryen-shell, an interpreter, to do optimizations and not interpret. Obviously it's not a huge deal since it's simple either way, but I think it's cleaner.\n. I think I like wasm-shell and wasm-opt. Having binaryen in the name is maybe a bit redundant.\n. A couple general questions before I look at the implementation:\nCould a test for this functionality be added to test/dot_s/alias.s? I think the test itself could probably be simplified quite a bit. Or in general I think if we are going to have a generated test like this we should also check in a .c or .ll file that it's generated from (maybe with a comment which includes the command used to generate the test).\nIf you look at test/dot_s/alias.s you can see what the support for function aliases looks like. I guess what this PR adds is support for object aliases. If you build it for Linux, what kind of ELF relocation results from this code?\n. wrt the implementation: I think this support for object aliases can just work like the current support for function aliases. See line 383 and 523 of s2wasm.h and the support for aliases in src/wasm-linker.{h,cpp}. It wasn't written with object aliases in mind but I think it could be straightforwardly generalized.\n. LGTM, just need to fix the emscripten version.\n. It's new, we are bringing it up. It won't work in this PR unless you rebase against the lastest master.\n. It looks like some clang output (e.g. the musl build on the waterfall) has output like\n.weak   ___environ\n    .hidden ___environ\n___environ = __environ\n    .weak   _environ\n    .hidden _environ\n_environ = __environ\nwhich seems to violate the assumption on line 427 that all aliases will have a size. Can you investigate?\n(you can repro by running the musl libc.py script as the waterfall does but with the --save-temps flag)\nSince that particular build is just experimental, I don't think we need to revert this patch for now.\n. LGTM\n. I wonder if it's not the status on the repo but on the WebAssembly organization that makes a difference. Neither of us is actually an owner of that organization.\n. I was able to make a build ( https://ci.appveyor.com/project/dschuff/binaryen ) that seems to be from the WebAssembly binaryen repo. I don't know if it matters that it's project/dschuff rather than project/WebAssembly or some such?\n. I don't appear to have access to the settings of WebAssembly/binaryen. I might be some kind of contributor or commiter rather than an owner.\n. https://ci.appveyor.com/project/WebAssembly/binaryen\nSeems to work.\nThe only problem now is that I accidentally signed up for a trial of the private-project account instead of the free OSS account, and I don't see a way to convert it from the account config (I can only buy the ugprades). I'll look into that.\n. Actually it looks like that's not a problem according to http://help.appveyor.com/discussions/questions/1118-how-to-change-my-plan-to-free-for-open-source-projects so we should be good.\n. OK, I tried revoking and re-authorizing.\n. Also tried a test PR: https://github.com/WebAssembly/binaryen/pull/624 but it doesn't appear to have triggered a build.\n. IIRC @kripken is the owner of the repo. (If not, then @jfbastien should be able to check).\n. Cool. Things seem to be happening now on my test PR: https://github.com/WebAssembly/binaryen/pull/624\n. The hook only included 'push' but not 'pull request'. since my PR was on a branch in the WebAssembly repo itself, and yours was on a forked repo, maybe that explains the different. I added the 'pull_request' event too. try again?\n. Actually, hold off 1 sec.\n. oh it did work that time. cool.\n. So right now we have Debug/Release x (Msys x 32/64 + VS2015 x 32/64)?\nDo we expect a lot of people to be doing Windows 32 builds? My guess is that almost all devs doing Linux and Windows-hosted builds will be using 64. I would guess that emscripten/wasm itself will be the most common 32-bit target :).\n. Maybe for now let's drop the debug builds for Msys and 32-bit VS. (I would expect users wanting to debug would prefer VS and be using 64-bit). We can always tweak later. \n. Great! I think this can go now, we can tweak as needed.\n. I'll switch it to use the unique one from the appveyor project: https://github.com/WebAssembly/binaryen/pull/626\n. Closing; this test has served its purpose.\n. Messed up the push, resettting.\n. LGTM, thanks.\n. LGTM\n. LGTM, can you rebase the conflicts?\n. I think we shouldn't create the function if there are no address-taken functions (because then we can have no table at all). Casting a random number to a function pointer is UB. Practically speaking, compilers will usually let you do it, especially if you just call them (e.g. when you have things mapped into memory like VDSOs or NaCl's syscall trampolines). However if you just casted a number like 17 and compared it to nullptr, you still wouldn't have anything be address-taken, you'd just get integer arithmetic.\n. 2 more comments, otherwise LGTM\n. Great! Could a test case for this be added, maybe to one of the existing dot_s tests?\n. Oh, could we just take one, say basics.s, and remove the .file line following the .text at the top? Then if this bug is not fixed, the .globl would not be parsed and everything would go wrong, right?\n. Yeah, that should work. Assuming of course that the .type following the .text is in fact a function then it should just be redundant and have no semantic effect.\n. LGTM, thanks!\n. In the past we've kicked around the idea of defining a flavor of wasm (an IR, if you like) which is not exactly wasm but more natural for many compilers to produce (aka a producer-oriented/subwasm/flat wasm). What you are describing as Binaryen's new non-isomorphic IR sounds a lot like that in some respects. As you have observed, Binaryen would then be a one-way tool (at least the compiler part would be; obviously from the user perspective Binaryen has always been a loosely-related collection of tools; e.g. we could still have wasm-as and wasm-dis if we wanted to, they would just not use the same IR).\nI think you are basically correct about the consequenses of moving Binaryen to this style of IR. Presumably it would evolve a bit (since it doesn't have to precisely track the current flavor of wasm we could rethink pain points that exist or as we find them), and libbinaryen (C API, optimizers, etc) would track this evolution.\nFor s2wasm it would depend on what we wanted to do with LLVM; we could make LLVM target the \"flatwasm\" IR if we wanted to. Moving the compiler part of LLVM fully to a non-wasm IR might have interesting consequences for linking formats and the other parts of LLVM, but that's a decision we can make independently of what we want Binaryen to be.\nPractically speaking, we may choose over some near-term period to keep on trucking and paper over the differences while we work out what we want the end product to be.\n. That makes sense; If we do want to just go toward a new IR, we do have sexpr-wasm-prototype which can take the role of binary encoding, decoding, and standalone interpretation. Then the IR can be designed for ease of production from whatever class of compilers we care about, and for wasm-specific optimizations.\n. @kripken \nIn general I'm on board with Binaryen's IR not needing to be wasm per se. Binaryen (as you are conceiving it here) is essentially a tool and optimization framework for compilers to more easily target wasm, and the IR you use for those optimizations doesn't need to correspond or translate 1:1 with wasm, even if you use it to implement a wasm->wasm optimizer.\nI'm a bit confused as to why we need to formalize and have a binary format (and e.g. and full-blown interpreter) for this IR. I can buy having a text format (which is useful for writing tests). But the following things make me nervous:\nIt sounds like you are conflating 2 different things with this proposal: A compiler IR meant for optimizations, and machine format/VM that you want compilers to target. Do we want to try to make this IR stable? (my opinion: no) Do we want to write a linker for this format? (my opinion: no). Do we want to define ABIs in this format? (probably not). A wise soul once cautioned the LLVM community about doing this and even though LLVM IR might be an extreme example compared to wasm, the underlying lesson is that that the goals of an optimization IR are different from a platform (and here especially I mean \"platform\" in a broader sense than just a virtual machine, e.g. ecosystem, interchange format, etc).\nFor example,  we know that it's likely that an optimizing compiler might want to use a CFG and not do its own control-flow restructuring, so Binaryen's library includes a relooper API. This is fine if we convert it to a structured IR before optimizing. But we wouldn't want to require that, so what do we do if we force everything through a binary format that matches the IR?  Making a binary format that supports both seems like a bad idea because even aside from the complexity, it's incompatible with the stated goal of keeping the IR close to wasm.\nAnother way to say it is, the goal of keeping the IR as close to wasm as possible may be opposed to the goal of making it useful for optimizations, and making more like a \"platform\" (binary format,e tc) is opposed to the goal of making it flexible for different use cases.\nHopefully that wasn't too ramble-y.\n. Those are all good goals, however:\n(TL;DR: we shouldn't tie our \"primary\" object code format to something other than real wasm if we can help it. Our most primitive mechanisms should be as primitive as possible).\nFirst, let's distinguish the container/file format from the content of the code section, and consider just the code (and any necessary relocations generally, that go with it).\nAny code format that we call \"the\" object file format or even that we just want to be \"the primary\" object file format has to be as close to real, actual wasm as possible, for a few reasons: There will always be those who want to \n1. produce real wasm themselves (even in \"relocatable\" intermediate format),\n2. produce real, linked, browser-ready wasm (i.e. do their own linking),\n3. who want to use \"standard\" libraries from the emscripten and/or LLVM ecosystem, \n4. who want to use libraries produced by producers who want to produce real wasm themselves\n...and of course we also want to support those who want not-1 and not-2.\nWe shouldn't impose a second format that isn't real wasm on those who want to do 1 but not 2, or on those who want 1) and 3), or who want 1) and 4)\nIf we have a code format that isn't wasm (in particular if our linker and tools use such a format), 1 and 3 become mutually exclusive (unless we ship all of emscripten/LLVM libraries and ports twice). Also a user who wants 4 will be required to do 1, and 4 and 3 become mutually exclusive (or at the very least, mixing 3rd-party libraries will be challenging) because even if we ship our libraries and ports twice, we can't require that everyone do it.\nSo all this is to say, I really think our primary linking tools should support real wasm, and linking should be as dumb as possible (i.e. should not require the linker to understand wasm semantics).\n(wanted to get this down before I forgot it,  idea/design sketch to follow, which hopefully supports what we want).\n. Let's suppose we have a container format, and a relocation format that fits in it, along with section-merging semantics and relocation types that cover what we need (e.g. signature table indices, function table indices, types, etc). It could be ELF or the wasm binary format, doesn't matter for this discussion. Le'ts call these .o or wasm object files. We'd want to make this as stable as possible.\nTools that linked this format would support any third-party tools that produced wasm directly, as long as they also produced our relocation info. So, what about our \"higher-level\" toolchain, users who want to have simpler compilers, and LTO?\nHere are a couple of thoughts:\n1) For simpler compilers, we can still define a second code format (e.g. .byn, or optimizer object file). It could be flexible (i.e. could support both CFG and structured control flow) and designed for more powerful optimizations. Notably, while wouldn't want to break it arbitrarily, the stability requirements would be much less onerous. Binaryen tooling would of course include a tool such as byn2o.\n2) For mixing byn-object and wasm object files, the simple option would be to run this byn2o tool on any byn-object files, and link everything as wasm. This allows any part of the link to be in any format, with only one linker required (and it can be a simple linker), and all the interesting semantics (symbol resolution, etc) can be defined only once: at the wasm-object layer. It allows any local optimizations on the byn format with high fidelity to the original source and allows any kind of additional optimization-related metadata we want to have in byn, without imposing that on users who don't need it.\n3) That leaves LTO. First let's leave aside LLVM LTO for the moment: we can have that in addition if we want it in any case, and we might in fact want it because LLVM IR has more C semantic information than byn or any other low-level format will. Also byn optimization will be focused on wasm-specific stuff: local wasm-specific stuff (AST formation/optimizations, control flow reconstruction etc) are handled adequately in separate compilation. So that leaves inter-procedural stuff: inlining/outlining, DCE, and probably stuff that feeds better DCE like global constant propagation). Some of that could be handled simply in a way like ELF function-sections. But we probably want to do better because size is so important. For that use case I think we should still link at the wasm layer, and then use our proposed wasm2byn tool to convert the whole linked program to byn for optimization. Compared to the opposite (making everything link and optimize at the byn layer) it has the following advantages:\n- It works even with wasm files produced by non-byn-emitting tools (this case can also be served by using wasm2byn on wasm input before linking but see the next point).\n- Linking semantics only have to be defined at one layer: the wasm layer. This seems like a big advantage because for example LLVM IR has some quite tricky bits and subtlety around its implementation of module merging for LTO. Even when it's simple, it still has to be duplicated from the lower-level definition. And we'd have to define how those semantics map in both directions (byn2wasm and wasm2byn) which is not the case with LLVM IR today. Practically speaking, I actually think the merging and symbol-resolution semantics won't be too terrible, but where there are corner cases, it will be easier to e.g. make the optimizer conservative and then improve where possible, rather than have to make it exactly precise all the time.\nDoing this means that to the extent that byn2wasm->wasm2byn is not exactly a precise round-trip, the code that gets LTO'd won't be exactly the same as what a byn-producing tool generated, but I can't really see why that would be a problem. Also, much of the byn optimization will still have happened before link-time, so any cases where it's critical can be handled there. In fact if we wanted to we could even include some metadata in the wasm object if we wanted to aid that, or do a full-on LLVM-style LTO if we wanted. But we wouldn't have to, and it could be added later, rather than being required.\n. First, linking and platforms:\n(Let's use \"platform\" instead of just \"linking\". Platform is where you define not just execution semantics, but also linking, ABIs, and other conventions. Fundamentally it's where you define interoperability). The first observation there is that we can't have only Binaryen as a platform. Unless we can mandate that everyone use Binaryen, then we either have to define completely and stably how it maps to the underlying wasm platform (thereby duplicating all the platform design work, creating a huge maintenance burden, and running into a lot of pitfalls) or say that we don't care about interoperating outside of our sub-platform. As an outside example, even systems that use a common framework like LLVM don't use that layer as their \"platform\" in this sense; they use the underlying target's native platform primitives (ELF object files, etc). LLVM could be capable of expressing everything needed to have this interoperability; in fact they tried it in the past, but it runs counter to the other goals they have for LLVM. They got it right for optimizability and readability right (as you mentioned upthread) but it came at the cost of LLVM's ability to be a good platform unto itself. LLVM doesn't need to be a platform in that sense, because it sits on other stable platforms where that work is already done. In essence they made the same choice I'm advocating here, for some of the same reasons.\nIntrospectability:\nThis is another way of saying \"understandability\" or \"readability\" and it sounds to me like this probably the most important thing to you (or at least the thing that is more important to you than maybe most of the other involved parties). First, understandability is subjective (for that matter, even ease of targeting is subjective). We've already seen that when we discussed a flavor of wasm more friendly to producers, but your idea of what that would ideally be was quite different from @sunfishcode's (AST vs flat 3-address style, etc). I think you can do much better on that front that if you can focus on it without being required to also maintain ABIs and worry about the implications of whether your binary format has attached metadata or sections, or what you have to do to your frontend in order to interoperate with Joe Schmo's compiler (or say, Herb Sutter's) who doesn't want to use Binaryen. In short, you can be opinionated.\nPhilisophical rant:\nIf we want to have an opinion about what code on the web should look like, we have a forum where we dictate that to our users: it's JavaScript. The whole point of wasm is to let our users dictate to us how they want to code on the web. Interoperability is absolutely key to that. In my opinion it's even more important than introspectability. Our primitives can't be opinionated because they have to be general. In other words I think a byn format will be much better at the things you care about if you don't have to care about all the things, and you can have more control over the things you care about.\n@qwertie I agree that \"binaryen\" being a repository with \"all the wasm tools\" and also a compiler library and also a linker and a file format and a compiler flag is confusing. I think we should probably try to factor tools, names etc and maybe even repos in a less confusing way before we release/publicize a toolchain. But that's another thread :)\n. @qwertie \n\nI had assumed he was talking more about computational introspectability: optimization, decompilation, making it easy to generate code at runtime. Various computational tasks are easier with an AST.\n\nThat's true, but I would consider that as just part of \"optimizability\" (or specifically it would be suitability to analysis which is of course part of optimization) which I had already considered as the other major goal of binaryen IR. My take on @kripken's comments (and ones that he has made in the past, and of course his ongoing concerns about the text format) was that he also considers understandability a primary goal. e.g. there is no doubt that LLVM IR is pretty good in that respect.\n\nI'm pretty sure there's an objective case to be made about an AST being more understandable to humans than a flat instruction list... to me it's so intuitively obvious that I'm not sure how to argue the  case.\n\n2 responses. \nFirstly: sure, when you put it like that it sounds obvious, but we are not talking about a structured AST vs, say, a traditional assembly language. A stack machine does not have the same structure as a pure AST form, but it also does not have the \"no-structure\" that an assembly language has. Here's another interesting observation: we've had a lot of lisp fans hanging around here since the beginning, who would no doubt share your intuitions about ASTs, but the switch to a stack machine has suddenly brought a lot of Forth fans out of the woodwork, who might have different opinions about how intuitive stack machines are :)\nSecondly: I am actually extremely skeptical that even if, say, we stay as an AST and get the best and most intuitive possible syntax for it, that the output of an optimizing compiler will be any more (or less) usefully readable than assembly code is for native C developers, or JVM or CLR bytecode is for users of those systems. Compilers do a lot of transformations (and doing more transformations often makes them more useful), and the output will always necessarily be much lower-level and well-removed from the source. Wasm developers will be using wasm for the same purposes that assembly or VM bytecodes are used today (as opposed to what you used to be able to do on web pages; i.e. read the JS source that the page author wrote). I say \"used to\" because optimized and minified JS is already no more (or less) useful than other VM bytecodes, and wasm will not make this situation any better, or worse. That isn't to say that understandability isn't valuable, or that we shouldn't try to make it as understandable as possible. But IMO we need to keep our expectations realistic as to the result and its utility.\n. LGTM\n. (I think you can still make an equivalent commit on master if you want that functionality now, before the stack branch merges)\n. We may want to keep stack on a branch alongside the binary_0xC branch in\nthe spec and the engines, so that we can transition about the same time?\nProbably worth a separate discussion about that.\nOn Mon, Aug 15, 2016 at 4:35 PM Alon Zakai notifications@github.com wrote:\n\nOk, maybe I'll do that. I was hoping to get all of stack merged sooner\nrather than later, but that's now how it ended up...\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/671#issuecomment-239960608,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKKaiispEt5v6oWvJbz2xt0oFonGqks5qgPe_gaJpZM4JktGT\n.\n. This is probably the wrong place to discuss it now, but might as well leave it here since it's on-thread. \n1. After some offline discussion with @kripken we decided that we could go ahead and put 0xc stuff on master since we don't expect to add anything new for 0xb. For uses that need 0xb, we can just check out the last version of Binaryen that worked with 0xb. Which brings me to...\n2. The last version that works completely with all of the other tools on 0xb is e268d939b86d8639d014b8036e7664d66b6a32e9 (before the tables and memories). We discovered from the waterfall builds that apparently sexpr-wasm doesn't support the syntax for that yet. We could switch to wasm-as for those use cases, but instead, I think for the purposes we care about we can just declare that version as the last 0xb version.\n3. For the waterfall build: \n   Currently the waterfall build tests the following:\n   1. Bare LLVM/clang with the C torture tests against v8's native wasm support (which will probably remain 0xb until the browsers have a flag day). \n   2. emscripten-integrated asm2wasm and LLVM backend support with the C torture tests against v8's native wasm support\n   3. emscripten+LLVM backend with the emscripten test suite against the binaryen interpreter (INTERPRET_BINARY binaryen method).\n\nI think we will use the 0xb version of s2wasm for (i) so we can continue to test v8 native wasm, and switch to INTERPRET_BINARY for (ii). @jgravelle-google should have a patch to the waterfall repo for that soon.\n. So just so I understand, environ is an extern object (as oppsed to a function)?\nWe currently automatically make any undefined reference to a function an import, and additionally generate a thunk for it if it's address-taken, but I don't think we do anything for objects currently.\n. OK, i think what I said is correct. I'm not familiar with the externs mechanism in emscripten, but assuming this uses it correctly then this looks fine to me. Can we get a test for this?\n. This should be covered by https://github.com/WebAssembly/binaryen/pull/843. I think I'm almost ready for this. The waterfall has been a bit chaotic lately. Right now the standalone (non-emscripten) tests are running with a frozen version of binaryen to test v8's native wasm mode, so they won't be affected. I'm about to land https://reviews.llvm.org/D24053 which fixes several tests. Currently though the emscripten build on the waterfall is actually broken because of the build warning that @aheejin reported in https://github.com/kripken/emscripten/pull/4501. So maybe we should fix that and get it building again before landing this? Shouldn't be too hard, I'll look into it.\n. I think so. Is it still the case that s2wasm/wasm backend is completely disabled? I guess what we have to do is just update the wasm building code in s2wasm, so that it builds the new IR?\n. Yeah, go ahead and land it. Thanks for the heads-up.\nOn Tue, Sep 6, 2016, 4:45 PM Alon Zakai notifications@github.com wrote:\n\n@dschuff https://github.com/dschuff: ping - are you ok to land this?\n(needs a merge fix which I'll fix, and later on master we can figure out\nthe .s/wasm-backend tests)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/678#issuecomment-245130811,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKH0y2PC2H7achrKPG-j8vJ2Fw9xuks5qnfsOgaJpZM4Jrn_s\n.\n. LGTM too. I guess this can land before the LLVM change too.\n. Yeah, it could be done with a script. e.g. https://github.com/mozilla/fxa-bugzilla-mirror looks potentially promising.\n. Good point; mabye we can just go with binaryen or some other WebAssembly GH repo for our own bugs for now. I'll additionally try to subscribe to wasm backend bugs and mirror those to GH if they get filed externally. For those bugs I guess we should try to keep most of the activity on bugzilla so it's visible to the reporter.\n. For now we'll just use Binaryen's tracker for LLVM bugs. I'll mirror any reports that we get on the upstream bugzilla.\n. (LGTM with that nit fixed)\n. Fixed in https://github.com/llvm-mirror/llvm/commit/0b1363654659d4edc744ac588e97cfb3813971a6\n. @kripken I'm going to go ahead and land this since it's a mechanical change and it's green (and it shouldn't conflict with the stack branch). We should hopefully be able to test the wasm backend on the stack branch now.\n. LGTM\n. LGTM\n. (modulo any breakage/conflicts after the stack branch; we still need to fix s2wasm).\n. Forgot to mention the torture tests aren't all passing yet, but this is still a good step.\n. No, I just got back to fixing the builder thing. I plan on landing it now as soon as CI builds finish.\n. I pushed my WIP binary format section branch to\nhttps://github.com/WebAssembly/binaryen/tree/binary-sections\n. Yeah, I think i can finish that up.\n. The only thing left is use of the new JS API for native-wasm. I don't think the JS engines support importing tables yet, and I think we still need to do things like instantiate WebAssembly.Memory instead of just passing ArrayBuffers around.\n. Current state is that type, import, function, table, memory, and export sections seem to match ml-proto; there's still some issue(s) inside the code itself, and the remaining top-level sections I haven't checked yet. I also updated the \"names\" section (now a user section) but haven't checked against any other tools.\n. Oh, oops; this was merged to the spec-update branch instead of master. I'll fix it to master manually.\n. It looks like it doesn't conflict with #711, right? (I mean technically it does touch wasm-binary.h but not the same lines). So I think it should be fine.\n. Why not just fix alias.s (i.e. fix the function type vs its return value) rather than disabling all of the .s tests? (or maybe we need a mechanism to disable individual tests because clearly just disabling them all whenever one is broken is terrible).\n. Actually, shouldn't the extra validation go in a separate PR anyway?\n. from alias.s it looks like __exit is void (i.e. no .result) but it also has return $pop4.  Also the drop for the call to __exit isn't in the .s, so I'm not sure exactly where it came from. It's also a known (to me) issue that s2wasm emits a bunch of redundant drops (the code I added in the last update to put them in for 0xc is really dumb) so I had already planned to look into the drop code once Binaryen's 0xc stabilized, so I'll look at this too.\n. @kripken  It's close but just wanted to get it up since I may not work on it more this weekend. Feel free to mess with it if you like.\n. OK, so I figured out more about the issues. This code is consistent with the current old-style type-checking scheme, and it works with one exception, the following test from test/spec/return.wast:\n\n(func (export \"as-br-value\") (result i32)\n    (block i32 (br 0 (return (i32.const 9))))\n  )\nThe .s parser ignores the block signature, and the result in the IR is the following:\n(func $0 (type $0) (result i32)\n    [unreachable] [unreachable] (block $block0\n      [unreachable] (br $block0\n        [unreachable] (return\n          [i32] (i32.const 9)\n        )\n      )\n    )\n  )\nNote that it considers the block to be unreachable rather than i32. This typechecks OK. Note also that without a block signature we don't know a priori whether the br should yield a value. The reason it can successfully parse the wast is because it has the ) that terminates the Element. In the binary format this was previously encoded in the br's arity immediate but now that's gone. With block signatures it's not necessary because the break target's arity tells how how many values to pop from the stack. When writing the binary, we write out the blocks with signatures, as the inferred type. But in this test the signature can't be inferred; the block end is unreachable, and the br targeting it is also unreachable. \nI made a hacky workaround which, for the purposes of encoding, infers the arities of unreachable break targets and encodes those as i32 (which on the decoder side will be ignored other than for the purposes of decoding). But I think we won't be quite compatible with other binary consumers until we correctly get the types of those blocks (which I think also implies updating the type checking).\n. @JSStats yes, that's what I'm saying we should do (i.e. actually parse the block signatures and use them when building the IR). Currently we still have the same type-inference code from binary 0xb before block signatures were adopted, and we should fix that.\n@kripken Currently (i.e. in this branch) the wast parser still ignores the block signatures entirely and the binary parser only uses them for decoding (the old type inference is still used when the block is finalized). I'll take a look at your branch, although I think we can probably merge this one as an intermediate step, and then put yours onto master.\n. So the binary format difference is because in the wast parser you replaced the block finalization with the logic that instead only marks the block as unreachable if no breaks target it and the fallthrough is unreachable. If you do that in the binary parser too then it works correctly (I have that working in my local branch).\nI do think the \"primary\" behavior should be that the type of blocks doesn't get changed by default. It might make sense to have a service for binaryen library users that might not know the block type up front (which I guess may include the optimization passes) but it doesn't need to have the same behavior.\n. I think the exit type being wrong is a problem with the .s file and not with s2wasm. Also there's one further failure in the wasm-opt tests before we can turn on drop validation:\n.. vacuum.wast\nexecuting:  bin/wasm-opt --vacuum split.wast --print\n[wasm-validator error in function $if-drop] unexpected false: Dropping a none value, on \n(drop\n  (if\n    (call $if-drop)\n    (call $int)\n    (br $out)\n  )\n)\n[wasm-validator error in function $if-drop] unexpected false: Dropping a none value, on \n(drop\n  (if\n    (call $if-drop)\n    (br $out)\n    (call $int)\n  )\n)\nFatal: error in validating input\n. Alternatively we could just create a table unconditionally, but this seems slightly more optimal. I wonder if tables can be empty?\n. Should fix the failures seen in https://github.com/WebAssembly/wabt/pull/127/\n. OK yeah maybe it would make more sense to just skip all this smarts and just always create a table, even if it's empty. the cost of that would be pretty minimal all around.\n. That does look like it might be interesting. Can we factor that code out from asm2wasm.h into some cpp file so that it can reused?\n. I haven't thought about the details of how it works yet... I just like for things to be in cpp files :)\n. Thanks!\nOn Mon, Oct 3, 2016 at 10:28 AM Alon Zakai notifications@github.com wrote:\n\n@kripken commented on this pull request.\nIn src/wasm-validator.h https://github.com/WebAssembly/binaryen/pull/726\n:\n\n@@ -28,7 +28,8 @@ namespace wasm {\n\nstruct WasmValidator : public PostWalker> {\n   bool valid = true;\n-  bool validateWebConstraints = false;\n-  bool validateWeb = false;\n-  bool validateGlobally = true;\n730 https://github.com/WebAssembly/binaryen/pull/730\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/726, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKOJi6oGuHZb_WvCWHefpjKicnrMdks5qwTsugaJpZM4KMIOw\n.\n. Can you add a test (maybe in memops.s)?\nAlso in the commit description, maybe make it \"width of the store\" or \"width of the stored value\" rather than \"width of the instruction\"\n. I would still like to have at least one small handwritten test. As you can see it's pretty easy to just auto-update the generated tests and miss things. I don't much care whether it's a .s test or  wast test, it should exercise the printing either way. I guess just a tiny function with an i64.store32 in test/unit.wast should do it, right? \n. Yeah, I have this and a bunch of other 0xc updates in my current working branch, which I hope to send a PR for today. If this is blocking you I'm happy to merge it now and rebase my branch. Otherwise this fix should be in shortly in any case.\n. TBH I'm not super thrilled about string names being the only/primary way to refer to so many things in Binaryen IR. Obviously that was a design decision and not a bug, and it does have some advantages, but it leads to difficulty and bugs like these. (Also it means that the IR can faithfully represent valid wasm without any names, although obviously that doesn't have to be a first-class goal now) If I were doing it from scratch I'd probably have pointers or some other handle be the way objects refer to each other in the IR, with name lookup as an optional addition. Obviously that's a bigger change and maybe you don't want that anyway :) But given that names don't need to be unique in the input language you either have to uniquify them or deal with the possibility of collisions (I suppose to be sure of break targets in the current IR you'll have to have code in several places that walks the scopes outward rather than relying on the names). Given that 1:1 is already not a goal and the IR design relies pretty heavily on names being the primary handle for so many things, making them unique is probably the way to go (unless you do want to get a little less reliant on the names).\n. Yes, hot off the waterfall.\n. (well my local build of the waterfall)\n. func.wast has\n\n;; TODO(stack): move these somewhere else\n(module (func $type-return-void-vs-enpty (return (nop))))\n(module (func $type-return-num-vs-enpty (return (i32.const 0))))\nand return.wast has\n;; TODO(stack): move these somewhere else\n(module (func $type-value-void-vs-empty (return (nop))))\n(module (func $type-value-num-vs-empty (return (i32.const 0))))\nAre my tests out of date?\n. Yeah the problem now is that e.g.\n(module (func $type-return-num-vs-enpty (return (i32.const 0))))\nis, in stack machine language:\n(func\ni32.const 0\nreturn\n)\nPreviously the return was encoded by binaryen with arity 1, and parsed with arity 1 which consumed the const. Now the return is inferred as arity 0 (because the function is void), and the const is left on the stack after parsing.\n. One of these days I'll remember to do it along with the binary format updates.\n. split.wast is generated by check.py as part of some tests (e.g. binary round-trip testing); because wast files can contain more than one wasm module, the script splits one of them out into its own file. (See the details in check.py).\n. Also, if the binary search or something else from <algorithm> is suitable here it's almost certainly better than writing something by hand. Even if it's slightly less optimized, it's a big win for maintainability; so it IMO would probably take a significant performance advantage to justify duplicating something from the standard library.\n. OK I rebased this on top of #750 and updated the tests.\n. There is a test in https://github.com/WebAssembly/spec/blob/binary-0xc/ml-proto/test/import-after-memory.fail.wast\n. (Otherwise lgtm)\n. If we want to make binaryen's type semantics/rules different from wasm proper, then we should probably implement a strict wasm type checker and run it at whatever point we convert for output. Of course there are also still wasm-only tools in wabt; I believe wabt's type checker is strict (and if not then we should make it that way).\n. Setting the build type to Debug or Release should work as before; now you an also use other types like RelWithDebInfo.\n. Wouldn't it be more conventional to just use CMake install targets instead? IIRC In some cases CMake actually does useful things when it installs (e.g. rewriting rpaths), so we probably should prefer that to just copying the build directory when we make distribution packages.\n. Hm. I do still think we want to have a working install step, but I agree that it's nice to also be able to use the build products in place for testing. So maybe we can just do both.\n. Also (and this is beyond the scope of this particular PR) but binaryen.js and wasm.js aren't really scripts we expect users to run directly, right? They just get packaged into larger things generated by emscripten or other packaging, so it probably doesn't make sense to have them in the bin directory in the installed location (especially if there's going to be a distro-style packaging). Maybe <prefix>/lib or <prefix>/share? Not sure.\n. Yeah, for this PR it's fine. I'm just saying I think we should move them in the future, and update the references.\n. I think the file format only calls for \\n and not \\r\\n (the only useful reference I've seen is https://en.wikipedia.org/wiki/Ar_(Unix)) but in general I would think that the format of archive files should be the same on all OSes, just as the format for executables and object files is the same (both LLVM object files now, and wasm objects in the future). So maybe we should try to prevent archive files from getting created in text mode instead. Right now as far as I know the only source of archives that are actually fed to this code is create_wasm_compiler_rt() in emscripten's tools/system_libs.py which just calls llvm-ar to create the archive. Are you finding that that results in archives with \\r\\n or did you create one manually?\n. All of the inputs should be GNU-style archive files, which should not be considered as text files, even though they happen to contain ASCII text :). So I guess the problem is that git is converting them on checkout because it thinks they are text. I think there's a way to get git to consider them as binary and not convert them.\n. If you add a .gitattributes file with the following content, does that help?\n*.a -text\n. LGTM, thanks!\n. This was always a waiting time bomb; I'm guessing he did a build with MSVS which just happened to initialize or lay out or allocate its classes differently, and just happened to get junk instead of a null pointer.\n. Yeah, I was just about to lament the fact that for msan to work with C++, you need an msan-built version of the C++ stdlib, which we don't have in our package.\n. I have seen random timeouts on Travis before :(\n. Hm, maybe the travis thing is real :( let me try it locally.\n. Was just about to say, I did that for tables and thought \"hey I should make the memory code the same even if the JS engines apparently don't care\".\n. Yeah it makes sense; V8 and the other tools should probably do that too. I haven't tried with WABT, maybe @binji knows.\n. The error running the tests looks unrelated to the change. That missing script comes from the waterfall piece that is supposed to get downloaded by check.py. Maybe that didn't work for you? What happens if you run check.py with --only-prepare first? (IIRC that's supposed to do the setup without running the tests).\n. What happens if you remove the test/local_revision file and then try?\nOn Thu, Oct 13, 2016 at 9:53 AM Benjamin Bouvier notifications@github.com\nwrote:\n\nI've tried check.py --only-prepare and then re-running with no more\nsuccess. Continuous integration is happy, though :)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/773#issuecomment-253572108,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKB0fBZbiSOwJUEg4cluw9cRdtMUFks5qzmIjgaJpZM4KWElV\n.\n. Oh, I forgot; test/waterfall is actually a git submodule and not part of\nthe waterfall build. So you probably just need to run git submodule update\n--init to get the submodules checked out.\n\nOn Thu, Oct 13, 2016 at 10:11 AM Benjamin Bouvier notifications@github.com\nwrote:\n\nNot better:\n$ ./check.py\n(downloading waterfall 11453: https://storage.googleapis.com/wasm-llvm/builds/linux/11453/wasm-binaries-11453.tbz2)\n(unpacking)\n(noting local revision)\ntrying waterfall clang at /code/binaryen/test/wasm-install/wasm-install/bin/clang\n[... tests execute ...]\n[ checking torture testcases... ]\nTraceback (most recent call last):\n  File \"./check.py\", line 558, in \n    import test.waterfall.src.link_assembly_files as link_assembly_files\nImportError: No module named waterfall.src.link_assembly_files\nThe test/waterfall directory is actually empty.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/773#issuecomment-253576872,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKCf_3-Hl8wjNxZ0i1xSIuT-X15W5ks5qzmZDgaJpZM4KWElV\n.\n. One thing valgrind does do is catch uses of uninitialized values, which\nASan does not. MSan does, but you have to have the C++ stdlib built with\nMSan too, which makes it harder.\nValgrind is a lot slower but in general easier. So as long as the support\nisn't too onerous I'm happy to have it.\n\nOn Mon, Oct 17, 2016 at 6:27 PM Alon Zakai notifications@github.com wrote:\nThanks, interesting.\nWe have AddressSanitizer coverage on travis, so it doesn't seem high\npriority to get valgrind up, but it might be useful. In particular it could\nbe useful to run locally when an issue seems like the kind valgrind can\ncatch.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/785#issuecomment-254381391,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKKGjMvH2LvLk-_ptWTphtT61Dkjjks5q1CBlgaJpZM4KY9IH\n.\n. Cool. by the way is the emscripten waterfall down, or has the URL changed or something?\n. Never mind, I had the old waterfall page bookmarked, and the upgrade changed the latter part of the URL. Looks good!\n. This is related to the discussion in #765 and https://github.com/kripken/emscripten/pull/4623.\n(I think) it reflects the current status quo, so we can iterate from here.\n. @kripken any objections to landing this? It shouldn't be controversial as it doesn't change anything about the way anything is built or installed, it just updates the install targets to include everything we actually use.\n. Probably should wait to merge until the rest of the repos.\n. It expects version 0xc of course\ud83d\ude01\nOn Tue, Oct 25, 2016, 4:09 PM Alon Zakai notifications@github.com wrote:\n\nWhat is the issue with binary.wast?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/803#issuecomment-256205375,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKJKmITwwxTqPIJY40IX5MfQ56_ajks5q3oxCgaJpZM4KfcM6\n.\n. Right, the problem with that is that is what I mentioned in the commit log; namely that the wast parser doesn't support the new syntax for the import tests, (register \"test\"). So I decided I'd rather disable the trivial binary test than the nontrivial import test.\n. https://github.com/WebAssembly/spec/blob/binary-0xd/interpreter/test/imports.wast#L18\n. Oh sorry, I read \"not on the new branch\" rather than \"not new on the branch\".\nSo I think the issue is that binaryen has the testsuite mirror repo as a submodule, and it is out of date. I added a binary-0xd branch to that, but it also includes the new syntax.\n. Yeah; I just commented on the v8 0xd patch (which just landed) and synced with Ben and the rest of the toolchain folks, and I think everything is ready. I've tested binaryen and wabt against v8, and AFAIK 0xd has landed in firefox too, so I'm going to go ahead and merge this.\n. I expect it's mostly just that asm2wasm has had a lot more optimization\neffort put into it than upstream LLVM  wasm backend has. s2wasm doesn't run\nany optimizations itself. You could try running wasm-opt over the output\nfrom s2wasm (it's a wasm->wasm optmizer that does the same optimizations\nthat asm2wasm uses).\n\nOn Wed, Mar 1, 2017 at 4:12 PM L. Krause notifications@github.com wrote:\n\nRebuilt LLVM with those commits and the build finishes successfully again.\nWhen running, I'm now getting an undefined reference error for\nasm[\"setTempRet0\"] in the generated .js file, in the definition of function\n_saveSetjmp. Changing the call to Module.asm[\"setTempRet0\"] gets rid of\nthe error.\nWith that change, I get a failing assertion assert(offset_high === 0) in\nsyscall140 (llseek) from here:\nhttps://github.com/kripken/emscripten/blob/04255b4ada1983301cb35cafbc5483db036149fe/src/library_syscall.js#L663\nIf I comment that assert out, the game starts and runs. That's great,\nthanks for the help so far!\nI notice the size of the binary generated by asm2wasm (~14.3MiB) is\nsmaller than that generated by s2wasm (~15.4MiB), how comes?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/824#issuecomment-283514196,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKNiEcNGB94fcppqDm7az7z5IVOZgks5rhglVgaJpZM4KqYQ8\n.\n. There are a lot of places in binaryen where we have abort() where it really should result in exit(-1) or something like that instead. abort() and assertion failures do (and are intended to) behave more like crashes, things that only happen if there is a bug in the program. For example, bad input should never call abort, it should just print an error message and exit (e.g. Binaryen has Fatal for this https://github.com/WebAssembly/binaryen/blob/master/src/support/utilities.h#L62). That would leave just a few places where there are real asserts or aborts, and those can be silent if we want.\n. Debug info is something we don't really have good support for (or really, any support for) in s2wasm right now. Currently we are focusing on making proper use of LLVM's MC infrastructure (e.g. https://reviews.llvm.org/D26722) along with wasm binary format support in LLVM. That will be the useful base on which we can build debug info support. There is a ways to go before we have something useful (ultimately we want to provide primitives which will make it possible to implement debuggers for any language in JS or wasm), although we may end up supporting something like source maps in the interim.. Yeah, I think we should.. Oh, sorry I missed this while I was out. This LGTM.. Can we split out the break-to-return and global stuff from the stacky-code stuff? They seem unrelated, and the stacky-code seems like it should get its own PR with a noticeable title, at least.. I thought we already had an implicit block on the function? so does that mean we create another (explicit) one for this case? Is there some way we can break to that instead?. Sure, go ahead.. It might be worth considering adding new IR node like first/reverse-block to avoid having to introduce locals in the future. If stacky code becomes common among binaryen's producers, or if we want to optimize code produced by stack-aware producers, then we'd probably be pessimizing just by parsing their code.. It's certainly true that pick with local constants (I guess those are essentially just SSA values) would handle the case of void expressions like the example you mentioned. However I would be hesitant to design Binaryen's IR around it without more consensus about whether and when it would be added to wasm. We still have to primarily target wasm as it exists today and in the near future.\n\nTo adopt any IR construct we'd want to have the design goals of ensuring that it can naturally express everything expressible in wasm, and also be useful for optimizations, so that we can avoid regressing code parsed from wasm that uses those constructs, and produce them whenever it would be a performance or size win.\nIt's not my current goal to use Binaryen to motivate changes in wasm, although I do think it could be a useful platform to do that. If someone were to come up with something that met the aforementioned criteria (which basically mean it would be useful for producers), and showed some useful improvement in performance/size of real programs (or the addition of some new capability) and additionally wasn't to onerous for consumers to implement, then that really would be a compelling and useful argument for adding it to wasm.. Oh, I forgot that block->list isn't a std::vector, it probably doesn't have the right iterator traits that the standard container types have. So yeah it may not be worth doing that just for this.. actually can you do typedef typename T value_type instead?. C++ UB for the win: https://www.youtube.com/watch?v=aRq1Ksh-32g. By \"IR\" do you mean LLVM IR? If so, then they would use the LLVM WebAssembly backend. Currently it converts LLVM IR into a text .s file, which Binaryen's s2wasm tool can convert to wast.. It's not so much a rationale as a limitation. We were working on bringing up the LLVM backend before the wasm binary format was finalized, and also it's much easier to make LLVM emit something that looks like assembly that something that looks like the wast text format, especially as it was when we started. Now that the binary format is mostly settled, we are working on adding binary format support to LLVM, which will eliminate the need for a text format (although one will continue to exist, since it's useful for various things like testing).. I have no problem with this for now; DCE is simple and cheap. I do think it would be an interesting exercise to try to avoid generating the structurally-unreachable code in the first place without relying on powerful IR. I have a feeling it might not be too bad and would likely be worth doing, and would also avoid the need for an O0 which produces invalid code (and in the event that we decide that it is valid, we can just back this change out anyway).. The other option, if we really do want to have all the code in the binary for debugging, would just be to wrap the br in a block by itself.. I don't think I really like the idea of letting the suffix always determine the file type; I think it will just lead to user surprise if the tools don't behave the same way given the same flags. I think the tools should default to writing binary (except wasm-dis of course) and have a flag (-S?) to control the output type. For reading we could just always sniff for binary and fall back to text (although that might lead to problematic error messages if the fiile is neither). That would mean that the generic write method could take a flag to specify the type, or just expose 2 different methods.\n@sunfishcode you mentioned you were looking at the s2wasm-alike that would read binary object files but that the read/write abstraction wasn't right; Is this what you wanted?. I don't know of any toolchain-y tool that changes its output format based on filename (as soon as I say that, I'm sure someone will prove me wrong....). Some change their input behavior (e.g. clang/gcc if not overriden by a flag) but in our case the formats are different enough that sniffing should be no problem.. Sure; just run wasm-opt over a large input, or do you have a better benchmark?. Biggest wasm I have handy is poppler (are any of the emscripten benchmarks or other tests bigger than ~2M)? and any differences seem in the noise on my machine.. No, this branch should be ready to go now.. Yeah the validator should definitely match whatever the spec and/or browsers do. I think validation is pretty ad-hoc right now because of the history of the IR (and the ways it differs now from wasm?). Anyway for now we can just fix this.. Responding in order of original comments:\nFirst, (and to @kripken's question about reifying and @jgravelle-google's suggested transform) I guess we should be a little more precise with what that means, because I think it's actually 2 things. One is an IR->IR transformation, changing the type of a node with unreachable type to another type (I'll call that a \"reifying transform\") and the other is what type you write when you convert to wasm (I'll just call that \"lowering\"). Reifying during lowering is obviously a requirement to generate valid wasm block signatures. But with respect to the IR itself, the original post left an open question: \"must nodes which are in fact unreachable have unreachable type?\" Which I think is equivalent to \"are reifying transforms always/ever valid?\", and \"can/must unreachable operands 'bubble up' to to their parent?\"\n@sunfishcode (i32.add (f32.const 0) (br 0))) is valid in the spec interpreter (assuming the br targets a void block) even though the f32.const is reachable, because the stack is polymorphic after the br. However  (i32.add (br 0)(f32.const 0) ) is invalid because the f32 goes on the stack after the branch. (edit: just as @binji and @jgravelle-google said in the followup comments). Rule 3b was originally written such that any unreachable operand made its parent valid but this is an example of why that shouldn't be. So we could define the validation rule for binary operators to reflect wasm's order dependency in case of unreachable code, or we could keep it symmetric (i.e. i32.add is invalid in binaryen if either of its operators is the wrong type).\nre: @kripken's second question: yes, my proposal is your (1): when lowering, emit a proper wasm type based on the outside context. We still want to have validation rules which are defined entirely in terms of Binaryen AST; hence the 2 options I just mentioned for binary operators. Both possibilities allow straightforward lowering to wasm, I guess it's just a question of whether an asymmetric validation rule makes optimizations more difficult. I suppose you could just model it the way you model other side effects when deciding if a transformation like commuting operands is valid, so maybe it's not so bad.\nAdding unreachable and dropping dead code sounds like a good optimization but I'm not sure we want to require that for emitting wasm, and I think it would be nice if we didn't have to add extra instructions.\nI think if as in @jgravelle-google's example might be a special case, need to think about that.. @wllang my understanding is that your last example is valid because the polymorphic stack supplies (any number of) whatever types are needed. I'm not sure I'd want AST with default arguments though; I haven't really thought through the consequences of that but it seems like it would be surprising. WRT if, that sounds about right. It feeds into @jgravelle-google's earlier example: if you modeled the arms of the if as implicit blocks then an optimization which eliminated unreachable blocks with no side effects could also be applied to if (e.g. in that example you could invert the condition and remove the unreachable block).\n@kripken WRT symmetry: obviously symmetry would make some optimizations simpler, but it could leave performance on the table by defeating other optimizations; e.g. if we have (i32.add (block i32 (A)) (block i32 (B))) and some optimization renders the tail of  block B unreachable (perhaps by turning br_if into br). If A has no side effects we can change A to anything or remove the add entirely. However suppose A does have side effects; say it's ((drop (call $foo [returns f32])) (get_local $bar [returns i32])). If the add is valid no matter what, we can remove the get_local and we don't care that the type is wrong. But if we have symmetry then the type of the block has to stay i32 and we have to leave the get_local (or replace it with unreachable). Maybe that's a contrived example but it illustrates some of the tradeoffs.\nWRT finding the right type during lowering for unreachable blocks: Every block is in some context, and has some parent. I think the type should be unambiguous in most cases (e.g. binops, conversions, etc). Possible exceptions might be cases like if or select where the types just have to match (if the type of the other operand is also unreachable, they could both be void), or if the parent is a block (then it would depend on the validation rules for blocks).\nSpeaking of validation for blocks, IIRC we currently require dropping results of all operands in the list except for the last, correct? In that case it would always be clear what the required type is. If we allowed blocks to be a little more stacky (e.g. any one operand could be left instead of just the last) then we would have to scan the block for non-unreachable operands before assigning a type for unreachable operands, but it seems like it would still be tractable.\nWrt round-tripping (or just plain creating binaryen IR from wasm): not sure, it kind of ties in to whether we require blocks whose end is unreachable to have unreachable type. If so, then during wasm parsing it seems like we'd need to propagate unreachables outward through the scopes when we find an unreachable node (and likewise during optimizations that create unreachable nodes). In that case I think we'd end up with the same IR whether the extra unreachable node was present or not?. > Wrt finding the right type during lowering for unreachable blocks: Yeah, its those cases like if etc. that worry me. It's not enough to just look up the stack, in general, you may need to look up, reach an if, then go down into the ifs other arm, and so forth.\nI think for if you don't. If both arms of an if or select are unreachable, then the if is void. If one is unreachable, then its type is the type of the reachable arm. But in that case you wouldn't be inferring the if's type, the type of the if would be i32 already. To find the type of an unreachable block which is the arm of an if you just look at the type of the if containing it, just like any other construct.\nThat leaves the more interesting case of parametric operators, select and drop. If you have (drop (block U (... (br 1) )) then there is no single requirement for the type of the block except it can't be void. I guess in that case for lowering to wasm you'd just pick i32 arbitrarily, or you could omit the drop and use void. You'd of course also want an optimization to remove the drop but that should be orthogonal.\nselect is also a little more interesting because it's parametric too and doesn't have a type signature in wasm, so you wouldn't need to infer it to lower it; but it would have a type in Binaryen. You could have (select (br) (br)(condition)) or (select (br) (block i32 (i32.const 0)) (condition)) (select (i32.const) (br)(condition)), which would all be valid wasm. If you had (select (br 1) (block U (br 2)) (condition)) or (select (i32.const 0) (block U (br 2)) (condition)) then how would you pick the type to lower the block? You'd want to pick the type based on the type of the select in the IR. I would think it would have type unreachable in the first case and i32 in the second case. In the first case you could go up another level and infer the select from its context.\nThinking more about blocks: could say a block has type unreachable if any of its elements is unreachable, and if no br targets it (regardless of its last element). An example would be (block (br 1) (i32.const 0))\nIn that case we might (or might not) need to add an unreachable element at the end. (I think this is independent of reifying though); i.e. for lowering you'd pick a type based on the context, and then if the type was not void and the last element was not void or unreachable, you'd add an unreachable or drop at the end to make it valid wasm. I don't think you'd need to add anything after the block. To do a reifying transformation you could infer a type from context and leave the contents of the block alone.\nThe alternative would be to say that a block is unreachable if no br targets it and its last element is unreachable. Then (block (br 1)(i32.const 0)) would have type i32. Not sure if there's a reason to prefer either of those options but the first seems more flexible?\nIt kind of ties into the question of whether blocks or other elements which could have type unreachable must have that type. I think it could work either way for emitting wasm; for creating binaryen IR from wasm and for transformations, it would be a bit of extra work to potentially fix up the type of a node that is created or made unreachable by a transformation, but it sounds like that might be a property we want for round-tripping anyway.. If we can get away with disabling just one spec test instead of all of them, let's definitely do that.. This LGTM to fix the various brokenness. We shouldn't call #903 resolved yet though.. V8 is supposed to accept 0x1 binaries: https://chromium.googlesource.com/v8/v8/+/fa7d1f8f75e340d917831ef74f401154b0a90cc7 does it not work for you?. There is one potential hiccup: jsc probably does not. But we want binaryen to work for the browsers that have preview releases that support wasm today, so I think 0x1 is the right thing. I'd like to have jsc work on the waterfall but we can always hack the binary or convert with some other tool or whatever, since the actual binary is the same.. oh i think that patch has not been merged to the browser yet. i think that's what ben is waiting on. anyway this LGTM. @wllang \nDisclaimer: This is my personal belief/opinion and I'm not a lawyer and I do not (or you, for that matter) represent the CG nor the W3C. I also do not officially speak for the Binaryen project.\nI don't believe Binaryen is technically a product of the wasm CG. For example the description given of CGs (cf https://www.w3.org/community/about/) is that a CG is for discussion and optionally publishing ideas or specs or (if specified in the misson) even producing code or tests, but for wasm specifically, code and tools seem outside the scope of the CG's stated mission.\nThis position makes sense to me for 2 reasons. \nFirst, my primary goal for binaryen (and wabt and LLVM which notably is definitely not affiliated with or covered by the CG) is that it be useful for people who want to build software for the web. This means (for example) that a primary goal and constraint is that the code we produce be accepted by the environments that people want to use and target; namely, web browsers (but also in the future, environments such as node.js and other possible non-JS embeddings of wasm). If we don't do that, then we are just a research project.  By the way, there's nothing wrong with research projects. I would be willing to consider contributions to Binaryen (or wabt or LLVM) that are meant for experimentation if they don't prevent us from serving our other users. But serving those users who just want to build code for wasm and the web is my primary goal. My goals and priorities might not be exactly the same as someone else's, and where there are differences, then we should discuss, persuade, negotiate, and advocate for the users and use cases that we care about. I would love to engage in any of those activities (but issuing ultimatums is not negotiating).\nSecondly, in some hypothetical future world where wasm is spec'd and shipped, and the browser vendors are no longer devoting resources to adding features, it's entirely possible that the CG will be closed, but that we or someone will still want to maintain and develop Binaryen and other tools. In other words, Binaryen could outlive the CG.\nMy conclusion is that I want Binaryen to be an open-source software product that serves its users (regardless of what happens on Github discussions) and also its bug tracker to be a place where everyone who cares feels like they can participate in a constructive way.. BTW I'm also happy to have \"influence the CG discussion and/or wasm standardization process\" be one of the goals and/or outcomes of Binaryen (hence my willingness to negotiate on goals and patches). But I fail to see what an attempt to explicitly disassociate ourselves from the CG would accomplish in that regard. \nBut in general we have to put our users first. You seem to be concerned that emitting binary format \"0x1\" would mislead users into thinking that the CG has published wasm. I don't think our users care about the CG's opinion of wasm. They also do not care that (for example) webkit-prefixed CSS properties are discouraged by the standard. They do not care about the purity of the wasm language, or the design process, or what we like to argue about on github, or version numbers. They only care about what helps them serve their users. Practically speaking, if we do not do this, nobody will be able to use Binaryen, and I care about that. \nTo the extent that Binaryen is part of the product of CG (and again, maybe it totally is) its purpose can still be different than the purpose of the design or spec parts of the CG. I want this space to be somewhere we worry about how to serve our users' purposes, not about sending messages to the web community. To the extent that we (the developers of Binaryen) are browser vendors or have conflicts or differences in priorities, I would hope we can resolve those in a friendly way, and thus far I believe we have, in a way that helps everyone. Alon may test most with SpiderMoneky, but he reports V8 bug as he finds them; I test mostly with V8 but I'm helping bring up JSC support on the build waterfall. In Binaryen I've focused most on support for the upstream LLVM backend and Alon has done more work with asm2wasm and optimizations. But somehow we manage to get along without arguments and threats.. > I am a user, and I am concerned about getting a good outcome.\nYou have made this concern perfectly clear in discussion on the other wasm projects. Not everyone is going to have the same priorities as you are, and the same idea of what a \"good outcome\" is, and the same opinion of what the tradeoffs are, and not everyone will pay the same cost for those tradeoffs.\n\nI hope there are a good number of CG members who are users very interested in meeting use cases including performance. I am a user, I am here.\n\nYou are not the only user. I am willing to lend some support your use case, but I'm not willing to compromise everyone else's use case to get it (e.g. by making Binaryen incompatible with the browsers many users want to use).\n\nThis is all about a subgroup attempting to ram through a release\n\nNot for me, it isn't. For me, \"this\" was your post demanding changes to Binaryen, with some vague threat of expulsion from a group which you do not control, whose purpose is not even particularly well-defined.  \n\nSo if CG members try to defend a good working environment\n\nDefending a good working environment is exactly what I'm trying to do here. \n\nI will give them a private vote, they do not need to support me, but I will at lease give them the respect of a vote and I will put the technical case to them and discuss it with them.\n\nYou are encouraged to discuss whatever you want with CG members, and take as many votes as you like. In fact, persuading others to come out in support of your ideas sounds like an excellent way to move those ideas forward in discussion and implementation.\n\nIf you fail to correct this within 24 hours a vote to take harsh action and expel the binaryen project will go to the members. If there are web browser vendors promoting or spreading misinformation then they also have 24 hours to disassociate from the CG and to stop using the CG branding. This is your first and final warning.\n...\nslur their character as being argumentative and threatening? Well shame on you.\n\nI don't know what else to say. I stand by my interpretation of this post as argumentative and threatening. I refuse to be ashamed of asking anyone not to be argumentative and threatening. I am sorry if a subgroup of the wasm CG has not respected your opinions, or implemented your ideas. I am sorry if you feel anyone has treated you with contempt. I don't want anyone to feel disrespected or threatened, and all I am trying to do is keep this part of the working environment (to the extent that I have influence over it) as friendly as possible. \nI humbly suggest that your approach is not likely to be very effective in achieving your ends, but I demand that you act respectfully and professionally, even (especially) if you believe that others have not so acted toward you.\n. Agreed this makes it more consistent with the general pattern in the IR of referring to everything by name.. Yeah, our review process has mostly been ad-hoc for Binaryen, but please do feel free to explicitly request reviews on anything you want.. It was originally a hack around the fact that you couldn't put a Name in an unordered map because it didn't have the right hash overload. Somone fixed that but we (I) didn't get around to going back and fixing all of the places that should be Names now.. https://www.cs.tut.fi/~jkorpela/chars/spaces.html :grin: . I'm on board with this general idea too. A few comments, and questions to make sure I understand right:\n1. It looks like this mode applies to both float->int and div/rem (I'm happy with that, although if there were some good reason to have separate flags/modes, I'd be ok with that in this tool too since it's not an emscripten-user-facing tool).\n2. As a nit, names like potentialTrapMode/potentiallyTrappingFoo seem unnecessarily verbose; I think the \"potential\" part goes without saying (we already have an op that always traps :) ) trappingOpMode (or even just trapMode) and trappingDiv/trappingConversion etc seem more readable.\nbut yeah in general this looks good to me too.. Actually also just so I understand. It looks like the clamp and JS mode for div/rem do the same thing now? Just return 0?. Actually I think makeTrapping* is accurate. Just because something is \"trapping\" doesn't mean it necessarily always traps, just that it may trap. . I think we should just support the extensible name section. Speaking of which, do we have any tests that we drop bogus name sections? we should.. V8 just landed a patch to update to extensible names section and I tested this patch against it. All of the aforementioned tests are passing, so I think this change can go in whenever we are ready.\nAs for when we are ready: basically, those tests break when binaryen doesn't match the JS engine. Since V8 is already updated and SM is presumably not, the right time to land it is presumably any time between now and when SM updates what it accepts. (at which point our waterfall with V8 will go green and those tests will cover this change, and the waterfall with SM will go red until it updates). Since it looks like the main emscripten buildbot is currently broken (and therefore we don't have SM test coverage right now anyway), I'd vote for just merging this without waiting.. OK, our bots are able to cover this again, so hearing no objections I'm going to go ahead and merge it.. This sort of capability is pretty much the sort of thing we've been thinking about defining along with the linking work.\nAt a high level, we want a way to define: \n What functions are exported when a module is linked (this would probably include some C++ syntax and a linker capability; see also #585)\n What the \"module name\" of a linked module is. This would at least include a JS capability because you explicitly provide this mapping from import module name to module when you instantiate a wasm module. But it might also include some sort of metadata on the module, so the JS loader code knows what the module thinks its name is\n* How undefined functions are handled when linking, and what module name imported functions have after linking. This would also include both C++ syntax and linker capability, and is what you are talking about here.\nObviously how this is designed depends on the overall static and dynamic linking scheme is expected to work. We've been working on the linking bits in https://github.com/WebAssembly/tool-conventions/blob/master/Linking.md and in the LLVM/binaryen/wabt code and haven't gotten as far as the C++ syntax yet but \n1. we are getting close enough now that it's probably worth bringing it up again and\n2. it makes sense to have the syntax also work as an \"escape hatch\" to operate outside that system. Because it totally makes sense to say \"I just want to provide some JS module and function and make it work myself\", which is kind of what I think you are talking about here. Also emscripten's various wasm<->JS binding mechanisms would presumably build on this primitive too.. oh and along with 2 above, I think the syntax you propose here is pretty much along the lines of what we've  been thinking about too.. Yeah I agree that linker module detection would be the expected way for things to work, but I also think it would be useful to have the \"escape hatch\" to allow the user (or some source-level framework) to specify how particular symbols are imported.. There is a distinction between the constituent libs (libasmjs.a, libsupport.a etc) and libbinaryen.{a,so}. I think the former are really more implementation/factoring details, and the latter should be what are actually exported/installed from the build. I think the intent of libbinaryen.so is that it be freestanding (with no dependence on the static libs) and libbinaryen.a should be also. Also I think we should probably just build and install both of them with an INSTALL step, and none of the intermediate libraries.. Yeah; unfortunately the CMake on Travis is ancient and doesn't support \"OBJECT\".. Thanks for the contribution!\n1) Can you please join the WebAssembly Community Group (https://www.w3.org/community/webassembly/, see also https://github.com/WebAssembly/design/blob/master/Contributing.md )\n2) Does gcc really issue warnings based on the location of comments?!  didn't know that.. Merged, thanks!. IIRC The JS files in src/js are just for building binaryen.js and probably don't even need to be installed. Not sure about binaryen.idl though. But if it does need to be installed, share/binaryen seems about right.. Yay, I :heart: dynamic analysis tools :)\nAlso when adding instrumentation we should make sure we should support putting the instrumentation in early and then optimizing the result; that's a big part of the advantage of compiler-based dynamic analysis.. I think the concern is that if you replace loads and stores with the calls, then the called function must also actually perform the load or store. Whereas if you just made it in addition to the load or store, then you wouldn't have to rely on the user code being correct.\nwrt inserting instrumentation early, I really just mean that in general we can instrument before optimization, thus exposing any instrumentation code to the existing optimizers, which can reduce the instrumentation cost. I think in this particular case with just the one extra call instruction, there won't really be much if any optimization opportunity because obviously we don't want to actually eliminate the calls (and that would be unsound if an optimization were to do that). But if an instrumentation pass inserts more computation (e.g. like ASan does) then optimizations like CSE might apply.. I looked into this the other day. It's not limited to just Binaryen; all of the Github services for all of the wasm projects seem to be down (including Travis and IRC; but not including AppVeyor which is a webhook). So presumably the problem is GH and not Travis. Previously the travis service had JF's token and I tried switching it to mine just to see if it would do something, but it didn't. So at this point I have no idea what's going on. I even tried adding the IRC service experimentally to one of my own repos, but that didn't work either. But all the GH status pages I can find say everything is working. So... dunno, that's as far as I got.. Surely it shouldn't be too hard to include the SSE flags conditionally on the target architecture though.. Might be worth trying a run of the waterfall script/torture tests with the pass enabled.. No, I'm not sure we'll never want other annotations. But I do know we want a more explicit representation of debug info, and that we don't currently want other annotations. So if we want more in the future we can always just add back the annotations mechanism.. But flake8 is happy now (I assume that's what was failing before), and this PR seems to fix that, so it can just land, right?. Yeah, definitely agreed.. LGTM, and looking green :). I'm curious what makes it impractical in LLVM? I could imagine there'd be a fair number cases that you'd have to bail out on (e.g. certain LLVM instructions, attributes, etc) but for simple constructors?. I don't think the code actually has UB. The C ternary operator is short-circuiting, so the conversion to unsigned only gets executed if the operand is > 10000. The 'as-if' rule allows the optimizer to modify the CFG and execute it unconditionally only if the operation has no side effects. I'm guessing that this operation has no side effects on the JS target and other architectures (and is therefore safe), but it does have side effects on wasm, and it's therefore not a valid transformation for the compiler to make.. IIUC the UB in question is converting a float to an unsigned int when the value is negative. Emitting the plain wasm instructions to implement this conversion is always fine, because we are allowed to trap when the source program does that. But the source program does not do that. It executes the conversion conditionally. What's not fine is removing the condition.\nSo I haven't looked at what CFGSimplify or whatever pass does exactly yet, but it must have some way of knowing which actions are side-effecting and which are not (e.g. it wouldn't remove conditions from calls). So if there's some target hook to specify that, then we can hook into it, or if we are comfortable with a more general hack, we may have to do that. But since we haven't seen this with the wasm backend (have we?) I'm thinking there's probably some target-specific behavior we can implement.. Yeah I just looked at CFGSimplify and it doesn't look like it does this kind of thing. Are you sure that's the pass that's doing it?. OK, I checked and it is SimplifyCFG that does this, and we just don't happen to run it in the wasm backend. But if you run SimplifyCFG on the wasm triple, you get the same behavior. So this is the same problem  either way.. I don't think we need to export the start function; as @jfbastien said, it's called automatically. Currently static initializers are very special in emscripten, and it has custom JS glue call them. In https://github.com/kripken/emscripten/issues/4218 I proposed that we switch to something more like what JF said (static initializers are called from the start function). One issue with that is that IIRC emscripten wants to do some kind of work in JS after instantiation but before the initializers run (although I think that's no longer necessary now that we can separately instantiate memory). Although in the discussion in the 4218 we also disagreed on the desirability of moving the constructor calling from JS to wasm.. BTW this patch looks fine but you need to update the test in test/dot_s/start_main0.s (see also the travis CI result). cc @jgravelle-google and @kripken in case I don't get to it.. @kripken as specified in the threading proposal https://github.com/WebAssembly/threads. Specifically https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md. Yes, we definitely need followup work. I probably should have said more about my current plan in a bug or something. But anyway, yeah this is definitely the beginning of adding atomic/shared mem support.\nThis PR (and the upcoming ones to add atomicrmw/cmpxchg etc) focus on getting the instructions in, and round-tripping via text and binary format. Then we definitely need to look at optimizations and such. Certainly many optimizations will need to treat atomic loads/stores differently, and atomicrmw and friends will be completely different IR instructions. Concurrently we can add asm2wasm/s2wasm support to actually use them.. Future PRs will add the visitors, including validation, optimizations, etc.. I figured \"end\" was consistent with C++ iterator ends and other general c-style bounds where the end is one-past-the-end.. FWIW I changed it because the bounds check as it was written before looked funny to me :). Currently there are no complete implementations of wasm threads in any JS VMs that I know of, but work has started in V8 and probably others too.\nMy highest-priority goal is to support end-to-end compilation with emscripten ASAP to test with the VMs. But of course if we end up getting things working before the VMs are ready then we can still probably do some testing with the interpreter. And of course this also requires some work on the emscripten side. Fortunately there's already some pthreads support for asm.js there, so hopefully it won't be too huge.. Wasm support for threads depends on the webassembly threads proposal (tracked in https://github.com/WebAssembly/threads) and is not yet shipped by default in browsers. This page describes how to turn wasm thread support on in Chrome and Firefox. Although since then, both browsers have also turned SharedArrayBuffer off by default too, so you need to turn that on as well. For chrome you can change the command line to include --enable-features='WebAssembly SharedArrayBuffer'. Thanks @jayphelps (and @sbc100)! Since we've implemented all the features I'll just close this issue, and any new work will just be bugfixes and enhancements.. I enabled the similar \"rolling builds\" feature on AppVeyor too\nOn Wed, Jul 12, 2017 at 7:58 PM Alon Zakai notifications@github.com wrote:\n\nGood idea, thanks, I didn't know about that. Done.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/1089#issuecomment-314956555,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKA4XdTVsn_S8fZ_XyONF1aHCUC74ks5sNYfRgaJpZM4OWTjm\n.\n. Actually now that I think of it there might be some issues with the C++ stdlib on trusty, which we use on Travis. If we can work any possible Trusty issues out, then we can do this.. @kripken do you have any suggestions for another good way to test? In particular I want to check that e.g. atomic loads don't get reordered. So maybe suggest an optimization pass that might do that kind of of reordering in an easily-testable way?. Thanks I'll check that out. And yes, an atomic load can cross a regular load because atomics don't have specified ordering with respect to non-atomic operations.. As in, they do have specified ordering? (actually I don't see any mention of that either way in  https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md) Is there another source I should be looking at?. Yeah my initial approach here is just to take the position that no sane compiler would optimize atomics.. Unrelatedly to atomics, @kripken is there any good way to write more than one test module for a particular pass pipeline? The filename is just the pipeline specification, and you can't put more than one module in a wast file (even though it splits the modules out before running) because it doesn't compare the expected output per-module.\nIf not, I may try to add something to the file-name-as-pass-specifier scheme to allow for that.. It didn't work for me, maybe i'm holding it wrong. I'll look at duplicate function elimination. It's a different module because it has a shared memory (we can do the same test with shared and non-shared memory and compare both ways). Other than that quibble, this all looks straightforward and LGTM. Thanks!. But yes, this is what I had in mind, thanks.. Got it, thanks! I'm going to go ahead and merge this so I can rebase on top of it.. @kripken  Can you try this patch? does it behave badly for you? For me it seems to send MergeBlocks into an infinite loop, but it looks really benign. So I'm probably just missing something stupid.. Gah, i knew it would be something dumb like that. I guess that's pretty much exactly why Google's style conventions all prefer passing by pointer instead of using non-const references.. Closing this, I'll roll it into the atomic PR.. See also https://github.com/kripken/emscripten/issues/5498. Does this actually help anything? Can't optimizers, wast files, and clients of the Binaryen C interface create code that is just a problematic? Also, this means that wast files are no longer isomorphic or round-trippable with binary files, which seems bad. I know we have a split between wasm and Binaryen IR, but previously we still had the property that if you encode Binaryen IR to binary or wast and read it back, you'd get the same thing, which is no longer the case.. Actually wait, this PR has the wrong type for atomic.wait. The naming is also misleanding. I'm going to file an issue against the spec proposal before landing this.. OK, the types are now fixed. We can quibble with the spec later if we want but this PR should work as-is.. The pass is in https://github.com/llvm-mirror/llvm/blob/master/lib/Transforms/IPO/MergeFunctions.cpp and yeah it would be great to do this in LLVM. Also IIRC JF is on the hook to find a reviewer for your MergeFuncs changes :). Just for posterity, the details are that you specify the stack size with s2wasm's --allocate-stack flag, so the end of the stack space is .stack plus whatever you specify the stack size to be.. Oops, didn't actually mean to click 'approve'. But my suggestions are really behavior changes. So if you want to start with behavior identical to asm.js SAFE_HEAP and make changes from there, I think I'd be OK with that.. I don't think I have strong opinions on principle. Making the type of a block match the last element (and especially having the asymmetry with none vs concrete types) does seem more 'wacky' to me on the face of it than making the children of a block symmetric. But I think this decision should be driven by its consequences, especially 1) ease and simplicity/minimality of the conversion to/from wasm, and 2) ease of implementing and reasoning about optimization. (and if there is weirdness, it's a good property that the weirdness directly corresponds to weirdness in wasm itself). IMO You've made a strong enough case here about # 2, what is the impact on conversion to and from wasm?. Efficiency FTW. LGTM. In the past I've usually also updated test/revision to the same build number as where these files came from. IIRC last time I tried that it caused some complications though, so we can land this one separately.. My (pretty bleeding-edge, fairly recent SVN) build of clang doesn't enable -Wimplicit-fallthrough by default (even with -Wall); I don't get these errors unless I do that. Are you turning that flag on yourself, or is that a recent change in clang? Also my gcc (6.3) doesn't support that flag or warn about these, I guess that must be a recent addition to gcc too.\n\nSo IIUC, this just warns everytime there's any fallthrough between switch labels without an annotation? That pattern is pervasive in binaryen, and it will take a lot more than just these patches to silence that warning, assuming we even want to.. HI @JohnSully @nezumisama sorry I derailed this, I didn't quite understand the exact behavior of the warning. Anyway #1196 has landed with essentially the same patch, hopefully it works for you. I'm going to go ahead and close this.. This should be fixed with #1196 . OK, I think I understand better. In both cases you want an expression or list of expressions. In one case (function top level, explicit block, if arm), you need it to be targetable by a branch. In the other case, it must not be targetable because its container is the one that's targetable (loop). In both cases you want to just use a bare expression if there are in fact no branches that target it.\nGiven that, I have 2 questions:\n1. Why does the logic have to be duplicated rather than shared (and have a parameter or something)\n2. Why are if-arms in the first category instead of the second? i.e. instead of containing blocks with names, why aren't the arms targetable the way loops are? Maybe because the jump is forward instead of back?\n. ok. the code seems ok; really getList is really only for loops (everything else can be branched to) so maybe just say in the comment directly that it's for loops because its branch target is on the loop instead of the block. \nOr actually, even better: let's just put that logic directly in visitLoop, and then maybe getNextExpressionOrBlock or getBlockOrSingleton or something like that for getBlock. > but did you want to implement in interpreter as well?\nNot in this PR. I actually haven't implemented any of them in the interpreter yet, because my focus has been plumbing things through so we can test in engines. Although this one would be much simpler than the ones requiring shared memory.. The previous PR works, although it's kind of sad that the builds take 2 minutes even though they don't do anything.\nAlso: what do y'all think about a further refinement:\nPut the gcc6+alpine tests back, but make the gcc5+ubuntu bot build-only? That still reduces our overall testing time, while keeping our alpine/musl test coverage and or gcc5 build coverage.. > OMG, am I really the only one here who understand how Travis works and your Travis configuration\u2026?!\n\nYes, you probably are. I at least have zero experience with Travis beyond the 3 or so times I've modified Binaryen's Travis build.\nIf this were only my configuration I'd just run the whole thing on Chromium's faster infrastructure and not even bother with Travis. I'm doing it this way for the community.\n\n\nAnd BTW I\u2019ve reduced built time for ubuntu jobs significantly by disabling sudo (i.e. switching to container infra), but someone has changed it back\u2026\n\nSudo is still disabled (https://github.com/WebAssembly/binaryen/blob/master/.travis.yml#L1), and has been since the first time .travis.yml was checked in.\nSo, could you at least maybe call us incompetent on the basis of correct facts?. No worries; please do suggest something better for this PR though? I knew it was hacky but didn't see any obvious better ways from a brief perusal of the Travis docs.. Closing in favor of #1173. Cool; I added it in a couple of obvious places but definitely not everywhere, and it hasn't been tested on real code yet.. @binji Are there any notable differences between Atomics.* and their wasm equivalents that we should be aware of?. Is it really even necessary to deploy for every commit on master? Like, you're not making a package for every single commit in Alpine, are you? Maybe just the release tags ought to be enough. I'd also be totally fine making extra release tags on demand if you want to package a particular revision, too.. We've already established that what is obvious to you, is not obvious to those of us who don't do build and distro packaging as a primary activity. So if you will humor me here, I will refrain from pointing out the similarity of your hack in this PR to the one in mine.. But you are right that the Alpine builds do offer extra testing (in the form of non-x86 builds) that we don't have coverage for elsewhere. So building on the master branch seems OK to me in light of that.. Also, the delayed build may be related to https://www.traviscistatus.com/incidents/r0f4m54qp0tr. Interesting, this looks like just the kind of case that would be improved by the venerable opcode table idea or the https://github.com/WebAssembly/decompressor-prototype. Oh, yeah should be fine to merge, we can experiment with it on bigger benchmarks too.. These were just the ones that triggered the warning, because it only triggers if you actually delete an object of this class (see e.g. https://wasm-stat.us/builders/linux/builds/24075/steps/binaryen/logs/stdio). Most of these happen because we stick them in a unique_ptr. We can do a wider refactoring if we want, but also we'll get the warning going forward. Come to think of it we should try to turn it on on Travis too, it would be unfortunate if we had it on the waterfall but not Travis.. I don't know of any others. I've mostly been using \"IR\" in my own comments, it's probably good enough.. Hm, I actually don't think we should automatically have -march=native in here at all; even when not cross-compiling, you risk generating a binary that won't run on the deployed machine. It's something the user should be able to do (i.e. we should support adding extra cflags in the build), but not something we should do automatically. So to fix your issue specifically, I guess I'd prefer a PR that removes it entirely.. (We could replace it with something like -mfpu=neon which would enable NEON. That seems to have been the original intention, and should be safe, as practically every ARM chip that is likely to run wasm should have that.. Just the one nit, and then LGTM. @kripken do you have any objections or better ideas?. What I wanted from this particular change was to go from an essentially nondeterministic build (i.e. it depends on whatever the host machine has) to something that's at least reproduceable. If I remember correctly, ARMv7+NEON always uses FTZ for vectors, but I'm not sure about scalars, presumably it's the same. So it may not be compliant with wasm in that respect. I think vfpv4 would probably work. It would rule out Cortex-A9-class hardware which IIRC is very common, but realistically, because of the zoo of configurations, anyone doing an ARM build probably has to have a particular set of configurations in mind, and at least I don't have one. Perhaps @flackr or whoever added this code does?. actually vfpv3 supports denormals too, and it looks like vfpv4 just adds half-precision and FMA. It looks like if you use -mfpu=vfpv3 it assumes 32 D registers, and FPUs which also support NEON have that many. If we use -mfpu=vfpv3-d16 then it includes e.g. cortex-a9 cpus without NEON. I think pretty much everything these days supports NEON. That was almost the case when we decided several years ago that NaCl on ARM would require NEON support, so it should be pretty safe now.\nSo yeah in summary, let's make this -mfpu=vfpv3.. lol @z2oh sorry you hit a perfect storm of conflicting reviewers. This isn't the first time @kripken and I have clashed on exactly this bit of style :D. I think you won mostly just by virtue of having written a lot of code in that style before I did, so I didn't want to change it all :). Oh hey, the translate-to-fuzz test is failing becuase... yeah this actually does change the behavior. Before, we had multiple rolls of the RNG to continue and now it's just one. Since that was probably the intended behavior, should we just auto-update the tests?. That looks about right to me. It's just the one test that's affected, and it will be affected in a random way, so it's probably correct. I'd say go ahead and commit it, and if @kripken agrees with my assessment we'll merge.. When do you want to load but don't care about validation?. I think if trapModeFromString were directly in the top-level tool file such as s2wasm.cpp then it would be best to have it directly exit but otherwise not so great. I'm not a huge fan of an invalid state in a general-purpose enum like TrapMode but I like it better than, say, alternative kinds of returns in trapModeFromString (at least in the absence of helpers like std::optional or ErrorOr/Expected etc).. Actually maybe the best option is just to throw an exception. Since we already use exceptions in Binaryen, which I seem to always forget.. LGTM, will merge after (that part of) the CI passes.. Can we do something like \nstatic_assert(&SubType::visitFoo != &OverridenVisitor<SubType>::visitFoo, \"Derived class must implement visitFoo\");. We do run the emscripten testsuite (at least the test_core part) against upstream LLVM/s2wasm on our bot (see e.g. https://wasm-stat.us/builders/linux/builds/25522/steps/Execute%20emscripten%20testsuite%20%28emwasm%29/logs/stdio). But it doesn't look like that actually builds hello_libcxx, that seems odd.. I don't have any PRs in flight right now. @jgravelle-google ?. Heh, ok. I don't have a strong opinion on that, I'll change it back if that's what goes in the spec. Related (and to https://github.com/WebAssembly/threads/pull/76) I do also like the idea of adding \"atomic\" to wait and wake.. That's the right thing for a code generator to do, but this is the validator for Binaryen IR. I decided to mirror wasm itself in this case, since that seemed simpler. The other option would be to allow it in Binaryen and then convert to using the extend instruction when encoding wasm, but it seemed like not  enough of a convenience win to justify having Binaryen be different from wasm in this respect.. Yeah, think of the checked-in .s tests as \"unit\" tests for the .s parser, (and the waterfall .c->.s->.wast pipeline as an integration test). We have existing binary<->wast tests, and if we add another format, we'll have similar tests for it.. Ah you're right; I was mostly trying to resolve the backwards\nincompatibility that was causing waterfall breakage. Maybe I'll add the new\nfunctionality in a separate change.\nOn Fri, Nov 10, 2017, 7:22 PM Ben Smith notifications@github.com wrote:\n\nThis doesn't seem to support the inline format: (call_indirect (param\ni32) (result i32) ...) etc.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/1281#issuecomment-343636769,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABEiKDBPKdk6bruVTyIDd86Q1PDM_CqPks5s1RMCgaJpZM4QaTot\n.\n. @kripken Have our spec tests really not been updated since 2016? I was going to try to update them here but if it's been that long then it probably makes more sense to do that in a separate change because there will certainly be a lot of unrelated stuff. The script I ran to update the tests for this PR also updated our copy of the spec tests, so I could check that in for now to get the tools all compatible again. But we should probably do another pull from the spec repo to get all the new tests (and also of course we've made changes to the IR since then so it's probably worth revisiting anyway).. Since we do support a subset of the upstream text format, I think it makes sense to make this change, so that we continue to support the same subset (instead of just an outdated subset). And probably also to make the change that @binji mentioned, since that's probably a small change too. So I updated the spec tests to their new-format equivalent.. @jayphelps I do think we want to support exactly the use case that you describe: allowing Binaryen to emit object files that are linkable with lld (and ideally, compatible with LLVM-generated binaries). That means writing relocations. I also agree with @kripken that we don't want to implement a linker; we should just use lld and I think it also should be able to handle the use cases that the current wasm-merge tool does. I also think we might want to support running wasm-to-wasm transforms and optimizations (i.e. the opt tool) on wasm object files; that would mean reading the relocations, and possibly making the optimizer aware of any conventions that would affect the ability to optimize.. The current plan is to have LLVM output object files, which are linked by lld and then incorporated by emscripten directly. We are pretty close to having this working. We do plan to also have LLVM be capable of producing (and consuming) a text format, which may be similar to the current one (see some discussion about alternatives here https://github.com/WebAssembly/tool-conventions/issues/17). When that happens, s2wasm won't be necessary anymore (because binaryen will not need to as a linker the way s2wasm does, and the linker will output a standard format directly). So we don't plan to invest a lot of work in improving s2wasm.\n\nHaving said that, if there's a bug (e.g. in the parser in https://github.com/WebAssembly/binaryen/blob/master/src/s2wasm.h) I'd accept patches to fix it.\nIf you are using s2wasm in your current project, now might also be a good time to try using LLVM's wasm object file output with lld, as we've recently gotten it feature-complete for C++ support.. The CG provides the legal protections for all technical contributions to WebAssembly and its projects. Most notably patent protection: see https://www.w3.org/community/about/agreements/summary/ for an overview and  https://www.w3.org/community/about/agreements/cla/ for details.. Yeah, it's pretty surprising that this slipped through. It's also possible that there's a test that calls stackAlloc, and then it clobbers the area outside the allocation but the test doesn't do enough that it gets caught.. No ideas, but you should disable it the same way we did in https://github.com/WebAssembly/binaryen/pull/183 so we still get ASan without leak detection.. We could match wabt and switch from the waterfall clang (which we haven't updated in forever) to travis's clang (e.g. https://github.com/WebAssembly/binaryen/commit/8ff8e68db558e0fc5de923a7fb5baa991e49f822) but that would be orthogonal to this change I think.. Bureaucracy (although the term I'd use is \"lawyers\") notwithstanding, I'm curious what you mean by \"more involved\". There are really just 2 steps:\n1. Sign up for the CG (agreeing to the IPR provisions)\n2. Contribute.\nObviously step 1 is absent if we pull out of the wasm org. Is there a concrete issue for you, or someone who will be unable to contribute with this requirement? Is it the extra step? Or some unwillingness/unclarity on the W3C IPR requirement vs the bare apache2 license?\nI don't have strong feelings about the org per se, and of course binaryen isn't really much different from LLVM which is its own org. although I do wonder if it means we would have to e.g. be careful to only discuss tool development in the tool repo (and avoid feeding ideas from the tool back into wasm itself? but what does that even mean?). Oh, I raced with @jfbastien. I guess another way of putting the the only concern I have:  how much do we have to worry about transitioning binaryen contribution to CG contribution. Although thinking a bi t more, I don't really think it would have been an issue in practice. Probably the opposite actually, since we don't have to ask people to join the CG to accept bug fixes or whatever. And also in practice if people what to discuss wasm itself we already punt those discussions to CG forums just to ensure that all the stakeholders will see it. \nSo yeah, I guess I'm not actually too worried about that.\nIt is a separate question about promoting projects. In some sense we don't want to privilege particular projects (although we, the employees of the browser vendors, do sort of do that anyway by virtue of actually contributing to them). There might be some value to indicating for people on the internet which projects are being actively worked on, and are up-to-date with the proposals, etc, but that could just as easily be done via some list on webassembly.org.. > Since the current process doesn't require IPR agreement simply to have a conversation that could eventually result in a spec change \nMy impression is that the intent of the process actually is to cover discussion and ideas to the extent possible. This is sort of a consequence of the fact that the actual design of wasm in practice hasn't happened via spec updates but rather design docs, etc. Although now that the process for new proposals is a bit more formalized and actually does involve forking the spec repo, maybe that's less of a concern than it was.. Oh my other question was, is the W3C IPR more really onerous than the apache2 license requirements? My non-lawyerly impression was that they have similar requirements around patent licensing, so if someone needs heavyweight legal approval from their employer to comply with one, then they might need it for the other too.. Seems reasonable. I can bring it up at the next CG video call.. Anything with a user-provided destructor is not trivial.\nSo IIRC the issue is that the global thread pool unique_ptr object is destroyed, during which its destructor destroys the ThreadPool object. During this destruction, its unique_ptrs are destroyed, calling the threads' destructors, which call ThreadPool::isRunning() through their parent pointer. isRunning then calls member functions on the global thread pool unique_ptr.\nAccording to [class.cdtor]/p4  member functions of a class can be called during its construction or destruction (including during construction/destruction of non-static data members). So calling ThreadPool::isRunning() during the destruction of the members is ok. Calling member functions on the global unique_ptr member object is also ok for the same reason. I think It's even OK to access data members on the thread pool because its destructor hasn't finished yet (members are destroyed after the user destructor is called). But the data members in a unique_ptr are just pointers, and the destructor is free to frob them as it pleases. So I think it's actually totally legit for the destructor to, e.g. copy the member pointer to a temp ptr, set the member ptr to null, and then delete the temp ptr. \nIn the new code, during this process, ThreadPool::isRunning() calls the boolean conversion and operator-> on the global unique_ptr (while its destructor is still on the stack), it's relying on that destructor keeping the state consistent (i.e. nulling the member pointer before calling delete). That seems... fragile. And I haven't even started to think about possible race conditions there.. But all this does make me agree more with @binji  in https://github.com/WebAssembly/binaryen/pull/1389#issuecomment-360889374. Oops, not sure how I missed that; should we update the validator to check the offset too?. Oh yeah i had thought we had code in the validator for that, but you're right, there's nothing beyond the runtime trap.. Now I'm kind of curious to see if the UBSan bot will catch this. We have a test that exercises this now, right?. I'd love to get to a place where everyone always clang-formats so the style is always consistent and nobody ever argues about it (Currently the style is just inconsistent). I like Chromium style more than LLVM but If we can agree on something I don't much care what it is.. (also git clang-format) is great when you start out without the whole codebase being formatted. It just formats the code that is changed from master.. Here's my bikeshed color preference...\nI mentioned before that I preferred chromium but looking at this list here, I actually prefer LLVM style for most of these (I think in general I must have a stronger preference to \"use less vertical space\" than the Chromium style does). EXCEPT for PointerAlignment which I feel more strongly about than pretty much all of the others combined. So my preference would be \"LLVM style except for PointerAlignment\" although there's a bit of an argument to be made to take a style altogether with no exceptions.\nActually if we're going to have a long line length, I think LLVM makes more sense because Chromium makes several choices (e.g. no BinPackParameters) that take up extra lines and don't use that extra horizontal space at all.. Also, if we want to just reformat everything, after we do it we could then add a presubmit check that runs clang-format over the code and fails if the output would change. That would prevent people from landing misformatted code (at the cost of making all contributors install clang-format, which would raise the barrier to contribution).. Thanks!. Probably; building a subset of the build targets would probably work. Binaryen has a variety of stuff; is there some use case you care more about than others? I suspect there's also possibly some refactoring that could reduce build time (moving code from headers to C++ files, or checking the CMake library targets for duplicates and fixing those).. LGTM. want to change the tests too? ;). From http://llvm.org/foundation/relicensing/ it looks like the license text is finalized although they seem to be be behind on publicizing the license agreement (although it ought to be soon). I think it makes sense to consider giving Binaryen and WABT the same license; although neither Binaryen nor WABT have runtime libraries in the same sense that LLVM does so it's not clear to me whether the first exception would apply (or whether that matters). I should check with the lawyers on our end. And then of course we'd need a plan to actually execute the relicensing. But assuming we can work it all out with the Binaryen contributors, I'm also interested it knowing from the OP or other interested parties whether this would actually solve their problem.. Looking back at it. In my comment above I expressed a preference for having a single static library (e.g. libbinaryen.a) and asked why we didn't do that. I'm not exactly sure what @chfast meant when they said \"but that's required\". Do you mean it's required to have separate static libs too? If so, why?\n@axic what's your use case? Would it be better to have one or many static libs?. +1, sounds like a good plan.. Another reason for \"wasm2js\" is that I'll bet all the engines that had good asmjs optimizations now also support wasm, so I guess the real target for this is older browsers that don't have good asmjs or wasm support.. @tlively has recently started working in SIMD in LLVM. So he, or someone, will likely also work on SIMD in Binaryen soon.. LLVM calls this dead argument elimination, which seems like a pretty good name.. At function creation time, if you knew enough to know whether to generate call or call_import, then when it analyzes a call, the optimizer should also know whether it calls an import or not, right? so it should be able to do the same optimization. Are parallel function passes allowed to read the Module object?. I'd call this WontFix: Working As Intended.. I wouldn't artificially limit it to less than 4G. Browsers can (and will) fix limitations transparently so we shouldn't have to update the tools later to accommodate that.. I created the WebAssembly AppVeyor account, so it's currently hooked up to my GitHub account. I'm not sure if it can easily be associated with the org instead. But in any case I can encrypt a token. Does it actually need full public_repo access (IIUC that gives it full commit rights to all repos writable by whoever creates the token). I guess I don't quite understand why deployment needs push access.. I'm surprised you are seeing any blocks that return values? The wasm backend does not model that at all (except as a special case, the last block in a function for fallthrough-return). Do we have a binaryen pass that creates those?. Oh I misunderstood you; you're saying the rereloop pass generates this pattern.. Yeah I think we may want to eventually add support for keeping reloc info up to date (without it we can't optimize object files), but we don't have it now, so it will definitely break. So always stripping the static linking sections makes sense. Or maybe we should even just refuse to process object files at all; object files aren't runnable until they are linked, and we will break them if we modify them (and since Binaryen's encode/decode isn't guaranteed to roundtrip we may always modify them), so I don't think running wasm-opt on an object file could ever work right now?. I wish we had thought to do this in 2016..... btw I actually do think that it might end up being worthwhile to do this to simplify emscripten. Or even to transition asm2wasm to not use underscores, but that's hard because there are a lot of places where users are specifying function names (e.g. -S EXPORTED_FUNCTIONS=['_foo'],  Module._foo(), probably others?)\nedit: actually, now that I think of it, I think the list of exported functions doesn't include the underscores. In any case yeah don't break the users.. This seems to have broken emscripten: https://logs.chromium.org/logs/wasm/buildbucket/cr-buildbucket.appspot.com/8927132592189836048/+/steps/emscripten__emwasm_/0/stdout. I guess the idea behind using Names is so the compare is just an identity comparison?\nCould you just use a static std::array<Name, 4>?. Not really a good cross-platform way; see e.g. https://github.com/llvm/llvm-project/blob/master/llvm/lib/Support/Windows/Program.inc. Actually no, that's more for process creation. There is https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/getpid?view=vs-2017\n. IIRC currently the model for debug locs is that there's a map from Expression* to a DebugLocation. Passes should probably be updating this map whenever they replace a node with another node, but I don't know of anywhere we do that. That's obviously a separate thing from DCE but it makes a big difference when trying to profile or debug optimized code.. +cc @juj . That's a good point. The reason I had it at the start (other than because that's where the init code is) is that stack overflow will immediately be caught and trap, rather than corrupting other data.\n. Do you mean you want me to put it back on the same line, like it was in the original?\n. oh nevermind, you mean to add braces if it's on another line.\n. I guess they are all unneccessary, and pretty clear now that the types are unambiguous and they all match. Removed.\n. Sorry I missed the comment about the name. How about --allocate-stack?\n. Actually it should be validated rather than rounded. It can't be rounded down because then there might not be enough space in linear memory, and it can't be rounded up because the interpreter would think it had more memory than was in the buffer.\n. Done.\n. That was needed because before https://github.com/WebAssembly/spec/pull/209 those tests had memory in units of bytes. But that landed, so I'll update this patch and this can hopefully go away.\n. Don't know? The only relevant change was the size of the memory, so maybe there's an off-by-one error somewhere in the binaryen interpreter  or something that gets papered over because of the larger memory? (or in LLVM, but that seems less likely because this test works in V8)\n. rol is defined as a template on like 508, and ror is defined on 521.\n. Actually those should probably private methods, or just free functions. let me fix that.\n. ok, done.\n. Couldn't this be an unordered_map?\n. Yes, although since I just ended up using std::ostream's << operator the forward is pointless anyway. I'll remove it.\n. That was leftover from debugging, removed.\n. Fixed in #317\n. Done.\n. minInitialMemory is now completely gone. In the previous commit it was always updated exactly when nextStatic was updated and exactly to its value. It only had one other use (at the top of fix() which now uses nextStatic instead. The consequence of unconditionally allocating the stack pointer is that there will never be a case with no globals.\n. Why not call it wasm-visitor.h after the class it declares? (or wasm_visitor.h? Do we have a naming convention around that? Or wasm-walker, since that's here too.). Also it might make sense to move the non-templated base class method implementations into a c++ file, especially if there's going to be several other files that include this.\n. OK\n. Can we at last move this to a cpp file so it doesn't have to get parsed by every pass implementation?\n. Well, I'd prefer that most of that other stuff not be in headers either :) e.g. the s2wasm implementation is only used in one place.\nI hadn't looked close enough to realize that you intended this to be derived from, and it's not that big so maybe this one is ok, but if you have a bunch of passes in different places you wouldn't want all of them to include all of the implementations of all of the algorithms.\nThere's not really any need for the algorithms to be in header files since they aren't templates themselves, right?\n. Should be virtual?\n. But this class isn't a template. If you're going to derive from it, and you want these base class methods to call noteNonLinear in the derived class, then it has to be virtual (otherwise they will call the abort implementation). If you want CRTP all the way down then this class has to be a template too.\nBacking up, what would the derived class be expected to implement?\n. When would there be an \"obvious\" order that isn't the order of execution?\n. Should we call this pushTask to make the stacking behavior a little more explicit?\n. How about making this a std::function? Also, it might be nice to have it return an Expression* instead of using the class-scoped variable. I think having that explicit would be a little clearer, although I guess it would complicate the default implementations of doVisitFoo()... What happens in that case if visitExpression and visitFoo both want to replace the node? the later one wins?\n. should this be WASM_UNREACHABLE() what's the difference in expected use between that and abort()?\n. How about LinearExectionWalker?\n. I feel like maybe these and addTask could be replace by something like:\nusing VisitNodeFn = std::function<void(VisitNodeTy*)>;\ntemplate <typename NodeTy>\nvoid addTask(VisitNodeFn<NodeTy> F, Expression** currp) {\n  auto taskFunc = [&self]() {\n    self->visitExpression(*currp);\n    F((*currp)->cast<NodeTy>());\n  }\n  stack.emplace_back(taskFunc, currp)\n}\nand at the addTask callsite,\nself->addTask<Loop>(self->visitLoop, currp);\nThat syntax is close but probably not exactly right; maybe @jfbastien can help. Also something would have to be done with scan too. Maybe instead of the lambda, we could just declare template <typename NodeTy> doVisit(VisitNodeFn<NodeTy>, Expression** currp) directly on the class and pass it to addTask. Then we could have\nself->addTask(doVisit<Loop>, currp);\nself->addTask(self->scan, &curr->cast<Loop>()->body);\nOr something like that. Then we wouldn't have to declare one of these for every node type.\n. If it's like llvm_unreachable which has basically the behavior you describe (i.e. it's compiled away in non-assert builds, and the optimizer assumes it's unreachable), then that sounds about right. AFAIK most of this codebase doesn't really have that distinction. Although it might be a useful one to start drawing, especially if you fold your assert/abort messages into unreachable as llvm's assert and unreachable do; then the release binary gets even better size benefits, which could be a big deal if we expect to be running this under wasm.\n. That seems fine, it would separate the switch away from recursive traversal.\n. Is visitExpression allowed to replace the current node? We should probably document it either way.\n. OK. In that case it looks like visitFoo will still see the old about-to-be replaced node. Is that what we want?\n. Done.\n. Done.\n. I also thought about making these functions that take vectors be\ntemplate <typename T>\nFunction* makeFunction(\n...\nT&& locals) {\nWhich has the advantage that they will take either an lvalue or an rvalue, so if you want to use the vector that initializes the function after the call you can. That has the downsides that it's less readable (not obvious that you need to pass a std::vector<NameType> or something convertible to that) and it means you can't use braced initialization syntax on what you pass without an explicit cast (or a temp variable), which is more verbose and ugly. But if we find ourselves wanting that we can reconsider.\n. This could just be \nsubprocess.check_output(cmd, stdout=subprocess.PIPE)\nsince you assert that the return code is 0\n. Actually never mind, you don't want that when stderr is a pipe too. This is fine.\n. That's fine, we can always add it back later if we have another use for it.\n. why does it matter that we don't eat the rest of the line here?\n. how about this (instead of what you have for 496-507)\nmustMatch(\".int32\"); // replaces the abort_on(...) below\n    do {\n      initializerFunctions.emplace_back(...);\n      assert(...);\n      skipWhitespace();\n    } while (match(\".int32\"));\n  } // end while (*s)\n} // end function\n. Hm, I think the while(*s) is basically to catch the end of the buffer if it's terminated early. But in this function right now it actually doesn't do anything, because it either breaks or aborts. So we could remove the outer while(*s) and make the end of the inner loop be } while (match(\".int32\") && *s); (that will cover  the case where .int32 is the last thing in the buffer). Then there's no outer loop so no break.\n Also it seems like the p2align should be optional (although maybe in practice it will always be there?).\n. I don't quite understand what this pass is for, can you explain it a bit?\n. The wasm backend output changed a long time ago, it always appends @FUNCTION to function names in contexts like this (see e.g. all of the other dot_s tests and waterfall output). It just so happened that before s2wasm didn't care about it.\n. Or, to be more precise, s2wasm has always just unconditionally stripped it from the names, so it didn't care whether it was there or not. With this PR we use that information to tell whether the relocation should be for a function or an object (instead of looking for an object with that name and assuming it's a function otherwise).\n. can you sort the headers (at least within a class, i.e. all C++ system headers)\n. I came up with something even better; the object is empty when the module is empty.\n. Done.\n. Actually we have to keep the allocation in the same place, because some AST node has a pointer to this call as its operand. So if we allocate a new node that pointer will dangle. Since we don't have parent pointers in the AST nodes, the only alternative is to write a pass to traverse the whole AST and replace the nodes, which I was hoping to avoid.\n. nop() is totally undefined behavior because if you allocate an object with a type, you can't reference it through a pointer of another type (even if the classes have the same initial member declarations).\nThat's similar to one idea I originally had which was to just change the _id field from CallId to CallImportId since those classes have exactly the same member declarations. But in either case when you traverse the AST you end up calling visitCallImport(CallImport* curr) on an object allocated as a Call and you're in UB-land.\nThere is a provision in the Standard that says if you have a union of types that have a common initial sequence (of member declaration), then you can access those members that way. So we could make the visitor operate on such a union type (and extract pointers to the subtypes and pass them to the visitor methods), but it would require the allocations to all be of the union type (i.e. the size of the largest type, which I believe is a vector, a Name, and 2 pointers, plus the base Expression), which would cost more memory.\nAnother option would be to have parent/user pointers in the AST so that we could easily reallocate them and fix the parents (or have such pointers just for the calls). I would actually be OK with that; the single-use nature of an expression tree makes this rather nice because when you do want to replace a node you only have one user to fix up. But IIRC you've expressed a desire not to have parent pointers in the past.\nAnother option would be to do a full-blown traversal pass just to change these nodes; I would rather not have to traverse the whole AST, when I could just do what I did here; i.e. just keep a list of the nodes that need to be fixed.\nAnother option would be to do what I did here; a little bit of ugly reallocation but safe and localized.\n. I think it can be done the way I'm doing it here, which is reallocation in-place. It's a bit ugly, but we can hide the ugliness, maybe inside nop() itself. I think we can land this as-is and then look at fixing nop()\n. oh also, I think we do still need to call the destructor in this case before we reallocate, but I'm not sure; maybe @jfbastien knows?\n. this could be a static_assert\n. This assert can go away now too.\n. They actually can't be because it's IString and not Name that has std::hash defined for it. Originally I just thought it better to use IString as the key but now the hash maps are starting to proliferate, maybe I should revisit that. Anyway, I'd like to make that a separate PR.\n. Done.\n. Done.\n. Done\n. Done.\n. Added comment and cleaned up\n. Done, and below as well.\n. Done\n. Added comment\n. I went ahead and clang-formatted it.\nIs it the public: and private: bits that look off? The default for my editor and clang-format is to make those indented 1 space.\n. Oh, please do something, anything, other than messing with LD_LIBRARY_PATH. Therein lies madness. Also it won't work on Windows.\n. We need to compile everything that gets linked into the shared library with -fPIC, on all platforms. It's only just lucky that things work now (because on x86-64 compilers prefer rip-relative addressing even when not generating strictly PIC code).\n. This could just be reachable.count(curr)\n. we'd better have a recursive function (and co-recursive pair?) in the test too.\n. these should use quotes instead of angle brackets.\n. auto it?\n. I agree :)\nActually it looks like most files use \"wasm.h\" and a few (mostly in src/passes) use <wasm.h>. So we aren't consistent. Can we at least not check in new files with angle brackets?\n. We could even make the queue/reachable types use const Function* in the containers, although some people feel that's overkill.\n. Something like this seems simpler:\nauto e = module->functions.end();\nauto it = module->functions.begin();\nwhile (it != e) {\n  if (not reachable) {\n    std::swap(it, --e);\n  } else {\n    ++it;\n  }\n}\nmodule->functions.erase(it, module->functions.end());\n. Oh actually that's essentially the same as what you wrote. I just find it more readable :).\n. The object is const; i.e. you can change where the pointer points, but you can't modify the object through it. T * const foo would be a pointer you can't retarget. I always found that counter-intuitive about C syntax.\n. Hm, i think it should work because it looks like the type only needs to be move-assignable and IIRC unique_ptr is. Try making your lambda take a const reference instead of a copy as its arg.\n. (And don't forget to actually erase the removed elements after the call to remove_if. It doesn't actually do that.)\n. Oh, Yeah I missed the v.erase() bit.\nBut I think @binji is right. The \"move-assignable\" bit should have tipped me off.\n. Does it work if you delete the copy ctor from your struct?\n. RotateLeft is a template where the 2 arguments are the same type. How does changing this from an explicit cast to an implicit conversion help?\n. Sorry I missed this before. I'm not sure having a second type is good here because they could end up being different sizes if we're not careful, and then the bit-twiddling doesn't work. If the warning is about negation of an unsigned value, maybe we could just cast it to signed for that expression instead.\nIf we did that, I think we wouldn't need #474 either.\n. Nope: https://github.com/WebAssembly/design/blob/master/AstSemantics.md#addressing\n. The WebAssembly semantics are that both operands are the same size, but that the shift count bits beyond the 5 least significant are ignored. C's semantics are that if the shift count is too large (e.g. if any of those bits are set) then the behavior is undefined (that's a very bad thing). The mask operation in the first 2 lines of the implementation is designed to implement the wasm rotate semantics but if it fails to mask all the higher-order bits (which could happen if U were accidentally larger than T) then the behavior of the interpreter would be undefined according to C shift semantics.\nThe effect of -count is, bitwise, the same if count is a signed or unsigned int, so -5  is 0xFFFFFFFB. and the right-shift count becomes 0xB (or 11, which is ) after masking. Other than that, this particular implementation only does bitwise operations and so is agnostic to whether the types are signed or unsigned.\n. Yeah, a utility function seems fine. For eventual wasm64 there would be a couple options. We could template things on the address size, or just make all the address fields 64 bit and dynamically check (or even do something different for e.g. the interpreter vs the linker if we wanted).\n. I like having spaces better in general, but consistency is better here I think. I'll change it.\n. Technically this ought to be ptrdiff_t, a signed quantity.\n. Maybe instead of casting everywhere here we should just introduce a char temp (convert num to a char once), and add that to '0'. We could also add an assert at the conversion time.\n. Actually looking at the code, this use of stringIndex/strchr is straight-up wrong. It doesn't matter right now because we don't use archives with symbol tables yet. You can leave this as-is (it will warn, as it should... because it's wrong :))\n. extra indent?\n. Is the plan to use this in more places? If not, let's just put a cast where the one use is. If so (and especially if there will be a lot) it might be cleaner to do something with an implicit conversion like we did with Address. (that can be a different PR).\n. Right; '0' + num promotes to int because num is an int. Actually what I had in mind wouldn't really work. I think let's just put the casts on num expressions directly rather than the promoted result, e.g. test[1] = '0' + (char)(num / 10); That makes it clearer that there won't be overflow (since we are testing the value of num) and prevents the promotion altogether.\n. We had talked before about making a .clang-format file but I think it hasn't been checked in yet. Also the files in Binaryen now come from several sources, so the formatting isn't in good shape at all right now... :(\n. OK; let's maybe handle Index in another PR then.\n. It is in C; It's actually not in C++ (http://en.cppreference.com/w/cpp/language/character_literal)\n. What about just changing the constructor of LEB to take a size_t argument instead of a T? That would force all arguments to be implicitly promoted at the construction site when necessary, and then the implementation would cast down to T and could also assert that it doesn't overflow.\n. Can we actually do what I suggested above (i.e. change (char)('0' + (num / 10)); to '0' + (char)(num / 10);?\n. What about something like #537 instead?\n. No, that's actually only there because it's passed to std::max and it wasn't getting implicitly converted. I put the type back and put a cast in the call to std::max instead.\n. index is an Index but index + 1 is a uint32_t because there's no operator+ overload. So it can't pick the right template for std::max because the arguments don't match. So you can cast newNumLocals to uint32_t or cast index + 1 to Index (in which case they will both implicitly convert to uint32_t).\n. operator++() is pre-increment and operator++(int) is post-increment. The extra parameter is an unused dummy which just serves to give them different mangled names.\n. (That's also why operator++(int) returns a copy instead of a reference)\n. Yes. The semantics are (assuming that T is u32) that the assigned value is promoted to u64, the u64 value is checked, and then truncated for the initialization. (well technically speaking the member initialization happens first). Of course that can all get optimized away when the assigmnent is from a u32. When the assignment is from a 64 bit type, then it actually matters.\n. Done.\n. Done.\n. Because then conversions become ambiguous (compiler doesn't know which constructor to pick).\n. Ah yeah, even better.\n. (Also this only is needed when mixing Index with other types. There are already other uses of std::max or min on Index in the codebase and they are fine as-is).\n. Here we're getting into particularities of the language that I'm slightly fuzzy on, but the issue comes up when the type is not exactly uint32_t or uint64_t but something else. e.g. when I actually tried it I got these errors on conversions from size_t and from literal 0\n. externTypes are the types of functions which are declared but not defined. You're right that it's simpler to keep the types along with the other function types, I fixed that. externTypesMap now just maps the declaration name to the type.\n. Fixed.\n. Fixed.\n. It does need to exist somewhere; a functionType is just a type (it can have a name, but that' the name for the type, i.e. the asm.js-style signature). We still need to have a list of the external functions that are not part of the module but that the linker knows how to generate thunks for. You're right that it doesn't necessarily need to be on the module. It could be in the linker instead. Although in that case it would be weird to have the types in the module, and the functions in the linker; probably would put everything in the linker.\n. I assume this labeling is what causes the results to report gcc as the compiler. What happens if we leave it as 'clang'? what happens if we just remove the 'addons' line below?\n. OK, I moved the mapping to the linker but decided to let the wasm module continue to own the function type itself, to allow for deduping and because it already has the unique_ptrs.\n. ... assuming we ever support more than 2^32 locals :)\n. It seems like it was always ambiguous with getSig(FunctionType*) (i.e. this template could have been instantiated with CallBase as FunctionType which isn't what we wanted). But it wasn't until this PR that we started seeing errors (i.e. everywhere we pass FunctionType* this template is getting instantiated instead) of the function. I'm guess it's because I changed FunctionType* to const FunctionType * in the other declaration. In any case this makes a bit more explicit the intention that it only work on calls. Unfortunately there is no CallBase class, just Expression with 2 kinds of calls, but I think it's still an improvement (even aside from now being necessary).\n. Done.\n. Oops, we raced and I didn't see the comment before I merged, sorry.\nNames with double underscores are reserved for use by the language implementation. So the only conflicts we need to worry about are those that we introduce, via the C/C++ headers, compiler, linker, etc. So I don't think this is a huge issue.\nHaving said that, it's not a bad idea to check for collisions. I'd rather not start depending on optimizations for correctness.\n. I guess technically having duplicate functions with the same name is not a correctness issue if they have different indexes, although it's a problem for wast files, and it causes errors in sexpr-wasm and wasm-as.\n. OK, except not all the output (e.g. when you run the binaryen tests) passes validation yet. And I'd like to have the ability to run it separately from fixing the invalid cases. So can we land this for now and then make it mandatory once the errors are fixed?\n. Done.\n. OK, how about this: I'm looking at one error right now. If it's the only one, I'll add it to this PR. Otherwise I'll do them separately :)\n. I did it that way so we would still get the output, for debugging purposes (the exit status is still 1). But since we expect it to be valid now, I could go either way on that.\n. If we are removing all the RegisterPass calls, can we now just delete its implementation? I don't see that in this PR.\n. Done.\n. Done, but renamed the original validateWebConstraints because they can't match.\n. I'm fine with making this wasm::make_unique. IIRC, std::make_unique is a new addition in C++14. Does VS2015 default to C++14?\n. I guess we should decide whether we want tabs or spaces in this file :)\n. off_t and size_t are types that are meaningful for the host, whereas we want these types to be correct for the target (for example if compiling for wasm32 on a 64-bit machine we could use 32-bit quantities but these would be 64). Also off_t is for file offsets, not memory offsets.\nFor the size I guess we should use wasm::Address which is an unsigned of the same size as the address size. For offset I guess we want something akin to ptrdiff_t but we don't have that. For now, since we actually only support wasm32, maybe we should just  put a typedef Offset int32_t below the definition of Address in wasm.h. There are definitely places where I used int before that should be this offset type instead, but you don't have to fix those in this PR. Let's just avoid making things any worse here :)\n. We should probably also emit an error if the symbols match but the types do not.\n. For aliases and labels, the period is just part of the name of the symbol and ideally should not be treated specially.\nActually probably we should handle object aliases in the scan() phase along with function aliases. Then I think process() wouldn't need to change.\n. Do you know much about what the expectations will be for symbol aliases, e.g.\n1) do we expect to define them more than once in an asm file (e.g. is your code on line 424 necessary?)\n2) do we expect that the aliasee will be declared before the alias (e.g. can we assert that e.g. the sizes match?)\n. 1. OK; in that case we should also add a test case (to alias.s is fine) to cover this behavior.\n2. I don't  think it should be necessary if alias size isn't used. IIRC you are right and it doesn't matter except for allocation, and of course only the aliasee is allcoated.\n. This is a downgrade of the emscripten version. I'm guessing your local client just isn't up to date? (Updated it with git submodule update).\n. Maybe for a future CL we should consider adding a libwasm to go alongside libasmjs and friends, to avoid this duplication of wasm.cpp everywhere.\n. Maybe we should close this handle at the end of the iteration.\nor just put it in a with open clause.\n. 2016 :)\n. Since it's possible for input to be syntactically correct (parseable) but invalid, this should probably be a Fatal() instead of an assert. And probably we want it to run even for release builds, so it doesn't confuse the passes, no?\n. This one we could keep optional if we expect the passes are correct. I'd guess that we'd eventually want to have the default behavior be no validation, but with a flag to validate between each pass.\n. how about assert(functionTypesMap.count(name))\n. This should probably result in some kind of validation error, rather than WASM_UNREACHABLE (since otherwise well-formed input could reach this code?)\n. Got it; but I don't see code for that in wasm-validator.h?\n. Ah, got it.\n. Might be worth having a comment explaining what these files are.\n. Should this test maybe have these functions in a different order than 0-1-2-3, so that it tests that the indexes aren't accidentally assigned just in order of appearance in the file?\n. I think this can have Address type instead of uint64_t like other address-sized things in wasm.\n. Is there any particular reason this new support for names has to be in this PR?\n. This comment should say 'address-taken' functions, since you can compare pointers without calling anything :)\n. This check means that if there's anything in the table, we bail, which I guess is for the case where the indexes are pre-assigned. Otherwise if that happens, we are basically already in a screwed-up state, right? Can we put an assert before we run the pre-assignment that the table is empty?\n. let's make this __wasm_nullptr or something a little bit more descriptive.\n. Oh, and let's make this assert(out.wasm.table.names.empty()), that's more readable.\n. Someone's been writing too much Python... :)\n. Btw I learned about http://en.cppreference.com/w/cpp/keyword/and in exactly this same way... also TIL (from the appveyor build) that apparently MSVC doesn't support it :)\n. For .s files which are generated from C/C++ files (i.e. not small and hand-written),  let's also check in the C/C++ source file, so the .s file can be easily regenerated if there is a major change. I've been checking them in right alongside the .s files in test/dot_s. Also this llvm_autogenerated directory is for tests which are generated from the .ll test cases from the wasm backend. We use test/dot_s for other tests, including those that are generated manually from C files. So this test (assuming you did manually generate it from a C file or hand write it) should go in test/dot_s.\n. Another option might be just to handwrite a test. IIUC we should just be able to copy the call instructions (and give them dummy local args) and then the test would be a lot smaller and simpler.\n. Pretty much everything in here is LLVM wasm-backend specific right now. It's possible that we generalize and document the format, but we're not so far along even defining what we want that I think we should split these hairs. I would argue that the fact that we have emscripten-specific exception behavior in here is just as weird if not more so. Anyway,  maybe fixEmExceptionInvoke or some such would be a more-descriptive name?\n. Since this one only handles longjmp, let's give it a different name from the ones that do both longjmp and EH.\n. This could be static, or in an anonymous namespace?\n. wasm-emscripten.cpp just needs to know that it shouldn't generate thunks for that, right? In other words, a dyncall thunk is just an indirect way of exporting a function. We could add some sort of interface to the linker (or somewhere else) saying \"can this function be exported\". Currently the dummy function and functions taking i64 are excluded. Unfortunately I'd consider the i64 exclusion to be more a property of the emscripten/web embedding than the linker proper though, so maybe that shouldn't go in the linker's version of what to exclude. Even so it might still be cleaner to have some sort of Linker::canExport(Name function) method than having the name itself be shared.\n. This could be getTableDataRef()\n. This could be getTableDataRef() too, right? Actually is there anywhere where we actually need to return a copy of the table?\n. I think we should maybe just have something like std::vector<Name>& getTable() and make its implementation keep the abstraction that pretends there can only ever be one table. If this has the side effect of creating an empty table, then we should just ensure that the other places that care handle that correctly. Also figure out why the segments and offsets, etc. But I think that can be in a future CL and doesn't need to block this one. I think what we have here is still an improvement.\n. I had it that way to match the rest of that function which didn't use a builder either. But I went ahead and made that whole section use a builder instead.\n. OK yeah I had it as true originally.\n. OK yeah; I was going on the design doc which says that mutable globals can't be exported but doesn't say anything about imports. For now though I think I like leaving the restriction until after refactoring; i'll remove that.\n. Done (required now that there's a variable decl in there).\n. Doesn't PEP8 style call for no spaces here?\n. Once we parse block signatures, we can just encode curr->type here which should never be unreachable. Likewise for ifs and loops.\n. Should we change the typeof Wasm on line 167 to typeof WebAssembly?\n. Kind is pretty general and not particularly clear... This is just used for imports and exports, right? Could this be called something like ExternKind?\n. Can there be some comment about what validateGlobally does and/or is for? Is it intended to be temporary?\n. IIUC the angry bots JS file is trying to also handle versions of wasm older than 0xc, and that the Wasm object is there to support that for now but is intended to go away before launch. Since Binaryen only emits 0xc now anyway, the JS should probably only support the new API.\n. Maybe GlobalKind? What you are describing sounds a lot like LLVM's GlobalValue (from which GlobalVariable and Function are derived). \nActually, do Table and Memory fall into the same taxonomy for GlobalOpt-like purposes? If not, then maybe we don't want to reuse the same enum for that.\n. I guess the design repo doesn't care about specifying anything other than the import and export types (i.e. Binaryen is different because it wants to model them in a more general IR). I really do think Global is the right description for the kind of thing we are trying to model; if I were doing my own naming I'd call overall thing Global or something else with global in the name (since it's global to the instance), and then have GlobalVariable. It's just unfortunate that the spec/design already has Global. Maybe ModuleValue or something with Module in the name?\n. \"such imports/exports\" are validation errors?\n. ExternalKind sgtm\n. That directory doesn't exist in any Binaryen repo or submodule. I'm guessing it was part of @sunfishcode's local checkout.\n. Yes but I like for my scripts to tell me when they do things, and what they do :)\n. Oh, that file shouldn't even be in the commit; got sucked in with git add on a directory...\n. Done.\n. do we need to add wasm.table.exists = true here?\n. Ah i see. in that case is it even necessary to have this line then? This line doesn't cause the table to exist, and the table constructor sets both of the limits to 0 anyway?\n. Ah right; so the intent is that asm2wasm output never (yet) has a growable table; and the import gets set up in its own place. Makes sense.\n. We should probably use argparse instead of the obsolete optparse. I think it should be a pretty minor change from what we have here since it looks like we're just using the basic features.\n. It seems unnecessary to have these options which are just on by default. It seems like the only use case would be just to allow them to appear after the negation versions to turn the option back on again?\n. Seems like we could factor this kind of thing into some function like ExecutableName() which might append .exe on Windows and nothing otherwise?\n. We are doing similar Windows work on the waterfall script currently as well, as we're bringing up mac and Windows builds, and I was just looking at a similar change there.  Our script infrastructure has a few batch files which we found we needed shell=True for that; but I don't think any of these are batch files, and I'd rather not have shell=True if we don't have to. I assume it's in this PR for a reason though, what makes it necessary here?\n. This was an extraneous comment that I accidentally left in in the previous PR; you don't need to copy it :) I don't think the name actually matters; maybe @kripken knows better and maybe even we should come up with a better name for this PR I think it's fine to leave as-is, just without the comment. (Bonus points if you remove the corresponding comment from the table part :) )\n. OK, we can factor it if we end up needing it in more places.\n. I'm pretty sure we don't use that for our automated tests or local development, and I don't think it's used in Binaryen's CI (which you are obviously updating), so if @kripken doesn't use it commonly, I don't think breakage is a big concern for that particular flag.\n. OK; this is fine for now. I'll think a little more as I update the waterfall scripts and if we come up with a better way than just having shell=True everywhere then we can update everything.\n. How about just if (toSkip >= parent->data.size())?\n. Oh, actually no, it's not; its the start of the data for the archive member represented by this. So this could be if ((data - (const uint8_t)parent->data.data()) + toSkip >= parent->data.size()) which has the advantage that we never even create a pointer that points outside parent->data().\n. OK, so the travis hang reproduces for me locally, and it's caused by adding shell=True here. Not immediately obvious why.\n. Interestingly I just checked and it looks like CMake adds '-O3' in release mode and '-g' in debug mode automatically, and these appear on the command line after (and thus override) our manually-specified flags. So maybe they aren't necessary anyway? (OTOH the -UNDEBUG does appear after the automatically-added -DNDEBUG and does have the desired effect).\n. Technically even having a pointer that points outside an allocation is UB (see http://stackoverflow.com/questions/10473573/why-is-out-of-bounds-pointer-arithmetic-undefined-behaviour) which is why i did the cryptic version. Practically, it's just supposed to point at 1-past-the end, which is ok, but... you know, paranoia.\n. Oh right, during configure? That's not going to work if the scripts are updated, will it? Is there something that forces a reconfigure if they change, is that automatic?\n. Yeah, keeping the behavior the same for this PR is fine (hence my LGTM above). I just noticed and figured I'd mention it. I guess technically RelWithDebInfo would be a larger binary than one with just assertions and no debug info, but you could always strip the binary and you'd get the same thing.\n. I did some experiments on Linux. Apparently shell=True has some effect on the stdin used by the process; if you feed something in, e.g. stdin=open('/dev/null') it works. Maybe nodejs is trying to read something from stdin?. shell=True also affects stdout; i.e. if you set your command to something like ['echo','foo'] the output will appear on your console with shell=False but not with shell=True. In other words, stdin/out/err are supposed to be inherited by the child process when not using redirection, but apparently shell=True has some other behavior (that doesn't seem to be documented as far as I can tell).\nAnyway it's odd and magical and makes me want to avoid shell=True even more :-/. Unfortunately although Python has lots of good shell-like tools, I don't think an equivalent to which/where is among them. However it's fairly straightforward to write: see e.g. https://chromium.googlesource.com/native_client/src/native_client/+/master/pynacl/file_tools.py#72\n. How about we add clang here, so maybe this will work on mac too? And I guess if we're going to do that we could call it HOSTCC or NATIVECC or something like that instead, since it doesn't matter that it's gcc, just that it's a compiler that targets the host/build machine rather than wasm.\n. I still think having install targets is the 'right' way to do this.\nWhen creating a distribution, we don't want to depend on a source dir, and I don't think we want this stuff in the bin dir; we want it in some other dir: probably lib, share or some subdir of one of those. For local testing, I don't care too much; we can add something to check.py to handle things to avoid having to run the install step if we want, I'm happy to always do out-of-tree builds, or whatever.\n. Do we really want 2 separate knobs for this? What happens if someone says O3 but also -s1? Those are contradictory. Especially if we are going to have Os and/or Oz then we don't also need a separate shrink argument, do we?\n. Also the reason that a truncating store is in wasm in the first place (and the reason that it's common in compilers) is that it's a common operation (storing just part of a larger value) that is basically free on real machines. If you have a value in a 64-bit register, you can store just the bottom 32 bits with a single instruction that reads from the smaller subregister. So it probably would be a performance win to do that optimization too (assuming the JS engine doesn't do it, of course).\n. isn't this just i32.store and not i32.store32? Binaryen's parser accepts this?\n. Well, it's not listed as an opcode in https://github.com/WebAssembly/design/blob/master/Semantics.md. It wouldn't make sense to give an opcode more than one name, so I guess the idea is just that i32.store32 is redundant and i32.store makes more sense.\n. There are 5. But they all could be used by emscripten, so it seemed simpler to do this to ensure that new ones get picked up (and this command also creates the destination directory, so it seemed simpler than writing 6 other commands).\n. Yeah I've seen projects where std::endl is banned in favor of just '\\n' because it gets expanded anyway and they didn't want the extra flush.\n. Could we split this into its own change? There's a bunch of cases where we use cashew::IString instead of Name in unordered sets and the like because of this issue and we can fix those along with it, but we probably don't want those in this change.. I guess this comment should be moved down. Should add a comment that this takes ownership of relocation. This is backwards compared to isFunctionImplemented (i.e. it's like !isFunctionImported). Maybe one or the other of these should be switched to make them consistent.. since parseImportGlobal doesn't do anything, could this just be skipToEOL()?. Maybe we should call these 'object imports' instead of 'global imports' since 'object' is the counterpart to 'function', the other kind of thing that can be imported (in the linker/ELF-like terminology that we are using). Functions and objects (i.e. the symbol's type in ELF terminology) can each be global or not (i.e. the symbol's binding in ELF terminology).. (And of course the fact that we use wasm globals to implement that is an implementation detail and also makes the term 'global' more confusing :)). Somewhere we should actually describe how imported globals work. Also it's a little weird that this function called fixRelocation doesn't really do anything to the relocation. Instead it either adds it unmodified, or generates some code (at which point it will never get added?). addRelocation might be marginally better; it seems like we could do even better than that, but it's not immediately obvious how).\nSince we already handle null relocations, we could separate the addRelocation bit and put the interesting logic in some function that either returns the relocation unchanged, or generates code and returns nullptr? Not sure.. blank line between functions.. ASan build says this is leaking.. where does relocation->data come from? Are we sure it is 0?. how about:\nauto relocation = make_unique<Relocation>(getRelocatableConst(target));\n...\nlinkerObj->addRelocation(relocation.release());\n...\nauto expr = relocationToGetGlobal(relocation.get());. I'm not sure LLVM can generate i32.const foo+2 anyway. I think this is fine for now because we will end up revisiting it for MC and linking support anyway.. This only affects the binaries that get downloaded from the waterfall. Unfortunately (and I actually forget why ATM) the tests in tests/torture-s are just checked directly in. So you have to just download the torture-s archive from the waterfall (e.g. https://storage.googleapis.com/wasm-llvm/builds/linux/13639/wasm-torture-s-13639.tbz2), replace the existing tests/torture-s directory with that, and commit that.. Oh, right, I see. I'm kind of ambivalent about that, actually. Because now the files are from a mix of sources, rather than just one. But I guess the real solution is to automate the update to easily use a waterfall build rather than a local build, or sanitize the files, or make the waterfall update script get the tests from the waterfall directly rather than checking them in. The downside of the latter is that running these tests now becomes dependent on downloading something external, but currently we have that anyway.. So, I'm not a fan of from foo import * but I can see the value of doing it this way here.\nCan we leave a TODO here describing that we can do more refactoring and/or make the references explicit?. Yeah that looks better now.. Could you just do std::copy_backward(expressions.begin(), expressions.end(), block->list.end()). maybe do something like\nwith open(...) as f:\n if actual != f.read():\n   fail(...)\nto close the handle?. I lifted this snippet more or less directly from LLVM, which has the same Release+Asserts mode :)\nBut yeah, the loop is the same, except that we are removing a flag rather than adding one. So I didn't really see a way to share the logic there. If we had another flag we wanted to remove we could maybe turn this into a function but this is kind of a special case. so I doubt it will be needed.. It's generated for assemblers to calculate the size of objects, but It's ignored by s2wasm. . (the whole line is ignored, that is). Unintentional, removed.. Could change these messages to reflect command line now.. It's basically a nicer way of spelling typedef in C++11: http://en.cppreference.com/w/cpp/language/type_alias. Fixed. Fixed. I just realized; does this read the entire file just to sniff the header? maybe we should fix that.. Should i be size_t or Index?. i should probably be size_t. Could just also use an unsigned type and do i != 0. yeah std::remove_if sounds good. But removing from importsMap is probably needed too, so maybe you can't just do that if we also need to fish the actual name out. So maybe just a size_t counter from 0 to size(), and then a temp index of size - i or something like that.. +1. I don't see it here but I assume the function starts out as nullptr too?. I like getLocalName and getLocalNameOrDefault. This behavior is fine for now; I'd be very interested in seeing how wasm build of __fixsfsi or __fixdfdi compares with FFI+JS version.. Should it also be unreachable when\n!ifFalse && ifTrue->type == unreachable?. Seems like this should probably just be a class-scoped variable rather than a static. I guess that having this ID also means that this pass should have isFunctionParallel be false, assuming we want unique IDs.. @jgravelle-google this looks.... uh... yeah.. This seems like a bad idea, as the value of 2 is arbitrary (e.g. if in the future we want more aggressive or smarter inlining, the ability to inline just some instances of a function,  etc). Also we reuse the value \"2\" below for the same purpose without naming it.. Maybe to be more general we could pass the use count into worthInlining (so it would be false today if the use count is > 1), and separately have logic that prevents eliminating exported functions.. Oh, one other question: if we are restricting inlining to single-use non-address-taken non-exported functions, is it ever not worthwhile to inline? It seems like removing a function (along with its declaration, locals, maybe signature, etc) would always result in a smaller binary (with the caveat that we might not want the functions to be too huge. Should we increase the size limit as long as we maintain these other restrictions?. Oh, yeah, we do want to limit re-optimization too. Anyway yeah fairly small is fine; I think inlining is something that really should be done at a higher level anyway. If it is done at the low level it should probably be on the basis of special knowledge of the target (i.e. wasm). So even this is kind of hacking around a limitation in LLVM (and even one that's solved by LTO, right?). Should we check here whether the call is actually to a debuginfo intrinsic?. How about, instead of calling count followed by insert,\n just calling insert, and then throwing if result.second is false? That way we only do one lookup instead of 2.. I think if the intent here is to make it more robust against/not crash with unexpected input then this should be a throw or some error return, or something that has consistent behavior in release builds.  WASM_UNREACHABLE is just __builtin_unreachable in that case and it means the compiler will just optimize assuming it never happens and probably crash somewhere else.\nOr is this intended to indicate that we are now confident (because of the parser hardening) that this will actually never happen? In that case then I agree that unreachable makes sense.. Could just directly call insert and check the second element of its return value to see if there was a duplicate. Not as big of a performance difference obviously as the other PR but maybe still worth it.. But a valid module without globals cannot have GetGlobal instructions.. I don't think we should ever call visitGetGlobal in a module without globals, so I can't see any reason why curr would not have a name. How is this happening? . @binji This uses the 2nd bit as the \"shared\" bit, i.e \n 0x03 is the flags value for shared.  https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md#spec-changes says it's 0x11 but I'm wondering if you meant 0b11?. The first 3 parameters are out-parameters, and the last one is an in-parameter, so I wanted to keep them together.. Yes, we probably should, but it's not common enough in this codebase. I'll fix this instance though since I'm touching it anyway.. I think it's because wasm-dis prints an extra newline, whereas wasm-opt --print does not. Should maybe fix that in another PR.. Every other instance of with in this file uses this pattern. I think it may have been a compromise between you should use with instead of just open().write!' and 'but verbosity!'. OK, but If I make any more changes to this code I'm going to have to go build mozjs just so I can test it =-O. I dunno, the point of having the bools in the signature is to abstract away the encoding details from the caller (as with initial and maximum). But having bits explicit is good; I moved that toBinaryConsts. Hm I actually like the pattern ofwriteResizeableLimits(..., .., ..., /shared=/false)here.. It means that it uses__builtin_unreachableonly in release mode, and aborts in debug mode. Makes catching bugs easier.. The return type is necessary because without it, non-void-returning visitors won't compile unless they have their own override. Probably all of these templates should have thereturn ReturnType()instead of being empty, otherwise passes can't fall back on them, which I'm guessing was not the intention.. This is the original handwritten test file, so it was just an old-fashioned typo in my fingers :). Fixed.. Yeah, most function-like macros lack the semicolon so you can doSET(a, b, c);but this (and especially the case-based ones) are a little funny. To fix SET I could wrap them in the standard do {} while(0) but not sure that would be an improvement.. Yeah I like that better.. Done.. I have a local branch with that change which I'll submit as a separate PR because it depends on this one (I already had this branch in flight when we decided that).. I thought about that but they are kind of specific to the validator where we want to easily make everything print with the extra type info. Otherwise they sort of just duplicate the stream-related functions there.. Fixed.. I do like that idea, but in this case I think it wouldn't change much; it would just remove the need for theremove_ptrbit.. No reason, just leftover from a previous edit. de-intented.. Likecase i32: case i64: case unreachable: break;?. I think with something like that you'd have the same problem, i.e. you want it to be transparent to the caller (e.g.  a template likefail) whether you are dealing with an expr (in which case you want to wrap it with FullTypePrinter) or not (in which case you don't). So IIUC to do that you'd have to specialize/overload/templatize FullTypePrinter similarly.. I really don't like option A, so I'll do B. Done.. @kripken the mergeblocks test goes into an infinite loop when I use this for select, but it looks just the same. any ideas?. Do we want to remove all the unreachable concrete elements at the tail? Why just one?. Heh... I seem to have absorbed LLVM's aversion to using 'type' in variable names.. Does unreachable type mean the node is allowed to be completely invalid? How does this sort of thing arise?. Sure, but this function validates the immediate bytes field, not the pointer. Regardless of what's in the pointer, a load with a bogus size should never happen. I guess we have to fix the comparison based on the type size to handle unreachable, but it still seems wrong to allow a totally different value for size. Can we remove the early-return and mabye useshouldBeEqualOrFirstIsUnreachablebelow instead?. Right, that's why I suggestedshouldBeEqualOrFirstIsUnreachablewhich is what we want for that. We can still compare bytes to 1,2, and 4. My point is that a 5-byte load is always invalid.. Don't we already haveshouldBeEqualOrFirstIsUnreachablethat does exactly this?. The flag would only change if the instruction itself changed after a previous visit. Shouldn't we keep it up to date with the instruction?. Yes.. I suppose given the way we are using it, rvalue reference might even be better.. but i is only ever used as an index into a std::vector, never to interact with anyIndex-related part of the IR. and we aren't handling overflow anyway?. I don't feel strongly either, I changed this PR.. Done.. Actually I just looked at clang's IR output and it's almost exactly the same all of those ways because it changes the signature anyway.. The idea is to prevent atomic loads from being reordered past each other. With just one thread, loads can be reordered as long as they don't pass a write, but with sequentially-consistent atomic loads, the intervening write could be on another thread. In general I'm trying to be conservative in this patch, but we'll have to stay pretty conservative as long as all atomics are SC.. Ah, got it. I'll fix that.. Sorry, pushed now.. Yeah, that's exactly what I have locally now.. Our existing style for enums mostly usesCapitalformat rather than all caps.. is this supposed to bestd::memmove?. thisstd::moveis fine, I just didn't know about it :). Let's#include at the top of the header though.. Probably could rename this ashasLocalSideEffectsfor clarity.. Probably should includeisAtomicsince it has to synchronize globally across threads.. Yeah i guess so. Actually it probably makes sense to havehasSideEffectsjust callhasGlobalSideEffectsrather than just duplicate the conditions too.. The check on line 74 ensures loads don't get moved across atomic loads. But I guess I'm thinking more of something like atomics.wake which has nonlocal effects but doesn't write memory.. Should conditionalize this on the presence of the wasm-reduce binary, or on !windows. Is this the reason wasm-reduce depends on !windows? If so, should put that in a comment in CMakeLists.txt too.. Might as well fix the \"Removeds\" typo too.. Should this test be updated so we don't remove a big chunk of it?. This paragraph should probably have a lot more detail about what the behavior is and why.. That part looks good, I think now it just needs a bit explaining the behavior difference for wast files.. Looks good, thanks.. Wait and wake take addresses in linear memory (like using the memory address for the value of a mutex), so they can trap for the same reasons as other memory operations. See https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md#wait-and-wake-operators. Copypasta?. I guess this is supposed to fault if the load is misaligned, which is right for asm.js, but misaligned loads are allowed in wasm. So, by default we might want to fault (or warn) anyway, since there could be performance implications, but we might want different handling for wasm. Also misalignment is not allowed for atomics, so we might want to handle those differently too.. Seems like this would be even better if we could check for a value less than emscripten's global base. Could we bake that value into this generated code, since the global base is set at compile time anyway?. This terminology \"untaken\" branches is confusing to me, since whether a branch is taken is a dynamic property that changes from run to run. Do you mean unreachable branches?. Maybe. Actually a lot of instructions probably should be renamed, and probably along with the binary format opcodes, it's kind of a mess (a lot of the opcode names predate the current spec scheme). I almost renamed the extension instructions here but decided that's not a great idea to mix it in with a functionality PR.. Yeah, theTruncandConvertopcode names useToTypebutPromote,Demote,Reinterpret, andExtenddon't. So... \u00af\\\\\\_(\u30c4)\\_/\u00af. Fixed.. Any changes in this content, or just moved out from shared?. Maybe just a little more detail about what it actually does?. Would make sense the call togetUnaryFunctionName` conditional on the mode being something other than allow? Then we wouldn't run the switch statement unless we knew we actually had to do something.\nCome to think of it, why do we even have the allow mode? Doesn't that make the whole pass a no-op?. Nit: We aren't really \"emulating\" it at all, we are literally actually calling JS to do the conversion.. Not that I want you to necessarily rewrite this whole patch, but would using a Builder make code significantly better?. is the 'XXX' meant for you to follow up on before commit?. I get that this matches asm2wasm, but I feel like we should have made this flag something like --trap-mode=<enum>. Like, if Allow is the default, this flag is really a no-op. Maybe a followup fix?. Yeah we can change both. But I agree that since we don't have the s2wasm one hooked up yet, that we might as well put what we finally want in s2wasm, then maybe fix asm2wasm in a followup PR.. The build from my branch push seems to have done the right thing? https://travis-ci.org/WebAssembly/binaryen/jobs/272576776 I'm going to let this PR build go though and we'll see.. Hm, interesting; it's actually not obvious whether it's better to clamp as early as possible (since it does actually seem better to just inline and remove i32s-rem if there's only one use), or later (since const-folding could eliminate calls before they get generated). Anyway we can land this one way and maybe experiment with that later.. This name is confusing. There is no Expression that's a list, other than a block. GetMaybeBlock makes sense if only because it could return either a block or a single instruction.. I don't really understand what you mean by \"potential\" here. This always returns an actual block, no? Is the difference just that it may or may not be an implicit block (e.g. a function body or if arm?. I guess what this means is that it could return a single instruction or an implicit block (which cannot be branched to, and will not appear in the wasm output)?. Ok, I see that's wrong. So the only difference from getList is that this could return a single instruction or an explicit block (that can be branched to).. Can we put this in a cpp file rather than a header file? My build times thank you for it :). can probably just remove the \"XXX\" and maybe say \"float is too small\". Can you just do\nif (seen.insert(curr).second) dupes.push_back(curr);. No, I agree the API is ugly.\nCould always do something like\nbool inserted;\nstd::tie<std::ignore, inserted> = seen.insert(curr);\nif (!inserted) dupes.push_back(curr);. I think having it all on one line like this makes this difficult to read (i.e. it's not obvious that the continue is conditional but the break is not). Could we do\ncase 0:\n if (!oneIn(4)) continue;\n break;\ninstead?. because \"notshared\" isn't a keyword anymore; anything not \"shared\" is implicitly not shared.. Could we just remove this comment altogether now?. How about calling this breakTargets instead, since it's not a set of the break instructions, but rather their targets?. Sounds good.. I think we should consider asm2wasm as an implementation detail of emscripten, and aggressively eliminate legacy compatibility things. . Does the builder API support adding stuff to the module like this? If not, maybe we should improve it.. you could make the last argument an enum, and then you wouldn't need the comments everywhere.. I'd say Immutable. Do we really not keep this anywhere in a better-indexed format, so that we have to do this loop on every function? Could we do it just once (on init, or visitModule or something)?. Binaryen already has them: https://github.com/WebAssembly/binaryen/pull/1167. C++11 has freed us from the classic swap trick; line 696 could be\nfunctionIndexes = std::move(indexes.functionIndexes);\nalthough in this case I guess it's not really any more concise.\nMaybe replace both lines with\nfunctionIndexes = std::move(ModuleUtils::BinaryIndexes(*currModule).functionIndexes); \nbut I'm not sure you can construct an object like that.. Should this catch a CalledProcessError instead? (Likewise below). Actually, it looks like OSError could be thrown too. We should probably catch both (or just Exception) so that we keep going if the executable is nonexistent (which throws OSError) or otherwise not working (CalledProcessError).. Either way: I do like being more specific in what we catch and if there's an exception type that we don't expect, it would more or less serve the same purpose as an assert by letting it go unhandled.. Hm, this is a bit verbose. I wonder if we could turn it into a macro a la DELEGATE?. Weird, it looks exactly equivalent except for the extra semicolon (although since I'm nitpicking, it probably shouldn't actually be called DELEGATE since it's not delegating, it's just asserting).. how about unhandled/unimplemented?. Yeah, sounds good.. Wouldn't that also copy in OptLevel and ShrinkLevel, which we don't want?. I figured we'd want to be able to set this without optLevel (see above). Me too, done.. Yes, done.. Yeah, done.. Then we wouldn't be able to bitwise or them together like Real C Programmers should.... although if they are going to have names, then generating them from a def file like that might make sense. Maybe an improvement for the future.. Debug break that I forgot to remove. Removed in \n6f85f55. Does it add them directly to the module? If so, why return them also?. should this be called getStaticBump for consistency? Also probably worth saying what exactly the static bump is here.. we probably don't want to print the whole module here; I assume this is leftover from you debugging this PR?. Why is this called \"linker\"? There should probably be some more comments here. This header is the most important part of the PR because this class will persist after asm2wasm and s2wasm are gone.. Edit: OK I see it's to export them. Maybe makeDynCallThunks could just export them itself, right after creating them?. Perhaps for a future PR but it occurred to me that I think we actually don't need the memory growth function anymore. IIRC it existed because some Module glue wants to grow the memory sometimes, which in asm.js it just did in JS, but for wasm it has to call into the module to execute grow_memory. But since we wrote this, I think we just added WebAssembly.Memory.prototype.grow. So I think we can remove this, and just use that in the JS glue.. EmscriptenGlueGenerator?. Wil this work if CMAKE_C_COMPILER is cl.exe (i.e. windows)?. should be size_t. This if-block is repeated 3 times here and below; can we factor it into a function? Any other common code from those uses that can also be factored out?. is stackPointerOffset being used as a proxy for \"use a heap global for the stack pointer or not\"?. That's a bit confusing, we should maybe just make an explicit bool or something.\n  . Mutable global imports is an \"import from future\" feature, where the future is the threads proposal.. I wonder if this (collection of limits) should go into abi.h or some similar place; i.e. these are not limitations of the binary format, but web-embedding specific. Maybe even a good way to turn them off and on, although that doesn't necessarily have to be in this PR.\n  . the runFunction name is confusing. we aren't running the function, we're running the optimizations on the function..  Do you know how this interacts with line 18  above? I guess this must override that so maybe we should add symbolize=1 here too.. I thought clang already defaulted to C++11?\n(actually I think its gnu++11, but that doesn't matter, does it?). Apropos our recent formatting discussion, this should be Memory::Segment& segment . Why the temporary here?. Edit: oh I didn't realize that this was just moved from below. Still though :D. This is parsing output from the compiler, right? I suppose we'll assert here if we unexpectedly get an emjs function that's not just a const? Maybe we should make a more explicit error check that also fires in release mode.. So the other targets would have a similar install rule that has everything other than this line?. Do you mean the fact that in shared mode we have one big dynamic library, whereas here we have one static library per module?\nActually come to think of it, for this use case (I'm assuming your use case is to install static libraries in a system to link into other programs), would it make more sense to also just have one big  one, e.g. libbinaryen.a? That seems more convenient to a user who doesn't care about the implementation details of Binaryen.. I don't think the work is significantly different. Previously you'd evaluate the condition, and then call the constructor, operator<<, and the destructor. Now you'll do those unconditionally, but each of those evaluates the condition; I'd be surprised if the optimizer didn't simplify that to a single evaluation for all 3 actions, which would make the result identical.. I guess this was just for testing?. Yes, all the work is behind the conditional in the old code. I'm just saying that for the new case after inlining I would expect the compiler to transform the 3 checks (each in one of the methods) to a single one, putting the same work behind the check.. This is just a little ambiguous whether the 'non' means 'not bitwise' or 'not equal'. Maybe 'typedEqual' or something like that would indicate what it is, rather than what it isn't?. I don't expect that this will work on Windows. Not sure about __m128 but IIRC that's just int128, right? That doesn't seem much more useful than an array of 16 chars?. can this just be pop_back()?. Maybe this should be enum class so externally it has to be spelled ABI::LegalizationLevel::Full instead of just ABI::Full? Or alternatively rename Full to FullLegalization just for clarity?. how about naming this shouldLegalize or something like that?. If we are going to use separate lines (which I think is good when adding initialization), my preference would be just to repeat the type on the second line. That reduces the coupling and makes it easy to move things around if we want.. Yeah, that's an even better reason actually.. It seems odd that this should be a feature option. Is it only here because you want to have it in more than one tool?. Can we call this previous or prev instead of last?. ",
    "binji": "With sexpr-wasm, I have a neat trick where I have a top-level Makefile drive the CMake build underneath. That way you can have different toolchain configurations easily accessible. Currently I support a full matrix of {gcc, gcc-i686, clang, emscripten, gcc w/ AFL fuzz} * {debug, release} * {msan, lsan, asan, ubsan}.\n. For sexpr-wasm, I have a --spec flag that generates output as JavaScript instead of as v8-native binary format. The JavaScript contains all the modules as arrays of bytes that are converted into array buffers and loaded via v8-native's WASM.instantiateModule function.\nSince some assertions require things that JavaScript can't handle (int64, checking nan bits), I write all assertions as exported functions in the module, each returning 1 if they succeed and 0 if they fail. assert_trap instead is wrapped in a try/catch block. assert_return_nan is handled by running (set_local 0 (call ...)) (f32.ne (get_local 0) (get_local 0)). These assertion functions are then exported and calls to these exported functions are added to the JavaScript source.\n. @kripken I mean JavaScript can't handle int64, so if you call an exported wasm function that returns int64, v8-native currently just truncates the value to an int32. So you can't actually do the assertion checks in JavaScript, even though that would be nice. Similarly, AIUI you can return NaN to JavaScript, but the value will be canonicalized, so you can't do the check in JavaScript.\n. None of those commands pull new changes, see https://git-scm.com/docs/git-submodule.\n. @kripken It's a pretty great build system, written originally as a GYP backend for Chromium to improve on the incremental build time. It's much more low-level than Make, and not meant to be written by hand, so it's only really used by meta build tools like CMake and GYP.\n. Right, but then it should be (table (br $BB1_5) ... to differentiate.\n. Looks like it is still broken for the default case:\n(block $BB1_6\n            (block $BB1_5\n              (block $BB1_4\n                (block $BB1_3\n                  (block $BB1_2\n                    (tableswitch \n                      (get_local $$0)\n                      (table (br $BB1_2) (br $BB1_3) (br $BB1_4) (br $BB1_5) (br $BB1_6)) (case $BB1_2)\n                    )\n                  )\n(see 20011219-1.c.s.wast)\n. @jfbastien I named it that before .wast existed :)\n. @JSStats There is a bug in sexpr-wasm-prototype, that example should fail with a signature mismatch (tested in the spec interpreter):\ntest3.wast:7.25-7.38: indirect call signature mismatch\nOTOH, the test in your CL to sexpr-wasm-prototype fails in the spec interpreter:\n;;; EXE: test/run-d8.py\n(module\n  (type $i_v (func (param i32)))\n  (import $print_i32 \"spectest\" \"print\" (param i32))\n  (import $print_i32_i32 \"spectest\" \"print\" (param i32 i32))\n  (func $test (result i32)\n    (call_indirect $i_v (i32.const 0) (i32.const 400))\n    (return (i32.const 1)))\n  (export \"test\" $test)\n  (table $print_i32)  ;; NOTE: references an import\n)\n(;; STDOUT ;;;\n400\ntest() = 1\n;;; STDOUT ;;)\nThis fails with the following error:\ntest.wast:10.10-10.20: unknown function $print_i32\nYou were right the first time, the spec interpreter does not allow a table to include references to imported functions; they are in a different index space. Makes sense, at least with the way things are currently defined:\n(module\n  (import $import0 \"foo\" \"bar\")\n  (func $func0)\n  (func\n    (call 0) ;; calls $func0\n    (call_import 0) ;; calls $import0\n  ) \n  (table 0) ;; references $func0. If we could reference imports, what would the index of import0 be?\n)\n. It means 2**4 == 16 == 0x10. I use 0x10 in sexpr-wasm as well.\n. No, num targets includes the default, which is always last. So num targets must be >= 1.\n. That is correct, v8-native binary format only uses names for exporting and importing, not for internal names.\n. Looking at the v8 source https://chromium.googlesource.com/v8/v8/+/master/src/wasm/wasm-opcodes.h#229:\n...\n  V(I32SConvertF64, 0x9e, i_d)    \\\n  V(I32UConvertF32, 0x9f, i_f)    \\\n  V(I32UConvertF64, 0xa0, i_d)    \\\n0x9e is i32.convert_s/f64 and 0xa0 is i32.convert_u/f64. The v8 opcode enums have the output type on the left.\n. looks like parsing.h allows \"-+nan\":\nbool negative = str[0] == '-';\n    const char *positive = negative ? str + 1 : str;\n    if (positive[0] == '+') positive++;\n    if (positive[0] == 'n' && positive[1] == 'a' && positive[2] == 'n') {\n  ...\n. Yep. https://github.com/WebAssembly/spec/blob/master/ml-proto/host/lexer.mll#L100\n. From the IRC log:\n15:54 < binji_> dschuff: weird, what was the error?\n...\n15:56 < dschuff> binji_: miscompile of the clz/ctz imlementation\n15:57 < dschuff> that returned 0 instead of 32 when given an input of 0\n16:00 < binji_> strange\n. Well, even if the input error isn't handled, having something like this would be better:\nvoid fatal(const char* msg) {\n  fprintf(stderr, \"error: %s\\n\", msg);\n  exit(1);\n}\nSo it would be possible to distinguish an error and a crash.\nAssertions are designed to be disabled (just define NDEBUG) so the program should have the same behavior with and without them enabled. That might be an easy way to determine which ones should be errors instead.\n. Good idea. Have you measured how deep the nesting gets now?\n. @antelle FYI: wasm-as does not currently produce a binary format output that is compatible with SpiderMonkey or v8. You'll want to use spidermonkify.py or sexpr-wasm-prototype if that's your goal.\n. @griffin2000 You may want to take a look at https://github.com/WebAssembly/waterfall, it does most of this (syncs and builds clang, s2wasm, sexpr-wasm, etc.) with some helpful python scripts. It drives the waterfall view here. \n. @griffin2000 yes, but you're currently resolving your c++ runtime symbols (_Znam for example) in JavaScript, which is not what you'll want to do in the long run. I don't know that anyone has tried building libc++ (or whatever library will provide those symbols) for wasm yet, though.\nThe wasm-waterfall builder does have an emcc w/ wasm backend + musl libc build which is a good start though: see the step named Compile LLVM Torture (emscripten+wasm backend) here.\n. The wasm binary format likely will move from being pre-order to post-order, and wasm-as generates a binary format that matches this future change. (Though it sounds like you may be seeing a different issue.)\nIf you want to generate a binary format that matches the format currently supported in browsers, you'll need to use spidermonkify or sexpr-wasm-prototype.\nPlease remember that WebAssembly is being actively developed. Many things will change between now and the first release.\n. The condition should be last, see the spec test here. sexpr-wasm runs and passes these tests, so I'm pretty sure it works.\n. I don't really like that we're generating this debug information as comments in the wast format. I think it would be better to develop a design first so we can have it exist as a real node.\n. This is pretty weird; why do you need each MixedArena to know about the others? Seems like it would be better to allocate a MixedArena per thread and destroy it when the thread is destroyed. Then you don't have to modify MixedArena at all.\n. I see, you want to allocate memory per-thread but have it owned by the Module? I'd say a more natural way to do this is to create a new MixedArena per thread, then pass it back to the main thread when the thread is finished with its operation. The main thread would then merge in the chunks allocated by the other thread. This way there is always one owner of any MixedArena, so it can still be written as a single-threaded class.\n. You can't hide from complexity when you start using threads. :)\nWhat I'm suggesting is conceptually very simple. If a work item needs to give back memory, it creates a MixedArena, and when it's finished it gives it back to the creator of the work item, which can do whatever it wants with the memory. In this case it would merge the memory into its own arena.\nThe trouble with making MixedArena handle everything is that it pushes all the complexity into MixedArena. You now have number of threads locks per MixedArena, where each previous lock in the linked-list must be acquired before you can allocate anything. You can make this better using TLS, but why bother? Isn't it easier to leave MixedArena as it is, and handle the complexity of dealing with threads where it already exists (i.e. in the thread queue)?\n. > But what if a work item needs to allocate memory in multiple arenas? That is, if the creator of the work item has multiple arenas?\nAllocate a MixedArena per module, for each work item.\nWhat you have now doesn't really make any sense to me. What is the point of having an arena per thread if you have to walk a linked list acquiring locks to get to the arena for your thread? If you're going to lock, you might as well just have two arenas, one for the first thread (no lock), and one for every other thread (lock).\n. > But, if the locks bother you\nIt's not the locks that bother me, it's the unnecessary synchronization. You're introducing threads to improve parallelism, and any synchronization you add hurts that.\nI took a closer look at how you're currently doing things. How about another approach: you currently shard work by Function. Why not just have a MixedArena per Function stored on the module? Now ownership still hangs off the Module, and you never need synchronization. Any known single-threaded code can continue to allocate via the primary Module allocator.\n\nBut, if you prefer, I can do the optimization to only lock when necessary here.\n\nSorry, I'm not trying to hold up your PR. Just trying to help :)\n. > So performance-wise, this should be near-optimal, I think.\nBut incorrect. :)\n\nAlthough I guess now I need atomic operations on next?\n\nYeah, you can't read next outside the lock without some other kind of synchronization. There are many documents describing the issues with the double-checked locking pattern, see this for example: http://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/.\n\nAbout arena per function: each MixedArena has some overhead, and modules can have many small functions, so I worry about having an arena allocator per function.\n\nIn the single-threaded version, just an empty std::vector and an int, 32 bytes on 64-bit machine. Function is 152 bytes, so not an insignificant addition. But you could make a Chunk struct and move index into that, then use a singly linked list instead of a std::vector to reduce that to one pointer.\n\nan operation might be parallel in basic blocks...\n\nOnce you do that, you're going to need more synchronization than just a thread-safe allocator. I wouldn't worry about designing for that case until you actually start doing it.\n. Challenge accepted!\nNothing fancy, but that's kind of the point. One neat thing is that the not-yet-filled chunks are handed back and forth between the Module and Task allocators, so it's likely they'll eventually get filled up.\n. > Looks like you're taking a lock a few times per task, which means per function?\nYeah, but that's just to manage the two queues. If that becomes highly contested, you could use a lock-free queue instead.\n\nA bigger concern is that you have an allocator per task, which means per function? It seems like that would lead to a great many chunks, at least one per function?\n\nIt would, but I work around that by having the main thread only queue up N*2 tasks at a time (where N is the number of threads in the pool). Since the chunks are stolen from the main thread's allocator and handed off to the thread's allocator right before they're used, you'll typically only have N*2 not-yet-filled chunks. Take a look at the sample output from that gist; you can see that it runs 200 tasks twice, but only creates 8 chunks.\n. Yeah, you still would end up spin-waiting, but the overhead would be less. But honestly, it's not even worth thinking about lock-free anything until the measurement shows it's worth it. The point I was making above is that this is a required synchronization point between the main thread and the worker threads, and there are ways you can optimize it, if necessary. The allocator is not required to be synchronized, so it's nicer if you don't.\nN*2 I just grabbed from nowhere. Since the main thread is queuing up the tasks, I figured it would be nice if the worker threads had a little slack in case the main thread isn't scheduled for a bit.\n. > In your approach it's the tasks, while allocations are trivially lock-free, while on the other hand in mine tasks are trivially lock-free, while allocations must be coordinated.\nThat's not true, they're orthogonal. You can just as easily have an allocator per-thread using a callback + atomic increment method (how you're currently doing it in binaryen). Stealing chunks becomes slightly more complex, requiring a lock or CAS on the chunk linked list. I implemented tasks as a queue becomes it is the normal, simple way of doing it.\n\nI guess which is better depends on the usage patterns.\n\nYeah, ultimately I'm guessing none of this really matters, and the majority of time will be spent elsewhere. That's usually how these things work. :)\n\nAside from perf, I think your approach is more code\n\nReally? My entire example including chunk allocator, thread, thread pool and a simple task fits in 300 lines of code. In any case, I'd argue that the simplicity of the solution is more important without measurement to prove otherwise. What you have currently requires synchronization in the form of atomics, locks or condition variables in the traversal, thread, thread pool, and arena classes. What I suggested requires only a lock and CV in the queue, where synchronization is required. But let me reiterate that there's nothing special about what I've written, it's the naive, obvious way of implementing threading. Are you certain that you need to add this complexity elsewhere for performance reasons? \nThink of this from the perspective of someone who doesn't know the code as well as you do. Isn't it easier to look at code where nearly everything is known to be accessed by only one thread?\nAnyway, I think we've discussed this to death, so I'll leave it at that.\n. Looks ok to me, 0xbbe in 30-bits is:\nb    b    e\n00 0000 0000 0000 0000 1011 1011 1110\nso the full 64-bits:\n```\n                         0xbbe  0                               -1\n000000000000000000101110111110 00 11111111111111111111111111111111\n00000000 00000000 00101110 11111000 11111111 11111111 11111111 11111111\n      00       00       2e       f8       ff       ff       ff       ff\n```\nThe strange part is that 0xfb in the .s file. It should be 0xf8.\nOh, I see. The original example was { -1, 3, 0xbbe } and you changed it { -1, 0, 0xbbe }\n. > So we should fix that. I guess the semantics are the same and only the name has changed so that should be simple.\nIt switched to returning pages. But maybe binaryen was already doing that?\n. In sexpr-wasm I perform the check using integers instead of floats: https://github.com/WebAssembly/sexpr-wasm-prototype/blob/master/src/wasm-interpreter.c#L83\nThe table is sorted by the binary representation of the float, so it's a little easier to understand the comparisons.\n. sure, I'll take a look.\n. https://github.com/WebAssembly/binaryen/pull/421\n. I moved it to safe_integer, seemed to fit with the other is* bounds checks there.\n. Looks pretty good. Have you thought about how you'd manipulate the AST after it has been created? Also, personally I'd suggest something shorter than Binaryen for the prefix. But maybe that's just me. :)\n. > No, I haven't thought much about manipulation yet. Hopefully most compilers won't need it? Probably that's too optimistic ;)\nWell, if you imagine the users of the API are just producers than yeah, probably not needed. I was imagining users who will want to read a binary module and then do stuff with it.\n\nAbout the prefix, how about \"Bin\"? Or any other ideas?\n\nHow about BYE :)\n. I like BYN better. BIN looks like it could be anything, but I can't think of anything else that looks like BYN. But really, I don't think it matters much. Just like with WebAssembly, you could use Binaryen as the prefix and mostly people won't complain. :)\n. @dschuff wrap it in a macro\nedit:\n</sarcasm>\n. @kripken A quick googling found this: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=60734\n. @kripken strange, I use the same technique in sexpr-wasm for threads, and it works fine for the i686 build on my ubuntu 14.04 laptop. See https://github.com/WebAssembly/sexpr-wasm-prototype/blob/master/CMakeLists.txt#L363. Maybe the difference is using target_link_libraries instead of modifying CMAKE_EXE_LINKER_FLAGS directly?\n. > Another option, I believe they're equivalent, is !n+1, which looks even worse.\nActually, it's ~n + 1. But yeah, doesn't look very nice. :)\n. No, I guess I should probably write up some spec tests for all these.\n. Some new spec tests: https://github.com/WebAssembly/spec/pull/289\n. Have you tried using linux perf? I've found that to be a pretty great tool for profiling.\nBasics:\n$ perf record my_exe arg1 arg2\n$ perf report\n. You can also try using perf record -g ... to give you call graph information. Also make sure to hit enter to zoom into the hot function, it will annotate the source/assembly to show you the hottest instructions. It's not 100% accurate, but it should give you a pretty good idea.\n. Not sure if this helps, but here's the code where I did similar analysis for my PNaCl interpreter: https://github.com/binji/pnacl.c/blob/master/src/pn_calculate_liveness.h\nThe state stored for the pass is this:\n```\ntypedef struct PNLivenessState {\n  PNBitSet seen_values;\n  PNBitSet livein;\n  PNBitSet seen_bbs;\n  PNBasicBlockId* bb_id_stack;\n} PNLivenessState;\ntypedef struct PNLivenessRange {\n  PNBasicBlockId first_bb_id;\n  PNBasicBlockId last_bb_id;\n  PNValueId slot_id;\n} PNLivenessRange;\nPNLivenessRange* value_liveness_range;\n```\nThese are all fixed size, seen_values has 1 bit/value, and seen_bbs and livein have 1 bit/basic block. The ranges are stored at basic block granularity for simplicity. This was reducing from SSA, though, so even that was a big win. Maybe it's not as useful here?\n(All this said, it still is one of the slowest passes.)\n. It's been a while since I've looked at this code, but IIRC you don't iterate over the bits. Instead, you iterate over basic blocks (in reverse, in PNaCl IR this is the same as postorder, I believe), then each value used in that basic block. Each value is evaluated individually to determine its range over the basic blocks.\nI'm pretty sure this was the algorithm I used: https://hal.inria.fr/inria-00558509v1/document, section 5.2. (Probably should have commented that in the code)\n. Well, the bitset isn't used for the allocation, it uses the per-value liveness range for that. Not sure what to call the register allocation, but it's basically just a linear scan with no spilling (and the ranges are never split). You can see the code here: https://github.com/binji/pnacl.c/blob/master/src/pn_calculate_liveness.h#L92\nI iterate over the live ranges (which are implicitly sorted by start point), keeping track of which are active. The available slots are stored as a min heap.\n. I agree with the SO post; automatic registration in C++ seems nice on the surface, but it has always come back to bite me. Making it explicit makes it easy to tell what happens, when it happens. And you don't need any static initialization order hacks (i.e. singletons).\nIt looks like you already have an explicit list of passes in pass.cpp to run, by name -- IMO it would actually be nicer to move the names of the passes into this file so they aren't spread across multiple files.\nAnother idea: it seems like the PassRegistrar is used primarily for the benefit of binaryen-shell, so you can reference passes by name on the commandline. Why not move the name-to-pass mapping there? You could entirely remove the registrar, because it there would be no need to create a pass dynamically by name. This has other benefits as well, as you could make a parameterized pass without having to subclass to override the arguments, etc.\n. @drom You might try sexpr-wasm for this. If you run sexpr-wasm --spec foo.wast -o bar.json where foo.wast has multiple modules, it will generate a JSON file called bar.json with information about the assertions, as well as modules named bar.0.wasm, bar.1.wasm, etc.\n. No, it's a separate codebase: https://github.com/WebAssembly/sexpr-wasm-prototype/\n. sexpr-wasm does no optimization on the AST. Not sure if binaryen does by default, but I think you can disable it. Also, sexpr-wasm uses canonicalized LEB128 values by default, but I think binaryen writes out 5-byte LEB values. You can pass --no-canonicalize-leb128s to make sexpr-wasm do the same. That should get them pretty close, I think.\n. > The user can add exported functions to the EXPORTED_FUNCTIONS compiler flag\nI actually found this to be pretty tedious; I ended up writing a script to automatically generate this in sexpr-wasm -- because the format is either quoted JSON on the commandline or a JSON file passed as response file. Wish I knew about __attribute__((used)), though I don't really like having to annotate the source either... :-|\n. Just a FYI: you can also validate using the ml-proto spec interpreter or using sexpr-wasm. They should all be consistent in their behavior, so if they're not, it's a bug. :)\nThough as I mentioned to kripken, parentheses aren't allowed in the internal names (the ones that start with $) in the current spec format, so those won't even parse in anything other than binaryen.\n. Yes, AIUI x != x is true if and only if x is NaN. (Actually, I rely on this when generating the assert_return_nan checks for the spec tests.)\n. V8 5.4.9 is from earlier this month: https://github.com/v8/v8/tree/5.4.9, it should be new enough.\n. Tables and memories aren't in binary-0xb, correct? I believe sexpr-wasm master is consistent with spec master (at least it works with testsuite master). I've been working on updating sexpr-wasm to binary-0xc of the spec repo. Pretty close with the stack stuff, but still need to do globals, tables and memories.\n. @kripken: Maybe this is not so dire. You can always do the transformation, you just need to fix up the block signature later depending on its context. And even then, that's only true if you don't know the concrete type of X (i.e. if it is unreachable).\n@dschuff: Yes, wabt is strict.\n. The memory sanitizer should catch this type of bug too. Though I should mention that I've had to remove this sanitizer from Travis on wabt because it doesn't seem to work there anymore. :-|\n. Yes, wabt should reject multiple memories or tables, whether imported or defined.\n. Probably worth adding a spec test that would catch this bug too.\n. @rongjiecomputer You may want to try the spec interpreter or wabt for learning the text format. Binaryen currently only supports the s-expression style for functions, which is non-canonical.\n. I guess this should be closed now that we've decided on full typechecking?. Read recently that you can ignore whitespace changes by adding &w=1 to the URL: e.g. https://github.com/WebAssembly/binaryen/pull/877/files?diff=unified&w=1\n:-). @jgravelle-google the order doesn't flip, so\n(module\n  (func\n    (drop (i32.add (f32.const 0) (br 0)))))\ndesugars to\n(module\n  (func\n    f32.const 0\n    br 0\n    i32.add\n    drop))\nwhich validates because the type stack at i32.add has [any, any]. The other order desugars to\n(module\n  (func\n    br 0\n    f32.const 0\n    i32.add\n    drop))\nwhich does not validate because the stack has [any, f32].. Cool! Just took a quick glance, but in general I think this API looks nicer to use.. Honestly, I don't write too much JavaScript, so I hope I didn't lead you astray. :-). See https://en.wikipedia.org/wiki/Erase%E2%80%93remove_idiom.. IIRC, using sse2 is required on x86 32-bit so it performs the correct floating point arithmetic. This is why I turned it on in wabt, anyway.. Perhaps there's a clever way to do this, but I ended up compiling an executable and using file to do this in wabt: https://github.com/WebAssembly/wabt/blob/master/CMakeLists.txt#L116. Yeah, we noticed this yesterday... not sure what's going on.. Just curious, why doesn't this fail the same way with the WebAssembly backend? Does it not run the CFGSimplify pass? Or is it already wired into some backend-specific hook?. @kripken see #987 :wink:. On Windows, I assume? Looks like that filename is 215 chars, so you should be able to fit it if you clone to a directory with a shorter path. Often when this happens I use subst to create a new drive mapping to that directory. That way the directory name is as short as possible.. Yes, previously infinity or inf was allowed, but it is simpler to just allow one.. Isn't the unreachable needed to properly typecheck?\nFor example:\n(func (result i32)\n  call $abort\n  ;; fails to typecheck, since $abort doesn't return i32\n). Good point. Is this a significant size?\nSeems like it would be best to handle in LLVM because it has more information. How would the wasm backend annotate the function to give to binaryen?. Yeah, I had a similar bug. Seems like kind of a dumb rule tbh, but it's not hard to support.. Yeah, I found that at least some C++11 type traits are missing on trusty (libstdc++ 4.8, I believe).. Yeah, it's not super explicit in that doc. But the idea is that nothing can move past an atomic access in either direction.. Can you include a link to the generated wasm file? That will make it easier to see what is failing.. There are a number of issues with this file, so it's hard to tell. Just trying to read it via wast2wasm or wasm-objdump fails because of an out-of-range index on a function call. Disabling that error manually, there seems to be issues with the name section too. Disabling that produces a huge number of type checking errors:\nlibc.wasm:0003aa5: error: type stack size too small at call. got 2, expected at least 4\nlibc.wasm:0003ab4: error: type stack size too small at call. got 2, expected at least 4\n...\nCross-referencing these against wasm-objdump output:\n003a82 func[0]:\n 003a8a: 02 7f                      | block i32\n 003a8c: 41 00                      |   i32.const 0\n 003a8e: 41 00                      |   i32.const 0\n 003a90: 28 02 04                   |   i32.load 2 4\n 003a93: 41 10                      |   i32.const 16\n 003a95: 6b                         |   i32.sub\n 003a96: 22 01                      |   tee_local 1\n 003a98: 36 02 04                   |   i32.store 2 4\n 003a9b: 20 01                      |   get_local 1\n 003a9d: 20 00                      |   get_local 0\n 003a9f: 28 02 3c                   |   i32.load 2 60\n 003aa2: 10 ee 09                   |   call 1262\n 003aa5: 36 02 00                   |   i32.store 2 0\n 003aa8: 41 06                      |   i32.const 6\n 003aaa: 20 01                      |   get_local 1\n 003aac: 41 00                      |   i32.const 0\n 003aae: 11 02 00                   |   call_indirect 2 0\n 003ab1: 10 cc 01                   |   call 204\n 003ab4: 21 00                      |   set_local 0\n 003ab6: 41 00                      |   i32.const 0\n 003ab8: 20 01                      |   get_local 1\n 003aba: 41 10                      |   i32.const 16\n 003abc: 6a                         |   i32.add\n 003abd: 36 02 04                   |   i32.store 2 4\n 003ac0: 20 00                      |   get_local 0\n 003ac2: 0b                         | end\n 003ac3: 0b                         | end\nHere are the relevant signatures:\n```\n - func[204] sig=31\n - func[1262] sig=78\n\ntype[31] (i32, i32, i32, i32) -> i64\ntype[78] (f64, i32, i32, i32) -> i32\n```\n\nIf I had to guess, I think your linker is not properly remapping function or type indexes.. I don't think the bad indexes can be caught any earlier than they currently are. There's nothing wrong with them as they are defined, just how they are actually used.. I don't really know enough about Binaryen to say if there's a problem here, but it seems this issue is stale. @DiamondLovesYou, feel free to reopen if this is in error.. I think some folks are guessing that it will have some benefit, but we would like to gather some data, which is why it would be useful to do experiments via binaryen if possible.\nIn particular, we were curious about the benefits of adding the pick operator, and fully generalized block signatures. The benefits of multiple return values is clearer.. I don't know anything about java bytecode, but I only see dups: https://en.wikipedia.org/wiki/Java_bytecode_instruction_listings. Still may be useful for experimentation, though.. The spec for the text format is here: http://webassembly.github.io/spec/text/index.html.\nIn general, the text format allows everything to be specified in any order. The only constraint is that imports must be specified before any non-imports.. Yep :-)\n@rossberg-chromium discussed it at the most recent WebAssembly CG meeting earlier this week. It is basically feature-complete, minus a few minor appendices.. @jayphelps I see. I don't really know much about binaryen, but it looks like it could just be added as another pre-parse, e.g. preParseTables.. @metalpavel you may want to follow along with the non-trapping-float-to-int proposal too. They're not available yet, but should help with this case.. Ah, I see the problem. wasmdump is the old name, the new name is wasm-objdump. wast2wasm won't even generate file since it isn't using the new block signature syntax:\ntest.wast:5:21: error: syntax error, unexpected VALUE_TYPE, expecting )\n    (block $label$2 f32\n                    ^^^\nFixing that produces the following error:\ntest.wast:6:8: error: type mismatch in block, expected f32 but got i32.\n      (i32.trunc_u/f64\n       ^^^^^^^^^^^^^^^\nThis error is correct; unreachable makes the stack polymorphic, so i32.trunc_u/f64 pops an f64 and pushes an i32. But then block wants an f32, so it is invalid.\nWe can generate the invalid wasm file with wast2wasm --no-check, then try to read it using wasm-objdump. This works, since wasm-objdump doesn't validate:\n000028 func[0]:\n 00002a: 02 7d                      | block f32\n 00002c: 00                         |   unreachable\n 00002d: ab                         |   i32.trunc_u/f64\n 00002e: 0b                         | end\n 00002f: 0b                         | end\nwasm2wast does validate, and produces the same error as above:\ntest.wasm:000002e: error: type mismatch in block, expected f32 but got i32.. It's not clear to me when you say \"valid\" whether you're referring to valid wasm or valid binaryen ir -- but neither of those examples are valid wasm. The stack is only valid at the end of a block if the contents of the stack match the block's signature. Since the signature in both cases is required to be empty, there can't be an i32 on the top of the stack at the block exit, even if the stack is polymorphic.. Hmm, maybe those tests were from before block signatures were added. Btw, if i32 format isn't allowed anymore, it has to be if (result i32).. The PR is more readable like this (no whitespace in diffs): https://github.com/WebAssembly/binaryen/pull/1158/files?w=1. Looks like the ppc64le build on master is timing out after 6 hours.. Hm, don't know what changed but it looks like those builds are finishing now.. > I haven't tried to actually run code, not sure if there is a wasm impl to test on.\nNot yet, unfortunately. I am working on a spec interpreter change for it, but I'm no ocaml expert, so it's taking time. I was thinking I might add it to wabt first since I know how that works. :-)\n\nAre there any notable differences between Atomics.* and their wasm equivalents that we should be aware of?\n\nOnly that there are 64-bit atomics. Otherwise they are the same (by design).. This is a bit surprising to me, since wabt's validation is actually one of the faster parts of loading. I understand binaryen's validation is different, but I assumed it was still single pass, right?\nI annotated wasm2wat w/ timings when loading tanks:\nread file: 0.0144852s\nread binary: 0.684837s\nvalidate: 0.190429s\napply names: 0.116855s\nwrite wat: 1.28688s\nThese probably could be a lot faster actually... :-} But the point is that validation is actually pretty small.. Yeah, all single-threaded for now. It's also worth noting that when I enable expression folding it gets quite a bit slower (unoptimized, so probably could improve). I assume binaryen is doing something like this when creating the IR (what I call \"read binary\" here), so maybe that explains some additional speed differences.\nread file: 0.0145758s\nread binary: 0.672801s\nvalidate: 0.158918s\napply names: 0.0924712s\nwrite wat: 2.66662s. Turning stuff like this:\ni32.const 0\ni32.const 1\ni32.add\ninto this:\n(i32.add (i32.const 0) (i32.const 1))\nThat's what the spec calls it, anyway: https://webassembly.github.io/spec/text/instructions.html#folded-instructions. In the past I've done it this way:\nenum BitfieldValues { Zero = 1 << 0, One = 1 << 1, Two = 1 << 2 };\ntypedef uint32_t Bitfield;\nLooks like that is covered as TestClassicMaskWithTypedef.. There is a (small) potential danger defining it in the base class, in that if you add an intermediary class you'll need to define super there as well, or it will silently do the wrong thing. Not sure if that's common in Binaryen though.. > This deletes any passes stored, which is a good idea since those are pointers which would otherwise leak, but seems to be fouling up the returned object.\nAh, looks like PassRunner needs a copy constructor. My guess is that gcc/clang are always optimizing using NRVO so the default copy constructor is never called.\n\nmsvc is probably just especially prudent/pedantic, ...\n\nYes, I've seen similar things w/ MSVC and w/ ubsan. If you think about it, it makes sense. The MSVC vector has an operator[] that is doing bounds checks. It doesn't know that you're just taking the address of the end, it still has to access the end value.\nYou should be able to move the arithmetic outside of the [] to workaround, I think:\nstd::move(&o[start] + MaxLEB32Bytes, &o[start] + MaxLEB32Bytes + size, &o[start] + sizeFieldSize);. > It looks invalid, in particular ... That is missing an open paren.\nIt's valid in the flat text format. Looks like output from wasm2wat. You can fold it so it can be parsed by binaryen tools by passing the --fold-exprs flag.. Wabt uses the (; N ;) comment style for this. I think it is a little nicer, since you can put it next to the name.. Me too, just thought I'd mention it. :-). Looks like it upgraded from flake8-3.4.1 to flake8-3.5.0. Probably would be good to pin it if possible.. It does seem like a bug, but perhaps it's a bug in the error reporting? Is there anything uninitialized in TranslateToFuzzReader::makeConst? Maybe the optimizer is making it lose track of where the uninitialized variable is defined.. Well, I already landed it in wabt: https://github.com/WebAssembly/wabt/pull/661. > Noted, wasm2wat issue again, it has different ordering than wasm-dis.\nYeah, wasm2wat writes everything in the order found in the binary file, for consistency. The text format allows for nearly everything to be in any order, with the exception of imports, which must come before all other functions, globals, memories, or tables.. Or perhaps just automatically convert the unsigned atomic RMW result to unsigned by using the new extend instructions. That was the intention, since there was pushback from the CG about adding so many signed atomic instructions.. There are no f32/f64 atomic ops in wasm currently, so it's probably best not to add these to binaryen.. This doesn't seem to support the inline format: (call_indirect (param i32) (result i32) ...) etc.. You can name function imports, see http://webassembly.github.io/spec/appendix/custom.html#function-names. It maps names to function indices, which includes the function imports first.. > BinaryenAddGlobalExport (though not supported in the MVP)\nGlobal imports and exports are supported in the MVP as long as they're immutable.. Yeah, there are no proposals currently. Though they've come up a number of times at the CG recently. I personally think they'd help with a current limitation of WebAssembly, where we require a copy-in/copy-out for any memory buffers that live outside linear memory (such as video or audio buffers).\nI think the biggest issue is that having more than one memory is difficult for producers (C/C++ don't really make this easy, though there is some limited support for segmented memory AIUI), and for consumers (many engines pin the memory base pointer for quick lookup).. > What does \"NFCI\" mean?\nThanks for asking @kripken, I assumed it was \"Not for check-in\" which has a very different meaning! :-). Might be nicer to have it inline at the location in the source, using diagnostic pragmas and checking the version via a predefined macro.. > Apologies in advance as I'm just not sure where a general WebAssembly dev chat might be taking place.\nWe chat on irc some. It's mostly active weekdays, during US workday hours. It would be cool to have more folks on at other times too, though!. It's come up that the exception handling proposal can probably be extended to support stack switching. There's no concrete proposal, though.. > Where would be the place to talk with or perhaps even collaborate with Go folks on this issue?\nThey mostly seem to be here: https://github.com/golang/go/issues/18892\nAnd we have regular WebAssembly Community Group meetings. If you have a proposal idea, it may be worthwhile to bring it up there.. > We should check if there is a spec test for this...\nThere's this one: https://github.com/WebAssembly/spec/blob/master/test/core/globals.wast#L50. This test is basically the same: https://github.com/WebAssembly/spec/blob/master/test/core/globals.wast#L119\n(assert_invalid\n  (module (global i32 (get_global 1)) (global i32 (i32.const 0)))\n  \"unknown global\"\n)\nIt probably could be clearer though, because this looks as though you can't reference a global with a higher index. That used to be true (pre MVP) but we switched to only allowing imported globals at some point.. This is allowed by WebAssembly, see this set of tests for example. This seems to be a binaryen restriction.. > This was disallowed earlier in the wasm spec process, right?\nMaybe...? Hard to remember what's changed over time. :-). I'm guessing @kripken will be able to respond better here, but I think the basic problem is that s2wasm is performing some of the responsibilities of linking by assigning the stack pointer a memory location (4). It is assuming that before any code is run the stack will be set up properly, allocating memory and setting the value at address 4 to the top of the stack.\nwasm-interp doesn't do any of this, and only runs exactly the code in the .wasm module, so when it reads the stack pointer at address 4 it gets 0. It then tries to allocate more space on the stack (subtracting 16) but ends up underflowing the stack pointer.\nIn any case, we're trying to move away from s2wasm use. The upstream LLVM backend can now produce .wasm files directly, which follow the behavior as outlined in tool-conventions. Work is also ongoing with using lld as the WebAssembly linker.\nEven with those tools, though, I believe there is an implicit assumption that the stack has been set up before any code is run. @sbc100 is that correct?. Yeah, UBSan started failing on the wabt bots, since I was pulling clang-3.6 and travis recently updated to clang-5.0. I was using ubuntu-toolchain-r-test too, perhaps that broke it.\nThat said, recent runs seem to be fixed on wabt ubsan, so maybe the Travis infra folks fixed it.. I took this as an opportunity to test out wasm2c... :-)\nIf we take a few examples:\n```wasm\n  (func (export \"f\") (param i32) (result i32)\n    (if (result i32)\n      (get_local 0)\n      (i32.const 42)\n      (i32.const 24)))\n(func (export \"g\") (param i32) (result i32)\n    (block\n      (block\n        (br_table 0 1 (get_local 0)))\n      (br 1 (i32.const 24)))\n    (br 0 (i32.const 42))\n  )\n(func (export \"h\") (param i32) (result i32)\n    (select\n      (i32.const 42)\n      (i32.const 24)\n      (get_local 0)))\n```\nAnd compile them with wasm2c, we get:\n```c\nu32 f(u32 p0) {\n  u32 i0;\n  i0 = p0;\n  if (i0) {\n    i0 = 42u;\n  } else {\n    i0 = 24u;\n  }\n  return i0;\n}\nu32 g(u32 p0) {\n  u32 i0;\n  i0 = p0;\n  switch (i0) {\n    case 0: goto B1;\n    default: goto B0;\n  }\n  B1:;\n  i0 = 24u;\n  goto Bfunc;\n  B0:;\n  i0 = 42u;\n  goto Bfunc;\n  Bfunc:;\n  return i0;\n}\nu32 h(u32 p0) {\n  u32 i0, i1, i2;\n  i0 = 42u;\n  i1 = 24u;\n  i2 = p0;\n  i0 = i2 ? i0 : i1;\n  return i0;\n}\n```\nIf you run this in compiler explorer, even with just -O1 they all generate the same function:\nasm\n        test    edi, edi\n        mov     ecx, 24\n        mov     eax, 42\n        cmove   eax, ecx\n        ret\nRunning the same thing through v8 (d8 --print-wasm-code) gives the same function each time as well:\nasm\n0xd9c54c11aa0     0  83f800         cmpl rax,0x0\n0xd9c54c11aa3     3  0f850a000000   jnz 0xd9c54c11ab3  <+0x13>\n0xd9c54c11aa9     9  b818000000     movl rax,0x18\n0xd9c54c11aae     e  e905000000     jmp 0xd9c54c11ab8  <+0x18>\n0xd9c54c11ab3    13  b82a000000     movl rax,0x2a\n0xd9c54c11ab8    18  c3             retl\n0xd9c54c11ab9    19  90             nop\n0xd9c54c11aba    1a  6690           nop\n. @kripken I'm not even close to an x86 expert, but my understanding is that cmov is not always a clear winner vs branch+mov. In this case cmov is probably a better choice, but in a larger function it increases register pressure and has longer dependency chains.. I'm no C++ language lawyer, but I believe this is UB. This SO answer gives some clues. Basically, the lifetime of the unique_ptr object ends when its lifetime ends, which is at the start of the call to the destructor. At that point, accessing members of the object is UB.. It seems much of the complexity here comes from having ThreadPool auto-initialization on ThreadPool::get. Even if you kept a global ThreadPool, you could probably simplify a lot by requiring the user to explicitly initialize the global ThreadPool object.. Personally, I like Chromium style, but I imagine not everyone knows what it looks like. Maybe it would be good to create a separate commit somewhere with all the C++ files updated so they can see what it would look like?. WebAssembly threading support is still in development, so it is not enabled by default in any browser. There has been some work done, see this page for more info.\n. I wrote this hack originally for wabt, so I'm definitely happy to see a better solution. But when I tried using CMAKE_SYSTEM_PROCESSOR with a i686 target, it still gives x86_64.. @jbeich I see, thanks for the info!. Yes, the files are the same. The first is using the folded format and the second is using the flat format. Binaryen only supports the folded format.\nYou can use wat-desugar to convert between the two:\n```sh\n$ cat test.wat\n(func $_xor (; 0 ;) (param $0 i32) (param $1 i32) (result i32)\n(local $2 i32)\n;;@ xor.c:3:0\n(set_local $2\n(i32.xor\n(get_local $1)\n(get_local $0)\n)\n)\n(get_local $2)\n)\n$ wat-desugar test.wat\n(module\n  (func $_xor (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    get_local $1\n    get_local $0\n    i32.xor\n    set_local $2\n    get_local $2)\n  (type (;0;) (func (param i32 i32) (result i32))))\n$ wat-desugar test.wat --fold\n(module\n  (func $_xor (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (set_local $2\n      (i32.xor\n        (get_local $1)\n        (get_local $0)))\n    (get_local $2))\n  (type (;0;) (func (param i32 i32) (result i32))))\n```\nwasm2wat also supports the --fold flag, to read a .wasm file into the folded text format.. The spec interpreter has the same error:\n```\n$ cat test.wat\n(global $hello i32 (i32.const 1))\n(memory 1)\n(data (get_global $hello) \"hi\")\n$ ./wasm test.wat\ntest.wat:3.19-3.25: invalid module: unknown global 0\n```\nBut if you import the global it works:\n```\n$ cat test2.wat \n(global $hello (import \"spectest\" \"global_i32\") i32)\n(memory 1)\n(data (get_global $hello) \"hi\")\n$ ./wasm test2.wat\n```. There's even a test for this case.\nHm, though now that you mention it, that rule makes sense for preventing recursive global definitions (and is defined in the spec here), but that uses a different frame F_im for evaluation (see step 5.a and 5.b).\nBut the offset evaluation should be using F instead (pushed in step 8).\n@rossberg, am I missing something, or is this a bug in the spec?. @tbodt you can also compile the function in its own module, export it, and put it in a table. Then the original module can use call_indirect to call this function.. @jfbastien I'm definitely not up-to-speed on WebAssembly licensing stuff -- but happy to add it to the agenda if someone can drive the conversation. :-). @kripken Thanks, I've added an agenda item here: https://github.com/WebAssembly/meetings/pull/296. We have a pretty full meeting, so it may end up pushed to the next one.. It came up in the CG here as well: https://github.com/WebAssembly/meetings/blob/master/2018/CG-01-26.md#contribution-policies-and-repos-for-tools-targeting-webassembly\nWith slides: https://docs.google.com/presentation/d/1sgxnT7pD5bTfmPv6MLnFlzIcszUDyTc9SKiSV6LZAJk/edit?usp=sharing\nDoesn't seem like there was a follow-up.\n@dschuff ?. > Meanwhile, is there some \"official\" WASM interpreter in C or C++?\nThe WebAssembly reference interpreter is written on OCaml: https://github.com/WebAssembly/spec/tree/master/interpreter\nBinaryen and wabt also have interpreters.\n\nAnother possibility may be to implement emitting WASM on my own,\n\nThis is not as difficult as you might expect; WebAssembly is a relatively simple format. See, for example, waforth which JITs Forth code.. > The LLVM wasm backend compiles LLVM IR to wasm, while Binaryen can also read wasm. \nThen why don't we make a tool that reads wasm into LLVM IR?\n\nLLVM codegen takes much more memory and is much slower than Binaryen's optimizations, because of how the two are designed. \n\nThis is definitely an important consideration, but remember that we are talking about an offline tool run by the developer. WebAssembly necessarily depends on the wasm producer to optimize the output so the consumer can be simpler. So it's important to bias toward spending more time optimizing on the developer's machine than to push that time to the client.\n\nThe LLVM wasm backend's internal IRs are less close to wasm than Binaryen's IR is.\n\nThat's mostly true for now, but for how long? We can represent multi-value in LLVM IR via SSA renaming, but how do we handle it in binaryen IR?\n\nIt also can't do optimizations like Binaryen's ctor-eval\n\nIs there a fundamental limitation in LLVM that prevents this? Or is it just that no one has done the work?. > I've tried to avoid adding WABT for example because it adds another megabyte or so of JS just for printing text format.\nCurrently the JS build of wabt includes a lot of extra cruft -- it wouldn't be too hard to separate some of it out to slim down the library.. @MaxGraey that's a bit outside the scope of wasm-objdump, in my opinion. What you'd probably want is something more like compiler explorer where you can provide wasm input and choose the VM to produce assembly output.. @kripken Hm, not so sure now that I take a quick look. It seems at least 350k or so is the re2c generated lexing function! Haven't really dug into the rest, but it looks like the callback-based parsing might be bloating the resulting library too.. > Most things are working pretty well and most of the remaining spec tests are exercising \"interesting\" aspects of the harness they're expected to be run under (multiple modules, etc)\nNone of the spec tests should be testing behavior of the harness, but some of them do require multiple modules to test proper linking behavior, validation, etc.. I guess it depends on how you're planning to use wasm2asm/wasm2js. If it's traditional emscripten-style where you're converting a monolithic app to JS, then yeah, probably doesn't matter. But in the future I imagine we'll see a lot more wasm module components, so the proper linking behavior will be important.. > I think VMs always implement it that way\nFor baseline compilers, I think you're right. But I know for example that v8's TurboFan based wasm compiler doesn't always use a jump table; there are some heuristics, but no deopts.. I don't know much about binaryen, but the atomic prefix will work the same way as the 0xfc prefix, so you can probably use that as a guideline.. 3435973836 => 0xcccccccc, 14757395258967641292 => 0xcccccccccccccccc. Those are values that MSVC uses to represent uninitialized stack memory, so I suppose istringstream is not even touching the values.\nI'd guess you'd have to check istr.fail() afterward instead.. There are some spec tests that describe expected behavior when parsing out-of-range constants: https://github.com/WebAssembly/spec/blob/master/test/core/const.wast\nSo yeah, it should be a parse error.. Compiler Explorer is often useful for examples like this:\ngcc:\nasm\nrem256_s(int):\n  mov edx, edi\n  sar edx, 31\n  shr edx, 24\n  lea eax, [rdi+rdx]\n  movzx eax, al\n  sub eax, edx\n  ret\nclang:\nasm\nrem256_s(int):                           # @rem256_s(int)\n        mov     eax, edi\n        sar     eax, 31\n        shr     eax, 24\n        add     eax, edi\n        and     eax, -256\n        sub     edi, eax\n        mov     eax, edi\n        ret. > and numerous tests now mix stack/sexprs which binaryen doesn't support.\nYou could use wat-desugar --fold to convert from flat format to folded format, if the flat format is not essential to the test. It would be a bit tedious, since it currently only works on individual modules, however.. Yes, it will remove comments (it'd be nice if the wabt parser kept them around for tools like this). It shouldn't remove blocks though; if you have a repro case I'd like to fix that.\nBut yeah, you can't just run it directly, but you could use it to help fold code rather than doing it by hand.. > What actually happened is that it put the export outside instead of inline\nOh, there should be an option for that, but it looks like it's only in wasm2wat and not wat-desugar. :sweat_smile: . FYI: there was some discussion about a similar topic here: https://github.com/WebAssembly/spec/issues/617. Andrew suggested that we should be able to do what you described here, something like (call $\"foo\"). Andreas suggested instead that we provide an annotation to create the correct name section info: (call $foo (@name \"foo\")). Anyway, if you have opinions about either of these, feel free to mention it on that issue.. Both of these files also have other issues too:\nh01.wasm has a code section that is too short (9 bytes).\n```\n$ wasm-objdump h01.wasm -s\nh01.wasm:   file format wasm 0x1\n0000018: error: invalid local declaration count 127, only 6 bytes left in section\n0000020: error: invalid section code: 126; max is 11\nContents of section Type:\n000000a: 0160 0001 7f                             .`...\nContents of section Function:\n0000011: 0100                                     ..\nContents of section Code:\n0000015: 0107 7fff ffff 7f7f 7e                   ........~\n```\nfunction 2 in h02.wasm has a local declaration of type 0x40:\n```\n$ wasm-objdump h02.wasm -d\n0000129: error: expected valid local type\n000029a: error: invalid section size: extends past end\n[---snip---]\n00011d func[2]:\n 00011f: 02 7f                      | local[0..1] type=i32\n 000121: ff ff ff ff 03 7c          | local[2..1073741824] type=f64\n```. I did something similar for the wabt releases here in case you wanna compare, though I'm no expert here :-)\nAnyway, this change lgtm.. You can use the online wat2wasm to convert it. Make sure to check the threads checkbox first.\nYou need to change the $0 to a 0 here too:\n(export \"memory\" (memory $0))\nYou can also convert it to the folded format so binaryen can parse it by using the wat-desugar tool in wabt:\nsh\n$ wat-desugar threads.wat --fold -o threads.folded.wat --enable-threads\nThis produces the following output:\nwasm\n(module\n  (import \"env\" \"memory\" (memory (;0;) 1 1 shared))\n  (export \"memory\" (memory 0))\n  (export \"tryLockMutex\" (func $tryLockMutex))\n  (export \"lockMutex\" (func $lockMutex))\n  (export \"unlockMutex\" (func $unlockMutex))\n  (func $tryLockMutex (param $mutexAddr i32) (result i32)\n    (i32.eqz\n      (i32.atomic.rmw.cmpxchg\n        (get_local $mutexAddr)\n        (i32.const 0)\n        (i32.const 1))))\n  (func $lockMutex (param $mutexAddr i32)\n    (block $done\n      (loop $retry\n        (br_if $done\n          (call $tryLockMutex\n            (get_local $mutexAddr)))\n        (drop\n          (i32.atomic.wait\n            (get_local $mutexAddr)\n            (i32.const 1)\n            (i64.const -1)))\n        (br $retry))))\n  (func $unlockMutex (param $mutexAddr i32)\n    (i32.atomic.store\n      (get_local $mutexAddr)\n      (i32.const 0))\n    (drop\n      (atomic.wake\n        (get_local $mutexAddr)\n        (i32.const 1))))\n  (type (;0;) (func (param i32) (result i32)))\n  (type (;1;) (func (param i32)))). Those instructions are not currently implemented in v8, but they will be before the feature is enabled. Many users don't see this issue because emscripten doesn't generate this instruction, and instead calls out to JavaScript's Atomics.wait and Atomics.wake (now called Atomics.notify).\nYou can test this on Firefox instead, see https://github.com/kripken/emscripten/wiki/Pthreads-with-WebAssembly for details.. My guess is that the binaryen parser doesn't support that syntax. The original syntax for call_indirect was:\nwasm\n(call_indirect (type $sig) ...)\nBut we added support for inline signatures later. You can use the wat-desugar tool in wabt to convert it to a form that binaryen should accept:\nsh\nwat-desugar old_file.wat --fold -o new_file.wat. This is very nice! Perhaps this is a separate issue, but I still think it would be better to check that the identifier actually matches the keyword.. Right, I can see this being performance sensitive, but I don't know that a tool/library should make the choice of sacrificing correctness for performance. I'd think it would be nice to have a flag at least, preferably with the default being to check. Otherwise it's very easy to have text files that work in binaryen, but don't work with any other tool.. Probably should change .clang-format for this too (I assume there's an option somewhere). This module is already invalid; it should have an i32 return value.. I see -- I didn't realize the binaryen validator was more permissive than WebAssembly. Doesn't that mean that binaryen can produce invalid wasm files?. This might add some global constructors, which may be undesirable (for example, Chromium tries to avoid them to improve startup speed). Probably not a big deal for a few names, but worth keeping in mind for things like this.. > I guess select in this case also faster than if-return\nI tested this out in v8 using the baseline compiler (liftoff) and the optimizing compiler (turbofan) with the following source:\n```wasm\n(func (export \"select\") (param i32) (result i32)\n  i32.const 1\n  i32.const 2\n  local.get 0\n  select\n)\n(func (export \"if\") (param i32) (result i32)\n  local.get 0\n  if\n    i32.const 1\n    return\n  end\n  i32.const 2\n)\n(func (export \"ifelse\") (param i32) (result i32)\n  local.get 0\n  if (result i32)\n    i32.const 1\n  else\n    i32.const 2\n  end\n)\n(func (export \"brif\") (param i32) (result i32)\n  i32.const 1\n  local.get 0\n  br_if 0\n  drop\n  i32.const 2\n)\n```\nLiftoff generates the following (with the function prologue and epilogue removed for easier reading)\n```asm\nselect:\n0xa42f72d3f25    25  b902000000     movl rcx,0x2\n0xa42f72d3f2a    2a  ba01000000     movl rdx,0x1\n0xa42f72d3f2f    2f  85c0           testl rax,rax\n0xa42f72d3f31    31  0f8405000000   jz 0xa42f72d3f3c  <+0x3c>\n0xa42f72d3f37    37  e902000000     jmp 0xa42f72d3f3e  <+0x3e>\n0xa42f72d3f3c    3c  8bd1           movl rdx,rcx\n0xa42f72d3f3e    3e  8bc2           movl rax,rdx\nif:\n0xa42f72d3e65    25  85c0           testl rax,rax\n0xa42f72d3e67    27  0f8431000000   jz 0xa42f72d3e9e  <+0x5e>\n0xa42f72d3e6d    2d  b801000000     movl rax,0x1\n...duplicated epilogue...\n0xa42f72d3e9d    5d  c3             retl\n0xa42f72d3e9e    5e  b802000000     movl rax,0x2\nifelse:\n0xa42f72d3dc5    25  85c0           testl rax,rax\n0xa42f72d3dc7    27  0f840a000000   jz 0xa42f72d3dd7  <+0x37>\n0xa42f72d3dcd    2d  b901000000     movl rcx,0x1\n0xa42f72d3dd2    32  e905000000     jmp 0xa42f72d3ddc  <+0x3c>\n0xa42f72d3dd7    37  b902000000     movl rcx,0x2\n0xa42f72d3ddc    3c  8bc1           movl rax,rcx\nbrif:\n0xa42f72d3d05    25  85c0           testl rax,rax\n0xa42f72d3d07    27  0f8431000000   jz 0xa42f72d3d3e  <+0x5e>\n0xa42f72d3d0d    2d  b801000000     movl rax,0x1\n...duplicated epilogue...\n0xa42f72d3d3d    5d  c3             retl\n0xa42f72d3d3e    5e  b802000000     movl rax,0x2\n```\nTurbofan generates the following:\n```asm\nselect:\n0xa42f72d4067     7  83f800         cmpl rax,0x0\n0xa42f72d406a     a  0f850a000000   jnz 0xa42f72d407a  <+0x1a>\n0xa42f72d4070    10  bb02000000     movl rbx,0x2\n0xa42f72d4075    15  e905000000     jmp 0xa42f72d407f  <+0x1f>\n0xa42f72d407a    1a  bb01000000     movl rbx,0x1\nif:\n0xa42f72d4027     7  83f800         cmpl rax,0x0\n0xa42f72d402a     a  0f850a000000   jnz 0xa42f72d403a  <+0x1a>\n0xa42f72d4030    10  b802000000     movl rax,0x2\n...duplicated epilogue...\n0xa42f72d4039    19  c3             retl\n0xa42f72d403a    1a  b801000000     movl rax,0x1\n0xa42f72d403f    1f  ebf4           jmp 0xa42f72d4035  <+0x15>\nifelse:\n0xa42f72d3fe7     7  83f800         cmpl rax,0x0\n0xa42f72d3fea     a  0f850a000000   jnz 0xa42f72d3ffa  <+0x1a>\n0xa42f72d3ff0    10  bb02000000     movl rbx,0x2\n0xa42f72d3ff5    15  e905000000     jmp 0xa42f72d3fff  <+0x1f>\n0xa42f72d3ffa    1a  bb01000000     movl rbx,0x1\nbrif:\n0xa42f72d3fa7     7  83f800         cmpl rax,0x0\n0xa42f72d3faa     a  0f850a000000   jnz 0xa42f72d3fba  <+0x1a>\n0xa42f72d3fb0    10  b802000000     movl rax,0x2\n...duplicated epilogue...\n0xa42f72d3fb9    19  c3             retl\n0xa42f72d3fba    1a  b801000000     movl rax,0x1\n0xa42f72d3fbf    1f  ebf4           jmp 0xa42f72d3fb5  <+0x15>\n```\nIn both cases the early return generates more code, but the generated code is nearly identical and likely to have no effect on performance.. > Just out of curiosity, is the local name requirement only a requirement of Binaryen (since obviously it only has namespaces and not index spaces) or is it also a requirement of the wasm text format?\nThe text format requires it:\n\nAn identifier context is well-formed if no index space contains duplicate identifiers.\n\nBut the custom section does not:\n\nEach index must be unique, but the assigned names need not be.. There are explicit tests in the spec repo that disallow these transformations, see https://github.com/WebAssembly/spec/blob/master/test/core/float_exprs.wast.. > Hmm, may I ask why this all legalized for LLVM but not for wasm?\nnan * -1 produce nan but -nan => -nan. That's main reason?\n\nSorry, was on vacation. The difference is that the nan bitpattern changes. fxx.neg will only flip the sign bit, but fxx.mul (and other operators) will produce an arithmetic nan, which is a quiet nan with an indeterminate sign bit. LLVM can optimize this because AIUI the C language doesn't say anything about\nnan bitpatterns.. No, the user of LLVM is operating with a different set of assumptions. If they care about nan bitpatterns, they know that they can't use LLVM for this (at least by default).. I don't know of any test suites you can use, but there's enough code here that having some simple tests would be useful. The existing usage in the codebase likely doesn't stress the edge cases, so a future user might get tripped up.. I think this is a good optimization, but I do think it would be better if it could handled by the original wasm producer, rather than as a separate pass in Binaryen. I understand that, at least in LLVM, some of the information is lost by the time the wasm is being generated. But generally that information is known (in the form of pointer to memory region plus member offset, etc), and seems like it could be propagated through the system.. > In C, the problem is that a program may assume a pointer may overflow, and that that is valid (!).\nAre you sure? That seems like it would be undefined behavior to me.. The ordering is just a historical accident of how @titzer added the opcodes to the implementation, IIRC.\n. The v8 source calls it I64SConvertI32 for example, but it maps cleaner to the .wast format (i64.convert_s/i32) if you call it I64ConvertSI32\n. I thought his response was pretty clear. memory's pointer must be aligned to at least a double, but there's no guarantee that the vector's allocator will give that. He's optimistically assuming that allocating a \"large enough\" buffer will give at least sizeof(double) alignment.\n. 1. Yes, he mentioned that too. \"We could allocate sizeof(double) extra and realign, but that breaks down when you resize causing a realloc which is now unaligned.\"\n2. It looks like get and set check that the \"address\" is aligned, but this is really just an index into the vector. So they won't work properly if memory's pointer is unaligned.\n. 1. That's a good question, not sure why 4096. I guess it just needs to be big enough that the allocator's fixed-block sub-allocator isn't used (although I bet those would be 8-byte aligned too).\n2. You could, I suppose. I'd find it confusing to have an alignment mismatch between wasm's memory and the host machine though.\n. always true?\n. it's still LEB128. 128 refers to the base, not the length of the value.\n. i32.const and i64.const should be sign-extended LEBs.\n. Not sure, but shouldn't this be T&&?\n. It's a pretty common technique in C/C++ API design. It makes it much easier to understand the call site:\nread_file(\"foo.bar\", false, true); // what does this mean?\nvs.\nread_file(\"foo.bar\", kAsText, kDebug);\n. Specifically, it is required to be a sign-extension of the value's sign bit, up to but not including the high bit of the final byte. So for a 32-bit value, there are 7 * 5 == 35 bits of data possible, but only 32 are valid. So the most significant byte of an encoded 5-byte LEB128 must be either 0b00000xxx or 0b01111xxx. If the LEB128 value is encoded in fewer than 5 bytes, then the sign bit is always 0b0100000, so no sign-extension is necessary.\n. Seems strange to not just use an enumeration here. Is this to prevent API breakage if the type values change?\n. Same here, this would be nicer as an enum, especially considering that these values are binaryen internal only.\n. You could use varargs for this for a slightly friendlier API\n. Probably nicer to have a way to add child expressions incrementally. Otherwise the API user will have to create their own array externally, only to have it allocate additional memory internally.\n. Might want to make an enum class so you can specify its size.\n. You could have both with and without varargs. But it's probably OK to just have this.\n. Yeah, you could have a size hint parameter in the constructor.\n. maybe they'd be clearer as (32 - 1) and (64 - 1)?\n. That's why some people write Struct const *var; instead of const Struct *var;, so in general you can just say that const modifies the thing to the left. Of course you can make it more complicated than that... :-)\n. Or use the remove-if erase idiom.\n. Actually, I think it can't be used here. remove* doesn't guarantee anything about the values after the new end point, so the destructors won't be called for those items. Sorry for the noise.\n. No, I think I'm confusing myself. :) Just tried a simple example and it works:\n```\ninclude \ninclude \ninclude \ninclude \nstruct S {\n  explicit S(int i) : i(i) { std::cout << \"S(\" << i << \")\\n\"; }\n  S(const S&) = delete;\n  S& operator =(const S&) = delete;\n  ~S() { std::cout << \"~S(\" << i << \")\\n\"; }\n  int i;\n};\nint main() {\n  std::vector> v;\n  v.emplace_back(new S(0));\n  v.emplace_back(new S(1));\n  v.emplace_back(new S(2));\n  v.emplace_back(new S(3));\n  v.emplace_back(new S(4));\n  for (auto &x : v) {\n    std::cout << x->i << std::endl;\n  }\n  v.erase(std::remove_if(v.begin(), v.end(),  {\n            return x->i % 2 == 0;\n          }), v.end());\n  for (auto &x : v) {\n    std::cout << x->i << std::endl;\n  }\n}\noutput:\nS(0)\nS(1)\nS(2)\nS(3)\nS(4)\n0\n1\n2\n3\n4\n~S(0)\n~S(2)\n~S(4)\n1\n3\n~S(1)\n~S(3)\n```\nedit: simplified the example\n. Yep. Shouldn't matter anyway, because the unique_ptr won't ever call it, right?\n. I believe you can also specify the std::max template parameter explicitly:\nstd::max<Index>(newNumLocals, index + 1)\n. This doesn't match the spec parser; using parens in the internal name is a syntax error.\n. Yes, internal names (the ones beginning with $) can't be quoted in the current spec format.\n. fwiw: the binary encoding doc calls it external_kind. The spec repo has them separate as export_kind and import_kind. I call it ExternalKind in wabt. EDIT: sorry, didn't see you mention that above. I think GlobalKind is confusing, as this is overloading \"global\".\n. Probably should remove this comment\n. I've usually seen this written as shell=is_windows. But yeah, the whole thing is pretty horrible. :-|\n. I'd didn't look closely at the PR, but using atomics inside a data structure without locks seems pretty dangerous. It at least warrants a comment explaining why this is safe.. Well, it could be even simpler than this, since sections have to appear in order as well. So you can just keep an int tracking the last seen section and compare against that.. :+1: . I often add a comment when I do this in a macro, e.g.:\n/* no semicolon */\nKind of like adding // fallthrough when falling throw a case statement.. Nope, there's an algorithm for it now too: http://en.cppreference.com/w/cpp/algorithm/move. Though in this case it probably could be memmove; I wouldn't be surprised if it compiles to the same code though. Oh, hm. OTOH, this should be std::move_backward actually since the regions overlap.. Oh, right. Never mind. :-). Not that anyone asked, but IMO this shouldn't be using bitfields either. :-). Perhaps the original extend instructions should be renamed now?. Makes sense, probably better for a cleanup PR.. It looks like it runs each yaml list item (starting with -) as a separate script, so this does the right thing.. Does this change work with smaller sized Atomic RMW operations too?. Thanks, looks good.. Perhaps you could keep the old tags around, but move to a new naming scheme for new tags: binaryen_* and emscripten_*. Not sure if that makes things better (since new tags have clearer names) or worse (there are now 4 different tag formats). :woman_shrugging: . Are you sure? This seems to work OK: https://godbolt.org/g/zFjpFw. Ah sorry, didn't realize I was looking at the fixed code. :-). You'll want to delete the copy assignment operator too.. The threads proposal has new instructions for this: https://github.com/WebAssembly/threads/blob/master/proposals/threads/Overview.md#new-sign-extending-operators. Modern style is except Exception: or except Exception as e:. Right, clearly this case hid a NameError which had to be fixed.. I called the flag --enable-threads in wabt, probably worthwhile to be consistent.. Could just use a struct of bools... :-)\nhttps://github.com/WebAssembly/wabt/blob/master/src/feature.h#L26. Might be a bit clearer to use hex here, I have a lot of powers-of-two memorized but this one has always eluded me :-). FYI, importing+exporting mutable globals has been separated out into its own proposal: https://github.com/WebAssembly/mutable-global.. drive by comment: on != 0 or !!on are the ways I usually see this written.. This is a regular expression match, i is first character (so i686 etc).. It doesn't need special flags. IIRC, this section is just because wasm requires IEEE754 behavior that is provided by SSE2, but not by x87, which will be used by default on i686 builds. x86_64 uses SSE2 by default.. Mentioned previously, but both of these are potentially undefined behavior. It would be better to switch Literal to storing uint32_t and uint64_t to avoid this.. > Was there a previous discussion of this?\nI thought so a while back, but I could be wrong. I just know that arbitrary operations on signed values get my UB-senses tingling. Using unsigned integers is always wrapping, so it's harder to make a mistake. But if you don't expose the representation publicly then it is probably ok.. In an import statement the limits express a constraint. The memory must be at least min pages, and at most max pages. You could check here that a data segment was always less than the max size, but that's an instantiation error, not an validation error.. Could use something like gperf too. :-). You could use = default here too. Not sure it makes a big difference, but I generally see = default used for cases like this.. typo?. make these private?. assert on usedFixed == 0?. assert on usedFixed == 0?. Follow random access iterator: https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator? e.g. use difference_type instead of int etc.. ",
    "jfbastien": "@kripken , would you mind if this repo were consistent with the other wasm ones? I don't want to force this on you, but it seems pretty weird to license everything differently!\nWe can discuss tomorrow over beers :-)\n. It's ninja fast! Probably won't make a difference for now, but for LLVM it's quite significant.\n. @kripken please confirm that all the source files were authored by you (not imported from elsewhere). I want to make sure we do this right!\n. Moved to test, merging.\n. Checking include guards is icky because it depends on inclusion order. I could move that class to its own header file, but it seem like overkill. No strong preference besides avoiding icky.\n. I've been running it as:\nrm -rf /s/wasm/experimental/buildbot/work/s2wasm-out/ ; mkdir /s/wasm/experimental/buildbot/work/s2wasm-out/ ; /s/wasm/experimental/buildbot/link_assembly_files.py --linker /s/wasm/binaryen-out/bin/s2wasm --files /s/wasm/experimental/buildbot/work/torture-out/\\*.s --fails /s/wasm/binaryen/test/s2wasm_known_gcc_test_failures.txt --out /s/wasm/experimental/buildbot/work/s2wasm-out/ |& tee out\nYou'll need buildot's GCC sub-directory, it contains the torture tests.\nThe other option is to pull the archived .s files for the waterfall, e.g.:\nhttps://storage.googleapis.com/wasm-llvm/builds/svn/wasm-torture-s-r256306.tbz2\nI could create a symlink-ish thing that points to the LKGR, so you know which rev to pull? Say something like:\nhttps://storage.googleapis.com/wasm-llvm/builds/svn/lkgr\nWhich is updated with the SVN ID when the build is green (I'll do the same with git ID).\n. Yeah lgtm with the update from #39.\n. @kripken can you file a bug on LLVM, and link to that bug in the list of known failures?\n. No worries, easy merge :)\n. cc @AndrewScheidecker \n. /cc @AndrewScheidecker \n. @kripken the original dates itself a bit, but it was pretty amazing special effects for the time (one of the first uses of CGI)! Tron 2 is just amazing. IIRC it has Bit in two places, but just in the background (on the mantelpiece, and as fireworks).\n. I can take a look.\n. @kripken I don't think this is quite ready to merge, but I'd appreciate your input (I'm heading out the door now, will get back to this later today).\n. @kripken I think this is now good to go, the tests all run and pass locally.\n. That sounds fine. I'm not sure how to do the git repo thought: the build server would require some credentials to upload its results. Or did you have something else in mind?\n. @kripken: LMK if #57 is what you were thinking about. If so, this PR will be rebased to just add the testing (since the update part should be done separately). I can also update README.md.\n. README updated, and everything but the testing remove. @kripken good to go?\n. Merged as one commit in c7e7a9215e4c833653549b806a29b02399320bd6, I wasn't sure how to update this PR with the squashed commits.\n. Done.\n. Use CC and CXX?\n. Oh so you have CXX=emcc already? check.py isn't using that envvar, but emcc is?\nCC2 and CXX2? ;-)\n. Here's my current thinking. I'm figuring things out with you, so I'm not 100% confident, LMK what you think!\nI think update.py should be used to update things that are checked in (like test/revision, the submodule hashes, and the .s tests). I really don't want us to be checking in binaries like LLVM (or their tarball).\nWe could download the following archive: https://storage.googleapis.com/wasm-llvm/builds/git/wasm-binaries-$(cat test/revision).tbz2\nMaybe add that archive to .gitignore as well as the folder it untars to, and then?\ncheck.py could do that download I guess? First check if present, if it is do nothing, otherwise download and untar? Some of that logic is in update.py, so maybe it should be shared. Or maybe update.py could have an option to only download from what's already in test/revision (right now it only contains the bot revision, I could put the full content of lkgr instead).\n. Would you like test/revision to contain more information on the build? Right now lkgr contains the following: https://gist.github.com/jfbastien/90c6f10d2a834927ad13\nI only take the build number right now.\n. I thought what you / I / @titzer / @dschuff had discussed was that I was going to do this.\nThe reasoning was that we have similar .s files for the torture tests, and they should be generated from the same version of LLVM and updated at the same time using update.py to keep our sanity. The current mechanism for the turture tests' .s files already checks in which LLVM hash the tests were generated from, and I confirmed with @kripken that I could check in the generated .s files for now (they're just omitted by .gitignore for now). A submodule may be better in the future, but checked in tests is OK for now.\nAnyhow, this is a heads up to the change I'll do soon :-)\n. @sunfishcode OK sounds good, it'll keep the same files at the same place you put them, tested the same way, but instead update them with update.py like the torture tests are and with a checked-in lkgr.\n. Is that a spec bug then?\n. I think the conflict is just on the submodule moving out of test/, which doesn't seem necessary.\nRest LGTM, I'll update it with the waterfall infra once committed.\n. Yeah, I'll move it once the code lives in https://github.com/WebAssembly/waterfall. I'm waiting for the bots to mirror the github repo first (otherwise we DDoS github.com, or builds flake when github.com is down).\n. This doesn't contain the .s files yet so it's easier to review in github. Once this LGTY I'll add the .s files and commit.\n. Last Known Good Revision.\n. Was this created with ./update.py? It should update lkgr as well, otherwise the files aren't reproducible.\n. The waterfall is currently broken because of the wasmate breakage, which is unrelated to this change (caused by the previous commit). I'm almost done removing it, and the waterfall should turn green after this.\nI guess for now a manual update is fine, but I'd really like to avoid doing this in the future.\n. It can be merged now, as the bot is currently red. Once this is checked in the bot will turn green and update.py should be able to update lkgr.\n. We'll force-update when there's a cross-repo dependency and the tree is red, we know why, and using the output from LLVM is the right thing to do because it'll green the tree (or punt the breakage to a stage after binaryen such as sexpr-wasm).\n. @kripken oh that's weird... I remember seeing that failure, thought it was me, and git pull \"fixed\" it, but I guess it was just flaking.\n. Documentation on env:\nhttps://docs.travis-ci.com/user/environment-variables/#Defining-Multiple-Variables-per-Item\n. This is currently failing to kick off multiple builds, and the linker can't find the sanitizer libraries. I'll look into it later, I'm going out into the Real World for now.\n. Reference for a good sanitizer cofiguration: https://github.com/gabime/spdlog/blob/master/.travis.yml\n. @kripken I fixed a bunch of UB, it looks like simple_ast.h:873 is causing the current failure:\n```\n.. emcc_O2_hello_world.asm.js emcc_O2_hello_world.fromasm\n.. emcc_hello_world.asm.js emcc_hello_world.fromasm\nTraceback (most recent call last):\n  File \"./check.py\", line 97, in \n    fail(actual, expected)\n  File \"./check.py\", line 57, in fail\n    ''.join([a.rstrip()+'\\n' for a in difflib.unified_diff(expected.split('\\n'), actual.split('\\n'), fromfile='expected', tofile='actual')])[-1000:]\nException: incorrect output, diff:\n--- expected\n+++ actual\n@@ -430,7 +430,7 @@\n               (set_local $$mul\n                 (f64.mul\n                   (get_local $$x)\n-                  (f64.const 18446744073709551616)\n+                  (f64.const 18446744073709551615)\n                 )\n               )\n               (set_local $$call\n```\nI'm slightly confused by this since the value is 0x10000000000000000 (just above uint64_t's max). Am I getting this wrong, or is the test wrong?\n. @kripken I believe this is ready to commit, assuming I've understood the code and fixed it correctly. This should now enforce UBSan, and we can to asan / tsan separately.\n. FYI @sunfishcode \n. Could you add the following to check.py:\nimport test.waterfall.src.link_assembly_files as link_assembly_files\nwasm_as_torture_out = os.path.abspath(os.path.join('test', 'wasm-as-torture-out'))\nif os.path.isdir(wasm_as_torture_out):\n  shutil.rmtree(wasm_as_torture_out)\nos.mkdir(wasm_as_torture_out)\nunexpected_result_count = link_assembly_files.run(\n    linker=os.path.abspath(os.path.join('bin', 'wasm-as')),\n    files=os.path.abspath(os.path.join('test', 'torture-s', '*.s')),\n    fails=os.path.abspath(os.path.join('test', 'wasm_as_known_gcc_test_failures.txt')),\n    out=wasm_as_torture_out)\nassert os.path.isdir(wasm_as_torture_out), 'Expected output directory %s' % wasm_as_torture_out\nshutil.rmtree(wasm_as_torture_out)\nif unexpected_result_count:\n  fail(unexpected_result_count, 0)\nIt'll also require a new test/wasm_as_known_gcc_test_failures.txt file, and an update of the test/waterfall submodule.\n. Not even mildly ready to fail on most-but-not-quite-all tests? :p\n. Ah OK, lgtm then :)\n. > Just out of curiosity, the llvm backend currently emits a .s file in a format that is not vaguely like wast. This tools is describe as 'Assemble a .wast (WebAssembly text format) into a .wasm (WebAssembly binary format)' and if so then the wasm-as naming looks confusing.\nIt consumes a .s file, the help is wrong but I hadn't noticed. Added a comment.\n\nIs it planned that the current .s format becomes the text format and superseded wast or might there be a separate .s format?\n\nThe .s format is just convenient for LLVM as it is now, because that got things off the ground faster without introducing alien concepts into LLVM (which the LLVM community may frown upon). It's meant to look similar to .s files for other architectures, LLVM makes that easy. @sunfishcode is experimenting with outputting binary directly from LLVM, which is more involved but then you get assembler and disassembler for free if you Do It The Right Way\u2122.\nThe plans for text format are still very up in the air, and the current s-expression format isn't agreed on either. .s seems less readable than .wast so I doubt we'll standardize it as The One True Text Format\u2122, but it may be useful to standardize between compilers, the same way standardizing .o / .a / .so files between compilers could be useful: they're not meant to get shipped to a browser, but tools can get along and that's nice.\n. @kripken ah right, I double-misread :-)\n@binji was using sexpr, but in general wasm-as seems intuitive. So would wast2wasm and similar.\n. I find the mix of virtual inheritance and \"static inheritance\" through CRTP a bit confusing: why not do CRTP everywhere, and entirely drop the virtual inheritance? It'll be faster, optimize better, and be as easy to write as virtual inheritance (and IMO easier than when both are mixed). The one danger is code bloat, but that can be avoided by factoring common code out of the CRTP core (so it doesn't get re-instantiated every time).\n. Right, I would have:\n```\nclass Pass {\npublic:\n  virtual ~Pass() = 0;\nprotected:\n  Pass() {}\n  Pass(Pass &) {}\n  Pass &operator=(const Pass&) = delete;\n};\ntemplate\nclass WalkerPass : public Pass, B {\npublic:\n  void run();\nprivate:\n  void walk(Expression ) {}\n  void walk(Function ) {}\n  void walk(Module *) {}\n};\n```\nOr something of the kind. If you want the equivalent of pure walk (in virtual-speak virtual void walk(Expression *) = 0;) then you just don't declare it in WalkerPass (though putting it in the docs is nice!). I'd avoid defaulting it to abort() if it's unexpected because it's nice for static polymorphism to fail at compile-time (you could also force that with a SFINAE error if the base is instantiated, e.g. int you_must_implement_this_function[-1];).\n. Curiously Recurring Template Pattern, where you have a class that inherits from a base class template-parameterized with the parent class' type. See LLVM's InstVisitor for an example. It allows you to express static polymorphism: the derived class \"implements\" the interface, and the base class only ever does direct calls (no virtual dispatch) when calling its child.\n. Yes, this should all be simpler once I move all the file updates to the same waterfall-based update.py mechanism. As long as we're all OK with temporary breakage while @sunfishcode juggle knives then we're fine, the breakage should be very short lived and nobody should lose fingers.\n. I'd rather fix the upstream LLVM first, it looks like it adds a compilation failures to the torture tests:\nhttps://build.chromium.org/p/client.wasm.llvm/builders/linux/builds/1787/steps/Compile%20LLVM%20Torture/logs/stdio\ns2wasm then fails on all the torture tests:\nhttps://build.chromium.org/p/client.wasm.llvm/builders/linux/builds/1787/steps/Link%20LLVM%20Torture%20with%20s2wasm/logs/stdio\nThe later can be fixed separately (now actually, since the torture .s archive is available), but it looks like the former isn't intended?\n. cc @sunfishcode \n. As discussed on IRC, sorry this was broken! I thought I wasn't on the hook to do it :-)\nFor next time, we just needed to:\n1. land the breaking change to LLVM.\n2. wait for a build to finish on the waterfall (it'll fail on the binaryen step, but we still have the torture tarfile).\n3. ./update.py --force-latest\n. lgtm\n. @kripken works now :)\n. Ugh, GCC's warnings are overly aggressive here.\n. Actually no, I misread the code and GCC seems to have gotten smarter (sees longjmp through the lambda).\n. Looks pretty great overall, all comments are minor things :-)\n. I had a few comments still open, but they were mostly improvements so I'm OK either way.\n. Looks pretty good!\n. @kripken I didn't bother to clean the archive for now (the waterfall does ninja install and takes everything). Let me clean that up :-)\n. I think this should help:\nhttps://github.com/WebAssembly/waterfall/commit/de0072c4f4b6c83942ddaa84d79f1130c2e6a782\nLet's see what the size of the next archive is.\nI'm also playing with V8 right now, causing intermittent breakage because the build + bot is weird.\nYes, this should untar just fine, e.g. update.py has the untar function that just does tar -xvf.\n. @kripken:\n\nI don't quite understand how your untar works - what is the subdir it expects to find the output in? I tried the name of the target dir, and I tried the name of the subdir inside the tar, and neither work. (I can't test this locally, so I'm relying on travis here, which is making this annoying.)\n\nI hope this makes sense: https://github.com/WebAssembly/binaryen/pull/112/files#r49939859\n. Oh I see, I renamed the output a short while ago, but hadn't run update.py since so it was downloading the older archive. I've now updated test/revision so that should be fixed.\nI agree with you that the API isn't best, let me pull your change and do something better to the untar API that'll work for update.py as well as what you have.\n. OK I've updated the API, you now just give untar(tarfile, outdir) where outdir is where you'd like the content to go, it'll figure out the subdir madness I had :-)\nOn llc: that's from -DLLVM_INSTALL_TOOLCHAIN_ONLY=ON, I guess I can't blindly use it. I'll have to manually install what we need, then (LLVM doesn't have an option to do that). I'll keep that, but move other tools that seem useful like LLVM.\n. @kripken OK I think I've added the right things. We'll have to wait for the next LLVM build to kick off (current is 94e1407bce28).\nI also need to fix the waterfall so you can force builds (so we can force-rebuild)... It'll do that now.\n. Hmm, I added support for forced rebuilds, but can't remember how to kick them off from the UI! The next build should contain the right content, though. Let me know if that's not the case.\n. @kripken: 5cbf5020590d61a5d9dbfcc77d7eb7cc144694c7 updates to build 2026 which has all the binaries you mention. The build is now at 75MB, I'll reduce it.\n. This should help reduce build size:\nhttps://github.com/WebAssembly/waterfall/commit/f4d3048cc45acd6d53ca4349ebe8746eb0feb04a\nLocally it was very significant, but I didn't have exactly the same build setup. Build ID 2027 should have it (I just updated binaryen to 2026).\n. @kripken fixed it :-)\nThe emcc tests fail for me afterwards, though.\n. Hmm, that's odd. In this case it's better to go with what you had before, and I'll refactor stuff into a shared form later (I'm going out right now, won't have time to looks for a while).\n. Yeah that sounds good :)\nI also moved LLVM to building with dylibs, the archive is now 24MB on build 2030 onwards. I haven't run update.py yet, to make sure I don't break you (since the current one works).\n. /cc @titzer \n. Let's just see what @titzer and @binji say. Either way is easy to go, they'll be able to reconcile the inconsistency.\n. I think this is what you suggested?\n. Moving the waterfall setup upwards allows us to set up the LLVM binaries and related environment so emcc can use them.\nIndentation is just to fit in the if.\n. I was about to ask you why more tests pass. Had you triaged any of them?\n. Yeah, I'm going to run the same tests on other VMs so my thinking is that we'll find any issues that are hiding anyways.\n. I like this overall, but am concerned about portability.\nShould this have a test that it works?\nIt may be useful to add a Travis OSX build for this. Unfortunately I don't think Travis supports Windows, so I think we'll have to accept poor coverage there for now.\n. I'd wait for them to relicense before doing so. Yay for same licenses ;-)\n. @Lichtso thanks for this. It's a small enough patch that you don't need to join the W3C CG, but it would be good if you could do so anyways for future patches:\nhttps://www.w3.org/community/webassembly/\nThanks!\n. V8 has support for start: https://codereview.chromium.org/1692173002/\nMaybe it's just missing from the binary format spec. @titzer ?\n. I'm doing bitcode linking of multiple files, which doesn't resolve the aliases. Maybe in the long-term we won't want them, but I definitely need it now and it's valid .s syntax so it seems useful.\n. Ugh, I inadvertently merged this while trying to get #149 in... Sorry about that we can revert and / or fix separately.\n. Closing for now since it's in. We can discuss further and I'll fix things as a follow up.\n. OK so we're good with the change as is? Seems to do the right thing :-)\n. @kripken do you know what this vanilla LLVM error is?\n. Travis: https://travis-ci.org/WebAssembly/binaryen/jobs/105331090\n. Ah OK, should I just merge then?\n. Waiting on branch alias: I made this PR based on it because GH was down :(\nI'm sure there's a way to fix it, but I'm sure it's easy to mess up.\n. Yeah I messed things up... Not a big issue, leaving as-is so Dan can chime in on #148.\n. Need to merge this to master, same problem as the other: it merged onto a non-master branch.\n. Yeah my fault, I was branching off branches while github was down.\n. Done.\n. Because it's UB to type-pun through unions otherwise. memcpy is also technically UB, but it's the only valid way to type-pun without incurring the wrath of compilers (there's a gentleperson's agreement).\n. I can factor it out as bit_cast or something if you want.\n. Done.\n. I think we want NaNs to compare not-equal to anything else: that's what hardware does. Does the spec repo not do this?\n. Sorry I was unclear. I mean: don't ever compare payloads. The FP semantics should be that a NaN in either LHS or RHS (or both) cause the comparison to be false, because that's what hardware will do. Doing a regular FP comparison in your interpreter should therefore Just Work.\n@rossberg_chromium is that not what the spec repo does?\n. Sorry I was unclear. I mean: don't ever compare payloads. The FP semantics should be that a NaN in either LHS or RHS (or both) cause the comparison to be false, because that's what hardware will do. Doing a regular FP comparison in your interpreter should therefore Just Work.\n@rossberg_chromium is that not what the spec repo does?\n. The main issue is that the interpreter wants to support IEEE-754 semantics without too much implementation hassle, and that requires the underlying platform to give you IEEE-754 for free. That's not the case on out-of-the-box x86-32 because of its ABI, so the bar is higher. You could also use a soft-float library if you were willing to pay the cost. The problem is you almost have IEEE-754 compliance, and it seems like passing integers around brings you back to free :-)\n. The core problem is returning FP in x87 registers. This change seems pretty un-natural. Why not either:\n- Pass in a pointer to FP return values instead of returning them.\n- Create a Float and Double class which have a union { i32 i; f32 f }; and override all the basic types.\nSeems like either would be more C++-y.\nThis works too, it's just not very intuitive IMO.\n. Looks unrelated to my change: the landing page says the build is already broken. Or am I reading this wrong? Sorry, jet lag, I make be totally wrong on something obvious :-(\n. Which tool? Do you have a repro? s2wasm should handle -nan correctly, I didn't bother with +nan but I guess it doesn't hurt.\n. It's allowed by the spec, or am I reading this wrong?\n. Ah I misunderstood: you weren't asking about - or +, you were asking about both -+ right?\n. @kripken: I'll start fixing the toolchain issues soon, including compiling the torture tests with a minimal C library (statically linked!).\n. @kripken merging for now to avoid cross-timezone wait, let me know if you want me to do a follow-up PR.\n. @kripken same thing, let me know if you want any follow-ups.\n. I reworked the code as we discussed, I think it's much better with your suggestions :-)\nI'll commit it since you seemed fine with it and I'm still in timezone asynchrony.\n. minSize simply gets std::vector to allocate a bigger number up front, guaranteed to be contiguous for std::vector, and that number happens to be ~page size so most backing allocators start going to mmap for that size which gives nicely aligned memory. \nOtherwise if the memory is say 64 bytes the the std::vector could just be allocated without being 8 byte aligned. I'm trying to avoid having the interpreter's memory be differently-aligned from what it's simulating.\n. Done in 3b89982be258921b120dfb2e951533b3e87b70e1.\n. Ah right, that's why I remembered this code getting fixed. I just didn't remember the part where it didn't land because of the bug :-)\n. Actually, we could also conditionalize this fix on !x86-32. That would address your immediate NaN bit issue while keeping correctness for the other platforms. WDYT?\n. Agreed.\n. Huh, weird. Thanks for fixing.\n. Can this be optional and off by default? It sounds like fixing SM is the better solution :-)\n. sgtm, sounds close to adding a --strip option? The design we're going for is that these names end up in a separate section in the binary, and you can strip it out just like with regular executables, so it seems natural to allow binaryen to strip the names earlier.\n. Repro instructions after building with asan:\n```\nbin/binaryen-shell test/kitchen_sink.wast 2>&1 | /s/llvm/llvm/projects/compiler-rt/lib/asan/scripts/asan_symbolize.py -d\n=================================================================\n==68826==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60200000adfa at pc 0x0000005be503 bp 0x7ffe4bf343b0 sp 0x7ffe4bf343a8\nREAD of size 1 at 0x60200000adfa thread T0\n    #0 0x5be502 in wasm::SExpressionWasmBuilder::parseExpression(wasm::Element&) /s/wasm/binaryen/src/wasm-s-parser.h:529\n    #1 0x5be502 in ?? ??:0\n    #2 0x5cbf6c in wasm::SExpressionWasmBuilder::parseExpression(wasm::Element*) /s/wasm/binaryen/src/wasm-s-parser.h:409\n    #3 0x5cbf6c in ?? ??:0\n    #4 0x5c8384 in wasm::SExpressionWasmBuilder::makeBlock(wasm::Element&) /s/wasm/binaryen/src/wasm-s-parser.h:689 (discriminator 1)\n    #5 0x5c8384 in ?? ??:0\n    #6 0x5beab7 in wasm::SExpressionWasmBuilder::parseExpression(wasm::Element&) /s/wasm/binaryen/src/wasm-s-parser.h:549\n    #7 0x5beab7 in ?? ??:0\n    #8 0x5b8e92 in wasm::SExpressionWasmBuilder::parseFunction(wasm::Element&) /s/wasm/binaryen/src/wasm-s-parser.h:369\n    #9 0x5b8e92 in ?? ??:0\n    #10 0x5a78e4 in wasm::SExpressionWasmBuilder::parseModuleElement(wasm::Element&) /s/wasm/binaryen/src/wasm-s-parser.h:285\n    #11 0x5a78e4 in ?? ??:0\n    #12 0x58d9d0 in SExpressionWasmBuilder /s/wasm/binaryen/src/wasm-s-parser.h:240 (discriminator 1)\n    #13 0x58d9d0 in ?? ??:0\n    #14 0x5829a6 in main /s/wasm/binaryen/src/binaryen-shell.cpp:381\n    #15 0x5829a6 in ?? ??:0\n    #16 0x7fb0f04b9ec4 in __libc_start_main /tmp/tmp.Htw1L27e9P/csu/libc-start.c:287\n    #17 0x7fb0f04b9ec4 in ?? ??:0\n    #18 0x4bac87 in _start ??:?\n    #19 0x4bac87 in ?? ??:0\n0x60200000adfa is located 0 bytes to the right of 10-byte region [0x60200000adf0,0x60200000adfa)\nallocated by thread T0 here:\n    #0 0x56780b in __interceptor_malloc asan_rtl (discriminator 12)\n    #1 0x56780b in ?? ??:0\n    #2 0x58fd72 in cashew::IString::set(char const*, bool) /s/wasm/binaryen/src/emscripten-optimizer/istring.h:75 (discriminator 1)\n    #3 0x58fd72 in ?? ??:0\n    #4 0x589e50 in IString /s/wasm/binaryen/src/emscripten-optimizer/istring.h:62\n    #5 0x589e50 in ?? ??:0\n    #6 0x5a0eb0 in wasm::SExpressionParser::parseString() /s/wasm/binaryen/src/wasm-s-parser.h:211 (discriminator 1)\n    #7 0x5a0eb0 in ?? ??:0\n    #8 0x59d4c6 in wasm::SExpressionParser::parse() /s/wasm/binaryen/src/wasm-s-parser.h:167\n    #9 0x59d4c6 in ?? ??:0\n    #10 0x59cd56 in wasm::SExpressionParser::parseInnerList() /s/wasm/binaryen/src/wasm-s-parser.h:149\n    #11 0x59cd56 in ?? ??:0\n    #12 0x59d3d2 in wasm::SExpressionParser::parse() /s/wasm/binaryen/src/wasm-s-parser.h:161\n    #13 0x59d3d2 in ?? ??:0\n    #14 0x59cd56 in wasm::SExpressionParser::parseInnerList() /s/wasm/binaryen/src/wasm-s-parser.h:149\n    #15 0x59cd56 in ?? ??:0\n    #16 0x59d3d2 in wasm::SExpressionParser::parse() /s/wasm/binaryen/src/wasm-s-parser.h:161\n    #17 0x59d3d2 in ?? ??:0\n    #18 0x59cd56 in wasm::SExpressionParser::parseInnerList() /s/wasm/binaryen/src/wasm-s-parser.h:149\n    #19 0x59cd56 in ?? ??:0\n    #20 0x59d3d2 in wasm::SExpressionParser::parse() /s/wasm/binaryen/src/wasm-s-parser.h:161\n    #21 0x59d3d2 in ?? ??:0\n    #22 0x59cd56 in wasm::SExpressionParser::parseInnerList() /s/wasm/binaryen/src/wasm-s-parser.h:149\n    #23 0x59cd56 in ?? ??:0\n    #24 0x59d3d2 in wasm::SExpressionParser::parse() /s/wasm/binaryen/src/wasm-s-parser.h:161\n    #25 0x59d3d2 in ?? ??:0\n    #26 0x59cd56 in wasm::SExpressionParser::parseInnerList() /s/wasm/binaryen/src/wasm-s-parser.h:149\n    #27 0x59cd56 in ?? ??:0\n    #28 0x58cf29 in SExpressionParser /s/wasm/binaryen/src/wasm-s-parser.h:127\n    #29 0x58cf29 in ?? ??:0\n    #30 0x582628 in main /s/wasm/binaryen/src/binaryen-shell.cpp:370\n    #31 0x582628 in ?? ??:0\n    #32 0x7fb0f04b9ec4 in __libc_start_main /tmp/tmp.Htw1L27e9P/csu/libc-start.c:287\n    #33 0x7fb0f04b9ec4 in ?? ??:0\nSUMMARY: AddressSanitizer: heap-buffer-overflow (/media/jfb/ssd/wasm/binaryen/bin/binaryen-shell+0x5be502)\nShadow bytes around the buggy address:\n  0x0c047fff9560: fa fa fd fa fa fa 07 fa fa fa 00 00 fa fa fd fa\n  0x0c047fff9570: fa fa fd fd fa fa 00 00 fa fa fd fa fa fa fd fa\n  0x0c047fff9580: fa fa 07 fa fa fa 00 00 fa fa 00 00 fa fa fd fa\n  0x0c047fff9590: fa fa fd fa fa fa 00 01 fa fa 00 00 fa fa 00 00\n  0x0c047fff95a0: fa fa fd fa fa fa fd fa fa fa 00 04 fa fa 00 00\n=>0x0c047fff95b0: fa fa 00 00 fa fa fd fa fa fa fd fa fa fa 00[02]\n  0x0c047fff95c0: fa fa 00 00 fa fa 00 00 fa fa fd fa fa fa fd fa\n  0x0c047fff95d0: fa fa 00 02 fa fa 00 00 fa fa 00 00 fa fa fd fa\n  0x0c047fff95e0: fa fa fd fa fa fa 00 01 fa fa 00 00 fa fa fd fa\n  0x0c047fff95f0: fa fa fd fd fa fa 00 00 fa fa fd fa fa fa fd fa\n  0x0c047fff9600: fa fa 00 05 fa fa 00 00 fa fa 00 00 fa fa fd fa\nShadow byte legend (one shadow byte represents 8 application bytes):\n  Addressable:           00\n  Partially addressable: 01 02 03 04 05 06 07\n  Heap left redzone:       fa\n  Heap right redzone:      fb\n  Freed heap region:       fd\n  Stack left redzone:      f1\n  Stack mid redzone:       f2\n  Stack right redzone:     f3\n  Stack partial redzone:   f4\n  Stack after return:      f5\n  Stack use after scope:   f8\n  Global redzone:          f9\n  Global init order:       f6\n  Poisoned by user:        f7\n  Container overflow:      fc\n  Array cookie:            ac\n  Intra object redzone:    bb\n  ASan internal:           fe\n  Left alloca redzone:     ca\n  Right alloca redzone:    cb\n==68826==ABORTING\n```\n. @kripken I think this is ready to commit, it fixes one of the asan issues.\n. I think it would be good to have a temporary thing for now, maybe with a command-line parameter to s2wasm allowing us to specify a non-default stack size.\nIn the long term have the toolchain-provided _start invoke setrlimit(RLIMIT_STACK, &rl); seems like the right approach. A program would have zero stack initially, and _start would set things up.\n. I squashed and committed.\n. What was the failure? You technically can't put non-inline functions in a header file.\n. @rossberg-chromium @binji it would be good for your parsers to support (start func).\n. Merged because timezones, let me know if you have any follow-up concerns that I should address.\n. > As mentioned above, I actually don't even understand what this pull request does. Please explain when you get a chance.\nYou mean https://github.com/WebAssembly/design/pull/495 isn't clear? Or the way this PR implements it isn't? I'm not sure what's unclear ;-)\n. Sorry, I didn't realize your question was expressing concern, I thought you just wanted a follow-up :-)\n. Huh that would be nice... Does it work locally? I didn't know about that option.\nOoh adding this would be nice too:\nASAN_OPTIONS=\"detect_leaks=1 symbolize=1 external_symbolizer_path=$SRC/third_party/llvm-build/Release+Asserts/bin/llvm-symbolizer\"\n(well, with the right path)\n. Yeah that sounds fine. But weird. I'd expect it to work!\n. FYI @sunfishcode @binji @kripken @titzer \nIt would be good to stage these changes next time so different tools don't break (e.g. @titzer is fixing V8 separately). We'll have more such changes as we bring things up and we'll need to have all patches ready before landing them, or at least be ready for the breakage.\n. Kind of, it can be improved but right now lkgr stays at the last time all the tip-of-tree components worked instead of individually testing them and then figuring out an lkgr from the ones that work.\nIn this case it wouldn't have helped though: different components pull the spec tests, so they break when they update the tests. I think in cases like this (or of the binary format, when we get there) we'll want to synchronize changes.\nIt's not a big issues, we're just churning stuff and figuring out what the dependencies are and how to do things. LMK if there's anything you think could improve here. It's not perfect but I'm hoping it stays low-process and low-pain!\n. Yeah that could help. We'd need to officially move them to their own repo. Let chat next week when I'm back in the US?\n. My rule would be: fuzzer-generate inputs should never be able to hit assert.\n. In most projects asserts are meant as a sanity check which can be disabled without the program being invalid. That means that user inputs should never be able to trigger asserts. This makes it easier to understand what the code does: when I add a new feature and hit an assert I know I messed up and broke how the program is intended to work.\n. Not quite good to go yet...\n. Updated and squashed.\n. Odd, the following three tests now seem to reliably fail with tsan on:\n    20040811-1.c.s.wast\n    pr43220.c.s.wast\n    vla-dealloc-1.c.s.wast\nBut pass on other configurations.\n. Right, the three tests just print out FAILED and nothing else. I can't repro the problem by just running one of the tests. It's only in the tsan builds though!\n. Sure, let's merge and move tsan to optional while it stays broken (and try to fix it).\n. That looks like a great start!\nI'd change most methods to be const, but otherwise lgtm.\n. lgtm for now, though the corner cases worry me this is a clear improvement.\n. One comment, looks good otherwise.\n. New tests which didn't make it to binaryen before the update. They're new in this PR.\n. The set of torture sets is currently pinned by the waterfall: https://github.com/WebAssembly/waterfall/blob/f18e24da6a5bad33816a6c3dc15b01f4cb75977b/src/build.py#L135\nI figured I'd only update that set from time to time (it doesn't change often anyways).\nSome of the tests don't make it through the pipeline though.\nIn this case @sunfishcode fixed an LLVM bug here: http://llvm.org/viewvc/llvm-project?view=revision&revision=260737\nand @dschuff updated the expected LLVM failures accordingly here: http://llvm.org/viewvc/llvm-project?view=revision&revision=260750\nThe tests could also fail s2wasm and not make it to binaryen-shell, or they could fail sexpr-wasm and not make it to d8 and spec.\n. Nice :-)\nMinor comments, looks good otherwise.\n. Cool, lgtm\n. If all passes, yes :-)\nOn Feb 19, 2016 5:01 PM, \"Alon Zakai\" notifications@github.com wrote:\n\nThis bumps the waterfall. @jfbastien https://github.com/jfbastien, is\nthat ok?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/203#issuecomment-186471854.\n. We should only land this post-March, right?\n. You're saying post-haste? :p\n. Loosening the parser rules would be fine IMO, but not as far as implementing automatic semicolon insertion. Unless @BrendanEich implements it as penance ;-)\n. Sorry, I'm late catching up to PRs... Fixed in #243.\n. Yeah that seems like the wrong fix.\n\nI initially intended --debug to take no parameters, but you had parts of binaryen using --debug=LEVEL so I had to follow that. I'd be happy to have on level.\n. Fixed in #256.\n. Thanks!\n. Saw from your prior PR. This is pretty.\n. #include <cctype> is better since you need the header for isdigit anyways (or <ctype.h> for the C version, but the C++ one is better for obscure reasons).\n. Oops, yes that's correct. Thanks!\n. I agree that it should be possible to run the tests without downloading any binaries. Isn't that already the case though? I thought the waterfall and emscripten binaries could be turned off / redirected?\n. Opened #284 to address some other issues.\n. It would be nicer to use something which owns the memory instead.\n. asan's leak detection is turned off in .travis.yml because of these. Would be nice to fix.\n. IMO in that case the best approach is to allocate istrings with their own bump allocator. That's much nicer than using the same allocator as other objects, and you can free it when the global context object is freed.\n. May as well compare to ssize_t: it's a lot of memory anyways :-)\nlgtm otherwise.\n. I wouldn't use the _s functions though. strncpy and such are better.\n. It's more idiomatic when you don't have constexpr, and in some weird cases gives the compiler more information (though in this case it's pretty straightforward, same codegen should occur).\n. Eh, consexpr or local enum are the better thing, but non of it matters in this case. I'm happy going with whichever you'd rather have.\n. Done.\n. It should be std::size_t, but otherwise I'd expect it to work as long as you've included cstddef or another one of the headers that declares std::size_t.\nRepro instructions?\n. Odd, musl seems self-consistent but on its own compared to other places. newlib uses __SIZE_TYPE__ which is provided by the compiler, and both clang and gcc's provided stddef.h does typedef __SIZE_TYPE__ size_t;.\nIt would be useful to ask on the musl list why things are done this way.\n. This thread? http://www.openwall.com/lists/musl/2016/01/25/10\nI would rather go for the \"non-odd\" thing in this context, i.e. musl's approach. We could also consider a different libc where the approach is more in-line with LLVM / GCC, but clearly musl's approach works for multiple other architectures so I'm not super thrilled to move away from it.\nOne big downside if we diverge is that it'll basically be impossible to upstream changes.\n. > I claim that I'm familiar with the toolchain work needed to support this, and with historical C code with invalid assumptions, and am willing to pay the price. If we ever have glibc/newlib/bionic/etc. ports, there are real advantages to making them ABI-compatible at the freestanding level, even if that means not following some conventions about what size_t \"should\" be in various places.\nI'm not sure I understand what you're advocating for.\nMaybe upstream musl would be OK with include/alltypes.h.in containing:\n```\nif defined(SIZE_T)\ndefine _Addr SIZE_T\nendif\n```\n?\nIt would keep the per-arch _Addr for compilers without __SIZE_T__ while honoring the compiler's guidance when it does. That does cause the same ABI issue if musl is used with different compilers, though.\n. Awesome, thanks for driving this.\nI'd like arch/wasm, but we can discuss separately.\n. Looks like there were a few build issues, but overall this sounds like a good idea.\n. Try putting support on the right: dependencies are filled right-to-left.\n. I'm OK if https://github.com/WebAssembly/binaryen/pull/302#discussion_r58278110 is done separately or here. I don't want to block this change on it, but I think it'll keep things sane.\n. > How about if we have a single binaryen.so shared library, that all the tools would be linked with dynamically? That would be good for other projects using binaryen as well, they would just link with it similarly.\nI think it's better to do small static libraries where possible: it keeps code sane, prevents introduction of odd dependencies, and keeps fast build time. Not that dylibs are bad either, it just seems to be a slightly unrelated thing: the end tools build faster, but you still need to rebuild the .so.\n. > Small static libs internally sounds ok, but are you fine with also having a single .so for external projects? e.g. the program in examples/, I'd like it to just link to libbinaryen and not to multiple static libs.\nYeah that sounds good, I'd tackle it after the static libs though.\n. Awesome, I think that's a pretty good improvement on its own. We can probably do more in that vein afterwards. I'll let @kripken merge if he likes.\n. The new failure wasn't making it through LLVM before, not it does and fails executing:\nhttps://github.com/gcc-mirror/gcc/blob/master/gcc/testsuite/gcc.c-torture/execute/pr38051.c\n. Tags sound simpler IMO.\n. Depends how you recommend consumers work. If we want to get it for the waterfall then it'll break :-)\n. Please send a PR.\n. Right, I thought that was already fixed with the right type?\n. Sounds fine as a short-term fix, probably worth opening an issue to undo this later?\n. This may just be that the files aren't open in binary mode?\n. It would be nice to fix the tsan bot before using this (the allow_failures section of .travis.yml).\n. Could you separate out the chrono stuff into its own PR before this one?\n. LMK what I can do to help with tsan. Looks like the current run is reporting a race, so it would be better to debug on a separate PR (i.e. make it pass without threads first, then fix the race it reports).\nIt just seems simpler to deal with chrono separately, and quicker to get through since it's not related to tsan.\n. It would be good to have no global ctors IMO. They lead to a bunch of confusion with initialization order, and they have a cost at load time (e.g. Chrome has removed all of them from its codebase).\nI'm not sure if you want to do this before or after the parallelization. Main's thread ID is all that's requiring a non-global for now, otherwise you could limp by with globals ctors...\n. Overall this looks good, but I'd really like the tsan bot to always pass before this goes in :-s\n. OK let's see if #351 works out.\n. It worked out! want to rebase and trigger a new build?\n. lgtm otherwise.\n. It would be good to get @rossberg-chromium / @binji input on the representation of the debug info. I think the spec repo may be the best place to suggest a syntax first, instead of here.\n. Hmm odd. Do they timeout locally? I thought I remembered there being tsan output before, maybe it went away!\n. Do the same build but with tsan, here's the script I use:\n```\n!/bin/bash\nset -e\nset -u\nset -x\nexport GOOG=/path/to/my/toolchain\nexport LD_LIBRARY_PATH=$GOOG/path/to/lib64/\nexport CC=$GOOG/bin/clang\nexport CXX=$GOOG/bin/clang++\nexport COMPILER_FLAGS=\"-fsanitize=thread\"\nexport BINARYEN_ROOT=/s/wasm/binaryen\nrm -rf $BINARYEN_ROOT/build-tsan\nmkdir $BINARYEN_ROOT/build-tsan\ncd $BINARYEN_ROOT/build-tsan\ncmake -G Ninja $BINARYEN_ROOT/ \\\n  -DCMAKE_C_COMPILER=$CC \\\n  -DCMAKE_CXX_COMPILER=$CXX \\\n  -DCMAKE_CXX_FLAGS=\"-fsanitize=thread\" \\\n  -DCMAKE_BUILD_TYPE=Debug\nninja\n```\nYou have to build and run with the same environment setup, because some of the tests also use the compiler.\n. Increasing the timeout seems like the best thing IMO. Could you do that?\n. Let's see if this works!\n. > Don't you need to update the waterfall too?\nNinjas sneak things in. ;-)\n. Worked!\n. Look at what LLVM does to handle Windows and pthread-in-libc:\nhttps://github.com/llvm-mirror/llvm/blob/master/cmake/config-ix.cmake#L93\n. > @jfbastien: it does sound good to do what llvm does, but seems like we'd need to import a lot of cmake from there, which makes me worry...\nProbably, but we know it works right on multiple platforms, so we won't need to keep fixing cmake :-)\n. At that point it's better to keep a reference to the allocator on a per-thread basis, instead of locking. Each thread owns its own bump allocator, no locks.\n. I tend to agree with @binji here. Either have one allocator per-thread if memory lifetime is bound to the work item, or have the allocator in each task (e.g. each function to be optimized has one). You can mix both approaches too (you know at each allocation point how long something will live), but in the end there's no lock.\nIf there are locks in the allocator you're usually better off with malloc.\n. Commit c825268 didn't sort the headers, it only added a blank line.\n. Yes, alphabetically. I fix it in a493b1dfcfbac5165beed3e05891fd467dd4da25.\n. The python code that handles tar files may be opening the file without binary mode?\n. It semi-broke a while ago and I haven't gone back to fix it (it downloads, but doesn't untar in-place). Up to you, it makes the URL easy to get...\n. Bots fail with:\nclang: error: -lpthread: 'linker' input unused\n: error: -lpthread: 'linker' input unused\n. Ugh the default is to recover and continue. I'm trying to fix now.\n. Closing, this was fixed by the other patches.\n. @kripken I think this one is now good to go, this now leads us to another exciting UBSAN failure :)\n. lgtm, ty!\n. Can you use std::ios_base::openmode instead of int, since that's the correct type?\n. Right, but other compilers may define openmode as something else than int, so what works for MSVC isn't a clear fit for non-MSVC.\n. Thanks!\n. @binji ah cool, that's about what I had in mind, but using numeric_limits's exponent and digits  to avoid hard-coding the exact representation.\nDo you mind importing what you have to binaryen? Seems silly to rewrite if you already have it.\n. Fixed by #421 (will re-run UBsan bot).\n. Looks great! ty.\n. Is green, passes my local ubsan build (or rather, takes it further). Merging.\n. When running check.py the remaining ubsan warnings are:\nstl_vector.h:866:9: runtime error: reference binding to null pointer of type 'char'\n../src/support/bits.cpp:71:40: runtime error: negation of -2147483648 cannot be represented in type 'int32_t' (aka 'int'); cast to an unsigned type to negate this value to itself\n../src/wasm.h:412:46: runtime error: signed integer overflow: -1711276032 + -882185124 cannot be represented in type 'int'\n../src/wasm.h:412:46: runtime error: signed integer overflow: 2081590212 + 229283573 cannot be represented in type 'int'\n../src/wasm.h:412:46: runtime error: signed integer overflow: 2130706432 + 16777216 cannot be represented in type 'int'\n../src/wasm.h:412:46: runtime error: signed integer overflow: 2147467264 + 16384 cannot be represented in type 'int'\n../src/wasm.h:412:46: runtime error: signed integer overflow: 2147479553 + 4096 cannot be represented in type 'int'\n../src/wasm.h:412:46: runtime error: signed integer overflow: -2147483648 + -1 cannot be represented in type 'int'\n../src/wasm.h:412:46: runtime error: signed integer overflow: -939524096 + -1677721600 cannot be represented in type 'int'\n../src/wasm.h:421:46: runtime error: signed integer overflow: -2147483647 - 2147479553 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 10 * -214748365 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 12 * -1431655765 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 1388815473 * 1103515245 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 202 * -939524096 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 41589 * 1812433253 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 47114711 * 1103515245 cannot be represented in type 'int'\n../src/wasm.h:430:46: runtime error: signed integer overflow: 75840000 * 156 cannot be represented in type 'int'\n../src/wasm.h:431:46: runtime error: signed integer overflow: 51991801852281540 * 1103515245 cannot be represented in type 'long'\n../src/wasm.h:533:46: runtime error: left shift of 255 by 31 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 2 by 31 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 305419896 by 14 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 305419896 by 24 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 305419896 by 28 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 4194303 by 14 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 4660 by 28 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 51277 by 25 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of 67076096 by 16 places cannot be represented in type 'int32_t' (aka 'int')\n../src/wasm.h:533:46: runtime error: left shift of negative value -1\n../src/wasm.h:533:46: runtime error: left shift of negative value -128\n../src/wasm.h:533:46: runtime error: left shift of negative value -150\n../src/wasm.h:533:46: runtime error: left shift of negative value -1656138329\n../src/wasm.h:533:46: runtime error: left shift of negative value -2023406815\n../src/wasm.h:533:46: runtime error: left shift of negative value -2122153084\n../src/wasm.h:533:46: runtime error: left shift of negative value -231451016\n../src/wasm.h:533:46: runtime error: left shift of negative value -255\n../src/wasm.h:533:46: runtime error: left shift of negative value -3532\n../src/wasm.h:533:46: runtime error: left shift of negative value -4\n../src/wasm.h:533:46: runtime error: left shift of negative value -581460070\n../src/wasm.h:533:46: runtime error: left shift of negative value -66524220\n../src/wasm.h:533:46: runtime error: left shift of negative value -9120\n../src/wasm.h:534:46: runtime error: left shift of 1090791845765373680 by 60 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 1311768467463786787 by 52 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 16777216 by 40 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 2305842459462008832 by 6 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 31 by 63 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 3853319862790607633 by 32 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 4294967295 by 48 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 4660 by 56 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 81985529216486895 by 8 places cannot be represented in type 'int64_t' (aka 'long')\n../src/wasm.h:534:46: runtime error: left shift of 81985529234382576 by 60 places cannot be represented in type 'int64_t' (aka 'long')\nSee ubsan docs here:\nhttp://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html\n. Bots are green!\n. > > About the prefix, how about \"Bin\"? Or any other ideas?\n\nHow about BYE :)\n\nKnown would be nice: \"the prefix? It is Known.\"\n. Merging since green, @kripken LMK if you'd like style adjustments.\n. > I think this is actually less nice.... :(\nBut is it thirty-two less one nice, or sixty-four less one nice?\n. > I think this is clearer personally, but if more people think otherwise I'm fine to leave it as is.\n\nInstead, perhaps a comment \"we don't shift more than the actual number of bits\" would be just as good, with the previous code.\n\nUpdated, is this better?\n. Waterfall looks sad from this:\nhttps://wasm-stat.us/builders/linux/builds/6415/steps/binaryen/logs/stdio\n. I'd do:\n1. auto\n2. size_t\n3. Agree with @dschuff, it's a property of the target, we should have a specific type for it.\n. I agree that the cast to void* is bad, but the solution really seems counter-intuitive. Would it be possible to return a proper pointer from all of these functions, and then have the C API be part where the cast to void* occurs? It seems like that would prevent inadvertently forgetting a cast in one place.\n. Right, what I mean is that the implicit conversion to void* isn't obvious, so forgetting the cast is easy. It seems better for none of these to return void*, return a C++ thing instead, and then cast those to void* in a C API wrapper.\nBut realistically these are all simple struct pointers, without magical inheritance right? It doesn't really matter in that case: all you want is that there be no pointer adjustment when casting to / from void*. It's benign UB in that case, so I wouldn't worry too much ;-)\n. Why even have the option? Is it useful?\n. Right, I would just respect the compiler's output and not even try doing more. No need for the option, just don't do it.\n. Does this lead to non-deterministic binary output?\n. lgtm\n. > > this didn't require any actual s2wasm change because s2wasm just accepts anything beginning with 'd', so it accepts either \"discard\" or \"drop\".\n\nThe very definition of \"feature, not a bug\".\n\nI think your account has been hacked by \ud83d\udc0e.wasm\n:stuck_out_tongue: \n. You can use the UniformRandomNumberGenerator version of random_shuffle (it's not deprecated), but not uniform_int_distribution because AFAIK different STLs implement it differently.\n. Ah yes, that should work. I thought you also wanted the distribution, but I think that's fine.\n. I think I just installed the hook properly. LMK if that's not the case.\n. Also, @kripken and @dschuff should already be admins for the binaryen repo.\n. This is confusing. Why not factor out the options object and share it, instead of duplicating its creation?\n. Just add a function, shared between different executables, which takes an Option object and adds these options to it, return it. Put it in a sharedlib so it compiles once only.\n. Maybe this is a silly question... but isn't LLVM a better place to do this? \ud83e\udd14. Yeah is it that LTO doesn't see everything? libc needs to be statically linked? It would be useful to, at a minimum, feed these limitations back to the LLVM community.. @kripken IIRC these aren't inherent limitations of LLVM. They're limitations of an out-of-tree tool, Evaluator.cpp, built on top of LLVM. Right?. Ah gotcha, I thought this was a separate thing. Still, I'm not sure it can't be fixed... but I guess now you have your own thing... I'm just very worried that WebAssembly tooling just doing its own thing when it logically should be in LLVM like this means that we'll get very little support from LLVM folks when it is needed.. But by that metric everything should be done in binaryen or Emscripten! This is one small thing, in the grand scheme of things it won't upset LLVM folks, but I really want this point to sink in: if the WebAssembly we recommend people use builds a bunch of stuff LLVM almost does but falls slightly short on then LLVM folks won't be thrilled. Over time, little by little, they'll be uninterested in supporting WebAssembly because when we see LLVM falling short we just work around it and leave the bugs behind.\nFWIW the same applies to, say GCC.\nThere totally is a place for special purpose tools! WebAssembly does things which I believe LLVM is thoroughly uninterested in, and is very happy to exist here. All I'm saying is I don't think this feature fits the description.\nNow is too late to change direction, but please next time consider the point I'm making.. The start function is automatically called when a wasm instance is create. I see little use in exporting it. All static initialization should be done there, and that doesn't seem to be the case?. @MichaReiser this is a fairly big contribution, can you please join the WebAssembly community group before this can be merged?. Looks like you didn't get to it?. Looks like endianness bug.. Does this actually occur?. Daniel, could you please join the WebAssembly Community Group for this contribution?. > Thanks, it does look like that's a factor here. Disabling that pass makes fannkuch 7.5% faster and 1.2% smaller.\nWhere is it 7.5% faster?. I guess if it's a lossless size win then it should be done, but if it's not lossless or not a size win then skewing for what a subset of VMs do at a specific point in time seems like the wrong approach. In those cases we should fix the VMs.. > Thanks I'll check that out. And yes, an atomic load can cross a regular load because atomics don't have specified ordering with respect to non-atomic operations.\nNot in WebAssembly.. Isn't this a perfect place to use LLVM's merge-funcs?. merge-funcs had some work-in-progress to also merge similar functions. It seems much more useful to continue that work rather than reimplement something that'll be WebAssembly-specific.. I can't find the reference right now, somewhere on LLVM. Regardless, the code probably would need an update. The basic idea is simple: MergeFunctions knows everything about each IR construct, and can be taught about what's a \"fuzzy\" comparator as well as the current exact comparators. Differing by e.g. one function call can be a thing that gets merged.\nIIRC with precise function merging the pass was a 7% size with on Chrome, back in summer 2015.. I'm happy to help review it.. Yes, it's a copy / paste, and that's what I was talking about.\nWe should work towards enabling it by default for LLVM. It's not just a size win, it's also a compile-time win because fewer functions are optimized. You can run exact match early for that. Partial match should run late, won't be a compile-time win, but will win on size.\nRe-importing Swift's improvements to LLVM is easy.. You don't want to do partial merge early because it can defeat other things such as inlining. First you do exact, and then after doing some passes you'd do partial.. With 100000 functions it'll be inefficient if you compare all of them to each other. LLVM migrated to a hashing-based approach to do this, and then does a strict comparison of what hashes the same. For \"fuzzy\" matching we just implemented two hashes: one for precise match, and one of fuzzy where we'd take into account e.g. opcode type like \"invoke\" but not say invoke target. As I said above this fuzzy matching never made it into the tree (my intern's term finished) but it's easy to add.. If you start doing fairly complex things like this it would be great to do good perf measurements on all available browser implementations. Merging things like + and * would save size, but VMs might want to start doing very different codegen and optimizations to \"undo\" some of the hurt this can cause.\nIt's a moving target, though: don't take current VM performance as a thing that won't change. All I mean is, please don't just measure on one engine and call it a day.. I don't think parse-time matters here. Download does, but parsing is nothing compared to work that the optimizer needs to do. Therefore, any compression which forces the optimizer to perform more work has to yield valuable download savings.. @wycats sorry for missing this discussion. The title made me mark-as-read. Please consider forking this question to its own thread instead of tacking it onto this one.\nTo answer your question: binaryen was started early in WebAssembly's history when much of the design was in flux, and it definitely provided significant input to what will become the final WebAssembly standard. I was one of the 4 CG chairs at the time, representing Google, and advice from representative companies' standards folks + lawyers, and W3C folks, was that WebAssembly contributions which affect the design must be under the W3C umbrella and contributors who provide significant input must be CG members. Binaryen fit that description and was therefore under the WebAssembly organization.\nNow that the design has settled more we could reconsider and put binaryen as well as other tools under their own organization. For example, the LLVM work now occurs directly in upstream LLVM. It remains true that significant contributions to the standard must come from CG members, but at this point tooling development doesn't influence the design as much as just get stuff working.\nIf you want to float this idea I recommend filing an issue here, and adding an agenda item for the next CG video call (today's is a bit late, but I'll soon post an agenda for the next meeting, at which point a PR for this can be created). CG video calls are open to all CG members, I suggest this path because it seems like the choice of un-CG-ifying binaryen should be put to CG members.. It's in the spec: https://webassembly.github.io/spec/core/appendix/implementation.html?highlight=implementation%20limit\nRefinements being discussed: https://github.com/WebAssembly/spec/issues/607. I think reducing code contributor friction is good, as long as the project remains something that people can use without fear of non-technical issues (i.e. having to talk to lawyers). With the W3C we have a solid framework, but most open source projects have also figured out similarly solid frameworks so I'm not too worried.\nI do think binaryen will contribute to the CG in the future, but these cases can be handled one at a time, and we can make sure such contributions come from CG members. Does anyone think that extra binaryen -> CG contribution hurdle is a problem? I certainly don't want to add friction to CG contributions.\nAnother thing to consider is whether we're \"promoting\" binaryen more than any other similar project. Are there competing projects which don't get as much traction as binaryen, and would it be better for the WebAssembly organization to feature each such project prominently on its website without promoting one more than the other?\nLet's also make sure any move doesn't break existing links on the internet!\nFinally, where would binaryen live if we were to move it?. This discussion makes me wonder if we even need people to join the CG to contribute significantly to binaryen without actually contributing to the design... That would be a question that W3C folks could answer, we might be in uncharted territory. If not then we can just change our PR approval process.. Will this mess up demangling?. If it seems incorrect, then when does it actually happen? Or is this fixing a non-issue?. Does Itanium name mangling specify how to mangle duplicate symbols?. Whatever makes usages easier short term sounds good to me, and long term follow-up as well. I just figured this was a non-obvious gotcha that you might not have thought about so I should ask :). Sad! That sounded like a pretty fun optimization.. @kripken http://llvm.org/foundation/relicensing/. > @jfbastien Thanks! And to be sure, the wasm projects are going to be licensed in the exact same way as LLVM?\nThat was discussed a long time ago. Probably worth bringing up again at the CG meeting. @binji ?. @kripken can you dig up the prior discussions for this?. Latest update on LLVM relicensing: http://lists.llvm.org/pipermail/llvm-foundation/2018-July/000162.html\n@dschuff I'd suggest you reach out to Danny (and say hi for me!). I had talked to him about it maybe ~3 years ago?. Done, I'll refactor it when I use it elsewhere.\n. Done.\n. clang-format. Do you have a style guide I can teach it? I'd rather just blindly format stuff, we can tell if which style to follow.\n. Sounds good. I won't format things I don't touch though, I'll do incremental.\n. Ah thanks, I hadn't noticed.\n. Done.\n. This is pretty new, older GCC doesn't haz feature and haz builtin... It falls back to abort even though it does have __builtin_unreachable. I could feature-detect GCC, but meh. In other words, this is The Right Way assuming new-ish compilers, others get the old stuff.\n. clang-format doesn't add braces, I just need to get used to it :-)\n. Can't you just conditionally include unistd and the #endif right after? The rest of the file could stay the same IIUC.\n. IIRC this is incorrect: MSVC emits the popcnt instruction unconditionally with __popcnt, which isn't available on all x86 CPUs.\n. Done. I was thinking about reworking the abort_on stuff at some point, it's not super friendly. Tracking line + column would be more helpful I think.\nMaybe later :)\n. Ah right, can you just wrap the use() stuff in #if defined(__linux__) || defined(__apple__) like below? Actually, probably just factor out that #if into its own macro.\n. That looks good.\n. I can import the following: http://src.chromium.org/native_client/trunk/src/native_client/src/include/portability_bits.h\nIt would require me to do it since it involves re-licensing code Google has copyrighted, I can do it in a separate PR if that's OK with @kripken.\n. https://github.com/WebAssembly/binaryen/pull/39\n. It's just to run Python's pep8 style-guide checker (which I run manually) but tell it to ignore 4-spaces style since all wasm codebases seem to use 2-spaces. I mostly just care about consistency, we could switch all the code to 4-spaces and then pep8 would be happy.\n. I'll move that to https://github.com/WebAssembly/waterfall soon, I just need a mirror in the buildbots to prevent flakes (waiting on Chrome infra to do this). Could it just stay where it is right now, instead of moving?\n. Yes.\n. I can do it if you want, but it seems like having the intro first is friendlier?\n. Changed to .\n. Done.\n. Could we share the support library? Maybe I can make it a git submodule? It's used in a few places, the duplication seems silly.\n. Indeed, I'd like to later change the code to parse out the - sign first, and negate if required. Maybe also carry the s/u distinction internally, I'm not sure about that one yet.\nFor now IIUC it does the right thing, without hitting UB.\n. I added an assert (had one before, dropped it because UBsan, but having it seems cleaner).\n. I believe it's this:\ntwoP32:\n        .int64  4294967296\n        .size   twoP32, 8\nWhich was being parsed with the int32 parser.\n. I guess what confuses me is why emscripten_optimizer/ is different. I'd like to use support/ in all parts of the binaryen codebase, including emscripten_optimizer/, so I'm trying to figure out the best way to do so.\n. OK I'll make the change @sunfishcode suggests.\n. Did an unrelated trip to meat-space, but this is now done.\n. Ah gotcha, I didn't realize that.\nI am, but you have to make sure that every single contributor to emscripten_optimizer is OK licensing it to Apache 2.0 as well! Is that the case?\nHaving it in its own repo sounds best IMO, but then it indeed requires duplicating safe integer support or factoring that one into another repo as well. I think it would be best to export both in repos, and generate .a files from them.\nDo you mind if we fix it for now, and factor it out later?\n. I was thinking of:\n- Applying the code as-is for now.\n- Factor out support/ into a separate repo.\n- Factor our emscripten_optimizer/ into a separate repo.\n- Use support/ in the new emscripten_optimizer repo.\n- Update binaryen to use both as submodules.\nWe can dual-license support and emscripten_optimizer, first as MIT + Apache 2.0, and eventually as MIT + Apache 2.0 with exceptions.\nWould that be OK?\nOtherwise, we can do one of:\n1. Fork emscripten_optimizer.\n2. Make emscripten_optimizer configurable: use wasm bits only if present.\n. The dump() function dumps from the current position of s onwards, so the previous error handling prints the file just after the number that was parsed. Setting s only on success prevents this.\nI'd rather just factor out these parsing functions (maybe also in safe_integer), and return value + n_parsed + error, but that's for another time.\n. 2016 now.\n. I just changed the API to either return a std::string or std::vector<char>. Change to:\nauto input(read_file<std::string>(options.extra[\"infile\"], options.debug));\n. std::endl and \\n mixture here and below is a bit odd. std::endl just flushes buffered output as well (std::cerr usually isn't so it's more of a C++ style thing than anything).\n. \"Link and assemble a .s into a .wasm\"\n. I would do typename ReturnType = void here, since it seems to be the default when you use it.\n. This could also be pure virtual, since run already is.\n. C++11 made the extra space in > > not necessary.\nI just use clang-format on all the code I write so there's never any style discussion ;-)\n. The default for WasmWalker is to do nothing, so you can just drop all of the empty visit* methods.\n. Do you want to default to abort()? Or do-nothing?\nIt could be a template parameter as well if both make sense:\nenum class VisitorDefaultBehavior { Abort, NoOp };\ntemplate<typename SubType, typename ReturnType = void, VisitorDefaultBehavior Behavior = VisitorDefaultBehavior::Abort>\nstruct WasmVisitor {\n  // ...\nprivate:\n  void Default() {\n    switch (Behavior) {\n    case VisitorDefaultBehavior::Abort: abort();\n    case VisitorDefaultBehavior::NoOp: break;\n    }\n  }\n  ReturnType visit*(...) {  Default(); }\n  // ...\n};\n. Yes, that's the ugly bit but it's squirreled away in the implementation. LLVM does it with a macro:\nhttps://github.com/llvm-mirror/llvm/blob/868145efb053c3f9294676cf4f36d6220e500269/include/llvm/IR/InstVisitor.h#L30\nI think it's pretty nice with a macro :-)\n. You shouldn't need the default case because we build with warnings that would tell you if you were missing one of the enum cases (as long as the type of curr->_id is enum). The compiler then assumes curr->_id must be one of the enum's values, and implicitly the default is __builtin_unreachable().\n. for (size_t z = 0, e = list.size(); z < e; ++z) {\nOr could you use a range-based for loop?\nSame comment for the other loops below.\n. byte & ~128 ?\n. Placeholder for what?\n. TODO: use waterfall\n;-)\n. Why is that the maximum for size?\n. const auto &buffer\n. Inc/dec of depth in debug code is correct? Doesn't that change what visit(curr) do depending on whether debug is on or not?\n. auto &child. Can it be const also?\n. auto &c, here and others below.\n. An alignment of 0 in the binary format means natural alignment? If so, it would be good to make it a symbolic constant instead.\n. Use std::pow<size_t> so it's explicitly using the integer variant.\n. This is using the floating-point log2 function, but you could instead assert(popcnt(mem) == 1); and then use ctz instead of log2.\n. Add a std::string ctor to IString instead?\n. auto *\n. You can run clang/tools/clang-format-diff.py to only format what you've changed. I use the emacs integration, where formatting is just one key-combo away :)\n. Hmm, there should be... default: WASM_UNREACHABLE(); is also fine, if all the compilers don't agree. I thought it was only MSVC that got that error nowadays (it's fixable by using the unreachable idiom in MSVC assume(false);).\n. It depends: some datastructures don't inline well, and sometimes the calls in the loop confuse the optimizer into emitting the size call on every iteration.\nRange-based-for will indeed fail if there's mutation, would be good to validate.\n. I'd instead just do os.path.exists('wasm-binaries-%s.tbz2' % rev), no need for local_rev. That's what update.py does. Could you use #117's code for that?\n. Same here, #117 should make this easier.\n. untar expects to get the name that the tarfile untars into, I guess that's not sure intuitive: wasm-install-$(build).tbz2 contains a single folder: wasm-install. The second parameter should be the path to where you want wasm-install to be, including wasm-install.\nIIUC you want WATERFALL_BUILD_DIR = os.path.join(BASE_DIR, 'wasm-install') and then below LLVM_DIR = os.path.abspath(os.path.join(WATERFALL_BUILD_DIR, 'bin')) though I'd call it BIN_DIR instead since it contains more than LLVM.\n. Ah OK, didn't know that. Sounds a bit dangeous to have const char * not have the same thing?\n. All the programs are using the same command-line support, so they either all work on none of them work ;-)\nI can add a separate command-line only test, but that seemed like overkill.\n. Correct, it's not tested elsewhere. It just seemed arbitrary to test it just for the shell, it seems better to test all the bin/ content or none of it. I can add such a test if you want.\n. I'd rather keep PIE, and use -fno-omit-frame-pointer. Also, -g3 is nicer if we're doing debug information, but then I'd rather split the build properly into debug and release (because I don't want to pay the debug info size overhead on release builds).\n. All the programs now use support/command-line.cpp, so you should probably just set it from there.\n. 2016\n. Yeah that's not portable ;-)\nCan you just use glibc's backtrace and backtrace_symbols when available, and do nothing otherwise (patches welcome if someone else cares)? e.g. through weak symbols.\n. I'm usually a fan of using xmacros for this type of repetitive table-like stuff :-)\nHave an external .inc file with macro-ized things like DO(SIGNUM, MESSAGE), and then #define DO(SIGNUM, MESSAGE, ...) ... and #include \"signals.inc\".\nIt's way less repetitive that way.\n. 2016\n. I usually prefer the C++ version of C headers.\n. clang-format, it sometimes catches the next line and formats it too.\n. Add symbolic constants for the mask, and reuse at the other place?\nAlso, assert the value is a nan?\n. You also need to check signbit is the same. \n. Though nans compare not equal all the time. If either is nan the comparison should be false (even if it's the same nan). \n. Ignore my refsctor comment, I just saw that you modified the code below. That's what I get for reviewing kn a phone from the airport. \nI'd still assert the number is nan though. \n. Isn't that the semantics we want, though?\n. Why add ceil? When you use std::log2() you get the integral version but it returns a double? Aren't the integer values you care about all correctly represented by double?\nAlso, why int8_t?\n. I thought the number had to be a power of 2? I guess it makes sense to have ceil if it doesn't have to be.\n. The vector's memory isn't guaranteed to be aligned either. A vector<double> would be but then you can't correct cast from it to the other types (only char works). We could allocate sizeof(double) extra and realign, but that breaks down when you resize causing a realloc which is now unaligned. All corner cases really because after a certain size the allocator plays nice anyways.\n. I made all of them explicit to avoid these types of ambiguity issues. It should be working as expected now? We could also use enum class to make things even more explicit.\n. Right, I was trying to get both to agree, but I can continue trying to get them to agree (by allocating a minimum size) yet check the actual address (so the behavior is correct). I'll do that today :)\n. ULL\n. Oh extra change, I initially modified implementedFunctions and had to change all its uses, but then put it back. I didn't realize I'd changed it to something else (I was just restoring the old behavior), but it can only ever be 0 or 1 so != seems more natural?\n. This is checking whether a --start was provided: an empty string means no. It's now .is() because of Name's API.\n. Actually it's !!startFunction which is horrible but .is() doesn't do the right thing.\n. Because it refers to a string \"\\0\" which isn't nullptr, whereas operator! checks for nullptr and str[0] == '\\0'. It's not very idiomatic C++!\n. startFunction is initialized with a std::string which makes it \"\\0\" because Name passes that to IString's ctor. So yes, it's a valid zero-length string :-)\nI much prefer idiomatic std::string, despite its shortcomings! Commoning strings is fine in some cases, but I'm not sure these tools really need it especially for such short strings which could just be inline. We could also use folly::string which is more configurable and closer to std::string. Also well tested, but I'm biased on that ;-)\n. String performance on large strings are a gain with the Name approach, but small strings usually win with the inline approach that most std::string implementations use. Names are usually small, so without measurements showing otherwise I'd just stick to std::string until we measure a perf issue. There's also the idiomatic argument: C++ APIs work a certain way, Name looks different and isn't obvious. This !! thing is an example of that.\nI went with Name since the rest of the codebase does that, but the corners seem sharp from here!\n. Oh, that's creating the _start function, creating enough locals to match main's (or rather, whatever startFunction says the function name is) expected arguments, and calling main with these arguments. It then exports _start and creates the (start $_start) entry.\n. Is this on purpose?\n. I'd use CHAR_BIT as the non-magic-number for \"bits per byte\" (here and other places).\n. A char is always one byte in C. CHAR_BIT is \"number of bits for smallest object that is not a bit-field (byte)\". In C++ \"For any object (other than a base-class subobject) of trivially copyable type T, whether or not the object holds a valid value of type T, the underlying bytes (1.7) making up the object can be copied into an array of char or unsigned char. If the content of the array of char or unsigned char is copied back into the object, the object shall subsequently hold its original value.\"\n. Here and other places, could you use numeric_limits instead of the macros?\n. What do both truncates to when out of range? Are there tests for them?\n. The active member is f32 here, no? That would need to be bit_cast to i32 first.\n. Same.\n. Here too, what happens on invalid inputs and is it tested?\n. std::signbit\n. I'm not super comfortable mapping the C++ STL behavior to wasm's, but I guess it'll do for now.\n. This is funny.\n. Color handling to cout seems wrong? Not related to this patch though.\n. 2016\n. Can't you continue chaining this since printWasm returns a stream ref?\n. 2016\n. The guidance changes on this, but the latest I've gotten is that the file date should be the one that the file was created on (it used to be: update every time a substantial modification happens, with date ranges).\nThis should all get fixed when / if we re-license :-)\n. Can you instead use markdown links and not HTML?\n. Oops, yes! Done.\n. Could you open a bug to fix this, and remove this define? I don't think we should be using these functions :-)\n. Use numeric_limits here instead of hard-coding these values.\n. This should be std::streampos, but it's probably better to use auto here.\n. cctype gives you std::isdigit.\n. We only have debug and release configurations on line 10, are relwithdebinfo and minsizerel ever possible?\n. Could you use an enum instead of a bool?\n. It's more about expressing intent: what does binary=false mean? Not a big issue, I just find it easier to document it that way.\n. You could use enum class and not need Flags namespace.\n. enum class would force writing the enum name in front.\n. Correct. It seems less confusing to me, but your way is fine if you prefer.\n. This is an odd way to organize things. In general I'd like static libs to contain everything under a folder, and nothing else (i.e. folder hierarchy reflects library hierarchy). It makes it way easier to understand how things work.\npass.cpp should move under passes/, and parres/ contains a bunch of passes which should be in passes/. That doesn't seem to make sense though, so the organization should probably be different (more subdirs under passes/?).\nThe \"right\" way to keep this clean is probably to use cmake's add_subdirectory from the root cmake file, and then have each subdir create whatever it wants (static libraries most likely).\n. Assert alignment is a power of 2?\n. Add to support/ utilities similar to LLVM's:\n```\ninline uintptr_t alignAddr(const void *Addr, size_t Alignment) {\n  assert(Alignment && isPowerOf2_64((uint64_t)Alignment) &&\n         \"Alignment is not a power of two!\");\nassert((uintptr_t)Addr + Alignment - 1 >= (uintptr_t)Addr);\nreturn (((uintptr_t)Addr + Alignment - 1) & ~(uintptr_t)(Alignment - 1));\n}\n/// \\brief Returns the necessary adjustment for aligning \\c Ptr to \\c Alignment\n/// bytes, rounding up.\ninline size_t alignmentAdjustment(const void *Ptr, size_t Alignment) {\n  return alignAddr(Ptr, Alignment) - (uintptr_t)Ptr;\n}\n```\nNicely reusable.\n. Why is this virtual? CRTP visitors shouldn't need any virtuals.\n. static\n. static std::atomic_flag\n. ?\n. std::atomic_flag v = ATOMIC_FLAG_INIT; should do it.\n. Oh I was silly and misread your usage. atomic::<bool> is the right solution with what you've written.\n. auto after = std::chrono::high_resolution_clock::now();\n. std::chrono::duration<double> diff = after - before;\n. Uggghh I'm really annoyed that std::make_unique is only C++14. /endrant\n. Weird include, doesn't \"support/threads.h\" work? We should just add it to the cmake search path if not.\n. static on both.\n. They're not :-)\nhttp://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#2046\n\nThe thread-id for global static initialization is unspecified, but it is not the default-constructed thread.\n\nThey can be called in parallel, or another thread than main.\nAlso: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0250r1.html\n. So yeah that should probably be in main.\n. If the above moves to main that this is also better off being held in the same lifetimes, instead of running into global object nightmares.\n. Add a comment to explain what the notification means.\n. Print thread id here and elsewhere? Makes it easier to de-interleave different debug prints.\n. That should be entirely avoided if the init is moved to main.\n. size_t num = std::max(1, std::thread::hardware_concurrency());\nand drop the next line.\n. The assert and store are racy without the lock you have in notifyThreadIsReady. Some a huge deal since it's an assert, but still...\n. Yeah C main() would construct the object, which contains all the stuff you need initialized early. If you want main's thread ID then there's not really a better way. You can still \"register\" the pointer to the object when it's constructed, and store that pointer in a static in this .cc so that you don't need to pass the pointer around.\n. \"only on the main thread\" comment is still correct? Are you just relying on tsan to catch violations of that rule?\n. Same, main thread?\n. Can you instead use std::stoi since it does error checking?\n. Is C needed?\n. > oh also, I think we do still need to call the destructor in this case before we reallocate, but I'm not sure; maybe @jfbastien knows?\nYes.\n. Hoist out this -g3 instead of duplicating below?\n. auto\n. ?\n. Dynamic alloca :(\n. Dynamic alloca :(\n. Sorry, should have elaborated: would have been nicer to have a container instead, so you can use the default dtor.\n. Small stack allocations are fine, but this one is controlled by the input, which is a Bad Idea. Dynamic allocation is better in those cases.\n. Right, my check isn't full-paranoid :)\n. #431\n. This is probably a better solution:\nhttps://cmake.org/Wiki/CMake_RPATH_handling\n. Change %lu to %zu instead?\n. Sorry, only just catching up to github. This looks good.\n. We can set up a .clang-format file: http://clang.llvm.org/docs/ClangFormat.html\nI'd like to be able to just format stuff and not have to worry about style :-)\nWould that be OK with you?\n. Without static libs it means all free-standing uses need to set LD_LIBRARY_PATH, which is pretty annoying for users I think. Why not stick with static in that case? rpath is the common thing otherwise.\n. Had to fix LD_LIBRARY_PATH in #441. RPATH really seems better...\n. TODO?\n. This is deprecated.\n. The version taking a UniformRandomNumberGenerator isn't deprecated, but getting uniform random numbers isn't implemented the same way in different STL implementations so you can't really use that either (it's better to write your own).\nMT is well defined though, so that's a good base to start from.\n. You don't need this only once thing since function static vars are guaranteed to be safely initialized once, on first call, even if there are threads. You can just have static PatternDatabase *database = new PatternDatabase;\n. And then the function is getDatabase() and returns that static value. No global. \n. It can be an atomic operation. I'd use what the language provides unless this benchmarks as a performance problem.\n. Atomics trap if misaligned as well.. https://github.com/WebKit/webkit/blob/master/Source/JavaScriptCore/wasm/WasmLimits.h. The official discussion is here: https://github.com/WebAssembly/spec/issues/607. ",
    "weilianglin": "I see. So before running WASM code, load_mapped_globals() should be called to copy imported variables to the correct locations and inside WASM, global variable access is interpreted to load/store of linear memory. \n. No, I also convert asm.js generated by EmScripten to v8-native binary format. Since v8-native still supports Global variable, I need to consider how to initialize the imported variables to the global variables. My current solution is to import variables by FFI function call, like\nModule.asmLibraryArg.getSTACKTOP = function getSTACKTOP() { return STACKTOP; };\nThen modify the asm.js code to call this initialization before running _main function. \n. In V8 binary format, functions and imports should share the same index space. Function table is encoded like below\n[kDeclFunctionTable, func_table_count, function_index1, function_index2, ...].   // index into the functions segment entries. \nFor call_indirect opcode, its encoding is like\nCallIndirect, func_signature_index, index_inside_func_table\nThanks\n-Weiliang\n. ",
    "jcbeyler": "If it helps, I just support it. It means that in the end you have one testsuite that is shared by all instead of forking that part.\n. So if it helps, I actually do exactly that. Though the input accepts multiple modules and the assert syntax, I end of generating one module per file and a separate file for all the asserts.\n. So it' s done inside my code. Basically I raise everything to a WasmModule then each WasmModule gets called via Generate and that creates a new file for each.\nAssertions for me return 0 on success or an integer for failure. This allows me to get it to return the line number of the assertion failure (I suppose it will never be 0 :)).\nI do not support yet assert_traps, ignoring them and assert_nan is handled internally by dong something similar to what binji is doing.\nI then have somehing similar to what binji has: a big function that LLVM generates for me that calls each of these asserts and bails if one returns a non-0 value (returning it). Then my driver will catch that return and say: hey you have an issue at this line\n. Agreed, I do that manually to keep the HEAD sane. Doing it at build time is really an invitation to having issues for the user / testers / etc.\n. Plus bug reports would become really annoying since each user might have a different configuration depending on what is happening in the submodules compared to what you have or will have by the time you test...\n. True I read way too fast the code. The pull command would be adding new updates :)\n. Actually you could put an option to build.sh that does the update or not and then test for that option. At least that way you don' t have to have two different scripts, no?\nIt' s mostly a build time question. Every time you build you will have to wait for git to finish checking the submodules. So depending on how often you are building, you may or not start caring about this\n. ",
    "TheKK": "git submodule update won't checkout the latest commit for submodules, but stay at the commit when you add it as submodule unless you manually checkout to different commit in submodules then commit changes in binaryen.\nPerhapse updating submodule in build.sh is not the best idea. But since files from these submodules are needed while running check.py, I think we should tell others to download them or help them with that.\n. As I know binaryen is now seeking for new build system, does that means build.sh will gone in the future? If so, maybe we could just put submodule update instruction to README, otherwise adding an option to build.sh sounds nice.\n. ",
    "ghost": "The V8 binary format might be a waste of time, and they already have a wast to binary encoder for testing, so perhaps just check that it can encode the asm2wasm output.\nIf you are working on the binary format then here's some background that I absorbed looking at publicly released prototypes and a little experimentation.\nThe polyfill-prototype-1 still seems a useful guide and it used a number of techniques to compress the opcode encoding but it is now obsolete because it was designed for a fixed set of opcodes and the current design appears to require supporting an arbitrary set of opcodes.\nIt used separate opcode tables for a child branch of the AST based on the immediate parent opcode, using the type I32, F32, and F64 to distinguish between opcode tables. This would appear to generalize to an adaptive tree based compression approach.\nIt used a byte size encoding which might be very significant for another 'string' based compression layer to do well with the output. However it does appear that a variable size Huffman encoding could do much better, and it's not clear if a general 'string' based compressor could predict the patterns nearly as well from a linearised AST.\nIt uses a one byte encoding for a few high frequency opcodes that includes an short immediate within this byte. Bit 7 encodes between the immediate format and the non-immediate format. The immediate format includes a 2 bit opcode field and a 5 bit immediate field. The non-immediate format includes a 7 bit opcode field.\nSome quick checking shows that considering both the parent opcode plus the argument position can give much better prediction for some high frequency opcodes. A simple Huffman encoding could compress these child opcodes very well above. Using a general 'string' compression algorithm would miss some of these patterns because there might be other branches between a parent opcode and a child opcode breaking up the 'string'.\n. Emscripten generated asm.js for the zlib benchmark. This example looks like asm.js if (i3 >>> 0 > i1 >>> 0) ...  Any asm.js unsigned operators might has similar issues.\n. From the zlib benchmark:\nUnnecessary block:\n(func $establishStackSpace (param $i1 i32) (param $i2 i32)\n    (block\n      (i32.store align=4\n        (i32.const 8)\n        (get_local $i1)\n      )\n      (i32.store align=4\n        (i32.const 16)\n        (get_local $i2)\n      )\n    )\n  )\nUnnecessary block $topmost, and unused block label.\n(func $b0 (param $i1 i32) (result i32)\n    (block $topmost\n      (call_import $abort\n        (i32.const 0)\n      )\n      (i32.const 0)\n    )\n  )\nThis one could be eliminated:\n(func $___unlockfile (param $i1 i32)\n    (block $topmost\n      (br $topmost)\n    )\n  )\nTwo unnecessary block $topmost use:\n(func $_bitshift64Ashr (param $i1 i32) (param $i2 i32) (param $i3 i32) (result i32)\n    (block $topmost\n      (if\n        (i32.lt_s\n          (get_local $i3)\n          (i32.const 32)\n        )\n        (block\n          (i32.store align=4\n            (i32.const 168)\n            (i32.shr_s\n              (get_local $i2)\n              (get_local $i3)\n            )\n          )\n          (br $topmost\n            (i32.or\n              (i32.shr_u\n                (get_local $i1)\n                (get_local $i3)\n              )\n              (i32.shl\n                (i32.and\n                  (get_local $i2)\n                  (i32.sub\n                    (i32.shl\n                      (i32.const 1)\n                      (get_local $i3)\n                    )\n                    (i32.const 1)\n                  )\n                )\n                (i32.sub\n                  (i32.const 32)\n                  (get_local $i3)\n                )\n              )\n            )\n          )\n        )\n      )\n      (i32.store align=4\n        (i32.const 168)\n        (if_else\n          (i32.lt_s\n            (get_local $i2)\n            (i32.const 0)\n          )\n          (i32.const -1)\n          (i32.const 0)\n        )\n      )\n      (i32.shr_s\n        (get_local $i2)\n        (i32.sub\n          (get_local $i3)\n          (i32.const 32)\n        )\n      )\n    )\n  )\nTwo unnecessary blocks:\n(func $___muldi3 (param $i1 i32) (param $i2 i32) (param $i3 i32) (param $i4 i32) (result i32)\n    (local $i5 i32)\n    (local $i6 i32)\n    (block $topmost\n      (set_local $i5\n        (call $___muldsi3\n          (get_local $i1)\n          (get_local $i3)\n        )\n      )\n      (set_local $i6\n        (i32.load align=4\n          (i32.const 168)\n        )\n      )\n      (block\n        (i32.store align=4\n          (i32.const 168)\n          (i32.or\n            (i32.add\n              (i32.add\n                (i32.mul\n                  (get_local $i2)\n                  (get_local $i3)\n                )\n                (i32.mul\n                  (get_local $i4)\n                  (get_local $i1)\n                )\n              )\n              (get_local $i6)\n            )\n            (i32.and\n              (get_local $i6)\n              (i32.const 0)\n            )\n          )\n        )\n        (get_local $i5)\n      )\n    )\n  )\n. Note sure about your first point. Functions seem to accept a list of expressions so the top block seems unnecessary (or perhaps this is just a difference between v8 and the current spec)?\nExplored some clean up passes (but just hacks in lisp):\n1. Firstly removed unused block labels. Walk the code, maintaining a stack of blocks with their labels and a use-counter. At exit of the block scope, flush the label is unused. Special case a single trailing break out of the block and remove it and the label.\n2. Flatten the blocks within contexts that already accept a list of blocks. Walk the code noting blocks and loops and lift un-labeled blocks into the parent list of expressions.\nThis seems to make the code a little more readable, and does reduce the compressed size. Also experimenting with when and unless for the common `if-block' patterns, which also improves readability and size, and removes some more explicit blocks.\n. Thank you for making a start. There is a little more to it. Need to keep a stack of the block labels to be able to account for those in scope. Fwiw, here are the CL implementations:\n``\n(defun remove-unused-block-labels (ast)\n  \"Remove named blocks that are not referenced. Destructively modifies\n  the 'ast.\"\n  (flet ((walk (name args results locals body)\n           (declare (ignore name args results locals))\n           (let ((blocks nil))\n             (labels ((remove-unused-block-labels* (ast)\n                        (cond ((not (consp ast)))\n                              ((and (eq (first ast) 'block) (symbolp (second ast)))\n                               (let* ((label (second ast))\n                                      (binding (cons label 0)))\n                                 (push binding blocks)\n                                 (dolist (expression (rest (rest ast)))\n                                   (remove-unused-block-labels* expression))\n                                 ;; Check that that 'blocks stack has been restored.\n                                 (assert (eq (first blocks) binding))\n                                 (cond ((zerop (cdr binding))\n                                        ;; Remove the label from the block.\n                                        (setf (rest ast) (rest (rest ast))))\n                                       ((= (cdr binding) 1)\n                                        (let* ((last (last ast))\n                                               (last-expression (first last)))\n                                          (when (and (consp last-expression)\n                                                     (eq (first last-expression) 'br)\n                                                     (eq (second last-expression) label))\n                                            ;; Block ending is a br out of the block, so eliminate the label.\n                                            (cond ((cddr last-expression)\n                                                   ;; A 'br' with an expression. Expect just one value.\n                                                   (assert (not (cdddr last-expression)))\n                                                   (setf (first last) (third last-expression)))\n                                                  (t\n                                                   ;; No expression, insert a nop?\n                                                   (setf (first last)(nop))))\n                                            (setf (rest ast) (rest (rest ast)))))))\n                                 (pop blocks)))\n                              ((member (first ast) '(br br_if))\n                               (let ((label (if (eq (first ast) 'br_if) (third ast) (second ast))))\n                                 (assert (symbolp label))\n                                 (let ((binding (assoc label blocks)))\n                                   (when binding\n                                     ;; Found a reference to a block label within scope.\n                                     (incf (cdr binding))))))\n                              (t\n                               ;; Some other form - walk the elements.\n                               (dolist (el ast)\n                                 (remove-unused-block-labels el)))\n                              )))\n               (remove-unused-block-labels body)))))\n    (map-wasm-functions #'walk ast))\n  ast)\n(defun flatten-blocks (ast)\n  \"Flatten unnecessary blocks, blocks with no label and used in a context that\n  already permits a list of expressions. Destructively modifies the 'ast.\"\n  (flet ((walk (name args results locals body)\n           (declare (ignore name args results locals))\n           (labels ((flatten (bexp)\n                      ;; Flatten child block into the 'bexp list of block expressions.\n                      ;; Expecting a cons to be updated if necessary.\n                      (assert (consp bexp))\n                      (do ((bexp bexp (rest bexp)))\n                          ((endp bexp))\n                        (let ((first (first bexp)))\n                          (when (consp first)\n                            (walk first)\n                            (when (and (eq (first first) 'block)\n                                       ;; If not a br target then flatten.\n                                       (not (symbolp (second first))))\n                              ;; Insert it into the current block expression list.\n                              (setf (first bexp) (second first))\n                              (setf (rest (last first)) (rest bexp))\n                              (setf (rest bexp) (rest (rest first))))))))\n                    (walk (ast)\n                      (when (consp ast)\n                        (let ((first (first ast)))\n                          (cond ((eq first 'block)\n                                 (cond ((symbolp (second ast))\n                                          (flatten (rest (rest ast))))\n                                       (t\n                                        (flatten (rest ast)))))\n                                ((member first '(let))\n                                 (flatten (rest (rest ast))))\n                                ((member first '(when unless))\n                                 (walk (second ast))\n                                 (flatten (rest (rest ast))))\n                                ((member first '(loop))\n                                 (assert (symbolp (second ast)))\n                                 (assert (symbolp (third ast)))\n                                 (flatten (rest (rest (rest ast)))))\n                                (t\n                                 (dolist (el ast)\n                                   (walk el)))))))\n                    )\n             (flatten body))))\n    (map-wasm-functions #'walk ast))\n  ast)\n```\n. Thank you.\n1. There is the case of a trailing br in a block targeting the same block. Where there is no br result expression can we just replace it with nop. For example:\n(func $_zcfree (param $i1 i32) (param $i2 i32)\n     (block $topmost\n       (call $_free\n         (get_local $i2)\n       )\n       (br $topmost)\n     )\n   )\n2. Opportunity missed here:\n(func $_i64Subtract (param $i1 i32) (param $i2 i32) (param $i3 i32) (param $i4 i32) (result i32)\n    (local $i5 i32)\n    (set_local $i5\n      (i32.sub\n        (get_local $i2)\n        (get_local $i4)\n      )\n    )\n    (set_local $i5\n      (i32.sub\n        (i32.sub\n          (get_local $i2)\n          (get_local $i4)\n        )\n        (i32.gt_u\n          (get_local $i3)\n          (get_local $i1)\n        )\n      )\n    )\n    (block\n      (i32.store align=4\n        (i32.const 168)\n        (get_local $i5)\n      )\n      (i32.sub\n        (get_local $i1)\n        (get_local $i3)\n      )\n    )\n  )\n1. Block in a loop.\n(loop $label$break$L17 $label$continue$L17\n        (block\n          (block $label$break$L19\n(block $label$break$L19\n            (tableswitch $switch$0\n1. Block in a case (just noticed this one, and it's not handled in my code yet either). Also a dead br here and could this be emitted to use the switch break label.\n(case $switch-case$1\n                (block\n                  (set_local $i16\n                    (get_local $i14)\n                  )\n...\n                  (br $label$break$L17)\n                  (br $switch$0)\n                )\n. Updated flatten-blocks to better handle loop and case.\nAdded the canonicalize-block-targets pass. Here's an example:\n(block $a (exp) (block $b (exp (br $b)) (br $b)))\n=>\n(block $a (exp) (block $b (exp (br $a)) (nop)))\nThe other passes can then clean this up to:\n(block $a (exp) (exp (br $a)) (nop))\nPractically only the elimination of the redundant trailing breaks seems useful on the asm2wasm output.\nHere's a real example. The (br $do-once$0) is eliminated as it falls through to the target anyway, and this allows the other passes to optimize away its target block.\n(block $topmost\n       (block $do-once$0\n         (if (i32.eq (i32.load (i32.const 9500)) (i8.const 0))\n             (block (set_local $i1 (call_function $_sysconf (i8.const 30)))\n               (if_else\n                (i32.eq\n                 (i32.and (i32.add (get_local $i1) (i8.const -1))\n                  (get_local $i1))\n                 (i8.const 0))\n                (block (i32.store (i32.const 9508) (get_local $i1))\n                  (i32.store (i32.const 9504) (get_local $i1))\n                  (i32.store (i32.const 9512) (i8.const -1))\n                  (i32.store (i32.const 9516) (i8.const -1))\n                  (i32.store (i32.const 9520) (i8.const 0))\n                  (i32.store (i32.const 9472) (i8.const 0))\n                  (i32.store (i32.const 9500)\n                   (i32.xor\n                    (i32.and (call_function $_time (i8.const 0))\n                     (i8.const -16))\n                    (i32.const 1431655768)))\n                  (br $do-once$0)) ; <<<<<\n                (call_function $_abort)))))\n       (br $topmost))))\n. Thank you. Yes, I was not running it with all the passes. Looking again, there are still opportunities to flatten blocks within loop and case. Also do we need to insert a nop when removing the br $a in (block $a (exp) (br $a)) so that the block still returns the same values rather than the values from (exp)?\n1. Block in loop not flattened.\n(loop $label$break$L17 $label$continue$L17\n        (block\n          (block $label$break$L19\n            (tableswitch $switch$0\n1. Block in case not flattened\n(case $switch-case$1\n          (block (set_local $i7 (i8.const 4)) (br $switch$0)))\nThere still remain some redundant br uses in block sub-expressions that could be removed, and sometimes removing these makes labels unused allowing a block to be flattened, but perhaps these could be addressed in a separate issue if at all.\n. It looks like this block was not flatten only because they are not optimized. Thank you.\n. Managed to get the set_local hoisted out of the if_else, but it looks like a smarter pass (dominator analysis) might be needed in general to then optimize away the local variable. Shall assume these are asm.js artifacts and will follow up if there are still similar issues with llvm.\n. The good examples, from compiled asm.js code are embedded in large functions. Perhaps this is just a carry-over from asm.js generation. I have trouble relating the wast back to the asm.js in a huge function, but this asm.js looks like it might translate into similar code. I'll give up on the asm.js path for now, and move to working with the llvm output and follow up if the issue remains.\nif (!i224) {\n       i265 = i247;\n       i266 = i249;\n       i267 = i250;\n       i268 = i252;\n      } else {\n       i225 = i224;\n       do {\n        i224 = HEAP32[i5 + 104 >> 2] | 0;\n        i225 = i225 + -1 | 0;\n        HEAP32[i5 + 104 >> 2] = i224 + 1;\n        HEAP16[i5 + 112 + (i224 << 1) >> 1] = i229;\n       } while ((i225 | 0) != 0);\n       i265 = i247;\n       i266 = i249;\n       i267 = i250;\n       i268 = i252;\n      }\n. Just out of curiosity, the llvm backend currently emits a .s file in a format that is not vaguely like wast. This tools is describe as 'Assemble a .wast (WebAssembly text format) into a .wasm (WebAssembly binary format)' and if so then the wasm-as naming looks confusing. Is it planned that the current .s format becomes the text format and superseded wast or might there be a separate .s format?\n. Track it down to the function signature-index and decl-flags being used in the wrong order. The fix would be to just flip their order in readFunctions and writeFunctions.  The design document has these backyards compared to the v8 reference implementation and the sexpr-wasm-prototype - already noted this at https://github.com/WebAssembly/design/issues/497. I recall encountering issues in the design document but noting move in particular, so practically comparison with the sexpr-wasm-prototype output and v8 testing might be needed.\n. The input was corrupted, misunderstood.\n. @kripken noted off-list that the problem was caused by an 'address taken but is not implemented' and the failure occurred trying to convert only .s file of a larger project, thank you. So the lesson is to not expect to be able to convert individual .s files to wast. That also seems to make wast/wasm not suitable as an 'object code' format even for pieces of statically linked code, but I guess that is fine because the bc will be linked.\n. @kripken Yes, pretty sure this is how the v8 encoding works a present. Perhaps the wasm spec allows an import in the function table? If so then how can this conflict be resolved?\n. @kripken This whole exercise seems to be to get something work using the v8 encoding fwiw, and then iterate. Can we follow v8 for now to get things working, and separately explore this grey area?\n. @kripken The implementation. The spec wording is 'index into the function segment entries, referencing a function', and perhaps the final qualification was intended to communicate that the imports and exports are excluded in this index.\n. 1. The implementation, the v8 source code, and their sexp converter, use an index into the functions excluding the imports.\n2. The v8 design spec, the documentation, notes the wording 'index into the function segment entries, referencing a function'.\nIt appears a consistent interpretation of the spec. I think we should use the implementation except perhaps in edge cases, but this is not an edge case, it's a very clear and a common path. There are probably also tests in the v8 source that define the expected interpretation. Writing clear documentation can be a challenge so such areas can be expected to need further qualification, so it should not be take literally.\n. @titzer The index space issue is a difference between call_indirect and call_function. V8 function tables are indexes into only the functions excluding the imports, whereas call_function has an index space including both functions and imports. Can you confirm that the wording in the spec follows the implementation?\n. @weilianglin Thank you. I know what the v8 implementation does, and this PR is to align the binaryen tool with this, but there is also a v8 design specification which specifies the table index is an 'index into the function segment entries, referencing a function'. I seems a consistent interpretation to me, but other people want some extra confirmation. So it might help so get an answer from @titzer just to confirm that these are consistent and that the v8 implementation is the correct interpretation of the design spec and not a bug?\n. @titzer Thank you. So the bug is in sexpr-wasm-prototype. Here's a test I used to convince myself:\n;;; EXE: test/run-d8.py\n(module\n  (type $i_v (func (param i32)))\n  (import $print_i32 \"stdio\" \"print\" (param i32))\n  (import $print_i32_i32 \"stdio\" \"print\" (param i32 i32))\n  (func $test (result i32)\n    (call_indirect $i_v (i32.const 0) (i32.const 400))\n    (return (i32.const 1)))\n  (export \"test\" $test)\n  (table $test)\n)\n(;; STDOUT ;;;\n400\ntest() = 1\n;;; STDOUT ;;)\nHere's the table section produced by sexpr-wasm-prototype:\n0000030: 05                                         ; WASM_SECTION_FUNCTION_TABLE\n0000031: 01                                         ; num function table entries\n0000032: 0000                                       ; function table entry\n0000034: 06                                         ; WASM_SECTION_END\nThis is what confused me, the $test function in the table is mapped to index 0. If this were correct then I believe the above example would loop, but it actually seems to call $print_i32 which is index 0 in the combined function index space. Sorry for the noise.\n. Checks pass, but only by copying the new results into the expected results. ptal.\n. Many of the $var$0 instances are bad. For example emcc_O2_hello_world.wast.fromBinary, first function $_malloc, about one page into the function:\nemcc_O2_hello_world.wast\n(set_local $i3\n              (i32.shr_u\n                (get_local $i2)\n                (i32.const 3)\n              )\n            )\n            (set_local $i4\n              (i32.load align=4\n                (i32.const 176)\n              )\n            )\n            (set_local $i5\n              (i32.shr_u\n                (get_local $i4)\n                (get_local $i3)\n              )\n            )\nemcc_O2_hello_world.wast.fromBinary \n(set_local $var$0\n              (i32.shr_u\n                (get_local $var$1)\n                (i32.const 3)\n              )\n            )\n            (set_local $var$0\n              (i32.load align=4\n                (i32.const 176)\n              )\n            )\n            (set_local $var$0\n              (i32.shr_u\n                (get_local $var$0)\n                (get_local $var$0)\n              )\n            )\n. Double checked this in the v8 source code: typedef BitField<bool, 4, 1> OffsetField;\n. Updated to use units of pages in the wast text format.\n. See https://github.com/WebAssembly/binaryen/issues/225\n. Sorry, also should have noted it drops the case index for the default at 0000019 abovr.\n. Caught by the kitchen_sink test and noted along with a few other issues in https://github.com/WebAssembly/binaryen/issues/138\n. @kripken Checking the actual output of v8. The sexp-wasm has a test/d8/select.txt that includes:\n(func $i32 (param i32) (result i32)\n    (i32.select (get_local 0) (i32.const 1) (i32.const 2)))\n... \n   (call $i32 (i32.const 0))\nwhich generates\ntest_i32_l() = 2\nand is encoded as\n; function 0\n0000016: 00                                         ; func flags\n0000017: 0000                                       ; func signature index\n0000019: 0000                                       ; func body size\n000001b: 05                                         ; OPCODE_SELECT\n000001c: 0e                                         ; OPCODE_GET_LOCAL\n000001d: 00                                         ; remapped local index\n000001e: 09                                         ; OPCODE_I8_CONST\n000001f: 01                                         ; u8 literal\n0000020: 09                                         ; OPCODE_I8_CONST\n0000021: 02                                         ; u8 literal\nSo it seems to be a documentation error.\n. It seems fair to see the document as derived from the implement in this case. The issue that @sunfishcode refers to is a change request for select not a clarification of the current state (from my reading of it anyway). Not sure why there has been no action of the select change, but conflating it with a br_if change might not have helped.\n@titzer Need some clarification on this one too?\n. @titzer If you support change select to put the condition last, which I am not arguing against, then could you please consider approving @sunfishcode PR in https://github.com/WebAssembly/design/pull/489 and just the select change if that is all there is consensus on. I would just like the tools to generate code compatible with the spec and implementations for a start - to get something running.\n. Lot more work here then I have time to complete or check.\n. The current code is far too strict. Not all sections are required and they need not be in order. There are just some constraints. The current code can not even read the output of sexp-wasm, nor my own encoder unless it has specific flags to emit specific patterns that wasm-dis accepts.\nBe more tolerant when decoding. Accept omitted sections, and accept them in any order except where there is an ordering constraint. Try to catch repeated sections.\nAvoid emitting unnecessary sections when encoding.\n. Sorry, this does not appear to fix the issue. See failures for all these opcodes now: 9d 9e 9f a0 a2 a3 a4 a5 a8 a9 aa ab ad ae af b0 b1 b3 b4 b5\n. The block size becomes a leb128 and the function body size become uint32 (fixed width to be easy to patch). Seems fine to me. I would not worry about interoperability at this stage. If it were me I'd just submit the patch to v8 and sexp-wasm. Would you like me to help by doing this?\nI was just wondering about the local variable sizes, why they are uint16 not leb128. Might it be in part because 2^16 is a good limit for implementations anyway, or are these to be revised too?\n. @titzer Some producers patch the function body size, so it helps them if it is a fixed width, however it does not seem a big burden to write it to memory first and then to a file when the body size is known.\n- Number of locals, currently uint16, would work easily as LEB128.\n- Function signature index, and length, currently uint8, also would work easily as LEB128.\n- Function flags, memory access flags, currently uint8. Moving to LEB128 might allow for extension?\n- Memory size, currently uint8, patches pending to use LEB128 in units of pages.\n- An i32.const.leb128 ? and a signed version?\n- An i64.const.leb??? and a signed version. Is an i32.const and i8.const accepted to functions expecting an i64?\n. Sorry, the function bodies are expected to be moved OOL, so it would be a burden to pre-compute their size. It would be necessary to compute all the function body sizes before emitting the functions section if they were all OOL. So a good reason to keep if a fixed width.\n. @kripken The issue of the export and import names has already been raised and these seem to be clearly the export and import names in the v8 encode. Binaryen needs to stop using the v8 encoding function name as an internal label name.\nThere seems little point hacking the power-of-two memory size when there are patches pending to move to a size in units of pages. Why don't you just land these patches to resolve the problem.\n. Great. Did you change all those u8's to leb128 too?\n. Perhaps these tools would be better off handling the floats as binary bits, rather than using native floats internally. If we simply had a raw bit representation then the tools could just pass them through as 32-bit or 64-bit integers. I have read the related issues, and I think I understand that you want to separate nan from the real numbers, but the binary encoding does not make this distinction and if we want to canonicalize the floats then surely this will need to be done by the runtime when reading them, but people could still put them in a data segment so what has been achieved.\n. binaryen's most important place appears to be assembling the llvm output, and perhaps similar roles. Would there be any support for emitting the hex-float format as the default. This might make it practical to strip the FP parsing/printing support from a deployed tool, and this is probably a significant chunk of code compared to the rest of tools such as wasm-as.\n. @jfbastien '-+nan' fails to parse in the ml-proto.\n. There is discussion on optimizing the encoding of the get_local and set_local immediate index by placing them in their own section (just the indexes), and similarly for constants - I understand this is 'layer-1'. Personally I thought the constant pools in the initial prototype looked useful, and perhaps could be re-visited, but this might need to be considered in light of a layer-1 and perhaps can be handled there.\n. A quick look at the i32.const.txt suggests many are int8 and should have been emitted in i8.const operators. Is binaryen using i8.const?\n. Looks like it could be made a command line option for a manage transition and for experimentation.\n. Has someone written a specification that you are following or is it a matter for experimentation?\nAre there particular goals for this decision?\nIt does not look like a pure post-order encoding. For example the EndMarker seems to just terminate a pre-order operator. If you wanted post-order then a block could still have an immediate count and would just pop the expressions from the stack.\nIf people want to actually interpret this code then it will need to deal with the values resulting from these expressions, so either need to explicitly discard unused values for each expression or be pre-order. To discard the unused values in a post-order encoding will require explicit pop operations be included. If you want to explore this then you might want to change the representation from an AST to a stack machine and evaluate that.\nI also expect people will want single-pass AST conversion with validation so will need to track pre-order state for some of these operations.\n. @kripken But if 'post-order' is just a 'general goal' then what basis is there for a move towards this? Would it not be more prudent to explore both options and then compared them on technical merit?\nIf abstracted well, and if it only affects the serialization of the AST, then if should not be a big burden for tools to support both pre and post order encodings.\nThere are some basic questions that no-one has been willing or able to answer such as:\nIs there an expectation that interpreters will interpret the code literally, or is it expected that it will be decoded into an AST first? It might be important because if interpreted literally then there is no top-down information, no expected types, no expected number of values, no function result type, no block labels. It becomes a stack machine and there is no longer an AST.\nIf it's is just a matter of the serialization of the AST then it might still have implications for single pass SSA conversion and for compression efficiency. It not clear how single pass SSA conversion could be done efficiently without pre-order information?\nAlso some effort was made to have binaryen be consistent with the v8 encoding, issues were filed on differences etc, and some progress has been made on resolving differences between the v8 encoding and the wasm spec. A quick look suggests that the only area still needing resolution is the br arity and mv issues - that seems really close to me. Plus the naming and number of some operators, which I submit a PR for soon.\n. Thank you all for the feedback. It's obviously much more subtle than just a post-order encoding, a hybrid. I'd like to implement an encoder/decoder and check the compression and explore some concerns. It would be very interesting to be able to compare the pre-order interpreter to a post-order interpreter, in particular I would like to understand the story for multiple values and if it now needs a pop operator and how validation would work etc. I'll have to follow up.\n. Might want to take a look at https://github.com/WebAssembly/binaryen/pull/121 and can I close it if your work addresses it all?\n. Not sure if that upstream issue was exactly related, but I left a note: https://connect.microsoft.com/VisualStudio/feedback/details/1559819/integer-literal-type-promotion.\nThe Compiler Warning (level 2) C4146 doesn't make any sense in these situations, IMO.\nBTW, I can't find it in the current master build logs, e.g.: https://ci.appveyor.com/project/WebAssembly/binaryen/branch/master/job/vcu72dj2y3r93fab. Probably because /Wall is disabled for VCR builds?\n. Thanks @kripken! I tried running the hello world example: bin/asm2wasm ./test/hello_world.asm.js in Windows PowerShell, it gives me: Fatal: Could not find pass: dce.\nApparently, dce pass does not initialized only print, print-minimized and print-full get attention of static initializer.\nIs the information in Readme outdated or should I open an issue? :)\n. If this is achievable via CMake configuration, that would be pretty awesome.\nAmong all the \"passes\", only the RegisterPass in Print.cpp is getting called. I don't know how this one is not optimized away by the compiler. The rest of the passes code is optimized when building asm2wasm.\nAFAIK, the linking is on demand with VC compiler in a way that if we want to keep those symbols alive (and tell the optimizer to back off), we would need to bring about certain configurations. I tried all the documented ways (setting /Include via pragma, setting /OPT:NOREF, turn of optimizers), but none of these worked. The static initilizers RegisterPass in all other passes source files except for Print.cpp don't get called. The robust approach suggested by commenters on the SO question (http://stackoverflow.com/q/9459980) is to either have the static registration code reachable or add a an custom registration function and explicitly call it after the translation unit executes.\n@equalsraf, @sethjackson, @joncaves, @jkotas, could you guys suggest a better way to make linker force kick the static initializer with VC 2015? After running the cmake . config build command (https://github.com/WebAssembly/binaryen/issues/577#issue-158915795) I opened binaryen.sln in VS215, set asm2wasm as a start up project and put a breakpoint in pass.cpp's ctor: https://github.com/WebAssembly/binaryen/blob/f6b5c1e/src/passes/pass.cpp#L33-L36. \nps - we are pursuing to incorporate experimental code generation for wasm in Core[RT/CLR]: https://github.com/dotnet/coreclr/issues/5303\n. > Would it work on windows?\nI think it has nothing to do with Windows as if we compile the code MingW compiler, it would work? But it is not working when compiled with VC++ compiler. The static initialization of dead code path is undefined behavior that is, for C++ compiler it is up to the implementer/vendor choice whether or not the optimizer should wipe out the code before static initialization happen. The implementation of binaryen is tied to GCC compiler's UD behavior. Unix/Windows is not the issue here.\n\nHow about just making the library with passes a shared library as opposed to static?\n\nWouldn't it be too invasive to change it from static->shared just for readability problem, compared to \"hey, what if we have forward declaration of all the passes structs in pass.h which is included everywhere that matters, and we have forward-declared like half of them structs already there, why not all?\" :smile: \nSomething like:\npass.h (already included by asm2wasm.cpp and all the other entry points of utilities)\n``` cpp\n// Line 226 onwards\nstruct DeadCodeElimination : public WalkerPass>> {\n  // forward declare the list of members here\n};\nstatic RegisterPass registerPass(\"dce\", \"removes unreachable code\");\nstruct DropReturnValues : public WalkerPass>> {\n  // forward declare the list of members here\n};\nstatic RegisterPass registerPass(\"drop-return-values\", \"stops relying on return values from set_local and store\");\n// and so on\n```\nthen use scope resolution in code files DeadCodeElimination.cpp etc. while removing structs re-definitions.\n. @kripken,when I was searching for similar flag for VC++, I found /OPT:NOREF optimizaiton and /INCLUDE linker flags of interest, but people were suggesting the behavior varies from compiler to compiler and that relying on static initialization to register objects is a bad idea in C++. Can you point me to C++ spec mandating the retention of static lib objects when optimizer has the opportunity to eliminate it as dead code? This way we will declare it as VC++ bug and report it to their bug tracker.\n. Sounds like \"whatever LLVM does or doesn't\" is a defacto standard over ISO. :smile: \nBut at any rate, with this bug still lurking, the VC builds are broken in a false-positive manner. For future, we can probably setup AppVeyor CI configure (in addition to TravisCI) in order to avoid build breakage on Windows.\nThanks for your patience.\n. Thanks @juj for the PR. Would also be nice to figure out or if some veteran Windows dev could point out that which flag to keep in our back pocket to make the static init magic happen in VCR for cases like these.\n@dschuff, nice points, now we have working clang on Windows too so future is looking promising. ;)\n. > using namespace\nThere is an excellent thread about this being a bad practice: http://stackoverflow.com/q/1452721.\n\nCan we tell VS to do only c++11, as we do for unix?\n\nOld way: https://msdn.microsoft.com/en-us/library/ff770576.aspx (requires older VS toolset to be installed)\nNew feature introduced in VS2015 Update 3: https://blogs.msdn.microsoft.com/vcblog/2016/06/07/standards-version-switches-in-the-compiler/ (which only supports /std:c++14 and /std:c++latest but not the down-versions.\n\nMy opinion is to get rid of \"using namespace\".\n. When you log on with GitHub Account, it would show a dropdown menu to select organization before proceeding to dashboard (given you are a member of WebAssembly org on GitHub).\n. It's all green now https://ci.appveyor.com/project/jasonwilliams200OK/binaryen/build/1.0.37 :smile: \n. This is how it appears to me:\nBefore login:\n\nAfter login with GitHub account:\n\nWhen I select the organization name from the drop down menu and press GitHub button again on the second screen, it takes me to https://ci.appveyor.com/projects where it lists the projects of this organization which are being monitored by AppVeyor. If it is some existing project which hasn't been configured yet, then we press the New Project button on top and list GitHub, BitBucket and so on in the left menu and the available projects in the right.\nDid you grant it access to your public repositories and organizations? Had you opted for no, then you can change it again by going to https://ci.appveyor.com/account, where you can revoke the github access and reauthorize .. this time permissively. :smile: \n. I think your issue seems to be related to https://github.com/appveyor/ci/issues/801#issuecomment-221960339 and https://github.com/appveyor/ci/issues/802. What I have gathered from this situation (which the issues probably don't list yet) is that if you are a collaborator to an organization and your membership is not visible publicly (GitHub profile such as in your profile WebAssembly is not listed to public), then AppVeyor doesn't recognize the membership. If you make the membership to WebAssembly visible and Revoke->then->Authorize again, does it then land you to the second-step login screen?\nyou can make your membership back to invisible after configuring the repo :)\n. Great, then it probably doesn't matter if it is observing the upstream rather than the fork (which is another kind of weirdness since that is suppose to only happen at https://ci.appveyor.com/project/WebAssembly/binaryen).\nYou can also view the settings page of this repo to find AppVeyor generic webhook: https://github.com/WebAssembly/binaryen/settings/hooks (just to validate everything is fine). It should be something like https://ci.appveyor.com/api/github/webhook   (pull_request and push). If that is there, then I will update README in this PR to point to dschuff/binaryen since that is configured. Whenever the upstream account will be setup, only the badge URL in README would be good to change.\nPlease let me know if the webhook is there so i can amend the commit. :)\n. @kripken, regarding the publicly visible membership, there seems to be a profile setting on GitHub, which lists the organizations under the display picture on profile page (https://github.com/kripken) for public. For example I can only see Unity3D logo on your profile. Probably AppVeyor is relying on the same kind of scope.\n. @dschuff, I googled the issue again and found this: http://help.appveyor.com/discussions/questions/1154-appveyor-account-for-github-organizations. This probably translates to our scenario like this:\n- As a collaborator (of any kind), signup with a regular appveyor account for organization called WebAssembly: https://ci.appveyor.com/signup.\n- Login with that account and go to https://ci.appveyor.com/account page and authorize with GitHub.\n- Then go to https://ci.appveyor.com/projects/new, select GitHub (first item in left menu -- already selected), scroll down to organization called WebAssembly and take binaryen from there.\nIf that works then we will have  https://ci.appveyor.com/project/WebAssembly/binaryen and this PR is good to go as is. :)\nWould you give it a try? Otherwise i will update the URL in readme.\n. Great! Thanks @dschuff. Then this PR as is ready. :)\nI have re-pushed the commit to see if AppVeyor shows up on the PR, but it does not. Seems like this solution might work: http://stackoverflow.com/questions/32607885/appveyor-doesnt-update-github-pull-request-with-the-build-status.\n. @FeodorFitsner (from AppVeyor) could you please suggest what steps need to be taken in this case to make AppVeyor build trigger in PR? Here is the account setup https://ci.appveyor.com/project/WebAssembly/binaryen and this PR is adding appveyor.yml but it is not triggering the build.\n. Thanks Feodor. I think we need someone with access to https://github.com/WebAssembly/binaryen/settings/hooks to verify if the appveyor webhook \"Payload URL\" value is same as the value of \"Webhook URL\" at https://ci.appveyor.com/project/WebAssembly/binaryen/settings. This normally gets added automatically and we never have to visit the settings page, but in this case we might have different URL.\n@dschuff, can you ping the owner of repo? Note that the full payload URL gets visible in edit mode; on list view it just shows https://ci.appveyor.com/api/github/webhook   (pull_request and push) (not the ?id part) clicking on it will open the edit view.\n. Thanks. I pushed a test commit, apparently it didn't triggered. :(\n. Yay, it worked! Thanks Derek. :)\nThe whole job matrix takes about an hour to build. We may want to remove the Debug builds or fast_finish+allow_failure (https://www.appveyor.com/docs/appveyor-yml line 105). What do you think?\n. Oh wow, it is taking 12 mins! I guess its a paid account thing (since the account is in trial period). So it spawns one VM per job on Azure cloud. For regular account it probably builds on their local servers using some first-come-first-serve / merry-go-round protocol. :smile: \n. We have: { mingw64, msvcr32 and msvcr64 } x { Debug, Release } configurations.\n. Amended; now we have mingw64 and msvcr{32,64} in Release, as well as msvc64 in Debug. Total of four jobs.\n. @FeodorFitsner, the badge URL https://ci.appveyor.com/api/projects/status/github/WebAssembly/binaryen?svg=true (public repo format) is rendering failure , while the build on master head is passing. Given that this account is trail and considered paid until the account expired while the repo is public, would we have to wait until the trail expired to get green status from badge using public URL format?\n. Can you give an example of stack-machine code that can not be expressed (with only encoding loss) in a structured AST? There might not be any such examples, given that dropping stack elements is currently constrained to block boundaries.\nAn explicit block1 was considered some time ago see https://github.com/WebAssembly/design/issues/650 As you note if it is explicit then it does not solve the problem as using it changes the code. While the text format might use it just for presentation, what if people use it in excess and this still need to be encoded. Also this is still limited to structured uses in the scope of the block.\nBut this can not express multiple uses of the function results, and does not work for functions returning multiple values in general. A general solution is needed, and I appeal to people to solve the general case first then optimize it for high frequency cases.\nThe example could also be presented as the following:\n(letc (($c0 (gimme-i32))\n       ($c1 (gimme-i32)))\n  (no-value-returned)\n  (i32.add $c0 $c1))\nAnd when people code references to these local constants that do not fit the stack usage pattern they would simply be encoded with get_value aka pick/pick_and_void. We could also move the function arguments onto the stack. Why not consider this proposal, it was communicated some time ago yet seems to have been ignored and there has been no rationale given?\nThe other option is the 'Stop consuming WebAssembly' option but I would look at it from a different perspective and view it as conceding that the wasm binary code is just a compressed encoding of the language that developers will actually work with and that the language that binaryen consumed would be the wasm text format and debugging would step through that code not the stack code which would be a throwaway intermediate encoding, just as debuggers do not step through compressed encodings. This would focus on the SSA decoded format, which is really what this is all about, and it might be better for analysis and transforms, but distant from the stack machine code. This would be a last-resort strategy, working around the product of the wasm group, but why should the group be in such a position, it is our group.\n. @kripken A sketch of a single pass stack-machine to text format algorithm is at https://github.com/WebAssembly/design/issues/753 This does not use a first operator, rather lexical constants, which would seem to work with the current proposal in the stack-machine to text direction, but be fragile in the other direction without the pick operator. Perhaps you can work it into something concrete, or if you find any show stoppers or loss then please report it so it can be understood and pondered. You could explore the utility of the pick operator, which would probably eliminate a lot of local variables.\n. @kripken If you introduce first now then the text format will probably be stuck with it and given that the lexical constants can also represent this pattern then there are now two text formats for the same stack machine code introducing a loss. I don't even think first aka block1 is a familiar operator to JS programmers so why bother introducing it, it's a dead end. A plan is needed.\n. @kripken A fundamental problem with this plan is that it still does not address multiple values. Development needs to more forward, develop a counter proposal that addresses the issues, rather than just resisting development and shuffling the chairs. People care about wasm because it is a deployment platform.\nI think the general point you are making about the disconnect between the language that producers want to easily emit and the twisted stack machine constraints is a key point. The same was seen with the x87, a numerical stack machine, where compilers just wanted to connect inputs and output but had to work around frustrating stack machine constraints, and to optimize for these constraints, and and to be able to annotate where values were for debugging. The pick operator helps a little as it can access values in general up the stack, but if the requirement that a block stack be empty except for the out values stands then this will require really frustrating swap and drop sequences to clean up the stack.\nIf wasm is just a target, and not optimized for code size, then the expressionless register based code is much simpler for producers.\n. @kripken The lexical constants, the pick aka get_value proposal, seems to be able to address the multiple values use case with a minimum complexity for an expression based language, so function return values are immediately assigned to these lexical constants and are then handled by single value expressions. It is close to the stack-machine proposal, but with some significant differences from what has been proposed.\nThe other option is to depend on local variables, and this takes wasm down the expressionless encoding path. The encoding efficiency was not as good, and the live range of definitions is not as well defined, but it would be a simple compiler target.\nA language with more general multiple values support was explored in https://github.com/WebAssembly/sexpr-wasm-prototype/pull/66 and the comments detail the design and operations.\n. The problems need to be solved, wasm is a deployment format, a web format, a format that developers will work with, so it needs to be more than a cryptic convoluted encoding.\nThere is a proposal that might address the 'dead code' problem. It looks like blocks will unwind. It's moving in the right direction to keep a useful structured presentation. If there are show stoppers then lets talk about them, solve the problems?\nIf wasm will not fly by the judgement of the community group then that would be a show stopper, no one would want that outcome, it will be resolved. I think the group has come a long way in the past six months, I see light at the end of the tunnel, just a little more patience, focus on the problems.\nI get the impression that binaryen might have run into a small barrier of having to change strategies, perhaps some help to get over these would clear the way, but the problems need to be understood and we need some clarity on where wasm is going which might take just a little longer.\n. @qwertie Your text format does not appear to be constrained to a 'familiar' structured code style, could adapt to even a linear stack machine code, so that is the reason it is a distant consideration for me. The show stoppers in the presentation format for me are other matters, such as structure and variable references etc, things that could be presented in a range of formats. I would be happy at this stage to even defer choices over a particular text format, defer the bike shedding, until post-MVP so long as there are some demonstrations of workable familiar text formats.\n. Reading code is subjective, subjective for the consumer, be it people or the machine, but that does not mean that readability if not a concern. If I were to put it to people that readability were subjective to the machine too and thus not a concern of the group then surely people would shake their heads. We have a large community group or experienced programmers to make a subjective judgements on the readability of the wasm format. I can point to many areas of readability for people that align with readability for machines too. These are not matters that can just be cast aside as subjective and ignored. The choice of chairs is also a subjective matter for the community group, but does that mean they can be arbitrary, the group members will make a judgement!\nThe lossless transform of the stack machine code to a structured presentation format seem possible, has been discussed elsewhere. If there are show stopper then please raise them? In the absence of show stoppers then it must be accepted as a technically plausible fact, so claims that the only presentation of the wasm code is a linear stack machine code are not sound, as not a sound basis for binaryen diverging.\nThe binaryen IR will need to address the multiple values problem to, so be as semantically expressive and efficient as the wasm code. It does not appear to have a path to doing so, so is unfortunately a dead end stuck were the wasm design was over six months ago.\nIf binaryen development were to engage and embrace the path being explored then it might add to the developement effort. I had personal encouraged this exploration many months ago, explaining how pick could be used to address the problems, giving examples of where I was at. So binaryen is six months behind now, is not adding much to development of the wasm design, but that seems understandable.\nA possible path forward, to get over this barrier, might be for that lossless transform to be coded up. Perhaps doing so in the binaryen development environment is a chunk of work, but perhaps someone could prototype it in a rapid prototyping language, ocaml etc, and use s-exp etc. I really do not see the technical show stoppers, the decoder might need to be more type aware but is that a show stopper. Attempting to write this transform would shed light on any show stoppers and add to the wasm design development.\nAnother path might be for binaryen to add an SSA decoder and to work on the SSA form. Wasm is designed to be easily decoded to SSA form, so this is not a big task. This might also help keep the decoder efficiency in mind, might make some decoder efficiency tests possible in binaryen etc, and perhaps help discover ways to optimize code to make this decoder more efficient (less intermediate phi's etc).\n. @kripken Supporting multiple values returned from function calls is a measurable runtime performance feature. The hardware likely supports returning some of these in registers, so it can be done efficiently. Without this feature these return values would need to be in the linear memory. The CIL style solution is to bundling them into a return structure. So can we agree that to that point it is a runtime performance feature?\nFrom then it is a matter of connecting these return values to their uses in the wasm encoding. At one extreme all the results could be stored in local variables, and at the other extreme all pushed to the values stack which is the proposed design solution. These choices might not affect the runtime performance of an optimizing computer, I can agree on that, but might for a baseline compiler and it might have a measurable impact for decoder efficiency and for some of the same reasons that it affects readability for people (people reading code want to know the scope or live range of values too, and the expression pattern helps a lot here, as would block scoped constants). If you wrote an SSA decoder for binaryen these issues would be clear, you would see the difference it makes to the work need at control flow merge points, the difference it makes to the known live set for a baseline compiler, and probably learn more and be back contributing to the wasm design development. Binaryen does some great optimizations of the expressions, and perhaps you could do something similar with a different set of constraints.\nI would like to understand the 'awkward semantics' and the 'downsides for the Binaryen optimizer', see if people can propose some solutions, and understanding these can be very valuable input into the wasm design, getting this right is the next step. I don't see the same conclusion that you seem to be seeing from the discussions, perhaps an example would help me understand?\nThe structured stack machine design is moving towards the SSA encoding which should be good for optimizations and transforms. If the function arguments are pushed onto the stack it would be closer again, and if loops could accept (pop) arguments then these could be emitted in SSA style, the pick operator gives the scoped SSA definitions. Writing an SSA decoder might help see some opportunities here.\n. @kripken Thanks, an example. So what is the problem here? The s-exp has a first node not in the stack machine encoding. Solution is to decode it away to a more workable representation, or just don't use first rather scoped constants (just like SSA definitions are referenced).\n```\n(i32.eqz\n  (first\n    (tee_local $x (call ..))\n    (store $x (i32.const 1))\n  )\n)\n\ncall\ntee-local $x\ni32.const 1\nstore\ni32.eqz\nAlternative representation:\n$def1: ..\n$def2: ..\n$def3: call $def1 $def2\n: set_local $x $def3\n$def4: i32.const 1\n: store $def3 $def4\n$def5: i32.eqz $def4\n```\nShould be easy to decode the wasm stack code into this format. It requires some type information, such as the number of arguments and results for functions calls, but is that a show stopper?\nConverting back to the stack code might not be so hard either, but might require live range information, but I thought binaryen already has that information to optimize the emitted expressions.\nConverting to the text format is also relatively easy. The definitions could just be presented as scoped constants, but with some live range information it could be usefully emitted as expressions where they fit.\nAre there problems with this approach? If the wasm encoding frustrates this then we need to bring them closer. Experience trying would likely help move the wasm design along.\n@qwertie first does not solve the problem in general, and we do need a general solution and need a plan for wasm otherwise the MVP might be a dead end. Your following example is not a familiar structured language, and the s-exp proposal already seems to allow something similar so this is just another way to present it. I think that the choice between s-exp or LES does not block the path of wasm, not in the same way that sorting out the handling of multiple values does.\n$y; $x; i32_eq; if {\n    1; set_local $x\n}\n. Moving call d earlier, if possible, would have advantages for performance, it would avoid the need to preserve the result of call c across the call d. But just use an IR closer to the wasm stack-machine code, for example in the following this transform is justified due to the real issue of reducing the live set at calls rather than some more remote cost associated with nodes.\n(block\n  (call a)\n  ($def1 (call c))\n  (call d)\n  (call b $def1)\n  (call e))\n=>\n(block\n  (call a)\n  (call d)\n  ($def1 (call c))\n  (call b $def1)\n  (call e))\n@qwertie LES alone does not make a 'better text format'. You seem to be arguing that LES can present both a structured language with expressions, and a list of stack machine instructions, so it seems already accepted that the choice of LES versus s-exp versus something else does not block wasm development. LES is free to change the naming if that helps, we can all accept that and opcode names do not block wasm design. Is there anything related to LES that requires changes to the wasm design?\n. @lukehutch It's not so bad, sleep on it and take another look. There is not really a 'stack machine' rather wasm is designed to decode to validated SSA form quickly, and with a few extensions code could be encoded in SSA form, so the 'stack machine' could be viewed as just an efficient encoding. The stack encoding is frustrating to work with, so just don't, it's not intended to be an IR, it's an encoding, just decode it to SSA form and work with that, and wasm is designed to make this easy to work with untrusted code by being able to validate and decode it to SSA in a single pass - that is good isn't it? Even the local variables are just place holders for holding definitions while decoding and are expected to be gone at the end of the decoding stage.\nThe design is not even complete, we don't have high performance decode/compile implementations yet and I suspect that some more changes will be necessary to support this. Wasm is optimized to compile down to machine code AOT, before it runs anyway, not incrementally compiled as needed and not optimize for an interpreter which is still possible.. @lukehutch I am trying to do just that, made some recent progress, but I don't have a conclusion on the encoding efficiency just yet. It is possible that @kripken is right, that the local variables will prove to be an efficient encoding and SSA 'much larger', but I am a long way from conceding just yet and if I do I'll be able to explain it. There are certain many functions that encode well in SSA form, but also see data flow patterns that are a challenge and I need to work through them.. @lukehutch Here's a quick example of where I'm at with it, the main function from a zlib benchmark. Compare it to binareyen IR and I hope people see merit in this, perhaps imagine it in your preferred language format. Obviously the code below needs work, lots of patterns that are not optimal, just trying to get to the proof of concept stage. E.g. many of the br_case paths need jump threading and can just fall through, the loop could fall through here, and I have a long long list of other patterns that need work. You'll just have to wait on the encoding efficiency, or perhaps ask @kripken if he really knows.\n(func $main ((n0 i32) (n1 i32)) (i32)\n   (declare (export \"main\"))\n   (set n2 (i32.sub (i32.load :offset 4 0) 16))\n   (i32.store :offset 4 0 n2)\n   (set n14\n        (block $block-1\n          (set n4\n               (block $block-2\n                 (br_if $block-2 (values 500) (i32.lt_s n0 2))\n                 (set n3 (i32.add (i32.load8_s (i32.load :offset 4 n1)) -48))\n                 (when (i32.gt_u n3 5)\n                   (i32.store n2 n3)\n                   (drop (call $printf 160 n2))\n                   (br $block-1 (values -1)))\n                 (br_case nil (0 1 2 3 4 5 0) n3\n                      (case (br $block-1 (values 0)))\n                      (case (br $block-2 (values 60)))\n                      (case (br $block-2 (values 250)))\n                      (case (br $block-2 (values 500)))\n                      (case (br $block-2 (values 2500)))\n                      (case (br $block-2 (values 5000))))))\n          (set n5 (call $malloc 100000))\n          (block $block-12\n            (loop $repeat-8 (n6 n7 n8) (values 0 0 17)\n               (set (n9 n10)\n                    (block $block-9\n                      (when (i32.lt_s n7 1)\n                        (unless (i32.and n6 7)\n                          (br $block-9 (values (i32.and n6 31) 0)))\n                        (br $block-9 (values n7 (i32.rem_u (i32.mul n6 n6) 6714))))\n                      (br $block-9 (values (i32.add n7 -1) n8))))\n               (i32.store8 (i32.add n5 n6) n10)\n               (set n11 (i32.add n6 1))\n               (br_if $repeat-8 (values n11 n9 n10) (i32.ne n11 100000))\n               (br $block-12 (values))))\n          (block $block-14\n            (loop $repeat-13 (n12) (values 0)\n               (call $doit n5 100000 n12)\n               (set n13 (i32.add n12 1))\n               (br_if $repeat-13 (values n13) (i32.lt_s n13 n4))\n               (br $block-14 (values))))\n          (drop (call $puts 176))\n          (values 0)))\n   (i32.store :offset 4 0 (i32.add n2 16))\n   (values n14))\n. @lukehutch It's binaryen output decoded to SSA retaining the control structure. There are already provisions in wasm to do encode much of this and it's a minor variation of the encoding:\n\n\nprovisions for blocks returning multiple values, presented as (set (v1 v2) (block ...))\n\n\nprovisions for loops having a signature which is used for the phi nodes here. The phi nodes and their values popped on loop entry are presented as (loop (n1 n2) (values v1 v2) ...) in the loop header here.\n\n\nTo encode the above requires adding the pick operator. \n\n\nThe above is presented in packed expression format, but it can be presented one operator per statement, it's just a different presentation. It's not clear above which definitions need pick and which are consumed in stack order, but that seems an encoding detail. Some redundant type information is also omitted in the presentation above.\n\n\nThe encoding benefits from having block ends unwind the stack.\n\n\nThe function arguments are pushed on the stack.\n\n\nChanged br_table to a table-case operator as the constraint on br_table of passing a fixed set of values to all targets was trouble to work with. Need to revisit this.\n\n\nThe lack of a label and separate signature for the loop exit path was trouble, so wrapped them all in a block and need to revisit this.\n\n\nThe control structure need not be preserved, it can be convert to basic blocks, perhaps numbering them to retain some ordering.\n\n\nIt is not necessary to start with binaryen wasm output. E.g. it is possible to start with machine code and structure the CFG and convert to SSA then convert it to the above format, and I do that too, write out C and compile it and decode it back to wasm just to double check. Found much simpler algorithms than the relooper to structure the code, one or two pages of code.\n\n\nHere's the above translate roughly to C, the C compiler cleans it up. Obviously a linear memory scheme needs to be chosen too, but for trusted code aligned to the target memory it would be as simple as follows. Have wasm code compiled in this way demonstrated running on IoT devices. Add pointer masking and good type derivation to minimise it and the code has a new layer of security and relatively good performance even without memory management. Add C type annotations and it can interoperate with C libraries cleanly. It's not valid C code due to all the casting, needs some compiler flags, perhaps there is a better approach, need to revisit.\nuint32_t main(uint32_t n0, uint32_t n1) {\n    const uint32_t n2 = (*(uint32_t *)(0 + 4)) - 0x10;\n    *(uint32_t *)(0 + 4) = n2;\n    uint32_t n14;\n    {\n        uint32_t n4;\n        {\n            if ((int32_t)n0 < (int32_t)2) {\n                n4 = 0x1F4;\n                goto $block_2;\n            }\n            const uint32_t n3 = ((int32_t)*(int8_t *)(*(uint32_t *)(n1 + 4))) + -48;\n            if (n3 > 5) {\n                *(uint32_t *)n2 = n3;\n                _printf(0xA0, n2);\n                n14 = -1;\n                goto $block_1;\n            }\n            switch (n3) {\n            case 1:\n                    n4 = 0x3C;\n                    goto $block_2;\n            case 2:\n                    n4 = 0xFA;\n                    goto $block_2;\n            case 3:\n                    n4 = 0x1F4;\n                    goto $block_2;\n            case 4:\n                    n4 = 0x9C4;\n                    goto $block_2;\n            case 5:\n                    n4 = 0x1388;\n                    goto $block_2;\n            case 0:\n            default:\n                    n14 = 0;\n                    goto $block_1;\n            }\n        }\n    $block_2:;\n        const uint32_t n5 = _malloc(0x186A0);\n        {\n            uint32_t n6 = 0;\n            uint32_t n7 = 0;\n            uint32_t n8 = 0x11;\n        $repeat_8:;\n            {\n                uint32_t n9;\n                uint32_t n10;\n                {\n                    if ((int32_t)n7 < (int32_t)1) {\n                        if ((n6 & 7) == 0) {\n                            n9 = n6 & 0x1F;\n                            n10 = 0;\n                            goto $block_9;\n                        }\n                        n9 = n7;\n                        n10 = ((n6 * n6) % 0x1A3A);\n                        goto $block_9;\n                    }\n                    n9 = n7 + -1;\n                    n10 = n8;\n                    goto $block_9;\n                }\n            $block_9:;\n                *(uint8_t *)(n5 + n6) = n10;\n                const uint32_t n11 = n6 + 1;\n                if (n11 != 0x186A0) {\n                    n6 = n11;\n                    n7 = n9;\n                    n8 = n10;\n                    goto $repeat_8;\n                }\n                goto $block_12;\n            }\n        }\n    $block_12:;\n        {\n            uint32_t n12 = 0;\n        $repeat_13:;\n            {\n                doit(n5, 0x186A0, n12);\n                const uint32_t n13 = n12 + 1;\n                if ((int32_t)n13 < (int32_t)n4) {\n                    n12 = n13;\n                    goto $repeat_13;\n                }\n                goto $block_14;\n            }\n        }\n    $block_14:;\n        _puts(0xB0);\n        n14 = 0;\n    }\n $block_1:;\n    *(uint32_t *)(0 + 4) = n2 + 0x10;\n    return n14;\n}. @lukehutch The efficiency comes from the common case of definitions that have a single use and are consumed in a stack like order, or in other words code that can be represented as an expression and encoded pre-order or post-order. Serial encodings are just not a good representation for some 'useful things' to do with the code, pre-order or post-order.. @lukehutch I gave up long ago on seeking an encoding with a one-to-one mapping to a useful presentation language, and it took me too long to realize that it's not necessary as you can define a canonical decoding that should be sufficient, sorry to people on that one. So consider the wasm binary as having many possible encodings for the same canonical language, and variations on that canonical language can be encoded in an unknown section. Perhaps you'll come to the same realisation at some point, but it seems healthy to explore and challenge.\nPractically the stack code is also interpreted and is even the default view-source format it seems. I would like to see some web browser hooks to allow custom presentation formats for view-source so the community can explore a range of text formats, and perhaps it will be possible some day.\nThe wasm code has structured control flow, which relates back to the validation. There are no operations that push a dynamic number of values and the stack depth is always uniquely defined (ignoring some differences in unreachable code).. Interesting example, but can't binaryen just note the signatures for blocks when it either parses them from the wast or decodes them from the binary, then it does not have to infer the block types, rather just check that all is valid. Their might be input sources for which the block signatures are not given, but it seem only necessary on those paths to infer the types, and these paths might just have to do some extra work to ensure that the fill block signatures are consistent top-down and bottom-up.\n. @dschuff That function would be invalid AST because the number of arguments to the return does not match the expected number. The stack machine code is valid, just not yet expressible in binaryen (one of the stacky) examples. The AST still needs to know the number of arguments to check that they match.\n. It's an interesting discussion. Still seem to be some matters to settle. Might it help to note why a block end fall-through might be unreachable, that this can not be worked around, with an example:\n(block $l0\n  (block $l1\n    (br_if $l1 ...)\n    (br $l0)\n    )\n  ...\n  )\nThen if the block fall through needs to be type validated then it seems to create some challenges. \n- What is the state of the stack after the branch, in the unreachable code area? Has the branch just popped its consumed values and left the rest, or like the br_if decision not touched any?\n- Does the branch push an unreachable value onto the stack? If the block returns no values then does this need to be dropped?\n- We seem to still have the requirement that the block stack be empty after consuming the values for the fall-through, so do the remaining values need to be dropped?\n- If a block returned multiple values then does it need multiple unreachable values pushed on the stack.\n@kripken there seem to be a lot of issues with the unreachable code and have you given any thought to the burden on binaryen of implementing the proposal in https://github.com/WebAssembly/design/issues/778\n. No use case for supporting the transform (X) => (block (Y) (X)) where the block label is not used comes to mind? It appears that in such cases the block is unnecessary and can be flattened into the parent block. If there are some examples then they might be interesting to consider?\nPerhaps binaryen could add an internal block type for a block for which the tail is unreachable, and just ensure that it is flattened before emitting the wasm. If there is a real need for this then perhaps this needs a type in wasm too.\n. A first/reverse-block does not solve the problem in general when the pick operator is added. Adding pick solves the problem in general, and then rather than using a local variable the value is left on the stack and picked as needed, and in the AST it can simply be expressed as an assignment to a constant block scoped variable so the solution is very similar to what was done here but without actually adding a local variable.\nI assume the trouble binary 'stacky' code was the following which can be expressed nicely in the AST as follows:\n(get_local $var$0)\n(set_local $var$0 (i32.const 100))\n(get_local $var$1)\n(i32.add)\n=>\n(set $c1 (get_local $var$0))\n(set_local $var$0 (i32.const 100))\n(i32.add $c1 (get_local $var$1))\nSo when the decoder finds that void operator while it is building an expression, it flushes all the pending pieces of expressions into these local constants (rather than adding local variables and a block). When the code pops these it just references them by name, so $c1 here. If these were being used multiple times then all but the last reference where if was popped would be (pick $c1). You might want to go one step further and hide the $c1 versus (pick $c1) distinction and make that an encoding detail to make the code easier to modify and write. \nIt works nicely, please please give it a try, see the merit in this path and then some of the other compelling design changes might be more obvious.. @kripken cool, so, um, how's other languages which can spit only IR can target wasm?. @dschuff yes, llvm ir. so ir -> .s -> wasm, ok, cool, why we need .s at all here once again?. @kripken good to know, thanks.\nstill not sure why we need .s here given that ir can generate it. what was the rationale behind .s format i and possibly other developers don't care about?. > Now that the binary format is mostly settled, we are working on adding binary format support to LLVM, which will eliminate the need for a text format (although one will continue to exist, since it's useful for various things like testing).\nEverything I wanted to hear, thanks! This makes sense, the issue can be closed now. > Instead, another alternative is to keep the type system as it is, i.e. allow unreachable on block, but fix it up when writing the binary.\nFwiw I've been exploring similar solutions, so settling the types for the encoding as part of the encoding stage. I also throw away a lot more of the type information in some IRs, and derive it at a later stage, to make it easier to work with the IR. For unreachable code, in some depth first walks of the code it returns the reachability of the child, which can be used in the parent to drop the dead code as appropriate. Block ends have a redundant values operator to make the bundle of values returned clear and this is absent if unreachable (in the encoding this is implicit in the block signature), so this is a bit like a fall-through reachable flag. So a permissive IR might be easier to work with, resolving types later, and this seems workable.. > For example, a block/if/loop that is never exited could be emitted with type none, then an unreachable instruction could be emitted.\nOr replace the unreachable type with the expected type.\n\nSlightly complicating this approach is that in the current type system, a block that has a (br) (no value) and ends in a return will have type unreachable - by the property of having the type of the last element.\n\nAll branches to the block label should have the same type, so if the end of the block is unreachable then use one of the other paths, and if there is an exit path then it seems odd to label the block as unreachable and if there a no values then give it the same type as nop. This sill leaves the problem of a block with no exit paths, but in that case I presume binaryen flags the block as unreachable and it can patch the expected type in later.\n. Let me add one other option to ponder. If there is an unreachable operator used deep in an expression then the expression can simply be split out into a series of live sub-expressions and the rest discarded. This can be done trivially when the IR is in a flat (no-expression) form in which all operators with a result set an SSA definition. I suspect this is why I did not find it necessary to propagate an unreachable type through expressions in general with one IR I am exploring, rather just had to deal with some block related issues.\nWriting an explicit unreachable operator after a block looks frustrating to handle, and perhaps it would be easier to work with it this is a flag on the block operator.\nHere's another way to look at this: let blocks have no fall-through, so if there is one then the block must end in a br operator, then the presence of that trailing br also flags that the block has a reachable exit. One of the IR's I am exploring ends blocks with a values operator if reachable, similar to this br. Just another possibility.\nI still have not got up to speed on the proposed validation rules, but cases such as the following illustrate some of my concerns, and could binaryen really read this into an AST, are values effectively materialized. Is this (i32.add (unreachable)) or (i32.add (unreachable) (unreachable))? There might be solutions such as defining operators such as i32.add to default arguments not supplied, but then it would default to (i32.add (i32.const 0) (i32.const 0)). I see more challenges getting something consistent with multiple values going down this path.\nblock i32\n  unreachable\n  i32.add\nend\n. On the if operator, if either the then or else branch exit is reachable (or even if there is a branch to the exit from within one of these paths that is reachable and both fall-through paths are unreachable) then it still has a reachable type.. The CG as a whole has not agree to release WASM any time soon, and to make these changes may mislead the web community and damage the development work. Thus on behalf of the CG members I ask that the binaryen project disassociated itself from the CG and to please stop using the WebAssembly banding of the CG. If you fail to correct this within 24 hours a vote to take harsh action and expel the binaryen project will go to the members. If there are web browser vendors promoting or spreading misinformation then they also have 24 hours to disassociate from the CG and to stop using the CG branding. This is your first and final warning.. @dschuff Yes binaryen could disassociate from the CG with little impact on it and avoid some bias on the process, and could take some reasonable measures to avoid misleading the community, for example to claim to only follow the deployments by the web browser vendors etc and to not reference these by the branding of the CG, and I call on it to do so. Alon is Mozilla staff I believe and the lead of this project so that might also create a conflict of interests that is hard to avoid, it's not just someone forking binaryen adding this change.. @dschuff This is not about positive influences that binaryen has had on the project, and they don't justify the current action. Bineryen and emscripten have not helped the group answer matters such as the utility of  a pick operator or the encoding efficiency of an SSA encoding or provided support for others to exploring compilers for these. I have written to Alon politely sharing my wip, and that was around a year ago and I believe the response then was that there was not time! Sorry this excuse seems damaging to the project to me, and if it were not for this excuse a year ago we might have made much better progress. I don't want to see the work of the group squashed by this constraint.\nI am a user, and I am concerned about getting a good outcome. It is not me saying that wasm is ready for a release. I can demonstrate many of the problems and can argue the technical case, and even demonstrate better alternatives, these are matters of good performance etc, matters that I believe users care about.  For example, Luke Wagner of Mozilla was recently supportive of a 15%-20% performance lose for 32-bit x86, see https://bugzilla.mozilla.org/show_bug.cgi?id=1338217 I think, well hope, there are users who care and such matters. I have engaged and pointed out the problems, and for a long time have suggested paths forwards. I believe I have more claim to representing a good outcome for users.\n\nI don't think our users care about the CG's opinion of wasm.\n\nI hope there are a good number of CG members who are users very interested in meeting use cases including performance. I am a user, I am here.\nThis is all about a subgroup attempting to ram through a release without being prepared to stand up and defend the technical merits of that decision, and a group that has failed to explore design ideas raised long ago, or to accommodate use case raised long ago.\nDon't try and blame the CG members, we have tried, we are not claiming the design is ready. Accept your own failures.\n\nBut somehow we manage to get along without arguments and threats.\n\nSo if CG members try to defend a good working environment and protect the group against what seems reasonable to describe as the absolute contempt for them by a subgroup then you are going to slur their character as being argumentative and threatening? Well shame on you. I will give them a private vote, they do not need to support me, but I will at lease give them the respect of a vote and I will put the technical case to them and discuss it with them.\nTo the CG, I have asked Mozilla for the peer of the Firefox WebAssembly component. I understand these position are based on merit and I believe I can demonstrate merit, I can certainly demonstrate better performance of some alternatives. If granted the peer I will focus the work on the technical matters to try to keep this process objective and will explore ways of opening it up so that more people feel confident contributing such as holding a competition in which you can all participate and receive some recognition for good entries in various categories.. > I stand by my interpretation of this post as argumentative and threatening.\nThat is a slur on my character, and a repeated one.\n\nbut I demand that you act respectfully and professionally\n\nThe business of this group is a professional matter. I believe your characterisation of it otherwise is a slur on my character. Take a look at yourself pal, and shame on you.. @qwertie Ok, thank you for the honest feedback, but I don't see much left that I can do, and not without support of the community. My offer to be the peer of the Firefox WebAssembly component was time limited and lapsed without response, and I have no interest in dealing with a hostile Mozilla. I believe the wasm 1.0 being promoted falls way short of the design principles and I have no wish to be associated with it. i certainly have wip with better performance and encodings that better meet the design principles and that overcome many shortcomings that the project will inevitably run into. There seems nothing left but to give up and so I resign (as soon as I work out how). So you need no longer need put up with me, have a good one, and I apologize to anyone who I may have offended but I hope someday people can accept that I just wanted to see the project a success and it seemed a generational opportunity and given my age my last chance to see. Obviously I am very disappointed in the outcome. Perhaps I can work with some of you in other forums where our interest are better aligned, e,g. I am taking my variant to low end IoT devices.. I just want to get started with web assembly. The docs at\nhttp://webassembly.org said I have to build from source.\nI just want to know if that will change soon.\n. ",
    "sunfishcode": "Note that it's not semantically valid in all cases to do this transformation at the asm.js level, because  asm.js code may depend on the value being wrapped, while wasm's offsets are defined to be non-wrapping. That said, this may be a useful thing to implement for now, because it'll probably work in most cases, and it'll be more representative of what we hope to have in production in the future.\nI have patches in progress which implement offset folding with non-wrapping semantics in the LLVM wasm backend using the inbounds property on getelementptr.\n. LLVM is currently prefixing call with return types, like i32.call. Does that address the concern here?\n. Yes, the type prefix is there even when the return value is ignored.\n. I guess I didn't really follow. In any case, if you're making something better, feel free to just replace the thing I did here; I have no emotional attachment to it.\nMy real work right now is blocked. I'm trying to unblock it. I don't really care what you're doing.\n. Updated:\n- run binaryen-shell on the expected .wast files for all dot_s and llvm_autogenerated tests\n- fixed a bug in hex literal printing found in immediates.s\n- remove .wast files from dot_s that are now in llvm_autogenerated\n. Ok, I reverted the submodule change. It wasn't actually important for anything; I had just removed it and then later re-added it and didn't happen to re-add it in the same place. It's now back to test/experimental.\n. There's still the code in check.py that does import test.experimental.buildbot.link_assembly_files as link_assembly_files and so on which is using it.\n. We need a lock-step change to both LLVM and binaryen here, and it's not clear to me how to get everything updated appropriately. I hoped I could just update the tests manually at the same time, and things would sort themselves out.\n. Yeah, if/if_else formation is just something that hasn't yet been implemented in the LLVM wasm backend.\nOther than that, the output should be fairly clean, and I'd be interested in any areas where it can be improved.\n. Also, the s2wasm parser will probably need to be updated to strip @FUNCTION symbol suffixes.\n. It conveys that the symbol is to be resolved to a function index, rather than a linear memory address. s2wasm is probably already special-casing function symbols in direct calls, so it doesn't change anything there, but for taking addresses, i32.const abc is the address of a variable in linear memory, while i32.const xyz@FUNCTION is a function index.\n. Ah, right, this may not be an issue for s2wasm.\nWhen linking multiple .o files together, ELF tools have a tendency to forget which symbols are for functions and which are for data because they assume you're just going to need a virtual address in either case. Using separate relocation codes for functions and data means that the tools always know what they're supposed to do.\n. That's right. There's still only a single namespace. The @-suffix syntax is just for saying \"I want the linker to do something special here instead of just giving me the virtual address\".\n. Changes lgtm. Merging.\n. dot_s tests are now updated. The guidance I got from JF for these kinds of changes is to just check them in and let the tests fail, and then run update.py once new generated tests are available.\n. I briefly looked at the changes; getNextLabel is pretty much what I was imagining binaryen would want to do. Note that this should fix issues that have popped up in a few places where a loop and a block end at the same place and previously would share a label.\n. https://github.com/WebAssembly/design/pull/489 is a PR to update the design repo to put the condition at the end.\n. The select condition has been moved to the end in the spec and design.\n. Re: 1, #524 was closed without any outstanding objections, so I think return is here to stay for the foreseeable future.\nRe: 2, Is it possible to have it just optimize away the toplevel loop and nothing else?\nRe: 3, Thanks! However, does this mean that round-tripping through wasm-as/wasm-dis does not always produce a result identical to the original?\n. Sorry, I forgot to notify binaryen when updating LLVM. https://github.com/WebAssembly/binaryen/pull/142 is a PR with newly generated tests. They contain uses of the new .p2align syntax.\n. Yes; as far as I know, LLVM's WebAssembly doesn't use .align anywhere anymore. It theoretically remains valid in the .s file syntax, though I don't know if s2wasm needs to worry about all possible valid .s syntax.\n. Looks good, with a minor fix pushed.\n. It's a standard feature of .s syntaxes in general, so my default assumption is we should support it too. Ordinarily aliases would be resolved by linking, and since s2wasm is effectively performing a linking function, there is some logic of having it support them. Does this cause any trouble?\n. The spec repo doesn't have assert_equal; it does have assert_return, and its intended behavior is to always test for a full exact bitwise match.\n. It's a full bitwise match of every bit.\n(If the expected value is a NaN and the result value is a NaN with the same sign bit and payload, that implies it matches every bit too, but it seems simpler to just do a straight bitwise comparison in all cases rather than handling NaN specially)\n. The differing bit is the \"signalling\" vs \"quiet\" NaN bit, which is the most-significant-bit of the payload. It looks like something somewhere is doing something that causes this bit to get set. Performing any floating-point operation would be sufficient to do that, since hardware implicitly sets that bit to 1.\n. The test is specifically testing that the implementation doesn't let that bit get set accidentally :-).\nYeah, it's any arithmetic-like operation that will set the bit. Loading and storing the value should be fine, as should be memcpy.\n. See my code comments on this issue; that's the likely culprit.\nYes, I believe it is possible and practical for an implementation to preserve the bits. The bug here seems to have just been the mask.\n. Oh, are you perchance building on 32-bit Linux? It uses x87 by default, and x87 loads and stores do set the bit.\n. @cosinusoidally Good point; that does indeed sound likely to be relevant. Unfortunately, the -mno-fp-ret-in-387 option changes the calling convention, so it isn't something to be used lightly. From the description, it sounds like it wouldn't be possible to call standard libm functions, because the system libm would still return its results in the x87 registers.\nI agree with JSStats; the safest thing to do is to pass float values around in int32_t and double values in int64_t whenever possible, on x87, to prevent it from fiddling with the bits. For what it's worth, the spec repo also does this, in an attempt to avoid some vagueries in OCaml.\n. @kripken I created https://github.com/WebAssembly/binaryen/pull/171 to illustrate how I think binaryen can implement this.\n. f32.abs, neg, and copysign can be changed to operate directly on the bits. They can do value.f32bits & 0x7fffffff and so on. For the rest, if you're doing arithmetic, that will set the bit anyway, so it doesn't matter.\n. Yes, all other arithmetic ops on all relevant architectures set the bit, and the wasm spec is written to expect this behavior.\n. This would be a great candidate for the spec repo's testsuite too.\n. It would be great to get testcases like this added to the spec repo's testsuite. wasm-as is tested against that, and many other things.\n. -+nan is not valid in the .s syntax -- both GAS and llvm-mc reject it.\n. This branch doesn't work as-is; there are a lot more places that do things with Literal objects that aren't quite right yet. But hopefully it demonstrates the idea.\n. @jfbastien I thought the lkgr tracking meant the system could tolerate temporary breakage. Is this not the case?\n. Would tracking lkgr for the tests as well fix this?\n. This PR looks superseded by https://github.com/WebAssembly/binaryen/pull/189 .\n. You're right. Ok, I've updated and rebased this PR now on top of your PR so it has just the additional changes.\n. lgtm.\nThough when I run check.py as described above, I still get:\nAssertionError: binaryen/a.wasm.js:88451\nvar real__cleanup.647 = asm[\"_cleanup.647\"]; asm[\"_cleanup.647\"] = function() {\n                 ^^^^\nwhich is #237. With the patch in #240 applied, it gets further, but then errors with:\nTraceback (most recent call last):\n  File \"./check.py\", line 590, in \n    os.unlink('a.wasm.asm.js') # we should not need the .asm.js\nOSError: [Errno 2] No such file or directory: 'a.wasm.asm.js'\n. Patch updated. I'm pretty sure \"globl\" is just historical.\n. Clang has a builtin notion of what type \"size_t\" is a typedef for. For the wasm target, it's currently set to unsigned long. One of emscripten's headers is defining size_t to be unsigned int. The two types are effectively interchangeable in terms of the generated code, but in terms of C++ type checking they have to match.\nI chose unsigned long in clang because the wasm32 target is ILP32, while wasm64 is LP64, so unsigned long is 32-bit on wasm32 and 64-bit on wasm64, so using unsigned long for both means each target gets the size it needs, while using the same type. It isn't necessary that we do this, but it is convenient that, for example, operator new mangles to _Znwm on both (instead of having _Znwj on wasm32).\nLooking more closely, it looks like it's system/lib/libc/musl/arch/emscripten/bits/alltypes.h, with\n```\ndefine _Addr int\n```\nand\ntypedef unsigned _Addr size_t;\nThis might be fixable by adding an #ifdef __wasm__ and #define _Addr long in alltypes.h, though I haven't actually tried it.\n. Benefits to fixing it in the musl headers:\n- C types and C++ name manglings are the same between wasm32 and wasm64\nBenefits to fixing it in clang:\n- Better compatibility with the current asm.js target\n. A simpler header fix than what I suggested above would be to define _Addr to be __INTPTR_TYPE__, a predefined macro in clang (and gcc and others). That avoids the need for an ifdef.\nI do see that musl has a consistency for using unsigned int on 32-bit platforms, but I don't see what the advantage of the consistency is. The vast majority of musl code is either portable and can't depend on the type of size_t anyway, or fully platform-specific and can but doesn't affect us.\nUser code depending on size_t being unsigned int is already not very portable. And, it is common to write tools such as ABI checkers which work in terms of symbol names, and avoiding gratuitous churn between wasm32 and wasm64 seems convenient, since wasm32 and wasm64 should ideally be ABI-compatible in every non-essential way.\n. It happens that I did ask the musl list a while ago; the concerns were: using non-standard extensions  require clang or gcc or a compatible compiler, using compiler macros means that musl's headers aren't the place to look to find out what something is, having musl's headers be explicit is more likely to expose problems where the compiler's ABI doesn't match musl's ABI, and one person asserted that C compilers shouldn't need to know these types.\nI find these reasons to be less applicable in wasm's situation, but don't feel strongly about it. I'd be ok with either the ifdef approach described above, or using __INTPTR_TYPE__ and similar macros.\n. Yes. I was encouraged by this reply: http://www.openwall.com/lists/musl/2016/01/26/8\nI claim that I'm familiar with the toolchain work needed to support this, and with historical C code with invalid assumptions, and am willing to pay the price. If we ever have glibc/newlib/bionic/etc. ports, there are real advantages to making them ABI-compatible at the freestanding level, even if that means not following some conventions about what size_t \"should\" be in various places.\n. I asked the musl developers, and they seem ok with the approach of defining _Addr to be long even on 32-bit platforms. See the thread here.\nConsequently, I support resolving this as:\n```\nifdef wasm\ndefine _Addr long\nelse\ndefine _Addr int\nendif\n```\nThe reason for the ifdef is to continue to also support the current asm.js ABI. An upstream submission would presumably want to switch from arch/emscripten to arch/wasm or so, at which time it might also make sense to only include the code for the wasm ABI.\n. This patch happened, which changed clang's definition, but it looks like you're right that emscripten's alltypes.in was not updated with it.\nFWIW, I am actually preparing patches to change it back now, with a clang patch here and a corresponding Emscripten patch I expect to post soon.. I believe the irreducible control flow issue is fixed in r267511.\n. Yes, the debug output format follows DWARF, so while the details may change, the overall format is pretty stable.\nThat said, I expect any approach focused on translating a subset of DWARF into some other format will be a temporary solution.\n. Because it will eventually be surpassed by browsers offering a debugging API, and content providing its own debuggers.\n. Ok, test added.\n. Also, this doesn't include the updates to bin/binaryen.js and bin/wasm.js because I'm not sure I built them properly.\n. It's reduced from tests/fuzz/17.c\n. I created https://github.com/WebAssembly/spec/pull/288/commits/377adc1c328285b38600a8f849805ea901b0acb0 however the bug here is that binaryen translates an omitted size in the s-expression format to an invalid size in the binary format, so I don't know if it covers that.\n. Do we have spec tests covering this?\n. An option for controlling imprecise optimizations sounds reasonable to me. I can see uses for optimizing arbitrary wasm without changing its behavior in any way; you could do things like run the spec tests with that optimization run on them, and they should all continue to pass. I can also see uses for developers who know they don't care about observing every last store in the event of a trap.\n. --fast-math typically implies a lot of other things, like relaxed precision, so that doesn't seem quite right. I like --assume-math-cannot-trap. Or how about --assume-no-math-traps?\n. I should also add, this didn't require any actual s2wasm change because s2wasm just accepts anything beginning with 'd', so it accepts either \"discard\" or \"drop\". The patch here just updates the tests.\n. Ok, let's do this.\n. We have to update everything to match.\n. Oh, oops. I misread what was going on there.\nI've now created https://github.com/WebAssembly/binaryen/pull/521 to fix this.\n. The tests pass for me and travis with this change.\n. Yes, I consider it a bug. If I'm debugging a wasm binary, I want to see exactly what's in the binary, even if it is suboptimal :-).\n. Merge conflict fixed, and merged. Thanks!\n. As long as it's just opcode renumberings, I'd recommend holding off for now, as there are potentially many more to come.\n. I'm now working on replacing s2wasm with a different approach for connecting LLVM output to binaryen -- LLVM now has the ability to emit wasm binaries directly, so with some extra bookkeeping, we can skip the .s parsing step, which is fairly fragile due to not being a \"real\" .s parser.\nThat said, this is a fairly big project, so if people want to continue maintaining s2wasm in its current form, they're welcome to.. If you're looking for a specific file, https://github.com/llvm-mirror/llvm/blob/master/lib/MC/WasmObjectWriter.cpp does a lot of the work of the actual wasm object writing.. I don't see this in the upstream LLVM WebAssembly backend. Do you have any LLVM patches applied?\n. This is actually safe for eq and ne, though not for lt/le/gt/ge.\n. Of course, what's optimal for expressions may not be optimal in general. However, single-use values are very common, so the stack machine encoding is quite effective.. Same here. This sounds ok if it doesn't end up being a lot of overhead for folks involved.\nAnother possible approach is to just use binaryen's tracker for these kinds of bugs for now. The LLVM community doesn't require all bugs be filed in bugzilla (and indeed, large numbers of LLVM contributors work for companies that utilize private bug trackers).\n. Yes, wasm tables can be empty.\n(module\n  (table anyfunc (elem))\n)\nIt'd indeed be tidy to use an empty table here.\n. It would be beneficial to simple consumers if producers could be relied on to make the choice of br_if vs select with heuristics that approximated the costs of each in common hardware. In theory, the code size difference could be eliminated by layer 1 compression.\nHowever, wasm may now be positioning itself to be appealing to relatively less sophisticated producers, so VMs may end up needing to be smart about this anyway, in which case it may be better to just emit the smaller form.\n. I'm not sure what you meant by \"L25\". Also, br_if is a conditional branch, so code after it can still be reachable.\n. Ah, thanks for tracking that down. Yes, there's a $pop0 and no corresponding $push0, so it's an LLVM bug. I'll look into it.\n. This is now fixed in LLVM in r286274, by adding explicit \"i32.const 0\" to provide an explicit $push in such situations.\n. This works for me on the code that prompted #857.. There is a patch for SM which implements this in https://bugzilla.mozilla.org/show_bug.cgi?id=1324032.. As an aside, the proposed rule in WebAssembly/design#894 only needs to delete all code after a br/br_table/return/unreachable until the end of its containing block/then/else/loop/function. If -O0 compile time is a concern, it should be possible to create a simple pass that just does the minimum necessary, which might be faster than full DCE.. @kripken The benefit would be that it would help the WebAssembly project find any other sources of instructions between br/etc and end/etc in the wild that would need to be fixed if WebAssembly/design#894 gets resolved in the direction that 3 browsers appear to prefer.. I mean llvm, wabt, SM's wasmTextToBinary, or any other wasm producers out there. We could:\n - locally apply the patch to SM\n - run this custom SM on a bunch of wasm content from the wild\n - if anything fails to validate, figure out what tool produced it and what would be needed to fix it\n. Yes, this is common in unoptimized code produced by LLVM. Notice how the store is present even in the LLVM IR. If you compile with optimization, eg. -O2, LLVM will avoid emittings stores and loads for most variables.. The first example does not validate, and the second does. The answers are the same for select.\nWhen replacing a return, br, br_table, or unreachable with a block, it's necessary to infer the return type from the surrounding context in order to give the block the required signature.\n. Why is the first example, (i32.add (f32.const 0) (br 0))), valid, under rule 3b or otherwise? The f32.const is reachable (assuming the sequence is reachable), so it's not clear why it wouldn't be checked under the opcode-specific rules for i32.add.\n(Historical note: around the 0xc timeframe, the spec actually explicitly permitted implementations to ignore type errors in unreachable code, so implementations weren't wrong or non-compliant.). This looks good to me. Obviously we could micro-optimize some things more if we really wanted, and the choice of what mode to have by default depends on how one weights various criteria, but what's here is a reasonable step forward.. As far as I'm aware, the \"env\" module is just something that works for simple cases right now, rather than being part of a more elaborate plan.\nThe way two-level namespacing works on Darwin is that, at static link time, the linker resolves symbols that will be provided by dynamic libraries, and records which library each symbol is resolved by. I expect we'll eventually have something similar to this, where the source code doesn't specify module names, and then linkers can rewrite the module name afterwards when it's determined which modules will be providing which symbols.\nDo we also need some way for source code to specify module names up front? It would certainly be useful right now, while most of the tools aren't mature and there aren't many other options. Longer term, it might be a little redundant with the linker module detection, but it might continue to be more convenient for some use cases.. The use case of typical C/C++ code that doesn't have module names, and that relies on the linker to assign module names, wouldn't use attributes. In this scenario, the linker doesn't need to feed any information back into LLVM etc.; it just needs to add module names to the imports of the output wasm module.\nSo, I think the answer to your specific question is that no, the attribute can't be the exclusive unit of management for link tooling. However, it may yet be worth having, along side other tools.\nOne question I have is about the meaning of module names. A filesystem path like \"./custom-logger.js\" is probably very handy for simple cases, because you can just provide that file yourself at the appropriate path in the filesystem. But it's another matter in the case of using libraries written by different people. If you're using a library, do you want it using attributes to specify paths to where it expects various modules will be at runtime? Will module names differ if you're using node versus running in a browser? I haven't thought about this deeply and don't know what the answers are.. I'm not opposed to the attribute. I'd like to understand it a little better.\nWould you mind spelling out a use case or two in a little more detail? Who would typically pick the module names, and at which phase in the build pipeline relative to C/C++ compilation? What information do they include (filesystem paths, versioning, prefixing/mangling, or anything else than a simple identifier)?\nDo module names ever need to be different depending on the environment the code will be run in? For example node versus browser? Or, runtime deployments with differing filesystem layouts?\n. Ok. For this use case of portable libraries for publishing to npm or browser CDNs specifically:\nWho would typically pick the module names, and at which phase in the build pipeline relative to C/C++ compilation? I'm not very familiar with modules, but from what I'm reading now, it looks like browser-compatible module names are URLs (possibly relative), which seems like they'd be fairly site-specific, and not the kind of thing that a C/C++ library shared by multiple sites would want to have hard-coded. Consequently, the main use case for this attribute would be in tools that generate C/C++ header files, for creating builds tailored to specific sites. Does that sound right?. Thanks, I think I have a handle on it now. The import directive sounds good to me.. I have a work-in-progress patch here which fixes this in the LLVM wasm backend.. One of the major reasons wasm has select in addition to if/br_if is that select was intended to have the performance characteristics of a conditional move in a typical hardware ISA. That is, it's not a branch, meaning it doesn't do branch prediction, meaning it doesn't have a misprediction penalty on eg. random conditions. And, this is how Firefox implements it. The numbers above suggest that others have not implemented it that way.\nYou mentioned at the top that your conditions are \"almost always false\", so branch prediction should do well, so if/br_if should do well.. The pass which does this in LLVM is LoopStrengthReduce, which is indeed not run in the fastcomp backend and is run in the wasm backend.\nLLVM appears to prefer two induction variables in this case because it eliminates a shl inside the loop. I don't believe current wasm engines are capable of optimizing this shl away, so it should, in theory, be slightly faster, except for the potential register pressure.\nIf you want to experiment with disabling this pass, you can add -disable-lsr to the llc command.. An export name is just a sequence of bytes; the sequence may have length 0. Such names couldn't be imported in JS, but under the current rules they're valid in the base wasm language.. An alternative for implementing clamping float-to-int conversion is fabs(x) < 0x1p31 ? (int)x : slowpath(x), which handles both positive and negative out-of-range as well as NaN in a single comparison, so it's smaller code and likely faster than doing multiple comparisons.. Right. The fabs trick is for signed conversions. If you're concerned about being slow in the corner cases, you can either do two branches, one for min and one for max, or, since the current code returns INT_MIN on error, you could make the \"slow path\" just be to return INT_MIN, since that's also the result value in the corner cases.\nFor unsigned, I think you need to do two branches, one for > -1 and one for < 0x1p32.. Does -mfpu=neon affect the handling of subnormals in the implementation of floating-point operators?. See also the discussion in https://bugs.llvm.org/show_bug.cgi?id=35385. I'll plan to revert the patch.. The patch is now reverted (in r319452).. @binji Yes, that's right.\nAlso, note that in the tool-conventions ABI, __stack_pointer is a wasm global variable accessed with get_global/set_global rather than being a memory location accessed with load/store.. While it will ultimately depend on the engine, the basic expectation is that if/br_if are conditional branches, br_table is a jump table, and select is a conditional move. This is what FIrefox generates on x86; you can see the code in the WebAssembly Explorer here. In such an engine, the short answers are: if/br_if are expected to be faster than a two-way br_table, and select is expected to be faster than if/br_if when the inputs are cheap and the condition is \"random\" (making branch prediction ineffective).. Because some part of me doesn't really believe that the committee actually chose .wat. Fixed.. Some of the tests use multiple modules per file, which is supported in wast and not wat. So I think they're meant to be wast.. I don't think there's an exclusively right answer here, but the trends seem to be favoring calling this the VM's job. As @kripken mentions, relying on the VM to do it saves wasm code size. And, it seems most VMs are already doing this for 32-bit, so it's not unreasonable to expect them to eventually do it for 64-bit too.. Yes, the sign bit of a NaN generated by an arithmetic instruction like 0/0 is nondeterministic in wasm.. The paper is very specific about using fused multiply-accumulate, including in algorithm 5, so it's not clear that the \"Full precise\" algorithm above is correct.\nFor the less precise version, that is something that Binaryen might want to have available, under control of something like a \"fast-math\" flag, because Binaryen is a much better place to do fast-math kinds of things than wasm engines.. I had initially removed it, but check.py does import experimental.buildbot.link_assembly_files as link_assembly_files and needs it.\n. Fixed.\n. These are the tests that are now in llvm_autogenerated, which is added to the script along with the dot_s tests.\n. Would it make sense to run binaryen-shell on all the dot_s tests too?\n. Another possible solution is to leave ret as int32_t but replace \"if (neg) ret = -ret;\" below with \"if (neg) ret = -uint32_t(ret);\".\n. Yes; the rule is: overflow on signed types is UB, while overflow on unsigned types is defined silent wraparound.\n. The payload mask should be 0xff800000 as wasm considers the quiet-nan bit to be part of the payload.\n. And 0xfff0000000000000 here.\n. Standard libary sqrt functions are pretty reliable in practice.\n. Done.\n. Done.\n. Another option is a C++11 enum class with an explicit type:\nenum class Color : uint32_t\n{\n    Red, Green, Blue\n};\n. It might make the C++ use case a little nicer while not harming the rust use case.\n. .Lfunc_end is still in the .s file, but is emitted after the .end_func so s2wasm doesn't consider it to be part of the function body. .LBB is still present and isn't referenced from the actual code, though it probably is referenced by debug info, which is probably why this patch needs to parse it.\n. Yes, a symbol assignment just assigns a value to a symbol, and does not create any actual program data of its own.\n. FWIW, LLVM does generate that, from code like this:\n```\nextern int foo[];\nint* foo(void) {\n    return &foo[2];\n}\n```. The only issue I'm aware of is the use of mutable global imports. Are there others?\nOne way to fix mutable global imports is to have Binaryen support the proposed mutable global import feature.. ",
    "AndrewScheidecker": "Updated to address feedback\n. I don't know if there's any reason to do this other than to allow WAVM to more easily execute things compiled by Emscripten, but the size of static data makes up a small part of large program .wast files. The maximum increase in size for the memory data in the text format is 3x, but the maximum increase in size for the code is much higher: ~33x on my polyfill-prototype-1 to .wast translation of the UE4 HTML5 demo.\n. I was browsing the issues and noticed that this is a dup of #1098.. Not quite, that gives me errors for isatty and STDOUT_FILENO. I could certainly put another #ifdef in use though.\n. You're right, this doesn't work on CPUs without the popcnt instruction. I think this change is still an improvement on not compiling, though. :)\n. What do you think about something like this?\n```\nif defined(linux) || defined(apple)\ninclude \nnamespace Colors {\n  inline void outputColorCode(std::ostream& stream,const char* colorCode) {\n    if((getenv(\"COLORS\") && getenv(\"COLORS\")[0] == '1') || // forced\n           (isatty(STDOUT_FILENO) && (!getenv(\"COLORS\") || getenv(\"COLORS\")[0] != '0'))) { // implicit\n      stream << colorCode;\n    }\n  }\nelse\nnamespace Colors {\n  inline void outputColorCode(std::ostream& stream,const char* colorCode) {}\nendif\ninline void normal(std::ostream& stream) { outputColorCode(stream,\"\\033[0m\"); }\n  inline void red(std::ostream& stream) { outputColorCode(stream,\"\\033[31m\"); }\n  inline void magenta(std::ostream& stream) { outputColorCode(stream,\"\\033[35m\"); }\n  inline void orange(std::ostream& stream) { outputColorCode(stream,\"\\033[33m\"); }\n  inline void grey(std::ostream& stream) { outputColorCode(stream,\"\\033[37m\"); }\n  inline void green(std::ostream& stream) { outputColorCode(stream,\"\\033[32m\"); }\n  inline void blue(std::ostream& stream) { outputColorCode(stream,\"\\033[34m\"); }\n  inline void bold(std::ostream& stream) { outputColorCode(stream,\"\\033[1m\"); }\n};\n```\n. ",
    "sletz": "It seems that the \"for loop\" syntax is not handled in \"parseAfterKeyword\" (in parse.h file)\nfor (i0 = 0; (((i0 | 0) < 2) | 0); i0 = (((i0 | 0) + 1) | 0)) {\n    HEAP32[dsp + 0 + ((i0 | 0) << 2) >> 2] = 0;\n}\n. Well, our code backend currently generates \"for loop\" yes.\n. FAUST (Functional Audio Stream) functional programming language specifically designed for real-time audio signal processing and synthesis (see http://faust.grame.fr)\n. Working now, thanks!\n. Well I found later on that the following generated JS code is not parsed correctly. Any chance it could also be fixed?\nfunction getJSONmydsp() {\nreturn \"{  \\\"name\\\": \\\"Noise\\\",  \\\"outputs\\\": \\\"1\\\",  \\\"meta\\\": [    { \\\"author\\\": \\\"Grame\\\" },   { \\\"copyright\\\": \\\"(c)GRAME 2009\\\" },   { \\\"license\\\": \\\"BSD\\\" },   { \\\"name\\\": \\\"Noise\\\" },   { \\\"version\\\": \\\"1.1\\\" }  ],  \\\"ui\\\": [    {    \\\"type\\\": \\\"vgroup\\\",    \\\"label\\\": \\\"0x00\\\",    \\\"items\\\": [      {      \\\"type\\\": \\\"vslider\\\",      \\\"label\\\": \\\"Volume\\\",      \\\"address\\\": \\\"/0x00/Volume\\\",      \\\"meta\\\": [       { \\\"style\\\": \\\"knob\\\" }      ],      \\\"init\\\": \\\"0\\\",      \\\"min\\\": \\\"0\\\",      \\\"max\\\": \\\"1\\\",      \\\"step\\\": \\\"0.1\\\"     }    ]   }  ] } \";\n}\n. OK, this is additional pure JS code that our backend adds with the asm.js module. We can live without that\ufffd\nThanks.\nLe 5 janv. 2016 \ufffd 18:25, Alon Zakai notifications@github.com a \ufffdcrit :\n\nThat doesn't look like valid asm.js? It doesn't have arrays or strings.\nBtw, please use escaping (4 backticks \"`\") to make code easier to read.\n\ufffd\nReply to this email directly or view it on GitHub.\n. \n",
    "titzer": "ES6 features are generally not allowed in the asm.js subset.\n. I've updated the spec to match the v8 implementation (i.e. decl flags\nfirst).\nOn Sat, Jan 16, 2016 at 10:37 PM, Alon Zakai notifications@github.com\nwrote:\n\nThe current implementation matches the v8 spec document, which I think\nmakes more sense to do. Since we may have multiple such implementations and\nwant to verify them against each other. If we want to change this, let's\nchange the spec first. So I don't think we should do anything here in\nbinaryen currently.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/113#issuecomment-172259749.\n. I think we should move the relevant parts of encoding into BinaryFormat.md\nand update it to be consistent with the implementation. Then we can iterate\non the BinaryFormat.md and keep implementations up to date with that.\n\nOn Sat, Jan 16, 2016 at 11:42 PM, JF Bastien notifications@github.com\nwrote:\n\nLet's just see what @titzer https://github.com/titzer and @binji\nhttps://github.com/binji say. Either way is easy to go, they'll be able\nto reconcile the inconsistency.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/115#issuecomment-172265781.\n. As for the unified index space, that was easier in the implementation but I\ndon't think we fully resolved that issue in the design. I'm happy to update\nboth the spec and implementation when we make a decision to have a separate\nindex for imports or not.\n\nOn Mon, Jan 18, 2016 at 9:40 AM, Ben L. Titzer titzer@google.com wrote:\n\nI think we should move the relevant parts of encoding into BinaryFormat.md\nand update it to be consistent with the implementation. Then we can iterate\non the BinaryFormat.md and keep implementations up to date with that.\nOn Sat, Jan 16, 2016 at 11:42 PM, JF Bastien notifications@github.com\nwrote:\n\nLet's just see what @titzer https://github.com/titzer and @binji\nhttps://github.com/binji say. Either way is easy to go, they'll be\nable to reconcile the inconsistency.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/115#issuecomment-172265781\n.\n. Weiliang is correct. All functions (including imports) are within one index\nspace which is indexed into by call opcodes and the indirection function\ntable.\n\n\nIn the future I think a separate dedicated import table makes sense, in\nwhich case we should probably separate the index spaces.\nOn Mon, Jan 18, 2016 at 12:08 PM, JSStats notifications@github.com wrote:\n\n@weilianglin https://github.com/weilianglin Thank you. I know what the\nv8 implementation does, and this PR is to align the binaryen tool with\nthis, but there is also a v8 design specification which specifies the table\nindex is an 'index into the function segment entries, referencing a\nfunction'. I seems a consistent interpretation to me, but other people want\nsome extra confirmation. So it might help so get an answer from @titzer\nhttps://github.com/titzer just to confirm that these are consistent and\nthat the v8 implementation is the correct interpretation of the design spec\nand not a bug?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/115#issuecomment-172499219.\n. The condition should go at the end. I had a CL that did that in the native\nprototype but didn't land it pending the other PRs. I'll make sure V8 is\nup-to-date and ping this thread when it is.\n\nOn Fri, Jan 22, 2016 at 2:51 AM, JSStats notifications@github.com wrote:\n\nIt seems fair to see the document as derived from the implement in this\ncase. The issue that @sunfishcode https://github.com/sunfishcode refers\nto is a change request for select not a clarification of the current\nstate (from my reading of it anyway). Not sure why there has been no action\nof the select change, but conflating it with a br_if change might not\nhave helped.\n@titzer https://github.com/titzer Need some clarification on this one\ntoo?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/131#issuecomment-173774773\n.\n. CL in flight: https://codereview.chromium.org/1624323003/\n\nOn Sat, Jan 23, 2016 at 10:37 PM, JSStats notifications@github.com wrote:\n\n@titzer https://github.com/titzer If you support change select to put\nthe condition last, which I am not arguing against, then could you please\nconsider approving @sunfishcode https://github.com/sunfishcode PR in\nWebAssembly/design#489 https://github.com/WebAssembly/design/pull/489\nand just the select change if that is all there is consensus on. I would\njust like the tools to generate code compatible with the spec and\nimplementations for a start - to get something running.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/131#issuecomment-174224531\n.\n. Maybe we should just make all sizes into LEB128?\n\nOn Wed, Jan 27, 2016 at 7:20 AM, JSStats notifications@github.com wrote:\n\nThe block size becomes a leb128 and the function body size become uint32\n(fixed width to be easy to patch). Seems fine to me. I would not worry\nabout interoperability at this stage. If it were me I'd just submit the\npatch to v8 and sexp-wasm. Would you like me to help by doing this?\nI was just wondering about the local variable sizes, why they are uint16\nnot leb128. Might it be in part because 2^16 is a good limit for\nimplementations anyway, or are these to be revised too?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/145#issuecomment-175425004\n.\n. BTW you can achieve arbitrarily big size blocks by nesting them in a tree\nstructure.\n\nOn Wed, Jan 27, 2016 at 9:37 AM, Ben L. Titzer titzer@google.com wrote:\n\nMaybe we should just make all sizes into LEB128?\nOn Wed, Jan 27, 2016 at 7:20 AM, JSStats notifications@github.com wrote:\n\nThe block size becomes a leb128 and the function body size become uint32\n(fixed width to be easy to patch). Seems fine to me. I would not worry\nabout interoperability at this stage. If it were me I'd just submit the\npatch to v8 and sexp-wasm. Would you like me to help by doing this?\nI was just wondering about the local variable sizes, why they are uint16\nnot leb128. Might it be in part because 2^16 is a good limit for\nimplementations anyway, or are these to be revised too?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/145#issuecomment-175425004\n.\n. Yes, I just added it on Friday. I'd like to update the binary format PR\n\n\n537 if we can resolve some of the discussion there.\nOn Sat, Feb 13, 2016 at 12:29 AM, JF Bastien notifications@github.com\nwrote:\n\nV8 has support for start: https://codereview.chromium.org/1692173002/\nMaybe it's just missing from the binary format spec. @titzer\nhttps://github.com/titzer ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/145#issuecomment-183527060\n.\n. Can we just pick a date for the postorder transition?\n\nOn Fri, Feb 26, 2016 at 8:29 PM, JSStats notifications@github.com wrote:\n\nHas someone written a specification that you are following or is it a\nmatter for experimentation?\nAre there particular goals for this decision?\nIt does not look like a pure post-order encoding. For example the\nEndMarker seems to just terminate a pre-order operator. If you wanted\npost-order then a block could still have an immediate count and would just\npop the expressions from the stack.\nIf people want to actually interpret this code then it will need to deal\nwith the values resulting from these expressions, so either need to\nexplicitly discard unused values for each expression or be pre-order. To\ndiscard the unused values in a post-order encoding will require explicit\npop operations be included. If you want to explore this then you might want\nto change the representation from an AST to a stack machine and evaluate\nthat.\nI also expect people will want single-pass AST conversion with validation\nso will need to track pre-order state for some of these operations.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/215#issuecomment-189575092.\n. On Sun, Feb 28, 2016 at 4:55 PM, JSStats notifications@github.com wrote:\n@kripken https://github.com/kripken But if 'post-order' is just a\n'general goal' then what basis is there for a move towards this? Would it\nnot be more prudent to explore both options and then compared them on\ntechnical merit?\nIf abstracted well, and if it only affects the serialization of the AST,\nthen if should not be a big burden for tools to support both pre and post\norder encodings.\nThere are some basic questions that no-one has been willing or able to\nanswer such as:\nIs there an expectation that interpreters will interpret the code\nliterally, or is it expected that it will be decoded into an AST first? It\nmight be important because if interpreted literally then there is no\ntop-down information, no expected types, no expected number of values, no\nfunction result type, no block labels. It becomes a stack machine and there\nis no longer an AST.\nI wrote a prototype pre-order direct interpreter after exploring various\nrewriting strategies and found that it's entirely possible to do direct\ninterpretation of preorder. It's also highly brittle and counterintuitive\n(since execution order reflects AST evaluation order, not encoding order).\nYou can see a prototype here: https://codereview.chromium.org/1675183004/\n\nI implemented a post-order prototype here:\nhttps://codereview.chromium.org/1694303002/\nThe data that I gathered from that prototype showed that postorder is\n40-60% faster to decode, with no loss in expressiveness. It was also a big\nsimplicity win. I didn't finish the job yet with a postorder interpreter,\nbut suspect that it will also be simpler and easier to reason about; the\npost order encoding reflect execution order.\n\nIf it's is just a matter of the serialization of the AST then it might\nstill have implications for single pass SSA conversion and for compression\nefficiency. It not clear how single pass SSA conversion could be done\nefficiently without pre-order information?\nIt works. One simply needs to use bracketed blocks (i.e. block ... end) and\nan in-order encoding of if (i.e. {cond} if {true} else {false} end). That\nactually works out quite naturally, since the in-order bytecodes appear at\nexactly the points where SSA renaming must split or merge environments.\nAlso some effort was made to have binaryen be consistent with the v8\nencoding, issues were filed on differences etc, and some progress has been\nmade on resolving differences between the v8 encoding and the wasm spec. A\nquick look suggests that the only area still needing resolution is the br\narity and mv issues - that seems really close to me. Plus the naming and\nnumber of some operators, which I submit a PR for soon.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/215#issuecomment-189982291.\n. The V8 patch probably doesn't apply cleanly anymore, but I suggest starting\nthere. I will update it soon.\n\nOn Tue, Mar 1, 2016 at 4:02 AM, JSStats notifications@github.com wrote:\n\nThank you all for the feedback. It's obviously much more subtle than just\na post-order encoding, a hybrid. I'd like to implement an encoder/decoder\nand check the compression and explore some concerns. It would be very\ninteresting to be able to compare the pre-order interpreter to a post-order\ninterpreter, in particular I would like to understand the story for\nmultiple values and if it now needs a pop operator and how validation\nwould work etc. I'll have to follow up.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/215#issuecomment-190688261.\n. +1 to not changing the behavior in the default case and having a compiler option. \n\nAFAIU, C undefined behavior would allow this reordering within the same control equivalence class; i.e. whenever undefined behavior becomes inevitable, that entire execution path becomes invalid and the compiler is free to do what it likes. So for producers coming from C, this optimization is OK (provided it doesn't lift across non-terminating calls). But from a pure WASM perspective this optimization is unsound.\n. One thing to watch out for is moving trapping operations themselves, since they may have a control condition that guards that they don't trap. (e.g. x != 0? 3 / x : 5)\n. ",
    "SerkanSipahi": "ok, thank you for your response :)\n. ",
    "Lichtso": "Done.\nI joined the W3C group too: https://www.w3.org/users/86901\n. @kripken I did not rerun the autogen, just used search & replace. As dschnuff said, s2wasm is the only thing affected.\n. This pull request is done, but there is a new bug: #572\n. ",
    "bsklaroff": "this is outdated, closing\n. ",
    "haxxpop": "Oh sorry, it's in the beginning of stdout so I didn't notice that.\nwarning: no interpreter provided (did not test spec interpreter validation)\nwarning: no mozjs found (did not check asm.js validation)\n. All submodules are up to date\nUbuntu 15.10\n. 64bit\n. I use everything from http://kripken.github.io/emscripten-site/docs/getting_started/downloads.html\n. ```\nThe following precompiled tool packages are available for download:\n           node-4.1.1-32bit       \n     *     node-4.1.1-64bit             INSTALLED\n           emscripten-1.30.0      \n           emscripten-1.34.1      \n           emscripten-1.35.0        \nThe following tools can be compiled from source:\n           clang-tag-e1.35.22-32bit \n           clang-tag-e1.35.23-32bit \n           clang-tag-e1.35.22-64bit \n           clang-tag-e1.35.23-64bit \n           clang-incoming-32bit   \n     *     clang-incoming-64bit         INSTALLED\n           clang-master-32bit     \n           clang-master-64bit     \n           emscripten-tag-1.35.22-32bit\n           emscripten-tag-1.35.23-32bit\n           emscripten-tag-1.35.22-64bit\n           emscripten-tag-1.35.23-64bit\n           emscripten-incoming-32bit\n           emscripten-master-32bit\n     *     emscripten-incoming-64bit    INSTALLED\n           emscripten-master-64bit  \nThe following precompiled SDKs are available for download:\nThe following SDKs can be compiled from source:\n         sdk-incoming-32bit     \n    *    sdk-incoming-64bit         INSTALLED\n         sdk-master-32bit       \n         sdk-master-64bit       \n         sdk-tag-1.35.22-32bit  \n         sdk-tag-1.35.23-32bit    \nItems marked with * are activated for the current user.\nTo access the historical archived versions, type 'emsdk list --old'\n```\n. I'm trying. My laptop is frozen now due to the compilation :)\nOn Feb 18, 2016 3:59 AM, \"Alon Zakai\" notifications@github.com wrote:\n\nThat should be ok. And the Travis CI stuff is 64-bit ubuntu as well, and\nit passes, so I'm puzzled why it fails for you.\nTry very latest master, perhaps, if you haven't already?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/199#issuecomment-185400679\n.\n. Do I need to run auto_update_tests.py ?\n. When I remove this test, it passes all other tests and everything is fine.\nI'm not sure what happen with this test case.\nhttps://gist.github.com/haxxpop/59840116dda4f16f5f06\n. \n",
    "rossberg": "Oops...\n. @JSStats, it's just an encoding change, it has no effect on semantics.\n. The discussion on WebAssembly/design#727 is probably relevant. Some specific comments:\n\n\nIt adds support for updated table definitions, including the default, elementType, initial, and max attributes, plus a name. Currently, the initial and max attributes must be equal to the number of elements. The elementType attribute is interpreted as a FunctionType index, and type homogeneity is enforced on table elements, unless the specified FunctionType has name \"anyfunc\", which corresponds to a FunctionType with a none parameter and return type none.\n\n\nAh no, anyfunc is emphatically not the same as a function type with no parameters and results! It is a dynamic function type. It is a new type constructor (i.e., keyword) that we probably have to allow in the type section to enable the model you envision. That is, you want the user to allow defining\n(type $anyfunc (anyfunc))\nNote that this has a number of implications, i.e., you can no longer assume that all type indices are legal to be used in various places, such as func declarations, func imports, or call_indirect.\n\nFormat:\n(table \"\" default )\n\nThe table name should be a variable, not a string. Also, to be consistent with the handling of all other name spaces, the name should be optional, i.e., it should be possible to reference tables purely by raw index.\nI'd also deal with the default declaration differently, see the latest WebAssembly/design#727 comments, but as a temporary experimental solution a flag might be fine.\n\n\nIt adds support for multiple tables. Example:\n  (table \"foo\" default (type $FUNCSIG$i) $a)\n  (table \"bla\" (type $anyfunc) $b $c $d)\n\n\nNote that the $x syntax is exclusively used for user-defined name space indices.\n\n\nIndirect calls have an immediate argument that specifies the index of the function call table. Example:\n  (call_indirect \"foo\" $FUNCSIG$i (get_local $1))\n\n\nSee above, this should be a var, which is a name space index either given as a symbolic $x or a raw number.\n\n\nBy default, parsing is backwards-compatible for the current assembler and s-exp formats, with the exception that tables in the s-exp format must have a name. Note that the binary format is not backwards-compatible. The following assumptions are made for backwards-compatibility: the value of the default flag is inferred to be true for the first table if unspecified but multiple tables are used, the type of the default table is inferred to be \"anyfunc\" if not specified\n\n\nI think this is obsolete with WebAssembly/design#727.\n\nthe target table of indirect calls is inferred to be the default table if the positional argument does not match a known table name, and the first table with index zero is the default table if multiple tables are used.\nExample:\ni32.call_indirect $0=, $pop0\ni32.call_indirect.1 $0=, $pop0, $1, $2, $3\n(table \"aaa\" $a $b)\n(call_indirect $FUNCSIG$ii $a $b $c)\nCurrently, the only enabled use case for multiple tables is Clang/LLVM code generation with CFI, which requires a corresponding upstream patch. The value passed in the .indidx assembler directive is now interpreted as the index of the indirect call table that the current function should be assigned to.\n. Right. I was following WebAssembly/design#727, but still missing the mutability flag. The init expression is terminated by 0x0F (end) in the encoding. It must have a matching type.\n\nAlso note that the opcodes for get/set_global are probably not final yet, because of the conflict between design PRs #727 and #711.\n. On 8 August 2016 at 23:14, Alon Zakai notifications@github.com wrote:\n\n@qwertie https://github.com/qwertie: Yes, I was taken by surprise by\nthe stack machine change. And from what I've seen online and off I was the\nonly browser-vendor person that opposed it. And you can see work going on\nfor it (e.g. in the spec repo). So for better or for worse, I think it's\nsafe to assume it's happening, even if nothing is truly final until it\nlands, is specced, and ships.\n\nThe superficial history is that most of it \"happened\" in ongoing\nconversations between a couple of Mozillians ad Googlers. Luke & Dan have\nbeen arguing in the more stack-ish direction for a while. Ben & I were\nrather skeptical at first, but feared \"slow drift\" (such as more\nincremental changes of the drop kind). The pivot point was the suggestion\nto \"allow void-expressions anywhere\", which quite plainly breaks the AST\nsemantics. So, to see to the end game, we prototyped a stack machine in\nformal spec, ml-proto and V8. It turned out to be simple enough to convert\nus over.\nThat said, I can definitely see the downsides. It is less structured, after\nall. And structure is usually good.\n. @lukehutch, the most compact representation for expressions is a pre- or post-order serialisation. The latter turns out to be slightly more efficient to process on the consumer side. A stack machine essentially is just the generalisation of such a post-order encoding. As such, it is pretty much optimal. In particular, it keeps all \"register indices\" entirely implicit.. @lukehutch, there is an injective mapping from Wasm expressions into the\nWasm stack machine. The inverse may require the introduction of auxiliary\noperators akin to C's comma operator in cases that are not in the image of\nthat embedding. But nothing more. In particular, general goto does not\nexist in Wasm; unlike other code formats, control is still structured in\nwell-nested form.\nFor debugging, browsers for now will show the plain stack machine format.\nThat actually turns out to be convenient in some ways, because you can step\nthrough it linearly. More bells and whistles with smart \"folding\" of\nsuitable instruction sequences into expression-like output are expected to\nfollow later.\n. @kripken, true, then you need auxiliary let's in general -- one reason why I'm not particularly fond of pick or other stack hacking ops, and would rather prefer a destructuring let block as primitive, which is more structured.. Sorry about that. I'm actually in the midst of a merge fest with rebasing the spec's stack branch onto the landed table changes. Should be complete soon.\n. Okay, everything is merged into the stack branch now.\n. Don't know if that helps, but I feel your pain. 0xc import/exports were a big change in the interpreter as well, and took longer than the entire stack machine rewrite. Quite a few basic assumptions were changing and required restructuring various types and interfaces.\n. Hm, it's not a (validation) error per se to export or import an i64-function. It is only a (runtime) error trying to use these from JavaScript. It should be perfectly fine to link them into another Wasm module, though.\n. Or you use the binary-0xd branch of the spec. :)\n. @dschuff, I'm confused, that syntax is not new on the branch.\n. Ah, I see, thanks. Btw, please let me know when you are fine with merging WebAssembly/spec#366. It sounds like it won't immediately affect you then.\n. Such a block is not valid, for the reason you mention. I'll add a test to the spec tests.. Actually, the test suite already contains corresponding tests, e.g.:\nhttps://github.com/WebAssembly/spec/blob/master/test/core/block.wast#L155. I'd also hope that it is easier to generate Wasm code than to output a complicated language like C. (Especially once you need features that C doesn't even provide, like exceptions or tail calls.). Yes, IIRC we dropped the check at some point. Rationale was that overlap cannot generally be detected during validation, because the offsets might be given by imported globals. And suitable runtime checks would be rather costly.. ",
    "nickbetteridge": "Thanks for the pointer to EM_ASM - I'll read through it. So I guess the route to manipulating the dom is building something around import/export?\n. OK. Thanks.\n. ",
    "Cellule": "I don't know how easy it would be to support that.\nI understand the point is to parse emscripten output. \nI was just hoping I could use this tool to convert existing asmjs test case to wasm. \nMost of them have been written by hand so I guess it is unlikely they will parse with a script parser.\n. I am getting a similar issue when using emscripten.\nDuring unzipping binaryen, emscripten gets the following error\nWARNING:root:retrieving port: binaryen from https://github.com/WebAssembly/binaryen/archive/version_44.zip\nWARNING:root:unpacking port: binaryen\nERROR:root:a problem occurred when using an emscripten-ports library. try to run    emcc --clear-ports    and then run this command again\nTraceback (most recent call last):\n  File \"D:\\projects\\ChakraTool\\WasmExprgen\\third_party\\wasm-exprgen\\third_party\\emscripten\\emcc.py\", line 2786, in <module>\n    run()\n  File \"D:\\projects\\ChakraTool\\WasmExprgen\\third_party\\wasm-exprgen\\third_party\\emscripten\\emcc.py\", line 1483, in run\n    extra_files_to_link = system_libs.get_ports(shared.Settings)\n  File \"D:\\projects\\ChakraTool\\WasmExprgen\\third_party\\wasm-exprgen\\third_party\\emscripten\\tools\\system_libs.py\", line 749, in get_ports\n    ret += [f for f in port.get(Ports, settings, shared) if not f.endswith('.txt')]\n  File \"D:\\projects\\ChakraTool\\WasmExprgen\\third_party\\wasm-exprgen\\third_party\\emscripten\\tools\\ports\\binaryen.py\", line 21, in get\n    ports.fetch_project('binaryen', 'https://github.com/WebAssembly/binaryen/archive/' + TAG + '.zip', 'binaryen-' + TAG)\n  File \"D:\\projects\\ChakraTool\\WasmExprgen\\third_party\\wasm-exprgen\\third_party\\emscripten\\tools\\system_libs.py\", line 686, in fetch_project\n    unpack()\n  File \"D:\\projects\\ChakraTool\\WasmExprgen\\third_party\\wasm-exprgen\\third_party\\emscripten\\tools\\system_libs.py\", line 665, in unpack\n    z.extractall()\n  File \"C:\\Python27\\lib\\zipfile.py\", line 1043, in extractall\n    self.extract(zipinfo, path, pwd)\n  File \"C:\\Python27\\lib\\zipfile.py\", line 1031, in extract\n    return self._extract_member(member, path, pwd)\n  File \"C:\\Python27\\lib\\zipfile.py\", line 1086, in _extract_member\n    file(targetpath, \"wb\") as target:\nIOError: [Errno 2] No such file or directory: 'D:\\\\projects\\\\ChakraTool\\\\WasmExprgen\\\\third_party\\\\wasm-exprgen\\\\output\\\\.emscripten_ports\\\\binaryen\\\\binaryen-version_44\\\\test\\\\passes\\\\rereloop_dce_remove-unused-brs_remove-unused-names_coalesce-locals_simplify-locals_reorder-locals_remove-unused-brs_merge-blocks_vacuum.txt'\nAre those tests files even needed in the package used by emscripten if it's only test files ?\nThis didn't use to be a problem.\nI had to update the version of emscripten because of issue https://github.com/kripken/emscripten/issues/6275 where binaryen would fail to download.\nNow it fails to extract because of that new test. Not sure when it was added, I used to have binaryen version 37 and the file wasn't there.\n. Looks like the test file has been there for longer than I thought.\nIt seems my installation process tries to run emscripten up to 5 times to verify.\nIt always fails the first time because of that file, but everything else has been correctly extracted, so on the second try emscripten doesn't attempt to extract and just goes on with building/running the port.\nAfter updating python on my build machine, it looks like I no longer encounter SSL issue and now my build process silently ignores that error.\nI wouldn't call it resolved, but at least I can run binaryen in emscripten again\n. ",
    "bnjbvr": "With that change and a small tweaks (translate text to binary + use \"read\" instead of \"readBinary\" + memory size is in number of pages and not bytes + memory must be exported with export \"memory\" memory), the hello_world demo runs under SM and prints \"hello, world\"!\nedit: /cc @lukewagner \n. Ha, I see https://github.com/WebAssembly/binaryen/commit/56c6ca407f3232ede398b78e7f284f6ed80c9f00 fixed the issue for tables two days ago; the same thing has to be done for memory.\n. For what it's worth, I am working on a PR right now, and it's almost ready.\n. @dschuff, for what it's worth, Spidermonkey rejects wasm programs which repeat the memory/table section after a memory/table has been imported.\n. I've tried check.py --only-prepare and then re-running with no more success. Continuous integration is happy, though :)\n. Not better:\n```\n$ ./check.py\n(downloading waterfall 11453: https://storage.googleapis.com/wasm-llvm/builds/linux/11453/wasm-binaries-11453.tbz2)\n(unpacking)\n(noting local revision)\ntrying waterfall clang at /code/binaryen/test/wasm-install/wasm-install/bin/clang\n[... tests execute ...]\n[ checking torture testcases... ]\nTraceback (most recent call last):\n  File \"./check.py\", line 558, in \n    import test.waterfall.src.link_assembly_files as link_assembly_files\nImportError: No module named waterfall.src.link_assembly_files\n```\nThe test/waterfall directory is actually empty.\n. Right, this is the command I was missing. I can now run all the tests locally and see that they all pass. Cheers!\n. Thanks for the review! I've updated the name and reversed the meaning (since --dont-fuzz-atomics or --no-fuzz-atomics seemed a bit weird). Now one needs to set the flag to enable generation of atomics. (Happy to reverse it again with a different name). Done!. > fyi @bnjbvr - when this lands you'll need --disable-threads for fuzzing without atomics\nThanks for the ping!. OK, I took it as a reminder for later to actually construct a string concatening importModule.importBase. Will remove both.\n. ",
    "markmontymark": "Ha, my bad....\n./bin/asm2wasm --debug test/hello_world.asm.js \nfails, but of course it does because it's taking test/hello_world.asm.js as the value of the debug option.\n. ",
    "brakmic": "Hi @kripken,\nI updated Cygwin and GCC to v.5.3.0 but still get the same error:\n```\n$ make\n[  2%] Building CXX object CMakeFiles/support.dir/src/support/command-line.cpp.o\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h: In static member function \u2018static void wasm::Literal::printFloat(std::ostream&, float)\u2019:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:236:16: error: \u2018isnan\u2019 was not declared in this scope\n     if (isnan(f)) {\n                ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:236:16: note: suggested alternative:\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:641:5: note:   \u2018std::isnan\u2019\n     isnan(_Tp __x)\n     ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h: In static member function \u2018static void wasm::Literal::printDouble(std::ostream&, double)\u2019:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:252:16: error: \u2018isnan\u2019 was not declared in this scope\n     if (isnan(d)) {\n                ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:252:16: note: suggested alternative:\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:641:5: note:   \u2018std::isnan\u2019\n     isnan(_Tp __x)\n     ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h: In member function \u2018wasm::Literal wasm::Literal::trunc() const\u2019:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:382:42: error: \u2018trunc\u2019 is not a member of \u2018std\u2019\n       case WasmType::f32: return Literal(std::trunc(getf32()));\n                                          ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:382:42: note: suggested alternative:\nIn file included from /usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:44:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/include/math.h:285:15: note:   \u2018trunc\u2019\n extern double trunc _PARAMS((double));\n               ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:383:42: error: \u2018trunc\u2019 is not a member of \u2018std\u2019\n       case WasmType::f64: return Literal(std::trunc(getf64()));\n                                          ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:383:42: note: suggested alternative:\nIn file included from /usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:44:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/include/math.h:285:15: note:   \u2018trunc\u2019\n extern double trunc _PARAMS((double));\n               ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h: In member function \u2018wasm::Literal wasm::Literal::nearbyint() const\u2019:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:389:42: error: \u2018nearbyint\u2019 is not a member of \u2018std\u2019\n       case WasmType::f32: return Literal(std::nearbyint(getf32()));\n                                          ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:389:42: note: suggested alternative:\nIn file included from /usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:44:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/include/math.h:279:15: note:   \u2018nearbyint\u2019\n extern double nearbyint _PARAMS((double));\n               ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:390:42: error: \u2018nearbyint\u2019 is not a member of \u2018std\u2019\n       case WasmType::f64: return Literal(std::nearbyint(getf64()));\n                                          ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:390:42: note: suggested alternative:\nIn file included from /usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:44:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/include/math.h:279:15: note:   \u2018nearbyint\u2019\n extern double nearbyint _PARAMS((double));\n               ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h: In member function \u2018wasm::Literal wasm::Literal::min(const wasm::Literal&) const\u2019:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:631:28: error: \u2018isnan\u2019 was not declared in this scope\n         bool lnan = isnan(l), rnan = isnan(r);\n                            ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:631:28: note: suggested alternative:\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:641:5: note:   \u2018std::isnan\u2019\n     isnan(_Tp __x)\n     ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:632:41: error: \u2018rnan\u2019 was not declared in this scope\n         if (!isnan(result) && !lnan && !rnan) return Literal(result);\n                                         ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:633:23: error: \u2018rnan\u2019 was not declared in this scope\n         if (!lnan && !rnan) return Literal((int32_t)0x7fc00000).castToF32();\n                       ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:640:28: error: \u2018isnan\u2019 was not declared in this scope\n         bool lnan = isnan(l), rnan = isnan(r);\n                            ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:640:28: note: suggested alternative:\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:641:5: note:   \u2018std::isnan\u2019\n     isnan(_Tp __x)\n     ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:641:41: error: \u2018rnan\u2019 was not declared in this scope\n         if (!isnan(result) && !lnan && !rnan) return Literal(result);\n                                         ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:642:23: error: \u2018rnan\u2019 was not declared in this scope\n         if (!lnan && !rnan) return Literal((int64_t)0x7ff8000000000000LL).castToF64();\n                       ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h: In member function \u2018wasm::Literal wasm::Literal::max(const wasm::Literal&) const\u2019:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:654:28: error: \u2018isnan\u2019 was not declared in this scope\n         bool lnan = isnan(l), rnan = isnan(r);\n                            ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:654:28: note: suggested alternative:\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:641:5: note:   \u2018std::isnan\u2019\n     isnan(_Tp __x)\n     ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:655:41: error: \u2018rnan\u2019 was not declared in this scope\n         if (!isnan(result) && !lnan && !rnan) return Literal(result);\n                                         ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:656:23: error: \u2018rnan\u2019 was not declared in this scope\n         if (!lnan && !rnan) return Literal((int32_t)0x7fc00000).castToF32();\n                       ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:663:28: error: \u2018isnan\u2019 was not declared in this scope\n         bool lnan = isnan(l), rnan = isnan(r);\n                            ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:663:28: note: suggested alternative:\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/wasm.h:47:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/include/c++/cmath:641:5: note:   \u2018std::isnan\u2019\n     isnan(_Tp __x)\n     ^\nIn file included from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.h:30:0,\n                 from /cygdrive/d/src/webassembly/binaryen/src/support/command-line.cpp:17:\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:664:41: error: \u2018rnan\u2019 was not declared in this scope\n         if (!isnan(result) && !lnan && !rnan) return Literal(result);\n                                         ^\n/cygdrive/d/src/webassembly/binaryen/src/wasm.h:665:23: error: \u2018rnan\u2019 was not declared in this scope\n         if (!lnan && !rnan) return Literal((int64_t)0x7ff8000000000000LL).castToF64();\n                       ^\nCMakeFiles/support.dir/build.make:110: recipe for target 'CMakeFiles/support.dir/src/support/command-line.cpp.o' failed\nmake[2]:  [CMakeFiles/support.dir/src/support/command-line.cpp.o] Error 1\nCMakeFiles/Makefile2:178: recipe for target 'CMakeFiles/support.dir/all' failed\nmake[1]:  [CMakeFiles/support.dir/all] Error 2\nMakefile:127: recipe for target 'all' failed\nmake: *** [all] Error 2\n```\nHere's my new GCC.\n$ c++ -v\nUsing built-in specs.\nCOLLECT_GCC=c++\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-pc-cygwin/5.3.0/lto-wrapper.exe\nTarget: x86_64-pc-cygwin\nConfigured with: /cygdrive/i/szsz/tmpp/gcc/gcc-5.3.0-3.x86_64/src/gcc-5.3.0/configure --srcdir=/cygdrive/i/szsz/tmpp/gcc/gcc-5.3.0-3.x86_64/src/gcc-5.3.0 --prefix=/usr --exec-prefix=/usr --localstatedir=/var --sysconfdir=/etc --docdir=/usr/share/doc/gcc --htmldir=/usr/share/doc/gcc/html -C --build=x86_64-pc-cygwin --host=x86_64-pc-cygwin --target=x86_64-pc-cygwin --without-libiconv-prefix --without-libintl-prefix --libexecdir=/usr/lib --enable-shared --enable-shared-libgcc --enable-static --enable-version-specific-runtime-libs --enable-bootstrap --enable-__cxa_atexit --with-dwarf2 --with-tune=generic --enable-languages=ada,c,c++,fortran,lto,objc,obj-c++ --enable-graphite --enable-threads=posix --enable-libatomic --enable-libcilkrts --enable-libgomp --enable-libitm --enable-libquadmath --enable-libquadmath-support --enable-libssp --enable-libada --enable-libgcj-sublibs --disable-java-awt --disable-symvers --with-ecj-jar=/usr/share/java/ecj.jar --with-gnu-ld --with-gnu-as --with-cloog-include=/usr/include/cloog-isl --without-libiconv-prefix --without-libintl-prefix --with-system-zlib --enable-linker-build-id --with-default-libstdcxx-abi=gcc4-compatible\nThread model: posix\ngcc version 5.3.0 (GCC)\nMaybe it would compile with MSVC toolchain? With a little help from CMake?\n. Hi again,\nAfter my failure with Cygwin I tried it with CMake under Windows.\nI used the CMake-GUI and defined the needed stuff (src folder, compiler version etc.). Generated the whole proj/sln files.\nNow, it compiles under VS 2015. :smiley: \n\nI'm not sure how many are using VS2015 to compile all this but if there's any interest I could write a small tutorial. Just to help others save their time (and prevent them from trying it with Cygwin under Windows :sweat_smile: )\nRegards,\n. Hi @kripken,\nAs promised, I wrote a small tutorial on building under Windows with CMake & VS2015.\nI hope it'll be of some value to others with similar problems.\nhttps://github.com/brakmic/brakmic/blob/master/webassembly/COMPILING_WIN32.md\nKind regards and many thanks :+1: \n. Hi,\nI'll open a new PR regarding the tutorial. \nRegards, \n. @dreamlayers \nNot a Ubuntu user but it could be related to this issue: https://github.com/WebAssembly/binaryen/pull/260\n. Oh, I see there's already a similar pull request. \nWell, I think I should close this one as the other is a few days older.\nSorry.\n. Honestly, I don't understand what \"sorting headers\" mean. \nAlphabetically or in some other way?\nI just spotted a problem regarding a compilation under VS2015 and wanted to provide a remedy. \nBut I think I should not interfere with such complex projects like WebAssembly because I'm not even able to understand what \"sorting headers\" mean. :smile: \nSorry for any inconvenience caused. Bye.\n. Of course. :smiley: \n. ",
    "AaronShea": "Oddly, I'm getting this exact same build error on Arch Linux\n. ",
    "dreamlayers": "Also fails in Ubuntu 16.04 64-bit, using g++ (Ubuntu 5.3.1-13ubuntu3) 5.3.1 20160330\nThe build is with -std=gnu++11\nThis is a namespace issue. isnan() and others exist in namespace std, so they're not seen by default. My workaround to get it to build was adding using namespace std; near the start of ~/.emscripten_ports/binaryen/binaryen-version_1/src/wasm.h, just before the namespace wasm { line. But, some people think that sort of thing is a bad idea: https://stackoverflow.com/questions/1452721/why-is-using-namespace-std-in-c-considered-bad-practice\nSo I guess the right solution is adding the std:: prefix where necessary?\n. ",
    "ramiro1234": "Is this still an issue and if so is it possible to get a little more background info?. I write the wasm output to a file and set the version manually. The browsers are not always up to date\n. I'll look at the code and see if this is something I can do. ramiro\n. Not much.\n I started off on the wrong track, got a little sidetracked and needed to get back into C++ mode. \nAnyway after looking at the code, everything needed - wasm-as and wasm-dis - is pretty much already there. I just need to write a class or 2 that puts everything together. I will focus on it over the next week and I should be able to come up with something.\nBasically I'm looking at   .wasm/.wast reader and a .wasm/.wast writer.  I will using the file extensions to determine which is which and that checking will be done within the classes.  Most of the tools/code don't do that so if you would rather have a separate file validation class let me know.\nI'll follow the same format as the rest of the code  and put most of the classes  in an .h file so it can be included as needed  and cobble together a small demo.\nSorry for the delay. \nramiro\n. Just a quick update on the unified reading/writing. \nI had hoped to submit something by this Friday but I ran into  some odd linking errors and, of course,\nI thought I had forgotten or overlooked something that I needed to  do.  \nAnyway, I finally got it to compile the code but I'm not really sure what I did to get it to work. So I am going to spend the weekend testing to see if I can nail down the issue just to make sure it's not the code.  I noticed there were some linking issues that have come up in the past with clang and will review to see if that has something to do with the problems I am having.\nramiro. Attached is a zip file with \u00a02 files:WebAsmReader.hwasm2wasm.cpp\nThe first file contains a struct which will read and write either wasm or wast files.Basically I used the code in wasm-as and wasm-dis but took out most the exception handling \u00a0sothat it can be handled by app/client. I used a char * to explicitly allocate and deallocate memoryto relieve memory pressure and did have to catch one exception to handle that but then rethrew it.The code still needs to be cleaned up but I thought I would leave it as is to make it easy to see thechanges \u00a0I made and whether I completely missed the boat on what you wanted.\nI should mention that at the beginning I got some strange output \u00a0and at other times odd linking errors but I never the track the source of the problem and over the weekend it never reocurred.\nLinking was no problem since I just edited the CMakeLists.txt file by addingSET(wasm2wasm_SOURCES\u00a0 src/tools/wasm2wasm.cpp)ADD_EXECUTABLE(wasm2wasm\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0${wasm2wasm_SOURCES})TARGET_LINK_LIBRARIES(wasm2wasm passes wasm asmjs support)SET_PROPERTY(TARGET wasm2wasm PROPERTY CXX_STANDARD 11)SET_PROPERTY(TARGET wasm2wasm PROPERTY CXX_STANDARD_REQUIRED ON)INSTALL(TARGETS wasm2wasm DESTINATION bin)\nIf I completely missed the boat on this just let me know. It was tons easier than I thought it would be so \u00a0I must be missing something\nram\nOn Monday, December 5, 2016 7:03 PM, Alon Zakai <notifications@github.com> wrote:\n\nCool, thanks for looking into this - it's becoming a high priority as we get close to stable wasm in browsers. This issue is probably the biggest relatively easy win in compile times, and it avoids some corner cases with really slow compile times (when the wast is ridiculously large).And yeah, using the file extension is what we want, I agree. Other details sound good too.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n/\n Copyright 2016 WebAssembly Community Group participants\n\n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n You may obtain a copy of the License at\n\n     http://www.apache.org/licenses/LICENSE-2.0\n\n Unless required by applicable law or agreed to in writing, software\n distributed under the License is distributed on an \"AS IS\" BASIS,\n WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n See the License for the specific language governing permissions and\n limitations under the License.\n*/\n//\n// wasm2wasm console tool\n//\ninclude \"support/colors.h\"\ninclude \"support/command-line.h\"\ninclude \"WebAsmReader.h\"\nint main(int argc, const char *argv[]) {\n  bool debugInfo =false;\nOptions options(\"wasm2wasm\", \"Unassemble .wasm (WebAssembly binary format) to .wast (WebAssembly text format)\\n or\"\n   \"\\nAssemble .wast (WebAssembly text format) to .wasm (WebAssembly binary format)\"\n   \"\\n filename extension determines selection (wast->wasm,wasm->wast) \");\n  options.extra[\"validate\"] = \"wasm\";\n  options.add(\"--output\", \"-o\", \"Output file (stdout if not specified)\", \n        Options::Arguments::One,\n         {\n          o->extra[\"output\"] = argument;\n          Colors::disable();\n        })\n        .add(\"--debuginfo\", \"-g\", \"Emit names section and debug info (wasm output only)\",\n          Options::Arguments::Optional,\n          & {\n            debugInfo = true;\n          })      \n        .add(\"--validate\", \"-v\", \"Control validation of the output module (wasm output only)\",\n           Options::Arguments::One,\n            {\n             if (argument != \"web\" && argument != \"none\" && argument != \"wasm\") {\n               std::cerr << \"Valid arguments for --validate flag are 'wasm', 'web', and 'none'.\\n\";\n               exit(1);\n             }\n             o->extra[\"validate\"] = argument;\n           })\n        .add_positional(\"INFILE\", Options::Arguments::One,\n         {\n          o->extra[\"infile\"] = argument;\n        });\noptions.parse(argc, argv);\n  WebAsmReader wr(debugInfo,options.extra[\"validate\"]==\"web\");\n  try{\nwr.write(options.extra[\"infile\"],\n         options.extra[\"output\"],\n         options.debug);\n\n} catch(ParseException &p){\n    p.dump(std::cerr);\n    std::cerr << std::endl;\n  }\n}\nifndef WEBASMREADER_H\ndefine WEBASMREADER_H\ninclude \ninclude \"support/file.h\"\ninclude \"wasm-binary.h\"\ninclude \"wasm-s-parser.h\"\ninclude \"wasm-printing.h\"\nusing namespace cashew;\nusing namespace wasm;\nstruct WebAsmReader\n{\nbool m_DebugInfo;\n  bool m_validateWeb;\n  WebAsmReader(bool debugInfo=false,bool valWeb=false):\n             m_DebugInfo(debugInfo),m_validateWeb(valWeb){}\nvoid write(std::string &inputFileName, \n             std::string &outputFileName,\n             bool debug=false)\n  {\n    if (inputFileName.length()>5)\n    {\n      auto ext = inputFileName.substr(inputFileName.length()-5);\n      if (ext.compare(\".wasm\")==0)\n      {\n        writeWast(inputFileName,outputFileName,debug);\n        return;\n      }\n      if (ext.compare(\".wast\")==0)\n      {\n        writeWasm(inputFileName,outputFileName);\n    //m_textInput=read_file<std::string>(fileName, Flags::Text, debug ? Flags::Debug : Flags::Release);\n\n    return;\n  }\n}\n\nthrow ParseException(\"filename must end in .wast or .wasm\");\n\n}\nvoid writeWast(std::string inputFileName,\n                 std::string& outputFileName, \n                 bool debug=false)\n  {\nauto input= read_file<std::vector<char>>(inputFileName, Flags::Binary, debug ? Flags::Debug : Flags::Release);\n\nif (debug) std::cerr << \"parsing binary...\" << std::endl;\nModule webasm;\n//try {\n  WasmBinaryBuilder parser(webasm, input, debug);\n  parser.read();\n\n// } catch (ParseException& p){\n      //p.dump(std::cerr);\n     // Fatal() << \"error in parsing wasm binary\";\n     // m_input.clear();\n     // throw p;\n     // return;\n   // }\n    if (debug) std::cerr << \"Printing...\" << std::endl;\n    Output output(outputFileName, Flags::Text, debug ? Flags::Debug : Flags::Release);\n    WasmPrinter::printModule(&webasm, output.getStream());\n    output << '\\n';\n    if (debug) std::cerr << \"Done.\" << std::endl;\n  }\nvoid writeWasm(std::string& inputFileName, \n                 std::string& outputFileName,\n                 bool debug=false)\n  {\n    struct stat st;\n    stat(inputFileName.c_str(),&st);\n    char p = new char[st.st_size+1];\n    std::ifstream infile(inputFileName);\n    infile.read(p,st.st_size);\n    infile.close();\n    Module webasm;\n    try {\n      if (debug) std::cerr << \"s-parsing...\" << std::endl;\n      SExpressionParser parser(const_cast(p));\n      Element& root = parser.root;\n      if (debug) std::cerr << \"w-parsing...\" << std::endl;\n      SExpressionWasmBuilder builder(webasm, *root[0]);\n    } catch (ParseException& pex){\n      //p.dump(std::cerr);\n      //Fatal() << \"error in parsing input\";\n      // awkward but finally not available\n      delete []p;\n      throw pex;\n    } \n    delete []p;\nif (m_validateWeb) {\n  if (debug) std::cerr << \"Validating...\" << std::endl;\n  if (!wasm::WasmValidator().validate(webasm,m_validateWeb)) {\n    throw ParseException(\"Error: input module not valid for Web\");\n  }\n}\n\nif (debug) std::cerr << \"binarification...\" << std::endl;\nBufferWithRandomAccess buffer(debug);\nWasmBinaryWriter writer(&webasm, buffer, debug);\nwriter.setDebugInfo(m_DebugInfo);\nwriter.write();\nif (debug) std::cerr << \"writing to output...\" << std::endl;\nOutput output(outputFileName, Flags::Binary, debug ? Flags::Debug : Flags::Release);\nbuffer.writeTo(output);\nif (debug) std::cerr << \"Done.\" << std::endl;\n\n}\n};\nendif\n. sure \nOn Wednesday, December 14, 2016 6:07 PM, Alon Zakai <notifications@github.com> wrote:\n\nCould you please make a PR on github with your changes? That would be more convenient to read.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n. Sorry, the holidays intruded and I also got a \u00a0bad case of the flu. I am just getting back on track. Should have something by the end of this week.\nramiro\u00a0 \nOn Tuesday, January 10, 2017 12:35 PM, Alon Zakai <notifications@github.com> wrote:\n\n@ramiro1234, this is getting urgent, so if you don't have time for it there's no problem (and lots of other non-urgent stuff you can contribute to if you want), but in that case we should let someone else do it. I'd like to see this landed in the next week or so.\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n. // The following works in Linux but not in Windows using Node.js\n// throws exception at Binaryen.compileWast\nvar Binaryen = require(\"./binaryen\");\nvar fs = require(\"fs\");\nvar  input ='(module\\n' +\n  '  (export \"add\" $add)\\n' +\n  '  (func $add (param $x f32) (param $y f32) (result f32)\\n' +\n  '    (f32.add\\n' +\n  '      (get_local $x)\\n' +\n  '      (get_local $y)\\n)))';\nvar b = Binaryen.compileWast(input);\nfs.writeFile(\"a.wasm\", b);\n// Workaround for Windows \nvar Binaryen = require(\"./binaryen\");\nvar fs = require(\"fs\");\nvar  input ='(module\\n' +\n  '  (export \"add\" $add)\\n' +\n  '  (func $add (param $x f32) (param $y f32) (result f32)\\n' +\n  '    (f32.add\\n' +\n  '      (get_local $x)\\n' +\n  '      (get_local $y)\\n)))';\nvar module = new Binaryen.Module();\nvar parser = new Binaryen.SExpressionParser(input);\nvar s_module = parser.get_root().getChild(0);\nvar builder = new Binaryen.SExpressionWasmBuilder(module, s_module);\nvar debug=false;\nvar buf0 = new Binaryen.BufferWithRandomAccess(debug);\nvar wasmWriter = new Binaryen.WasmBinaryWriter(module,buf0,debug);\nwasmWriter.write();\nvar b = Buffer(buf0.size());\nfor (var i=0; i<buf0.size(); i++)b[i]= buf0.at(i);\nfs.writeFile(\"a.wasm\", b);\n. You were right. It was a Node.js bug. Sorry about that. Buffers are such a core part of Node I didn't think that would be the problem.\n. technically the latest version of  Nightly does not support wasm, it supports Web Assembly. The latest versions of Chrome Canary and Nightly support the latest updates to Web Assembly in terms of version and JS API. You will get an error message saying if the version is not up-to-date  but for the latest JS API it will simply say wasm not supported.  Only the latest tools are guaranteed to work as far as the latest browsers are concerned. \nFor those working on s-expressions there are some differences in the Web Assembly Toolkit and binaryen with the Web Assembly Toolkit being a little more up-to-date.  The makes a difference mostly for compiler writers of which I am one.\nYou can't work on the bleeding-edge without bleeding a little bit.. Forget my previous message. Nightly on Linux is fine. I downloaded and forget to set the config. Anyway it should not be a wasm issue as far as Nightly is concerned. It does the current version and the new JS API.\n  . Actually I was thinking that too since it really does not add functionality but it was quick and easy way to demo the code. I'll wait\u00a0 for all of the comments before starting to make any changes.\nr\nOn Wednesday, January 11, 2017 12:44 PM, Alon Zakai <notifications@github.com> wrote:\n\nThanks! Looks like a good start. I'll write a bunch of specific comments, but first one general thing: I don't think we need to add a wasm2wasm tool. Instead, we should use the new ability to read/write wast/wasm in wasm-opt. Then it would do what wasm2wasm does, plus optionally optimize.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.  \n. Sorry but my laptop is dying. I have a backup system but it is too old to run the newer versions of c++ and some of the other tools. \u00a0I tried downloading and building to see if I could at least do something but it just didn't work.\u00a0\nSorry about all of this. I am having trouble at work as well but the tools I rely on there don't rely as much on the latest versions so I can get by.\u00a0\nI have had the worst luck this year. My house almost caught fire over the holidays and just lately I thought I had lost my wallet and was going to get in real trouble at my job.\u00a0\nEverything is working out or will work out but at the moment I don't have a system powerful enough and up-to-date enough to really do anything and it will be at least a while before I do.\nramiro\n\u00a0\u00a0\n\u00a0\nOn Monday, January 23, 2017 5:14 PM, Alon Zakai <notifications@github.com> wrote:\n\n@ramiro1234: this particular feature is fairly urgent as I mentioned before. if you don't have time to address the comments quickly, I think I should take over. Sorry about that, but lots of other important stuff that is less urgent :)\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.  \n. not needed. \nI was fiddling with the make files because I got some weird linking errors and forgot to back out this change. \nr. ",
    "froydnj": "Repeating the question on whether this is still an issue.. The warnings have gone away in #1386, so I guess this issue can be closed?  Trying to express memory ownership more clearly with types would be good, but that should be a separate issue.. There's nothing cross-platform for sscanf, but it looks like #882 added /D_CRT_SECURE_NO_WARNINGS, as the initial error suggests.  So I think this issue can be closed.. Looks like the original report came from mismatched pieces of the toolchain, so this PR should be closed?. @kripken You said ~year ago this was getting urgent, has it been done in the meantime?. @kripken It looks like this issue can be closed now?. @kripken, can we close this now?. Looks like #978 got fixed, so this can be closed now?. @kripken, since #1219 got merged, can you close this, please?. Can we go ahead and close this, then, @binji?. Since #1301 got merged, can we close this, @kripken?. > Hmm, one remaining topic mentioned above is whether we should built with -Werror or not. Perhaps it should be on for testing, but not on by default for users? Or perhaps it's better to see errors even there and get reports on them?\nI think that's a separate bug; I've filed #1387 for discussion on that.. @zachrip, have you had a chance to look into this?. Is this a wontfix given comments like \"the plan is to avoid the .s format entirely, so llvm would emit a wasm and binaryen's s2wasm wouldn't be needed\", or will s2wasm continue to be supported?. @krisselden Do you have plans to finish this up?. On my local Linux machine, python tests/runner.py binaryen3.test_sqlite takes about 25-30s, depending, before erroring out with:\n```\ntest_sqlite (test_core.binaryen3) ... (checking sanity from test runner)\nINFO:root:(Emscripten: Running sanity checks)\n  ok\n\nRan 1 test in 25.794s\nOK\n```\nwhich I think means that it ran all the optimizations appropriate to this bug.\nInspecting the process tree with tracetree says that about half of that time goes to running opt and about half that time to asm2wasm.  I assume the asm2wasm part is the part we're concerned about here.\nLooking at a perf profile is frustrating, as I don't think the bits in the SDK are compiled with appropriate options to enable cheap backtraces.  A flat profile for the above command says ~20% of the time is doing malloc/free.  LocalGraph::visitGetLocal and SimplifyLocals::visitPost show up taking ~3% of the time each--and that's over the entire run, so roughly 6% each during asm2wasm (!).\nDoing a callgraph profile says that we're spending a lot of time manipulating std::_Rb_tree<SetLocal*, SetLocal*, ...> instances; I think these correspond to manipulating LocalGraph::getSetses, LocalGraph::mappingStack, or LocalGraph::breakMappings.  The breakMappings.erase() call in LocalGraph::visitBlock is responsible for a lot of free traffic, for instance.\nSo a smaller representation for LocalGraph::Sets would be a good starting point.. Doing a EM_SAVE_DIR=1 run unfortunately doesn't seem to save the .asm.js files (?); at least, my /tmp/emscripten_temp is full of tmp${garbage}.jsfunc_0.js.jo.js.jo.js.jso.js files, and nothing looking like an .asm.js file, so it's a bit hard to run the asm2wasm command on its own.... Indeed, I mistakenly read those as member variables, not globals!  Clearing them would indeed be the reasonable thing to do in that case.. There's a well-known benchmark in C that features static variables that are actually used without regard to their static-ness; they can be fully converted to automatic, local variables for a performance win.  In a former life, I wrote an optimization pass to do this.  The consensus from that thread was that some form of PRE would do most of the work for this optimization, and that you'd really only need some sort of cleanup pass to recognize stores as dead.\nThis case sounds pretty similar, though perhaps with JS, the optimization pass would trigger a bit more often?. Fixed some issues in #1386, but left the signed/unsigned issues for a little later.. > lgtm, but looks like flake8 has some style errors that fail the tests.\nYeah, trying to fix linting errors.  I don't suppose the testsuite can lint itself as a test...?. Eh, I can follow the rule now that I know it's being checked for, and everything passes now anyway!. > Is it worth having Travis do out-of-tree builds to avoid regressing here? I figure if we test out-of-tree, its unlikely that in-tree will break, whereas the inverse is less true.\nThis would be great!  It would need #1370 addressed, at least, but maybe that could be hacked around in the Travis setup.. > These changes don't require updates in the existing wasm2asm tests?\nGood point, added tests for translating everything (no assertions yet, though).  The asm.js looks a little funny (multiple returns, for instance), but that can be handled in a followup.. > Should we merge this or did you have more thoughts on refactoring?\nI have no additional thoughts on refactoring.  I can see the point about shorter/simpler code though; I think there are fewer local variables generated with this version than my original blocked version.. Cool!  I'll look at removing the extraneous return statements next week.. It looks like this is all that's needed:\ndiff\ndiff --git a/src/wasm2asm.h b/src/wasm2asm.h\nindex 59f2d6a..5cd757e 100644\n--- a/src/wasm2asm.h\n+++ b/src/wasm2asm.h\n@@ -655,7 +655,8 @@ Ref Wasm2AsmBuilder::processFunction(Function* func) {\n   ExpressionList* stats = isBodyBlock ?\n       &static_cast<Block*>(func->body)->list : nullptr;\n   bool endsInReturn =\n-      (isBodyBlock && ((*stats)[stats->size()-1]->_id == Expression::ReturnId));\n+      (isBodyBlock && ((*stats)[stats->size()-1]->_id == Expression::ReturnId)) ||\n+    func->body->_id == Expression::ReturnId;\n   if (endsInReturn) {\n     // return already taken care of\n     flattenAppend(ret, processFunctionBody(func, NO_RESULT));\nwhich requires regenerating all the .2asm.js files; I'm going to wait until at least #1442 lands before putting together a PR for this.. > Just wanted to make sure you're aware of auto_update_tests.py, which does that automatically.\nI was not, that's super useful!  I had written a one-liner to update the tests, but it wasn't perfect; having an already-written script will make things much easier.. @kripken Can you repush this to re-run CI now that multiple return statements have been fixed?. I would have said mentioning testing with node and spidermonkey in the README.md, but I see there's nothing specifically mentioning wasm2asm there in the first place.  So I don't think we need anything there.  No other concerns from me!. > Not sure what the CI errors are - maybe not all tests were updated?\nSigh, apparently CI checks out extra tests in a different repo and runs those, too?  How are those supposed to be updated in parallel?. Specifically, address.2asm.js and forward.2asm.js were not updated, because those files don't exist in the binaryen repo, only in the testsuite repo.. Oh, I see, I don't have to update a separate repo, I just have to have the repo checked out, and auto_update_tests.py will take care of those automatically.  I was confused!. @kripken I don't know where to go from here.  The test passes locally for me, and I think I've regenerated the JS files correctly.  Can you try regenerating the files?. Sigh, last thing to fix:\nexecuting:  bin/asm2wasm /home/travis/build/WebAssembly/binaryen/test/two_sides.asm.js --trap-mode=clamp -O0\n[PassRunner] running passes...\n[PassRunner]   running pass: finalize-calls...        0.0004724 seconds.\n[PassRunner]   (validating)\nThe job exceeded the maximum time limit for jobs, and has been terminated.\nIs this a known potential problem?  I guess it's possible that the change might have eliminated a return statement that was there before, and thus the test never returns, or something?. > I've seen that before, it seemed like a random CI failure. Might be ok after a restart.\nHm, OK.  Had to fix another merge conflict anyway, so rebased and pushed again.  We'll see if CI is happy now.. Hopefully fixed the merge conflicts, so assuming all the tests pass, this can be merged.. > It's hitting a problem that looks like a bad merge to me - it's looking for a file that doesn't exist, with a very long name, that we recently added an option to use a numeric name for, #1450. Perhaps in the merge that logic got lost?\nYou're totally right; I failed to actually consider why I was getting merge conflicts when rebasing, and just took my version.  I should have looked a little closer at what was going on.  Ideally this push will address that rebasing issue.. That seems reasonable to me.  I'll try to have a go at implementing that.. > But for non-emscripten programs, yeah, this is not valid to do in general. An option might be to do a function call out to JS to do it for us. That has the downside of being slower and requiring us to include some JS support code which I don't think we have needed yet.\nJust to be clear, this would make the resulting code almost-asm in the same way that touching grow_memory and similar already do?. Gah, always forget about the binaryen tests.  Building binaryen.js worked out, but running ./auto_update_tests.py afterwards did not:\n```\n[ checking example testcases... ]\nbuild:  gcc test/example/c-api-hello-world.c -c -o example.o -Isrc -g -L/home/froydnj/src/emsdk-portable/clang/e1.37.36_64bit/binaryen/lib -pthread\n/home/froydnj/src/binaryen.git\n   c-api-hello-world.c test/example/c-api-hello-world.c test/example/c-api-hello-world.txt\nlink:  g++ -std=c++11 example.o -lbinaryen -Wl,-rpath=/home/froydnj/src/emsdk-portable/clang/e1.37.36_64bit/binaryen/lib -Isrc -g -lasmjs -lsupport -L/home/froydnj/src/emsdk-portable/clang/e1.37.36_64bit/binaryen/lib -pthread -o bin/example\n/usr/bin/ld: cannot find -lbinaryen\n/usr/bin/ld: cannot find -lasmjs\n/usr/bin/ld: cannot find -lsupport\ncollect2: error: ld returned 1 exit status\nTraceback (most recent call last):\n  File \"./auto_update_tests.py\", line 208, in \n    os.remove(output_file)\nOSError: [Errno 2] No such file or directory: 'bin/example'\n```\nPatched things manually and ./travis-emcc-tests.sh seems to succeed now.. Ah, getTemp() reuses temporary variables: https://github.com/WebAssembly/binaryen/blob/master/src/passes/I64ToI32Lowering.cpp#L1395\nThat doesn't seem correct, since we can't know in general whether a temporary is necessarily dead when its corresponding C++ object is destroyed.\n. OK, but getTemp actually tries to avoid that, because we can move TempVar values around, and the moved-from values shouldn't free the temporary variable for future use.  So in this case C++ lifetimes should provide a reasonable facsimile of lifetimes of the values in the compiled program.  But here they're not, because we're reusing a value when it's actually still live.... Ah, ok, this is actually pretty straightforward: the lowering pass is a PostWalker visitor, so we're visiting the leaves first.  In the original example, that's the i64.shl instructions.  But we don't remember that the low bits from the first i64.shl instruction need to remain live for the i64.or instruction, so the temporary that stored the low bits is reused for the second i64.shl instruction.  We do remember the high bits, since those are stuffed in a table for reuse and thus their TempVar values are not destroyed.\nThe straightforward solution is to remember the low bits as well, though that would require creating local vars for every such value, with corresponding setLocal/getLocal instructions, leading to somewhat cluttered IR.  The not-straightforward solution is to rewrite the lowering pass to walk the IR differently.. Another option is to run a pre-flattening pass before i64 lowering so we never have to deal with tree structure in wasm2asm.  This seems to work well in testing.. > Tests don't look fully updated, did you update them after rebuilding the js?\nI thought I did!  I will take a second look.. > Looks good, but also this makes me think, maybe we should only run optimization passes when optimizing? For now though this seems fine.\nI don't understand this comment.  Is there a optimization switch for wasm2asm (I don't see one), or are you talking about a higher level tool?. Also, since I botched the test updating here, I'll just wait until #1483 lands before updating this, since there will be conflicts otherwise.. The rebased patch shows that em++ was doing a fine job of cleaning up unused variables on its own, but it's still nice to not have a bunch of clutter in the output. :). This will require rebasing (I didn't update the binaryen.js and wasm.js files for that reason), but I wanted feedback on the approach.. New version pushed that pulls the remapping further up the respective functions.. They are translated to asm.js and executed via this code: https://github.com/WebAssembly/binaryen/blob/11a83d799d1b539f7c7a1eec987dc87119a098dd/scripts/test/wasm2asm.py#L47-L52. For ease of debugging?. Doh, good catch.. My (limited) understanding is that the corresponding get_local generated later will perform the truncation.  The reasons for this are not clear to me, but it is at least consistent with what all the other i64 lowering does.\nThe asm.js looks like this before the patch:\njs\n function $5($0, $0$hi) {\n  $0 = $0 | 0;\n  $0$hi = $0$hi | 0;\n  var i64toi32_i32$0 = 0, $3 = 0, $4 = 0, $5 = 0, $6 = 0, $7 = 0, $8 = 0, $9 = 0, $10 = 0;\n  $4 = (i64toi32_i32$0 | 0) == (0 | 0);\n  i64toi32_i32$0 = $0$hi;\n  return $4 & ($0 | 0) == (0 | 0) | 0 | 0;\n }\nNotice that we've completely dropped anything having to do with the high bits.  After the patch (without the eqz (or x y) optimization introduced later in the patch series), it looks like:\njs\n function $5($0, $0$hi) {\n  $0 = $0 | 0;\n  $0$hi = $0$hi | 0;\n  var i64toi32_i32$0 = 0, i64toi32_i32$1 = 0, $4 = 0, $5 = 0, $6 = 0, $7 = 0, $8 = 0, $9 = 0, $10 = 0, $11 = 0, $12 = 0, $13 = 0, $14 = 0, wasm2asm_i32$0 = 0;\n  return ($0$hi | 0) == (0 | 0) & ($0 | 0) == (0 | 0) | 0 | 0;\n  return wasm2asm_i32$0 | 0;\n }\nwhich is much more sensible.. How is that any different from the original code, which used curr->value directly?. The original code wanted to do (and (eqz $hi) (eqz $lo)) which is a valid translation of i64.eqz: if both 32-bit parts are equal to zero, the 64-bit integer is equal to zero.  But the code as written was generating the above asm.js, which was wrong.\nEven with the (eqz (or $hi $lo)) algorithm, if you change it to use a bare curr->value:\n```c++\n    TempVar highBits = fetchOutParam(curr->value);\nBlock* result = builder->blockify(\n  builder->makeUnary(\n    EqZInt32,\n    builder->makeBinary(\n      OrInt32,\n      builder->makeGetLocal(highBits, i32),\n      curr->value\n    )\n  )\n);\n\nreplaceCurrent(result);\n\n```\nYou get incorrect results, because the asm.js looks like:\njs\n function $5($0, $0$hi) {\n  $0 = $0 | 0;\n  $0$hi = $0$hi | 0;\n  var i64toi32_i32$0 = 0, $3 = 0, $4 = 0, $5 = 0, $6 = 0, $7 = 0, $8 = 0, $9 = 0, $10 = 0, $11 = 0;\n  $3 = i64toi32_i32$0;\n  i64toi32_i32$0 = $0$hi;\n  return ($3 | $0 | 0 | 0) == (0 | 0) | 0;\n }\nwhich is pretty bogus.. This part is probably my least favorite part of the change, because we're overloading the environment variable to mean multiple things:\n\nValidate the IR between passes.\nDump out intermediate IR between passes.\nSaving the IR from the last pass for debugging purposes.\nWrite timing information.\nStatus updates about how things are progressing.\n\nIt's not clear to me that all of these should really be crammed into a single option; it feels cleaner to have multiple command-line options, say, --print-times, --validate-between-passes, --dump-pass-ir, or similar.  Then we would ditch the environment variable altogether.  WDYT?. Done!. ",
    "antelle": "Here's a stack trace in a debug build\n```\n(gdb) bt\n0  0x00007f2cd545b267 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:55\n1  0x00007f2cd545ceca in __GI_abort () at abort.c:89\n2  0x0000000000471e49 in wasm::WasmBinaryWriter::getFunctionIndex (this=0x7fff4765b6c0, name=...)\nat /home/antelle/binaryen/src/wasm-binary.h:687\n\n3  0x0000000000471aad in wasm::WasmBinaryWriter::writeExports (this=0x7fff4765b6c0)\nat /home/antelle/binaryen/src/wasm-binary.h:651\n\n4  0x00000000004703de in wasm::WasmBinaryWriter::write (this=0x7fff4765b6c0)\nat /home/antelle/binaryen/src/wasm-binary.h:464\n\n5  0x000000000046c4ce in main (argc=4, argv=0x7fff4765c048)\nat /home/antelle/binaryen/src/wasm-as.cpp:57\n\n```\nThe function name was _emscripten_replace_memory.\nJust tried to remove an export with this function from wast file, and it worked without error.\n. Yes, I mean growth. Thanks for status! I thought it was supported already.\n. ",
    "rwtolbert": "I think the std:: is probably required for non-Windows.\nA simpler fix is to #include <cctype> \n. :thumbsup: \nI spent some time this weekend making the build happy using VS2015. Just a few small changed here and there and I can do everything except run the tests that assume they can download and run a pre-built executable.\nBut I know this is a young project, so I'm not sure if there is too much churn to keep Windows/VS2015 as a first-class build platform or if there are too many daily changes to keep test output checked in as opposed to re-generating it locally.\nI'd love to help with both, just don't want to get in the way.\nand if there is a better place to discuss, let me know.\n. I think being able to also use a locally built LLVM should work. At least now I see the reason for the current behavior.\nTurns out, I only thought that was my problem on Windows. Actually, I'm crashing in a real test (binary-shell) that should work with out that piece, so I need to dig deeper into the cause of that problem first.\n. ",
    "buddhabrot": "Actually looks like more work is needed for ninja, will check it out\n. ",
    "juj": "Likewise the logic in function wasm::toSInteger32 and the others in that file are suspicious: the assert()s first ensure that the conditions exist for x to be in range, but then it still dynamically checks that it is so.\n. Another such location is in src\\wasm-interpreter.h, where there is a function size_t getFinalAddress(LS* curr, Literal ptr), but the function body returns a uint64_t, which gets truncated to 32-bit size_t. The return value should probably be a uint64_t, but this in turn ripples to where the function gets called, so needs a bit larger change to coordinate.\n. \"We can't really support running wasm64 code in a 32-bit process, so I don't think values that are supposed to hold linear address indices necessarily need to be 64-bit.\"\nI was thinking about the case that the binaryen toolchain was compiled as a 32-bit executable (e.g. default CMake config does that), but that it was still used to target wasm64. I know wasm64 is not a thing yet, but I presume the size_ts were being used with the intent to be forward compatible? So the bitness of the native executables doesn't have a meaning here, but addresses are intended to always be 64-bit to be future compatible with wasm64?\nAgreed that this is not a problem yet, but marked this down since this is generating a bunch of Visual Studio compiler warnings when doing truncating assignments. I'd be ok with using uint64_t to signal address or a size of a memory block, but having a specific typedefs like wasmptr_t and wasmsize_t (which equal to uint64_t) or something like that would be good as well.\n. Thanks, addressed review comments.\n. Thanks for merging and fixing the error!\n. Looks good - is the truncation intended, if x has a fractional part? (the assert before would ensure that it is always an integer)\n. Thanks - the earlier PR I did fixed build for VS2015, but the Emscripten unit test server has VS2013 Update 3. Tested locally with VS2013 Update 5, which builds current master correctly, so updated the Emscripten buildbot to VS2013 Update 5 as well, hopefully that should fix the remaining build issues.\n. https://github.com/WebAssembly/binaryen/pull/582 tries a minimal adjustment to pass linking to make this work.\n. I have not read about such decision, but I'd like to support VS2013.\n. The changes introduced here are small, so could we take a pragmatic approach and support vs2013 as long as that doesn't cause large refactoring? There are users who have asked vs2013 support for binaryen, and given that the current changes are on the complexity of adding few this-> statements to the build, I would not like to reject the support altogether?\n. Updated pull request. Unrelated, had to add a std:: to compile on VS2015.\n. Travis complains about the build when running the tests, but I'm not sure if I understand what's going on. Trying to carefully read through to find if I typoed a pass name or something, but nothing catches my eye. \n. The wasm:: namespace is not there by mistake, the project fails to compile in VS2015 without it in a VS error that make_shared is ambiguous and don't know how to resolve to either std::make_shared or wasm::make_shared.\n. err, meant make_unique above and not make_shared. VS2015 does have std::make_unique, but it finds it conflicting with wasm::make_unique. The exact error is\n1>C:\\code\\binaryen\\src\\tools\\binaryen-shell.cpp(204): error C2668: 'wasm::make_unique': ambiguous call to overloaded function\n1>  c:\\code\\binaryen\\src\\support/utilities.h(56): note: could be 'std::unique_ptr<wasm::Output,std::default_delete<_Ty>> wasm::make_unique<wasm::Output,std::basic_string<char,std::char_traits<char>,std::allocator<char>>&,wasm::Flags::BinaryOption,wasm::Flags::DebugOption>(std::basic_string<char,std::char_traits<char>,std::allocator<char>> &,wasm::Flags::BinaryOption &&,wasm::Flags::DebugOption &&)'\n1>          with\n1>          [\n1>              _Ty=wasm::Output\n1>          ]\n1>  C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\include\\memory(1628): note: or       'std::unique_ptr<wasm::Output,std::default_delete<_Ty>> std::make_unique<wasm::Output,std::basic_string<char,std::char_traits<char>,std::allocator<char>>&,wasm::Flags::BinaryOption,wasm::Flags::DebugOption>(std::basic_string<char,std::char_traits<char>,std::allocator<char>> &,wasm::Flags::BinaryOption &&,wasm::Flags::DebugOption &&)' [found using argument-dependent lookup]\n1>          with\n1>          [\n1>              _Ty=wasm::Output\n1>          ]\n1>  C:\\code\\binaryen\\src\\tools\\binaryen-shell.cpp(204): note: while trying to match the argument list '(std::basic_string<char,std::char_traits<char>,std::allocator<char>>, wasm::Flags::BinaryOption, wasm::Flags::DebugOption)'\n. In above, VS2015 does say \"[found using argument-dependent lookup]\". I'm not sure if there is an explicit ambiguity clause saying if ADL lookup vs non-ADL lookup are treated the same, or if one should be ignored if the other one is matched, but to me VS2015 is correct here, the first param is a std::map, so it'd look in std::make_unique, and there's using namespace wasm; in the file, which would bring wasm::make_unique in as well.\n. Those flags don't fix the issue, as there is no /std:c++11. I think the simplest fix would be to just add the wasm:: in the few places like I did in my PR, or alternatively rename wasm::make_unique to something else. \nAlternatively, I could remove using namespace wasm; just in binaryen-shell.cpp, but that will result in 143 added explicit wasm:: qualifications in binaryen-shell.cpp, as opposed to the four cases that #582 adds. (actually the build issue occurs on only one of those four lines, but added them all for consistency)\n. Yes, VS2013 and VS2015 both unconditionally compile code with the std::make_unique function enabled, i.e. in C++14 mode with this respect. That function is not in global namespace, but due to argument-dependent lookup (ADL or Koenig lookup), it pulls it from within std:: since a parameter to that function is in the std:: namespace (std::map in this case).\nWrapping the code inside namespace wasm does not fix the issue, since the root problem for that code remains, that an unqualified make_unique can either mean wasm::make_unique (since we're inside the namespace), or std::make_unique (due to ADL). I think the options are either to explicitly qualify with wasm:: or rename.  \n. The main rationale for this is that with Emsdk we want to do out of tree builds, and Emsdk itself is lined up to be able to do both a Debug and a Release build of a SDK side by side, and the builds are put to separate directories. The RelWithDebInfo target is the default target that the incoming developer branch uses, so matching that across all built repos on the build system simplifies a bit.\n. The try build currently fails because it needs this line, so probably good to merge after #771.\n. Actually, given that Travis is saying something else red about #771, updated this PR to carry the above change.\n. The CMake install step would probably just complicate here, since that would require doing an install before being able to use the build products. I don't think it's worth to start complicating the build steps more.\n. They are referenced e.g. in https://github.com/kripken/emscripten/pull/4623/files#diff-ae40e645f84e893ce5d037b5efc53be6R1973. I did not want to change the directory structure more than necessary (just look at both bin/ and without), so I let binaryen.js and wasm.js live in the same directory they were at, which is originally from https://github.com/WebAssembly/binaryen/tree/master/bin.\n. These two files are text files that are passed as input to s2wasm, and git converts them on checkout from \\n line endings to \\r\\n line endings (the most common repository line ending format people use with git):\n- https://github.com/WebAssembly/binaryen/blob/master/test/linker/archive/foobar.a\n- https://github.com/WebAssembly/binaryen/blob/master/test/linker/archive/barlong.a\nLoading those files assert fails immediately in a memcmp trying to find !<arch>\\n when it sees !<arch>\\r\\n instead. My understanding is that all input files to s2wasm are in textual format like this?\n. Or hmm, perhaps that assumption is not correct, and these two are just special cases..\n. Yeah, that does work, but oddly it's a bit flaky and only works on a clean checkout. I.e.\ngit clone https://github.com/WebAssembly/binaryen.git\ncd binaryen\ngit checkout archive_files_windows_eol_fix\ndoes not work if master branch doesn't have the .gitattributes set, but the archive_files_windows_eol_fix branch does.\nAfter checking out archive_files_windows_eol_fix, deleting the .a files and git reset --harding back to archive_files_windows_eol_fix, the files do get \\n endings. So on the long run this will work - on Windows side one will need to reclone once this reaches master.\n. Yeah, the .gitattributes route is better than the original one. Thanks for noticing that!\n. Visual Studio deterministically initializes all data to 0xcccccccc in debug builds, so it crashed there immediately when running. Hadn't seen this before when using binaryen on Windows because haven't gotten the test suite to run before.\n. The try build times out for some reason, https://travis-ci.org/WebAssembly/binaryen/jobs/167373236, but not quite sure why that would happen? Has there been flakiness like this with travis before?\n. Pushed the change to argparse, hopefully that wakes up travis (or perhaps something indeed causes a timeout here..)\n. Yay, passes travis now. How does this look?\n. I think after this is merged, the Linux bot should pass (http://clb.demon.fi:8112/#/builders/4/builds/16/steps/10/logs/stdio)\n. Looks like these failures also occur on Travis servers, but the fatal error is not actually triggering a test suite failure: https://travis-ci.org/WebAssembly/binaryen/jobs/167907643#L3145\nI wonder if these tests are expected to fail (given the filenames), but they are just noisy and are shouting out the error they expect to see? In that case, perhaps it is possible to somehow mute the error from getting printed if the error is expected? That way all printed errors would be real errors.\n. Had to make a small build fix after @kripken's comment above to fix the torture+waterfall build. Not sure how the waterfall builds work btw, since I'm unable to get them running, the download step always fails for me.\n. The fix was to add these two lines: https://github.com/WebAssembly/binaryen/pull/785/files#diff-80ee07c6b10902b1bae15660a736de65R108 and https://github.com/WebAssembly/binaryen/pull/785/files#diff-80ee07c6b10902b1bae15660a736de65R630 and the one line below. Those calls run without valgrind, I don't know how to integrate with them, or if that makes sense even, since they call a script link_assembly_files outside this repository.\n. For curiosity, timings to run the suite with and without Valgrind:\n```\nWithout Valgrind:\nreal    10m26.104s\nuser    13m16.888s\nsys     1m31.612s\nWith Valgrind:\nreal    39m9.835s\nuser    41m17.384s\nsys     2m28.404s\n```\nso Valgrind will be about 4x perf cost to run the suite. (optional of course)\n. Set up the OS X bot to run with Valgrind, so if there's something that might pop up, the bot should report now. Ran the suite through Valgrind locally, it came out clean.\n. The output looks like this: http://pastebin.com/SPwVTKbm\n. In the above list, all C6000 and C28000 level warnings are from static analyzer.\n. Windows buildbot now runs with VS static analyzer enabled (but in warnings mode only).\n. There was an upgrade from buildbot 0.8 to buildbot 0.9, and that changed the URLs. The address http://clb.demon.fi:8112/ can be used to visit (like you already noticed)\n. This looks great to me. One minor note, like discussed f2f, I think the terms of \"precise\" and \"imprecise\", and also \"dangerous\" are on the vague side, that they do have the effect of raising alarm bells in reader's mind, but they don't quite mention what exactly it is that is dangerous or imprecise by the feature.\nIs there big difference implementation wise to always return INT_MIN on float-to-int out of range, versus INT_MIN and INT_MAX? I think the clamping behavior with INT_MIN and INT_MAX would be preferable (even if it differs from x86), because it does have a greater chance of actually being useful. Would it be trivial to support either mode? If so, we could make it part of the set of flags that was being discusssed in https://github.com/kripken/emscripten/issues/4625 for this.\n. Stellarificesquement job! lgtm. Thanks for the quick digging into this.. Great! Ran tests with this, before the fix uncompressed .wasm size on my test is 50\u00a0898\u00a0263 bytes (but doesn't work since it's affected by the issue), and after the fix (with the selectify pass disabled), it runs smooth and .wasm size is 50\u00a0965\u00a0668 bytes (+0.13% larger). This was a -Oz build in both cases. lgtm!. Err sorry, I had a misunderstanding here! My first understanding of this PR was that this PR would disable selectify pass as whole, but now I understand it does not.\nThis PR does fix the build to work correctly, and without this PR it did not work, so this PR works as expected. What I meant to write is that the size comparisons here were comparing a broken build to a working build.. Tried this out on UE4, and works nicely, with a 1-2% speed boost. lgtm!. I'd recommend doing the same for float-to-int conversion as well, especially because it looks like f32-to-int conversion currently upconverts to f64 before going to integer. Here is a screenshot of the impact of float-to-int conversion in Ogg Vorbis decoding audio (highlighted in red):\n\n. Sorry for missing this before!\nBefore we fix this, we really need to have a test case in Emscripten suite about this, since these types of items are critical and we don't routinely test MinGW compiler at the moment. Currently we run the Binaryen suite on VS2015 on each commit, but that is not catching the issue at the moment. @griffin2000, @jerstlouis: do you know of a short test case to repro to see the crash? I'm now building with Binaryen to test this out.\n. Investigated this in closer detail, I see that building Emscripten and Binaryen with MinGW 7.1.0, it does fail e.g. in Emscripten's test other.test_binaryen_debug.\nThe problem indeed is MinGW specific and does not appear in Visual Studio. However this is due to a bug in function wasm::read_file that only manifests in MinGW libstdc++ and not Visual Studio's c++ library.\nThe behavior that text file reading on Windows (in both VS and MinGW) has is that if a file has a byte sequence \\r\\n on disk, then reading those bytes in to memory in text mode should result in \\r\\n getting converted on the fly to \\n in memory. MSDN: \"Also, in text mode, carriage return\u2013linefeed combinations are translated into single linefeeds on input, and linefeed characters are translated to carriage return\u2013linefeed combinations on output.\".\nThis has the effect that the size on disk of a file is larger in bytes than the file size in memory, since \\r\\n -> \\n contracts the size by one byte when going to memory. The function ifstream::tellg() used in wasm::read_file always returns the size of the file in disk bytes, and that is the size that is allocated to memory. When the file is later read as text, there are more bytes allocated to it in memory than are needed, since the representation shrinks as \\r bytes are removed.\nThe behavioral difference that is observed here between Visual Studio and MinGW is that on Visual Studio, calling infile.read(&input[0], insize);, where insize is the disk size (and not the memory size), the excess bytes are not touched and they all end up being \\0s. This is benign for parser.h, and the code then constructs a std::string that just has excess \\0s at the end, one for each removed \\r character. However on MinGW it looks that the excess memory ends up getting garbage characters, most likely due to an in-memory contraction algorithm that removes \\rs in one go after a binary read. This is the root source of the crash, i.e. wasm::read_file returns a std::string that has garbage characters in the end, which then later fails in parser.h, when it is rolling through the garbage characters.\nThe bug is in wasm::read_file as opposed to MinGW I believe. One should not expect that infile.read() would read exactly as many characters in as is requested in bytes. However there is no good C++ fstream API to ask how many characters it was able to read. Therefore instead, PR #1088 shows how to fix using C file API, which works on MinGW.\nThe difference with the fix here and #1088 is that unconditionally passing binary flag to file open means that, on Windows, the \\r characters will begin to appear in the in memory representations of files opened in text mode. In parser.h function isSpace, those are currently taken into account, so for the parser at least, that is not a problem. (bool isSpace(char x) { return x == 32 || x == 9 || x == 10 || x == 13; } /* space, tab, linefeed/newline, or return */). However it should be made certain that all of the \\r characters are efficiently consumed, since this PR now has an asymmetricity that text files will then be opened in binary mode, but can still be written in text mode, which would mean that if any \\r\\n sequences are retained in memory, then those would get duplicated to \\r\\r\\n if they are later written out as text. I'm not sure if that can ever happen though.\nThe PR #1088 retains the current property that text content in memory only ever has \\n newlines and never \\r\\n, though it does revert to C API to be able to do that, since fstreams aren't too flexible for this purpose. Ultimately, I am ambivalent as to which way to go to fix. This PR is ok if we know that \\rs in memory are always ok and expected (are there locations in code beyond parser.h that would need to be audited for this?), and that it will not cause incorrect \\r\\r\\n expansion later due to this asymmetric nature.. > does anyone know why mingw is special here?\nThe difference seems to be as to how VS and MinGW perform the contraction of \\r characters. VS seems to discard \\r characters as it is going through the read, whereas MinGW seems to first read the whole file in memory in binary, and then use an in-memory filter algorithm to weed out \\rs, which resulted in garbage chars (leftovers of the input file) being observed as opposed to \\0s.. > Why are \\r even generated though? Are they only generated when done on Windows?\nEmscripten has a linker flag --output_eol linux|windows that can be used to choose the desired output line ending mode, on both Windows and Linux hosts. It defaults to the host choice, so on Windows, you can pass --output_eol linux linker flag to get \\n line endings.\n. Rewrote the PR to use gcount.. There was that unrelated change in this PR, added #1103 for that.. Good find @kripken , it indeed seems to have been a temporary bug. When reporting this, I had assumed that Xcode was already at its latest version, since generally Xcode updates via OS X autoupdates, but looks like that is no longer(?) the case here, and I had to explicitly reinstall Xcode to get to a newer version.\nSo updating Xcode from 7.3.3 to 8.3.1 resolved this issue.\nHowever this means that we only support macOS Sierra from now on, and older OS X versions are not supported. On OS X side, people are often quite eager to update, so perhaps that won't be any trouble.. This looks perfect, thanks!\nBtw, is there such a thing as float->u32 or float->u64 conversion? (since those would have different ranges to check). > Fully built binaries sounds potentially useful, cc @juj\nThis could be useful for developers who specifically look for standalone Binaryen toolchain. Though we do already have dedicated OSX, Linux and Windows hardware set up to continuously build, test and deploy Binaryen as part of the Emscripten SDK toolchain installation. That architecture is triggered by whenever a new tag is pushed to the repository for Emscripten and Binaryen. See here for reference: http://clb.demon.fi:8112/#/builders/1/builds/290 . Step 10 there performs the unit testing, and in http://clb.demon.fi:8112/#/builders/8/builds/173, step 5 does the build and deployment.\nI'm not familiar with Travis to be able to review this pull request. If this is useful for some users, then feel free to work this in. @jirutka : would you be the maintainer for this, or are you proposing that me or @kripken would take the ownership of maintaining?. > On Windows, latest precompiled emscripten/clang is 1.37.9 from April or so\nThe latest precompiled SDK should be sdk-1.37.14-64bit on all operating systems. If your emsdk is not showing that, try emsdk update (or emsdk update-tags if you're using git version of Emscripten) This is the expected output:\n```\nC:\\code\\emsdk>emsdk update-tags\nFetching all tags from Emscripten Github repository...\nDone. 102 tagged releases available, latest is 1.37.15.\nFetching all tags from Binaryen Github repository...\nDone. 28 tagged Binaryen releases available, latest is 1.37.14.\nFetching all precompiled Nightly versions..\nDownloading: C:/code/emsdk/llvm-nightlies-32bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/nightly/win_32bit/index.txt\nDownloading: C:/code/emsdk/llvm-nightlies-64bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/nightly/win_64bit/index.txt\nDownloading: C:/code/emsdk/emscripten-nightlies.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/emscripten/nightly/win/index.txt\nFetching all precompiled tagged releases..\nDownloading: C:/code/emsdk/llvm-tags-32bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/tag/win_32bit/index.txt\nDownloading: C:/code/emsdk/llvm-tags-64bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/tag/win_64bit/index.txt\nC:\\code\\emsdk>emsdk list\nThe following precompiled tool packages are available for download:\n...\nThe following tools can be compiled from source:\n...\nThe following precompiled SDKs are available for download: (Run \"git pull\" followed by \"./emsdk update-tags\" to pull in the latest list)\n...\n         sdk-1.37.13-64bit\n         sdk-1.37.14-64bit\nThe following SDKs can be compiled from source:\n...\n         sdk-tag-1.37.14-64bit\n         sdk-tag-1.37.15-64bit\nItems marked with * are activated for the current user.\nItems marked with (*) are selected for use, but your current shell environment is not configured to use them. Type \"emsdk_env.bat\" to set up your current shell to use them, or call \"emsdk activate --global \" to permanently activate them.\nTo access the historical archived versions, type 'emsdk list --old'\nC:\\code\\emsdk>emsdk install sdk-1.37.14-64bit\nInstalling SDK 'sdk-1.37.14-64bit'..\nInstalling tool 'clang-e1.37.14-64bit'..\nDownloading: C:/code/emsdk/zips/emscripten-llvm-e1.37.14.zip from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/tag/win_64bit/emscripten-llvm-e1.37.14.zip\nUnpacking 'C:/code/emsdk/zips/emscripten-llvm-e1.37.14.zip' to 'C:/code/emsdk/clang/e1.37.14_64bit'\nDone installing tool 'clang-e1.37.14-64bit'.\nInstalling tool 'node-4.1.1-64bit'..\nThe contents of file 'node_4.1.1_64bit.zip' already exist in destination 'C:/code/emsdk/node/4.1.1_64bit', skipping.\nDone installing tool 'node-4.1.1-64bit'.\nInstalling tool 'python-2.7.5.3-64bit'..\nThe contents of file 'python_2.7.5.3_64bit.zip' already exist in destination 'C:/code/emsdk/python/2.7.5.3_64bit', skipping.\nDone installing tool 'python-2.7.5.3-64bit'.\nInstalling tool 'java-7.45-64bit'..\nThe contents of file 'portable_jre_7_update_45_64bit.zip' already exist in destination 'C:/code/emsdk/java/7.45_64bit', skipping.\nDone installing tool 'java-7.45-64bit'.\nInstalling tool 'emscripten-1.37.14'..\nDownloading: C:/code/emsdk/zips/1.37.14.zip from https://github.com/kripken/emscripten/archive/1.37.14.zip\nUnpacking 'C:/code/emsdk/zips/1.37.14.zip' to 'C:/code/emsdk/emscripten/1.37.14'\nDone installing tool 'emscripten-1.37.14'.\nDone installing SDK 'sdk-1.37.14-64bit'.\n```\n\nOn Linux, more specifically on Travis trusty instances, precompiled binaries are incompatible with the respective system glibc/libstdc versions.\n\nDo you know if there exists documentation somewhere on how binaries should be built on Ubuntu to be compatible across different versions of Ubuntu? Or is this unfixable/unsupported and one needs to always build on the same Ubuntu version where one uses the binary?. > Seems there is something broken in my emsdk then. For reference, this is the output on my side:\nOh, emsdk update exiting without any messages is a bug that was present in earlier version, see this thread: https://groups.google.com/forum/#!topic/emscripten-discuss/bKCQxN6Q76Y. Apologies about the issue, bootstrapping to newest emsdk should fix that.\n\nThere are compiler flags to link glibc (-static-libgcc) and libstdc++ (-static-libstdc++) statically as far as I know, with the latter being somewhat error prone [1] [2] [3].\n\n@kripken : I wonder if we should add these as add_definitions(-static-libgcc) add_definitions(-static-libstdc++) to Binaryen's CMakeLists.txt?. > That\u2019s why it\u2019s useful to have fully static binaries (compiled with musl libc, as I did in this PR), these works on any Linux system, regardless of libc or kernel version (newer than 2.6).\nI think it would be good to configure that kind of thing in the generic CMakeLists.txt instead of in the Travis-specific configuration, since otherwise Travis will be testing a different build than is made by default, which might cause some Travis-specific issues, especially since @dcodeIO mentioned that these flags can be error prone.. The signal 9 killed message seems to always have been due to running out of memory. Sounds like this was fixed, so let me close as resolved.. Rewrote this PR to use C++ API with the istream::gcount() function. Also fixes a subtle C++ standard issue that dereferencing &input[0] is not allowed if input.size()==0. (this would assert fail on MSVC runtime in debug builds). Tested MinGW to be able to asm2wasm hello_world.c, which now properly passes.. Perhaps you have python 3 installed through which emsdk is running? Emsdk should be run on python 2, though just recently I did update it to be python 3 compatible again: https://github.com/juj/emsdk/commit/fd087c100da863752d5a892b7b7cecfdb0523731.\nLet me close this, feel free to reopen in https://github.com/juj/emsdk if that was not the cause and the issue still persist (try emsdk update or git clone https://github.com/juj/emsdk.git to get the above update). This is intentional. The tags on Binaryen point to the version of Emscripten that should be used with it. That is, Emscripten 1.37.16, 1.37.17, 1.37.18 and 1.37.19 all use Binaryen version 34. The release CI builders snapshot all four toolchain repositories (emscripten, fastcomp, fastcomp-clang, binaryen) on the same tag version to package the appropriate build.\n. The error is\n/home/jaday/dev/wasm/emsdk/binaryen/master/src/wasm/wasm-s-parser.cpp: In member function \u2018wasm::Expression* wasm::SExpressionWasmBuilder::makeExpression(wasm::Element&)\u2019:\n/home/jaday/dev/wasm/emsdk/binaryen/master/src/wasm/wasm-s-parser.cpp:876:9: error: this statement may fall through [-Werror=implicit-fallthrough=]\n         if (!strncmp(str, \"wake\", strlen(\"wake\"))) return makeAtomicWake(s);\n         ^~\n/home/jaday/dev/wasm/emsdk/binaryen/master/src/wasm/wasm-s-parser.cpp:878:7: note: here\n       default: abort_on(str);\n       ^~~~~~~\nTry changing\ncase 'w': {\n        if (!strncmp(str, \"wake\", strlen(\"wake\"))) return makeAtomicWake(s);\n      }\nto\ncase 'w': {\n        if (!strncmp(str, \"wake\", strlen(\"wake\"))) return makeAtomicWake(s);\n        abort_on(str);\n      }\nto see if that fixes the build. @kripken: does that look like a good fix to have overall?. This works pretty well. One related(?) item I'm seeing is that Emscripten pthreads tests fail with this \"atomic loads must be unsigned\" assert: https://github.com/WebAssembly/binaryen/blob/master/src/wasm/wasm-validator.cpp#L492\nWhen I comment that out, everything seems to be ok. Can that assert just be removed, or what is the rationale there?. Not quite sure what the spec status there is, though I do observe that with this PR paired with #1266, the pthreads test suite passes fully in Firefox Nightly \\o/. As a test case, a.cpp:\n```c++\ninclude \nint main()\n{\n    volatile unsigned char x = 5;\n    assert(x == 5);\n}\n```\nem++ a.cpp -o a.html -s USE_PTHREADS=1 -s WASM=1 -O1\nCuriously the unsigned operation does not appear in an -O0 build, only on -O1 and higher.. The issue occurs in this set of branches:\n - Emscripten: https://github.com/juj/emscripten/commits/pthreads_hack\n - Emscripten-fastcomp: https://github.com/juj/emscripten-fastcomp/commits/64bit_wasm_atomics\n - Emscripten-fastcomp-clang: current incoming, i.e. https://github.com/kripken/emscripten-fastcomp-clang/commits/incoming\n - Binaryen: https://github.com/WebAssembly/binaryen/commits/heapu64\nWith those, if I run the above test case and command line to build, it gives the error. My pthreads_hack is basically the same as Derek's threads-hack pull request, except that I've adapted it to work with Lars's Wasm try build; although for purposes of the compilation error, this probably would not matter.. Perfect!. Updated with test. I notice that python auto_update_tests.py unfortunately does not work on Windows. It runs into the following:\n```\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-emscripten-finalize test\\lld\\reserved_func_ptr.wast -S --global-base=568 --emscripten-reserved-function-pointers=3\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-emscripten-finalize test\\lld\\reserved_func_ptr.wast -S --global-base=568\n[ checking wasm-opt -o notation... ]\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\hello_world.wast -o a.wast -S\n[ checking wasm-opt binary reading/writing... ]\n.. memory-import-shared.wast\n     C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-import-shared.wast --print\n['C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt', 'test\\print\\memory-import-shared.wast', '--print'] (module\n (import \"env\" \"memory\" (memory $0 (shared 256 256)))\n)\n C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-import-shared.wast --print-minified\n\n.. memory-shared.wast\n     C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-shared.wast --print\n['C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt', 'test\\print\\memory-shared.wast', '--print'] (module\n (memory $0 (shared 23 256))\n)\n C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-shared.wast --print-minified\n\n.. min.wast\n     C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\min.wast --print\n['C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt', 'test\\print\\min.wast', '--print'] (module\n (type $0 (func (param f32) (result f32)))\n (type $1 (func (param i32 i32) (result f32)))\n (type $2 (func (param i32) (result i32)))\n (type $3 (func (param i32 i32 i32) (result i32)))\n (memory $0 256 256)\n (export \"floats\" (func $floats))\n (func $floats (; 0 ;) (type $0) (param $f f32) (result f32)\n  (local $t f32)\n  (f32.add\n   (get_local $t)\n   (get_local $f)\n  )\n )\n (func $neg (; 1 ;) (type $1) (param $k i32) (param $p i32) (result f32)\n  (local $n f32)\n  (tee_local $n\n   (f32.neg\n    (block $block0 (result f32)\n     (i32.store\n      (get_local $k)\n      (get_local $p)\n     )\n     (f32.load\n      (get_local $k)\n     )\n    )\n   )\n  )\n )\n (func $littleswitch (; 2 ;) (type $2) (param $x i32) (result i32)\n  (block $topmost (result i32)\n   (block $switch-case$2\n    (block $switch-case$1\n     (br_table $switch-case$1 $switch-case$2 $switch-case$1\n      (i32.sub\n       (get_local $x)\n       (i32.const 1)\n      )\n     )\n    )\n    (br $topmost\n     (i32.const 1)\n    )\n   )\n   (br $topmost\n    (i32.const 2)\n   )\n   (i32.const 0)\n  )\n )\n (func $f1 (; 3 ;) (type $3) (param $i1 i32) (param $i2 i32) (param $i3 i32) (result i32)\n  (block $topmost (result i32)\n   (get_local $i3)\n  )\n )\n)\n C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\min.wast --print-minified\n\n[ checking wasm-opt passes... ]\n.. 1.wast\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt --rereloop --dce --remove-unused-brs --remove-unused-names --coalesce-locals --simplify-locals --reorder-locals --remove-unused-brs --merge-blocks --vacuum split.wast --print\n.. O.wasm\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt -O split.wast --print\n[parse exception: inline string contains NULL (0). that is technically valid in wasm, but you shouldn't do it, and it's not supported in binaryen (at 0:116)]\nFatal: error in parsing input\nTraceback (most recent call last):\n  File \"auto_update_tests.py\", line 439, in \n    sys.exit(main())\n  File \"auto_update_tests.py\", line 424, in main\n    update_wasm_opt_tests()\n  File \"auto_update_tests.py\", line 135, in update_wasm_opt_tests\n    actual += run_command(cmd)\n  File \"C:\\code\\emsdk\\binaryen\\master\\scripts\\test\\support.py\", line 160, in run_command\n    raise Exception(('run_command failed (%s)' % code, out + str(err or '')))\nException: ('run_command failed (1)', '')\n```\nif I manually skip that by deleting the file print/min.wast, it then aborts in\n```\n[ checking wasm-opt -o notation... ]\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\hello_world.wast -o a.wast -S\n[ checking wasm-opt binary reading/writing... ]\n.. memory-import-shared.wast\n     C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-import-shared.wast --print\n['C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt', 'test\\print\\memory-import-shared.wast', '--print'] (module\n (import \"env\" \"memory\" (memory $0 (shared 256 256)))\n)\n C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-import-shared.wast --print-minified\n\n.. memory-shared.wast\n     C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-shared.wast --print\n['C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt', 'test\\print\\memory-shared.wast', '--print'] (module\n (memory $0 (shared 23 256))\n)\n C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt test\\print\\memory-shared.wast --print-minified\n\n[ checking wasm-opt passes... ]\n.. 1.wast\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt --rereloop --dce --remove-unused-brs --remove-unused-names --coalesce-locals --simplify-locals --reorder-locals --remove-unused-brs --merge-blocks --vacuum split.wast --print\n.. O.wasm\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt -O split.wast --print\n[parse exception: inline string contains NULL (0). that is technically valid in wasm, but you shouldn't do it, and it's not supported in binaryen (at 0:116)]\nFatal: error in parsing input\nTraceback (most recent call last):\n  File \"auto_update_tests.py\", line 439, in \n    sys.exit(main())\n  File \"auto_update_tests.py\", line 424, in main\n    update_wasm_opt_tests()\n  File \"auto_update_tests.py\", line 135, in update_wasm_opt_tests\n    actual += run_command(cmd)\n  File \"C:\\code\\emsdk\\binaryen\\master\\scripts\\test\\support.py\", line 160, in run_command\n    raise Exception(('run_command failed (%s)' % code, out + str(err or '')))\nException: ('run_command failed (1)', '')\n```\nand if to skip over that, I delete all files in test/print/, it then failed at\n```\n[ checking wasm-opt passes... ]\n.. 1.wast\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt --rereloop --dce --remove-unused-brs --remove-unused-names --coalesce-locals --simplify-locals --reorder-locals --remove-unused-brs --merge-blocks --vacuum split.wast --print\n.. O.wasm\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt -O split.wast --print\n[parse exception: inline string contains NULL (0). that is technically valid in wasm, but you shouldn't do it, and it's not supported in binaryen (at 0:116)]\nFatal: error in parsing input\nTraceback (most recent call last):\n  File \"auto_update_tests.py\", line 439, in \n    sys.exit(main())\n  File \"auto_update_tests.py\", line 424, in main\n    update_wasm_opt_tests()\n  File \"auto_update_tests.py\", line 135, in update_wasm_opt_tests\n    actual += run_command(cmd)\n  File \"C:\\code\\emsdk\\binaryen\\master\\scripts\\test\\support.py\", line 160, in run_command\n    raise Exception(('run_command failed (%s)' % code, out + str(err or '')))\nException: ('run_command failed (1)', '')\n```\nso looks like some recurring incompatibility.\nRunning python check.py to test if my hand-made test works, I get\n```\n.. translate-to-fuzz.wast\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt --translate-to-fuzz split.wast --print\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt --translate-to-fuzz split.wast --print --debug\nexecuting:  C:\\code\\emsdk\\binaryen\\master_vs2017_64bit_binaryen\\bin\\wasm-opt --translate-to-fuzz split.wast --print\n[PassRunner] running passes...\n[PassRunner]   running pass: print... 0.00184034 seconds.\n[PassRunner]   (validating)\n[PassRunner] passes took 0.00184034 seconds.\n[PassRunner] (final validation)\nincorrect output, diff:\n--- C:\\code\\emsdk\\binaryen\\master\\test\\passes\\translate-to-fuzz.txt\n+++ actual\n@@ -1,12 +1,13 @@\n (module\n  (type $FUNCSIG$i (func (result i32)))\n  (type $FUNCSIG$vjifiiji (func (param i64 i32 f32 i32 i32 i64 i32)))\n- (type $FUNCSIG$jdfiid (func (param f64 f32 i32 i32 f64) (result i64)))\n  (type $FUNCSIG$v (func))\n+ (type $FUNCSIG$idi (func (param f64 i32) (result i32)))\n+ (type $FUNCSIG$iddi (func (param f64 f64 i32) (result i32)))\n  (memory $0 (shared 1 1))\n  (data (i32.const 0) \"n\\00\\05E\\00\\00\\00\\00\")\n- (table $0 2 2 anyfunc)\n- (elem (i32.const 0) $func_2 $func_14)\n+ (table $0 2 anyfunc)\n+ (elem (i32.const 0) $func_8 $func_10)\n  (global $global$0 (mut f32) (f32.const 536870912))\n  (global $global$1 (mut f32) (f32.const 2147483648))\n  (global $global$2 (mut f64) (f64.const -1048576))\n@@ -14,12 +15,12 @@\n  (global $hangLimit (mut i32) (i32.const 10))\n  (export \"func_0\" (func $func_0))\n  (export \"func_1\" (func $func_1))\n- (export \"func_3\" (func $func_3))\n+ (export \"func_1_invoker\" (func $func_1_invoker))\n  (export \"func_3_invoker\" (func $func_3_invoker))\n+ (export \"func_5\" (func $func_5))\n  (export \"func_5_invoker\" (func $func_5_invoker))\n- (export \"func_7_invoker\" (func $func_7_invoker))\n- (export \"func_10_invoker\" (func $func_10_invoker))\n- (export \"func_13\" (func $func_13))\n+ (export \"func_8\" (func $func_8))\n+ (export \"func_8_invoker\" (func $func_8_invoker))\n  (export \"hangLimitInitializer\" (func $hangLimitInitializer))\n  (func $func_0 (; 0 ;) (type $FUNCSIG$i) (result i32)\n   (local $0 i32)\n@@ -64,27 +65,146 @@\n     )\n    )\n   )\n+  (nop)\n+ )\n+ (func $func_1_invoker (; 2 ;) (type $FUNCSIG$v)\n+  (call $func_1\n...\n```\nalthough I think it did run through the minify-imports test and pass, so I'll land this if CI shows green.. > Does ./check.py pass for you?\nUnfortunately no, that gets the error listed in the last block above. (translate-to-fuzz fails). Oh, forgot to merge this before. The error message does read like adding _ENABLE_EXTENDED_ALIGNED_STORAGE is the correct thing here - I presume Binaryen will want the extended alignment. Old Visual Studios will possibly compile wrong, both with and without this PR. So landing this PR does not cause old Visual Studios to break any more than they did before. Unfortunately I am unable to currently work on backwards compatibility for older VSes, it may be worth either to consider adding a compiler version check to require new enough VS, if enabling backwards compatibility is not important (atm for us it is not, we have been able to update all users to newest). Sure, #283.\n. Followed a code pattern in existing location in code, changed that to use numeric_limits as well.\n. Changed to std:streampos\n. Check.\n. Looks like PassRegistry is still needed, since the command line options want to map pass name strings to passes. Adjusted the registry to allow this.\n. VS2015 says there's std::make_unique that is ambiguous with this, and fails to compile. The project defines its own wasm::make_unique in src/support/utilities.h that it conflicts with.\n. I'm afraid I have no idea. :/\n. Agree, but there was an existing --torture parameter, so I did not want to remove that or some existing users could break. Wanted to be systematic then.\n. Considered that, but then settled for this since it's only a single location in the script.\n. The issue is with the suffixes, which may be emcc, emcc.bat, or nodejs.exe, which this doesn't specify. The suffixes are autodetected only if shell=True, otherwise it does not look for nodejs.exe when asking to run nodejs.\n. optparse is not obsolete, it is just no longer developed.. but sure, I'll convert.\n. It is not obvious to me that this->data would equal to parent->data.data(). Is that the case?\n. That kind of if() statement reads a bit cryptic. Pushed a bit simplified form that should be easy to read.\n. Yes, the FILE(COPY) command below adds new directories under bin/, for example bin/js.\n. These occur right during the CMake configure step.\n. Yeah, -O3/-g are CMake defaults. Considered deleting these directives altogether, but thought that there was some specific desire to do just -O2 and -g3 and wanted to keep the behavior identical. (Fixing platform specific bugs doesn't generally mix well with changing behavior)\nI would like to remove the -UNDEBUG directive altogether and have people build the CMake RelWithDebInfo target when they want assertions, so that Release could be without assertions for performance purposes. Currently Release comes with assertions enabled so not nice for performance. But that change can occur separately if agreed on.\n. Unfortunately there is no simple spot to do it for dynamic copying. Being at configure time means that after making a change, one can reissue cmake to redeploy, so that's something that will always occur on CI etc.\nThe full CMake'y way with dependency analysis would be to create build targets out of them and have the build action be a copy command with add_custom_command(OUTPUT, ...), but that is a bit messy because it needs a target to build the files in, so either create a virtual target that only has the copyable files, or piggyback on another target project to build. If this is a concern, I can take a peek, but generally prefer to keep it simple.\n. Alright, thanks for checking that. I'll refactor to avoid the shell=Trues.\n. Alright, let me retract this pull request and figure something better out.\n. Ok, changed.\n. I find the word \"dangerous\" that is used here is not that self-documenting, I find I need to read the contents carefully to understand what it means. \"Dangerous\" from whose perspective? I.e. is it dangerous that the generated code might trap, or dangerous in the sense of unsafe from the user perspective that it will silently ignore div by zero and output an undefined result. Perhaps makeDangerousI32Binary could instead be makePotentiallyTrappingI32Binary or something like that?\n(Not critical at all though, fine with the current name, since this is more an internal code thing, and not something that end users will interact with)\n. The issue was that I could not find a suitable way to get the number of chars that were actually read using a C++ API. However with https://github.com/WebAssembly/binaryen/pull/986#issuecomment-314779011 re-did this PR to use istream::gcount(), which gives that information.. Rewrote this PR, resolved.. void appears twice (not that it matters). ",
    "data-ux": "Help with compiling the binaryen shell to JS would be appreciated. I think it would be even better if the evaller.js could be input with either binary or s-expession wasm modules. That way it would have broader applicability. I can contribute a wrapper JS that exposes the functionality, but I haven't done c++ development in 15 years, so I'm afraid I cannot be useful on that front.\nTo my understanding the AST semantics of MVP WebAssembly have stabilized and I'm assuming the eventual official text format will be a close textual representation of the AST (syntax details like parens or not might change etc.). Or do you foresee that it's possible the official text format will be a further departure, for example code would be presented in C-like syntax?\n. Yeah, I found the text format discussion in the design repo. The most important use case for the text format is \"view source\" of modules distributed as binary. In my opinion a direct mapping of the AST to text would serve the use case best. Adding any kind of translation/sugar, like infix operators and the like, would only make it harder to reason about the underlying actual wasm code.\nI'm hoping my wasm playground can inform the discussion about the official text format. I'm planning to add a couple of different rendering styles that users can choose from.\nThe evaller.js would be useful in any case.\n. Yeah, this is pretty much perfect. Great work. I have published my playground with the new binaryen.js as the WASM machinery: http://ast.run/.\nDo the current bindings support calling exports with other types than f64? It also seems that exported functions can only return f64, too.\n. Yes removing that line works for me too. According to this, clang needs the -pthread flag when compiling, but not when linking. Maybe the linking would work on Linux, too, without the flag?\n. Error persists at 31dd39a .\n. Thanks. We also need to update the test.\n. The binaryen.js test fails with TypeError: Binaryen.AllocatingModule is not a function for me. I assumed it was because of the changes in #361.\n. My PR #391 resolved it locally, but does not pass Travis.\n. Yeah, now all is good.\n. > The conversion issue is a real problem though, as JS lacks 64-bit ints. Perhaps an I64Literal should be constructed using i32 low, i32 high, and instead of geti64 we could have geti64Low, geti64high.\nYes, that would be the most rigorous approach. Though I do think it would be fine for many use cases to convert the numbers to closest possible value in both ways (integers between \u2212(253 \u2212 1) and (253  \u2212 1) would convert exactly).\n. Ok, now we have I64Literal with constructor & get-methods using low & high bits.\n. This is something I came up with: we use castObject on the JS side to downcast the returned Literal into I64Literal (or whatever type the literal is). We can then call geti64Low() & geti64High() which are now on the I64Literal class as they should.\nThe surprising thing is that the above works at all. Downcasting like that would be illegal in C++. Are there any reasons we shouldn't use castObject like this?\n. Yes, all ready. Thanks for your guidance in getting this feature realized!\n. Sorry for the late reply. I really don't understand the WebIDL binding in enough detail to have an informed opinion, unfortunately. \nYes, the test is missing all Binaryen.destroy(x) calls, if that's what you mean.\n. It's used in the Literal interface definition, exposing the type instance variable. So that the JS application using binaryen.js can find out the Literal type by calling .get_type() on a Literal instance.\n. Yeah, ok.\n. We can put the methods on the I64Literal-class, but then we need a way to convert a Literal instance(returned by callExport()) to I64Literal in order to call the methods. We could add a constructor to I64Literal that takes a Literal as argument, but that feels somewhat convoluted. Making geti64Low() & geti64High() static methods on I64Literal is the best I can think of but it seems clumsy, too.\n. ",
    "vvuk": "Thanks -- deleted my comment, because my actual bug was that I had a stray -m64 that snuck in to my compile args, which was selecting the wasm64 target.  That was what was actually causing my problem.. ",
    "FrancoisChastel": "Hello, does this issue is really closed ? Seem like I face the same issue when trying to compile raknet using emscripten :\nIn file included from /private/var/tmp/_bazel_root/7eac25f81ba1cb3897eb750dd5c677da/external/raknet/Source/Router2.cpp:14:\nIn file included from /private/var/tmp/_bazel_root/7eac25f81ba1cb3897eb750dd5c677da/external/raknet/Source/Router2.h:26:\nIn file included from /private/var/tmp/_bazel_root/7eac25f81ba1cb3897eb750dd5c677da/external/raknet/Source/UDPForwarder.h:27:\nIn file included from /private/var/tmp/_bazel_root/7eac25f81ba1cb3897eb750dd5c677da/external/raknet/Source/SimpleMutex.h:20:\nIn file included from /private/var/tmp/_bazel_root/7eac25f81ba1cb3897eb750dd5c677da/external/raknet/Source/RakMemoryOverride.h:22:\nexternal/emscripten_toolchain/system/include/libcxx/new:181:66: error: 'operator new' takes type size_t ('unsigned long') as first parameter\n_LIBCPP_NODISCARD_AFTER_CXX17 _LIBCPP_OVERRIDABLE_FUNC_VIS void* operator new(std::size_t __sz) _THROW_BAD_ALLOC;\n                                                                 ^\nexternal/emscripten_toolchain/system/include/libcxx/new:182:66: error: 'operator new' takes type size_t ('unsigned long') as first parameter\n_LIBCPP_NODISCARD_AFTER_CXX17 _LIBCPP_OVERRIDABLE_FUNC_VIS void* operator new(std::size_t __sz, const std::nothrow_t&) _NOEXCEPT _NOALIAS;\n                                                                 ^\nexternal/emscripten_toolchain/system/include/libcxx/new:189:66: error: 'operator new[]' takes type size_t ('unsigned long') as first parameter\n_LIBCPP_NODISCARD_AFTER_CXX17 _LIBCPP_OVERRIDABLE_FUNC_VIS void* operator new[](std::size_t __sz) _THROW_BAD_ALLOC;\n                                                                 ^\nexternal/emscripten_toolchain/system/include/libcxx/new:190:66: error: 'operator new[]' takes type size_t ('unsigned long') as first parameter\n_LIBCPP_NODISCARD_AFTER_CXX17 _LIBCPP_OVERRIDABLE_FUNC_VIS void* operator new[](std::size_t __sz, const std::nothrow_t&) _NOEXCEPT _NOALIAS;\n                                                                 ^\nexternal/emscripten_toolchain/system/include/libcxx/new:215:70: error: 'operator new' takes type size_t ('unsigned long') as first parameter\n_LIBCPP_NODISCARD_AFTER_CXX17 inline _LIBCPP_INLINE_VISIBILITY void* operator new  (std::size_t, void* __p) _NOEXCEPT {return __p;}\n                                                                     ^\nexternal/emscripten_toolchain/system/include/libcxx/new:216:70: error: 'operator new[]' takes type size_t ('unsigned long') as first parameter\n_LIBCPP_NODISCARD_AFTER_CXX17 inline _LIBCPP_INLINE_VISIBILITY void* operator new[](std::size_t, void* __p) _NOEXCEPT {return __p;}\nWhich version of emscripten_toolchain / emscripten_clang fix this issue ?. @kripken some clue ? :) . ",
    "tzik": "Not yet, I posted a request for joining it.\n. Ah, nice to hear that. I'm OK to wait for your fix too.\n. I meant \"the 25th line of foo.s\".\nThough the previous line of it is br_if, its condition ($pop6) is always true.\n. That changes the output of llc, and unbreaks it.\nAnd adding -O0 to llc also changed the situation, probably one of the default optimization passes in WebAssembly CodeGen in LLVM.\n. s2wasm still hits the assertion even after I replaced the condition to always false.\n. Took a look to the corresponding LLVM code.\nI think the issue happens when we store an uninitialized value into $pushX= and use it as $popX. LLVM holds the initialization as an IMPLICIT_DEF instruction, which seems an internal instruction to reserve an register. Then the code generator drops the instruction at AsmPrinter, and leaves the dangling $popX.\n. OK. Done.\n. OK, I updated it to catch CalledProcessError, and to pass through others (e.g. NameError and TypeError thrown when typo or when NODEJS is None).. ",
    "shibukawa": "My fix works on Mac, but doesn't work on Linux. support/safe_integer.cpp is already in libsupport.a, but the symbol in this library is missing. It is weird issue. I am trying on Ubuntu now.\n. Exactly! I can build on Ubuntu. I reopen this ticket.\n. I read passes code and understood. Linking code has side-effects because source codes in pases folder register theirselves. So my initial approach was wrong (it links all codes as a static library).\nNow libpass.a contains minimum codes. The result becomes 50s -> 43s.\n. I updated my PR to use ADD_SUBDIRECTORY.\n. If you are making better solution, feel free to discard my commit.\n. ",
    "pjuftring": "Like this?\n. ",
    "griffin2000": "PR sent. Though note this is just code that works for me, not necessarily suitable for checking into master.\n. That is the same error I got in VS2013, I fixed by making everything an int, but I suspect that is not the correct solution. I will see if I can work out the correct fix when I get the chance (if no one else gets to it first)\n. From emcc:\nemcc DCEL.cpp MS.cpp Blob.cpp -o html/Blob.js -O3 -s EXPORTED_FUNCTIONS=\"['_Blobify']\" -s TOTAL_MEMORY=200000000\nTried various variations such as removing optimization, etc. Same result.\nCCode.zip\n. When I add --separate-asm it complains that I need to compile to HTML. If I compile to HTML, then the .js file that results doesn't seem to have the functions exported correctly.  When I try and run _Blobify from my Javascript app it says:\nUncaught TypeError: Module.asm is not a function\n  (anonymous function)  \nUncaught TypeError: _Blobify is not a function\n  init  \n  (anonymous function)\n. Do I need a particular Emscripten build for BINARYEN=1 to work? \n. My bad, missed a file.  Trying again...\nCCodeAgain.zip\n. You can load that in Javascript using Wasm.instantiateModule, Though I've not found a single piece of documentation or a spec for that function anywhere.\nThere is an example of using WASM here, that I am basing my code on:\nhttp://evanw.github.io/thinscript/\n. After a lot of hacking I was able to get the whole pipeline to work in Chrome Canary (with webassembly enabled in the flags).\nHere is my test app with the makefile I used to compile to Wasm. The compilation required a custom version of Clang, and some bug fixes to the various other tools (posting these shortly).  \nRunWasm.zip\n. Thanks, will take a look. Though most of the issues I've seen are bugs in the tool's C code. Right now while simple examples work I getting issues accessing the stack for more complex examples.\n. The JS code for running WASM in that ZIP should (I think?) work for you regardless of how you are generating your WASM binary\n. @binji as my issue not relevant to OP I moved to it's own thread:\nhttps://github.com/WebAssembly/binaryen/issues/340\n. Actually I was using older version of LLVM. My bad.\n. Test case attached.  See line 13431:\n```\n            (select\n              (i32.eq\n                (get_local $$2)\n                (i32.load offset=8\n                  (get_local $$0)\n                )\n              )\n              (get_local $$5)\n              (get_local $$2)\n            )\n```\nWastTestCase.zip\n. This was generated from the attached .S file with S2WASM:\nTestSFIle.zip\n. ## That's probably issue #338, I am using ToT from a day or two ago with that fix.\nSent from myMail app for Android Monday, 11 April 2016, 06:06PM -07:00 from Alon Zakai < notifications@github.com> :\n\nAre you using an old version of s2wasm perhaps? Current s2wasm fails to parse that .s file.\nIf you're using an older s2wasm, before the spec update on the order of select operands, it would explain the error. Like sexpr-wasm that  @binji noted, binaryen passes the spec tests, so it has to be correct on this, unless some weird corner case is somehow being hit.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or  view it on GitHub\n. @kripken  --allocate-stack 1000000 did the trick, thanks\n. \n",
    "jasonmoore29": "I also cannot compile using VS2015, after following the instructions on https://github.com/brakmic/brakmic/blob/master/webassembly/COMPILING_WIN32.md \nThe issue is also in file.cpp\nError   C2676   binary '|=': 'std::_Iosb<int>::_Openmode' does not define this operator or a conversion to a type acceptable to the predefined operator support binaryen\\src\\support\\file.cpp   27  \nError   C1001   An internal error has occurred in the compiler. support binaryen\\src\\support\\file.cpp   27\n. ",
    "rumkin": "Ok. I've converted binary into Uint8Array in node with this script:\n``` javascript\n// wasm-to-array.js\n'use strict';\nconst fs = require('fs');\nvar stdin = process.stdin;\nvar stdout = process.stdout;\nstdout.write('var wasm = new Uint8Array([');\nstdin.on('data', chunk => {\n  var i = -1;\n  var l = chunk.length;\nwhile(++i < l) {\n    stdout.write(chunk.readUInt8(i) + ',');\n  }\n});\nstdin.on('end', () => {\n  stdout.write('])\\n');\n  stdin.pause();\n});\nstdin.resume();\n```\nRun\nshell\ncat add.wasm | node wasm-to-array.js\nAnd got:\njavascript\nnew Uint8Array([66,67,192,222,33,12,0,0,192,0,0,0,11,130,32,0,2,0,0,0,18,0,0,0,7,129,35,145,65,200,4,73,6,16,50,57,146,1,132,12,37,5,8,25,30,4,139,98,128,12,69,2,66,146,11,66,100,16,50,20,56,8,24,73,10,50,68,36,72,10,144,33,35,196,82,128,12,25,33,114,36,7,200,200,16,98,168,160,168,64,198,240,1,0,0,0,81,24,0,0,67,0,0,0,27,242,34,248,255,255,255,255,1,144,8,118,40,135,121,152,135,54,128,7,121,40,135,113,72,135,121,40,135,54,48,7,120,104,135,112,32,7,192,28,194,129,29,230,161,28,0,194,29,222,161,13,204,65,30,194,161,29,202,161,13,224,225,29,210,193,29,232,161,28,228,161,13,202,129,29,210,161,29,0,122,144,135,122,40,7,128,112,135,119,104,3,115,144,135,112,104,135,114,104,3,120,120,135,116,112,7,122,40,7,121,104,131,114,96,135,116,104,135,54,112,135,119,112,135,54,96,135,114,8,7,115,0,232,65,30,234,161,28,0,194,29,222,161,13,210,193,29,204,97,30,218,192,28,224,161,13,218,33,28,232,1,29,0,115,8,7,118,152,135,114,0,8,119,120,135,54,112,135,112,112,135,121,104,3,115,128,135,54,104,135,112,160,7,116,0,204,33,28,216,97,30,202,1,32,234,193,29,230,33,28,204,161,28,218,192,28,224,161,13,218,33,28,232,1,29,0,115,8,7,118,152,135,114,0,136,122,152,135,114,104,131,121,120,7,115,160,135,54,48,7,118,120,135,112,160,7,192,28,194,129,29,230,161,28,0,0,0,73,24,0,0,1,0,0,0,19,130,0,0,137,32,0,0,10,0,0,0,50,34,200,8,32,100,133,4,147,33,164,132,4,147,33,227,132,161,144,20,18,76,134,140,11,132,100,76,16,16,115,4,96,80,2,80,70,0,0,0,19,176,112,152,135,118,80,135,121,104,131,122,112,135,117,112,135,119,184,7,119,104,131,114,104,135,121,24,7,121,72,7,120,160,135,114,112,135,13,225,80,14,109,144,14,113,160,7,120,160,7,120,208,6,233,128,7,122,128,7,122,128,7,109,144,14,113,96,7,122,16,7,118,160,7,113,96,7,109,144,14,115,32,7,122,48,7,114,160,7,115,32,7,109,144,14,118,64,7,122,96,7,116,160,7,118,64,7,109,96,14,115,32,7,122,48,7,114,160,7,115,32,7,109,96,14,118,64,7,122,96,7,116,160,7,118,64,7,109,0,15,122,48,7,114,160,7,115,32,7,122,48,7,114,208,6,246,16,7,114,128,7,122,48,7,114,160,7,113,32,7,120,208,6,238,48,7,114,208,6,179,16,7,114,128,7,67,20,1,0,128,0,0,0,0,200,195,0,0,0,23,0,0,0,51,8,128,28,196,225,28,102,20,1,61,136,67,56,132,195,140,66,128,7,121,120,7,115,152,113,12,230,0,15,237,16,14,244,128,14,51,12,66,30,194,193,29,206,161,28,102,48,5,61,136,67,56,132,131,27,204,3,61,200,67,61,140,3,61,204,120,140,116,112,7,123,8,7,121,72,135,112,112,7,122,112,3,118,120,135,112,32,7,0,0,0,113,32,0,0,3,0,0,0,6,160,12,0,38,137,13,76,16,10,0,0,97,32,0,0,5,0,0,0,19,4,65,44,16,0,0,0,1,0,0,0,132,114,0,0,25,0,0,0,0,0,0,0,])\nThen I try to run it in FF:\njavascript\nvar compiled = new Uint8Array([/* ...array here... */]);\nvar exports = Wasm.instantiateModule(compiled, {global: global}).exports;\nconsole.log(exports.add(1,2);\nResult is:\nTypeError: wasm validation error at offset 4: failed to match magic number\nCode to run is here:\nhttps://jsfiddle.net/vrw9922o/\nSo where am I wrong?\n. @kripken Yep, it looks I'm using broken emscripten build in my docker. It looks like something went wrong with versions:\nI'm running build process\nshell\ndocker run --rm -v $PWD:/files -w /wrk/binaryen  -e WASM_BACKEND=1 binaryen ./test/emscripten/emcc /files/add.c -o /files/add.wasm -s BINARYEN=1\nWARNING:root:generating system asset: is_vanilla.txt...\nWARNING:root:                                          ok\nWARNING:root:LLVM version appears incorrect (seeing \"3.3\", expected \"3.9\")\nERROR:root:Emscripten, llvm and clang repo versions do not match, this is dangerous (1.36.1, 1.20.0, 1.20.0)\nERROR:root:Make sure to use the same branch in each repo, and to be up-to-date on each. See http://kripken.github.io/emscripten-site/docs/building_from_source/LLVM-Backend.html\nINFO:root:(Emscripten: Running sanity checks)\nWARNING:root:java does not seem to exist, required for closure compiler, which is optional (define JAVA in //.emscripten if you want it)\nWARNING:root:closure compiler will not be available\nWARNING:root:retrieving port: binaryen from https://github.com/WebAssembly/binaryen/archive/version_7.zip\nWARNING:root:unpacking port: binaryen\nWARNING:root:generating port: binaryen_tag_version_7.txt...\nWARNING:root:building port: binaryen\n-- The CXX compiler identification is GNU\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Building with -std=c++11\n-- Building with -msse2\n-- Building with -mfpmath=sse\n-- Building with -Wall\n-- Building with -Werror\n-- Building with -Wextra\n-- Building with -Wno-unused-parameter\n-- Building with -fno-omit-frame-pointer\n-- Building with -O2\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /.emscripten_ports/binaryen/binaryen-version_7\nScanning dependencies of target support\n[  2%] Building CXX object CMakeFiles/support.dir/src/support/bits.cpp.o\n[  4%] Building CXX object CMakeFiles/support.dir/src/support/colors.cpp.o\n[  7%] Building CXX object CMakeFiles/support.dir/src/support/command-line.cpp.o\n[  9%] Building CXX object CMakeFiles/support.dir/src/support/file.cpp.o\n[ 12%] Building CXX object CMakeFiles/support.dir/src/support/safe_integer.cpp.o\nLinking CXX static library lib/libsupport.a\n[ 12%] Built target support\nScanning dependencies of target asm2wasm\n[ 14%] Building CXX object CMakeFiles/asm2wasm.dir/src/asm2wasm-main.cpp.o\n[ 17%] Building CXX object CMakeFiles/asm2wasm.dir/src/pass.cpp.o\n[ 19%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/MergeBlocks.cpp.o\n[ 21%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/PostEmscripten.cpp.o\n[ 24%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/Print.cpp.o\n[ 26%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/RemoveUnusedBrs.cpp.o\n[ 29%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/RemoveUnusedNames.cpp.o\n[ 31%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/SimplifyLocals.cpp.o\n[ 34%] Building CXX object CMakeFiles/asm2wasm.dir/src/passes/ReorderLocals.cpp.o\n[ 36%] Building CXX object CMakeFiles/asm2wasm.dir/src/emscripten-optimizer/parser.cpp.o\n[ 39%] Building CXX object CMakeFiles/asm2wasm.dir/src/emscripten-optimizer/simple_ast.cpp.o\n[ 41%] Building CXX object CMakeFiles/asm2wasm.dir/src/emscripten-optimizer/optimizer-shared.cpp.o\nLinking CXX executable bin/asm2wasm\n[ 41%] Built target asm2wasm\nScanning dependencies of target binaryen-shell\n[ 43%] Building CXX object CMakeFiles/binaryen-shell.dir/src/binaryen-shell.cpp.o\n[ 46%] Building CXX object CMakeFiles/binaryen-shell.dir/src/pass.cpp.o\n[ 48%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/LowerIfElse.cpp.o\n[ 51%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/MergeBlocks.cpp.o\n[ 53%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/NameManager.cpp.o\n[ 56%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/PostEmscripten.cpp.o\n[ 58%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/Print.cpp.o\n[ 60%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/RemoveImports.cpp.o\n[ 63%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/RemoveUnusedBrs.cpp.o\n[ 65%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/RemoveUnusedNames.cpp.o\n[ 68%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/SimplifyLocals.cpp.o\n[ 70%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/ReorderLocals.cpp.o\n[ 73%] Building CXX object CMakeFiles/binaryen-shell.dir/src/passes/Metrics.cpp.o\nLinking CXX executable bin/binaryen-shell\n[ 73%] Built target binaryen-shell\nScanning dependencies of target s2wasm\n[ 75%] Building CXX object CMakeFiles/s2wasm.dir/src/pass.cpp.o\n[ 78%] Building CXX object CMakeFiles/s2wasm.dir/src/passes/Print.cpp.o\n[ 80%] Building CXX object CMakeFiles/s2wasm.dir/src/s2wasm-main.cpp.o\nLinking CXX executable bin/s2wasm\n[ 80%] Built target s2wasm\nScanning dependencies of target wasm-as\n[ 82%] Building CXX object CMakeFiles/wasm-as.dir/src/wasm-as.cpp.o\nLinking CXX executable bin/wasm-as\n[ 82%] Built target wasm-as\nScanning dependencies of target wasm-dis\n[ 85%] Building CXX object CMakeFiles/wasm-dis.dir/src/pass.cpp.o\n[ 87%] Building CXX object CMakeFiles/wasm-dis.dir/src/passes/Print.cpp.o\n[ 90%] Building CXX object CMakeFiles/wasm-dis.dir/src/wasm-dis.cpp.o\nLinking CXX executable bin/wasm-dis\n[ 90%] Built target wasm-dis\nScanning dependencies of target wasm2asm\n[ 92%] Building CXX object CMakeFiles/wasm2asm.dir/src/wasm2asm-main.cpp.o\n[ 95%] Building CXX object CMakeFiles/wasm2asm.dir/src/emscripten-optimizer/parser.cpp.o\n[ 97%] Building CXX object CMakeFiles/wasm2asm.dir/src/emscripten-optimizer/simple_ast.cpp.o\n[100%] Building CXX object CMakeFiles/wasm2asm.dir/src/emscripten-optimizer/optimizer-shared.cpp.o\nLinking CXX executable bin/wasm2asm\n[100%] Built target wasm2asm\n@griffin2000 Congrats but I'm on linux and trying to create docker buildbox.\n. ",
    "bstavroulakis": "I had the same issue when I ran the example in Chrome. It was fixed when I ran it in Chrome Canary.\n. ",
    "yurydelendik": "Example of .s file (generated with clang -g1 option) (llvm needs https://gist.github.com/yurydelendik/a37b786dae40736ed7a1b04770f9c9ed):\n```\n        .text\n        .file   \"test.bc\"\n        .hidden test\n        .globl  test\n        .type   test,@function\ntest:\n.Lfunc_begin0:\n        .file   1 \"test.c\"\n        .loc    1 1 0\n        .param          i32\n        .result         f32\n        .local          f32\n.Ltmp0:\n        .loc    1 2 13 prologue_end\n        f32.convert_s/i32       $1=, $0\n.Ltmp1:\n        .loc    1 4 12\n        f32.const       $push0=, 0x1p1\n        f32.div         $push1=, $pop0, $1\n        .loc    1 4 3 is_stmt 0\n        return          $pop1\n.Ltmp2:\n        .endfunc\n.Lfunc_end0:\n        .size   test, .Lfunc_end0-test\n    .section        .debug_str,\"MS\",@progbits,1\n\n.Linfo_string0:\n    .....\n```\ns2wasm output:\n(module\n  (memory 1)\n  (export \"memory\" memory)\n  (export \"test\" $test)\n  (;!file 1 \"test.c\";)\n  (func $test (param $$0 i32) (result f32)\n    (local $$1 f32)\n    (;!loc 1 2 13;)\n    (set_local $$1\n      (f32.convert_s/i32\n        (get_local $$0)\n      )\n    )\n    (return\n      (;!loc 1 4 12;)\n      (f32.div\n        (f32.const 2)\n        (;!loc 1 4 12;)\n        (get_local $$1)\n      )\n    )\n  )\n)\nP.S. source \nc\nfloat test(int i) {\n  float n = i;\n  float c = 2.0f;\n  return c / n;\n}\n. Related conversation at https://github.com/WebAssembly/spec/issues/258\nJust to clarify. I want to limit this PR only to parsing of .s files (that we are producing with clang's '-g' flag). Embedding the debug info into wast or wasm format needs to be out of this PR scope (I placed this info as comments in wasm atm). So far we cannot only pull DWARF information about binding of virtual registers to the variable names, rest of it (files, line numbers, scopes) looks okay. \n. Just to make sure, the .s file produced by llvm webassembly backend will contain non-translated subset of DWARF stored in llvm assembly text format. The goal will be parse and repackage it into something browsers can consume (e.g. subsections in wasm, separate files, etc.). Is it correct?\n. Changed title to better reflect the intent of the PR.\n. Added '--debug-info' argument to the s2wasm to enable printing of the \"debug\" comments. More advanced example can be found at https://gist.github.com/yurydelendik/352dc3250d92191fc7f38dd0daf6a022 . Please notice that we might have \"guide\" bookmarks/labels in the text format to setup scope and ranges needed for debug sections:\n(module\n  (memory 1)\n  (export \"memory\" memory)\n  (export \"test\" $test)\n  (;!file 1 \"test.c\";)\n  (func $test (param $$0 i32) (result f32)\n    (local $$1 f32)\n    (;!bookmark test;)\n    (;!bookmark .Ltmp0;)\n    (;!loc 1 2 13;)\n    (set_local $$1\n      (f32.convert_s/i32\n        (get_local $$0)\n      )\n    )\n    (;!bookmark .Ltmp1;)\n    (;!loc 1 4 3;)\n    (return\n      (;!loc 1 4 12;)\n      (f32.div\n        (;!bookmark test;)\n        (f32.const 2)\n        (;!bookmark .Ltmp1;)\n        (;!loc 1 4 12;)\n        (get_local $$1)\n      )\n    )\n  )\n.....\n  (;!dbg_section .debug_loc,\"\",@progbits\n.....\n.Ldebug_loc2:\n    .int32  .Ltmp1-.Lfunc_begin0\n    .int32  .Lfunc_end0-.Lfunc_begin0\n    .int16  7                       # Loc expr size\n    .int8   16                      # DW_OP_constu\n    .int8   128                     # 1073741824\n    .int8   128                     # DW_OP_stack_value\n    .int8   128                     # \n    .int8   128                     # \n    .int8   4                       # \n    .int8   159                     # \n    .int32  0\n    .int32  0\n    ;)\n....\nThe example above shows that from '.Ltmp1' bookmark to '.Lfunc_end0' one, some variable ('c') can be evaluated using constant 2.0 (an expression can be more complex). The point is that we will need to mark AST node somehow to properly set ranges in the code, and single range in .s file might map into multiple \"AST\" ranges (? checking this atm).\n. typo at https://github.com/WebAssembly/binaryen/blob/master/src/emscripten-optimizer/parser.h#L240\n. Still an issue for me at 5494c531db301 . Depends on clang/llvm version?\n. Probably this one is related http://public.kitware.com/Bug/view.php?id=12652 : \"We have always had to pass compilation flags to the compiler front-end when using it for linking. It matters at least for C++ because some compilers actually do real compilation at link time to do template instantiation (pre-linker)...\"\n. Can we use ADD_COMPILE_FLAG(\"-Qunused-arguments\") ?\n. test was added to test/unit.asm.js\n. FWIW __cxa_pure_virtual how affects wasm-compiler-rt compilation (when WASM_BACKEND is used)\n. Thanks.\n. Added comment for the WASM_UNUSED macro, fixed debug.s tests output, and addressed size and auto type nits.\n. See also https://github.com/WebAssembly/wabt/pull/432. >   What is the URL?\nThe URL is the final JavaScript JSON source maps resource (as defined in the https://github.com/WebAssembly/design/pull/1051) and intended to be read (URL and then source maps) by devtools.\n.txtmap-file will be further transformed into/from JSON source maps as defined by the design PR.\n\nLooks like there is both code to write out a separate binary map file, but also read and write inside the binary?\n\nAt the moment .txtmap is used to store debug information, but final \"destination\" is JSON map file. The .wasm and .txtmap (later .map) file go side-by-side (similar to JS source maps). The .wasm binary file does not contain any debug location information, only the sourceMappingURL (which points to .map). To import the location information, the .txtmap (later .map) must be read at the same time as .wasm by wasm-dis to place that in AST. . > Thanks, but what does \"later map\" mean in all those cases? Is that an expected spec change, or something happening now in the toolchain?\nFor emscripten, there is https://github.com/kripken/emscripten/commit/e8dd1c8859403b160978efcd78dc8e6e8dacc13f which is planning to use regular tools/source-maps/sourcemapper.js, however the design PR recommends to use columns instead of lines. We can further modify https://github.com/kripken/emscripten/blob/master/tools/source-maps/sourcemapper.js#L130 to use byteoffset as a column. For prototyping, I'm using txt2map4wasm package (https://github.com/yurydelendik/txt2map4wasm).. @kripken Would you recommend to add JavaScript source map generation to this PR?. > But I'm not sure how simple it is, what do you think?\nAbout 200 SLOC, I'll submit that shortly. Now asm2wasm and friends are exporting valid JS source map directly. For sake of simplicity of this PR and sake of re-import (for wasm-dis), I limited it to the following format:\n{\"version\":3,\"sources\":[\u2026source file names\u2026],\"names\":[],\"mappings\":\"\u2026VLQ encoded entries\u2026\"}\nnotice that the \"sources\" field must precede the \"mappings\" field in the JSON.. If there ever be instantiate static property, can it be async (return Promise)? That will simply initialization for modules that needs to load binary WebAssembly and memory.. @dcodeIO There are two methods of WebAssembly module instantiation: via instantiate by providing ArrayBuffer, or via instantiateStreaming by providing Response object. In first case, the URL of the WebAssembly module is unknown and JS engine will generate fake URL, and devtools will not know what to do with relative source map URL in this case. (I recommend to provide absolute source map URL if the instantiate is used). For the instatiateStreaming case, the WebAssembly module URL is known and relative source map URL can be used. Does this answer the question above?. > Also I expect relative sourceMappingURLs to be expanded from the .wasm path in Firefox.\nIt depends. The WebAssembly.instantiateStreaming needs to be used for relative sourceMappingURL so it can be resolved (see https://bugzilla.mozilla.org/show_bug.cgi?id=1431864). The spec for sourceMappingURL is not finalized yet (see https://github.com/WebAssembly/design/pull/1051) and it's not clear how to resolve relative URL from WebAssembly.instantiate. > wasm-dis + wasm-as --source-map-url\nis wasm-dis used with --source-map to ingest location attributes into wat?. Sorry, I'm a little bit confused what this issue about. Could you describe the problem again and also include STR, actual and expected result?. Can you provide version for emscripten and binaryen? #1628 can be in play here\n. I just checked a dump (via https://wasdk.github.io/wasmcodeexplorer/) of built wasm with incoming emscripten:\n\n1219 == 0x4C3  The return 0; points to the right location. WFM\nP.S. \n. > I am using emscripten version 1.38.8\nv1.38.8: 07/06/2018 predates fix for https://github.com/WebAssembly/binaryen/pull/1628 (7/25/2018)\nClosing as fixed. Please check your files with newer version to reopen the issue.. > annotation to create the correct name section info: (call $foo (@name \"foo\"))\nBinaryen is using names section as source of the identifiers. Ideally, it is a one-way conversion: name section id can be missing or non-unique, so binaryen mutates the original name to fit its needs. Addressing WebAssembly/spec#617 issue might not fully cover the issue we are having with using name section data as function/local names. Annotations will be a way to go.\nCurrently, this patch is only fixing wasm-dis output when weird names are present in the name section (and somewhat recover the name section when wasm-as -g is used). > Do we have testing code for source maps? Is it worth adding this case? \nI have post-processed source maps that includes \"sourcesContent\", that precede the mappings field in JSON, and has mapping in the text. Not sure if it worth adding a test in this case. We probably need to include proper JSON parsing/encoding library instead in the future.. > How about using uint8_t instead of unsigned?\nFixed\n\nAlso might as well change base64Encode to receive a vector of those.\n\nThis change goes all the way to Module -- maybe different patch.\n\nPlease also add a test.\n\nDone. @hugo-dc there is no \"quoted\" ids. As I understand, (func \"id\" ... is informal abbreviation of (func (export \"id\") ... or (export \"id\" $0)(func $0 ..... > for example: $$LT$alloc..raw_vec..RawVec$LT$T$C$$u20$A$GT$$GT$::allocate_in::$u7b$$u7b$closure$u7d$$u7d$::h6cf9e7103de625a6 (.llvm.4335108165078411230)\nspace is not a part of id and needs to be removed or escaped.. Minimal test case:\n(module\n  (table $t (export \"table\") 1 anyfunc)\n  (elem $t (i32.const 0) $f)\n  (func $f (nop))\n)\ngenerates:\n```\nfunction asmFunc(global, env, buffer) {\n \"use asm\";\n var HEAP8 = new global.Int8Array(buffer);\n var HEAP16 = new global.Int16Array(buffer);\n var HEAP32 = new global.Int32Array(buffer);\n var HEAPU8 = new global.Uint8Array(buffer);\n var HEAPU16 = new global.Uint16Array(buffer);\n var HEAPU32 = new global.Uint32Array(buffer);\n var HEAPF32 = new global.Float32Array(buffer);\n var HEAPF64 = new global.Float64Array(buffer);\n var Math_imul = global.Math.imul;\n var Math_fround = global.Math.fround;\n var Math_abs = global.Math.abs;\n var Math_clz32 = global.Math.clz32;\n var Math_min = global.Math.min;\n var Math_max = global.Math.max;\n var Math_floor = global.Math.floor;\n var Math_ceil = global.Math.ceil;\n var Math_sqrt = global.Math.sqrt;\n var abort = env.abort;\n var nan = global.NaN;\n var infinity = global.Infinity;\n var i64toi32_i32$HIGH_BITS = 0;\n function $0() {\n}\nvar FUNCTION_TABLE_v = [$0];\n return {\n};\n}\nconst memasmFunc = new ArrayBuffer(65536);\nconst retasmFunc = asmFunc({Math,Int8Array,Uint8Array,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array,NaN,Infinity}, {abort:function() { throw new Error('abort'); }},memasmFunc);\n```. > Is there a reason to keep around the old behavior? It may be simpler to just remove it?\nNot sure about how friendly we needs to be with asm.js. I can remove that if needed.. >  it still doesn't generate the wasm2js.vcxproj file \n@Boscop I verified on different Window machine, the wasm2js project present for me. Can you check the branch again?. >  I'm pretty sure the generated debug info will always be broken because it refers to binary offsets in the code, no?\nCorrect. If code or data sections are modified in any way, the debug sections will become invalid.. skipWhitespace() in the loop does it.\n. we need to break at some point. can we remove white (*s) and use mustMatch(\".p2align\") before the code you suggested ?\n. Fixed. Thanks.\n. This parameter defines the sourceMappingURL property that will be written in the .wasm custom section.. the file is still a standalone file, I just changed its output format -- binary wasm just contains the reference. > is there still a binary file, with a \"reference\"? if so where is that documented, i don't think i see it in t he design pr?\nhttps://github.com/WebAssembly/design/pull/1051/files#diff-8e85308ab5cc1e83e91ef59233648be2R219\n\"For wasm, a custom section named \"sourceMappingURL\" contains the URL.\". > what i am asking is, should we change the parameter names to --source-map or something similar\nI can change that, yes. For JSON file name it will be --source-map, and for url (embedded in the wasm) --source-map-url. Is it correct?. That is correct. If --source-map is specified, asm2wasm and wasm-as emit additional JSON source map file. If --source-map-url is specified, the optional custom section section \"sourceMappingURL\" will be added to the wasm file.\nIf --source-map is specified for wasm-dis, this JSON source map file is used to read location information and to add these to the wast output.. I would rather move this out of scope this PR -- --source-map and --source-map-url are not really optimization options and have different meaning in some cases, e.g. for asm2wasm --source-map means output file, but for wasm-dis -- input file.. the code above generates proper data for test;a.wasm is just a file we can delete -- we only need source map from this run.. That's related to writing of the external file. The writing of writeSourceMapProlog/writeSourceMapEpilog does not depend on presence of sourceMapUrl. I just wanted to change the above to if (!sourceMapUrl.empty()), but thought it will be weird to write just URL in the wasm without generated map file.. data segments have expressions -- this fixes a crash caused by using get_global from such expression that tried to access debug location information.. I could reproduce crash with the debug information that now produced by the updated logic. I don't think we need an additional tests since I found this bug when was adjusting the test cases.. it has -- wasm-as exported name as \"1\". fixed. That's my concern as well. The text format's ids will be valid and re-exported as is. I'm not sure about C API though.\nIn my opinion, this code produces invalid text output, e.g. (call \"$()\", and needs to be changed. I can change logic and move ids escape here and check/decode incoming ids during text parsing.. reverted printing logic to produce quoted identifier when () present . I think it is default name that is coming from https://github.com/WebAssembly/binaryen/blob/master/src/wasm/wasm-binary.cpp#L1034 or https://github.com/WebAssembly/binaryen/blob/master/src/wasm/wasm-s-parser.cpp#L374. It just create this name from wast I typed in the complexNames.wast below -- I can retype it unescaped.. fixed. the attached test verifies just that.. the (uint8_t) cast is needed to fix the bug. the \"the integer promotions\" extends it to integer. I can be explicit and add (uint32_t) everywhere.. since std::optional is available in C++17, I choose to do its replacement std::pair -- I can do with some custom type if you want.. currFunction is set after most of its header is parsed (after locals), I need to determine if function parsing started before makeFunction is called.. loc contains original source location for beginning of s-expr parents/block, endLoc contains original source location for ending of this block.. it is expected. currFunction and func are set below at line 1094 -- makeFunction needs params and vars that are read at line 1073 (readNextDebugLocation call at 1069 uses isInFunction). Sorry, highBits (now falseBits) will contain that. I got carried away with optimizations and pushed wrong commit. Changed makeIf to makeSelect, reverted this.. done. Fixed. Yeah, I tried. With select we are doing the same mistake/bug (but for 'true' branch in this case). Also, I tried to simplify logic and lower amount of temps without any luck so far. . One of my solutions was:\nTempVar highBits = getTemp();\n    TempVar cond = getTemp();\n    Block* result = builder->blockify(\n      builder->makeSetLocal(\n        highBits,\n        builder->makeSelect(\n          builder->makeTeeLocal(cond, curr->condition),\n          builder->makeGetLocal(fetchOutParam(curr->ifTrue), i32),\n          builder->makeGetLocal(fetchOutParam(curr->ifFalse), i32)\n        )\n      ),\n      builder->makeSelect(\n        builder->makeGetLocal(cond, i32),\n        curr->ifTrue,\n        curr->ifFalse\n      )\n    );\n    replaceCurrent(result);\n    setOutParam(result, std::move(highBits));\nfor the second function in the i64-select.wast, that produced the following:\nvar i64toi32_i32$3 = 0, i64toi32_i32$2 = 0, i64toi32_i32$0 = 0, i64toi32_i32$1 = 0, wasm2js_i32$0 = 0, wasm2js_i32$1 = 0, wasm2js_i32$2 = 0;\n  i64toi32_i32$3 = 1;\n  i64toi32_i32$2 = (wasm2js_i32$0 = i64toi32_i32$0, wasm2js_i32$1 = i64toi32_i32$1, wasm2js_i32$2 = i64toi32_i32$3, wasm2js_i32$2 ? wasm2js_i32$0 : wasm2js_i32$1);\n  i64toi32_i32$0 = 4294967295; // ??? why i64toi32_i32$0 initialized after i64toi32_i32$2\n  i64toi32_i32$1 = 0;\n  i64toi32_i32$2 = i64toi32_i32$2;\n  i64toi32_i32$3 = (wasm2js_i32$0 = 4294967295, wasm2js_i32$1 = 0, wasm2js_i32$2 = i64toi32_i32$3, wasm2js_i32$2 ? wasm2js_i32$0 : wasm2js_i32$1);\n  i64toi32_i32$HIGH_BITS = i64toi32_i32$2;\n  return i64toi32_i32$3 | 0;. Other debug relocation sections maybe present, not only \"reloc..debug_info\" or \"reloc..debug_line\", if it is possible use curr.name.find(\"reloc..debug\") == 0 here instead.. the same problem was with set_local as well. I swapped order of calculation for low and highBits -- now it works as expected.. ",
    "adam852": "Try to remove pthread section in CMakeLists.txt. It works on my OS X 10.11.4\nELSE()\n  ADD_COMPILE_FLAG(\"-std=c++11\")\n  ADD_COMPILE_FLAG(\"-msse2\")\n  ADD_COMPILE_FLAG(\"-mfpmath=sse\")\n  ADD_COMPILE_FLAG(\"-Wall\")\n  ADD_COMPILE_FLAG(\"-Werror\")\n  ADD_COMPILE_FLAG(\"-Wextra\")\n  ADD_COMPILE_FLAG(\"-Wno-unused-parameter\")\n  ADD_COMPILE_FLAG(\"-fno-omit-frame-pointer\")\n  #ADD_LINK_FLAG(\"-pthread\")\n. CMAKE_CXX_LINK_EXECUTABLE is a variable which contain linking cmd.\nDefault value is:\n<CMAKE_CXX_COMPILER>  <FLAGS> <CMAKE_CXX_LINK_FLAGS> <LINK_FLAGS> <OBJECTS>  -o <TARGET> <LINK_LIBRARIES>\nMy proposition for separating flags for compiling and linking is something like this:\nSET(CMAKE_CXX_LINK_EXECUTABLE \"<CMAKE_CXX_COMPILER> <LINK_FLAGS> <OBJECTS>  -o <TARGET> <LINK_LIBRARIES>\")\n. \"Do not use -pthread on Darwin\nIt's not needed because Darwin has POSIX Threads in libc\"\nhttp://www.libusb.org/ticket/96\nIF(NOT ${CMAKE_SYSTEM_NAME} MATCHES \"Darwin\")\n    ADD_COMPILE_FLAG(\"-pthread\")\n  ENDIF()\n. I think, add the flag for all without OSX. I did two tests without the \"pthread\" flag on OSX (you can see effects below). \nbash-3.2$ cmake .\n-- The CXX compiler identification is AppleClang 7.3.0.7030029\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++\n-- Check for working CXX compiler: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- No build type selected, default to Release\n-- Building with -std=c++11\n-- Building with -msse2\n-- Building with -mfpmath=sse\n-- Building with -Wall\n-- Building with -Werror\n-- Building with -Wextra\n-- Building with -Wno-unused-parameter\n-- Building with -fno-omit-frame-pointer\n-- Building with -O2\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /Users/adam/test_binaryan/binaryen\nbash-3.2$ make\nScanning dependencies of target support\n[  1%] Building CXX object CMakeFiles/support.dir/src/support/bits.cpp.o\n...\n[100%] Linking CXX executable bin/asm2wasm\n[100%] Built target asm2wasm\nbash-3.2$ make clean\nbash-3.2$ rm -R CMakeFiles\nbash-3.2$ rm CMakeCache.txt\nbash-3.2$ CXX=g++-mp-4.9 cmake .\n-- The CXX compiler identification is GNU 4.9.3\n-- Checking whether CXX compiler has -isysroot\n-- Checking whether CXX compiler has -isysroot - yes\n-- Checking whether CXX compiler supports OSX deployment target flag\n-- Checking whether CXX compiler supports OSX deployment target flag - yes\n-- Check for working CXX compiler: /opt/local/bin/g++-mp-4.9\n-- Check for working CXX compiler: /opt/local/bin/g++-mp-4.9 -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- No build type selected, default to Release\n-- Building with -std=c++11\n-- Building with -msse2\n-- Building with -mfpmath=sse\n-- Building with -Wall\n-- Building with -Werror\n-- Building with -Wextra\n-- Building with -Wno-unused-parameter\n-- Building with -fno-omit-frame-pointer\n-- Building with -O2\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /Users/adam/test_binaryan/binaryen\nbash-3.2$ make \nScanning dependencies of target support\n[  1%] Building CXX object CMakeFiles/support.dir/src/support/bits.cpp.o\n...\n[100%] Linking CXX executable bin/asm2wasm\n[100%] Built target asm2wasm\nbash-3.2$ \n. Ok, I found a better way for setting \"-pthread\" flag. I've made PR. \n. Yes, it is.\n. I've just joined the w3c wasm group.\n. cc @kripken - ok, I will check it.\n. Unfortunately C is needed for support of old version of cmake module FindThreads. Now cmake miniumum version is 2.8.7, from 3.4.0 it does'nt need C.\n. ",
    "floooh": "Btw, I also stumbled over this on OSX after updating to the latest Xcode 7.3 beta command line tools (it worked with older clangs). I fixed it like this (still prints the warning, but doesn't stop the build):\ncmake\n  IF(\"${CMAKE_CXX_COMPILER_ID}\" MATCHES \"Clang\")\n    ADD_COMPILE_FLAG(\"-Wno-error=unused-command-line-argument\")\n  ENDIF()\n. PS: but I think @adam852's PR is the cleaner solution...\n. PS: the output directory only has the following files:\n\u279c  oryol (webgl2) \u2717 ls /Users/floh/projects/fips-deploy/oryol/wasm-ninja-release/\nCoreHello.asm.js CoreHello.js     CoreHello.wast\n. Thanks for the update! I'll close this issue and check the current status from time to time :)\n. Compiling with-O0 I'm getting a binaryen assertion in the linker stage:\nAssertion failed: (double(ret) == getNumber()), function getInteger, file /Users/floh/.emscripten_ports/binaryen/binaryen-version_18/src/emscripten-optimizer/simple_ast.h, line 231.\nThis happens when compiling the demos that have the bug, but not in the others that work correctly. \nI'll try to build a minimal test case tomorrow to simplify the bisect.\nAnother thing that occured to me: std::rand() is integer, but the results are used as float. Maybe the problem is not rand() itself, but the casting from int to float?\nThe emscripten linker command line is:\n/Users/floh/projects/fips-sdks/osx/emsdk_portable/emscripten/incoming/em++    --em-config /Users/floh/projects/fips-sdks/osx/emsdk_portable/.emscripten --cache /Users/floh/projects/fips-sdks/osx/emsdk_portable/.emscripten_cache  -fno-exceptions -fno-rtti -std=c++11 -stdlib=libc++ -fstrict-aliasing -Wall -Wno-multichar -Wextra -Wno-unused-parameter -Wno-unknown-pragmas -Wno-ignored-qualifiers -Wno-long-long -Wno-overloaded-virtual -Wno-deprecated-writable-strings -Wno-unused-volatile-lvalue -Wno-inconsistent-missing-override -Wno-warn-absolute-paths -Wno-expansion-to-defined -O0 -g -D_DEBUG_ -D_DEBUG -DFIPS_DEBUG=1   --em-config /Users/floh/projects/fips-sdks/osx/emsdk_portable/.emscripten --cache /Users/floh/projects/fips-sdks/osx/emsdk_portable/.emscripten_cache  --memory-init-file 1 -s TOTAL_MEMORY=134217728 -s ERROR_ON_UNDEFINED_SYMBOLS=1 -s EXPORTED_FUNCTIONS=\"['_main','_enter_fullscreen','_enter_soft_fullscreen']\" -s NO_EXIT_RUNTIME=1 -s NO_FILESYSTEM=1 -s DISABLE_EXCEPTION_CATCHING=1 -s WASM=1 -s 'BINARYEN_METHOD=\"native-wasm\"'  -O0 -g CMakeFiles/Instancing.dir/Instancing.cc.o CMakeFiles/Instancing.dir/shaders.cc.o  -o /Users/floh/projects/fips-deploy/oryol/wasm-make-debug/Instancing.html  ../../Modules/Gfx/libGfx.a ../../Modules/Assets/libAssets.a ../../Modules/Dbg/libDbg.a ../../Modules/Input/libInput.a ../../Modules/Gfx/libGfx.a ../../Modules/Resource/libResource.a ../../Modules/Core/libCore.a\n. Ok, so here's a minimal repro case. I had to use one of the Oryol samples, the problem doesn't seem to happen in a simple hello-world-style test.\nTo reproduce the problem:\n```\n\ngit clone https://github.com/floooh/wasm_test_dump\ncd wasm_test_dump\n./minrepro.sh\n...\nAssertion failed: (double(ret) == getNumber()), function getInteger, file /Users/floh/.emscripten_ports/binaryen/binaryen-version_18/src/emscripten-optimizer/simple_ast.h, line 231.\n...\n```\n\nIgnore all the 'unresolved symbol' warnings, I only added the minimal set of .bc libs which are required to generate that assertion. \nOne interesting thing: if the order of Shapes.bc and libAssets.bc is reversed in the compile command line, the assert doesn't happen.\nSo, running this triggers the assert:\nem++ Shapes.bc libAssets.bc -o Shapes.html -s WASM=1 -O0\nBut running this doesn't:\nem++ libAssets.bc Shapes.bc -o Shapes.html -s WASM=1 -O0\nDo you have time to do a bisect? If not, what would be the recommended procedure to set up an automatic bisect for binaryen, do you have a script for this somewhere?\nI might not have time until next week to do this though :/\n. Another interesting thing I just noticed: leaving away the -O0, or compiling with -O3 also triggers the assert with the .bc files in the repo... this doesn't happen though when the entire build is compiled with -O3 (so that the bitcode object files are already compiled with -O3).\nI'm assuming/hoping that the assert and the code-gen-problem with optimization on have the same cause (so that if the assert is no longer triggered, the optimized version would also be correct). If the 2 problems are unrelated I probably need to add a few more things to the repo (such as .bc files with different optimization levels).\n. Ok, I'll give it a try and report back. Is the fix already in the incoming emscripten SDK or do I need to setup a separate binaryen like in the 'old days'?\n. You're assumption was right, the assertion is gone, but the original problem's is still there, at least it's confirmed that it's also happening with -O0 builds, not just -O3. I'll update the test-case git repo with new files so that a complete .html can be built and tested. I'll also try to find out what's wrong with those float numbers (they should be in the range 0.0 to 1.0 for the vertex colors, but seem to be smaller by at least half, or even go into negative range).\n. Ok, git repo is updated (https://github.com/floooh/wasm_test_dump, the bitcode files are actually exactly the same).\nThere's 2 build scripts, one to build the WASM version, and one for the asm.js version:\n``` bash\nbuild the wasm version:\n\n./build_wasm.sh\n\nbuild the asmjs version\n\n./build_asmjs.sh \n```\n\nThis builds the files Shapes_wasm.html and Shapes_asmjs.html.\nThe faulty WASM version should look like this (vertex colors too dark):\n\nAnd the correct asm.js version like this:\n\nI'll try to do a bisect on binaryen (now that I have binaryen running from the repo again it should be trivial), but I'm traveling and might only be able to go back to this in a couple of days.\n. Ok, here's some interesting new info: all vertex colors above 0.5 are instead negative. It looks like a signed/unsigned mixup of the original integer random numbers.\nFor instance, here are the first 5 vertices for the cube in the asm.js demo (those values are the correct ones):\nx: 0.000547, y: 0.088207, z: 0.404341, w: 1.000000\nx: 0.124982, y: 0.585633, z: 0.471635, w: 1.000000\nx: 0.697425, y: 0.383120, z: 0.843062, w: 1.000000\nx: 0.112603, y: 0.830233, z: 0.155412, w: 1.000000\nx: 0.776852, y: 0.631963, z: 0.740406, w: 1.000000\nAnd here the same vertices in the broken WASM demo, note how all values 'v' above 0.5 are instead (-1.0 + v)\nx: 0.000547, y: 0.088207, z: 0.404341, w: 1.000000\nx: 0.124982, y: -0.414367, z: 0.471635, w: 1.000000\nx: -0.302575, y: 0.383120, z: -0.156938, w: 1.000000\nx: 0.112603, y: -0.169767, z: 0.155412, w: 1.000000\nx: -0.223148, y: -0.368037, z: -0.259594, w: 1.000000\nThe computation for those random numbers in GLM looks tricky (here: https://github.com/g-truc/glm/blob/2336264f4eecea8a029b14e54b275e77318c3782/glm/gtc/random.inl#L228):\ncpp\n    template <template <class, precision> class vecType>\n    struct compute_linearRand<float, highp, vecType>\n    {\n        GLM_FUNC_QUALIFIER static vecType<float, highp> call(vecType<float, highp> const & Min, vecType<float, highp> const & Max)\n        {\n            return vecType<float, highp>(compute_rand<uint32, highp, vecType>::call()) / static_cast<float>(std::numeric_limits<uint32>::max()) * (Max - Min) + Min;\n        }\n    };\nAnd that compute_rand for uint32 also looks a bit non-trivial (it's building the 32 bit number from 2 16-bit numbers, here: https://github.com/g-truc/glm/blob/2336264f4eecea8a029b14e54b275e77318c3782/glm/gtc/random.inl#L105\ncpp\n    template <precision P, template <class, precision> class vecType>\n    struct compute_rand<uint32, P, vecType>\n    {\n        GLM_FUNC_QUALIFIER static vecType<uint32, P> call()\n        {\n            return\n                (vecType<uint32, P>(compute_rand<uint16, P, vecType>::call()) << static_cast<uint32>(16)) |\n                (vecType<uint32, P>(compute_rand<uint16, P, vecType>::call()) << static_cast<uint32>(0));\n        }\n    };\n... and the 16-bit number in turn is built by or-ing 2 8-bit numbers... and finally an 8-bit random number is built like this:\ncpp\nstd::rand()) % std::numeric_limits<uint8>::max();\n...maybe I can build a simplified test case with this in mind...\n. All working fine now, I have updated the WebAssembly samples at http://floooh.github.io/oryol/ and http://floooh.github.io/oryol-samples/.\nThanks!\n. PS: Any ETA when the fixed Binaryen will be in the emscripten incoming SDK?\n. ",
    "BSalita": "Shouldn't be a problem for several reasons. There's a similar line in the function just below it. auto resolves to int. Also infile.open(filename, flags); expects flags to be castable to int. This is all a good argument against using auto instead of a concrete type.\nauto flags = std::ofstream::out | std::ofstream::trunc;\nI'll open a pull request.\n. Yes, that works too. Be aware that VS reports  std::ios_base::openmode as an alias for int.\ntypedef int std::ios_base::openmode;\n. I suppose the bitwise operations could yield non-ints. I suspect if that were true though, some of the usage would become syntax errors and there would be all sorts of compatibility havoc. \n. You are correct that std::ios_base::openmode is the best choice. I tested compatibility using several online sites:\nrextester compiles clang, gcc, or Visual Studio\ngodbolt compiles many versions of clang, gcc\nwandbox compiles many versions of clang, gcc\nI tested the following code:\n#include <fstream>\nint main()\n{\n    std::ifstream infile;\n    int flags = std::ifstream::in; // auto (only clang, gcc), int (only clang, VS) or std::ios_base::openmode (compatible with all)\n   flags |= std::ifstream::binary;\n   infile.open(\"some file\", flags);\n   return 0;\n}`\nThe results show that std::ios_base::openmode is the only type that compiles on all C++ compilers and template libs. I'll issue a pull request using std::ios_base::openmode.\n. Fix is in PR #418\n. Can you try the very same PR again. It was dependent on #471 being merged, which it is now so #470 should now work.\nOn Wednesday, May 11, 2016 7:33 PM, Alon Zakai <notifications@github.com> wrote:\nThis caused some errors on travis.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. done. \nOn Wednesday, May 11, 2016 8:37 PM, Alon Zakai <notifications@github.com> wrote:\nI think you need to rebase on master and push -f to this branch again.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. I created a new PR #474 which has now passed. \nOn Wednesday, May 11, 2016 8:50 PM, Alon Zakai <notifications@github.com> wrote:\nI don't see an update here, it still looks like 71a0755 is what's in the branch?\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Another option, I believe they're equivalent, is !n+1, which looks even worse.\nMicrosoft is right in that the programmer of a negative unsigned may not know what they're getting. \nOn Thursday, May 12, 2016 8:27 PM, Alon Zakai <notifications@github.com> wrote:\nNegation of unsigned is still unsigned? That sounds odd. Also looks a little odd in the code. No other option here?\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. I'm unsure where we are on this. Do I need to take some action to get a merge?\n. Good. It was on my list to learn how to add compiler defs to cmake so that _CRT_SECURE_NO_WARNINGS\u00a0would be added to Visual Studio files. Derek beat me to it.\nThere's another flag that should be added which supresses some legacy issues:\u00a0_SCL_SECURE_NO_WARNINGS\nHere's the output from Visual C++ when\u00a0_SCL_SECURE_NO_WARNINGS\u00a0isn't used:\nc:\\program files (x86)\\microsoft visual studio 14.0\\vc\\include\\xutility(2442): warning C4996: 'std::copy_n::_Unchecked_iterators::_Deprecate': Call to 'std::copy_n' with parameters that may be unsafe - this call relies on the caller to check that the passed values are correct. To disable this warning, use -D_SCL_SECURE_NO_WARNINGS. See documentation on how to use Visual C++ 'Checked Iterators'1> \u00a0c:\\program files (x86)\\microsoft visual studio 14.0\\vc\\include\\xutility(2442): note: see declaration of 'std::copy_n::_Unchecked_iterators::_Deprecate'1> \u00a0c:\\sw\\wasm\\binaryen\\binaryen32\\src\\binaryen-c.cpp(410): note: see reference to function template instantiation '_OutIt std::copy_n>>,size_t,char>(_InIt,_Diff,_OutIt)' being compiled1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0with1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0[1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0_OutIt=char ,1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0_InIt=std::_Vector_iterator>>,1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0_Diff=size_t1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0] \nOn Friday, May 13, 2016 12:11 AM, Alon Zakai <notifications@github.com> wrote:\nlgtm. @BSalita, what do you think?\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. On my C projects, I prefer to avoid external defs. I prefer to have a #include \"impldefs.h\" at the top of each source file. Inside impldefs are #pragmas which turn off compiler Visual Studio warnings. I stuff other conditional definitions based on compiler/system/bit-ness/endian. The benefit is that I don't have to be concerned about settings defs in make files. Its easier to maintain. I see that there's some similar file in binaryen but it isn't carried through to all source files.  \nGood. It was on my list to learn how to add compiler defs to cmake so that _CRT_SECURE_NO_WARNINGS\u00a0would be added to Visual Studio files. Derek beat me to it.\nThere's another flag that should be added which supresses some legacy issues:\u00a0_SCL_SECURE_NO_WARNINGS\nHere's the output from Visual C++ when\u00a0_SCL_SECURE_NO_WARNINGS\u00a0isn't used:\nc:\\program files (x86)\\microsoft visual studio 14.0\\vc\\include\\xutility(2442): warning C4996: 'std::copy_n::_Unchecked_iterators::_Deprecate': Call to 'std::copy_n' with parameters that may be unsafe - this call relies on the caller to check that the passed values are correct. To disable this warning, use -D_SCL_SECURE_NO_WARNINGS. See documentation on how to use Visual C++ 'Checked Iterators'1> \u00a0c:\\program files (x86)\\microsoft visual studio 14.0\\vc\\include\\xutility(2442): note: see declaration of 'std::copy_n::_Unchecked_iterators::_Deprecate'1> \u00a0c:\\sw\\wasm\\binaryen\\binaryen32\\src\\binaryen-c.cpp(410): note: see reference to function template instantiation '_OutIt std::copy_n>>,size_t,char>(_InIt,_Diff,_OutIt)' being compiled1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0with1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0[1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0_OutIt=char ,1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0_InIt=std::_Vector_iterator>>,1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0_Diff=size_t1> \u00a0 \u00a0 \u00a0 \u00a0 \u00a0] \nOn Friday, May 13, 2016 12:11 AM, Alon Zakai <notifications@github.com> wrote:\nlgtm. @BSalita, what do you think?\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\n. Still it would be nice to have a #include at the top of each file. They're also handy for special OEM definitions and debugging. Anyway, if devs are accustomed to putting defs into cmake then we should continue. Yes, Visual C++ #pragmas allows you to suppress any warnings and can do many other handy things. \nOn the other hand, warnings are disabled for the posix systems via command line flags. (I don't even know if there are pragmas for that with those compilers, but it's certainly not common practice to use them). So given that I think I'd rather have all the warning disabling going on in one place (CMakeLists.txt) for all platforms.\u2014\n. Looks like the signatures of some functions in wasm-binary.h should be similarly changed to use Index instead of int32_t or others.\n1. Index getImportIndex(Name name)\n2. Index getFunctionIndex(Name name)\n. Thanks for putting up with me. I'm a bit clumsy with the tools and teamwork. I'll gradually improve.\nI should be able to actively participate for another month, maybe much longer.\nThanks for taking this on!\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Looks like I need to install gcc and clang so I can provide better quality PRs. Visual Studio alone isn't sufficient. Fortunately, I can now use gcc and clang in Microsoft's new bash shell feature. \n. The benefit to having cleaner PRs is less time teammates look at my code and more time for their own work.\n. Is there some action I have to take to get this PR merged?\n. Could you list the remaining controversial parts? I'm ok with another round of justification. I believe you're thinking some of these changes are optional because you're not seeing the compiler warnings that I'm seeing. The compiler warnings are largely a result of the existing code not dealing with 32/64 issues properly.\n. Regarding warnings, my belief is that you treat them as errors. That's clearly not shared by others on this forum. My own code is warning-less is all environments. There are some exceptions such as warnings due to bugs in compilers (non-existent now), or serving as To Do reminders that should be addressed later.\nRegarding clutter, if you mean syntax needed to suppress warnings due to type differences (casting), I don't see that as clutter. I see it as necessary. When you have source code that needs to run on multiple compilers, different endians, different architectures (32 vs 64, arm vs Intel), different OSs, incorporate legacy considerations, optimal performance, differing loaders/linkers, signed/unsigned compiler diffs, fetch/store alignments, struct packing diffs, I don't know how you do that other than adding syntax to the code at issue. To be clear, such clutter is in your future and you won't be able to prevent it. Of course if you want to limit the source code to a couple compilers, and just 32 or 64-bit, you'll have no more clutter than you have now.\nThere are ways to mitigate clutter such as your suggestion to create new vector and map classes just to workaround size() casting. A way to hide endian clutter is to create endian template classes with operator overloads. However, all these have trade-offs. I fear such classes will add complexity, add CPU cycles, and redirect development time better spent elsewhere.\n. End of the day here. I'll tackle tomorrow. \nOn Monday, May 23, 2016 9:09 PM, Derek Schuff <notifications@github.com> wrote:\nOK after looking some more, I think we should:\n1. Remove toIndex from this PR\n2. Remove SIZE32LEB from this PR.\n3. Change the constructor of LEB to take a size_t argument as I suggested above (that can be in this PR because it's a pretty trivial change).\n4. Land #537 or something like it in a separate PR.If you do 1 and 2 and optionally 3 for this PR, then it LGTM.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. That's ok by me. However, it's a moving target as I'm busily working on additional Visual C++ features.\nYesterday the task was to build binaryen-c.cpp as a static library.\nToday I was able to build binaryen-c.cpp as a DLL.\nSince the DLL is now available, I was able to translate c-api-hello-world.c example into C#. Works fine. So now .Net is able to call binaryen methods. I should have c-api-kitchen-sink.c working early this week.\nOn Saturday, May 14, 2016 2:51 AM, Alon Zakai <notifications@github.com> wrote:\nNice!Perhaps we should mention this in the readme?\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. I've posted an update to the repo with source code of binaryen-c examples in C#. I see that kitchen sink blows up in the optimizer step. It does so in both original C and CS so I believe it's not my code. I'll look into it further. This work went really fast, less than half the time I estimated.\nhttps://github.com/BSalita/c-api-examples\nFrom README:\nVisual Studio 2015 solution for building WebAssembly/binaryen/test/examples/binaryen-c files. Examples are built using test source code in bot C and C#. \n- Builds binaryen-c.cpp into a static library.\n- Builds binaryen-c-dll.c into a dynamic library by DllExporting from the static library.\n- Builds c-api-hello-world.c (uses static library)\n- Builds c-api-kitchen-sink.c (uses static library)\n- Builds cs-api-hello-world.cs (uses dll)\n- Builds c-api-kitchen-sink.cs (uses dll)\n  To use, clone WebAssembly/binaryen. Be sure to edit all this repos project files (.vcxproj) to path source files at the binaryen cloned directory. \nOn Saturday, May 14, 2016 10:15 PM, Bob Salita bsalita@yahoo.com wrote:\nThat's ok by me. However, it's a moving target as I'm busily working on additional Visual C++ features.\n  Yesterday the task was to build binaryen-c.cpp as a static library.\n  Today I was able to build binaryen-c.cpp as a DLL.\n  Since the DLL is now available, I was able to translate c-api-hello-world.c example into C#. Works fine. So now .Net is able to call binaryen methods. I should have c-api-kitchen-sink.c working early this week.\nOn Saturday, May 14, 2016 2:51 AM, Alon Zakai notifications@github.com wrote:\nNice!Perhaps we should mention this in the readme?\u2014\n  You are receiving this because you authored the thread.\n  Reply to this email directly or view it on GitHub\n. I'd like to get #491 accepted and then try this PR. This may be the solution to avoiding casting form of clutter.\n. Cheers \nOn Wednesday, June 1, 2016 12:44 AM, Alon Zakai <notifications@github.com> wrote:\nNice!\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. RotateLeft and RotateRight get compiler warnings because they negate an unsigned value (-count). So we have a compiler warning that needs to go away. I thought I did that in a way that wouldn't change semantics and might be an instruction faster.\nhttp://stackoverflow.com/questions/4267194/compiler-warning-for-unary-operation-on-unsigned-int/4267258#4267258\nThere are multiple issues involved and I am researching further. Here's some thoughts.\n1) What is the intention of the negation and what is the C++ compiler actually doing? I believe the intent was to get a signed value. However, the result of the negation is an unsigned value. You can remove the warning by coding -(int)count or -(int64)count. That might be the compiler's default handling? Looks like typing is i32->u32->int.\n2) For sure if my PR changed the semantics, that would be wrong of me.\n3) You say the 2 args should be the same type. Why?\n4) For sure if my PR added cycles, that would be wrong of me. The ultimate resolution should be same cycles or faster.\n5) What is the specification of shift count? Must count be positive or can it also be negative. What happens if it's greater than the number of bits of the left hand operand type?\nI'm continuing to look into these questions. What can you tell me?\nOn Wednesday, May 11, 2016 9:04 PM, Derek Schuff <notifications@github.com> wrote:\nIn src/wasm.h:> @@ -583,15 +583,15 @@ class Literal {\n\n}\n   Literal rotL(const Literal& other) const {\n     switch (type) {\n-      case WasmType::i32: return Literal(RotateLeft(uint32_t(i32), uint32_t(other.i32)));\n-      case WasmType::i64: return Literal(RotateLeft(uint64_t(i64), uint64_t(other.i64)));\n-      case WasmType::i32: return Literal(RotateLeft(uint32_t(i32), other.i32));\n  RotateLeft is a template where the 2 arguments are the same type. How does changing this from an explicit cast to an implicit conversion help?\u2014\n  You are receiving this because you authored the thread.\n  Reply to this email directly or view it on GitHub\n. Derek, you didn't miss anything. The PR's came in at different times because I'm not yet spun up with git commands. I need some more experience.\nYou raised some questions which I probably should have considered more deeply. Shift and rotate semantics can differ between languages, implementations and instruction sets.\nRegarding shift and rotate operators, I don't see any relationship between the types of the left and right operands. It seems wrong to me that they would need to be the same. I certainly don't see the need when looking at the WebAssembly design document or our C++ implementation.\nI've now read the WebAssembly ast-semantics design document. It says the right hand operand (RHO) must be treated as an unsigned value and only the lower 5/6 bits are actionable. I don't see that a positive int (other.i32) will be semantically different than an unsigned. What about a negative other.i32. I'm not sure if it makes a semantic difference either but it does give me a headache thinking it through. Even if a negative shift count can be handled, I'm not sure if it's worth giving even one comparision/anding/negation to deal with that strange case.\n\nOn Wednesday, May 11, 2016 9:20 PM, Derek Schuff <notifications@github.com> wrote:\nIn src/support/bits.h:> @@ -66,14 +66,14 @@ int CountLeadingZeroes(T v) {\n\nreturn CountLeadingZeroes(typename std::make_unsigned::type(v));\n }\n-template \n-inline static T RotateLeft(T val, T count) {\n+template \nSorry I missed this before. I'm not sure having a second type is good here because they could end up being different sizes if we're not careful, and then the bit-twiddling doesn't work. If the warning is about negation of an unsigned value, maybe we could just cast it to signed for that expression instead.If we did that, I think we wouldn't need #474 either.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Thanks for the detailed answers. I now see that binary encodings of dyadic operators contain no operand typing and therefore both operands must be the same type as the opcode. Lot's to learn. \n\nOn Thursday, May 12, 2016 1:20 AM, Derek Schuff <notifications@github.com> wrote:\nIn src/support/bits.h:> @@ -66,14 +66,14 @@ int CountLeadingZeroes(T v) {\n\nreturn CountLeadingZeroes(typename std::make_unsigned::type(v));\n }\n-template \n-inline static T RotateLeft(T val, T count) {\n+template \nThe WebAssembly semantics are that both operands are the same size, but that the shift count bits beyond the 5 least significant are ignored. C's semantics are that if the shift count is too large (e.g. if any of those bits are set) then the behavior is undefined (that's a very bad thing). The mask operation in the first 2 lines of the implementation is designed to implement the wasm rotate semantics but if it fails to mask all the higher-order bits (which could happen if U were accidentally larger than T) then the behavior of the interpreter would be undefined according to C shift semantics.The effect of -count is, bitwise, the same if count is a signed or unsigned int, so -5 is 0xFFFFFFFB. and the right-shift count becomes 0xB (or 11, which is ) after masking. Other than that, this particular implementation only does bitwise operations and so is agnostic to whether the types are signed or unsigned.\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. Absolutely. I'll change it and look for other instances.\n. Visual Studio editor artifact. I'll have to change Visual Studio indentation settings. Apparently there's no pretty print scheduled? So it's all up to the programmer to manually pretty print?\n. I'm not sure what you mean. The issue is that arithmetic operators are promoting to int.\n. Three files, so far: Print.cpp, wasm-binary.h, wasm-builder.h\n. I believe '0' is also an int.\n. Yet another thing I learned today.\n\nOn Friday, May 13, 2016 10:38 PM, Derek Schuff <notifications@github.com> wrote:\nIn src/emscripten-optimizer/simple_ast.h:>          if (num >= 3) {\n\ntest++;\n       test[0] = 'e';\n       if (num < 10) {\n-            test[1] = '0' + num;\n-            test[1] = (char)('0' + num);\n  It is in C; It's actually not in C++ (http://en.cppreference.com/w/cpp/language/character_literal)\u2014\n  You are receiving this because you authored the thread.\n  Reply to this email directly or view it on GitHub\n. Just a whitespace change.\n. Do you mean add an assert() within toIndex()? Yes, if max (size) is passed as an additional parameter, an assert could be added. Should I do that?\n. @kripken Assert added in toIndex(). I'm requesting a merge now. After merge, I'll go back and look over the additional suggestions. Changes are plentiful enough that I don't want to complicate the PR further.\n. In wasm-binary.h, in mapLocals() line 586, I added a toIndex(). Looks like it will always assert. However, travis passes so I'm thinking the code is never executed. I can't tell if curr is suppose to be equal to size() correctly, or if curr is off by 1, or it's just a work in progress. Can you have a look?\n. How about if I create an overload with one parameter that includes your suggested assert?\n\u00a0assert(index <= std::numeric_limits::max())\nOr should I just change two to one parameter? \n\nIn src/wasm.h:> @@ -91,6 +91,11 @@ struct Name : public cashew::IString {\n\n// An index in a wasm module\n typedef uint32_t Index;\n+inline Index toIndex(size_t index, size_t max) {\nI'm not sure about the second parameter. It does help in some cases, but we may not always have that information around, and we'd need to write a lot of getFunction()->getNumLocals(). I suggest just asserting on just the size of the type, assert(index <= std::numeric_limits::max()).\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. I'm being stupid. I removed the assert to test and then forgot about it. This explains why mapLocals didn't assert. I'll uncomment.\n\nIn src/wasm.h:> @@ -91,6 +91,11 @@ struct Name : public cashew::IString {\n\n// An index in a wasm module\n typedef uint32_t Index;\n+inline Index toIndex(size_t index, size_t max) {\n- //assert(index < max);\n  indentation looks wrong here\u2014\n  You are receiving this because you authored the thread.\n  Reply to this email directly or view it on GitHub\n. I removed the second parameter of toIndex() and inserted the new assert. How's it looking now for a merge?\n. The usualfor idiom has array indexing within it. In this case there is none. So I could go either way. The toIndex() is needed somewhere because in 64-bit, sizeof(size_t) > sizeof(Index). However, as soon as there's an array index, or the underlying type of Index is changed, the code would break unless toIndex() is used as it currently is.\n. All .size() are size_t so a cast is needed for any assigning to a 32-bit value. The reason for SIZE32LEB exists is to cast 64-bit size_t 32-bit LEB. I'm suspect that some of the int32_t in this file should be uint32_t or Index or some new name. I don't want to even peek at this issue until this PR is closed.\n. fixed\n. To eliminate toIndex(), not only would we have to change to IndexedVector but also to IndexedMap.\n. Since SIZE32LEB performs a useful task, properly casting size_t to 32-bit, we should do the opposite. Accept it for now. Perhaps someone can come up with a better solution for SIZE32LEB specifically or all of the *32LEB cast in general.\n. I've not wanted to create more changes to this PR preferring to implement in another PR. However, since you asked twice, I went ahead and coded per your request.\n. \n",
    "MI3Guy": "Ah, Sorry. I just submitted a request to join.\n. C++ only guarantees a conversion from void* to the original class.\nFor instance if you do Loop* -> void* the standard allows converting back using void* -> Loop* but does not define the behavior of void* -> Expr* -> Loop*.\nIf we convert Loop* -> Expr* -> void* then converting from void* -> Expr* works and after that you can always convert that Expr* to Loop*.\n. static_cast would certainly work. I added implicit_cast because if a pointer of the wrong type is used it will ensure that it is an error. Essentially it avoids any of the risks associated with doing a normal cast.\n. static_cast also allows for conversions from void* or a hypothetical base class. I believe there are other cases where there may be an issue, but I can't recall them (I think they involve virtual/multiple inheritance). If you don't think these (admittedly minor) benefits are worth it, I can make the change.\n. The bin directory is all specified individually so I was did the same thing. I'll defer to those who know the code better than I do.\n. ",
    "wanderer": "ok @kripken  i'm not planing on picking this up, so ill close it.\n. thanks @kripken \n. ",
    "petamoriken": "Sorry for my late reply.\nhttps://github.com/guybedford/wasm-stdlib-hack solved this issue.\nThanks!. ",
    "ddcc": "Yes, I've joined the working group through Google. I have the failing binary testcases; the earlier fix for the assertions in finalize() is the new assert at wasm-binary.c:1483.\n. Is there somewhere that I should put the malformed WASM testcases? The spec repository seems to only have WAST testcases.\n. They are probably generic enough to be put in the spec repo. I did some fuzzing on the interpreter from WebAssembly/sexpr-wasm-prototype, and there were some similar problems. I can also start writing up some tests for the issues from #549.\n. Additionally, the description of the names section states that \"a validation error in this section does not cause validation for the whole module to fail, and is instead treated as if the section was absent\". This seems to be imply that a rollback is necessary on encountering a validation error? \nIt also states that the count of function_names may be greater or less than the actual number of functions. Currently (post-#546), the existing implementation checks that the count is equal to the number of functions.\n. @dschuff: I'm not sure how this should be implemented without explicitly performing the copy.\n. Yeah, I can move over the test. For x86_64 Linux ELF, they are just regular data symbols (readelf -a):\n37: 0000000000400720    24 OBJECT  LOCAL  DEFAULT   15 _ZTV1C\n    38: 0000000000400700    24 OBJECT  LOCAL  DEFAULT   15 _ZTV1B\n. I've moved the logic over to scan(), but process() still needs to be changed to parse and skip over object aliases. Otherwise, the original code in process() will terminate the loop as soon as a non-dot character is encountered, but this will miss other directives after the object aliases.\n. Ok, should be fixed now. Not sure what this appveyor build failure is; don't recall seeing it before.\n. Hmm, part of this seems to be from an existing but previously unknown bug, because s2wasm was skipping over unrecognized input. Coincidentally, I previously encountered issues with the __environ symbol when trying to build Python for WebAssembly, but hacked up a workaround and didn't follow up.\nIt turns out that weak symbols don't necessarily have a size. This should be fixed in #630.\n. I have a draft LLVM patch, it still needs more tests, discussion, and review.\n. Would it be possible to merge this? Do you mind reviewing the code?\n. Ok, that functionality has been moved.\n. The patch was merged in LLVM today.\n. Good point, fixed.\n. Done.\n. I will split off the backend changes to the table data structure into a separate patch, while leaving the frontend parsing untouched. This should make it easier to add multiple table support in the future.\n. Correct me if I'm wrong, but I thought that #682 added support for multiple tables, though the MVP only supports one default table per #727?\n. Is this OK to merge?\n. Added comment.\n. There's a bit of a trade-off on the dummy function. Is it something we always want to create, even if no functions are address taken? The only case that a function indexes is compared against is if at least one of lhs/rhs is a function.\n. Should be good now.\n. I think your patch looks more comprehensive.\n. Yes, it is an external object. I see the following in library.js:\n```\nif USE_PTHREADS\nenviron: '; if (ENVIRONMENT_IS_PTHREAD) _environ = PthreadWorkerInit._environ; else PthreadWorkerInit._environ = _environ = allocate(1, \"i32*\", ALLOC_STATIC)',\nelse\nenviron: '{{{ makeStaticAlloc(1) }}}',\nendif\n__environ__deps: ['environ'],\n  __environ: 'environ',\n```\nBut even with this patch, it doesn't work. The generated JS file omits the environ symbol:\nvar _environ=STATICTOP; STATICTOP += 16;;var ___environ=_environ\nThe libc.bc build does produce an external global for __environ:\n@__environ = external local_unnamed_addr global i8**, align 4, but nothing for environ. Normally, libc provides weak aliases from environ, _environ, and ___environ to __environ, but since we blacklist env, this is not built.\n. Correct me if I'm interpreting the code wrong, but isn't it reading an unsigned 32-bit LEB into a signed 32-bit integer type, which will overflow the upper half of values to negative?\n. 1. Yes, I've been building various programs for testing, and found that the compiler produced aliases to aliases. That code wasn't in the original version of this pull; I added it yesterday.\n2. I'm not sure what you mean by matching sizes; the size of an alias should always be less or equal than the size of the parent object minus the offset. AFAIK the aliasee is always declared before the alias, so we can check the sizes, but the current pull doesn't do this (the size field isn't used). Currently, the size information is stored separately from a Relocation in a StaticObject, but the latter are in a staticObjects vector that isn't efficient to search. I'm not sure if we want to change this to a map, or add a size field to relocations for this?\n. 1. I added the test case; B aliases A, which aliases .L__unnamed_1.\n2. Ok, I will drop the size field.\n. Oops, that's what #657 is for :)\n. It's not support for names, it's the reverse map of functionIndexes. The reason it's necessary is that functionIndexes maps from function names to indirect table indexes. But in order to emit the pre-assigned function names in sorted order, I need a sorted reverse map from indirect table indexes to function names.\n. This function should always be called before the functions with pre-assigned indices are handled, since the pre-assigned functions will  start at index 1, so the two should be mutually compatible.  But the intention is to check just in case the table is non-empty when this function is called,  so I will convert it to an assert.\n. ",
    "alexcrichton": "I've been playing around with binaryen, the LLVM WASM backend and Rust lately and I think this may help us quite a bit right now! We generate intrinsics like \"memcpy\" and such into LLVM modules and we're forced to export them all the way through to codegen to ensure it's not an unresolved symbol (for now). These are all currently hidden symbols but they currently get exported from the wasm module. \nA good first step I think would be to avoid exporting these symbols, with an ideal end goal of GC'ing them out during the linking phase that s2wasm/wasm-as is doing, but I'd be fine with just not exporting to start out with!\nWould y'all still be interested in a patch for this? It looked like it wouldn't be too hard to shim this in to the current s2wasm (just avoiding exporting hidden functions). Ah yeah I wasn't actually sure of any way right now to go from LLVM IR to a wasm module, but if there's a more \"well supported\" alternative that'd be great! I certainly don't mind using whatever :). Thanks! I've renamed the lowering function (good catch!) although after running ./auto_update_tests.py I'm not seeing any new files to commit. Where should I be expecting such a file to materialize?. Hm I still can't seem to figure this out :(\nIf I touch the test/wasm2asm/i64-shifts.2asm.js file or if I comment out these lines the *.js file doesn't get filled in. It also looks like there's no other *.2asm.js files in test/wasm2asm?. That seems to have done the trick!. Let's see how Travis likes that.... Ah no worries! Hopefully this'll make the next patch easier :). Ok thanks for reviewing! I've moved the inline codegen to a separate function, generated only if necessary as part of the i64->i32 lowering pass. Other than that I hope to enable the i64.wast test soon for wasm2asm and get some more coverage!. Updated!. Should be done now! (I think?). I'm doing my best currently w/ this PR to get the spec tests running where possible, but unfortunately there's a lot of gotchas in running then through wasm2asm so it's just taking a bit of time!. Ok! I've gotten things to what I believe is a workable state. You can now do:\n```\n$ ninja\n$ cp test/spec/conversions.wast .\nremove a few test cases in conversions.wast (described below)\n$ bin/wasm2asm conversions.wast > foo.js\n$ node foo.js\n$ spidermonkey foo.js\n```\nand it all works! Surprisingly lowerTruncFloatToInt didn't turn up any bugs (as I thought it might) but it did find a bug in lowerConvertIntToFloat. I switched lowerConvertIntToFloat to doing all arithmetic in f64 rather than f32, and then casting to f32 at the end.\nThe main caveat with wasm2asm and spec tests is that NaN is pretty funny. I believe in wasm you can observe different bit patterns for NaN (via reinterpretation instructions and such). In JS, however, some implementations (V8 I think?) allow witnessing this but other implementations (SpiderMonkey and JSC) seem to not and instead canonicalize NaN representations.\nI added custom code to the test suite so when when comparing two floats for equality any two nan values are considered equal. This does not, however, fix tests that look like:\n(assert_return (invoke \"i32.reinterpret_f32\" (f32.const nan)) (i32.const 0x7fc00000))\nThis is specifically testing that when a NaN is casted to an integer we get the right bits back out. This is unfortunately implementation defined, so we can't run these tests and have them pass on all JS interpreters.\nOnce all those tests are commented out though (just the ones converting NaN to bits), then the entire conversions.wast spec test passes!\nWould you like me to copy the modified test into the test/wasm2asm folder? . Oh I should also mention that a lot of what's happening here feels like I'm hacking around things that I don't fully understand, if you've got suggetions of how to restructure anywhere please let me know!. Sure thing! I copied the entire conversions.wast file wholesale into the test/wasm2asm folder and then commented out the tests that casted from NaN to an int and then asserted on the bit pattern.. Hm now I'm a bit confused! I think it's passing the test in test/wasm2asm, but the Travis failure (which I can indeed reproduce locally) is failing on test/spec/conversions.wast which is known to fail and shouldn't be running.\nDid that test start running by accident because wasm2asm now succeeds when converting it? Or do you know how I could suppress that test from being run automatically?. Ah I may have just found it!. Ah the name was left as test/wasm2asm/conversions.wast and the correspodning test/wasm2asm/conversions.2asm.js existed. That, by inference of the script, automatically enabled the test/spec/conversions.wast test (because conversions.2asm.js existed). I just renamed the test to not have the exact same name. Oh sorry https://github.com/WebAssembly/binaryen/pull/1554 is based on this one, so this'll want to land first. . Ah good point, updated!. > Do we expect there to be more such instructions we want to remove by lowering to simpler stuff?\nHm a good point! Arguably this could be folded into the i64-to-32 pass I think in the sense that no one but wasm2asm is using that pass, right? Otherwise I think we'll want to get rid of atomics for wasm2asm, right? (although I don't if atomics are supported in raw JS).\n\nOtherwise thanks for the sharp eye and should be updated!. Oops!\nI'm hoping it's fixed now, but let's wait and see.... Ok I think this should be all green now!. Note that this currently builds on https://github.com/WebAssembly/binaryen/pull/1550 (first commit), and it ended up getting a little larger than I originally intended. If you'd prefer that I trim it down and/or split it up, please just let me know!. Aha interesting, CI is failing on Travis but passing locally. It appears due to a change in V8 wrt NaN and binary encodings. Taking a look at this program:\njs\nvar i = new Int32Array(1);\nvar f = new Float32Array(i.buffer);\nf[0] = -NaN;\nconsole.log(i[0]);\nOn node 10.0.0, what I have installed locally, this prints -4194304, or 0xffc00000. On node 8.11.2, not what Travis is using but what I just downloaded, this prints 2143289344, or 0x7fc00000. In other words it looks like node 8.11.2 isn't distinguishing between -NaN and NaN, while node 10.0.0 is distinguishing between the two (and any other arbitrary bit pattern I think!)\nDo you have a preferred solution for this? I could copy the test in like the conversions.wast and edit it to remove tests known to fail, but I could also update the version of Node on CI. Just lemme know which is preferred!. Updated!. Ok I've rebased this, fixed up a few issues, and hopefully tidied it up a bit. So long as Travis comes back green!. Er sorry, next up is the node version issue, which I can fix whichever way you'd prefer. Ok! I think that may be everything, but let's wait and see.... Hurray a green bill of health!. Updated!. FWIW the \"linker\" here isn't really a linker per se but rather just copying a few functions over. It does have some logic for recursively copying over referenced functions, but it ends up being pretty small and probably doesn't need most of the functionality in a full-blown linker and whatnot. I've discovered one more bug related to table offsets preventing some Rust code from working by default, and that should be fixed now!. @kripken oh sure I'm fine splitting up however you'd like. Would you like an i64 PR and then an \"everything else\" PR? Or PRs per every few commits?. I think most of the remaining commits are pretty straightforward (although I could be wrong). Want to look them over and if something major comes up I can split it out?. Ok I've posted https://github.com/WebAssembly/binaryen/pull/1563 which contains just the first commit, and I can rebase this if that lands first. er sorry, didn't mean to close. Ok! I've rebased over https://github.com/WebAssembly/binaryen/pull/1563 now. Updated!. Sounds like a great plan to me as well! In wasm-bindgen I've got a was2es6js tool which currently supports a --wasm2asm flag which uses wasm2asm under the hood to replace a wasm file with an ES6 module. Some things I've learned from that which we'll want to do here:\n\nWe'll want to initialize the contents of memory with the data segments of a wasm module. Currently I've just got it storing base64 strings and then decoding them on the fly to initialize the main memory chunk.\nAt least what wasm-bindgen has been doing is emitting ES module output by default, but we'd probably also want a flag to not do that. For example wasm-bindgen has a --no-modules flag which is intended for directly loading in a browser (no packaging) and otherwise just disallows importing anything. I'm not sure the exact same would work for wasm2js but it may be worth thinking about the import story for wasm2js, e.g. how are we emitting JS with those imports? (maybe like a --amd flag? --commonjs?)\nWe'll want to add a new pass which renames all imported functions in a wasm module. Right wasm2asm would choke if you have, for example, (import \"foo\" \"bar\") as well as (import \"baz\" \"bar\") (aka the same name from two different modules). It should be fine to handle this all transparently though by renaming everything to a unique name and then reassembling the mapping from the imported items.\nAs a bit of a usability improvement I think we'll want to accept raw wasm input instead of only wast input, but that's a pretty minor addition!\n\nFWIW I've found that the spec tests are quickly reaching diminishing returns. Most things are working pretty well and most of the remaining spec tests are exercising \"interesting\" aspects of the harness they're expected to be run under (multiple modules, etc). After https://github.com/WebAssembly/binaryen/pull/1558 I think it might be worthwhile to dive straight into the emscripten test suite or fuzzing without trying to get too many more spec tests working, although I could be wrong!. Also FWIW with #1558 applied as well as https://github.com/WebAssembly/binaryen/issues/1562 implemented I believe wasm-bindgen's entire test suite is passing running through wasm2asm instead of through WebAssembly in node. Additionally I've now taken https://github.com/Hywan/gutenberg-parser-rs as-is and run it through wasm2asm and it works like a charm, so wasm2asm is definitely approaching \"pretty ready\"!. Hm perhaps yeah! Although I guess it'd be like a oneshot thing where it'd always just \"compile\" the same module? \nI've found that the ES module boundary is at least a pretty easy one to polyfill at, but it definitely means that if you're using wasm2js then you'd have to have some sort of other bundler in play. Most of the time for production use cases that's already the case though?. @binji ah sorry yeah that's what I mean. In the sense that those things aren't too interesting in terms of the feature set of wasm2asm specifically :). Ok updated!. I've pushed a new commit which removes the duplicate run of the remove-non-js-ops pass by duplicating intrinsics. > Although, I'm not sure what you mean by \"duplicating intrinsics\" so I must be missing the important part?\nOh just in the sense of i64.popcnt now exists rather than two calls to i32.popcnt, not literal duplication per se. \ud83d\udc4d \nSorry about that!. This may also have to do with different node.js versions, I had to upgrade to version 10 to get the all the tests passing. Ok should be updated!. Updated!\nIt was originally called mem yeah but with the tests some of them instantiate multiple wasm modules which means that the mem needs tob e named separately, and for now it was just easiest to append the function name (which was already unique) onto the end.. Er oops, updated!. Sure thing!. Ah sorry about that! Would it be possible to ignore the test for wasm2js mode? From a feature perspective I'm not sure how practical it'd be to support imported memories for wasm2js because the only way it'd work is to pass in a duck-typed object that looked like WebAssembly.Memory (because that can't be assumed to exist). I've posted the Windows half to https://github.com/WebAssembly/binaryen/pull/1700. A bit of a delayed response, but FWIW this looks good to go to me!. I've also got an example release from this AppVeyor build for poking around too. For someone with both push access to this repository they'll need to generate a github personal access token with at least the public_repo scope. That'll then need to be entered into AppVeyor's web UI for encrypting it, and then the value that comes out will needed to be updated in this PR. Ah ok, thanks! I can generate a token but I'd still need you (or whomever configured AppVeyor) to encrypt it. (which I think will be on this page). Oh dear this is where I've never had a great time with AppVeyor's permissions model. In theory there's someone with the \"WebAssembly\" (I think?) account on AppVeyor and in theory it somewhat connects with GitHub permissions but in practice I haven't ever figured that out.\nIf you log in to AppVeyor does the top left icon have WebAssembly under it? If not, do you know who originally set up AppVeyor?. Ah ok, I think I may be misinterpreting the URLs that I can see then! If you can see the project and poke around settings then that's all you need to be able to do. If you go to \"Settings\" on the top and then \"Encrypt YAML\" that's where a token needs to be entered and then pasted here afterwards. @kripken or @dschuff sorry for taking awhile to circle back to this, but was wondering if y'all had the chance to see if a secret can be configured for AppVeyor for this repo?. I believe it needs public_repo, yeah, and trust me I'd love to implement a better auth system which doesn't give such wide permissions to the token.... Hm I'm not sure! IIRC these came straight out of LLVM, so it may some stack manipulation or something like that. May be a good point to regenerate them. It seems like it's likely a bug! I sort of forget at this point :(. This all sounds like a great idea to me! FWIW the idea that we might implement wasm2js in Rust was primarily motivated that its maintainership here seemed to be waning. If it picks up though we're happy to help.\nI'd personally agree that asm.js isn't too important at this point for the reasons mentioned, and the only desire we'd have is that wasm2js emits an ES module (as it does today) for inclusion into apps. Eventually we'd like to include this at least as a default option (if not on by default) in pipelines like Webpack.. @kripken that sounds great! And yeah definitely agreed that the output format isn't too too important in that we can translate one way or the other as necessary. I think the polyfill approach is probably more flexible because it's how wasm is always used at the fundamental level today!. FWIW this I find suspicious in the sense that it's the same code generation for unsigned and signed integers, but it currently matches what Emscripten does and is related to https://github.com/kripken/emscripten/issues/6530. Ah yeah this is one of the \"weird hacks\" that I'd love for a better solution for. The general idea is that during --allow-asserts mode for wasm2asm needs to check the return value of functions that return a i64, but the function itself only returns the lower 32 bits and the higher 32-bits are stashed away in a global. During this mode the flag here is set which is then used to generate a function that the JS can use to extract the upper bits which can then be used to assert the right value comes out.\nThat being said if a better solution doesn't come up then this definitely warrants a comment!. Ah yeah I just found that this fixed a bug or two in some of the spec tests so I threw it in, but I'm not acutally certain whether it's necessary aftewards as well, I just assumed.. Ah I was pretty sloppy in code generation for a few of the replacements and I noticed that sometimes the js got way smaller with optimization passes so I threw it in here, but I'd be more than willing to add a flag later on if you'd prefer!. Yeah this is sort of a hack and abuse of makeName. The makeName emits the raw string into the JS without much other ado, so this needs to somehow emit two arguments in one Ref (to avoid a larger refactoring) which ends up with a hack like this. If you'd prefer I can try to figure out a way that doesn't require the hack. I think this is probably due to enabling optimizations by default, but if that's backed out this'll probably get fixed. Aha now I remember. The br_table_temp spec test fails without this. I'll investigate that later though, I've removed this change for now. Ah this is switching the alpine chroot to basically using a docker image instead. It was easier at least for me to find a Node.js image using Alpine than it was to figure out the chroot script. Functionally they're basically the same though with this alpine shim function. Ah unfortunately I think that's just a string literal with #include in it :(\n(didn't work locally). Currently the pass is run twice, before and after the i64 -> i32 lowering. The second time is due to the fact that the lowering pass can create intrinsics that weren't previously lowered. For example i64.ctz is lowered to i32.ctz, which is in turn lowered to an intrinsic.. Ah just that the way I wrote it in Rust LLVM would recognize it and emit a popcnt instruction, which is what this part was trying to avoid. I just haven't gotten around to hand-writing a wast blob to remove the need for the manual construction here. Hm it looks like somehow a different strategy will be required here, MSVC is barfing on a \"too long\" string literal in any case.. Ok I've moved this from a string literal to a file that's generated as part of the build using a giant array listed in a static. Apparently MSVC doesn't have the same limits on that! I believe CI should be green afterwards. Oh sure yeah, they're listed at https://gist.github.com/alexcrichton/e7ea67bcdd17ce4b6254e66f77165690#file-build-sh. Er oops sorry, forgot to carry over all the other related commits to this branch.... Oops sorry, forgot to pull in those commits. Sure yeah, the example here is the i64.ctz instruction. The first remove-non-js-ops pass doesn't remove it (as it doesn't have anything to lower to currently). The i64-to-i32 pass then lowers that to adding the result of i32.ctz on each half. The wasm2asm pass, however, doesn't know how to implement i32.ctz so it aborts.\nIn other words, the first pass runs to remove operations that may use i64, like the lowering of i64.div_s. The second pass then removes i64 as a type everywhere. Finally if the i64 removal injected any instructions that we still don't know what to do with they're cleaned up by remove-nonjs-ops again. Sure! I added that in https://github.com/WebAssembly/binaryen/pull/1563/commits/cefc31ae8825640cd72504f92fbf47d36864793d. Ah yeah it's basically arbitrary right now. We could add intrinsics for i64.ctz but I figured it was easiest to rely on the existing pass to split that and probably slightly more efficient codegen which calls i32.ctz twice instead of i64.ctz, and then I figured it was best to leave it all in one pass instead of splitting it off. I suppose we could organize it like that? I don't really see though how it'd be cleaner or maintainable per se than what's currently there. It seems like it'd be taking the current intrinsic injection pass and basically splitting it across two passes because it needs to happen in two locations. \nIs there a downside to running the pass twice? . I think though the only reason that this could be construed as arbitrary is in the sense that the i64.ctz intrinsic isn't lowered and instead it only lowers the i32.ctz intrinsic. If you'd prefer I could add intrinsic calls for both of those and we wouldn't have to run it twice.\nOtherwise I don't think the purpose of each pass is really that arbitrary. The i64-to-i32 pass successfully eliminates all 64-bit integers, it just panics if it hits things like division. The remove-non-js-ops successfully injects a bunch of intrinsics, it just doesn't handle everything it possibly can.\nAren't there already required orderings as well? For example if flatten isn't run before i64-to-i32 then broken code is produced?. Sure thing. Hm I'm not sure, but appveyor passed!. I added a comment as well, but NaN and Infinity aren't valid asmjs as they need to be imported explicitly through the global environment, and the names nan and infinity here I think match what emscripten does today. Ah I originally tried this and it clashed with Global, but I've done the rename and otherwise renamed usage of Global to class Global. That'll cause test failures in the test suite currently because they assert that literal asm.js compilation succeeds, but should that assertion get removed?. To me it seems like moving away from strict asm.js is probably a larger change and may want to happen in a separate PR?. The destination to call is the last operand but before this patch was evaluated first, so to force the index being called to get evaluated last this was done to hit the \"slow path\" of assigning temporaries. Ah I only described it in the commit message but I should copy here as well, but the tl;dr; is that *dst = src; in JS is somewhat special, for example foo[bar] = baz(); will evaluate the destination, foo[bar], first. Afterwards if baz() changes the foo array (such as __wasm_grow_memory()) then the original store will be completed but won't actually store to the new array.\nThis forces stores to always look like:\nval = func();\nMEM[dst] = val;\nand that way if func() changes MEM it'll still go in the right location.. I think flatten was just for helper passes, not the final code. This came up despite having flatten in the middle.\n(all the issues fixed here were fixing test failures). Indeed! And I'd be totally fine using some more official!. FWIW this code injected here is purely for the test harness, it is only used in --allow-asserts mode which is basically internal testing as I understood it?. Sure thing, added some TODO annotations!. If that's the case though the optimization possibilities aren't too important, right?. Ok, do you want me to change this to something else in the meantime?. Ok makes sense, should I change the pass ordering instead of these changes?. Oh hm I'm not sure I quite understand this comment, can you elaborate? I did want to be sure to emit the new ESM output by default, though!. Sounds good to me! Unfortunately though I'm pretty unfamiliar with C++ templates, and that change generates:\nFAILED: /usr/bin/clang++    -Isrc -std=c++11 -Wall -Werror -Wextra -Wno-unused-parameter -fno-omit-frame-pointer -fPIC -fcolor-diagnostics -O3 -DNDEBUG -O2 -UNDEBUG   -std=gnu++11 -MD -MT CMakeFiles/wasm2js.dir/src/tools/wasm2js.cpp.o -MF CMakeFiles/wasm2js.dir/src/tools/wasm2js.cpp.o.d -o CMakeFiles/wasm2js.dir/src/tools/wasm2js.cpp.o -c src/tools/wasm2js.cpp\nIn file included from src/tools/wasm2js.cpp:25:\nsrc/wasm2js.h:78:29: error: use 'template' keyword to treat 'dynCast' as a dependent template name\n  auto* c = segment.offset->dynCast<Const>();\n                            ^\n                            template \n1 error generated.\ndo you know how that could be resolved?. Oh nice! This sort of plays into the question though I think of what to do with all the old output. In the wast mode it supports the --allow-asserts option which parses the remaining s-expressions and needs the original parser (e.g. can't use ModuleReader).\nI wasn't really sure what to do with all the old tests that actually exercise wasm2asm, the new ESM output isn't compatible with spidermonkey I think and is only compatible with experimental node.js, so it makes it a bit more difficult to test (but perhaps not impossible!).\nDo you have a preferred method of how this is handled? At the very least it seems definitely worthwhile to have a comment here explaining what's going on, but you may know of a better way to handle all this!. Oh this was the if (!flags.onlyAsmjsWrapper) checks added to src/wasm2asm.h. Basically this is keeping compatibility with the old test suite by ensuring that all the tests disable the ESM output. Ah ok, makes sense!\nDo you know of a good way to blacklist test for wasm2js in the test suite? I remember now after doing this again that the first failure I hit was:\nexecuting:  bin/wasm2js test/empty_imported_table.wast\nFatal: non-function imports aren't supported yet\nwhich makes sense in that wasm2js doesn't work with an imported function table right now, but that test is explicitly testing an imported function table!. I think this may be indented one level too deep. I think this may also need to be de-indented by one. This'll need to be filled in with an actual value before merging!. True! The use case in https://github.com/WebAssembly/binaryen/issues/1695 was motivated by downloading precompiled binaries programmatically and it's easier to download one format vs two for us at least. I don't personally know the invocation to create a zip file, but it should be easy to make both if needed!. ",
    "benvanik": "Any chance of this landing? It'd be nice to not export the world :)\n. That makes sense - tests are good :)\nToday wasm-opt can't do any dead function elimination and almost all inlining is prevented on code coming from clang, as s2wasm acting as the linker pins everything as an export. With this PR patched in my binaries get much much better.\nDo you see the flow (clang -> s2wasm -> wasm-opt -> wasm-as) changing with LLVM? (guessing maybe clang -> lld -> wasm-opt -> wasm-as?) If lld does the linking and wasm-opt only ever sees things that really are exported that seems fine (I'm assuming from what I've seen discussed that wasm-opt is still used in that flow instead of/in addition-to the llvm optimizer - is that correct?)\n. ",
    "guybedford": "Perhaps this would be worth landing behind a command line flag, if there is reservation to merging this? That way we can at least start running with the use cases. I'd really like to adopt this approach in my own compilation test workflows.. @sunfishcode thanks so much for your response, is https://github.com/llvm-mirror/clang/blob/master/test/Driver/wasm-toolchain.c the best place to start to try and follow this direct wasm output from llvm?. I just got this error on the latest LLVM (built from source as of May 19 with wasm target) compiling C++ with s2wasm.\n<< _ZTVN7esprima8PoolableE >>\n[[bad mustMatch:]]:\n==========\n.weak   _ZTVN7esprima8PoolableE\n    .p2align    2\n_ZTVN7esprima8Pool\n==========\nAbort trap: 6\nany suggestions at all re a debugging approach here?. I found that removing the .weak  _ZTVN7esprima8PoolableE line in the above fixes the s2wasm error.. Potentially for importing a pre-built wasm library from wasm, but a better example might be loading a js function (say a logger) where we know it already exists in a compiled form in js. The function name can come from the same name as the c function, although a custom symbol could be provided for that as well, but I'm not sure it's strictly necessary flexibility.\nIt's just about controlling the 'env' name when it is known to be another resolution during the linking process, to get some analog to c-style static library linking.\nLet me know if that makes sense?. The example workflow would replace 'env' in the output with './custom-logger.wasm' (should really use '.js' in the example though), where 'void custom_logger(int val)' is a function definition only.. To clarify the exact workflow, the idea is that the following:\nc\nvoid custom_logger(int val) __attribute__ ((import, name (\"./custom-logger.js\")));\nwhere custom_logger is treated as an external symbol, provides the WAST output:\n(import \"./custom-logger.js\" \"custom_logger\" (func $custom_logger (param i32)))\nThe process of setting this env path could be an option somewhere in the workflow as well, it just seemed like an attribute carried through the chain of tooling the easiest from what I could tell.. @sunfishcode I'd be interested to hear your feedback here if you can. It's just about ensuring we have the tools for managing this compilation boundary down to the runtime semantics, in whatever form.. To give some background, I'm the author of SystemJS and node-es-module-loader, both of which provide the ability to load WASM modules alongside ES modules in the browser and NodeJS respectively.\nAs I've been experimenting with build tooling for WASM, I've been defining this boundary by using visibility attributes on functions exactly as in the #585 approach which works perfectly to my needs, and then this exactly handles the module name component.\nCertainly this is a process that should be handled by the linker and overall build tooling, where the resolution should be determined by the tool - so an attribute shouldn't necessarily be used directly by end-users... but if the attribute were to be supported through the toolchain, that would then enable a path for the linker tooling to use this attribute to communicate to LLVM potentially? Then it just happens to provide a path forward for tooling today.\nSo my question is - does a function attribute make sense as the unit of management for link tooling in future, and if not, what other mechanism might there be?. The linker in C/C++ is well-established such that resolving a symbol can be assumed a standard protocol. We don't have this same thing in the world of the JS/WASM runtime - rather we have NodeJS module resolution and browser module resolution, and then compilers and build tools all have their own configurations and options for customizing this module resolution.\nI think it will be important for LLVM to be able to serve this need for WASM compilations to be able to fit into the JS ecosystem in this way. This would mean accepting that LLVM shouldn't be a source of truth for determining the output import names, but rather should allow these to be tuned from tools that drive the process around LLVM. It is possible in JS (and likely also in WASM) to build modules without even having external modules present at build time as we don't need binary information as the export interface is already clear.\nA function attribute would lend itself well to being driven through tooling, alternatively some ability to provide a manifest describing the import boundary and what import names should be emitted.\nI really think some path here is needed, and it would be great to see how progress can be made. I'd be interested to hear further what would be the best way to go about this, whether is it being taken care of, is it not yet necessary or ready, or if can I assist in any way?. So the assumption I'm running on here is that we would be able to load WASM alongside ES modules  in both NodeJS and the browser via\njs\nimport {fn} from './file.wasm';\nexport function thing () {\n  return fn();\n}\n, with WASM in turn loading JS and other WASM imports using the same loader resolution process, which seems to be a discussed direction in the WASM docs.\nThe general workflow for JS apps is to start with something that loads based on the NodeJS module resolution system, then to build that into an optimized browser build. It's pretty clear that this heavily ingrained approach is not going to be changing at all easily at least.\nSay I'm a library author writing a piece of JS code I want to publish to npm, which has a part of itself written in WASM, and the WASM also imports from JS. In writing the WASM file that imports a local JS file, I would want to be sure that the import specifier in file.wasm is loading ./wasm-dep.js from the same folder.\nSo assuming this kind of JS/WASM module loading integration in browser and in Node (which, while I understand the dynamic WebAssembly.instantiate will always be supported, enables easier portable protocols for integration into Node and the browser), the only information needed is the ability to control this output module specifier to control the JS/WASM static import boundary. Even if my library is built using some magical new language build tool compiling to JS and WASM, if I want to publish portable code to npm, that tool would likely also want the ability to set this module name in order to provide portable library interfaces from WASM.\nFor browser optimization a build tool will then take that combined tree and perform optimizations, including perhaps mangling and altering module names and resolutions for the JS/WASM interface boundaries, but this process would at this point likely be independent of LLVM, at least initially in any tooling that would be developed for this. So the main use case that applies initially I think is the one of creating portable libraries for publishing to npm or browser CDNs.. To answer the other question, for the Node v browser code distinction, the standard process it to provide separate entry points into the app (main and browser configured in package.json), then to rely on static dead code ellimination from inlining conditions like if (typeof window !== 'undefined') require('browser-code');. Variations on these themes will likely naturally scale to the WASM/ES module contracts for builds between Node and browser.. Yes exactly, this is very much for tool wrapping headers or in the bc / s files, assuming we have this ES module / WASM module loader integration.\nIt's a little wider though as even at the development phase there is a need to want to control the module specifier - so it would even be part of my process as an app developer, building C into wasm with the right names.\nThere may also be cases where shared C/C++ libraries want to hard-code these specifier names. Say if the C/C++ library wanted to specify a dependency on a WASM npm library from npm itself, for the \"wasm architecture\" case, it could hard code that dependency from C as a plain specifier like c-lib/x, but mostly tooling injections would likely be the workflow I'd expect.. Just noticed it seems like this is a duplicate of the discussion in https://github.com/WebAssembly/binaryen/issues/585.. It sounds like https://github.com/WebAssembly/binaryen/pull/587 would exactly handle this actually... moving comments to there.. https://github.com/WebAssembly/binaryen/pull/587 may also resolve this issue, but I haven't tested this further.. #587 didn't help, it seems something about the free name is reserved. Changing the name fixed this - I wouldn't worry too much about it further as it is a bad name to use publicly anyway.. @pipcet thanks I managed to get the s2wasm tests to pass that way. ~~Although I still get:~~\nbuild:  /usr/bin/gcc /Users/guybedford/Projects/binaryen/test/example/c-api-hello-world.c -c -o example.o -I/Users/guybedford/Projects/binaryen/src -g -Lbin/../lib -pthread\nclang: warning: argument unused during compilation: '-Lbin/../lib'\n   c-api-hello-world.c /Users/guybedford/Projects/binaryen/test/example/c-api-hello-world.c /Users/guybedford/Projects/binaryen/test/example/c-api-hello-world.txt\nlink:  /usr/bin/g++ -std=c++11 example.o -lbinaryen -I/Users/guybedford/Projects/binaryen/src -g -lasmjs -lsupport -Lbin/../lib -pthread -o bin/example -Wl,-rpath=$ORIGIN/../lib\nclang: warning: argument unused during compilation: '-pthread'\nld: unknown option: -rpath=$ORIGIN/../lib\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nTraceback (most recent call last):\n  File \"./check.py\", line 455, in <module>\n    os.remove(output_file)\nOSError: [Errno 2] No such file or directory: 'bin/example'\n~~at the end of the test run.~~\n(The above is just my local setup obviously).... ",
    "bobvanluijt": "Thanks @kripken \nYou mention that I would get a test.asm.js if I added the binaryen flag, but -s BINARYEN=1 is that flag, right? Or else, how would I add the binaryen flag to the emcc command?\n. Aha, and this should be the emcc from the incoming branch, right?\n. Awesome, one last question. I don't seem to be able to find 3.9.0, the latest available is 3.8.0 http://llvm.org/releases/\n. ",
    "lqd": "Confirmed fixed by #595 :+1: \n. Ok so I've retested, the binaryen-shell crash is now indeed gone.\nSo, to sum up the \"issue\" if you can call it that: it seems there's a difference between what I was able to validate with BinaryenModuleValidate, which then failed validation with binaryen-shell.\nThis was generated by BinaryenModulePrint after a successful BinaryenModuleValidate :\n\nclojure\n(module\n  (memory 1 1)\n  (start $__wasm_start)\n  (type $print_i32 (func (param i32)))\n  (type $rustfn-0-6 (func (param i32)))\n  (type $rustfn-0-126 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-2 (func))\n  (type $__wasm_start (func))\n  (type $rustfn-0-12 (func))\n  (type $rustfn-0-11 (func (param i32)))\n  (type $rustfn-0-49 (func (param i32) (result i32)))\n  (type $rustfn-0-57 (func (param i32) (result i32)))\n  (type $rustfn-0-175 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-68 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-159 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-72 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-112 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-119 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-133 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-144 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-195 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-179 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-147 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-151 (func (param i32 i32) (result i32)))\n  (type $rustfn-0-155 (func (param i32 i32) (result i32)))\n  (import $print_i32 \"spectest\" \"print\" (param i32))\n  (func $wasm::print_i32 (type $rustfn-0-6) (param $0 i32)\n    (local $1 i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (block\n      (set_local $4\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $1\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (call_import $print_i32\n            (get_local $3)\n          )\n          (set_local $2\n            (i32.const -1)\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (i32.store\n            (i32.const 0)\n            (get_local $4)\n          )\n          (return\n            (get_local $4)\n          )\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialEq_for_i32_::eq (type $rustfn-0-126) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.eq\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialEq_for_i32_::ne (type $rustfn-0-126) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.ne\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_i32_::lt (type $rustfn-0-126) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.lt_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_i32_::le (type $rustfn-0-126) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.le_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_i32_::gt (type $rustfn-0-126) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.gt_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_i32_::ge (type $rustfn-0-126) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.ge_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $main (type $rustfn-0-2)\n    (local $0 i32)\n    (local $1 i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (local $13 i32)\n    (local $14 i32)\n    (local $15 i32)\n    (local $16 i32)\n    (local $17 i32)\n    (local $18 i32)\n    (local $19 i32)\n    (local $20 i32)\n    (local $21 i32)\n    (local $22 i32)\n    (local $23 i32)\n    (local $24 i32)\n    (local $25 i32)\n    (local $26 i32)\n    (local $27 i32)\n    (local $28 i32)\n    (local $29 i32)\n    (local $30 i32)\n    (local $31 i32)\n    (local $32 i32)\n    (local $33 i32)\n    (local $34 i32)\n    (local $35 i32)\n    (local $36 i32)\n    (local $37 i32)\n    (local $38 i32)\n    (local $39 i32)\n    (local $40 i32)\n    (local $41 i32)\n    (local $42 i32)\n    (local $43 i32)\n    (local $44 i32)\n    (local $45 i32)\n    (local $46 i32)\n    (local $47 i32)\n    (local $48 i32)\n    (local $49 i32)\n    (local $50 i32)\n    (local $51 i32)\n    (local $52 i32)\n    (local $53 i32)\n    (local $54 i32)\n    (local $55 i32)\n    (local $56 i32)\n    (local $57 i32)\n    (local $58 i32)\n    (local $59 i32)\n    (local $60 i32)\n    (local $61 i32)\n    (local $62 i32)\n    (local $63 i32)\n    (local $64 i32)\n    (local $65 i32)\n    (local $66 i32)\n    (local $67 i32)\n    (local $68 i32)\n    (local $69 i32)\n    (block\n      (set_local $69\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $0\n            (i32.const 0)\n          )\n          (set_local $1\n            (i32.const 1)\n          )\n          (set_local $5\n            (get_local $0)\n          )\n          (set_local $6\n            (get_local $1)\n          )\n          (set_local $4\n            (i32.eq\n              (get_local $5)\n              (get_local $6)\n            )\n          )\n          (set_local $3\n            (get_local $4)\n          )\n          (call $wasm::print_i32\n            (get_local $3)\n          )\n          (set_local $2\n            (i32.const -1)\n          )\n        )\n      )\n      (block\n        (block\n          (block $bb1\n            (set_local $10\n              (get_local $0)\n            )\n            (set_local $12\n              (get_local $1)\n            )\n            (set_local $11\n              (get_local $12)\n            )\n            (set_local $9\n              (call $impls::_impl_PartialEq_for_i32_::eq\n                (get_local $10)\n                (get_local $11)\n              )\n            )\n          )\n        )\n        (block\n          (block\n            (block $bb2\n              (set_local $8\n                (get_local $9)\n              )\n              (call $wasm::print_i32\n                (get_local $8)\n              )\n              (set_local $7\n                (i32.const -1)\n              )\n            )\n          )\n          (block\n            (block\n              (block $bb3\n                (set_local $16\n                  (get_local $0)\n                )\n                (set_local $17\n                  (get_local $1)\n                )\n                (set_local $15\n                  (i32.ne\n                    (get_local $16)\n                    (get_local $17)\n                  )\n                )\n                (set_local $14\n                  (get_local $15)\n                )\n                (call $wasm::print_i32\n                  (get_local $14)\n                )\n                (set_local $13\n                  (i32.const -1)\n                )\n              )\n            )\n            (block\n              (block\n                (block $bb4\n                  (set_local $21\n                    (get_local $0)\n                  )\n                  (set_local $23\n                    (get_local $1)\n                  )\n                  (set_local $22\n                    (get_local $23)\n                  )\n                  (set_local $20\n                    (call $impls::_impl_PartialEq_for_i32_::ne\n                      (get_local $21)\n                      (get_local $22)\n                    )\n                  )\n                )\n              )\n              (block\n                (block\n                  (block $bb5\n                    (set_local $19\n                      (get_local $20)\n                    )\n                    (call $wasm::print_i32\n                      (get_local $19)\n                    )\n                    (set_local $18\n                      (i32.const -1)\n                    )\n                  )\n                )\n                (block\n                  (block\n                    (block $bb6\n                      (set_local $27\n                        (get_local $0)\n                      )\n                      (set_local $28\n                        (get_local $1)\n                      )\n                      (set_local $26\n                        (i32.lt_s\n                          (get_local $27)\n                          (get_local $28)\n                        )\n                      )\n                      (set_local $25\n                        (get_local $26)\n                      )\n                      (call $wasm::print_i32\n                        (get_local $25)\n                      )\n                      (set_local $24\n                        (i32.const -1)\n                      )\n                    )\n                  )\n                  (block\n                    (block\n                      (block $bb7\n                        (set_local $32\n                          (get_local $0)\n                        )\n                        (set_local $34\n                          (get_local $1)\n                        )\n                        (set_local $33\n                          (get_local $34)\n                        )\n                        (set_local $31\n                          (call $impls::_impl_PartialOrd_for_i32_::lt\n                            (get_local $32)\n                            (get_local $33)\n                          )\n                        )\n                      )\n                    )\n                    (block\n                      (block\n                        (block $bb8\n                          (set_local $30\n                            (get_local $31)\n                          )\n                          (call $wasm::print_i32\n                            (get_local $30)\n                          )\n                          (set_local $29\n                            (i32.const -1)\n                          )\n                        )\n                      )\n                      (block\n                        (block\n                          (block $bb9\n                            (set_local $38\n                              (get_local $0)\n                            )\n                            (set_local $39\n                              (get_local $1)\n                            )\n                            (set_local $37\n                              (i32.le_s\n                                (get_local $38)\n                                (get_local $39)\n                              )\n                            )\n                            (set_local $36\n                              (get_local $37)\n                            )\n                            (call $wasm::print_i32\n                              (get_local $36)\n                            )\n                            (set_local $35\n                              (i32.const -1)\n                            )\n                          )\n                        )\n                        (block\n                          (block\n                            (block $bb10\n                              (set_local $43\n                                (get_local $0)\n                              )\n                              (set_local $45\n                                (get_local $1)\n                              )\n                              (set_local $44\n                                (get_local $45)\n                              )\n                              (set_local $42\n                                (call $impls::_impl_PartialOrd_for_i32_::le\n                                  (get_local $43)\n                                  (get_local $44)\n                                )\n                              )\n                            )\n                          )\n                          (block\n                            (block\n                              (block $bb11\n                                (set_local $41\n                                  (get_local $42)\n                                )\n                                (call $wasm::print_i32\n                                  (get_local $41)\n                                )\n                                (set_local $40\n                                  (i32.const -1)\n                                )\n                              )\n                            )\n                            (block\n                              (block\n                                (block $bb12\n                                  (set_local $49\n                                    (get_local $0)\n                                  )\n                                  (set_local $50\n                                    (get_local $1)\n                                  )\n                                  (set_local $48\n                                    (i32.gt_s\n                                      (get_local $49)\n                                      (get_local $50)\n                                    )\n                                  )\n                                  (set_local $47\n                                    (get_local $48)\n                                  )\n                                  (call $wasm::print_i32\n                                    (get_local $47)\n                                  )\n                                  (set_local $46\n                                    (i32.const -1)\n                                  )\n                                )\n                              )\n                              (block\n                                (block\n                                  (block $bb13\n                                    (set_local $54\n                                      (get_local $0)\n                                    )\n                                    (set_local $56\n                                      (get_local $1)\n                                    )\n                                    (set_local $55\n                                      (get_local $56)\n                                    )\n                                    (set_local $53\n                                      (call $impls::_impl_PartialOrd_for_i32_::gt\n                                        (get_local $54)\n                                        (get_local $55)\n                                      )\n                                    )\n                                  )\n                                )\n                                (block\n                                  (block\n                                    (block $bb14\n                                      (set_local $52\n                                        (get_local $53)\n                                      )\n                                      (call $wasm::print_i32\n                                        (get_local $52)\n                                      )\n                                      (set_local $51\n                                        (i32.const -1)\n                                      )\n                                    )\n                                  )\n                                  (block\n                                    (block\n                                      (block $bb15\n                                        (set_local $60\n                                          (get_local $0)\n                                        )\n                                        (set_local $61\n                                          (get_local $1)\n                                        )\n                                        (set_local $59\n                                          (i32.ge_s\n                                            (get_local $60)\n                                            (get_local $61)\n                                          )\n                                        )\n                                        (set_local $58\n                                          (get_local $59)\n                                        )\n                                        (call $wasm::print_i32\n                                          (get_local $58)\n                                        )\n                                        (set_local $57\n                                          (i32.const -1)\n                                        )\n                                      )\n                                    )\n                                    (block\n                                      (block\n                                        (block $bb16\n                                          (set_local $65\n                                            (get_local $0)\n                                          )\n                                          (set_local $67\n                                            (get_local $1)\n                                          )\n                                          (set_local $66\n                                            (get_local $67)\n                                          )\n                                          (set_local $64\n                                            (call $impls::_impl_PartialOrd_for_i32_::ge\n                                              (get_local $65)\n                                              (get_local $66)\n                                            )\n                                          )\n                                        )\n                                      )\n                                      (block\n                                        (block\n                                          (block $bb17\n                                            (set_local $63\n                                              (get_local $64)\n                                            )\n                                            (call $wasm::print_i32\n                                              (get_local $63)\n                                            )\n                                            (set_local $62\n                                              (i32.const -1)\n                                            )\n                                          )\n                                        )\n                                        (block\n                                          (block $bb18\n                                            (i32.store\n                                              (i32.const 0)\n                                              (get_local $69)\n                                            )\n                                            (return\n                                              (get_local $68)\n                                            )\n                                          )\n                                        )\n                                      )\n                                    )\n                                  )\n                                )\n                              )\n                            )\n                          )\n                        )\n                      )\n                    )\n                  )\n                )\n              )\n            )\n          )\n        )\n      )\n    )\n  )\n  (func $__wasm_start (type $__wasm_start)\n    (i32.store\n      (i32.const 0)\n      (i32.const 65535)\n    )\n    (call $main)\n  )\n  (func $panic_fmt (type $rustfn-0-12)\n    (local $0 i32)\n    (local $1 i32)\n    (local $2 i32)\n    (block\n      (set_local $2\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n        )\n      )\n      (loop $shape$2$break $shape$2$continue\n        (block $bb1\n        )\n        (block\n          (br $shape$2$continue)\n        )\n      )\n    )\n  )\n  (func $panic (type $rustfn-0-11) (param $0 i32)\n    (local $1 i32)\n    (local $2 i32)\n    (block\n      (set_local $1\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n      )\n    )\n  )\n  (func $_Ordering_as_clone::Clone_::clone (type $rustfn-0-49) (param $0 i32) (result i32)\n    (local $1 i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $1\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $2\n            (i32.store\n              (i32.const 0)\n              (i32.sub\n                (i32.load\n                  (i32.const 0)\n                )\n                (i32.const 32)\n              )\n            )\n          )\n          (i32.store\n            (i32.load\n              (i32.const 0)\n            )\n            (get_local $3)\n          )\n          (set_local $4\n            (get_local $1)\n          )\n          (set_local $5\n            (get_local $4)\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (i32.store\n            (i32.const 0)\n            (get_local $6)\n          )\n          (return\n            (get_local $5)\n          )\n        )\n      )\n    )\n  )\n  (func $Ordering::reverse (type $rustfn-0-57) (param $0 i32) (result i32)\n    (local $1 i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (block\n      (set_local $3\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $1\n            (get_local $0)\n          )\n        )\n        (block $shape$2$break\n          (block $switch$1$leave\n            (block $switch$1$default\n              (block $switch$1$case$4\n                (block $switch$1$case$3\n                  (br_table $switch$1$case$3 $switch$1$case$4 $switch$1$default\n                    (i32.load8_u\n                      (get_local $1)\n                    )\n                  )\n                )\n                (block\n                  (block\n                    (block $bb2\n                      (set_local $2\n                        (i64.const 0)\n                      )\n                    )\n                    (block\n                      (br $shape$2$break)\n                    )\n                  )\n                )\n                (br $switch$1$leave)\n              )\n              (block\n                (block\n                  (block $bb3\n                    (set_local $2\n                      (i64.const -1)\n                    )\n                  )\n                  (block\n                    (br $shape$2$break)\n                  )\n                )\n              )\n              (br $switch$1$leave)\n            )\n            (block\n              (block\n                (block $bb1\n                  (set_local $2\n                    (i64.const 1)\n                  )\n                )\n                (block\n                  (br $shape$2$break)\n                )\n              )\n            )\n            (br $switch$1$leave)\n          )\n        )\n      )\n      (block\n        (block $bb4\n          (i32.store\n            (i32.const 0)\n            (get_local $3)\n          )\n          (return\n            (get_local $2)\n          )\n        )\n      )\n    )\n  )\n  (func $impls::_impl_Ord_for_i32_::cmp (type $rustfn-0-175) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (block\n      (set_local $10\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $5\n            (get_local $2)\n          )\n          (set_local $6\n            (get_local $3)\n          )\n          (set_local $4\n            (i32.eq\n              (get_local $5)\n              (get_local $6)\n            )\n          )\n        )\n        (block $shape$2$break\n          (if\n            (get_local $4)\n            (block\n              (block $bb1\n                (set_local $10\n                  (i64.const 0)\n                )\n              )\n              (block\n                (br $shape$2$break)\n              )\n            )\n            (block\n              (block $bb2\n                (set_local $8\n                  (get_local $2)\n                )\n                (set_local $9\n                  (get_local $3)\n                )\n                (set_local $7\n                  (i32.lt_s\n                    (get_local $8)\n                    (get_local $9)\n                  )\n                )\n              )\n              (block $shape$5$break\n                (if\n                  (get_local $7)\n                  (block\n                    (block $bb3\n                      (set_local $10\n                        (i64.const -1)\n                      )\n                    )\n                    (block\n                      (br $shape$2$break)\n                    )\n                  )\n                  (block\n                    (block $bb4\n                      (set_local $10\n                        (i64.const 1)\n                      )\n                    )\n                    (block\n                      (br $shape$2$break)\n                    )\n                  )\n                )\n              )\n            )\n          )\n        )\n      )\n      (block\n        (block $bb5\n          (i32.store\n            (i32.const 0)\n            (get_local $10)\n          )\n          (return\n            (get_local $10)\n          )\n        )\n      )\n    )\n  )\n  (func $_Ordering_as_Ord_::cmp (type $rustfn-0-68) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (local $13 i32)\n    (block\n      (set_local $11\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $6\n            (get_local $2)\n          )\n          (set_local $5\n            (i32.load8_u\n              (get_local $6)\n            )\n          )\n          (set_local $4\n            (get_local $5)\n          )\n          (set_local $10\n            (get_local $3)\n          )\n          (set_local $9\n            (i32.load8_u\n              (get_local $10)\n            )\n          )\n          (set_local $8\n            (get_local $9)\n          )\n          (set_local $7\n            (get_local $8)\n          )\n          (set_local $11\n            (call $impls::_impl_Ord_for_i32_::cmp\n              (get_local $4)\n              (get_local $7)\n            )\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (i32.store\n            (i32.const 0)\n            (get_local $11)\n          )\n          (return\n            (get_local $11)\n          )\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_i32_::partial_cmp (type $rustfn-0-159) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (block\n      (set_local $7\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $5\n            (get_local $2)\n          )\n          (set_local $6\n            (get_local $3)\n          )\n          (set_local $4\n            (call $impls::_impl_Ord_for_i32_::cmp\n              (get_local $5)\n              (get_local $6)\n            )\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (set_local $7\n            (i32.store\n              (i32.const 0)\n              (i32.sub\n                (i32.load\n                  (i32.const 0)\n                )\n                (i32.const 16)\n              )\n            )\n          )\n          (i32.store8\n            (i32.load\n              (i32.const 0)\n            )\n            (i32.const 1)\n          )\n          (i32.store offset=8\n            (i32.load\n              (i32.const 0)\n            )\n            (get_local $4)\n          )\n          (i32.store\n            (i32.const 0)\n            (get_local $7)\n          )\n          (return\n            (get_local $7)\n          )\n        )\n      )\n    )\n  )\n  (func $_Ordering_as_PartialOrd_::partial_cmp (type $rustfn-0-72) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (local $13 i32)\n    (block\n      (set_local $11\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $6\n            (get_local $2)\n          )\n          (set_local $5\n            (i32.load8_u\n              (get_local $6)\n            )\n          )\n          (set_local $4\n            (get_local $5)\n          )\n          (set_local $10\n            (get_local $3)\n          )\n          (set_local $9\n            (i32.load8_u\n              (get_local $10)\n            )\n          )\n          (set_local $8\n            (get_local $9)\n          )\n          (set_local $7\n            (get_local $8)\n          )\n          (set_local $11\n            (call $impls::_impl_PartialOrd_for_i32_::partial_cmp\n              (get_local $4)\n              (get_local $7)\n            )\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (i32.store\n            (i32.const 0)\n            (get_local $11)\n          )\n          (return\n            (get_local $11)\n          )\n        )\n      )\n    )\n  )\n  (func \"$impls::_impl_PartialEq_for_()_::eq\" (type $rustfn-0-112) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (block\n      (set_local $4\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (i32.const 1)\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $4)\n        )\n        (return\n          (get_local $4)\n        )\n      )\n    )\n  )\n  (func \"$impls::_impl_PartialEq_for_()_::ne\" (type $rustfn-0-112) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (block\n      (set_local $4\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (i32.const 0)\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $4)\n        )\n        (return\n          (get_local $4)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialEq_for_bool_::eq (type $rustfn-0-119) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.eq\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialEq_for_bool_::ne (type $rustfn-0-119) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.ne\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialEq_for_u8_::eq (type $rustfn-0-133) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.eq\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialEq_for_u8_::ne (type $rustfn-0-133) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.ne\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func \"$impls::_impl_PartialOrd_for_()_::partial_cmp\" (type $rustfn-0-144) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (block\n      (set_local $4\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (i64.const 0)\n        )\n        (set_local $4\n          (i32.store\n            (i32.const 0)\n            (i32.sub\n              (i32.load\n                (i32.const 0)\n              )\n              (i32.const 16)\n            )\n          )\n        )\n        (i32.store8\n          (i32.load\n            (i32.const 0)\n          )\n          (i32.const 1)\n        )\n        (i32.store offset=8\n          (i32.load\n            (i32.const 0)\n          )\n          (get_local $3)\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $4)\n        )\n        (return\n          (get_local $4)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_Ord_for_u8_::cmp (type $rustfn-0-195) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (block\n      (set_local $10\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $5\n            (get_local $2)\n          )\n          (set_local $6\n            (get_local $3)\n          )\n          (set_local $4\n            (i32.eq\n              (get_local $5)\n              (get_local $6)\n            )\n          )\n        )\n        (block $shape$2$break\n          (if\n            (get_local $4)\n            (block\n              (block $bb1\n                (set_local $10\n                  (i64.const 0)\n                )\n              )\n              (block\n                (br $shape$2$break)\n              )\n            )\n            (block\n              (block $bb2\n                (set_local $8\n                  (get_local $2)\n                )\n                (set_local $9\n                  (get_local $3)\n                )\n                (set_local $7\n                  (i32.lt_s\n                    (get_local $8)\n                    (get_local $9)\n                  )\n                )\n              )\n              (block $shape$5$break\n                (if\n                  (get_local $7)\n                  (block\n                    (block $bb3\n                      (set_local $10\n                        (i64.const -1)\n                      )\n                    )\n                    (block\n                      (br $shape$2$break)\n                    )\n                  )\n                  (block\n                    (block $bb4\n                      (set_local $10\n                        (i64.const 1)\n                      )\n                    )\n                    (block\n                      (br $shape$2$break)\n                    )\n                  )\n                )\n              )\n            )\n          )\n        )\n      )\n      (block\n        (block $bb5\n          (i32.store\n            (i32.const 0)\n            (get_local $10)\n          )\n          (return\n            (get_local $10)\n          )\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_u8_::partial_cmp (type $rustfn-0-179) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (block\n      (set_local $7\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $5\n            (get_local $2)\n          )\n          (set_local $6\n            (get_local $3)\n          )\n          (set_local $4\n            (call $impls::_impl_Ord_for_u8_::cmp\n              (get_local $5)\n              (get_local $6)\n            )\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (set_local $7\n            (i32.store\n              (i32.const 0)\n              (i32.sub\n                (i32.load\n                  (i32.const 0)\n                )\n                (i32.const 16)\n              )\n            )\n          )\n          (i32.store8\n            (i32.load\n              (i32.const 0)\n            )\n            (i32.const 1)\n          )\n          (i32.store offset=8\n            (i32.load\n              (i32.const 0)\n            )\n            (get_local $4)\n          )\n          (i32.store\n            (i32.const 0)\n            (get_local $7)\n          )\n          (return\n            (get_local $7)\n          )\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_bool_::partial_cmp (type $rustfn-0-147) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (local $13 i32)\n    (block\n      (set_local $11\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $6\n            (get_local $2)\n          )\n          (set_local $5\n            (get_local $6)\n          )\n          (set_local $4\n            (get_local $5)\n          )\n          (set_local $10\n            (get_local $3)\n          )\n          (set_local $9\n            (get_local $10)\n          )\n          (set_local $8\n            (get_local $9)\n          )\n          (set_local $7\n            (get_local $8)\n          )\n          (set_local $11\n            (call $impls::_impl_PartialOrd_for_u8_::partial_cmp\n              (get_local $4)\n              (get_local $7)\n            )\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (i32.store\n            (i32.const 0)\n            (get_local $11)\n          )\n          (return\n            (get_local $11)\n          )\n        )\n      )\n    )\n  )\n  (func \"$impls::_impl_Ord_for_()_::cmp\" (type $rustfn-0-151) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (block\n      (set_local $4\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (i64.const 0)\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $4)\n        )\n        (return\n          (get_local $4)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_Ord_for_bool_::cmp (type $rustfn-0-155) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (local $9 i32)\n    (local $10 i32)\n    (local $11 i32)\n    (local $12 i32)\n    (local $13 i32)\n    (block\n      (set_local $11\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block\n        (block $bb0\n          (set_local $2\n            (get_local $0)\n          )\n          (set_local $3\n            (get_local $1)\n          )\n          (set_local $6\n            (get_local $2)\n          )\n          (set_local $5\n            (get_local $6)\n          )\n          (set_local $4\n            (get_local $5)\n          )\n          (set_local $10\n            (get_local $3)\n          )\n          (set_local $9\n            (get_local $10)\n          )\n          (set_local $8\n            (get_local $9)\n          )\n          (set_local $7\n            (get_local $8)\n          )\n          (set_local $11\n            (call $impls::_impl_Ord_for_u8_::cmp\n              (get_local $4)\n              (get_local $7)\n            )\n          )\n        )\n      )\n      (block\n        (block $bb1\n          (i32.store\n            (i32.const 0)\n            (get_local $11)\n          )\n          (return\n            (get_local $11)\n          )\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_u8_::lt (type $rustfn-0-133) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.lt_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_u8_::le (type $rustfn-0-133) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.le_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_u8_::ge (type $rustfn-0-133) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.ge_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n  (func $impls::_impl_PartialOrd_for_u8_::gt (type $rustfn-0-133) (param $0 i32) (param $1 i32) (result i32)\n    (local $2 i32)\n    (local $3 i32)\n    (local $4 i32)\n    (local $5 i32)\n    (local $6 i32)\n    (local $7 i32)\n    (local $8 i32)\n    (block\n      (set_local $6\n        (i32.load\n          (i32.const 0)\n        )\n      )\n    )\n    (block\n      (block $bb0\n        (set_local $2\n          (get_local $0)\n        )\n        (set_local $3\n          (get_local $1)\n        )\n        (set_local $4\n          (get_local $2)\n        )\n        (set_local $5\n          (get_local $3)\n        )\n        (set_local $6\n          (i32.gt_s\n            (get_local $4)\n            (get_local $5)\n          )\n        )\n        (i32.store\n          (i32.const 0)\n          (get_local $6)\n        )\n        (return\n          (get_local $6)\n        )\n      )\n    )\n  )\n)\n\nHowever it doesn't pass binaryen-shell validation, giving those errors:\n\n[wasm-validator error in function $Ordering::reverse] 2 != 1: set_local type must be correct, on\n(set_local $2\n  (i64.const 0)\n)\n[wasm-validator error in function $Ordering::reverse] 2 != 1: set_local type must be correct, on\n(set_local $2\n  (i64.const -1)\n)\n[wasm-validator error in function $Ordering::reverse] 2 != 1: set_local type must be correct, on\n(set_local $2\n  (i64.const 1)\n)\n[wasm-validator error in function $impls::_impl_Ord_for_i32_::cmp] 2 != 1: set_local type must be correct, on\n(set_local $10\n  (i64.const 0)\n)\n[wasm-validator error in function $impls::_impl_Ord_for_i32_::cmp] 2 != 1: set_local type must be correct, on\n(set_local $10\n  (i64.const -1)\n)\n[wasm-validator error in function $impls::_impl_Ord_for_i32_::cmp] 2 != 1: set_local type must be correct, on\n(set_local $10\n  (i64.const 1)\n)\n[wasm-validator error in function $23] 2 != 1: set_local type must be correct, on\n(set_local $3\n  (i64.const 0)\n)\n[wasm-validator error in function $impls::_impl_Ord_for_u8_::cmp] 2 != 1: set_local type must be correct, on\n(set_local $10\n  (i64.const 0)\n)\n[wasm-validator error in function $impls::_impl_Ord_for_u8_::cmp] 2 != 1: set_local type must be correct, on\n(set_local $10\n  (i64.const -1)\n)\n[wasm-validator error in function $impls::_impl_Ord_for_u8_::cmp] 2 != 1: set_local type must be correct, on\n(set_local $10\n  (i64.const 1)\n)\n[wasm-validator error in function $27] 2 != 1: set_local type must be correct, on\n(set_local $4\n  (i64.const 0)\n)\nAssertion failed: WasmValidator().validate(wasm), file G:\\work\\tests\\mir2wasm\\binaryen\\src\\tools\\binaryen-shell.cpp, line 225\n\nI guess it couldn't be related to VS2015 and potentially missing symbols again, could it ? I'll try to repro on osx as well, you never know.\n. I think the first option: I was sending invalid data to the api and it ended up validated, I'll try to extract a reduced test case.\n. haha ok cool I was doing it as well but you were faster :)\nwhat was also interesting is that 1) binaryen-shell caught this error, do they have different validation behaviors ? 2) with the api, optimizing the same data first then made it fail validation then\n. Awesome, thanks Alon :)\nI'll test it out once it lands to make sure we didn't miss anything\n. I still sometimes stumble upon interesting cases, but this one is definitely fixed, so I'll close the issue. I'll open other specific issues if/when I can isolate some new cases.\n. @binji oh really, thanks a lot for all this information, I wasn't even aware we'd generate such names and I'll change those, so @kripken can remove this escaping if need be (or make it a validation error). \n. @kripken ooh! I was looking at your recent commits on the trace-api branches and it looked real good, awesome that it's already done!\nI'll try it out and get back to you. Great work.\n. @kripken I was able to get a trace without problems. I didn't try it under osx clang/gcc but getting the trace to compile with VS2015 was harder.\nIt seems it doesn't like empty arrays such as: BinaryenIndex paramTypes[] = {  };\nwhich fails with: \"error C2466: cannot allocate an array of constant size 0\"\n(after making it compile, I still have issues linking, but that's more indicative of my level of experience with VS2015, ie none whatsoever, vs gcc, than because of the trace output per se)\n. To me the incomprehension wasn't about the optimizations, but that validation passes on those seemingly incorrect wast files without optimizations ?\nTo showcase this further, I've updated the traces to do 2 validations, one before and one after optimizing. The validation on the unoptimized module will not detect errors, the validation on the now optimized module will print the errors out.\n. 1) Yeah sorry, we are calling BinaryenModuleCreate https://github.com/brson/mir2wasm/blob/master/src/trans.rs#L61 but before asking for tracing \u2014 I didn't realize/notice the tracing calls should be done before creating the module :(\nI'll move it up.\n2) indeed those files and traces were not from master (we're 8 days behind or so right now). \nSo I have tried with master:\n1) the function which was optimized to (nop) is now (unreachable) so now both modes pass validation\n2) as you mention, the drop of a call to the void-returning function is now detected and fails validation. (interestingly the (return (get_local $0)) there is now a (return))\nI'll close this issue and push our update to master. Thanks @kripken !\n. @kripken AFAICT some of the layout changed since that PR (some of the src was moved from \"binaryen sources\" into different libs) but I don't think even back then that command would have worked, since there were multiple libs already right ?\nBUILD_STATIC_ON does not change the layout/dependencies or number of libraries in binaryen: it only builds 7 static libs instead of 7 shared libs. Building with BUILD_STATIC_ON results in these libraries being built today:\n- libasmjs.a\n- libast.a\n- libbinaryen.a\n- libemscripten-optimizer.a\n- libpasses.a\n- libsupport.a\n- libwasm.a\n(and not a single libbinaryen :)\nAdding each of those to the given command would solve the problem \u2014 even though they are not all strictly required for this particular example, eg this builds correctly for me:\ng++ test.cpp -Llib -Isrc -lbinaryen -lwasm -last -lasmjs -lsupport -lpasses\n. Weird\n$ ls -l lib/\ntotal 5984\n-rw-r--r--  1 rrakic  staff    22808 Mar 15 22:30 libasmjs.a\n-rw-r--r--  1 rrakic  staff    43568 Mar 15 22:30 libast.a\n-rw-r--r--  1 rrakic  staff   403448 Mar 15 22:33 libbinaryen.a\n-rw-r--r--  1 rrakic  staff    90032 Mar 15 22:31 libemscripten-optimizer.a\n-rw-r--r--  1 rrakic  staff  1815288 Mar 15 22:31 libpasses.a\n-rw-r--r--  1 rrakic  staff   101552 Mar 15 22:31 libsupport.a\n-rw-r--r--  1 rrakic  staff   573512 Mar 15 22:30 libwasm.a\n$ g++ test.cpp -Llib -I../ -lbinaryen -lwasm -last -lasmjs -lsupport -lpasses -pthread && ./a.out && echo $?\nprintf I added to your test.cpp\n0\nedit: also I'm on osx so g++ is effectively clang. I'm not sure either, and I thought it didn't add them to libbinaryen.a but I'm less experienced with cmake than you.\n(sorry, I did mean to say I was on osx and had updated the previous comment)\n. In any case it seems listing all the .a does not help you compile as much as it did help me :). @pipcet thanks for the help !. \"can\" refer I presume\n. ",
    "eholk": "Having dynamic by default with the option to build static seems like the right approach to me.\n. I'm not completely sure which one the build system picked up, but it was probably either g++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4 or clang version 4.0.0 (http://llvm.org/git/clang.git 7759c7d28c3c5ad00d2e3310384c5e7073de1f97). If it's using the git version of clang, that seems like a pretty likely culprit for the compiler bug.. It looks like asan is reporting memory leaks with this new change. I'm not sure why this should be worse, because the old version had absolutely no way to ever free the StringSet.. We might as well close it. I tried a few ways to fix the leaks, but that just exposed more of the problems I was trying to avoid and I got distracted. It'll be easy enough to revisit in the future if needed.. As I was looking into this I thought \"Wouldn't it be nice if there were a way to trace all the API calls and arguments so people could reproduce this without having to run mir2wasm.\" Lo and behold, there was! I'm seriously impressed.. I updated the gist. You are correct. It looks like mir2wasm was mapping types incorrectly.. > In short, we think we can allow blocks (and everything else in Binaryen IR) to have unreachable type, and basically freeze those types into block signatures (i.e. reify them) when converting to wasm proper.\nmir2wasm does something similar to this. Rust has an unreachable type, !, for functions that never return. In general we map Rust types to an appropriate binaryen type, so for example all pointers become i32s. For !, mapping this to void would be reasonable, and this works for functions returning !, but because we can't declare void locals, we are careful to avoid creating locals at all for ! \"values\". I don't think this is quite the same thing we're talking about here though.\n. Okay, I just finished reading this thread, so here are some thoughts of varying degrees of vagueness, relatedness, and self-consistency.\n\nRegarding symmetry, I think there's a higher level question of whether the binaryen IR defines an evaluation order (although I realize everyone else in the thread probably already knows if binaryen defines an order). If it does, then obviously you have to respect that, but if not then you have a lot more freedom. For example, if you don't define an evaluation order, the following transformation is always valid. (I'm using \u22a5 to represent unreachable)\n(i32.add (A...) (B... : \u22a5))   =>  (B... : \u22a5)\nThat obviously gives you a ton of freedom in eliminating dead code, although I expect these semantics would be surprising to binaryen users.\n\nI think the safest way to think of unreachable or \u22a5 is that is a fresh type variable. This is how the Wasm type system works. In this way, unreachable isn't really more as a type, but more of an assertion that we don't know anything about that context.\nA consequence of this is that you don't get to propagate unreachable. So in our i32.add example, we'd have something like:\n(i32.add (A...) (B... : t1))\nwhere t1 is a new type variable. Because it occurs in a context that needs an i32, then we'd set t1 to i32. This also means that something like\n(i32.add (A... : f32) (B... : \u22a5))\nis always illegal, because there's an f32 value in an i32 context.\n\nAnother way to think of unreachable is as an effect. I think this way makes more sense if you want to reason about DCE or code reordering, or whether unreachable infects its context.\nI think unreachable as an effect is pretty much orthogonal to unreachable as a fresh type variable, so it might actually make sense to do both of them. If that's the case, then it would probably reduce confusion to be explicit about when we are talking about each sense of unreachable.\nWith unreachable as an effect, this isn't so much a type, but another attribute on expressions. So then in the same way you can say \"this expression has type i32 and writes memory as an effect\" you could say \"this expression has type f32 and has the effect of not returning.\" The type and various effects (writes memory, traps, doesn't return, calls functions) are each independent properties.\n\nAs far as when you go to reify an unreachable block (and here reify basically means \"produce a concrete solution to all the constraints on the type variable\"). Most of the time this will be easy, because most things in Wasm (and presumably binaryen) have concrete types. I'm skeptical that this is always going to be the case (or at least, care will be needed to ensure this property if it's wanted).\nIn the most general case, you'd have to do something like Hindley-Milner type inference. At the end you still might have type variables, but this means nothing observes that particular type and thus you can pick whatever you want (such as i32). Basically, in this situation, the type doesn't matter, but Wasm requires a type annotation, so you have to invent something.\n\nI'm not sure how helpful this is, but one way to think of type systems is that they define a logic that you can use to prove properties about programs. One way you might use this in binaryen is as a tool to decide whether it a particular optimization is correct and applicable.\n\nGoing back to @dschuff's original requirements, here's the way I would think of the requirements.\n1. We want a language BinaryenIR, and a language Wasm, each with an associated type system, where WellTyped[L](M) means that module M is accepted by L's type system.\n2. We want a function WasmFromBinaryen, which is compiles BinaryenIR to Wasm.\n3. We also want a function BinaryenFromWasm, which converts a Wasm modules to binaryen's internal representation.\n4. WasmFromBinaryen(BinaryenFromWasm(M) is not necessarily equal to M.\n5. BinaryenFromWasm(WasmFromBinaryen(M) is also not necessarily equal to M.\n6. If WellTyped[BinaryenIR](M) then WellTyped[Wasm](WasmFromBinaryen(M))\n7. If WellTyped[Wasm](M) then WellTyped[BinaryenIR](BinaryenFromWasm(M))\n8. All of binaryen's optimizations and transformations preserve WellTyped[BinaryenIR].\nIf you were doing a paper on this, most of the paper would be focused on proving 6 and 7. It's good to be really precise and explicit about what is BinaryenIR and Wasm and think of them as different languages and type systems entirely, especially because they will in practice be very similar. For example, I've seen some papers which use different colors for code in the source language and the target language to keep from mixing them up. As a bonus, you might also want to define a relation between BinaryenIR types and Wasm types (such as i32[BinaryenIR] ~ i32[Wasm], etc.) and also show that the various translations between languages preserve type relations.. This looks fixed to me now. Thanks!. > > Line length limits. 80 feels much too short to me, personally.\n\nI personally prefer 80 cols, but don't mind extending it if others have concerns. Do you have some good number you feel comfortable with in mind?\n\nI don't do much work on binaryen, so I wouldn't put a lot of weight on my opinion, but I've been a staunch believer in 80 columns for most of my life. That said, Rust seems to have standardized on 100 columns and I find that is not only not terrible, but even somewhat pleasant. I could get behind standardizing on 100 columns.. I don't know if there's a preferred method, but any of the ones you listed should work. It might be interesting to benchmark each one and see which comes out fasted.. ",
    "chrisber": "Same problem here:\n- Chrome Version 54.0.2840.100 (64bit):\n  - Uncaught (in promise) WebAssembly.compile(): Result = expected version 0b 00 00 00, found 0d 00 00 00 @+4\n- Chromium: Version 53.0.2785.143 Built on Ubuntu , running on Ubuntu 16.04 (64-bit:\n  - Uncaught (in promise) WebAssembly.Instance(): Result = expected version 0b 00 00 00, found 0d 00 00 00 @+4\n- Node: v7.1.0:\n  - WebAssembly.Module(): Result = expected version 0b 00 00 00, found 0d 00 00 00 @+4\nAny workaround to compile to the correct target version?\n. ",
    "parulkhanna": "Hi, \nThanks for the reply. Can you please provide me the steps how to do that. I am unable to find a method. \n\nOtherwise, you can use trunk builds of v8 or spidermonkey, or use a nightly build of firefox or chrome with a flag.\n\nThanks,\n. Hi, \nCan you provide me with the steps on how I can run wasm file in browser. I am not getting the explanation on this link https://github.com/WebAssembly/polyfill-prototype-1.\nthanks,\n. Hi, I used the following command and still got the same error. (screenshot attached)\n`./emcc hello_world.c -s BINARYEN=1 -s \"BINARYEN_METHOD='native-wasm'\" -s 'BINARYEN_SCRIPTS=\"spidermonkify.py\"' -o helloworldy.html\n\n. Thank you  for the information. Really helped.\n. the output\n. https://gist.github.com/parulkhanna/94b8f798c6637594163fca66907b06a1\n. Hi, Thanks for recommending the fix. Finally, the toolchain compiled the code successfully with just a warning and no errors.\n2 warnings generated.\nwarning: Output contains some very large functions (6758 lines in Ia), consider building source files with -Os or -Oz, and/or trying OUTLINING_LIMIT to break them up (see settings.js; note that the parameter there affects AST nodes, while we measure lines here, so the two may not match up)\nWhenever I am trying to run the output, getting this error ! (Browser: Firefox Nightly)\n\n. Hi,\nThe issue has been resolved. whenever I used -s ALLOW_MEMORY_GROWTH=1 the error popped up.  I removed the flag. Updated the settings.js file in emscripten source to higher memory value and it worked. \nThanks for the help. \n. emcc 1.36.5 (commit e2276a93cde6af63dcf425626c29ee40d2a8bb88)\nbinaryen version, I don't know how to retrieve that.\nI am using Mac OS X. and trying to compile following programs. in native-wasm format. \nhttps://github.com/B-Con/crypto-algorithms\nThey work perfectly fine in asm.js format and also Interpret-binary format. The error is only displayed in case of native-wasm build in all cases.\nThanks,\n. Ok. Thank you for the quick response. I should probably wait then for a stable version. \n. ",
    "FeodorFitsner": "Make sure AppVeyor's webhook is added to the repo. You can see webhook URL on General tab of AppVeyor project settings.\n. I guess there is another project using the same GitHub repo. To use this format the repo should be unique in AppVeyor database.\n. ",
    "lukester1975": "Oh that's interesting that you can reproduce with interpreted-binary - which browser(s) was that?\nAs for guaranteed, which part do you mean? There should definitely (eventually) be 0 byte recv() after a disconnection. I'd also expect send() to fail at some point - given emscripten's select() doesn't allow exceptFds it has to be one or the other (or both)! (As an aside, I've tried poll() in case some of the additional events like POLLHUP, POLLERR were triggered, but sadly not.)\nI'll try to have a further poke around, but all this web stuff is like wizardry to me. I'm just a systems programmer tasked with getting something running in a browser :)\nThanks\nLuke.\n. Well the sample is only sending, but select()ing for readability on the socket also in order to detect connection breaks (by way of a 0 byte receive). Any actual data received is just dropped on the floor (if something is entered in netcat, for example).\nOK I'll do some more playing around. Not sure I can get the testcase any smaller though, other than trying a native JS WebSocket example doing the same thing to cut out some of those layers.\nThanks\n. Hi\nLooks like this can be closed after #882.\nThanks!\nLuke.\n. Hi\nOK I ran myu build with EMCC_DEBUG=1 to see the asm2wasm invocation, than ran that (I couldn't see a way to get asm2wasm --debug passed from emcc directly):\n/home/luke/.emscripten_ports/binaryen/binaryen-version_23/bin/asm2wasm ../../../../bin/Amsio_asm_js_emcc137_cxx11_mds.asm.js --total-memory=16777216 -O3 --mem-init=../../../../bin/Amsio_asm_js_emcc137_cxx11_mds.html.mem --mem-base=1024 --wasm-only --debug\nBut it didn't appear to help at the point of the assert:\n```\n\n[PassRunner]   (validating)\n[PassRunner]   running pass: precompute...                     0.105964 seconds.\n[PassRunner]   (validating)\n[PassRunner]   running pass: vacuum...                         0.22301 seconds.\n[PassRunner]   (validating)\n[PassRunner]   running pass: duplicate-function-elimination... 0.235529 seconds.\n[PassRunner]   (validating)\n[PassRunner]   running pass: remove-unused-module-elements...  0.10914 seconds.\n[PassRunner]   (validating)\n[PassRunner]   running pass: memory-packing...                 1.118e-06 seconds.\n[PassRunner]   (validating)\n[PassRunner] passes took 12.9433 seconds.\n[PassRunner] (final validation)\n[PassRunner] running passes...\n[PassRunner]   running pass: finalize-calls...\nasm2wasm: /home/luke/.emscripten_ports/binaryen/binaryen-version_23/src/asm2wasm.h:964: void wasm::Asm2WasmBuilder::processAsm(cashew::Ref)::FinalizeCalls::visitCallImport(wasm::CallImport*): Assertion `type->params[i] == f64' failed.\n```\nSo poking around in the code I saw CallImport::target. Dumping that out before the assert:\nif (type->params[i] != f64)\n            std::cerr << \"Oops. Failed in: \" << curr->target << std::endl;\nGives:\nOops. Failed in: $___cxa_throw\nThis is a C++ codebase that will throw various places - I'm just ignoring that for now, and haven't enabled catching (built with -O3).\nHopefully that makes some sense, from what you said above I could see it might given exception catching is disabled!\nI'll try to see if I can replicate with some simple exception throwing.\nRegards\nLuke.\n. I have a bit more info: the code is built with ASYNCIFY=1 and it doesn't trip the assert if built without ASYNCIFY.\nNo luck with a simple example yet, however!\n. Ah that's nice, thanks - it's caused by a throw in a default case of a switch that can never be reached. I'll see if I can get it down to a few lines...\nAs an aside, if it's OK to ask, since ASYNCIFY is deprecated is there another way to implement coroutines? emscripten_coroutine_create, emscripten_coroutine_next and emscripten_yield are perfect for my use case and I'm not really sure of the relationship with emterpreter and wasm, if there is any (or indeed how to use emterpreter to get similar functionality...).\nThanks!\nLuke.. wasm-assert.tar.gz\nOK attached is as minimal a demo of the assert as I can get (bearing in mind the asserts don't fire on a VC++ build!).\nem++ Main.cpp -o Main.html -s ASYNCIFY=1 -O3 -s WASM=1 -I ./boost -I .\nSeems to be somewhat related to using BOOST_THROW_EXCEPTION (the archive has the relevant bits of boost in it): changing that for a regular throw removes the assert. Then again, changing any line left in the example does similar - e.g. removing the throw on the default switch case; removing the if statement in BadThrow() so it always throws; removing either the STATE_1 or STATE_2 cases; removing Exception::m_message even though it's unused...\nHope that's of some help if it needs fixing!\nRegards\nLuke.\nPS thanks, I'll take a look at library_async.js though I suspect it's way over my head!. Cool, I'm glad it was a simple fix.\nThanks. ",
    "facekapow": "Basically what I'm asking is, what globals do I need to provide to Wasm.instantiateModule? (sorry if that got lost in the additional info) Thanks for the quick response, btw.\n. Well, I kind of got it to work. Basically, I copy pasted a regular a.out.js, and instead of asm = (function(global, asm, ..., I did asm = Wasm.instantiateModule(u8, { env: Module.asmLibraryArg }). I copied everything except the asm function and the real__* functions. The kind of part comes from the fact that it'll be parsed and work, but when trying to use fibonacci, abort() is called. Is there even any documentation on how to use the C/C++ compiled WebAssembly?\n. All that I'm trying to do is see how to include compiled C/C++ code with WebAssembly. Whether or not I use a main, I would have to provide the globals for instantiateModule, and I was just wondering where they would be defined so I could include them. Is they environment provided and I'm just not getting it because I'm using master instead of incoming?\nI'm not using incoming, because with incoming, when I do emcc -v, I get:\nWARNING:root:generating system asset: is_vanilla.txt...\nWARNING:root:                                          ok\nERROR:root:Emscripten, llvm and clang repo versions do not match, this is dangerous (1.36.5, 1.36.0, 1.36.0)\nERROR:root:Make sure to use the same branch in each repo, and to be up-to-date on each. See http://kripken.github.io/emscripten-site/docs/building_from_source/LLVM-Backend.html\nINFO:root:(Emscripten: Running sanity checks)\nemcc (Emscripten gcc/clang-like replacement + linker emulating GNU ld) 1.36.5\nclang version 3.9.0 (https://github.com/kripken/emscripten-fastcomp-clang/ 4fddcbc67c8950a54b169030ad9b2d66288d5d5f) (https://github.com/kripken/emscripten-fastcomp/ 21f1267bad4d8c523fae483104d4348cfb279cfe) (emscripten 1.36.5 : 1.36.5)\nTarget: x86_64-apple-darwin15.4.0\nThread model: posix\nInstalledDir: ~/opt/emsdk/clang/fastcomp/build_incoming_64/bin\nERROR:root:Emscripten, llvm and clang repo versions do not match, this is dangerous (1.36.5, 1.36.0, 1.36.0)\nERROR:root:Make sure to use the same branch in each repo, and to be up-to-date on each. See http://kripken.github.io/emscripten-site/docs/building_from_source/LLVM-Backend.html\nINFO:root:(Emscripten: Running sanity checks)\nI was also getting this before installing master. And llvm and clang and emscripten are always compiled from source, so I don't understand why there'd be a version mismatch.\n. > Sorry, I don't understand what that means? Compiled C/C++ code becomes WebAssembly.\nSorry for all the confusion, I understand that the compiled code becomes WebAssembly, but the second part of your comment solves all this. I knew there had to be something I was missing. I'll remove the whole emsdk and reinstall from incoming later today and hopefully close this issue.\n. Ok, this time for some reason the incoming branch worked perfectly! Thanks for all the help!\n. Just recompiled today and this seems to be gone now. Weird. Anyways, thanks for the help.. ",
    "alexanderby": "This tutorial can help to understand what properties should environment have https://codelabs.developers.google.com/codelabs/web-assembly-intro/index.html?index=..%2F..%2Findex#3. I made it work after reading some Google tutorial https://codelabs.developers.google.com/codelabs/web-assembly-intro/index.html?index=..%2F..%2Findex#3\n```c\n// hello.c\ninclude \nfloat bezier1(float t, float p0, float p1) {\n    return (1 - t) * p0 + t * p1;\n}\n```\nsh\nemcc hello.c -s ONLY_MY_CODE=1 -s WASM=1 -s EXPORTED_FUNCTIONS=\"['_bezier1']\"  -o hello.js\nI didn't understand why I have to use underscore in function name and why I have to create a JS file. But it works.\nFinally, my JS code:\njavascript\nconst memory = new WebAssembly.Memory({ initial: 256, maximum: 256 });\nconst importObj = {\n    env: {\n        abortStackOverflow: () => { throw new Error('overflow'); },\n        table: new WebAssembly.Table({ initial: 0, maximum: 0, element: 'anyfunc' }),\n        tableBase: 0,\n        memory: memory,\n        memoryBase: 1024,\n        STACKTOP: 0,\n        STACK_MAX: memory.buffer.byteLength,\n    }\n};\nfetch('hello.wasm').then((response) => response.arrayBuffer())\n    .then((bytes) => WebAssembly.instantiate(bytes, importObj))\n    .then((wa) => alert(wa.instance.exports._bezier1(0.5, 10, 20)));\nOverall I think there is so much overkill. As far as WebAssembly is supported in all the modern browsers I expect to just doing something like npm install c-to-wasm and then node node_modules/.bin/c-to-wasm index.c index.wasm. Installing all that tools, containing python etc. and doing OS specific tricks seems strange for mainstream web development toolchain.. ",
    "aheejin": "This bug only affects scan(), not process() and \".globl\" is only checked in process(). So we have to remove \".file\" and \".globl\" line to reproduce the bug. The case I discovered this bug was \".text\" appears in the middle of a file and the \".text\" line was directly followed by \".type\", skipping the \".type\" line and not recognizing a defined function there.\n. To simply reproduce a bug with basic.s without deleting any line, I can just add \".text\" before any \".type\" declaration.\n. Not sure if he is notified @ddcc\n. Oh one more thing, this bug is only reproduced when one word directive (like .text) is before a '.type' directive that declares a function which is not 'main'. So I couldn't reproduce the bug by simply deleting some lines from basics.s, which was the reason I added a new test.\n. @dschuff \n. @jpporto\n. @kripken It should pass all exception-related test cases in emscripten, after I submit all the related CLs or PRs to the following repos:\n- llvm: under review\n- binaryen: under review\n- emscripten: I haven't submitted a PR. PRs I submitted to emscripten are not really about exception handling itself, but more about resolving bugs or issues to make the environment work. I will submit a PR implmenting EH once other emscripten-related PRs are resolved.\n. Done\n. The reasons I didn't do any actual reformatting here were\n1. I was not sure about doing the massive change on the whole codebase and messing up git blame history by reformatting all the code\n2. I wanted to get everyone's preferences and feedback first on the style.\nI like the preview idea too. Maybe I'll go ahead and submit the whole-codebase-reformatting PR for each style so that everyone can take a look. They wouldn't (and shouldn't) be landed; they are just to give a sense of how each style looks. After we decide on a style, we'll see if we need to actually reformat the whole codebase or not.. @kripken \n\nIf etc. arms on a new line need curly braces (that one saves me from bugs now and then).\n\nWhichever style we choose, we can make sure this one sticks by overriding it.\n\nLine length limits. 80 feels much too short to me, personally.\n\nI personally prefer 80 cols, but don't mind extending it if others have concerns. Do you have some good number you feel comfortable with in mind?. @sbc100 That makes sense. I'll do that.. @kripken Looks like clang-format itself cannot insert or delete any characters like curly braces. It just formats code. If we want to enforce curly braces for one-line ifs, we need clang-tidy instead. I can do that, but maybe that calls for another PR.. ## Comparisons on Binaryen\n- Current vs. Chromium style\n- Current vs. LLVM style\n- Current vs. Google style\n- Current vs. Mozilla style\n- Current vs. Webkit style\n- Chromium vs. LLVM style\nIt's hard to tell exactly which style resembles the current codebase the most, but I think either Chromium or LLVM style would be OK. (Webkit uses the indent width of 4 and Mozilla breaks after the return types of top-level functions, which I found as most different things from the current codebase)\nDifferences between LLVM and Chromium styles\nHere are some properties in which LLVM and Chromium have different values. (There are many other properties where their values are the same. I didn't list them up here.) You can compare Chromium vs. LLVM style output for binaryen here. Note that even if we choose one style, we can override each property separately, so it doesn't mean we should accept everything on that style.\nAccessModifierOffset\nChromium: -1\ncpp\nclass A {\n public:\n private:\n};\nLLVM: -2\ncpp\nclass A {\npublic:\nprivate:\n};\nAlignEscapedNewlines\nChromium: left\n```cpp\ndefine A   \\\nint aaaa; \\\n  int b;    \\\n  int dddddddddd;\nLLVM: rightcpp\ndefine A                                                                      \\\nint aaaa;                                                                    \\\n  int b;                                                                       \\\n  int dddddddddd;\n```\nAllowAllParametersOfDeclarationOnNextLine\nChromium: false\ncpp\nvoid myFunction(int a,\n                int b,\n                int c,\n                int d,\n                int e);\nLLVM: true\ncpp\nvoid myFunction(\n    int a, int b, int c, int d, int e);\nAllowShortFunctionsOnASingleLine\nChromium: Allow class-inlined functions only\ncpp\nclass Foo {\n  void f() { foo(); }\n};\nvoid f() {\n  foo();\n}\nvoid f() {\n}\nLLVM: Allow all\ncpp\nclass Foo {\n  void f() { foo(); }\n};\nvoid f() { bar(); }\nAlwaysBreakBeforeMultilineStrings\nChromium: true\ncpp\naaaa =\n    \"bbbb\"\n    \"cccc\";\nLLVM: false\ncpp\naaaa =  \"bbbb\"\n        \"cccc\";\nAlwaysBreakTemplateDeclarations\nChromium: true\ncpp\ntemplate <typename T>\nclass C {};\nLLVM: false\ncpp\ntemplate <typename T> class C {};\nBinPackParameters\nChromium: false\ncpp\nvoid f(int aaaaaaaaaaaaaaaaaaaa,\n       int aaaaaaaaaaaaaaaaaaaa,\n       int aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa) {}\nLLVM: true\ncpp\nvoid f(int aaaaaaaaaaaaaaaaaaaa, int aaaaaaaaaaaaaaaaaaaa,\n       int aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa) {}\nConstructorInitializerAllOnOneLineOrOnePerLine\nChromium: true\ncpp\nSomeClass::Constructor()\n    : aaaaaaaa(aaaaaaaa),\n      aaaaaaaa(aaaaaaaa),\n      aaaaaaaa(aaaaaaaaaaaaaaaaaaaaaaaaa) {\n  return 0;\n}\nLLVM: false\ncpp\nSomeClass::Constructor()\n    : aaaaaaaa(aaaaaaaa), aaaaaaaa(aaaaaaaa),\n      aaaaaaaa(aaaaaaaaaaaaaaaaaaaaaaaaa) {\n  return 0;\n}\nIndentCaseLabels\nChromium: true\ncpp\nswitch (fool) {\n  case 1:\n    bar();\n    break;\n  default:\n    plop();\n}\nLLVM: false\ncpp\nswitch (fool) {\ncase 1:\n  bar();\n  break;\ndefault:\n  plop();\n}\nPointerAlignment\nChromium: left\ncpp\nint* a;\nLLVM: right\ncpp\nint *a;\nSpacesBeforeTrailingComments\nChromium: 2\ncpp\nvoid f() {\n  if (true) {  // foo1\n    f();       // bar\n  }            // foo\n}\nLLVM: 1\ncpp\nvoid f() {\n  if (true) { // foo1\n    f();      // bar\n  }           // foo\n}. @kripken What I did is something like\n$ cd binaryen/src\n$ find ./ -name '*.cpp' -or -name '*.h' | xargs clang-format -i\n(You can specify a style in the command line using something like clang-format -style=llvm .... If you have .clang-format in the top project directory that's not needed.). @kripken Oh and I also noticed you preferred type* a over type *a in #1403. If we want to choose the LLVM style maybe we should tweak that, because LLVM defaults to type *a.. @jgravelle-google Do you have any preferences?. So, to sum up the responses here,\nThings everyone seems to be OK with:\n- LLVM as the base style\n- PointerAlignment: left (as in int* a)\nThings people have different preferences on:\n- IndentCaseLabels\n  - Our to-be base style (LLVM) sets this to 'false' (don't indent), and @dschuff said he wanted shorter columns\n  - @aheejin prefers 'false' as well, but don't mind much\n  - @rongjiecomputer, @kripken, @sbc100 seem to prefer 'true' (indent)\n  - Current binaryen codebase mostly indents case lines, so 'true' (indent)\n  - Conclusion: I think if no one has strong preferences we can do this as 'true' (indent). Would this be OK?\n\nColumnLimit\nSeveral people expressed preferences for 80 cols (@dschuff, @aheejin, @sbc100, and @eholk)\n@eholk also suggested 100 cols can be OK\n@kripken suggested 120 cols\nConclusion: Well, it's hard to decide :) How about 100 as a midpoint?\n\nLet me know if you have further concerns. If there's no more comments, I'll fix the style as\n- Base style: LLVM\n- PointerAlignment: left\n- IndentCaseLabels: true\n- ColumnLimit: 100. I found some more tweaks that more closely matches the current codebase, like\n- AllowShortCaseLabelsOnASingleLine: true\n- AllowShortBlocksOnASingleLine: true\n- AllowShortFunctionsOnASingleLine: Inline\nMaybe I'll give this couple more days to see if I can find more.. Pushed some tweaks to follow the styles on the current codebase.\n- ContinuationIndentWidth: 2\ncpp\n// ContinuationIndentWidth: 2\nint i = longFunction( // Assume this line is very long\n  arg); // this line is indented by ContinuationIndentWidth\nThis was set to 4 in the LLVM style, but the current codebase almost always uses 2.\n\n\nConstructorInitializerIndentWidth: 2\ncpp\n// ConstructorInitializerIndentWidth: 2\nMyClass::MyClass\n  : init1(init1), init2(init2), ... // This line is indented by ConstructorInitializerIndentWidth\nThis was set to 4 in the LLVM style, but the current codebase almost always uses 2 as well.\n\n\nAlignAfterOpenBracket: DontAlign\n\n\n```cpp\n// AlignAfterOpenBracket: Align\nsomeLongFunction(argument1,\n                 argument2);\n// AlignAfterOpenBracket: DontAlign\nsomeLongFunction(argument1,\n  argument2); \n// AlignAfterpenBracket: AlwaysBreak\nsomeLongFunction(\n  argument1, argument2);\nLLVM's style sets this to `Align`, but the current codebase mostly don't align. And given that now we have longer-than-common column limit 100, setting this to `Align` can make lines likecpp\nsomeVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryVeryVery...VeryVeryLongFunction(arg1,\n                                                                            arg2);\n```\n\nI thought about adding these, but ended up not doing that.\n- AllowShortCaseLabelsOnASingleLine: true\n- AllowShortIfStatementsOnASingleLine: true\n- AllowShortBlocksOnASingleLine: true\n- AllowShortLoopsOnASingleLine: true\nThese allow (more precisely, force) short case labels / if statements / blocks / loops into a single line. For example, if AllowShortIfStatementsOnASingleLine is true,\ncpp\nif (condition)\n  foo();\nbecomes\ncpp\nif (contidion) foo();\nIf these are set, all short case labels / if statements / blocks / loops are merged into a single line. What I wanted is to allow single lines but not to merge all existing codebase to single lines, but apparently there is no way to do that, because the output of clang-format should be determined based on code and style configurations.. In https://github.com/WebAssembly/binaryen/pull/1407#issuecomment-365224159, I wrote the reason why I ended up not doing that. Refer to the paragraph starts with\n\nI thought about adding these, but ended up not doing that. ...\n\n\nIn short, if I enables these parameters, all code that are written in \ncpp\nif (j > 0)\n  std::out << \", \";\nwill be all converted to\ncpp\nif (j > 0) std::cout << \", \";\nWhile I wanted to allow the short one-line form, I was not sure if we should merge all existing two-line code into a single line. So there is no \"leave code as is\" kind of option. For example, if we set AllowShortIfStatementsOnASingleLine to true, all short if statements are merged into a single line if they fit within 100 cols, even if they are currently written in two lines. If we don't set the option, all if statements are converted to the two-line form as you saw. We have to choose one. We can set it to true if you prefer that.\nOh, and one more thing, even if we set AllowShortIfStatementsOnASingleLine to true, it does not handle if with else. Currently there is no option that allows this code:\ncpp\nif (j > 0) do_this();\nelse do_that();\nThey are always broken down to\ncpp\nif (j > 0)\n  do_this();\nelse\n  do_that();. @kripken \n1. clang-format cannot add characters like { }. We need clang-tidy for that.\n2. I don't think there's a way to do that unless we develop a separate program that 1) runs clang-format to compute the result 2) computes a map of a person to lines and 3) asks each person to commit the corresponding change.\nAnd I agree there's no much benefit to preserving only the author while we can't preserve the last 'history' anyway.. @kripken Maybe it's better to add .clang-tidy and fix {} thing automatically, to lessen the hassle.. Unlike clang-format that is a part of clang, clang-tidy is one of clang extra tools, so it isn't built by default unless you check out clang extra tools with llvm and clang as instructed here. clang+llvm official releases contain clang-tidy binaries too, so I think you don't need to build it by yourself.. #1395 has conflicts with this, so it looks like this needs merging with master.. @sbc100 To my understanding, the reason @kripken wanted clang-tidy was he wanted to ensure there is always enclosing braces for single-line ifs and loops. So, he wanted to convert\ncpp\nif (condition)\n  statement;\nto\n```cpp\nif (condition) {\n  statement;\n}. I haven't checked all the code changes yet, but I also wonder if the bugs are caused by clang-format or clang-tidy. IIUC clang-format cannot change characters in code except whitespaces.\nI also agree that this might be hard to test. Applying the style incrementally, by recommending people to apply clang-format on the part of the code they modify using git clang-format, might be a better option.. Oh, I didn't know about this, and that was just a mistake, as you expected. I'll change it to &&.\n. Done\n. Done\n. Done\n. I'm not sure how I can make it more general. You mean, it should not sound like a LLVM specific thing? But what this function does is basically converting LLVM IR type names into wasm type names in function signatures, so I don't know how it can be independent of LLVM.\n. I added a semi-handwritten test to dot_s (it was not handwritten from scratch, but I kind of removed all unnecessary parts from a simple generated file, resulting in a simple test case).\n. Done\n. Oh, I was mistaken about the prefix _ thing. emscripten creates\nvar _FUNCNAME = Module[_FUNCNAME] = asm[FUNCNAME]\nfor every function that is exported from a wast file anyway, so we don't need to modify something frmo emscripten side for this. What I did is we need to export malloc and free from wast side, and I don't think this is related with _ prefix thing. Is it?\n. Then what we need to do is\n1. Add 'malloc' and 'free' along with '_malloc' and '_free' back to emcc.py, because the prefix _ will matter again\n2. Make s2wasm read an extra setting file, because the list of exported functions can be too large to be passed as something like comma-separated command-line argument (or is it not?)\n3.  Make s2wasm export functions it read from that settings file or command-line argument\nDo you think we should do this rather than just exporting malloc and free for now?\n. I added a TODO comment.\n. It looks like this walker runs twice, once in wasm-emscripten-finalize tool and again in wasm-link-metadata tool. Is this redundancy intended, or can't be helped? Asking because I have similar concerns for other stuff; I need to generate some emscripten glue and also some metadata based on the same walker. In the current setup, the two tools are separate, so should the walker always run twice? If it's just scanning the module twice, that might not be a big burden though.. Yeah I agree, we can even unify check.py with auto_update_tests.py because they basically share many processes, but maybe not today though. \ud83d\ude1e. Done. Done in s2wasm too. Yeah I did that first in s2wasm to match neighboring code style and basically copy-pasted it into other tools, but not messing with options.extra is better, so.. Done. Done. Maybe const auto& would be better to prevent copying?. Done. Yeah what I wanted to do is sig[0] + 'i' + sig[1:], but std::string did not have a one-argument constructor from a char.. Done. I'd like to remove this too. If no one else has concerns, I'll remove it.. The reason I used items is iteritems is deprecated in Python 3 and items does not generate an array but rather generates a generator in Python 3. (So items behaves the same way as in iteritems does in Python 2) Migrating all scripts to be Python 3 compatible should be something we should do later though.. Setting AllowShortCaseLabelsOnASingleLine to true allows this, but settings also means converting all two-line case statements into a single line if they fit in 120 cols, the current ColumnLimit. There are several options like this; refer to the bottom of https://github.com/WebAssembly/binaryen/pull/1407#issuecomment-365224159 for details.\nSo we have to either convert all\ncpp\ncase 'i':\n  blahblah;\ninto \ncpp\ncase 'i': blahblah;\nor we have to convert all\ncpp\ncase 'i': blahblah;\ninto\ncpp\ncase 'i':\n  blahblah;\nSo the point is, even though the option name is AllowShortCaseLabelsOnASingleLine, there is no option that allows something. clang-format, in nature, forces a single style for given code and configurations. The option should read as ForceShortCaseLabelsOnASingleLine.\nMerging all two-line case statements (or if statements, ...) into a single line may not sound that bad, but we also have ColumnLimit of 120, which is longer than usual. This will merge a lot of two-line case statements into one. So, I was not able to decide, so I ended up not adding those Allow*** options. We can add them if people prefer that.. When comparing changes in #1407, I also noticed this, and I couldn't help it. The only option that allows multi-line definition in this case was ColumnLimit = 0, which effectively enforces no limit on the column length. Funnily, this allows multi-line definitions. Don't know why.\n. nit: whitespace between () and {?. I don't understand... this part checks whether jsCalls have already been created or not, and if they have, they should have already respected to avoid the 0 index, no?. So before this part was\njsCallStartIndex = wasm.table.segments[0].offset->cast<Const>()->value.getInteger() + tableSegmentData.size();\nwhich is executed when you first call jsCalls, and this respects avoiding the 0 index.. This way, every time you check if there have been already created jsCalls, you add the table size to the start index again and again.. Ah, you are right... Sorry for the confusion!. Nevermind, I was confused... \ud83d\udc4d. ",
    "qwertie": "@kripken Do you know what the decision-making process is for WebAssembly? I'm increasingly getting the feeling that major decisions are made in private discussions behind closed doors, or other unknown places, with little important discussion happening in the design repo. Did the change to a stack machine catch you by surprise as well?\nBased on what I know so far (which is no doubt less than what you know), \"Keep on trucking, for now\" looks like the best option (for now), because \n- I don't know if the stack machine is a final, irreversible decision.\n- It looks like there are AST equivalents for the new stack machine semantics (have you discovered anything in the stack machine that can't be expressed in AST form with a new operator like 'first'?)\n- By maintaining an AST form for Wasm code, you maintain knowledge about the two-way isomorphism between AST and stack machine. I think that's just useful knowledge from an academic perspective. It could be useful to other engineers in the future and useful to the computer science field.\n- Converting stack-based wasm to an AST is a potentially useful feature to many people. By keeping this ability, you reduce the need for people to migrate to other tools, making your tool more popular and by implication, you yourself ;)\n- It is probably easier to adapt gradually to the changes in Wasm as they happen. We're predicting certain things in the future like a pick operator and multi-values, but we don't know that these will actually happen in the form currently being considered. I think before ripping out functionality or engaging in a major rewrite, you should be certain it is necessary.\n- (edit) As you mentioned, ASTs seem easier to work with for some common optimizations.\n\nThis puts us in the uncomfortable position of optimizations needing to take into account that more AST nodes might mean less code size\n\nAre \"virtual\" nodes really uncomfortable in terms of code complexity, or it is mainly uncomfortable psychologically? If it's the latter, I think you'll get used to it after awhile.\n. > I am leaning more in the forked-IR direction.\nIf \"forked-IR\" means \"an AST-based IR that is very similar to, and easily convertible to, the Wasm stack machine, such that arbitrary Wasm stack-machine code can be converted easily to the IR,\" it sounds like a good plan to me. It's even better if Wasm-to-IR-to-Wasm and/or IR-to-Wasm-to-IR are (guaranteed to be) lossless roundtrips.\n. OIC - \"~\"  means \"varies proportionally with\". Aka x \u03b1 y...\nIt seems to me you can model most of this with a per-node weight - say, most operations have weight 1, multiplications have weight 2-ish, divisions have weight 10-ish... and you can define three weights, one for \"optimize for speed\", one for \"optimize for size\" and one for \"balanced\". If an algorithm needs positive weights, that's okay: it might be better to give first a weight of 0.001 rather than 0 since w; x; y + z has the (small) virtue of being easier to understand than w; first (y, x) + z. On the other hand, another optimizer might have chosen w; first (y, x) + z intentionally, let's say because w might modify memory read by x... anyway, I've never written optimizers so I'm probably not helping :)\nI see that multi-values are likely to happen as currently envisioned because they seem easy for the back-end to support. But local variables do everything we would use pick for, so I think it'll be awhile before they consider that - unless they eliminate local variables entirely (a slightly horrifying thought).\nFWIW I support your opposition to the stack machine, or at least I think there should be a closely-related AST variant of Wasm for the text format and for binaryen. I recognize the (small) value of the stack machine in the final back-end, but still wonder if there's some way to achieve a similar benefit in the AST paradigm (I'm cursing myself for not having found the time to learn Wasm better, otherwise I'd love to investigate this.)\nIt sounds like you weren't really consulted about this decision, but do you know what the decision-making process is?\n. @kripken I'm not seeing it. What's an example where first would have a negative weight?\n. A negative weight isn't needed here: if first's weight is zero or near-zero, the first version has lower total weight so the optimizer should prefer it.\n. Good counterpoints, @kripken. It seems like not only do the browser people have all the power over Wasm design, but they aren't concerned with pleasing any other audience, so we can't expect Wasm to end up suitable for any purpose other than code execution. Forking into two formats is unfortunate, but avoids relying on the browser people to offer concessions to us.\nI guess the fork itself is already set in stone, and the question is just, how much can still be done on the \"browser Wasm\" side (just linking?) I wonder if using Wasm as the linking format might indirectly encourage the browser people not to completely forget about stakeholders other than themselves (e.g. because people will take more feature requests to the Wasm CG instead of whoever ends up in charge of \".byn\" - maybe that's you.)\nWhere did this name \"byn\" come from, and post-MVP, will it cater to ALL languages, not just systems languages? The naming scheme of all the tools here is rather baffling to me.\n\nI've argued for a long time I believe wasm has been going down a bad path in terms of its text format\n\nWhat path is that? Do you have inside information or am I just not monitoring all the right channels? I'm frustrated that no one will talk to me about my text format proposal - no bikeshedding, not even a simple \"for\" or \"against\".\n. I'm confused, because I thought it was clear that a structured text format is still usable even in the stack machine - and that LES works fine even for a linear list of instructions (with just a little bit of structure given by the block-expressions {...}, loop (label) {...}, and if (...) {...}.)\n. > For example, code that conceptually does this (and that I wish we could represent as this!),\n\nif (x == y) {\n  x = 1;\n}\n\n@kripken But we can represent stack machine code that way! The proposal I keep begging people to read also includes a flat representation (which is the same language used differently). But rather than simply transliterating the s-expressions syntax, I proposed a more compact representation, something like this:\n$y; $x; i32_eq; if {\n    1; set_local $x\n}\n\nIntrospectability:\nThis is another way of saying \"understandability\" or \"readability\"\n\n@dschuff Maybe. I had assumed he was talking more about computational introspectability: optimization, decompilation, making it easy to generate code at runtime. Various computational tasks are easier with an AST.\n\nunderstandability is subjective\n\nI'm pretty sure there's an objective case to be made about an AST being more understandable to humans than a flat instruction list... to me it's so intuitively obvious that I'm not sure how to argue the case.\n. @kripken I agree with your incremental plan.... except:\n\nif it encounters overly-stacky code, it might use extra locals or such to fit it into our AST\n\nDoesn't the first operator solve this problem though? (Apologies if we're going in circles, but unlike JSStat's proposal, first is a very simple solution that seems to allow perfect round-trips, and it's too early to have two IRs or commit to a particular way of handling multi-values)\n\nthere are examples in the discussion earlier\n\nWell, one example. As I pointed out though, the example didn't illustrate a \"negative weight\" problem, and the general idea of assigning weights to operators seems useful in itself. Can you give a more problematic example?\n. @drom LES has three advantages over Forth syntax: (1) Similarity to JS + (2) familiarity to typical developers (two longstanding design criteria for the text format); and (3) general purpose use related or unrelated to WebAssembly (edit: for instance, using the same parser for binaryen, even though Wasm is a stack machine and binaryen is AST-based).\n\nThe wasm MVP isn't going to do that, as it's shipping a linear list of stack machine instructions (somewhere between 1 and 2 - portable like 2, but no objects). And while wasm might get a better text format later, without an AST it will always have to deal with non-AST patterns\n\n@kripken I don't care how compressed the timeframe is, I'm certain it's possible to have the better text format now. If they run with my proposal (taking line break as a terminator), they can start with a flat format now and add structure later, when they have time, without necessarily changing the official spec.\nIMO the documented spec should just have a section on syntactic sugar for infix operators, which the browsers will initially ignore and which is straightforward to code in an assembler. But if this time crunch is serious they can even skip that part.\nMeanwhile I can write LES parsers for them to use, or they can take up my original proposal of defining Wasm as a subset of LES (and therefore write Wasm-specific parsers). The biggest thing I'm asking for is to change some opcode names, e.g. i32_add or i32'add instead of i32.add, to keep the grammar of LES at LL(2) instead of LL(*). What do you think, can you talk to the others for me?\n. > assuming the order of operations allows it we want to do this transform:\n(block\n  (call a)\n  (call b\n    (first (call c) (call d))\n  )\n  (call e)\n)\n==>\n(block\n  (call a)\n  (call b (call c))\n  (call d)\n  (call e)\n)\nBy itself, I don't see any reason to perform this transformation (and since it changes the order of ops you wouldn't do it without a good reason). So, why do it?\n. > are we sure we don't need some other node to have the smallest weight, now and in the future?\nBeing effective now is enough. In the future, the weights can be changed, but with multivalues, we might switch to a completely different solution (whether it's separate IR or an AST-based solution) for which first is syntactic sugar or even deprecated.\n. Er... what's that about not modelling the drop type system changes?\n. I'm primarily concerned that if they don't accept certain changes now (e.g. renaming the operators), after MVP they will reject LES on the basis that, essentially, the punctuation marks are set in stone because 10s of 1000s of users are now used to them, and LES doesn't accept the punctuation in identifiers without escaping. Besides, it just makes a lot of sense to choose a format that has a shot at being forward-compatible.\nI would be willing to write a browser addon, but I have no idea how to do it. Any ideas? I also intend to write a parser for binaryen.\n. Well, what you're suggesting is integrating an addon with the experimental WebAssembly engine, isn't that right? Ideally I would write the debugger's pretty-printer, but I wouldn't have guessed that it was even possible (in an add-on) if you hadn't brought it up. Or is your idea rather that the browser provides access to a binary representation of resources like images and wasm modules, and I should just parse the binary? (one challenge with that would be that addons are written in JS - who has written code to decode Wasm modules in JS?)\n. P.S. Thanks for the link and the tips!\n. I have no expertise at this, but have a couple of comments. In .NET the JIT will not inline a method of the form...\nint Sum(int n1, int n2, int n3, int n4, ...) { return n1 + n2 + n3 + n4 + ... ; }\n...if the number of arguments is sufficiently large, so I think they forgot about the \"opportunity cost\" of not inlining. Inlining eliminates the code that shuffles data into the correct registers and puts excess arguments onto the stack, so the inlining decision should take into account not just the size-cost of inlining but also the size-cost of not inlining.\nHere are a couple of thoughts I often have about inlining. I often write functions of this form:\ncpp\nvoid MaybeDoSomething(int x) {\n   if (condition that is rarely true and may or may not involve x) {\n      large and expensive procedure\n   }\n}\nI sometimes wish my compiler could inline just the \"if\" and not the whole procedure.\nI also often write internal functions plus public APIs that wrap them, like\ncpp\npublic: void InsertItem(int index, T item) {\n   if ((size_t)index > _list.size()) \n      throw ....;\n   if (this->IsReadOnly())\n      throw ...;\n   InsertItemCore(index, item);\n}\nprivate: void InsertItemCore(int index, T item) {\n   _list.Insert(index, foo);\n   ... implementation-specific bookkeeping ...\n}\nMy goal is to avoid unnecessary \"bureaucratic\" checks when I know those checks will succeed. What I really want is a single function with two distinct entry points, but in lieu of that, I want the \"Core\" function to be inlined in the public function. So sometimes I wish I could insert an inlining hint at a specific call site.\n. Where is this trace thingie and how does it work?. > I humbly suggest that your approach is not likely to be very effective in achieving your ends, but I demand that you act respectfully and professionally, even (especially) if you believe that others have not so acted toward you.\n+1 to that. I share @wlllang's desire for more inclusive and transparent behavior from the browser devs, but he often takes an overly harsh, confrontational approach. Which evidently hasn't worked if they're already switching to the final version 0x01 :(. @wllang I see. Well, on a positive note, I have admired the persistence and determination with which you pursued your ideas in the face of indifference. If I had that same tenacity, I really think I would have been able to influence the design, at least a little.. ",
    "lukehutch": "I am building a compiler for a new language, and came to the conclusion that the most important backend I could build would be a wasm backend, given that it has the potential to become the standard way to ship processor-agnostic binaries for server, desktop and mobile, both inside and outside the browser.\nI just now came back to get an update on the progress of wasm, for the first time in 6 months, and discovered the switch from AST to stack-based architecture. I consider this to be a huge mistake (and I think the binayen folks on this thread are being too diplomatic about how to cope with the upstream change!).\nThere are several reasons why switching to a stack-based architecture is a bad idea:\n(1) As pointed out in other comments, this is a major step backwards for the transparency of code and ease of learning on the web: stack-based code is nearly impossible to read.\n(2) Stack-based architectures are massively inefficient at runtime, which wastes battery on mobile, causes UI latency and jank (which incurs a cognitive burden in users), kills baby polar bears etc. etc. \n The following paper shows how much overhead a stack-based VM incurs compared to a register-based VM, after significant effort was expended to optimize both:\nhttps://www.usenix.org/legacy/events/vee05/full_papers/p153-yunhe.pdf\nAs far as I can tell, the reasons for switching to a stack-based architecture was initially the trigger of allowing void expressions anywhere, but ended up coming down to the increased ease of building the runtime (since you don't have to build as much compiler backend infrastructure if you're already at a lower level than an AST), as evidenced in the following comment by @rossberg-chromium from earlier in this issue:\n\nThe superficial history is that most of it \"happened\" in ongoing\nconversations between a couple of Mozillians ad Googlers. Luke & Dan have\nbeen arguing in the more stack-ish direction for a while. Ben & I were\nrather skeptical at first, but feared \"slow drift\" (such as more\nincremental changes of the drop kind). The pivot point was the suggestion\nto \"allow void-expressions anywhere\", which quite plainly breaks the AST\nsemantics. So, to see to the end game, we prototyped a stack machine in\nformal spec, ml-proto and V8. It turned out to be simple enough to convert\nus over.\n\nIt is likely that even more overhead would be incurred between compilers forced to compile from a stack-based IR and an AST-based IR than even the difference between stack-based and register-based IR, since the higher level of an AST-based IR makes so many optimizations simpler. For an example of the types of hoops you have to jump through to safely perform even simple dead-code elimination in a stack-based IR, see this paper:\nhttp://set.ee/publications/bytecode07.pdf\nSo many simple optimizations require careful thought, soundness proofs, and new abstractions (such as swapping virtual stack snapshots due to differences in control flow) when reasoning about a stack-based VM, and most peephole optimizations are simply undoing some ineffeciencies imposed on the code by lowering to a stack-based form (e.g. replacing DUP SWAP with DUP), because the representation is so low-level:\nhttp://www.rigwit.co.uk/thesis/chap-5.pdf\nhttps://users.ece.cmu.edu/~koopman/stack_compiler/stack_co.html\nSome other reasons why stack-based representations can be more inefficient include the following (there are many -- the quoted points are taken from this Wikipedia page):\n\nStack machines must always properly unwind the stack before exiting an execution frame (they cannot leave unneeded values on the stack, the way that a register machine can simply leave unneeded values in registers, depending on the calling convention).\n\"Some in the industry believe that stack machines execute more data cache cycles for temporary values and local variables than do register machines.\"\n\"In register machines, a subexpression which is used multiple times with the same result value can be evaluated just once and its result saved in a fast register. . . With stack machines, in contrast, results can be stored in one of two ways: A temporary variable in memory. . . The second way leaves a computed value on the data stack, duplicating it as needed.\" (both are inefficient)\n\"Rigid code order: Scheduling memory accesses requires explicit, spare registers. (Out-of-order execution) is not possible on stack machines without exposing some aspect of the micro-architecture to the programmer.\"\n\"it takes about 1.88 stack-machine instructions to do the work of a register machine's RISC instruction.\"\nStack machines \"hide a faster register machine inside . . .  if the code stream instead had explicit register-select fields which directly manipulated the underlying register file, the compiler could make better use of all registers and the program would run faster.\"\n\"Interpreters for virtual stack machines are often slower than interpreters for other styles of virtual machine. This slowdown is worst when running on host machines with deep execution pipelines, such as current x86 chips. A program has to execute more instructions when compiled to a stack machine than when compiled to a register machine or memory-to-memory machine. Every variable load or constant requires its own separate Load instruction, instead of being bundled within the instruction which uses that value. \"\n\"In some interpreters, the interpreter must execute a N-way switch jump to decode the next opcode and branch to its steps for that particular opcode. . . The host machine's prefetch mechanisms are unable to predict and fetch the target of that indexed or indirect jump. So the host machine's execution pipeline must restart each time the hosted interpreter decodes another virtual instruction. This happens more often for virtual stack machines than for other styles of virtual machine.\"\n\"Pure stack machines are quite inefficient for procedures which access multiple fields from the same object. The stack machine code must reload the object pointer for each pointer+offset calculation.\"\n\n(3) AOT compilation from a stack-based IR is much more complicated than AOT compilation from an AST. This means that some implementers of wasm will simply choose to build an interpreter, rather than an AOT compiler, leading to great inefficiencies. (On the other hand, if an interpreter is what is wanted, building an interpreter for an AST-based IR would not be much more complicated than building an interpreter for a stack-based IR -- so compilation suffers with a stack-based design, but interpretation does not suffer either way.)\nBasically, stack based IRs / bytecode systems are a terrible idea if you care about either interpreter efficiency, difficulty of writing optimizing AOT compilers, or about code transparency, readability or learnability. It is sad that four guys made this decision, perhaps without considering all aspects of these issues, which will affect both billions of devices and billions of users. This is a major step back for the web.\nIs there any chance the decision could be revisited?\n(I see this is a binaryen bug, but at least people are talking about the issues here -- is there a better venue for this discussion?). @kripken Correct, wasm will typically be AOT-compiled down to native code. But most of the points I raised are also true of AOT compiled code, not just interpreted code.\nFrom the Wikipedia page on stack machines: \"The object code translators for the HP 3000 and Tandem T/16 are another example.(15)(16) They translated stack code sequences into equivalent sequences of RISC code. Minor 'local' optimizations removed much of the overhead of a stack architecture. Spare registers were used to factor out repeated address calculations. The translated code still retained plenty of emulation overhead from the mismatch between original and target machines. Despite that burden, the cycle efficiency of the translated code matched the cycle efficiency of the original stack code. And when the source code was recompiled directly to the register machine via optimizing compilers, the efficiency doubled. This shows that the stack architecture and its non-optimizing compilers were wasting over half of the power of the underlying hardware.\"\nRefs:\n(15) HP3000 Emulation on HP Precision Architecture Computers, Arndt Bergh, Keith Keilman, Daniel Magenheimer, and James Miller, Hewlett-Packard Journal, Dec 1987, p87-89. (PDF)\n(16) Migrating a CISC Computer Family onto RISC via Object Code Translation, K. Andrews and D. Sand, Proceedings of ASPLOS-V, October, 1992\nBoth of these papers are old, but the point is still true today that optimizing stack-based IR code is exceptionally difficult. Stack-based IRs make the code less efficient, and most of the difficult work of building an optimizing compiler is just using local optimizations to undo the inefficiency of the stack machine. Once you undo that efficiency, you're left with code that is borderline obfuscated, difficult to optimize further, and much less efficient than code that has not passed through a stack IR stage.\nThanks on the pointer to the wasm design repo, I'll post there.. @wllang then why not encode directly in SSA form? Adding the stack-based form only obfuscates the problem. That doesn't make any sense, there is no value added by the stack-based representation other than the intellectual curiosity of how to optimally solve the new problems that a stack machine introduces when you're trying to convert to a more useful form.. @wllang thanks for the example. What is this exactly? Is this some SSA code converted from the lowlevel stack representation, rendered into s-expression form, or is this a proposed alternative to the current stack machine model?. @wllang Thanks for explaining. The thing I don't understand is: why encode in stack form at all, if all the consumers of wasm are going to have to undo the stack representation (as you have) in order to do anything useful?\n(@kripken I don't think code size is the full answer here -- there must be a non-SSA form that is also non-stack-based, and much easier to work with than the current stack-based system.). @wllang @rossberg-chromium are you saying that for this particular stack machine, there is a guaranteed bijective mapping between the stack representation and the AST, and the stack representation is only used as an efficient serialization mechanism for the AST? If the stack representation is only used to serialize the AST, and it is neither intended to be interpreted nor to be displayed in stack-based form in browser debugging tools, then it makes sense that this is a non-issue.\n(It is not true for stack machines in general that the stack representation can be unambiguously translated into an AST, depending on what operations are supported, and what the semantics of those operations are. For example, all deserialization bets are off if the stack machine supports a goto instruction that is able to jump to any instruction, or if it supports operations that can push a varying number of parameters onto the stack, depending on an input value.). > Practically the stack code is also interpreted and is even the default view-source format it seems.\nIf the stack code is interpreted directly as a stack machine only when single-stepping in the debugger, that's fine (and, presumably, the debugger would also be free to single-step through an AST-ified representation of the stack format if it wanted to give the user the option of stepping at a higher level). However, if the fundamental stack-based execution model of wasm is preserved even in the AOT-compiled code, meaning that there is an actual stack machine (beyond the call stack) used to store all intermediate values even in compiled code, then there are enormous efficiency implications. See the links I provided in my initial comment for quantitative evidence and qualitative explanations for how badly the stack machine model can impact performance (and therefore battery life, etc.).\nSo I guess this is at the core of my concern: what will AOT compilers do with wasm stack machine code, and how will it be run outside of the debugger?. @kripken thanks for confirming this. What is the reason for the remaining 5% overhead? Does it come down to reduced opportunities for optimization in wasm SSA form code? Or overhead of sandboxing?. ",
    "sqbqamar": "@tsangint did you solve your problem..I face same problem... @tsangint did you solve your problem..I face same problem... ",
    "poutineashton": "I had the same problem and founded that I was linking with librairies that was built with another binutils version.. ",
    "ARyakhovskiy": "I had the same issue. Solved it by deleting .o file from Make/linux64GccDPOpt directory (it had conflicting copies from build on 2 different machines for some reason. This may or may not apply to your case though) and then rebuilding. Hope it helps.. ",
    "ceautery": "@kripken - I'm running 64 bit Chrome Canary 54.0.2827.0 with chrome://flags/#enable-webassembly enabled, and a local web server. To reproduce what I'm seeing...\nCreate test.asm.js with the following content:\n```\nfunction TestModule() {\n  \"use asm\";\nfunction test(n) {\n    n = n | 0;\n    return n % 2\n  }\nreturn { test: test }\n}\n```\nConvert to S-expr syntax, and assemble with:\nbinaryen/bin/asm2wasm test.asm.js -o test.wast\nbinaryen/bin/wasm-as test.wast -o test.wasm\nPlace test.wasm in web server's root directory.\nCreate test.html with this content:\n```\n<!doctype html>\n\n\n",
    "bodokaiser": "I am getting the same error.\nFull code\nLatest emscripten, chrome canary.\n. Ah I see. Is there somewhere a standalone example or do I need to defiddle the .js file?\n. Is there actually some minimal js file available which will work with asm.js and .wasm?\n. It would be nice to have a minimal html+js for\n- only asm.js\n- only wasm\n- wasm and asm as fallback\n. ",
    "artin-phares": "@kripken \n\nBy default emcc will generate a .js file that will instantiate the wasm module and pass it the necessary imports automatically for you.\n\nI'm using following command to compile\nemcc counter.c -s WASM=1 -s SIDE_MODULE=1 -o counter.wasm\nGetting .wasm file from it, but no .js file. What did I miss?. Ok. I simply did not have to use SIDE_MODULE flag (which is obviously opposite to 'by default').\nThis works fine\nemcc counter.c -s WASM=1 -o counter.js. ",
    "justinmchase": "@alexanderby \n\nInstalling all that tools, containing python etc. and doing OS specific tricks seems strange for mainstream web development toolchain.\n\nI think so too but I suspect there will be a period of bootstrapping and then the language revolution should take off. The fact that you can use binaryen to dynamically compile subsequent wasm leads me to think there is an opportunity for radically new toolchains.. Oh interesting, I thought it was running as a nodejs binary module. \ud83d\udc4d . I'll think about that, I suppose I could just malloc a chunk of linear memory and then use it as a stack. That makes sense to me. In fact that sounds fairly desirable.\nIt may make for a pretty good usecase for having multiple memories. One for stack one for heap. I saw you guys discussing that elsewhere in a different thread. If they were separate then you wouldn't have to malloc your entire stack up front, you could let it grow as much as you wanted in its own memory.\nBut I'm not sure I would add abstractions like this into binaryen itself, unless wasm natively supports it. I could totally see it as an optional module that many would want to just import and add on but I would add as little as possible to binaryen itself. For example, tying it to a particular implementation of a GC seems like a bad idea, they're not always desirable for one thing and it seems like supporting diversity increases innovation. It would make sense to have a popular GC module that you could just bolt on but I wouldn't put it into binaryen itself, imo.. ",
    "KargJonas": "If you get an error like this (with alexanderbys code): Uncaught (in promise) LinkError: WebAssembly Instantiation: Import #1 module=\"env\" function=\"__memory_base\" error: global import must be a number or WebAssembly.Global object:\nhttps://github.com/googlecodelabs/web-assembly-introduction/issues/11. ",
    "sethsamuel": "Just looked in the actual test/add.asm.js and I was missing the wrapper function.\n. ",
    "rsms": "Good idea! I'll make the change @kripken\n. Okay, no more command-line argument, but instead uses EMSCRIPTEN env var\n. PR has been updated with additional changes\n. Managed to repro. a.js generated by check.py seems to simply concatenate binaryen.js instead of loading it separately (relied on global \"this\" to reflect window, global, etc.) Changes makes export explicit to window || global || this (check.py related to binaryen.js passes for me.)\n. Okay! Tests passed.\nYou can try opening test/binaryen.js/browser.html in FF or Chrome. It essentially loads binaryen.js and does this, printing info to body as it goes:\njs\nlet buf = Binaryen.compileWast(input1);\nWasm.verifyModule(buf);\nlet m = Wasm.instantiateModule(buf, {\n  env: {\n    add: function(a, b) { return a + b; }\n  }\n});\nlet res = m.exports.add(10.0, 20)\n. Screenshot of what test/binaryen.js/browser.html looks like when window.Wasm is undefined:\n\n. https://www.w3.org/users/93385 (should also be listed under https://www.w3.org/community/webassembly/participants)\n. See https://gist.github.com/rsms/e33c61a25a31c08260161a087be03169\nTL;DR: -Oz --llvm-lto 1 -s ELIMINATE_DUPLICATE_FUNCTIONS=1 yields best over-all performance in my measurements.\n. Yup! \ud83d\ude03 \n. A constructor accepting a reference instead of a pointer is required for WebIDL use (in src/js/binaryen.idl)\n. I attempted this but was unable to make it work with closure compiler and commonjs/amd environments.\n. The iterable protocol relies on Symbol.iterator and thus for a browser without Symbol (ES6 feature), the BufferWithRandomAccess is not extended to be iterable.\n[Symbol.iterator] is how the iterable protocol is implemented. Making BufferWithRandomAccess iterable allows using it with TypedArray.from(iterable). There might be a better way to do this on a higher lever, by using TypedArray in some form (wrapped?) in the Binaryen code, avoiding using the internal BufferWithRandomAccess. But for now I think this is a good start.\n. @kripken Disabling optimizations for the debug build makes it easier to look through the generated code and to draw parallels to the source IMHO. Happy to change it to -Oz for both targets if you prefer. Let me know!\n. When building Figma to asm.js, we've found these settings to generate small and fast code.\nHowever, I'm right now running a bunch of variations of the flags for binaryen.js and will post the results with file size and perf measurements here in a few minutes.\n. ",
    "loganchien": "Sure.  Now you can find me (Logan Chien) in participants list.\n. ",
    "wibblymat": "Thanks @kripken, got it. Is the stack pointer always at offset 4?\n. ",
    "rongjiecomputer": "You are right, it is originated from src/passes/OptimizeInstructions.cpp.\n```\n(gdb) backtrace\n0  wasm::SExpressionWasmBuilder::SExpressionWasmBuilder (this=0x263fc70,\nwasm=..., module=...) at src/wasm-s-parser.h:272\n\n1  0x000000000045103b in wasm::PatternDatabase::PatternDatabase (\nthis=0x5ac9c0 <wasm::database>) at src/passes/OptimizeInstructions.cpp:59\n\n2  0x000000000041f143 in __static_initialization_and_destruction_0 (\n__initialize_p=1, __priority=65535)\nat src/passes/OptimizeInstructions.cpp:74\n\n3  0x000000000041f16d in _GLOBAL__sub_I__ZN4wasm8I32_EXPRE ()\nat src/passes/OptimizeInstructions.cpp:179\n\n4  0x0000000000422755 in __do_global_ctors ()\n5  0x00000000004013bb in __tmainCRTStartup ()\n6  0x000000000040151b in mainCRTStartup ()\n```\nsrc/passes/OptimizeInstructions.wast.processed did have EOL issue when I opened it with Notepad, so I manually changed the EOL to \\n and tried again. No luck.\n~~Maybe I should copy-paste content of src/passes/OptimizeInstructions.wast.processed instead of using #include \"OptimizeInstructions.wast.processed\"?~~ input = strdup(...) is working properly.\n(gdb) print input\n$4 = 0x42e2590 \"\\n;; This file contains patterns for OptimizeInstructions. Basic\nally, we use a DSL for the patterns,\\n;; and the DSL is just wasm itself, plus s\nome functions with special meanings\\n;;\\n;; This file is con\"...\n(gdb) print strlen(input)\n$5 = 6010\n~~Since I used-O0flag,static PatternDatabase databaseis initialized even though it is not used, maybe-O2will work.~~ I have tried-O2and-O2 -g` separately, both failed.\n. I think I know what was the issue: the order of initialization of global variables.\nI set a breakpoint at __static_initialization_and_destruction_0 to check the initialization of global variables. But when I reached wasm::PatternDatabase::PatternDatabase from OptimizeInstructions.cpp, Name MODULE(\"module\") from wasm.cpp was not initialized yet. This is why assert(module[0]->str() == MODULE) in wasm::SExpressionWasmBuilder::SExpressionWasmBuilder failed.\n(gdb) print module[0]->str()\n$1 = {str = 0x2653dc0 \"module\"}\n(gdb) print MODULE\n$2 = {<cashew::IString> = {str = 0x0}, <No data fields>}\nDo you know how to manually re-order the sequence of global variables initialization?\n. I found a workaround for this: instead of declaring static PatternDatabase database in global scope of OptimizeInstructions.cpp, declare it in OptimizeInstructions::visitExpression since database is only used in this function. It works for now, but not if in the future database is used by more than one function across multiple codes.\n. #694 The fix is working nicely, should be no problem now!\n. Done!\nI have just joined the group, didn't know that a student can join the group too!\n. Is split.wast included in https://storage.googleapis.com/wasm-llvm/builds/linux/11453/wasm-binaries-11453.tbz2 or somewhere else?\n. I changed the implementation and ran benchmark on BananaBread, please see the link below.\nhttps://gist.github.com/rongjiecomputer/b56c780137ef53502a0c2cd78938d6c4\n@dschuff  std::lower_bound is more efficient than my hand-written version. The only way to surpass <algorithm> is directly code in assembly.\nstd::lower_bound does not seem to improve the performance much. It is worth noting that std::move and std::move_backward improve the performance much more than binary search, so it looks like LocalSet spends more time in moving data than searching.\nPlease let me know which implementation is better.\n. @kripken I have no more changes to make. IMHO, changing data structure can wait until the compiler is more or less stable.\n. This significantly speed up --debug when BINARYEN_PASS_DEBUG is not set, only takes about 10+ seconds to finish everything with banana.wast!\n. Summary of commit Simplify print:\n- Replace std::endl in stringify (simple_ast.h) to '\\n'. (Flushing too much while printing large amount of data is inefficient)\n- Replace const char* string with length exactly 1 to char in printing.\n- Combine multiple const char* strings into one in printing.\n// Before\nos << \"Hello\\n\";\nos << \"World\\n\";\n// After\nos << \"Hello\\n\"\n      \"World\\n\";\nBy the way, why some (actually most)  C++ codes in this project use cout etc while others use [f]printf? (I personally prefer printf for speed and program size).\n. Files with C-style printf:\n- src/support/archive.cpp\n- src/emscripten-optimizer/parser.h\n- src/cfg/Relooper.cpp\n- src/emscripten-optimizer/simple_ast.h\nIf it is decided to use ostream everywhere, please add this to the start of all int main():\nstd::ios_base::sync_with_stdio(false); // By not syncing with C stdio, ostream works faster. But if one place still use printf, things will break.\nstd::cin.tie(0); //  Don't flush cout before reading from cin\nPlease see http://www.open-std.org/JTC1/SC22/WG21/docs/TR18015.pdf (page 68) for reasons why iostream is much hated and how to improve it (slightly).\n. The tests got stuck before compilation was even started.\nShould I make another commit to convert those 4 files with stdio.h to iostream before merging?\n. I re-forked the repository and only applied diff related to wrap description. The commit for \"Simplify print\" is removed.. I use binaryen to learn how to hand-write wast and asm.js, I often get assertion failures because syntax error in my input file, so much until I decided to run binaryen only in gdb even though I am not debugging the program.\n. In the end I use d8 --validate_asm to check asm.js, compile it to wast with asm2wasm. Use wast2wasm to check hand-written/compiled wast, compile it to wasm, then interact with it using d8 --expose_wasm.\n. Not a frequent contributor, but I really prefer IndentCaseLabels: true (which is what current codebase does), for the rest my opinion is the same as everyone else (LLVM + PointerAlignment: left).. Done!\n. Yes.SetConsoleTextAttribute works by changing internal console flag at the moment of printing, instead of inserting a \\033[* like Linux/Mac. Since this information cannot be passed to another program by piping, color will not work. Forcing colors is thus meaningless for Windows.\n. For Windows, [f]printf, cout/cerr or any ostream in text/console mode will automatically expand '\\n' to \"\\r\\n\", but not in binary mode.\n. static const?. This works:\nstatic constexpr char DEFAULT_OPT_PASSES[] = \"O\";. ",
    "jgravelle-google": "Depends on https://github.com/kripken/emscripten/pull/4558 in order to not crash in emscripten.py - an assumption there was that we would not have an empty string as the function body in an EM_ASM call, which is only a problem for s2wasm for reasons I'm not completely aware of. asm2wasm was successfully outputting empty functions for the same input.\n. Seems ok to me, for what it's worth?\n. lgtm\n. Turns out there were autogenerated llvm tests that cover this, that we updated incorrectly with the 0xc changes.\nI could add tests to unit.wast, but they'd basically be a copy+paste of the tests in i64-load-store-alignment.wast. Thoughts?\n. The \"unknown relocation: environ\" is probably one of the known failures: https://github.com/kripken/emscripten/blob/incoming/tests/test_core.py#L4615\nIt seems to be an internal emscripten/binaryen thing (s2wasm not being aware of the things in library.js because of an ordering/forwarding mismatch, is my current theory)\nCurrently s2wasm isn't quite ready for production use, so I fear you'll run into more issues for a while with it. I'd actually really like to see what those issues are, so I appreciate you trying it, but I don't want you to set your expectations too high just yet.\nwebassembly.org doesn't mention s2wasm at all (aside from a few mentions of the \"upcoming upstream LLVM wasm backend\"), but binaryen's README.md doesn't make it very clear that it's still experimental. Should we reword that to be more explicit?\n. That looks similar to failure we're seeing on the wasm waterfall https://wasm-stat.us/builders/linux/builds/16834/steps/Link%20LLVM%20Torture%20with%20s2wasm/logs/stdio\n(More general wasm waterfall link: https://wasm-stat.us/console)\nThis is due to some recent churn in what the LLVM backend is emitting that s2wasm doesn't support yet. The EM_ASM change fixes a post-s2wasm failure, so this just a regression as opposed to uncovering new failure.\nIf you wanted to try with the EM_ASM change but not the breaking LLVM change, I currently have the following revisions:\nLLVM - git hash fd07c4c7b5350fa8a0aa91e4248f0023638db5d8, subversion revision 295840\nclang - git hash a745be5724ad975e8456500c52f12d7ef2995770, subversion revision 295843\nWhich should be compatible with latest emscripten/binaryen.\nThanks for trying it again!. Added tests, addressed all comments.\nRefactored to generate expressions more directly.\nAdded some minor optimizations to turn\ni32.const $push0=, 0\ni32.store foo+2($pop0), 7\nfrom\n(i32.store\n  (i32.add\n    (i32.const 0)\n    (i32.add\n      (i32.const 2)\n      (get_global $foo)\n    )\n  )\n  (i32.const 7)\n)\ninto\n(i32.store offset=2\n  (get_global $foo)\n  (i32.const 7)\n). Correct, instead of ./check.py --suite s2wasm or something, I run test/s2wasm.py.\nThe nice thing there is we don't need to modify check.py to check if not options.test_suite or options.test_suite == 's2wasm': before each test.. The story is I didn't run the waterfall tests before merging https://github.com/WebAssembly/binaryen/pull/843 . That runs a bunch of backend tests without emscripten, which means running s2wasm without the --emscripten-glue flag, which didn't add any global imports to the wast, which results in invalid get_globals.\nImporting globals isn't actually specific to emscripten, so we should just always import imported globals.. Thinking more about taking a node with unreachable child and making it unreachable:\nI'm going to use U as shorthand for unreachable for the rest of this comment.\nAlso ([letter]...) is an arbitrary sequence of AST nodes that'll get backreferenced later.\n(block f32\n  (A...)\n  (block U\n    (B...)\n  )\n  (C...)\n)\nIs it always valid to transform this to:\n(block U\n  (A...)\n  (block U\n    (B...)\n  )\n)\nMy gut says yes. This is a form of DCE, and the bubbling out of U opens up more opportunities later on.\nFurther, we got the outer block with type f32 because the context it's in requires it. Therefore we can re-write the type later when we serialize to wasm. So:\n(func (result f32) (block f32 (A...) (block U (B...)) (C...))) ->\n(func (result f32) (block U (A...) (block U (B...)))) ->\n(func (result f32) (block f32 (A...) (block f32 (B...))))\nWhere can't we bubble out U? if is one such case. For example given\n(if i32\n  (condition)\n  (block U ...)\n  (block i32 ...)\n)\n, we can't rewrite the if with U because it is not always unreachable, so any bubbling out has to stop there.\nHow does this interact with br_if and br_table? br_if and br are modeled in Binaryen IR as Break nodes, which optionally take a condition and optionally a value. An unconditional break is always unreachable. A conditional break has the value that it passes. That value might be unreachable, and in that case the break should take unreachable as its value and continue propagating it.\nPresumably we want a single pass to propogate unreachability as far as it can go that we run early, followed by unreachable-DCE?. I believe that's a misunderstanding we had while drafting the post that wasn't fixed after the fact - we noticed for the next two examples and you're right it's not valid.\nCutely, (i32.add (br 0) (f32.const 0)) I believe is valid wasm, because the linear form is f32.const 0; br 0; i32.add. But it's saner to not let that typecheck in binaryen IR?. LGTM as well. In general I usually keep quiet because I'm unsure that I have enough context to know whether the general direction is a good idea or not. I'll try to err on the side of asking obvious questions going forward.. lgtm. Good call, done. Oh never did land this, whoops. This currently happens to not cause problems, given functionsToThunk = {1, 2, __dummyFunc, 3}, the state after the std::remove is probably something like {1, 2, 3, 3}, so we try to add 3 twice, which happens to not do anything because it's already in the file. But, we should probably not do that.. Looks fine to me. I think this is really a JSBackend issue, but it's only user-visible with asm2wasm which is why I filed it in Binaryen.\nAnd it isn't clang, the generated IR that we get out of clang still leaves the conversion as being done conditionally:\n```llvm\n; Function Attrs: noinline nounwind\ndefine i32 @main() #0 !dbg !9 {\nentry:\n  %retval = alloca i32, align 4\n  %d = alloca double, align 8\n  %l = alloca i32, align 4\n  store i32 0, i32 %retval, align 4\n  call void @llvm.dbg.declare(metadata double %d, metadata !13, metadata !15), !dbg !16\n  store double -1.200000e+01, double %d, align 8, !dbg !16\n  call void @llvm.dbg.declare(metadata i32 %l, metadata !17, metadata !15), !dbg !18\n  %0 = load double, double* %d, align 8, !dbg !19\n  %cmp = fcmp ogt double %0, 1.000000e+04, !dbg !20\n  br i1 %cmp, label %cond.true, label %cond.false, !dbg !21\ncond.true:                                        ; preds = %entry\n  %1 = load double, double* %d, align 8, !dbg !22\n  %conv = fptoui double %1 to i32, !dbg !24\n  br label %cond.end, !dbg !25\ncond.false:                                       ; preds = %entry\n  %2 = load double, double* %d, align 8, !dbg !26\n  %conv1 = fptosi double %2 to i32, !dbg !28\n  br label %cond.end, !dbg !29\ncond.end:                                         ; preds = %cond.false, %cond.true\n  %cond = phi i32 [ %conv, %cond.true ], [ %conv1, %cond.false ], !dbg !30\n  store i32 %cond, i32 %l, align 4, !dbg !32\n  %3 = load i32, i32 %l, align 4, !dbg !33\n  %cmp2 = icmp ne i32 %3, -12, !dbg !35\n  br i1 %cmp2, label %if.then, label %if.end, !dbg !36\nif.then:                                          ; preds = %cond.end\n  call void @abort() #9, !dbg !37\n  unreachable, !dbg !37\nif.end:                                           ; preds = %cond.end\n  call void @exit(i32 0) #9, !dbg !38\n  unreachable, !dbg !38\nreturn:                                           ; No predecessors!\n  %4 = load i32, i32* %retval, align 4, !dbg !39\n  ret i32 %4, !dbg !39\n}\n```\nThe wasm backend leaves it to be conditionally executed (and doesn't trap), and the IR looks pretty much the same for both.. (thinking out loud)\nThis also makes sense from the perspective of nested operations and unreachable propagation.\nE.g.,\n(i32.add\n  (i32.const 6)\n  (i32.add\n    (unreachable)\n    (i32.call $foo)\n  )\n)\ncorresponds to the linear\ni32.const 6\nunreachable\ni32.call $foo\ni32.add\ni32.add\nso the outer add should also be unreachable, so we should set the inner add to unreachable so that can propagate.. Hm. Sounds like we need to re-rethink what unreachable means in the type system. https://github.com/WebAssembly/binaryen/issues/903\nMy gut feeling is that the complexity stems from:\n1. us overloading unreachable to mean both \"this node has unreachable type\", and \"this node was marked unreachable as part of an IR pass and we need to fix it up when we want to output wasm\"\n2. unreachability can propagate both up and down the layers of the AST. So the asmjs folder in the emscripten cache is for the asm.js pipeline. Meaning that libc.bc was built with the asmjs-unknown-emscripten target triple, whereas s2wasm expects the wasm32-unknown-unknown triple. So I wouldn't expect that to work.\nOf note is that Emscripten supports running the wasm LLVM backend + s2wasm pipeline, https://github.com/kripken/emscripten/wiki/New-WebAssembly-Backend . It uses ~/.emscripten_cache/wasm/ as its cache folder.. In theory, probably. In practice, it'll be processing patterns we don't expect, so who knows.. That's less verbose and doesn't lose any information, good call.\nAnd I hadn't fully considered that. In my head this fixes failing emscripten tests, but it'd be good to have in-repo testing of it.\nProbably something like https://github.com/WebAssembly/binaryen/blob/master/scripts/test/s2wasm.py#L98 ?. Ah, yeah makes sense.. Yay refactoring. Looks generally good modulo @kripken's comments. Nice. Oh, I didn't think about that as being a lint failure but no yeah that makes sense. Probably fine as-is then.. lgtm. Oh, missed your last comment.\nSo yeah, seems like there will be some possible (albeit maybe contrived?) cases where it doesn't fully work, but that's known/expected and brings us closer to correct.\nLgtm. A bit late, but code looks fine to me. Looks good to me. @kripken any more thoughts?. Supported in https://github.com/WebAssembly/binaryen/pull/1168 and https://github.com/WebAssembly/binaryen/pull/1210. I think this pass should be ready to merge at this point? Is there anything I'm missing?. Ok there we go.\nSo: what we discussed earlier turned out to be way trickier than I was expecting due to timing issues that I still don't understand. So I bailed on that and basically did what @kripken suggested in the first place, and just directly call the makeTrapping functions inline in asm2wasm, the way they were done before I touched it at all.\nI did this by introducing a new helper class, GeneratedTrappingFunctions, which either collects the generated functions to add later, or it adds them immediately to the module. This lets us avoid any global/static variables, while letting us keep  the desired functionality on either end, and reuse the code to boot.\nThe test diffs now are totally additive (s2wasm test case, plus the added trapping_sint_div_s case in unit.asm.js), or new functionality (handling f32-to-int in asm2wasm without having to convert to \n f64s first, and [not yet implemented] double->uint32 conversion), which should be much more reasonable.\nOnly thing I'm unhappy with is the name: GeneratedTrappingFunctions. Any suggestions?. In other fun news, rebasing this on master I run into a problem:\nRunning bin/asm2wasm test/unit.asm.js -O --mem-init=a.mem gives different results for the function trapping_sint_div_s when the environment variable BINARYEN_PASS_DEBUG is 1. With it set, the function gets const-folded into just (i32.const 0), otherwise it calls the generated function as usual.. Yep, happens with BINARYEN_CORES=1 too.\nI figure the problem is that we're adding functions while we're iterating over the module in asm2wasm, therefore the call target isn't visible when working in parallel, therefore it can't be const-folded. But when debugging or single-threading, that's less of a problem.\nIn any case I only added the trapping_sint_div_s test because I was changing the order of optimizations/inlining with respect to trapping functions. So I just removed the offending test because that's not necessarily something we care about now that the timing is the same and other tests haven't changed.. Sure, the test I added in https://github.com/WebAssembly/binaryen/pull/1168/commits/33cbbc8506a2523b41ed1489ca1961706bd2638c causes the problem. Just tested it on master and it reproduces the issue.\nI think it's because asm2wasm is creating new functions while running optimizations on functions in the background.. Hm, can we land this before #1208? That fix is going to look very different as a result of this PR.\nAnything else outstanding here or should I merge?. Hello @jirutka, some feedback on your communication style.\nSome of the language used in your comments can be perceived as being disrespectful or insulting. Things such as:\n\nOMG, am I really the only one here who understand how Travis works\n\nand\n\nTo be honest it\u2019s hard to believe you that you\u2019ve actually read the Travis documentation.\n\nadd nothing productive to the conversation. In saying:\n\nThis has nothing in common with distro packaging, but purely with CI, actually very essential principle of CI\u2026\n\nyour \"actually very essential principle of CI\" can be easily read as \"this is elementary and you are stupid.\" Because your message is otherwise unchanged by leaving it off, that it is included at all serves to communicate that that is the reading you intended.\nYou've left other comments that do serve a purpose, but are phrased in such a way as to be insulting as well. For example:\n\nIt (obviously) does not deploy for every commit on master\n\nis equally factually correct and useful rewritten as:\n\nIt does not deploy for every commit on master\nAha, this is really very confusing\u2026 \ud83e\udd26\u200d\u2642\ufe0f\n\nis a reasonable point to make, that the current versioning scheme is confusing. However, the italicized \"very\", paired with the \ud83e\udd26\u200d\u2642\ufe0f, can easily be read as saying \"whoever came up with it is an idiot.\" Especially given that you are addressing the authors directly, perhaps a gentler tone would be more productive. For example:\n\nI see. That's pretty unintuitive for a newcomer.\n\nGiven the reaction you've already gotten, your tone seems to be coming across as disrespectful, even if that wasn't the intention. So please try to pay more attention to that in the future.\nIn general, I would like that the Binaryen repo be a pleasant place for people to work. One where debate is encouraged, because all participants feel secure that ideas and implementations will be criticized, not people, character, or motivations.. Overall looks good, but Travis is failing because:\nwasm2asm: /home/travis/build/WebAssembly/binaryen/src/passes/I64ToI32Lowering.cpp:70:\nIndex wasm::I64ToI32Lowering::TempVar::operator unsigned int(): Assertion `!moved' failed.\nso that should probably be fixed. I think that as a general principle, pulling in external tests being off-by-default is totally reasonable. Probably the spec tests should still be ran by default, because they're smaller and more normative, but yeah most people probably don't need to run the waterfall all the time.. Rrright, the bitwise operators return ints, not enum types.\nSome searching says there's probably not a simple better way: https://blogs.eae.utah.edu/jkenkel/c-bitmasks-the-mess/\nFrom there: I think the best solution is to add something like Windows' DEFINE_ENUM_FLAG_OPERATORS macro to a Binaryen util header? (Either re-implement or copy: http://www.cplusplus.com/forum/general/44137/ ) That way we get around this mostly easily in the future.\nI remember now running into the same problem when adding enum flags in wasm2asm, which we then changed to bitfields.. Pretty much. It doesn't sit well with me because it's adding to domain-logic complexity to avoid implementational coupling.\nAlthough one minor upside is any zero-initialized TrapMode fields will be Invalid unless initialized, which counts for something? calloc users rejoice?\nBut yeah, optional is what I really want here. Or something like Haskell's Either. Still this isn't too bad.. Not possible to do in Walker because that tosses out the WalkerType, so super::scan just calls Walker::scan which just aborts.\nAlternatively, we could redeclare the typedef in each derived walker, which would keep the WalkerType information, but duplicate the typedef and add something to remember to do in the future when we derive Walkers probably. I like the small-change part of just having one typedef, but I'm not married to that per se.\nHistorical funsies, C++ almost had a super keyword that did basically this, but the committee decided that typedeffing everywhere was better https://stackoverflow.com/a/180633 .. Trying with the example you provided:\nTrying to access the field with a period in its name in JS like so: main.exports._GLOBAL__sub_I_main.cpp, does not work.\nAccessing it via its string name: main.exports['_GLOBAL__sub_I_main.cpp'], has no issues, aside from the memory access out of bounds runtime error that you saw from manually editing the wat. So, not a bug at all as far as I can tell.\nThe memory out of bounds is because that function is writing locals to the stack in linear memory, which has no corresponding data section to initialize it, so it starts out zeroed, gets subtracted from in _ZN16PermutationTable7SetSeedEi, underflows to UINT_MAX, then is out of bounds when written to in the call to _ZN3rng7setSeedEy. So, also not a bug.\nThe wasm32-unknown-unknown-wasm target is very much under development. The wasm64 target is defined, but pretty much entirely unimplemented.. Nice, thanks. No PRs, no staged commits that rely on that dir, looks good to me. Updating the pinned waterfall version to take advantage of attributes in the expected failures. Updating torture-s files as well so we can have green builds for both.. Ping @kripken @dschuff , any objections to updating the waterfall revision / checked in .s torture tests?. As I understand it, the checked in .s torture tests are something of an additional layer of regression testing for the s2wasm parser. I think they made more sense before the wasm spec had stabilized?\nBut yeah, we won't recreate them after removing s2wasm.. For what it's worth I have some support for reading reloc and linking sections in a tool I'm working on to generate emscripten-readable metadata (currently called lld-metadata, which will change before it lands) on the o2wasm branch. If you want to use that in any way, it's here: https://github.com/WebAssembly/binaryen/blob/o2wasm/src/tools/lld-metadata.cpp. \"o2wasm\" is on a branch still: https://github.com/WebAssembly/binaryen/pull/1346 and https://github.com/kripken/emscripten/pull/6056\nIt's experimental and relies on LLD support, which is also somewhat-experimental (although last I heard it's getting closer). Having looked into this a bit, it looks like the .s that we're getting from llc has calls to __assert_fail@FUNCTION, but indirect references to (i.e. pushes to the value stack of) just __assert_fail without the @FUNCTION. The @FUNCTION version is declared as an external function and imported, but the references don't match, and are considered unresolved link errors. Need to look a bit deeper to see why that's the case. https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vague mentions it\nSounds like the mangling happens first, and only post-mangled symbols can be duplicated. It's resolved at link-time by putting things in separate sections. Wasm only has one names section, but names are allowed to be duplicated, so that works for the binary format.\nBinaryen's problem is that it uses names internally to refer to things. So we could either rework Binaryen to allow name duplication, or we can add some magic to re-dupe any duplicated names before writing out a wasm binary. Change the . separator to .$#MAGIC_BINARYEN_DUPE: or something that really really shouldn't collide with anything, and strip that pattern again before writing out. And I think we'd want to preserve the magic dupe string in the text format, to avoid potential problems there (e.g. two functions with the same symbol but different signatures, or being able to reconstruct a similar binary from a text representation).\n@jfbastien should we figure that out before landing this? I'm in favor of landing, because currently modules with duplicate symbols fail to be read, instead of can't be demangled, so this should still be a step forward.. It is a non-obvious gotcha that I had not thought about, so thank you for bringing it up :)\nWas trying to make sure there were no second-order issues that relied on demangling that I was also missing. Sounds like this is good to merge then.. Ping, any go/no-go?. Whoops, sorry https://github.com/WebAssembly/binaryen/pull/1426. Why .was instead of .wat?. Oh I didn't mention it in the description but this also affects the o2wasm path. Anything wasm-backend. I said \"s2wasm\" very imprecisely there.\nThis won't make transitioning any easier (o2wasm path is currently set up with text output to fit here), but it is an improvement to both of them, and some weirdness we can probably remove.. s2wasm doesn't recognize the get_global .s syntax from LLVM.\nThere's actually two wasm triples, wasm32-unknown-unknown-elf and wasm32-unknown-unknown-wasm. -wasm is the default, but s2wasm expects the conventions of -elf. So, the command you want for use with s2wasm is:\nclang -emit-llvm --target=wasm32-unknown-unknown-elf -nostdlib -S main.c\nFor posterity: -wasm is the default when manually invoking clang, because that can output a wasm object file (.o), which LLD can link, skipping s2wasm and the assembly format entirely. That's another path to building wasm modules, though it's neither entirely stable nor entirely supported by Emscripten at the moment, so it's not as recommended for use today, unless you're feeling experimental.. o2wasm is an older informal name for the path that uses LLD as a linker instead of s2wasm.\ns2wasm path: .c file -> clang -S -> .s file -> s2wasm --emscripten-glue -> .wasm file with emscripten runtime functions\no2wasm path: .c file -> clang -c -> .o file -> lld -> .wasm file -> wasm-emscripten-finalize -> .wasm file with emscripten runtime functions\nwasm-emscripten-finalize is the relevant binaryen tool for that particular path.\nIn the future the plan is to let LLD be the linker, and support the text format via an assembler/disassembler from LLVM as well.\nFor the time being I don't think there's much harm in adding things to s2wasm, because that works today. Only downside would be totally new features that won't be supported in the object file format, but import_module should be.. Yeah we landed wasm-emscripten-finalize so we there's no need for it, deleted.. I agree that we should fix it in a Binaryen pass, which is why I filed this here as opposed to Emscripten :)\nAnd I think that saying \"wasm backend is smaller than asm2wasm because asm2wasm does something fairly degenerate\" is an unsatisfying place to wind up.. My gut says we should only fix major issues.\nSo here the issue is that we want to export both the memory and a function. Currently we only export memory with the name \"memory\", making any functions (and presumably globals) named \"memory\" get clobbered by the memory export.\nFundamentally in wasm, we can't export two things with the same name. https://github.com/WebAssembly/design/blob/master/Modules.md#exports\nI think the correct fix here would be some way to change the name of the memory export, so that the user can use \"memory\" for something else. I would file that as being a feature request, and in the face of deprecation recommend that we not spend time on it (although patches welcome?).\nA workaround here exists in the form of the --import-memory flag, which doesn't generate an export for memory in the first place.\nIt may be worth considering here how other binaryen tools handle this sort of name collision, and if it makes sense to add a renaming flag to asm2wasm/wasm-opt.. @sbc100 @binji and I had an in-person discussion\nSome highlights:\n\n\nWe should probably fail with an error when we do have these collisions, vs. silently dropping one of the exports.\n\n\nWe should change the default export name (in LLD at least) to __wasm_memory (or something), with a flag to override. Emscripten can keep using \"memory\" via that flag.\nWe could change the name to just __memory which would be nicer for the hello world-style programs, but if we ever need to change that it would be a breaking change, so it's probably better to be conservative now.. I believe bin/empty.txt is so the directory is pre-created upon checkout. Without any files in a directory git doesn't track directories.. It does link them in, but it does so as .s files IIRC. Which maybe we want to use here, but I feel like using more general .wast would be better. I do believe wasm-linker would be in scope to remove as part of removing s2wasm.. The reason for this is there are two wasm targets in llvm, one made for s2wasm, and one made to better model wasm instructions 1-1. So, calling s2wasm magic.s, I get \n```\n[[function element:]]:\n==========\nend_function\n.Lfunc_end0:\n    .size   magic, .Lfunc_end0-magic\n\n\n==========\nAborted\nWhich is to say it trips over the `end_function`. This is because the `wasm32` target models the end of a function as an instruction, whereas the `wasm32-unknown-unknown-elf` target (the one made for s2wasm) uses the `.endfunc` directive instead. Replacing one with the other, I get:\n(module\n (table 0 anyfunc)\n (memory $0 1)\n (export \"memory\" (memory $0))\n (export \"magic\" (func $magic))\n (func $magic (; 0 ;) (result i32)\n  (i32.const 610)\n )\n)\n```\nwhich works!\nSo: use --target=wasm32-unknown-unknown-elf, and it should Just Work.\n(additionally you should be able to just say clang --target=wasm32-unknown-unknown-elf magic.cpp -S -o magic.s, if you don't want to look at the intermediate bitcode). Oh interesting, I misread that. Lgtm then, once it starts working.\n(Looks like Travis remembers directory between commands, so only one cd ${BUILD_DIR}?. > May be you have older cpu architecture than me where multiplication is not so cheap\nTo me this says even more strongly that this is the VM's job. (In theory) the VM can know what CPU the code is running on, and if this optimization makes sense. Even if not all the VMs are implementing this today, we should ship maximally optimizable code for the future. I'd hate to be in a position where the VMs pattern-match on this in order to undo it back into a division on some architectures, for example.\nFor what it's worth, running the webassembly.studio project in Chrome 67 on my machine gives me:\ndivision by uint64 constant 1e10 (mulh/shift): 279.611328125ms\ndivision by uint64 constant 1e10 (normal): 934.128173828125ms\nAnd Firefox Nightly (62):\ndivision by uint64 constant 1e10 (mulh/shift): 366ms\ndivision by uint64 constant 1e10 (normal): 1094ms. Upstream LLVM + LLD, which is what emscripten is using now.\nWhich is to say, clang hello.c -o hello.wasm --target=wasm32 -nostdlib -Xlinker --no-entry -Xlinker --allow-undefined should just work. Apparently DAE only removes dead arguments, it's IPConstantPropagation that makes them dead in the first place. This is maybe semantically useful, because there might be dead arguments that aren't due to constant-propagation, so it could be useful to run DAE without IPCP?. This looks good, is there an accompanying emscripten-side change? Or does this somehow not break things.\nMight be useful to see the simplifications this allows us to do emscripten-side, to see how much this buys us.\nFor clarity: I fully support minimizing the inconsistencies and unifying these, and this seems like the easiest way to do that.\nGiven infinite engineering time, I'd like to move asm2wasm to use upstream's conventions. It's possible that the simplest path to get to that state is to maintain both conventions for now, and convert for free when we eventually deprecate asm2wasm. It's likely though that it doesn't matter which convention we use, and simplifying our implementation is the only thing we can actually get out of it, so I don't feel at all strongly about this, and am just thinking out loud in case anyone else has better insights here.. In general I feel we should audit the deleted tests for features we still care about that we no longer have coverage for, which is mostly going to be metadata, but any of the emscripten-glue parts of s2wasm may not have a corresponding wasm-emscripten-finalize test.. In general wasm-emscripten-finalize lets us change LLVM output to match emscripten's expectations, meaning it frees us to make changes that are convenient for one without worrying about breaking the other.\nSo: the only reasons I'm aware of that we even generate the stackSave/stackRestore functions is for emscripten interop. If we want to change how that's done, there's no constraint on it other than emscripten library code.\nConsiderations:\nstackSave/stackRestore get called by emscripten library js code in general at runtime, so we need to generate it anyway in wasm-emscripten-finalize to metaDCE later as far as I know.\nThey definitely get called in dynamic libraries today because we can't export mutable globals.\nBut, I'd think that changing only the initially-set stack position shouldn't affect anything else, and should be pretty straightforward. Sgtm. Seems fine to me, I think custom analysis would be overkill, though it would probably have fewer side-effects on the rest of the module.\nAlternatively we could teach the EM_JS pass to understand the O0 patterns, because it will pretty much always be one or the other, if that's simpler and not too fragile.. I'm generally opposed to boolean arguments, but was thinking that in this case it had a 1:1 mapping with user input, i.e. the \"--allow-memory-growth\" flag. However that's more of a consequence of how it happens to work, today, so it makes sense to change it.\nGoing to go with calling it directly from s2wasm.cpp, that seems like the right way to slice it.\nThanks!\n. I'm liking the feeling of having a wasm::emscripten:: namespace for this file.\n. Ah, whoops - forgot to take that out after adding the header.\nAlthough, I also moved AsmConstWalker into the .cpp file, so the header doesn't need to be including wasm-traversal.h anymore.\n. This doesn't seem like a great spot for this, but I'm not sure where it belongs.\n... it seems especially poor because wasm-emscripten.cpp has to include wasm-linker.h, just because it needs to know about dummyFunction.\nThoughts/ideas?\n. This is the one where we really need it :)\nIf we don't have any entries in the table, here we want to return an empty container that we can ignore. If we wanted a ref, we need to take it from the table, which is empty, so we would either assert or index-out-of-bounds.\nIn particular splitting this into ref and non-ref versions lets us modify the data conveniently, and read the data, without needing to guard against size > 0 so we don't mutate it, is the intent\n. In my head, getTableDataRef is useful for when you want to modify the table data, and getTableData is for when you want to read it. Getting the ref directly will be faster, returning a copy is more in line with that intent.\n. More middle-of-the-road, lets strip dummyFunction before calling into wasm-emscripten (https://github.com/WebAssembly/binaryen/commit/1c5fdb97b7b90327c87f6434d8163f19ec9fb423). That way, the linker can exclude what it wants to exclude, and the i64-exclusion can still be embedding-specific knowledge.\n. Rephrasing: we don't need it, but I think it's cleaner.\nPreviously we had a check that size > 0 so we would avoid calling getTableSegment, which would add a segment if there was none, which would cause an empty table to be emitted in the wasm, vs no table which was expected.\nThe progression was essentially: check or misbehave quietly -> check or fail loudly -> don't need to check. So, the whole point of the getTableData method is to abstract out the if. Whether that's a worthwhile abstraction, I'm not totally sure, though I feel the calling code is clearer.\n. Debug print?\n. Would required=False with a default of os.path.join(ROOT_DIR, 'third_party', ... make sense?\n. Right, this is in a for loop. Lgtm!\n. Merge conflicted here, and in 15 more places\nLooks to be only in the autogenerated tests though, so probably worth just regenerating them now that this is rebased\n. Oh right, the files are all-green and end with .orig\nLgtm\n. The indentation level needs to live across instances. The class takes advantage of RAII to decrement the indentation when we're done visiting a node. So, a given instance is transient, but the level of indentation is fundamentally shared.\nFor now I can add wasm-interpreter.cpp with the implementation of the Indenter class, and as a future project we can start migrating things into it.\n. Somewhat ironic, that.\n. Should probably be a better name as well.\n. Added because when building wasm-interpreter.cpp, Visitor was undefined. We had happened to have already included pass.h before including wasm-interpreter.h elsewhere.\n. My thought was to futureproof; if we do something weird like i64.store48 we possibly want it to fall back to that logic.\nAlthough that would still cause problems by writing 2 too many bytes, and it doesn't protect against anything larger, and overall yeah it's probably better to err on readability here.\n. Rrright.\nWe only generate i64 stores in printf when using the llvm wasm backend. Is there a way to convince asm2wasm to do so as part of the i64 wasm-only additions you added recently? If not, should I move this under the wasm_backend tests? \n. Talking with @dschuff, this test probably shouldn't actually be relegated to wasm_backend only. The reason being there's no guarantee that we'll never have truncated stores in asm2wasm, so as soon as we do this case is being generated and not tested.\nThe reason the wasm backend emits i64.store32 is simply to avoid two operations where one would suffice. It would be possible (and maybe marginally beneficial?) to add a peephole pass in binaryen that converts (i32.store (i32.wrap <i64 expr>)) to (i64.store32 <i64 expr>)\nThe C code in vprintf.c that winds up generating the i64.store8s looks like:\nc\nstatic char *fmt_u(uintmax_t x, char *s)\n{\n    unsigned long y;\n    for (   ; x>ULONG_MAX; x/=10) *--s = '0' + x%10;\n    for (y=x;           y; y/=10) *--s = '0' + y%10;\n    return s;\n}\n(uintmax_t is i64 on 64-bit targets.)\nSo we have an i64 and write to an i8, so i64.store8 is a natural instruction.\n. Weird. The wast emitted by my asm2wasm without the optimization for fmt_u includes:\n(i32.store8\n  (tee_local $1\n    (i32.add\n      (get_local $1)\n      (i32.const -1)\n    )\n  )\n  (i32.wrap/i64\n    (i64.or\n      (call $i64u-rem\n        (get_local $0)\n        (i64.const 10)\n      )\n      (i64.const 48)\n    )\n  )\n)\nwhich looks exactly like it should match the pattern\n. Checking out the i64-store8 branch and compiling again I get something totally different:\n(set_local $$rem\n  (call $i64u-rem\n    (get_local $$x$addr$012)\n    (i64.const 10)\n  )\n)\n(set_local $$add\n  (i64.or\n    (get_local $$rem)\n    (i64.const 48)\n  )\n)\n(set_local $$conv\n  (i32.and\n    (i32.wrap/i64\n      (get_local $$add)\n    )\n    (i32.const 255)\n  )\n)\n(set_local $$incdec$ptr\n  (i32.add\n    (get_local $$s$addr$013)\n    (i32.const -1)\n  )\n)\n(i32.store8\n  (get_local $$incdec$ptr)\n  (get_local $$conv)\n)\nwhich doesn't even look like the same style so I'm probably doing something wrong.\nAre the i64.store8s being generated in (func $_fmt_u?\n. Ah, makes sense\nMeanwhile I think my binaryen is generating unoptimized code because of an impedance mismatch between the new -O flags and the version of emscripten I'm using\nSo that should be all the mysteries solved\n. Apparently '\\n' gets expanded to \"\\r\\n\" on windows regardless, and endl is defind as being identical to os << '\\n' << std::flush.\nFrom the C++14 draft spec here (http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf , 12MB PDF):\nnamespace std {\n  template <class charT, class traits>\n    basic_ostream<charT,traits>& endl(basic_ostream<charT,traits>& os);\n  }\n}\n\u00a7 27.7.3.8 1063\n1 Effects: Calls os.put(os.widen(\u2019\\n\u2019)), then os.flush().\n2 Returns: os.\nAnd I cannot find any reference in the spec itself that explains why os << '\\n' gets correctly expanded. But, from http://en.cppreference.com/w/cpp/io/basic_ostream/operator_ltlt2:\nBefore insertion, first, all characters are widened using os.widen()\nSo, TIL some things.\n. Done.\nTurns out Name didn't have an implementation of hash and equal_to whereas cashew::IString did, so I added those to Name so we could use it in sets.. Yeah good call. I'll revert globalImports back to cashew::IStrings for now, and make a separate PR to move them all.. Yes, which more succinctly expresses the intent, and also fits nicely with the assembler directives on the previous line that we also just skip.. potentiallyFixUpExpressionIfRelocationWasActuallyDoneAndIsNotImportedOtherwiseJustAddRelocation?\nWith the way I've written it, there's three cases. Let's use makeLoad as an example, creating a Load expression called curr:\n1.  * i32.load $push1=, 4($pop0)\n    * Parse up to the ,\n    * Call getRelocatableConst and get a numeric literal 4\n    * Set curr->offset.addr to 4\n    * Parse the $pop0, set curr->ptr to that expression\n2.  * i32.load $push1=, foo($pop0)\n    * Parse up to the ,\n    * Call getRelocatableConst and get a non-imported global foo\n    * Create a relocation record for foo\n    * Add relocation record to linker, to set curr->offset.addr to the global value at link-time\n    * Parse the $pop0, set curr->ptr to that expression\n3.  * i32.load $push1=, external_foo($pop0)\n    * Parse up to the ,\n    * Call getRelocatableConst and get an imported global external_foo\n    * Create a relocation record for external_foo\n    * Parse the $pop0, set curr->ptr to that expression\n    * Modify curr->ptr to add get_global external_foo and the $pop0 expression [1]\nSo, due to the interleaving of parsing, stashing relocations for later, and constructing the expression, this is the factoring I came up with.\n... Having written all that out, it occurs to me that we don't need to be passing around relocations here, and can instead have the first part return the expression that gets generated if we have an imported global, which reduces the jankiness somewhat. I'll push a change with that and we'll see how that looks.\n[1]: Rereading the code that does this, it doesn't currently incorporate any $pop0 expressions other than i32.const 0. I guess a test case is in order there.. This also needs to be moved to test/shared.py, or it'll cause errors when there are failures.. relocation->data is the target pointer that we pass in to getRelocatableConst. Given that it's a field on an expression that we're in the middle of creating, it should be either 0 or junk.\nFor a non-imported global, we clobber that value when we do the relocation in wasm-linker.cpp, so this is morally equivalent.. Trivia: there's an interesting, annoyingly-subtle interaction here.\nThere's four places that call getRelocatableConst: load, store, const, and data section initializer.\nIn data, we don't model get_global at all, so we abort here for now.\nFor load and store, this writes to the offset=___ field, and is why we do this.\nConst is the odd one, because the pointer we write to is the value of the const we're creating. Without this that would become an (i32.const 0), that the other optimization would remove.\nEither way we turn i32.const $push0=, foo+2 into (i32.add (i32.const 2) (get_global $foo))\nI imagine this is quirky enough that it will someday become a problem, and it's probably worth just emitting a bunch of (i32.add (i32.const 0)s and letting the optimizer take care of it, just for sanity's sake.. Or from code like:\n```c\nstruct Foo {\n    int a;\n    int b;\n    int c;\n};\nextern struct Foo foo;\nint main() {\n  printf(\"foo: %p\\n\", &foo.c);\n  return 0;\n}\n```\nHaving thought about this more, I believe each piece of it works in isolation. We write to the constant expression we generate. We preserve the existing expression when we add the get_global. This isn't actually unsafe in that case, just oddly redundant. Going to keep it for now.. Right, I added those files that changed from my local waterfall's torture-s build (fprintf-1.c.s, gofast.c.s, fprintf-chk-1.c.s, vfprintf-1.c.s, vfprintf-chk-1.c.s).\nNo other files changed except for the .file and .ident directives, so I didn't add them to this patch because of noise.\n. Agree. Wound up just expanding it, it's only six lines.\nMight still be worth a TODO now that I think about it.. Is the -free part stripped and ignored, only used for human readability?. Intentional extra newline?. Should probably be consistent with the trailing } // namespace wasm. If this is adding a class of tests that can be ran with BINARYEN_PRINT_FULL set, then the test that this PR adds should have a name besides just PRINT_FULL.asm, something like PRINT_FULL.unreachable_function_block_type.asm.js I'd think. What about startsWith(input, \"//@line\") ? Providing startsWith in a utility header.. memcpy?. In that case why not have the test script only set this if asm == 'PRINT_FULL.asm.js'? That way the intent of multiple small tests in this one special file is documented by the code itself.. Magic numbers are magic :)\nDoes this 100 match the 100 a few lines down?\nWould be good to replace these with named constants for clarity.. is___ makes me thing \"boolean\". Better name would be just debugInfo, which can still be used in a boolean context.. Seems unused. Don't feel strongly enough about it to block\nActually a best-of-both-worlds thing would be to leave the PRINT_FULL substring check, and rename the test to PRINT_FULL_generic.asm.js or something. That way both are reasonably-well supported, and it's more clear that generic tests go there.. Ah, makes sense. I would make this a top-level function as opposed to a lambda\n1) when reading this code it can be assumed that startsWith exists elsewhere, so it doesn't interrupt the flow of reading this function\n2) the way its currently implemented a better name would be inputAtTheCurrentPositionStartsWith(\"foo\"). I feel startsWith(input, \"foo\") is more explicit at the call site and requires less context for the reader to keep in their head\nBoth should be inlineable by the compiler so it should be equivalent to the unrolled version, either way.. This could theoretically be optimized by the compiler to be equivalent to what came before, but if (!seenUseAsm && startsWith(input, \"asm\") && (input[3] == '\\'' || input[3] == '\"')) is a possible rewrite that should almost-certainly be the same, while being I think equally legible. (I feel ambivalent about this either way though). These comments are pretty helpful, thanks!. In my head it's a top-level function that requires no state, so of the entire file. In theory it could be put in a utils header and shared.. Should also probably return false if *string == 0 for completeness, e.g. startsWith(\"foo\", \"foobar\"). Probably worth pulling the 5s into a constant?\nActually yeah it's not obvious why 5 and not 4, presumably consuming asm\\'\\n?. Nothing to do here just a thought/comment/observation:\nThis interleaving section of strcpy and *out++ = char is pretty verbose and I wish there was a cleaner/more compact way to do it.\nSomething like outStream << DEBUGINFO_INTRINSIC << '(' << fileIndex << ',' << line << \");\", though that would require a very different model of how this is done and probably isn't worth it?. Probably yeah. That trips a warning because size_t (and also Index) is unsigned, which makes i >= 0 always true. Which would be bad.\nAlternatively could do:\nc++\nfor (size_t i = 0; i < imports.size(); ++i) {\n  int index = imports.size() - i - 1;\nthough the way it is now feels more direct.\n... Although I should probably normalize my i--s with my ++is. Except I want to include zero. We need to hit every index in reverse order.\nCould also do\nc++\nfor (size_t i = imports.size(); i > 0; --i) {\n  int index = i - 1;\nCould also create a vector of indices to remove and do this two-pass.\nCould also use std::remove_if and a lambda, which more directly expresses what we mean.\nIn any case, looking at this again I should maintain what I assume is a class invariant, suggested by removeImport just above, and also erase the name from importsMap. I don't have that much context around this but it seems straightforward.\nMaking sure I understand: before we would defer to how the SubType visited the table/memory, which didn't necessarily walk the entire module. Walks being recursive, visits being non-recursive?\nIf so this seems correct.. This seems right in general. Curious if there was behavior you were observing, or just noticing that this should be cleaned up while you were here.. That's confusing how that works. It's also unclear that passDebug should be consistent across calls to the function.\nI think static const int better expresses how this is used, and ensures that nobody writes to it after initialization.. This comment helped explain why there are two variables for debug, why we set it to 0, how this is expected to work etc.. Oh, I didn't read this closely enough before to realize we were writing to the static var. That seems less-than-good. Tracking the recursion instead seems more direct in terms of what it's expressing, but seems similarly fragile.\nIn particular, we have to remember to never leave this scope between recursion++ and recursion--.\nMy understanding is that we recurse indirectly, when passes call other passes? If so we can have two functions here, run to run passes externally, and runInternal that other passes can call.\nThe high-level idea that's being expressed here seems to be \"Am I a top-level pass?\".\nQuick grepping makes it look like we currently call nested PassRunners in the following way:\nc++\nPassRunner passRunner(module);\npassRunner.add<FixImports>(&illegalToLegal);\npassRunner.run();\n, where this takes place inside of void run(PassRunner* runner, Module* module) override. Would it be possible or desirable to have nested passes reuse the original PassRunner? Something like\nc++\nrunner->runNestedPass<FixImports>(&illegalToLegal);\nThe key here I think being making explicit the difference between recursive calls and top-level calls at the call site, which lets us avoid a bit of implicit state. Probably the simplest way to do that would be to replace run() with runNested() for passes called from passes.. My first thought: should this be wrapped with if (import->type == none) ?\nReading more closely, import is the call site, so this doesn't overwrite anything else.\nWould it make sense to rename import to callImport to make it clearer?. Instead of ret->cast<CallImport>(), how about just import?. Hm, that's two good points. Ok, I'm fine with merging this as-is for now. I'm sure there's a way to refactor this to better isolate the debug weirdness from the rest of the code, but my ideas at the moment are nontrivial.. I'm all for making wasm.h more minimal.\nI'd like to go much farther, and move pretty much everything out of wasm.h into separate header/implementation files. So move Module to wasm/module.h, Const to wasm/const.h, Literal to wasm/literal.h, etc.\nThen because I'm sure it'd be convenient for some files to know about all the things currently in wasm.h, leave wasm.h where it is, but replace its contents with #includes to everything that gets moved out.\nDoes that sound like a good idea at all? If so I should do it in its own PR I think.. Oh nice, this was pretty much what I was thinking of. Wound up being less cross-cutting than I'd thought.. Another thought I had was to split the debug run into a separate function from the non-debug run, so it's clearer that the debug run has its own weirdness that maybe we don't need to care about elsewhere.\nHow about:\n remove isNested\n make PassRunner::run the virtual method\n move the debug run logic to doRunDebug and the non-debug case to doRun, both protected non-virtual methods\n PassRunner::run can just be\nc++\nif (options.debug || passDebug) {\n  doRunDebug();\n} else {\n  doRun();\n}\nand NestedPassRunner::run can always just call doRun()\nThat's the more OO way to do it. Alternatively we can let isNested be a field on PassRunner and not need subclassing at all. Though if we have enough different logic, using dynamic dispatch instead of repeatedly checking if (isNested) is probably cleaner.\nAnd either way I think it's worth it to split this out into doRun and doRunDebug at this point.. Splitting it up is separate if we keep isNested I think.\nI think we want isNested iff we don't have a NestedPassRunner subclass. Most directly: if we use isNested for dispatching to nested or not-nested code, the code for the nested case would live in PassRunner, and not NestedPassRunner. In the limit, the only code in NestedPassRunner is an override of isNested, which smells like we're using the wrong tool. My argument is basically, if the purpose behind the subclass is to put nesting-specific logic there, and deciding which passes to run is nesting-specific, then that's where that logic should live.\nSubclassing can be a very heavy hammer, as it constrains and enforces design in various ways. For example if we introduce another kind of PassRunner, say a FooPassRunner, can a FooPassRunner be nested?\nI guess I'm asking, why promote the concept of nesting into the class hierarchy in the first place?. Either specified as another field in the constructor (ew), added to the PassOptions struct (that isn't code-smelly but it isn't what that struct is for), or set externally before run. So cleanest would probably be:\nc++\nPassRunner runner(module);\nrunner.setIsNested(true);\nrunner.add<Pass>();\nrunner.run();\nOr PassRunner runner = PassRunner::createNestedPassRunner(module) that sets the field however it gets set.\nAnd I can't think of a different kind of runner either, hence the Foo example. I think I prefer the subclassing idea, just because it's useful for partitioning the nested case away from the non-nested case. Plus we can refactor  later when we have a better idea of what other types of PassRunners exist.\nMy main objection to a virtual isNested method is is that it uses polymorphism to dynamically dispatch the value of a flag, so we can switch on that flag to do different logic. Better would be to either polymorphically dispatch to different logic, or switch on a non-polymorphic flag to do logic. This introduces two levels of indirection where we really just need one.\nAs you said before, we may want to do other stuff based on whether a runner is nested or not. But that's what polymorphism is for, we can make anything that changes into a virtual call, and put the nesting-specific logic in the subclass. On the other hand, if splitting up the logic like that is too inconvenient, then let's not deal with the (mental and design) overhead of having a subclass, and encode nestedness as a member field.\nI'm ok with either method, so long as they're consistent.. I think it'd be useful to clarify what's convenient to have in wasm.h and why. From my perspective the file is too large and all-encompassing, and has too much implementation baked in to the header.\nWould you be opposed to a separate PR to move function implementations into wasm.cpp?\nFor the scope of this PR, I'll just move Name to its own file.. Looking at these functions more I'm thinking that separate from not belonging in this header file, they don't belong as member functions of these classes. Well I'm 50/50 split on whether substring is a first-class concept for Names, but this is definitely too opinionated for Module.. Done in https://github.com/WebAssembly/binaryen/pull/910/commits/bdaa866c5b4c46eb0a12f64aed681b1b547199f5. I mean we could rename these to getLocalNameButIfItIsntThereReturnAnEmptyResultInstead, but that's kind of a terrible name :P\nActually, less-jokingly we could rename the methods to getLocalNameOrEmpty (or OrDefault?).\n(Do we then rename getLocalName to getLocalNameOrFail? giveMeLocalNameOrGiveMeDeath?)\nIn my head, having a descriptive name is better than having a concise comment is better than having to read the code, and that holds regardless of whether the code is simple or co-located.\nOne sentence of English is (usually) easier to read than one line of code, so comments can be easier to read. Comments don't have to be correct though.\nBeing able to know immediately at the call site is better than having to reference the header/implementation at all, so good naming is even better.\nOn the other hand, \"try* means get* but with a default\" is a sensible convention, which when followed means the calling code can be more concise. It requires the reader be familiar with the conventions, so adds a bit of mental overhead, but if it simplifies things and is used enough it can be a win.\nI am almost certainly overthinking this.\nI think a comment is the right change to make in this PR :P. Oh hm, Module uses a different convention than Function does. Maybe change both prefixes to tryGet? That seems like a good mix of concise and obvious to me, and I don't think would need a comment. Thoughts?. Nit: Nested ternary expressions are generally unfriendly to read. Though this one isn't too bad, breaking this into an if/else might be more quickly scannable.\nNit: Mild repetition of ret->value->type == f64, maybe promote to a bool isDouble?. Should either have a TODO explaining why not opt=1, or ditch the for loop and opt-related flags. ditto. Kinda odd to me that memory.h does not have the Memory class in it, but does use Memory. Maybe either rename the file to memory-utils.h, or move the Memory class here?. Should probably also #include vector.h, literal.h, and wasm.h. Nit: at first glance I asked \"why do we iterate over memory.segments twice?\" An explanatory comment could be good, or even better extracted into another MemoryUtil function, bool hasOnlyConstOffsets(Memory const&);. Maybe call it dangerousGlobals?. Can the set of dangerous names affect equality?. Nit: might as well name it Iterator, to be as explicit as possible? I assume it'll get autoed everywhere anyway.\n... Not that Iter is particularly hard to translate, but the full name is slightly more explicit? \"Nit\" for a reason.. Could extract the function and use -1 (or UINT_MAX) to signal \"not found\". Or something like bool segmentHasIndex(Table::Segment const& segment, Index& startIndex);. Oh, hm. This is pretty non-obviously tied to the prior condition. My expectation on first glance was that \"because we found a segment, we should always return or throw from if (found). But we only care about a segment when the index is in bounds, so probably that should be included in setting found.\nI think helper functions would make this more clear? Something like\n```c++\nValue checkThings(Collection things) {\n  for (auto& item : things) {\n    if (weCareAbout(item)) {\n      return getValueFor(item);\n    }\n  }\n  throw NoItemsWeCareAbout();\n}. This big switch statement looks pretty nearly copy-pasted from https://github.com/WebAssembly/binaryen/blob/62e9f5d881e2d7e7f9f5da845ed2dbc176bc0bc5/src/shell-interface.h#L166 .\nWe can move the switch logic to a helper function in the parent class, that takes a template argument that we can swap out what we want to do with a given invoke.\nSo this could look like:\nc++\nLiteral load(Load* load, Address addr) override {\n  switchOnLoad<doLoad>(load, addr);\n}\nand the one in shell-interface.h would be\nc++\ntemplate <typename T>\nT getMemory(Address address) {\n  return memory.get<T>(address);\n}\nLiteral load(Load* load, Address addr) override {\n  return switchOnLoad<getMemory>(load, addr);\n}. ditto. Probably invert this by adding intermediate variables.\nSomething like\nc++\nauto zeroConst = wasm->allocator.alloc<Const>()->set(Literal(int32_t(0)));\nauto segment = Memory::Segment(zeroConst, temp);\nwasm->memory.segments.push_back(segment);. Do we have tests for flattening multiple data segments in the input?. Yeah that's way clearer.. Turns out yes, but less easily than I'd have thought.\n```c++\ninclude \ninclude \ntemplate \nclass PrintF {\npublic:\n    static void print(T item) {}\n};\ntemplate <> class PrintF {\npublic:\n    static void print(int item) {\n        printf(\"%d\\n\", item);\n    }\n};\ntemplate <> class PrintF {\npublic:\n    static void print(float item) {\n        printf(\"%f\\n\", item);\n    }\n};\ntemplate \nclass Cout {\npublic:\n    static void print(T item) {\n        std::cout << item << '\\n';\n    }\n};\ntemplate  class Func>\nvoid doPrints() {\n    Func::print(3);\n    Func::print(4.6f);\n}\nint main() {\n    doPrints();\n    doPrints();\n    return 0;\n}\n```\nTemplate-templates are a thing, but the syntax is very specifically template <template <[[template args]]> class TemplateName>, so the template-template has to be a class, not just a function.\nMy first-draft suggestion before template-templates was virtual templates, but that's not a thing.\nSo the choice is either complex duplication or templated function-wrapper classes that we pass as arguments to template-templates. Basically which of those represents the lesser evil. I, don't actually know how I feel about that.. That's a good point, I hadn't considered it from a declarative perspective. Looking at it again, I think it's kind of a wash. But, here are some thoughts:\n\nThe biggest thing that jumped out is the very long expression that allocates the Const with a literal value of 0. A helper function like Const* newInt32Const(int32_t value); would work wonders here.\nWe have a temp variable as part of the expression, which causes the reader's eyes to have to backtrack to the definition above anyway. We can replace that with an anonymous rvalue, just an inline std::vector<char>(), which is in keeping with the ast-ey way.\nWe're mixing object construction and pushing that object to a vector. Which is clearly correct if we're doing something like vec.push_back(4), but becomes a stylistic thing for larger expressions.\nC++ isn't the greatest at expressing DSLs like that. In something like Python you could do:\npython\nsegments.append(\n  Memory.Segment(\n    offset=Const(Literal(0)),\n    init=temp\n  )\n)\nand if you had a bigger more complex expression it'd be easier to follow:\npython\nfoo = Big(\n  nasty=Nested(\n    expression=That(),\n    we=Clearly(\n      have=All(the),\n      right=Vars()\n    ),\n    for=Because()\n  ),\n  the=Language(supports=it)\n)\n, vs in C++\nc++\nfoo = Well(\n  this->Definitely(\n    Compiles(),\n    but(\n      From(a),\n      Readers,\n    ),\n    perspective,\n    It(can),\n  Be(Hard(\n    to(Know()),\n    what\n  ),\n  all(this),\n  means\n)\n, so something in the style of\nc++\nauto segment = Memory::Segment(offset, init);\nis more typical.\n\nThe main goal I have is \"how can we minimize the mental stack needed for a reader to parse this expression,\" so by apply the technique of intermediate variables we divide the expression into smaller chunks that a reader can process individually.\nThere's more than one way to do that though, and something like\nc++\nwasm->memory.segments.push_back(\n  Memory::Segment(newInt32Const(0), std::vector<char>())\n);\nis quite readable, and has an AST-ey flavor to it.. I think the switch is hairy enough that that's an improvement.\nI also just realized there's another option: macros :/.\nCould be done either to generate the switch, or to generate the boilerplate virtual functions. I don't think that's actually cleaner than the virtual functions though.. We could replace that Segment constructor with one that takes advantage of move semantics, which is probably what we want there anyway considering we swap the vectors, so having to std::move any lvalues we call it with makes it more obvious at the call site that the vector was mutated. Plus it lets us use rvalues for them.. Good point. Sounds fine, the difference is reasonably marginal.. Nit: This could also stand to be && for similar reasons. Shouldn't this clear os.environ['BINARYEN_PASS_DEBUG'] in the case that old_pass_debug is None?. Do we need to try/finally here? It adds nesting, and we don't actually catch the exception, so it'll end the script execution anyway.. Maybe a silly question, but could ExpressionManipulator be a namespace instead of a struct, if it only has static methods and no state?. Symmetry: We don't need to check if sw->condition is nonnull?. The +1s look strange to me.\nIs it expected that we're only changing numBreaks by 1 at a time? If so it would be good to encode that with something like enum BreakChange { addBreak, removeBreak };, which would also make the semantics more obvious.. This logic is reused a lot. It's probably worth moving to a helper method or three in Break.\nI'd think isConditionUnreachable, isValueUnreachable, and hasUnreachableChild (which just does return isConditionUnreachable() && isValueUnreachable();) ?. Ditto. In particular that can encapsulate the asymmetry of not needing to check curr->condition != nullptr. :) O(bad). Yay splitting compound lines. Typo: flipped ( before \"which\"\nActually what does *& mean in  (which is *&)?\nOh, \"a pointer reference.\" Might be better phrased \"which is a &\", or \"which is a reference\". This line seems weird.\n... This function seems really* weird.\nSo I like splitting the line.\nI like aligning the optimizes. I think that /* . */ is a confusing way to do that. Better would be just whitespace, but then because it comes on a line after an if, it looks like the body of the if. Although with the comment it still looks like that.\nThe comment does do a good job of sticking out and saying \"hey this is unusual,\" so that worked.\nThe if statements are copy-pasted from optimize's internals.\nSo, I propose:\n```c++\nBlock* outer = nullptr;\nouter = optimize(curr, curr->ifTrue,    outer);\nouter = optimize(curr, curr->ifFalse,   outer, &(curr->ifTrue));\n        optimize(curr, curr->condition, outer, &(curr->ifTrue), &(curr->ifFalse));\n``. Name could be misinterpreted to mean \"forcibly set thefullflag\". MaybeshouldForceFull?. Mostly I'm not used to seeing unary no-op+, especially without the corresponding-1, particularly on this line https://github.com/WebAssembly/binaryen/blob/76af34609b2d3aeb18ec34275b3991663d9da742/src/ast/type-updating.h#L68.\nMy reading here is that you wrote it that way to tell the reader that the1is a delta, which is a good thing to communicate. The advantages I see of the enum idea is that\n1. you can't lose the context across call frames. We pass theint change` value around through a few functions, and without knowing how it's going to be used, it could have any int value.\n2. you can more easily reason about it because we're constraining the range from \"all int values\" to \"+1/-1\", and encoding that information in the type.\nThe unary pluses are unusual, but if we don't want to go with an enum then I'd prefer we leave them in, because I think it does clue the reader in to the purpose of the value at the call site.. Nit: Can probably just drop \"*&, i.e., \". Nit: Double-spacing before throw\nAs an aside: yay for changing asserts to errors with messages!. Wait what?\nIf currFunction we throw, but if !currFunction we assert?. 4x reuse, how about extracting this to uint64_t checkedTableSize(char*, Element&);\nAnd/or, they all say \"excessive table size\", when two of them are memories.. Also should this use atoll?. More candidates for reuse + atoll. This is just clunky enough and repeated enough to feel like it should be extracted to a function.\nSomething like\nc++\ncurr->type = getResultType(*s[i]);\nif (curr->type != none) {\n  i++;\n}\nOr if we want to be cute,\nc++\nif ((curr->type = getResultType(*s[i])) != none) {\n  i++;\n}\n(let's not be cute :p). It feels like we should be able to reuse a lot of the logic from makeTrappingFloatToInt32, they're very structurally similar.. /*signed*/s might be useful, just to know at a glance what true/false mean.. Should probably be cmd = [MOZJS, 'a.js']?. Instead of two bools in the signature, would it make sense to have a MemoryFlags enum?\nc++\nenum MemoryFlags {\n  memoryHasMaximum = 1 << 0,\n  memoryIsShared = 1 << 1\n};\nAs it is now we're basically inlining the knowledge of the flag layout, which is probably less obvious in the future.\nFailing that a link in a comment to the threads proposal might be good, because otherwise that's implicit knowledge.. Instead of calling naked falses, would defaulting the param to false make sense?. Nit: o.write(out) on its own line. Yeah consistency > perfection. Seems fine. That is also pretty reasonable. Yay for big ugly macros that make the actual code easier to read.\nAnd yay for cleaning up afterward.. These bounds look arbitrary without referencing BinaryConsts' definition (and/or the threads proposal).\nWould it be worth adding at the end of BinaryConsts' definition something like\nc++\nAtomicRMW_BEGIN = I32AtomicRMWAdd,\nAtomicRMW_END = I64AtomicRMWXchg32U,. Not sure if I should complain that a missing terminal semicolon is a bit odd looking, considering that this is a nested macro that's right next to its use.\nI guess: at a quick skim, this gave me a double take, but this is almost-certainly OK.. Yay method extraction. a and o are kinda iffy names, but they're very local and are probably fine. But they have the same initialization code and so this might be more clear as:\nc++\nuint64_t value = atoll(eq);\nif (value > std::numeric_limits<uint32_t>::max()) throw ParseException(\"memory attribute value too large\");\nif (str[0] == 'a') {\n  *align = value;\n} else if (str[0] == 'o') {\n  *offset = value;\n} else throw ParseException(\"bad memory attribute\");. Nit: helper function? bool isTypeIntOrUnreachable(WasmType t)? The switch/default/fail is just odd enough to be not totally obvious.\nOr bool shouldBeIntegerOrUnreachable(WasmType, Expression*, const char*) to match the shouldBeEquals. This line seems overindented. Remove commented-out code. ditto. Yay error messages.\nMight be worth adding more context though? \"Unexpected type while visiting const\" or something?. Can reduce a level of nesting here by changing this to early-return style:\nc\nif (size >= used + safety) {\n  return;\n}. No return after printAssign?. Should this print to stderr?. Ah, good reword of the comment here to be more explicit about what's \"???\"\nYeah this seems like the kind of thing we should know? But also seems like the kind of thing that should already be broken. Which ties in nicely to the whole concept of \"having tests.\"\nWhich is to say I'm ok with leaving this as-is until we have a failing test to motivate what it should be. I also think we should get some tests for  pretty much asap.. Better idea: have check.py import scripts.test.wasm2asm as wasm2asm, wrap the check code in a function, check_wasm2asm, and call it from here. (Then comment out the call). Why not indent this line two extra spaces, instead of disabling that warning project-wide?. What about foundProblem, or didFindProblem?. This might be cleaner as a switch (left->op) /*...*/ case ShlInt32: case ShrUInt32: /* ... */. Nit: is leftHasEffects clearer? Without looking at the definition it's not immediately clear whether leftEffects is the boolen or if it's leftSideEffects. Not sure if \"has effects\" makes that too much better, and it seems kind of a wash because \"side effects\" mirrors the hasSideEffects method name.. Typo: positions. I think ideally it'd be a python-y elif left.op in [ShlInt32, ShrUInt32, ...]:, though that's less nice to express in C++.\nI agree that a switch is syntactically more gross, and stacking case x: case y: case z: is unpleasant. Goodness knows the evils that people can do unto each other via switch statements. The aesthetic preference I'm aiming for here is reducing the repeated left->op ==s, to get a better \"semantic meaning per syntax token\" ratio.\nBut the key word there is probably \"preference\", so I think it's fine as-is.. Oh I thought this was commented-out code at first\nProbably worth a comment like \"This is implemented as\" to make that clearer.. Hm, bool parameters are kinda icky because they tend to not offer context at the call site for what true/false actually means. (https://blogs.msdn.microsoft.com/twistylittlepassagesallalike/2011/06/02/against-bool-parameters/)\nHow about makeRotFunc takes a WasmType instead of a bool, we assert(type == i32 || type == i64), and locally in makeRotFunc we have bool is32Bit = type == i32;\nEdit: OH, this true/false is for left/right rotation. Maybe similar advice, but with opcodes instead of types? This actually lets you collapse the two bools, because RotLInt32 encodes all the information you need.. I'd put these addFunction calls into their own method, addWasmCompatibilityFunctions or something. The list of functions to add is likely to grow, and it's logically one operation.. Kind of interesting that lshift can be a right shift when !isLRot. That's probably fine, but a bit odd.. Alphabetical? Or does order matter here.. Maybe assertBitwiseEqual? It's harder to see that this can assert/abort now that it has more distance between it and the callsite.\nAlternatively: static bool isBitwiseEqual, that we call with assert(isBitwiseEqual(a, b)), though that makes it harder to weave in the cout for non-equal literals.. Would it be useful to log that their types aren't integral, or the values of the literals passed in?\nWould that be useful for all the branches of this function?. The alternating caps here kinda hurts my eyes. addDeNanSupport?\nAlternatively, addNanRemovalSupport, and change \"de-NaN\" to \"remove NaN\" throughout.\nI think just changing addDeNaNSupport to addRemoveNaNSupport is less jarring. Specifically the high-low alternating character pattern is what I think is most problematic (e.g. \"QqQqQ\").. Maybe a note to say \"This isn't a uniform distribution, but it doesn't need to be.\". upTo(upTo(x)) is non-obvious at first glance that it's skewing the distribution. (Made further non-obvious by the name upTo that hides that the number is even random)\nHow about wrapping this idiom in a function:\nc++\nIndex getLessThanWeightedLow(Index limit) {\n  return getLessThan(getLessThan(limit));\n}. Double-underscores are reserved for C++ implementations right? Is single-underscore sufficient here?. I feels odd that upTo(5) has a range of [0, 1, 2, 3, 4], and it hides that it's getting a random number. getLessThan maybe?. So upTo(x) feels a bit too terse, but I really like oneIn(x).\nBut maybe for consistency it should be getOneIn(x).. It's also like a lot of rand calls (like http://introcs.cs.princeton.edu/java/12types/RandomInt.java.html). These all make sense once you know what they're doing, my issue with the name upTo is just that to me it doesn't say it's one of those kinds of functions, and \"up to\" in particular sounds distinct from \"up to but not including\".\nIn my head using get in the name ties it to the get methods already in this class, which are random, implying that this is also random, and therefore an exclusive range.\nBut, no I don't feel particularly strongly about it.. This is kind of convoluted to read (call(dot(dot('e', 'message'), 'includes'), expectedErr))\nThe dot-expressions feel like one logical unit, so that's harder to mentally map to and from an AST I feel.\nI think this is a good time to extract e.message.includes to a variable.\nOr to add a vararg helper method, makeDotted(\"e\", \"message\", \"includes\"). (Actually kidding, but I'm not opposed). Talked about this in person\nKind of unfortunate, but better than not having node support I guess :/. This function is pretty long, and pretty nested. Helper methods? Something like\n```\ndef processAllAsserts(root)\n  for expr in root:\n    processSingleAssert(expr)\ndef processSingleAssert(expr):\n  if isEmpty(expr):\n    return\n  if expr[0] == \"assert_return\":\n    processAssertReturn(expr)\n    # ...\n. Could this bec++\nif (isStatement(func->body)) {\n ...\n} else if (func->result != none) {\n ...\n} else {\n ...\n}\n```\nwhich would reduce nesting?\nDitto if (endsInReturn). This gets reused almost wholesale from just above. Helper function? Possibly helper lambda?. Nice. Nit: extra space in )  {. Why do we need moduleBuilder, why not just builder = new Builder; ... delete builder;?\nEdit: guessing because builder gets reassigned during the walk? Eek.\nA) Is that reasonable to avoid?\nB) A comment might be useful to mention that.. Does this not leak?\nIf this may be the first entry, should we only create after checking that we need to?\nIf we're running this in parallel, is this racy either way?. Nice semantic compression. Why not load.isAtomic && load.align != load.bytes or isAtomic && align != bytes?. Can we pull this out to the caller? It's non-obvious that the curr parameter is just a template, and by putting this copy in the same place as the callsite, it makes this usage less unusual.. Yay. Looks pretty symmetric: https://github.com/WebAssembly/design/blob/master/Semantics.md#linear-memory-accesses. This looks like it changes the order of what gets ran when. I'm not inherently opposed to that, but I'm not sure if the existing order had some broader reason behind it.. Almost all of the comments were just grabbed as-is from asm2wasm\n... which makes references to asm.js all the more misleading.\nAnd \"handle\" is probably the better word here?. Allow does make the whole pass a no-op. It seems cleaner than conditionally adding the pass if the flag is set.\nCould probably do something more clever by not walking the module if Allow, by overriding one of the Walker methods. Would still introduce a sequence point by being another non-parallel pass.. Well we don't have this hooked up in Emscripten yet, so now seems like a great time to make an asymmetric change.. Just moved from shared. Indeed it does https://github.com/WebAssembly/binaryen/commit/a853c0b0ef9f6c2965f1cca9f4b05fee0b465f34 , thanks. Well we'll need to make an Emscripten patch to change the plumbing for asm2wasm anyway, we can bundle that with the patch to add plumbing for s2wasm, and we can keep them the same in Binaryen in the meantime.\nSo:\nKeep this as is for now\nFollow up with a patch to Binaryen to change both sets of args to --trap-mode=<blah>\nAt the same time submit a patch to Emscripten to add s2wasm's invocation and change asm2wasm's.. If we keep the .h and .cpp, should we duplicate the comment across both, leave it in the header, or move it to the implementation?. That it does. How about TrapModePass?. The pass needs an argument though, which means we need to have the Mode enum and constructors visible to callers.\nIt's weird and I'm not sure where to put it. It isn't registered by name with the pass system, so it doesn't really belong in passes/, but it is a pass over the module. Originally I had it all in a header file in src/, but that seemed wrong.\nast/ seems fine to me, thanks.. My PR description was pretty sparse on detail, and I forgot to write down at least one case:\n* Because we change the timing of when we convert things to calls, optimizations happen in different orders. This lets constant folding be more effective, as seen in big_uint_div_u (in test/unit.fromasm), because we can constant fold the i32.div_u instruction directly, and then it doesn't generate a clamping call at all.\nIn this case, we add clamping after the inliner has run, so i32s-rem gets generated and called, instead of generated, used once, inlined, and removed.\nEssentially: semantically these should all be the same, but the timing isn't identical and that perturbs the optimizer.. I currently run it as early as possible, which is necessarily after AutoDrop because the IR isn't valid before AutoDrop runs - asm2wasm seems to rely on AutoDrop cleaning it up, and we validate after each pass. We could run this separately in a separate PassRunner, or run AutoDrop and only AutoDrop separately in a separate PassRunner.\nThe other complication w/r/t timing in asm2wasm is the OptimizingIncrementalModuleBuilder that we use when running optimization passes that runs passes on each function - meaning the passes added to it need to be function-parallel, which we fundamentally can't make the clamping pass be because it adds functions to the module and thus introduces a sequence point for pass scheduling. Which we can probably work around with a separate pass runner. Maybe.. Yeah that's way cleaner, and has the benefit of letting us run this in wasm-opt as well, which means I can write some finer-grained tests for it.. The other downside to adding the functions before any optimizations, is that then in the pass we have to explicitly exclude any generated functions when running on functions, because otherwise we'll replace the i32.div_u instruction in the $i32u-div function with a call to $i32u-div.\nThe pass also gains a precondition, \"must have called helper function addTrappingFunctions before running this pass\".\nThese both make the pass less pass-like, but probably does a better job of maintaining asm2wasm's behavior exactly as it is today. I was operating under the assumption that that's a non-goal as long as the semantics are the same.. Sounds very plausible. Let me try to add a test that exposes that behavior.\nI originally implemented this as a pass for s2wasm and asm2wasm just calling utility functions directly, basically changing nothing about its flow (see https://github.com/WebAssembly/binaryen/pull/1168/commits/8ffe1c9ecdedba8df4564aecba0f60c204d4b313). I was able to use the pass for asm2wasm as well, which let me move the utility functions into the pass itself, which let me store the added functions on an instance variable on the pass object, instead of being a static variable, and generally make the interface much nicer.\nClean code does not trump working code, so I'll fix it.. Added an INT_MIN / -1 test in https://github.com/WebAssembly/binaryen/pull/1168/commits/691cf5e8af7c8f0e4c98b0f3a323336cdbc878d9. It does not currently misoptimize into a trap, and thinking about it a bit more I'm not sure if any optimization pass should ever do so?\nDo these optimizations happen other than in OptimizeInstructions.cpp? Are there any patterns you can think of that would get optimized into an unconditional trap that I should check?. What happens if:\nc++\nTempVar a(1, pass);\nTempVar b(2, pass);\nTempVar c(3, pass);\na = b;\nb = c;\n?\n(having only looked at this struct in this PR). Maybe I did. I thought we only cared about doing that in order to avoid potentially optimizing trapping opts into unconditional wasm traps.\nAs far as correctness goes, if that's not a concern then this is still fine.\nThis does change the visibility of the clamping to the optimizer, which I was assuming wasn't as important because of the inherent slowness of clamp/js modes as it was.\nIf we do care, I still think we should use a pass, with the following approach:\n1. change the pass to be function-parallel\n2. run it as early as possible (right after AutoDrop)\n2. generate all the generated functions all the time, because we don't know which ones we need\n3. let DCE remove the ones we don't need\n. I think those are temporary ./check.py files that I accidentally added with git add test/ in my excitement that this worked. Will remove.. Why is there still usage in general?\nBecause asm2wasm uses it elsewhere and I'm not sure what it does, and because the \"js\" trap mode calls a javascript import, which needs to be an f64. Somewhat misleading because it doesn't do the generation directly. TrappingFunctionContainer maybe?. XManager sounds too general to me, I hear it saying \"I do many X-related things, none are specific\".\nThis class is responsible for making sure functions get generated only once, and adding them to the module at the appropriate time. It does not explicitly generate them, so Builder is out. Container isn't quite right but I'm not sure what's most precise.\nStorage? Cache? Stash? thesaurus.com isn't really helping me here.\nNaming things is hard.. Nit: should the try/catch surround the for loop, instead of the other way around? They probably get optimized identically so it's probably totally moot.. Three bool args make me think this should be flags.\nc++\nenum ValidatorFlags {\n  ValidateWeb = 1 << 0,\n  ValidateGlobally = 1 << 1,\n  ValidateQuiet = 1 << 2\n}\n//...\nbool WasmValidator::validate(Module& module, ValidatorFlags flags);\n//...\nvalidator.flags(wasm, ValidateGlobally | ValidateQuiet);. Sounds reasonable. Yeah, should I not? And if so, should I remove --imprecise as well?\nActually if we keep it I should update --imprecise to say \"old name for --trap-mode=allow\" now, to keep that consistent.. Nit: Given we have Features and FeatureSet, would it make sense to call the enum of flags just Feature? Benefit would be that it would be clear that a variable named features is probably a FeatureSet. FeatureSet features maybe?. To be honest I'm not entirely enthused about the class name \"EmscriptenGlueLinker\", but I can't think of what else to call it. EmscriptenGluer? Emscriptenifier?\nBut also secretly these were so I could change emscripten:: into emscripten.. Barring a better class name, glueLinker is better here yeah.. I forgot that : wasm(wasm) worked. This is from the old linker.emscriptenGlue, if (debug) WasmPrinter::printModule\nMorally I'm ok with printing the pre-glue module if you're debugging s2wasm.. sgtm, also yeah future-PR. Because it generates emscripten glue, and used to operate on the wasm linker...\nSuggestions welcome please. That's probably best yeah.. Yes it should be.. Yes, this makes even more sense later on when I want to use Address(0) (or something) to signal \"no stack pointer specified, stack pointer is a global, use that instead\". Although I also need an entirely separate way to specify which global is the stack pointer so I'd need a separate constructor anyway...\nBut still yeah, asm2wasm shouldn't have to care what Address(0) may or may not mean. (Also, following @dschuff's prior suggestion to emit grow memory via the JS API we won't need this in asm2wasm at all, but future PRs are future PRs.). The names are placeholder and something I was having trouble with.\nFor lld-metadata, it runs over wasm object files to create a json metadata file. So maybe a name like obj-metadata? link-metadata? o2json?\nFor lld-emscripten, it runs over a post-link wasm binary, so doesn't really interact with linking at all. It's also linker-agnostic (as far as I know), so lld- is a really terrible prefix. So, wasm-emscripten? emscriptenify? wasm2emwasm?\nMy votes go to obj-metadata and wasm-emscripten, so if those aren't objectionable I'll go with them.. Yeah good call, thanks. Here I was copying what asm2wasm and s2wasm do, with simple header comments and more detail in the help message. I figured that made sense because otherwise it would pretty much be copying the help message to the comment. The purpose of the tool isn't likely to change though, so that's probably fine.. Yes, they aren't clang-specific. They are fully-linked non-object wasm files for this tool though.. Ah, nice catch.. Ditto lld-emscripten. Standard as mentioned in https://github.com/WebAssembly/tool-conventions/blob/master/Linking.md , which I should link to in a comment. It is entirely conceivable that we handle object files elsewhere in binaryen too, so a more-common header file sounds like a good idea.. Mm. Wasm object files are almost-wasm, so can generally be read by a wasm binary reader, but they have some differences that can cause validation failures, so they need to be handled slightly differently. This seemed like the nicest interface to handling them differently I could add to ModuleReader.. It does :). Turns out we don't need this for this patch, but I assume it's more useful to have than not.\nHaving said that, this was originally one tool. I thought I could go from lld output .o file to emscripten-modified .o file and write out a .json at the same time, but for that to actually work we would need to rewrite the relocations vs just preserving them, so in the limit we would need this tool to be a fully-fledged linker in its own right.\nSo this will preserve custom sections, but if those sections contain binary offsets that we aren't aware of, then they will probably be semantically broken.. This is why we need to know if the file is a wasm object file, as far as I know (there may be other differences I'm not aware of, or there may be new differences in the future). In particular: https://github.com/WebAssembly/tool-conventions/blob/master/Linking.md#merging-global-section explains that we use them to represent global symbols (though it doesn't explicitly say whether said globals are mutable - I'm not sure if they have to be or if they just happen to be).\n  . Is the limit in VMs 100*1000, or 100*1024?\nIs there a reference we can link to for this, because all I see on https://webassembly.github.io/spec/core/appendix/implementation.html?highlight=implementation%20limit is \"implementations may impose some limit\". Are there runtime cases where this might not be true?\nI secretly like this as-is as an affirmation of the expected postcondition of the previous two lines, just in case the reader doesn't feel like doing the algebra. (Although my first reaction was \"wait isn't this always true\"). These two conditions are repeated three times here. Maybe extract a lambda (or method), if (isEmptyOrConst(segment)) continue;?. Oh, I was thinking merge the conditions to reduce line/continue count, i.e. go from\nc++\nif (foo.isA()) continue;\nif (foo.isB()) continue;\nto\nc++\nif (foo.isAOrB()) continue;\nThere's one condition where which checks both size() == 0 and NOT ->is<Const>, so either leave it standalone or also make isEmptyOrNotConst.\nThis is also fairly minor, so Nit. Yeah the name isAOrB is pretty contrived. I think ideally it would be something like canEmit or isSafeToEmit or canMerge or something, where the name implies why we care about A or B. I'm not sure if A and B are actually related though? So I mentioned it so that if you had an idea for what to unify them as, you could name it well. Failing that, a unifying function is probably overkill yeah.. The need to read object files is for wasm-link-metadata, which reads a wasm object file pre-LLD. We don't use --relocatable or --emit-relocs, and we don't care if the stack pointer is exported or not (wasm-emscripten-finalize adds stack-manipulating functions as part of its interface with Emscripten).\nSo, no problems. This changes the behavior slightly subtly because os.listdir('test/foo/') returns ['a', 'b', 'c'], but glob.glob('test/foo/*') returns ['test/foo/a', 'test/foo/b', '/test/foo/c']\nThis is actually even more convenient because we get paths directly and don't need to append 'test/foo' everywhere.. This makes things a good deal simpler, thanks. I think I'll do this as a followup, and remove wasm-link-metadata and incorporate it into wasm-emscripten-finalize.. I'd say declare numReservedFunctionPointers before parsing the args, defaulted to 0, and do the stoi inside the lambda. Then you don't need to mess with options.extra, and you don't need to check whether you can find it.\n... Maybe do that for s2wasm as well? Maybe not though, because it should match the neighboring code (although I'd be ok with it all using the other style, I'm not asking you to rewrite it. Also if we can delete s2wasm then it's moot?). ditto here. I didn't know that std::string constructor existed. Huh. This is clever (in a not-bad kind of way), it reads like python string slicing.. This is short enough that it might as well be inline in JSCallWalker?. Might be good to someday make this a generalized mechanism now that it's used more than just for s2wasm. Not today though?. At first I thought if you had say 3 foos, you'd get foo foo_1 and foo_2 - which you would.\nBut the problem you're pointing out is if you had 2 foos and a foo_1, which would break it.\nThis sounds like the perfect thing to add a test for.... This is also what wabt does, and I'll change this to do that as well so that it's less likely to have this sort of transitive collision.. Because creating an Output object to handle the metadata wipes the file if we aren't printing to stdout. It always passes std::ofstream::trunc. We could get around this by:\nA) adding a trunc/append flag, which is three sets of options to Output, which smells like we need a different factoring altogether.\nB) modifying ModuleWriter to take an Output as a parameter to write, instead of / in addition to the filename APIs.\nC) saying \"screw it\" and just doing it manually inline.\nI went with C, but actually looking at the internals to ModuleWriter, it already uses Output internally, so it should be pretty trivial to change the interface to take Outputs as parameters, and refactor the current interface as convenience wrappers around that. That sounds best.. Done https://github.com/WebAssembly/binaryen/pull/1408/commits/50d8fa7b4979228aa9473ab7fcfd6920c03b02ad. Nit: items could be iteritems. This is totally moot for this case (allocating a list of length 2 is a non-issue), but as far as I know, in general iterating over generator expressions is preferred to iterating over a list (e.g. range vs. xrange)\nSee also: https://stackoverflow.com/questions/10458437/what-is-the-difference-between-dict-items-and-dict-iteritems. 80 chars exactly... and PEP8 specifies <= 79. I don't even know what this does, so I'll just revert it. Seems harmless to leave in then?. I'd rather not, we should test that this explicitly sets the value.\n... Which means I should explicitly pass something that ISN'T the default to better verify it works.. None of the other check.py sub-scripts do so I'm inclined to leave it as-is.. Yep and yep https://github.com/kripken/emscripten/pull/6215/files#diff-e64ed58dc838bc8cb95295fef5447e1fR1896. Yeah, seems reasonable.\nThe idea here was that we should be the only ones generating these __em_js__* functions, so we should know if/when we ever change their format.\nBut if a user ever does prefix that, we might as well give a saner-sounding \"hey no don't\".. Technically yes. Should probably explicitly annotate this with a TODO(jgravelle), uncomment when EM_JS lands. I was thinking one of these would rebase on the other, and fix it then. Explicit is better though.. Consider: change the condition to\nc++\nwinning = tryToRemoveFunctions(names);\nif (winning) {. Nit: should be didRemove because no fun allowed \ud83d\ude1b . Yeah that captures the nuance there better. The comment makes it perfect.. :). Debug print. debug print. This has the implicit assumption that we walk function bodies after we walk all imports. I don't think that will change but it's a possible source of fragility.. Talked locally. This is unlikely to change, and is covered by the test/dot_s/fix_em_ehsjlj_names.wast test, so is unlikely to break without CI noticing. Lgtm. It seems really questionable to me that these names differ only by leading capitalization.\nI'd say rename IntrinsicsModule to IntrinsicsModuleText, to make it clearer.. wasm-linker is very s2wasm-specific, and only \"links\" symbols internal to a module, i.e. it does data layout.\nFrom wasm-linker.h:\n\n(In particular, there is no merging of multiple modules). Currently this is only inteded to turn a .s file produced by LLVM into a usable wast file.\n\nI'd think wasm-merge would be what you'd want instead? My understanding  (and a quick glance at the code) is it mostly resolves imports/exports, which is what we want here.. Is this a flake8 thing? I personally prefer the semantically-meaningful comment (the shebang) to be visually separated from the copyright boilerplate, though this is the sort of thing I can't really bring myself to get worked up about.. Yay putting things in functions. nit: why is this triple-quoted string using ''', when the other one uses \"\"\"?\nIs there a standard for which to use? Either way these should be the same.. I'd expect the these to all get inlined, and then all the if (condition)s to get coalesced into one, so these should be identical code-gen wise, though maybe that's relying too much on the optimizer.\nThe thing I like about this is we still keep the old Fatal for places where FatalIf is impractical. For semantics: https://github.com/WebAssembly/binaryen/blob/dd95d06c78757775ae52db08064805adaaf13cc3/src/tools/s2wasm.cpp#L247-L251\nAnd I can see making this more explicit for perf-sensitive bits too, to avoid relying on the optimizer.. I forgot we could, like, check: https://godbolt.org/g/Kj4Lj4\nLooks like nearly-identical codegen to me, thanks inlining.. Can probably remove this line. Probably need to implement this line for full s2wasm parity. Agree, hence lgtm. Why uncaps Binaryen?. Comment is wrong, don't need \"if not specified\" if we're always doing this. nit: do not match\nAlso should this check be before the call to fixEmEHSjLjNames?. Nit: is this 3-space indented?. It looks like this just doesn't work well without --flatten, right? As opposed to \"something terrible happens\". The other comments give a good heuristic to the user, whereas this one is more descriptive of what it makes Binaryen do. I'd word this more like \"optimizations that usually aren't worth it, can be many times slower than -O3\" to give the user a better sense of what the tradeoff is here (optimization at all costs). Should this check live in StackIROptimizer itself? Or should StackIROptimizer(...).run() never be a no-op, at which point we should maybe add an assert to StackIROptimizer itself.. Should this be a #define? Probably for now I guess, because we won't want to use this unless developing the stack optimizer. Can change it later if we need to, for now probably best to keep it simple.. Is this any less weird?\nfor (Index j1 = values.size(); j1 != 0; --j1) {\n  Index j = j1 - 1;\nThe while (1) is kinda weird... but so is the off-by-one for loop :/. So this prints the module twice? Should it?\nI'd expect we should just print once, with valid wat if we have stack IR, and folded form if we don't. Binaryen's wast parser can handle flat wat, right?. Maybe \"flattening should have been done before now\"? Or am I misreading here. canRemove would be slightly more precise. Would for (Index i = numParams - 1; i >= 0; --i) { be equivalent here?. If we don't clear them here, we'd wind up with things like (func $foo (param $var$0 i32) (param $var$2 i32)) right? (having deleted $var$1)\nIs there anything wrong with that? It makes it a bit clearer that this optimization happened, and is less work. Do we depend on names being sequential later on?. Er, why not?. ... and I can't help but read this as \"cow\". Makes sense. I thought we used names for everything in binaryen so it would've just worked out, but nope. (Reading more carefully we fix up the indices of the get/set local instructions). Right, darn it unsigned.\nI remembered asking about this for similar looking code relatively recently, but thought that was a different case. Fool me twice... shame on unsigned.\n... for (Index i = 0; i != UINT_MAX; ++i) { ? Not sure if that's better or worse.. That's mysterious, what does asm2wasm do with i64 invokes?\nLGTM otherwise. Kind of weird that we reuse importedNames for both declares and invokeFuncs. This is correct, because we have the invariant that invokeFuncs start with \"invoke_\", and declares explicitly do not, but there's intervening code that makes that non-obvious.\nI'd say use two std::sets to make it obvious that they don't conflict. Why not while (i > 0) {?\nOr even for (Index i = list.size(); i > 0; i--) {. Hm, rather than undoing the changes, how about having a second list, updatedNumSetsForIndex, counting up and seeing if the number of sets is identical. That makes this else clause unnecessary.. All these if (canMove)s are really awkward control flow. This loop is also getting really deeply indented. Can probably fix both of these by extracting some functions here, which can turn this loop into something like:\nc++\nif (interestingToMove(curr)) {\n  if (!effects.hasGlobalSideEffects() &&\n      !effectsSoFar.invalidates(effects) &&\n      !(effects.noticesGlobalSideEffects() && loopEffects.hasGlobalSideEffects())) {\n    bool canMove = getsAreOk(curr) && setsAreOk(curr, numSetsForIndex);\n    if (canMove) {\n      // We can move it! ...\n    }\n  }\n}\nThis also lets us say things like return false instead of canMove = false; break in those functions, which should simplify things more.. I'd write this\nc++\nbool unsafeToMove = effects.hasGlobalSideEffects() ||\n    effectsSoFar.invalidates(effects) ||\n    (effects.noticesGlobalSideEffects() && loopEffects.hasGlobalSideEffects());\nif (!unsafeToMove) {\njust to factor out the common !. Why not Index ret = curr->imported() ? 15 : 4; // imports may be costlier? Is there a better future-fix that I'm not seeing?. Ditto, why not check if the call is imported?. if (left->imported() != right->imported()) return false; ?\nWhich I think is technically an XOR, but for readability != is better, it fits the pattern better, and etc.. This feels pretty redundant now? Though the refactoring here will be more thorough than just changing the field types, so probably worth holding off for a future patch.. ... OH, because these are Calls, and don't have that property.\nEffectAnalyzer is at least a Walker, so has a reference to the module, but CostAnalyzer is a Visitor and so needs that explicitly. Ok, future work.. Should this also check !func->imported()?. Ah, and then\ncpp\nif (!left->imported()) {\n  return ExpressionAnalyzer::equal(left->body, right->body);\n}\nreturn true;\nso maybe that's not actually more readable.. Missing leading whitespace. Are these checks needed because imports have the same namespace as functions now?. How about:\n```c++\ndoIndent(o, indent);\no << '(';\nif (!curr->imported()) {\n  printMedium(o, \"global \");\n} else {\n  printMedium(o, \"import \");\n  printText(o, curr->module.str) << ' ';\n  printText(o, curr->base.str) << ' ';\n  o << \"(global \";\n}\nprintName(curr->name, o) << ' ';\nif (curr->mutable_) {\n  o << \"(mut \" << printType(curr->type) << \") \";\n} else {\n  o << printType(curr->type);\n}\nif (!curr->imported()) {\n  o << ' ';\n  visit(curr->init);\n} else {\n  o << ')'\n}\no << ')';\no << maybeNewLine;\n```\nThis adds support for printing mutable global imports (even though that's not currently allowed? We'll add it sooner or later) without duplication.\nAnyway maybe that's not the best approach either, but duplicating the global-name-type printing across these branches feels weird.. Presumably curr->name should be printed with printName here?. Can we flip this conditional, if (curr->imported()) { /* import printing logic */ } else { //...?\nThe else here is really far from the if, and makes it harder to see the else's precondition. The many intermediate ifs ands nests don't help either.\nI'm tempted to say flip to if (curr->imported()), copy the o << maybeNewline;, and add an early-return, just to avoid more nesting. That may be more controversial, however.. Alternatively: extract the imported case to a helper function, void printImportFunction(Function* curr);, and handle it totally separately (basically rename the existing visitImport?).\nOr: just because Imports aren't separate in the IR, doesn't mean we can't have separate functions to handle them.\nCould do something like:\n```c++\nvoid printImportCommon(Importable* curr) {\n  printMedium(o, \"import \");\n  printText(o, curr->module.str) << ' ';\n  printText(o, curr->base.str) << ' ';\n}\nvoid printImportedFunction(Function* curr) {\n  printImportCommon(curr);\n  if (curr->type.is()) {\n    visitFunctionType(currModule->getFunctionType(curr->type), &curr->name);\n  }\n  o << maybeNewline;\n}\n``\nand reuse for globals and the like.\nProbably could keep most of these inline.. Yeah, probably a good idea to extract the import header.. Also,maybeNewLinehere?. Whytemplate Tinstead of using the base class,Importable?. Oo these wound up very nice and linear, cool!. Should these loops use ModuleUtils::iter(Imported|Defined)Functions?. This \"All Functions\" comment seems a bit more misleading when it's only defined functions, and thefunctionson a module also include imports. Yay cleanup. I like how this change makes the ExternalKind enum go away, which makes this all cleaner.. ?\nWhy do we have falsy functions in wasm.functions? Why can we assert!curr->imported()` and have that work?\nAnd, is this simpler if we use ModuleUtils::iterDefinedFunctions?. Duplicated function bodies here\nHow about\nc++\nauto setDCEName = [&](Importable* import) {\n  auto id = getImportId(import->module, import->base);\n  if (importIdToDCENode.find(id) == importIdToDCENode.end()) {\n    auto dceName = getName(\"importId\", import->name.str);\n    importIdToDCENode[id] = dceName;\n  }\n};\nModuleUtils::iterImportedFunctions(wasm, setDCEName);\nModuleUtils::iterImportedGlobals(wasm, setDCEName);. ?\nShould this check that the global is actually spectest.print?. Oh, okay, this is very weird.\nIf I understand this right:\nWe first iterate over all the imported globals, if we find any globals we error with a message about spectest.print\nThen we iterate over all the imported functions, if we find any that aren't spectest.print, we error saying \"unknown import\"\nFinally we iterate over all the imported globals again, if we find any that aren't spectest.print, we error saying \"uknown import\"\nSo I predict this handles the tests that we have now, but would fail with very weird error messages in other cases, consider:\nwast\n(module\n  (import \"foo\" \"bar\" (global $bar i32)\n)\nwhich would fail with\nspectest.print should be a function, but is a global\nunknown import: foo.bar\nSo, we should probably change this to just\nc++\nModuleUtils::iterImportedFunctions(wasm, [&](Function* import) {\n  if (import->module != SPECTEST || import->base != PRINT) {\n    std::cerr << \"unknown function import: \" << import->module << '.' << import->base << '\\n';\n    invalid = true;\n  }\n});\nModuleUtils::iterImportedGlobals(wasm, [&](Global* import) {\n  std::cerr << \"unknown global import: \" << import->module << '.' << import->base << '\\n';\n  invalid = true;\n});. Extract as writeImportHeader(func, ExternalKind::Function)?. c++\nModuleUtils::iterImportedFunctions(*wasm, add);\nModuleUtils::iterDefinedFunctions(*wasm, add);. Ditto. (ditto). Is this handled further down, or does this still need a fix?. Ditto?. Ah, yeah makes sense. And the assert as well suggests \"we should not have any imports here\", so sgtm. Oh, cool. And annoying. Seems best as-is then.. That's what I was thinking yeah, sgtm . Oo, slick. Should these be if (!getterExists) {?\nAs written this should always fail if the getter or setter already exists... and it looks like it does, so we're not missing test coverage.. Could be made redundant with\nc++\nfor (size_t i = 1; i < size; i++) {\n  if (list[i - 1]->type == unreachable) {\n//.... Misread this as being upTo(n ** 2) instead of upTo(upTo(n)). nit: might as well put the early-out before list = pair.second if they don't depend on each other. Is it okay that this can have duplicates from list?. In theory this may not have to change, as everything will be indexed relative to the start of the segment, and so 0 is roughly exactly correct, with respect to how we actually use this, i.e. reading things out of the memory statically.\nBut we can yank this TODO once we're more sure that's the case (i.e. once we actually support EM_ASM in shared libraries), just thinking out loud here.. Seems inconsistent to have i64 abort, but unreachable breaks out of the switch, to abort later.. Could also do More |= SkipEmptyBlocks();, unfortunately not ||= but they're logically equivalent. That's a lot of auto... I don't really have any sense of what the types are by this point.. typo: s/__post_instanciate/__post_instantiate/. typo: expects. Should be alphabetically sorted. or, maybe with the other ir/ includes?. This changes stackSave to __stackSave? But stackRestore still doesn't start with the dunder? I'm confused.. nit typo: avoids. Nit: These could be private. I think they should be because they're not part of the API, but it's really pretty moot.. nit: I feel this would be nicer to indent everything an additional tab (aka 2 spaces), but this is probably just me. Are the nops because of the simplify-locals pass? Would we expect to get more than one?\nI'm completely okay with leaving this as-is until we have a need a for loop here, because this is simpler / easier to read.. I thought << curr printed the function body. Is that << *curr or does that not actually exist?\nThe thought being that printing the unexpected code inline with the error would be the information a user would really want, vs. the name which lets one look up the code later via wasm-dis.. Why 10? I'd think 4 or 8 would be more cache-friendly, though I guess it depends on how big std::vector is. Can we extract this pattern into a more reusable mechanism? E.g. Name name = runner->getPassOptionPrefixedBy(\"extract:\")\nI predict that as we get more pass args, we'll do that way more.. We've been doing that for a while now yeah:\nhttps://github.com/WebAssembly/binaryen/blob/65446aeade5b5a1acab6ae2a605ae1702251fda2/scripts/test/asm2wasm.py#L51-L54\nThough looking for where we do: not in any one spot, oh dear. Is the assert better than Fatal + error message?. Talked in person: the Fatal is up above, the assert is re-affirming that as a precondition. That should be a comment inline, because reversing this is exactly the sort of thing someone would think is a reasonable simplification. Should we add capture_output to emscripten's shared.py? (Not knowing what that enables in any detail). Huh, yeah merging it with the num_failures clause above makes that even nicer :+1: . ... I take back some of the nice things I've said about Python. ",
    "EvanWieland": "@jadekler I'm on MacOs too and am having the same issue. Any luck?\n. ",
    "jadekler": "@EvanWieland Not yet. :/ Thanks @kripken will give it a shot\n. ",
    "ojii": "@kripken I manually built binaryen from master from git, set BINARYEN_ROOT to that directory in ~/.emscripten and ran the tutorial again with no problem. so looks like it's a problem with how emcc builds it.\n. ",
    "tomgwozdz": "I'm having the same issue, but it worked fine for me around November 1st or so, on OSX.  a few days later it started having trouble, if that helps narrow down the cause.\n. I'm not sure how to do that.  I was just following these steps to get it running: http://webassembly.org/getting-started/developers-guide/  At what stage would I be bisecting?  And on what repo?  I'm sure how emsdk does things internally.\n. ",
    "Nithanaroy": "I was able to get it working by following these steps https://gitlab.sd.apple.com/npasumarthy/my-first-webassembly\nREADME.pdf\n. ",
    "jbajwa": "@kripken \nHi, I am experiencing the same issue on my mac. I did a git bisect, and the first bad commit is https://github.com/kripken/emscripten/commit/1f5e49bceb01e3ace3c09584df935e0bc43552cc\nRemoving env from subprocess.check_call(['cmake', '--build', '.'] + make_args, env=env) and subprocess.check_call(['cmake', '-DCMAKE_BUILD_TYPE=' + cmake_build_type, '.'], env=env) fixes the issue, so maybe an env variable is incorrectly being deleted on mac? Hope this helps.\n. I'm able to generate the wasm/html file by not passing the env variable to cmake, but when I run the html file it gives an exception thrown error, haven't looked into it further. For now I've manually built  binaryen as suggested in the earlier comments (if you don't want to build manually then the other option is to checkout a branch in your local repo from https://github.com/kripken/emscripten/commit/a28973d1b60a22723768e4e2bbe77b6795f964d1)\n. @kripken \nYes, you're correct, it is failing to build with fastcomp/../clang. Maybe in the python script could have some logic for mac?\nif sys.platform.startswith('darwin') \n  call cmake without env\nelse\n  call cmake with env\nAlthough, the system compiler might not be as upto date as fastcomp/clang?\n. @kripken \nSorry for the delay. I just tried to compile with your changes and its building without error although when I open the html file in the browser I get this error \"Exception thrown, see JavaScript console\"\nFollowing information in the console log:\ninput.html:1249 trying binaryen method: native-wasm\nprintErr @ input.html:1249\ninput.html:1249 no native wasm support detected\nprintErr @ input.html:1249\ninput.js:336 Uncaught no binaryen method succeeded. consider enabling more options, like interpreting, if you want that: https://github.com/kripken/emscripten/wiki/WebAssembly#binaryen-methods\nI don't see this error if I checkout from https://github.com/kripken/emscripten/commit/a28973d1b60a22723768e4e2bbe77b6795f964d1\n. I enabled webassembly in chrome chrome://flags/#enable-webassembly. Getting this error now\ninput.html:1249 trying binaryen method: native-wasm\nprintErr @ input.html:1249\ninput.js:172 Uncaught TypeError: Right-hand side of 'instanceof' is not an object\n    at doNativeWasm (http://localhost:8080/input.js:172:32)\n    at Object.Module.asm (http://localhost:8080/input.js:326:23)\n    at http://localhost:8080/input.js:2176:1\nAm I missing anything?\n. OK, so I realized my mistake. I wasn't using chrome canary. :) Its working as expected on Canary with webassembly enabled. Thanks for your help.\n. ",
    "MarkHarper": "@jbajwa, what steps did you follow after removing env?\n. ",
    "juanpicado": "I'm experiencing the same issue, I share this http://stackoverflow.com/a/40625922/308341 FYI.\n. ",
    "eska014": "\nHow is the startup time compared to asm.js? If it's worse, then something is wrong. One possibility is that the wasm binary is in a side file, and downloaded separately, so webserver performance matters more - how are you testing?\n\nOn Firefox, asm.js startup takes about 25 seconds, 3 seconds when cached. Firefox occasionally locks up for a minute when starting Godot per asm.js though, so it can take much longer, usually on the first time testing. WebAssembly startup takes about 10 seconds, so definitely faster.\nOn Chromium, asm.js startup takes about 4 seconds, I guess due to caching. Between Ctrl+Shift+Del, 'Disable Cache' in DevTools, Icognito mode and Ctrl+F5, nothing seems to disable/delete the asm.js cache, so no idea about times when running uncached. WebAssembly startup takes about 15 to 20 seconds.\nBy startup time, I mean compilation+engine initialization, without download time.\nI suppose there's no caching for WebAssembly? I'm also surprised about Chromium's compilation speed, taking up to twice as long as Firefox in worst cases.\nI've been testing with both 1) a server in the same country 2) locally per python -m SimpleHTTPServer. All files involved are hosted on the same server, in the same directory. We're using Emscripten's loading code by using emcc's --shell-file option.\nI'm subtracting the download time displayed in each browser's devtools from all times though.\nHere are examples of Godot per asm.js and WebAssembly:\n- http://godot.eska.me/temp/asmjs-2dplatformer\n- http://godot.eska.me/temp/wasm-2dplatformer\n\n\nThe s2wasm issue is a bug in the wasm backend or s2wasm, can you provide the bitcode file? That should be enough to reproduce the problem.\n\nSorry, the error with s2wasm was caused by a configuration mistake on my end, I'm now getting this error:\nAssertion failed: (!estack.empty()), function operator(), file src/s2wasm.h, line 713.\nThe new bitcode files are here if still relevant:\n- http://godot.eska.me/temp/emcc-0-basebc.bc.xz\n- http://godot.eska.me/temp/emcc-1-linktime.bc.xz\n\n\nThe Memory issue is strange - Firefox and Chrome should be running the same checks. What is TOTAL_MEMORY at compile time? Do you modify memory size during startup, perhaps? And, is this with or without memory growth?\n\nWe explicitly define TOTAL_MEMORY in the HTML file before running. The value is set by game developers during export of their game within the engine's editor, I've been testing with 268435456. Memory growth is not enabled. \n. @lars-t-hansen Wow, baseline compiler give very nice results, taking 3 to 4 seconds. But the tab crashes after the first few frames of the game are rendered. This is still on Firefox with the memory checks compiled out, otherwise I continue to get imported Memory with incompatible size.\n\nIf I remove the explicit TOTAL_MEMORY = 268435456 from the HTML, this is what I get:\n- Firefox, standard compiler: Tab crashes before rendering a frame of the game\n- Firefox, baseline compiler: Cannot enlarge memory arrays. [...]\n- Chromium: Cannot enlarge memory arrays. [...]\n. You're right, compiling with -s ALLOW_MEMORY_GROWTH=1 fixes the issue. I'm also no longer getting crashes with the baseline-compiler, not sure if this related to memory growth or changes to the baseline-compiler since I last compiled.\nAre there significant optimizations we're missing out on by enabling memory growth?\nAs for s2wasm, I recompiled LLVM and the error does seem to be gone. I'm now getting this:\nFatal: Unknown relocation: __environ\nThere's no such name in Godot, looks like it comes from Emscripten.\n@lukewagner\n\nChrome doesn't have any asm.js caching that I know of\n\nThat explains it, I was assuming it works similar to Firefox. Thanks for the tip about explicit caching, I'll give it a try.\n\ngodot might be missing the Chromium asm.js pseudo-AOT optimization path\n\nIs there something we can do about this in Godot?\n@lars-t-hansen\nThanks for the update on the crash, I recompiled Firefox and confirm it no longer crashes.\n. @jgravelle-google Thanks for the warning. I'm aware that s2wasm is still rather WIP though, I'm reporting these failures with the prospect of hitting a new wall after an error is resolved.\nBut I agree that one could easily get the wrong idea about the state of the LLVM-backend path from Binaryen's readme.\nBy the way, I also think it would be helpful to note in Binaryen's readme that one needs to set a CMake option to compile the WebAssembly backend in LLVM (LLVM_EXPERIMENTAL_TARGETS_TO_BUILD=WebAssembly if I remember correctly). Took me a bit to realize the first time.\n. Saw that there were changes to the linker, so tried building with s2wasm again. Build finishes successfully, now I'm getting this error when starting:\nfailed to compile wasm module: TypeError: import object field 'emscripten_asm_const_int' is not a Function`\nI assume it's this issue: WebAssembly/design#769\n@kripken Thank you, we've enabled memory growth for WebAssembly builds.. Tried s2wasm again with the EM_ASM PRs merged. The build terminates from s2wasm, printing this:\n[[object_alias:]]:\n==========\n__dso_handle, 1\n        .import_global  __environ\n        .size   __environ, \n==========. Rebuilt LLVM with those commits and the build finishes successfully again.\nWhen running, I'm now getting an undefined reference error for asm[\"setTempRet0\"] in the generated .js file, in the definition of function _saveSetjmp. Changing the call to Module.asm[\"setTempRet0\"] gets rid of the error.\nWith that change, I get a failing assertion assert(offset_high === 0) in syscall140 (llseek) from here: https://github.com/kripken/emscripten/blob/04255b4ada1983301cb35cafbc5483db036149fe/src/library_syscall.js#L663\nIf I comment that assert out, the game starts and runs. That's great, thanks for the help so far!\nI notice the size of the binary generated by asm2wasm (~14.3MiB) is smaller than that generated by s2wasm (~15.4MiB), how comes?. Gave it a try with s2wasm+wasm-opt, here are the results. Using release builds now, I forgot I was using debug builds for the previous comparison\nasm2wasm:   13591777\ns2wasm -O:  14723647\ns2wasm -Os: 14723647\ns2wasm -Oz: 14723647\ns2wasm -O2: 14729818\ns2wasm -O3: 14729818\ns2wasm -O1: 14730066\ns2wasm:     15563060\ns2wasm -O0: 15668791\nThat's already a nice improvement. I'll keep my fingers crossed for optimizations in the LLVM backend.. What's going on with Chrome 57-stable? WebAssembly is enabled, but won't start:\nLinkError: WebAssembly.instantiate(): Import #3 module=\"env\" function=\"___dso_handle\" error: global import must be a number\n\nWebAssembly support is only mentioned in the 57-beta change log, not for 57-stable. Is it not officially supported yet? Or is this an issue in the build?\nWorks in Chrome Canary 59.0.3037.0.\nIt also works in Firefox 52 =). WebAssembly is working fine in our development-branch at this point, and I don't want to leave this issue open forever.\nThank you very much for your help! I'll open a new issue if we happen upon any concrete issues.\nIn the coming months we'll release Godot Engine 3.0 (currently in alpha) with WebAssembly export and hopefully get some real-world feedback.. That's a lot more helpful, the instructions seem clear to me as well.\n. ",
    "lars-t-hansen": "Re startup time, Firefox has a faster compiler for wasm (the \"baseline\" compiler) that is not yet in use but which is still present in recent builds.  I'd be curious to know what compilation+initialization times you're seeing if you use this compiler.  You can enable it by setting javascript.options.wasm_baselinejit to true in about:config.\n. Crash with standard compiler logged: https://bugzil.la/1316321.\nThough apparently this was known already:  https://bugzil.la/1316156.\n. https://bugzil.la/1316156 has been fixed and will presumably show up in Nightlies in a day or two.\n. > Currently there are no complete implementations of wasm threads in any JS VMs that I know of, but work has started in V8 and probably others too.\nWork is going on in SpiderMonkey but given current workloads and summer vacation schedules we're not expecting to be done until late Q3 (and that's not a commitment, just a well-educated guess).. Haven't looked at the details here yet but a fair amount of conservatism is in order since we don't have undefined behaviors.  Atomics must never be reordered with respect to each other, and non-atomic operations must never be reordered with respect to atomic operations.  I believe there is space to weaken atomic operations in some cases (so as to minimize the amount of fencing in the implementation) but we don't yet have any way of expressing weaker operations, so that's a bit academic.  It is legal to elide eg redundant atomic loads and stores in some circumstances, but one has to be very careful about observability and termination.  Personally I would just leave all atomic ops in the program. . FWIW, I expect the engines to start optimizing atomics eventually, notably, removing redundant fencing.  For example, SpiderMonkey on x86 emits an MFENCE after every atomic store (or uses an LOCK+XCHG for the store) but that's only necessary between the last store in a sequence of atomic stores and the subsequent load (atomic or not).  Also, engines can remove redundant atomic operations on the (extended) basic block level more easily than binaryen can.. ",
    "lukewagner": "@eska014 Chrome doesn't have any asm.js caching that I know of; I expect godot might be missing the Chromium asm.js pseudo-AOT optimization path and thus the compilation is happening at runtime and that's the difference you're seeing.  Otherwise asm.js-on-Chrome would be slower then WebAssembly-on-Chrome.\nHowever, WebAssembly actually supports explicit caching by storing compiled WebAssembly.Module objects in IDB using IDBObjectStore.put and get.  On FF, I've measured this to be significantly faster than asm.js caching.  (Note: until bug 1312808 is fixed, cached Modules get invalidated when the FF build-id updates, this should be fixed soon and before release.)\n. It seems like a good idea to have an \"absolutely remove all obviously-dead code\" pass in binaryen so that, if WebAssembly/design#894 gets resolved to disallow code between unconditional branches and end/else (which it now appears 3 browsers would prefer), we can trivially turn that on whenever wasm output is enabled so that, regardless of any previous passes, we can always get valid wasm output.  Maybe this could even be integrated into the AST-to-binary pass since it should be quite easy to do if you're already recursively walking over the tree.. @kripken Do you think you'd be able to apply this patch to SM and run the test suite?  It should just throw a validation error if it encounters this case.. Ok, thanks for doing that!  I'll reach out to see how they're building AB.. In the meantime, even if it's only temporary until WebAssembly/design#894 gets resolved; it'd be most appreciated to always run DCE in -O0 that way this isn't an issue if we make that change.. I think #880 fixes the root issue here?\n@kripken Yeah, the goal is to pave the way for being able to land https://bugzilla.mozilla.org/show_bug.cgi?id=1324032 and maximizing the options we have in WebAssembly/design#894 so that \"oh but there is already some breakage in the wild\" doesn't end up being a sticking point.  If later it turns out it's unnecessary, then we could turn it back off by default on -O0.. Politely requesting a ping whenever this change is ready to land so we can update browsers simultaneously.  Because it's a custom section it's not a \"breaking\" change, but still it'd be nice to minimize the window of not-working-ness.. Hey thanks a lot!  So I don't know if yous have been following design/#989, but @titzer's proposal is to name the updated extensible-names section utf8-names instead of just names.  Still need a PR on design repo to nail that down, though.  What's nice is this could allow engines to accept both names and utf8-names for a period of time, smoothing the transition.. Is --strip run by default as part of normal opt builds?  If so, then I think it'd be better to leave the producers section in, since it's fairly miniscule in size, unlike the names and other sections that people are probably meaning to remove when they --strip.  How about having a separate --strip-producers or --strip-all for testing and for when people really mean to remove the producers?. > It is over 100 bytes, which is small compared to a large wasm I agree, but not all wasms are large, and also it's 100 bytes times every wasm downloaded over the internet, which adds up.\nSince this is mostly just a matter of deciding what are reasonable defaults, how about only stripping the producers section by default when doing so provides a meaningful size reduction, say, >.1%.. There's also a benefit to the toolchain and ecosystem to get reporting on what tools are being used and how much, and that will, practically speaking, be entirely lost if the defaults that everyone use strip the producers section by default.  So if there is a <.1% size reduction, it seems like the downside is negligible while there is a concrete upside.. More than idle curiosity, seeing what tools are used, and how much, can help prioritize time spent on various projects and validate time already spent.  Just normal data-driven development type stuff.. Getting away from vague notions of popularity is the goal of using real measurement data though :)  Ultimately, usefulness is subjective, but this was discussed a couple times in various wasm CG meetings and the issue and multiple groups seemed think it was useful.  @dschuff thoughts?. ",
    "kungfooman": "@eska014 TL;DR: try restarting Chrome\nJust had the same error message, basically from one code change to the other... Chrome worked for weeks and is/was my main WASM testing plattform. Had no clue what could even cause it, since I reverted the change, recompiled, reloaded... still had this error. So the compiled binaries were fine. After wasting more and more time, to figure out the case, I tested a minimal main() { printf(\"...\"); } example and it still failed with the ___dso_handle error. Tested same generated test.html/test.wasm in Firefox and it worked without any issues. So I knew Chrome didn't work right for some reason. After a Chrome restart everything worked fine again... so in my case I ran into some Chrome bug, cannot reproduce it (yet) tho. \n. ",
    "qog314": "Correct, things that don't use SDL work just fine. \nYes, I have set the wasm flag in Nightly. \nThe emscripten version is emsdk-1.35.0-portable-64bit. \nThe program compiles without incident; the error shows in developer tools when I try to access the html page. \nThis is the only thing I can find resembling a stack trace:\nno native wasm support detected pal_sdl.html:1249:13\nModule.printErr http://localhost:8000/pal_sdl.html:1249:13\ndoNativeWasm http://localhost:8000/pal_sdl.js:197:7\nintegrateWasmJS/Module.asm http://localhost:8000/pal_sdl.js:328:23\n<anonymous> http://localhost:8000/pal_sdl.js:11477:10. I updated to the latest version by doing\n./emsdk update latest\n./emsdk activate latest\nsource ./emsdk_env.sh\nNow, none of the tests will compile. Here is the traceback:\nTraceback (most recent call last):\nFile \"./emcc\", line 13, in <module>\n    emcc.run()\nFile \"/opt/emsdk_portable/emscripten/master/emcc.py\", line 1777, in run\n    binaryen_bin = os.path.join(shared.Settings.BINARYEN, 'bin')\nFile \"/usr/lib/python2.7/posixpath.py\", line 77, in join\n    elif path == '' or path.endswith('/'):\nAttributeError: 'int' object has no attribute 'endswith'\nHave I missed a step?\n. I have updated incoming according to those commands. I am still getting the \"no native wasm support detected\" error.\nIs it possible that this is a linux only issue? My colleague, who is on windows, is not having this issue. . The angry bots demo works fine. \nMy colleague is on 1.36.5; I am on 1.36.14, but was on 1.36.0 before. I was wrong before - he is also on linux, but doesn't know which version. \nI tested a build he compiled and it runs fine on my nightly. \nThis would indicate there's something specifically wrong with my toolchain, yes?. I am not sure what fixed this, but I restarted the nightly browser and suddenly I am not getting that error anymore. \nI didn't make any other changes. Weird. . ",
    "rd-secretstuff": "Increasing MAX_NAME_INDEX to 10000 in RelooperJumpThreading.cpp will make the 'too many names in RelooperJumpThreading :(' error go away, but the remainder of the fail stays the same.\nIt looks like in my case the nameCounter will go up as high as 7820, compared to the current MAX_NAME_INDEX maximum of 1000 only.. Sorry, the code cannot be shared. :(\nthe relevant output is : \nDEBUG:root:saving intermediate processing steps to /tmp/emscripten_temp\nDEBUG:root:(not saving intermediate /tmp/emscripten_temp/emcc-0-basebc.bc because deferring linking)\nDEBUG:root:emcc: LLVM opts: -strip-debug -disable-verify -internalize -internalize-public-api-list=MyExportedFunctions,__cxa_demangle,malloc,free,__errno_location,fflush,__cxa_can_catch,__cxa_is_pointer_type,malloc,free,malloc,free,malloc,realloc,malloc -globaldce -disable-loop-vectorization -disable-slp-vectorization -vectorize-loops=false -vectorize-slp=false -vectorize-slp-aggressive=false  [num inputs: 31]\nDEBUG:root:emcc step \"post-link\" took 4.44 seconds\nDEBUG:root:LLVM => JS\nDEBUG:root:emscript: llvm backend: /home/user/emsdk_portable/clang/fastcomp/build_incoming_64/bin/llc /tmp/tmprkGFyw/myproject_release.bc -march=js -filetype=asm -o /tmp/emscripten_temp/tmpZ3pN2M.4.js -emscripten-precise-f32 -emscripten-global-base=1024 -O3 -enable-emscripten-cxx-exceptions -emscripten-wasm -emscripten-only-wasm\nDEBUG:root:  emscript: llvm backend took 8.70709395409 seconds\nDEBUG:root:emscript: js compiler glue\nDEBUG:root:  emscript: glue took 0.233507871628 seconds\nDEBUG:root:emscript: python processing: function tables and exports\nDEBUG:root:asm text sizes[[77932735, 4365], 17820, 214, 6744, 0, 16833, 301422, 59968, 294, 5218, 113426]\nDEBUG:root:  emscript: python processing: function tables and exports took 0.0199429988861 seconds\nDEBUG:root:emscript: python processing: finalize\nDEBUG:root:  emscript: python processing: finalize took 0.0731379985809 seconds\nDEBUG:root:emcc step \"emscript (llvm => executable code)\" took 11.98 seconds\nDEBUG:root:applying pre/postjses\nDEBUG:root:emcc step \"source transforms\" took 0.43 seconds\nDEBUG:root:wrote memory initialization to ../webassembly/release/myproject_release.js.mem\nDEBUG:root:emcc step \"memory initializer\" took 1.71 seconds\nDEBUG:root:emcc step \"js opts\" took 0.00 seconds\nDEBUG:root:separating asm\nDEBUG:root:PYTHON not defined in /home/user/.emscripten, using \"/usr/bin/python\"\nDEBUG:root:JAVA not defined in /home/user/.emscripten, using \"java\"\nDEBUG:root:Cache: acquiring multiprocess file lock to Emscripten cache\nDEBUG:root:Cache: done\nDEBUG:root:Cache: released multiprocess file lock to Emscripten cache\nDEBUG:root:check tells us to use asm.js backend\nDEBUG:root:using binaryen, with method: native-wasm\nDEBUG:root:asm2wasm (asm.js => WebAssembly): /home/user/.emscripten_ports/binaryen/binaryen-version_21/bin/asm2wasm ../webassembly/release/myproject_release.asm.js --total-memory=16777216 -O3 --mem-init=../webassembly/release/myproject_release.js.mem --mem-base=1024 --wasm-only\nasm2wasm: /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm.h:1551: wasm::Function* wasm::Module::getFunction(wasm::Name): Assertion `functionsMap.count(name)' failed.\nTraceback (most recent call last):\n  File \"/home/user/emsdk_portable/emscripten/incoming/emcc\", line 13, in <module>\n    emcc.run()\n  File \"/home/user/emsdk_portable/emscripten/incoming/emcc.py\", line 2029, in run\n    subprocess.check_call(cmd, stdout=open(wasm_text_target, 'w'))\n  File \"/usr/lib/python2.7/subprocess.py\", line 540, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command '[u'/home/user/.emscripten_ports/binaryen/binaryen-version_21/bin/asm2wasm', '../webassembly/release/myproject_release.asm.js', '--total-memory=16777216', '-O3', '--mem-init=../webassembly/release/myproject_release.js.mem', '--mem-base=1024', '--wasm-only']' returned non-zero exit status -6\nmake: *** [myproject] Error 1 \nRunning from the command line will give the following results:\n``\n/home/user/.emscripten_ports/binaryen/binaryen-version_21/bin/asm2wasm myproject_release.asm.js --total-memory=16777216 -O3 --mem-init=myproject_release.js.mem --mem-base=1024 --wasm-only\nasm2wasm: /home/rodney/.emscripten_ports/binaryen/binaryen-version_21/src/wasm.h:1551: wasm::Function* wasm::Module::getFunction(wasm::Name): AssertionfunctionsMap.count(name)' failed.\nAborted\n```\nIt looks like it failed or stopped adding more functions to the functionsMap somewhere and then fails when it checks if a certain named function is in the map.\nMaybe there are additional hard coded limits in the code somewhere. \nThe project that I am compiling is about half a million lines of C++ code that is why the resulting asm.js file is 74 MiB. callstack : \n```\n10 0x000000000046f54d in main ()\n9  0x00000000004806d4 in wasm::Asm2WasmBuilder::processAsm(cashew::Ref) ()\n8  0x000000000048ad08 in wasm::OptimizingIncrementalModuleBuilder::finish() ()\n7  0x00000000004bba38 in wasm::PassRunner::run() ()\n6  0x0000000000539e7e in wasm::RemoveUnusedFunctions::run(wasm::PassRunner, wasm::Module) ()\n5  0x0000000000538f3d in wasm::Walker >::doVisitCall(wasm::DirectCallGraphAnalyzer, wasm::Expression*) ()\n4  0x000000000046be43 in wasm::Module::getFunction(wasm::Name) [clone .part.251] ()\n. The following callstack is after disabling optimizations and with ADD_COMPILE_FLAG(\"-g3\")\nProgram received signal SIGABRT, Aborted.\n0x00007ffff700dc37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56\n14 0x00000000006cc47c in main (argc=7, argv=0x7fffffffd758) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/tools/asm2wasm.cpp:107\n13 0x00000000006bfb33 in wasm::Asm2WasmBuilder::processAsm (this=0x7fffffffccb0, ast=...) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/asm2wasm.h:861\n12 0x00000000006deedc in wasm::OptimizingIncrementalModuleBuilder::finish (this=0x4e2ca370) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm-module-building.h:168\n11 0x00000000006df2e7 in wasm::OptimizingIncrementalModuleBuilder::optimizeGlobally (this=0x4e2ca370) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm-module-building.h:222\n10 0x000000000073b391 in wasm::PassRunner::run (this=0x7fffffffc270) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/passes/pass.cpp:231\n9  0x00000000007dc2b6 in wasm::RemoveUnusedFunctions::run (this=0x5c4d0730, runner=0x7fffffffc270, module=0x7fffffffce30) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/passes/RemoveUnusedFunctions.cpp:50\n8  0x00000000007dbe7d in wasm::DirectCallGraphAnalyzer::DirectCallGraphAnalyzer (this=0x7fffffffbe80, module=0x7fffffffce30, root=std::vector of length 7064, capacity 8192 = {...}) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/ast_utils.h:87\n7  0x00000000007dc76f in wasm::Walker >::walk (this=0x7fffffffbe80, root=@0x56987978: 0x5690aa90) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm-traversal.h:247\n6  0x00000000007ddd5b in wasm::Walker >::doVisitCall (self=0x7fffffffbe80, currp=0x5690af20) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm-traversal.h:265\n5  0x00000000007dbf1f in wasm::DirectCallGraphAnalyzer::visitCall (this=0x7fffffffbe80, curr=0x5690af28) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/ast_utils.h:92\n4  0x00000000006d91d4 in wasm::Module::getFunction (this=0x7fffffffce30, name=...) at /home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm.h:1551\n3  0x00007ffff7006ca2 in __GI___assert_fail (assertion=0x839663 \"functionsMap.count(name)\", file=0x839550 \"/home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm.h\", line=1551, function=0x83d840  \"wasm::Function* wasm::Module::getFunction(wasm::Name)\") at assert.c:101\n2  0x00007ffff7006bf6 in __assert_fail_base (fmt=0x7ffff71573b8 \"%s%s%s:%u: %s%sAssertion `%s' failed.\\n%n\", assertion=assertion@entry=0x839663 \"functionsMap.count(name)\", file=file@entry=0x839550 \"/home/user/.emscripten_ports/binaryen/binaryen-version_21/src/wasm.h\", line=line@entry=1551, function=function@entry=0x83d840  \"wasm::Function* wasm::Module::getFunction(wasm::Name)\") at assert.c:92\n1  0x00007ffff7011028 in __GI_abort () at abort.c:89\n0  0x00007ffff700dc37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56\n```\nThe code I am building is a heavily modified version of the xspice circuit simulator. The original code was C but lots of C++ code has been added to it. Some minor parts of the code use generated code mostly to create static struct definitions followed by some functions (it creates a spice code model), the complexity of the generated files is very low and they are indistinguishable from hand coded files. \nThere are about 31 cpp files auto generated with around 1000 lines of code in each of them. \nThe C code in general uses a lot of structs to emulate some kind of object oriented design (These parts of the code are a couple of decades old from before C++ was a thing and we have not been given time since to clean it up). \n. The getFunction function fails when trying to get _testSetjmp.\nA function with that name was indeed never added to functionsMap of the Module class in wasm.h. Where do I build that code?. The fastcomp change seems to have worked and the build completed without errors. I now have a 1.1 GiB wast file and a 7.0 MiB wasm file. I hope I only need the wasm file :-). ",
    "brson": "Is the error here on rustc's side, where we are emitting simd IR to a platform  that doesn't support it?. ",
    "CryZe": "That seems likely, but I didn't dig too deep into this back when I was getting these errors a lot.. Looks like neither f32.rem nor f64.rem are WebAssembly instructions, which means binaryen will try to replace it with a f64-rem function that it provides itself. Seems like there's no f32-rem. This seems to be the code that does the replacement:\nhttps://github.com/WebAssembly/binaryen/blob/e865f2fa2863b6e91521c059a61a4483769bf5c9/src/asm2wasm.h#L1822-L1838\nSeems like it just needs a check that promotes the f32 arguments to f64, which seems to be done with:\nc\ncurr->operands[i] = parent->builder.makeUnary(PromoteFloat32, curr->operands[i]);\nInterestingly, this is part of visitCallImport which seems to be the function that fixes calls to imports. So I feel like that should've been fixing the arguments, but it maybe didn't get called?!\nhttps://github.com/WebAssembly/binaryen/blob/master/src/asm2wasm.h#L1350. ",
    "tutorialstechnology": "Hi!\nWe tracked this issue and after reading it we created a new tutorial. https://tutorials.technology/tutorials/54-Webassembly-tutorial-using-emscripten-hello-world.html\nPlease let us know if you find mistakes or if there is a better way of working with webassembly.\nwe want to help people!\nthanks. ",
    "chicoxyzzy": "Thank you for your answer!\nIn fact my goal is to create a wasm module (using Rust) with simple function exported to use from JS via JavaScript API in Canary / FF Nightly\nMaybe there are some articles / docs / blog posts which can help?\n\nBTW, how can I emit HTML? Should I call rustc with some Binaryen flags passed to it somehow?\n\nSorry for my newbie questions :(. > To emit html, you just call emcc with -o output.html, the suffix tells it what to emit. Not sure where that fits in with rustc though.\nIt was as simple as\nbash\nrustc --target=wasm32-unknown-emscripten hello.rs -o output.html\n\ud83c\udf89 \n\nit doesn't need libc or other system libs\n\nI just need arithmetic operations without any I/O. Standalone wasm is exactly what I need. Thank you! I'll try it.. @brson is there any way to pass -s option to emcc? I believe that -s \"BINARYEN_METHOD='interpret-binary'\" should be passed to run compiled JS in Node.js. Just noticed that wiki page is still outdated https://github.com/WebAssembly/binaryen/wiki/binaryen.js-API. index -> strToStack(name). index -> strToStack(name). index -> name. index -> name. ",
    "m4b": "@chicoxyzzy no i don't think so, this is the same old tired issue of not being able to pass link arguments to the \"system\" linker (in this case emcc) via cargo.\nOf course, you can:\n\nrun the cargo command with -vv\ncause it to fail\ncopy the \"linker\" command\nadd your -s \"BINARYEN_METHOD='interpret-binary'\" to the \"link line\"\nhit enter and it should work\n\nAlternatively, you can perform some path hackery and have emcc automatically pass -s  along with rest of the arguments.\nPS: your your suggestion works by the way, thank you, I couldn't seem to find this mentioned anywhere obviously.... ",
    "alexandrelessard": "Thanks for the quick response.\nI am not in a position to provide easily the full setup to repro this situation.\nI will find a simplified setup hopefully next week to help that, \nThanks.  I can provide a way for you to repro the \"none\" generation.\nIntegrationDemo.asm.js.zip\n(using 1.37.1 tool chain)\nHave an version of asm2wasm.exe with debug symbols.\nAdd a breakpoint in:\n\\binaryen\\binaryen-version_21\\src\\wasm.h\ninside the none case:\ninline const char* printWasmType(WasmType type) {\n  switch (type) {\n    case WasmType::none: \n        return \"none\";\nand run the following command:\nasm2wasm integrationDemo.asm.js --wasm-only\non this file:\nIntegrationDemo.asm.js.zip\nThese \"none\" will cause crashes int he wasm-as.exe later in the pipeline.\nThanks. Yes i am using both at the moment.. ",
    "cr88192": "deeptail0.asm.zip\nhopefully this works...\n. ",
    "briangavin": "Wow that was fast!   Your fix works great :). ",
    "yancybulski": "sorry,\nthis is the original code (part of it), and it's running with asm.js...the brwoser didn't said anything about it not being valid\njavascript\nfunction Lb(aa, da) {\n    aa = aa | 0;\n    da = da | 0;\n    var zb = 0; {\n        zb = Ya[(Va + ((aa >>> 12) << 2)) >> 2] | 0;\n        if ((zb | 0) == -1) {\n            Kb(aa, da);\n        } else {\n            Wa[aa ^ zb] = da;\n        }\n    };\n}. javascript\nbad parseExpression state:\n==========\n;\n            if ((zb | 0) == -1) {\nsame . ",
    "kf2093": "thanks, I'll keep playing around then :). ",
    "baptistemanson": "I'm curious and would like to ask you a question, if you excuse my ignorance. \nWhy did you decide to have the superoptimizer running on the wast? And not on the LLVM representation?. ",
    "kazuki": "Thanks. I joined community group and agreed individual CLA.. ",
    "Horcrux7": "I can't see any binary download on this page.. Thank you very much. I have it.. ",
    "pipcet": "Thanks! Yeah, I verified the size change matches what should happen (again, if I'm reading the spec correctly): plus 5 bytes for the subsection size, 1 byte for the subsection type, 2x1 byte for the indices, minus 2 bytes for the missing local count. \nThere's one slight change in behavior: the old code used to die when presented with a module that defined local names, the new code simply ignores the local[2] subsection of the \"name\" section. I think the new behavior is better, as I can run binaryen utilities directly on my wasm modules without having to strip the \"name\" section, but if you prefer the old behavior I can change it.. @lukewagner I confess I haven't been following that discussion, but I think that's an excellent idea (I'm not so sure utilities should support the \"name\" subsection still, but that's a separate issue from changing the name).\n@kripken I suggest delaying this PR here until the design repo PR is through.. If I'm reading https://github.com/WebAssembly/design/pull/1016 correctly, the proposal to rename the \"name\" section has been dropped.\nThe question now is whether it's too late to handle only the new extensible name section, or whether some sort of autodetection (not very hard) is required to tell whether we're looking at an old-style or new-style \"name\" section. (Unless I'm mistaken, an old-style \"name\" section will never split into valid subsections).\nIn either case, I think it's time to make the extensible name section the default.. Thanks for testing!\nI think the plan was for SM to update when binaryen does, so obviously I agree we should merge it soon.. Good idea about the test; am I right in thinking that currently wasm-opt doesn't output to stdout, even if -o isn't specified? I can get a test working using -o /dev/stdout, but I don't think that's really portable.\nI'm afraid there's no good documentation for \"dyninfo\" right now: it's just a rewritten version of the intermediate ELF file's dynamic symbol section, and I'm still undecided whether it would be better to leave the section in binary format and decode it in the dynamic loader.... Hmm. I'd like to make sure that the binary section is actually reproduced one-to-one by wasm-opt, so I guess I should be creating a temporary file in the test directory.\nThanks for the link! As I'm moving from testing things privately to working with the binutils people, a number of things have turned up that would justify inclusion in (informative, at least) WebAssembly documents. I'm actually about to open an issue about it there :). Hmm. The error you report above, errno = 128, corresponds to EKEYREVOKED. Are you sure your system time isn't set to the future? What does date say?\nETA: actually, it's what git reports for all network errors. Can you access the github servers when you use git directly?. Yes, the instructions work here. There's something wrong either with your network connection (firewall?) or git version (I notice you have git in /usr/local, so I assume you've built it yourself), I think.. I'm not sure how it's causing that error, but removing the second \"use asm\"; appears to fix things.. Can you post your entire input file? This one works for me, with all semicolons and such:\nfunction calculator(global) {\n    \"use asm\";\n    function add(x, y) {\n        x = x | 0;\n        y = y | 0;\n        return x + y | 0;\n    }\n    return { add: add };\n}. As for the check.py issue, does check.py --no-test-waterfall work?. That looks like a clang-vs-gcc issue (as used for building binaryen, not for the wasm code :-) ). Does it happen with the vanilla tree? It might be worth filing a separate issue for that.. Have you tried grouping the libraries with -Wl,-( and -Wl,-)? That appears to fix the issue here (and there might not be a correct order to specify the libraries in anyway):\n$ g++ test.cpp -Llib -I../ -Wl,-\\( -lbinaryen -last -lasmjs -lsupport -lpasses -lwasm -Wl,-\\) -pthread && ./a.out && echo $?\n0. absolutely! And that actually caught a silly bug in my non-binaryen code, so thanks for the suggestion!. Just the latter, currently, but I'm looking at combining them when it makes sense to do so (I'm currently emitting tee_local at way too late a stage, by looking at the opcode stream for the right combinations, for example).. ",
    "trzecieu": "One issue what missed is that every time build is bigger then normal.\nAfter compiling 100 more samples I see that: \n- 2 builds are ~~corrupted~~ extended\nRight now I've noticed that every time I have one or two more symbols: \n__ZNKSt3__27num_getIcNS_19istreambuf_iteratorIcNS_11char_traitsIcEEEEE6do_getES4_S4_RNS_8ios_baseERjRm\n__ZNKSt3__27num_getIcNS_19istreambuf_iteratorIcNS_11char_traitsIcEEEEE6do_getES4_S4_RNS_8ios_baseERjRPv\nWhen compiled with EMCC_DEBUG=1 I have the same:\n-  *temp.asm.js from build folder\n-  *bc.o.js from build emcc temp folder. Hi @kripken,\nTesting with BINARYEN_CORES=1 gives the same result I means: \n- hashes of asm.js builds are the same \n- hashes of .wasm build is different\n- hashes of .bc.o.js from EMCC_TEMP_DIR are the same \n\nSoon I will try to loop over only asm2wasm command.\nI found in a debug log: \nDEBUG:root:asm2wasm (asm.js => WebAssembly): /home/piotr/Projects/ff-sample/mobile/emsdk/.ports_sdk-incoming-64bit/binaryen/binaryen-version_29/bin/asm2wasm build/enginesample_wasm.temp.asm.js --total-memory=67108864 -O2 --mem-init=build/enginesample_wasm.js.mem --mem-base=1024 --wasm-only --symbolmap=build/enginesample_wasm.js.symbols -o build/enginesample_wasm.wasm\nAnd I see that enginesample_wasm.temp.asm.js is not preserved in EMCC_TEMP_DIR, can you please tell me if this is the same file what *.bc.o.js?\n. ",
    "mbana": "any clues? or better yet an ETA.. @kripken hey, any updates on this?\ni would really like to try this out locally.\ncan you offer any hints?. ok, do you have an ETA on when this is going to be fixed?\nalso, could you look at the instructions and double-check that they are correct before i look at this further.. i tried once more here is the output:\n```$ mkdir wa\n~/dev $ \n~/dev $ cd wa\n~/dev/wa $ ls -lah\ntotal 0\ndrwxr-xr-x  2 mbana staff   68 Apr  9 20:41 .\ndrwxr-xr-x 31 mbana staff 1.1K Apr  9 20:41 ..\n~/dev/wa $ \n~/dev/wa $ \n~/dev/wa $ \n~/dev/wa $ git clone https://github.com/juj/emsdk.git\nCloning into 'emsdk'...\nremote: Counting objects: 928, done.\nremote: Compressing objects: 100% (19/19), done.\nremote: Total 928 (delta 7), reused 0 (delta 0), pack-reused 909\nReceiving objects: 100% (928/928), 437.77 KiB | 588.00 KiB/s, done.\nResolving deltas: 100% (579/579), done.\n~/dev/wa $ cd emsdk\n~/dev/wa/emsdk $ ./emsdk install sdk-incoming-64bit binaryen-master-64bit\nFetching all tags from Emscripten Github repository...\nInstalling SDK 'sdk-incoming-64bit'..\nInstalling tool 'clang-incoming-64bit'..\nCloning into '/Users/mbana/dev/wa/emsdk/clang/fastcomp/src'...\nERROR: Repository not found.\nfatal: Could not read from remote repository.\nPlease make sure you have the correct access rights\nand the repository exists.\n['/usr/local/bin/git', 'clone', 'https://github.com/kripken/emscripten-fastcomp/', '/Users/mbana/dev/wa/emsdk/clang/fastcomp/src'] failed with error code 128!\nInstallation failed!\n~/dev/wa/emsdk $ date\nSun Apr  9 20:42:24 BST 2017\n~/dev/wa/emsdk $ \n```\nsame error.\n\ncan you try the above on a fresh docker container, say, even a linux one and see if the instructions on the site are correct.\nthanks. ",
    "sudocurse": "Hey, @mbana, making these changes should help. https://github.com/juj/emsdk/pull/82\n. ",
    "Durisvk": "If I remove the second \"use asm\"; I get this error:\nbad parseExpression state:\n==========\nfunction add(x, y) {\n        x = x | 0;. aah yes this one works for me too.. thank you, you can close the issue :). ",
    "gouletr": "Verified it fixes the compile issue with our engine. Thanks! \ud83d\udc4d . ",
    "rjw57": "Yup, the test case succeeds for me when binaryen built as a shared library and I'd have expected it to when binaryen was built as a static library. AFAICT building as a static library is not tested for in CI?. It still fails for me:\n$ g++ test.cpp -Llib -I../ -lbinaryen -lwasm -last -lasmjs -lsupport -lpasses -pthread\nlib/libpasses.a(RemoveUnusedBrs.cpp.o): In function `wasm::RemoveUnusedBrs::doWalkFunction(wasm::Function*)::FinalOptimizer::visitBlock(wasm::Block*)':\nRemoveUnusedBrs.cpp:(.text._ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE[_ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE]+0x1bb): undefined reference to `wasm::ExpressionManipulator::spliceIntoBlock(wasm::Block*, unsigned int, wasm::Expression*)'\nRemoveUnusedBrs.cpp:(.text._ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE[_ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE]+0x4af): undefined reference to `wasm::ExpressionManipulator::spliceIntoBlock(wasm::Block*, unsigned int, wasm::Expression*)'\ncollect2: error: ld returned 1 exit status. > BUILD_STATIC_ON does not change the layout/dependencies or number of libraries in binaryen: it only builds 7 static libs instead of 7 shared libs. \nWhen BUILD_STATIC_LIB is OFF I get 6 static libs and one shared:\n$ ls -l lib/\ntotal 7604\n-rw-r--r-- 1 rjw57 rjw57   37098 Mar 15 22:10 libasmjs.a\n-rw-r--r-- 1 rjw57 rjw57   98126 Mar 15 22:10 libast.a\n-rwxr-xr-x 1 rjw57 rjw57 2464328 Mar 15 22:10 libbinaryen.so\n-rw-r--r-- 1 rjw57 rjw57  215228 Mar 15 22:10 libemscripten-optimizer.a\n-rw-r--r-- 1 rjw57 rjw57 4054642 Mar 15 22:10 libpasses.a\n-rw-r--r-- 1 rjw57 rjw57   98764 Mar 15 22:10 libsupport.a\n-rw-r--r-- 1 rjw57 rjw57  805028 Mar 15 22:10 libwasm.a\nThis is consistent with the way CMake seems to like to do things BTW.. > Adding each of those to the given command would solve the problem\nI'm not sure that's true since all of the mentioned libraries are linked into libbinaryen.a via CMakeLists.txt:140\nTARGET_LINK_LIBRARIES(binaryen ${all_passes} wasm asmjs ast support)\nBut I confess I'm not sure off the top of my head if this will cause all the objects in libwasm et al to be linked into libbinaryen.a.. > Weird\nWeird indeed. Is this Linux or OS X? My static binaries are a lot larger when compiled with BUILD_STATIC_LIB=ON and no other configuration.\n$ ls -l lib/\ntotal 5860\n-rw-r--r-- 1 rjw57 rjw57   37098 Mar 15 22:23 libasmjs.a\n-rw-r--r-- 1 rjw57 rjw57   98126 Mar 15 22:23 libast.a\n-rw-r--r-- 1 rjw57 rjw57  677130 Mar 15 22:23 libbinaryen.a\n-rw-r--r-- 1 rjw57 rjw57  215228 Mar 15 22:23 libemscripten-optimizer.a\n-rw-r--r-- 1 rjw57 rjw57 4054642 Mar 15 22:23 libpasses.a\n-rw-r--r-- 1 rjw57 rjw57   98764 Mar 15 22:23 libsupport.a\n-rw-r--r-- 1 rjw57 rjw57  805028 Mar 15 22:23 libwasm.a. Here's a full fresh build log:\n```\nrjw57@thor:binaryen (master)\n$ git show-ref master\na407b989ecc0c57ed4862ceaaa25acb0a41af63c refs/heads/master\na407b989ecc0c57ed4862ceaaa25acb0a41af63c refs/remotes/origin/master\nrjw57@thor:binaryen (master)\n$ mkdir build; cd build; cmake -DBUILD_STATIC_LIB=ON ..; make -j2 2>&1 >/dev/null\n-- The C compiler identification is GNU 6.2.0\n-- The CXX compiler identification is GNU 6.2.0\n-- Check for working C compiler: /usr/bin/cc\n-- Check for working C compiler: /usr/bin/cc -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Check for working CXX compiler: /usr/bin/c++\n-- Check for working CXX compiler: /usr/bin/c++ -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- No build type selected, default to Release\n-- Looking for pthread.h\n-- Looking for pthread.h - found\n-- Looking for pthread_create\n-- Looking for pthread_create - not found\n-- Check if compiler accepts -pthread\n-- Check if compiler accepts -pthread - yes\n-- Found Threads: TRUE\n-- Building with -std=c++11\n-- Building with -msse2\n-- Building with -mfpmath=sse\n-- Building with -Wall\n-- Building with -Werror\n-- Building with -Wextra\n-- Building with -Wno-unused-parameter\n-- Building with -fno-omit-frame-pointer\n-- Building with -fPIC\n-- Building with -O2\n-- Building with -UNDEBUG\n-- Configuring done\n-- Generating done\n-- Build files have been written to: /home/rjw57/projects/binaryen/build\nrjw57@thor:build (master)\n$ cat >test.cpp\n// test.cpp\n// compile with: g++ test.cpp -Llib -Isrc -lbinaryen\ninclude \"src/binaryen-c.h\"\nint main() {\n        return BinaryenNone();\n}\nrjw57@thor:build (master)\n$  g++ test.cpp -Llib -I../ -lbinaryen -lwasm -last -lasmjs -lsupport -lpasses -pthread && ./a.out && echo $?\nlib/libpasses.a(RemoveUnusedBrs.cpp.o): In function wasm::RemoveUnusedBrs::doWalkFunction(wasm::Function*)::FinalOptimizer::visitBlock(wasm::Block*)':\nRemoveUnusedBrs.cpp:(.text._ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE[_ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE]+0x1bb): undefined reference towasm::ExpressionManipulator::spliceIntoBlock(wasm::Block, unsigned int, wasm::Expression)'\nRemoveUnusedBrs.cpp:(.text._ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE[_ZZN4wasm15RemoveUnusedBrs14doWalkFunctionEPNS_8FunctionEEN14FinalOptimizer10visitBlockEPNS_5BlockE]+0x4af): undefined reference to `wasm::ExpressionManipulator::spliceIntoBlock(wasm::Block, unsigned int, wasm::Expression)'\ncollect2: error: ld returned 1 exit status\nrjw57@thor:build (master)\n$ uname -a\nLinux thor 4.8.0-41-generic #44-Ubuntu SMP Fri Mar 3 15:27:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\n```. > I'm not sure either, and I thought it didn't add them to libbinaryen.a but I'm less experienced with cmake than you.\nI'm not entirely sure what happens in this case either so let's just assume one has to list all the various .a archives :).\n\nI did mean to say I was on osx and had updated the previous comment\n\nAh, perhaps that's the wrinkle.. No, indeed. It's a bit late to investigate more here but at least we've got it down to one undefined reference. I'll look a bit more later on since I want to get static linking to work so I can package some Python bindings nicely. (Static linking libbinaryen.a into a .so with the Python module makes things easier in this regard.). Yes, this fixes it for me too. Thanks, @pipcet. I'll just have to find a way to translate that magic into a form Python's C-module building stuff understands.. CMake has a handy \"OBJECT\" veriant of add_library() which might also be helpful: https://cmake.org/cmake/help/v3.0/command/add_library.html. Re-opening assuming people want to discuss @dschuff 's point. ",
    "alexreg": "Thanks for your prompt response.\nBecause a) they don't belong in places like /usr/local/bin/, since they are not executable, b) the Homebrew package manager complains about this.\nI would suggest they go in one of the .../share/ or .../libexec/ directories, personally. e.g. /usr/local/share. Yeah, I think so. Though I don't understand cmake very well either. In any case, I'm sure cmake is capable of doing this.... ",
    "liul8258": "@kripken Thank you for the reply. Will try it right now.. ",
    "winduptoy": "What about LLVM?. ",
    "mmha": "\n\nSorry, that was an oversight. I just registered.\n\n\nI think gcc requires the // fallthrough comment to be right before the next case label. I merely moved the comment out of the scope. Interestingly C++17's [[fallthrough]] and gcc's __attribute__ ((fallthrough)) can be put inside the scope.. \n\n",
    "phil-el": "Hi, /usr/src must be avoided, it's used for reference only. Also js as a name is way too generic, you are more likely to have conflict with other package with such name, can the content of /js go to share/binrayen?. ",
    "jirutka": "Agree. I don't know for what are these files inside src/js really used or useful.. > Please join the wasm group if you haven't already.\nDone.. Yes, it does.. >  Just to confirm, this doesn't remove any existing testing, and just adds one new test mode? (the others are refactored, but remain, and still run with the same tests?)\nYes, it does not remove any existing tests. I should make the refactoring as a separate commit to make it more clear, my fault.\n\nIt sounds like that new job is slower since it does more builds?\n\nYes, just not job, but build. One build may consists of multiple stages (there\u2019s just one called \u201ctest\u201d) and each stage may consists of multiple jobs (there are currently 10 jobs).\n\nDo you have a sense of how much?\n\nIt depends\u2026 Jobs which build binaryen on emulated architecture are very slow, takes around 30\u201340 minutes (as you can see here). Other jobs takes just about 5 minutes.\n\nIn particular I worry if it's close the timeout (15 minutes on travis, I think?) we might have failed jobs now and then.\n\nThis limit is applied to a single job, not build. There\u2019s no time limit for complete build. As I noted, I\u2019ve disabled tests in jobs running in emulation to not exceed the time limit.\nBTW Travis runs max. 5 jobs in parallel.\n\nLooks like 5 new builds, 3 of which take >30 minutes, but don't timeout, if I read that correctly?\n\nYup.. > Fully built binaries sounds potentially useful, cc @juj\nOkay, I\u2019ve added it to this PR.\nYou just need to replace secret: TODO with your encrypted personal GitHub token (use gem travis to encrypt it: travis encrypt YOUR_TOKEN). I recommend to create a separate GitHub account for this, because personal access tokens have too wide scope. Unfortunately Travis does not support any better authentication method for deployment to GitHub Releases.\nOnce you set up it and tag new release, Travis should automatically build and deploy a tar.gz archive with statically linked binaries for each architecture (x86_64, x86, aarch64, armhf, ppc64le) into Releases (it looks like this).. > maybe the binary building should be disabled for now, until we decide how to integrate it with our other stuff?\nWhat exactly do you mean? What other stuff?\n\nJust to not be wasteful\n\nJobs in the build stages are always run, that\u2019s intentional \u2013 I\u2019ve moved all builds on emulated architectures to the build stage. Their purpose it not just to create binaries for deployment, but also to check if binaryen actually can be built on the specific architecture.\nDeployments (creating tarball and deploying to GH Releases) are run only when you push tagged commit. \nIf you don\u2019t wanna set GH token for deploying yet, then you can comment out deploy: key or add condition: false  # disabled for now to on: key under deploy:.. @juj https://github.com/WebAssembly/binaryen/pull/1064#issuecomment-314088910:\n\nThough we do already have dedicated OSX, Linux and Windows hardware set up to continuously build, test\u2026\n\nBut only for x86_64, right? Then silly bugs like #1059 happens. This is the original motivation of this PR, to regularly build binaryen on different architectures (deploying static binaries is just a bonus), so I don\u2019t have to fix or disable Alpine\u2019s binaryen package for some architectures on upgrades. ;)\n@juj https://github.com/WebAssembly/binaryen/pull/1064#issuecomment-314088910:\n\n@jirutka : would you be the maintainer for this, or are you proposing that me or @kripken would take the ownership of maintaining?\n\nI can maintain it, that\u2019s not a problem. I know Travis CI very well.\n@dcodeIO https://github.com/WebAssembly/binaryen/pull/1064#issuecomment-314101778:\n\nOn Linux, more specifically on Travis trusty instances, precompiled binaries are incompatible with the respective system glibc/libstdc versions.\n\nThat\u2019s why it\u2019s useful to have fully static binaries (compiled with musl libc, as I did in this PR), these works on any Linux system, regardless of libc or kernel version (newer than 2.6).\n. Just don\u2019t forget to set GH token for deployment, see https://github.com/WebAssembly/binaryen/pull/1064#issuecomment-310790766.. > I think it would be good to configure that kind of thing in the generic CMakeLists.txt instead of in the Travis-specific configuration\u2026\nThat would be a bit more complicated, not just moving some configuration from .travis.yml to CMakeLists.txt. Most Linux distributions use GNU libc (glibc) which is not very suitable for static linking \u2013 the resulting binary is very big or it\u2019s not possible at all. Much better option (not just) for static linking is musl libc. However, this means additional build-time dependency you need to install (see https://www.musl-libc.org/download.html). \nI used alpine-chroot-install to run binaryen build inside Alpine environment (on Travis). Since Alpine uses musl libc, we also got opportunity to build statically linked binaries with musl for free (it\u2019s just about setting CFLAGS/CXXFLAGS).\nI\u2019m sorry, but I don\u2019t wanna invest more time to this, like hacking CMakeLists.txt to deal with musl libc on glibc systems.\n\n\u2026 since otherwise Travis will be testing a different build than is made by default\n\nNo, it does test both. I haven\u2019t changed/removed your existing test jobs, I\u2019ve just added additional jobs, so extended test coverage to extra architectures, another libc and also static builds. So I really don\u2019t understand your point.\nThe only problem is that other architectures are not fully tested, it only runs build, not test suite (I\u2019ve already explained the reasons in this PR), but it\u2019s definitely better than not testing them at all (the current state). It\u2019d be better to have real aarch64, armhf and ppc64le HW to run tests or at least more powerful x86_64 HW that can handle emulation overhead, but that\u2019s obviously not for free (there\u2019s no hosted CI offering non-x86_64 HW).. I also recommend to enable \u201cAuto cancel branch builds\u201d and \u201cAuto cancel pull request builds\u201d, to safe Travis resources and your time (waiting for PRs to be green). It can\u2019t be enabled via .travis.yml yet, so you have to enable it at https://travis-ci.org/WebAssembly/binaryen/settings. It\u2019s documented \u2192here; tl;dr:\n\nIf you are only interested in building the most recent commit on each branch you can use this new feature to automatically cancel older builds in the queue that are not yet running.\n\nThis is useful in situations like when contributors push multiple commits into pull request during short time period. You typically don\u2019t care about test results for intermediate commits, just for the HEAD. There\u2019s a limit for number of simultaneously running jobs, so it\u2019s not desirable letting run already superseded builds, when you need results for the latests state.. Aha, that\u2019s really confusing, but okay.. No, we didn\u2019t, I cannot check your token for you\u2026 Most likely you didn\u2019t select the scope public_repo when creating the token. So you have to go to https://github.com/settings/tokens, Edit the token and select scope public_repo.. After that you should restart the failed Deploy jobs in https://travis-ci.org/WebAssembly/binaryen/builds/267886933.. Yeah, this is already fixed.. OMG, am I really the only one here who understand how Travis works and your Travis configuration\u2026?!\nI\u2019ll send proper solution later, please don\u2019t merge this.. ~~And BTW I\u2019ve reduced built time for ubuntu jobs significantly by disabling sudo (i.e. switching to container infra), but someone has changed it back\u2026~~ (EDIT: Pardon, this wasn\u2019t in this project). > Sudo is still disabled (https://github.com/WebAssembly/binaryen/blob/master/.travis.yml#L1), and has been since the first time .travis.yml was checked in.\nPardon, you\u2019re right, this was in another project.. It\u2019s not just hacky, it doesn\u2019t make damn sense and breaks deployment of static binaries. To be honest it\u2019s hard to believe you that you\u2019ve actually read the Travis documentation.\nI\u2019m gonna open PR in few minutes.. Better solution (also with some unrelated fixes) is ready in #1173.. It (obviously) does not deploy for every commit on master, only for release tags. However, jobs in build stage are still run for every commit in master, mainly to verify build on non-x86 architectures and also to verify release build. It\u2019d be quite bad to find out that something is broken only after tagging new release\u2026. There\u2019s something wrong, Travis haven\u2019t started build for this PR. Now I\u2019m not sure if there\u2019s some bug that branches attribute in a job is applied to whole build or something else. I\u2019m gonna open another PR just to test it.. > We've already established that what is obvious to you, is not obvious to those of us who don't do build and distro packaging as a primary activity.\nThis has nothing in common with distro packaging, but purely with CI, actually very essential principle of CI\u2026\nAlso we don\u2019t need anything of this for Alpine packages, we build software ourselves in our build infra. This is just for you (Binaryen project), to increase coverage of your tests and as a bonus provide static binaries for your users which actually work on every Linux system (not like your existing glibc-based binaries, as someone else mentioned).\n\nI will refrain from pointing out the similarity of your hack in this PR to the one in mine.\n\nYou can, unfortunately I really end up with similar hack as you. \ud83d\ude3f But there are important differences: it does not disable building and deploying static binaries and it does not unnecessary run Alpine installation when not needed (exists as early as possible).\nThe problem is that Travis still does not support conditional jobs or stages; I thought that it\u2019s already supported, but I was wrong (I\u2019m using more CIs and it apparently started confusing me).. > Also, the delayed build may be related to https://www.traviscistatus.com/incidents/r0f4m54qp0tr\nAha, so maybe not-so-hackish solution will work\u2026 I\u2019ll test it once Travis is green again.. Okay, this PR is ready. Build jobs are still triggered, but finish after ~30 seconds. Unfortunately Travis currently does not offer any proper solution.. BTW is there some way how to cut the build time? Maybe omit some components, so at least some part would be built on emulated architectures?. > \u2026is there some use case you care more about than others?\nI don\u2019t know, I currently don\u2019t use Binaryen for anything. You\u2019d probably better know what components are more important for your users and takes more time to build.. What\u2019s the purpose of these version_* tags? They looks like redundant for me, so I\u2019ve intentionally excluded them and included only real release tags. Of course I can change it.. Aha, this is really very confusing\u2026 :man_facepalming:\nI recommend to use standard versioning scheme for binaryen releases following SemVer (binaryen provides C API, so it should also clearly communicate its stability and reflect (non)breaking changes in version number). This is typically prefixed with \u201cv\u201d for tags. And then create tags like emscripten-x.y.z, if you really need them.. I\u2019ve just updated the PR.. ",
    "mtrive": "It looks like OSX default stack size is 8MB too, so bumping it to 8MB on Windows would make sense.. ",
    "puzrin": "@kripken I've read all those wiki pages (very helpful) about wasm, standalone modules, llvm backend etc. Technically, if i write uint64_t * uint64_t in C source, it will be supported via asm2wasm. But wast will contain external function call to do multiplication. That will work with runtime only (not in standalone mode) and not fast. LLVM will generate native instruction. May be i did something wrong, or something was changed last week.\nAbout EMCC_WASM_BACKEND=1. As far as i've understoot from wiki article, i need to install manually latest llvm to make that work. So, since i had to do it, i installed binaryen too and used directly to understand technology better. My makefile still has 2 two ways to build wasm.\nAnd one more note, not sure where is proper place for report. Emsdk now hardcodes 256 pages minimal memory limit. When you manually create&pass Memory for standalone module, <4MB produces stange linking errors, difficult to understand how to fix.\nFinally, i have all compilation methods working and no problems. But may be sharing notes about my adventures will give you idea how to make live more easy for next novices. You can close this issue anytime, i don't pretend on anything.. > You can allow wasm traps, and then it will get rid of all that overhead\nAh, thanks, that's not obvious. Probably worth add this key at standalone page build command.\n\nAbout the 256 pages issue, I don't understand, do you have a testcase or steps to reproduce?\n\nSee this hack (commented out after switch to llvm). Without it creating new instance will throw error when Memory size is < 256 pages.\nI can prepare you standalone sample if you wish, but that should be 100% reproducible with any standalone module, assembled via emsdk.\nwast head after llvm:\nwast\n(module\n (import \"env\" \"memory\" (memory $0 1)) <===================== min requirement 1 page\n (table 0 anyfunc)\nwast head after emsdk:\nwast\n(module\n (import \"env\" \"memoryBase\" (global $memoryBase i32))\n (import \"env\" \"memory\" (memory $0 256)) <===================== min requirement 256 pages\n (import \"env\" \"table\" (table 0 anyfunc))\n (import \"env\" \"tableBase\" (global $tableBase i32))\n (global $STACKTOP (mut i32) (i32.const 0))\n (global $STACK_MAX (mut i32) (i32.const 0))\n. 1. C code, compiled by emsdk has (import \"env\" \"memory\" (memory $0 256)) inside.\n2. Webassembly spec says somewhere, that if imported Memory is less than initial memory value from module source, module instance creation should fail. Firefox and Chrome implement such behaviour.\nInitial memory size from wasm file become mandatory requirement for minimal Memory size on instance init in browser. I think, forcing 4MB minimal size in emsdk/emscripten for standalone modules is overkill. If i pass Memory manually, i know exactly what i do, and there should be no limit at all (or 1 page).\n. ",
    "H-Plus-Time": "Compiling a dummy executable probably is the clever way of doing it, since file is a fair bit more stable than uname. PR 978 is pretty much identical to the linked wabt implementation.. ",
    "winksaville": "On the WebAssembly module docs I see in the Global Section it says:\n\"The global section provides an internal definition of zero or more global variables.\"\nAnd in the Table section it also says:\n\"The table section contains zero or more definitions of distinct tables.\". So the rebased change is now passing the tests and based on the spec the intent of the change is reasonable. Are there other people we should specifically ask to \"review/comment\" on the PR and its intent? What more would you like me to do?. What do you think?. Is there some guidance on how a test is created?. Ping, I've responded to comments and added a test anything else I need to do?. I've found that wasm-link in the wabt tools performs the same function:\n\nwasm-link: simple linker for merging multiple wasm files.\n\nShould we consolidate the effort into just one tool?. I've created an account, https://www.w3.org/users/99047 and I've joined the WebAssembly community, thus I've signed the CLA.. I'll rebase, do you want me to push the rebased version?\nOn Wed, Apr 19, 2017 at 10:29 AM Alon Zakai notifications@github.com\nwrote:\n\nThanks! Ok, last issue is the failure on travis. I think that's just old\nbreakage we had. If you merge current master in to this branch, it should\nfix it.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/972#issuecomment-295356614,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA-hHIE69sE57m9x7EPUoHGWeXjWgFAUks5rxkRugaJpZM4M_8An\n.\n. I rebased locally and ran ./check.py and it appeared to work, there was a [ success! ] although some tests didn't run:\n```\nbinaryen method succeeded.\n..../home/wink/foss/emscripten/emcc -o a.wasm.js -s BINARYEN=1 /home/wink/prgs/binaryen/test/printf.c -Oz -s BINARYEN_METHOD=\"interpret-binary\" -s BINARYEN_TRAP_MODE=\"js\"\n     (no post)\n...... wasm\n     (no args)\nexecuting:  /usr/bin/node a.wasm.js\ntrying binaryen method: interpret-binary\nbinaryen method succeeded.\n\n[ success! ]\ncould not run vanilla LLVM from waterfall: Command '['/home/wink/prgs/binaryen/test/wasm-install/wasm-install/bin/clang', '-v']' returned non-zero exit status 127, looked for clang at /home/wink/prgs/binaryen/test/wasm-install/wasm-install/bin/clang\nno mozjs found (did not check native wasm support nor asm.js validation)\nno interpreter provided (did not test spec interpreter validation)\n`\nI then forced push to my fork:\ngit push --force origin fix-typo-in--finalize-table-base-short-name-to-ftb\n. Previously the `assert(curr->name.is())` was valid, but with the removal of the tests at lines 125 above it global memory and tables are optional.. A valid module may not have globals.. Removing and yes tests are needed, my current example was combing two separately compiled C modules, what I was thinking was taking the wast output of those and build a test mimicking the current tests, is that acceptable?. IIRC, this routine is being called anyway so this projection was necessary.. I don't know, but here in findImports:\n  void findImports() {\n    findImportsByBase(wasm, MEMORY_BASE, & {\n      memoryBaseGlobals.insert(name);\n    });\n    if (memoryBaseGlobals.size() == 0) {\n      Fatal() << \"no memory base was imported\";\n    }\n    findImportsByBase(wasm, TABLE_BASE, & {\n      tableBaseGlobals.insert(name);\n    });\n    if (tableBaseGlobals.size() == 0) {\n      Fatal() << \"no table base was imported\";\n    }\n  }\n``\nAs you can see in the code above, it assumes memoryBaseGlobals and tableBaseGlobals exist andFatal()'s if not. In my change I removed those two conditional calls toFatal()` and \"fixed\" a couple uses via name.is() tests. So my guess is that @kripken added the test in findImports because there is an assumption that they \"always\" exist somewhere.\nI'll try to find more information.. Here is what I found, wasm-merge manages the input files as an InputMergeable:\nstruct InputMergeable : public ExpressionStackWalker<InputMergeable, Visitor<InputMergeable>>, public Mergeable {\nWhich isA ExpressionStackWaker.\ntemplate<typename SubType, typename VisitorType = Visitor<SubType>>\nstruct ExpressionStackWalker : public PostWalker<SubType, VisitorType> {\nWhich isA PostWalker:\ntemplate<typename SubType, typename VisitorType = Visitor<SubType>>\nstruct PostWalker : public Walker<SubType, VisitorType> {\nWhich isA Walker\ntemplate<typename SubType, typename VisitorType>\nstruct Walker : public VisitorType {\nExpressionStackWalker, PostWalker & Walker are defined in wasm-traversal.h\nI modified findImports, removing the conitiionals:\nvoid findImports() {\n    findImportsByBase(wasm, MEMORY_BASE, [&](Name name) {\n      memoryBaseGlobals.insert(name);\n    });\n    //if (memoryBaseGlobals.size() == 0) {\n    //  Fatal() << \"no memory base was imported\";\n    //}\n    findImportsByBase(wasm, TABLE_BASE, [&](Name name) {\n      tableBaseGlobals.insert(name);\n    });\n    //if (tableBaseGlobals.size() == 0) {\n    //  Fatal() << \"no table base was imported\";\n    //}\n  }\nI then added a bunch of debug and when I execute wasm-merge on my test C files compiled with clang the stack trace is:\n```\n(gdb) bt\n0  0x00007f96fc888a10 in raise () from /usr/lib/libc.so.6\n1  0x00007f96fc88a13a in abort () from /usr/lib/libc.so.6\n2  0x00007f96fc881607 in __assert_fail_base () from /usr/lib/libc.so.6\n3  0x00007f96fc8816b2 in __assert_fail () from /usr/lib/libc.so.6\n4  0x000000000067d474 in InputMergeable::visitGetGlobal (this=0x7ffd5a2fc2f0, curr=0x1eeb4f8) at src/tools/wasm-merge.cpp:311\n5  0x000000000069f465 in wasm::Walker >::doVisitGetGlobal (self=0x7ffd5a2fc2f0, currp=0x1eeb150) at src/wasm-traversal.h:291\n6  0x000000000069814a in wasm::Walker >::walk (this=0x7ffd5a2fc2f0, root=@0x1eeb150: 0x1eeb4f8) at src/wasm-traversal.h:268\n7  0x000000000069328c in wasm::Walker >::walkTable (this=0x7ffd5a2fc2f0, table=0x1eeadd8) at src/wasm-traversal.h:194\n8  0x000000000068cb0a in wasm::Walker >::doWalkModule (this=0x7ffd5a2fc2f0, module=0x1eead60) at src/wasm-traversal.h:232\n9  0x00000000006864cc in wasm::Walker >::walkModule (this=0x7ffd5a2fc2f0, module=0x1eead60) at src/wasm-traversal.h:208\n10 0x000000000067e7e6 in InputMergeable::merge (this=0x7ffd5a2fc2f0) at src/tools/wasm-merge.cpp:429\n11 0x00000000006726cd in main (argc=7, argv=0x7ffd5a2fd058) at src/tools/wasm-merge.cpp:627\nThe key routine looks to be doWalkModule and it crashing in walkTable which is NOT conditionally.\n  // override this to provide custom functionality\n  void doWalkModule(Module module) {\n    // Dispatch statically through the SubType.\n    SubType self = static_cast(this);\n    for (auto& curr : module->functionTypes) {\n      self->visitFunctionType(curr.get());\n    }\n    for (auto& curr : module->imports) {\n      self->visitImport(curr.get());\n    }\n    for (auto& curr : module->exports) {\n      self->visitExport(curr.get());\n    }\n    for (auto& curr : module->globals) {\n      self->walkGlobal(curr.get());\n    }\n    for (auto& curr : module->functions) {\n      self->walkFunction(curr.get());\n    }\n    self->walkTable(&module->table);\n    self->walkMemory(&module->memory);\n  }\nIf you then look at the declaration for Table in src/wasm.h:\nclass Table {\npublic:\n  static const Address::address_t kPageSize = 1;\n  static const Index kMaxSize = Index(-1);\nstruct Segment {\n    Expression offset;\n    std::vector data;\n    Segment() {}\n    Segment(Expression offset) : offset(offset) {\n    }\n    Segment(Expression* offset, std::vector& init) : offset(offset) {\n      data.swap(init);\n    }\n  };\n// Currently the wasm object always 'has' one Table. It 'exists' if it has been defined or imported.\n  // The table can exist but be empty and have no defined initial or max size.\n  bool exists;\n  bool imported;\n  Name name;\n  Address initial, max;\n  std::vector segments;\nTable() : exists(false), imported(false), initial(0), max(kMaxSize) {\n    name = Name::fromInt(0);\n  }\n};\n```\nIt says \"The table can exist but be empty and have no defined initial or max size.\". Thus it seems code is not handling the \"empty\" case properly. I'm not sure if that should be handled by the traversal code such as doWalkModule or the \"visitGetGlobal\" routines. Someone with more familiarity with the code will need to decide. NOTE: I'm a total neophyte with the code base and very likely wrong, so take this all with a huge grain of salt.\n. ",
    "cretz": "Thanks. Closing.\nI am essentially building the syscalls the emscripten-compiled wasm calls out to, e.g. here where I do writev. But I see now w/ the standalone is a much better target for this.. ",
    "sbalko": "Interestingly, the corresponding asm.js file does indeed have two copies of _memcpy, which are however different. One looks like a compiled one:\nfunction _memcpy($0,$1,$2) {\n $0 = $0|0;\n $1 = $1|0;\n $2 = $2|0;\n var $$0196$lcssa = 0, $$0196255 = 0, $$0199$lcssa = 0, $$0199254 = 0, $$0212$lcssa = 0, $$0212253 = 0, $$0229 = 0, $$10 = 0, $$10209 = 0, $$11 = 0, $$11210 = 0, $$1197$lcssa = 0, $$1197223 = 0, $$12 = 0, $$1200$lcssa = 0, $$1200222 = 0, $$1213$lcssa = 0, $$1213221 = 0, $$12211 = 0, $$1238 = 0;\n var $$2198 = 0, $$2201 = 0, $$2214226 = 0, $$2247 = 0, $$3 = 0, $$3202 = 0, $$3215235 = 0, $$4 = 0, $$4203 = 0, $$4216244 = 0, $$5204227 = 0, $$5217 = 0, $$5228 = 0, $$6205236 = 0, $$6237 = 0, $$7206245 = 0, $$7246 = 0, $$8 = 0, $$8207 = 0, $$9 = 0;\n var $$9208 = 0, $10 = 0, $100 = 0, $101 = 0, $102 = 0, $103 = 0, $104 = 0, $105 = 0, $106 = 0, $107 = 0, $108 = 0, $109 = 0, $11 = 0, $110 = 0, $111 = 0, $112 = 0, $113 = 0, $114 = 0, $115 = 0, $116 = 0;\n var $117 = 0, $118 = 0, $119 = 0, $12 = 0, $120 = 0, $121 = 0, $122 = 0, $123 = 0, $124 = 0, $125 = 0, $126 = 0, $127 = 0, $128 = 0, $129 = 0, $13 = 0, $130 = 0, $131 = 0, $132 = 0, $133 = 0, $134 = 0;\n var $135 = 0, $136 = 0, $137 = 0, $138 = 0, $139 = 0, $14 = 0, $140 = 0, $141 = 0, $142 = 0, $143 = 0, $144 = 0, $145 = 0, $146 = 0, $147 = 0, $148 = 0, $149 = 0, $15 = 0, $150 = 0, $151 = 0, $152 = 0;\n var $153 = 0, $154 = 0, $155 = 0, $156 = 0, $157 = 0, $158 = 0, $159 = 0, $16 = 0, $160 = 0, $161 = 0, $162 = 0, $163 = 0, $164 = 0, $165 = 0, $166 = 0, $167 = 0, $168 = 0, $169 = 0, $17 = 0, $170 = 0;\n var $171 = 0, $172 = 0, $173 = 0, $174 = 0, $175 = 0, $176 = 0, $177 = 0, $178 = 0, $179 = 0, $18 = 0, $180 = 0, $181 = 0, $182 = 0, $183 = 0, $184 = 0, $185 = 0, $186 = 0, $187 = 0, $188 = 0, $189 = 0;\n var $19 = 0, $190 = 0, $191 = 0, $192 = 0, $193 = 0, $194 = 0, $195 = 0, $196 = 0, $197 = 0, $198 = 0, $199 = 0, $20 = 0, $200 = 0, $201 = 0, $202 = 0, $203 = 0, $204 = 0, $205 = 0, $206 = 0, $207 = 0;\n var $208 = 0, $209 = 0, $21 = 0, $210 = 0, $211 = 0, $212 = 0, $213 = 0, $214 = 0, $215 = 0, $216 = 0, $217 = 0, $218 = 0, $219 = 0, $22 = 0, $220 = 0, $221 = 0, $222 = 0, $223 = 0, $224 = 0, $225 = 0;\n var $226 = 0, $227 = 0, $228 = 0, $229 = 0, $23 = 0, $230 = 0, $231 = 0, $232 = 0, $233 = 0, $234 = 0, $235 = 0, $236 = 0, $237 = 0, $238 = 0, $239 = 0, $24 = 0, $240 = 0, $241 = 0, $242 = 0, $243 = 0;\n var $244 = 0, $245 = 0, $246 = 0, $247 = 0, $248 = 0, $249 = 0, $25 = 0, $250 = 0, $251 = 0, $252 = 0, $253 = 0, $254 = 0, $255 = 0, $256 = 0, $257 = 0, $258 = 0, $259 = 0, $26 = 0, $260 = 0, $261 = 0;\n var $262 = 0, $263 = 0, $264 = 0, $265 = 0, $266 = 0, $267 = 0, $268 = 0, $269 = 0, $27 = 0, $270 = 0, $271 = 0, $272 = 0, $273 = 0, $274 = 0, $275 = 0, $276 = 0, $277 = 0, $278 = 0, $279 = 0, $28 = 0;\n var $280 = 0, $281 = 0, $282 = 0, $283 = 0, $284 = 0, $285 = 0, $286 = 0, $287 = 0, $29 = 0, $3 = 0, $30 = 0, $31 = 0, $32 = 0, $33 = 0, $34 = 0, $35 = 0, $36 = 0, $37 = 0, $38 = 0, $39 = 0;\n var $4 = 0, $40 = 0, $41 = 0, $42 = 0, $43 = 0, $44 = 0, $45 = 0, $46 = 0, $47 = 0, $48 = 0, $49 = 0, $5 = 0, $50 = 0, $51 = 0, $52 = 0, $53 = 0, $54 = 0, $55 = 0, $56 = 0, $57 = 0;\n var $58 = 0, $59 = 0, $6 = 0, $60 = 0, $61 = 0, $62 = 0, $63 = 0, $64 = 0, $65 = 0, $66 = 0, $67 = 0, $68 = 0, $69 = 0, $7 = 0, $70 = 0, $71 = 0, $72 = 0, $73 = 0, $74 = 0, $75 = 0;\n var $76 = 0, $77 = 0, $78 = 0, $79 = 0, $8 = 0, $80 = 0, $81 = 0, $82 = 0, $83 = 0, $84 = 0, $85 = 0, $86 = 0, $87 = 0, $88 = 0, $89 = 0, $9 = 0, $90 = 0, $91 = 0, $92 = 0, $93 = 0;\n var $94 = 0, $95 = 0, $96 = 0, $97 = 0, $98 = 0, $99 = 0, $scevgep = 0, $scevgep278 = 0, $scevgep279 = 0, $scevgep280 = 0, $scevgep281 = 0, $scevgep282 = 0, $scevgep283 = 0, $scevgep284 = 0, $trunc = 0, $trunc$clear = 0, label = 0, sp = 0, sp_a = 0;\n sp = STACKTOP;\n $3 = $1;\n $4 = $3 & 3;\n $5 = ($4|0)!=(0);\n $6 = ($2|0)!=(0);\n $7 = $6 & $5;\n if ($7) {\n  $$0196255 = $1;$$0199254 = $0;$$0212253 = $2;\n  while(1) {\n   $8 = ((($$0196255)) + 1|0);\n   $9 = load1($$0196255);\n   $10 = ((($$0199254)) + 1|0);\n   store1($$0199254,$9);\n   $11 = (($$0212253) + -1)|0;\n   $12 = $8;\n   $13 = $12 & 3;\n   $14 = ($13|0)!=(0);\n   $15 = ($11|0)!=(0);\n   $16 = $15 & $14;\n   if ($16) {\n    $$0196255 = $8;$$0199254 = $10;$$0212253 = $11;\n   } else {\n    $$0196$lcssa = $8;$$0199$lcssa = $10;$$0212$lcssa = $11;\n    break;\n   }\n  }\n } else {\n  $$0196$lcssa = $1;$$0199$lcssa = $0;$$0212$lcssa = $2;\n }\n $17 = $$0199$lcssa;\n $18 = $17 & 3;\n $19 = ($18|0)==(0);\n if ($19) {\n  $20 = ($$0212$lcssa>>>0)>(15);\n  if ($20) {\n   $21 = (($$0212$lcssa) + -16)|0;\n   $22 = $21 & -16;\n   $23 = (($22) + 16)|0;\n   $scevgep278 = (($$0199$lcssa) + ($23)|0);\n   $$1197223 = $$0196$lcssa;$$1200222 = $$0199$lcssa;$$1213221 = $$0212$lcssa;\n   while(1) {\n    $24 = load4($$1197223);\n    store4($$1200222,$24);\n    $25 = ((($$1197223)) + 4|0);\n    $26 = load4($25);\n    $27 = ((($$1200222)) + 4|0);\n    store4($27,$26);\n    $28 = ((($$1197223)) + 8|0);\n    $29 = load4($28);\n    $30 = ((($$1200222)) + 8|0);\n    store4($30,$29);\n    $31 = ((($$1197223)) + 12|0);\n    $32 = load4($31);\n    $33 = ((($$1200222)) + 12|0);\n    store4($33,$32);\n    $34 = ((($$1197223)) + 16|0);\n    $35 = ((($$1200222)) + 16|0);\n    $36 = (($$1213221) + -16)|0;\n    $37 = ($36>>>0)>(15);\n    if ($37) {\n     $$1197223 = $34;$$1200222 = $35;$$1213221 = $36;\n    } else {\n     break;\n    }\n   }\n   $scevgep = (($$0196$lcssa) + ($23)|0);\n   $38 = (($21) - ($22))|0;\n   $$1197$lcssa = $scevgep;$$1200$lcssa = $scevgep278;$$1213$lcssa = $38;\n  } else {\n   $$1197$lcssa = $$0196$lcssa;$$1200$lcssa = $$0199$lcssa;$$1213$lcssa = $$0212$lcssa;\n  }\n  $39 = $$1213$lcssa & 8;\n  $40 = ($39|0)==(0);\n  if ($40) {\n   $$2198 = $$1197$lcssa;$$2201 = $$1200$lcssa;\n  } else {\n   $41 = load4($$1197$lcssa);\n   store4($$1200$lcssa,$41);\n   $42 = ((($$1197$lcssa)) + 4|0);\n   $43 = load4($42);\n   $44 = ((($$1200$lcssa)) + 4|0);\n   store4($44,$43);\n   $45 = ((($$1200$lcssa)) + 8|0);\n   $46 = ((($$1197$lcssa)) + 8|0);\n   $$2198 = $46;$$2201 = $45;\n  }\n  $47 = $$1213$lcssa & 4;\n  $48 = ($47|0)==(0);\n  if ($48) {\n   $$3 = $$2198;$$3202 = $$2201;\n  } else {\n   $49 = load4($$2198);\n   store4($$2201,$49);\n   $50 = ((($$2201)) + 4|0);\n   $51 = ((($$2198)) + 4|0);\n   $$3 = $51;$$3202 = $50;\n  }\n  $52 = $$1213$lcssa & 2;\n  $53 = ($52|0)==(0);\n  if ($53) {\n   $$4 = $$3;$$4203 = $$3202;\n  } else {\n   $54 = ((($$3)) + 1|0);\n   $55 = load1($$3);\n   $56 = ((($$3202)) + 1|0);\n   store1($$3202,$55);\n   $57 = ((($$3)) + 2|0);\n   $58 = load1($54);\n   $59 = ((($$3202)) + 2|0);\n   store1($56,$58);\n   $$4 = $57;$$4203 = $59;\n  }\n  $60 = $$1213$lcssa & 1;\n  $61 = ($60|0)==(0);\n  if ($61) {\n   return ($0|0);\n  }\n  $62 = load1($$4);\n  store1($$4203,$62);\n  return ($0|0);\n }\n $63 = ($$0212$lcssa>>>0)>(31);\n L27: do {\n  if ($63) {\n   $trunc = $17&255;\n   $trunc$clear = $trunc & 3;\n   switch ($trunc$clear<<24>>24) {\n   case 1:  {\n    $64 = load4($$0196$lcssa);\n    $65 = ((($$0196$lcssa)) + 1|0);\n    $66 = $64&255;\n    $67 = ((($$0199$lcssa)) + 1|0);\n    store1($$0199$lcssa,$66);\n    $68 = ((($$0196$lcssa)) + 2|0);\n    $69 = load1($65);\n    $70 = ((($$0199$lcssa)) + 2|0);\n    store1($67,$69);\n    $71 = ((($$0196$lcssa)) + 3|0);\n    $72 = load1($68);\n    $73 = ((($$0199$lcssa)) + 3|0);\n    store1($70,$72);\n    $74 = (($$0212$lcssa) + -3)|0;\n    $75 = ($74>>>0)>(16);\n    if (!($75)) {\n     $$5217 = $74;$$8 = $71;$$8207 = $73;\n     break L27;\n    }\n    $76 = (($$0212$lcssa) + -20)|0;\n    $77 = $76 & -16;\n    $78 = (($77) + 19)|0;\n    $scevgep279 = (($$0196$lcssa) + ($78)|0);\n    $79 = (($$0212$lcssa) + -19)|0;\n    $$0229 = $64;$$2214226 = $74;$$5204227 = $73;$$5228 = $71;\n    while(1) {\n     $80 = ((($$5228)) + 1|0);\n     $81 = load4($80);\n     $82 = $$0229 >>> 24;\n     $83 = $81 << 8;\n     $84 = $83 | $82;\n     store4($$5204227,$84);\n     $85 = ((($$5228)) + 5|0);\n     $86 = load4($85);\n     $87 = $81 >>> 24;\n     $88 = $86 << 8;\n     $89 = $88 | $87;\n     $90 = ((($$5204227)) + 4|0);\n     store4($90,$89);\n     $91 = ((($$5228)) + 9|0);\n     $92 = load4($91);\n     $93 = $86 >>> 24;\n     $94 = $92 << 8;\n     $95 = $94 | $93;\n     $96 = ((($$5204227)) + 8|0);\n     store4($96,$95);\n     $97 = ((($$5228)) + 13|0);\n     $98 = load4($97);\n     $99 = $92 >>> 24;\n     $100 = $98 << 8;\n     $101 = $100 | $99;\n     $102 = ((($$5204227)) + 12|0);\n     store4($102,$101);\n     $103 = ((($$5228)) + 16|0);\n     $104 = ((($$5204227)) + 16|0);\n     $105 = (($$2214226) + -16)|0;\n     $106 = ($105>>>0)>(16);\n     if ($106) {\n      $$0229 = $98;$$2214226 = $105;$$5204227 = $104;$$5228 = $103;\n     } else {\n      break;\n     }\n    }\n    $scevgep280 = (($$0199$lcssa) + ($78)|0);\n    $184 = (($79) - ($77))|0;\n    $$5217 = $184;$$8 = $scevgep279;$$8207 = $scevgep280;\n    break L27;\n    break;\n   }\n   case 2:  {\n    $107 = load4($$0196$lcssa);\n    $108 = ((($$0196$lcssa)) + 1|0);\n    $109 = $107&255;\n    $110 = ((($$0199$lcssa)) + 1|0);\n    store1($$0199$lcssa,$109);\n    $111 = ((($$0196$lcssa)) + 2|0);\n    $112 = load1($108);\n    $113 = ((($$0199$lcssa)) + 2|0);\n    store1($110,$112);\n    $114 = (($$0212$lcssa) + -2)|0;\n    $115 = ($114>>>0)>(17);\n    if (!($115)) {\n     $$5217 = $114;$$8 = $111;$$8207 = $113;\n     break L27;\n    }\n    $116 = (($$0212$lcssa) + -20)|0;\n    $117 = $116 & -16;\n    $118 = (($117) + 18)|0;\n    $scevgep281 = (($$0196$lcssa) + ($118)|0);\n    $119 = (($$0212$lcssa) + -18)|0;\n    $$1238 = $107;$$3215235 = $114;$$6205236 = $113;$$6237 = $111;\n    while(1) {\n     $120 = ((($$6237)) + 2|0);\n     $121 = load4($120);\n     $122 = $$1238 >>> 16;\n     $123 = $121 << 16;\n     $124 = $123 | $122;\n     store4($$6205236,$124);\n     $125 = ((($$6237)) + 6|0);\n     $126 = load4($125);\n     $127 = $121 >>> 16;\n     $128 = $126 << 16;\n     $129 = $128 | $127;\n     $130 = ((($$6205236)) + 4|0);\n     store4($130,$129);\n     $131 = ((($$6237)) + 10|0);\n     $132 = load4($131);\n     $133 = $126 >>> 16;\n     $134 = $132 << 16;\n     $135 = $134 | $133;\n     $136 = ((($$6205236)) + 8|0);\n     store4($136,$135);\n     $137 = ((($$6237)) + 14|0);\n     $138 = load4($137);\n     $139 = $132 >>> 16;\n     $140 = $138 << 16;\n     $141 = $140 | $139;\n     $142 = ((($$6205236)) + 12|0);\n     store4($142,$141);\n     $143 = ((($$6237)) + 16|0);\n     $144 = ((($$6205236)) + 16|0);\n     $145 = (($$3215235) + -16)|0;\n     $146 = ($145>>>0)>(17);\n     if ($146) {\n      $$1238 = $138;$$3215235 = $145;$$6205236 = $144;$$6237 = $143;\n     } else {\n      break;\n     }\n    }\n    $scevgep282 = (($$0199$lcssa) + ($118)|0);\n    $185 = (($119) - ($117))|0;\n    $$5217 = $185;$$8 = $scevgep281;$$8207 = $scevgep282;\n    break L27;\n    break;\n   }\n   case 3:  {\n    $147 = load4($$0196$lcssa);\n    $148 = ((($$0196$lcssa)) + 1|0);\n    $149 = $147&255;\n    $150 = ((($$0199$lcssa)) + 1|0);\n    store1($$0199$lcssa,$149);\n    $151 = (($$0212$lcssa) + -1)|0;\n    $152 = ($151>>>0)>(18);\n    if (!($152)) {\n     $$5217 = $151;$$8 = $148;$$8207 = $150;\n     break L27;\n    }\n    $153 = (($$0212$lcssa) + -20)|0;\n    $154 = $153 & -16;\n    $155 = (($154) + 17)|0;\n    $scevgep283 = (($$0196$lcssa) + ($155)|0);\n    $156 = (($$0212$lcssa) + -17)|0;\n    $$2247 = $147;$$4216244 = $151;$$7206245 = $150;$$7246 = $148;\n    while(1) {\n     $157 = ((($$7246)) + 3|0);\n     $158 = load4($157);\n     $159 = $$2247 >>> 8;\n     $160 = $158 << 24;\n     $161 = $160 | $159;\n     store4($$7206245,$161);\n     $162 = ((($$7246)) + 7|0);\n     $163 = load4($162);\n     $164 = $158 >>> 8;\n     $165 = $163 << 24;\n     $166 = $165 | $164;\n     $167 = ((($$7206245)) + 4|0);\n     store4($167,$166);\n     $168 = ((($$7246)) + 11|0);\n     $169 = load4($168);\n     $170 = $163 >>> 8;\n     $171 = $169 << 24;\n     $172 = $171 | $170;\n     $173 = ((($$7206245)) + 8|0);\n     store4($173,$172);\n     $174 = ((($$7246)) + 15|0);\n     $175 = load4($174);\n     $176 = $169 >>> 8;\n     $177 = $175 << 24;\n     $178 = $177 | $176;\n     $179 = ((($$7206245)) + 12|0);\n     store4($179,$178);\n     $180 = ((($$7246)) + 16|0);\n     $181 = ((($$7206245)) + 16|0);\n     $182 = (($$4216244) + -16)|0;\n     $183 = ($182>>>0)>(18);\n     if ($183) {\n      $$2247 = $175;$$4216244 = $182;$$7206245 = $181;$$7246 = $180;\n     } else {\n      break;\n     }\n    }\n    $scevgep284 = (($$0199$lcssa) + ($155)|0);\n    $186 = (($156) - ($154))|0;\n    $$5217 = $186;$$8 = $scevgep283;$$8207 = $scevgep284;\n    break L27;\n    break;\n   }\n   default: {\n    $$5217 = $$0212$lcssa;$$8 = $$0196$lcssa;$$8207 = $$0199$lcssa;\n    break L27;\n   }\n   }\n  } else {\n   $$5217 = $$0212$lcssa;$$8 = $$0196$lcssa;$$8207 = $$0199$lcssa;\n  }\n } while(0);\n $187 = $$5217 & 16;\n $188 = ($187|0)==(0);\n if ($188) {\n  $$9 = $$8;$$9208 = $$8207;\n } else {\n  $189 = ((($$8)) + 1|0);\n  $190 = load1($$8);\n  $191 = ((($$8207)) + 1|0);\n  store1($$8207,$190);\n  $192 = ((($$8)) + 2|0);\n  $193 = load1($189);\n  $194 = ((($$8207)) + 2|0);\n  store1($191,$193);\n  $195 = ((($$8)) + 3|0);\n  $196 = load1($192);\n  $197 = ((($$8207)) + 3|0);\n  store1($194,$196);\n  $198 = ((($$8)) + 4|0);\n  $199 = load1($195);\n  $200 = ((($$8207)) + 4|0);\n  store1($197,$199);\n  $201 = ((($$8)) + 5|0);\n  $202 = load1($198);\n  $203 = ((($$8207)) + 5|0);\n  store1($200,$202);\n  $204 = ((($$8)) + 6|0);\n  $205 = load1($201);\n  $206 = ((($$8207)) + 6|0);\n  store1($203,$205);\n  $207 = ((($$8)) + 7|0);\n  $208 = load1($204);\n  $209 = ((($$8207)) + 7|0);\n  store1($206,$208);\n  $210 = ((($$8)) + 8|0);\n  $211 = load1($207);\n  $212 = ((($$8207)) + 8|0);\n  store1($209,$211);\n  $213 = ((($$8)) + 9|0);\n  $214 = load1($210);\n  $215 = ((($$8207)) + 9|0);\n  store1($212,$214);\n  $216 = ((($$8)) + 10|0);\n  $217 = load1($213);\n  $218 = ((($$8207)) + 10|0);\n  store1($215,$217);\n  $219 = ((($$8)) + 11|0);\n  $220 = load1($216);\n  $221 = ((($$8207)) + 11|0);\n  store1($218,$220);\n  $222 = ((($$8)) + 12|0);\n  $223 = load1($219);\n  $224 = ((($$8207)) + 12|0);\n  store1($221,$223);\n  $225 = ((($$8)) + 13|0);\n  $226 = load1($222);\n  $227 = ((($$8207)) + 13|0);\n  store1($224,$226);\n  $228 = ((($$8)) + 14|0);\n  $229 = load1($225);\n  $230 = ((($$8207)) + 14|0);\n  store1($227,$229);\n  $231 = ((($$8)) + 15|0);\n  $232 = load1($228);\n  $233 = ((($$8207)) + 15|0);\n  store1($230,$232);\n  $234 = ((($$8)) + 16|0);\n  $235 = load1($231);\n  $236 = ((($$8207)) + 16|0);\n  store1($233,$235);\n  $$9 = $234;$$9208 = $236;\n }\n $237 = $$5217 & 8;\n $238 = ($237|0)==(0);\n if ($238) {\n  $$10 = $$9;$$10209 = $$9208;\n } else {\n  $239 = ((($$9)) + 1|0);\n  $240 = load1($$9);\n  $241 = ((($$9208)) + 1|0);\n  store1($$9208,$240);\n  $242 = ((($$9)) + 2|0);\n  $243 = load1($239);\n  $244 = ((($$9208)) + 2|0);\n  store1($241,$243);\n  $245 = ((($$9)) + 3|0);\n  $246 = load1($242);\n  $247 = ((($$9208)) + 3|0);\n  store1($244,$246);\n  $248 = ((($$9)) + 4|0);\n  $249 = load1($245);\n  $250 = ((($$9208)) + 4|0);\n  store1($247,$249);\n  $251 = ((($$9)) + 5|0);\n  $252 = load1($248);\n  $253 = ((($$9208)) + 5|0);\n  store1($250,$252);\n  $254 = ((($$9)) + 6|0);\n  $255 = load1($251);\n  $256 = ((($$9208)) + 6|0);\n  store1($253,$255);\n  $257 = ((($$9)) + 7|0);\n  $258 = load1($254);\n  $259 = ((($$9208)) + 7|0);\n  store1($256,$258);\n  $260 = ((($$9)) + 8|0);\n  $261 = load1($257);\n  $262 = ((($$9208)) + 8|0);\n  store1($259,$261);\n  $$10 = $260;$$10209 = $262;\n }\n $263 = $$5217 & 4;\n $264 = ($263|0)==(0);\n if ($264) {\n  $$11 = $$10;$$11210 = $$10209;\n } else {\n  $265 = ((($$10)) + 1|0);\n  $266 = load1($$10);\n  $267 = ((($$10209)) + 1|0);\n  store1($$10209,$266);\n  $268 = ((($$10)) + 2|0);\n  $269 = load1($265);\n  $270 = ((($$10209)) + 2|0);\n  store1($267,$269);\n  $271 = ((($$10)) + 3|0);\n  $272 = load1($268);\n  $273 = ((($$10209)) + 3|0);\n  store1($270,$272);\n  $274 = ((($$10)) + 4|0);\n  $275 = load1($271);\n  $276 = ((($$10209)) + 4|0);\n  store1($273,$275);\n  $$11 = $274;$$11210 = $276;\n }\n $277 = $$5217 & 2;\n $278 = ($277|0)==(0);\n if ($278) {\n  $$12 = $$11;$$12211 = $$11210;\n } else {\n  $279 = ((($$11)) + 1|0);\n  $280 = load1($$11);\n  $281 = ((($$11210)) + 1|0);\n  store1($$11210,$280);\n  $282 = ((($$11)) + 2|0);\n  $283 = load1($279);\n  $284 = ((($$11210)) + 2|0);\n  store1($281,$283);\n  $$12 = $282;$$12211 = $284;\n }\n $285 = $$5217 & 1;\n $286 = ($285|0)==(0);\n if ($286) {\n  return ($0|0);\n  return ($0|0);\n }\n $287 = load1($$12);\n store1($$12211,$287);\n return ($0|0);\n}\nWhereas the other seems to come from the emscripten runtime:\n```\nfunction _memcpy(dest, src, num) {\n    dest = dest|0; src = src|0; num = num|0;\n    var ret = 0;\n    var aligned_dest_end = 0;\n    var block_aligned_dest_end = 0;\n    var dest_end = 0;\n    // Test against a benchmarked cutoff limit for when HEAPU8.set() becomes faster to use.\n    if ((num|0) >=\n      8192\n    ) {\n      return _emscripten_memcpy_big(dest|0, src|0, num|0)|0;\n    }\nret = dest|0;\ndest_end = (dest + num)|0;\nif ((dest&3) == (src&3)) {\n  // The initial unaligned < 4-byte front.\n  while (dest & 3) {\n    if ((num|0) == 0) return ret|0;\n    HEAP8[((dest)>>0)]=((HEAP8[((src)>>0)])|0);\n    dest = (dest+1)|0;\n    src = (src+1)|0;\n    num = (num-1)|0;\n  }\n  aligned_dest_end = (dest_end & -4)|0;\n  block_aligned_dest_end = (aligned_dest_end - 64)|0;\n  while ((dest|0) <= (block_aligned_dest_end|0) ) {\n    HEAP32[((dest)>>2)]=((HEAP32[((src)>>2)])|0);\n    HEAP32[(((dest)+(4))>>2)]=((HEAP32[(((src)+(4))>>2)])|0);\n    HEAP32[(((dest)+(8))>>2)]=((HEAP32[(((src)+(8))>>2)])|0);\n    HEAP32[(((dest)+(12))>>2)]=((HEAP32[(((src)+(12))>>2)])|0);\n    HEAP32[(((dest)+(16))>>2)]=((HEAP32[(((src)+(16))>>2)])|0);\n    HEAP32[(((dest)+(20))>>2)]=((HEAP32[(((src)+(20))>>2)])|0);\n    HEAP32[(((dest)+(24))>>2)]=((HEAP32[(((src)+(24))>>2)])|0);\n    HEAP32[(((dest)+(28))>>2)]=((HEAP32[(((src)+(28))>>2)])|0);\n    HEAP32[(((dest)+(32))>>2)]=((HEAP32[(((src)+(32))>>2)])|0);\n    HEAP32[(((dest)+(36))>>2)]=((HEAP32[(((src)+(36))>>2)])|0);\n    HEAP32[(((dest)+(40))>>2)]=((HEAP32[(((src)+(40))>>2)])|0);\n    HEAP32[(((dest)+(44))>>2)]=((HEAP32[(((src)+(44))>>2)])|0);\n    HEAP32[(((dest)+(48))>>2)]=((HEAP32[(((src)+(48))>>2)])|0);\n    HEAP32[(((dest)+(52))>>2)]=((HEAP32[(((src)+(52))>>2)])|0);\n    HEAP32[(((dest)+(56))>>2)]=((HEAP32[(((src)+(56))>>2)])|0);\n    HEAP32[(((dest)+(60))>>2)]=((HEAP32[(((src)+(60))>>2)])|0);\n    dest = (dest+64)|0;\n    src = (src+64)|0;\n  }\n  while ((dest|0) < (aligned_dest_end|0) ) {\n    HEAP32[((dest)>>2)]=((HEAP32[((src)>>2)])|0);\n    dest = (dest+4)|0;\n    src = (src+4)|0;\n  }\n} else {\n  // In the unaligned copy case, unroll a bit as well.\n  aligned_dest_end = (dest_end - 4)|0;\n  while ((dest|0) < (aligned_dest_end|0) ) {\n    HEAP8[((dest)>>0)]=((HEAP8[((src)>>0)])|0);\n    HEAP8[(((dest)+(1))>>0)]=((HEAP8[(((src)+(1))>>0)])|0);\n    HEAP8[(((dest)+(2))>>0)]=((HEAP8[(((src)+(2))>>0)])|0);\n    HEAP8[(((dest)+(3))>>0)]=((HEAP8[(((src)+(3))>>0)])|0);\n    dest = (dest+4)|0;\n    src = (src+4)|0;\n  }\n}\n// The remaining unaligned < 4 byte tail.\nwhile ((dest|0) < (dest_end|0)) {\n  HEAP8[((dest)>>0)]=((HEAP8[((src)>>0)])|0);\n  dest = (dest+1)|0;\n  src = (src+1)|0;\n}\nreturn ret|0;\n\n}\n```\n. Nope, I basically hacked Binaryen to ignore the issue. The resulting wasm\nruns fine.\nOn Sat, Jun 3, 2017 at 1:22 AM, Jordan Scheller notifications@github.com\nwrote:\n\n@sbalko https://github.com/sbalko any luck resolving the issue? I am\nseeing the same failed assertion.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/980#issuecomment-305819569,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACGHM9siMGEvIe9P6T17pMWQKkn_e8ovks5sACi_gaJpZM4NHB4K\n.\n\n\n-- \nSoeren Balko\nDirector and CTO\nclipchamp.com\nsoeren@clipchamp.com\nAdd videos to your emails with the FREE Clipchamp plugin for Gmail\nhttps://chrome.google.com/webstore/detail/video-recorder-for-gmail/fjnhblbojcifepajihbcmanhlcbcipbh\n!\n. ",
    "jfizz": "@sbalko any luck resolving the issue? I am seeing the same failed assertion.. ",
    "joel-liu": "@sbalko I experienced the same issue. Could you share how you hacked binaryen to ignore the issue?\nThanks very much.. @kripken  Thanks very much! . ",
    "kanaka": "Okay, I'll look into adding a test.. I've updated the PRs with the new parameter names. I've also added a test here that makes sure the output is correct (no type mangling/legalizing) when the option is used.. That's fine with me. Do you want me to use a similar name for the emscripten and fastcomp options? \"legalize\" seemed a bit specific to binaryen so that's why I moved towards a more generic naming.. ",
    "jerstlouis": "http://www.cplusplus.com/reference/istream/istream/read/\n\"The number of characters successfully read and stored by this function can be accessed by calling member gcount.\". My approach to parsing text files that may or may not contain \\r is always to ignore \\r. Simpler that way. I would recommend doing the same and avoiding all these \"text\" mode caveats. Through I think gcount should still be used here.. Was just making it the same as the MSVC section. MinGW defaults to 2 MB I think.. Is it possible that it's not MinGW specific but also an issue when built with Visual Studio?. If the code already always handles skipping \\r and works on Linux which does not have a non-binary mode, then there's no reason why the file should be opened without the binary flag, and I can't see how it would work better on Visual Studio.\nThere's other reports of asm2wasm crashing, see for example: https://github.com/WebAssembly/binaryen/issues/327 which crashes at exactly the same spot.. Why are \\r even generated though? Are they only generated when done on Windows? It doesn't make sense to me to generate files meant to be used across platforms differently whether they're created on one platform or another. The 'text' mode and \\r\\n really needs to disappear anyway, it's such a horrible relic of the past.. Again opening as binary when outputting the asm.js will avoid those \\r's. This will be an issue trying to get reproducible output across systems. Really, the 'text' mode has no reason to be.. ",
    "dcodeIO": "It appears that this particular line originates from https://github.com/WebAssembly/binaryen/commit/c0f0be986d9009a05a3bbaf42c841b863d9b83c1\nbut is based upon https://github.com/WebAssembly/binaryen/commit/3fbae879fc1b678e748ab3f8c24148e1c3818f45#diff-d68568a2814906f8832b7d340fed1f62R1217 @jfbastien . This PR simply removes the explicit exportFunction call on the start function under the assumption that this doesn't cause any issues. Currently, it is exported (see), and kripken suggested to ping the original author of the line in question to make sure.. Sorry, this one has been gathering dust. Rebased on master and updated affected test cases.. Resolved by #1292. Just joined the group!. I know this is bad timing, but I already started work on these additional functions. I also wonder if there isn't an optimization pass already that joins duplicate function signatures / eliminates unused ones?. Unfortunately, even though I updated to emscripten-master-64bit, I am now seeing the __cxa_thread_atexit warning again when I run build-js.sh. Hence I wasn't able to update / test the binaries accordingly (I am probably just doing something wrong here).\nEdit: Seems I got it all wrong and just have to update incoming instead of switching to master, sec.... Rebased on master, updated the binaries and squashed the commits. Might be a good idea to recompile again once your changes to RemoveUnusedModuleElements have been merged.. Thanks! FYI: I published the recent JS build to npm under the binaryen name so I and others can easily depend on it from our packages. If you'd like to take this over and/or have an idea how we could automate publishing to npm, just drop me a note!. Going to try building on Travis CI, but I have no idea how this will turn out due to time limits. Repo: https://github.com/dcodeIO/binaryen.js. As far as I am concerned, this can be moved to wherever it fits best, of course. Provided that I get it to work, that is.. I believe one issue here is that building binaryen.js differs from the other build targets quite a bit in that it requires an up-to-date installation of the Emscripten SDK (including a compatible install of LLVM/clang etc.) to be present. Of course compilation can be done manually, but if we can automate that, we probably should.. Btw., it seems Travis is killing compilation because of memory exhaustion or something like that - as expected. One does not simply build LLVM/clang on Travis, I assume.. Now simply tried installing emscripten-incoming from sources while using a clang nightly. As the issues linked above already noted, this then fails with:\n/home/travis/build/dcodeIO/binaryen.js/emsdk-portable/clang/e1.37.13_64bit/llc: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by /home/travis/build/dcodeIO/binaryen.js/emsdk-portable/clang/e1.37.13_64bit/llc)\nI remember that I was able to fix that for another project by building with -static-libgcc. Not sure if -static-libstdc++ is required.. I believe I got it working now (once ccache is saturated, a build takes about 10 minutes). One issue I have, though, is that build-js.sh only generates warnings like warning: unresolved symbol: _ZN4wasm26createInstrumentLocalsPassEv instead of generating an error. This results in a situation where the build completes, but the final binaries are broken. @kripken Do you think this can be fixed in build-js.sh itself? If not, I'd try to build a wrapper around the build script that is looking for error-worthy output instead.\nFurther plans are to install a Travis cron job to build binaryen.js like once a day and publish it to npm under some special tag, like @next. Or, of course, merge the task into the main repository if that is preferred.\nEdit: Added a simple test case loading the compiled file and performing a few operations. That should catch obviously broken builds at least.. Documentation for the JS-API can be found at this location.\nIf I'm not mistaken, parsing text format isn't supported currently even though it could be, but the inverse is:\njs\nvar binaryen = require(\"binaryen\");\nvar myModule = binaryen.readBinary(input);\nvar wastString = myModule.emitText();. Hmm, it doesn't seem that the constructor accepts such an argument. On the JS side, a reference to an existing module (a pointer) can be passed in, though.. Is there a chance to support this on function / source code level, too? For example, I have a couple of builtins that I am currently declaring programmatically, but it would be super convenient to be able to use some sort of inline-assembly instead. More a nice-to-have, not super important, of course.\nCould be that it is already possible to emulate this somehow with this PR when using temporary modules. Iirc, there is already some debugging utility that does the inverse, i.e. converting a subset of statements or expressions to s-expr syntax. Not sure if that's exposed already, though.. Afaik the timeout on travis-ci.org is 50 minutes and trusty instances are limited to max. 4 gb ram, 2 cores, 20 gb of disk space. [1] [2]. For what it's worth: Emsdk's precompiled binaries haven't been of any use to me. On Windows, latest precompiled emscripten/clang is 1.37.9 from April or so, missing fixes to build recent binaryen.js for example. On Linux, more specifically on Travis trusty instances, precompiled binaries are incompatible with the respective system glibc/libstdc versions.\nAppreciating any improvements there.. Seems there is something broken in my emsdk then. For reference, this is the output on my side:\n```\nC:\\Program Files\\Emscripten>emsdk update\nC:\\Program Files\\Emscripten>\nC:\\Program Files\\Emscripten>emsdk update-tags\nFetching all tags from Emscripten Github repository...\nDone. 102 tagged releases available, latest is 1.37.15.\nFetching all tags from Binaryen Github repository...\nDone. 28 tagged Binaryen releases available, latest is 1.37.14.\nFetching all precompiled Nightly versions..\nDownloading: C:/Program Files/Emscripten/llvm-nightlies-32bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/nightly/win_32bit/index.txt\nDownloading: C:/Program Files/Emscripten/llvm-nightlies-64bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/nightly/win_64bit/index.txt\nDownloading: C:/Program Files/Emscripten/emscripten-nightlies.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/emscripten/nightly/win/index.txt\nFetching all precompiled tagged releases..\nDownloading: C:/Program Files/Emscripten/llvm-tags-32bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/tag/win_32bit/index.txt\nDownloading: C:/Program Files/Emscripten/llvm-tags-64bit.txt from https://s3.amazonaws.com/mozilla-games/emscripten/packages/llvm/tag/win_64bit/index.txt\nC:\\Program Files\\Emscripten>emsdk list\nThe following precompiled tool packages are available for download:\n           clang-nightly-e1.37.9-2017_04_19_23_39-64bit\n           clang-nightly-e1.37.9-2017_04_20_04_06-64bit\n           clang-e1.30.0-64bit\n           clang-e1.34.1-64bit\n           clang-e1.35.0-64bit\n           clang-e1.37.1-64bit\n           clang-e1.37.8-64bit\n           clang-e1.37.9-64bit\n           node-4.1.1-32bit\n    ()    node-4.1.1-64bit             INSTALLED\n           python-2.7.5.3-32bit\n    ()    python-2.7.5.3-64bit         INSTALLED\n           java-7.45-32bit\n    ()    java-7.45-64bit              INSTALLED\n           spidermonkey-37.0.1-64bit\n    ()    spidermonkey-nightly-2015-04-12-64bit        INSTALLED\n           git-1.9.4\n           emscripten-1.30.0\n           emscripten-1.34.1\n           emscripten-1.35.0\n           emscripten-1.37.1\n           emscripten-1.37.8\n           emscripten-1.37.9            INSTALLED\n           emscripten-nightly-1.37.9-2017_04_19_23_39\n           emscripten-nightly-1.37.9-2017_04_20_04_06\n           vs-tool-0.9.4                Not available: Visual Studio 2010 was not found!\n    (*)    crunch-1.03                  INSTALLED\n           gnu-2.5.4\n           mingw-4.6.2-32bit\nThe following tools can be compiled from source:\n           clang-tag-e1.37.14-32bit\n           clang-tag-e1.37.15-32bit\n           clang-tag-e1.37.14-64bit\n           clang-tag-e1.37.15-64bit\n           clang-incoming-32bit\n    ()    clang-incoming-64bit         INSTALLED\n           clang-master-32bit\n           clang-master-64bit           INSTALLED\n           emscripten-tag-1.37.14-32bit\n           emscripten-tag-1.37.15-32bit\n           emscripten-tag-1.37.14-64bit\n           emscripten-tag-1.37.15-64bit\n           binaryen-tag-1.37.13-32bit\n           binaryen-tag-1.37.14-32bit\n           binaryen-tag-1.37.13-64bit\n           binaryen-tag-1.37.14-64bit\n           emscripten-incoming-32bit\n           emscripten-master-32bit\n    ()    emscripten-incoming-64bit    INSTALLED\n           emscripten-master-64bit      INSTALLED\n           binaryen-master-32bit\n    (*)    binaryen-master-64bit        INSTALLED\nThe following precompiled SDKs are available for download: (Run \"./emsdk update\" to pull in the latest list)\n         sdk-nightly-1.37.9-2017_04_19_23_39-64bit\n         sdk-nightly-1.37.9-2017_04_20_04_06-64bit\n         sdk-1.30.0-64bit\n         sdk-1.34.1-64bit\n         sdk-1.35.0-64bit\n         sdk-1.37.1-64bit\n         sdk-1.37.8-64bit\n         sdk-1.37.9-64bit\nThe following SDKs can be compiled from source:\n         sdk-incoming-32bit\n    *    sdk-incoming-64bit             INSTALLED\n         sdk-master-32bit\n         sdk-master-64bit               INSTALLED\n         sdk-tag-1.37.14-32bit\n         sdk-tag-1.37.15-32bit\n         sdk-tag-1.37.14-64bit\n         sdk-tag-1.37.15-64bit\nItems marked with * are activated for the current user.\nItems marked with (*) are selected for use, but your current shell environment is not configured to use them. Type \"emsdk_env.bat\" to set up your current shell to use them, or call \"emsdk activate --global \" to permanently activate them.\nTo access the historical archived versions, type 'emsdk list --old'\nC:\\Program Files\\Emscripten>\n```\n\nDo you know if there exists documentation somewhere on how binaries should be built on Ubuntu to be compatible across different versions of Ubuntu? Or is this unfixable/unsupported and one needs to always build on the same Ubuntu version where one uses the binary?\n\nThere are compiler flags to link glibc (-static-libgcc) and libstdc++ (-static-libstdc++) statically as far as I know, with the latter being somewhat error prone [1] [2] [3].. As I am unable to run the tests locally because I am on Windows and the Travis build is also failing lately, things become a bit difficult here.\nI assume that 'mozjs' is just a recent Spidermonkey shell, is that correct? If so, the version I am running locally doesn't seem to provide a CommonJS environment like the initial comment in binaryen.js-post.js (that lead me to adding the additional line to check.py) stated (there's no module or require defined in my local js shell). If the latter assumption is correct, the additional line added to check.py wouldn't be necessary and it should \"just work\" without it (correctly resulting in this[\"Binaryen\"] = Module;, making Binaryen available globally already), but hard to tell without a way to test this. If you have a way to run the JS tests on top of this PR's current state, that should show if it is working without the additional line that I removed in my last commit.. Exposing globally alongside exporting as a module doesn't, in my experience, cause any practical problems usually and I am also fine with this approach for my specific use case.\nWhen there is a var Binaryen = (...)(), though, it'll always declare this variable, no matter the context (might be local, might be global) and no matter the return value of the closure (even when it returns nothing, there'll be a Binaryen var evaluating to undefined).\nHence, where avoiding a global is of importance for some reason, people came up with the (nowadays relatively standard) fallback in question that checks for global, window and this in this order. global is node-like and also catches other custom environments reliably (where window might be something else), window browser-like and this usually catches everything else like running within a web worker or the a.js use case we have here.\nNo matter how you decide, I'll happily change it to fit your needs.. Thanks, that makes sense. For what it's worth, this markdown file documents a second call function named just like the first, that's why I got it wrong (assumed this had been merged).. The emsdk repository might be a better place for emsdk related issues.. Would be quite useful in binaryen.js as well, i.e. as Module#emitAsm.. It seems that 9a18081 is the only commit with code changes in 1.37.18, and 1.37.17 is working. I used precompiled binaries locally.\n\nFor completeness, on my Travis setup,\nlatest working was 8dbe100 / log,\nfirst broken was ea1f866 / log,\nwhile 9a18081 is somewhere in between.. JS files have been compiled with 1.37.17 and should be fine (in reference of https://github.com/WebAssembly/binaryen/issues/1135).\nCan try to add a test - is test/binaryen.js the right place for it?\nLinking to https://github.com/WebAssembly/binaryen/issues/1141 (failures above might fall under \"finish wasm2asm translation of ops\" while the additional functions are separate).. Note, though, that this test case has been specifically crafted to show that emitAsmjs is basically working (with the getLocalNameOrGeneric change I made), while it actually doesn't do anything useful yet in more complex scenarios. For example\n\nusing a module.block as the body with an inner return or an i32 result obtained via getLocal fails\ncalling module.validate() afterwards fails because of the injected asm.js helpers\n.... Might also be useful for things that use Binaryen, but not LLVM.. I see. So, if you'd publish current binaryen.js to npm, what version number (A.B.C form) would you use? 0.0.37 ? 37.0.0 ? Something entirely different?. Well, currently the buildbot is using 1.37.20. Suggesting to change that to 37.0.0 and go with the version tag from now on. However, that'll pretty much prevent any future versioning changes, at least for this exact package. That's why I'm asking - don't want to mess this up.. Great, thanks!. Sure, can do that as well!. Alright, updated the PR accordingly.. Imho the respective tool (using the API) should provide printing of the entire module as an option, not the API itself where one function should do one thing. For instance, one could simply do\n\nif (!BinaryenModuleValidate(the_module))\n  BinaryenModulePrint(the_module);\nleading to the exact same output as before, while there is no way to print just the validation messages (which I am interested in) as it is atm. Just removing this line and leaving it up to the user to print the module contents where necessary also avoids adding more options (do env vars even work in JS?).. This commit should add explicit printing of the module to all places where it has been printed before but then wasn't due to the change.. I am a bit puzzled what's going on there. \nUnfortunately, I cannot run the waterfall tests on Windows because there are no such binaries (downloading waterfall 13645: https://storage.googleapis.com/wasm-llvm/builds/windows/13645/wasm-binaries-13645.tbz2 ... HTTP Error 404: Not Found).. Just checked: Local output is the same as shown on Travis.. Seems to produce the expected output if I do this, but I must admit that I do not understand why validate didn't print the module at this occasion before. Only accountable candidate I observed there is info.quiet being true, but I can't spot any flags being provided.. The latest commit will most likely break tests because of the addition of a tracing globals map similar to those used for expressions and functions. I also figured that some form of BinaryenExpressionPrecompute would be ideal for my use case (though I haven't yet understood how Flow works) and in turn would make some (but not all) of the additions nice-to-have but not immediately useful for me anymore.. Not sure about setting names, though. Is it necessary to update the respective lookup maps (i.e. Module#functionsMap) on name changes as well? These are indexed by Name, and the updates perform a Name#set.. The latest commit also changes BinaryenRemoveImport to BinaryenRemoveImportByName and BinaryenRemoveExport to BinaryenRemoveExportByName for clarity (there might be multiple ways to reference an export, not just by name but also by reference, in the future). While this probably won't be much of an issue (it's relatively new and I'm probably the only one who was ever using it), I also feel that changing this now is better than doing it later. Once updated, this can also become transparent to binaryen.js users.\nIn general, a clean solution would also require renaming all the methods that take a Module as their first argument to BinaryenModuleXY, with BinaryenRemoveImport becoming BinaryenModuleRemoveImportByName. Currently, both notations are used - sometimes with, sometimes without Module. Not immediately necessary, but might become an issue in the future, so mentioning.. Closing in favor of splitting this up into multiple PRs.. Hmm... while this now builds, c7e4ee2 should have errored on the binaryen.js/kitchen-sink.js test, which apparently isn't run anymore?. Turned out that one convention could be:\n\nUsing names in BinaryenAddSomething-style functions\nSomething-references in BinaryenSomethingAdd-style ones\n\nHence closing.. Note that BinaryenSetMemoryExport isn't ultimately necessary because there is BinaryenAddExport / BinaryenRemoveExport. However, there is no BinaryenHasExport yet, or any other way to determine the export name of the memory in order to check for a memory export, so I decided to include it for convenience.. Sure, could also update BinaryenAddExport / BinaryenRemoveExport / BinaryenAddImport / BinaryenRemoveImport accordingly plus introducing BinaryenHasExport / BinaryenHasImport. Depending on the external kind provided, these would then perform additional steps (i.e. updating wasm->memory for memories).. One issue I see is that different ExternalKinds currently require a different set of arguments. There is just one memory (for now), for example, so there is not really an internalName, while there is one for functions. That could be circumvented by creating one SetXYExport etc. for each ExternalKind, including their respective additional steps. Also, not everything can be exported atm (only Function (wwith internal name), Table and Memory (both without internal name)).. While introducing ExternalKind to the C-API with the intent to unify AddImport/AddExport, I noticed that BinaryenAddImport currently has the following signature:\nBinaryenImportRef BinaryenAddImport(\n  BinaryenModuleRef module,\n  const char* internalName,\n  const char* externalModuleName,\n  const char *externalBaseName,\n  BinaryenFunctionTypeRef type <---\n)\nThe last parameter is used for function types exclusively. Globals would need a different type parameter, namely their WasmType. Hence wondering if unifying, with some kind-dependent and otherwise irrelevant parameters (i.e. functionTypeIfApplicable, globalTypeIfApplicable), is really what we want. I'd still prefer one AddImport/AddExport function for each kind.\nHow would you design it?. Closing in favor of #1292. Might come back to the respective getters and setters later.. Not sure why the build shows as errored (besides that I didn't add a test because I don't remember how to re-generate the .txt fixtures). The different steps completed successfully.. Currently trying to regenerate the tests. On Windows, this results in .wast files using 0xD 0xD 0xA line endings (literally double 0xD), and it eventually terminates with\n[parse exception: inline string contains NULL (0). that is technically valid in wasm, but you shouldn't do it, and it's not supported in binaryen]Fatal: error in parsing input\nTraceback (most recent call last):\n  File \"auto_update_tests.py\", line 103, in <module>\n    actual += run_command(cmd)\n  File \"...\\binaryen\\scripts\\test\\support.py\", line 161, in run_command\n    raise Exception(('run_command failed (%s)' % code, out + str(err or '')))\nException: ('run_command failed (1)', '')\nwhich is thrown in wasm-binary.cpp:1399 after evaluating the characters (then followed by \\0)\nf\na\nc\n-\no\np\nt\n\u0005\n\u00f9\n\u00c7\n\u00c7\n\u00c7\nNot sure if that helps in any way, but I wasn't able to figure this out yet.. Sorry, had a bad start on this one. Should actually stick to the text format now and implement supported ops only.. Seems the AppVeyor build failed for a different reason.. Should be good to merge once the checks complete. I just recently merged master when I noticed that the other one landed. I believe the second still needs some review updates anyway.. Still thinking how to implement a BinaryenExpressionPrecompute function by reusing the precompute pass. That would be super useful.. Yeah, the reason is that the MVP does not allow more complex (for example binary) expressions as initializers of, let's say, globals and I am trying to avoid reimplementing precompute in my compiler. Hence, if I have a const global with an initializer like 1 << 2, I can't use it as is, but must instead make the global mutable and initialize it in the start function.\nBeing able to precompute just the initializer would solve this, while not affecting the entire module and not having to reinvent the wheel.. Sure, that would be one option. This will, however, not cover things like globalB = 1 + globalA.. Well, because globalA then doesn't exist in the empty module (edit: unless I add all of them, as you noted). Got something working now, though, will create a PR soon. Simply reuses precomputeValue of Precompute.. Btw. I also regenerated the js/kitchen-sink test in #1288 - in case something conflicts.. Just noticed: The C-API assumes that there is a memory, using name \"0\". Hence, Module#addMemoryImport works with \"0\" as the name only. Even when renaming utilities would be in place, the memory would have to be manually renamed from \"0\" to something else first.\nPossible not-so-nice solutions:\n\nJust document, for now\nAccept an additional internalName parameter in Module#setMemory, breaking the API\nDeprecate Module#setMemory in favor of a new Module#addMemory once multiple memories are supported, but not sure if that's even on the roadmap\n\nThe same goes for tables.. Sure, going to investigate. Now that there's BinaryenModuleRunPasses, something like BinaryenExpressionRunPasses and, maybe as a companion, BinaryenFunctionRunPasses could be even more general.\nMight need a way to set some options then, i.e. Precompute with propagate on/off for example.. Closing in favor of #1295.. Thought to add an additional parameter because the function requires the module as a parameter anyhow. In terms of a nice API, BinaryenFunctionRunPasses would ideally take a funktion reference as its first parameter (at least that's the naming scheme I have in mind, alternative here is BinaryenModuleRunPassesOnFunction).\nRegarding my use case: Somewhat. I'd then use the initializer expression I'd like to precompute as the body of a new function, optimize that, obtain a reference to the updated body (here: BinaryenFunctionGetBody, still todo), remove the function again, evaluate the expression's kind expecting a const (here: BinaryenExpressionGetId) and finally replace the initializer of the respective global.\nOn BinaryenFunctionOptimize: Sure, initially added that as well (as BinaryenModuleOptimizeFunction), but then settled for the general solution because of previous comments. Not a big deal to add it as well, though.. > So I am leaning to BinaryenFunctionRunPasses, taking the module as the final param (like RelooperRenderAndDispose).\nSounds good.\n\nAbout the second paragraph, I think that's a general enough thing that I'd like a binaryen utility for it. It should also handle locals etc. properly, so it's not as simple as your use case, but feasible. If that makes sense I can do that later today (unless you want to).\n\nThat'd be great, I'm not too familiar with the internals yet.. One thing about splitting up module and function entrypoints (BinaryenModuleRunPasses+ BinaryenFunctionRunPasses) I see is that, while it fits well to the C-API, the JS-API doesn't benefit from the split because it can have methods on the module instance (with the module parameter substituted). Module#runPasses, for example, is a member of module instances already. When removing the optional functionName parameter from it, there'd have to be a Module#runPassesOnFunction which we tried to avoid in the C-API - or - a static Module.functionRunPasses taking the module as its second argument.\nI see two ways to deal with that: 1) Simply accept that the JS-API differs and keep functionName as an optional parameter just there or 2) use that additional parameter in C (BinaryenModuleRunPasses) as well to make it uniform.. The latest commit adds the following JS-API as well:\n\nModule#optimizeFunction accepting both a name or a function reference\nModule#runPassesOnFunction accepting both a name or a function reference\n\nI also added the minimum required utility functions to make a test case from my specific use case (see binaryen.js/functions.js):\n\nBinaryenGetFunction / Module#getFunction\nBinaryenRemoveFunction / Module#removeFunction\nBinaryenFunctionGetBody / getFunctionBody. > However, wasm switches can only support comparing something to a constant, so only the get_local part could be generalized\n\nIn my case, most of the pattern, except $target-label and $case-value (possibly constant) is always the same:\ns\n(br_if $target-label\n  (i32.eq\n    $always-the-same-condition\n    $case-value\n  )\n)\n... [next case br_if]\n... [br to default case]\n<- outer blocks of cases. The common case is either a constant\njs\n  case 2:\nor constant global\njs\n  case Token.DOT:\nbut it might also be something like\njs\n  case 1<<2:\nthat becomes a constant after precompute. Hence, when precompute has been performed already, all of these should be constants.. Closing as this has landed.. On 2: I see, but we'd need additional functions for functions, imports, exports, globals etc. as well, if I'm not mistaken.\nOn 4 / WriteWithSourceMap: Hmm, personally I'd not want to include the entire source map in the WASM, just an URL to the external file containing the source map. In JS you can do both (inline or external, with external being the default for production builds). Then, if I ever had a need to debug something, I'd use the source map (browser dev tools do this automatically) and otherwise save the bandwidth. @yurydelendik ?. Implemented in https://github.com/WebAssembly/binaryen/pull/1392. Related: get_global on a missing global validates, but ultimately errors with an assertion error:\n```js\nvar mod = new binaryen.Module();\nvar funcType = mod.addFunctionType(\"v\", binaryen.void, []);\nvar func = mod.addFunction(\"test\", funcType, [],\n  mod.block(\"\", [\n    mod.drop(\n      mod.getGlobal(\"missing\", binaryen.i32)\n    )\n  ])\n);\nmod.addExport(\"test\", func);\nif (mod.validate())\n  console.log(\"-> validates\");\nmod.emitBinary(); // -> Assertion failed: mappedGlobals.count(name), at: binaryen/src/wasm/wasm-binary.cpp,355,getGlobalIndex at Error\n``. Related:get_local` on a missing local validates:\n```js\nvar mod = new binaryen.Module();\nvar funcType = mod.addFunctionType(\"v\", binaryen.void, []);\nvar func = mod.addFunction(\"test\", funcType, [],\n  mod.block(\"\", [\n    mod.drop(\n      mod.getLocal(0, binaryen.i32)\n    )\n  ])\n);\nmod.addFunctionExport(\"test\", \"test\", func);\nconsole.log(mod.emitText());\nif (mod.validate()) {\n  console.log(\"-> validates\");\n  var binary = mod.emitBinary();\n  new WebAssembly.Module(binary); // CompileError: WebAssembly.Module(): Compiling wasm function #0:test failed: invalid local index: 0 @+34\n}\n```\n```\n(module\n (type $v (func))\n (memory $0 0)\n (export \"test\" (func $test))\n (func $test (; 0 ;) (type $v)\n  (drop\n   (get_local $0)\n  )\n )\n)\n-> validates\nCompileError: WebAssembly.Module(): Compiling wasm function #0:test failed: invalid local index: 0 @+34\n``. LGTM (never relied onbinaryen.undefined` as the default in blocks). Closing as this has landed.. I see. When I think about it, my use case is more about code generation in general and not so much about optimization. Similar to the constant evaluation stuff earlier, I am just trying to reuse what Binaryen already has. Not so sure anymore if that makes a lot of sense here.\nIdeally, I could use a tool to convert a ready-made function in Binaryen IR to a Binaryen IR block expression like the inlining pass does (let's say BinaryenFunctionAsExpression, exposing the functionality provided by static Expression* doInlining(Module* module, Function* into, InliningAction& action)), without ever adding the function and reuse the expression multiple times instead. Would that be something you'd consider useful as an alternative to this PR, or do you think it would be best to not rely on Binaryen in this case and let my compiler do the function->expression conversion manually?. Closing for now. Might create a new PR once I have a better idea.. I see, thanks a lot. Just tried it with first running flatten/ssa (like so), but that doesn't seem to produce the same result (note the amount of locals, previously emitted just 3 or so) for me.\nI'd assume that order of passes is important there somehow?. My implementation is supposed to call the respective C-API functions directly (if func is omitted it uses the module functions; it is omitted here), no queueing. This is the API trace of just the call to optimize():\n```c\n// beginning a Binaryen API trace\ninclude \ninclude \ninclude \"src/binaryen-c.h\"\nint main() {\n  std::map functionTypes;\n  std::map expressions;\n  std::map functions;\n  std::map relooperBlocks;\n  BinaryenModuleRef the_module = NULL;\n  RelooperRef the_relooper = NULL;\n  {\n    const char* passes[] = { \"flatten\", \"ssa\" };\n    BinaryenModuleRunPasses(the_module, passes, 2);\n  }\n  BinaryenModuleOptimize(the_module);\n  return 0;\n}\n```\nPerformed like this:\nts\n  optimize(func: FunctionRef = 0): void {\n    // see: https://github.com/WebAssembly/binaryen/issues/1331#issuecomment-350328175\n    _BinaryenSetAPITracing(1);\n    this.runPasses([ \"flatten\", \"ssa\" ], func);\n    if (func) {\n      _BinaryenFunctionOptimize(func, this.ref);\n    } else {\n      _BinaryenModuleOptimize(this.ref);\n    }\n    _BinaryenSetAPITracing(0);\n  }. Sure! This is the wast being optimized:\nmemcpy.wast\nThis is the wast generated from the above using wasm-opt --flatten --ssa -O:\nmemcpy.wasm-opt-flatten-ssa-O.wast\nThe latter seems to be identical to what the compiler generated through optimize().\nFor reference, this is the optimized wast before I added flatten and ssa:\nmemcpy.optimized.wast. Tests are going to fail now because I haven't touched them yet.. > What tracing issue did you hit with BinaryenExpressionClone? I think we'll want that eventually anyhow.\nThe issue was that when cloning let's say a set_local(0, i32.const), cloning just the outer expression is fine tracing-wise while cloning the inner one (recursively) would either require calling the C-API method responible for creating it converting from the C++ API to C to C++ again or manually printing the expression[foo] = BinaryenConst(...) trace basically by duplicating the tracing code. Not an unsolvable issue of course.\n\nIIUC, the API here has getLoad, getBinary etc., and you need to call it with the right one? How about a single method, getInfo (or some better name), which receives a node of any kind and returns the JSON metadata for it (internally it would get the node id and use that)?\n\nYeah, there is getExpression. Not sure about the name though (maybe getExpressionInfo, likewise getFunctionInfo, getConstInfo). Could also make the other ones private, but thought it also doesn't hurt to have them.. Hmm, turns out that testing this new API will be somewhat error prone, because infos include pointer values that tend to change when binaryen.js is recompiled :(. Not yet implemented: getImportInfo, getExportInfo, getMemoryInfo, getTableInfo. Did I miss something? Might also be cool to have getters (and setters) for custom sections, but that's something for another PR.. > One followup idea I have is to add another field to the JSON infos, that gives their class in JS\nWhen I think about it, ideally we'd have TypeScript-like enums first that allow forward and backwards lookups of all these things, like types, expression ids, external kinds, operations etc. Something in the form\n```js\nType[Type[\"none\"] = Module'_BinaryenTypeNone'] = \"none\";\nType[Type[\"i32\"] = Module'_BinaryenTypeInt32'] = \"i32\";\n...\nExpressionId[ExpressionId[\"InvalidId\"] = Module'_BinaryenInvalidId'] = \"InvalidId\";\nExpressionId[ExpressionId[\"BlockId\"] = Module'_BinaryenBlockId'] = \"BlockId\";\n...\n```\nfor each enum-like. With that in place it'd be really easy to look up the numeric ids and string names of everything in both directions. Wdyt?. > I guess it depends on if we want JSON.stringify of these info objects to be self-explanatory\nWe'd then also have to do the same for types I guess? I'd be fine with just the ids, keeping the JSON minimal. Though, we could also make info objects be 'class' instances that provide all sorts of additional utility, in this context for example a getter that returns the string name of an id by implicitly calling the enum utility I proposed above.. I must admit that my tests are fairly limited at this point. What I can do, though, is to run all the tests once with the changes (and ssa/flatten turned on) and make a commit of it that'll show the differences in each one's fixtures. Let me check.... Here's the diff: https://github.com/AssemblyScript/assemblyscript/commit/9021a7c01a6ecac88741f1c33cba44a4134b0ab1 (the memcpy one)\nEdit: Oh, let me guess, this is not a default optimization yet. Sec\nA diff without flatten/ssa and just merge-locals turned on: https://github.com/AssemblyScript/assemblyscript/commit/5c24168cd729db115803843415a850339f0574ad\n(seems I am not a help here). lgtm. As long as the exported interface is the same (that is, Binaryen() is called in postJs - is it?), I don't expect any issues with MODULARIZE.\nRegarding pointer values:; Yeah, these tend to change every time something is changed and binaryen.js is recompiled. There are a few occasions where something seems wrong, like for the names in the tests (probably missing a Pointer_stringify), but there are others like body in functionInfo where it's hard to work around, unless we decide to test them in another form without printing.. Just noticed that the module loader code is gone entirely. Does MODULARIZE add similar checks for require/define and the global object on its own?. It's relatively simple, actually:\nCommonJS is synchronous: Check if a global require function is present to be sure plus check if there is a non-null module object with an exports property (CommonJS initializes this to an empty object). If so, assign the exported interface to module.exports, which is what a CommonJS module exposes to the outside when requireed from another file.\njs\nif (typeof require === \"function\" && typeof module !== \"undefined\" && module && module.exports)\n  module.exports = the_interface;\njs\n// other file would do\nvar Binaryen = require(\"./path/to/binaryen\");\n// Binaryen is `module.exports` from above\nAMD is asynchronous: Check if a global define function is present plus check that it has a trueish amd property to be sure. If so, call it with a suitable factory function that returns the exported interface, which is evaluated when used as a dependency of another module or the main file.\njs\nif (typeof define === \"function\" && define.amd)\n  define(function() { return the_interface });\njs\n// other file would do\ndefine([\"./path/to/binaryen\"], function(Binaryen) {\n  // Binaryen is what is returned from the factory function above\n});\nAdditionally it's always a good idea to expose the module on the global object (window in a browser, global in node, self in web workers) in case a CommonJS or AMD environment is present but not used, just like if defining a global var the_module_name.\njs\nvar globalObject = typeof window !== \"undefined\" && window || typeof global !== \"undefined\" && global || self;\nglobalObject.the_module_name = the_interface;\nUnordered seems to be ideal, that is export unconditionally in every way possible so it \"just works\" no matter what.\nIf you want I'll take a look after this is merged. Could also be an enhancement to MODULARIZE in general if all of this was implicit.. > Is it standard though to add it to the global object, don't most people use the proper require etc. technique?\nThere is something called universal module definition (UMD) that doesn't go as far as my suggestions above, e.g., doesn't unconditionally export on the global object. That's somewhat how it was before this PR.\nIn my experience, though, additional issues originate from mixing these things, which is sometimes inevitable when different modules from different authors with different loaders combined with different bundlers are used in a single application.\nNot sure what's best. UMD as above forces everyone to create compatible modules while doing more avoids more issues.\n\nOtherwise this looks ok to merge?\n\nMight fail with AMD loaders at first. I am not using AMD myself, but I can take a look and send a PR as a follow-up, probably simply consisting of adding the following two lines to binaryen.js-post.js:\njs\nif (typeof define === \"function\" && define.amd)\n  define(function() { return Module; });\nThat should do for now if Binaryen() is called automatically anyway.. I think I made a mistake by suggesting to call the Binaryen() function implicitly because exports aren't consistent now. AMD and CommonJS export the factory function while the var also calls it and reassigns to itself.. Hmm. From a JS/node module perspective I'd say that a user expects a ready-to-use API on require(\"binaryen\"), not an API one has to instantiate. While there might be valid reasons to do so in special cases, instantiating multiple APIs that might then instantiate multiple modules each doesn't feel right to me in the usual case. This is specific to binaryen.js, of course, and other emscripten-compiled modules might actually intend to be instantiated multiple times.\nIn this context MODULARIZE_INSTANCE seems like the right thing to implement as it lets the developer decide what's the usual use case. Maybe, a MODULARIZE_INSTANCEed module could still provide a way to create another instance beside the default one to cover rare special cases. Like a static instantiate function on the default export (the default instance)?\nIt pretty much boils down to the question whether exporting a default instance of a module makes sense for a specific emscripten-compiled module or not. A static instantiate function could also become the common denominator between MODULARIZEed and MODULARIZE_INSTANCEed emscripten modules (instead of just exporting a function one has to call), with the sole difference that one exports a default instance and the other does not.\nLet's say, when MODULARIZEed, a function to instantiate a new module would be exported for backwards-compatibility that also has an instantiate static property referencing itself. A MODULARIZE_INSTANCEed module would export a default instance that also has an instantiate static property on the exported default instance.. Yeah, that was my thought. Like providing a similar API like WebAssembly in the browser, while still providing a way to export something like a synchronously instantiated node module.. I don't know the full picture, but if the instantiation code runs once anyway, there's not much a tree-shaking/dead-code-eliminating compiler could optimize away - unless singleton instantiation is simpler and can exclude a heap of code. Can it?. There's also this one that I am maintaining. It has parseText but is probably not fully up to date either.\nIf you like, I could try to update my one with the latest changes and additions, and we copy the relevant over?. The other documentation should be up to date now.. Maybe, in this specific example, the if could also be replaced by a select because both arms are free of side effects and not deeply nested. I think I read somewhere that Firefox compiles it branchless?. > Btw, what are you compiling with?\nbinaryen.js's default optimizations (is that -Oz?). Reminds me that I always wanted to add the ability to specify optimization levels to the C-API :). > Can you make a testcase showing the wrong output, I can debug that?\nThis is the test case I used: https://github.com/AssemblyScript/assemblyscript/blob/d89703cdad5ed5cb44189b2ca0f69e9cfc16829f/tests/binaryen/optimize-if-eqz.js\n```s\n(module\n (type $i (func (param i32) (result i32)))\n (memory $0 0)\n (export \"test\" (func $test))\n (func $test (; 0 ;) (type $i) (param $0 i32) (result i32)\n  (if (result i32)\n   (i32.eqz\n    (get_local $0)\n   )\n   (i32.const 0)\n   (get_local $0)\n  )\n )\n)\n(module\n (type $i (func (param i32) (result i32)))\n (memory $0 0)\n (export \"test\" (func $test))\n (func $test (; 0 ;) (type $i) (param $0 i32) (result i32)\n  (if (result i32)\n   (get_local $0)\n   (get_local $0)\n   (i32.const 0)\n  )\n )\n)\n```\nMy binaryen.js version is a couple of commits behind master atm, though (40.0.0-nightly.20171229).. Thanks for the clarification!. Appears the JS tests are working now, but there's a leak sanitizer error somewhere else. What have I done.. Tests seem to fail now because, with debugInfo being 0 by default, some (or all) wasts don't have names anymore. Previously the API behaved as if debugInfo had been explicitly activated, but I don't know how. Maybe because none of the respective functions/options has been called/set in the C-API before? Seems that this affects specific tests only that write and read back a binary, which is expected.. Ah, seems printing an array to console looks different between shells (and some properties are not visible in mozjs). Latest commit should format it explicitly.. Being part of the WebAssembly org is probably the most effective way that someone discovers it by accident. And then a wild bureaucracy appeared \ud83d\udca5. Maybe somewhat similar:\ns\n (func $assembly/tlsf/Control#sl_bitmap_set (; 0 ;) (type $iiiv) (param $0 i32) (param $1 i32) (param $2 i32)\n  (i32.store\n   (i32.add\n    (i32.add\n     (get_local $0)\n     (i32.const 20)\n    )\n    (i32.mul\n     (get_local $1)\n     (i32.const 4)\n    )\n   )\n   (get_local $2)\n  )\n )\nor ($0 + 20) + ($1 * 4). Seems to me 20 could become the store offset? Is that actually desirable?. Thanks, makes sense.. Another thing that might have a simple explanation:\ns\n (func $assembly/ugc/Control#get:set1 (; 0 ;) (type $ii) (param $0 i32) (result i32)\n  (get_local $0)\n )\nis not being inlined for example here\ns\n (func $assembly/ugc/Control#init (; 5 ;) (type $iv) (param $0 i32)\n  (call $assembly/ugc/Header#clear\n   (call $assembly/ugc/Control#get:set1\n    (get_local $0)\n   )\n  )\n  ...\n )\nin wasm-opt -O2 --inlining but is in wasm-opt -O3 --inlining, is that correct? Seems to me that inlining this one is preferable in any case.. So, if the size of the function body equals that of a call (2 bytes if the immediate function index is less than 128, otherwise more, but this might change after optimizations and linking so cannot be relied upon), it can be inlined everywhere even if exported for a performance-win. If it is not exported, function declaration and its body can also be removed for an additional 3 + 2 bytes size-win, again varying with immediates, with the possibility of eliminating its function type as well (unlikely because it's such a simple one, but theoretically possible). Is that the kind of thinking that applies here?. Thanks!. > The other followup we discussed was to use the new MODULARIZE_INSTANCE option, which landed in emscripten earlier today, were you going to do that?\nThat's great, going to take a look now :). Currently testing with version 42. When I set optimizeLevel=2, shrinkLevel=2 and debugInfo=0, inlining should be performed as of this, but it isn't. Not sure if that's a general issue or if I missed something when I initially added the options. Putting this here in case you have an idea.\nCould it be that both inlining and inlining-optimizing are necessary?. I think I might actually be wrong. While I was preparing an example, I noticed that a couple of functions are indeed inlined with the $__inlined_something block removed.\nFor what it's worth, the examples I initially prepared were:\ntlsf.ts -> tlsf.untouched.wast -> tlsf.optimized.wast using -O3 --noDebug (3, 0, false).\nugc.ts -> ugc.untouched.wast -> ugc.optimized.wast again using -O3 --noDebug (3, 0, false).. These variables are tracing specific (not used by the module, but by tracing) and created when BinaryenSetAPITracing(1) has been called. Hence, when tracing evaluates to true, the variables are guaranteed to be set. I'm not exactly sure how arena allocation handles this, but their contents point to no longer used memory (if not even free'd), so clearing them when disposing a module is a sane thing to do..  > But to optimize this, it seems like the conditions are: the global is only used in one function, and that function will only be called at most once. Which can really only apply to the start method.\nYeah, or if one (or multiple) functions use the (same) global, but (each of them) reinitializes it anyway. Might not be a size-win, though, when its multiple functions because a single global declaration is replaced with multiple locals.. > Everything except for the final stores could be optimized using general methods (eventually; we don't have proper PRE or GVN yet)\nThat reminds me of another thing. Accesses to this etc. become loads and stores in my case. You mentioned registers earlier, so might it also make sense to lower these to locals except for the final store as well?\nts\nclass Foo {\n  baz: i32 = 24; // is accessed by offset 0 in load/store\n  bar(): void { // becomes a wasm function\n    this.baz = this.baz + 42; // store(this, 0, load(this. 0) + 42)\n    return this.baz; // load(this, 0)\n  }\n}\n\nBut maybe in AssemblyScript and others this may be common?\n\nIn AssemblyScript's case it's relatively common because of the implicit start function that wraps all the top-level logic of all source files, combined with the relatively specific fact that the compiler doesn't have all the information beforehand.\nNot sure yet where to draw the line between what the AssemblyScript compiler should do (here: do one more pass over the AST and keep track of things), and what's better to do in Binaryen.. Hmm, seems some environments work, while others hang here.. > That crash is due to libc aliases for globals\nWorks with the fix! :). > You might need to implement a bunch of things for the imports here - e.g. binaryen uses exceptions so there will be invokes, and it does syscalls to print logging, etc. Not sure it will be practical to do.\nYeah, you are right. Isn't practical, especially when Emscripten already does all of this.\nI have a working WASM version now, but it required a couple of changes to binaryen.js-post.js to work, because the post-js immediately calls some exports (like when setting up Module['i32'] = _BinaryenTypeInt32()) without waiting for the module to become ready. While all of this is straight forward, now I'm not sure if MODULARIZE/MODULARIZE_INSTANCE should handle such conditions automatically (not running post-js at all until the module is ready) or if it's better to just patch it into post-js using onRuntimeInitialized. What'd you say?\nI have an API in mind now that, when loading binaryen.js the usual way, you get an instance of the JS interface. The JS interface could then also provide an instantiateWasm function or something that one could use to lazily get an API that's backed by WASM instead. But that might change, still trying out all sorts of things :). > e.g. binaryen uses exceptions so there will be invokes, and it does syscalls to print logging, etc. \nI remember that exception catching wasn't enabled when building binaryen.js not long ago, but I'm not sure how relevant this is. I wonder if it would it be possible to simplify these parts on the C/C++ side so it becomes easier to link with the wasm version? Asking because I intend to link Binaryen compiled to WASM with the AssemblyScript compiler compiled to WASM, making it a single binary, eventually.. Thanks for the insights! Closing while waiting for the specs to land :). One way to make loading lazily work could be to provide the .then interface under all conditions, making it resolve instantly when it's not a lazy build. A non-lazy build would then initialize instantly while a lazy-build would require that the user uses .then. Both versions work like MODULARIZE_INSTANCE, and the safest way to use it would be to always use .then (though not necesary in a non-lazy-build), so things are interchangable. Hope that makes sense :). Ok, this one should \"just work\" (except for the cwd issue above), but .then is named .ready here so it doesn't conflict for now.\n```js\nvar Binaryen = ...;\n// can test if already ready\nconsole.log(Binaryen.isReady);\n// or just use a promise and wait for it, no matter if already ready\nBinaryen.ready.then(function() {\n  ...\n}, function(err) { throw err; });\n// or if you like it rather fancy\n(async function() {\n  await Binaryen.ready;\n  ...\n})();\n``. Actually I figured that.readyshould probably remain a binaryen.js-only thing because it requires specific knowledge of which parts in post-js must be delayed (here:initializeConstants`). Generalizing this functionality would most likely result in more confusion than it'd be useful. At least \"you should probably use MODULARIZE instead\" seems like a more useful advice to me than \"you first have to find out which parts of your code would fail in an asynchronous instantiation scenario, then wrap that in a function and do X, then Y and maybe Z\".\nRemains the cwd issue.. Hmm, I really thought Module.locateFile or Module.filePackagePrefixURL could solve this (if the latter also works for non-prepackaged files, just trying it as well), but it seems that both aren't actually accessed when I put the following in binaryen.js-pre.js and include it in just the wasm build:\njs\nModule['locateFile'] = function(file) {\n  throw \"locateFile called: \" + file;\n};\nObject.defineProperty(Module, 'filePackagePrefixURL', {\n  get: function() {\n    throw \"filePackagePrefixURL accessed\";\n  }\n});\nAny ideas?. Seems integrateWasmJS is executed before the pre-js code is. Is there a way to insert code even earlier?. Scratch that, I have two --post-jses ... nooo. Just figured that a.js has to be generated to bin/ now by check.py because it, like binaryen-wasm.js that is a part of it, looks for binaryen-wasm.wasm in the same directory. That's expected and actually an indicator that it is functioning as intended.. > Did we check if node.js can handle synchronous compilation? that would be best.\nI know that node.js supports new WebAssembly.Instance(new WebAssembly.Module(...), {}), if that counts as synchronous. Though, as node.js is all about doing things asynchronous, I'd say that designing things to do compilation in the background is even better.\n\nIs there some way in module loaders to handle this? What i mean is, when you do require() in node.js, is that an async or a sync operation from the perspective of the module being loaded? If node allowed an async callback for the require to complete, that would be really cool...\n\nrequire is a synchronous operation that usually returns something (like at least a handle). In binaryen-wasm's case, it returns the same thing a browser would get when accessing Binaryen before it is ready. In all cases, the recommended (and universal) usage is:\njs\nBinaryen.ready.then(() => {\n  ... use it ...\n});\n\nIf we can't do either of those things to keep the API synchronous, I think we should consider changing it to be asynchronous everywhere - the asm.js and wasm versions being different seems confusing. But i'm not sure.\n\nIf I understood correctly, there is no way to do synchronous loading in browsers anyway if one wants to use an additional .wasm file (not embedded as base64 or something), is this right? If so, the default case should be asynchronous anyway because there's at least one important target that doesn't support synchronous instantiation.\nFrom binaryen-wasm' vs. binaryen.js perspective, the key difference is that binaryen.js can, technically, be used right away (conveniently keeps backwards compatibility). BUT: In the docs I'd always recommend the asynchronous way (see example above) from this point onwards, to minimize confusion.\nOr, in other words: Switching synchronous binaryen.js with asynchronous binaryen-wasm.js and vice-versa will just work as long as Binaryen.ready is used as shown above. That's what the updated tests are doing as well so these work with both versions. Again, I hope this makes sense :). Currently it looks like this:\njs\nimport { Binaryen } from \"./binaryen-wasm.js\";\nBinaryen.ready.then(...);\nor\njs\nimport { Binaryen } from \"./binaryen-wasm.js\";\nawait Binaryen.ready;\n...\n\nAbout .ready.then(), could it be just .then() like MODULARIZE does now? Or is .ready better for some reason?\n\n.ready has the advantage that it is a promise and thus can be used with await. It also does some binaryen.js specific things as outlined above, which conveniently retains backwards-compatibility when continuing to use just binaryen.js. It might be possible to make .then work similar, but that'd require that an Emscripten module instance extends promise and that it also does that in MODULARIZE_INSTANCE. Would look like:\njs\nimport { Binaryen } from \"./binaryen-wasm.js\";\nBinaryen.then(...);\nor\njs\nimport { Binaryen } from \"./binaryen-wasm.js\";\nawait Binaryen;\n...\n\nI see that Parcel allows synchronous syntax for loading wasm, by translating it to async at bundling time. We probably don't want to depend on a specific bundler, though, but that would have been nice...\n\nI don't think that we can hook to import like in Parcel's examples, because when using binaryen.js or binaryen-wasm.js one is actually importing a .js file, not a .wasm. Unfortunately, I don't know what happens when the imported element in an async import(...) scenario is a promise itself. If it propagates that to where async import(...) is happening, changing .then as above might actually make it possible, but I'd not bet that this is how it's done.. Looked this up pretty quick: It seems we can actually do that import thing. The only thing necessary is to return a promise as the module's export. Does this already work with just .then because it resembles one? Is anything with a .then property awaitable?. I've worked something out here, which essentially makes every module a valid promise by means of var Module = new PromisedModule() and then works as usual (using .then if asynchronous, using nothing at all if synchronous). That's a node-version for easy testing, but one could also replace require with import, for example when using Parcel. Let me know if that's something you'd tolerate in Emscripten or not, as it's certainly doing... well... JavaScript-y things.\nBtw, if we stuff PromisedModule into pre-js for now, it sould already work that way in binaryen.js/binaryen-wasm.js. Might be useful as a testing ground for this functionality, and if it turns out to be good enough, could translate to Emscripten.\nEdit: Tweaked it a bit so it behaves correctly in chaining scenarios.. The obvious alternative here is to simply provide a common .ready property on everything.\n\nMODULARIZE .ready promises the instantiated module (what the outer wrapper function did) and should then propagate to...\nMODULARIZE_INSTANCE .ready promises the module instance itself once it's ready (what onRuntimeInitialized did).\n\nIn any case, the result of .ready would be a ready to use module. In MODULARIZE it is a unique one, with its own memory etc., while in MODULARIZE_INSTANCE it's always the same one.\nIn this case, binaryen.js in its current state could be used as a test case, without changes, as it implemements the second. Btw, libwabt.js uses such a ready promise.. I think I'd favor the .ready promise because of its simplicity. Less code and no need for promise shenanigans. Has zero drawbacks except style.. > is that a general convention in the JS space these days?\nNot that I'm aware of. I guess it just makes sense to use a Promise, and to use ready as its name :). Fixed by https://github.com/WebAssembly/binaryen/pull/1433. Btw. there is one thing about source maps that made me wonder, but that's more about how Firefox handles them and not really regarding Binaryen.\nIf I use \"myModule.wasm.map\" as the sourceMapURL instead of, let's say, \"http://127.0.0.1:8080/myModule.wasm.map\", Firefox issues a warning that the WASM's source map url isn't a valid URL. My assumption is that this is either still in the works or actually necessary for a specific reason / a result of using the fetch API?\nSource map error: TypeError: tlsf.optimized.wasm.map is not a valid URL.\nRessource address: wasm:http://127.0.0.1:8080/tests/:7a53f53b7897a9f2\nSource map adress: tlsf.optimized.wasm.map. Thanks, yes, makes sense!. Sure, if copying my other docs here isn't an option, I can try to keep this one up to date, too. Do you mind if I do that in a separate PR, including all the previous changes that are still missing?. I made these initially to include typing information for the binaryen npm package, and later extended them with links to the specs etc... > for example yours are missing Module.set_local\nThe aliases are not explicitly listed, but noted at the bottom of the variable accesses section:\n\n\nVariable access methods above are also aliased in underscore notation, e.g., get_local.\n\n\nbut I should probably change that so it is more visible. Do you have any preference on the default notation there? get_local or getLocal?\n\nI'm fine to go with yours, in which case we should make sure everything documented here is in yours\n\nThe docs are actually based on yours (initially was the same file), but I might have stripped one or two details in the process.\n\nThoughts?\n\nI always feel a bit guilty by hosting another version of the docs, or the binaryen package on npm, because people might misunderstand that I am not the primary author of these. My repository merely exists because I rely on up to date JS builds with TypeScript definitions for AssemblyScript, so I figured that I automate that and publish it to npm in case others have that need as well. If you have an idea how we could provide that in another form, under your control, I am also fine with moving the entire thing. If that's not important to you, I can also continue to host it in the AssemblyScript org.. Related: https://github.com/WebAssembly/binaryen/issues/1349. Alright, I just split the API from the README to make this easier: https://github.com/AssemblyScript/binaryen.js/blob/master/API.md\nTheoretically, that file could also be pulled from there somehow.. Or, actually, that file could be updated here directly, and I include it into my repo's README, which would certainly make more sense and guarantee that things are aligned. Only thing I'd need is that the <!-- BEGIN API --> comment (or any other permanent marker) s retained.\nEdit: The TOC is generated automatically by an npm module. We'd either have to do that here, or update it here manually, or remove the TOC here. I'm fine with any.. Or: We could maintain it within the wiki :) Decisions, decisions.\nI actually like this idea, see: https://github.com/WebAssembly/binaryen/wiki/binaryen.js-API. That's true,. I guess I just like how easy it is to keep it updated now, e.g., adding just a sentence or correcting a typo even without a PR. Your call :). Thanks!. Related: https://github.com/WebAssembly/binaryen/pull/1333. One thing that might still be colliding frequently after this and https://github.com/WebAssembly/binaryen/pull/1424 is if there are no names at all, where there is a function $0 and a local $0, both called respectively used in the same function. Not sure if https://github.com/WebAssembly/binaryen/pull/1424 handles these as well? If not, maybe unnamed functions should have a unique prefix (fun$?), too. Same for globals (glo$?) vs. locals.. Let's do it afterwards, as it touches different files (isn't done in wasm2asm, but rather in core, if I'm not mistaken?). Would probably be a better match for inclusion in https://github.com/WebAssembly/binaryen/pull/1424.. No problem. Btw, one thing I noticed when building the JS files these days is this warning, that I don't know where it comes from: warning: unresolved symbol: llvm_nearbyint_f64. Doesn't cause any breakage, though.. Can confirm that the warning is gone with 1.37.36, thanks!. js\ntest=module.addFunction(\"test\",_void_,[],[\n    logi(int(10))\n])\nShouldn't this be\njs\ntest=module.addFunction(\"test\",_void_,[], module.block(\"\", [\n    logi(int(10))\n]))\n@kripken: Do you think that accepting an array instead of requiring a block expression there, alternatively, would be a good addition? The JS bindings could technically check this, but I am not exactly sure about the block's return type that might also have to be inferred there. Maybe the auto type?. Hmm, when I look at the bindings, it appears to just pass the argument through, so even if it doesn't throw, it should still not result in a valid body.. Should be in the README now, thanks! :). Thanks, makes sense.\n\nAlternatively, we could focus on getting simple cases right like this one\n\nHmm, when I think about it a bit that might already be sufficient because it must be a simple case to be worth it anyway, if I understood this correctly. Like replacing a call with an add just to save the immediate. Didn't quite understand the implications of flipping arguments, unfortunately, so I might still be missing something.. Thanks, now I hopefully understand. So, it appears to me that inlining could be safely performed without introducing a block if either of the following conditions is met:\n\narguments are in the same order\narguments are flipped but the second that becomes the first doesn't write to a var or memory or call a function that might do so (except its own locals)\narguments are flipped but the first that becomes the second doesn't read from a var or memory or call a function that might do so (except its own locals)\n\nObviously, 1) already catches the case outlined above, but so would 2) because there's no write, but not 3) because there are reads.\nDoes that make sense? :). Seems that I don't have something interesting, all kinda basic. Fwiw: The untouched files are those generated by the AssemblyScript compiler, the optimized ones have been optimized by Binaryen with -O. The one that comes the closest to interesting might be this one.. Oh, and there is this one, of course. If you are looking for something specific, I can update the switch test with more cases if you wish.. While reading through this and the discussion on the Souper repository, I wondered whether it would make sense if a frontend like AssemblyScript could provide some information to Binaryen whether a constant or expression actually is a smaller type of integer, like i8, i16, u8, u16, bool (i1)?\nThis might of course be out of scope for Binaryen because there are no such types in WASM, just thought I ask before tackling this issue with my superficial knowledge :). > Which looks like what we want here :)\nRight, thought about tee'ing the entire expression as well when I read my post again, which of course makes more sense in the specific example. Might sufficiently cover my use case, if it also covers this example (I guess):\nts\nfunction div16_internal(x: i16): i16 {\n  return x / -x;\n}\nwat\n (func $div16_internal (; 1 ;) (type $ii) (param $0 i32) (result i32)\n  (return\n   (i32.div_s\n    (i32.shr_s\n     (i32.shl\n      (get_local $0)\n      (i32.const 16)\n     )\n     (i32.const 16)\n    )\n    (i32.shr_s\n     (i32.shl\n      (i32.sub\n       (i32.const 0)\n       (get_local $0)\n      )\n      (i32.const 16)\n     )\n     (i32.const 16)\n    )\n   )\n  )\n )\n\nWith that said, though, I wonder if the opposite ABI doesn't make more sense: for each function returning an i16, it may be received in many places. In other words for each return there are multiple more places where the returned value is received. So doing this on the return seems more compact than in each place the value might be received, unless i'm missing something.\n\nActually I don't know exactly what I am doing here. The idea is to avoid sign-extensions between function calls if not ultimately necessary like C/Rust do with their internal ABIs. One such place is divisions, another is on comparisons, and an obivous one is on returns from exported functions, while everything else can, theoretically, remain unwrapped. Before these experiments, all functions in AssemblyScript simply made sure that whatever is returned from a function is properly wrapped (basically all C-ABI internally), which led to quite a few unnecessary extensions between internal calls. Hmm.... What I am thinking about now is to keep track of possible expression value ranges, statically, and take those into account when generating wraps. Ranges of constants (single value), bitwise ands (effectively limits range), clz (1-32/64), comparisons (0-1) and so on could then be precomputed statically, avoiding wrapping unless the range is unknown or overflows. But: To me this looks like something that Binaryen might already be doing or might do at some point. Is/will it? If it does/will, I wonder how a frontend could integrate with it in order to skip generating wraps while emitting code, instead of having to run an additional pass.. Btw., would it make sense to have passes for transforming sign extensions in either direction? If there was one to convert the new operations to something supported today, the AssemblyScript compiler could use the new instructions already instead of implementing an option on its own.. Done: https://github.com/WebAssembly/binaryen/wiki/binaryen.js-API#sign-extension-operations-. Appears CI failed for other reasons. For reference, the following is the saved binary from\njs\nvar mod = new binaryen.Module();\nvar funcType = mod.addFunctionType(\"v\", binaryen.none, []);\nvar func = mod.addFunction(\"0\", funcType, [],\n  mod.drop(\n    mod.block(\"label$1\", [\n      mod.loop(\"label$2\",\n        mod.unreachable()\n      )\n    ], binaryen.i32)\n  )\n);\nmod.addExport(\"0\", \"0\");\n\nWhen reading it back, it becomes the original (apparently invalid) text format:\nwat\n(module\n (type $0 (func))\n (export \"0\" (func $0))\n (func $0 (; 0 ;) (type $0)\n  (drop\n   (block $label$1 (result i32)\n    (loop $label$2\n     (unreachable)\n    )\n   )\n  )\n )\n)\nSo...\n\nNot sure why this is just a bug in the text format - the binary for it is fine.\n\nis this just the text printer missing something the binary writer adds implicitly? Asking because when looking at the comments above, it appears to be more complicated than that?. What if we'd just do\nc\n    if (curr->type != none && curr->body->type == unreachable) {\n      o << maybeNewLine;\n      !minify && doIndent(o, indent);\n      printOpening(o, \"unreachable\");\n      o << ')';\n    }\nright below this line, similar to what the binary writer does?\n$> wasm-opt the-file.wat --print\nwat\n(module\n (type $0 (func))\n (func $0 (; 0 ;) (type $0)\n  (drop\n   (block $label$1 (result i32)\n    (loop $label$2\n     (unreachable)\n    )\n    (unreachable)\n   )\n  )\n )\n). > How important is it that binaryen can emit the wasm text format correctly?\nFor AssemblyScript it's quite convenient to have a text format printer provided by Binaryen (while there isn't really a need to read text format), so it can be its sole dependency. I've tried to avoid adding WABT for example because it adds another megabyte or so of JS just for printing text format.. My buildbot basically\n\nInstalls and compiles Emscripten incoming from source (using ccache so it's relatively fast)\nUpdates Binaryen, which is a submodule, to latest (for nightlies) or a specific tag if there is a new one (for releases)\nRuns a build script very similar to build-js.sh and outputs the result to index.js\nRuns a sanity test to make sure that the binary is working\nCreates a Git tag, pushes the changes back to GH and publishes to npm\n\nWhile this doesn't create any GH releases (and index.js is a asm.js binary), this essentially looks, feels and behaves like a simple, regular node module repo otherwise. I am ok with moving the bot somewhere else if that sounds good to you. Can of course also make one for wasm.js.. > The one tricky bit is the rest of the tests, that is, that tested the bundled optimized build.\nMaybe the JS specific tests could then be run by the buildbot (the sanity tests it currently has are relatively basic so any improvement there would be great anyway). One thing to note afaik is that the JS tests cover some parts of the C-API that the C tests do not cover yet.. It's basically the index.js file.\nGitHub:\n master: https://raw.githubusercontent.com/AssemblyScript/binaryen.js/master/index.js\n version_48: https://raw.githubusercontent.com/AssemblyScript/binaryen.js/v48.0.0/index.js\nrawgit.com as a CDN:\n master: https://cdn.rawgit.com/AssemblyScript/binaryen.js/master/index.js\n version_48: https://cdn.rawgit.com/AssemblyScript/binaryen.js/v48.0.0/index.js\nnpm:\n latest: https://unpkg.com/binaryen@latest/index.js\n nightly: https://unpkg.com/binaryen@nightly/index.js\n* version_48: https://unpkg.com/binaryen@48.0.0/index.js. From what I can tell unpkg.com is relatively popular among node.js developers because it pretty much behaves like npm with its urls. It's open source and according to its README sponsored by CloudFlare and Heroku.\nNot sure how common RawGit is, but I like its sheer simplicitly (just something simple serving GH repos via CloudFlareStackPath afaik) and that one can pick exact commits as well.. Commit above should fix that, I hope.. > Or, getting the latest tagged version would avoid that issue too.\nBeing able to just emsdk install latest would be ideal, but last time I checked precompiled binaries didn't work on Travis CI because of a glibc mismatch. I think there are a couple issues I opened or replied to at emsdk / emscripten somewhere. Do you know if there has been any progress on making proper static binaries?. I see, thanks. goes learn docker. For a bit of background: What AssemblyScript does there is inline calls to functions annotated with an @inline decorator. That happens right away on code generation, compiling the function as a block, before any passes are being run. My expectation would be that this should optimize just fine like any other user provided code before optimizations, as the same could, theoretically, have been written by a programmer manually? The blocks are named ...|inlined - might that cause trouble (or could even be used as the key information necessary)?. @kripken Does --flatten have to be run before, after or between other optimizations?. AssemblyScript currently simply passes the optimize levels down to Binaryen, and I wonder if it might make sense to run flatten + local-cse on other occasions than -O4 as well due to the compiler usually emitting blocked code, as the improvement of 20% is quite significant.\nFor example, it might well be that a user wants -Oz with the best possible code size reduction, so does it make sense to run flatten + local-cse there as well due to AssemblyScript's design (while LLVM-based compilers wouldn't have to)?. Would it, maybe, make sense to have another option there like --no-llvm, for compilers like AssemblyScript to utilize on any optimize level, and Binaryen then doing the right thing accordingly to achieve roughly the same at the end?. Yeah, not sure if there's a common denominator for what LLVM is doing before passing code to Binaryen, but if there is, maybe that'd make a good name? Maybe --pre for \"preoptimized\"? Or, more general, something like --no flatten --no local-cse for things a compiler like LLVM has already done, and otherwise including these?. What I'm doing now is to magically increase the optimize level on -O3 and -Oz in an attempt to keep optimization options somewhat symmetric to other toolchain (it appears to me that providing the original -Oz, for example, doesn't make a lot of sense without flatten etc. when AssemblyScript is the generator). But I worry that, at some point (or already), -Oz might deviate from --optimizeLevel 4 --shrinkLevel 2 or something like that, so an additional option that'd allow me to just rely on Binaryen to do the right thing, no matter the optimize level, would make that more convenient for me. Not sure how valid this concern actually is, but that'd be my reasoning :). I was referring to LLVM/clang, Emscripten and Binaryen sharing optimization levels, and I thought it would be great if AssemblyScript could share as much of these as well. For example, I imagine users comparing outputs of multiple toolchains based on the same optimization levels, so unifying that seems like something that could avoid misunderstandings and feel more coherent when switching between toolchains in general.\nAn additional option indicating preoptimization by LLVM might help to achieve this, because -O4, as it stands, always implies all of -O3, even if LLVM would also flatten with -O2 for example. I actually don't know if it does, but if it does, there'd be no way to achieve the same with the AssemblyScript compiler except specifying passes manually. For example, my understanding so far is that LLVM would always produce flattened code (again, I actually don't know), and that the AS compiler should always run flatten from -O1 upwards.. Thanks, can confirm that it is compiling without issues again! :). Great, thanks! And yep, the bot compiles and uses incoming currently.. Works again, thanks!. Just noticed: With this change it isn't possible anymore to override printing to stdout, which I used to do in AssemblyScript because I am using the C-API directly. Not sure what to do instead now, but the way it is currently would make it necessary to compile a custom binaryen.js or something for the compiler. Any idea?\nEdit: Just after writing this down I figured that I can do the following, which works again:\n```js\nModule.prototype.toText = function toText() {\n  return new binaryen.Module(this.ref).emitText();\n};\nModule.prototype.toAsmjs = function toAsmjs() {\n  return new binaryen.Module(this.ref).emitAsmjs();\n};\n``. So, does Emscripten still callModule['print']if it is present? I thought it is using the inner (to the generated JS, and thus inaccessible from the outside)out` function now.\nEdit, again: Just checked the Emscripten PR linked above, that explains that Module['print'] is picked up at instantiation. Answers my stupid question :). (going to fix the tests tomorrow, if it's otherwise good). Not sure if this is heading into this direction, but it would be a nice bonus if tooling based upon Binaryen could provide output of an entire module in stacky text format as an option some day as well :). Btw. my impression was that this would also fit well into precompute because function arguments are already known to be constant and the Flow, well, just flows (stopping early) and does not have to care about introducing temp vars or blocks. Not sure if this is of any significance, though, haven't actually looked at the inliner.. While looking through my old issues here I figured that this one is actually related to https://github.com/WebAssembly/binaryen/pull/1898, heh. Similarly, it's not necessary for our use case anymore, hence closing.. Yay! Any plans for a BinaryenModulePrintWat or similar for the C-/JS-API? :) (can do this as well in a PR later if you'd prefer). > My guess is that that's a new assert added there\nThat'd make sense, yeah.\nThe test module looks like:\nwat\n(module\n (type $i (func (result i32)))\n (import \"env\" \"provided\" (func $imported (result i32)))\n (import \"env\" \"memory\" (memory $0 0))\n (export \"main\" (func $main))\n (export \"memory\" (memory $0))\n (func $main (; 1 ;) (type $i) (result i32)\n  (return\n   (i32.const 0)\n  )\n )\n)\nLikely the memory import then.. Thanks! Made it so that the bot removes the memory import again before testing the asm.js output, which works. Other than that, being able to import memory somehow with JS output would be great, of course (to mimic WebAssembly.Memory, maybe accept just { buffer: someBuffer }, which would also work with a proper memory instance?).. Should also add the new parameter to the JS wrapper here.. Ok, so you are envisioning something like the following API to make an existing memory non-imported?\nc\nBinaryenSetMemory(\n  theModule,\n  BinaryenMemoryGetInitial(theModule),\n  BinaryenMemoryGetMaximum(theModule),\n  BinaryenMemoryGetExportName(theModule),\n  BinaryenMemoryGetSegments(theModule),\n  BinaryenMemoryGetSegmentOffsets(theModule),\n  BinaryenMemoryGetSegmentSizes(theModule),\n  BinaryenMemoryGetNumSegments(theModule),\n  false // imported\n);\nNot sure about the large amount of API calls necessary to do this, but we'd probably want getters and setters for all these things anyway at some point so it'd be ok I guess.. Also seems that BinaryenGlobalGetName is already utilized in Module#getGlobalInfo, even though it doesn't exist yet.. Btw, is it possible to emit stack IR with the current C-/ JS-API?. Hmm, looks like it isn't as easy anymore to intercept stdout (because out is an inner var). What do you think about adding an option, for example on Module#emitText or alternatively something like Module#preferStackIR(bool), that indicates whether to output stack ir?. Yeah, sounds good!. Btw. one minor thing I noticed is that if we output stack ir, that there's a comment (; has Stack IR ;) on every function, which feels redundant. Would it be ok to omit it when outputting stack ir specifically?. Can run this branch against our full test suite and make a commit from the changes. Just let me know once it's good for a run :). Commit: https://github.com/AssemblyScript/assemblyscript/commit/1a377be221ab68e563de36235e2fbbf1ded2587b\nThis actually broke the std/array test that now runs into an unreachable. Most likely hitting an assertion in the test file now that it didn't before. Need to investigate. @MaxGraey any idea?\nFor a bit of context: The .untouched.wat file next to the respective .optimized.wat file is the one that becomes optimized. The diff shows optimized before vs. optimized after :)\nTo update and compare on your own, just drop another binaryen.js into the lib/ folder on that branch and run npm run test:compiler -- --create to update the fixtures (need to run npm run install once beforehand to set up the repo).. @MaxGraey still seeing an unreachable when I comment out all of unshift and shift :( but shift is involved, as it errors at the first assert below the internalCapacity check.\nUpdate: This is hitting the asserts in lines 215, 225, 237, 250, 292, 331. Sure, can do that tomorrow :) The failing test might indicate a bug in one of the new passes as well. Will try to isolate the issue to see where this comes from.. Commit: https://github.com/AssemblyScript/assemblyscript/commit/b8830e5b22eb8cb07c4d79711cdb918dcff9323b\nSame as before, still failing that one test, but with diifs for binaries before and after :). One of the more interesting ones might be std/libm (+7 bytes), because it's somewhat large-ish and includes all the math stuff. Largest total increase in size is in std/map (+126 bytes). Largest total reduction in size is in std/array (-208 bytes), which is coincidentally the failing test.. The files of interest are libm.optimized.wasm before that commit (not yet using o4-moar branch) and libm.optimized.wasm after that commit (using o4-moar branch). The wat file libm.optimized.wat is the respective stack-ir representation. Optimization setting for these is -O4 without any size optimizations.. Hmm, that's strange. All I did is to switch out the version of binaryen.js the compiler is using with one I compiled from this branch, and regenerated the fixtures to create a diff commit. By adding a bit of logging I verified that the optimization options set are optimizeLevel=4 and shrinkLevel=0. Will try to update my emscripten version and recompile. The normal version of binaryen.js (not o4-moar branch) it uses is based on commit https://github.com/WebAssembly/binaryen/commit/da3bb2ffcc8a6efd6a95a07f7de793d1362f4a07 btw, not sure if this is relevant.. New commit: https://github.com/AssemblyScript/assemblyscript/commit/de4db0c7a1a40c7b3203f1c5879bb1d13722cf3e\nThis updates normal binaryen.js to https://github.com/WebAssembly/binaryen/commit/955a9a9440f26438ba50e35ebe57a86a5111d4a1 (before) and I recompiled the o4-moar build (after) with latest Emscripten. Looks very similar, though, but I am definitely seeing some br_tables in the text outputs (Edit: these might be just the hardcoded ones?). If that's still wrong somehow, my copy of the Binaryen repo with the o4-moar branch must be broken somehow I guess.. Just in case you are running something from the AssemblyScript branch, which you probably aren't, make sure to run npm run clean once to clear the outdated distribution files it will pick up otherwise.. Added a little test case that reproduces the br_table issue here: https://github.com/AssemblyScript/assemblyscript/commit/5d189398557a33c083ebd147c52091a7d0304f51. Happens with the o4-moar binaryen.js only, maybe it's useful?\nAnd this is my local branch that I built the second version of binaryen.js from, pushed to GH: https://github.com/dcodeIO/binaryen/tree/o4-moar - shows as even, hmm.. In this test case, it emits a br_table when using master but not when using o4-moar.. Yes it has 2 after other optimizations (maybe that's the issue?), but 5 before. To run this you can simply clone that branch and run node tests/binaryen/br_table-opt.js. That uses the binaryen.js build in lib/binaryen.js to run the code, which is the o4-moar one in the repo. Changing require('../../lib/binaryen') to require(\"binaryen\") uses master (requires npm install).. We can run any sequence of passes through Module#runPasses, though I hoped that we could avoid that for simplicity. Once we start running specific passes instead of relying on Binaryen to do the right thing, there's a lot we can do wrong but not reliably measure.\nIs there maybe a way for Binaryen to tell whether running rereloop makes sense for specific inputs?. Thanks for the ping! Updated the relevant local/global sections on the wiki.. Yep, essentially all the _s and _u instructions that currently have a trailing type. Is there any interest in renaming the c++/binaryen-c enums as well? (e.g. UnaryOp::ConvertUInt64ToFloat32 represents f32.convert_i64_u currently). Another way this could be done on our side is to mark each call that shall be inlined, instead of marking a function, if that would fit better.. I see, yeah. Considering that passes currently don't take any parameters (in the C and JS APIs), an alternative could be to keep a record of all calls that shall be inlined while constructing the IR normally (on our side), and once the module has been created, call something like BinaryenInline(moduleRef, callExprRef) for each call expression previously recorded for inlining. This way directed inlining could be performed before (and independently of) running any passes on a per-call basis while leaving bookkeeping to the user (nothing in wasm.h or anywhere else in Binaryen), plus the ability to return an error code or something per inlining operation. Once all inlining is complete and returned an OK status, the user could then remove the functions that are no longer necessary before optimizing. Wdyt?. > Why would an error code be necessary for the inliner?\nWas thinking in terms of trying to inline a function into itself or something like that, preventing it from being removed. Just a true/ false return from BinaryenInline is enough for my use case.\n\nAnd, why would the user need to remove functions that are no longer necessary\n\nIn our use case, that'd make sense when not running any passes and the user wants just the \"untouched\" output (i.e., \"remove-unsed-module-elements\" could remove other things as well). Up to the user ofc, could also just rely on the pass to do it.. Closing in favor of https://github.com/WebAssembly/binaryen/pull/1898. While trying this out I noticed that there is an issue with block names not being unique. That'll need a fix.. Overall this looks somewhat inefficient due to traversing the entire function body twice (replacing the call + making unique labels), hmm.... > What do you mean by \"creation time\" here?\nThe ideal API for my use case would be to simply call BinaryenCallInline(...) just as I would call BinaryenCall and it would inline the function in place. But that requires to have an actual Function already where we can add the additional locals to, but with the C-API you first build the body and then call BinaryenAddFunction with it, which then creates the function that we needed earlier to add locals to. Hence mentioning a builder-like API that would first create the function and then we'd add to its body, making something like this possible. Not sure how feasible this is, though, as it's quite some work for a quite specific need.\n\nWhat do you think about my suggestion from earlier to make the API \"force-inline function X\"\n\nYeah, that'd most likely make the most sense here. My thinking was that doing it on a per-call basis would make it as general as possible to cover all cases, even those we haven't thought about yet where a function is inlined only sometimes for example.\nUnfortunately, I just figured that there's another issue with doing inlining as an afterthought, that comes from not being able to precompute expressions that include an inlined helper (we use these like macros in C++), because precompute doesn't traverse into called functions (inlined bodies, as we did before manually, could simply be precomputed). This is pretty much a showstopper and I haven't yet come up with a solution.. So, I figured that we are relying on inlining so much, for example we need ad-hoc precompute on inlined code for our macros to work, that doing inlining after everything else actually raises more concerns than it solves. I made my peace with it now and improved this on our side. Hope that I didn't waste too much of your time, and thanks for helping me out, as always! :) [took a while for me to figure this out, sorry]. > That is, it seems like using this PR (or an improved version of it) to inline first thing, and then optimize, would get what you want?\nTo me it appears that the amount of work to implement what's necessary simply isn't worth it. Let me try to give an example:\nts\n@inline function GET_SIZE<T>(): usize {\n  if (isReference<T>()) return offsetof<T>();\n  return sizeof<T>();\n}\nThat's a simplified example of a macro (everything in its body is actually constant, T is always known and the inner calls are built-ins that emit constants) as I described earlier, which in our case has the (occasional) requirement to evaluate to a constant value when used as part of another expression as well. For example:\nts\nload<i32>(somePtr, GET_SIZE<f64>());\nHere, the second argument to the load<T> built-in becomes the explicit offset immediate of the emited load instruction, which must be fixed at compile-time as of WebAssembly's design. This makes it necessary to inline the function right away, because the precompute pass that we use to evaluate the argument doesn't traverse into calls for good reasons but is able to precompute inlined blocks. If we'd delay inlining of the call any longer, we wouldn't be able to compile the load call. As you can see, this is mostly something useful in our standard library, but not so important for user code.\nThat's why it appears to me that a BinaryenCallInline-ish API that'd inline immediately is the only proper solution to the issue, but would require a lot of work (can't inline while we don't have a function to inline into yet, as described above). Maybe, having a precompute pass that can traverse into functions independently of inlining (so we can delay inlining) might be another solution, but i haven't thought that through yet.. Closing this in favor of an eventual improved solution, that is if someone else or myself happens to have a fitting use case again. Thanks for all your feedback!. Would it be viable to make it an optional pass that a user must run explicitly? For instance, we have a discussion over at AssemblyScript to eventually add a compiler flag that emits deterministic code exclusively, but it seems that unless this flag is set, doing such optimizations would be fine.. I wonder if this pass would make sense in scenarios where the low unused memory region is significantly smaller? In AssemblyScript it's just 8 bytes for example, essentially only leaving some space for null / asm.js reinterpretations.. It's using immediate offsets where straight-forward, for example when accessing class instance fields, but there are some occasions where it isn't that easy, for example when doing indexed array accesses (due to the fact that these are actual operator overloaded functions where constant offset components become mutable locals, in turn losing \"precomputability\"). Can also imagine that, after other optimizations, even our \"proper\" loads might be condensable even more.. In AssemblyScript's (standard library) case that's always undefined behaviour, yeah. A user who's using load<T> directly might assume something else, of course, but to me it appears that we should rather document that than miss out on the optimizations.. Does this imply that a compiler that doesn't use LLVM/Emscripten won't be able to output a JS version (we don't care about valid asm.js, just something JS) with just Binaryen / BinaryenModulePrintAsmjs anymore? That'd be sad.. Not really bound to the external API, as long as it can either be run directly or easily postprocessed. A WebAssembly-ish API, similar to how Wasm works in browsers, would be great though :). Guess who borked it because it now doesn't parse anymore :)\nEdit: Reverted to the initially approved state. While updating this to use stack allocation, I noticed that other API functions doing it that way like\nc\nvoid BinaryenSIMDShuffleGetMask(BinaryenExpressionRef expr, uint8_t *mask) {\n  if (tracing) {\n    std::cout << \"  BinaryenSIMDShuffleGetMask(expressions[\" << expressions[expr] << \"]);\\n\";\n  }\n  ...\n}\ndon't mention the return value in tracing. Is this intended?. Trying out a few things. Going to revert if that doesn't work.. Ok, seems this is working, if I'm not missing something that is. Now also uses stack allocation for literals that previously relied on a temporary malloced buffer.. Might also need integration into the C-API I think. Also, would imagine that one situation where this comes in handy is specifying the low memory region for constant offset propagation added lately, which is a constant currently iirc.. Wondering if this needs integration with the C-API somehow, to specify which features are targeted by a generator.. FYI: It simply didn't compile without this change but I actually don't know if TrivialGlobalManager is the right type here.. For reference, this is where the C API breaks while JS does not, which is unfortunate of course, Though, I require this to emulate what teeLocal does for locals, but for globals. More precisely, I am using a typed block there that first performs a setGlobal followed by a getGlobal, which is the block's result, effectively doing the same (though not nearly thread-safe) as a teeGlobal instruction, if it'd exist.. I wasn't able to pinpoint it unfortunately. For what it's worth, I previously tried setting -s USE_PTHREADS=0 and -s NO_EXIT_RUNTIME=1, but compilation still resulted in the same issue, if that helps and if these flags are connected to the issue at all. Ultimately decided to put it in the main API entrypoint of both. wasm.js seems to assume that it is compiled with Emscripten, while binaryen-c can be compiled both as a C library as well as with Emscripten. These files are not included in the respective other library / tool.. What do you think about using -1 to explicitly force the previous behavior (if that is possible at all)? The JS wrapper could then also check for undefined as you suggested. If that's not possible, I'd of course be ok with dropping the old behavior - I actually didn't know about it, which is why I missed finalize.. To make sure, I also added TODO comments in my last commit referencing the PR.. For improved readability, it might be desirable to do this for all types in every traced function. That's some boring work, though, and I haven't yet managed to run the tests locally, so I decided not to touch this.. My use case here is that I am compiling a couple of functions (i.e. malloc etc.) from C first, then loading the resulting module into binaryen.js for further processing (adding more functions). Without BinaryenGetStructuralFunctionType (or how it'll be named finally, suggesting BinaryenGetFunctionTypeBySignature), there is no way to obtain a reference to any of the existing signatures (even if I know their types exactly, or their names even when these become 0, 1, etc. after compilation without -g), and I had to create a duplicate signature instead. This is somewhat related to the optimizer not yet merging / removing unused signatures.. Just copied this from the respective add function to make sure that I don't accidentally break something. I'm not super experienced in C++, so I am just super cautious most of the time. Going to rename it.. Sure, but the problem would remain if the optimizer wasn't part of the plan, i.e. because the user actually intends to keep unused functions so these can be used in the next build step (i.e. after linking something else). That's related to the only options there are either use the optimizer with default options or don't use the optimizer at all when using binaryen.js.\nRegarding the optimization pass: If you could add this that'd be great, as it will solve other issues I have here with signatures being still present after optimization.\nI personally felt that adding GetFunctionType (or GetStructuralFunctionType, or GetFunctionTypeBySignature), using pretty much the same parameters as AddFunctionType, would make a good API addition especially because it doesn't require a shift in the way how to obtain an existing function type when a user already knows how to add one.. My issue is just that I am already using this functionality, but you are right, it's mostly because of the lack of an alternative. What if we'd add this for now, with a name different than GetFunctionType as you suggested, and I add a comment that it is subject to be removed again once a better alternative is in place? Unfortunately, I haven't yet obtained the understanding how to return actual data, instead of just a pointer which is what most of the code currently does, to JS. Otherwise, I'd of course love to contribute something better than that.\nRegarding the first paragraph: Somewhat, I am fine with the default optimizations within my exact use case. It's just as you said, there is no better alternative yet.. Changed this initially just to put everything into a closure. Now that a.js is instrumented instead of the production build and the Binaryen global exposed conditionally, it's actually necessary.. The way it works now is:\n\nCheck if binaryen.js is run in a CommonJS context. If so, export Module\nCheck if binaryen.js is run in an AMD context. If so, define a factory method that returns Module\nOtherwise, expose Module as the global var 'Binaryen' respecting various possible names of the global object.\n\nThe reason why the additional line is necessary in check.py is that the generated a.js is run inside of a CommonJS context, but not used like that (it is not require-d, a.js is non-standard) because the tests are just concatenated. That's merely a special case of the test suite making the additional line necessary, but it is not a real world use case (this line is not necessary anywhere else, just in a.js). Doing so eliminates the need to add non-standard code to the distribution, as you suggested earlier.. Can try. This depends on whether there is a require function with file system access in 'MozJS', respectively what else is the intended way to load stand-alone CommonJS modules there. If that's possible, a.js could just var Binaryen = require(\"./bin/binaryen.js\"); the distribution instead of copying its contents.. For clarity purposes, and to avoid similar uncertainties in the future, it might help to have i.e. \"e1.37.20\" emscripten tags and \"v37.0.0\" for actual release tags or something like that. At least that'd make it a bit clearer and sticks, at least for release tags, to what's commonly used as tag names.. is this correct?. Idea here is to have a simple way to iterate over all function types (by calling this function with 0, 1, etc. until it returns NULL) and then being able to use the getters and setters below to evaluate and maybe modify them. Could be used, for example, when loading an existing module with the intention to unify function type names to combinations of \"i\", \"I\", \"f\", \"F\" and \"v\" in their debug info.. Sure, going to split it up then - and taking the array idea into account.. Yeah, though about this as well. Could do either, or both. Ultimately, when thinking about it, one thing that came to my mind was to return instances of a new class  Expression, holding a BinaryenExpressionRef, with these expression methods, including print. That'd be quite similar to Module and Relooper, somewhat connected to #1273 and not yet doable without other functions working with references (i.e. could do that for everything, like Globals, Functions, FunctionTypes ...).. I don't have a clear preference there because I have switched to using the C-API directly from both JS and WASM, hoping that it becomes interchangeable eventually (see). Not sure if that's an option for upstream as well in the long them, i.e. by making the wrapper just an npm package instead of compiling it in (generating just the raw C-API compiled to both JS and WASM that'd become a lower-level dependency for wrappers, in whatever JS-dialect, to utilize).. Yeah, from a performance perspective it might be better to stick to expression references. Considering performance, it might also be better to use real prototypes instead of assigning instance methods through this['emitText'] = etc. as well (haven't benchmarked, probably irrelevant as long as just one or two modules are created).\nMy idea above was (sorry, updated the links to point to the public repo) to provide just the bare minimum (the raw C-API compiled to JS/WASM) by WebAssembly/binaryen, leaving the respective wrappers, like one using just references or one using classes for everything, up to external modules because there might be more than one wrapper in JS-space anyway, looking at all the languages that transpile to it. For instance, I am using just the static Module exports in the links above, but not the wrapper functions/classes. Just a random thought, of course.. Might be that my requirements are a bit different. Basically, I am speculating on the feasibility of compiling Binaryen to WASM one day, and then being able to simply switch between the two (either calling from JS or linking into a WASM module) with the only common denominator being the raw C-API. In the AssemblyScript case this makes even more sense because the higher level wrapper (2nd link) can be shared between TS and AS as well.\nRegarding just providing a minimal API: As I know the crazy people doing npm, there'd probably be multiple wrappers around in a week or two, each focusing on other things (i.e. one being entirely class-based, one being just a few helpers to the C-API and another being written in CoffeScript or something). Not super important, though, because binaryen.js, as it stands, still exposes the underlying raw C-API. Just thinking aloud :). Wasn't sure if there might be additional atomic ops in the future, besides rmw. Other than that, we'd also have to repeat the { 'rmw': ... } four times below then - or did you mean to remove the rmw subsection entirely?. I see, thanks. This could be done for other functions as well. Though, the updated commit now uses the usual format similar to the other functions. Suggesting to leave the refactoring for another PR.. test_ids() is relatively new (from #1269). Looks like I skipped DropId when it was initially created :(\nSometimes I am editing the tests by hand because I can't run them on Windows without spinning up a VM. Makes me feel guilty.. Not yet because, unlike BinaryenFunctionOptimize, BinaryenRemoveFunction expects a name, not a reference. What I'm trying to establish, though, is using names in BinaryenAddSomething-style functions, and Something-references in BinaryenSomethingAdd-style ones. Here, that'd be BinaryenFunctionRemove (note: doesn't fit well to the C++ API because wasm->removeFunction expects a name).. I believe no matter how we do it, the API will remain unnecessarily complex unless (here) imports and exports inherit their function or global type from the respective internal element. I know that they don't for a good reason, that is everything remains independent of each other, but API-wise.... When doing the reverse, that is optionally resolving a reference to its name everywhere, we'll end up decoding and encoding even more strings :(. That is, for example, having BinaryenAddFunctionImport for function imports and BinaryenAddExport(..., BinaryenExternalKind) for function exports - or otherwise not-so-useful but symmetrically named functions. All this boils down to imports requiring a kind, a variable type for globals respectively a function type for functions or nothing at all for everything else. If that wouldn't be necessary (here; instead inherited from the linked internal element), we could just do a uniform AddImport/AddExport without worrying about these details in the API.. Sorry, just thinking about how to do it.\n\n\nCurrent state of this PR: One Add*Import for each element and one Add*Export for each element, with some import types taking specific parameters (i.e. functionType, globalType). No ExternalKinds to specify anywhere.\n\n\nOne Add*Import for each element with some imports taking specific parameters (i.e. functionType for Function imports, type for Global imports), but just one AddExport taking an ExternalKind, making parameters somewhat asymmetric. If I understand correctly, that corresponds to your initial comment.\n\n\nIf some Imports wouldn't need functionType or type, we could just make a single AddImport taking an ExternalKind, just like for AddExport. Not sure if that can be implemented within the internal API or if it could otherwise be emulated in just the C-API, but that's basically what I tried and obviously failed to elaborate on.\n\n\nTL;DR Not sure what's best either.. Might it make sense to test for the inverse as well, i.e., the constant in left and the condition in right?. I see, didn't know that. How little I know after all :). This makes me sad.. RunPasses has the disadvantage that one has to know exactly which passes are available in the current version of the API. It also seemed to me that some passes do different things depending on the actual levels?\nIn this case, all of Optimize, RunPasses, OptimizeFunction and RunPassesOnFunction would need such a variant with more params.. Possibly not when you are asking. Though, previously, the global var was a singleton instance (through concatenation of Binaryen = Binaryen()) while module loaders received a factory function. My intention here was to make sure that module loaders receive the singleton instance as well so it's consistent and backwards-compatible until something else is in place.. Assumption here is that, in spidermonkey, there isn't a global module or exports so that the last case of the module loader sets up a global, just like in a browser\njs\nelse\n  (typeof self !== \"undefined\" ? self : this)['Binaryen'] = instantiate();\nand the workaround is skipped (condition is false).\njs\nif (typeof module === \"object\" && typeof exports === \"object\")\n  Binaryen = module.exports;\nBut I agree, that should also be tested.. That was my first thought as well but then I discovered that tools/optimization-options.h has a dependency on Options in support/command-line.h which felt wrong to include.. changed this to evaluate the keys because output differs in node (looks like Instance { exports: ... }). that's because the names section isn't generated by default now. Sure, is fine for me either way.. Currently the defaults are in support/defaults.h, which is then included in binaryen-c.h and tools/optimization-options.h. I'd probably just move them then, so it might be better when you'll take a look.. This functionality is lost because the factory function is named Binaryen that also has a local named Binaryen. Thus, the function cannot be referenced anymore (arguments.callee is prohibited in ES5 strict mode).\njs\nvar Binaryen = function(Binaryen) {\n  Binaryen = Binaryen || {};\nThat's not a problem, though, and it might be better to incorporate MyModuleInstance.instantiate into MODULARIZE_INSTANCE in a WASM-compatible way, if at all.. Not sure what happened there that it looked like\nc\n getExpressionInfo(f64.const)={\"id\":15,\"type\":4,\"value\":9.5}\n   {\n], expressions[160], expressions[163], expressions[166] ...\nbut it's correct now. As if any part of the output contained control characters or something.\nEdit: Ah, I see you already dealt with it here. Hmm, one of the Travis jobs failed (7207.5) with exactly this while others worked. Seems this appears randomly, which is bad.. Nooo, not again. Just automatic line trimming in my IDE, and I always forget :). Quoting here prevents issues when running bash on Windows, where paths might contain white spaces.. Without, there is a warning when running binaryen-wasm.js. Is that correct?. I tried, but it wasn't defined already at this point.. Let me double check. You are right, this must have been caused by something else.. Just checked again without a minifier. Appears pre-js goes right after if (!Module) Module = typeof Binaryen !== 'undefined' ? Binaryen : {}; (starts at line 21) while ENVIRONMENT_IS_NODE is defined a bit later (line 63).\n```js\nvar Binaryen = function(Binaryen) {\n  Binaryen = Binaryen || {};\n// The Module object: Our interface to the outside world. We import\n// and export values on it. There are various ways Module can be used:\n// 1. Not defined. We create it here\n// 2. A function parameter, function(Module) { ..generated code.. }\n// 3. pre-run appended it, var Module = {}; ..generated code..\n// 4. External script tag defines var Module.\n// We need to check if Module already exists (e.g. case 3 above).\n// Substitution will be replaced with actual code on later stage of the build,\n// this way Closure Compiler will not mangle it (e.g. case 4. above).\n// Note that if you want to run closure, and also to use Module\n// after the generated code, you will need to define   var Module = {};\n// before the code. Then that object will be used in the code, and you\n// can continue to use Module afterwards as well.\n// if (!Module)is crucial for Closure Compiler here as it will otherwise replace everyModule` occurrence with a string\nvar Module;\nif (!Module) Module = typeof Binaryen !== 'undefined' ? Binaryen : {};\n// --pre-jses are emitted after the Module integration code, so that they can\n// refer to Module (if they choose; they can also define Module)\n// Make sure node is able to find the .wasm next to the .js file. Only relevant\n// when building binaryen-wasm.js (not used for binaryen.js currently).\nif (\n  typeof process === 'object' && typeof require === 'function' && // IS_NODE\n  typeof window !== 'object' &&                                   // !IS_WEB\n  typeof importScripts !== 'function'                             // !IS_WORKER\n) {\n  Module['locateFile'] = function(file) {\n    var nodePath = require('path');\n    return nodePath.join(__dirname, file);\n  };\n}\n// Sometimes an existing Module object exists with properties\n// meant to overwrite the default module functionality. Here\n// we collect those properties and reapply after we configure\n// the current environment's defaults to avoid having to be so\n// defensive during initialization.\nvar moduleOverrides = {};\nvar key;\nfor (key in Module) {\n  if (Module.hasOwnProperty(key)) {\n    moduleOverrides[key] = Module[key];\n  }\n}\nModule['arguments'] = [];\nModule['thisProgram'] = './this.program';\nModule['quit'] = function(status, toThrow) {\n  throw toThrow;\n};\nModule['preRun'] = [];\nModule['postRun'] = [];\n// The environment setup code below is customized to use Module.\n//  Environment setup code \nvar ENVIRONMENT_IS_WEB = false;\nvar ENVIRONMENT_IS_WORKER = false;\nvar ENVIRONMENT_IS_NODE = false;\nvar ENVIRONMENT_IS_SHELL = false;\n...\n``\nThat's [here](https://github.com/kripken/emscripten/blob/incoming/src/shell.js#L26) and [here](https://github.com/kripken/emscripten/blob/incoming/src/shell.js#L53).. The current dir is the project's base directory, wherea.jswas generated before, which wasn't that great either. Hence, a temp directory sounds ideal, will take a look.. Would it make sense to move just theENVIRONMENT_IS_XYdefinitions up so pre-js can use/modify them? Could create a PR for this if it makes sense.. See: https://github.com/kripken/emscripten/pull/6137. I just reused what's done forBinaryenLiteral[here](https://github.com/dcodeIO/binaryen/blob/c7bc4cf99a62f3357138880b4e9ba97f13536844/src/js/binaryen.js-post.js#L285), which is also a returned struct, above, and reused its temporary buffer. I actually don't know how exactly this works :). It's actually exactly howoutput` works (seen from the JS-side), just with two such buffers. What's done there is that the user pre-allocates a buffer or two on the JS side and provides their pointers including their maximum length. The function then returns the number of bytes written so that the JS side can trim the buffer, and in this specific case it has to return two (hence the struct).\nThere is a FIXME on the JS side because these buffers are currently capped to 1MB. I guess if we solve this one, the API might change anyway. From JS perspective, it would be ideal not to pre-allocate anything and just receive a properly sized buffer incl. its length from the function. With the ABI stuff, that'd look like\nc\nstruct {\n  void* buffer;\n  size_t bufferSize;\n}\nor something, and I don't currently have a better idea (can't use passing by reference from JS for example, except there's also an ABI for that?). Any idea?. Maybe, if we could write just the source map without having to also write the binary, we could split that, making it two functions that return just size_t. Might require some changes to the binary writer, though, as source map generation is currently piggybacked on top of writing a binary (what about a specific sourcemap writer?). Wouldn't fix the hard-wired limit, though.. MSVC emitted a warning (C4800) there, converting an int to a bool. Not sure why.. BinaryenModuleAllocateAndWrite seems good. Thanks, on != 0 is what I used now.. Sure, going to add one!. The warning was C4018: \">=\": signed/unsigned mismatch, presumably due to integer promotion on the rhs. thought so :) the warning here was C4065: switch statement contains 'default' but no 'case' labels. Also added the CDNs to the README on the bot now, in case you'd prefer linking to that: https://github.com/AssemblyScript/binaryen.js#usage-with-a-cdn. Ah, right, made it so that there's a mutable and a constant global for each one.. What did happen here?. I see. What about \"optimize-stack-ir\", should this pass be run as well?. Currently, the PR does just 2., but I also like 1. for simplicitly, going to add this :). Decided to go with an additional optimize parameter on the function because it's otherwise the same, hope that's ok :) Also added a test.. I actually use this functionality with the old constructor to wrap a C-style reference in a JS-style module, because the compiler uses the C-API so it can cross-compile to JS and WASM. Can we either keep the old API or expose this helper?. Thanks :). Thanks, missed that there's already code doing it this way. Updated accordingly!. I'm not overly familiar with this, but from what I've read setw affects the next output operation only. While setfill doesn't seem to be used anywhere else, saving and then resetting it might be good practice though.. Yeah, this relates to https://github.com/WebAssembly/binaryen/blob/master/src/binaryen-c.cpp#L2632 respectively https://github.com/WebAssembly/binaryen/blob/master/src/binaryen-c.h#L822. makes sense, changed it :). ",
    "MichaReiser": "\nI think the example output might be missing the set_local in the if?\n\nOh.. and I tried so hard to get it right! Yes, indeed.\n\nOverall it looks like if this doesn't change code size, then it replaces a set of a local with a branch. \n\nI am more interested in runtime than code size so I never looked at it. But I think code size should be reduced if multiple succeeding assignments can be collapsed into a single if block. But I can try to measure it with the unit test cases.\n\nConsidering performance, I'm not sure how to read those figures? Is the JS line a pure handwritten JS implementation? And what are the colored bars versus the x's?\n\nThe chart is from my project speedy.js. So the JS line is the baseline and equals the runtime of an equivalent JavaScript implementation. The colored bars show the speedup of the WASM code generated by my compiler compared to JS. The x's are the relative speedup of a C++ implementation (Emscripten) with the same result. \nWhich benchmark do you mean? The embenchen or Massive? Is there any documentation how to run these benchmarks?\nAbout emitting. I agree. It even might have a negative impact on other optimization passes like loop vectorization. But I think such an optimization pass is worth it as long as the VMs do not provide this kind of optimization. One thing I expect of WASM is to have a predictable performance across browsers. So, either the browsers are intelligent enough, or we help them a little to make them look as they are ;)\nAnyway. I intentionally made it a nondefault optimization pass that can be enabled by interest. . @jfbastien I am now a proud member of the WASM community group. ",
    "Alexander1994": "Sigh, I can no longer replicate it. The code works just fine. Should probably just close it. I tried all yesterday to get that code to work but it always crashed when the loop went on for a certain period of time then encountered the delete statement. I am rewritting that part of my codebase anyways. It just looked like a pretty big bug to me.. ",
    "sanyabeast": "me too. plz help. ",
    "meta221": "Thank you very much. I compiled wasm/libc.bc using Emscripten's new WebAssembly backend and it did work.\nAlthough shouldn't every output of llc when it is targeting the \"wasm32\" architecture be valid for s2wasm to consume?. ",
    "RangerMauve": "Having it on NPM is a really good idea since it'll make it easier for people using JS to make tools with binaryen. Is there anything I could do to help with the effort of automating the publishes?. Would it be possible to add it to this repo as a PR instead? Then it could run whenever a git release passes. I think the question I'd have for @kripken is what the current process is for tagging releases on github.\nIt might be that it'd be easy enough to get this thing on npm without having to set up any fancy travis scripts.\nYou could add a package.json with main pointing to bin/binaryen.js and copy over the index.d.ts (maybe rename to binaryen.d.ts) file from @dcodeIO's repo and add that to the package.json.\nThen anybody with access to npm could publish manually when a release is being made. I'm not seeing anything super fancy for tagging github releases, so I'm not sure if it's worth over-engineering the npm releases yet.. Does travis allow docker images? It'd make sense to build a docker image with all the tools that are required and then re-use that as a basis for the image used to run tests or build the JS bundle.\nThat way the image could be built on a dev machine instead of having travis do it.. Seems that might be viable: https://docs.travis-ci.com/user/docker/. Somebody has already set up docker images with emscripten installed. Do these look like they'd work for this use-case? https://github.com/apiaryio/emscripten-docker. In Rust-land there's a crate called stdweb which is adding interop with browser APIs, and yew which is adding a react-like interface with the DOM for WASM applications in Rust.. ",
    "hgarrereyn": "I'm got exactly the same error trying to build on OSX 10.11.6 with the same clang version as above.\nI fixed it by building with homebrew clang instead of Apple clang:\nbrew install llvm --with-clang --with-asan\nIt installed:\n$ /usr/local/opt/llvm/bin/clang++ -v\nclang version 4.0.0 (tags/RELEASE_400/final)\nTarget: x86_64-apple-darwin15.6.0\nThread model: posix\nInstalledDir: /usr/local/opt/llvm/bin\nThen in CMakeCache.txt I changed:\nCMAKE_CXX_COMPILER:FILEPATH=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++\nto\nCMAKE_CXX_COMPILER:FILEPATH=/usr/local/opt/llvm/bin/clang++\nand make worked without errors.. ",
    "kgryte": "I am also running into this issue on macOS (OS X Yosemite 10.10.5).. @juj regarding the OS X side of things, I believe you have two counterexamples in this thread of people who are not running the latest macOS.. ",
    "jaredonline": "For anyone else coming to this thread, after upgrading to macOS Serria I had to then delete \n.emscripten_cache/\n.emscripten_cache.lock  \n.emscripten_ports/\nFrom my home directory, otherwise I got a bunch of errors about missing header files like\nRelooper.h:25:10: fatal error: 'assert.h' file not found\nOnce I did that I was able to compile easy-peasy.. ",
    "hugotox": "I have the same problem with xcode 8.3.3 on sierra. @hgarrereyn could you please elaborate how to install? What do you mean  by building with homebrew clang instead of Apple clang and where is CMakeCache.txt?. ",
    "darko20": "Do this:\nbrew install llvm --with-clang --with-asan\nthen in the root directory of the binaryen source distribution, do this (on one line):\ncmake . -DCMAKE_C_COMPILER=/usr/local/opt/llvm/bin/clang -DCMAKE_CXX_COMPILER=/usr/local/opt/llvm/bin/clang++\nthen \nmake\nthen\nmake install\nWorked for me on macOS 10.11.4. ",
    "zabesto": "Warning: llvm: this formula has no --with-asan option so it will be ignored!\nWarning: llvm: this formula has no --with-clang option so it will be ignored!. ",
    "langongjin": "Thanks all, it solved by updated my Mac system and Xcode. My clang++ was working for c++11, but maybe not good incompatible for \"thread-local\". I think the only thing need to do is update xcode (if there are some problem for update xcode, we have to update the Mac system first) if somebody have the same issue. Thanks all again!. ",
    "sbc100": "I ran ./check.py add in reported success. Ended up having to add a WASM_NORETURN to make this work.  What do you think?. Perhaps wasm_unreachable should become a function and move into a .c file?. I see.  I guess Fatal() is better for the case I was trying to fix.  I'll close this for not.   (FWIW llvm_unreachable does log before it exits but its used in a lot more places I think).. I think so yes. @binji ?. Yes, looks like this, along with a bunch of other changes landed here: https://github.com/WebAssembly/spec/pull/471 in the spec.\nThis change, along with one other change to allow alternative syntax for 'loop' signatures seems to enough to allow s2wasm output to be handled by wastwasm.. OK I made the more comprehensive change.   Tests seems to pass.  PTAL.. @jgravelle-google this change should help green the waterfall.. Refactored.. The C and C++ compiler are independently settable.   I always set both of them when calling cmake.  .\nFor C++ projects setting the C compiler should have no effect as you suggest.  But it looks like we use 'dummy.c' to test for features at cmake time.     If binaryen really has no C files in it then a better fix might simply be to never set CMAKE_C_FLAGS, or perhaps to use dummy.cc for feature testings?   But presumably there is a chance some .c code might be part of binaryen in the future (was there C API in works?) so this fix might be the best one.  . Adding C++-only flags to CMAKE_C_FLAGS is fundamentally the problem although there are several solutions.. Strange.  Sorry I didn't realize this file was actually used outside of the wasm waterfall.  Will revert.. Perhaps its worth upgrading the minimum requirements to Xenial (the latest ubuntu LTS)?. Done. As a followup it should be possible to use to the command line to select which test(s) to run. Github has done a terribel job of formatting this change..  It mostly just indentation changes.. I agree although I think its preferable to be in control of when we choose to update rather than having travis start failing for an external reason.. \nemcc-llvm-backend-output.s.old.txt\nemcc-llvm-backend-output.s.new.txt\n. This happens when you link object files that contain the same local (static) function names.   I believe llvm-link already does this exact thing, so it not a problem there, but with lld we simply allow multiple functions with the same name (this is also what native ELF tools do).. Oh yeah,  I ben's idea.    Then we could see how different the style is to what exists today.  it would be good to choose a style based on what the code looks like today.. This change just effects what clang-format does when run in this directory.\nIt doesn't do any enforcement.  Which is probably a good thing initially I guess.. Maybe you can just evaluate them locally, and upload branches for just the one or two configs that you find to have the minimal impact?. Basically yes.   As a first step we can ask people to run git clang-format origin/master on PRs. which only formats the lines they touch.\nIf you want to do a bulk reformat you just run clang-format (probably with -i for inplace since you are in a git checkout).\n. Oh me too ... please make sure we have IndentCaseLabels: true.  I find it crazy that llvm doesn't do this.. I don't see that much benefit to having git blame drive the clang-format.   The problem with the reformatting IMHO is that it adds the extra commit so don't immediately see the last change to a given line.  Preserving the author doesn't really buy much when you looking back the history, you really want to see the change itself.. at least not in my experience.. Clang-format can be run on specific lines, right?  (that is how git clang-format works) .  So I think it is mostly likely possible to pipe the line numbers from blame into clang-format..  I'm only doubting the benefits.. I wasn't expressing an option about reformatting the whole code, vs letting it happen organically.  \nI'm was just saying that if you are going to reformat the whole codebase its best to do it in one big commit, rather then trying to slice it up based on the author of a given line.. On linux systems it seems to be packaged (e.g. sudo apt-get install clang-tidy). Is it worth having Travis do out-of-tree builds to avoid regressing here?   I figure if we test out-of-tree, its unlikely that in-tree will break, whereas the inverse is less true.. PR title staill says \".was\".  Otherwise lgtm.. Do you know it was was clang-tidy or clang-format that introduced the bugs.\nMy understanding of clang-format at least is that this should be impossible.   Not sure thats true of clang-tidy which I guess can do more complex transforms.   If it was clang-format that did it, its probably worth filing a bug.. Done. PTAL.. I see.  Is jsifier.js able to somehow export a function from wasm that wan't exported at link time?  I guess it could use some kind of binaryen tool to do this?    I will take another look and also run more tests as suggest.. Both other.test_warn_undefined and other.test_circular_libs continue to pass after this change with llvm backend.\nThey both fail with lld but thats a different story.. Is this OK to land?\nI guess we can followup by looking that the uses of implementedFunctions, and removing some redundant code.\n. Test with llvm backend everything passes in ./tests/runner.py binaryen2\nAlso tested with EMCC_EXPERIMENTAL_USE_LLD=1  ./tests/runner.py binaryen2 and the failures went from FAILED (failures=6, errors=66) to FAILED (failures=3, errors=18). This code does rely on the specific order of visito: visitImport -> visitTable -> visitCallImport -> visitModule.  Is that a reasonable assumption, or should I instead made several passes that run in sequence?  @kripken ?. Oh, actually I guess I only depend on the imports coming first.  . Good question. I was mostly moving it because it just seems like the right place.\nLooking at the docs:\nIf before_install, install or before_script return a non-zero exit code, the build is errored and stops immediately.\nIf script returns a non-zero exit code, the build is failed, but continues to run before being marked as failed. \nSo it looks like things in before_script that fail are considered more like infra failures (e.g. failed to install stuff).. Yes but there are files in that directory:\n$ git ls-files bin/\nbin/binaryen.js\nbin/wasm.js. Sadly this is just how travis works.. each of the \"scripts\" runes independently, and if any one of them fails then the whole thing is considered to have failed, but it doesn't stop at the first failure.\nThere are probably ways around this.  I'll give it a go.. So this kind of bug won't creep in again: https://github.com/WebAssembly/binaryen/issues/1568. I am trying to add another config.  The original config is building in the source tree still.  At least that is my intention.. Fixed in #1569. @alexcrichton, does this seems reasonable?. I'm generally against keeping generated files under source control.    But I suppose in this case these files are not wholly reconstructible based on binaryen and its submodules?   i.e They are not that easy to rebuild exactly because their exact contents depends on the whole emscripten SDK, right?\nCan travis/circle build and publish these to github releases?  Maybe they already do?. Probably worth holding off landing this for a week or two... Also removed all the .s files!  . It seems that this change broke an test on the wasm waterfall: binaryen2.test_float_builtins\nhttps://logs.chromium.org/v/?s=chromium%2Fbb%2Fclient.wasm.llvm%2Flinux%2F35628%2F%2B%2Frecipes%2Fsteps%2FExecute_emscripten_testsuite__emwasm_%2F0%2Fstdout\n. Do you still want to land this?\nI'd would like to see mutable global support in binaryen.  . I think this should be covered now by #1785  and . Oops: https://github.com/WebAssembly/binaryen/pull/1656. Do we have testing code for source maps? Is it worth adding this case?  Otherwise lgtm. Its hard for me to remember why I I originally marked this as fatal.   If this fixes the issue then lgtm I guess. Hmm.. I wonder if that escaping change is going to have other effect on this invoke renaming.. I think this broke a couple of tests on the wasm waterfall:\ne.g. ./tests/runner.py other.test_override_environment (with LLVM set to upstream)\nSee https://logs.chromium.org/v/?s=chromium%2Fbb%2Fclient.wasm.llvm%2Flinux%2F35770%2F%2B%2Frecipes%2Fsteps%2FExecute_emscripten_testsuite__emwasm_%2F0%2Fstdout\nLooks like 3 test a failing due to wasm-emscripten-finalize is segfaulting. Thanks for tracking that down!. I guess it depends if you consider setTempRet0/getTempRet0 part of the JS interface?  I think perhaps they are since they used for 64-bit returns and emscripten-specific sjlj handling.  If you really know what you are doing you can also just implement your own versions of these functions however you like.. I had to retrain a bunch of tests.  Could you take another look and make sure this looks sensible.\n. Closing in favor of https://github.com/WebAssembly/binaryen/pull/1709. I feel like for your solution to work you would need to tell binaryen if\nyou were building a dll or not.  Since I in the dll case you must always\nimport these.\nI think I like this solution.  Creating new imports for of these functions\nseems ok even none emscripten users no?  Implementing these functions\nshould be easy enough for none emscripten users too.\nOn Thu, Oct 18, 2018, 18:21 Alon Zakai <notifications@github.com wrote:\n\n(Of if you prefer to work on it that's fine with me too, of course.)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/1709#issuecomment-431072892,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAfe5eiy7fzlMoUl0gbPIgc_r4zROFS2ks5umKp4gaJpZM4XtAmF\n.\n. Ok, I see what you mean.   I was thinking we could leave them in extras.c so in this case the would be already implemented in the wasm module. \n\nHowever, I think you are right, keeping them out of the main asm/wasm module in all cases is probably simpler.  At least assuming that works.\nI guess this will need to be multi-faceted change then across many repos.    Does fastcomp not already use the imported versions of these functions?. OK, I think I agree we should alwasy import them.  However, for this initial change I'd prefer to allow them to continue to optionally exist in the module.  If I remove this possibility we would need to regenerate (or otherwise modify) as lot of input asm.js test files.   Maybe we could do that as a followup once all the different changes have landed?. My initial fix is to use _exit() or abort() rather that exit().   A better long term solution is probably to try to handle errors more gracefully, or maybe switch to using a C++ exception. Definitely in favor of have full case coverage rather than default, in order to have the compiler help you out when you add new cases. \nThis is what llvm (or at lld) tries to do.    The LLVM_UNREADABLE after the switch is needed to gcc and not clang sadly so it important to remember to build with gcc as well as clang.. I think this change broke my build:\n$ ninja -C ../binaryen-out install\nninja: Entering directory `../binaryen-out'\n[3/40] Building CXX object CMakeFiles/wasm-shell.dir/src/tools/wasm-shell.cpp.o\nFAILED: CMakeFiles/wasm-shell.dir/src/tools/wasm-shell.cpp.o \n/usr/local/google/home/sbc/dev/chromium/src/third_party/llvm-build/Release+Asserts/bin/clang++   -I/usr/local/google/home/sbc/dev/wasm/binaryen/src -std=c++11 -Wall -Werror -Wextra -Wno-unused-parameter -fno-omit-frame-pointer -Wswitch -fPIC -fcolor-diagnostics -g -O0 -g3   -std=gnu++11 -MD -MT CMakeFiles/wasm-shell.dir/src/tools/wasm-shell.cpp.o -MF CMakeFiles/wasm-shell.dir/src/tools/wasm-shell.cpp.o.d -o CMakeFiles/wasm-shell.dir/src/tools/wasm-shell.cpp.o -c /usr/local/google/home/sbc/dev/wasm/binaryen/src/tools/wasm-shell.cpp\nIn file included from /usr/local/google/home/sbc/dev/wasm/binaryen/src/tools/wasm-shell.cpp:23:\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/8.0.1/../../../../include/c++/8.0.1/memory:80:\n/usr/lib/gcc/x86_64-linux-gnu/8.0.1/../../../../include/c++/8.0.1/bits/unique_ptr.h:81:2: error: delete called on non-final 'wasm::ShellExternalInterface' that has virtual functions but non-virtual destructor [-Werror,-Wdelete-non-virtual-dtor]\n        delete __ptr;\n        ^\n/usr/lib/gcc/x86_64-linux-gnu/8.0.1/../../../../include/c++/8.0.1/bits/unique_ptr.h:274:4: note: in instantiation of member function 'std::default_delete<wasm::ShellExternalInterface>::operator()' requested here\n          get_deleter()(__ptr);\n          ^\n/usr/local/google/home/sbc/dev/wasm/binaryen/src/tools/wasm-shell.cpp:96:26: note: in instantiation of member function 'std::unique_ptr<wasm::ShellExternalInterface, std::default_delete<wasm::ShellExternalInterface> >::~unique_ptr' requested here\n    auto tempInterface = wasm::make_unique<ShellExternalInterface>(); // prefix make_unique to work around visual studio bugs\n                         ^\n1 error generated.\n[25/40] Building CXX object CMakeFiles/binaryen.dir/src/binaryen-c.cpp.o\nninja: build stopped: subcommand failed.. I think we should leave the linking section, otherwise the wasm object becomes basically useless as a linker input.\nHaving said that I think that I think that running the module through binaryen (i.e. modifying the code offsets) already breaks this information no?   Is binaryen capable of recreating/updating the reloc and linking sections?  If not then we probably should remove them in all cases since they will be inaccurate  otherwise.. In general this information should already be stripped by lld if it is run with the corresponding flags:\n--strip-all            Strip all symbols\n  --strip-debug          Strip debugging information\nNo harm in adding these flang to binaryen too I suppose, but we probably want to put them on lld to save time there too if we don't want this info.. We do.. but I'm running into another place where I need to handle this and I thought \"why do we keep having to deal with this, isnt' this exactly what wasm-emscripten-finalize is for\".\nThere is also at least once place where emscripten want to distinguish between \"user-space\" functions, and it uses this as a kind of namespace.\nIts not super important, we could cotninue to handle both in emscripten... I think I'm gonna hold off on this, at least for now.. Somehow this broke emscripten:\nhttps://logs.chromium.org/logs/chromium/bb/client.wasm.llvm/linux/37756/+/recipes/steps/emscripten__emwasm_/0/stdout\nemscripten:INFO: generating system library: libcxx.a... (this will be cached in \"/home/chrome-bot/.emscripten_cache/wasm_bc/libcxx.a\" for subsequent builds)\nemscripten:INFO:  - ok\nemscripten:INFO: generating system library: libcxxabi.bc... (this will be cached in \"/home/chrome-bot/.emscripten_cache/wasm_bc/libcxxabi.bc\" for subsequent builds)\nemscripten:INFO:  - ok\nFatal: Module::getFunction: $__invoke_%\\22class.std::__2::basic_ostream<char.std::__2::char_traits<char>>::sentry\\22*_%\\22class.std::__2::basic_ostream<char.std::__2::char_traits<char>>::sentry\\22* does not exist\nshared:ERROR: '/b/build/slave/linux/build/src/src/work/wasm-install/bin/wasm-emscripten-finalize /tmp/tmpQoo4PD/out.wasm -o /tmp/tmpQoo4PD/out.wasm.o.wasm --global-base=1024 --emscripten-reserved-function-pointers=0' failed (1)\nTraceback (most recent call last):\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/embuilder.py\", line 288, in <module>\n    sys.exit(main())\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/embuilder.py\", line 195, in main\n    build(CXX_WITH_STDLIB, ['libcxx.a'], ['-s', 'DISABLE_EXCEPTION_CATCHING=0'])\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/embuilder.py\", line 119, in build\n    shared.Building.emcc(cpp, args, output_filename=temp_js)\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/tools/shared.py\", line 2201, in emcc\n    run_process([PYTHON, EMCC, filename] + args + ['-o', output_filename], stdout=stdout, stderr=stderr, env=env)\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/tools/shared.py\", line 169, in run_process\n    return run_base(cmd, universal_newlines=universal_newlines, check=check, *args, **kw)\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/tools/shared.py\", line 164, in run_base\n    result.check_returncode()\n  File \"/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/tools/shared.py\", line 150, in check_returncode\n    raise Py2CalledProcessError(returncode=self.returncode, cmd=self.args, output=self.stdout, stderr=self.stderr)\ntools.shared.Py2CalledProcessError: Command '['/usr/bin/python', '/b/build/slave/linux/build/src/src/work/wasm-install/emscripten/emcc.py', '/tmp/tmppWqxQI/src.cpp', '-s', 'DISABLE_EXCEPTION_CATCHING=0', '-o', '/tmp/tmppWqxQI/out.js']' returned non-zero exit status 1\nI'm investigating now.. Maybe \"NoAtExit\"  or \"RemoveAtExitCalls\" might have a been more descriptive names.  But  this is great news by any name!. I'm ok with wasm-emscripten-finalize doing this. Although I would imagine\nmost real programs will always end up requiring stackSave/stackRestore\nanyway.\nOn Tue, Dec 11, 2018 at 11:06 AM Jacob Gravelle notifications@github.com\nwrote:\n\nIn general wasm-emscripten-finalize lets us change LLVM output to match\nemscripten's expectations, meaning it frees us to make changes that are\nconvenient for one without worrying about breaking the other.\nSo: the only reasons I'm aware of that we even generate the\nstackSave/stackRestore functions is for emscripten interop. If we want to\nchange how that's done, there's no constraint on it other than emscripten\nlibrary code.\nConsiderations:\nstackSave/stackRestore get called by emscripten library js code in general\nat runtime, so we need to generate it anyway in wasm-emscripten-finalize to\nmetaDCE later as far as I know.\nThey definitely get called in dynamic libraries today because we can't\nexport mutable globals.\nBut, I'd think that changing only the initially-set stack position\nshouldn't affect anything else, and should be pretty straightforward. Sgtm\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/1818#issuecomment-446322434,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAfe5e8vKIgtMkDQQDmTPb0DBmpGuSIyks5u4AIZgaJpZM4ZOAMG\n.\n. I would go for parity with asm2wasm.. thats what wasm-emscripten-finalize tried to do in general IIUC.\n\nThis will hopefully all go away once we have mutable global import/export.. Does this mean we no longer have a wasm interpreter in JS?   We should probably update the README if so.. > > I'm not convinced we really need to be installing static libraries and binaryen headers other than the one we already install (\"binaryen-c.h\")\n\nMy colleagues assure me that they need to inherit from ShellExternalInterface from shell-interface.h to execute C++ function from wasm:\nhttps://github.com/soramitsu/polkadot/blob/master/test/deps/binaryen/binaryen_test.cpp#L18\n\n\nI see. Do they also have the requirement that they need to work from a \"packaged\" or \"installed\" version of binaryen, or can they use it directly from a source archive or git checkout?  \n. Can you respond to my earlier comments, and also split the PR as I suggested?   Then we can revisit.\n. Its this something we can add to travis to reject regressions before they land?  (Like clang format?). In general this looks awesome..  Looks like this broke the emscripten tests: wasm2.test_source_map and wasm3.test_source_map.\nI guess to be expected, the debug line information only shored 11 and 12 now.  Should we just update the test expectations for 02 and above?. Hmm.. looking at the test case it looks like the function in question is marked as \" attribute((noinline))\" .. I guess that doesn't get propagated to binaryen and its inlining it anyway maybe?. Hmm... do we want wasm-emscripten passes to be idempotent like this?  I would have thought that calling the EmscriptenGlueGenerator in the middle of some other pass seems like a bug.  Does \nFuncCastEmulation pass really depend on this?  If so perhaps generateDynCallThunks would be better exposes as pass itself?. I don't think I have a clear enough understanding of why emulate-func-casts needs these dynFuncs so I don't really know the correct solution.\nI can imagine a user accidentally defining their own function called \"dynCall_\", in this case it would be better to have wasm-emscripten-finalize error our perhaps?  At least i think wasm-emscripten-finalize should be able to assume that its input has not yet been finalized.\nMostly it just seems strange that emulate-func-casts is doing parts of the the finalize process.  Anyway lgtm for now since this change goes introduce that strangeness, but fixes a real bug.. Actually we can do a little better.. Oh sorry I should have given some context.  We use wasm-opt --metrics in some emscripten tests in order to measure properties of the wasm module.   In this code we assert if the property is not found.  I suppose we could instead return zero there?  But its a good interface to check I think.. How many files are in this directory?  If its only a few its probably safer to explicitly list them here, no?\n. Sounds good.  Seems like perhaps WASM_UNREACHABLE() might have been the wrong thing to use here.. Done.  \nI guess there isn't yet a test for this case, but I manually verified it produces the expected result: e.g. \"Fatal: callImport: unknown import: env.abort\".    . Should we not be consistently using \"with ... open as:\" ?. Why do some of these have a trailing newline?. What?  You want to waste almost 8 entire bytes for every command line run!  You know thats almost 64 bits right?   . Oops. Fixed.. Does this work?  I seems to remember that each element of the script list will run .. even if the others fail.  i.e. this is not a script, but a list of scripts.  I could have changed since my last travis work though I guess... for obj_file in sorted(glob.glob(os.path.join(lld_path, '*.o'))):  ?. or maybe a helper since it repeats below:\n```\ndef files_in_path(dirname, pattern):\n  return sorted(glob.glob(os.path.join(dirname, pattern)))\nfor obj_file in files_in_path(lld_path, \"*.o\"):\n```. We now have single init function that lld produces called __wasm_call_ctors()  it should always exist in the linked binary.  It can be exported by using the -e/--export= argument to lld. In lld we explicitly include this also in all the final binary outputs.  Combined with the change below maybe this tool can run on the output of lld rather than on the .o file?. Isn't the llvm convention for this to add  \".1\" ?   (i.e. isn't this was llmv-link does?)\nAt least this is what lld does wen you ask it to export locals and you have multiple locals with the same name (from different compilation units).. https://github.com/llvm-mirror/lld/blob/master/wasm/Writer.cpp#L622\n. Hmm.. why not have new/changes code formatted to 80 cols like most other projects?\nFrom a cursory look at the binaryen code it looks like most of the long lines are comments.  I'm particularly keen on the nicely wrapping comments, so I would love to see this line removed :)    But perhaps we can land it like this and remove in the followup CL?. This is technically unrelated.  Something I did in my original version of this change.\nI'm not sure what the old syntax is supposed to do?  Does \"-text\" work?   Anyway probably want to make this a separate change.. This is unrelated too, but something i needed to get out-of-tree testing working.. is it wasm or wast?  the print statement and the function name seem to disagree.. Does this fit on one line now?. Can we rely on the default for --global-base rather than passing it here and above?. add sys.exit(0) or change to sys.exit(test_wasm_emscripten_finalize())?. Does emscripten support the non-default path though?  Can the user control this?\nIf so, then yes I agree should use and test the flag. \n. I wonder if we can find a setting to allow this kind of thing?. This one seems pretty bad. This too.  I wonder if this could should be done via a \"#include .def\" thing?. Is it OK to looks this structure?. This looks a but odd. . I've standardized on using a live to separate but with a leading #.  This mimiks what wabt does. But surely in the case where the condition is false, the old code won't ever call the constructor?. Indeed, verified early fail and now reverted.. I was a little confused when I read this to, but I think its correct.\nWe are tying to calculate a table index here, not a segment index.  The old code was assuming that they were same thing (i.e. that the segment started at 0).\nWith this new code we either return \"segment start\" + \"segment size\"   OR \"segment size\" + \"segment offfset of first jsCalls\". . Done. We can do that as a followup maybe?. I was thinking that we only really care when there are functions that we want to rename.. Is this really needed?  Is the build or test process dropping .map files in the source tree?. Done. Sorry, I'm following llvm and chromium style which says only use auto when the type name appear already on the RHS. e.g. thinks like casts or things that take the type as template arg like make_unique<>.   Otherwise that reader can't infer the type.   I can leave these alone if you prefer.. Yes, thats the idea.    I've added more checks and comments that hopefully make it more clear.. I've added an assert that its an import.   Since its an export we already existing early from this function. \nI thought that imported functions were just function in the new model?  Is there some way to explicitly remove a function export?. They can be imports in the case of SIDE_MODULE I believe.    Some of the test cases import them from env.  I. You are right, this is more complicated than I thought.\nThese functions are also improted by the wasm backend codegen if this change lands:\nhttps://reviews.llvm.org/D53240\n(which I think it should).\nIf you want to take a look at cleaning all this on that would be great.  I was having some more thoughts about it this morning.\nHere is how I think it should go:\n\nWe should never create these function as part of binaryen\nWe should assume they exist and import them if they don't\nWe rely on the embedder to provide them, or for them to be compiled in at build time (this is the RELOCATABLE vs non-RELOCATABLE case)\n\nThis way we can remove the codegen from binaryen.   In the RELOCATABLE case these will end up as imports.  In the none-RELOCATABLE case these will be defined in the the JS code. . But don't want to allow these functions to also be locally defined within the module.   For example, in the llvm backend case they get compiled into the main modules from extras.c.. Its not more common to prefer .zip for windows artifacts and .tar.?? for UNIX?. What are these new exceptions for?. Do you need python3 here?. Why both with this guard?  \n. Oh I see.  fstrings are python 3.6 and most likely out version of flake8 is too old   Is it a good idea to depend on such a recent version of python\nMore generally it seems like flake8 is not configurable enough for us we probably want to look for another such tool.\nCan you add comments to the .flake8 file? . Nice!. Are these two types of unreachability really the same?   The latter means something like data corruption happened to break the type system and given the enum a bad value, whereas the former is maybe bad input?  (or maybe not?). oops, good catch.\n. This part is confusing me.  Why would segments get renamed by renameFunctions()?\nI can see the previous code did this too but I can't see why .... Sorry, I wanted to land this to get the waterfall green again.  Will upload a followup. What happens if you don't do this?. If I was feeling picky I would ask you split this into three separate PR:\n\nMoving/using of shared constants\nFix the ctor eval issue\nImport STACKTOP.\n\nIts up to you if you actaully want to do that.. Is it the convention to add these extra newlines between namespace declaration?  If not I've remove them.. Aren't names in binaryen intern'd in some way as to allow a simple pointer comparison for this kind of thing?. This command seems wrong.  lld has already assigned all its globals before finalize is called.. Do we need this new argument?  Won't the existing stack pointer assigned by lld be correct?   . The only reason I can see that finalize needs to know this is because it wants to write \"staticBump\" to the metadata output about the binary.   as long as we need staticBump we will to continue to pass this.. But in this new world, isn't the stack pointer already set by lld to the correct value?     Does emscripten put stuff on the stack at startup?   If so, doesn't it already have a way of moving the stack pointer by calling stackSave/stackRestore?\nPerhaps this argument should be called \"--initial-stack-pointer\"?\nI'm happy with the PR going in either way as I think its a step forward, I'm just trying to see possible improvements going foreword.. My understanding is that the memory layout used by lld/wasm-backend is \n1.  zero page\n2.  static initialized data\n3.  bss data\n4.  stack (grows down)\n5.  heap\nI believe that emscripten adds global data after (3), which mean its clobber the end of the stack (since the stack growns down).    So I believe the inital stack pointer set by lld (which grows down) will always be correct... but I'm not totally sure about all this right now.\nHappy for this change to land as is and we can try to simplify and possible remove this argument.. Looks like the brackets are no longer needed?  But maybe you want to keep this as fully automated CL?. Why is this an improvement?    Do you know which modernize pass did this?. Is this preferred/different to Index arity = UnsetArity;?  . Can you make these cmakes a separate PR. Is this for IDE integration? . the convention so far in this file seems to be ALL_CAPS for cmake stuff.  Probably better to follow the local convention for changes like this.. Seems like this whole block is duplicated in a lot of places.. and that these values should really be the defaults.  Are they not?. Because the input argument custom is passed by value, and will only live the lifetime on the constructor anyway.   (Took me a while to see the pattern here but I think it makes sense).. \nAre you embedding command line arguments in the file name?  Perhaps we could instead put these in command in the intput file, or in a separate \".run\" file?\nDriveby comment, no need to fix in this CL.\n. Alphasort. Hmm.. this seems odd.  num_failures is a variable that is imported from  scripts.test.shared but is a global in this file.     Is this doing what you expect it to do?  If we want changes to be visible in shared we would probably not use global by shared.num_failures.   . Because I don't like python's ternary syntax (maybe I'm biased), how about moving the return 1 into the block above as an early out and then just return 0 at the end here?. It makes me sad that we need all this boilerplate... Looking at the details of how num_failures is currently used, I think you probably want to use a new local here.. either that or somehow hook into the existing shared.fail_with_error system. . yay to code changes to make comments not-needed. But the num_failures that is global the this module is different to one in shared isn't it? \nUpdating num_failures in shared won't effect this value and vice versa.  I guess that bug already existed but this make it worse.\n. In python when you re-assign a global, it doesn't effect modules that have already imported that global. . ",
    "kom1che": "Hi,\nThank you for respond.\nI need time to expand my ROM from 4G upto 8G, but I still can't to finish installation process (guided by WebAssebly Developers Guide) without interaptions and memory crash!!\nWhat is the final volume of the emsdk folder? I stoped on 22.7Gb. Is it Ok?. ",
    "Mototroller": "@kom1che, try to install emsdk from scratch with lower amounts of threads (see this advice). By default its make uses all available cores for building, and sometimes it's fatal (I've found it should be MEMORY(GB) > 2 * THREADS empirically).. ",
    "pannous": "Thanks,  the answer seems to be\nBinaryen = require('binaryen.js')\nwast=`(module\n  (func $addTwo (param i32 i32) (result i32)\n    (i32.add\n      (get_local 0)\n      (get_local 1)))\n(export \"addTwo\" (func $addTwo))\n)`\nmodule=new Binaryen.Module(wast)\nmodule.emitBinary()\n unfortunately it hangs here without an error message.  sorry I must be blind,  I can't find the proper way to do it.\nGoing with https://github.com/ewasm/wast2wasm / wabt.js for now. 'not yet' is funny, it did already work before with the methods mentioned above (Binaryen.SExpressionParser(wast) and Binaryen.compileWast(wast)). beautiful!\nBinaryen.parseText() now works ++. oh sorry, stupid mistake.\nwasmx is a little program which executes wasm's main method. embarrassingly it's a little helper I wrote a while ago.\n```\nfunction wasmx(){\n  node -r ~/.wasm.js -e \"wasmx('$1').then(console.log)\"\n}\n~/.wasm.js :\nfs = require(\"fs\")\nwasmx = async (_wasm, imports = {}) => {\n    if (new File(_wasm).isFile) _wasm = fs.readFileSync(_wasm)\n    else _wasm = new Uint8Array(_wasm)\n    module = await WebAssembly.compile(_wasm)\n    instance = await WebAssembly.instantiate(module, imports)\n        return instance.exports.main()\n}\n```\nsure warrents a proper node module ;). full code:\n```\n;; wasmx foo.wast\n(module\n (type $int (func (result i32)))\n (type $void (func (result i32)))\n (type $int_int (func (param i32) (result i32)))\n (table 1 1 anyfunc)\n (memory $0 10)\n (data (i32.const 1) \"hello wasm!\\00\")\n (data (i32.const 20) \"Hello!\\00\")\n (export \"memory\" (memory $0))\n (export \"main\" (func $main))\n (import \"console\" \"log\" (func $log (param i32)))\n(func $str_len (type $int_int) (param i32) (result i32)\n  (local $len i32)\n  (local $char i32)\n  (set_local $len (i32.const 1))\n  (call $log (i32.load8 offset=1 align=1 (get_local $0)))\n  (call $log (i32.load8 offset=(get_local $0) align=what is going on?))\n  (loop $while\n     (set_local $len (i32.add (get_local $len) (i32.const 1) ) )\n     (set_local $char (i32.load8 offset=0 align=1 (get_local $0)))\n     ;;(set_local $char (i32.load8 offset=(get_local $0) align=1 (get_local $len))) ;;WHY NOT???\n     (set_local $0 (i32.add (get_local $0) (i32.const 1) ) )\n     (call $log (get_local $char))\n     (if (get_local $char) \n      (br $while)\n     )\n  )\n  (get_local $len)\n)\n(func $main (type $int_int)\n  (call $str_len (i32.const 20))\n)\n)\n. semi complete program:\ntest=module.addFunction(\"test\",void,[],[\n    logi(int(10))\n])\nmain=module.addFunction(\"main\", void, [], [\n    module.call('test',[],void),\n    log(I32.add(int(42), int(10))) ;; works\n]);\nconsole.log(module.validate());// works without call to test, fails with above line \n```\n. thx, will post program on monday.. here is the minimal (not)working code:\n```\nBinaryen=require('./binaryen')\nmodule = new Binaryen.Module();\nconst void  = module.addFunctionType(\"v\", Binaryen.None, []);\nconst iv = module.addFunctionType(\"iv\", Binaryen.None, [Binaryen.i32]);\nmodule.addFunctionImport(\"logi\", \"console\", \"log\", iv);\nlog=x=>module.callImport(\"logi\", [x], Binaryen.None)\ntest=module.addFunction(\"test\", void ,[],[\n    log(module.i32.const(10))\n])\nmain=module.addFunction(\"main\", void, [], [\n    log(module.i32.const(10)), // works\n    module.call(\"test\",[],void), // breaks\n]);\nmodule.setStart(main);\nmodule.validate()\nconst binary = module.emitBinary();\nconst compiled=new WebAssembly.Module(binary)\nnew WebAssembly.Instance(compiled,  {console:{log:x=>console.log(x)}});\nthe goal here is less to solve the issue in the code above, but to make debugging/asserts in general much more helpful so that developers can solve their problems themselves. If you remove the module.call there are other ways to make the compiler fail in very cryptic ways: flip logi/log \u2026. @dcodeIO  but this works just fine without ` module.block(\"\", ` :\nmain=module.addFunction(\"main\", void, [], [\n    log(module.i32.const(10)), // works\n]);\n```. Thanks, works with fresh npm version and module.block(\"\",\nAlso I found debuggability improved, sorry for using old version before.\nIt does not work if module.autoDrop(); is added. Is that normal or should I open new issue?. I found out that just removing\nconsole.log(module.validate());\nturns useless error messages like\nreturn 0;\n}\n/usr/lib/node_modules/binaryen/index.js:1\n(function (exports, require, module, __filename, __dirname) { var Module=typeof Module!==\"undefined\"?Module:{};function instantiate(Module){Module=Module||{};var moduleOverrides={};var key;for(key in Module){if(Module.hasOwnProperty(key)){moduleOverrides[key]=Module[key]}}Module[\"arguments\"]=[];Module[\"thisProgram\"]=\"./this.program\";Module[\"quit\"]=(function(status,toThrow){throw toThrow});Module[\"preRun\"]=[];Module[\"postRun\"]=[];var ENVIRONMENT_IS_WEB=false;var ENVIRONMENT_IS_WORKER=false;var ENVIRONMENT_IS_NODE=false;var ENVIRONMENT_IS_SHELL=false;if(Module[\"ENVIRONMENT\"]){if(Module[\"ENVIRONMENT\"]===\"WEB\"){ENVIRONMENT_IS_WEB=true}else if(Module[\"ENVIRONMENT\"]===\"WORKER\"){ENVIRONMENT_IS_WORKER=true}else if(Module[\"ENVIRONMENT\"]===\"NODE\"){ENVIRONMENT_IS_NODE=true}else if(Module[\"ENVIRONMENT\"]===\"SHELL\"){ENVIRONMENT_IS_SHELL=true}else{throw new Error(\"Module['ENVIRONMENT'] value is not valid. must be one of: WEB|WORKER|NODE|SHELL.\")}}else{ENVIRONMENT_IS_WEB=typeof win\nabort(). Build with -s ASSERTIONS=1 for more info.\ninto something useful, because\nconsole.log(module.emitText());\nstill works in some cases. and Assertion failed: mappedFunctions.count(name), at: binaryen/src/wasm/wasm-binary.cpp,425,getFunctionIndex can be guessed to mean: \"No such function\"\nwhich one is missing can then be determined by comparing all calls with all functions. One example amongst many:\nBinaryen=require('binaryen')\nlet wasm = new Binaryen.Module()\nwasm.addFunctionType(\"vI\", Binaryen.i32, []);\nwasm.addFunctionType(\"vI\", Binaryen.i32, []);\nprints \nAssertion failed: functionTypesMap.find(curr->name) == functionTypesMap.end(), at: binaryen/src/wasm/wasm.cpp,698,addFunctionType\nWhich is very hard to debug in bigger projects, because neither the js stack nor the name in question is preserved. In general curr->name should always be printed in assert statements.. Why is the js stack not preserved in the first place?\nThere sure is a cleaner way but for now this little patch helped a lot:\n/usr/lib/node_modules/binaryen/index.js (line 134/135)\nfunction backtrace(){\n    try{throw new Error()}catch(ex){return ex;}\n}\nfunction W(b){\n    try{var e=Sb();return b()\n    }catch(x){\n            console.log(backtrace());\n        throw x\n    }finally{Rb(e)}\n};. beautiful. ",
    "cpitclaudel": "Yeah, since ulimit works around it it might not be worth fixing. Part of my reason for posting this was documentation.. ",
    "AlgorithMan-de": "I had read the stackoverflow discussion - doing the FS.init didn't seem like it would work, given the hardcoded window.prompt in TTY.default_tty_ops.get_char, so I hadn't tried it. Now that I did, it works without editing hello.js :+1:\nI think though, that the generated hello.html should provide an implementation that shows how to do it (it can do function stdin(){return window.prompt('Input:');} by default, even if it's redundant - just to have an example).\nI also think the svg and the css should go in separate files, because the hello.html becomes so big just because of these 2, it's intimidating - it looks like it's to complicated to understand, so it discourages you from reading and modifying it to your needs.. Running self-compiled emscripten from current HEAD against self-compiled LLVM from current HEAD still produces this issue on my rather large project. I wasn't able to construct a small example that produces the error yet.\nIt also complains LLVM version appears incorrect (seeing \"7.0\", expected \"6.0\"). I tried using stock LLVM downloaded using ./emsdk install latest but that apparently has version 4.0 (!?) and doesn't support WASM. As of now, I am completely unable to compile my project to WASM.. Okay, I have got it running by doing ./emsdk install latest; ./emsdk activate latest and not pointing to my self-compiled LLVM in ~/.emscripten (I thought ./emsdk activate latest would have overwritten that configuration, but apparently hadn't). ",
    "chgibb": "Just some random from the internet chiming in here; there is no limit (as far as I know) to the total size of all artifacts uploaded to Github releases throughout the lifetime of a repository. From a users perspective, instead of providing a single tarball with several different artifacts, it would be more friendly to have multiple artifacts for each release. There is however, I believe, a 2GB file size limit for each individual artifact in a given release. With respect to Travis timeouts, a given job will timeout after 10 minutes of inactivity. That is, 10 minutes of no logs being generated. If you have a long running build step, it could be worth it to have something to just loop every minute or so and print a time or something just to keep the build alive.. ",
    "appetizermonster": "Thanks for the advice\nCould you explain how to profile the compiled WebAssembly with browsers?\nI couldn't find a way to profile it.\nI only can see \"wasm-function[xxx]\" on the JavaScript Profiler in Chrome and Firefox even with the -g, --profiling options.\nThere is no docs describes how to profile WebAssembly.. ",
    "wanderingbort": "Hi, I've encountered a similar error for a different reason.  The full repro case, which compiles and runs when targeting x86_64 linux but fails in s2wasm --allocate-stack 1024  is: \n```c++\nstruct Foo {\n    int value;\n};\ntemplate\nT const & sfunc() {\n    static T foo;\n    foo.value = 5;\n    return foo;\n}\nint main() {\n    auto const &thing = sfunc();\n    return thing.value;\n}\nthe error this produces:\n<< _ZZ5sfuncI3FooERKT_vE3foo >>\n[[bad mustMatch:]]:\n==========\n.weak   _ZZ5sfuncI3FooERKT_vE3foo\n        .p2align        2\n_ZZ5sfuncI3FooER\n==========\n```\nFor reference, this was seen using local build of LLVM/Clang release 40 with WebAssembly enabled and a latest build of binaryen on Ubuntu 16.04:\n$ clang++ -emit-llvm --std=c++14 -O0 --target=wasm32 -fomit-frame-pointer \\\n   -fno-threadsafe-statics -fno-stack-protector -fno-rtti -fno-exceptions -S \\\n   -o test.ll test.cpp\n$ llc -march=wasm32 -asm-verbose=false -thread-model=single -O0 test.ll \\\n   -o test.s\n$ s2wasm --allocate-stack 1024 test.s > test.wast\n. ",
    "SBKarr": "Same:\nclang++-Oz -I./sources -emit-llvm --target=wasm32 -fomit-frame-pointer -fno-threadsafe-statics -fno-stack-protector -fno-rtti -fno-exceptions  -std=c++14 -c sources/test.cpp -o build/sources/test.bc\nllvm-link build/sources/test.bc -o build/cpp.bc\nllc -asm-verbose=false -o build/cpp.s build/cpp.bc\ns2wasm build/cpp.s > build/cpp.wast\n<< _ZTV4Vec3 >>\n[[bad mustMatch:]]:\n==========\n.weak   _ZTV4Vec3\n    .p2align    2\n_ZTV4Vec3:\n    .int32  0\n    .int32  0\ntest.cpp:\n```cpp\nstruct Vec3 {\n    float x;\n    float y;\n    float z;\nVec3(float x, float y, float z)\n: x(x), y(y), z(z) { }\n\nvirtual ~Vec3() { }\n\nvirtual float sq_dist() const {\n    return x * x + y * y + z * z;\n}\n\n};\nVec3 makeVec3(float x, float y, float z) {\n    return Vec3 ( x, y, z );\n}\n```\nbuild/cpp.s:\n```\n    .text\n    .file   \"llvm-link\"\n    .hidden _Z8makeVec3fff\n    .globl  _Z8makeVec3fff\n    .type   _Z8makeVec3fff,@function\n_Z8makeVec3fff:\n    .param      i32, f32, f32, f32\n    .local      i32, i32, i32, i32\n    i32.const   $4=, _ZTV4Vec3\n    i32.const   $5=, 8\n    i32.add     $6=, $4, $5\n    copy_local  $7=, $6\n    i32.store   0($0), $7\n    f32.store   4($0), $1\n    f32.store   8($0), $2\n    f32.store   12($0), $3\n    return\n    .endfunc\n.Lfunc_end0:\n    .size   _Z8makeVec3fff, .Lfunc_end0-_Z8makeVec3fff\n.section    .text._ZN4Vec3D2Ev,\"axG\",@progbits,_ZN4Vec3D2Ev,comdat\n.hidden _ZN4Vec3D2Ev\n.weak   _ZN4Vec3D2Ev\n.type   _ZN4Vec3D2Ev,@function\n\n_ZN4Vec3D2Ev:\n    .param      i32\n    .result     i32\n    return      $0\n    .endfunc\n.Lfunc_end1:\n    .size   _ZN4Vec3D2Ev, .Lfunc_end1-_ZN4Vec3D2Ev\n.section    .text._ZN4Vec3D0Ev,\"axG\",@progbits,_ZN4Vec3D0Ev,comdat\n.hidden _ZN4Vec3D0Ev\n.weak   _ZN4Vec3D0Ev\n.type   _ZN4Vec3D0Ev,@function\n\n_ZN4Vec3D0Ev:\n    .param      i32\n    call        _ZdlPv@FUNCTION, $0\n    return\n    .endfunc\n.Lfunc_end2:\n    .size   _ZN4Vec3D0Ev, .Lfunc_end2-_ZN4Vec3D0Ev\n.section    .text._ZNK4Vec37sq_distEv,\"axG\",@progbits,_ZNK4Vec37sq_distEv,comdat\n.hidden _ZNK4Vec37sq_distEv\n.weak   _ZNK4Vec37sq_distEv\n.type   _ZNK4Vec37sq_distEv,@function\n\n_ZNK4Vec37sq_distEv:\n    .param      i32\n    .result     f32\n    .local      f32, f32, f32, f32, f32, f32, f32, f32\n    f32.load    $8=, 4($0)\n    f32.mul     $7=, $8, $8\n    f32.load    $6=, 8($0)\n    f32.mul     $5=, $6, $6\n    f32.add     $4=, $7, $5\n    f32.load    $3=, 12($0)\n    f32.mul     $2=, $3, $3\n    f32.add     $1=, $4, $2\n    return      $1\n    .endfunc\n.Lfunc_end3:\n    .size   _ZNK4Vec37sq_distEv, .Lfunc_end3-_ZNK4Vec37sq_distEv\n.hidden _ZTV4Vec3\n.type   _ZTV4Vec3,@object\n.section    .data.rel.ro._ZTV4Vec3,\"aGw\",@progbits,_ZTV4Vec3,comdat\n.weak   _ZTV4Vec3\n.p2align    2\n\n_ZTV4Vec3:\n    .int32  0\n    .int32  0\n    .int32  _ZN4Vec3D2Ev@FUNCTION\n    .int32  _ZN4Vec3D0Ev@FUNCTION\n    .int32  _ZNK4Vec37sq_distEv@FUNCTION\n    .size   _ZTV4Vec3, 20\n.ident  \"clang version 6.0.0 (trunk 319631)\"\n.functype   _ZdlPv, void, i32\n\n```\nLLVM: latest (6.0.0 - 319631) and 5.0.0 stable\nBinaryen: latest\nTemporary workaround (src/s2wasm.h):\n@@ -1320,7 +1320,7 @@ class S2WasmBuilder {\n     }\n     skipWhitespace();\n     Address align = 4; // XXX default?\n-    if (match(\".globl\")) {\n+    if (match(\".globl\") || match(\".weak\")) {\n       mustMatch(name.str);\n       skipWhitespace();\n     }. ",
    "brion": "How much RAM is assigned to the VM? Linking the big LLVM & clang libs is very memory-intensive, and will likely fail if you only have 1 or 2 GB assigned. I've had good luck with 4GB VMs.. I have a couple concerns about the \"wasm polyfill\" approach:\n Will this work with multiple modules? In ogv.js I load separate modules for each file type, and so may have multiple instances of different demuxers running in the same JS context. They need to not stomp on each other if they each load a polyfill for the WebAssembly namespace.\n If the polyfill replaces the global WebAssembly object, other code that's loaded into the web app later may think WebAssembly is available and try to compile and run its own modules, which would presumably fail.\nThese can probably be resolved by allowing the polyfill to use a custom namespace, and maybe also emitting it as a separate file which can be loaded once.\nNote also for my case, JS output mostly targets IE 11 and old versions of Safari and Edge, so I need to avoid ES6 modules.. ",
    "OughtImpliesCan": "Just added 4 GB of RAM and these commands into a terminal:\ncd emsdk\n./emsdk install sdk-incoming-64bit binaryen-master-64bit\ninitialized to that 54% and now says it's linking but no other messages have been logged to the terminal for about five minutes now, might give it another five minutes but if all else fails I can just wipe this VM and start over with the 50 GB of storage and 4 GB of RAM and see what happens.  Any suggestions?. Starting over at 4 GB of RAM did the trick, thanks!. ",
    "weitjong": "I believe 4GB is still not enough and build process started to swap, and that killing the performance. You can use the \"free -h\" command in another terminal to confirm this. . ",
    "Lachrista": "@dschuff \nI use -s USE_PTHREADS=1 -s WASM=1 to compile a wasm.but ,When I use the wasm file in firefox and Google, it's error reporting.\n\"Uncaught TypeError: [object Uint32Array] is not an integer shared typed array.\n    at Atomics.store ()\n    at Object.initMainThreadBlock \"\nI don't understand why this is, because it can be used normally in asm. Js.\nThis problem is very upsetting to me. I don't know how to solve it.. I don't think that's the reason.\nBecause I have already opened the corresponding configuration in Google, but it will still be wrong.\nchrome://flags/ ,I've already set up\n(1)shared-array-buffer\n(2)All about webassembly\nnow ,Has been an error\n\"Uncaught TypeError: [object Uint32Array] is not an integer shared typed array.\nat Atomics.store ()\nat Object.initMainThreadBlock \"\nI don't know how to solve this problem.. ",
    "jayphelps": "Mutable globals now supported by @sbc100 \ud83c\udf89 https://github.com/WebAssembly/binaryen/pull/1785. @binji wow I hadn't even seen that site before \ud83d\ude31 looks like the draft spec you all have been working on. Thanks much!\n. @binji I don't have a ton of cycles, but if the fix is rather quick I'm happy to do it--though it seems like the correct way would be to refactor things to not parse function bodies until after parsing the rest of the file.\nCc/ @dschuff since I believe he authored that particular check.\nEdit: I also just remembered that I'm no longer apart of the CG because my involvement in wasm is not related to my employer and I cannot join without it representing them (by W3C rules). I think that prevents me from contributing code entirely \u2639\ufe0f . I tried solving it by installing gcc via brew install gcc and using CC=gcc-8 CXX=g++-8 ./check.py however I still receive the same error:\n\nError details\n\nbuild:  gcc-8 /Users/jayphelps/Projects/jayphelps/binaryen/test/example/c-api-hello-world.c -c -o example.o -I/Users/jayphelps/Projects/jayphelps/binaryen/src -g -Lbin/../lib -pthread\n   c-api-hello-world.c /Users/jayphelps/Projects/jayphelps/binaryen/test/example/c-api-hello-world.c /Users/jayphelps/Projects/jayphelps/binaryen/test/example/c-api-hello-world.txt\nlink:  g++-8 -std=c++11 example.o -Lbin/../lib -lbinaryen -I/Users/jayphelps/Projects/jayphelps/binaryen/src -g -pthread -o bin/example -Wl,-rpath=$ORIGIN/../lib\nld: unknown option: -rpath=$ORIGIN/../lib\ncollect2: error: ld returned 1 exit status\nTraceback (most recent call last):\n  File \"./check.py\", line 675, in \n    sys.exit(main())\n  File \"./check.py\", line 657, in main\n    run_gcc_tests()\n  File \"./check.py\", line 566, in run_gcc_tests\n    os.remove(output_file)\nOSError: [Errno 2] No such file or directory: 'bin/example'\n\n\n--\nI noted ld: unknown option: -rpath=$ORIGIN/../lib and some googling suggested it might need to be a comma instead -rpath,$ORIGIN/../lib so I change that line in check.py.\nI also noticed that an old PR had the rpath stuff excluded on Mac though that change was later lost. I'm not sure what's right.\nThat resolved the error, but then I got fatal error: _stdio.h: No such file or directory\nMore googling suggested that I needed to update my xcode \"command line tools\" so I used:\nsudo softwareupdate -i \"Command Line Tools (macOS High Sierra version 10.13) for Xcode-9.4\"\nPHEW. Now it works!\nAside from the -rpath,$ORIGIN/../lib change, I wonder if there's anything that can be done to make this easier for Mac users, or if we just need to provide some additional instructions for setup.. To be clear, if it is something that makes sense in binaryen I would try to add it when I get the time. Not asking others to do the work for me \ud83d\udd7a \nEdit: of course I haven't had the time lol. @kripken Cool. use case: using binaryen as a backend to build wasm AST, emitting each unit to disk as relocatable binary, so we can then link them all together with any deps. Since this is pretty standard stuff I was worried that I'm missing something about binaryen since it feels like most who use binaryen's AST backend would end up wanting this at some point? Want to make sure I'm not misunderstanding something.. Fixed bool mutable_ = false; default, rebuilt tests, however I needed to update the testsuite/spec files to pick up mutual global support and in doing so it opened a big old can of worms with incompatibilities \ud83d\ude31. I also couldn't find an intermediate commit we can use to ship this. I've been digging through them for a while now, so far biggest ones are the renaming of memory instructions (e.g. grow_memory -> memory.grow) and numerous tests now mix stack/sexprs which binaryen doesn't support. Gonna see how far I get. If I'm not back in a few days send help \u2620\ufe0f\ud83c\udff3\ufe0f . @binji thanks for the tip--I really do appreciate it. Unfortunately wat-desugar strips comments and also removes some extraneous code that are part of the test (like deeply nested blocks). But lmk if I'm misunderstanding!. > if you have a repro case I'd like to fix that\nturns out I was looking at the git diff incorrectly. What actually happened is that it put the export outside instead of inline--my eye saw the export \"deep\" and thought the code was removed. Sorry about that!\n```\n(func (export \"deep\") (result i32)\n    (block (result i32) (block (result i32)\n    (; etc...I removed the rest for comment readability ;)\n\n                                    (block (result i32) (block (result i32)\n                                      (call $dummy) (i32.const 150)\n                                    ))\n                                  ))\n                                ))\n                              ))\n                            ))\n                          ))\n                        ))\n                      ))\n                    ))\n                  ))\n                ))\n              ))\n            ))\n          ))\n        ))\n      ))\n    ))\n  ))\n))\n\n)\n```\n```\n(func (;5;) (result i32)\n    (block (result i32)  ;; label = @1\n      (block (result i32)  ;; label = @2\n    (; etc...I removed the rest for comment readability ;)\n\n                                                                        (block (result i32)  ;; label = @37\n                                                                          (block (result i32)  ;; label = @38\n                                                                            (call $dummy)\n                                                                            (i32.const 150))))))))))))))))))))))))))))))))))))))))\n\n(export \"deep\" (func 5))\n```. Thanks @sbc100! I had ran into a blocker with the spec test suite but if it passed for you it must have since been resolved. Woot woot!. Updated. I had needed to rebuild the js files. 4a6a2f7ebdb63c37800458ab55ecc5404a15c74b feel free to squash after review.. Should we keep support for the old instruction names in wat/wast parsers? FWIW wabt did. @kripken cool. I had started to go down the road of finding and fixing them but I just keep finding more  divergences. What I'm gonna do is comment out the ones that binaryen does not support, with a comment--sound good?. btw I noticed one example in the spec tests where I think mixing AST/stack syntaxes can be ambiguous. This may not be news to everyone else, but I thought it was interesting.\n```\n(func (export \"as-return-value\") (result i32)\n  (block (result i32)\n    (i32.const 1)\n  )\n  (return)\n)\n;; vs.\n(func (export \"as-return-value\")\n  (block (result i32)\n    (i32.const 1)\n  )\n  (return)\n)\n```\nBinaryen parses the first one fine, but it fails validation because in AST form it's an empty return, whereas in parsers that support mixed AST/stack form like wabt, the block's value is used as the return operand but if and only if the function has a result signature expecting one, otherwise it's treated as an empty return ignoring the block value. \ud83e\udd2fIf I'm wrong, lmk.. @kripken Made more progress but I can't seem to figure out this latest error. It's not clear where these fail functions come from or why this particular test is failing. I manually ran it and I believe it's returning 31353 instead of the expected 122. I believe these are new tests pulled in from test/spec, but I didn't comment this particular one out because it passed the wasm tests.\nCurious if something immediately jumps out at you?\n(See Travis or below)\nexecuting:  install/bin/wasm2js /home/travis/build/WebAssembly/binaryen/test/spec/address.wast\nexecuting:  install/bin/wasm2js /home/travis/build/WebAssembly/binaryen/test/spec/address.wast --allow-asserts\nskipping ( assert_trap ( invoke 32_good5 ( i32.const 65508 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8u_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8s_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16u_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16s_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8u_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8s_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16u_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16s_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_malformed ( module quote (memory 1) (func (drop (i32.load offset=4294967296 (i32.const 0)))) ) i32 constant )\nskipping ( assert_trap ( invoke 64_good5 ( i32.const 65504 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8u_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8s_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16u_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16s_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32u_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32s_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 64_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8u_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 8s_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16u_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 16s_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32u_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32s_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 64_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32_good5 ( i32.const 65525 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 32_bad ( i32.const 1 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 64_good5 ( i32.const 65511 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 64_bad ( i32.const 0 ) ) out of bounds memory access )\nskipping ( assert_trap ( invoke 64_bad ( i32.const 1 ) ) out of bounds memory access )\nexecuting:  /home/travis/.nvm/versions/node/v10.9.0/bin/node --experimental-modules --loader ./scripts/test/node-esm-loader.mjs a.2asm.mjs\n(node:45693) ExperimentalWarning: The ESM module loader is experimental.\nexecuting:  /home/travis/.nvm/versions/node/v10.9.0/bin/node --experimental-modules --loader ./scripts/test/node-esm-loader.mjs a.2asm.asserts.mjs\nTraceback (most recent call last):\n  File \"./check.py\", line 691, in <module>\n    sys.exit(main())\n  File \"./check.py\", line 667, in main\n    wasm2js.test_wasm2js()\n  File \"/home/travis/build/WebAssembly/binaryen/scripts/test/wasm2js.py\", line 105, in test_wasm2js\n    test_wasm2js_output()\n  File \"/home/travis/build/WebAssembly/binaryen/scripts/test/wasm2js.py\", line 80, in test_wasm2js_output\n    out = run_command(cmd, expected_err='', err_ignore='The ESM module loader is experimental')\n  File \"/home/travis/build/WebAssembly/binaryen/scripts/test/support.py\", line 160, in run_command\n    raise Exception(('run_command failed (%s)' % code, out + str(err or '')))\nException: ('run_command failed (1)', '(node:45703) ExperimentalWarning: The ESM module loader is experimental.\\nReferenceError: fail15 is not defined\\n    at file:///home/travis/build/WebAssembly/binaryen/a.2asm.asserts.mjs:346:17\\n    at ModuleJob.run (internal/modules/esm/module_job.js:96:12)\\n')\n```js\nfunction $14(i) { // 16u_good5\n  i = i | 0;\n  return HEAPU16[(i + 25 | 0) >> 1] | 0 | 0;\n}\n// ... etc ...\nfunction check15() {\n return (retasmFunc.$16u_good5(0 | 0) | 0 | 0) == (122 | 0) | 0;\n}\nif (!check15()) fail15();\n```\nwat\n(func (export \"16u_good5\") (param $i i32) (result i64)\n  (i64.load16_u offset=25 align=2 (get_local $i))        ;; 122 'z\\0'\n)\n;; ... etc ...\n(assert_return (invoke \"16u_good5\" (i32.const 0)) (i32.const 122)). Happens locally too. Saw that other ticket mentioning node 10. I tried various versions of node, including latest.\nI\u2019ll make a separate PR for the submodule\u2014it\u2019s already in a separate commit so it\u2019s easy \ud83e\udd19. This feels dirty but seemed like a simple solution without deciding to completely rethink about imports/globals are represented. You're not missing something, I was! You are correct and it actually explains why some codegen around the tests were adding in a drop. Great catch.. The test revealed that I had incorrectly added spaces here. testing revealed I missed adding the support to this file.. @kripken It's not clear why all these changed to mutable. Perhaps this is revealing a bug I introduced?. Oh! Is it because those asmjs globals were actually mutable but previously we couldn\u2019t represent that?. btw char* funcNames vs char *funcNames pointer placement isn't consistent in the codebase but I tried to be consistent with other similar contexts. Happy to follow any pattern.. Most of the changes so far are naive find-and-replaces with case sensitivity. I've fixed a few spots where I found that it made things incorrect. e.g. memory.size() vs memory_size() but there might be others.\nThis was one such spot, where I needed to change the parser itself because it assumed that anything with a dot was i32|i64|f32|f64 operations.. Added for parity with the other kitchen sink demo but also cause the general info call defers to a number of other calls and I figured you\u2019d recommend exposing this one lol. No problem! Changing \ud83e\udd19. Done. ",
    "am11": "For Windows, unless there is a major blocker; should the AppVeyor script be updated to validate against VS2017 v15.3 instead of VS 2015.3? It has better C++ STD support with perf improvements than its predecessors.\nFor local development, the minimal Build Tools for Visual Studio 2017 pulls the required toolchain without needing to install the full IDE. Tools are installable even on headless nano server via command line. Based on project configuration (setting one flag), the compiled binaries can be made compatible with older versions of Windows as well (16 yrs. old XP support is still there), which is no different than what VS2015 and 2013 has to offer at the cost of lesser standards support.\n. ",
    "DiamondLovesYou": "I'm building a dynamic linker for wasm, so I've made a few changes to the way s2wasm links and is the reason you see a different error (and I forgot). Let me see what code I can submit PRs for (waiting to hear back..).\nIn this specific case, the function ptr will be set in the table after the module is instantiated.\nHowever I'm surprised exp isn't in this libc code (it's the libc embuilder.py produces in the cache). I'm not using (most of) Emscripten for this work, I've reused a previous project of mine as a driver, and am only reusing the system libraries from Emscripten. It looks like most of the math functions are defined in wasm-libc.bc, so it looks like I'll have to add that library to what's distributed with the rest of LLVM (which is what I'm currently porting to WebAssembly). It wasn't your intention, but nice catch, thanks!. I should add that this issue happens on every LLVM shared component built, not just on the libc I've provided.. Sure: https://gist.github.com/DiamondLovesYou/d5fbf3865a2bf5f6a36cf3ddc66efcc8/raw/863ef1e47ee75a27961871273b16460611a37eb5/libc.wasm. That has been an issue additionally. I'll look into this. However, wouldn't those incorrect indexes be caught by the verifier?. ",
    "tlively": "This the beginning of my work on wasm2asm. Getting it fully functional will allow me to use it in the Rust compiler to support asm.js and eventually remove Rust's dependency on Fastcomp.\ncc @eholk @jgravelle-google @kripken . @kripken thanks for bringing up those issues. My hope is that the control flow flattening will work, but if it doesn't then I'm prepared to do work to find a transformation. I will probably try to emit and use library code for i64 support initially, just to get something working, but it would probably be good to emit smarter code later.\nMy priority is definitely offline compilation, but I agree that client-side seems useful as well. What kind of tradeoffs do you think would be important there?. I was failing CI earlier because of unused imports in wasm2asm.py. Does that lint only run on the files under scripts?\nEdit: It looks like it does only run for scripts. The difference in parentheses and semicolons between the current code and the previous working version of wasm2asm is due to the removal of STAT nodes in https://github.com/WebAssembly/binaryen/commit/f6c0bc26b65c6cfd58d1bb011c1587d343c42ab5. @kripken do you know if there are any situations in which missing these semicolons would be semantically incorrect? If so, I should bring back STAT nodes.. Cool, I know semicolons are emitted after ifs and loops, so I just added a special case for statements in blocks. This PR should be good to go now.. @kripken The semicolons should be good enough for now. Is there anything else you see that should be fixed?. cc @eholk @jgravelle-google . The Travis failure is due to it using an old version of node :/. There are still memory leaks. I'll have to fix them tomorrow.\ncc @eholk @jgravelle-google . @kripken @jgravelle-google This should be good to go now.. @kripken Anthing else that needs to be done with this one?. Looks like this created a memory error in asm2wasm. Working on a fix now.\nEdit: Hmm, maybe not. Maybe I just forgot to rebuild?\nEdit2: The memory error is on a local branch I rebased and not pushed anywhere.. Adds a pass for lowering i64s to i32s and a small amount of functionality to wasm2asm.h. It does not implement lowering for every instruction yet, but it implements enough to fully translate a simple hello world Rust program from wasm to asm.js.\nThere are no tests (yet) so there are probably correctness errors, but it would be good to get review started ASAP.\ncc @kripken @eholk  @jgravelle-google \n. @kripken @jgravelle-google what needs to be done to merge this?. I had to rebase and fix conflicts just now. It would be great to get this merged soon. Is there anything else I can fix before then?. @kripken This should be all set!. @kripken This is a potential fix for your last comment in #1134. It ensures that all local variables always have names, and uses generic names instead of null names as defaults.. @kripken The last build just timed out. I think running it again should fix it.. Closing in preference of #1189.. Yeah there's all sorts of wonkiness going on with br_tables right now. I'm working on it!. I had to update my strategy for lowering Switch expressions to always use trampoline blocks because the previous strategy relied on being able to store a single variable into multiple locations in a lookup table, which is no longer possible.. @kripken @jgravelle-google any more thoughts on this change?. lgtm, but how did you notice that this was broken? I do test locally with both spidermonkey and v8 and the wasm2asm tests pass for me. Did you have local tests failing?. Will update this on top of #1757 once it lands.. Closing in favor of #1777 and its successors. I was printing a bunch of half-baked expressions to debug a separate issue and ran into this segfault. I agree it probably shouldn't happen on valid IR, but it can still be useful to print invalid IR for debugging.. @kripken see the line I added to .travis.yml. I don't think that's what you had in mind, but I thought that comparing the script output to the gen-s-parser.inc file would be more lightweight than doing a second build.. @binji, @kripken mentioned to me that this parser is occasionally performance sensitive, so it may be important that we don't have to check every character. But with the script it would be very easy to also generate a second implementation that is just a chain of if (strcmp(... Maybe we could emit that slow version for debug builds and the fast one for release builds or something like that?. I suppose this still lets through something like \"i64.atomic.rmw32_u.compxchgZZZZZZZ\", but I'm not sure how much we care about that.. Are there any more concerns about this PR? I would like to start submitting new PRs on top of it whenever possible.. @kripken Do we care about supporting the older compilers? If so, we should probably do something other than just silence the warning.. @Markyparky56 But if we want to support VS 2017 15.8 or earlier, it sounds like we should decrease MAX_ALIGN so we actually get an error when it would be otherwise miscompiled.. @kripken Would you say this is good for landing now?. @kripken This is hopefully good to go now.. I'll handle the idx -> index renaming in another PR. Thanks for catching that.. I'm not too happy with the design here, so I will rework this soon.. This was superseded by #1851.. I believe this might be one of the special cases of Binaryen's type system where its treatment of unreachable code is different from WebAssembly's since Binaryen wants to be able to reason locally about types, but if that is not the case, then there is a bug in the Binaryen validator since this module passes validation.. I'm fine with leaving it as-is, too.. LGTM!. Thanks for catching those, @chicoxyzzy! Let's see if it works this time.. I believe this code is actually coming from LLVM. If you enable the sign-ext CPU feature in the LLVM wasm backend, for example by passing -msign-ext to clang (or emcc), then it should use the saturating conversion instruction.. It looks like you tested with the x86 backend in that link. This is target cpu feature in the WebAssembly backend.. Yes, the WebAssembly backend is under active development, so you'll need a recent build of clang to get all the new features. In fact, clang 8 will be the first LLVM to include a non-experimental WebAssembly backend.. Sorry, yes, I was thinking of -mnontrapping-fptoint. I'm not sure what Emscripten is doing here after the initial wasm code is emitted by LLVM.. Section 6.5.6, paragraph 8 of the C17 spec says\n\nIf both the pointer operand and the result point\nto elements of the same array object, or one past the last element of the array object, the evaluation\nshall not produce an overflow; otherwise, the behavior is undefined\n\nSo I think this is indeed undefined behavior. However, we might still want to support code that depends on it?. Section 6.2.6.3, paragraphs 5 and 6 say\n\nAn integer may be converted to any pointer type. Except as previously specified, the result is implementation-defined, might not be correctly aligned, might not point to an entity of the referenced\ntype, and might be a trap representation.\nAny pointer type may be converted to an integer type. Except as previously specified, the result\nis implementation-defined. If the result cannot be represented in the integer type, the behavior is\nundefined. The result need not be in the range of values of any integer type.\n\nUnfortunately I can't find anything that might be referenced by the \"except as previously specified\" phrase, but it is promising that it can explicitly be a trap representation.. I strongly support this direction for wasm2js. Replacing Fastcomp was exactly my goal when I worked on this as an intern in summer 2017, with the motivation of simplifying Rust's dependency on Emscripten.. @dcodeIO, if I understand correctly, that will still work but the JS you get may be different that what it is today. In fact the JS will be better because wasm2js will be feature-complete enough to support all emscripten tests.. Right, that's the only thing left to match the spec proposal. AFAIK, that change has not actually been made in any tools yet (although I would be happy to fix that on monday).. @kripken This has no more outstanding dependencies.. Can I get an explicit lgtm on the new handling of options.abort_on_first_failure in run_unittest? Unfortunately I didn't see a good way to reuse the error handling in shared.py that properly counts the number of individual test failures.. Yes, it would be a good idea to add feature manipulation support to the C API. That should be a separate PR, though, since this is more of a bug fix than an API change. . Ah, good point. I'll be sure to test and fix those cases once the unittest support lands.. This is more or less hacked together to get around the fact that existing code depends on being able to open and close and get the size of the input file. I would like to rewrite the input handling to more gracefully handle both stdin and files.. I think ideally all the file I/O would be unified to read from istreams into stringstreams and return strings, using file size as a hint and not requiring files to support seeking or opening. But that is all annoying enough that I would rather land this now and get on with other stuff.. This code had previously been deleted, so I just brought it back exactly how it was. I don't see why there wouldn't be a return here, but I don't want to mess with it before I have tests running.. These changes are a result of STAT nodes being removed from the code base. I will put them back in to fix this.. Yes, since there aren't many tests right now anyway. I was planning to enable the tests in a future PR that would finish 32 bit support and add more tests.. Yes, the MOZJS case in test_wasm2asm() cannot use equality because the error message contains timing information that is not test-independent.. The full stderr of mozjs for successful test looks like a.2asm.js:warning: Successfully compiled asm.js code (total compilation time 4ms; caching disabled by missing command-line arguments). The only part the test cares about is Successfully compiled asm.js code. I don't know of a way to stop the timing information from being emitted, which would allow us to use equality here. . The loop body and if arms are already taken of, but when I tried making it add a ; after each element of a block, I got a lot of ugly double semicolons and semicolons on their own line. Is that preferable to leaving them out or reinstating STAT nodes? I have a separate simple fix for the parentheses problem.. I was also thinking of lazily adding these functions as they're required. Do you think that would be worth doing?. I use try...catch in the translation of assert_trap to JS. The translation of assert_trap tests is behind a --pedantic flag because asm.js does not trap in places where wasm does.. I extracted the dot expressions into their own variable, but if anything it looked worse. So I went ahead and made the vararg helper. Now it looks great.. Yeah, I emit normal JS outside the asm.js module. This JS can call into the module's exported functions for correctness testing. The generated tests are not part of this CL because they are generated by the script. Even then, the tests including try...catch are not generated by the script because they do not pass since asm.js does not trap on things like divide by zero. You can generate and see these tests manually by doing bin/wasm2asm --allow-asserts --pedantic test/spec/i32.wast.. The older node was somewhere around version 0.10. It didn't have functions like Math.imul and Math.fround, so it couldn't run the asm.js tests.. These tests don't use emscripten so there is no polyfill. The error was \"undefined is not a function\" when trying to use Math.imul.. @kripken How would I use a polyfill here? Also, the files I added to the tests are very large. I suspect it would be better to have a separate smaller test case for this functionality and not check in large test files for the actual unit tests like those in i32.wast.. I tried the polyfill, and it worked, but old node has another error preventing us from using it:\n```\nfunction check272() {\n  console.error(2147483647|0, 2147483648|0, asmModule.le_s(2147483647|0, 2147483648|0))\n  return (asmModule.le_s(2147483647 | 0, 2147483648 | 0) | 0 | 0) == (0 | 0) | 0;\n}\nif (!check272()) fail272();\nThis is one of the generated test cases. I added the console.error call. It prints `2147483647 -2147483648 1` and fails. The function implementing `asmModule.le_s` is\n function $$23(x, y) {\n  x = x | 0;\n  y = y | 0;\n  return (x | 0) <= (y | 0) | 0;\n }\n```\nwhich I believe is correct.. Yeah it turns out all we needed was a node_js key in the travis config. Since travis supports this natively, should we still have a TODO to remove it?. From pass.h:\n\nThis should always be safe unless you do something in the pass that makes it\n  not thread-safe; in other words, the Module and Function objects and\n  so forth are set up so that Functions can be processed in parallel, so\n  if you do not ad global state that could be raced on, your pass could be\n  function-parallel.\nFunction-parallel passes create an instance of the Walker class per function.\n  That means that you can't rely on Walker object properties to persist across\n  your functions, and you can't expect a new object to be created for each\n  function either (which could be very inefficient).\n\nThis comment seems to contradict itself about whether a new Pass object is created for each function, although currently this is the case. Regardless, setting builder should be thread safe. I'm assuming that in the future Pass objects will be able to be reused and that the module level structures (e.g. globals) will be walked in parallel passes as well.\nHere's the simplest allocation scheme that should work: Allocate the builder for each object in whichever comes first: a call to doWalkModule or a call to doWalkFunction. Never allocate builder for that Pass again, and free it in the destructor.\n. I wasn't able to find a reproducer after a quick check just now, but if I remember correctly at one point during development I had a situation where parent was either an Assign or an AssignName node, neither of which are Arrays.. Because the next few lines where it creates new low and high names would break if the local didn't have a name to start out with. Even if it didn't crash, there would be a possibility of duplicate names, which would be bad.. My reading of the spec says that it should be possible to do something like a 6 byte load into an i64. It looks like Binaryen doesn't allow anything but powers of 2 for load sizes, though. Is my reading of the spec wrong?. Tied to previous comment.. After parsing test/spec/globals.wast we're left will a nullptr in the list of globals. This causes wasm2asm to crash (and is clearly incorrect) without this check.. It turns out that the root issue was actually that the vector of globals was modified while being iterated through, which invalidated the iterator.. Is this also the case for stores?. @kripken @jgravelle-google Bump. I'd like to get this quick fix in so this can be merged. Is it both loads and stores that only support 1, 2, 4, or 8 bytes?. Yeah, I can clean this up in a follow up. I think I did do this to keep the length of the array correct, which seemed better than assuming all previous variables had also had names.. Now that Functions can create default names, perhaps it makes the most sense to require a name for everything and fix any passes that omit names to use default names instead.. No, being move-only is critical for the correctness of these vars. When an expression is lowered its high bits are stored in a new variable and this variable is stored in a lookup table to be retrieved by the expression's parent. The parent can choose to reuse or free the variable, but until the parent expression is processed, the variable must not be used for anything else.\nBy only allowing variables to be moved and not copied, we can ensure that a variable cannot be improperly reused. Without the move semantics it would be impossible to use RAII for these variables since they would be freed and potentially reused before the parent expression could consume them.. This code doesn't compile because the assignment operator has been deleted. However, if you used std::move to use move assignment, you're totally right that this is completely broken. It leaks 1 and 3 and frees 2. I'll fix this when I have time, probably tomorrow or Friday.. It would compile fine but it would leak the 1 when a was overwritten with b, since destroying a after that frees the 2 instead of the 1. However, the sample code you linked contains the fixed version that frees the old value before overwriting it in the move assignment operator.. This seemed cute but probably isn't super portable. Happy to use a std::array<uint8_t, 16> or similar instead.. Not really, but I like its f-strings and this script will never need to be run by end users.. This is the same way includes of TableGen-generated code works. #undefing the macro here means that clients don't need to worry about doing it after #includeing the generated results. Strictly speaking, this guard is completely unnecessary since right now you either include the entire file or none of it. I could remove it if it seems distracting.. multiple spaces after comma (for the giant list) and invalid syntax (since flake8 doesn't know about some python3 f-string stuff).. f-strings were introduced in python 3.6, but I've removed them so we can relax this requirement to just python 3.. I removed the f-strings, so now any python3 should work and I could remove the E999. Comments added to .flake8.. Not necessary because the op buffer is always null terminated. I could definitely change it if it's a matter of principle, though.. @MaxGraey Most instructions wouldn't benefit much from that because the parser skips checking many intermediate characters, so I'm not sure it's worth the added complexity. If we really want to push performance here there are bigger algorithmic wins available to us such as choosing which character to look at based on which will discriminate the most instructions.. @MaxGraey that looks like it would work, but the logic for deciding when to use a switch and when to use an if/else looks like it would be more complicated than the current solution that always uses a switch. I think we can go with the current solution for now, but if you want to play around with it and see if you can get a perf win with a different solution we can definitely swap it in.. Unfortunately this pattern is necessary to keep the older compilers from complaining about reaching the end of a non-void function.. I agree that WASM_UNREACHABLE is not the right way to deal with bad input. I was careful in the binary parser to keep defaults for when we read junk bytes. In this particular instance, it seemed safe enough to assume that this function is being passed a valid AsmType.. Correct, a future PR will add assembling and disassembling.. Note that this PR does not introduce v128 literals. That will come in a future PR.. All uses of getBits will need to work for v128 types as well, so I think it would make sense to change getBits to fill a buffer with as many bits as there are in the underlying type.. This will come in the PR that introduces v128 literals, probably the next one.. Yes, essentially. The natural alignment of vectors is 16 bytes, and any smaller power of two alignment is also allowed. This will be implemented in a future PR.. I went ahead and renamed them since it was a relatively small change.. Seems like a fine change to make.. Another option here would be to change the argument to be a raw pointer. The nice thing about doing that (and not zeroing out the rest of the 16 bytes) is that you can use getBits to write into any type that is appropriate to hold the literal's underlying value (e.g. int32_t or int64_t) rather than just an array of bytes. WDYT?. I would not need to zero-initialize this array if I made the change to getBits that you suggest below, so this will be resolved by that discussion.. I used getBits (with the void* change) here since the literals have to be reinterpreted as the correct type before their bits can be extracted via geti32 and friends. Happy to change this if we decide to go the other direction with getBIts.. Yes, the current code now has getBits take a void*. You can see how this is used in the implementation of less at the bottom of literal.h. Overriding getBits for each size seems similar to removing the type asserts from geti32() and geti64(), which would also serve most of the same usecases. getBits would then become getv128 since it wouldn't be useful otherwise.. This is fixed now.. @kripken how critical is this given that the default setting is to enable SIMD values in the fuzzer?. Done.. Yes, the actual problem is that the abstract stuff isn't hooked up yet. However, that will require a little bit more work because abstract will need to gain a notion of SIMD lanes, so I'd rather save that for a separate PR.. Why not check the last element as well?. So you'd want to flow out the i32.const 1 even if the return was unreachable?. Nit: Might be simpler to return early if this condition is false rather than put the rest of the function in an if block.. If I understand this correctly, the fuzzer must now be run from a directory that is a sibling to the bin directory. Would it be better to use the options parsed in scripts/test/shared.py to allow access to --binaryen-bin? Granted, not all of those options make sense for a fuzzer, but it would also allow maximum flexibility and reduce duplicated effort. The only trick would be to separate the pass-through arguments from those that should be parsed by shared.py as options for the fuzzer itself. #1830 takes this approach but is slightly hacky.. This isn't part of this PR, but it would be good to raise an exception with a helpful message here for consistency in error reporting.. 2019!. ok I guess that's fine then :P. Is this a standard style we have in the codebase? It looks weird to me to have this split over two lines but only have one int, especially with the comment only on the second line.. Same here, I would usually default to putting the multiple declarations on the same line, even with definitions.. Here too.. here.. And here. No worries if this is the standard style, of course.. Cannot handle?. They do. This prefix should probably be renamed to MiscPrefix, as it is called in the spec proposals.. Instead of allocating in this function, it would be better to have the user pass in a buffer to be filled. That way the JS layer could use a stack allocation and avoid the malloc/free entirely. See how BinaryenLiteralVec128 is implemented and used for an example.. Sorry for the post-merge comment, but looking back at this, do we need to reset the ostream state after std::setfill and std::setw?. I think this code needs to be wrapped in a call to preserveStack to undo the stack allocation when it is done copying out the values.. Nice catch :+1: . Nice! I think it is good to get rid of this allocated temp. Perhaps we can have a variable to store the result of _BinaryenSizeofLiteral(), though? It seems silly to have so many calls into a function that always returns the same value.. where does this 12 come from?. :+1: . Sorry, this fell off my radar somehow. I think any error here is handled in the calling code. It's a bit moot since there is only one caller, but this lets the caller decide what is an error and what is not without the complexity of an allowError argument.. This is all copied from emscripten's shared.py. The only difference is that I added support for the capture_output parameter in run_process.. This fixes a bug where if some multiple of 256 tests fail, the exit code would be 0 (on linux, anyway).. This depends on #1950 to run.. @kripken ping. Does that seem reasonable or should I change this? CI failures after the latest push were due to a timeout.. It would be great to upgrade to python3 instead, but that should probably be a separate discussion.. @jgravelle-google I think we can wait to add capture_output to emscripten's shared.py until someone wants to use it. All it does is store the process's stdout and stderr on the returned object so they can be programmatically inspected. Emscripten tends to store output in temporary files instead.. @jgravelle-google Good point. I'm not sure a comment makes sense anymore with the change @sbc100 suggested, though.. Yes, this is definitely doing what I expect it to do, which is count unittest failures as equivalent to any other failures. shared.num_failures is imported into the global namespace of this module, but shared is not, so using shared.num_failures instead of global num_failures would require a redundant import. Looking at shared.fail_with_error, it basically does the same thing but respects the abort_on_first_failure option. I will update this code to respect that option as well.. Wow you're totally right. That's nuts. TIL. Fixing now.. ",
    "pepyakin": "Looks good to me. However, I would like to validate this PR on the original case. But I'm not sure how can I build emscripten with binaryen on #1111 branch.... Is there any way to pass this to rustc? \nBINARYEN env var doesn't work (. Yep, that worked, thank you! \nCan confirm that the original case is valid!. Yes, I have just joined.. Done!\nAs side question: I'm on macOS, and it looks like neither ./check.py nor ./auto_update_tests.py are working, because macOS waterfall builds.\n\nExpand `./check.py` output\n\n```\n$ ./check.py                                                                                                                                                                             \n(downloading waterfall 13645: https://storage.googleapis.com/wasm-llvm/builds/mac/13645/wasm-binaries-13645.tbz2)\nTraceback (most recent call last):\n  File \"./check.py\", line 24, in \n    from scripts.test.shared import (\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/shared.py\", line 249, in \n    fetch_waterfall()\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/shared.py\", line 217, in fetch_waterfall\n    downloaded = urllib2.urlopen(url).read().strip()\n  File \"/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 154, in urlopen\n    return opener.open(url, data, timeout)\n  File \"/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 437, in open\n    response = meth(req, response)\n  File \"/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 550, in http_response\n    'http', request, response, code, msg, hdrs)\n  File \"/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 475, in error\n    return self._call_chain(*args)\n  File \"/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 409, in _call_chain\n    result = func(*args)\n  File \"/usr/local/Cellar/python/2.7.9/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.py\", line 558, in http_error_default\n    raise HTTPError(req.get_full_url(), code, msg, hdrs, fp)\nurllib2.HTTPError: HTTP Error 404: Not Found\n```\n\n\nBecause of this I had to write my own Dockerfile. I'm wondering if it is worth to check-in that Dockerfile for those like me?. > Hmm, you can run check and auto-update with --no-test-waterfall to work around that. \nIndeed, --no-test-waterfall helped, thanks! But there is another issue popped up.\n\nDockerfile looks like it might be useful to check in, yeah. Is there a convention for such things, like what directory they go in, etc?\n\nI'm not an expert in such kind of things. Example that I know of is rust, but they use docker along with Travis CI.. Travis-CI failure looks like it is spurious.\nThe command \"sudo -E apt-get -yq --no-install-suggests --no-install-recommends --force-yes install cmake g++-5\" failed and exited with 100 during .. As an aside, is it correct to reuse Expression in a such way?\nCan code like this cause problems?\nc\nBinaryenExpressionRef x = GenerateBIgExpressionTree(module);\nBinaryenExpressionRef y = BinaryenBinary(module, BinaryenAddInt32(), x, x);\n. Thank you for clarifying!. It seems there are actually different failures that show up non-deterministically!\nAssertion failed: (doWorkers.size() == num), function work, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 161.\nAssertion failed: (old == threads.size()), function resetThreadsAreReady, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 195.\nAssertion failed: (!running), function work, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 162.\nAssertion failed: (ec == 0), function unlock, file /BuildRoot/Library/Caches/com.apple.xbs/Sources/libcxx/libcxx-307.5/src/mutex.cpp, line 48.\nAnd it also can just succeed or never terminate!\n. So, when it doesn't terminate, there are couple of threads sitting in wasm::Thread::mainLoop:98. https://github.com/pepyakin/binaryen-rs/blob/d307d5ae20918effb6f273f80671a0376a0165f4/src/lib.rs#L1236 \nAlso, the same failure was spotted while executing this test\nhttps://github.com/pepyakin/binaryen-rs/blob/d307d5ae20918effb6f273f80671a0376a0165f4/src/lib.rs#L1252\nAssertion failed: (ec == 0), function unlock, file /BuildRoot/Library/Caches/com.apple.xbs/Sources/libcxx/libcxx-307.5/src/mutex.cpp, line 48.\nProcess 98665 stopped\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-34bc79fc7b73fca8) stopped.\n(lldb) bt\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylib`pthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylib`abort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib`__assert_rtn + 320\n    frame #4: 0x00007fff8ece7142 libc++.1.dylib`std::__1::mutex::unlock() + 54\n    frame #5: 0x0000000100389292 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::initialize(unsigned long) [inlined] std::__1::unique_lock<std::__1::mutex>::~unique_lock(this=0x000070000679bd20) at __mutex_base:157\n    frame #6: 0x0000000100389272 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::initialize(unsigned long) [inlined] std::__1::unique_lock<std::__1::mutex>::~unique_lock(this=0x000070000679bd20) at __mutex_base:155\n    frame #7: 0x0000000100389272 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::initialize(this=0x0000000100c021e0, num=8) at threads.cpp:126\n    frame #8: 0x0000000100387a14 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::get() at threads.cpp:143\n    frame #9: 0x00000001000e8477 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000679c970)::$_0::operator()() const at pass.cpp:276\n    frame #10: 0x00000001000e6dd3 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000679d550) at pass.cpp:311\n    frame #11: 0x000000010040a969 binaryen-34bc79fc7b73fca8`wasm::WasmValidator::validate(this=0x000070000679d758, module=0x0000000100c02730, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #12: 0x00000001000469e4 binaryen-34bc79fc7b73fca8`::BinaryenModuleValidate(module=0x0000000100c02730) at binaryen-c.cpp:2004\n    frame #13: 0x0000000100006ee9 binaryen-34bc79fc7b73fca8`binaryen::Module::is_valid::h6f7fe82e8fe3f983 + 57\n    frame #14: 0x000000010000b512 binaryen-34bc79fc7b73fca8`binaryen::tests::test_hello_world::hcd6bc71bba10d3ff + 450\n    frame #15: 0x000000010002c542 binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #16: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #17: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #18: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #19: 0x000000010001ca41 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #20: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #21: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #22: 0x000000010001c8a9 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #23: 0x00000001000222d8 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #24: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #25: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #26: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #27: 0x0000000100038a02 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #28: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #29: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #30: 0x000000010003897c binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #31: 0x0000000100461908 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #32: 0x0000000100461905 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #33: 0x000000010046b9c9 binaryen-34bc79fc7b73fca8`std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #34: 0x00007fff9033493b libsystem_pthread.dylib`_pthread_body + 180\n    frame #35: 0x00007fff90334887 libsystem_pthread.dylib`_pthread_start + 286\n    frame #36: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13. https://github.com/pepyakin/binaryen-rs/blob/d307d5ae20918effb6f273f80671a0376a0165f4/src/lib.rs#L1236\nAssertion failed: (!running), function work, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 162.\nProcess 98697 stopped\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-34bc79fc7b73fca8) stopped.\n(lldb) bt\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylib`pthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylib`abort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib`__assert_rtn + 320\n    frame #4: 0x00000001003899be binaryen-34bc79fc7b73fca8`wasm::ThreadPool::work(this=0x00000001025003c0, doWorkers=size=1)>, std::__1::allocator<std::__1::function<wasm::ThreadWorkState ()> > >&) at threads.cpp:162\n    frame #5: 0x00000001000e8931 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000ef42970)::$_0::operator()() const at pass.cpp:299\n    frame #6: 0x00000001000e6dd3 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000ef43550) at pass.cpp:311\n    frame #7: 0x000000010040a969 binaryen-34bc79fc7b73fca8`wasm::WasmValidator::validate(this=0x000070000ef43758, module=0x0000000100c09c50, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #8: 0x00000001000469e4 binaryen-34bc79fc7b73fca8`::BinaryenModuleValidate(module=0x0000000100c09c50) at binaryen-c.cpp:2004\n    frame #9: 0x0000000100006ee9 binaryen-34bc79fc7b73fca8`binaryen::Module::is_valid::h6f7fe82e8fe3f983 + 57\n    frame #10: 0x000000010000b512 binaryen-34bc79fc7b73fca8`binaryen::tests::test_hello_world::hcd6bc71bba10d3ff + 450\n    frame #11: 0x000000010002c542 binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #12: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #13: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #14: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #15: 0x000000010001ca41 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #16: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #17: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #18: 0x000000010001c8a9 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #19: 0x00000001000222d8 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #20: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #21: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #22: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #23: 0x0000000100038a02 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #24: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #25: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #26: 0x000000010003897c binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #27: 0x0000000100461908 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #28: 0x0000000100461905 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #29: 0x000000010046b9c9 binaryen-34bc79fc7b73fca8`std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #30: 0x00007fff9033493b libsystem_pthread.dylib`_pthread_body + 180\n    frame #31: 0x00007fff90334887 libsystem_pthread.dylib`_pthread_start + 286\n    frame #32: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13. https://github.com/pepyakin/binaryen-rs/blob/d307d5ae20918effb6f273f80671a0376a0165f4/src/lib.rs#L1252\nAssertion failed: (!ThreadPool::get()->isRunning()), function Thread, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 50.\ntest tests::test_relooper_with_different_module ... ok\nProcess 98716 stopped\n* thread #2, name = 'tests::test_simple', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-34bc79fc7b73fca8) stopped.\n(lldb) bt\n* thread #2, name = 'tests::test_simple', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylib`pthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylib`abort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib`__assert_rtn + 320\n    frame #4: 0x00000001003872f3 binaryen-34bc79fc7b73fca8`wasm::Thread::Thread(this=0x0000000100c025e0) at threads.cpp:50\n    frame #5: 0x0000000100387ef5 binaryen-34bc79fc7b73fca8`wasm::Thread::Thread(this=0x0000000100c025e0) at threads.cpp:49\n    frame #6: 0x0000000100389444 binaryen-34bc79fc7b73fca8`std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > wasm::make_unique<wasm::Thread>() at utilities.h:60\n    frame #7: 0x0000000100388882 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::initialize(this=0x0000000100c02390, num=8) at threads.cpp:115\n    frame #8: 0x0000000100387a14 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::get() at threads.cpp:143\n    frame #9: 0x00000001000e8477 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000a1c78f0)::$_0::operator()() const at pass.cpp:276\n    frame #10: 0x00000001000e6dd3 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000a1c84d0) at pass.cpp:311\n    frame #11: 0x000000010040a969 binaryen-34bc79fc7b73fca8`wasm::WasmValidator::validate(this=0x000070000a1c86d8, module=0x0000000102500180, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #12: 0x00000001000469e4 binaryen-34bc79fc7b73fca8`::BinaryenModuleValidate(module=0x0000000102500180) at binaryen-c.cpp:2004\n    frame #13: 0x0000000100006ee9 binaryen-34bc79fc7b73fca8`binaryen::Module::is_valid::h6f7fe82e8fe3f983 + 57\n    frame #14: 0x000000010000b809 binaryen-34bc79fc7b73fca8`binaryen::tests::test_simple::h103cd8ffdd599a23 + 617\n    frame #15: 0x000000010002c542 binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #16: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #17: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #18: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #19: 0x000000010001ca41 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #20: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #21: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #22: 0x000000010001c8a9 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #23: 0x00000001000222d8 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #24: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #25: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #26: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #27: 0x0000000100038a02 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #28: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #29: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #30: 0x000000010003897c binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #31: 0x0000000100461908 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #32: 0x0000000100461905 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #33: 0x000000010046b9c9 binaryen-34bc79fc7b73fca8`std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #34: 0x00007fff9033493b libsystem_pthread.dylib`_pthread_body + 180\n    frame #35: 0x00007fff90334887 libsystem_pthread.dylib`_pthread_start + 286\n    frame #36: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13\n(lldb)\nThird one from BinaryenModuleValidate. https://github.com/pepyakin/binaryen-rs/blob/d307d5ae20918effb6f273f80671a0376a0165f4/src/lib.rs#L1236\nAnother one from BinaryenModuleValidate\nAssertion failed: (!ThreadPool::test to_cstr::tests::test_use_cases ... get()->isRunning()), function Thread, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 50.\nok\nProcess 98751 stopped\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-34bc79fc7b73fca8) stopped.\n(lldb) bt\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylib`pthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylib`abort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib`__assert_rtn + 320\n    frame #4: 0x00000001003872f3 binaryen-34bc79fc7b73fca8`wasm::Thread::Thread(this=0x0000000102b00c00) at threads.cpp:50\n    frame #5: 0x0000000100387ef5 binaryen-34bc79fc7b73fca8`wasm::Thread::Thread(this=0x0000000102b00c00) at threads.cpp:49\n    frame #6: 0x0000000100389444 binaryen-34bc79fc7b73fca8`std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > wasm::make_unique<wasm::Thread>() at utilities.h:60\n    frame #7: 0x0000000100388882 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::initialize(this=0x0000000100e003a0, num=8) at threads.cpp:115\n    frame #8: 0x0000000100387a14 binaryen-34bc79fc7b73fca8`wasm::ThreadPool::get() at threads.cpp:143\n    frame #9: 0x00000001000e8477 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000b31e970)::$_0::operator()() const at pass.cpp:276\n    frame #10: 0x00000001000e6dd3 binaryen-34bc79fc7b73fca8`wasm::PassRunner::run(this=0x000070000b31f550) at pass.cpp:311\n    frame #11: 0x000000010040a969 binaryen-34bc79fc7b73fca8`wasm::WasmValidator::validate(this=0x000070000b31f758, module=0x0000000100d004a0, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #12: 0x00000001000469e4 binaryen-34bc79fc7b73fca8`::BinaryenModuleValidate(module=0x0000000100d004a0) at binaryen-c.cpp:2004\n    frame #13: 0x0000000100006ee9 binaryen-34bc79fc7b73fca8`binaryen::Module::is_valid::h6f7fe82e8fe3f983 + 57\n    frame #14: 0x000000010000b512 binaryen-34bc79fc7b73fca8`binaryen::tests::test_hello_world::hcd6bc71bba10d3ff + 450\n    frame #15: 0x000000010002c542 binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #16: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #17: 0x000000010002c53d binaryen-34bc79fc7b73fca8`test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #18: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #19: 0x000000010001ca41 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #20: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #21: 0x000000010001c9fc binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #22: 0x000000010001c8a9 binaryen-34bc79fc7b73fca8`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #23: 0x00000001000222d8 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #24: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #25: 0x00000001000222c2 binaryen-34bc79fc7b73fca8`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #26: 0x0000000100479aef binaryen-34bc79fc7b73fca8`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #27: 0x0000000100038a02 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #28: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #29: 0x00000001000389c9 binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #30: 0x000000010003897c binaryen-34bc79fc7b73fca8`alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #31: 0x0000000100461908 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #32: 0x0000000100461905 binaryen-34bc79fc7b73fca8`std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #33: 0x000000010046b9c9 binaryen-34bc79fc7b73fca8`std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #34: 0x00007fff9033493b libsystem_pthread.dylib`_pthread_body + 180\n    frame #35: 0x00007fff90334887 libsystem_pthread.dylib`_pthread_start + 286\n    frame #36: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13. I don't know about C++ memory model and concurrency semantics but  doesn't this should be wrapped in somekind of mutex? \nhttps://github.com/WebAssembly/binaryen/blob/63ebdb6d360c6e96e6f0e10974dfd8c29baade73/src/support/threads.cpp#L140-L146\nBecause, at the time we get into initialze some other thread might get there and initialize pool twice?\n\nRust starts to panic\n\nNo there are no panics. What you see is machinery to catch a panic and a test setup.\n. Example of BINARYEN_THREAD_DEBUG\n```\n[POOL] initialize()\n[POOL] initialize()\n[POOL] work() sequentially\n[POOL] reset threads are ready\ntest to_cstr::tests::test_use_cases ... ok\ntest tests::test_relooper_with_different_module ... ok\n(block\n[THREAD  (block 0x70000c3a1000$] block$2$breakchecking for work\n[THREAD 0x70000bd98000(] nopchecking for work\n)\n  ([THREAD block0x70000be1b000]\nchecking for work\n   (br $block$2$break)\n  )\n )\n (block\n  (nop[THREAD )0x70000be9e000\n]  checking for work\n)\n)\n[THREAD 0x70000c424000] checking for work\ntest relooper::tests::test ... [POOL] notify thread is ready\nok\n[THREAD 0x70000c4a7000] checking for work\n[THREAD 0x70000c52a000] checking for work\n[POOL] initialize() waiting\n[THREAD 0x70000c5ad000] checking for work\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] work() on threads\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[POOL] reset threads are ready\nAssertion failed: (!ThreadPool::get()->isRunning()), function Thread, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 52.\nerror: An unknown error occurred\n```\nrunning 8 tests\ntest to_cstr::tests::test_to_cstr_stash_option ... ok\ntest tests::test_use_same_expr_twice ... ok\ntest to_cstr::tests::test_use_cases ... [POOL] ok\ninitialize()\n[POOL] work() sequentially\n[POOL] work() sequentially\n[POOL] reset threads are ready\ntest tests::test_relooper_with_different_module ... [THREAD ok\n0x70001060e000] checking for work\n([THREAD test tests::test_unreachable ... ok\nblock\n0x700010005000] checking for work\n (block [THREAD $block$2$break\n0x700010088000  (nop)\n ]  checking for work\n(block\n[POOL] notify thread is ready\n   (br $block$2$break)\n  )\n )\n[THREAD  0x70001010b000(block\n]  checking for work\n (nop)\n[THREAD  )\n0x700010691000)]\nchecking for work\n[THREAD 0x700010714000] test relooper::tests::test ... checking for work\nok\n[THREAD 0x700010797000] checking for work\n[POOL] initialize() waiting\n[POOL] notify thread is ready\n[THREAD 0x70001040b000] checking for work\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] work() on threads\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x70001060e000] thread waiting\n[THREAD 0x700010005000] thread waiting\n[THREAD 0x700010088000] thread waiting\n[THREAD 0x700010691000] thread waiting\n[THREAD 0x70001010b000] thread waiting\n[THREAD 0x700010714000] thread waiting\n[POOL] reset threads are ready\nAssertion failed: (old == threads.size()), function resetThreadsAreReady, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 197.. > I see, thanks. As I said, I know very little about Rust :)\nYeah, feel free to ask in future!\n\nAnother issue is that I think you are running tests in multiple threads? We didn't test that, so we need some more carefulness to handle that properly.\n\nExactly! I assumed C API is supposed to run fine in multithread environment, is this assumption correct?. Ok, I've updated binaryen to the latest master and getting following two failures:\nFirst:\nrunning 9 tests\nAssertion failed: (!ThreadPool::isRunning()), function Thread, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 51.\nProcess 89480 stopped\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-0f7351d0ba7e4ea7) stopped.\n(lldb) bt\n* thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylib`pthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylib`abort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib`__assert_rtn + 320\n    frame #4: 0x0000000100376993 binaryen-0f7351d0ba7e4ea7`wasm::Thread::Thread(this=0x0000000102300b50) at threads.cpp:51\n    frame #5: 0x0000000100377245 binaryen-0f7351d0ba7e4ea7`wasm::Thread::Thread(this=0x0000000102300b50) at threads.cpp:50\n    frame #6: 0x0000000100378bc4 binaryen-0f7351d0ba7e4ea7`std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > wasm::make_unique<wasm::Thread>() at utilities.h:60\n    frame #7: 0x0000000100378002 binaryen-0f7351d0ba7e4ea7`wasm::ThreadPool::initialize(this=0x0000000102300720, num=8) at threads.cpp:116\n    frame #8: 0x0000000100377c84 binaryen-0f7351d0ba7e4ea7`wasm::ThreadPool::get() at threads.cpp:157\n    frame #9: 0x00000001000d04c7 binaryen-0f7351d0ba7e4ea7`wasm::PassRunner::run(this=0x000070000a037970)::$_0::operator()() const at pass.cpp:276\n    frame #10: 0x00000001000cee23 binaryen-0f7351d0ba7e4ea7`wasm::PassRunner::run(this=0x000070000a038550) at pass.cpp:311\n    frame #11: 0x00000001003facc9 binaryen-0f7351d0ba7e4ea7`wasm::WasmValidator::validate(this=0x000070000a038758, module=0x0000000102300190, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #12: 0x000000010002bc34 binaryen-0f7351d0ba7e4ea7`::BinaryenModuleValidate(module=0x0000000102300190) at binaryen-c.cpp:2006\n    frame #13: 0x000000010000d2f9 binaryen-0f7351d0ba7e4ea7`binaryen::Module::is_valid::h30b6f4c52bdc3dc8 + 57\n    frame #14: 0x000000010000b322 binaryen-0f7351d0ba7e4ea7`binaryen::tests::test_hello_world::hfb02bbe837ce977a + 450\n    frame #15: 0x0000000100469fc2 binaryen-0f7351d0ba7e4ea7`test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #16: 0x0000000100469fbd binaryen-0f7351d0ba7e4ea7`test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #17: 0x0000000100469fbd binaryen-0f7351d0ba7e4ea7`test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #18: 0x00000001004acc7f binaryen-0f7351d0ba7e4ea7`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #19: 0x000000010045a4c1 binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #20: 0x000000010045a47c binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #21: 0x000000010045a47c binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #22: 0x000000010045a329 binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #23: 0x000000010045fd58 binaryen-0f7351d0ba7e4ea7`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #24: 0x000000010045fd42 binaryen-0f7351d0ba7e4ea7`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #25: 0x000000010045fd42 binaryen-0f7351d0ba7e4ea7`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #26: 0x00000001004acc7f binaryen-0f7351d0ba7e4ea7`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #27: 0x0000000100476482 binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #28: 0x0000000100476449 binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #29: 0x0000000100476449 binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #30: 0x00000001004763fc binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #31: 0x0000000100494a78 binaryen-0f7351d0ba7e4ea7`std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #32: 0x0000000100494a75 binaryen-0f7351d0ba7e4ea7`std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #33: 0x000000010049eb59 binaryen-0f7351d0ba7e4ea7`std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #34: 0x00007fff9033493b libsystem_pthread.dylib`_pthread_body + 180\n    frame #35: 0x00007fff90334887 libsystem_pthread.dylib`_pthread_start + 286\n    frame #36: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13\nand second:\nrunning 9 tests\ntest to_cstr::tests::test_to_cstr_stash_option ... ok\nAssertion failed: (!running), fuAssertion failed: (!ThreadPool::nction work, file /Users/pepyakiisRunning()), function Thread, fn/dev/my/binaryen-rs/binaryen-syile /Users/pepyakin/dev/my/binars/binaryen/src/support/threads.cyen-rs/binaryen-sys/binaryen/srcpp, line 177.\n/support/threads.cpp, line 51.\nProcess 89603 stopped\n* thread #2, name = 'tests::test_unreachable', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-0f7351d0ba7e4ea7) stopped.\n(lldb) bt\n* thread #2, name = 'tests::test_unreachable', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib`__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylib`pthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylib`abort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib`__assert_rtn + 320\n    frame #4: 0x000000010037913e binaryen-0f7351d0ba7e4ea7`wasm::ThreadPool::work(this=0x0000000100c02ba0, doWorkers=size=1)>, std::__1::allocator<std::__1::function<wasm::ThreadWorkState ()> > >&) at threads.cpp:177\n    frame #5: 0x00000001000d0981 binaryen-0f7351d0ba7e4ea7`wasm::PassRunner::run(this=0x0000700000c5c950)::$_0::operator()() const at pass.cpp:299\n    frame #6: 0x00000001000cee23 binaryen-0f7351d0ba7e4ea7`wasm::PassRunner::run(this=0x0000700000c5d530) at pass.cpp:311\n    frame #7: 0x00000001003facc9 binaryen-0f7351d0ba7e4ea7`wasm::WasmValidator::validate(this=0x0000700000c5d738, module=0x0000000102b00190, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #8: 0x000000010002bc34 binaryen-0f7351d0ba7e4ea7`::BinaryenModuleValidate(module=0x0000000102b00190) at binaryen-c.cpp:2006\n    frame #9: 0x000000010000d2f9 binaryen-0f7351d0ba7e4ea7`binaryen::Module::is_valid::h30b6f4c52bdc3dc8 + 57\n    frame #10: 0x000000010000bbdc binaryen-0f7351d0ba7e4ea7`binaryen::tests::test_unreachable::h57159d1bc306b867 + 524\n    frame #11: 0x0000000100469fc2 binaryen-0f7351d0ba7e4ea7`test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #12: 0x0000000100469fbd binaryen-0f7351d0ba7e4ea7`test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #13: 0x0000000100469fbd binaryen-0f7351d0ba7e4ea7`test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #14: 0x00000001004acc7f binaryen-0f7351d0ba7e4ea7`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #15: 0x000000010045a4c1 binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #16: 0x000000010045a47c binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #17: 0x000000010045a47c binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #18: 0x000000010045a329 binaryen-0f7351d0ba7e4ea7`std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #19: 0x000000010045fd58 binaryen-0f7351d0ba7e4ea7`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #20: 0x000000010045fd42 binaryen-0f7351d0ba7e4ea7`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #21: 0x000000010045fd42 binaryen-0f7351d0ba7e4ea7`std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #22: 0x00000001004acc7f binaryen-0f7351d0ba7e4ea7`panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #23: 0x0000000100476482 binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #24: 0x0000000100476449 binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #25: 0x0000000100476449 binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #26: 0x00000001004763fc binaryen-0f7351d0ba7e4ea7`alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #27: 0x0000000100494a78 binaryen-0f7351d0ba7e4ea7`std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #28: 0x0000000100494a75 binaryen-0f7351d0ba7e4ea7`std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #29: 0x000000010049eb59 binaryen-0f7351d0ba7e4ea7`std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #30: 0x00007fff9033493b libsystem_pthread.dylib`_pthread_body + 180\n    frame #31: 0x00007fff90334887 libsystem_pthread.dylib`_pthread_start + 286\n    frame #32: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13\nThese failures are not so frequent as with previous version (i.e. with this version I can get 3-4 successful runs in a row). First failure is definitely more frequent than second one.. Hm, it seems BINARYEN_THREAD_DEBUG uncovers some more failures.\nNote that cpp line numbers skewed a little because I added #define BINARYEN_THREAD_DEBUG\n```\nrunning 9 tests\ntest to_cstr::tests::test_to_cstr_stash_option ... ok\ntest tests::test_use_same_expr_twice ... ok\ntest to_cstr::tests::test_use_cases ... ok\n[POOL] ::get()\n[POOL] ::get()\n[POOL] ::get()\n[POOL] ::get() creating\n[POOL] initialize()\n[POOL] reset threads are ready\n[POOL] ::get()\n[POOL] check if running\n[POOL] ::get()\ntest tests::test_relooper_with_different_module ... ok\n[POOL] work() sequentially\n[POOL] work() sequentially\n[POOL] check if running\n(block[THREAD\n (block $block$2$break\n0x70000ca4e000]  checking for work\n [POOL] (check if running\ntest tests::test_unreachable ... ok\n[THREAD nop0x70000c242000] )checking for work\n[POOL] (::get()\n[THREAD block\n0x70000c2c5000   (br ] $checking for work\nblock$2$break)\n  [POOL] )check if running\n[POOL] )::get()\n[POOL]  notify thread is ready\n(block\n  (nop)\n[POOL]  ::get()\n)\n[POOL] )\ncheck if running\n[THREAD 0x70000c348000] checking for work\ntest relooper::tests::test ... [POOL] notify thread is ready\nok\n[POOL] notify thread is ready\n[POOL] ::get()\n[POOL] check if running\n[THREAD 0x70000c648000] checking for work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] check if running\n[POOL] ::get()\n[THREAD 0x70000be3c000] checking for work\n[POOL] notify thread is ready\n[POOL] work() on threads\n[POOL] notify thread is ready\n[POOL] check if running\nAssertion failed: (doWorkers.size() == num), function work, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/su[THREAD pport/threads.cpp, line 178.\n0x70000bebf000] checking for work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] initialize() waiting\n[THREAD 0x70000bf42000] checking for work\nProcess 90265 stopped\n thread #2, name = 'tests::test_simple', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\nlibsystem_kernel.dylib__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-0f7351d0ba7e4ea7) stopped.\n(lldb) bt\n thread #2, name = 'tests::test_simple', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylibpthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylibabort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib__assert_rtn + 320\n    frame #4: 0x000000010037a77b binaryen-0f7351d0ba7e4ea7wasm::ThreadPool::work(this=0x0000000100c020d0, doWorkers=size=1)>, std::__1::allocator<std::__1::function<wasm::ThreadWorkState ()> > >&) at threads.cpp:178\n    frame #5: 0x00000001000d08d1 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x000070000c5c38f0)::$_0::operator()() const at pass.cpp:299\n    frame #6: 0x00000001000ced73 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x000070000c5c44d0) at pass.cpp:311\n    frame #7: 0x00000001003fc7c9 binaryen-0f7351d0ba7e4ea7wasm::WasmValidator::validate(this=0x000070000c5c46d8, module=0x0000000103c00080, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #8: 0x000000010002bb84 binaryen-0f7351d0ba7e4ea7::BinaryenModuleValidate(module=0x0000000103c00080) at binaryen-c.cpp:2006\n    frame #9: 0x000000010000d249 binaryen-0f7351d0ba7e4ea7binaryen::Module::is_valid::h30b6f4c52bdc3dc8 + 57\n    frame #10: 0x000000010000b607 binaryen-0f7351d0ba7e4ea7binaryen::tests::test_simple::h0dd0ae5c0c283f4d + 775\n    frame #11: 0x000000010046bac2 binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #12: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #13: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #14: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #15: 0x000000010045bfc1 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe> at panicking.rs:459 [opt]\n    frame #16: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #17: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #18: 0x000000010045be29 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #19: 0x0000000100461858 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}} at mod.rs:406 [opt]\n    frame #20: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #21: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> at panicking.rs:480 [opt]\n    frame #22: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #23: 0x0000000100477f82 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe> at panicking.rs:459 [opt]\n    frame #24: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #25: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}} at mod.rs:405 [opt]\n    frame #26: 0x0000000100477efc binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #27: 0x0000000100496578 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #28: 0x0000000100496575 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #29: 0x00000001004a0659 binaryen-0f7351d0ba7e4ea7std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #30: 0x00007fff9033493b libsystem_pthread.dylib_pthread_body + 180\n    frame #31: 0x00007fff90334887 libsystem_pthread.dylib_pthread_start + 286\n    frame #32: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13\n```\n```\nrunning 9 tests\ntest to_cstr::tests::test_to_cstr_stash_option ... ok\n[POOL] ::get()\n[POOL] ::get()\n[POOL] test tests::test_use_same_expr_twice ... ::get()\nok[POOL]\n::get() creating\ntest to_cstr::tests::test_use_cases ... ok\ntest tests::test_relooper_with_different_module ... ok\n([POOL] blockinitialize()\n[POOL]  ::get()\n(block $block$2$break\n[POOL]  ::get()\n [POOL] (reset threads are ready\nnop)\n  [POOL] (work() sequentially\nblock\n   (br $block$2$break)\n[POOL]   )\nwork() sequentially\n )\n (block\n  (nop)\n[POOL]  check if running\n)\n)\n[POOL] check if running\n[THREAD 0x70000d1c6000test relooper::tests::test ... ] checking for work\nok\n[POOL] test tests::test_unreachable ... check if running\nok\n[POOL] ::get()\n[THREAD 0x70000d249000] checking for work\n[POOL] notify thread is ready\n[THREAD 0x70000cdc0000] checking for work\n[POOL] check if running\n[POOL] ::get()\n[POOL] ::get()\n[POOL] notify thread is ready\n[POOL] check if running\n[THREAD 0x70000ce43000] checking for work\n[POOL] notify thread is ready\n[POOL] check if running\n[THREAD 0x70000cec6000] checking for work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] check if running\n[THREAD 0x70000d2cc000] checking for work\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] check if running\n[POOL] ::get()\n[THREAD 0x70000d5cc000] checking for work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x70000d64f000] checking for work\n[POOL] initialize() waiting\n[POOL] ::get()\n[POOL] ::get()\n[POOL] ::get()\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[POOL] work() on threads\n[POOL] notify thread is ready\n[THREAD 0x70000d1c6000] thread waiting\n[THREAD 0x70000d249000] thread waiting\n[THREAD 0x70000cdc0000] thread waiting\n[THREAD 0x70000ce43000] thread waiting\n[THREAD 0x70000cec6000] thread waiting\n[THREAD 0x70000d2cc000] thread waiting\n[THREAD 0x70000d5cc000] thread waiting\n[POOL] are threads ready?\n[POOL] reset threads are ready\nAssertion failed: (old == threads.size()), function resetThreadsAreReady, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 213.\nProcess 90273 stopped\n thread #2, name = 'tests::test_simple', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\nlibsystem_kernel.dylib__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-0f7351d0ba7e4ea7) stopped.\n(lldb) bt\n thread #2, name = 'tests::test_simple', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylibpthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylibabort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib__assert_rtn + 320\n    frame #4: 0x0000000100379fcf binaryen-0f7351d0ba7e4ea7wasm::ThreadPool::resetThreadsAreReady(this=0x0000000102f004b0) at threads.cpp:213\n    frame #5: 0x000000010037a878 binaryen-0f7351d0ba7e4ea7wasm::ThreadPool::work(this=0x0000000102f004b0, doWorkers=size=1)>, std::__1::allocator > >&) at threads.cpp:182\n    frame #6: 0x00000001000d08d1 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x000070000d5478f0)::$_0::operator()() const at pass.cpp:299\n    frame #7: 0x00000001000ced73 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x000070000d5484d0) at pass.cpp:311\n    frame #8: 0x00000001003fc7c9 binaryen-0f7351d0ba7e4ea7wasm::WasmValidator::validate(this=0x000070000d5486d8, module=0x0000000102b00420, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #9: 0x000000010002bb84 binaryen-0f7351d0ba7e4ea7::BinaryenModuleValidate(module=0x0000000102b00420) at binaryen-c.cpp:2006\n    frame #10: 0x000000010000d249 binaryen-0f7351d0ba7e4ea7binaryen::Module::is_valid::h30b6f4c52bdc3dc8 + 57\n    frame #11: 0x000000010000b607 binaryen-0f7351d0ba7e4ea7binaryen::tests::test_simple::h0dd0ae5c0c283f4d + 775\n    frame #12: 0x000000010046bac2 binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #13: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once at function.rs:223 [opt]\n    frame #14: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #15: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #16: 0x000000010045bfc1 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #17: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] std::panic::catch_unwind,()> at panic.rs:365 [opt]\n    frame #18: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #19: 0x000000010045be29 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace at backtrace.rs:133 [opt]\n    frame #20: 0x0000000100461858 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}}<closure,()> at mod.rs:406 [opt]\n    frame #21: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #22: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> at panicking.rs:480 [opt]\n    frame #23: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #24: 0x0000000100477f82 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe<closure>> at panicking.rs:459 [opt]\n    frame #25: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind,()> at panic.rs:365 [opt]\n    frame #26: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}}<closure,()> at mod.rs:405 [opt]\n    frame #27: 0x0000000100477efc binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #28: 0x0000000100496578 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #29: 0x0000000100496575 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #30: 0x00000001004a0659 binaryen-0f7351d0ba7e4ea7std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #31: 0x00007fff9033493b libsystem_pthread.dylib_pthread_body + 180\n    frame #32: 0x00007fff90334887 libsystem_pthread.dylib_pthread_start + 286\n    frame #33: 0x00007fff9033408d libsystem_pthread.dylibthread_start + 13\n```\n```\nrunning 9 tests\ntest to_cstr::tests::test_to_cstr_stash_option ... ok\n[POOL] test tests::test_use_same_expr_twice ... ::get()\nok\n[POOL] ::get()\ntest to_cstr::tests::test_use_cases ... [POOL] ::get()\nok\n[POOL] ::get() creating\n[POOL] initialize()\n[POOL] reset threads are ready\n[POOL] check if running\n[POOL] ::get()\ntest tests::test_relooper_with_different_module ... ok[POOL]\ncheck if running\n[POOL] ::get()\n[POOL] work() on threads\n[THREAD 0x7000073ab000(block] checking for work\n[POOL]  work() on threads\n(block $block$2$break\n[THREAD Assertion failed: (!running), function work, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 179.\n 0x700006da2000 ] (checking for work\nnop)\n[POOL]  check if running\nProcess 90277 stopped\n thread #2, name = 'tests::test_unreachable', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\nlibsystem_kernel.dylib__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-0f7351d0ba7e4ea7) stopped.\n(lldb) bt\n thread #2, name = 'tests::test_unreachable', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylibpthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylibabort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib__assert_rtn + 320\n    frame #4: 0x000000010037a7fc binaryen-0f7351d0ba7e4ea7wasm::ThreadPool::work(this=0x0000000103000130, doWorkers=size=1)>, std::__1::allocator<std::__1::function<wasm::ThreadWorkState ()> > >&) at threads.cpp:179\n    frame #5: 0x00000001000d08d1 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x0000700007326950)::$_0::operator()() const at pass.cpp:299\n    frame #6: 0x00000001000ced73 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x0000700007327530) at pass.cpp:311\n    frame #7: 0x00000001003fc7c9 binaryen-0f7351d0ba7e4ea7wasm::WasmValidator::validate(this=0x0000700007327738, module=0x0000000100c09e50, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #8: 0x000000010002bb84 binaryen-0f7351d0ba7e4ea7::BinaryenModuleValidate(module=0x0000000100c09e50) at binaryen-c.cpp:2006\n    frame #9: 0x000000010000d249 binaryen-0f7351d0ba7e4ea7binaryen::Module::is_valid::h30b6f4c52bdc3dc8 + 57\n    frame #10: 0x000000010000bb2c binaryen-0f7351d0ba7e4ea7binaryen::tests::test_unreachable::h57159d1bc306b867 + 524\n    frame #11: 0x000000010046bac2 binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #12: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #13: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #14: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #15: 0x000000010045bfc1 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe> at panicking.rs:459 [opt]\n    frame #16: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #17: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #18: 0x000000010045be29 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #19: 0x0000000100461858 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}} at mod.rs:406 [opt]\n    frame #20: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #21: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> at panicking.rs:480 [opt]\n    frame #22: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #23: 0x0000000100477f82 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe> at panicking.rs:459 [opt]\n    frame #24: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #25: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}} at mod.rs:405 [opt]\n    frame #26: 0x0000000100477efc binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #27: 0x0000000100496578 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #28: 0x0000000100496575 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #29: 0x00000001004a0659 binaryen-0f7351d0ba7e4ea7std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #30: 0x00007fff9033493b libsystem_pthread.dylib_pthread_body + 180\n    frame #31: 0x00007fff90334887 libsystem_pthread.dylib_pthread_start + 286\n    frame #32: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13\n```\n```\nrunning 9 tests\ntest tests::test_use_same_expr_twice ... ok\n[POOL] ::get()\n[POOL] test to_cstr::tests::test_to_cstr_stash_option ... ::get()\n[POOL] ok::get()\n[POOL] ::get() creating\n[POOL] initialize()\n[POOL] reset threads are ready\n[POOL] check if running\ntest to_cstr::tests::test_use_cases ... [POOL] ::get()\nok\n[POOL] ::get()\ntest tests::test_relooper_with_different_module ... ok[POOL]\nwork() on threads\n[POOL] check if running\n[THREAD Assertion failed: (!ThreadPool::isRunning()), function Thread, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 53.\n0x700008cc0000(] blockchecking for work\n(blockProcess 90297 stopped\n thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\nlibsystem_kernel.dylib__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-0f7351d0ba7e4ea7) stopped.\n(lldb) bt\n thread #2, name = 'tests::test_hello_world', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylibpthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylibabort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib__assert_rtn + 320\n    frame #4: 0x00000001003768e3 binaryen-0f7351d0ba7e4ea7wasm::Thread::Thread(this=0x0000000100c02830) at threads.cpp:53\n    frame #5: 0x0000000100377a25 binaryen-0f7351d0ba7e4ea7wasm::Thread::Thread(this=0x0000000100c02830) at threads.cpp:52\n    frame #6: 0x000000010037a074 binaryen-0f7351d0ba7e4ea7std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > wasm::make_unique<wasm::Thread>() at utilities.h:60\n    frame #7: 0x000000010037904c binaryen-0f7351d0ba7e4ea7wasm::ThreadPool::initialize(this=0x0000000100c02730, num=8) at threads.cpp:118\n    frame #8: 0x0000000100378a02 binaryen-0f7351d0ba7e4ea7wasm::ThreadPool::get() at threads.cpp:159\n    frame #9: 0x00000001000d0417 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x000070000842f970)::$_0::operator()() const at pass.cpp:276\n    frame #10: 0x00000001000ced73 binaryen-0f7351d0ba7e4ea7wasm::PassRunner::run(this=0x0000700008430550) at pass.cpp:311\n    frame #11: 0x00000001003fc7c9 binaryen-0f7351d0ba7e4ea7wasm::WasmValidator::validate(this=0x0000700008430758, module=0x0000000100d07d20, features=1, flags=2) at wasm-validator.cpp:1029\n    frame #12: 0x000000010002bb84 binaryen-0f7351d0ba7e4ea7::BinaryenModuleValidate(module=0x0000000100d07d20) at binaryen-c.cpp:2006\n    frame #13: 0x000000010000d249 binaryen-0f7351d0ba7e4ea7binaryen::Module::is_valid::h30b6f4c52bdc3dc8 + 57\n    frame #14: 0x000000010000b272 binaryen-0f7351d0ba7e4ea7binaryen::tests::test_hello_world::hfb02bbe837ce977a + 450\n    frame #15: 0x000000010046bac2 binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] test::run_test::{{closure}} at lib.rs:1510 [opt]\n    frame #16: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> [inlined] core::ops::function::FnOnce::call_once<closure,(())> at function.rs:223 [opt]\n    frame #17: 0x000000010046babd binaryen-0f7351d0ba7e4ea7test::{{impl}}::call_box<(),closure> at lib.rs:142 [opt]\n    frame #18: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #19: 0x000000010045bfc1 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe> at panicking.rs:459 [opt]\n    frame #20: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #21: 0x000000010045bf7c binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace [inlined] test::run_test::run_test_inner::{{closure}} at lib.rs:1447 [opt]\n    frame #22: 0x000000010045be29 binaryen-0f7351d0ba7e4ea7std::sys_common::backtrace::__rust_begin_short_backtrace<closure,()> at backtrace.rs:133 [opt]\n    frame #23: 0x0000000100461858 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> [inlined] std::thread::{{impl}}::spawn::{{closure}}::{{closure}} at mod.rs:406 [opt]\n    frame #24: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call<std::panic::AssertUnwindSafe<closure>,()> [inlined] std::panic::{{impl}}::call_once<(),closure> at panic.rs:300 [opt]\n    frame #25: 0x0000000100461842 binaryen-0f7351d0ba7e4ea7std::panicking::try::do_call,()> at panicking.rs:480 [opt]\n    frame #26: 0x00000001004ae77f binaryen-0f7351d0ba7e4ea7panic_unwind::__rust_maybe_catch_panic at lib.rs:101 [opt]\n    frame #27: 0x0000000100477f82 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panicking::try<(),std::panic::AssertUnwindSafe> at panicking.rs:459 [opt]\n    frame #28: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::panic::catch_unwind<std::panic::AssertUnwindSafe<closure>,()> at panic.rs:365 [opt]\n    frame #29: 0x0000000100477f49 binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> [inlined] std::thread::{{impl}}::spawn::{{closure}} at mod.rs:405 [opt]\n    frame #30: 0x0000000100477efc binaryen-0f7351d0ba7e4ea7alloc::boxed::{{impl}}::call_box<(),closure> at boxed.rs:817 [opt]\n    frame #31: 0x0000000100496578 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread [inlined] alloc::boxed::{{impl}}::call_once<(),()> at boxed.rs:827 [opt]\n    frame #32: 0x0000000100496575 binaryen-0f7351d0ba7e4ea7std::sys_common::thread::start_thread at thread.rs:24 [opt]\n    frame #33: 0x00000001004a0659 binaryen-0f7351d0ba7e4ea7std::sys::unix::thread::{{impl}}::new::thread_start at thread.rs:90 [opt]\n    frame #34: 0x00007fff9033493b libsystem_pthread.dylib_pthread_body + 180\n    frame #35: 0x00007fff90334887 libsystem_pthread.dylib_pthread_start + 286\n    frame #36: 0x00007fff9033408d libsystem_pthread.dylib`thread_start + 13\n```. It seems this PR have an error different error\n```\n\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] ::get()\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x700009a98000] thread waiting\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x70000910c000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009089000] checking for work\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[THREAD 0x700009512000] thread waiting\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009a98000] thread waiting\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009089000] checking for work\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] doing work\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[POOL] ::get()\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009a98000] thread waiting\n[POOL] ::get()\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x700009089000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009089000] checking for work\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[THREAD 0x70000948f000] thread waiting\n[POOL] ::get()\n[THREAD 0x700009a98000] thread waiting\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009089000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x700009a98000] thread waiting\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009089000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009089000] checking for work\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[POOL] ::get()\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009a98000] thread waiting\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009089000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[POOL] ::get()\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009a98000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009b1b000] thread waiting\n[THREAD 0x70000948f000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009089000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[POOL] ::get()\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] notify thread is ready\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009512000] thread waiting\n[POOL] ::get()\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009a98000] thread waiting\n[POOL] ::get()\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x70000948f000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009089000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x700009a98000] thread waiting\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009089000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000910c000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x70000918f000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[THREAD 0x70000948f000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009a98000] thread waiting\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] checking for work\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[POOL] ::get()\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] notify thread is ready\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[POOL] ::get()\n[THREAD 0x700009a98000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[THREAD 0x700009089000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009089000] checking for work\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000918f000] doing work\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[POOL] ::get()\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] ::get()\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] ::get()\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x700009089000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[POOL] notify thread is ready\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x700009a98000] thread waiting\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\n[POOL] ::get()\n[POOL] ::get()\n[POOL] work() on threads\n[POOL] running = true\n[POOL] reset threads are ready\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000948f000] checking for work\n[THREAD 0x700009089000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] doing work\n[THREAD 0x700009089000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000910c000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000910c000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x70000918f000] checking for work\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x70000948f000] getPoolFromWorker: after creation\n[THREAD 0x70000910c000] getPoolFromWorker: after creation\n[THREAD 0x70000918f000] doing work\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009512000] checking for work\n[POOL] ::get()\n[POOL] ::get()\n[THREAD 0x70000918f000] getPoolFromWorker: after creation\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009512000] doing work\n[POOL] notify thread is ready\n[POOL] notify thread is ready\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009595000] checking for work\n[THREAD 0x700009512000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009595000] doing work\n[POOL] ::get()\n[THREAD 0x700009e1b000] send work to thread\n[THREAD 0x700009a98000] checking for work\n[THREAD 0x700009595000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[THREAD 0x700009e1b000] work sent\n[THREAD 0x700009a98000] doing work\n[POOL] ::get()\n[POOL] main thread waiting\n[THREAD 0x700009b1b000] checking for work\n[THREAD 0x700009a98000] getPoolFromWorker: after creation\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[THREAD 0x700009b1b000] doing work\n[POOL] ::get()\n[THREAD 0x70000948f000] thread waiting\n[THREAD 0x700009b1b000] getPoolFromWorker: after creation\n[THREAD 0x70000910c000] thread waiting\n[THREAD 0x70000918f000] thread waiting\n[POOL] notify thread is ready\n[THREAD 0x700009512000] thread waiting\n[THREAD 0x700009595000] thread waiting\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x700009089000] getPoolFromWorker: after creation\n[THREAD 0x700009a98000] thread waiting\n[POOL] notify thread is ready\n[POOL] are threads ready?\n[POOL] ::get()\n[THREAD 0x700009b1b000] thread waiting\n[POOL] are threads ready?\n[POOL] notify thread is ready\n[THREAD 0x700009089000] thread waiting\n[POOL] are threads ready?\n[POOL] main thread waiting\n[POOL] running = false\n[POOL] work() is done\ntest tools::tests::test_translate_to_fuzz ... ok\ntest result: ok. 9 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out\n[THREAD 0x7fff990373c0] getPoolFromWorker: after creation\nAssertion failed: (pool), function getPoolFromWorker, file /Users/pepyakin/dev/my/binaryen-rs/binaryen-sys/binaryen/src/support/threads.cpp, line 65.\nProcess 45913 stopped\n thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\nlibsystem_kernel.dylib__pthread_kill:\n->  0x7fff90249d42 <+10>: jae    0x7fff90249d4c            ; <+20>\n    0x7fff90249d44 <+12>: movq   %rax, %rdi\n    0x7fff90249d47 <+15>: jmp    0x7fff90242caf            ; cerror_nocancel\n    0x7fff90249d4c <+20>: retq\nTarget 0: (binaryen-8ffc9f51d13f63b0) stopped.\n(lldb) bt\n thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGABRT\n  * frame #0: 0x00007fff90249d42 libsystem_kernel.dylib__pthread_kill + 10\n    frame #1: 0x00007fff90337457 libsystem_pthread.dylibpthread_kill + 90\n    frame #2: 0x00007fff901af420 libsystem_c.dylibabort + 129\n    frame #3: 0x00007fff90176893 libsystem_c.dylib__assert_rtn + 320\n    frame #4: 0x0000000100377849 binaryen-8ffc9f51d13f63b0wasm::getPoolFromWorker() at threads.cpp:65\n    frame #5: 0x00000001003785f5 binaryen-8ffc9f51d13f63b0wasm::Thread::~Thread(this=0x00000001036001f0) at threads.cpp:78\n    frame #6: 0x00000001003789a5 binaryen-8ffc9f51d13f63b0wasm::Thread::~Thread(this=0x00000001036001f0) at threads.cpp:77\n    frame #7: 0x000000010037c1a7 binaryen-8ffc9f51d13f63b0std::__1::__vector_base >, std::__1::allocator > > >::~__vector_base() [inlined] std::__1::default_delete::operator(this=0x0000000100c09db8, __ptr=0x00000001036001f0)(wasm::Thread) const at memory:2397\n    frame #8: 0x000000010037c186 binaryen-8ffc9f51d13f63b0std::__1::__vector_base<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::~__vector_base() [inlined] std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >::reset(this=0x0000000100c09db8, __p=0x0000000000000000) at memory:2603\n    frame #9: 0x000000010037c133 binaryen-8ffc9f51d13f63b0std::__1::__vector_base >, std::__1::allocator > > >::~__vector_base() [inlined] std::__1::unique_ptr >::~unique_ptr(this=0x0000000100c09db8) at memory:2571\n    frame #10: 0x000000010037c133 binaryen-8ffc9f51d13f63b0std::__1::__vector_base<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::~__vector_base() [inlined] std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >::~unique_ptr(this=0x0000000100c09db8) at memory:2571\n    frame #11: 0x000000010037c133 binaryen-8ffc9f51d13f63b0std::__1::__vector_base >, std::__1::allocator > > >::~__vector_base() [inlined] std::__1::allocator > >::destroy(this=0x0000000103100230, __p=0x0000000100c09db8) at memory:1838\n    frame #12: 0x000000010037c0ff binaryen-8ffc9f51d13f63b0std::__1::__vector_base<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::~__vector_base() [inlined] void std::__1::allocator_traits<std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::__destroy<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > >(__a=0x0000000103100230, __p=0x0000000100c09db8) at memory:1706\n    frame #13: 0x000000010037c0ec binaryen-8ffc9f51d13f63b0std::__1::__vector_base >, std::__1::allocator > > >::~__vector_base() [inlined] void std::__1::allocator_traits > > >::destroy > >(__a=0x0000000103100230, __p=0x0000000100c09db8) at memory:1574\n    frame #14: 0x000000010037c0d3 binaryen-8ffc9f51d13f63b0std::__1::__vector_base<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::~__vector_base() [inlined] std::__1::__vector_base<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::__destruct_at_end(this=0x0000000103100220, __new_last=0x0000000100c09d80) at vector:417\n    frame #15: 0x000000010037c05e binaryen-8ffc9f51d13f63b0std::__1::__vector_base >, std::__1::allocator > > >::~__vector_base() [inlined] std::__1::__vector_base >, std::__1::allocator > > >::clear(this=0x0000000103100220) at vector:361\n    frame #16: 0x000000010037c03f binaryen-8ffc9f51d13f63b0std::__1::__vector_base<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::~__vector_base(this=0x0000000103100220) at vector:444\n    frame #17: 0x000000010037bff5 binaryen-8ffc9f51d13f63b0std::__1::vector >, std::__1::allocator > > >::~vector(this=0x0000000103100220 size=1) at vector:450\n    frame #18: 0x000000010037bfd5 binaryen-8ffc9f51d13f63b0std::__1::vector<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> >, std::__1::allocator<std::__1::unique_ptr<wasm::Thread, std::__1::default_delete<wasm::Thread> > > >::~vector(this=0x0000000103100220 size=1) at vector:450\n    frame #19: 0x000000010037bfac binaryen-8ffc9f51d13f63b0wasm::ThreadPool::~ThreadPool(this=0x0000000103100220) at threads.h:72\n    frame #20: 0x000000010037bf75 binaryen-8ffc9f51d13f63b0wasm::ThreadPool::~ThreadPool(this=0x0000000103100220) at threads.h:72\n    frame #21: 0x0000000100376d53 binaryen-8ffc9f51d13f63b0std::__1::unique_ptr >::~unique_ptr() [inlined] std::__1::default_delete::operator(this=0x0000000100564500, __ptr=0x0000000103100220)(wasm::ThreadPool) const at memory:2397\n    frame #22: 0x0000000100376d38 binaryen-8ffc9f51d13f63b0std::__1::unique_ptr<wasm::ThreadPool, std::__1::default_delete<wasm::ThreadPool> >::~unique_ptr() [inlined] std::__1::unique_ptr<wasm::ThreadPool, std::__1::default_delete<wasm::ThreadPool> >::reset(this=0x0000000100564500, __p=0x0000000000000000) at memory:2603\n    frame #23: 0x0000000100376ceb binaryen-8ffc9f51d13f63b0std::__1::unique_ptr >::~unique_ptr() [inlined] std::__1::unique_ptr >::~unique_ptr(this=0x0000000100564500) at memory:2571\n    frame #24: 0x0000000100376ceb binaryen-8ffc9f51d13f63b0std::__1::unique_ptr<wasm::ThreadPool, std::__1::default_delete<wasm::ThreadPool> >::~unique_ptr(this=0x0000000100564500) at memory:2571\n    frame #25: 0x00007fff901b0178 libsystem_c.dylib__cxa_finalize_ranges + 332\n    frame #26: 0x00007fff901b04b2 libsystem_c.dylibexit + 55\n    frame #27: 0x00007fff9011b23c libdyld.dylibstart + 8\n```\n. I can confirm that this fix works!\nFWIW, I'm running macOS 10.12.6, with clang version Apple LLVM version 9.0.0 (clang-900.0.39.2) (have no idea how this version scheme is mapped to the original LLVM's). @kripken oops, done!. > Sorry, yeah, wasm-reduce is not very portable.\nNo worries, that's ok! : )\n\nI don't know how to replace timeout in a portable way (maybe using threads?).\n\nI think that might be possibe with pthread?\n\nI'm also not sure how to fix the BINARYEN_ROOT issue, basically the executable needs to find another executable in the same dir as it, is there a way to do that in C++?\n\nMaybe you can extract base-dir from an argv[0] and put it into a global variable? \n. cc https://github.com/WebAssembly/spec/pull/756. I used wat2wasm --no-check ). Yeah, I understand and expected answer like that. But, I'm still wondering, isn't this issue affect assert_invalid cases in testsuite? Is binaryen just skips these?. Yep, can confirm that it works! However, the ./check.py fails\n\n\n```\n.. /Users/pepyakin/dev/etc/binaryen/test/lld/duplicate_imports.wast\nexecuting:  bin/wasm-emscripten-finalize /Users/pepyakin/dev/etc/binaryen/test/lld/duplicate_imports.wast -S --global-base=568\nincorrect output, diff:\n\n--- /Users/pepyakin/dev/etc/binaryen/test/lld/duplicate_imports.wast.out\n+++ actual\n@@ -6,10 +6,16 @@\n  (type $FUNCSIG$ij (func (param i64) (result i32)))\n  (type $FUNCSIG$fifd (func (param i32 f32 f64) (result f32)))\n  (type $FUNCSIG$fidd (func (param i32 f64 f64) (result f32)))\n+ (type $legaltype$puts2 (func (param i32 i32) (result i32)))\n+ (type $legaltype$invoke_ffd (func (param i32 f64 f64) (result f64)))\n+ (type $legaltype$invoke_ffd2 (func (param i32 f64 f64) (result f64)))\n  (import \"env\" \"puts\" (func $puts1 (param i32) (result i32)))\n  (import \"env\" \"puts\" (func $puts2 (param i64) (result i32)))\n  (import \"env\" \"invoke_ffd\" (func $invoke_ffd (param i32 f32 f64) (result f32)))\n  (import \"env\" \"invoke_ffd\" (func $invoke_ffd2 (param i32 f64 f64) (result f32)))\n+ (import \"env\" \"puts\" (func $legalimport$puts2 (param i32 i32) (result i32)))\n+ (import \"env\" \"invoke_ffd\" (func $legalimport$invoke_ffd (param i32 f64 f64) (result f64)))\n+ (import \"env\" \"invoke_ffd\" (func $legalimport$invoke_ffd2 (param i32 f64 f64) (result f64)))\n  (global $global$0 (mut i32) (i32.const 66128))\n  (global $global$1 i32 (i32.const 66128))\n  (global $global$2 i32 (i32.const 581))\n@@ -25,7 +31,7 @@\n  (export \"stackAlloc\" (func $stackAlloc))\n  (export \"stackRestore\" (func $stackRestore))\n  (export \"__growWasmMemory\" (func $__growWasmMemory))\n- (func $main (; 4 ;) (type $1) (result i32)\n+ (func $main (; 7 ;) (type $1) (result i32)\n   (drop\n    (call $puts1\n     (i32.const 568)\n@@ -33,13 +39,46 @@\n   )\n   (i32.const 0)\n  )\n- (func $__wasm_call_ctors (; 5 ;) (type $2)\n+ (func $__wasm_call_ctors (; 8 ;) (type $2)\n   (nop)\n  )\n- (func $stackSave (; 6 ;) (result i32)\n+ (func $legalfunc$puts2 (; 9 ;) (param $0 i64) (result i32)\n+  (call $legalimport$puts2\n+   (i32.wrap/i64\n+    (get_local $0)\n+   )\n+   (i32.wrap/i64\n+    (i64.shr_u\n+     (get_local $0)\n+     (i64.const 32)\n+    )\n+   )\n+  )\n+ )\n+ (func $legalfunc$invoke_ffd (; 10 ;) (param $0 i32) (param $1 f32) (param $2 f64) (result f32)\n+  (f32.demote/f64\n+   (call $legalimport$invoke_ffd\n+    (get_local $0)\n+    (f64.promote/f32\n+     (get_local $1)\n+    )\n+    (get_local $2)\n+   )\n+  )\n+ )\n+ (func $legalfunc$invoke_ffd2 (; 11 ;) (param $0 i32) (param $1 f64) (param $2 f64) (result f32)\n+  (f32.demote/f64\n+   (call $legalimport$invoke_ffd2\n+    (get_local $0)\n+    (get_local $1)\n+    (get_local $2)\n+   )\n+  )\n+ )\n+ (func $stackSave (; 12 ;) (result i32)\n   (get_global $global$0)\n  )\n- (func $stackAlloc (; 7 ;) (param $0 i32) (result i32)\n+ (func $stackAlloc (; 13 ;) (param $0 i32) (result i32)\n   (local $1 i32)\n   (set_global $global$0\n    (tee_local $1\n@@ -54,12 +93,12 @@\n   )\n   (get_local $1)\n  )\n- (func $stackRestore (; 8 ;) (param $0 i32)\n+ (func $stackRestore (; 14 ;) (param $0 i32)\n   (set_global $global$0\n    (get_local $0)\n   )\n  )\n- (func $__growWasmMemory (; 9 ;) (param $newSize i32) (result i32)\n+ (func $__growWasmMemory (; 15 ;) (param $newSize i32) (result i32)\n   (grow_memory\n    (get_local $newSize)\n   )\n\nTraceback (most recent call last):\n  File \"./check.py\", line 675, in \n    sys.exit(main())\n  File \"./check.py\", line 650, in main\n    lld.test_wasm_emscripten_finalize()\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/lld.py\", line 46, in test_wasm_emscripten_finalize\n    fail_if_not_identical_to_file(actual, expected_file)\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/shared.py\", line 315, in fail_if_not_identical_to_file\n    fail_if_not_identical(actual, f.read(), fromfile=expected_file)\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/shared.py\", line 305, in fail_if_not_identical\n    fail(actual, expected, fromfile=fromfile)\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/shared.py\", line 300, in fail\n    fail_with_error(\"incorrect output, diff:\\n\\n%s\" % diff_str)\n  File \"/Users/pepyakin/dev/etc/binaryen/scripts/test/shared.py\", line 288, in fail_with_error\n    raise Exception(msg)\nException: incorrect output, diff:\n\n--- /Users/pepyakin/dev/etc/binaryen/test/lld/duplicate_imports.wast.out\n+++ actual\n@@ -6,10 +6,16 @@\n  (type $FUNCSIG$ij (func (param i64) (result i32)))\n  (type $FUNCSIG$fifd (func (param i32 f32 f64) (result f32)))\n  (type $FUNCSIG$fidd (func (param i32 f64 f64) (result f32)))\n+ (type $legaltype$puts2 (func (param i32 i32) (result i32)))\n+ (type $legaltype$invoke_ffd (func (param i32 f64 f64) (result f64)))\n+ (type $legaltype$invoke_ffd2 (func (param i32 f64 f64) (result f64)))\n  (import \"env\" \"puts\" (func $puts1 (param i32) (result i32)))\n  (import \"env\" \"puts\" (func $puts2 (param i64) (result i32)))\n  (import \"env\" \"invoke_ffd\" (func $invoke_ffd (param i32 f32 f64) (result f32)))\n  (import \"env\" \"invoke_ffd\" (func $invoke_ffd2 (param i32 f64 f64) (result f32)))\n+ (import \"env\" \"puts\" (func $legalimport$puts2 (param i32 i32) (result i32)))\n+ (import \"env\" \"invoke_ffd\" (func $legalimport$invoke_ffd (param i32 f64 f64) (result f64)))\n+ (import \"env\" \"invoke_ffd\" (func $legalimport$invoke_ffd2 (param i32 f64 f64) (result f64)))\n  (global $global$0 (mut i32) (i32.const 66128))\n  (global $global$1 i32 (i32.const 66128))\n  (global $global$2 i32 (i32.const 581))\n@@ -25,7 +31,7 @@\n  (export \"stackAlloc\" (func $stackAlloc))\n  (export \"stackRestore\" (func $stackRestore))\n  (export \"__growWasmMemory\" (func $__growWasmMemory))\n- (func $main (; 4 ;) (type $1) (result i32)\n+ (func $main (; 7 ;) (type $1) (result i32)\n   (drop\n    (call $puts1\n     (i32.const 568)\n@@ -33,13 +39,46 @@\n   )\n   (i32.const 0)\n  )\n- (func $__wasm_call_ctors (; 5 ;) (type $2)\n+ (func $__wasm_call_ctors (; 8 ;) (type $2)\n   (nop)\n  )\n- (func $stackSave (; 6 ;) (result i32)\n+ (func $legalfunc$puts2 (; 9 ;) (param $0 i64) (result i32)\n+  (call $legalimport$puts2\n+   (i32.wrap/i64\n+    (get_local $0)\n+   )\n+   (i32.wrap/i64\n+    (i64.shr_u\n+     (get_local $0)\n+     (i64.const 32)\n+    )\n+   )\n+  )\n+ )\n+ (func $legalfunc$invoke_ffd (; 10 ;) (param $0 i32) (param $1 f32) (param $2 f64) (result f32)\n+  (f32.demote/f64\n+   (call $legalimport$invoke_ffd\n+    (get_local $0)\n+    (f64.promote/f32\n+     (get_local $1)\n+    )\n+    (get_local $2)\n+   )\n+  )\n+ )\n+ (func $legalfunc$invoke_ffd2 (; 11 ;) (param $0 i32) (param $1 f64) (param $2 f64) (result f32)\n+  (f32.demote/f64\n+   (call $legalimport$invoke_ffd2\n+    (get_local $0)\n+    (get_local $1)\n+    (get_local $2)\n+   )\n+  )\n+ )\n+ (func $stackSave (; 12 ;) (result i32)\n   (get_global $global$0)\n  )\n- (func $stackAlloc (; 7 ;) (param $0 i32) (result i32)\n+ (func $stackAlloc (; 13 ;) (param $0 i32) (result i32)\n   (local $1 i32)\n   (set_global $global$0\n    (tee_local $1\n@@ -54,12 +93,12 @@\n   )\n   (get_local $1)\n  )\n- (func $stackRestore (; 8 ;) (param $0 i32)\n+ (func $stackRestore (; 14 ;) (param $0 i32)\n   (set_global $global$0\n    (get_local $0)\n   )\n  )\n- (func $__growWasmMemory (; 9 ;) (param $newSize i32) (result i32)\n+ (func $__growWasmMemory (; 15 ;) (param $newSize i32) (result i32)\n   (grow_memory\n    (get_local $newSize)\n   )\n```\n\n\n. ",
    "metalpavel": "Thank you for explanation. Warning definitely should be, but also this is issue because it generation wrong code. Why it generate trunc_uinstead trunc_s?. Functions like uint32_t wasm::toUInteger32(double x) with optimizations will be useless unless you add __attribute__ ((optnone)).\nFor example:\n```\ninclude \ninclude \nuint32_t toUInteger32(double x) {\n  return std::signbit(x) ? 0 : (x < std::numeric_limits::max()\n                                    ? (uint32_t)x\n                                    : std::numeric_limits::max());\n}\nint main(int argc, char ** argv) {\n    double a = argc > 0 ? INFINITY : 123;\nstd::cout << \"a: \" << a << std::endl;\n\nuint32_t b = toUInteger32(a);\n\nstd::cout << \"b: \" << b << std::endl;\n\nreturn 0;\n\n}\nWill crash with `Uncaught RuntimeError: integer result unrepresentable`. Without optimizations it's ok `__attribute__ ((optnone)) uint32_t toUInteger32(double x)`.\nCommand: `emcc hello.cpp -O3 -s WASM=1 --emit-symbol-map --bind -s TOTAL_MEMORY=67108864 -s ALLOW_MEMORY_GROWTH=1 --memory-init-file 1 -o hello.html`. Unfortunately `-s \"BINARYEN_TRAP_MODE='clamp'\"` is bad for performance. In my app fps decreasing near for 2 times with this option. For now, using unoptimized function in several cases is better.. Here is my simply benchmark with different types of floating points operations casts:\ninclude \ninclude \ninclude \nconst size_t COUNT = 10000000;\nstd::vector doubles(COUNT);\nstd::vector floats(COUNT);\nstd::vector ints64(COUNT);\nstd::vector ints32(COUNT);\nstd::vector results(COUNT);\nvoid test() {\n    double d = 0.0;\n    float f = 0.f;\n    uint64_t i64 = 0;\n    uint32_t i32 = 0;\nfor(size_t i = 0; i < COUNT; ++i) {\n    doubles[i] = d += 0.25;\n    floats[i] = f += 0.25f;\n    ints64[i] = i64 += 1;\n    ints32[i] = i32 += 1;\n}\n\nfor(size_t i = 0; i < COUNT; ++i) {\n    ints64[i] += doubles[i] * 0.25;\n    ints32[i] += doubles[i] * 0.25;\n    ints64[i] += floats[i] * 0.25f;\n    ints32[i] += floats[i] * 0.25f;\n\n    results[i] = ((doubles[i] * ints32[i]) + (floats[i] * ints32[i])) -\n                 ((doubles[i] * ints64[i]) + (floats[i] * ints64[i]));\n}\n\n}\nint main(int argc, char ** argv) {\ntypedef std::chrono::high_resolution_clock Clock;\ntypedef std::chrono::time_point<Clock> TimePoint;\n\nconst int TEST_COUNTS = 100;\nuint32_t sum = 0;\n\nfor (int i = 0; i < TEST_COUNTS; ++i) {\n\n    TimePoint start = Clock::now();\n\n    test();\n\n    TimePoint end = Clock::now();\n\n    uint32_t duration =\n        std::chrono::duration_cast<std::chrono::milliseconds> (\n            end - start).count();\n\n    std::cout << \"step \" << i << \" time: \" << duration << \"ms\"\n              << std::endl;\n\n    sum += duration;\n}\n\nstd::cout << \"average: \" << sum / TEST_COUNTS << \"ms\" << std::endl;\n\nreturn 0;\n\n}\nTests:\nModel Name: MacBook Pro\nModel Identifier: MacBookPro11,4\nProcessor Name:   Intel Core i7\nProcessor Speed:  2,2 GHz\nNumber of Processors: 1\nTotal Number of Cores:    4\nL2 Cache (per Core):  256 KB\nL3 Cache: 6 MB\nMemory:   16 GB\nSystem Version: macOS 10.12.6 (16G29)\n\nChrome (Version 60.0.3112.78 (Official Build) (64-bit)) average:\n205ms: em++ hello.cpp -O3 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n346ms: em++ hello.cpp -O3 -s WASM=1 -s TOTAL_MEMORY=16777216 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\n~40% diff\n205ms: em++ hello.cpp -O2 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n347ms: em++ hello.cpp -O2 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\n~40% diff\n227ms: em++ hello.cpp -O1 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n375ms: em++ hello.cpp -O1 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\n~40% diff\n267ms: em++ hello.cpp -O0 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n424ms: em++ hello.cpp -O0 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\nWith memory grow up at starting to: 536870912 !!!\n~40% diff\n\nFirefox (54.0.1 (64-bit)) average:\n257ms: em++ hello.cpp -O3 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n389ms: em++ hello.cpp -O3 -s WASM=1 -s TOTAL_MEMORY=16777216 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\n~35% diff\n260ms: em++ hello.cpp -O2 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n390ms: em++ hello.cpp -O2 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\n~35% diff\n269ms: em++ hello.cpp -O1 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n373ms: em++ hello.cpp -O1 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\n~28% diff\n306ms: em++ hello.cpp -O0 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html\n411ms: em++ hello.cpp -O0 -s WASM=1 -s TOTAL_MEMORY=33554432 -s ALLOW_MEMORY_GROWTH=1 -o hello.html -s \"BINARYEN_TRAP_MODE='clamp'\"\nWith memory grow up at starting to: 536870912 !!!\n~25% diff\n\nSafari Technology Preview didn't made it =(\n```\n. possible duplicate https://github.com/kripken/emscripten/issues/5179. ",
    "nidin": "Perfect\ud83d\udc4d\ud83c\udffb. Thanks for the quick response \ud83d\ude42. @kripen I can submit a PR for this. Is there any restrictions that shared memory need to be declared with max pages ?. \ud83d\udc4d\ud83c\udffb I will update it.\nOn Mon 24. Sep 2018 at 4:43 PM, Daniel Wirtz notifications@github.com\nwrote:\n\nShould also add the new parameter to the JS wrapper here\nhttps://github.com/WebAssembly/binaryen/blob/master/src/js/binaryen.js-post.js#L1079\n.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/issues/1679#issuecomment-423998898,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAMGZiqCg9uwnVkVqekL8qsIA_IlFT-Fks5ueO-JgaJpZM4WkpzX\n.\n. @kripken Any idea why Travis CI build is failing?\nI found this in log!\n```\nexecuting:  install/bin/wasm-as --validate=web /home/travis/build/WebAssembly/binaryen/test/validator/invalid_export.wast\n[wasm-validator error in module] 2 == 2: Exported function must not have i64 return type, on \n$export64\nFatal: Error: input module is not valid.\n\nexecuting:  install/bin/wasm-as --validate=web /home/travis/build/WebAssembly/binaryen/test/validator/invalid_import.wast\n[wasm-validator error in module] 2 == 2: Imported function must not have i64 parameters, on \n$bad\nFatal: Error: input module is not valid.\n``. @kripken castinguint8_ttoint` fixed the tests. . I guess it's a breaking change due to extra argument, so we need to add this change to breaking change list.. @kripken That's sounds good. I will change it to bool. When I was testing last month, Binaryen was complaining about max memory. I will test with bool and let you know the results.. I guess it's from unified imports and non-imports PR. @kripken ?. Or did i accidentally renamed it!! \ud83e\udd14 . Ha, It's my mistake. I guess I need more sleep \ud83e\udd2a. ",
    "nazar-pc": "I have 32GiB of RAM and compilation doesn't consume any significant amount of it (less than 1% anyway).\nAlso standalone testcase wouldn't be small, since it compiles with 34 exported functions and doesn't with 35. Looks like it doesn't matter which exact functions are exported, I can pick another 35 functions and it still fails.\nDo you have any ideas what can I do to debug this further, other than EMCC_DEBUG=1 and -v which do not print anything useful? As the last resort I'll just upload it as is, but there is a lot of code there.\nThe only file which is present after failure is noise-c.js.mem, no js or wasm files.. This is clearly asm2wasm issue, with WASM=0 compilation finished fine, attaching artifacts (js and mem files).\nnoise-c.wasm.zip\nAnd with separate asm file:\nnoise-c-asm.wasm.zip\n. Intermediate files that cause asm2wasm to exit with SIGABRT:\nnoise-c.wasm.zip\nnazar-pc@nazar-pc /w/g/noise-c.wasm> /media/Data/emsdk-portable/clang/e1.37.18_64bit/binaryen/bin/asm2wasm -d -g noise-c.temp.asm.js --total-memory=16777216 -O2 --mem-init=noise-c.js.mem --mem-base=1024 --wasm-only -o noise-c.wasm\nLoading 'noise-c.temp.asm.js'...\nparsing...\nwasming...\nasm2wasming func: stackAlloc\nasm2wasming func: stackSave\nasm2wasming func: stackRestore\nasm2wasming func: establishStackSpace\nasm2wasming func: setThrew\nasm2wasming func: setTempRet0\nasm2wasming func: getTempRet0\nasm2wasming func: _noise_cipherstate_struct_size\nasm2wasming func: _noise_handshakestate_struct_size\nasm2wasming func: _noise_symmetricstate_struct_size\nasm2wasming func: _noise_cipherstate_new_by_id\nasm2wasming func: _noise_cipherstate_new_by_name\nasm2wasming func: _noise_cipherstate_free\nasm2wasming func: _noise_cipherstate_get_cipher_id\nasm2wasming func: _noise_cipherstate_get_key_length\nasm2wasming func: _noise_cipherstate_get_mac_length\nasm2wasming func: _noise_cipherstate_init_key\nasm2wasming func: _noise_cipherstate_has_key\nasm2wasming func: _noise_cipherstate_encrypt_with_ad\nasm2wasming func: _noise_cipherstate_decrypt_with_ad\nasm2wasming func: _noise_cipherstate_encrypt\nasm2wasming func: _noise_cipherstate_decrypt\nasm2wasming func: _noise_cipherstate_set_nonce\nasm2wasming func: _noise_cipherstate_get_max_key_length\nasm2wasming func: _noise_cipherstate_get_max_mac_length\nasm2wasming func: _noise_dhstate_new_by_id\nasm2wasming func: _noise_dhstate_free\nasm2wasming func: _noise_dhstate_has_keypair\nasm2wasming func: _noise_dhstate_has_public_key\nasm2wasming func: _noise_dhstate_generate_dependent_keypair\nasm2wasming func: _noise_dhstate_clear_key\nasm2wasming func: _noise_dhstate_set_public_key\nasm2wasming func: _noise_dhstate_is_null_public_key\nasm2wasming func: _noise_dhstate_calculate\nasm2wasming func: _noise_dhstate_get_role\nasm2wasming func: _noise_dhstate_set_role\nasm2wasming func: _noise_handshakestate_new_by_id\nasm2wasming func: _noise_handshakestate_new\nasm2wasming func: _noise_handshakestate_free\nasm2wasming func: _noise_handshakestate_new_by_name\nasm2wasming func: _noise_handshakestate_get_role\nasm2wasming func: _noise_handshakestate_get_protocol_id\nasm2wasming func: _noise_handshakestate_get_local_keypair_dh\nasm2wasming func: _noise_handshakestate_get_remote_public_key_dh\nasm2wasming func: _noise_handshakestate_get_fixed_ephemeral_dh\nasm2wasming func: _noise_handshakestate_get_fixed_hybrid_dh\nasm2wasming func: _noise_handshakestate_needs_pre_shared_key\nasm2wasming func: _noise_handshakestate_has_pre_shared_key\nasm2wasming func: _noise_handshakestate_set_pre_shared_key\nasm2wasming func: _noise_handshakestate_set_prologue\nasm2wasming func: _noise_handshakestate_needs_local_keypair\nasm2wasming func: _noise_handshakestate_has_local_keypair\nasm2wasming func: _noise_handshakestate_needs_remote_public_key\nasm2wasming func: _noise_handshakestate_has_remote_public_key\nasm2wasming func: _noise_handshakestate_start\nasm2wasming func: _noise_handshakestate_fallback\nasm2wasming func: _noise_handshakestate_fallback_to\nasm2wasming func: _noise_handshakestate_get_action\nasm2wasming func: _noise_handshakestate_write_message\nasm2wasming func: _noise_handshake_mix_dh\nasm2wasming func: _noise_handshakestate_read_message\nasm2wasming func: _noise_handshakestate_split\nasm2wasming func: _noise_handshakestate_get_handshake_hash\nasm2wasming func: _noise_hashstate_new_by_id\nasm2wasming func: _noise_hashstate_free\nasm2wasming func: _noise_hashstate_get_hash_length\nasm2wasming func: _noise_hashstate_hash_one\nasm2wasming func: _noise_hashstate_hash_two\nasm2wasming func: _noise_hashstate_hkdf\nasm2wasming func: _noise_hashstate_hmac\nasm2wasming func: _noise_aesgcm_new\nasm2wasming func: _noise_name_to_id\nasm2wasming func: _noise_protocol_name_to_id\nasm2wasming func: _noise_protocol_id_to_name\nasm2wasming func: _noise_pattern_lookup\nasm2wasming func: _noise_pattern_reverse_flags\nasm2wasming func: _noise_symmetricstate_new_by_id\nasm2wasming func: _noise_symmetricstate_new\nasm2wasming func: _noise_symmetricstate_new_by_name\nasm2wasming func: _noise_symmetricstate_free\nasm2wasming func: _noise_symmetricstate_get_protocol_id\nasm2wasming func: _noise_symmetricstate_mix_key\nasm2wasming func: _noise_symmetricstate_mix_hash\nasm2wasming func: _noise_symmetricstate_encrypt_and_hash\nasm2wasming func: _noise_symmetricstate_decrypt_and_hash\nasm2wasming func: _noise_symmetricstate_get_mac_length\nasm2wasming func: _noise_symmetricstate_split\nasm2wasming func: _noise_new_object\nasm2wasming func: _noise_free\nasm2wasming func: _noise_clean\nasm2wasming func: _noise_is_equal\nasm2wasming func: _noise_is_zero\nasm2wasming func: _noise_curve448_new\nasm2wasming func: _noise_curve448_generate_keypair\nasm2wasming func: _noise_curve448_set_keypair\nasm2wasming func: _noise_curve448_set_keypair_private\nasm2wasming func: _noise_curve448_validate_public_key\nasm2wasming func: _noise_curve448_copy\nasm2wasming func: _noise_curve448_calculate\nasm2wasming func: _noise_newhope_new\nasm2wasming func: _noise_newhope_generate_keypair\nasm2wasming func: _noise_newhope_set_keypair\nasm2wasming func: _noise_newhope_set_keypair_private\nasm2wasming func: _noise_newhope_validate_public_key\nasm2wasming func: _noise_newhope_copy\nasm2wasming func: _noise_newhope_calculate\nasm2wasming func: _noise_newhope_change_role\nasm2wasming func: _noise_blake2s_new\nasm2wasming func: _noise_blake2s_reset\nasm2wasming func: _noise_blake2s_update\nasm2wasming func: _noise_blake2s_finalize\nasm2wasming func: _BLAKE2s_reset\nasm2wasming func: _BLAKE2s_update\nasm2wasming func: _blake2s_transform\nasm2wasming func: _BLAKE2s_finish\nasm2wasming func: _curve448_eval\nfish: \u201c/media/Data/emsdk-portable/clan\u2026\u201d terminated by signal SIGABRT (Abort). Well, it is not limited by number of functions. Looks like the size of noise-c.temp.asm.js is causing things to fail. 412.6 KiB file works fine, 1.2-1.3 MiB file crashes.\nWhat is the limit and how to change it?. I didn't specify SIMD=1, exact command used for compilation is in the first message and in log file.\nDoes SIMD depend on compilation options only or it may also be specified in source code somehow?\nThe source code I'm using is this: https://github.com/rweather/noise-c. Looks like #855, but without descriptive error from asm2wasm this time.\nWhen looking at clang options I'm wondering where -vectorize-loops -vectorize-slp come from. Is it because of emscripten-fastcomp-clang?. There are also some files in the code base that explicitly use vectorization:\n```c\nif defined(SSE2) && defined(GNUC) && GNUC >= 4\ndefine USE_VECTOR_MATH 1\n...\nelse\nundef USE_VECTOR_MATH\nendif\n``. With mentioned PR I'm gettingSIMD is used, but not supported in WASM mode yet, which is useful.\nIs there a way to de-vectorize code or something like that?. OK, solutions is not related to this project in general, so I'm closing issue, thanks for your help!. In my case there are no#define`: https://gist.github.com/nazar-pc/984c342f0dd7bc4e0ae383a47033d319\nNow I'm looking for someone to convert it to SIMD-free and then will write a patch to be applied to sources before compilation.\nIt is interesting how old problems like lacking SIMD support come back with new tech like WebAssembly.. ",
    "getsidd": "Hey kripken,\nYes, i can do that but i want to test wasm-as. So in order to validate the output from wasm-as i would need to have a reference wasm file to check with right. I was wondering if i can find something like that to test it.. Cool. Thanks, I'll use wasm-as.. ",
    "xtuc": "I'm currently working on https://github.com/xtuc/js-webassembly-interpreter. I think that a client side interpreter would be more efficient since you can take advantage of the WASM format and It also allows you to switch to native if supported/needed.\nI'm planning to use asm.js in the interpreter to have better performance. . That might be worth adding to the specification? I can create the issue if you want.. Ok I didn't know about that. I think it's still valuable to support it in the text format.\nI'm not able to find o2wasm in binaryen, could you please indicate me where it is?. Thanks for the pointers @jgravelle-google.\nI think it's worth to continue with s2wasm here, at least for experimentation purposes. Unfortunately, I'm doing it on my free time.. For reference that would work with https://reviews.llvm.org/D42520. Yes a tag can trigger a build and then a simple curl (plus a token) can create the release with the files. . That's a good point, I would prefer publishing on npm instead of a GH release. It's more convenient. . You can use Unpkg or bundle.run (if you need to bundle it). Yes, millions of peoples rely on these services even if none of them are official products. \nCould we fix the latest builds of binaryen.js? For example https://travis-ci.org/AssemblyScript/binaryen.js/builds/395478938 (I have trouble understanding the log on mobile sorry). ",
    "achoudhury85": "Hello Alon\nThe 20% improvement was measured on a Tableau internal codebase that is very C++ template heavy. (the codebase after all optimizations and DFE was at around 4 Mb and with SFE, the size went down to 3.2Mb). I put together a simple template heavy example since we can't share the Tableau internal codebase to demonstrate SFE's effectiveness, although, we should note that we go from 620Kb to 505kb without DFE in that example (if we first apply DFE for the example, SFE's effectiveness drops to 5%).\nNumbers for hello_libcxx.js:\nWithout DFE\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>emcc -O3 hello_libcxx.cpp -o hello_libcxx.js\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>ls -l hello_libcxx.js\n-rw-r--r-- 1 achoudhury domain users 459432 Aug 21 10:48 hello_libcxx.js\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>node \\~/code/SimilarFunctionElimination/src/run_sfe.js --file \\~/code/emscripten/emscripten/tests/hello_libcxx. > hello_libcxx_reduced.js\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>ls -l hello_libcxx*.js\n-rw-r--r-- 1 achoudhury domain users 459432 Aug 21 10:48 hello_libcxx.js\n-rw-r--r-- 1 achoudhury domain users 436977 Aug 21 10:50 hello_libcxx_reduced.js\nSo without DFE turned on, SFE yields around a 5% reduction in size for hello_libcxx.js.\nWith DFE\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>emcc -O3 -s ELIMINATE_DUPLICATE_FUNCTIONS=1 hello_libcxx.cpp -o hello_libcxx.js\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>ls -l hello_libcxx*.js\n-rw-r--r-- 1 achoudhury domain users 441718 Aug 21 10:54 hello_libcxx.js\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>node \\~/code/Similar-Function-Elimination/src/run_sfe.js --file \\~/code/emscripten/e\nmscripten/tests/hello_libcxx.js > hello_libcxx_reduced.js\nachoudhury-lnx$\\~/code/emscripten/emscripten/tests>ls -l hello_libcxx*.js\n-rw-r--r-- 1 achoudhury domain users 441718 Aug 21 10:54 hello_libcxx.js\n-rw-r--r-- 1 achoudhury domain users 429709 Aug 21 10:55 hello_libcxx_reduced.js\nSo, with DFE turned on, SFE yields only an additional 3% reduction for hello_libcxx.cpp.\nThis size reduction seems expected as hello_libcxx doesn't really make use of any template code. \nHope this helps, and let me know if you have further questions.\nRegards,\nArnab. @kripken - Our current implementation handles as many functions as possible that are deemed to be \"similar in nature\". Thus if we have N functions that all have literals and identifiers in the same places in the AST, we will parametrize the literals and identifiers accordingly and invoke a single helper function from each one of the N functions. The helper function would have parameters corresponding to the number of locations all N functions differ in.\nI'm not sure I follow why this is inefficient - can you expand a bit on that :)? Thanks!. Thanks for the update @jfbastien. In SFE, we solve this problem by hashing the canonicalized ASTs of all N functions, and we bucket on the hashes. Functions that are similar will hash to the same bucket (since their canonicalized ASTs - i.e., AST with consistent placeholders for literals and identifiers, are the same and will hash to the same value). \nSo, we don't actually compare all N functions, we make one pass through all the functions where we hash and bucket them. Hope this helps.. Thanks @kripken.\nRegarding complexity, we pondered the exact question you posed quite a bit when designing SFE. We realized that for this case where A is similar to B, and B is similar to C, given that A and B are differing only by identifiers and literals, and so are B and C, we can posit that A, B, and C are all structurally similar, i.e., their AST's tree structure is the same, except for differences in leaf nodes that can be either identifiers or literals.  Once we get to this realization, we then further realize that their canonicalized ASTs will be the same (since we replace literals and identifiers with placeholders), and thus, A, B, and C will hash to the same bucket and we will generate a single helper function that all 3 call out to. In terms of space overhead, this is great. The generated function will have more extra parameters however, and we will incur the penalty of an extra function call at runtime.\nI still don't follow completely about the efficiency part, but this is probably more due to the fact that I need to read up a bit on WASM optimization :). \nLet me know if you have more questions.\n. Hey folks - I'll have some numbers out on compression with and without SFE by EOD today. Alon, I'll also take a look at what the percentages are for literals vs identifiers. Thanks!. Hey folks, here are some numbers for a number of codebases with uncompressed and gzip9 sizes (all in bytes) listed with and without SFE. As can be seen, gzip savings varies, in the case of ammo.js for example, gzip performed quite poorly with SFE turned on, but in other cases like BananaBread - SFE+gzip results in big savings.\n| JS File                         | Uncompressed | With Gzip9  | \n|---------------------------------|--------------|-------------| \n| Roll-A-Ball With SFE            | 17,828,112 | 4,343,711 | \n| Roll-A-Ball Without SFE         | 19,349,834 | 4,433,581 | \n| Tableau Internal JS With SFE    | 3,198,386  | 696,932   | \n| Tableau Internal JS Without SFE | 3,964,275  | 715,952   | \n| ammo.js With SFE                | 1,880,651  | 387,550   | \n| ammo.js Without SFE             | 1,888,389     | 386,182   | \nEDIT - looks like the previous BananaBread numbers were off as the BananaBread JS was unoptimized. So, the best case savings seems to be for Roll-A-Ball - around 100Kb . Here is another analysis of SFE (I have excluded BananaBread as I don't have it optimized) where we run variants of SFE that canonicalize only on literals or only on identifiers. We compare the resultant sizes vs vanilla SFE (where we canonicalize ASTs on both literals and identifiers), and also the size without SFE.\nAmmo.js was a bit surprising - running SFE where we canonicalize only on identifiers actually enlarged the size of the file - since we're not optimizing too much with ammo.js, the additional parameter and return type annotations seem to be bumping up the size of the file. Probably worth a future fix where we measure in bytes the size with and without SFE when reducing.\n| JS File             | SFE With Identifiers | SFE With Literals | Vanilla SFE  | Without SFE  | \n|---------------------|----------------------|-------------------|--------------|--------------| \n| Roll-A-Ball         | 19,117,209         | 18,375,377      | 17,828,112 | 19,349,834 | \n| Tableau Internal JS | 3,422,383          | 3,844,775       | 3,198,386  | 3,964,275  | \n| Ammo.js             | 1,891,843          | 1,877,376       | 1,880,651  | 1,888,389  | . ",
    "hackcasual": "I'm on the same team as @achoudhury85. SFE is likely to be a bit better in the WASM world, as it can more efficiently represent the hoisted variants, which means there is less overhead with helper functions. SFE commonly hoists things like vtable pointers (~4 bytes in textual notation, ~2 bytes with LEB128 encoded integers) and structure memory layout, ~2-3bytes - 1 byte.\nThis is perhaps another argument for having binaryen support some level of this, as some of the cost computation will be unique to the WASM binary encoding.. We use a purely greedy approach, which may in some cases mean we would do better by evicting a function from a similarity set.\nLooking at a simple example:\n```javascript\nfunction z1(a, b)\n{\n  var $1 = 5 | 0 * b;\n  return R[Q[a << 4 + 12] - $1];\n}\nfunction z2(a, b)\n{\n  var $1 = 6 | 0 * b;\n  return R[Q[a << 4 + 12] - $1];\n}\nfunction z3(a, b)\n{\n  var $1 = 5 | 0 * b;\n  return R[Q[a << 4 + 16] - $1];\n}\n```\nThe algorithm roughly follows this process:\n\nReplace every hoistable value (constants, function references) with a place holder\nHash the replaced AST\nFunctions that hash to the same value are part of the same similarity set\nFunctions in the same similarity set are compared with each other and any differeing locations in the AST are marked\nA new function is generated that takes in the parameters the original function did, plus all parameters that represent the variation in the AST\n\nFrom our example the functions will get converted to this:\njavascript\nfunction (a, b)\n{\n  var $1 = \u03d5 | \u03d5 * b;\n  return R[Q[a << \u03d5 + \u03d5] - $1];\n}\nAfter comparing them, we'll get the merged function like this:\n```javascript\nfunction zPrime(a, b, $$1, $$2)\n{\n  var $1 = $$1 | 0 * b;\n  return R[Q[a << 4 + $$2] - $1];\n}\nfunction z1(a, b)\n{\n  return zPrime(a, b, 5, 12);\n}\nfunction z2(a, b)\n{\n  return zPrime(a, b, 6, 12);\n}\nfunction z3(a, b)\n{\n  return zPrime(a, b, 5, 16);\n}\n```\nHopefully that helps clarify things\n. Yep, we brought that up as a possible improvement. I believe in our code base we have quite a few cases with smart pointer logic where the functions have a lot of similarity at the beginning, but one is a shorter version of the other. For obvious reasons, finding those cases are a lot harder. It's possible you could do something by hashing subtrees, but you'll also need to normalize identifier names.. Yeah, you can arbitrarily handle any AST difference as long as scope is preserved. I'd say in that case you're not likely to find a function that just differs by an operation like that though, so we haven't collected what it would actually help with.. So our current code doesn't handle that, but you could do it through replacing the AST node with a place holder.. At a certain point you'll end up with all the complexity in resolving the similarity sets.. In theory it's better than DFE when it comes to GZIP, as its context aware. While DFE is picking up stuff that is basically free for LZW type compressors, SFE is being a little bit smarter. In any case, even if gzip brings the results down a bit, there is something to be said for less stuff to parse.. That's a good point, I'd say for measuring likely impact, using DFE would be a good first approximation for the gains here.. /D_DISABLE_EXTENDED_ALIGNED_STORAGE will revert to old behavior. ",
    "Joffrey": "I close this issue because a possible (and enough) workaround is about the .stack symbol provided by s2wasm.\nThanks to Derek Schuff.\n00:16:16        dschuff | oh btw, for the .stack thing, you might be able  \n                        | to declare a .stack extern in your C code and    \n                        | have get get resolved by s2wasm. ",
    "conrad-watt": "Fixed by #1154. Thanks!. ",
    "kumpera": "Just updated my emsdk checkout with the latest binaryen and it's working!\nThanks a lot for such lightning fast response. \ud83d\udc4d . I'll explore using EMULATED_FUNCTION_POINTERS and see how far it gets me.\nOtherwise I'll address the comments you made above and update this PR.\n. @kripken so, I tried EMULATED_FUNCTION_POINTERS and it does solve the function table issue beautifully, but now all indirect functions are being exported which fails module instantiation with: \nModule.instantiateWasm callback failed with error: CompileError: at offset 100961: too many exports\n. EMULATED_FUNCTION_POINTERS produces an 11Mb js module \ud83d\ude31so I don't think it's usable at all.. @kripken I tried it, it generates good wasm, but the JS glue is busted at 11MB (compared to 100k without that option). I think we can close this issue as the emcc fix works just as well.. ",
    "nezumisama": "Hi. Clang doesn't need any flags, at least in versions 37 and 1.37.20. But gcc does. I've created patches for both versions.\nVersion 37:\ndiff -Naur binaryen-version_37.old/src/tools/translate-to-fuzz.h binaryen-version_37/src/tools/translate-to-fuzz.h\n--- binaryen-version_37.old/src/tools/translate-to-fuzz.h   2017-09-06 17:41:09.128587002 +0200\n+++ binaryen-version_37/src/tools/translate-to-fuzz.h   2017-09-06 18:01:15.453592860 +0200\n@@ -615,7 +615,13 @@\n         }\n         switch (conditions) {\n           case 0: if (!oneIn(4)) continue;\n+#if defined(__GNUC__) && !defined(__clang__)\n+              __attribute__ ((fallthrough));\n+#endif\n           case 1: if (!oneIn(2)) continue;\n+#if defined(__GNUC__) && !defined(__clang__)\n+              __attribute__ ((fallthrough));\n+#endif\n           default: if (oneIn(conditions + 1)) continue;\n         }\n         return builder.makeBreak(name);\ndiff -Naur binaryen-version_37.old/src/wasm/wasm-s-parser.cpp binaryen-version_37/src/wasm/wasm-s-parser.cpp\n--- binaryen-version_37.old/src/wasm/wasm-s-parser.cpp  2017-09-06 17:41:09.128587002 +0200\n+++ binaryen-version_37/src/wasm/wasm-s-parser.cpp  2017-09-06 17:57:45.035459630 +0200\n@@ -869,6 +869,9 @@\n       }\n       case 'w': {\n         if (!strncmp(str, \"wake\", strlen(\"wake\"))) return makeAtomicWake(s);\n+#if defined(__GNUC__) && !defined(__clang__)\n+        __attribute__ ((fallthrough));\n+#endif\n       }\n       default: abort_on(str);\n     }\nVersion 1.37.20:\ndiff -Naur binaryen-1.37.20.old/src/tools/translate-to-fuzz.h binaryen-1.37.20/src/tools/translate-to-fuzz.h\n--- binaryen-1.37.20.old/src/tools/translate-to-fuzz.h  2017-09-06 17:47:17.514471939 +0200\n+++ binaryen-1.37.20/src/tools/translate-to-fuzz.h  2017-09-06 18:10:24.494153688 +0200\n@@ -609,7 +609,13 @@\n         }\n         switch (conditions) {\n           case 0: if (!oneIn(4)) continue;\n+#if defined(__GNUC__) && !defined(__clang__)\n+              __attribute__ ((fallthrough));\n+#endif\n           case 1: if (!oneIn(2)) continue;\n+#if defined(__GNUC__) && !defined(__clang__)\n+              __attribute__ ((fallthrough));\n+#endif\n           default: if (oneIn(conditions + 1)) continue;\n         }\n         return builder.makeBreak(name);\nNote I'm checking both __GNUC__ and __clang__, because clang defines both (pretending to be GCC?) but doesn't accept the attribute statement.. @dschuff I have clang 4.0.1 and GCC 7.1.1 - only GCC throws an error due to -Wimplicit-fallthrough. The flag was added in GCC 7 and is enabled with -Wextra, see: https://developers.redhat.com/blog/2017/03/10/wimplicit-fallthrough-in-gcc-7/\nAlso, it only warns about switches in those 2 places. If this codding style is common, it might be a good idea to explicitly add -Wno-implicit-fallthrough aka -Wimplicit-fallthrough=0. Or you can set another number, see the manual - when a non-zero number is set, GCC accepts fallthrough in case of comments. . ",
    "JohnSully": "I simply checked out clang from their git repo (latest) built it with\ndefaults (cmake+make) and then did the same with the webassembly projects.\nThis was the only one I had a problem with.  I'm not sure how the flag\nitself managed to get enabled but it seemed to me like it was good coding\npractice to have explicit fallthrough regardless and the changes were\nrather small.\nOn Wed, Sep 6, 2017 at 9:54 AM, Derek Schuff notifications@github.com\nwrote:\n\nMy (pretty bleeding-edge, fairly recent SVN) build of clang doesn't enable\n-Wimplicit-fallthrough by default; I don't get these errors unless I do\nthat. Are you turning that flag on yourself, or is that a recent change in\nclang? Also my gcc (6.3) doesn't support that flag or warn about these, I\nguess that must be a recent addition to gcc too.\nSo IIUC, this just warns everytime there's any fallthrough between switch\nlabels without an annotation? That pattern is pervasive in binaryen, and it\nwill take a lot more than just these patches to silence that warning,\nassuming we even want to.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/1162#issuecomment-327546869,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ADtuAgqDJa8HP6Pw8_mJgC19aEaTGjGGks5sfs5PgaJpZM4PLgUy\n.\n. \n",
    "mrugacz95": "Use Python 2.7. ",
    "reesmanp": "@kripken yes, the fix works and I have now completed the install without any further issues. Thank you.. ",
    "flackr": "Sure, that works. Done.. Apologies for the delay - I didn't notice we had arrived at a resolution. I've adopted the suggested flag and dropped the comment.\nIn my case I'm targeting a raspberry pi, building using a cross compilation sdk from a high end x86_64 desktop.. Done.. ",
    "gczuczy": "May I ask whether this has been merged?\nFreeBSD/aarch64 hit this issue, and the relevant bug report is https://bugs.freebsd.org/bugzilla/show_bug.cgi?id=225600 .\nSo, this would most probably solve the current issue with the FreeBSD port.\n. ",
    "jbeich": "@gczuczy, aarch64 doesn't support any -mfpu= value e.g.,\n$ gcc7 -mfpu=vfpv3 test.c\ngcc7: error: unrecognized command line option '-mfpu=vfpv3'\n$ clang60 -mfpu=vfpv3 test.c\nclang-6.0: warning: argument unused during compilation: '-mfpu=vfpv3' [-Wunused-command-line-argument]\n. @flackr, can you squash commits into one and rebase against master branch? I plan #1438 to depend on this one but it doesn't look pretty atm.. @binji,  when cross-compiling (see docs or wiki) CMAKE_SYSTEM_PROCESSOR should be set manually as it defaults to host architecture.. i is from i386, i486, i586, i686 while ^i is to avoid matching something with 86 substring that isn't a descendant of Intel 8086. CMake itself uses^i.86$ pattern in one of its modules.\nhttps://github.com/Kitware/CMake/blob/v3.10.2/Modules/FindJNI.cmake#L40. ",
    "z2oh": "Awesome, the build got much farther with that fix @juj. It failed again for a similar reason further along but I was able to resolve the new issue now that I knew what to look for. Lines 641-645 of src/tools/translate-to-fuzz.h read:\nswitch (conditions) {\n    case 0: if (!oneIn(4)) continue;\n    case 1: if (!oneIn(2)) continue;\n    default: if (oneIn(conditions + 1)) continue;\n}\nwhich I changed to:\nswitch (conditions) {\n    case 0: if (!oneIn(4)) continue; break;\n    case 1: if (!oneIn(2)) continue; break;\n    default: if (oneIn(conditions + 1)) continue;\n}\nand then I was able to build successfully!\nThanks for the assistance! Since I already have these changes made locally, I would be happy to make a PR for them if there is interest.. I ran ./auto_update_tests.py and a subsequent run of ./check.py passed on my system. Here is the output of git diff: https://hastebin.com/zayuraniho .\nI know very little about the testing process of this project, so I can't really say if this is correct or not. Should I commit this change?. Good point. Changed in b377dde.. Fixed in 90364e3.. ",
    "Markyparky56": "Attached a zip with a test case producing an example of a _GLOBAL___sub_I exported function which is uncallable due to the presence of a period in its name. \nContents includes the code file (main.cpp), the bitcode from clang (main.bc), the s-expressions from llc (main.s), the webassembly text format from s2wasm (main.wat) and the compiled wasm from wat2wasm (main.wasm). Also included is main.html which loads the module to demonstrate that it doesn't initialise the object which otherwise would be initialised by the start up function, and that the exported global function is visible under the instance's exports (check the developer console for all output).\nwasmtestcase.zip\nCompiled using this process on windows:\n```\n\nclang -c -v --target=wasm32 -std=c++14 -emit-llvm -Oz main.cpp\nllc -O2 main.bc -o main.s\ns2wasm main.s > main.wat\nwat2wasm main.wat -o main.wasm\n```\n\nI understand there is another wasm32 target available via --target=wasm32-unknown-unknown-wasm, but it uses lld which I haven't got installed yet, that's the next item on my list to investigate though. . Tried compiling the same code file with the command\n```\n\nclang --target=wasm32-unknown-unknown-wasm -std=c++14 -Oz -c -v main.cpp -o main.wasm\nBut it returns a fatal error from the backend:\nfatal error: error in backend: Wasm COMDATs only support SelectionKind::Any, '_ZN16PermutationTable7SetSeedEi' cannot\n      be lowered.\nclang.exe: error: clang frontend command failed with exit code 70 (use -v to see invocation)\n```\nWaiting on llvm.org/bugs getting back with an account so I can submit the bug report it gives me.\n\nTried --target=wasm64-unknown-unknown-wasm since that last error about lowering is is probably linked to the fact that my code uses a lot of unsigned long longs. Get a slightly less legible error:\nnote: Checked the design docks to confirm, the MVP only supports wasm32, making the likelihood of this working slim, even if the targets are available\nfatal error: error in backend: Cannot select: 0x70df798: i32,ch = load<LD1[%3](tbaa=<0x2b15b8>), zext from i8>\n      0x70b4760, 0x70df528, undef:i64\n  0x70df528: i64 = add 0x70df3f0, 0x70df4c0\n    0x70df3f0: i64 = sign_extend 0x70df388\n      0x70df388: i32 = WebAssemblyISD::ARGUMENT TargetConstant:i32<0>\n        0x70df320: i32 = TargetConstant<0>\n    0x70df4c0: i64 = WebAssemblyISD::Wrapper TargetGlobalAddress:i64<%class.PermutationTable* @permTable> 0\n      0x70df730: i64 = TargetGlobalAddress<%class.PermutationTable* @permTable> 0\n  0x70df590: i64 = undef\nIn function: GetPermAt\nclang++.exe: error: clang frontend command failed with exit code 70 (use -v to see invocation)\nThe WebAssembly backend is still experimental, which this may be highlighting.\nInterestingly, if I remove the period from the GLOBAL... function in the wat code output by s2wasm and compile it via wat2wasm, manually calling it after the module is instanced throws a RuntimeError: memory access out of bounds. Since the global function just invokes the SetSeed function of the class, if you export a C call to that function calling that also throws the same error. Double checked that the code was safe but adding a main function which mirrors the html file and compiled that to a simple exe and it works as expected. . Bug for the wasm backend here, they are aware of the lacking COMDAT support.\nNever even thought to try accessing the export via a string, spent too much time with C++ maybe. \nCompiling the test case with em++, then converting the wasm back to wat with wasm2wat shows that at some point during compilation the _GLOBAL__sub_I_main.cpp was converted to _GLOBAL__sub_I_main_cpp\nSolved the issue of there being no stack to play with by specifying -s 524288 (maybe a little much for this but a safe amount) when calling s2wasm i.e. s2wasm -s 524288 main.s > main.wat, and it works like a charm! . Yes, that's the loop that Visual Studio keeps pointing me to with the exception. \nI build using the cmake commands\ncmake -G \"Visual Studio 15 2017 Win64\" . && cmake --build .\nWhich I think defaults to Debug, looking at the .ilk and .pdb files it fills the bin folder with for each executable, but I also tried compiling specifying -DCMAKE_BUILD_TYPE=Release and RelWithDebInfo prior to making this and both of those still pointed me there. \nNot sure about valgrind, never heard of it let alone used it, any specific process you're looking for? \nI can add a watch to passes and take a look at it's contents. Doing this for wasm-opt on the wasm file from the testcase shows a std::vector of size 26, each of the elements (besides having a value/address) shows up as:\n```\n-       [0] 0x0000000000aafc80 {name= }    wasm::Pass \n+       __vfptr 0xdddddddddddddddd {???, ???, ???, ???, ???, ???}   void * \n+       name       std::basic_string,std::allocator >\n````\nCan't immediately wrangle cmake to build binaryen with mingw, as it gets stuck trying to compile a dummy executable, so can't check if it's a visual studio/msbuild/windows exclusive issue.\n```\nCMake Error at CMakeLists.txt:121 (if):\n  if given arguments:\n\"C:/binaryen_mingw/dummy\" \" PE32+ executable for MS Windows (console) Mono/.Net assembly\n\n\" \"MATCHES\" \"x86[-_]64\"\nUnknown arguments specified\n```\nGoing to see how it copes on my Windows 10 machine, which also has VS2017. Unfortunately don't have any *nix installations but given your puzzlement this feels like something which you haven't experienced before?. Same issue on Windows 10, steps to reproduce:\ngit clone https://github.com/webassembly/binaryen.git\ncd binaryen\ncmake -G \"Visual Studio 15 2017 Win64\" .\ncmake --build .\nbin\\wasm-opt test\\passes\\simplify-locals.wast --print. According to this SO post Dr. Memory can achieve some of valgrind's functionality on windows, so ran the wasm-opt test\\passes\\simplify-locals.wast --print through it. \nOutput:\n```\nDr. Memory version 1.11.0 build 2 built on Aug 29 2016 02:41:18\nDr. Memory results for pid 3808: \"wasm-opt.exe\"\nApplication cmdline: \"c:\\binaryen\\bin\\wasm-opt.exe c:\\binaryen\\test\\passes\\simplify-locals.wast --print\"\nRecorded 115 suppression(s) from default C:\\Program Files (x86)\\Dr. Memory\\bin64\\suppress-default.txt\nError #1: UNADDRESSABLE ACCESS of freed memory: reading 0x00000000011feff0-0x00000000011feff8 8 byte(s)\n0 wasm::PassRunner::run               [c:\\binaryen\\src\\passes\\pass.cpp:288]\n1 main                                [c:\\binaryen\\src\\tools\\wasm-opt.cpp:177]\nNote: @0:00:03.676 in thread 14320\nNote: 0x00000000011feff0-0x00000000011feff8 overlaps memory 0x00000000011feff0-0x00000000011ff028 that was freed here:\nNote: # 0 replace_operator_delete_nothrow                            [d:\\drmemory_package\\common\\alloc_replace.c:2974]\nNote: # 1 std::_Container_base12::~_Container_base12                 [c:\\program files (x86)\\microsoft visual studio\\2017\\community\\vc\\tools\\msvc\\14.11.25503\\include\\xutility:116]\nNote: # 2 std::_String_val<>::~_String_val<>\nNote: # 3 std::_Compressed_pair<>::~_Compressed_pair<>\nNote: # 4 std::_String_alloc<>::~_String_alloc<>                     [c:\\program files (x86)\\microsoft visual studio\\2017\\community\\vc\\tools\\msvc\\14.11.25503\\include\\xstring:1742]\nNote: # 5 std::basic_string<>::~basic_string<>                       [c:\\program files (x86)\\microsoft visual studio\\2017\\community\\vc\\tools\\msvc\\14.11.25503\\include\\xstring:2247]\nNote: instruction: mov    (%rax) -> %rax\n```\nwasm-opt then crashed as expected. \nDecided to step through wasm-opt, since VS does let you pass command line arguments when running the application with the debugger. The issue appears to arise between lines 176 and 177\nPassRunner passRunner = options.getPassRunner(wasm);\npassRunner.run();\nLooking at getPassRunner, passes is fine until it returns passRunner\nPassRunner getPassRunner(Module& wasm) {\n  PassRunner passRunner(&wasm, passOptions);\n  if (debug) passRunner.setDebug(true);\n  for (auto& pass : passes) { // passes is a vector with 1 pass here \n    if (pass == DEFAULT_OPT_PASSES) {\n      passRunner.addDefaultOptimizationPasses();\n    } else {\n      passRunner.add(pass); // Following this through adds a valid pass\n    }\n  }\n  return passRunner; // Everything looks fine \n}\nHowever, because we're returning a local its destructor gets called when we leave the function, which is defined as:\nPassRunner::~PassRunner() {\n  for (auto pass : passes) {\n    delete pass;\n  }\n}\nThis deletes any passes stored, which is a good idea since those are pointers which would otherwise leak,  but seems to be fouling up the returned object. As a quick fix attempt I switched getPassRunner over to returning a pointer and deleting it after the call to passRunner->run() which seems to avoid it breaking. Additionally this seems to be the only call to options.getPassRunner() and seems to date back to this commit?\nSticking with that little fix, and trying to run wasm-opt -O1 on the testcase.wat file, I'm back to the vector subscript out of range error in WasmBinaryWriter::finishSection with the std::move call I mentioned earlier. It's possible it may work without debug assertions in place, msvc is probably just especially prudent/pedantic, but I think you can use some pointer math to achieve the same?\nChanging the [] lookup off the end of the vector to lookup at the end then add 1 to the reference in finishSection\n// Before\nstd::move(&o[start + MaxLEB32Bytes], &o[start + MaxLEB32Bytes + size], &o[start + sizeFieldSize]);\n// After\nstd::move(&o[start + MaxLEB32Bytes], &o[start + MaxLEB32Bytes + size-1]+1, &o[start + sizeFieldSize]);\nAnd writeFunctions\n// Before\nstd::move(&o[start], &o[start + size], &o[sizePos + sizeFieldSize]);\n// After\nstd::move(&o[start], &o[start + size-1]+1, &o[sizePos + sizeFieldSize]);\nSeems to work fine, no complaints or errors. Unfortunately the .end() iterator is not dereferencable, because &*o.end() looks so much nicer.\nApologies if this was rather rambling, but I just had it open as I worked my way through and recorded findings and changes. . Created a branch on a personal fork here with the std::move fix, which I can create a pull request for, is there anything I have to do before that?\nFor the PassRunner fix, a copy constructor may not be the easiest fix because of PassRunner's destructor and its vector of pointers to wasm::Pass objects, do you want me to create a pull request for the quick fix with a pointer or work out one for a copy constructor?. std::move fix PR, requested an account for the community group. As another side note, while I was digging through wasm-opt, I noticed you declare a std::vector<std::string> passes in the main function, which is never used. Probably left over from a previous iteration.. Since both the read access violation issue and the vector subscript out of range issue have been sorted, shall we close this issue?. Yes, profile here.. Don't mean to resurrect this issue or anything, but if you, like me, happen across this in a search to find a replacement to s2wasm then you'd better get familiar with wasm-ld. Check out wasm-ld --help. \nThe -Xlinker --no-entry and -Xlinker --allow-undefined switches are just the beginning, wasm-ld includes switches for --import-memory, --initial-memory=X and even has the facility for explicit (or blanket) symbol exporting. By default it is set to --no-export-dynamic which means no functions will be exported, which seems a little odd but at least now you no longer have to deal with it exporting all your C++ name-mangled functions beside your nice clean extern \"C\" functions.. MSVC 15.9 is the latest version, released last week. The year is not synced with the version number.\nPassing the enable define does switch the functionality internally, it's not just silencing a warning.. Since a fix appears to have been merged I'll close this issue.. ",
    "caspervonb": "Making sure I'm on master, and I was.\nconsole\n$ git status\nOn branch master\nYour branch is up-to-date with 'origin/master'.\nnothing to commit, working tree clean\nlldb run -f ./bin/wasm2asm -- main.wasm\nconsole\nProcess 10013 launched: '/usr/local/bin/wasm2asm' (x86_64)\nlibc++abi.dylib: terminating with uncaught exception of type wasm::ParseException\nProcess 10013 stopped\n* thread #1: tid = 0x996e, 0x00007fff90ffcf06 libsystem_kernel.dylib`__pthread_kill + 10, queue = 'com.apple.main-thread', stop reason = signal SIGABRT\n    frame #0: 0x00007fff90ffcf06 libsystem_kernel.dylib`__pthread_kill + 10\nlibsystem_kernel.dylib`__pthread_kill:\n->  0x7fff90ffcf06 <+10>: jae    0x7fff90ffcf10            ; <+20>\n    0x7fff90ffcf08 <+12>: movq   %rax, %rdi\n    0x7fff90ffcf0b <+15>: jmp    0x7fff90ff77cd            ; cerror_nocancel\n    0x7fff90ffcf10 <+20>: retq\nCan't recall how to print a pretty trace right now so stepping up manually\n``console\n(lldb) up\nframe #1: 0x00007fff92ac04ec libsystem_pthread.dylibpthread_kill + 90\nlibsystem_pthread.dylibpthread_kill:\n    0x7fff92ac04ec <+90>:  cmpl   $-0x1, %eax\n    0x7fff92ac04ef <+93>:  jne    0x7fff92ac04f8            ; <+102>\n    0x7fff92ac04f1 <+95>:  callq  0x7fff92ac15fe            ; symbol stub for: __error\n    0x7fff92ac04f6 <+100>: movl   (%rax), %eax\n(lldb) up\nframe #2: 0x00007fff950b86e7 libsystem_c.dylibabort + 129\nlibsystem_c.dylib`abort:\n    0x7fff950b86e7 <+129>: movl   $0x2710, %edi             ; imm = 0x2710 \n    0x7fff950b86ec <+134>: callq  0x7fff950dfa76            ; symbol stub for: usleep$NOCANCEL\n    0x7fff950b86f1 <+139>: callq  0x7fff950b86f6            ; __abort\nlibsystem_c.dylib__abort:\n    0x7fff950b86f6 <+0>:   pushq  %rbp\n(lldb) up\nframe #3: 0x00007fff897ebf81 libc++abi.dylibabort_message + 257\nlibc++abi.dylib__cxa_bad_cast:\n    0x7fff897ebf81 <+0>: pushq  %rbp\n    0x7fff897ebf82 <+1>: movq   %rsp, %rbp\n    0x7fff897ebf85 <+4>: pushq  %rbx\n    0x7fff897ebf86 <+5>: pushq  %rax\n(lldb) up\nframe #4: 0x00007fff89811a47 libc++abi.dylibdefault_terminate_handler() + 267\nlibc++abi.dylibdefault_unexpected_handler:\n    0x7fff89811a47 <+0>:  pushq  %rbp\n    0x7fff89811a48 <+1>:  movq   %rsp, %rbp\n    0x7fff89811a4b <+4>:  leaq   0x1066(%rip), %rax        ; \"unexpected\"\n    0x7fff89811a52 <+11>: movq   %rax, -0x110d68f1(%rip)   ; cause\n(lldb) up\nframe #5: 0x00007fff96e346c3 libobjc.A.dylib_objc_terminate() + 124\nlibobjc.A.dylib_objc_terminate:\n    0x7fff96e346c3 <+124>: addq   $0x8, %rsp\n    0x7fff96e346c7 <+128>: popq   %rbx\n    0x7fff96e346c8 <+129>: popq   %rbp\n    0x7fff96e346c9 <+130>: jmp    0x7fff96e3241e            ; objc_end_catch\n(lldb) up\nframe #6: 0x00007fff8980f19e libc++abi.dylibstd::__terminate(void ()()) + 8\nlibc++abi.dylibstd::__terminate:\n    0x7fff8980f19e <+8>:  leaq   0x3601(%rip), %rdi        ; \"terminate_handler unexpectedly returned\"\n    0x7fff8980f1a5 <+15>: xorl   %eax, %eax\n    0x7fff8980f1a7 <+17>: callq  0x7fff897ebe80            ; abort_message\n    0x7fff8980f1ac <+22>: movq   %rax, %rdi\n(lldb) up\nframe #7: 0x00007fff8980ec12 libc++abi.dylib__cxa_throw + 121\nlibc++abi.dylib__cxxabiv1::exception_cleanup_func:\n    0x7fff8980ec12 <+0>: pushq  %rbp\n    0x7fff8980ec13 <+1>: movq   %rsp, %rbp\n    0x7fff8980ec16 <+4>: cmpl   $0x1, %edi\n    0x7fff8980ec19 <+7>: jne    0x7fff8980ec28            ; <+22>\n(lldb) up\nframe #8: 0x00000001002720e3 wasm2asmwasm::Element::operator + 707 at wasm-s-parser.cpp:61\n   58 \n   59   Element Element::operator {\n   60     if (!isList()) throw ParseException(\"expected list\", line, col);\n-> 61     if (i >= list().size()) throw ParseException(\"expected more elements in list\", line, col);\n   62     return list()[i];\n   63   }\n   64\n```. Head is at 47c9021401a69d407a3e730012824cae75dd66f9.\nWill do some more debugging to see where it's failing.. > That line (if (i >= list().size()) looks innocuous. But then maybe the debugger is getting the line wrong.\nTests do fail on gcc torture tests, compilation errors.. GCC isn't installed ;)\nThat is does seem like the correct line tho, stepping through and list().size() does return 0.. Original pipeline is with clang --target=wasm32-unknown-unknown-wasm but same error happens with binaries assembled with wasm-as and wast2wasm.\nMinimal example.\nconsole\necho '(module\n (type $0 (func (result i32)))\n (table 1 1 anyfunc)\n (memory $0 2)\n (export \"memory\" (memory $0))\n (export \"main\" (func $0))\n (func $0 (type $0) (result i32)\n  (i32.const 42)\n )\n)' > foo.wast\nwasm-as foo.wast -o foo.wasm\nwasm2asm foo.wasm --debug\nFails with the same error as above, and its on the root element.\nLoading 'foo.wasm'...\ns-parsing...\nw-parsing...\nlibc++abi.dylib: terminating with uncaught exception of type wasm::ParseException\n. While the above does parse and compile, some fairly trivial code-gen from clang is failing\nconsole\n(module\n  (type (;0;) (func (result i32)))\n  (func $main (type 0) (result i32)\n    i32.const 0)\n  (table (;0;) 0 anyfunc)\n  (memory (;0;) 1)\n  (export \"main\" (func $main))\n  (data (i32.const 0) \"\\00clang version 6.0.0 (https://llvm.org/git/clang.git 0ea7666767cbc2c89d2fbd5717a5bd98f53d3f7f) (https://llvm.org/git/llvm.git 44847b2e9838888e1536c90ad442a3958362139a)\\00\"))\nconsole\nwasm2asm obj/main.wat \nlibc++abi.dylib: terminating with uncaught exception of type wasm::ParseException\nSome error details would be a nice addition? ;). Yep it was wasm2wat, last issue with clang's codegen is the global(s) but that's a llvm issue? -O3 removes them as unused anyway.. Closing as resolved since we have error messages now.. > Perhaps we should make the s-parser look ahead for the table definition, but it currently doesn't.\nNoted, wasm2wat issue again, it has different ordering than wasm-dis.\nMental note; Use binaryen tools for binaryen tools.\n\nYeah, wasm and asm.js semantics are different for indirect calls,\n\nIs that actual Asm.js semantics or Emscripten semantics that can be thrown away?\nFrom what I can tell a valid table in WebAssembly pretty much tells us the assignment operations for the elements? \ne.g, a module with a table always looks something like the following.\nwat\n(module \n  ;; ...\n  (table (;0;) 1 anyfunc)\n  (elem (i32.const 0) $func))\n  ;; ...\n)\nFrom this it seems trivial to generate tables with the same indexing\n```javascript\nfunction asm(global, env, buffer) { \n  // (table (;0;) 1 anyfunc)\n  var table = {\n    elements: new Array(1),\n    get: function(index) {\n      index = index | 0;\n  return this.elements[index];\n},\nset: function(index, value) {\n  index = index | 0;\n  this.elements[index] = value;\n},\ngrow: function(size) {\n  // throw, resize array?\n},\n\n};\n// (elem (i32.const 0) $func))\n  table.set(0 | 0, func);\nreturn {\n  };\n```\nThis first pass doesn't touch call_indirect, so it can live next to the current semantics.\nWhy? it will allow tables to work somewhat like what one would expect from a WebAssembly module and so \"host\" code/libraries do not need to need to know if they are working with a WebAssembly.Table or ad-hoc Asm.js table.\n\nBtw, what are you doing here, for context?\n\nTL;DR; I'm passing function pointers to JavaScript.\nThat example above was just a minimal reproduction, did a bunch of variations to see where it was failing and also trying to figure out how the table's were indexed.\nActual use case is calling function pointers from JavaScript in some minimal platform glue, it expects table to be available at some point, import or export doesn't matter.\n```javascript\nforeign['platform_schedule_tick_callback'] = function(targetId, callbackId, userOffset) {\n  var target = document.getElementById(targetId);\n  var callback = foreign['table'].get(callbackId);\nwindow.requestAnimationFrame(function(timestamp) {\n    var result = callback(targetId, timestamp, userOffset);\n    // et cetera\n  }, target);\n};\n```\nAsm.js comes in as a fallback for browsers that do not support WebAssembly, which is still quite a few especially on low end mobile.. Uhm yeah just realized the above is not legal Asm.js, with objects and all, hmph.. Previously mentioned in https://github.com/WebAssembly/binaryen/issues/1256. In the meantime I've had to hack my way around this with a fairly gnarly shell script, basically wasm2asm generates code per normal then I add another layer \"wasm compatible\" around it.\n```js\nfunction wasm(imports) {\n  var memory = {\n    buffer: new ArrayBuffer(64 * 1024),\n  };\nvar exports = asm(self, imports.env, memory.buffer);\n  var indirect_function_table = {\n    elements: [\n      exports['tock'],\n      exports['tick'],\n    ],\nget: function(index) {\n  var entry = this.elements[index - 1];\n  if (entry == null) {\n    throw new RuntimeError(\"invalid table entry at \" + index);\n  }\n\n  return entry;\n},\n\n};\nfunction asm(global, env, buffer) {\n    \"use asm\";\n// ...\nvar callback = env.callback;\n\nfunction __wasm_call_ctors() {\n}\n\nfunction tock() {\n  // ...\n}\n\nfunction tick() {\n  //\n}\n\nfunction main() {\n  callback(1 | 0) | 0;\n  callback(2 | 0) | 0;\n}\n\nreturn {\n  __wasm_call_ctors: __wasm_call_ctors,\n  tock: tock,\n  tick: tick,\n  main: main,\n};\n\n}\nreturn {\n    exports: {\n      main: exports.main,\n      __memory: memory,\n      __indirect_function_table: indirect_function_table,\n    },\n  }\n}\n```\nThe obvious pitfall to my approach however is that my \"loose\" function table is only gettable, but I've never actually had use case yet for a settable function table.\nDoing it this way seems more doable than interfacing Asm.js internal function tables.. ",
    "tsavola": "I get weak references when using libcxx and assigning something (traditional function or lambda) to a std::function.\nIt seems binaryen's test suite doesn't run the hello_libcxx test. It probably would be a large undertaking to get libcxx-dependent tests to run?. ```c++\ninclude \nstatic void dummy() {}\nint main()\n{\n  std::function f = dummy;\n  return 0;\n}\n```\nhttps://gist.github.com/tsavola/f0b36840ccf2b0639591aa7f30750498\n. ",
    "axic": "I think this PR can be closed since #1607 s2wasm has been removed.. I think this PR can be closed since #1607 s2wasm has been removed.. Thanks!. @kripken @dschuff @chfast are there any reasons against this PR? What needs to be done to have this merged?. @chfast ping. ",
    "krisselden": "Looked like it had even more build-js.sh changes but looks like the extra ones are just ordering changes, it does include all of these changes.. @kripken so name can have more symbols than just '-' or ':' I was motivated because rust was emitting names with ':' but should I sanitize all of these?\nlet symbol = ['+''-''*''/''\\\\''^''~''=''<''>''!''?''@''#''$''%''&''|'':''`''.''\\'']\nlet name = '$' (letter | digit | '_' | symbol)+. @froydnj this was superseded by\n1340 which handled grow_memory and export memory\n1433 which handled name mangling\n. I will refactor to just automatically do it based on the presence of grow_memory and I'll fix the python linting rules.\nI used Object.create() because it is how you create with descriptors and need the buffer to be a getter so it reflects the replacement when memory grows.  I could use the new es2015 shorthand instead get buffer() { return buffer; } but not sure if the cashew ast supported that.  I could also assign memory as a var, and just ensure memory.buffer = buffer is part of replacement, but this way I don't create the memory object unless it is exported.. Microsoft already has signed a contribution agreement (as a member of the W3C), and we believe we are covered by that signed agreement.  So can we submit without signing another agreement?. Definitely caused confusion with my request that it was a PR of code changes and I needed to sign a CLA that is about contributing to the web assembly spec.. >  we'd have some asm.js and some support JS on the outside\nwould like to create a function on the outside that you could call for setting the data sections on the buffer you pass into the asmFunc. Because buffer needs to be a getter over the buffer var so we are exporting a living binding and Object.create supports an array of descriptors.\n. I don't think asm.js exports can be anything other than functions.\nhttp://asmjs.org/spec/latest/#validateexport-s\n. Is enforcing the maximum growth important for a first pass?  The primary motivation is getting backward compatibility when targeting wasm first.\n. The export shims the WebAssembly.Memory interface and is also the only way to get the reassigned buffer post memory growth, the imported buffer is only the initial buffer.. Exporting memory allows for memory growth externally, via the grow function even if the module itself doesn't have grow_memory instructions.  I will log a message when \"almost asm\" is triggered with the reason why.. ",
    "blackjyn": "I set EMCC_DEBUG=1 in my env and got this:\n\nI noticed at this:\n\nDEBUG:root:check tells us to use asm.js backend\nDEBUG:root:using binaryen, with method: native-wasm\nDEBUG:root:asm2wasm (asm.js => WebAssembly): D:/DEVSDK/EMScripten/binaryen_v37\\bin\\asm2wasm x.temp.asm.js --total-memory=16777216 --emit-potential-traps -O1 --mem-init=x.js.mem --mem-base=1024 --wasm-only -o x.wasm\n\nbut what should I do?. Well, My problem got fixed by updating to the latest\nThank you for bundling precompiled binaries for Windows. ",
    "msprotz": "https://jonathan.protzenko.fr/whacl-star/ed25519-c/Ed25519.wasm\nhttps://jonathan.protzenko.fr/whacl-star/ed25519-c/Ed25519.wast\n\nI was indeed only looking at the last line in the message. What I took for a complete dump of my file was actually an error; piping through less reveals a slew of [wasm-validator error in function $0] 0 == 0: block with value must not have last element that is none, on: <huge-dump>... every function in the module seems to exhibit the error\nthe duplicate import seems spurious\n\nNote that https://jonathan.protzenko.fr/whacl-star/ed25519-c/main.html will happily load, instantiate and execute that module in your browser.\nThanks,\nJonathan. Wonderful, thanks very much! That was fast :)\nThe code comes from my KreMLin compiler https://github.com/FStarLang/kremlin . KreMLin takes code written in F* and generates C or WASM. F* is a verification-oriented language, meaning the programmer writes code that enjoys memory safety, functional correctness, and a degree of resistance to side-channels. Kremlin takes that and generates C code and now, WASM code too.\nOur flagship application is hacl-star (see https://github.com/mitls/hacl-star/), a set of verified cryptographic algorithms that enjoy the guarantees above. Mozilla's NSS recently integrated one our of algorithms. We now intend to ship a WASM version of the library. The generated code is very minimalistic, and the toolchain is very simple, meaning we are relatively confident that the guarantees that hold for the original F* code also apply to the resulting WASM code.\nThe landing page of HACL* has pointers to papers, if you're curious. \nNow for more details:\nThe reason for data_start being exported by every one of my modules is that each module lays out its own constant strings in the data segment (using relative addressing), then relies on a custom \"loader\" to tell the next module where exactly the start of the data segment is. Perhaps there's a more idiomatic way of doing this? The relevant code is in propagate at, say, https://jonathan.protzenko.fr/whacl-star/ed25519-c/loader.js\nCheers,\nJonathan. The bypass route has multiple advantages:\n- simpler compilation scheme, meaning a much smaller compiler to trust (i.e. a couple thousand lines of ML rather than all of LLVM)\n- more control over things such as side-channel preservation (mostly relying on the fact that no optimizations are performed... of course, this doesn't prevent JITs from introducing side-channels)\n- a much smaller codesize than what emscripten generates (from what we could tell from our initial experiments).\n@prosecco can comment more on the advantages of the \"bypass\" toolchain I'm sure.\nThe wasm binary / wast generation is done using https://github.com/WebAssembly/spec -- I directly reuse Andreas' library which is also written in OCaml. No extra work for me! The W module in https://github.com/FStarLang/kremlin/blob/master/src/CFlatToWasm.ml#L4 is Andreas' library, and I convert my AST to binary here: https://github.com/FStarLang/kremlin/blob/master/src/OutputJs.ml#L79\nSo far, things have been working out fine for us with Wasm. I've lobbied @rossberg extensively for tail-call optimization and SIMD support, which are the two big features that would change our life...\nThanks,\nJonathan. ",
    "prosecco": "As Andreas says, bypassing C may often be better for compiling DSLs that may more naturally translate to WASM.\nFor our source language and examples, which are predominantly focused on security-centric applications, there is at least three important advantages in targeting WASM,\neven though we also generate C code from the same toolchain, so we could easily have used emscripten.\n1) We carefully verify side-channel mitigations in our source code and we want to preserve them at least all the way to WASM.\n     We have some ideas on verifying that the assembled/interpreted versions of WASM also preserve these properties.\n     This would have been harder to guarantee for a full-fledged compiler like llvm/emscripten.\n2) We want our generated code to be defensive against common JavaScript flaws.\n    This means that within our JavaScript wrapper code we want to minimize any dependence on the tamperable JS environment.\n    In previous work, we managed to isolate security-critical code using a statically typed subset of JavaScript (http://antoine.delignat-lavaud.fr/doc/usenixsec13.pdf http://antoine.delignat-lavaud.fr/doc/usenixsec13.pdf)\n    We think WASM is much better for this kind of defensive programming, as long as the JS<->WASM API is carefully designed.\n    Again, writing our own compiler helps us keep tight control over this kind of isolation guarantee.\n3) We want the generated crypto code to be small and potentially reviewable/auditable.\n    When we compile our code directly from F* to WASM we end up with a 20K file.\n    An emscripten compiled version of Curve25519, as used by Signal Desktop, for example, is over 200KB.\n\nOn 6 Nov 2017, at 19:40, Jonathan Protzenko notifications@github.com wrote:\nThe bypass route has multiple advantages:\nsimpler compilation scheme, meaning a much smaller compiler to trust (i.e. a couple thousand lines of ML rather than all of LLVM)\nmore control over things such as side-channel preservation (mostly relying on the fact that no optimizations are performed... of course, this doesn't prevent JITs from introducing side-channels)\na much smaller codesize than what emscripten generates (from what we could tell from our initial experiments).\n@prosecco https://github.com/prosecco can comment more on the advantages of the \"bypass\" toolchain I'm sure.\nThe wasm binary / wast generation is done using https://github.com/WebAssembly/spec https://github.com/WebAssembly/spec -- I directly reuse Andreas' library which is also written in OCaml. No extra work for me! The W module in https://github.com/FStarLang/kremlin/blob/master/src/CFlatToWasm.ml#L4 https://github.com/FStarLang/kremlin/blob/master/src/CFlatToWasm.ml#L4 is Andreas' library, and I convert my AST to binary here: https://github.com/FStarLang/kremlin/blob/master/src/OutputJs.ml#L79 https://github.com/FStarLang/kremlin/blob/master/src/OutputJs.ml#L79\nSo far, things have been working out fine for us with Wasm. I've lobbied @rossberg https://github.com/rossberg extensively for tail-call optimization and SIMD support, which are the two big features that would change our life...\nThanks,\nJonathan\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/WebAssembly/binaryen/issues/1264#issuecomment-342244233, or mute the thread https://github.com/notifications/unsubscribe-auth/AEYAnvJ5utg2Q937D8a8tAcEssOYzI30ks5sz1KmgaJpZM4QQeu2.\n\n\n. ",
    "AmaanC": "\nUntil wasm adds that, though, the zeros are annoying but they do almost vanish when gzipping, so it's not too bad, I think?\n\nI haven't played with many settings but it's not as good as you might hope. (156 byte wasm + 309 byte wasm = 5.3kb gzip.)\n\nIf it could receive an add of a constant and a global, then we could optimize out those zeros.\n\nI don't quite understand what you mean; not quite sure how dylink and memoryBase interact, sorry! Is there something more comprehensive than the docs on WebAssembly.org and the tool-conventions one I linked to?\nWould copying the dylink section (when only one of the files has the section) into the output file make sense?\nFor context, I'm trying to add the call_indirect operator into a wasm file generated by emscripten.\n. @kripken Thought I'd ask again in case you missed it:\n\nWould copying the dylink section (when only one of the files has the section) into the output file make sense?\n\nI can start work on a PR for that if you think we could get that merged upstream!. ",
    "Razican": "Not sure, but maybe a null comparison of first before returning it could fix the warning, but I haven't programmed in C++ for a long time, so I will probably be wrong.. I would probably need some more information on what the code does. Is first always an integer different from 0?\nThis would fix the warning:\ncpp\n  template<typename T, typename... Args>\n  T pickGivenNum(size_t num, T first, Args... args) {\n    if (num == 0 && first) return first;\n    return pickGivenNum<T>(num - 1, args...);\n  }\nbut I guess it can be 0. In any case, something in those lines could work.\nAnother option would be to temporarily pass the -Wno-uninitialized flag to the compiler. Where could I do that?. I did the suggested solution. It works in my GCC 7.2.. It should work as this was on the \"not Windows\" condition branch.. I added the comment and signed up for the community group :). ",
    "daurnimator": "Never use -Werror in a release make file (use it for development only)! My C compiler introducing new warnings shouldn't break your software.. ",
    "jakirkham": "Guess this should be closed as won't fix given s2wasm was dropped. ( https://github.com/WebAssembly/binaryen/pull/1607 ). Guess this should be closed as won't fix given s2wasm was dropped. ( https://github.com/WebAssembly/binaryen/pull/1607 ). Guess this should be closed as won't fix given s2wasm was dropped. ( https://github.com/WebAssembly/binaryen/pull/1607 ). Thoughts on this?. Was asm2wasm suppose to be renamed to js2wasm too?. FWIW we make Conda binaries in conda-forge. Here's the feedstock.. ",
    "ylluminate": "Thanks so much for the thoughts @kripken. emscripten might be the most sane path initially. Crystal does use a GC, but I don't think supporting this would be important at all going to js / browser since there's no direct allocation in code.  I've been surprised to see how fast Crystal is going with it now being past Rust on TIOBE and jumping so insanely quickly over such a short period of time. There's been a lot of talk about isomorphism and Opal has been on the table, but folks keep thinking that going directly over via WebAsm would be the better route.\nI guess there could be some fear that emscripten might be a little too heavy, but frankly I could see some remarkable benefits more or less everywhere from what you've mentioned there re: emscripten.. That's great to know @binji! I'm sure an IRC-Gitter bridge (Crystal uses this) would also be quite useful since a lot of other projects do this as well and it just adds to the conversation.. So @kripken I guess the next extension to this would be regarding what output needs to be produced by the crystal compiler in order for emscripten to receive it? I'm not seeing, so far, how llvm being the common point produces the common byte code or output that'll be consumable.\nThe main argument I'm getting right now from actual crystal devs is effectively \"since emscripten + asm.js don't provide garbage collection, we cannot do anything yet.\"  I was under the impression that GC would not be an issue until we get to actual webasm output since the JS VM will be handling GC. Handling memory allocation/deallocation for C/C++ would be necessary since it's part of the language itself and it doesn't take GC into consideration, but a language like Crystal should be able to take advantage of the current emscripten implementation so as to not require any manual memory handling...  Am I missing something here?  . Huh, very interesting. Let me rephrase and tell me if this groks your statement generally: emscripten's goal isn't a direct JS conversion like Opal does it and so we do need to look at GC, but that's (perhaps easily) doable.. Where would be the place to talk with or perhaps even collaborate with Go folks on this issue?\nThis all makes me wonder if the Opal approach may not be more sane and productive one at this point in time...  . So @kripken since you're able to do this it certainly sounds like a winning proposition that would make this pretty straightforward, right @RX14? . What would be involved Crystal-side once @kripken is able to implement it? . Have you gotten any further in this (thought) process @kripken?. I think that there may be others who would be willing to work through this even if @RX14 doesn't have the time right now since he's polishing off the native Windows support. I have horrendous demands on my time presently, but I know of others that are also interested. I know others such as @t-richards have raised the importance of this and may have interest in helping and then some of the framework developers such as @paulcsmith of Luck Framework have some serious interest in this.  We may be able to rally through this if we can get over this hump! \ud83d\ude38 . So @kripken I guess we need to set up some kind of test initially.  What would be the process of getting bdwgc to run via emscripten/binaryen? I think I'm going to at least dabble in this in order to get it kickstarted...  This is a pretty important feature that's just lacking bandwidth, so I don't want that to hold it up. \n@RX14 so Crystal uses vanilla bdwgc, right?. @kripken what's your take on this: https://github.com/ivmai/bdwgc/issues/163. @kripken I've got several guys committed to this now.  We'll push through this and make it work if you can get us the binaryen modification.. @kripken there's been some worry here about DOM access in WASM.  Obviously from a lot of chatter I'm seeing, DOM WASM access is still quite some time out (a lot of pink unicorn icons floating around it apparently)...\nBut as far as I can figure, one of the advantages of using Emscripten is that it is still, for the time being, going to JS / asm.js and the DOM should still be accessible.  Is this correct and if so how would this DOM access be accomplished?\nThere's a good deal of push to make a transpiler a la Opal, but given that Crystal is built atop LLVM and you've done what you've done, that would be a very intensive investment compared to just getting it running atop Emscripten with existent stdlibs, etc.\nIf we can access the DOM conveniently then it's just a matter of holding off on actual TRUE WASM output for web application centric apps until we figure out a way to access the DOM with WASM (ie, if a game is being developed in Crystal and it doesn't need the DOM directly then this could fill temporary isolated DOM needs)...\nDoes that make sense or am I spouting nonsense?. The main impetus presently for Crystal WASM is to use it for web app frameworks such as Lucky, Amber, Kemal, and bringing Hyperloop over, thus seamless DOM is critical.\nCould you clarify your statement as I'm not groking it quite yet?: \n\nThe main problem there is you can't collect cycles between the two worlds yet, but otherwise it can work very well.\n\nIt would have other fantastic applications, but, like I said, we've got to get to a seamless experience for web development first and foremost.\n. So given the discouragement from the missing direct DOM access and a tremendous amount of resistance due to that (and some other life issues), I thought I'd step back to this issue to see if anything has changed.\nHas anyone worked up a clean or direct method of handling DOM interaction via Emscripten?\nHas anything else changed that would affect our above discussions?\n. ",
    "RX14": "Crystal currently uses bdwgc, and has lots of roots on the stack, is there any kind of possible solution?. @kripken the thing is we don't ever have nothing on the stack. The language is like go - built around green threads (fibers) with \"blocking\" calls. We always provide the illusion of a stack (with the illusion of it containing GC roots), even when waiting for events.\nPorting crystal is pointless if you just end up with a stdlib which is impossible to port.. Actually, go seems to be working on wasm, and bypass this problem by managing their own stack in linear memory. What a pain.. @kripken is there (or is likely to be) any sort of way to switch stacks in wasm. If not, then that's probably why go is going the slow and painful route.. Indeed, while wasm is awesome, it'll take one or two years I think before it matures to be able to truly support Crystal as-designed. People can either hack it in before then or wait or skip wasm and make a crystal codegen backend for JS. Not that the latter won't likely be similarly hacky around concurrency and GC.. >Basically a pass that ensures all i32s are spilled to a linear memory location. Then Boehm GCing would just work.\nIs wasm 32-bit?. It's certainly not something i'm going to have time to work on - i'd rather work on windows support. If @kripken thinks he can get a GC with a simple malloc/realloc/push_stack interface similar to bdwgc working on wasm that's fantastic, and we'll probably use it in the future when we port to wasm. But wasm is hardly a priority for me personally.\nAnd no, nothing is exactly straightforward about porting a self-hosted language to a new platform :). I don't know, i'm not too familar with wasm and it's limitations. The only way to find out what they are is probably to try to port.. The first thing to get working is bdwgc on a simple test C program. Once that's working then its just going through the same process as windows is now. . @ylluminate yes vanilla bdwgc. ",
    "erlend-sh": "You can see an example workaround for DOM access here:\nhttps://github.com/DenisKolodin/yew#virtual-dom-independent-loops-fine-updates\nhttps://github.com/rust-lang-nursery/rust-wasm#the-dom-gc-integration-and-more. ",
    "zachrip": "@kripken I'll take a look into it, I don't have a whole lot of experience in this area but would love to contribute.. @kripken it seems that other things like clang just read from stdin if you have a lone dash: clang -. If I'm not mistaken there's not much to do in terms of cross-platform work as you're just reading from cin, no?. @froydnj I looked into it a little bit but haven't made much progress. I'd still love to have this ability so I'll probably dig deeper in the next week or so. Will update.. ",
    "vajraBodhi": "@kripken Yes, I want to do it manualy, I will try the method you provided. Thank you.. ",
    "wycats": "This would be great to have for Glimmer, where we're targeting wasm but still need asm.js output for older browsers (we still support IE11, for now).. While I'm sure @krisselden is happy to fill out another form, I'm curious @kripken: is there a reason that contributions to binaryen require joining a community group?. Is there some reason that this tool needs to live in this org and be under the W3C IPR policy (as opposed to a standalone repository licensed under Apache2?)\nAre any of the active contributors to this repository only active because of the fact that the repository is part of what WebAssembly umbrella and protected (specifically) by W3C IPR?. @dschuff I don't want to speak on @krisselden's behalf too strongly, but I believe that step 1 has, indeed, been a contribution blocker for him.\nIn his case, it's because the process of getting approval for new IPR provisions requires legal approval, and legal approval can drag on.\n\nI don't have strong feelings about the org per se, and of course binaryen isn't really much different from LLVM which is its own org. although I do wonder if it means we would have to e.g. be careful to only discuss tool development in the tool repo (and avoid feeding ideas from the tool back into wasm itself? but what does that even mean?)\n\nSince the current process doesn't require IPR agreement simply to have a conversation that could eventually result in a spec change (but rather in order to submit a patch to the spec), I don't think we would need to worry about conversations that happen outside of this org.. @dschuff now I raced with you:\n\nProbably the opposite actually, since we don't have to ask people to join the CG to accept bug fixes or whatever\n\nThat's what I was saying, yeah.. > There might be some value to indicating for people on the internet which projects are being actively worked on, and are up-to-date with the proposals, etc, but that could just as easily be done via some list on webassembly.org.\nIndeed. We could even just move things to an org like webassembly-tools that would have the same \"feel\" as today's blessed tools, but without the CG/IPR overhead.. > Oh my other question was, is the W3C IPR more really onerous than the apache2 license requirements? My non-lawyerly impression was that they have similar requirements around patent licensing, so if someone needs heavyweight legal approval from their employer to comply with one, then they might need it for the other too.\nMy understanding from @krisselden is that their lawyers already understand Apache2, so it's an easy rubber stamp, while the W3C IPR is a new one for them. Also, the agreement is about the spec, while this contribution is to a tool, so it was a little ambiguous.. I'm excited for this!. ",
    "copy": "Can confirm the dylink sections are now preserved by was-opt. Cheers!. ",
    "winsvega": "GNU Make 4.1\nBuilt for x86_64-pc-linux-gnu\ngcc (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609. looks like the issue was the include headers order that we had in our project.. after the headers were moved to another file it works\n+#include \"wast2wasm.h\"\n +\n +#include <libdevcore/CommonData.h>\n +\n +#include <boost/test/unit_test.hpp>\n +\n +// Disable MSVC warning \"unary minus operator applied to unsigned type\".\n +#pragma warning(push)\n +#pragma warning(disable: 4146)\n +#include <wasm-binary.h>\n +#include <wasm-s-parser.h>\n +#include <wasm-validator.h>\n +#pragma warning(pop)\nbinaryen is a part of Hera repo which used with wasm. \nI guess the issue might  have been that in our project we already have defenition for hash \nand it produced such conflict. . ",
    "aardappel": "Possible testcase:\ngit clone https://github.com/aardappel/lobster.git\ncd lobster/dev/emscripten\nmake\n\nI can try o2wasm.. is there a flag to force it?. for reference, it is not anything assert specific, compiling with -DNDEBUG now we get Unknown symbol: $glGenBuffers. The .s file references glGenBuffers@FUNCTION multiple times and emscripten_glGenBuffers@FUNCTION once, and no references without @FUNCTION in the code (though references in .function are without @FUNCTION).. ",
    "maoyuyang": "oh, I wrote the square function wrong. It should not be the same as the add func. sorry. and thank you for your answer. ",
    "cuviper": "I also fixed it -- #1400. There were a couple more locations that came up after fixing the first two errors.. Updated with the requested style change.. Sure, I can do that.  But FWIW, nearby code has a lot of const std::string &argument, which is why I wrote it this way.. ",
    "mnater": "\nThe issue here is that var k = 10; is not valid asm.js, and asm2wasm assumes the input is valid.\n\nIn my understanding of http://asmjs.org/spec/latest/#variable-type-annotations var k = 10; was valid asm.js. At least it passes all asm.js validators I tried with no error...\nCould you explain in Layman's Terms why this isn't valid?. ",
    "hlolli": "+1 getting the same in node.js 9.3.0\nSo I updated to node 9.7.1 and this is my version\nemcc -v\nemcc (Emscripten gcc/clang-like replacement + linker emulating GNU ld) 1.37.35\nclang version 5.0.0  (emscripten 1.37.35 : 1.37.35)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /opt/emsdk-portable/clang/tag-e1.37.35/build_tag-e1.37.35_64/bin\nFound candidate GCC installation: /usr/lib/gcc/x86_64-redhat-linux/7\nSelected GCC installation: /usr/lib/gcc/x86_64-redhat-linux/7\nCandidate multilib: .;@m64\nCandidate multilib: 32;@m32\nSelected multilib: .;@m64\nINFO:root:(Emscripten: Running sanity checks)\nshared buffer array is surely there\n```\nnode\n\ntypeof SharedArrayBuffer\n'function'\n. some observation\nfunction updateGlobalBufferViews() {\n  if (!(buffer instanceof SharedArrayBuffer)) {\n    buffer = new SharedArrayBuffer(buffer.byteLength );\n  }\n  Module['HEAP8'] = HEAP8 = new Int8Array(buffer);\n  Module['HEAP16'] = HEAP16 = new Int16Array(buffer);\n  Module['HEAP32'] = HEAP32 = new Int32Array(buffer);\n  Module['HEAPU8'] = HEAPU8 = new Uint8Array(buffer);\n  Module['HEAPU16'] = HEAPU16 = new Uint16Array(buffer);\n  Module['HEAPU32'] = HEAPU32 = new Uint32Array(buffer);\n  Module['HEAPF32'] = HEAPF32 = new Float32Array(buffer);\n  Module['HEAPF64'] = HEAPF64 = new Float64Array(buffer);\n}\nThe global buffer clearly isn't SharedArrayBuffer, buf running this code cuases error:\nfailed to asynchronously prepare wasm: CompileError: WasmCompile: Compiling wasm function #4451:_sbrk failed: invalid block arity > 1 @+2447972\nCompileError: WasmCompile: Compiling wasm function #4451:_sbrk failed: invalid block arity > 1 @+2447972\n```\nprints two times. \n",
    "timkerchmar": "Same issue observed when attempting to compile a bare bones OpenGL app: https://github.com/timkerchmar/tsintegration/tree/emscripten/painter/Emscripten\nThis version of build.sh also fails on tls initialization.\nem++ ../Painter.cpp ../../lib/TSIntegration.cpp ../../lib/TSThread.cpp ../../lib/emscripten/main.cpp -I../../lib -s FULL_ES3=1 -s USE_PTHREADS=1 -s WASM=1 --emrun  --separate-asm -o foo.html. ",
    "retrogradeorbit": "I am also getting this problem. I have not put any pthread code in the codebase, I have just switched on the    -s USE_PTHREADS=1 flag. The code compiles, however, when launching the test javascript loader in node, the first line requires() the emscripten produced javascript, which then blows up with:\n```\n/pthreadtest/pthreadtest.js:71\n   throw ex;\n   ^\nTypeError: [object Uint32Array] is not an integer shared typed array.\n    at Atomics.store ()\n    at Object.initMainThreadBlock (pthreadtest/pthreadtest.js:1018:11)\n    at Object. (pthreadtest/pthreadtest.js:5056:38)\n    at Module._compile (module.js:652:30)\n    at Object.Module._extensions..js (module.js:663:10)\n    at Module.load (module.js:565:32)\n    at tryModuleLoad (module.js:505:12)\n    at Function.Module._load (module.js:497:3)\n    at Module.require (module.js:596:17)\n    at require (internal/module.js:11:18)\nMakefile:57: recipe for target 'test' failed\n```\nMy node version seems to support these inbuilts:\n```\n$ node -v\nv8.10.0\n$ node\n\nnew SharedArrayBuffer(10);\nSharedArrayBuffer { byteLength: 10 }\nAtomics\n{}\nAtomics.store\n[Function: store]\n```\nthe generated pthreadtest.js line 1018 is:\n\nAtomics.store(HEAPU32, PThread.mainThreadBlock + 116 >> 2, tlsMemory);. ",
    "athei": "Same problem with Firefox 60 and javascript.options.shared_memory enabled. So pthreads + webassembly is plain broken right now? The quoted page infers that it should work to a certain degree, though.. I tried with Firefox Nightly today. I can confirm that it does work. However, the WebAssembly.instantiateStreaming()support seems to be broken:\nwasm streaming compile failed: TypeError: Response has unsupported MIME type index.html:1249:13\nfalling back to ArrayBuffer instantiation index.html:1249:13\nI suspect it is just something that is broken in Nightly, because Firefox should support it.\n. Yes its not fatal. I tested with this one: https://github.com/brson/basic-http-server\n. I am not sure which create is responsible for mime selection. There is hyper, http and mime. But hyper depends on http but not mime. And http does not depend on mime, too. I guess I will just file with hyper and see how it goes.. It seems that the mentioned webserver does not include any Content-Type whatsoever. Not even for html. As a consequence I switched to one with a larger popularity: https://www.npmjs.com/package/http-server\nIt seems to get it right. It does supply to correct mime which I verified with Wireshark: simc.pcapng.gz. But I still get the warning about wasm streaming compile failed: TypeError: Response has unsupported MIME type.\nUsing 63.0a1 (2018-06-27) (64-bit). Bug in emscripten or Firefox?\n. I checked with a hello world program with current Safari 11.1.1. The warning does not occur there. The same is true for Chrome 67.\nIt seems to be a Firefox Bug. Happens in Nightly and in Stable.. I can confirm that the console MIME error does not appear when using your python file. I did a quick skim through a trace and it seems that both servers using the correct MIME type application/wasm. There must be something else that the javascript server is doing wrongly. I traced both transmissions but for me they look basically the same. I do not get why it does not work with the javascript server.\njavascript.pcapng.gz\npython.pcapng.gz\n. No worries I looked into it and looked deeper into the server response. The javascript server returned:\napplication/wasm; charset=utf-8 instead of application/wasm like it should. The latter is what your python server returns. I will report it upstream.. ",
    "Priysha-Aggarwal": "@kripken \nI tried to compile a simple threaded C program using emscripten by command : \n\"emcc mutex.c -s USE_PTHREADS=1 -s WASM=1 -o mutex.html --memory-init-file 1\" , I got the same error as posted by @retrogradeorbit on 31 May.\nAlso I tried running the generated html file on firefox nightly(63) but the JS console displays:\n\"TypeError: invalid array type for the operation\" w.r.t. PThread.mainThreadBlock. \nAs mentioned by you, I tried installing Nightly version(62) from this link but the download button is hyperlinked to nightly version 63, can you please share the suitable link for the same.. Thanks for the link.\nAlthough this link again directed me to the download link for Firefox Nightly 63 browser, but i was able to get Nightly 62 successfully from this link.\nAlthough, even now running the html file from compiling a simple \"helloworld\" c code, using pthreads, gives me the same error : \nTypeError: invalid array type for the operation\nCommand used : emcc program.c -s USE_PTHREADS=1 -s WASM=1 -o program.html \nI am working on a linux 16.04 system with x86 architecture. \nAny suggestions on this issue would be very helpful.. Yes, i have enabled javascript.options.shared_memory in the browser, without that it gives \"ReferenceError: Atomics is not defined\".\nI am currently working with emscripten 1.38.6.\nAs i mentioned in my first post, i get the error \"TypeError: invalid array type for the operation\" w.r.t. PThread.mainThreadBlock.\nAlso, as mentioned on this link, \"Chrome Canary is currently not available on the Linux platform. \" So, i can't try running the HTML file on it.\nEdit : Tried with emscripten 1.38.7 too, leads me to the same error.\nWhat OS have you tested this on? @kripken . @kripken , thanks a lot for your prompt replies. \nI am listing the build steps that I followed on an Intel i7 machine running Ubuntu 16.04.3. Please suggest if I am doing anything wrong with the build itself:\n1) Built emscripten SDK exactly as mentioned in this link I have all the software prerequisites as mentioned there.\n2) As mentioned here, cloned the incoming branch of emscripten using below command: \n./emsdk install sdk-incoming-64bit (this is mentioned here )\n3) Downloaded the Firefox nightly version 62 and 63 and set javascript.options.shared_memory boolean variable to \u201ctrue\u201d.\n4) Compiled a pthread_create hello world example as following: \nemcc program.c -s USE_PTHREADS=1 -s WASM=1 -o program.html --memory-init-file 1\n5) Launched program.html generated above in both the Firefox nightly versions that always shows :\nPreallocating 1 workers for a pthread spawn pool.\nPreallocating 1 workers for a pthread spawn pool.\nwith a constant \"running\" sign for too long.\n6) While running node program.js gives me :\n/Users/priysha/emsdk/emscripten/incoming/mutex.js:106\n      throw ex;\n      ^\nTypeError: [object Uint32Array] is not an integer shared typed array.\n    at Atomics.store ()\n    at Object.initMainThreadBlock (/Users/priysha/emsdk/emscripten/incoming/mutex.js:1821:17)\n    at Object. (/Users/priysha/emsdk/emscripten/incoming/mutex.js:5651:38)\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\n    at Module.load (internal/modules/cjs/loader.js:599:32)\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\n    at startup (internal/bootstrap/node.js:236:19)\nThanks in advance.. @kripken \nI have uploaded my project here.\nNote that i have build the project with debug information i.e. using -g flag with emcc and uploaded all the used and generated files on the above link.\nKindly try building this and suggest.\nThanks!. @kripken \nI tried compiling using -s PTHREAD_POOL_SIZE=8 flag too but no success. \nI will file the issue as suggested by you.\nThank you for your time and effort.. ",
    "vivkumar": "Hi @kripken , went through all your above suggestions to @Priysha-Aggarwal . I am still not clear why I am unable to just use \"node hello.js\" command to run a plain hello world c code (doesn't have any pthread API/header inside it) when compiled using the command line \"-s USE_PTHREADS=1\". I tried this on Ubuntu 16.04 with the installations steps as mentioned in 5 posts above. Even using PTHREAD_POOL_SIZE also doesn't help. The exception thrown is exactly same as reported by @Priysha-Aggarwal 5 posts above. Is it that the only way to run an executable created with \"-s USE_PTHREADS=1\" is by using a browser (e.g., Firefox nightly)? If its running for you using node then I think the issue could be either with build steps (but you said above this is correct) or the versions of software dependencies.. Thanks very much @kripken for clarifying my doubts.. ",
    "thomasjammet": "Hi all,\nI am still having the invalid array type for the operation error log in all Firefox versions on Windows (the last I tried is 62.0b9 (64 bit)).\nTo reproduce the error you can just compile the tests/pthread/hello_thread.c test application with  USE_PTHREADS=1 : \nemcc .\\hello_thread.c -o main.html -s USE_PTHREADS=1\nAnd of course I have enabled javascript.options.shared_memory. The same application works in Chrome Canary (Version 69.0.3496.0).\nAlso my version of emcc is 1.38.8 incoming but I have tried with many other versions and I am still having this bug. \nAny help would be really appreciated!. Thanks @kripken, \nI prefer to post bugs with short sample code so I have tried to dig into the reason of the issue. It seems that in the main.js application compiled the main buffer (used to initialize the HEAPU32 array) is an ArrayBuffer instead of a SharedArrayBuffer. \nAnd strangely in Chrome it is a SharedArrayBuffer as expected. Could it be a buffer initialization error?\n. Thanks @koconnor, I updated to FireFox Nightly 63.0a1 (64 bit) and it works fine! . ",
    "koconnor": "@kripken, @thomasjammet:\nAn update for you all.  I am using emscripten 1.38.10 on MacOS X 10.13.5.  I have a pthreads test app that will give the 'invalid array type' message from this line:\nAtomics.store(HEAPU32, (PThread.mainThreadBlock + 116 ) >> 2, tlsMemory); // Init thread-local-storage memory array.\nwith FireFox Quantum 61.0.1 (64-bit) with config javascript.options.shared_memory -> true\n(as it should with the Spectre vulnerability 'fix'.)\nBut it does work with both Firefox Nightly (63.0a1 (2018-07-27) (64-bit)) and Chrome Version 70.0.3504.0 (Official Build) canary (64-bit) with the appropriate configs.  @thomasjammet, it may work for you with similar versions, I don't have a Windows machine to try those tests.\nOn to other issues!. ",
    "gusew": "Thank you for your reply. We have evaluated a similar example with the emterpreter-async option, as you have recommended. Unfortunately, the behavior of the program when executed by the emterpreter is not as expected and very likely not correct. \nWe overwrite the original system call with a small function that introduces a sleep (contents of file 'pre.js'):\n```\nreal_doReadv = function(){};\nfunction sleep_doWritev(stream, iov, iovcnt){\n  var result = real_doWritev(stream, iov, iovcnt);\n  _emscripten_sleep(2000);\n  return result; \n}\nvar Module = {};\nModule['preRun'] = function(){\n  real_doWritev     = SYSCALLS.doWritev;\n  SYSCALLS.doWritev = sleep_doWritev;\n};\nThen, we compile our example program (contents of file 'main3.c'):\ninclude \nint main() {\n  FILE * f;\n  char   in;\n  char   out;\nprintf(\"Async syscall test\\r\\n\");\n  printf(\"open for write\\r\\n\");\n  in = 'i';\n  f  = fopen(\"/test\", \"w\");\n  fputc(in, f);\n  printf(\"%c written\\r\\n\", in); \n  fclose(f);\nprintf(\"open for read\\r\\n\");\n  f   = fopen(\"/test\", \"r\");\n  out = fgetc(f);\n  printf(\"%c read\\r\\n\", out); \n  fclose(f);\nprintf(\"test terminated\\r\\n\");\n  return 0;\n}\n```\nCompiler arguments:\nemcc --pre-js pre.js -o test.html main3.c -s FORCE_FILESYSTEM=1 -s EMTERPRETIFY=1 -s EMTERPRETIFY_ASYNC=1 -s DEFAULT_LIBRARY_FUNCS_TO_INCLUDE='[\"memcpy\", \"emscripten_sleep\", \"memset\", \"malloc\", \"free\"]' -s SYSCALL_DEBUG=1 -Werror -s NO_EXIT_RUNTIME=1\nInstead of the following expected output sequence:\nAsync syscall test\nopen for write\ni written\nopen for read\ni read\ntest terminated\nwhat we observe is the following output sequence:\nAsync syscall test\nAsync syscall test\nopen for write\nopen for write\ni written\ni written\nopen for read\nopen for read\ni read\ni read\ntest terminated\ntest terminated\nHowever, the call to emscripten_sleep has an effect but somehow on each system call and not only when the write call is executed. You can find the example files as well as the call to emcc in the \nexample.zip.\n. ",
    "faucct": "Also I expect relative sourceMappingURLs to be expanded from the .wasm path in Firefox. Does this issue belong to Firefox or a Web Assembly spec?. > is wasm-dis used with --source-map to ingest location attributes into wat?\nYes, it is. I have updated your repository and tried changing sourceMappingURL, but wasm-dis completes with errors and changes pi.wast:\nwasm-dis pi.wasm --source-map pi.wasm.map -o pi.wast\nskipping debug location info for 1116\nskipping debug location info for 1120\nskipping debug location info for 1124\nskipping debug location info for 1143\nskipping debug location info for 1203\nskipping debug location info for 1221\nskipping debug location info for 1254\nskipping debug location info for 1362\nskipping debug location info for 1381\nskipping debug location info for 1389\nskipping debug location info for 1437\nskipping debug location info for 1489\nskipping debug location info for 1564\nskipping debug location info for 1586\nskipping debug location info for 1597\nskipping debug location info for 1608\nskipping debug location info for 1627\nskipping debug location info for 1631\nskipping debug location info for 1635\nskipping debug location info for 1647\nskipping debug location info for 1760\nskipping debug location info for 1771\nskipping debug location info for 1778\nskipping debug location info for 1789\nskipping debug location info for 1804\nskipping debug location info for 1838\nskipping debug location info for 1871\nskipping debug location info for 1875\nskipping debug location info for 1917\nskipping debug location info for 1921\nskipping debug location info for 1949\nskipping debug location info for 2011\nskipping debug location info for 2062\nskipping debug location info for 2084\nskipping debug location info for 2107\nskipping debug location info for 2151\nskipping debug location info for 2183\nskipping debug location info for 2226\nskipping debug location info for 2269\nskipping debug location info for 2321\nskipping debug location info for 2460\nskipping debug location info for 2467\nskipping debug location info for 2526\nskipping debug location info for 2536\nskipping debug location info for 2540\nskipping debug location info for 2584\nskipping debug location info for 2719\nskipping debug location info for 2802\nskipping debug location info for 2806\nskipping debug location info for 2877\nskipping debug location info for 2913\nskipping debug location info for 2954\nskipping debug location info for 3056\nskipping debug location info for 3139\nskipping debug location info for 3143. ",
    "jwasinger": "Great!  Now it's working :)\nThanks,\nJared. Thanks for the quick reply! I tried that.  Still getting the same error.. Ah I see!  Now it's working for me.  Thanks :). ",
    "z--z---z-----": "Thanks. I am closing this issue then as there is another issue where this is being taking care of.. The number of gets and sets are identical, but the sequence of instructions is not the same.\nWould it be a confusing debugging experience?. ",
    "TerrorJack": "@eholk I'm starting to do some basic experiments. I'm compiling a huge switch statement and generating a long chain of nested blocks and using a huge br_table to branch to relative blocks.\nThe problem is, binaryen seems not to scale. For a mere block number of 10^6, validation of the whole module has been taking more than 10 minutes on my laptop. There is no complex logic in each block, it's simply getting an Int32 parameter, branch to the block which sets a local variable with parameter value and finally returning the value of the local variable.\nIs there a brief summary of time complexities of binaryen's internal algorithms? Is there some quadric slowdown hidden somewhere?. @kripken I'm explicitly invoking BinaryenModuleValidate so I'm not complaining about hidden validation. I still wish I can run validation on functions with lots of blocks though, as a sanity check of a wasm targeting compiler it's useful.. @kripken I'll provide a generated binary file later (if binaryen isn't stuck when validation is skipped). @kripken It's at https://drive.google.com/file/d/1XSynR89OmoQAybb0dluv6RC-Dlh7M3ic/view?usp=sharing\nI only managed to get 1k blocks, since binaryen begins to stall when the number exceed 10k.. @kripken Binary parsing is not a bottleneck, thanks to your PR.. @lorenzleutgeb I used call_indirect. There aren't detailed statistics though, the reason is simply to ease implementation. The top-level \"switch\" is a bit tricky to get right (under the hood there's a long chain of nested blocks). . @kripken I see, if it's not desirable to implement it in C++, at least we can implement it in markdown?. @kripken Write the workaround in docs, for the convenience of later compiler authors. This behavior persists even if I comment out all add(\"reorder-locals\") in pass.cpp. Maybe I'm digging not deep enough here.. All right, after jumping a bit deeper in the rabbit hole: it seems StackWriter::mapLocalsAndEmitHeader is the root cause of local re-mapping, and it's wired-in behavior of binaryen's binary serialization, there is no way to opt-out and prevent re-mapping. Apologies for spamming everyone's inbox, closing this issue.. Turns out I was wrong after reading binaryen code; when a memory import was added via C API, no memory section will be written to the output binary, and the same applies to tables.. ",
    "lorenzleutgeb": "@TerrorJack I need to choose one of the methods that you mention in the first post too, and would like to leverage your test results. Could you share them please? Which polyfill did you choose and why?. ",
    "tbodt": "My usecase is having a nice development environment running on an iOS device. Qemu + WebAssembly seemed like the most promising way to make this fast. . @davidar No, I never found the time to work on it. It's still on my list of unfinished projects that I might work on later though.. @atrosinenko Multithreading was recently re-enabled (in Chrome at least) because other spectre mitigations were put in place.. As for compiling one basic block at a time, you can either:\n\nPut all the basic blocks in a function, run binaryen's relooper on the function, and reload the module\nWait for tailcall support, make each basic block its own function that ends with a tailcall, and reload the module\n\nEither way, you have to reload the module with all your code in it, which requires the browser to throw out all of its existing compiled machine code and start over. It seems like WASM wasn't designed with this use case in mind.. ",
    "davidar": "Did this go anywhere? I'd also be interested in seeing this happen. @atrosinenko You seem to have quite some experience building QEMU with Emscripten, I'm curious if you have any thoughts on this issue?. ",
    "atrosinenko": "@davidar Now I'm planning to rewrite my port of QEMU on top of v3.0 implementing WASM JIT instead of Asm.js one that was implemented more as proof-of-concept (and fall back to compiling plain TCI in Asm.js) -- see qemujs-v2 branch. But I fear Binaryen's Apache 2.0 license is not compatible with QEMU that is AFAIK GPLv2 as a whole (different parts have different license options sometimes).\nFor Asm.js I was compiling basic block after N executions (hooked qemu_tb_exec -- you can see diff of v2.4.1...emscripten branches) and hope it will be much faster when eliminating machine code -> TCI bytecode -> asm.js -> parse JS -> ... -> machine code flow.. > Regarding the license, that is something we should fix if, if it's a problem.\nBut isn't changing a license a big problem when there are already 64 contributors (or do you have copyright transfer)? (I'm not a lawyer, maybe Apache 2.0 is not a problem...)\nDo you mean upstreaming Binaryen support for QEMU? If so, it may be worth reading QEMU contributor guidelines beforehand: Contribute/SubmitAPatch, to not fix formal requirements afterwards. But not sure whether they would accept such a port. For example, AFAIK now multithreading in browsers is disabled due to security reasons, so I have some kludges to make QEMU single-threaded at the cost of stability. On the other hand, if the original issue was about native QEMU linked to system JS/WASM-engine, then only CPU thread would be \"single-threaded\", so why not... Anyways, it would be great to upstream as much as possible.\nMeanwhile, is there some possibility in WASM to compile one basic block at a time to WASM modules and then, when QEMU decides to directly link them, somehow link these modules, so they can pass execution from one piece of AOT compiled code to another one efficiently?. @dschuff \n\nBut assuming we can work it all out with the Binaryen contributors, I'm also interested it knowing from the OP or other interested parties whether this would actually solve their problem.\n\nAs an interested party, I don't know right now whether Binaryen can help me :) , I was just asked what I think on using Binaryen as a QEMU backend and I answered on what I consider a blocker (maybe it isn't really). Now you say it can be fixed, then I need to re-evaluate.\nDo I get it right, Binaryen can be used as a library constructing WASM binaries at run-time and even somehow optimize them? Meanwhile, is there some \"official\" WASM interpreter in C or C++? Another possibility may be to implement emitting WASM on my own, it would be some difficulty to master its binary format, but not sure whether I need much more than that from Binaryen.. Sounds very promising!. Here is a WIP example. Right now, the block layer does not work, since I had troubles with compiling with Emterpretify (hard to specify what to Emterpret and what not).. On Chrome it is expected and I don't know how to work around it generally, except for fixing Chrome. :)\nIn Firefox it should run Memtest (and then wait forever), OpenWRT expected to run for a while, then crash (everything tested without Network support).. I fear, it is not because of the main WASM module, but because of ~1000th one -- when I debugged it the last time it successfully compiled 1000+ small WASM modules, then crashed, the same with Firefox, but with a much large module number. It would probably be quite easy to compile not everything if I manage to set up interpretation in Bynarien. \nCompiling selected TBs only after some execution count would probably be much faster, as well.. @kripken I copied it to separate directory: https://atrosinenko.github.io/qemujs-demo/chrome-bug/shell.html -- it will probably be deleted sometime, but can be considered as a stable URL for the time of fixing the bug.. Thanks! Now I work on using Binaryen interpreter for first N executions, it even run Memtest in Chrome, but now it leaks (in a C meaning of leak) even in Firefox, so I try to run in natively but with Binaryen instead of TCI / native TCG. \n@tbodt Maybe it can somehow be used on iOS semi-natively this way (with JITting through the standard system JS engine inside a native app), but I know almost nothing about iOS development.. Thanks!. ",
    "caffeinum": "I dont know if this is very connected to this issue.\nI am trying to build c-lightning to WASM, and the section on cross-building asks to use qemu-user to build project:\n```\nTwo makefile targets should not be cross-compiled so we specify a native CC:\nmake CC=clang clean ccan/tools/configurator/configurator\nmake clean -C ccan/ccan/cdump/tools \\\n  && make CC=clang -C ccan/ccan/cdump/tools\nInstall the qemu-user package. This will allow you to properly configure the build for the target device environment. Build with:\nBUILD=x86_64 MAKE_HOST=arm-linux-androideabi \\\n  make PIE=1 DEVELOPER=0 \\\n  CONFIGURATOR_CC=\"arm-linux-androideabi-clang -static\"\n```\nHere is the link. https://github.com/ElementsProject/lightning/blob/master/doc/INSTALL.md#to-cross-compile-for-android\nI am not sure how to use qemu for WASM? Is it possible yet?\nADDITIONAL NOTE:\nIf I try to build using emscripten directly using:\nbash\nemconfigure ./configure\nThen the error pops up like that:\nbash\nAlekseys-MacBook-Pro:lightning caffeinum$ emconfigure ./configure\n-n Compiling ccan/tools/configurator/configurator...\nerror: unresolved symbol: popen\nAborting compilation due to previous errors | undefined\nTraceback (most recent call last):\n...\nException: Expected the command ['/Users/caffeinum/emsdk/node/8.9.1_64bit/bin/node', '/Users/caffeinum/emsdk/emscripten/1.38.12/src/compiler.js', '/tmp/tmp7dqefN.txt', '/Users/caffeinum/emsdk/emscripten/1.38.12/src/library_pthread_stub.js'] to finish with return code 0, but it returned with code 1 instead! Output: // The Module object: Our interface to the outside world. We import\n// and export values on it. There are various ways Module can be used:\n// 1. Not defined. We create it here\n// 2. A function parameter, function(Module) { ..generated code.. }\n// 3. pre-run appended it, var Module = {}; ..generated \nERROR:root:Configure step failed with non-zero return code: 1.  Command line: ./configure at /Users/caffeinum/lightning\nI set up an issue: https://github.com/ElementsProject/lightning/issues/1370\nAlso, using an approach for cross-compiling in the instruction, https://github.com/ElementsProject/lightning/blob/master/doc/INSTALL.md#to-cross-compile-for-android, how do I set target_host value?\nSorry if that's the wrong place!\n. ",
    "fitzgen": "Test case: wasm_game_of_life_bg.zip\n. I just rebuilt and this is fixed on the latest master. Sorry for the noise!. Sounds great to me! Thanks for writing this up.\nOnly missing bit I can see, which is maybe an optional nice-to-have, would be differential fuzzing between another wasm implementation and the output of wasm2js.. Ah, ok! I think it is also valuable just to run random wasm programs through wasm2js as well, without the differential step :). @ashleygwilliams is this generally good to merge? Does it still need to be \"WIP\"? Did you see @kripken's question about determining whether we are expecting to see differences in the travis build now (or only once there is a new tagged release?)\nThanks!. To be clear, this is size(self) + sum(size(x) for x in dominated_by(self)) right?\nThat is, this is not the sum of sizes of everything transitively reachable in the call-graph from this function -- it doesn't include transitively reachable children that are also reachable from other exported functions?. Ok, so this is removing the export, generating the wasm again for this parallel universe, and then getting the resulting size? SGTM. Does this handle the case when one exported function calls another exported function?. > What does dominated_by mean?\nIf A dominates B in a graph with some root R, then all paths from R to B must pass through A. In this situation, R = any exported function.\nhttps://en.wikipedia.org/wiki/Dominator_(graph_theory)\nIt is also used in heap profiling: https://developer.mozilla.org/en-US/docs/Tools/Memory/Dominators_view. The start function: definitely. Unsure about table.. ",
    "regehr": "whoops, nevermind-- was missing some args, sorry!. ",
    "chfast": "It's better to have a single one.\nOn Fri, Aug 3, 2018, 20:21 Derek Schuff notifications@github.com wrote:\n\nLooking back at it. In my comment above I expressed a preference for\nhaving a single static library (e.g. libbinaryen.a) and asked why we\ndidn't do that. I'm not exactly sure what @chfast\nhttps://github.com/chfast meant when they said \"but that's required\".\nDo you mean it's required to have separate static libs too? If so, why?\n@axic https://github.com/axic what's your use case? Would it be better\nto have one or many static libs?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/WebAssembly/binaryen/pull/1511#issuecomment-410336632,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAi_xOmiGp5nqc3-OIaNRPdqPQ5YQv4Zks5uNJSogaJpZM4ThIUz\n.\n. Should I still work on this?. > Have you joined the w3c community group? (required for contributors)\n\nI have.\n\nLooks like there are some compilation errors on CI here.\n\nFixed.. Ping.. Unfortunately, yes, because of the shared - static lib build asymmetry in this project.. Having single static library would be a bit more convenient, but that's required. I can handle multiple static libs in CMake exported config files.. The bigger problem is that there are not public headers for these libraries, so we cannot use them.. I've seen this, but make_unique is not included in every file I modified. I'm happy to change this accordingly. . Ok, I will try to change it. But I believe I used clang-format here.. Sure, I can send following PRs changing other methods. Do you mean the methods taking raw pointers only in this class?\nHere I wanted to send the set of minimal changes to get the feedback about the proposed changes.\nShould I change the curr argument name? I don't think it is a good name here.. This is fixed already.. I reverted the code format change.. I applied requested changes. If you want me to wait for some monster PR touching 315 files to be merged... it does not sound reasonable.. Yes, you do: https://github.com/WebAssembly/binaryen/blob/master/.clang-format#L4. I removed this commit.. ",
    "jfoote": "Change made -- thanks! . ",
    "Becavalier": "I also tried the target \"wasm32-unknown-unknown-elf\", but the same result.\n\nllc: : error: unable to get target for 'wasm32-unknown-unknown-elf', see --version and --triple.\n. Fixed by rebuilding LLVM with setting WebAssembly as target.. Thanks all!. @kripken @binji make sense, thanks!. I used the WebAssembly module compiled by wabt, but I got the following error message from the browser:\nUncaught (in promise) CompileError: AsyncCompile: Compiling wasm function \"lockMutex\" failed: invalid Atomics opcode @+132\nBrowser version: \nVersion 72.0.3582.0 (Official Build) canary (64-bit)\n\nHere I also enabled the following two flags:\nWebAssembly threads support.\nExperimental enabled SharedArrayBuffer support in JavaScript.\nIt seems like v8 did not implement the the WAT opcode \"i32.atomic.wait\" and \"i64.atomic.wait\" by looking into the following source code: \nhttps://github.com/v8/v8/blob/fa12290de739364e14aefbd858f10f0b942b42a6/src/wasm/function-body-decoder-impl.h#L63\nAny idea?. @binji I get it, thank you!. ",
    "MaxGraey": "\"Failed to fetch http://ppa.launchpad.net/ubuntu-toolchain-r/test/ubuntu/pool/main/g/gcc-5/g++-5_5.5.0-12ubuntu1~14.04_amd64.deb\". Hmm, what if just remove return result for such kind of code? Like:\nwast\n(module\n (func $0\n   (block $label$1\n    (loop $label$2\n     (unreachable)\n    )\n   )\n )\n)\nOr this sintetic example?\nBecause this doesn't depend on unreachable. Current code behave (failed) the same:\n```wast\n(module\n (func $0\n  (drop\n   (block $label$1 (result i32)\n    (loop $label$2\n     (nop)\n    )\n   )\n  )\n )\n)\n``. @binji it will be great ifwasm-objdumpprovide an opportunity to optionally emit machine code representation (x86-64 for example) of wasm file. This allowed bycapstone` and one of standalone VM for example and Web Aseembly Studio used this. WDYT?. Yah, may be better to create another separate tool for this routine. The main idea to determine which is codegen quality better for specific wasm operations or optimizations and how this changes during evolution some VM to get informative feedback and estimation about some binaryen performance optimizations.\nPS Sorry for offtop. Hmm. May be also need update node's version in this part?\nhttps://github.com/alexcrichton/binaryen/blob/6de340182537d49abf12136010a92a4d21383ee7/.travis.yml#L65. Hi @sara66,\nPhantomJS using pretty old WebKit version which doesn't support WebAssembly.. You can find some cli compiler flags In gulpfile.js.\n\"main.ts\",\n    \"--baseDir\", \"assembly\",\n    \"--binaryFile\", \"../out/main.wasm\",\n    \"--sourceMap\",\n    \"--measure\",\n    \"-O3\"\nASC also support configure additional binaryen passes via:\n\"--runPasses optimizing-inlining inlining\"\nAnd rebuild\nBut this didn't help for me. Thanks, Alan! I will address your explanation to @dcodeIO . That happened because binaryen can't recognize unsigned value and always operate with signed integer types, right?. Ahh, sorry. I link to older complicated and not isolated version (updated \"full example\" link). But that almost the same. The binaryen already run with \"-O3\" optimization, see gulpfile.js flags. Yah, I like idea about -O4 or -Ofast (which apply all perf passes). Thanks @binji seems it a good start point. Hmm, the best way if this doing by VM of course, especially if machine support mulq/umulh instructions. But current LLVM/VM (jit) in some reason don't do this for u64/i64 and doing this only for u32/i32.\n\nInteresting, I thought VMs would be doing this kind of thing. I see this on firefox\n\nHmm, interesting. May be you have older cpu architecture than me where multiplication is not so cheap\nPS I have Intel x64 Crystal Well family chip\n@sunfishcode WDYT? I know crettone optimize this case even for u64/i64 but seems latest Chrome and Firefox don't manage this currently. 3x+ times speedup for only polyfilled umul so we can definitely expect significant boost when using builtin instructions like mulq or imulh/umulh if arch support it.\nSince we are determined that this is in part of VM I'm closing this issue.. It will be great if binaryen will allow evaluate automatically or manually during compile time some pure functions for example which has all input arguments are constants and doesn't call any other non-pure functions, mutable globals or other side-effects in its body but can call himself (recursive). Something similar as constexpr in C++ 11. wdyt?. Yeah, determine pure function case can be hard job for binaryen and it should do on host compiler side. Some compiler like C++ can handle this via constexpr but some like AssemblyScript or Go doesn't. So this could be provided by binaryen as api method but called manually per function instead implement this as some optimization pass. Or better if this feature should implement compiler by itself?\nEDIT\nbtw it seems constexpr handle by LLVM but not sure, may be that module needs just for const folding.. Yah, but it seems speculatable LLVM flag for functions is pretty close to pure function. About constant expressions they are described here but it seems they need only for simple constant folding. So hard to tell who should do this job. May be host compiler should but using some helper routines from binaryen . You are right! For signed integers It require more complicated optimization. GCC (LLVM?) can provide it. Example on C:\nc\nint32_t rem256_s(int32_t a) {\n  return a % 256;\n}\nto something similar (not optimal version):\nc\nint32_t rem256_s(int32_t a) {\n  return (a & 255) | (unsigned(-(a < 0)) & ~255);\n}\nEDIT and close to optimal:\nc\nint32_t rem256_s(int32_t a) {\n  return (a & 255) | ((a >> 31) & ~255);\n}\nAnd I should mentioned Mozilla's wasm JIT compiler can optimize i32.rem_s with POT constant but not optimal (using branch):\nasm\n  sub rsp, 8                            ; 0x000000 48 83 ec 08\n  mov ecx, edi                          ; 0x000004 8b cf\n  mov eax, ecx                          ; 0x000006 8b c1\n  test eax, eax                         ; 0x000008 85 c0\n  js 0x1a                               ; 0x00000a 0f 88 0a 00 00 00\n 0x000010:                              \n  and eax, 0xff                         ; 0x000010 25 ff 00 00 00\n  jmp 0x23                              ; 0x000015 e9 09 00 00 00\n 0x00001a:                              \n  neg eax                               ; 0x00001a f7 d8\n  and eax, 0xff                         ; 0x00001c 25 ff 00 00 00\n  neg eax                               ; 0x000021 f7 d8\n  nop                                   ; 0x000023 66 90\n  add rsp, 8                            ; 0x000025 48 83 c4 08\n  ret                                   ; 0x000029 c3\nAnd my branch-less (optimal) version:\nasm\n  sub rsp, 8                            ; 0x000000 48 83 ec 08\n  mov eax, edi                          ; 0x000004 8b c7\n  sar eax, 0x1f                         ; 0x000006 c1 f8 1f\n  and eax, 0xffffff00                   ; 0x000009 25 00 ff ff ff\n  and edi, 0xff                         ; 0x00000e 81 e7 ff 00 00 00\n  or eax, edi                           ; 0x000014 0b c7\n  nop                                   ; 0x000016 66 90\n  add rsp, 8                            ; 0x000018 48 83 c4 08\n  ret                                   ; 0x00001c c3. Thanks @binji!\nGCC sometimes using very speculative optimizations like in this case.\nAnd it seems Clang version is more correct than mine, so right version should be:\nc\nint32_t rem256_s(int32_t a) {\n  return a - (((a >> 31 & 255) + a) & ~255);\n}. Hi Alon, will the blog describe the process of emitting IR for souper optimizer and how its rules or optimized result could be exported back to binaryen?. Oh, great! I look forward to. @kripken do you have some plan add \"Loop Invariant Code Motion\" pass? It would be nice have optimization which move invariant code out from body loop.. @kripken This pretty useful for non-LLVM backed languages like AssemblyScript and Go. Just see this example. dotOptimal function require a lot of manual caching without  \"Loop Invariant Code Motion\". Invariant variable caching has to be done almost constantly as soon as there is work with structures or indexed arrays inside loops. . @kripken Yeah, inlining length and __get it seems problem of AS, but anyway I think any call which can't pass loop iteration as argument could be hoisting if hasn't contain mutable globals at the same time which could cause to side effects.. Thank you @kripken for efficiency!. @kripken Could you include this LICM pass under -O4 opt flag (which I hope apply it in early stage)? I tried use LICM as additional pass after all with combination of \"flatten\" but it significantly increase binary size.. I created example: https://webassembly.studio/?f=p1ec32awtqi\nCurrently it uses \"-O3\" and \"--runPasses\", \"precompute-propagate, licm\". \"-O3\" in AssemblyScript is actually forced to \"-O4\" for binaryen internally.\nIf I adding \"flatten\" to passe like \"flatten, precompute-propagate, licm\". With \"flatten\" I got much bigger and not optimal result:\nhttps://webassembly.studio/?f=pwdlgy78krs. At first link AS used -O4 and \"precompute-propagate + licm\" additional passes but without \"flatten\". Result the same as -O4 without licm and produce this code for loop:\nwat\n...\n(func $licmTest (export \"licmTest\") (type $t0) (param $p0 i32) (result i32)\n    (local $l0 i32) (local $l1 i32)\n    block $B0\n      loop $L1\n        get_local $l0\n        get_local $p0\n        i32.ge_s\n        br_if $B0\n        get_local $l1\n        f64.const 0x1.bcb7b1526e50ep-2 (;=0.434294;)\n        f64.const 0x1.bcb7b1526e50ep-2 (;=0.434294;)\n        f64.const 0x1.8246d97276aabp-3 (;=0.188612;)\n        call $f0\n        f64.mul\n        f64.add\n        i32.trunc_s/f64\n        i32.add\n        set_local $l1\n        get_local $l0\n        i32.const 1\n        i32.add\n        set_local $l0\n        br $L1\n        unreachable\n      end\n      unreachable\n    end\n    get_local $l1)\nSecond link using -O4 + flatten + precompute-propagate + licm and produce this:\nwat\n(func $licmTest (export \"licmTest\") (type $t0) (param $p0 i32) (result i32)\n    (local $l0 i32) (local $l1 i32) (local $l2 i32) (local $l3 i32) (local $l4 i32) (local $l5 i32) (local $l6 i32) (local $l7 i32) (local $l8 i32) (local $l9 i32) (local $l10 i32) (local $l11 i32) (local $l12 i32) (local $l13 f64) (local $l14 f64) (local $l15 f64)\n    block $B0\n      block $B1\n        loop $L2\n          block $B3\n            get_local $l0\n            set_local $l2\n            get_local $p0\n            set_local $l3\n            get_local $l2\n            get_local $l3\n            i32.ge_s\n            set_local $l4\n            get_local $l4\n            br_if $B1\n            nop\n            get_local $l1\n            set_local $l5\n            f64.const 0x1.8246d97276aabp-3 (;=0.188612;)\n            call $f0\n            set_local $l13\n            f64.const 0x1.bcb7b1526e50ep-2 (;=0.434294;)\n            get_local $l13\n            f64.mul\n            set_local $l14\n            f64.const 0x1.bcb7b1526e50ep-2 (;=0.434294;)\n            get_local $l14\n            f64.add\n            set_local $l15\n            get_local $l15\n            i32.trunc_s/f64\n            set_local $l6\n            get_local $l5\n            get_local $l6\n            i32.add\n            set_local $l7\n            get_local $l7\n            set_local $l1\n            nop\n            get_local $l0\n            set_local $l8\n            get_local $l8\n            i32.const 1\n            i32.add\n            set_local $l9\n            get_local $l9\n            set_local $l0\n            nop\n            br $L2\n            unreachable\n            unreachable\n          end\n          unreachable\n          unreachable\n          unreachable\n        end\n        unreachable\n        unreachable\n      end\n      nop\n      get_local $l1\n      set_local $l10\n      get_local $l10\n      set_local $l11\n    end\n    get_local $l11\n    set_local $l12\n    get_local $l12\n    return)\nBoth versions it seems don't do LICM pass. Or I miss something. > Did you mean -O4 is run first? it should be run after the other three.\nIt seems AssemblyScript apply general optimizations first and after that add optional extra passes, but better ask that to @dcodeIO about that. As I remember C provide _Bool, true and false via . @kripken We are very grateful if you check this PR plz. Unfortunately we can't move forward without that PR and WebAssembly Studio's AS instance also broken without this changes. . I mean FMA as mul+add (may be better called this MAD or MAC) instruction set which on most modern hardware execute at the same time at hardware level. However some CPUs support special fma (fused multiply add) which execute at the same time + eliminate rounding error which appear if we execute mul and add sequentially. Anyway this algorithm should works without fma.\nIn my example I implemented from article algorithm 5 (version 1, full percise) and algorithm 4 (version 2). probably memcmp should be little faster. Oh, great! I think better if you start some basics and may be after I add additional methods/rules for that pass =). Great! Are you plan merge this to master? Or I can just fork oi2 and continue work in separate branch?\nbtw I use one trick with range checking if all arguments is unsigned. Like:\njs\n(a >= const1) & (a <= const2)\nwhere a, const1 and const2 are unsigned ints\njs\na - const1 <= const2 - const1\nis it make sense implement this rule as well, wdyt?. Also figure outing some useful rules for integer (sing/unsign) comparators:\nx > x - 1\ncould always transform to:\nx != MIN_VALUE\nand\nx + 1 > x\ncould always transform to:\nx != MAX_VALUE. Also wdyt using for x != 0:\nwat\nget_local $0\ni32.eqz\ni32.eqz\ninstead\nwat\nget_local $0\ni32.const 0\ni32.ne\nThis reducing code by 1 byte, but generate worse machine code so this probably useful only for shrink code >= 2. Of course this not very likely code because if/else/select don't require this operation explicitly. @kripken Sorry, currently I busy on work but I hope I will return to this on weekend. Just note. Found another possible improvments like transform this:\nwat\ni32.const 1\ni32.const 0\nget_local $p0\nselect\nor this:\nwat\nget_local $p0\nif $I0 (result i32)\n  i32.const 1\nelse\n  i32.const 0\nend\nto this (depending on $p0 type)\nwat\nget_local $p0\ni32.const 0\ni32.ne. More possible optimizations:\n1. from:\nwat\n(func $t1 (export \"t1\") (type $t0) (param $p0 i32) (result i32)\n    get_local $p0\n    i32.const 0\n    i32.lt_s)\nto:\nwat\n(func $t1 (export \"t1\") (type $t0) (param $p0 i32) (result i32)\n    get_local $p0\n    i32.const 31\n    i32.shr_s)\n2. from:\nwat\n (func $t2 (export \"t2\") (type $t0) (param $p0 i32) (result i32)\n    get_local $p0\n    i32.const -1\n    i32.ne)\nto (but not always possible, probably valid only if result used as i1 in next steps):\nwat\n(func $t2 (export \"t2\") (type $t0) (param $p0 i32) (result i32)\n    get_local $p0\n    i32.const -1\n    i32.xor). We have a pretty performance controversial n-body benchmark output. It will be great if you tests new -O4 passes on it.. @dcodeIO Try to comment tests for Array#shift.. Hmm, it seems somthing broken inside memcpy/memmove in that case . Hmm, but how we can disable specific pass? AS allow only add custom passes after default passes handled by binaryen but not exclude (ban some passes) and if realize this feature (exclude pass) it would pretty danger. @dcodeIO right?\n. You should add export_function \"_BinaryenTypeVec128\" to build-js.sh as well. Thanks!. Sure. Here you are:\nhttps://webassembly.studio/?f=hs1t59kh1sl\nOn my machine\nFirefox 65 b5 results:\ncached globals: 162ms\nglobals: 190ms\nChrome 72.0.3626.17 beta results:\ncached globals: 189.93017578125ms\nglobals: 217.11474609375ms. In my opinion this should be done by toolchain because we have wide range standalone VMs for example which not using extra smart jit for staying simple. But this should be using only for high level optimizations because it could increase produced size.\nPS also I checked LLVM-backed wasm from C++ and Rust and they are both also use caching for global variables. So most VMs oriented on LLVM-based output I guess so this another reason for doing this by binaryen for better consistency. Wavm which use jit by LLVM definitely the fastest standalone VM for now if trust this bench results but most of VMs doesn't use even JIT or use very simple JIT like Cranelift (wasmer). But if this is easy to implement in a VM this of course would be more preferable.. awesome! Thanks. @dcodeIO it seems need rename double to int instructions as well i32.trunc_s.f32 -> i32.trunc_f32_s and etc.. Hmm, this also happened with one level up for shrinkage. Like -O3s. Is it make sense using this also for -O3? I guess select in this case also faster than if-return. @binji thanks for info! \nFirefox more sensitive in this case:\nselect:\nasm\nwasm-function[0]:\n  sub rsp, 8                            ; 0x000000 48 83 ec 08\n  mov eax, 1                            ; 0x000004 b8 01 00 00 00\n  mov ecx, 2                            ; 0x000009 b9 02 00 00 00\n  test edi, edi                         ; 0x00000e 85 ff\n  cmove eax, ecx                        ; 0x000010 0f 44 c1\n  nop                                   ; 0x000013 66 90\n  add rsp, 8                            ; 0x000015 48 83 c4 08\n  ret                                   ; 0x000019 c3\nif-else:\nasm\nwasm-function[1]:\n 0x000000:                              ; 0x000000 from: [0x000006, 0x000011]\n  sub rsp, 8                            ; 0x000000 48 83 ec 08\n  test edi, edi                         ; 0x000004 85 ff\n  je 0x16                               ; 0x000006 0f 84 0a 00 00 00\n 0x00000c:                              \n  mov eax, 1                            ; 0x00000c b8 01 00 00 00\n  jmp 0x1b                              ; 0x000011 e9 05 00 00 00\n 0x000016:                              \n  mov eax, 2                            ; 0x000016 b8 02 00 00 00\n  nop                                   ; 0x00001b 66 90\n  add rsp, 8                            ; 0x00001d 48 83 c4 08\n  ret                                   ; 0x000021 c3\n. Currently AS using binaryen's -O4 which already include flatten and local-cse but without --rereloop which unnecessary for AS because it use binaryen as code/loop generator. But this not helps. On C/C++ this undefined behaviour and non-deterministically depends on hardware. For example ARM use saturation/clamp mode, Intel cpus uses some kind of wrap mode. So may be make sense actually call binaryen's clamp mode as bound mode or border mode and existing clamp rename or modify behaviour to saturation mode for align to new saturation instructions like i32.trunc_u:sat/f64?. ~~Hmm, I don't think so. I can'r see any difference between with -msign-ext and without:\nhttps://godbolt.org/z/oNdu4G~~. in that link used latest clang x86-64 bit compiler. Btw it seems -msign-ext flag supports only after clang 6.0. -msign-ext relate to wasm zero/sign extention proposal. For current case we should use -mnontrapping-fptoint flag. But anyway I don't think this glue code coming from LLVM (I mean legacy clamp mode without using non-trapping conversion flag from latest LLVM) because this behaviour handling by -s BINARYEN_TRAP_MODE='clamp' flag for emcc. @binji \nI see:\nhttps://github.com/WebAssembly/spec/blob/master/test/core/float_exprs.wast#L163\nHmm, may I ask why this all legalized for LLVM but not for wasm?\nnan * -1 produce nan but -nan => -nan. That's main reason?. Also LLVM based compilers as Rust and emscripten produce:\nwat\nget_local $p0\nf64.neg\nfor x * -1.0 without -ffast-math\nShould they also disable this optimizations?. @kripken Good catch, looks like I meant another expression. Remove that. @binji I understand this. But I wondering is it necessary skip this optimizations for LLVM-backed compilers when they targeting to Wasm as well? . Wow. This is unexpected!. Other possible optimization for floats found on n-body bench:\nc++\nfunction div(x: f64): f64 {\n    return -x / 1000.0;\n}\ncurrently produce:\nwat\n(func $div (export \"div\") (type $t0) (param $p0 f64) (result f64)\n    get_local $p0\n    f64.neg\n    f64.const 0x1.f4p+9 (;=1000;)\n    f64.div)\nbut optimal:\nwat\n(func $div (export \"div\") (type $t0) (param $p0 f64) (result f64)\n    get_local $p0\n    f64.const -0x1.f4p+9 (;=-1000;)\n    f64.div)\n. @kripken We waiting this for a long time=)\nhttps://github.com/AssemblyScript/assemblyscript/issues/32. @tlively Just need replace i32 to i32x4 for now, right?. Hmm, after this PR or that commit (I'm not sure) some our generated tests increased size. Also it led to performance degradation in n-body benchmark on ~5%.\nResults before:\nPerforming 20000000 steps (AssemblyScript WASM) ...\nTook 2928.2440619999998ms\nResults after:\nPerforming 20000000 steps (AssemblyScript WASM) ...\nTook 3045.604018ms. Sure!\nThis archive contain wat and wasm n-body example before release 69 and latest 72-nightly (actually master upstream). All where built with -O4 in term of binaryen:\nnbody-binaryen-example.zip\nAlso here you could see difference:\nhttps://github.com/MaxGraey/assemblyscript/commit/ce698644412f6d0275923d1b919f1101f9827816#diff-764be5e57c2f6ba87580e44a5b0cc033\n. @kripken Is this information enough? Let me know if you need anything else.. Ok, I rechecked bench several times without any background tasks for avoid fluctuations and should make adjustments - slowdown not 4-5% but 2-3%.. before and after wat and wasm files attached to this comment: https://github.com/WebAssembly/binaryen/pull/1940#issuecomment-471086813. Ah, got it! Here you are (.wasm):\nuntouched.wasm.zip\nand untouched .wat file you can find here: https://github.com/MaxGraey/assemblyscript/blob/ce698644412f6d0275923d1b919f1101f9827816/examples/n-body/build/untouched.wat. Yes, as I mentioned in this comment you should use -O4. I'm not sure this regression changes coming from this PR. It could probably after that commit\nYou could see wat differences here: \nhttps://github.com/MaxGraey/assemblyscript/commit/ce698644412f6d0275923d1b919f1101f9827816#diff-764be5e57c2f6ba87580e44a5b0cc033\nIt show 72 version produce 2 more instructions and increase size on 2 bytes more. Thanks Alon! Hope this will go away after your next improvements . Hi @kripken. Shouldn't this also reserve null, eval and true keywords?. I think make sense use pointer + offset like:\nc++\n// for \"block\"\nswitch (op[1]) {\n    case 'l': if (strcmp(op + 2, \"ock\") == 0) .... Got it! Another suggestion use less nested switch/case approach but more nested if-else + divide & conquer:\nc++\nswitch (op[0]) {\n   case 'b': {\n      int cmp = strcmp(op, \"block\");\n      if (cmp == 0) { makeBlock }\n      if (cmp > 0) {\n         cmp = strcmp(op, \"br\");\n         if (cmp == 0) { makeBreak }\n         if (cmp > 0) {\n            if (strcmp(op, \"br_if\") { ... }\n            ...\n         }\n      }\n      break;\n   }\n   case 'c': {\n     ...\n   }\n}\nso it similar to ternary search tree. wdyt?. It seems this should be BinaryenMemoryInitId. I guess it's total size of 3 pointers called binaryPtr, binaryBytes and sourceMapPtr. ",
    "Hywan": "\ud83c\udf89 . > Additionally I've now taken Hywan/gutenberg-parser-rs as-is and run it through wasm2asm and it works like a charm, so wasm2asm is definitely approaching \"pretty ready\"!\n\u2764\ufe0f . ",
    "uuhan": "@jgravelle-google Thanks!. ",
    "xqyww123": "@kripken, thank you, but could you please tell me more about parameter name, or an example of grow_memory calling. Really thanks.. So, could I regard name as just a comment for developing?. OK I understand you, nameOperand is the name of feature to test by has_feature.\nThanks.. ",
    "Others": "As suspected, entirely my fault, was using the wasm32-unknown-unknown-wasm target instead of the wasm32-unknown-unknown-elf target.. ",
    "nepx": "I see. I was worried that browsers might deoptimize large switch statements (like V8 in the past) but I guess they don't these days. \nA computed goto definiately helps performance as well. On native, the switch-case version ran at just 800,000 blocks per second while the computed goto ran at either 10 or 100 million blocks per second (I forgot which one), although a dynamic recompiler can definitely help there (one block contains more than one x86 instruction and several micro-ops, so performance isn't that dismal). . Well, I did some poking around and it turns out I forgot to turn on optimizations. \nI tested it out and it turns out that the browser version of the switch statement table is actually consistently faster than native (approx 10,500,000 blocks per second on Firefox vs. 10,000,000 on native, wow!). So I guess the browser is doing some neat optimizations under the hood and I shouldn't lose any sleep over this, although a computed goto would be really nice. . @torch2424 Thanks for the interest! Your emulator looks fabulous. \nI'm building an x86 Linux process emulator in C, and am attempting to get a dynamically-linked \"Hello World\" executable to run (glibc refuses to cooperate with me). I originally created this issue because my two main switch loops (decoder, execution engine) have over three hundred cases apiece, and I wanted to experiment with various types of execution modes to see if I could shave off a few cycles. Ultimately, I found out that using a switch loop was the better option (readability and code size), and I found out that most of my overhead came from looking up blocks in the cache. \nThat was a few months ago, and by this point I have added a simple JIT compiler (x86 only, currently, though that might change) to it, so it's not much of an issue anymore. If the CPU is a bottleneck, then I'd advise writing a JIT compiler rather than rewriting your execution loop as all methods or vice versa. Even caching decoded operations can give you a massive performance boost. \nI'm planning on open-sourcing it as soon as I get \"Hello World\" (and a few other simple applications) to work and find a way to prevent the dynamic recompiler/optimizer from crashing. \nI feel like this issue should be low-priority; it seems like a lot of work for little gain. It might be nice just as a proof-of-concept to show how powerful Binaryen is, but aside from that there's really no reason to add this feature when there are so many other things to do...\nGood luck on your emulator! . ",
    "torch2424": "Hello @nepx !\nAs in \"forgot to turn on optimizations\", you mean you forgot the -O3 flag?\nI'm also building an emulator and happened to stumble across this.\nAlso is your emulator open source anywhere? :)\nI don't want to derail the original issue though, so feel free to reach out over email, Twitter, etc.... ",
    "vloppin": "Thanks for the review, I will try to have a look soon.\nI have issues to run tests (diff fail even if there are no visible difference, not yet investigate deeper for now maybe endline characters ... , Windows issues ?). I investigate on testing and the check.py seems to works with the following PR #1605 \nSo It's reveal this bug #1606 \nWith theses commits, all test pass (without my localgraph & effectanalyser modifications) excepts translate-to-fuzz one.\nIt seems to be a parsing problem too. (Moving the reading from File::Binary to File::Text helps a bit but doesn't solve all)\nAs the testing framework seems to works on my computer I will try to look into this PR.\n\nI'm unsure about the EffectAnalyzer change. For small amounts a vector is definitely faster, but in large amounts it might be the opposite - an std::set keeps the data always sorted to all operations are pretty fast. But, we should measure on a bunch of codebases.\n\nDo you have any codebases samples to measure ?\n. I have a look into your suggestions and it's solved the issue. Tests are ok.\nI find another small speedup by replacing LocalGraphInternal::Info::lastSets vector by a unordered_map.\nI am trying to set up figures to evaluate speedup (for each step), but infortunately most of samples don't compile on windows host ... I will try to bench all this under Linux.\nFor now on my test case (asm2wasm -O3 on binaryen.test_sqlite) I have the following results :\n| Test  | Base | Remove seen set | Replace vector -> umap |\n| ------------- | ------------- | ------------- | ------------- |\n| SQLite  | 13.692 s  | 7.844 s | 6.892 s |\nI create a new branch containing only LocalGraph changes on my fork. I will create a new PR once I get figures.. > Hmm, what's the actual issue here - why can we use istringstream for the hex case but not the other, where you changed it to strtoull?\nIndeed we should use the same methods on both.\nMy issue is that istringstream doesn't read properly (or at least doesn't return the same value than other compilers) uint64_t bigger than limits.\nThis parts of the test failed and the first value isn't -1 as excepted.\n```(func $unary-binary-may-trap\n   (drop\n    (i64.div_s\n     (i64.const 70847791997969805621592064)\n     (i64.const 729618461987467893)\n    )\n   )\n. FYI, I just did this simple test :\n```\n// Example program\ninclude \ninclude \ninclude \nint main()\n{\n  std::string str = \"70847791997969805621592064\";\n  {\n      uint32_t v = strtoul(str.c_str(), nullptr, 10);\n      std::istringstream istr(str);\n      uint32_t temp;\n      istr >> temp;\n  std::cout << \"32 -> \" << v << \" \" << temp << std::endl;\n\n}\n  {\n    uint64_t v = strtoull(str.c_str(), nullptr, 10);\n    std::istringstream istr(str);\n    uint64_t temp;\n    istr >> temp;\nstd::cout << \"64 -> \" << v << \" \" << temp << std::endl;\n\n}\n}\n```\nThere is the result :\n - Visual Studio 2015 / 2017\n32 -> 4294967295 3435973836\n64 -> 18446744073709551615 14757395258967641292\n - GCC\n32 -> 4294967295 4294967295\n64 -> 18446744073709551615 18446744073709551615\nVisual Studio doesn't check for overflow when using istringstream ... or maybe there are a mystic flag somewhere to enable ...\nSo I think we should modify i32 too ...\n. Indeed, I will fix all this and create a new PR.\nThanks !. > A test would be good, yeah. Can maybe add one inside tests/unit.wast.\nOk, I will have a look on that.\n\nHowever, should we not just throw a ParseError on such inputs? Or is it valid to read them as -1?\n\nHum ... I don't know. I did this modification to fix the vacuum.wast (passes) on Windows. But indeed, raising an error could be a better alternative ... (I didn't check on the spec if it gives us the right thing to do). From WABT\nuint64_t value = 0;\n  Result result = ParseUint64(s, end, &value);\n  if (has_sign) {\n    // abs(INT64_MIN) == INT64_MAX + 1.\n    if (value > static_cast<uint64_t>(INT64_MAX) + 1) {\n      return Result::Error;\n    }\n    value = UINT64_MAX - value + 1;\n  }\nIt's sound interesting to have the same behaviour between tools, so maybe we should raise an error there.\nIt's imply to modify the vacuum.wast test.. Now I throw ParseException on read error.\nSo I propose to add a test into test/validator/invalid_number.wast instead of tests/unit.wast, Ok ?. I add a simple test for invalid number.\nBut I think we should test other case for hexadecimal and floating number.\nThe main problem are in the parsing. Indeed, when it found an error it stops the parsing.\nFrom my point of view, when I process a wrong text file into a tool, I rather than the tool give me all the errors (and if possible the line) than one by one.. Add another one small optimisation.\n\nCreate a new struct for blocks containing only required information.\nUse counter to avoid invalidation at each loop.\n\n| Test  | Base | Previous | Latest |\n| ------------- | ------------- | ------------- | ------------- |\n| SQLite  | 12.969 s  | 6.935 s | 6.455 s |\n| Prolog | 81.139 s | 28.505 s | 23.675 s |\n| Bullet | 1.458 s | 1.286 s | 1.260 s |\n| Poppler | 11.913 s | 5.973 s | 5.524 s |\n| Lua | 0.976 s | 0.896 s | 0.891 s |. > Btw, have you joined the w3c group yet?\nIn progress. I'm still alive. I'm looking to join W3C group & legal stuff related to my employment contract. Sound good but it's requiring some times ... (Especially during summer holidays). My W3C registration is done ! So there is my last pending modification.. Only one remark about changing size_t to Index on line 101 and 108.\nThere these 'index' are table index and not set/get index, so it can be confusing. (Furthermore this introduce warnings in x64 targets :)). > Interesting, which compiler do you see a warning on?\nSorry .. I misread typedef I read int32_t ... \n\nI guess those could be size_t as they are the size of the container there. However, we do have the assumption that the number of total wasm \"things\" fits in Index, and the number of blocks in those containers is bounded by that.\n\nIndeed. In the main loop foreach numLocals I increment a reference counter.\nThen while I traverse the optimized block struct I compare the traverseIdx to ensure I didn't see this block in this loop.\nSo, yes it size_t traverseIteration; \\\\ last Traversed Iteration should be better.\n. Ok ... wrong habit from old GCC which dislike this .... Ok. There it's still an unordered_map from my previous commit. Indeed before It was a vector containing the lastSets per cells (each cell were an Index => Bad idea when there are a lot of locals).\nIn this commit, changing this container speed up the process.\nWhen I changed the algorithm to introduce the new struct, I noticed that this container wasn't so big (worst case one hundred elements) and profiler told me that searching take some times. So I test using a vector which are appropriate there.\nI keep the unordered_map because it's easy to gather last item for a key using a map :)\nWhen you speak about comments, there or in the source code ?. >it looks like currentBlock only refers to the entry? In that case, perhaps the name could be changed to reflect that (entryFlowBlock perhaps)?\nIndeed. ",
    "BenHenning": "Is there a recommended alternative to s2wasm? I was using this for my own pipeline rather than using emscripten. Is there a new recommended build toolchian for folks who don't or can't depend on emscripten?. ",
    "rrhitman": "Also, in the link, https://github.com/kripken/emscripten/wiki/Linking, it is mentioned that for linking projects with dlopen, \n\nyou must load the side module into the filesystem, so that dlopen (or fopen, etc.) can access it. \n\nHow to do that ?\n. Sorry for the duplicate issues. Will close this down. Thank you for the link.. ",
    "seshness": "Thanks for looking into this, and for the explanations! We'll use the js trap mode for now.\nWill the LLVM wasm backend support, or even need, something like EMULATE_FUNCTION_POINTER_CASTS?\nI might be wildly off base here, but is there a way to isolate the effect of EMULATE_FUNCTION_POINTER_CASTS to, say, the few libraries like Python that require it, without forcing that flag on the linking of the final executable?\nI suspect not from grepping for EMULATE_FUNCTION_POINTER_CASTS, and trying to understand how it works.. ",
    "Kimundi": "Update: I've discovered https://github.com/WebAssembly/binaryen/pull/1513, which was basically about the same issue, but seems to not have exposed the no-atomics option as a commandline flag.. ",
    "lizhengxing": "got it, thanks, Alon!. ",
    "aseemgarg89": "I am using emscripten version 1.38.8\nFor me the source map for the given file decodes to \n[{\"source\":\"hello.c\",\"generatedLine\":1,\"generatedColumn\":1205,\"originalLine\":3,\"originalColumn\":0,\"name\":null},{\"source\":\"hello.c\",\"generatedLine\":1,\"generatedColumn\":1213,\"originalLine\":4,\"originalColumn\":0,\"name\":null},{\"source\":\"hello.c\",\"generatedLine\":1,\"generatedColumn\":1225,\"originalLine\":5,\"originalColumn\":0,\"name\":null}]\nthe objdump (also verified in the wasmcodeexplorer linked above) shows the return at 0x4c5 == 1221.\nThe other 2 seem to be correct (1-based) at 0x4b4 == 1204 and 0x4bc == 1212.\nPS: I am building this on a macbook.\nscreenshot of relevant part of objdump\n\n. Attaching my generated files for reference.\nhello.tar.gz\n. ",
    "HongxuChen": "Seems that the section size issue may also raise a bad_alloc exception.\nwasm-dis.zip.\n```\n./wasm-objdump -d wasm-dis/alloc_01.wasm\nalloc_01.wasm:  file format wasm 0x1\n0000052: error: invalid section code: 507; max is 11\nCode Disassembly:\n$ ./wasm-objdump -d wasm-dis/alloc_02.wasm\nalloc_02.wasm:  file format wasm 0x1\n000002a: error: invalid section code: 16383; max is 11\nCode Disassembly:\n```\n. No problem, we will focus on those that you think crucial.. ",
    "apoleon": "The build will fail if the python interpreter is not installed or on the PATH and build-js.sh is used to build binaryen.js and wasm.js from source. So every occurrence of python should be changed to python3 to make binaryen compatible with Python 3 at least. I haven't tested yet if the rest of the code is compatible with Python 3. Please remember that Python will reach EOL status next year. https://pythonclock.org/. ",
    "ashleygwilliams": "@kripken i am very happy to open a PR- i should be able to do it all just fine- the only thing i'd need help with would be understanding your current release versioning system (i see semver-seeming and \"version_#\" things and don't know how they relate) as well as a github key (though i may be able to reuse whatever the current setup is using)! i can get a WIP PR by tomorrow morning. maybe we can hop on a quick call to discuss the versioning thing? (or just a reply here would also work). i'll get a PR started and we can go from there! . hrm. travis isn't running on this so this isn't gonna get tested. lemme look and see why- if you have any thoughts @kripken ... feel free to chime in!. whoops! sorry for the delay, i forgot that this had a WIP on it. i think it should be ready to go. \n@kripken - i don't expect that this should do anything beyond adding an OSX release.\n. Curious of the status of this! Would love to see it merged- I also repicked up work on #1698 - both of these are blocking on getting wasm-opt support into wasm-pack which we would love to have for the next release (ideally in the next week or so!). ",
    "hugo-dc": "So, is this a problem with the disassembler?, that wast code was generated by wasm-dis.. ",
    "tom-010": "Or this Tutorial.. ",
    "jakogut": "Thanks for such awesome projects!\nHere's the source for that function: https://github.com/videolan/vlc/blob/3.0.0-git/src/modules/bank.c#L610\nI'll test out that fix, and get back to you in a minute.. It builds! Ship it!\nYou're a fucking wizard.. Here you go.\nlibvlc_bitcode.zip\n. I'm unsure if that's a problem for my application yet. I'll likely need plugins for things like codecs and muxers, but those will likely be linked in to the application, and won't necessarily need to be loaded dynamically like VLC traditionally does.. @kripken Actually, it seems now that configuring VLC with --disable-shared causes problems with symbols being multiply defined. Also, the number and size of the plugins means that dynamically loading them is much more practical, so it seems that this will be a requirement for my application.. ",
    "linzj": "\nHi @linzj, can you please use escaping, so that the text is more readable? Use three backticks (`) on a line before and a line after all the code to be escaped.\n\nDone.. No, without -g, the output is exactly what I am expecting.\nI am trying to release a optimized wasm module with debugging info. I have not tried the --profiling flags. I just use the old scheme that c++/c project used to build. Just like cmake's RelWithDebInfo.. Thanks. Maybe I get what I want. But I still can't accept that -g will change the output of the code itself. For a classic elf output, -g will not change its code. The debug information will be add to a specified section.. ",
    "antoan": "Pardon my ignorance, aren't  chrome.* APIs based on javascript? \nhttps://developer.chrome.com/extensions/tabs\nI was hoping to call this from WASM using a tool like Embind.. Thank you very much.. ",
    "ngg": "So it seems like the bug is in the i64-to-i32-lowering pass, where select and if are handled the same way and TempVar highBits is always set in the false branch which becomes the high bit output of the full instruction. This works ok for if because only one of the branches actually execute, but in case of select, both branches execute so the high bits will always come from the false branch.. lgtm, works well for my original testcase from which I created that small reproduction case, thanks!. ",
    "Boscop": "I did the following steps:\n\nwasm2js frontend.wasm -o wasm.jsm\n\n(The frontend.wasm file was generated by cargo web deploy along with a frontend.js file.)\nSince it is in ESM format, which IE doesn't support, I transpiled it with babel to UMD so that it works in IE11:\n\nnode --max-old-space-size=16384 node_modules\\@babel\\cli\\bin\\babel.js --plugins @babel/transform-modules-umd --presets @babel/preset-env wasm.jsm -o wasm.js -s true --module-id meow\n\nInspired by this.\nThen I changed the generated frontend.js file to this:\nInstead of fetching the wasm file, compiling and instantiating it, and then calling its main() function, since I want to load the wasm.js file, I do that in index.html. But here I first assign all the imports to window so that the wasm.js file can access them, and store instance.initialize with window so that I can call it after wasm.js was loaded:\njs\nfor (var i in instance.imports) window[i] = instance.imports[i];\nwindow.__initialize = instance.initialize;\nThe rest of that file stays the same.\nNow in index.html I put <script src=\"wasm.js\"></script> in the <head> and <script src=\"frontend-init.js\"></script> in the <body>. This file contains the following:\njs\nwindow.__initialize({ exports: window.meow });\nWhen I open index.html in the browser, it loads the frontend UI and also executes the code that connects via websocket to my backend etc. BUT then I get this error:\nfrontend.js:428 Uncaught TypeError: Cannot read property 'get' of undefined\n    at Object.Module.STDWEB_PRIVATE.dyncall (frontend.js:428)\n    at WebSocket.output (frontend.js:171)\nModule.STDWEB_PRIVATE.dyncall @ frontend.js:428\noutput @ frontend.js:171\nerror (async)\n(anonymous) @ frontend.js:527\n__extjs_7c5535365a3df6a4cc1f59c4a957bfce1dbfb8ee @ frontend.js:527\n_$LT$frontend__app__Model$u20$as$u20$yew__html__Component$GT$__update__hc3f28c3839ea6127 @ wasm.jsm:118591\n_$LT$yew__html__ComponentEnvelope$LT$COMP$GT$$u20$as$u20$yew__scheduler__Runnable$GT$__run__hc2bdd83f84c2f23f @ wasm.jsm:112824\nyew__scheduler__Scheduler__put_and_try_run__h74799cfeb6bb02bb @ wasm.jsm:29774\nfrontend__main__h4b6651b4f1b2a19d @ wasm.jsm:42438\nstd__rt__lang_start___$u7b$$u7b$closure$u7d$$u7d$__hc2ce99dbb9f784cb @ wasm.jsm:44454\nstd__sys_common__backtrace____rust_begin_short_backtrace__hc3417943071d4ca9 @ wasm.jsm:43623\nstd__rt__lang_start__h60080c07a5a697ad @ wasm.jsm:41592\nmain @ wasm.jsm:154530\ninitialize @ frontend.js:747\n(anonymous) @ frontend-asm.js:1\nfrontend.js:428 Uncaught TypeError: Cannot read property 'get' of undefined\n    at Object.Module.STDWEB_PRIVATE.dyncall (frontend.js:428)\n    at WebSocket.output (frontend.js:171)\nLine 428 of frontend.js is the middle line of these 3:\njs\nModule.STDWEB_PRIVATE.dyncall = function( signature, ptr, args ) {\n    return Module.web_table.get( ptr ).apply( null, args );\n};\n@yurydelendik helped me on IRC with this and he said that apparently wasm2js doesn't support web table..\nWhat would it take to make this work? :)\nBonus question: I'd prefer to init the js module in the same frontend.js file, like it does it with the wasm file originally. How can I adapt the fetch code so that it fetches and evals the wasm.js file, so that I can then call instance.initialize on it and call  its main() function in the same setup js file? So that in my index.html file I only have to include one js file (like in the original wasm case).\n. I cloned your fork and ran cmake, and it generated some .vcxproj files but not for wasm2js, any idea why?\n```\n\ndir\n\n2018-12-01  15:06              .\n2018-12-01  15:06              ..\n2018-12-01  15:06            63,396 ALL_BUILD.vcxproj\n2018-12-01  15:06               288 ALL_BUILD.vcxproj.filters\n2018-12-01  15:06            74,661 asm2wasm.vcxproj\n2018-12-01  15:06               733 asm2wasm.vcxproj.filters\n2018-12-01  15:06            21,647 binaryen.sln\n2018-12-01  15:06            74,262 binaryen.vcxproj\n2018-12-01  15:06               726 binaryen.vcxproj.filters\n2018-12-01  15:06            15,240 CMakeCache.txt\n2018-12-01  15:06              CMakeFiles\n2018-12-01  15:06            12,113 cmake_install.cmake\n2018-12-01  15:06            11,482 INSTALL.vcxproj\n2018-12-01  15:06               530 INSTALL.vcxproj.filters\n2018-12-01  15:06            74,377 s2wasm.vcxproj\n2018-12-01  15:06               867 s2wasm.vcxproj.filters\n2018-12-01  15:06              src\n2018-12-01  15:06            74,223 wasm-as.vcxproj\n2018-12-01  15:06               592 wasm-as.vcxproj.filters\n2018-12-01  15:06            74,241 wasm-dis.vcxproj\n2018-12-01  15:06               593 wasm-dis.vcxproj.filters\n2018-12-01  15:06            74,609 wasm-merge.vcxproj\n2018-12-01  15:06               595 wasm-merge.vcxproj.filters\n2018-12-01  15:06            74,573 wasm-opt.vcxproj\n2018-12-01  15:06               593 wasm-opt.vcxproj.filters\n2018-12-01  15:06            74,698 wasm-shell.vcxproj\n2018-12-01  15:06               736 wasm-shell.vcxproj.filters\n2018-12-01  15:06            46,380 ZERO_CHECK.vcxproj\n2018-12-01  15:06               531 ZERO_CHECK.vcxproj.filters\n              25 File(s)        772,686 bytes\n               4 Dir(s)  171,630,764,032 bytes free\n``\n. When I delete thebuilddir and start again, it still doesn't generate thewasm2js.vcxprojfile that I get when building the upstreamWebAssembly/binaryen`.\nThis is the output from cmake:\nD:\\data\\yurydelendik\\binaryen\\build> cmake ..\n-- Building for: Visual Studio 14 2015\n-- The C compiler identification is MSVC 19.0.24215.1\n-- The CXX compiler identification is MSVC 19.0.24215.1\n-- Check for working C compiler using: Visual Studio 14 2015\n-- Check for working C compiler using: Visual Studio 14 2015 -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Check for working CXX compiler using: Visual Studio 14 2015\n-- Check for working CXX compiler using: Visual Studio 14 2015 -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- No build type selected, default to Release\n-- Building with /wd4146\n-- Building with /wd4267\n-- Building with /wd4244\n-- Building with /WX-\n-- Building with /O2\n-- Building with /D_CRT_SECURE_NO_WARNINGS\n-- Building with /D_SCL_SECURE_NO_WARNINGS\n-- Building with /UNDEBUG\n-- Linking with /STACK:8388608\n-- Configuring done\n-- Generating done\n-- Build files have been written to: D:/data/yurydelendik/binaryen/build\nThis is the side by side comparison of the ALL_BUILD.vcxproj files (upstream on the left):\n\nAny idea why this is happening?. ",
    "awtcode": "Thanks for doing this @kripken :) Really appreciate it. What build flags should I use to ensure that only dynCalls are legalized?\nIn my case, I believe the i64 exported functions are not called from JS as well so is there a way to turn off legalization for these functions? Thanks for your help.. Sorry for the confusion @kripken. I was thinking about i64 functions that we export explicitly e.g. EMSCRIPTEN_KEEPALIVE and -s EXPORTED_FUNCTIONS. Since I won't be calling them from JS but only Wasm, will they still be legalized with LEGALIZE_JS_FFI=0? From what I understand, only dynCalls need to be legalized at this point in time.\nBut I am fine with all explicitly exported functions being legalized at this point in time as the number is not large. Let me know if I need to provide more clarifications.. Thanks for the clarification @kripken.  . @kripken , will you be releasing a new version of emsdk that contains this PR?. ",
    "wizard29": "Hello guys,\nIs there any way to resolve the issue listed above?\nI have recently faced the same problem. I use the 1.38.28 version.\nThank you in advance.. ",
    "crsib": "Just FYI: we are having the same issue and we get the following stack trace\n```\nThread 17 \"asm2wasm\" received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fffebfa0700 (LWP 19588)]\n0x00000000006ddbb0 in wasm::Walker)>::doVisitSwitch(wasm::Visitor, wasm::Expression*) ()\n(gdb) bt\n0  0x00000000006ddbb0 in wasm::Walker)>::doVisitSwitch(wasm::Visitor, wasm::Expression*) ()\n1  0x00000000006e33e9 in wasm::RemoveUnusedBrs::doWalkFunction(wasm::Function*) ()\n2  0x00000000006e4ef0 in wasm::WalkerPass > >::runOnFunction(wasm::PassRunner, wasm::Module, wasm::Function*) ()\n3  0x0000000000572d16 in wasm::PassRunner::runPassOnFunction(wasm::Pass, wasm::Function) ()\n4  0x0000000000572ed4 in std::_Function_handler::_M_invoke(std::_Any_data const&) ()\n5  0x000000000081e8c7 in wasm::Thread::mainLoop(void*) ()\n6  0x00007fffff12d8f0 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n7  0x00007ffffe8976db in start_thread (arg=0x7fffebfa0700) at pthread_create.c:463\n8  0x00007ffffe5b188f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\n```\n/home/dvedenko/emsdk/clang/e1.38.28_64bit/binaryen/bin/asm2wasm glenginew.temp.asm.js --total-memory=67108864 --trap-mode=allow -O3 --mem-init=glenginew.js.mem --mem-base=1024 --wasm-only --symbolmap=glenginew.js.symbols -o glenginew.wasm --mvp-features. Works in -O2 though\nAlso, it works on 1.38.11. If needed - I can provide you with .temp.asm.js and .mem files. > Thanks, those input files would allow me to debug this.\nThe files are here:\nhttps://crsib.s3.eu-central-1.amazonaws.com/monosnap/emscripten_temp.zip\nThank you very much for the help, I will provide you with any additional information needed\n. Wow, that was quick! Thank you @kripken!\nIt's the iqoption.com/traderoom, but I'm afraid it would be inaccessible in the US, as we do not have a US license. . ",
    "nth10sd": "@kripken Doesn't seem to work for me with version 62:\n$ ./js-dbg-64-dm-linux-ad6f51d4af0b w1-out.wrapper w1-out.wasm\nw1-out.wrapper:23:41 CompileError: at offset 40: bad type\nStack:\n  @w1-out.wrapper:23:0\nOn mozilla-central rev ad6f51d4af0b.. Equivalent command on version 52:\ncalling: func_0\n   result: 37\ncalling: hangLimitInitializer\ndone.. Binaryen seed for the above tests:\n```\n\nTargeting SpiderMonkey / Gecko (trunk).\n``. I ran v62 also with-ttf --disable-threads --disable-mutable-globals --disable-nontrapping-float-to-int` and it still caused the compile error.\nHow/where do I find/use wabt? Also, how should I disable SIMD?. I'll need to figure this out in the new year. However, this integration has already found mozilla bug 1516720 (assertion failure with 32-bit SM).. --disable-simd makes version-62-generated files work with SpiderMonkey again. Thanks!. Thanks! Please land and release a new version whenever you get round to it. I guess the project is settling on the 61 numbering and not the 1.38.x format going forward?. ",
    "rickomax": "On asm.js (EMSDK 1.37.33):\nfunction __ZNKSt3__28ios_base6getlocEv($0,$1) {\n $0 = $0|0;\n $1 = $1|0;\n var $2 = 0, label = 0, sp = 0;\n sp = STACKTOP;\n $2 = ((($1)) + 28|0);\n __ZNSt3__26localeC2ERKS0_($0,$2);\n return;\n}\nSeems one parameter is being omitted.\nI cannot find the \"getLoc\" method declaration on the LLVM bitcode (libassimp.bc disasm).\nThe only places referencing it which aren't method calls on the LLVM bitcode I found are:\n!558578 = distinct !DISubprogram(name: \"getloc\", linkageName: \"_ZNKSt3__215basic_streambufIcNS_11char_traitsIcEEE6getlocEv\", scope: !16241, file: !16242, line: 144, type: !558579, isLocal: false, isDefinition: true, scopeLine: 144, flags: DIFlagPrototyped, isOptimized: true, unit: !354313, declaration: !558581, variables: !558582)\n; Function Attrs: optsize\ndeclare %\"class.std::__2::locale::__imp\"* @_ZNKSt3__28ios_base6getlocEv(%\"class.std::__2::ios_base\"*) local_unnamed_addr #8\nOn an older EMSDK version (1.37.3) which is working, the asm.js function is declared as:\nfunction __ZNKSt3__28ios_base6getlocEv(i1) {\n i1 = i1 | 0;\n var i2 = 0, i3 = 0;\n i2 = STACKTOP;\n STACKTOP = STACKTOP + 16 | 0;\n if ((STACKTOP | 0) >= (STACK_MAX | 0)) abortStackOverflow(16);\n i3 = i2;\n __ZNSt3__26localeC2ERKS0_(i3, i1 + 28 | 0);\n STACKTOP = i2;\n return HEAP32[i3 >> 2] | 0;\n}\nSince I'm using the code on Unity, I have to use the bundled EMSDK of the specific Unity version, so I'm afraid I won't be able to fix that if that requires updating EMSDK/Binaryen.. Any way to skip the asm2wasm validation process?. Building on a newer EMSDK version (1.38.11) doesn't give the above errors, but give some errors regarding missing symbols:\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected number of arguments 1 in call to '_ZNKSt3__215basic_streambufIcNS_11char_traitsIcEEE6getlocEv', should be 2\nwarning: unexpected return type %\"class.std::__2::locale::__imp\"* in call to '_ZNKSt3__215basic_streambufIcNS_11char_traitsIcEEE6getlocEv', should be void\nwarning: unexpected number of arguments 1 in call to '_ZNKSt3__215basic_streambufIcNS_11char_traitsIcEEE6getlocEv', should be 2\nwarning: unexpected return type %\"class.std::__2::locale::__imp\"* in call to '_ZNKSt3__215basic_streambufIcNS_11char_traitsIcEEE6getlocEv', should be void\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected number of arguments 1 in call to '_ZNKSt3__28ios_base6getlocEv', should be 2\nwarning: unexpected return type %\"class.std::__2::locale::__imp\"* in call to '_ZNKSt3__28ios_base6getlocEv', should be void\nwarning: unexpected number of arguments 2 in call to '_ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE13get_allocatorEv', should be 1\nwarning: unexpected return type i32 in call to 'aiSetImportPropertyInteger', should be void\nwarning: unexpected return type i32 in call to 'aiSetImportPropertyFloat', should be void\nwarning: unexpected return type i32 in call to 'aiSetImportPropertyString', should be void\nwarning: unexpected return type i32 in call to 'aiSetImportPropertyMatrix', should be void\nwarning: unexpected number of arguments 2 in call to '_ZN6il2cpp6icalls8mscorlib6System6String22RedirectToCreateStringEv', should be 0\nwarning: unexpected number of arguments 4 in call to '_ZN6il2cpp6icalls8mscorlib6System6String22RedirectToCreateStringEv', should be 0\nwarning: unexpected number of arguments 5 in call to '_ZN6il2cpp6icalls8mscorlib6System6String22RedirectToCreateStringEv', should be 0\nwarning: unexpected number of arguments 4 in call to '_ZN6il2cpp6icalls8mscorlib6System6String22RedirectToCreateStringEv', should be 0\nwarning: unexpected number of arguments 2 in call to '_ZN6il2cpp6icalls8mscorlib6System6String22RedirectToCreateStringEv', should be 0\nwarning: unexpected number of arguments 3 in call to '_ZN6il2cpp6icalls8mscorlib6System6String22RedirectToCreateStringEv', should be 0\nwarning: unexpected number of arguments 0 in call to '_ZNSt3__216forward_as_tupleIJEEENS_5tupleIJDpOT_EEES4_', should be 1\nwarning: unexpected number of arguments 0 in call to '_ZNSt3__216forward_as_tupleIJEEENS_5tupleIJDpOT_EEES4_', should be 1\nwarning: unexpected number of arguments 0 in call to '_ZNSt3__216forward_as_tupleIJEEENS_5tupleIJDpOT_EEES4_', should be 1\nwarning: unexpected number of arguments 1 in call to '__cxa_pure_virtual', should be 0\nwarning: unexpected number of arguments 0 in call to '_ZNSt3__216forward_as_tupleIJEEENS_5tupleIJDpOT_EEES4_', should be 1\nerror: unresolved symbol: _ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE2atEj\nerror: unresolved symbol: _ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE4findEcj\nerror: unresolved symbol: _ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE5rfindEcj\nerror: unresolved symbol: _ZNKSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE7compareEjjPKcj\nerror: unresolved symbol: _ZNSt3__212__next_primeEj\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE5eraseEjj\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6appendEPKcj\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6insertEjPKc\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6insertEjPKcj\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE6resizeEjc\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE7replaceEjjPKc\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEE7reserveEj\nerror: unresolved symbol: _ZNSt3__212basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEC1ERKS5_jjRKS4_\nerror: unresolved symbol: _ZNSt3__213basic_istreamIcNS_11char_traitsIcEEE4readEPci\nerror: unresolved symbol: _ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE6setbufEPci\nerror: unresolved symbol: _ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE6xsgetnEPci\nerror: unresolved symbol: _ZNSt3__215basic_streambufIcNS_11char_traitsIcEEE6xsputnEPKci\nerror: unresolved symbol: _Znaj\nerror: unresolved symbol: _Znwj\nerror: unresolved symbol: _ZnwjRKSt9nothrow_t. The newer bitcode file has been compiled with the same EMSDK version as Unity 2019 (EMSDK 1.38.11)\nThe libcxx versions LLVM is linking (libcxx.a and libcxxabi.bc) don't have any of the missing methods indeed:\nDEBUG:root:PYTHON not defined in C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\emscripten.config, using \"C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_Win\\python\\2.7.5.3_64bit\\python.exe\"\nDEBUG:root:EMCC_WASM_BACKEND tells us to use asm.js backend\nwarning:root:invocation: C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten\\emcc.py @C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\..\\Temp\\emcc_arguments.resp  (in C:\\Repos\\trilib\\2019\\New Unity Project\\Temp\\StagingArea\\Data)\nwarning:root:Read response file C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\..\\Temp\\emcc_arguments.resp: ['-O3', '-g2', '-DUNITY_WEBGL=1', '-s', 'PRECISE_F32=2', '-s', 'USE_WEBGL2=1', '-s', 'FULL_ES3=1', '-s', \"EXTRA_EXPORTED_RUNTIME_METHODS=['addRunDependency','removeRunDependency','FS_createPath','FS_createDataFile','ccall','cwrap','stackTrace']\", '-s', 'DISABLE_EXCEPTION_CATCHING=0', '-s', 'TOTAL_MEMORY=32MB', '-s', 'ASSERTIONS=1', '-s', 'DEMANGLE_SUPPORT=1', '-s', 'ERROR_ON_UNDEFINED_SYMBOLS=1', '-s', 'WASM=1', '-s', \"BINARYEN_TRAP_MODE='allow'\", '-s', 'ALLOW_MEMORY_GROWTH=1', '-s', 'MODULARIZE=1', '-s', 'EXPORT_NAME=UnityModule', '--memory-init-file', '1', '--emit-symbol-map', '--output_eol', 'linux', '-o', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Temp\\\\StagingArea\\\\Data\\\\linkresult_wasm\\\\build.js', '--pre-js', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\prejs\\\\CachedXMLHttpRequest.js', '--pre-js', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\prejs\\\\FileSystem.js', '--pre-js', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\prejs\\\\FullScreen.js', '--pre-js', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\prejs\\\\LoaderSetup.js', '--pre-js', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\prejs\\\\MediaDevices.js', '--pre-js', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\prejs\\\\SendMessage.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\Audio.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\Cursor.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\Eval.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\FileSystem.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\Logging.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\Profiler.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\SystemInfo.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\UnetWebSocket.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\Video.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\WebCam.js', '--js-library', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\lib\\\\WebRequest.js', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Assets\\\\TriLib\\\\TriLib\\\\Plugins\\\\WebGL\\\\libz.bc', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Assets\\\\TriLib\\\\TriLib\\\\Plugins\\\\WebGL\\\\libstb_image.bc', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Assets\\\\TriLib\\\\TriLib\\\\Plugins\\\\WebGL\\\\libassimp.bc', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Temp\\\\StagingArea\\\\Data\\\\Native\\\\build.bc']\nDEBUG:root:asm.js opts not forced by user or an option that depends them, and we do not intend to run the asm.js, so disabling and leaving opts to the binaryen optimizer\nDEBUG:root:compiling to bitcode\nDEBUG:root:emcc step \"parse arguments and setup\" took 0.01 seconds\nDEBUG:root:using bitcode file: C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\TriLib\\TriLib\\Plugins\\WebGL\\libz.bc\nDEBUG:root:using bitcode file: C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\TriLib\\TriLib\\Plugins\\WebGL\\libstb_image.bc\nDEBUG:root:using bitcode file: C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\TriLib\\TriLib\\Plugins\\WebGL\\libassimp.bc\nDEBUG:root:using bitcode file: C:\\Repos\\trilib\\2019\\New Unity Project\\Temp\\StagingArea\\Data\\Native\\build.bc\nDEBUG:root:emcc step \"bitcodeize inputs\" took 0.00 seconds\nDEBUG:root:emcc step \"process inputs\" took 0.00 seconds\nDEBUG:root:will generate JavaScript\nDEBUG:root:binaryen root already set to C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\binaryen\nDEBUG:root:forcing stdlibs: set(['libcxxabi'])\nDEBUG:root:PYTHON not defined in C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\emscripten.config, using \"C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_Win\\python\\2.7.5.3_64bit\\python.exe\"\nDEBUG:root:EMCC_WASM_BACKEND tells us to use asm.js backend\nDEBUG:root:PYTHON not defined in C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\emscripten.config, using \"C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_Win\\python\\2.7.5.3_64bit\\python.exe\"\nDEBUG:root:EMCC_WASM_BACKEND tells us to use asm.js backend\nDEBUG:root:PYTHON not defined in C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\emscripten.config, using \"C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_Win\\python\\2.7.5.3_64bit\\python.exe\"\nDEBUG:root:EMCC_WASM_BACKEND tells us to use asm.js backend\nDEBUG:root:PYTHON not defined in C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\emscripten.config, using \"C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_Win\\python\\2.7.5.3_64bit\\python.exe\"\nDEBUG:root:EMCC_WASM_BACKEND tells us to use asm.js backend\nDEBUG:root:including libcxx.a\nDEBUG:root:including libcxxabi.bc\nDEBUG:root:including dlmalloc.bc\nDEBUG:root:including libc.bc\nDEBUG:root:including gl.bc\nDEBUG:root:including wasm-libc.bc\nDEBUG:root:including libc-extras.bc\nDEBUG:root:emcc step \"calculate system libraries\" took 3.73 seconds\nDEBUG:root:linking: ['C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Assets\\\\TriLib\\\\TriLib\\\\Plugins\\\\WebGL\\\\libz.bc', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Assets\\\\TriLib\\\\TriLib\\\\Plugins\\\\WebGL\\\\libstb_image.bc', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Assets\\\\TriLib\\\\TriLib\\\\Plugins\\\\WebGL\\\\libassimp.bc', 'C:\\\\Repos\\\\trilib\\\\2019\\\\New Unity Project\\\\Temp\\\\StagingArea\\\\Data\\\\Native\\\\build.bc', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\dlmalloc.bc', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\libc.bc', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\gl.bc', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\wasm-libc.bc', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\libc-extras.bc', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\libcxx.a', 'C:\\\\Program Files\\\\Unity 2019.1.0a12\\\\Editor\\\\Data\\\\PlaybackEngines\\\\WebGLSupport\\\\BuildTools\\\\Emscripten_FastComp_Win\\\\cache\\\\asmjs\\\\libcxxabi.bc']\nDEBUG:root:adding object C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\TriLib\\TriLib\\Plugins\\WebGL\\libz.bc to link\nDEBUG:root:adding object C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\TriLib\\TriLib\\Plugins\\WebGL\\libstb_image.bc to link\nDEBUG:root:adding object C:\\Repos\\trilib\\2019\\New Unity Project\\Assets\\TriLib\\TriLib\\Plugins\\WebGL\\libassimp.bc to link\nDEBUG:root:adding object C:\\Repos\\trilib\\2019\\New Unity Project\\Temp\\StagingArea\\Data\\Native\\build.bc to link\nDEBUG:root:adding object C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\dlmalloc.bc to link\nDEBUG:root:adding object C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\libc.bc to link\nDEBUG:root:adding object C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\gl.bc to link\nDEBUG:root:adding object C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\wasm-libc.bc to link\nDEBUG:root:adding object C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\libc-extras.bc to link\nDEBUG:root:considering archive C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\libcxx.a\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\algorithm_9e9ed988.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\chrono_c0cc8b00.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\condition_variable_8db83e31.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\ios_087e100a.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\iostream_989a09ed.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\locale_f36e0233.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\memory_226c3f41.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\mutex_cdd4d261.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\new_8b186b3f.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\stdexcept_ca45be18.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\string_a29b194f.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\system_error_41fbcb95.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\thread_f9c2e2ef.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\vector_472937d5.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\exception_02e912fc.cpp.o to link\nDEBUG:root:adding object c:\\users\\ricko\\appdata\\local\\temp\\emscripten_temp_zxkcra_archive_contents\\future_902e36fd.cpp.o to link\nDEBUG:root:done running loop of archive C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\libcxx.a\nDEBUG:root:adding object C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\cache\\asmjs\\libcxxabi.bc to link\nDEBUG:root:emcc step \"link\" took 1.36 seconds\nDEBUG:root:saving intermediate processing steps to C:\\Users\\ricko\\AppData\\Local\\Temp\\emscripten_temp\nDEBUG:root:(not saving intermediate C:\\Users\\ricko\\AppData\\Local\\Temp\\emscripten_temp\\emcc-0-basebc.bc because deferring linking)\nDEBUG:root:emcc: LLVM opts: -strip-debug -disable-debug-info-type-map -internalize -internalize-public-api-list=main,__cxa_demangle,malloc,free,__errno_location,fflush,malloc,malloc,free,malloc,__cxa_can_catch,__cxa_is_pointer_type,malloc,htonl,htons,ntohs,htonl,htons,ntohs,malloc,free,htonl,htons,ntohs,malloc,_get_tzname,_get_daylight,_get_timezone,memalign,htons,_get_environ,free,free,_get_tzname,_get_daylight,_get_timezone,_get_environ,malloc,malloc,free,_get_environ,malloc,htons,malloc,htons,htonl,htons,ntohs,realloc,malloc,strlen,_get_environ -globaldce -disable-loop-vectorization -disable-slp-vectorization -vectorize-loops=false -vectorize-slp=false  [num inputs: 26]\nDEBUG:root:emcc step \"post-link\" took 123.97 seconds\nDEBUG:root:LLVM => JSINFO:root:Executing emscripten.py compiler with cmdline \"C:\\Users\\ricko\\AppData\\Local\\Temp\\tmpuqmqyp\\build.bc -o C:\\Users\\ricko\\AppData\\Local\\Temp\\tmpuqmqyp\\build.bc.o.js --libraries C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\Audio.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\Cursor.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\Eval.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\FileSystem.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\Logging.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\Profiler.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\SystemInfo.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\UnetWebSocket.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\Video.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\WebCam.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\lib\\WebRequest.js,C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten\\src\\library_pthread_stub.js\"\nDEBUG:root:TEMP_DIR not defined in C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\emscripten.config, using C:\\Users\\ricko\\AppData\\Local\\Temp\nDEBUG:root:emscript: llvm backend: C:\\Program Files\\Unity 2019.1.0a12\\Editor\\Data\\PlaybackEngines\\WebGLSupport\\BuildTools\\Emscripten_FastComp_Win\\llc.exe C:\\Users\\ricko\\AppData\\Local\\Temp\\tmpuqmqyp\\build.bc -march=js -filetype=asm -o C:\\Users\\ricko\\AppData\\Local\\Temp\\emscripten_temp\\tmpfkwawx.4.js -emscripten-stack-size=5242880 -O3 -emscripten-precise-f32 -emscripten-assertions=1 -emscripten-global-base=1024 -enable-emscripten-cpp-exceptions -emscripten-no-exit-runtime -emscripten-wasm -emscripten-only-wasm\nNow I wonder how using the same EMSDK version to build the bitcode library and the final WASM build gives these inconsistencies.. Looks like the \"libcxx.a\" contains only 64-bits counterparts of the missing symbols:\n```\noperator new (_Znaj) (missing)\noperator new (_Znam) (on libcxx.a)\nstd::__2::__next_prime(unsigned int) (_ZNSt3__212__next_primeEj) (missing)\nstd::__2::__next_prime(unsigned long) (_ZNSt3__212__next_primeEm) (on libcxx.a)\noperator new(unsigned int) (_Znwj) (missing)\noperator new(unsigned long) (_Znwm) (on libcxx.a)\noperator new(unsigned int, std::nothrow_t const&) (_ZnwjRKSt9nothrow_t) (missing)\noperator new(unsigned long, std::nothrow_t const&) (_ZnwmRKSt9nothrow_t) (on libcxx.a)\n```. Turns out I had the .emscripten file cache pointing to a wrong Clang version. Gonna test the new BC file.. @kripken The issue was caused by the .emscripten cache file indeed, it was pointing to wrong LLVM/Clang versions and generating a broken BC library. Thank you for your support!. ",
    "wcventure": "Please use \"wasm2js $POC\" to reproduce the problem.. Can be broken again.\nPOC.zip\ngit log\n```\ncommit e63c4a7d04c145dafaf4b09de5f9f5de69cee8ef (HEAD -> master, origin/master, origin/HEAD)\nAuthor: Alon Zakai alonzakai@gmail.com\nDate:   Tue Jan 22 17:15:37 2019 -0800\nMore misc ASAN fixes (#1882)\n\n* fix buffer overflow in simple_ast.h printing.\n* check wasm binary format reading of function export indexes for errors.\n* check if s-expr format imports have a non-empty module and base.\n\nFixes #1876\nFixes #1877\nFixes #1879\n\n```\n```\nAddressSanitizer:DEADLYSIGNAL\n=================================================================\n==4544==ERROR: AddressSanitizer: SEGV on unknown address 0x000000000000 (pc 0x000000a81aa3 bp 0x7ffed8a90870 sp 0x7ffed8a90000 T0)\n==4544==The signal is caused by a READ memory access.\n==4544==Hint: address points to the zero page.\n    #0 0xa81aa2 in AddressIsPoisoned /home/hjwang/Documents/CLib/llvm-6.0.1/projects/compiler-rt/lib/asan/asan_mapping.h:343\n    #1 0xa81aa2 in QuickCheckForUnpoisonedRegion /home/hjwang/Documents/CLib/llvm-6.0.1/projects/compiler-rt/lib/asan/asan_interceptors_memintrinsics.h:32\n    #2 0xa81aa2 in __asan_memcpy /home/hjwang/Documents/CLib/llvm-6.0.1/projects/compiler-rt/lib/asan/asan_interceptors_memintrinsics.cc:23\n    #3 0xe09f05 in wasm::WasmBinaryBuilder::getFunctionIndexName(unsigned int) /home/hjwang/Documents/Experiment/binaryen/src/wasm/wasm-binary.cpp:970:10\n    #4 0xdfed24 in wasm::WasmBinaryBuilder::processFunctions() /home/hjwang/Documents/Experiment/binaryen/src/wasm/wasm-binary.cpp:1534:45\n    #5 0xdea7a4 in wasm::WasmBinaryBuilder::read() /home/hjwang/Documents/Experiment/binaryen/src/wasm/wasm-binary.cpp:706:3\n    #6 0xf39472 in wasm::ModuleReader::readBinary(std::__cxx11::basic_string, std::allocator >, wasm::Module&, std::__cxx11::basic_string, std::allocator >) /home/hjwang/Documents/Experiment/binaryen/src/wasm/wasm-io.cpp:52:10\n    #7 0xf3a2f0 in wasm::ModuleReader::read(std::__cxx11::basic_string, std::allocator >, wasm::Module&, std::__cxx11::basic_string, std::allocator >) /home/hjwang/Documents/Experiment/binaryen/src/wasm/wasm-io.cpp:71:5\n    #8 0xac966c in main /home/hjwang/Documents/Experiment/binaryen/src/tools/wasm-opt.cpp:144:14\n    #9 0x7f7b87f69b96 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x21b96)\n    #10 0x9c2fe9 in _start (/home/hjwang/Documents/Experiment/binaryen/build/bin/wasm-opt+0x9c2fe9)\nAddressSanitizer can not provide additional info.\nSUMMARY: AddressSanitizer: SEGV /home/hjwang/Documents/CLib/llvm-6.0.1/projects/compiler-rt/lib/asan/asan_mapping.h:343 in AddressIsPoisoned\n```. Some other different Assertion Fail. Please use \"./wasm2js $POC\" to reproduce the error.\nAF.zip\n1.\nbinaryen/src/passes/I64ToI32Lowering.cpp:1608: wasm::I64ToI32Lowering::TempVar wasm::I64ToI32Lowering::fetchOutParam(wasm::Expression *): Assertion `outParamIt != highBitVars.end()' failed.\n2.\nsrc/wasm-builder.h:263: wasm::Store *wasm::Builder::makeStore(unsigned int, uint32_t, unsigned int, wasm::Expression *, wasm::Expression *, wasm::Type): Assertion `isConcreteType(ret->value->type) ? ret->value->type == type : true' failed.\n3.\nsrc/passes/I64ToI32Lowering.cpp:896: void wasm::I64ToI32Lowering::visitUnary(wasm::Unary *): Assertion `hasOutParam(curr->value) || curr->type == i64 || curr->type == f64' failed.. ",
    "willglynn": "Sorry, I didn't see the CONTRIBUTING.md. I requested a W3C account but am not yet able to join the group; I'll post again when that changes.\nAs for why this is happening, I don't quite know what I'm looking at, but I'll tell you what I do know. Calling main() with ASSERTIONS=2 EMULATE_FUNCTION_POINTER_CASTS=0:\nInvalid function pointer '1685' called with signature 'iii'. Perhaps this is an invalid value (e.g. caused by calling a virtual method on a NULL pointer)? Or calling a function with an incorrect type, which will fail? (it is worth building your source files with -Werror (warnings are errors), as warnings can indicate undefined behavior which can cause this)\nThis pointer might make sense in another type signature: ii: 0  iiii: 0  i: _rb_obj_dummy  iiiii: 0  iiiiii: 0  iiiiiii: 0  iiiiiiii: undefined  iiiiiiiii: undefined  iiiiiiiiii: undefined  iiiiiiiiiii: undefined  iiiiiiiiiiii: undefined  iiiiiiiiiiiii: undefined  iiiiiiiiiiiiii: undefined  iiiiiiiiiiiiiii: undefined  iiiiiiiiiiiiiiii: undefined  iiiiiiiiiiiiiiiii: undefined  viii: 0  vii: 0  vi: 0  viiii: 0  jij: 0  viiiii: 0  v: 0  viiiiii: 0  viiiiiiii: undefined  viiiiiiiii: 0\n$1685 is enumerator_init_copy, which is called correctly from C but is additionally exposed to Ruby. Symbolizing the backtrace, the call did indeed come from the Ruby VM machinery:\nb8395\n_call_cfunc_1\n_vm_call0_cfunc_with_frame\n_vm_call0_cfunc\n_vm_call0_body\n_rb_vm_call0\n_rb_call0\n_rb_call\n_rb_funcall\n_rb_class_inherited\n_rb_define_class\n_InitVM_Object\n_Init_Object\n_rb_call_inits\ndynCall_v\n\u2026\ncall_cfunc_1 looks like it should be calling the function pointer with ii, which\u2026 would be correct and isn't the signature in the complaint? How do I hunt down b8395?. ",
    "msorvig": "Attaching wasm file which reproduces the crash: gui_opengl.wasm.zip\n. Yep, this was on macOS. \nI tried running with \"ulimit -s 65532\" (64MB, the maximum allowed value) now but I still get the crash.. Yes, applying #1905 fixes the issue. Thanks! \n(looks like removing the debug output there was sufficient, for my test case). ",
    "surma": "Personally, I'd expect wasm-opt to overwrite the input file. That being said, all but the last option work for me, so I fully support your PR :). Closes #1907. ",
    "caiiiycuk": "Ahaha, sorry guys only after posting here I realized that actual index is here\n\n(func $7538 (; 7925 ;) (type $0) (param $0 i32) (param $1 i32) (result i32)\n\nProbably I can access it through C++ api. Sorry). ",
    "alstrup": "It is our own compiler for a functional language called flow - not related to the flow from Facebook. I ran the tool in the Windows Subsystem for Linux, so the crash might be related to that. When I run with gdb, I get this stacktrace, which is probably not much help:\nStarting program: /mnt/c/work/binaryen-version_68/wasm-opt -O2 euler7.wasm\nunknown name subsection at 25318\n[New LWP 378]\n[New LWP 379]\n[New LWP 380]\n[New LWP 381]\nThread 5 \"wasm-opt\" received signal SIGABRT, Aborted.\n[Switching to LWP 381]\n0x0000000000766428 in ?? ()\n(gdb) bt\n0  0x0000000000766428 in ?? ()\n1  0x000000000076646a in ?? ()\n2  0x0000000000000000 in ?? ()\nIf it helps, I attach the .wat behind the .wasm file.\neuler7.zip\n. It runs and runs, and then fails at this point:\nexecuting:  bin/wasm-opt split.wast -O\n(no output file specified, not emitting output)\n     (binary format check)\n       bin/wasm-as split.wast -o a.wasm -g\n       bin/wasm-dis a.wasm -o ab.wast\n       bin/wasm-opt ab.wast\n(no output file specified, not emitting output)\nexecuting:  bin/wasm-shell ab.wast\n.. spec/unwind.wast\nexecuting:  /mnt/c/Program Files/nodejs/node.exe -e process.stdout.write(typeof WebAssembly)\nnet.js:145\n    this._handle.open(options.fd);\n                 ^\nError: EINVAL: invalid argument, uv_pipe_open\n    at Error (native)\n    at new Socket (net.js:145:18)\n    at createWritableStdioStream (internal/process/stdio.js:156:16)\n    at process.getStdout [as stdout] (internal/process/stdio.js:10:14)\n    at [eval]:1:8\n    at ContextifyScript.Script.runInThisContext (vm.js:25:33)\n    at Object.exports.runInThisContext (vm.js:77:17)\n    at Object. ([eval]-wrapper:6:22)\n    at Module._compile (module.js:570:32)\n    at bootstrap_node.js:357:29\nTraceback (most recent call last):\n  File \"check.py\", line 635, in \n    sys.exit(main())\n  File \"check.py\", line 611, in main\n    run_binaryen_js_tests()\n  File \"check.py\", line 432, in run_binaryen_js_tests\n    node_has_wasm = NODEJS and node_has_webassembly(NODEJS)\n  File \"/mnt/c/work/binaryen/scripts/test/support.py\", line 173, in node_has_webassembly\n    return run_command(cmd) == 'object'\n  File \"/mnt/c/work/binaryen/scripts/test/support.py\", line 160, in run_command\n    raise Exception(('run_command failed (%s)' % code, out + str(err or '')))\nException: ('run_command failed (1)', ''). The tool worked when I ran it on the original .wat based on master, so I guess we can close this.. ",
    "Warchant": "@kripken yes, I will definitely fix that.. >I'm not convinced we really need to be installing static libraries and binaryen headers other than the one we already install (\"binaryen-c.h\")\nMy colleagues assure me that they need to inherit from ShellExternalInterface from shell-interface.h to execute C++ function from wasm:\nhttps://github.com/soramitsu/polkadot/blob/master/test/deps/binaryen/binaryen_test.cpp#L18\nDo you have any code example, how to mimic that logic with binaryen-c.h?. >I see. Do they also have the requirement that they need to work from a \"packaged\" or \"installed\" version of binaryen, or can they use it directly from a source archive or git checkout?\nWe prefer hunter for dependency management :) \nIt is the same as \nwget https://github.com/WebAssembly/binaryen/archive/1.38.28.tar.gz\ntar -xf 1.38.28.tar.gz\ncd 1.38.28\nmkdir build\ncd build\ncmake .. \nmake install\nSo, I forked binaryen, patched (this PR), and added it to hunter. . @sbc100 any thoughts on the problem I've described above?. Please, re-run failed build https://travis-ci.org/WebAssembly/binaryen/jobs/499303663\n. You can merge once CI succeeds. @kripken just signed in. @sbc100 yes, you can do that. \nI already do this.\nHowever time to analyze the whole codebase is significant even for single set of checks (e.g. modernize-*).\nYou may want to write a script to get modified files from last commit and apply clang-tidy for them.\n. Any updates?. I did this because of warnings in appveyor. \nhttps://ci.appveyor.com/project/WebAssembly/binaryen/builds/22694718\nI fixed this error in next commit.. >List initialization does not allow narrowing\nhttps://stackoverflow.com/a/18222927. Sure. This was necessary to run analyzers. std::function is still an object, and it can be moved. Since std::function can be arbitrarily complex/expensive to copy, it is better to move it.\nhttps://stackoverflow.com/a/13680662/1953079. https://clang.llvm.org/extra/clang-tidy/checks/modernize-pass-by-value.html. When you pass by const ref, you always do a copy of an object.\nWhen you do pass by value, then move, then for rvalue objects you can do double move, which is more preferable (faster) for most types (because when you copy, you need to allocate a memory, when you move - allocations can be avoided) https://stackoverflow.com/a/37443572/1953079. ",
    "Ryooooooga": "I just rebase the branch onto master and did nothing.. ",
    "coldfire913": "thanks for the comment. the indentation is caused by IDE settings required by our company and I have changed to fit the code standards on your side.\nThe response file is the default option for our team here as we have thousands of global ctors in the system...  and we prefer to have another PR for the option work.  . ",
    "NWilson": "I think Clang/LLD currently always emit the stack pointer as a mutable global when producing \"final\" output - but it's not exported since that would be illegal. (An \"object\"/intermediate Wasm file doesn't contain the stack-pointer global.)\nDo you use --relocatable/-r or just --emit-relocs  when you're running LLD? --relocatable makes LLD output a merged \"object file\" rather than the final Wasm output, and --emit-relocs is a sort of halfway house, where it emits a \"final\" Wasm output but with the linking metadata. It's a bit broken (at least on this stack pointer issue) because --emit-relocs on its own will create the stack pointer global, yet without exporting it, so relocations can't really be processed by the next stage :(\nI'm asking because I have an LLD review open at the moment that explicitly breaks --emit-relocs. I'm thinking though that for your purposes, it's probably what you want, and I should instead fix --emit-relocs to export the SP as a mutable global. And finally, wasm-emscripten-finalize would strip the stack-pointer export, making the file legal again for the browser.. Thanks - I've been looking forward to mutable global exports landing in browsers! Then you can get rid of some of your helper functions maybe too, once js can manipulate the stack.. "
}