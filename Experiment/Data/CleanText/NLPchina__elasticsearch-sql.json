{
    "ansjsun": "what your es version ? i used it in 1.3.2 , and make sure it installed ,, in this result . the plugin  not workd\n. 1. see your  plugin dir is empyt? \n   .if empty down  http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/0.1/elasticsearch-sql-0.1.jar to plugin/sql dir\n. hello i am very very very sorry .. i package jar is bad , now i fix it ..\nnow you shoud \n1. remove plug/sql \n2../bin/plugin -u http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/0.1/elasticsearch-sql-0.1.jar --install sql \nyou see the plug/sql like this \ntotal 8\ndrwxr-xr-x  7 ansj  staff  238 Sep 19 12:22 ./\ndrwxr-xr-x  4 ansj  staff  136 Sep 19 12:22 ../\ndrwxr-xr-x  8 ansj  staff  272 Sep 19 12:22 META-INF/\ndrwxr-xr-x  4 ansj  staff  136 Sep 19 12:22 com/\n-rw-r--r--  1 ansj  staff   45 Sep 19 12:22 es-plugin.properties\ndrwxr-xr-x  6 ansj  staff  204 Sep 19 12:22 org/\ndrwxr-xr-x  3 ansj  staff  102 Sep 19 12:22 support/\ngood luck \n. it log lose some config file \nyou try this\n1.down http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/0.1/elasticsearch-sql-0.1.jar \n1. mkdir plugin/sql\n   cp elasticsearch-sql-0.1.jar  plugin/sql\nif now it not work ..\nuse jar xvf elasticsearch-sql-0.1.jar to plugin/sql\nmake sure you dir like this\n[ansj@sunmatoMacBook-Air-4 sql]$ll\ntotal 8\ndrwxr-xr-x  7 ansj  staff  238 Sep 19 12:22 ./\ndrwxr-xr-x  4 ansj  staff  136 Sep 19 12:22 ../\ndrwxr-xr-x  8 ansj  staff  272 Sep 19 12:22 META-INF/\ndrwxr-xr-x  4 ansj  staff  136 Sep 19 12:22 com/\n-rw-r--r--  1 ansj  staff   45 Sep 19 12:22 es-plugin.properties\ndrwxr-xr-x  6 ansj  staff  204 Sep 19 12:22 org/\ndrwxr-xr-x  3 ansj  staff  102 Sep 19 12:22 support/\n. your sql is err i think ..\nchould you give me you sql ?\n. \u6ca1\u6709'\u53f7\u5427' \u8fd8\u6709\u4e0d\u80fd\u8fd9\u4e48select \u6700\u65b0\u7684\n\u5e94\u8be5\nselect * from \u4f60\u7d22\u5f15\u7684\u540d\u79f0 limit 10 ;\n. you try \nselect * from [your index name] limit 10 ;\n. open your chrome or  iE\nvisit \nhttp://192.168.1.213:9200/_sql?sql=select%20*%20from%20contributions%20limit%2010\nwhat you see ?\n. i am sorry ..in my elasticsearch it work ok ! \ni did not know this error !\nand i did not know why action is  \"org.xbib.elasticsearch.action\" \n.   . i am sorry to that \nmy plugin is only coven sql to elasticsearch query ...so you can use /_sql/_explain?sql=...\u3000to get Elasticsearch query .\u3000and use it to query ...\nor in you project add elasticsearch-sql.jar  to query ..you see my example ...\nhttps://github.com/NLPchina/elasticsearch-sql/tree/master/src/test/java/org/nlpcn/es4sql\ngood luck\n. yes \u770b\u4f60id\u50cf\u662f\u4e2d\u56fd\u4eba..\u6211\u6bd4\u8f83\u64c5\u957f\u4e2d\u6587....\u6709\u4e00\u4e2a\u7279\u70b9 select * from bank \u5982\u679c\u4e0d\u52a0limit\u4f1a\u5168\u90e8\u67e5\u51fa\u7684..\u5982\u679c\u8d70\u9ed8\u8ba4\u7684\u65b9\u5f0f..\u6211\u8bb0\u5f97\u662f\u9ed8\u8ba4\u53ea\u67e5\u8be210 or 20 \u6761\n. in 0.2 it not support index name have \".\" in  0.3 http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/0.3/ it fixed .\n. i use sql parse by durid , The SQL standard the table can not have '.'  so ..it throw error . it will be fix in 0.5 version .. thanks \n. it is hard for me  , in feature try to do it \n. \u597d\u7684\u8fd9\u4e2abug\u6211\u8bb0\u4e0b\u4e86\u3002\u3002\u4f60\u53ef\u4ee5\u7528 select count(order_num),sum(order_num) from olap.sales \u8fd9\u4e2a\u65b9\u5f0f\u5e94\u8be5\u4e0d\u62a5\u9519\u7684\n. thanks , it is a big bug ... it will be fix on 0.5  . \n. it think you not define  asc or desc  \ngroup by rci order by rci\norder by rci asc\nso i lose it .. in 0.5 if not define , it default  asc ...\n. \u4e0d\u662f\u6545\u610f\u7684\u989d..\u7c97\u5fc3...\u989d\n. i use it in \nhttps://github.com/NLPchina/elasticsearch-sql/blob/master/src/main/java/org/elasticsearch/plugin/nlpcn/RestSqlAction.java\nit search by es default ...\nso ..how do ? i am not good at this ..can you help me ?\n. in plugin model , it search use \n```\n@Override\nprotected void handleRequest(RestRequest request, RestChannel channel, final Client client) throws Exception {\n\n    String sql = request.param(\"sql\");\n\n    if (sql == null) {\n        sql = request.content().toUtf8();\n    }\n\n    SearchDao searchDao = new SearchDao(client);\n\n    SearchRequestBuilder explan = searchDao.explan(sql);\n\n    if (request.path().endsWith(\"/_explain\")) {\n        BytesRestResponse bytesRestResponse = new BytesRestResponse(RestStatus.OK, explan.toString());\n        channel.sendResponse(bytesRestResponse);\n    } else {\n        SearchRequest searchRequest = explan.request();\n        searchRequest.listenerThreaded(false);\n        client.search(searchRequest, new RestStatusToXContentListener<SearchResponse>(channel));\n    }\n}\n\n```\nso i think it not instead a new client .\nin explan function it not must connect original client .. \n. thanks your suggest\nin this domain could set default row count \nhttps://github.com/NLPchina/elasticsearch-sql/blob/master/src/main/java/org/nlpcn/es4sql/domain/Select.java\nand now . it set default 200!\n. if you use equal it will use  termFilter  if you set 'order by _score ' it use or termQuery\nif you want use match_phrase you could use like this \nSELECT * FROM myindex WHERE message=match_query('hello world')\nif you want other mehtod to query see this example : \nhttps://github.com/NLPchina/elasticsearch-sql/blob/master/src/test/java/org/nlpcn/es4sql/MethodQueryTest.java\n. if you want use distinct , you can use , group my field \nlike this \n\nhttps://github.com/NLPchina/elasticsearch-sql/blob/master/src/test/java/org/nlpcn/es4sql/AggregationTest.java\n\n```\nselect topHits('size'=3,age='desc') from bank  group by gender \n```\ni think if your mapping the  field is  analysis .\nif you want use agg ,  so you field is must not_analysis .\n. what version of your es server ?\nwe only use it on 1.3.2 !\nand please give me your es back log thanks \n. so  i think it  not support . . 1.1.1.\ni am very sorry to that ,it only support 1.3.2 .. :(\n. later version .. i think ...\nwhen we publish 1.4.x  \n1.3.2 version continue to fix bug. but not add new features.\nOn Nov 24, 2014, at 8:35 PM, phani546 notifications@github.com wrote:\n\nokay thank you i will try on elastic search version 1.3.2.\nCould you please tell me when is the next release for this plugin to work with ES 1.3.2 or later versions?\nThanks\nphani\n\u2014\nReply to this email directly or view it on GitHub.\n. i am sorry ,,it not used by 1.4.1,,\n. hello ..i am add it in 1.4.1 can you try it and tell me ..what happend !\n\n```\n./bin/plugin -u http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/1.4.1/elasticsearch-sql-1.4.1.jar --install sql \n```\n. i think you can add explan button ,,it do function  explan ..to result elasticsearch query ...\n```\nSearchRequestBuilder select = searchDao.explan(\"select sum(age),count(*), count(distinct age) from bank  group by gender order by count(distinct age)  desc  limit 3\");\nSystem.out.println(select);\n```\n. i add it but i did not think it can run any browser , it in chrome can be run . \n. it is cool ..but ...e .it not easy ...\nlike this \n```\nselect count(*) from table\n```\nyou are great!!\n. thanks great .. \n. i think you can use it by range like this \nselect count(age) from bank  group by range(age, 20,25,30,35,40)\nand now . i think it is using ...\nwe will add it . thank you \n. 1.3.6 \u5c1d\u8bd5\u4f7f\u75281.3.2\u7684\u7248\u672c\n. \u63d2\u4ef6\u7248\u672c\u3002\u3002\u3002\u662f\u548ces\u7248\u672c\u4e00\u81f4\u3002\n. \u628a\u4f60\u7684sql\u8bed\u53e5\u53d1\u51fa\u6765\u3002\u3002\u3002\u3002\n. \u597d\u50cf\u8868\u540d\u79f0\u4e0d\u80fd\u6709\u51cf\u53f7\u3002 sql\u89e3\u6790\u4f1a\u8ba4\u4e3a\u662f\u8fd0\u7b97\u7b26\n. \u4e0d\u77e5\u9053\u997f\u3002\u3002\u3002\u52a0\u4e2a \nSELECT * FROM \"kibana-init\" limit 10 \u8bd5\u8bd5\n. you are great\n. yes you can ...\n. add explain button ..\n. i think in functions do this is not good idea ... but i think we can add it like script ..example: javascript groovy ..or python script do it ... how to implement it .. \n. the index name can not have '-' i\n. only can search indexes like this  .. select * from index1, index2,index3.... \n. hi @nkastur i use it in to explan query like this \nresult is \n```\n{\n  \"from\" : 0,\n  \"size\" : 200,\n  \"query\" : {\n    \"filtered\" : {\n      \"filter\" : {\n        \"bool\" : {\n          \"must\" : {\n            \"or\" : {\n              \"filters\" : [ {\n                \"query\" : {\n                  \"match\" : {\n                    \"field3\" : {\n                      \"query\" : 5,\n                      \"type\" : \"phrase\"\n                    }\n                  }\n                }\n              }, {\n                \"query\" : {\n                  \"match\" : {\n                    \"field3\" : {\n                      \"query\" : 7,\n                      \"type\" : \"phrase\"\n                    }\n                  }\n                }\n              }, {\n                \"query\" : {\n                  \"match\" : {\n                    \"field3\" : {\n                      \"query\" : 9,\n                      \"type\" : \"phrase\"\n                    }\n                  }\n                }\n              } ]\n            }\n          }\n        }\n      }\n    }\n  },\n  \"_source\" : {\n    \"includes\" : [ \"field1\", \"field2\" ],\n    \"excludes\" : [ ]\n  }\n}\n```\nso you can install \n./bin/plugin -u https://github.com/NLPchina/elasticsearch-sql/releases/download/1.3.1/elasticsearch-sql-1.3.1.zip --install sql\nand visit http://localhost:9200/_plugin/sql/\ntry your sql ...\n. could you help me try some case like \n\"123abc\"\n\"abc def\"\nwhat is you analysis is keyword ? or others ...\ni think is analysis to split it ...\n. \u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2015\u5e743\u670820\u65e5\uff0c02:23\uff0cJake Heimbouch notifications@github.com \u5199\u9053\uff1a\nWhen executing the simple query\nselect * from documents where xComment IS NULL\na QueryParsingException occurs from Elastic. QueryParsingException[[documents] No text specified for text query\nThe query:\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n        \"filtered\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": {\n                        \"not\": {\n                            \"filter\": {\n                                \"query\": {\n                                    \"match\": {\n                                        \"xComment\": {\n                                            \"query\": null,\n                                            \"type\": \"phrase\"\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\nShould really be:\n{\n  \"query\":{\n    \"constant_score\": {\n      \"filter\": {\n        \"missing\": {\n          \"field\": \"xComment\"\n        }\n      }\n    }\n  }\n}\nAlso, the generated query does not make use of the \"missing filter\" or the \"exists filter\" from Elastic.\nhttp://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-missing-filter.html\nhttp://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-exists-filter.html\nHow can I assist in getting this fixed?\n\u2014\nReply to this email directly or view it on GitHub.\n. i think if you used group by .you must use agg function ! like this ... select count(*) from index group by f1,f2 \n. cd es\n\nlike this  pwd\n/home/ansj/soft/elasticsearch-1.6.0\ninput \n./bin/plugin -u https://github.com/NLPchina/elasticsearch-sql/releases/download/1.3.4/elasticsearch-sql-1.3.4.zip --install sql\nand wait it ok !!\nif not you can open  https://github.com/NLPchina/elasticsearch-sql/releases/download/1.3.4/elasticsearch-sql-1.3.4.zip  to down it ..and unzip in plugin dir!\nif you can not down it .check you network ! \n. \u5bf9\u4e8e\u9700\u8981\u805a\u5408\u67e5\u8be2\u7684\u5b57\u6bb5\u6700\u597d\u7528keyword\u65b9\u5f0f\uff0c\u4e5f\u5c31\u662f\u4e0d\u5206\u8bcd\u7684\u65b9\u5f0f\u3002\n. i think you can install this plugin on ES server! so you can visit it by resultful api ,\nso has nothing to do with the language\n. Hi   @yangaoquan \n\u4f60\u597d\u76ee\u524d \u4e0d\u652f\u6301distinct  \u4f46\u662f\u4f60\u53ef\u4ee5\u901a\u8fc7 ,topHits\u6765\u5b9e\u73b0\u7c7b\u4f3c\u7684\u529f\u80fd\nselect topHits('size'=3,age='desc') from bank  group by gender\n. index name must not start with '_'\n. i think you can use it by restful api!\n. i think save to many relationship  in es is not a good idea !\nyou must redundancy ,task all data in one table;\nif you data is net struct i think you need other database or neo4j or ....\n. your javahome is less than 1.7\n\u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2016\u5e743\u670814\u65e5\uff0c17:26\uff0ccjuexuan notifications@github.com \u5199\u9053\uff1a\nwhen I install this plugin ,it report this error\n[root@storage3 elasticsearch-2.2.0]# ./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.2.0/elasticsearch-sql-2.2.0.zip \nException in thread \"main\" java.lang.UnsupportedClassVersionError: org/elasticsearch/plugins/PluginManagerCliParser : Unsupported major.minor version 51.0\n    at java.lang.ClassLoader.defineClass1(Native Method)\n    at java.lang.ClassLoader.defineClassCond(ClassLoader.java:631)\n    at java.lang.ClassLoader.defineClass(ClassLoader.java:615)\n    at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:141)\n    at java.net.URLClassLoader.defineClass(URLClassLoader.java:283)\n    at java.net.URLClassLoader.access$000(URLClassLoader.java:58)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:197)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:190)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:306)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:301)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:247)\nCould not find the main class: org.elasticsearch.plugins.PluginManagerCliParser.  Program will exit.\n\u2014\nReply to this email directly or view it on GitHub.\n. it is here #199\n. i think you want like this , use _all for all field\n    SELECT * FROM elasticsearch-sql_test_index where _all='Ayala' \n. it run in plugin , why not use rest Api  .\n. it is here ! https://github.com/NLPchina/elasticsearch-sql/releases/tag/2.3.1.0\n. in here !  @dadoonet say:\n\nhttps://github.com/elastic/elasticsearch/commit/28f82fb568c3185a8ce10c5f09b4dbd33a8bbe9e\n```\nThe opposite is true. If you try to install a version of a plugin which was built with a newer version of elasticsearch, it will fail the same way:\n```\nbut the api not change , only change  pom.xml es.version . and deploy it ...\n. i think you needthis . https://github.com/NLPchina/elasticsearch-sql/wiki/Join\n. And how could I use GROUP BY with no limit ?\nThank you so much.\nI am looking forward for your help.\nyou can run SELECT COUNT() FROM activities\nWHERE appId LIKE '570f3e5ba61682c71a2b320f'\nAND timestamp BETWEEN '2016-04-20T00:00:00.000+0700' AND '2016-04-21T00:00:00.000+0700'\nGROUP BY deviceId limit 0\nif no set , the default value is 200 ;\n. @ottboy4  '-','*' is the keyword of SQL \nso if you SELECT *Name, -age FROM table  is ambiguity of -age or 100-age.\nwe can did exclude or include function define field like this  SELECT include(*Name), exclude(lastName) FROM table\nbut make sure this is useful.\n. hi @ottboy4  we parse sql use a standard SQL parser,\nand do not want In violation of the rules of SQL\nin +,-,*,/ in sql is calculate operator.\nso support it like this :\nSELECT exclude('name','_ge'),include('b'),exclude('_ddre*'),include('gender') FROM account \n. only add testcase in here \nhttps://github.com/NLPchina/elasticsearch-sql/blob/elastic2.3.2/src/test/java/org/nlpcn/es4sql/SourceFieldTest.java\nWhat did you see my broken English ability, can't complete the document\n. @ottboy4 great thanks\uff01\n. \u652f\u6301\u4e86,\u6709\u95ee\u9898\u544a\u8bc9\u6211\u554a....es\u7684\u7248\u672c\u53f7\u592a\u64cd\u86cb\u4e86,\u6bcf\u4e2a\u5c0f\u7248\u672c\u7f16\u8bd1\u4e00\u6b21.\u7b80\u76f4\u8981\u547d..\n. sorry it explain result is\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n        \"bool\": {\n            \"must\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"match\": {\n                                \"bhv_wb_class2.search_days\": {\n                                    \"query\": 1,\n                                    \"type\": \"phrase\"\n                                }\n                            }\n                        },\n                        {\n                            \"match\": {\n                                \"wb_fdback_ds_test.weekclick\": {\n                                    \"query\": 4,\n                                    \"type\": \"phrase\"\n                                }\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    \"_source\": {\n        \"includes\": [\n            \"uid\"\n        ],\n        \"excludes\": []\n    }\n}\nif not join you need two query did it \n. thx\n. the size in group query is 0,\nbecause you need size in aggregations {....};\nyou see you result .it is ok \nselect ucid, ch_id from online_user_20160516 where _type = 'srh' group by ucid limit 0,2000 \nbut if you group by ucid it only have ucid .not have ch_id .\nit result is  ucid , count(ucid) ; \n. the plugin have been installed\uff01\nyou can visite\nip\uff1aport/_plugin/sql\nif page not found \nRemove Es/plugin/sql directory \nInstall again \n\u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2016\u5e746\u67082\u65e5\uff0c23:32\uff0cShows Le notifications@github.com \u5199\u9053\uff1a\nOS: WINDOWS 10\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. i think you need restart server when installed plugin !\n. http://localhost:9200/_sql/_explain?sql=select * from indexName limit 10\n\nuse it to explain sql to es json query!\n. this plugin only convert SQL queries to ES queries! \nso ES supports SQL to support\n. did you need this ? https://github.com/NLPchina/elasticsearch-sql/wiki/Join\n. if you want agg a field , it must not analyzed! \nyou can set analyzed keyword type !\n. select * from index/type\uff0cindex/type1\n\u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2016\u5e746\u670820\u65e5\uff0c14:59\uff0cCindy Ming notifications@github.com \u5199\u9053\uff1a\nhttp://localhost:9200/_sql?sql=select * from indexName limit 10\nHow Can I select data from type\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. did you need this ? https://github.com/NLPchina/elasticsearch-sql/wiki/Join\n. i think not support  , in sql it need tow query to do this !\n. date_range \u4e0d\u9700\u8981\u6392\u5e8f...\u6362\u53e5\u8bdd\u8bf4\u6ca1\u6709\u6392\u5e8f\u529f\u80fd...\u662f\u6309\u7167\u4f60 date_range(field='time','now-1h','now','now-1M','now') \u8f93\u5165\u7684\u987a\u5e8f\u6392\u5e8f\u7684\n. @eliranmoyal I think it's a good idea.\nallegedly in October , ES5.0 released , in that version we did  ?\n. thk\n. look at  #29,\n\ni think you need restart your es server \n. select * from INDEX_NAME/TYPE1,INDEX_NAME/TYPE2  where ....\n. to\u3002count\uff08*\uff09 \n\u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2016\u5e748\u670825\u65e5\uff0c21:37\uff0csatapsa notifications@github.com \u5199\u9053\uff1a\nThis doesnot work\nselect count(t.*) as counts,sum(t.size) from xxx/locs t\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. hi @wanglifengwf  i am not sure it support distinct\n\ni am sure it support count(distinct(userId)) ;\nyou can try it \nSELECT userId FROM logstash-api-access-2016.08.17 where ip = '112.65.191.239' group by userId\n. @allwefantasy \nor this  \nselect topHits('size'=1)  FROM logstash-api-access-2016.08.17 where ip = '112.65.191.239'  group by userId\n. it return es result ... \ni think the ui skip empty result .\nso .you need skip it in your javacode .\n. \u6211\u5fc3\u601d\u4e86\u4e0b\u3002\u6211\u7684\u82f1\u6587\u4f30\u8ba1\u4f60\u90fd\u4e0d\u61c2\u3002\u610f\u601d\u5c31\u662f\u6709\u4e2a\u7c7b\u6d4b\u8bd5\u8fd4\u56de\u7684\u6570\u7ec4\u4e0d\u5bf9\u3002\n\u8fd8\u6709 maven \u91cc\u9762\u7684 profiles \u914d\u7f6e\u3002ci\u4e0d\u8ba4\uff0c\u52a0\u4e0a -Plocal \u4e5f\u4e0d\u884c\u3002\u6211\u53c8\u6539\u56de\u6765\u4e86\u3002\u8d77\u7801\u4e0d\u662f\u4e00\u76f4fail\u4e86\u3002\u8fd8\u662f\u4e2d\u6587\u597d\u8bf4\u8bdd\u54c8\u54c8\n. oka\n. where foundTime>\"2016-09-19\"  AND foundTime<\"2016-12-12\"\n. @allwefantasy . ok i will did it ... i have commit maven center , later you will see it in mvnrespository . @dangxunb  http://mvnrepository.com/artifact/org.nlpcn/elasticsearch-sql . \u597d\u50cf\u662f\u4e0d\u80fd.\u6211\u4ee5\u524d\u75281.x\u7684\u65f6\u5019\u5c31\u8fd9\u5fb7\u884c..\u73b0\u5728\u4e0d\u592a\u5173\u5fc3\u65f6\u533a\u5c31\u6ca1\u6ce8\u610f\u8fc7..\u4f60\u67e5\u67e5es\u6587\u6863,\u5982\u679c\u6ca1\u6709\u4f60\u53ea\u80fd\u8bbe\u7f6etime_zone\u4e86. @allwefantasy . @shi-yuan  can you try it ?. aha you a great !\nin #241 \nWe discussed about the Filter and Query, not use the order by the score ,\nbut in sql , only havewhere keyword .\nso ,could we add two keyword filter,'query' in sql , defaultwhere equals filter \nexample\nselect * from aaa where c=1 filter a=1 query b= 1\nwe need to define a rule ,  I can try to write the SQL parse\n. I think you are right , we need correct  sql standard . \n@allwefantasy What do you think ?\n. some one suggest like this \nselect * from bla where a=1 and (b=2 or c=2)  or /*query*/ d = 3\nI feel the query function is good way ..\nsimple to implement\n. hi @eliranmoyal  I think we not need query , in sql we only support filter , Or in accordance with the current strategy. \nwe need add a param in method example : QueryAction create(Client client, String sql ,QueryBuilder query) . aha\u3002in here you will learn chinese\n\u53d1\u81ea\u6211\u7684 iPhone\n\n\u5728 2016\u5e7412\u670814\u65e5\uff0c13:55\uff0cEliran Moyal notifications@github.com \u5199\u9053\uff1a\nAre you using it with java or by rest api?\ndelete still not works #339\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. what  is your es version ?\n\ntry explain button to  find the query dsl .\nlet me see \n. soruce is  column?\nyour source column need set analyzer 'keyword'.\n. \nselect address from bank where address= matchPhrase('671 Bristol Street')  order by _score desc limit 3\n. es-sql-site-standalone not working #364  . you can clone  this project \nhttps://github.com/NLPchina/elasticsearch-site\nand run ....\nvisite http://localhost:8080/web/sql/ to use it .\nnot need install plugin in es , support all 5.x. In the past period of time , we have more workds at relase new version , but not add new feature in plugin.\nwe are tired for es version .\nAt least third of the current es development plugin is not very friendly .\nSo we added a es-site to deal with,  this is just an experiment . \n. you can clone  this project \nhttps://github.com/NLPchina/elasticsearch-site\nand run ....\nvisite http://localhost:8080/web/sql/ to use it .\nnot need install plugin in es , support all 5.x. make sure .you es version is 5.x , and you checkout master branch !\nWhat does your background log show\n. setting elasticsearch ip and port open 'elasticsearch-site/jcoder_home/resource/ioc.js'\nmake suer ip and port can visit  . port default transport 9300,  \nsuggest , install it on your es machine\n. I am so sorry ,  currently not supported 'xpack.security.user' config, i will add it now .. i commit it , you can take a pull ..\n````\nprivate void init(boolean securityOpen, String security, String... clusterNodes) {\n        try {\n        Builder builder = Settings.builder().put(\"client.transport.sniff\", true);\n\n        if (securityOpen) {\n            builder.put(\"xpack.security.user\", security);\n        }\n\n        Settings settings = builder.put(\"client.transport.ignore_cluster_name\", true).build();\n\n````\nchange your config like this \n````\nvar ioc = {\n    esClient: {\n        type: \"org.nlpcn.elasticsearch.site.ESClient\",\n       args: [true, 'name:passowrd',\"127.0.0.1:9300\"],\n        events: {\n            depose: 'destroy'\n        }\n    }\n};\n````. yes you can . you can in elasticsearch-site dir\ngit checkout .\ngit pull\nopen config to setting !\n. I fix it ,  you can clone or pull ,\nyou can try it \ngit checkout .\ngit pull\nand restart , \nopen  http://localhost:8080/  username:admin password:admin\nclick Ioc Manager \n\nvisit http://localhost:8080/web/sql/\n\ngoodluck for you \n. \u7528\u6237\u540d\u5bc6\u7801\u9700\u8981\u6539ioc\u914d\u7f6e\u3002\u3002\u5c31\u662f\u518d\u540e\u53f0\u6539\u3002\u3002\u4e0d\u80fd\u518durl\u4e2d\u4f20\u5165. \u662f\u7684. i think it is a bug . your es version 5.x pull master\n                          2.x pull 2.x branch\nyou jdk must 1.8\n. \u4f60\u53ef\u4ee5\u4e0b\u8f7d\u4e0b\u6765\u4e2azip\u7136\u540e\u628a\u91cc\u9762\u7684... plugin-descriptor.properties \u91cc\u9762\u7684es\u7248\u672c\u6539\u6210\u4f60\u7684\u7248\u672c..\n\u7136\u540e\u653e\u5230es\u7684plugin\u76ee\u5f55\u4e0b,\u4e0d\u51fa\u610f\u5916\u5c31\u53ef\u4ee5\u8fd0\u884c\u4e86. distinct \u4e0d\u51c6. \u91c7\u7528  HyperLogLog++   \u662f\u4e00\u79cd\u4f30\u503c\u5f97\u65b9\u5f0f.\n\u5177\u4f53\u8bf4\u660e\u770b\u8fd9\u91cc\u5427\nhttps://www.elastic.co/guide/en/elasticsearch/guide/2.x/cardinality.html. like this \nSELECT * FROM myindex group by a limit 100\nes query is \n{\n    \"from\": 0,\n    \"size\": 0,\n    \"aggregations\": {\n        \"a\": {\n            \"terms\": {\n                \"field\": \"a\",\n                \"size\": 100\n            }\n        }\n    }\n}. @dick318 \u5192\u53f7\u662f\u4e0d\u662f\u9700\u8981\u8f6c\u8bd1\u4e00\u4e0b...\u4f60\u8bd5\u8bd5 \"80\\:\". default ...... default is 200 ,,because it big data ,if you not has any set  so we add default size is 200. . \u4ee3\u7801\u91cc\u9762\u5199\u7684\u5462...\u5e94\u8be5\u662fsql\u89e3\u6790\u4ee3\u7801..\u4f60\u8bd5\u8bd5\u641c\u7d22\u4e0blimit\u5e94\u8be5\u80fd\u627e\u5230.... @furiousbanana @hungrytortoise  may be  try it https://github.com/NLPchina/elasticsearch-sql/wiki/Scroll . @zhaolihe \u9080\u8bf7\u4f60\u8fdbgroup \u9ebb\u70e6\u70b9\u540c\u610f\u54e6. \u628acar_no\u7684\u5206\u8bcd\u65b9\u5f0f\u6539\u6210keyword. \u662f\u4e0d\u662fes\u6ca1\u914d\u7f6e\u8de8\u57df\u652f\u6301\u3002\u3002\n\u5f00\u542f\u8de8\u57df\u8bbf\u95ee\u652f\u6301\uff0c\u9ed8\u8ba4\u4e3afalse\nhttp.cors.enabled: true  \n\u8de8\u57df\u8bbf\u95ee\u5141\u8bb8\u7684\u57df\u540d\u5730\u5740\uff0c(\u5141\u8bb8\u6240\u6709\u57df\u540d)\u4ee5\u4e0a\u4f7f\u7528\u6b63\u5219\nhttp.cors.allow-origin: /.*/ . \u5df2\u53d1\u5e03.\u53ef\u80fd\u7d22\u5f15\u9700\u8981\u4e24\u5929\u624d\u80fd\u770b\u5230.. \u5efa\u8bae\u628a wiki \u529f\u80fd\u4e5f\u52a0\u4e0a\u3002\u8fd9\u6837\u66f4\u591a\u7684\u4eba\u80fd\u4f7f\u7528\u65b0\u529f\u80fd. good job. ",
    "nl19856": "I am using 1.3.2.\n. Put it there:\nls -l /usr/share/elasticsearch/plugins/sql/\ntotal 52\n-rw-r--r--. 1 root root 45009 Sep 16 12:48 elasticsearch-sql-0.1.jar\ndrwxr-xr-x. 3 root root  4096 Sep 18 12:29 META-INF\ndrwxr-xr-x. 3 root root  4096 Sep 18 12:29 org\nMakes nodifference.\n. No luck :-(\n[root~]# /usr/share/elasticsearch/bin/plugin -r sql\n-> Removing sql...\nRemoved sql\n[root~]# /usr/share/elasticsearch/bin/plugin -DproxyHost=localhost -DproxyPort=18081 -u http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/0.1/elasticsearch-sql-0.1.jar --install sql\n-> Installing sql...\nTrying http://maven.nlpcn.org/org/nlpcn/elasticsearch-sql/0.1/elasticsearch-sql-0.1.jar...\nDownloading ...........DONE\n[root@nlvora213 ~]# ls -l /usr/share/elasticsearch/plugins/sql\ntotal 8\ndrwxr-xr-x. 3 root root 4096 Sep 19 11:09 META-INF\ndrwxr-xr-x. 3 root root 4096 Sep 19 11:09 org\n[root@nlvora213 ~]# find /usr/share/elasticsearch/plugins/sql\n/usr/share/elasticsearch/plugins/sql\n/usr/share/elasticsearch/plugins/sql/META-INF\n/usr/share/elasticsearch/plugins/sql/META-INF/maven\n/usr/share/elasticsearch/plugins/sql/META-INF/maven/org.nlpcn\n/usr/share/elasticsearch/plugins/sql/META-INF/maven/org.nlpcn/elasticsearch-sql\n/usr/share/elasticsearch/plugins/sql/META-INF/maven/org.nlpcn/elasticsearch-sql/pom.properties\n/usr/share/elasticsearch/plugins/sql/META-INF/maven/org.nlpcn/elasticsearch-sql/pom.xml\n/usr/share/elasticsearch/plugins/sql/META-INF/MANIFEST.MF\n/usr/share/elasticsearch/plugins/sql/org\n/usr/share/elasticsearch/plugins/sql/org/nlpcn\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/exception\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/exception/SqlParseException.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Where$CONN.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Paramer.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Condition.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Where.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/KVValue.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Field.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/SearchResult.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Order.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Condition$OPEAR.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/MethodField.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Index.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/domain/Select.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/Util.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/SearchDao.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/AggregationQuery.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/DefaultQuery.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/Query.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/maker\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/maker/Maker$1.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/maker/Maker.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/maker/FilterMaker.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/maker/QueryMaker.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/query/maker/AggMaker.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/parse\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/parse/SqlParser.class\n/usr/share/elasticsearch/plugins/sql/org/nlpcn/es4sql/parse/FieldMaker.class\n. That was what I just was doing :-)\nIt is at least not saying that no handler is found for _sql ..\nNow I get : {\n    \"error\": \"ClassCastException[com.alibaba.druid.sql.ast.expr.SQLCharExpr cannot be cast to com.alibaba.druid.sql.ast.expr.SQLQueryExpr]\",\n    \"status\": 500\n}\n. http://161.89.52.214:9200/_sql?sql='select * from * limit 10'\n. This returns 10 documents:\n curl -XGET 'http://192.168.1.213:9200/contributions/_search?pretty'\nThis:\n curl -XGET 'http://192.168.1.213:9200/_sql/_explain?sql=\"select * from contributions limit 10\"'\nThis seems to be like an error connecting to http://161.89.52.213:9200/_sql?sql='select * from contributions limit 10'. The response status was 0.\nCheck out the W3C XMLHttpRequest Level 2 spec for more details about when this happens.\nI just  noticed that the elasticsearch logfile show a java stack dump:\n2014-09-22 18:53:43,115][WARN ][http.netty               ] [Stanley] Caught exception while handling client http traffic, closing connection [id: 0x26f51725, /192.168.1.213:31493 :> /192.168.1.213:9200]\njava.lang.IllegalArgumentException: invalid version format: (X86_64-UNKNOWN-LINUX-GNU) LIBCURL/7.19.7 NSS/3.13.1.0 ZLIB/1.2.3 LIBIDN/1.18 LIBSSH2/1.2.2\n        at org.elasticsearch.common.netty.handler.codec.http.HttpVersion.(HttpVersion.java:102)\n        at org.elasticsearch.common.netty.handler.codec.http.HttpVersion.valueOf(HttpVersion.java:62)\n        at org.elasticsearch.common.netty.handler.codec.http.HttpRequestDecoder.createMessage(HttpRequestDecoder.java:75)\n        at org.elasticsearch.common.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:189)\n        at org.elasticsearch.common.netty.handler.codec.http.HttpMessageDecoder.decode(HttpMessageDecoder.java:101)\n        at org.elasticsearch.common.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:500)\n        at org.elasticsearch.common.netty.handler.codec.replay.ReplayingDecoder.cleanup(ReplayingDecoder.java:554)\n        at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.channelDisconnected(FrameDecoder.java:365)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:102)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:74)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.elasticsearch.common.netty.channel.Channels.fireChannelDisconnected(Channels.java:396)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.close(AbstractNioWorker.java:360)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioServerSocketPipelineSink.handleAcceptedSocket(NioServerSocketPipelineSink.java:81)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioServerSocketPipelineSink.eventSunk(NioServerSocketPipelineSink.java:36)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendDownstream(DefaultChannelPipeline.java:779)\n        at org.elasticsearch.common.netty.handler.codec.oneone.OneToOneEncoder.handleDownstream(OneToOneEncoder.java:54)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:591)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendDownstream(DefaultChannelPipeline.java:582)\n        at org.elasticsearch.common.netty.channel.Channels.close(Channels.java:812)\n        at org.elasticsearch.common.netty.channel.AbstractChannel.close(AbstractChannel.java:197)\n        at org.elasticsearch.http.netty.NettyHttpServerTransport.exceptionCaught(NettyHttpServerTransport.java:310)\n        at org.elasticsearch.http.netty.HttpRequestHandler.exceptionCaught(HttpRequestHandler.java:50)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.exceptionCaught(SimpleChannelUpstreamHandler.java:153)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.exceptionCaught(FrameDecoder.java:377)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:112)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:74)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.elasticsearch.common.netty.channel.Channels.fireExceptionCaught(Channels.java:525)\n        at org.elasticsearch.common.netty.channel.AbstractChannelSink.exceptionCaught(AbstractChannelSink.java:48)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.notifyHandlerException(DefaultChannelPipeline.java:658)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:566)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:74)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n        at java.lang.Thread.run(Thread.java:722)\n. {\n    \"error\": \"CreationException[Guice creation errors:\\n\\n1) No implementation for org.elasticsearch.cluster.ClusterService was bound.\\n  while locating org.elasticsearch.cluster.ClusterService\\n    for parameter 1 at org.xbib.elasticsearch.action.river.jdbc.state.RiverStateService.(Unknown Source)\\n  at unknown\\n\\n1 error]\",\n    \"status\": 500\n}\n. It seems to conflict with the  river-csv plugin\n. I removed plugins : jdbc lang-python repository-hdfs \nNow it is working\nSo somehow your plugin interferes with the others or the other way around.\n. ",
    "daledude": "0.3 still has an issue.\ncurl -G \"http://localhost:9200/_sql?pretty\" --data-urlencode \"sql=SELECT count(*) FROM data-2014.10.12\"\n{\n  \"error\" : \"ParserException[illegal sql expr : SELECT count(*) FROM data-2014.10.12]\",\n  \"status\" : 500\n}\nI tried with quotes:\ncurl -G \"http://localhost:9200/_sql?pretty\" --data-urlencode \"sql=SELECT count(*) FROM 'data-2014.10.12'\"\n{\n  \"error\" : \"IndexMissingException[['data-2014] missing]\",\n  \"status\" : 404\n}\n. If someone codes one of the functions I'd like to contribute more by looking at how it was done. I haven't been able to find a thorough resource on scripting so I haven't been able to really wrap my head around it. I admit I haven't looked very hard.\n. I'll check it out after vacation. Thank you!\n. Version 1.4.1 still same issue. You can check by doing a simple query below. Make sure there are no spaces at the end of the lines.\nselect\ncount(*)\nfrom\nsomeindex\n1.4.1 no longer likes my query because the index name is formatted like data-2015.08.22. If I create an alias like data20150822 the query works.\n. This is very cool! Will this be able to be used with functions such as SUM(), AVG(), etc?\n. @allwefantasy very cool! Seems to be a small issue. The result of the below SQL:\nSELECT \nsum(case when myfield = 'value' then 1 else 0 end) as Summed\nFROM data20160811\nResults in this JSON:\n{\n    \"from\": 0,\n    \"size\": 0,\n    \"_source\": {\n        \"includes\": [\n            \"SUM\"\n        ],\n        \"excludes\": []\n    },\n    \"aggregations\": {\n        \"Summed\": {\n            \"sum\": {\n                \"field\": \"if( (doc['myfield'].value=='value')){1} else {0}\"\n            }\n        }\n    }\n}\nThe \"field\" should be \"script\", no?\n. I'm using Elasticsearch 2.4.1, btw.\n. Works. Thanks!\n. ",
    "triStone": "More details:\n5 of them are [eventpool], 10 of them are pipe\n. ",
    "phani546": "I am using 1.1.1 version.\nwhen i access the query i am getting following exception.\nLogs :\njava.lang.AbstractMethodError: org.elasticsearch.plugin.nlpcn.RestSqlAction.handleRequest(Lorg/elasticsearch/rest/RestRequest;Lorg/elasticsearch/rest/RestChannel;)V\n        at org.elasticsearch.rest.RestController.executeHandler(RestController.java:159)\n        at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:142)\n        at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:121)\n        at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:83)\n        at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:291)\n        at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:43)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n        at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)\n        at org.elasticsearch.common.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)\n        at org.elasticsearch.common.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:74)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n[2014-11-24 17:53:06,001][WARN ][http.netty               ] [node2] Caught exception while handling client http traffic, closing connection [id: 0xda9350c4, /0:0:0:0:0:0:\n0:1:55571 => /0:0:0:0:0:0:0:1:9201]\njava.lang.AbstractMethodError: org.elasticsearch.plugin.nlpcn.RestSqlAction.handleRequest(Lorg/elasticsearch/rest/RestRequest;Lorg/elasticsearch/rest/RestChannel;)V\n        at org.elasticsearch.rest.RestController.executeHandler(RestController.java:159)\n        at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:142)\n        at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:121)\n        at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:83)\n        at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:291)\n        at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:43)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n        at org.elasticsearch.common.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)\n        at org.elasticsearch.common.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)\n        at org.elasticsearch.common.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)\n        at org.elasticsearch.common.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n        at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:74)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n        at org.elasticsearch.common.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n        at org.elasticsearch.common.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:318)\n        at org.elasticsearch.common.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n        at org.elasticsearch.common.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n        at org.elasticsearch.common.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n        at org.elasticsearch.common.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n        at java.lang.Thread.run(Thread.java:745)\n[2014-11-24 17:53:06,017][WARN ][http.netty               ] [node2] Caught exception while handling client http traffic, closing connection [id: 0x1c37d21d, /0:0:0:0:0:0:\n0:1:55572 => /0:0:0:0:0:0:0:1:9201]\nThanks\nphani\n. okay thank you i will try on elastic search version 1.3.2.\nCould you please tell me when is the next release for this plugin to work with ES 1.3.2 or later versions?\nThanks\nphani\n. okay thank you.\n. ",
    "omershelef": "I added aggregations support to the site,\neven multiple group by supported (buckets inside buckets)\n. I added loading button feature.\n. I would like to set up Travis CI Platform for this repository. to make it, I will need to configure web hook through the settings page. can I have admin access on this repoistory, to get permission for the settings page?\n. As far as I know, there is no current plan for JDBC driver.\n. What is the query you were trying to make?\n. Elasticsearch-sql use MySQL dialect. square brackets is invalid in MySQL. if your index name is \"myindex\" just drop the brackets:\nSELECT * FROM myindex\nif your index name is \"[myindex]\".  use backticks:\nSELECT * FROM `[myindex]`\n. What version of elasticsearch-sql are you using?\n. I am trying to reproduce your problem. I installed elasticsearch 1.4.2 and elasticsearch-sql 1.2.\nbut it seems to working fine on my computer.\naccording to the error it seems that elasticsearch trying to query on index named \"_sql\" instead of the \"test_1\"...\nAre you trying to query using the web frontend or the rest api? if you are using rest, what is the exact url you used?\nwhat operating system are you using?\nwhat java version?\nEDIT:\nI managed to reproduce the problem. using POST request when elasticsearch-sql not installed will cause this error. I assume you query through the web frontend, so maybe The plugin was not installed correctly.\nopen the elasticsearch folder, plugins/sql. it should contains elasticsearch-sql-1.2.jar and _site folder.\nmaybe the jar is missing?\nif the answer is yes, try to remove this folder, and reinstall.\n. Happy to help. Do you have any idea why this jar was missing? you installed the plugin in a different way?\n. Yes you can use the _explain end point. for example:\nhttp://localhost:9200/_sql/_explain?sql=SELECT * FROM myindex WHERE age > 20  GROUP BY gender\nwill return this:\n{\n  \"size\" : 0,\n  \"query\" : {\n    \"filtered\" : {\n      \"filter\" : {\n        \"bool\" : {\n          \"must\" : {\n            \"range\" : {\n              \"age\" : {\n                \"from\" : 20,\n                \"to\" : null,\n                \"include_lower\" : false,\n                \"include_upper\" : true\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  \"aggregations\" : {\n    \"gender\" : {\n      \"terms\" : {\n        \"field\" : \"gender\",\n        \"size\" : 200\n      }\n    }\n  }\n}\nThere is not explain button currently in the website, but we will implement it in the future. \nThe explain endpoint is currently broken on the master branch, but I will fix it before creating new release. As long as you will download the latest release 1.2 you will be ok.\n. It may be possible to implement it, but it will be hard to make it work on every case. \nFor fields in default query (not aggregation) you can use scripted field.  Sorting by function also possible using scripting. \nAggregations is a pretty complex case, there is experimental feature in elasticsearch 1.4 which we can rely on, scripted metric. It provides kind of map reduce support so although its name implies, it may be suitable to creating buckets as well.\n. It looks like a bug, i will fix it on next release\n. After a quick look at the code, It may be better if you just wrap your index name with backticks.\nSELECT * FROM `logs-2015.01.13`\n. It might be very hard to satisfy such requirment, elasticsearch itself does not support join queries like relational databases does. The best it can do is add limited support for document joining on parent child relations or use client side join when the number of documents is relatively small.\nYou have any thoughts on how to implement such thing?\n. Thank you. :+1: \n. what version of elasticsearch-sql are you using?\nthis bug was already fixed.\n. Make sure you installed elasticsearch-sql correctly\n. In sql LIKE the charcter _ represenets one character of any type this equivalant to the ? In elasticsearch wildcard query\n. Thank you from the contribution. please fix the host back to \"localhost\" instead of \"10.1.1.44\" in MainTestSuite\n. The tests when running in java 8 are still failing, if you have time, it will be nice to fix it.\nyou can see the details here: https://travis-ci.org/NLPchina/elasticsearch-sql/builds/55103049\n. This bug have been fixed. your query should work now. Sorry for the long waiting.\n. Thank you!\n. Thanks for your contribution!\n. This query should work... have you tried running it and got an error?\nwe actually have test which pass that running this query:\nSELECT insert_time FROM %s/online WHERE insert_time BETWEEN '2014-08-18' AND '2014-08-21' LIMIT 3\n. I opened a feature issue #62.\n. What about using one \"count distinct\" per column. for example:\nSELECT COUNT(DISTINCT column1), COUNT(DISTINCT column2) FROM myindex\n. Currently there is no way to use this plugin as a local library easily.\nFor now you can use this as a library by creating TransportClient, pass it to SearchDao constructor and call\nexplain method. You can look at the tests code to see example of how to do it. The SearchDao created in MainTestSuite and you can look at how to use it in QueryTest.\nThe tests run in the travis CI locally without Elasticsearch-sql plugin installed, so this should work.\nMaybe a more easy local API will be developed.\nAnd just from curiosity, why you prefer not to install the plugin? \n. The code is in query.js\nThe results is parsed in two different ways, DefaultQueryResultHandler parsed standard queries. and AggregationQueryResultHandler is parsing aggregations result and will be used when the query contains 'GROUP BY' clause.\nGood luck!\n. Subqueries is not supported in elasticsearch-sql.\n. That query actually should work.\nCan you give a concrete example of this query and why you think the results is wrong?\n. Yes, the release was'nt published successfully. try again now.\n. By the way, the orig_hex100 AS mykey still return orig_hex100 as the column name instead of mykey. the AS keyword is supported only for functions (aggregations have name in elasticsearch) for now. that is because oridinary field name change is not supported by elasticsearch query. (but can be achieved by transform the results from the query by the plugin.)\n. I believe this addition is unnecessary. The plugin should use SQL syntax to achieve aggregations. you can get the same result using 'GROUP BY' which will translated into aggregations.\n. You can make this query using SQL syntax but not by one query. only one aggregation is possible per query, As for subaggregations, it is possible. for example, gender WITHIN state:\nSELECT firstname ,lastname,gender,state FROM myindex group by state,gender\nIf you feel you must make this through one query. I think it's for the best to implement this feature in more SQL friendly syntax, for your query example:\nSELECT firstname ,lastname,gender,state FROM myindex group by (gender), (state, gender)\nusing brackets we can make multiple aggregations and still support subaggregations. \nSorry for your trouble. but the current form of the feature is not related to the sql plugin, Please consider to implement the above proposal\n. This code cannot be merged in the current form. this kind of code is hard to maintain and understand.\nAggregations code belong to AggregationQueryAction class. also you cannot just use regex in the middle of nothing, you need to change the structure of Select class and change the sql parsing to support this feature.\nI cannot merge shortcuts, although it tempting.\n. @ottboy4 please look at my comment above for my code review.\nabout the implementation. I think AGG function is unnecessary. look at the forth comment for my opinion on the implementation details.\n. I agree, for now see issue #58. It possible to use elasticsearch-sql without installiing it. \n. Is it possible that the standard analyzer tokenize chinese by characte? If this is the case, you must group by field which is not analyzed. The group by works by terms aggregation. \n. Currently there is no better way then to call directly the REST api. if you want use elasticsearch-sql as a library instead of elasticsearch plugin, see issue #58\n. Great contribution! thank you!\n. Nice!\n. Great contribution! you have a small merge conflict on the AggregationTest. fix it with another commit and I will merge this\n. Thanks, I will make a new release now\n. Wildcard is already supported please make us know if you having any problems \n. \u05d9\u05d0 \u05e9\u05e4\u05d9\u05e5!\n. Thanks for the bugfix!\n. If you are not Ordering by score, the plugin use filters.\n. Please fix it back to localhost\n. Please remove --no-check-certicicate. The tests not pass this way\n. ",
    "bigbo": "@ansjsun  \u8bf7\u95ee,\u4ee5\u540e\u8fd9\u4e2a\u63d2\u4ef6\u6709\u66f4\u65b0\u561b?\u80fd\u652f\u6301\u5230\u6700\u65b0\u7684ES\u7248\u672c\u4e0d?\n. @ansjsun ,\u6211\u5c1d\u8bd5\u4e86\u75281.3.2\u7248\u672c\u7684\u63d2\u4ef6,\u7ed3\u679c\u8fd8\u662f\u62a5\u9519\u554a:\n Error: {\"error\":\"NoClassDefFoundError[org/durid/sql/ast/statement/SQLSelectQuery]; nested: ClassNotFoundException[org.durid.sql.ast.statement.SQLSelectQuery]; \",\"status\":500}\n\u80fd\u6307\u70b9\u4e0b\u4ec0\u4e48\u539f\u56e0\u561b?\n. SELECT * FROM kibana-init limit 10 ;\n. \u90a3\u8868\u540d\u6709-\u53f7\u7684\u8bdd\u8fd9\u79cd\u60c5\u51b5\u600e\u4e48\u5199sql\u8bed\u53e5?\n. ",
    "dpj2010": "Elasticsearch 2.3.1\n./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.3.1.0/elasticsearch-sql-2.3.1.0.zip \nAfter doing this, you need to restart the Elasticsearch server. Otherwise you may get errors like Invalid index name [sql], must not start with '']; \",\"status\":400}.\n\u9700\u8981\u91cd\u542f\n. Elasticsearch 2.3.1\n./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.3.1.0/elasticsearch-sql-2.3.1.0.zip \nAfter doing this, you need to restart the Elasticsearch server. Otherwise you may get errors like Invalid index name [sql], must not start with '']; \",\"status\":400}.\n. Elasticsearch 2.3.1\n./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.3.1.0/elasticsearch-sql-2.3.1.0.zip \nAfter doing this, you need to restart the Elasticsearch server. Otherwise you may get errors like Invalid index name [sql], must not start with '']; \",\"status\":400}.\n. ",
    "otisg": "+1 for adding JDBC support to ES .... though not sure if JDBC4ES functionality should live under this project or be a separate project?\nhttps://github.com/apache/incubator-calcite seems like a good tool to use for this... \n. +1 for this one.\n. ",
    "sigma420": "+1\nOn 17 Jan 2015 4:41 am, \"Omer Shelef\" notifications@github.com wrote:\n\nReopened #28 https://github.com/NLPchina/elasticsearch-sql/issues/28.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/28#event-220397117.\n. \n",
    "aniketbhatnagar": "+1\n. ",
    "muthu1086": "+1\n. Hi Any pointers in this\n. ",
    "blue20080": "+1\n. Yes,I agreen with @perlun ,I had the sam issue too.\n. ",
    "cploonker": "+1\n. ",
    "jaynblue": "+1\n. ",
    "ebuildy": "com.alibaba.druid has JDBC built in, I believe, is is possible to use it?\n. ",
    "skanda83": "+1 for jdbc support\n. ",
    "ChrisFeldmeier": "+1\n. ",
    "MobileAppVault": "+1\n. +1\n. ",
    "enzogro": "+1\n. +1\n. thank you!!\n. ",
    "allwefantasy": "@otisg  I have tried calcite to add this feature to es-sql.  It's proved to be unsuitable. calcite kind like spark datasource API which provide scanTable,filterTabe,translateTable which means you cannot access original sql(Raw SQL) but some expressions .  Also,  this means join ,group by action are all done in calcite which really impact performance . \n. @ebuildy  com.alibaba.druid has JDBC built in, I believe, is is possible to use it?\nThis is good, Have already support JDBC by rewriting some druid classes, check url bellow: \nhttps://github.com/allwefantasy/elasticsearch-sql/tree/jdbc-support\nInstall Step\n\ndownload project\npackage  jar\nadd jar to your project\n\nExample Code\n```\npublic class JDBCTests {\n    @Test\n    public void testJDBC() throws Exception {\n        Properties properties = new Properties();\n        properties.put(\"url\", \"jdbc:elasticsearch://127.0.0.1:9300/twitter2\");\n        DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n        dds.setInitialSize(1);\n        Connection connection = dds.getConnection();\n        PreparedStatement ps = connection.prepareStatement(\"SELECT split(trim(concat_ws('dd',newtype,num_d)),'dd')[0] as nt from  twitter2\");\n        ResultSet resultSet = ps.executeQuery();\n        while (resultSet.next()) {\n            System.out.println(resultSet.getString(\"nt\"));\n        }\n    ps.close();\n    connection.close();\n    dds.close();\n}\n\n}\n```\n. You should start a elasticsearch instance  before running JDBCTests . Do not forget modify the code: \n/Chagne 127.0.0.1 to your elasticsearch host.\nproperties.put(\"url\", \"jdbc:elasticsearch://127.0.0.1:9300/\" + TestsConstants.TEST_INDEX);\n. We think this is all about ES  not ES-SQL. \n. You are wrong to use SQL.  When  using group by , you can only select fields in group by or use some aggregation function eg. SUM,MAX on specific field.\n. This bug may  have been fixed  in master branch . It happened cause cluster_name in es-sql  is not consistent with the es instance.\n. You can modify MainTestSuit's setup function . Add lines like following:\njava\nSettings settings = Settings.builder().put(\"client.transport.ignore_cluster_name\",true).build();\n        client = TransportClient.builder().addPlugin(DeleteByQueryPlugin.class).settings(settings).\n                build().addTransportAddress(getTransportAddress());\nIf it do not fix your problem, please reopen this issue. \n. @eliranmoyal  This feature have already merged to master?\n. select * FROM myindex where1 = 1 is more sql style and SELECT * FROM myindex where script('1 == 1') make newbies confuse . So if es-sql support  this future would be more convenience.   New pr to fix this issue will be created later. \n. @vganjare is right.  So this is not issue and es-sql no need to support since the query url already have this done. \n. Since  _source is disabled ,you can only  access the value of fields  which are  in aggregation functions eg.  group by ,sum \n. @srijiths  @eliranmoyal  can we just close this issue? \n. @flyingandrunning The query you mentioned is wrong cause table is keyword . you can try \nselect count(t.*) as counts ,sum(t.size) from your_table_name t\ninstead of\nselect count(t.*) as counts ,sum(t.size) from table t\nyou can also try run your query  in http://www.nlpcn.org:9999/web/ which provides a convenient way to explain your sql.\n. Yes ,this is a bug .  query like select count(*) as counts,sum(t.size) from xxx/locs t group by t.field do not handle table alias.  We will fix later . \n. @satapsa  @eliranmoyal @ansjsun  New pull request  ( https://github.com/NLPchina/elasticsearch-sql/pull/271  ) have already fix this bug.\n. @eliranmoyal  @ansjsun   group by and distinct  sometimes may  have the same effect  . If  distinct used and group by block not found in sql ,we can just automatically add it for user . \nSELECT distinct(userId) FROM logstash-api-access-2016.08.17 where ip = '112.65.191.239'\nwill be translate to :\nSELECT userId FROM logstash-api-access-2016.08.17 where ip = '112.65.191.239' group by userId\n. @shi-yuan  Ok \n.  version 2.3.5. But my pr is merged to master.\n. \u55ef csv\u597d\u50cf\u8fd4\u56de\u7684\u7ed3\u679c\u503c\u987a\u5e8f\u4f1a\u53d1\u751f\u53d8\u5316  \u8fd9\u4e2a\u5bb9\u6613\u4fee\u6b63  \u6211\u660e\u5929\u4fee\u6b63\u4e0b\u3002\u55ef  \u90a3\u4ee5ci\u80fdpass\u4e3a\u51c6\n. Why you wanna close the connection between this plugin and elasticsearch?\n. It's not supported yet for now. However you can use script grammar below:\nSELECT * FROM myindex where script('doc[\"columnA\"].value == doc[\"columnB\"].value') and script('doc[\"columnC\"].value == doc[\"columnD\"].value')\nKind tricky, we will create a PR to make it looks more sql style.\n. check this PR:  https://github.com/NLPchina/elasticsearch-sql/pull/278\n. Check this class:\norg.nlpcn.es4sql.jdbc.ObjectResultsExtractor\nHow to use\n```\nprivate ObjectResult getObjectResult(boolean flat, String query, boolean includeScore, boolean includeType) throws SqlParseException, SQLFeatureNotSupportedException, Exception, CsvExtractorException {\n        SearchDao searchDao = new org.nlpcn.es4sql.SearchDao(client);\n    //String rewriteSQL = searchDao.explain(getSql()).explain().explain();\n\n    QueryAction queryAction = searchDao.explain(query);\n    Object execution = QueryActionElasticExecutor.executeAnyAction(searchDao.getClient(), queryAction);\n    return new ObjectResultsExtractor(includeScore, includeType).extractResults(execution, flat, \",\");\n}\n\nObjectResult extractor = getObjectResult(true, getSql(), false, false);\nList headers = extractor.getHeaders();\nList> lines = extractor.getLines();\n``\n. You can create Map by combining headers and lines. Headers are keys, Lines are batch of values. \n. Ok, I will  make PR  for this later. \n. Not supported yet.... and it looks difficult to implement this with aggregation functions.\n. @daledudecase whenis now able to be used with functions such as SUM(),AVG(),etc.  check this PR: https://github.com/NLPchina/elasticsearch-sql/pull/300\n. Thefieldshould be 'script'\u3002 Already fixed:  https://github.com/NLPchina/elasticsearch-sql/pull/303\n. The error happened causecom.alibaba.druid.sql.parser.Lexerthought 'number' + 'e'  was decimalValue.  Can you just make a alias name for the index which you query?\n. Update: note that this is a bug in druid library which is open source project for jdbc datasource. Maybe we can check the latest version to make sure whether the issue has been fixed.\n. elasticsearch dependency in pom.xml is declaredprovided`,so you should add elasticsearch dependency in your project \n. Good job \n. @will0815  Have you modified the JDBC URL eg.\nproperties.put(\"url\", \"jdbc:elasticsearch://139.196.218.206:9300,139.196.218.205:9300/\" + TestsConstants.TEST_INDEX);. @RaniRaven  com.mysql.jdbc.Driver would be ok. @stopit  can you try index1/type2 instead of index1.type2?. Caching result query in memory may crash user's application ,or may even crash ES.  Also this behavior can cause some confusion in people who lack of basic search engine concept.\n. Shard hint will help but it is not intuitive for  the users  who is not familiar to ES. Also peoples may forget providing shard hint when using SQL like that.\n. Can we just add some lines in org.nlpcn.es4sql.query.AggregationQueryAction.explain\n@ such as:\n`` java\nif (lastAgg != null && lastAgg instanceof TermsBuilder && !(field instanceof MethodField)) {\n                   // here we  set shard size to 2000 since the defaultsize` value \n                   // which is  200 is ok for most situation.\n                  //   However we know nothing about the number of  shards, \n                  // so we just give  a default value 10\n                  if(select.getRowCount()<200){\n                        ((TermsBuilder) lastAgg).shardSize(200*10)\n                    }\n                    ((TermsBuilder) lastAgg).size(select.getRowCount());\n                }\n```\n. Can you provide us the exception stack message ?\n. The SQL you provide can be translated to es query successfully:\nleft query:\n{\n  \"from\" : 0,\n  \"size\" : 1,\n  \"_source\" : {\n    \"includes\" : [ \"idcardNo\" ],\n    \"excludes\" : [ ]\n  }\n}\n right query:\n{\n  \"from\" : 0,\n  \"size\" : 1,\n  \"_source\" : {\n    \"includes\" : [ \"idcardNo\" ],\n    \"excludes\" : [ ]\n  }\n}\nDo I miss something?\n. \u6211\u5728master\u5206\u652f\u662f\u53ef\u4ee5\u7684\u3002\n. select *  from traffic_statistics_v4_m200106  where date_format(foundTime,'yyyy-MM-dd')>'2016-09-19' AND date_format(foundTime,'yyyy-MM-dd')<'2016-12-12'\nWell, field foundTime should be date  in elasticsearch mapping. here is the translation of the sql:\n{\n  \"from\" : 0,\n  \"size\" : 200,\n  \"query\" : {\n    \"bool\" : {\n      \"filter\" : {\n        \"bool\" : {\n          \"must\" : {\n            \"bool\" : {\n              \"must\" : [ {\n                \"script\" : {\n                  \"script\" : {\n                    \"inline\" : \"def date_format_328401213 = new Date(doc['foundTime'].value - 8*1000*60*60).format('yyyy-MM-dd') ;date_format_328401213 > '2016-09-19'\"\n                  }\n                }\n              }, {\n                \"script\" : {\n                  \"script\" : {\n                    \"inline\" : \"def date_format_1962265930 = new Date(doc['foundTime'].value - 8*1000*60*60).format('yyyy-MM-dd') ;date_format_1962265930 < '2016-12-12'\"\n                  }\n                }\n              } ]\n            }\n          }\n        }\n      }\n    }\n  }\n}\n. So,when should we close the connection?  I guess PooledConnection just return the connection to pool, and physical connection will really close the connection. \n. @In master branch, \"select idcardNo a FROM user limit 1\" will be translated to \njson\n{\n  \"from\" : 0,\n  \"size\" : 1,\n  \"_source\" : {\n    \"includes\" : [ ],\n    \"excludes\" : [ ]\n  },\n  \"script_fields\" : {\n    \"a\" : {\n      \"script\" : {\n        \"inline\" : \"doc['idcardNo'].value\"\n      }\n    }\n  }\n}\nIt's a pity that es do not support this query and return all result. It only work when you have some specific operations eg. groupby.\nYou can try this:\nselect ak a FROM user group by a limit 1\n. Notice that count(distinct) uses hyperloglog++ algorithm to compute the result.  This means the result is approximate, not acurrate. \n. Make sure  groovy script is enabled in your es cluster. @oreak We are waiting more people to upgrade es 5.0 . . @woderia  groovy is required to support functions eg. split,log, +,-,*,/  which are not  supported originally by ES. If  wanna sql supports join,subquery,  you may try es-hadoop project which\nprovide spark-sql support\nOn Tue, Nov 29, 2016 at 10:51 PM, Lars notifications@github.com wrote:\n\nOkay, thats look really nice\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/333#issuecomment-263590503,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAwsPkXwv0EAFfZo_1CGq4xSHEu-5h7xks5rDDv0gaJpZM4K93uX\n.\n\n\n-- \nBest Regards\n\n\u5f00\u9614\u89c6\u91ce      \u4e13\u6ce8\u5f00\u53d1\nWilliamZhu   \u795d\u6d77\u6797      zhuhl@csdn.net\n\u4ea7\u54c1\u4e8b\u4e1a\u90e8-\u57fa\u7840\u5e73\u53f0-\u641c\u7d22&\u6570\u636e\u6316\u6398\n\u624b\u673a\uff1a18601315052\nMSN\uff1azhuhailin123@hotmail.com\n\u5fae\u535a\uff1a@PrinceCharmingJ  http://weibo.com/PrinceCharmingJ\n\u5730\u5740\uff1a\u5317\u4eac\u5e02\u671d\u9633\u533a\u5e7f\u987a\u5317\u5927\u885733\u53f7\u96621\u53f7\u697c\u798f\u7801\u5927\u53a6B\u5ea712\u5c42\n\nhttp://www.csdn.net                              You're the One\n\u5168\u7403\u6700\u5927\u4e2d\u6587IT\u6280\u672f\u793e\u533a                               \u4e00\u5207\u7531\u4f60\u5f00\u59cb\nhttp://www.iteye.net\n\u7a0b\u5e8f\u5458\u6df1\u5ea6\u4ea4\u6d41\u793e\u533a\n. Really awesome. Why close this PR?. @eliranmoyal  May we try to work with this project elastic-grok-script-plugin  in order to support  regular expression which enhance the power of schema-on-read ? . Adding new keywords would be  better.  eg.\nselect * from bla where \nquery  by  a=1  and (b=2 or c=2)\nfilter by  d = 3. ",
    "jekey": "I run the JDBCTests, got error:\njava.sql.SQLException: Error\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)\nat com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\nat com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\nat com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:62)\nat org.nlpcn.es4sql.JDBCTests.testJDBC(JDBCTests.java:26)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:497)\nat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\nat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\nat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\nat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\nat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\nat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\nat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\nat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\nat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\nat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\nat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\nat org.junit.runner.JUnitCore.run(JUnitCore.java:160)\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:117)\nat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:234)\nat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:74)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:497)\nat com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\nCaused by: NoNodeAvailableException[None of the configured nodes are available: [{#transport#-1}{113.12.15.234}{113.12.15.234:9200}]]\n    at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:290)\n    at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:207)\n    at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:55)\n    at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:288)\n    at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:86)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:56)\n    at org.elasticsearch.action.ActionRequestBuilder.get(ActionRequestBuilder.java:64)\n    at org.nlpcn.es4sql.query.SqlElasticSearchRequestBuilder.get(SqlElasticSearchRequestBuilder.java:43)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeSearchAction(QueryActionElasticExecutor.java:23)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeAnyAction(QueryActionElasticExecutor.java:44)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.getObjectResult(ElasticSearchDruidPooledPreparedStatement.java:74)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:47)\n    ... 27 more\n. ",
    "ashclegit": "Hi..I downloaded the project (latest version) and packaged it in eclipse. and then I have a test project in which I am adding the package as an external jar. and have created a test code -\nimport com.alibaba.druid.pool.DruidDataSource;\nimport com.alibaba.druid.pool.ElasticSearchDruidDataSourceFactory;\nimport java.sql.*;\n//import java.util.ArrayList;\n//import java.util.List;\nimport java.util.Properties;\nimport org.nlpcn.es4sql.TestsConstants;\npublic class JDBCtests {\n    public static void main(String args[]) throws Exception {\n         try{\n             Properties properties = new Properties();\n             properties.put(\"url\", \"jdbc:elasticsearch://localhost:9300/\" + TestsConstants.TEST_INDEX);\n            // properties.put(\"url\", \"jdbc:elasticsearch://localhost:9300/twitter2\");\n             DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n             Connection connection = dds.getConnection();\n             PreparedStatement ps = connection.prepareStatement(\"SELECT  gender,lastname,age from  \" + TestsConstants.TEST_INDEX + \" where lastname='Heath'\");\n             //PreparedStatement ps = connection.prepareStatement(\"SELECT split(trim(concat_ws('dd',newtype,num_d)),'dd')[0] as nt from  twitter2\");\n             ResultSet resultSet = ps.executeQuery();\n             //List result = new ArrayList();\n             while (resultSet.next()) {\n                   System.out.println(resultSet.getString(\"lastname\") + \",\" + resultSet.getInt(\"age\") + \",\" + resultSet.getString(\"gender\"));\n             }\n             ps.close();\n             connection.close();\n             dds.close();\n         }\n         catch(SQLException e)\n         {\n             System.out.println(e.getErrorCode());\n             System.out.println(e.getMessage());\n             System.out.println(e.getSQLState());\n             e.printStackTrace();\n         }\n    /*Properties properties = new Properties();\n    properties.put(\"url\", \"jdbc:elasticsearch://localhost:9300/\" + TestsConstants.TEST_INDEX);\n    DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n    Connection connection = dds.getConnection();\n    PreparedStatement ps = connection.prepareStatement(\"SELECT  gender,lastname,age from  \" + TestsConstants.TEST_INDEX + \" where lastname='Heath'\");\n    ResultSet resultSet = ps.executeQuery();\n    //List<String> result = new ArrayList<String>();\n    while (resultSet.next()) {\n          System.out.println(resultSet.getString(\"lastname\") + \",\" + resultSet.getInt(\"age\") + \",\" + resultSet.getString(\"gender\"));\n    }\n    ps.close();\n    connection.close();\n    dds.close();*/\n\n}\n\n}\nI run the program and its throwing an exception showing -\nERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.\njava.sql.SQLException: Error\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)0\nat com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\nat com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\nat com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:61)\nat constructors.JDBCtests.main(JDBCtests.java:24)\n\nCaused by: [elasticsearch-sql_test_index] IndexNotFoundException[no such index]\n    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.infe(IndexNameExpressionResolver.java:676)\n    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.innerResolve(IndexNameExpressionResolver.java:630)\n    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:578)\n    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:168)\n    at org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:140)\n(full trace not copied).\ncould you please help and why use port 9300 when we have 9200.\n. ",
    "arnono1": "setInitialSize max is 8 ?. ",
    "kaliseo": "Simple match_all query\nLe Wed Jan 07 2015 at 19:03:52, Omer Shelef notifications@github.com a\n\u00e9crit :\n\nWhat is the query you were trying to make?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/29#issuecomment-69063303\n.\n. \"SELECT * FROM [myindex] LIMIT 100;\"\n\nLe Thu Jan 08 2015 at 21:55:38, Thierry LEFORESTIER kali.seo@gmail.com a\n\u00e9crit :\n\nSimple match_all query\nLe Wed Jan 07 2015 at 19:03:52, Omer Shelef notifications@github.com a\n\u00e9crit :\nWhat is the query you were trying to make?\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/29#issuecomment-69063303\n.\n. I didn't set bracket, it was just to give the index example ^^. Sorry\n\n\nLe Fri Jan 16 2015 at 10:54:59, Ville-Matti Riihikoski \nnotifications@github.com a \u00e9crit :\n\n1.2\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/29#issuecomment-70231257\n.\n. \n",
    "vixriihi": "Quoting doesn't seem to help (ES version 1.4.2)\nMy query is:\nSELECT * FROM `test_1`\nand the result is always the same (with and without quotes):\n{\"error\":\"InvalidIndexNameException[[_sql] Invalid index name [_sql], must not start with '_']\",\"status\":400}\n. 1.2\n. Yes. I was using web frontend and the jar was missing. Re-installed and now everything is working as expected. Thank you for a great plugin\n. Unfortunetly I don't. I used the one liner from the frontpage to install.\n. ",
    "VictorCano": "Hi, i'm also experiencing this error, although in my sql plugin folder the .jar file exists.\n/usr/share/elasticsearch/plugins/sql# ls\n_site  elasticsearch-sql-1.3.jar\nI'm using ElasticSearch 1.4.2 and the 1.3 version of the plugin. Do you have any idea how I could get to fix this? Thanks!!\n. ",
    "TarasB": "Hi, \nThe same problem. File elasticsearch-sql-1.3.1.jar exists.\nError message:\n Error: {\"error\":\"InvalidIndexNameException[[sql] Invalid index name [_sql], must not start with '']\",\"status\":400}\nI tried ElasticSearch 1.4.4 and 1.5.0 - result is the same.\nAdditional info:\nOS - Centos 6.5\nJava - Java(TM) SE Runtime Environment (build 1.7.0_60-b19)\nThank you,\nTaras\n. I just found that issue #42 describes the same problem. I am closing this issue.\nThank you,\nTaras\n. ",
    "Prazzy": "Thanks for the details.\n. +1\n. ",
    "eliranmoyal": "some implementation of this features now enabled on 1.4.5 using scripts.\nlook on scripted_fields  and scripted_metric on aggregations page\n. Hey, some questions before i'll try to implement this:\n1. on \"desc indexName\"\nwhat if the index contains more than one type?\n2. on \"desc [indexName]/[mapping]\" do you mean indexName/type? cause if not i don't understand the difference between this and \"show [indexName]\"\n. added on 1.4.4\nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/1.4.4\nwiki link\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Show-Commands\n. Hey , I've been working on a version with join support.\nCurrently only allow EQUAL conditions on join and some other restrictions (no group by and order by support on joins..)\nI would really appreciate it if you give it a try\nhttps://github.com/eliranmoyal/elasticsearch-sql\nexample:\n\nfeel free to contact me at (eliran.moyal1 gmail) if you having any trouble or problems :) \n. limited version of this feature enabled since 1.4 , read about it here\nIf you have issues feel free to re-open the issue / create another one :)\n. hey hymansun , it's a problem that index starts with dot. i tried fixing it but it turns out to be a bit complicated..\nYou can always use alias to your index and query it\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html \n. Well by sub queries I meant \nselect * from x where in ( select..)\nOn joins both need to be tables.. just push the where to the end.\nlike that:\nsql\nselect w1.props from web w1 \njoin web qwe \non w1.props.Article = qwe.props.Article\nwhere qwe.props.Article like '%alfa%'\n. Your query was just fine until the where. just put the o.name ='Bill'\nand just call it join, there is no meaning for inner here\nlike this:\nSELECT o.ID, w.Name, o.Name \nFROM web w\nJOIN web o on w.ReferenceToAnotherId=o.ID  \nWHERE w.name = 'Bill'\n. Haven't tried I think it should work (because elasticsearch can search terms in arrays ) but you will have 2 results and not one..\nTry this:\n{ ID: 3, Name: 'Mary', RelatedName: 'Jack' }\n{ ID: 3, Name: 'Mary', RelatedName: 'Bill' }\nselect w2.ID , w2.Name , w1.Name  from web w1\njoin web w2 on w2.RelatedIDs in w1.ID\nOr this\nselect w2.ID , w2.Name , w1.Name  from web w1\njoin web w2 on w2.RelatedIDs  = TERM(w1.ID)\n. +1\nStarting to working on it\n. Hey i'll add the rest of them today:  PolygonFilter, GeoHashCellFilter and GeoDistanceRangeFilter\n. What do you say about something like an hint?\n\" USE_SCROLL(docsPerFetch,timeoutInMilli)\" with defaults of 10000,10000\nFor example this query:\nSELECT /*! USE_SCROLL(100,5000)*/ gender,firstname,balance FROM  accounts\nwill return you a searchResponse with valid scrollId to scroll with.\n. It's a bit problem to set it as default because on its main core elasticsearch-sql just translates sql to ActionRequest and execute it.\nAnd from what i found the first query on scroll does not return any docs, and that is not what I think it's the best for simple users.\nYeah you are right, But I believe that the best scroll size is depends on size of docs + network + elasticsearch cpu and ram and num of docs you want to fetch eventually.\nI accept that  10k is really big so i'll change it but this is why i let you choose with parameters on the hint :)\nIt's working right now you can check the latest version 1.4\nand read about it on the wiki\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Scroll\n. what is the operation \"|\"\nis it bit wise or?\n. Thanks. done \nHelping #68 \n. 1. We use alibaba druid in order to translate the string to SqlExpr.\n   2.On Normal select - We take the sqlExpr and:\n   - translates the \"from\" to index and type.\n   - translates the Where to elastcisearch filter\n   - creates the elastcisearch request.\nFor join , delete and aggregations it's a bit more complicated\nif you have any other questions feel free to send me an email. my email can be found on pom.xml \n. can you check it with the latest version?\n. fixed, and dots are allowed again\nThe new line was a problem after the select.\nI made a new release (1.4.2)\n. You are right. I think it is because it is on the group by statement.\nwhat do you say about something like : \ngroup by date_histogram(field='insert_time','interval'='2h','format'='yyyy-MM','alias'='yourAlias')\n. Done\nI'll make a new release with more features this weekend.\n. check it on a new release 1.4.1 \nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/1.4.1/elasticsearch-sql-1.4.1.zip\n. the order is lon and then lat\n. check our wiki and please tell us if you having any other problems\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Geographic-Queries\n. Hey sorry we are not supporting insert commands.\nI do not know about any plan of adding this king of support.\na good way to do this without it is simply using Logstash.\nImplement a simple input plugin calling our plugin with the query and pass on the hits to the next plugin. (or do it with a bash filter)\nAnd then simply put the elasticsearch output plugin\n. I don't think you can page on elastic when using aggregations.\nsee https://github.com/elastic/elasticsearch/issues/7956  for term agg\nand for date histogram\nhttps://github.com/elastic/elasticsearch/issues/7103\n. Do you mean space separated index name? \n. I got it working on my fork. \nI got a PR but its on for 14 days now.. So if you want you can build my fork and try it out :) \n. Check it with latest version (1.4) it is working now\n. Fields with @ is a bit problem for sql (those are variables.) I will work on it.\nabout the 2nd problem. if you don't add the '@timestamp' you still not getting the allHostsInSession value?\n. Check on latest version \n. yes you can\n. Hey Caleb, I have merged my own branch first so yours now have conflicts (sorry for that).\nIt should be pretty easy for you to make it work with the latest code.\nThe thing you need to change is\ngoing to the class \"ElasticSqlExprParser\" on method primary()\nand put there an if(lexer.token() == Token.NOT) and then the \"Not\" code from the old \"SQLExprParser\" class.\nThanks!\n. On regex do you mean this?:\nhttps://www.elastic.co/guide/en/elasticsearch/reference/2.0/query-dsl-regexp-query.html \nIt's currently not supported.\nYou can always click Explain on web interface and see the request that will be sent to elastic\n. try \"where column <> 'xyz'\"\n. When you doing aggregations query you can only get the aggregated data. I don't know if elasticsearch support such things.. \n. but they appear separately (your fields under Hits and aggregated data under aggregations).\nif you'll try the http://localhost:9200/_sql?sql=yourSql\nyou'll get the result in json like at sense.\nDo you want that for metric aggregations we will show on web interface the hits and for each hit the aggregation data from aggregation section? I don't know if it is the required result. @omershelef  what do you think?\n. Oh, I think it's a bit complicated (for every hit i need to find the right bucket..).\nWe don't have any logic on the web interface now (only parsing results from elastic).\n. Not yet, I'll try to implement this later this week\n. stats already supported :) \nI checked it and it's just not showing good on web interface , i'll fix it.\nI will add precentiles and extended_stats\n. It should work on 1.3.5\nSELECT STATS(age) from accounts\nit will only work on http://localhost:9200/_sql?sql=SELECT STATS(age) from accounts\nnot on web interface (there's a bug there on stats query, i'll fix it)\n. its on the aggregations section below. at least its like that on 1.4.2 that i'm using \n. Yeah , just wait till tomorrow i'll finish with all you need :)\n. Check it on the newest version 1.4.3\nexamples can be found on our wiki\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Beyond-SQL-Features\n. Yes\n. Is this working for you? Can I close this issue? \n. Try ctrl+f5? maby the last version is still in your chrome.\nGo to http://xx.xxx.xx.xxx:9200/_plugin/sql\nAnd you should get something like this\n\n. Cool, thanks\n. can you add example and explanation on the wiki?\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Aggregations\n. On your first example, I saw the problem , I will make a fix that will take the \"value_as_string\" for such fields.\nI don't understand the 2nd example. what is the mapping of test_date_dd?\n. ok thats wierd, its working fine on my elastic. can you give me the result of\nhttp://yourHost:9200/_sql?sql=select min(test_date_dd) from  xxxxxxx/test_locs\n. Good, I'll fix it this weekend \n. check the newest version \nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/1.4.4\n. use elastic time format in string like this\nSELECT test_date FROM  xxxx/test_locs WHERE anotherTime < '2015-09-29T00:00:00'\n. Oh, I never used the delete statement before.. I'll have a look at it on the weekend\n. check the newest version \nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/1.4.4\n. Thanks! I'll finish some stuff and make a new release tomorrow :)\n. Hey, we do not support elasticsearch 2.0 yet. I hope I will able to make a new version in the next couple of weeks \n. check the new release\nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/2.0.0\n. I checked and there are major api changes between the versions (no more Filters only queries , delete by query is now a plugin etc..) so I need to compile against the new version and make all tests pass..\n. check the new release \nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/2.0.0\n. Thanks \n. Checked it and found that this is only bug on new table presenter. will fix on new version.\nYou can use the previous presenter with the option: useOldTable on the left side of the UI.\n. check version 1.4.6 (if you are using elastic 1.X )\nand 2.0.1 (if you are using elastic 2.0.0)\nit contains the fix\n. Hey, I did not encounter this issue now or before.\nMaby try with -t 5m \nIt will set a 5minute timeout.\nBWT You can always download the zip file\nfrom here:\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/1.4.6/elasticsearch-sql-1.4.6.zip\nsave it to your computer and do:\n./bin/plugin -u file:///home/yourFolder/elasticsearch-sql-1.4.6.zip --install sql\n. Np :) \n. Thanks\n. Sure , you can just \nselect * from xx/xx where test_date between '2014-08-17' and '2014-08-18'\nYou can also use the now keyword:\nselect * from xx/xx where test_date between '2014-08-18' and now\nselect * from xx/xx where test_date between now-1h and now\nor just \nselect * from xx/xx where test_date > now-1h\nThe date format needs to match the date format you put on your mapping\n. I've tested the plugin with elasticsearch 1.4-1.7 .\nMaby the api changed for java based plugins (kopf and head are site based )\nI'll try and test it with 1.3.4 on the weekend\n. Sorry, too many changes since 1.3.4 \nplease upgrade your elasticsearch if you want to use this plugin.\n. You mean when using the plugin like this:\nhttp://xxxx:9200/_sql?sql=select * from x\n?\n. This is not possible right now.\nI'll add this feature soon\nDo you want the column names in the first row like in csv? \n. Hey , I've made it possible for queries that doesn't contain aggregations.\njust need to add \nhttp://xxxx:9200/_sql?format=csv&sql=select * from x\nand also this avilable if you have nested objects\nhttp://xxxx:9200/_sql?format=csv&flat=true&sql=select * from x\nI'll try work on aggregations tomorrow but it looks a bit hard (too many types of aggregations)\nanyway i'll make a release with this feature on Tuesday/Wednesday \n. The new version with this feature is out\nmake sure you read the wiki about it\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/CSV-result\nTell me about your experience with this feature\n. Yeah\n. The 1.4.8 released yesterday, if you installed it than you should be able to use it\n. Thanks!\nWhat do you say about suppprting something like this:\n\"where nested('comments', comments.age='28' and comments.stars='4')\"? \n. I'll create a new release this weekend. I'll add an explanation on the wiki in this kind of queries. \n. Yeah I've notice it before.\nThe problem is that the columns order at result stage is always the mapping order for your type.\nMainly the plugin just translate the query to elasticsearch json and the ui just parse the results and do not interfere in the way so there is no easy fix for it.\n. I don't understand, What do you want it to  return? There is no sub queries in elasticsearch so I have to do the process before the last request. \n. Oh I see. you are using it as a library..\nI need to do a big refactor so people can use it as a standalone library in a good way.\nI'll try to add a bit of functionality on this weekend for your use case like injecting an QueryAction and than you will be able to override the setIndicesAndTypes\n. Guess i didn't thought about this kind of aggregations.\ni'll add it to this weekend release.\nReally thanks for experimenting with the master and new features!! \n. You are now able to do select sum(nested(comments.age)) from index\nyou can also use it on buckets aggregations  with the nested option , like this:\nselect count(*) from index\ngroup by date_histogram('field'='message.date','interval'='1d','alias'='day', 'nested' ='message')\nOn nested you need to enter the nested path.\n. Yeah from 2.0 you need to compile your plugin with each version.\nI'll create a branch and a release for 2.1 today/tomorrow.\n. check release 2.1 \nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/2.1.0\n. Thank you, and thanks  for using it :) \nHow do you want it to look like? \nIs hint ok? \nsql\nSelect /*!  IGNORE_UNAVILIABLE */ * from x,y,z\nAlso, which version of elasticsearch are you using? I will create a patch for you if you don't want to wait until the next release \n. I've create a version for you with this update.\nyou can compile it using maven (there is an explanation on wiki)\nOr send me an email - my mail is on pom.xml and i will send you the zip .\nFrom what I saw :  if all the indices are unavailable you will still get error but if some of them exists it will be ok.\nthis is the hint: /*! IGNORE_UNAVAILABLE*/\n. it's only available on master branch (for elastic 1.4-1.7 ) not in any release yet.\nYou simply need to use a sql hint:\nsql\nSELECT SELECT /*! IGNORE_UNAVAILABLE */ * FROM index1,index2,index3\nWHERE ....\n. No , i just pushed this commit yesterday. you can compile it on your own / send me an email and i will send you the zip file.\n. yes and yes\n. You can use scroll api to do paging in your client. \nThe scroll api is good for your client and for your elasticsearch cluster.\n. It uses scan and scroll if order by not provided. The search_type on url occures from the 2nd request. And from there it doesn't matter if the type provided or not (it uses the first search type) \n. I think that elasticsearch 2.1 is stable. they officially released it 20 days ago..\nif you upgrade to 2.1.0 use the 2.1.0 plugin version\nif you upgrade to 2.0.0 use 2.0.2 plugin version\n. What is IF? Is it some kind of switch case? \nI don't think there is something like that in elasticsearch..\nYou can use scripted aggregation, read about it on the wiki, tell me if you are having trouble with it \n. This is what i ment:\n``` sql\nselect sum(script('special_sum',\n                  'doc[\"final_status\"].value == 1? 1: 0')) as special_sum from yourIndex\n```\nIf you are having any problems re-open this issue.\n. Sure, I'll fix it.\n. this is fixed on the new versions\nthanks for mention this\nyou can also specify specific sizes for next terms agg like this:\nsql\nSELECT COUNT(*) FROM account GROUP BY gender, terms('alias'='ageAgg','field'='age','size'=3)\n. Hey ,\nIt cannot parsed as sql.. \nSo i'll create you something like this:\nsql\nselect * from index/doc where ['0304'] > 123\nHope i'll create a release this weekend \n. I'm using mysql parser with minor changes. On sql you can always select static values(literals)  before the from clause (it is not possible on elasticsearch so I used them as fields). \nBut on where you must have identifiers on left side of the condition, identifiers are like words (must start with a-Z)  but it can also be wrapped by brackets \n. You will be able to use it this way:\nsql\nSELECT ['0304'] FROM index/doc\nwhere ['0304'] >123\nas you mentioned this will also work\nsql\nSELECT `0304` FROM index/doc\nwhere ['0304'] >123\n. yeah it will work for order by and for group by\n. Hey the new version with this feature is now out\ncheck it and tell me if you are having problems\ngood luck :) \n. Do like this:\nSQL\nselect * from myIndex where my_date between 'now/d' and 'now/d'\n. Hey, I'll be working on this on the next couple of days\n sorry for the long wait\n. check the new version 2.1.1\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/2.1.1/elasticsearch-sql-2.1.1.zip\n. duplicate #129\nI'll work on this :) \n. Hey tiger \nI think you got the parameters wrong it's \nWhere nested(A.field,'A') ='xxx' and nested(B.field,'B')='yyy'\n. Ok i see the problem. i'll look at it tomorrow\nthanks\n. Ok it's a bug. \njust for you to understand me:\ncomplex nested is nested(PATH, condition)\nsimple nested is  nested(field,PATH) OP value\nA workaround is not to put complex nested on left side.\nmeaning:\nBAD - will not work\nsql\nselect * from myIndex where nested('A', A.field='xxx') and c='zzz'\nGOOD - will work\nsql\nselect * from myIndex where c='zzz' and nested('A', A.field='xxx')\nAlso if you can just use the simple nested on the left side.\nsql\nselect * from myIndex where nested(A.field,'A') ='xxx'  and nested('B', B.field='xxx')\nI'll fix it , but hope this workaround works for you for now.\n. I do not understand Chinese. \nI guess you want a distinct but I don't think it's available in elasticsearch \nYou can do a group by and it will work pretty much the same \nSelect * from myindex group by ip \n. Cardinality is distinct count not distinct values\n. What your elastic version? \nIf you are doing SELECT * FROM index\nare you still not getting data?\ncan you post the json that is out when you click explain?\n. I don't familiar with this feature (security on elasticsearch). can you give me a link how to install it on my elasticsearch?\n. Great !\nIt is a bit a problem to use a plugin from another plugin\nhttps://github.com/elastic/elasticsearch/issues/14585 \n. Hey, you can try to install the latest 1.x version (1.4.8), if it is not working I'll install 1.7.4 and will test it tomorrow \n. Did you restart the elasticsearch service after installation?\n. @anduo1989 \nI've just installed elasticsearch 1.7.4 and it worked fine.\nAfter installing 1.4.8 version of the plugin when I didn't restart the service I did get:\n{\"error\":\"InvalidIndexNameException[[_sql] Invalid index name [_sql], must not start with '_']\",\"status\":400}\nBut after the restart of elasticsearch it worked fine.\n. Hey @milodky \nI didn't wrote this feature and yes, I looked and unfortunately it does not support escaping..\nI'll make a quick fix for it tomorrow so you will be able to escape underscore and also %.\n. escaping are &PERCENT and &UNDERSCORE\n. Guess you are are right\nDo you know if escaping them in elasticsearch is just putting a backslash before?\n. Hey @rahuldaskar and @milodky , I'm really sorry\nwasn't here for about a month+\nhave you tried two backslashes?\nI tried and it worked for me\nAdded 2 docs one with message \"sos\" another with \"s*s\"\nwhen asking\nsql\nselect * from myIndex\nwere myField like 's*s'\ngot both of them\nwhen asking \nsql\nselect * from myIndex\nwere myField like 's\\\\*s'\ngot only s*s document. There is no such option now.\nI will add this feature \n. This is not currently supported\nI see there is lot of options for this feature and this is not something intuitive to implement (not another filter / aggregation)\nCan you provide example for how you want it to look on queries? (maybe an hint?)\n. Thanks\nI'll be working on this soon :) \n. Sorry for the long wait , check the new release :)\nIt is only available through rest api (not on site)\n. Yes here\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Highlight\n. yes it is a duplicate of #116 \nif it is very important to you I will think how to do this.\n. elasticsearch does not support date functions so i have nothing to translate to.\nBut you can do it with scripting\nTo select fields with scripts you can do something like this:\nsql\nselect script('hour','doc[\"insert_time\"].date.hourOfDay') , message from myIndex\nThere is example here for scripting on query : \nhttps://github.com/NLPchina/elasticsearch-sql/wiki/ScriptQuery\n. @umaxfun is right , you can always use scripts.\nAlso the format is the format in your mapping, so if you will index a date with other format on your mapping you will get that format when displaying this field.\n. What's your mapping?\n. I believe it is just the number of milli seconds from 1970-01-01 00:00:00 to your indexed time 2016-01-07 00:00:00\nmeaning the unix time in milliseconds\n. @bassduh \nif you are still having trouble . this will work (maybe there are better ways)\nsql\nSELECT script('myFormat','new Date(doc[\"insert_time\"].value).format(\"yyyy-MM-dd HH:mm:ss\")') , insert_time FROM yourIndex\n. In elasticsearchsql on 1.x versions if you don't order by _score than it will be a filter.\nOn elasticsearch2.x elastic changed the api and it decides itself\n. Hey , \nYeah its a bug, I just parsed the source and not the fields from the result.\nwill fix in next version.\nThanks!\n. Sorry for the long wait , check the new release :) \n. look at the last example here:\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Script-Fields\n. I think there is. whats the field that is different between docs?\n. The csv feature is from 1.4.8\nyou can read the the release notes here:\nhttps://github.com/NLPchina/elasticsearch-sql/releases \n. Hey,\nthe _score and _id fields always returns from elasticsearch response so i don't know whether you requested them or not (the results parser has no knowledge about the query and just translates elasticsearch responses).\nI can add a feature to the options to let you choose if you want to add the _score and the _id fields to the table.\nIs that ok for you?\n. sorry for the long wait , check the new release \n. not sure what are you trying to do.\ncan you give an example?\nyou can always create scripted aggregation with code if it's not an elasticsearch feature.\n. Oh,\nI couldn't find something like that in elasticsearch so i have nothing to translate to..\nthe cardinality is like distinct-count and not breakable.\nI managed to do it using the scripted_metric  , but its look a bit ugly.. \nyou can read about scripted metrics here: elastic and  in our wiki\n``` sql\nSELECT \n scripted_metric(\n'init_script' = '_agg[\"distinctAges\"]=new HashSet()',\n'map_script'='_agg.distinctAges.add(doc[\"age\"].value)' ,\n'combine_script'='return _agg.distinctAges;', \n'reduce_script'='allAges = new HashSet();\n   for(agesFromShard in _aggs) {\n    allAges.addAll(agesFromShard);\n   };\n   sum = 0;\n   for(age in allAges){\n    sum+=age;\n   };\n   return sum;\n   ') as sum_distinct\nFROM elast*/account\n```\n. Yeah, when I'll finish with my exams next week :) \n. sorry for the long time.\nI was needed to change some code in order to support elasticsearch 2.2.0\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/2.2.0/elasticsearch-sql-2.2.0.zip \n. It's on branch elastic2.2\n. this works for me..\ncan you show your mapping for the field city?\nif it is analyzed i think you should query in lower case:\nsql\nSELECT * FROM xxx/xx where city like 'new%'\n. Yeah its all about analyzers and how they work.. \nIf you want to read more about it read here : http://stackoverflow.com/questions/5483903/comparison-of-lucene-analyzers\nusing the not_analyzed keyword just saves the text \"as is\"\n. what is the replace function? I don't think elasticsearch has this kind of functionality\nbut you can always create a script field\nsql\nSELECT message, script('replaced_field','doc[\"message\"].value.replace(\"MSDW_WOOJ_ALGO_SWP\",\"TESTNAME\")'\nFROM DISCFIX where FIXTags.11 = 'Y2VMB7FHKNB' \nand FIXTags.17 = 'zVcKuLJ4SASj66a-jakP9gA'\n. What do you mean? Do you want to convert it to elasticsearch json? \n. Yes, if you are using the elasticsearch-sql  website just click on the explain button. \nOn the rest api you can ask with _explain?sql=yourSql\n. http://localhost:9200/_sql/_explain?sql=select * from a where fielda='b'\n. and that is exactly what the EXPLAIN does..\nWEB:\n\nAPI:\n\n. hey, this is not currently supported\ni'll add this feature with an hint \n. Sorry for the long wait , check the new release\nyou can now query like this\nsql\nSELECT /*! ROUTINGS(myRouting) */ * FROM myIndex/myType\nsql\nSELECT /*! ROUTINGS(myRouting,mySecondRouting) */ * FROM myIndex/myType\n. Yeah, use the api with _sql?sql=\nI don't know much python but maybe there is a way to use the elasticsearch python lib for the results parsing \n. select * from index1/type1,index2/type2 etc...\n. Use not_analyzed on mapping of this field to avoid this kind of behavior in elasticsearch. \nIt's happen only in elasticsearch-sql plugin? What happens when you query on native javaapi or restapi \n. Hey\nyou need to use dynamic_templates - for your index\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/dynamic-templates.html\nnext time for elasticsearch related questions just open it on the elasticsearch discuss forum\n. https://github.com/NLPchina/elasticsearch-sql/wiki/NestedTypes-queries\n. For your first quesion, if this plugin was only translating to JSON and sending the request maybe it was easier to support it , maybe even changing the JSON according to version config.\nBut this plugin uses the Java-Api which changes a-lot from version to version now..\nAnd from 2.x you must compile your plugin against the same version you work with, it causes wierd issues if you don't.\nI will make you a new release but i think that after this release I will only support latest elastic version.\n. I think a feature like that is a big change for this plugin.\nLately I don't have a lot of time working on this project (work and finishing my master degree).\nMy roadmap now is:\n1. making this project an independent library \n2. more than 2 tables joins\n3. supporting jdbc\nI think that plugin that just converting the sql to json could maybe built only on JavaScript and than it will make it more accessible for users.\n. Really sorry for the long wait\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/2.1.2.0/elasticsearch-sql-2.1.2.0.zip\n. Hey I've tried to recreate this issue but couldn't\ncan you give me more details?\nwhich elasticsearch version exactly are you running?\nwhat is the command you ran?\nthanks\n. yeah there are some constraints. semicolons are not allowed.\nI will fix it for you.. \nFor now you can create aliases (for example replace all semicolons with dots)\n. What is your elasticsearch version? Which plugin version did you download ? \n. the master is for 1.x versions as mentioned on readme file\nthis is the release for you (on branch elastic2.2)\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/2.2.0/elasticsearch-sql-2.2.0.zip \n. Reverse nested is only used for aggregations...... There is no need to use it here\nRead about nested here\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/NestedTypes-queries\nFor your usage if you want docs with attributes that contains an attribute which have key 'block'  and value 880 just do\nSelect * from myindex where nested('attributes', attributes.paramkey='BLOCK' and value=880)\n. for BLOCK=880 and LINE!=800\nsql\nSELECT * FROM x\nwhere nested('attributes',attributes.paramkey='BLOCK' and attributes.value=880)\nand nested('attributes',attributes.paramkey='LINE' and attributes.value<>880)\nfor BLOCK=880 and LINE=7\nsql\nSELECT * FROM x\nwhere nested('attributes',attributes.paramkey='BLOCK' and attributes.value=880)\nand nested('attributes',attributes.paramkey='LINE' and attributes.value=7)\n. ok it it a known issue which i've fixed  #131\ni'll create a release with more features this sunday\n. not sure if this is possible in elasticsearch.. the geoBoundingBox filter is used only for GeoPoints types..\nread about it here\nhttps://www.elastic.co/guide/en/elasticsearch/reference/2.0/query-dsl-geo-bounding-box-query.html\nyou need to change your document and mapping in order to use it.\nalso it looks like you dont even save it as numbers.. so a workaround like asking\nsql\nselect * from index where nested('attributes',attributes.paramKey = 'GPSX' and attributes.value > topLeftX ) etc..\nwon't work either \n. Hey, sorry but no and I don't think I will be able to support it soon\n. yes use percentiles\nSELECT percentiles('age') p FROM yourIndex\n. it is not available now , will be on next version\n. Ya, hopefully tomorrow \n. Hey, haven't finish merging for all versions but here is the one for you\nelasticsearch-sql-1.4.9.zip\n. ./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.2.1.0/elasticsearch-sql-2.2.1.0.zip \n. Yes\nthere is a rest api.\n(you can also use post)\ncurl http://localhost:9200/_sql?sql=SELECT%20*%20FROM%20yourIndex\n. Sorry never really used curl\n. Hey, the mapping for the field is the default for date? \n. Well I checked and it worked fine on site\nThan I checked the api and I got the same error as you did.\nchecked and it turns out to be url escaping for '+' on browser.\nif you need to query with your browser just replace the + with %2B\n. ?\n. two ways:\nlets say you want to group by a field called firstname\nimplicit way:\nsql\nSELECT * FROM yourIndex\ngroup by firstname\nlimit 3\nexplicit way:\nsql\nSELECT * FROM yourIndex\ngroup by terms('field'=firstname,'size'=3,alias='name')\n. Oh, this is not implemented. \nI wasn't aware of this option.. \nI'll add this\n. The new version is out :) \n. yes , I'm creating a version with escapes so you will be able to escape _ and % \n. check the new version\nyou can escape the _a with &UNDERSCOREa\n. Yes, which version of elasticsearch-sql are you using? \n. well I've implemented this already so its wierd\nthis query\nsql\nselect insert_time from elast*/online  \ngroup by date_histogram(field='insert_time','interval'='1.5h','format'='yyyy-MM-dd-HH','time_zone'='-01:00','alias'='myAlias')\ntranslates to:\n{\n    \"from\": 0,\n    \"size\": 0,\n    \"_source\": {\n        \"includes\": [\n            \"insert_time\"\n        ],\n        \"excludes\": []\n    },\n    \"fields\": \"insert_time\",\n    \"aggregations\": {\n        \"myAlias\": {\n            \"date_histogram\": {\n                \"field\": \"insert_time\",\n                \"interval\": \"1.5h\",\n                \"time_zone\": \"-01:00\",\n                \"format\": \"yyyy-MM-dd-HH\"\n            }\n        }\n    }\n}\n. I'm using elasticsearch java-api and the api returns double for all those aggregations.\nthis is just the toString of the double..\nany suggestions on how to do it more readable? (not really familiar with numbers formattings)\n. Thanks! i will try it :)\n. the query seems odd , does the sub-query is really on the same index?\nis id is the _id of elasticsearch or do you have a different field called id?\n. if you need an idsQuery on your data using an FK on another index\nthis is the way:\nsql\nselect * from yourIndex \nwhere _id = IDS_QUERY(yourType,(select myFk from otherIndex where firstname = 'Wilson')\n. sub queries on other fields (not on ids) should be like this:\nsql\nselect * from firstIndex \nwhere field1 IN ( select field2 from secondIndex)\nwill result in lot of or queries on first index with values from second index\nif you are looking for terms filter\nsql\nselect * from firstIndex \nwhere field1  = IN_TERMS ( select field2 from secondIndex)\nwill result in one termsFilter on there terms that fetched from secondIndex \nit should work. if you are having any troubles post here the error and the explain that returned\n. the sub queries is only available for where clause.\nI don't think it will be possible to translate this kind of queries to elasticsearch dsl\n. I am not familiar with kettle's http post.\nbut when you query elasticsearch you have to mention size - determines the number of docs returned\nor from and size.\nthe default size is 200 on this plugin, you can change it with limit\nsql\nselect * from yourIndex limit 1000\nwill result in 1000 size\nsql\nselect * from yourIndex limit 1000,1000\nwill get you the next 1000\n. in elasticsearch you must mention result size\nyou can put something like 99999999\nand get all of it\n. ./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.3.0.0/elasticsearch-sql-2.3.0.0.zip \n. currently this is not supported, i'll add this to next version\n. two options:\n1. from & size:\nsql\nLIMIT 10,20\nwill result in from and size parameters for elasticsearch\n1. use scrolling , read about it here:\n   https://github.com/NLPchina/elasticsearch-sql/wiki/Scroll\n. will fix on next version.\nwhich elasticsearch-sql version are you using?\n. the second query uses scripted_fields and it is easy to translate it to elasticsearch dsl\nreade here : https://github.com/NLPchina/elasticsearch-sql/wiki/Script-Fields\nfor the first query there is something called scripted_metrics \nread here : https://github.com/NLPchina/elasticsearch-sql/wiki/Aggregations\nIt is a bit hard even for something simple as *20\neventually everything translated to elasticsearch dsl , there is no easy data manipulation for agg results yet..\n. Where is the zip from? \n. you downloaded the code in a zip file..\ndownload the compiled plugin from here:\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/2.3.0.0/elasticsearch-sql-2.3.0.0.zip\n. sure, I'll work on this soon\n. If you have the time I will really appreciate it, for any help about the source code you can email me (my mail is on pom.xml)/twitter pm me\n. No, this is not supported \n. I don't understand, can you explain with example please? \n. Hey, sorry wasn't online\nWe actually support filter aggregations\nsql\nselect sum(trans_type) as type_trans_total_amount\nfrom index_trans\ngroup by  filter ( trans_type between 120 and 1230) , date_histogram(field='create_time','interval'='day',\"format\"=\"yyyy-MM-dd\",'alias'='create_date')\n. Thanks , from which branch did you forked?\n. so can u make the pull request to branch 2.3.0?\n. Cool, can you add tests?\ncheckout MainTestSuite to add a mapping and a json file with data to load\nafter it add test to TestQuery class like nestedQuery tests.\nI also see it broke one test of nestedqueries tests  the \"nestedOnInQuery\" test so it failing the build.\nI will look on it tomorrow if you are having trouble\n. not supported yet. will add this\n. I'm using the Java api and I don't think there is a way to translate this. \nIf you care about wasting Internet, you can try the format=csv option (check on wiki) \n. @Carlos-Mosquera \nsql\nSELECT name FROM gotCharacters WHERE name.firstname = IN_TERMS(daenerys,eddard)\n. Sorry for the late answer. \nIs it still relevant?\nif yes please show the mapping for the tags field\n. hey , yes I think it will be a nice addition\nhow do you want to see this feature in sql?\n. hey @Selvinaz1984  , sorry for not being online on this project for some time.\nI'll add this feature to next version (with the configuration support)\nIf you already made this with configuration send me your code or create a pull request\n. yes read the wiki\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Aggregations\non multiple aggregation section\nsomething like\nsql\nselect ...\ngroup by (sex) , (language)\n. look at the settings on the left side -> flat results\n. what do you mean by filter context?\nI believe filter queries are not available since version 2.0 of elasticsearch \n. Ok I'll check this , thanks!\n. @allwefantasy @ansjsun \nwhat do you think?\nshould we put everything in filter context if not order by score?\n. Hey @shanielh \nI'm I sorry wasn't working on this for some time.\nI'll support this on the next version.\nwhich elasticsearch version are you using? (I will make an hotfix for your version if necessary ) \n. elasticsearch-sql-2.1.2.1.zip\nUse it with the full syntax of terms group by\nlike this:\nsql\nSELECT count(*) FROM myIndex/person\ngroup by terms('field'='nickname','missing'='unknown','alias'='nicknames')\n. use brackets to escape \nsql\n select `from` from table_name\n   where appName = 'app_name'\n   and dateTime >= 'today_date'\n   and [`from`] like 'u%'\nalso like will not work if from field is analyzed (using wildcard)\n. is this: #135\nnot working for you now?\nI'm sorry I don't have shield to test it and it is also a plugin.\nfrom my experience running a plugin from inside a plugin is not possible\nhttps://www.elastic.co/guide/en/shield/current/_using_elasticsearch_java_clients_with_shield.html\nhttps://github.com/elastic/elasticsearch/issues/14585\n. which elasticsearch version are you using?\ncan you post the mapping?\nI'll check this and will prepare a feature for this if possible\n. hey @srijiths \nI have noticed it too\nBut I couldn't able to get the fields on the _search api..\ndo you know how to do a post request that does not involve aggregations and get the fields and not only the id?\n. Oh ok..\nSo are you having any other problems?\n. What do you want to see?\nFrom what I tested you can search and filter and see only the amount of docs return.\n. Well I've noticed you only get the number of docs.\n\nFor the next version I am going to add the id column to the results so you'll be able to see it\nAlso I've noticed it cause a bug on csv format , i'll fix it too\n. Also I can't say I have tested all the scenarios on this index  (lot of work)\nBut if you'll have any problem I'll be happy to help \n. Can you try without the \"t\"\n. Yeah distinct is not supported (there is no such feature in elasticsearch) \nCount distinct is supported(cardinality feature on elasticsearch) \nI'll make an error when using only distinct on the next version \n. Great can you add tests? \n. Also from my experience if you create a client per request it can cause a lot of problems.\nUsing the same instance of the client (i.e singleton) is the best option for TransportClient\n. You can use the csv option on search and use flat=true\nread about it here\n. show the select please\n. There is a workaround for your issue\nsql\nSELECT * FROM ['5ed516e548a8458c825ec3655127cd46']\n. We don't support paging /scrolling for not native elasticsearch queries now. hey , lot of conflicts\nfrom first view It looks like you are trying to push to older version of elastic (1.x)\nmaybe you want to merge to branch 1.x?\n. check for IN or IN_TERMS\nsql\nselect * from myIndex\nwhere myField IN ('x','y')\nwill result in a query on myField with or between 'x' , 'y'\nsql\nselect * from myIndex \nwhere myField =  IN_TERMS(x,y)\nwill result in a terms filter on myField with values 'x' , 'y'\nIf you meant something else please send the elasticsearch equivalent \n. Yes there is some support for this query\nsql\nSELECT * FROM yourIndex/parentType where children(childrenType, childrenField)='value'\nor\nsql\nSELECT * FROM yourIndex/parentType where children(childrenType, childrenField) in ('a','b')\n. I'm not sure (didn't wrote this feature)\ncan you show the equivalent in elasticsearch and what result do you want? \nI'll search the code\n. hey, this feature is not supported yet\nI'll add this soon\n. its on master now , do you need it for a specific version?\n. There you go \nelasticsearch-sql-2.4.0.1.zip\ninstall it with path (plugin.bat install  file:PATH_TO_FILE )\nI'll fix some more stuff / add features and hopefully will make a formal release this weekend\n. https://github.com/NLPchina/elasticsearch-sql/releases/tag/2.4.0.1\n. Maybe we should add shard hint? \n. Great, thanks\n. No, grouping use es aggregations, sub queries is only used for filters\n. Done,\n./bin/plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.4.1.0/elasticsearch-sql-2.4.1.0.zip\n. Sorry it is not supported now, parameters only supported in script filters now.\nI'll add this soon :)\n. you can use curl\nlook here :  #174 \nYou can also use the csv parameter for better reading\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/CSV-result\n. crate.io are doing the aggregations by their own , we use elasticsearch.\nyou can always create your own aggregation implementation using elasticsearch scripted metric\nlook at the bottom here:\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Aggregations\n. Yes , I will work on this soon. I am pretty much done with rest plugin and jdbc\nbut since site plugins are not supported anymore I am not sure what to do with the site\nShould I make a standalone version of the site with something like node.exe ?\n. This is the plugin for elasticsearch 5.0 tested against elasticsearch 5.0.1\nyou can use the rest api  and the jdbc client.\nSince elasticsearch disabled plugin sites on elasticsearch5 you can't use it like you used to.\nIf you want to use the site you can  just open the index.html in elastic_home/plugins/sql/_site\n(make sure to add to elasticsearch.yml cors flags in order for the site to work.)\nI'm trying to work on kibana plugin for the site, but if i won't succeed i'll just add a node server to host it.\nTell me if you are having any problems , an official release will come later this week\nelasticsearch-sql.zip\n. https://github.com/NLPchina/elasticsearch-sql/releases/tag/5.0.1 . Hey ,\nwe support all elasticsearch function on dates (max , etc..)\nfor + , - and basic functions we use script fields\nmeaning query like\nsql\nselect insert_time+60000 as time_add_minute from myIndex/myType\nwill translate into  script field with value of  doc['insert_time'].value + 60000\nYou can add your own script fields if you like to do anything else\nlook here:\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Script-Fields\nfor something like part of dates look at this issue\nhttps://github.com/NLPchina/elasticsearch-sql/issues/142\n. Hey, care to add some tests (atleast for CommonResultsExtractor)?. Also , whats bad with default which returns elasticsearch result?. currently , no. Yes you can\nA bit ugly but this will work\nsql\nSELECT insert_time FROM elast*/online where \nscript('doc[\"insert_time\"].date.monthOfYear==10')\nyou can also use it for query\nsql\nSELECT script('myMonth','doc[\"insert_time\"].date.monthOfYear') , insert_time FROM elast*/online\nread more about it here\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/ScriptQuery\nand this is the class that elasticsearch using for more properites\nhttp://joda-time.sourceforge.net/apidocs/org/joda/time/MutableDateTime.html\n. https://github.com/NLPchina/elasticsearch-sql/releases/tag/5.0.1. duplicate of #325\nwill work on this soon. Hey\nwell this is a bit complex\nI have this in mind and in my todo-list but I didn't start working on it. When asking for group by (code),(timeandhour)\nit means two different on same level aggregations  (multiple aggregations) and not sub-aggregations\nThis is not supported for now by our jdbc client (as it not standard for rational databases to support this)\nif you are looking for sub-aggregations (for each code group by timeandhour)  try group by code,timeandhour. Looks pretty straight forward so i will confirm this\nbut can you add some tests please?. Hey ,\nsorry this type of query is not implemented yet  . For the more generic idea there is none (we are not planing querying data not by elasticsearch) \nBut I am planing  to add something like \"having clause\"  to help with this specific kind of queries. This called bucket selector aggregation https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-pipeline-bucket-selector-aggregation.html. Hey, can you send the explain json please? Probably just a bug on ui but I want to be sure . well sorry @elyday but I think you are wrong\nthe result is just fine.\ngrouping means like nested \"for each\"\nfor each column1 value1\n    for each column2 value2\n       for each column3 value3 \n          for each column4 value4 \n              save sum of all column5 values where column1 = value1 and column2 = value2 and column3=value3 and column4 = value4\nfor result like yours you probably want to group by only three fields. meaning:\n GROUP BY column, column2, column4\nread about group by here for example\nhttp://www.w3schools.com/sql/sql_groupby.asp\n. the sql-web-page works through the java-api so it should be the same. Yes, I'm having some troubles with delete specific type but it seems working.\nWill be released this weekend . Not in the first version but later. sorry man, somehow I'm still getting the weirdest errors again\n{\"type\":\"class_cast_exception\",\"reason\":\"org.elasticsearch.index.reindex.DeleteByQueryRequest cannot be cast to org.elasticsearch.index.reindex.DeleteByQueryRequest\"}\nit looks like it is still a different module in elasticsearch and the import is on wrong order. i'll try and open a request for that. yeah turns out it is still a plugin but provided by default\nI opened an issue about plugins using other plugins then ,I just commented on it now and they say they still not worked on it ... hey, sorry not now \nI'll work on this soon. done\nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/5.1.1.0\n(talking to myself). the rule now is : if ordering by score -> query context , if not ordering by score filter context.\nI think we should use filter context by default when not ordering by score because this is the fastest and probably the most common usage in elasticsearch.\nI want to stick with correct sql standard.\nI think i'll do something like this:\nwhen not ordering by score if you want something to go to query \ndo this:\nsql \nselect * from bla where query( a=1 and (b=2 or c=2) ) or d = 3\nand if ordering by _score they need to use filter()\nit is working in parser , i think this should be simple to implement\nwhat do you say?\n. I'll check the complexity for the keyword, for the comment it doesn't say where it ends, and im not sure we can see where the comment was on parsed sql (will check it when I will get home later) . can't find the comment. Are you using it with java or by rest api?\ndelete still not works #339 . Hey from elasticsearch 5.0 elastic does not support site plugins anymore \nRead about the release https://github.com/NLPchina/elasticsearch-sql/releases/tag/5.0.1\nOr in readme file on a workaround until we will finish kibana plugin . how are you trying to install it?\nfor windows open cmd\nnavigate to your elasticsearch bin\nrun\nplugin.bat install https://github.com/NLPchina/elasticsearch-sql/releases/download/2.4.1.0/elasticsearch-sql-2.4.1.0.zip\nrestart your elasticsearch service and use it. Read release notes/readme, there is a standalone website now. Elasticsearch no longer support plugin websites since elasticsearch5.0. You need to restart your elasticsearch service after installation . when grouping by sex you will need to use aggregate function on name and age\nwhat is data?\ni don't see how \"select name,age from tableName group by sex\" works in any sql engine.\nsomething like this: \"select sex, sum(name),sum(age) from tableName group by sex\"\nwill work\n. ",
    "jstortz": "+1\nI'll vote for this.\n. @bsreekanth have you found other combinations that don't work?\n. Just noting here that ElasticSearch 1.6 was released on June 9th.\n. We need to be able to perform a query and then have standard elastic aggregations and sub aggregations returned in the response of that query.  We need to get counts (and sub counts) across multiple fields of the data set returned.  This addition provides that. It IS necessary for our business requirements.\nHere is a sample query to start discussion:\nSELECT firstname, lastname, gender, state FROM elasticsearch-sql_test_index\nWe actually need to use all the data returned by this query, we display the data in a table for the business user to review. In this example though, we also need a breakdown of the data by three categories: gender,  state and gender WITHIN state.\nWith this addition we would add gender,state,state:gender and it would provide that information in the response.  The explain looks like the elastic query below and works great:\nIf you believe this can already be done with group by please provide an example. If having reviewed our requirement you think it should be implemented differently please supply some suggestions for the group to consider.\nGET elasticsearch-sql_test_index/_search\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"_source\": {\n        \"includes\": [\n            \"firstname\",\n            \"lastname\",\n            \"gender\",\n            \"state\"\n        ],\n        \"excludes\": []\n    },\n    \"aggregations\": {\n        \"gender\": {\n            \"terms\": {\n                \"field\": \"gender\",\n                \"size\": 0,\n                \"order\": {\n                    \"_term\": \"asc\"\n                }\n            }\n        },\n        \"state\": {\n            \"terms\": {\n                \"field\": \"state\",\n                \"size\": 0,\n                \"order\": {\n                    \"_term\": \"asc\"\n                }\n            },\n            \"aggregations\": {\n                \"gender\": {\n                    \"terms\": {\n                        \"field\": \"gender\",\n                        \"size\": 0,\n                        \"order\": {\n                            \"_term\": \"asc\"\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n. Omer, it is no trouble. We wanted to submit something so we could begin discussion with you and have something you can look at and comment on, just like you did.  Thank you for your feedback!\nI agree that a single aggregation, including sub-aggregration would work.  Because we need more than one we will have to push forward with our change.  You suggestions on the format are good.  We will talk about them Monday to see how our implementation can be changed to match that.  I like the look and feel of your suggestion.\nThanks!\n. ",
    "jimrice57": "how about using a union type of function where you can query multiple indexes then combine the data into a single data set?\n. So here is my scenario - I have an index per week for 52 weeks for 5 years.   Sometimes it would be nice to be able to query week1-5 and week 10-20 - the index structure should be the same but not have a multiple table option in the select does not allow me to perform that operation.  I can do something like week 1* which give me 10 weeks but was looking for a way to pick things without multiple runs.   For example - give me the count and sum of the records that have cola=value from week 1 and 5 and 35?   A union would all me to query each week individually then display then all out.\n. Having the same issues - using ES 1.4.1 and SQL 1.3.1\nhave jar file and _site in following location - /usr/share/elasticsearch/plugins/sql\nrw-r--r-- 1 root root 488877 Mar  4 15:37 elasticsearch-sql-1.3.1.jar\ndrwxr-xr-x 4 root root    116 Mar  4 15:37 _site\nany suggestions?\n. query running SELECT * FROM cdr2-201401\n. We played around and figured it out - you have to restart the master node in order to get the plugin to work  - that is odd behavior for a plugin\n. We only had to start the Master.\n. ",
    "jmcgdz": "What about joining across multiple types within the same index?\nIs that the same problem/issue?\n. @jimrice57 Is that the aliases usecase?\nhttp://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html\nIf you can query by aliases I think that will solve your issue.\n. ",
    "nkastur": "Hi omershelef ,\nThanks for the response. Here are the details -\nElastic search version : \n{\n  \"status\" : 200,\n  \"name\" : \"myhost\",\n  \"cluster_name\" : \"myCluster\",\n  \"version\" : {\n    \"number\" : \"1.4.2\",\n    \"build_hash\" : \"927caff6f05403e936c20bf4529f144f0c89fd8c\",\n    \"build_timestamp\" : \"2014-12-16T14:11:12Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"4.10.2\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\nSQL plugin version -\nelasticsearch-sql-1.4.1 ( elasticsearch-sql-1.4.1.jar).\nPlease let me know if you need more details.\n. Hi omershelef ,\nWith elasticsearch 1.4.1 and sql plugin 1.3.1 , the explain query generates the exact query as above. Thank you so much .\n. ",
    "mguissine": "Just installed the pugin and restarted master node as suggested in the previous post, still having issue, my error is: {\"error\":\"InvalidIndexNameException[[sql] Invalid index name [_sql], must not start with '']\",\"status\":400}\nquery I run: select * from indexname\n. Update: plugin is working after restarting all the nodes where it was installed\n. ",
    "timhavens": "Error: {\"error\":\"RemoteTransportException[[node12][inet[/:9300]][indices:admin/create]]; nested: InvalidIndexNameException[[sql] Invalid index name [_sql], must not start with '']; \",\"status\":400}\nRestarted all nodes...no worky....too bad so sad\nOK Never Mind....actual SERVER OS restarts solved this.  I was thinking all the chatter about restarts folks just meant restarting ES.\nWorks now very well....impressed.\n. ",
    "perlun": "I had the same issue, also had to restart after installing. Maybe this ought to be documented in the installation instructions.\n. PR on the way.\n. ",
    "yinchuan": "same issue too.\n. ",
    "hymansun": "why i restarted all node\u2018s  OS by excute reboot command\uff0cit still display error message :  Error: {\"error\":\"InvalidIndexNameException[[sql] Invalid index name [_sql], must not start with '']\",\"status\":400} when i excute sql: SELECT * FROM \".kibana\" or SELECT * FROM .kibana.\n. The ES's version that i intalled was 1.7.0.\n. ",
    "jheimbouch": "@omershelef, if I wanted to use the string literal \"_\" in my LIKE clause, how would I do that?\nWhen it sets the _ to ?, it could match something that doesn't actually have an _. \n. I can confirm, that this does not take into account the AND.\n\nMy evaluation, would be that this is the correct output:\n\n. @bsreekanth Pull Request #49 fixes this problem.\n. As an update, I have a pending Pull Request that solves this issue.\n. Closing issue now that pull request has been merged.\n. @omershelef, I have changed it back. Apologies, I missed that when originally committing.\n. I will look into this when I get back to the office. Thanks!\n\nOn Mar 19, 2015, at 6:37 PM, Omer Shelef notifications@github.com wrote:\nThe tests when running in java 8 are still failing, if you have time, it will be nice to fix it.\nyou can see the details here: https://travis-ci.org/NLPchina/elasticsearch-sql/builds/55103049\n\u2014\nReply to this email directly or view it on GitHub.\n. @omershelef, I ran 'mvn package' on my localhost, with jdk1.8.0_40 and the build passed.\n\nI see that the TravisCI is building with 1.8.0_31. Is it possible to get that updated?\n. @ansjsun, Your only comment was \"Sent from my iPhone\" - Did you mean to include something else?\n. IS MISSING can be used in place of IS NULL\n. @KangYongKyun , thank you for finding this error. We have re-evaluated our test and you are correct. This pull request should be merged. To fix the unit test, so that your pull request gets approved, please fix the unit test here:\nsrc/test/java/org/nlpcn/es4sql/QueryTest.java\nLine 416, Column 29 - Replace '11' with '127'\n. The tests all passed locally before I committed the latest code. A screenshot can be seen here: \n\n@omershelef Can you help me determine why this fails when running against Travis CI ?\n. @omershelef could you take a look at the new implementation of the sub aggregate functionality please? I believe it meets the requirements discussed throughout this thread. Thank you.\n. ",
    "yongkyun": "@jheimbouch Thank you for your answer. I fixed the second unit test's result. \nsrc/test/java/org/nlpcn/es4sql/QueryTest.java\nLine 416, Column 29 - Replace '11' with '127'\n. You need to follow date format \nExampe : SELECT count(*) FROM logstash-2015.03.18 where @datetime between '2015-03-18T00:00:00+00' and '2015-03-18T23:59:59+00'\n. If it is possible to use format in sql query, query is converted to like this. \n{\n    \"range\" : {\n        \"@datetime\" : {\n            \"gte\": \"2015-03-18\",\n            \"lte\": \"2015-03-18\",\n            \"format\": \"yyyy-MM-dd\"\n        }\n    }\n}\n. If date field(example:@timestamp) mapping is like below \n@timestamp: {\nformat: dateOptionalTime\ntype: date\n}\nrelated documents\n- https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html\n- http://joda-time.sourceforge.net/api-release/org/joda/time/format/ISODateTimeFormat.html#dateOptionalTimeParser()\ndateOptionalTime format \nIt accepts formats described by the following syntax:\ndate-opt-time     = date-element ['T' [time-element] [offset]]\n date-element      = std-date-element | ord-date-element | week-date-element\n std-date-element  = yyyy ['-' MM ['-' dd]]\n ord-date-element  = yyyy ['-' DDD]\n week-date-element = xxxx '-W' ww ['-' e]\n time-element      = HH [minute-element] | [fraction]\n minute-element    = ':' mm [second-element] | [fraction]\n second-element    = ':' ss [fraction]\n fraction          = ('.' | ',') digit+\n. please check this issue\nhttps://github.com/NLPchina/elasticsearch-sql/issues/42\n. if you will create index like below or set mapping configuration to index, It will works like that you want.\ncurl -XPOST localhost:9200/bulk_points -d '{\n    \"mappings\" : {\n        \"point\" : {\n            \"properties\" : {\n                \"orig_hex100\" : { \"type\" : \"string\", \"index\" : \"not_analyzed\" }\n            }\n        }\n    }\n}'\nIf you will set mapping configuration after creating index and putting data, existed data in that index is not adapted to new mapping configuration. The Incomming data after setting mapping configuration is adapted to mapping configuration.\nYou must read elasticsearch's analysis and mapping.\nelasticsearch analysis : https://www.elastic.co/guide/en/elasticsearch/guide/current/analysis-intro.html#analysis-intro\nelasticsearch mapping : https://www.elastic.co/guide/en/elasticsearch/guide/current/mapping-intro.html\n. it depend on mapping information. \nIf you set filed's mapping setting like\n'{\n  \"properties\" : {\n    \"field_name\" : {\n      \"type\" :    \"string\",\n      \"index\":    \"not_analyzed\"\n    }\n  }\n}'\n, you can get result what you want.\nfield_name part must be replaced your own field name\n. ",
    "yelouati": "did you find a solution?\n. ",
    "kyunam": "I tried it but it didn't work.\n. Thank you Sir! All your replies worked.\nAlso, one correction - the one I said it didn't work (BETWEEN '2014-08-18' AND '2014-08-21'), it works.\nAs references, the followings worked.\n1.\nSELECT * FROM bulk_points/point where CREATED_DATE between '2015-03-18' and '2016-03-18'\n2.\nSELECT * FROM bulk_points/point where CREATED_DATE between '2015-03-18T00:00:00+00' and '2016-03-18T23:59:59+00'\n3.\nGET bulk_points/point/_search\n{\n  \"from\": 0,\n  \"size\": 3,\n  \"query\": {\n    \"filtered\": {\n      \"filter\": {\n        \"bool\": {\n          \"must\": {\n            \"range\": {\n              \"CREATED_DATE\": {\n                \"gte\": \"2015-03-18\",\n                \"lte\": \"2016-03-18\",\n                \"format\": \"yyyy-MM-dd\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n4.\nGET bulk_points/point/_search\n{\n    \"from\": 0,\n    \"size\": 3,\n    \"query\": {\n        \"filtered\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": {\n                        \"range\": {\n                            \"CREATED_DATE\": {\n                                \"from\": \"2015-03-18\",\n                                \"to\": \"2016-03-18\",\n                                \"include_lower\": true,\n                                \"include_upper\": true\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n5.\n{\n  \"from\": 0,\n  \"size\": 3,\n  \"query\": {\n    \"filtered\": {\n      \"filter\": {\n        \"bool\": {\n          \"must\": {\n            \"range\": {\n              \"CREATED_DATE\": {\n                \"gte\": \"2015-03-18 00:00:00\",\n                \"lte\": \"2016-03-18 00:00:00\",\n                \"format\": \"yyyy-MM-dd HH:mm:ss\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n. thanks again!\n. ah  \"not_analyzed\"!\nIt works like a charm!\nThank you!\n. Thanks for pointing this out. I was wondering about it too!\n. ",
    "haoyixin": "me, too\n. ",
    "MaheshSankaran": "am also seeing this issue.Kindly solve it.\n. ",
    "sim1st": "Long time no see.\nI want to handle result data.\nbut as a plugin, I just can see result as table.\nCould you explain where the code that printing data set in plugin web page is?\n. I'm sorry for opening same Issue.\n. ",
    "umaxfun": "Test query:\nselect * from web inner join (select * from web where props.Article like '%alfa%') qwe on web.props.Article = qwe.props.Article\nResult:\n{\"error\":\"ClassCastException[com.alibaba.druid.sql.ast.statement.SQLSubqueryTableSource cannot be cast to com.alibaba.druid.sql.ast.statement.SQLJoinTableSource]\",\"status\":500}\nAre they supported now but I use them unsupported way? :)\n. My real problem is that my index has self references. We have kind of a table\nID | Name | ReferenceToAnotherId\n1  | Jack | null\n2  | Bill | 1 -- < here 1 is a reference to the first record\nI'm trying to get how to make a query like this:\nSELECT w.ID, w.Name, o.Name \nFROM web w\nINNER_JOIN web o on w.ReferenceToAnotherId=o.ID  \nWHERE name = 'Bill'\nso that result was 1, Bill, Jack\n. Wow! It was just a typo, thank you very much for your help!\nAnd does the machinery of joins work when field type is an array? We have arrays of ids stored in one field (kind of one to many relationship). So the table above becomes this one:\nID | Name | RelatedIDs\n1  | Jack | null\n2  | Bill | null\n3  | Mary | [1,2]  -- < here is a reference to the records 1 and 2\nThe expected result after some joiny sql query I cannot imagine is:\n{ ID: 3, Name: 'Mary', SomeField: ['Jack', 'Bill'] }\nAm I missing a helper function or something?\n. Thank you :+1: \n. See https://github.com/NLPchina/elasticsearch-sql/issues/142 for resolution :)\n. ",
    "satapsa": "In Elasticsearch - when you sat 2 tables - do you mean 2 indices - where w1 is one index and w2 is another ?\n. I installed the 1.3.5 release and it solved the issue.\n. I am not getting the parsing error. However the GEO_BOUNDING_BOX is NOT filtering out the records it is supposed to\nselect * from index_name/test_locs  where GEO_BOUNDING_BOX(test_loc,35.00,-85.280000,25.00,-75.00)\nThe same in curl is filtering out the records correctly.\ncurl -XGET 'ip:9200/index_name/test_locs/_search?pretty'-d '{\"query\":{\"filtered\":{\"filter\":{\"geo_bounding_box\":{\"test_loc\":{\"top_left\": {\"lat\": 35.00,\"lon\": -85.28},\"bottom_right\": {\"lat\":  25.00,\"lon\": -75.00}}}}}}}'\nNote : test_loc is the name of the geo_point\n. Elastic seach supports this. If I run the the query( copying from explain) in \"sense\" , I get the result back for the non-aggregated fields as well.\n. I think that would work. The result will be like\ntest_loc_x test_loc_y  code  myval1\nx1             y1      47     6\nx2             y2      47     6\nx3             y3      47     6\nx4             y4      47     6\nx5             y5      47     6\nx6             y6      47     6\nx7             y7       7     1\n. Thanks a lot !! Support for \"stats\" and \"extended_stats\"  will be really helpful.\n. Can you please provide me an example ? I am on version 1.3.5. Do I need to upgrade ? Which version should I upgrade to ?\n. I donot see the max, min, sum etc coming back though\n{\"took\":45,\"timed_out\":false,\"shards\":{\"total\":4,\"successful\":4,\"failed\":0},\"hits\":{\"total\":999,\"max_score\":1.0,\"hits\":[{\"_index\":\"xxxx_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8Xbw\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"xxxx_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8Xb3\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8Xb7\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"xxxx_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8Xb\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8XcB\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8XcF\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8XcJ\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8XcN\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8XcR\",\"_score\":1.0,\"_source\":{}},{\"_index\":\"ookla_201506_1000\",\"_type\":\"locs\",\"_id\":\"AU-9VqeaORdCmoSZ8XcV\",\"_score\":1.0,\"_source\":{}},.............................\n. I donot see a aggregation section for the stats. However when I run the same for max I can see the aggregation section\n http://myIP:9200/_sql/?sql=select max(downlaod_kbps) from xxxxx/locs \n---\"aggregations\":{\"MAX(downlaod_kbps)\":{\"value\":null}}}\nSo seems 1.3.5 is not supporting stats.\n. Thanks a lot . That is great !!\n. I have to upgrade the sql plugin to 1.4.3 to access these features ?\n. Planning to check it out today. Need to upgrade the Elastic search. Can you please hold on to it till Monday ?\n. Hi Eliranmoyal\nI upgraded the sql plugin to 1.4.3. It pulls the result for the following. However it does not the Web-ui\nhttp://xx.xxx.xxx.xxx:9200/_sql?sql=select stats(download_kbps) from xxxxxx/locs\nhttp://xx.xxx.xxx.xxx:9200/_sql?sql=select stats(upload_kbps) from xxxxxx/locs\nhttp://xx.xxx.xx.xxx:9200/_sql?sql=select stats(download_kbps),stats(upload_kbps) from xxxx/locs\nhttp://xx.xxx.xx.xxx:9200/_sql?sql=select extended_stats(download_kbps),extended_stats(upload_kbps) from xxxx/locs\n. Yeap.- you are right. I can see the output now. Cool ..\nThank you very much !!\n. That is is the day part of the date. Ex if the date is 2015-09-02 00:00:00, test_date_dd is 2.\ntest_date_dd is of type 'integer' and test_date is of type 'date' of format \"YYYY-MM-dd HH:mm:ss\"\nQuery and Result below\nSELECT test_date_dd,test_date_dd,test_date_mm,test_date_yy,test_date FROM xxxxxxx/test_locs limit 2\nResults\ntest_date                        test_date_yy  test_date_mm  test_date_dd\n 2015-09-02 00:00:00     2015                     9                    2 \n2015-09-03 00:00:00      2015                     9                    3 \n. \"aggregations\":{\"MIN(test_date)\":{\"value\":1.4401152E12,\"value_as_string\":\"2015-08-21 00:00:00\"}}}\nI believe if it can return the result as \"value_as_string\", we can get the correct value for test_date.\n. SELECT test_date FROM xxxx/test_locs WHERE test_date < now-15d works fine. However when I am trying to delete am not able to\ncurl -XDELETE 'http://xxxxxx:9200/_sql?sql=SELECT test_date FROM xxxxxx/test_locs WHERE test_date < now-15d'\ncurl: (52) Empty reply from server\nIs there a delete option in the sql plugin ?\n. I am getting the following error when running the delete statement on the sql Web interface\nDELETE FROM xxxxxx/test_locs WHERE test_date < now-15d\nError:{\"error\":\"ActionRequestValidationException[Validation Failed: 1: source is missing;]\",\"status\":400} \n. Thank you\n. That will be a very good feature to have. Please let us know when it is available.\n. I am on Elasticsearch 1.7 and sql plug in 1.4.8. will the csv format availbale for the same ?\n. So I donot need to do any upgrade on the plugin and it will be availble to me now ?\n. Ok. My mistake. I had installed 1.4.3 a month ago. So I need to install 1.4.8 to access the new feature. Makes sense. Thanks\n. Does the scroll option provided by the sql plugin uses bith scroll and scan. \n SELECT /! USE_SCROLL(100,30000)/ firstname , balance FROM accounts \nIt seems the sorting should be disabled by using\n_search?search_type=scan&scroll=1m \n. Thanks Eliranmoyal\n. https://www.elastic.co/downloads/shield\nI am on Elasticsearch 1.7 and thus shield 1.0.0 was downloaded automatically.\nPlease let me know, if you have any more questions.\n. I am sending the query\nhttp://xxxxxx:9200/-u xxx -p yyy  _sql?sql=SELECT abc as my key from xxxx/xxx group by test_loc limit 0\nHowever it is returning the status all the indices and is not returning the the result as is supposed to be.\n. Hi Eliranmoyal\ni found a way around of using the ( Python) base64.encodestring(username,password) and add the request to the header and it worked.\nurl=\"http://xxxxx:9200/_sql?sql=SELECT+****++AS+mykey%2C+count%28%2A%29+AS+myval1+FROM+xxxxx%2Fxxxx+WHERE+xxxx%3E0+AND+xxxxx+in%2847%2C37%2C27%2C7%29+and+GEO_BOUNDING_BOX%28xxx%2C-93.29192853733362%2C44.98521676873701%2C-93.24924922748754%2C44.972952619045344%29+GROUP+BY+xxxx+LIMIT+0\"\nreq = urllib2.Request(url)\n    base64string = base64.encodestring('%s:%s' % (\"username\", \"password\")).replace('\\n', '')\n    req.add_header(\"Authorization\", \"Basic %s\" % base64string)\n    res=urllib2.urlopen(req)\n    print res.read()\n. Yes - indeed - I could . Thanks for the reply\n. Hi Eliranmoyal\nI am getting a date \"value\":1.4521248E12,\"value_as_string\":\"2016-01-07 00:00:00\"\nIs 1.4521248E12 in GMT, UTC or local format ?\n. \"format\":\"YYYY-MM-dd HH:mm:ss\",\n\"type\": :date\"\n. Hi Eliranmoyal\nI want the difference between the min and the max of the test date. In the example it is dealing with the the date field directly \nWhen I rin the queru separately I am getting a min - \n\"minDate\":{\"value\":1.4416704E12,\"value_as_string\":\"2015-09-08 00:00:00\"}}}\nand max - \"maxDate\":{\"value\":1.4418432E12,\"value_as_string\":\"2015-09-10 00:00:00\"\nSo the date difference should be 2\nHowever am not getting the result in the query below.\nSELECT min(test_date) as minDate,max(test_date) as maxDate, script('diffInDays','(doc[\\'minDate\\'].value - doc[\\'maxDate\\'].value)/3600/24*10000000000) FROM xxx/test_locs\nIs there a way around it ?\nThanks for your help in advance.\n. Thanks a lot for your quick reply.\n. Hi Eliranmoyal\nJust wanted to update you that the query is taking a long time . we are looking for 20000 records. Is there a way to improve the speed ?\n. Hi Eliranmoyal\nGood to know this option. I ran the query for another field. The value is all in Capital letters.\nIt looks like group by doesnot work, when the field is analysed only.\n\"cell_id\": {\n\"type\": \"string\"\n}\n_Result with the above definition _\nThe follwing works\nSELECT * from xxxx/test_locs where cell_id like 'sm*' limit 5\nFollowing Doesnot work\nSELECT count(cell_id) cellCnt, cell_id from xxx/test_locs where cell_id like 'sm*' group by cell_id\n\n\"cell_id\": {\n\"index\": \"not_analyzed\",\n\"type\": \"string\"\n}\n_Result with the above definition _\nFollowing does not work\nSELECT * from xxxx/test_locs where cell_id like 'sm*'\nFollowing Works\nSELECT * from xxxtest_locs where cell_id like 'SM*'\nFollowing Works\nSELECT count(cell_id) cellCnt, cell_id from xxxxi/test_locs where cell_id like 'SM*' group by cell_id\n. select  distinct(field_name)  FROM xxx/xxx \n. Thanks for the quick response. \nIs \"median\" supported ? I tried stats and extended_stats, but cannot find it.\n. If I want to pick only the percentiles 95 and 99, how can I specify the same in the query ?\n. What is the target date for the next version ? Will it be for Elastcsearch 1.7 as well ?\n. Thanks a lot !!\n. Getting no result back for this like\nSELECT * from xxx/xxx  where fields_name Like 'SM-G%'\nThe field values are like\nSM-G900V\nSM-G920V\n. This doesnot work\nselect count(t.*) as counts,sum(t.size) from xxx/locs t\n. Got a result for count , but not for size\nselect count(*) as counts,sum(t.size) from xxx/locs t\n. what will be the sql plugin version for this ?\n. I am on sql plugin version 1.4.8 and Elasticsearch 1.7. Are the values in MULTIPLOYGON  in lat, lon format ?\nSELECT * FROM xxx WHERE GEO_INTERSECTS(location,'MULTIPOLYGON (((-106.137103  31.662889,-106.124132  31.656255,106.095866  31.634966)),\n((-106.263776  31.666654,-106.242391 31.673099,-106.204974 31.554178)))')\nlocation is defined as a geo_point\nGetting the following error\n Error: {\"error\":\"SqlParseException[couldn't create shapeBuilder from wkt: 'MULTIPOLYGON (((-106.137103 31.662889,-106.124132 31.656255,106.095866 31.634966)), ((-106.263776 31.666654,-106.242391 31.673099,-106.204974 31.554178)))']\",\"status\":500}. ",
    "norberto-enomoto": "What is the roadmap to have the plugin support for Elasticsearch 1.5.x?\n. ",
    "yehosef": "+1\n. ",
    "mastermind1981": "Thanks it works \n. ",
    "ottboy4": "Omer,\nI will be taking over what @jheimbouch was working on.\nWhat are your thoughts on adding an aggregate function to do what we are looking for? For example, something like AGG(). This way, it would follow the same pattern as other aggregate functions in the SQL syntax.\nSome examples would be...\nSELECT firstname, lastname, gender, state, AGG(state, gender) FROM myindex\nWhere this would add in the aggregates state \u2192 gender and not affect anything else. \nSELECT firstname, lastname, gender, state, AGG(state, gender), AGG(firstname, lastname) FROM myindex\nHere it is getting the aggregate of two different high level aggregates.\nSELECT firstname, lastname, gender, state, AGG(gender) FROM myindex GROUP BY state, gender\nHere is an agg with a group by as well.\nThis way shows the AGG function similar to other aggregate functions like COUNT, AVG, etc. The only difference is unlike those others, the AGG function would not add a new column to the result.\nWe were simply looking for a better alternative for how to implement the multi-leveled aggregates. If the aggregate function approach doesn't work, we can continue the approach of putting it in the group by.\nThanks,\nCaleb\n. @omershelef, have you had a chance to review this last update yet? Thanks!\n. @omershelef, Have you had a chance to view this yet?\nAlso, after this gets merged, can you cut a 1.3.6 release?\n. @omershelef, Have you been able to review this update?\nThanks!\nCaleb\n. @eliranmoyal, No problem! My changes should all be merged properly now.\nThanks!\n. Done! Thanks.\n. Great! Appreciate it!\n. I'm open to whatever works best; however, I could see it being implemented in a similar way to the way  /! USE_SCROLL / is implemented.\nSomething maybe like this...\nSELECT /*! HIGHLIGHT(fields_to_highlight, options) */ * FROM index\nMore realistic example...\nSELECT /*! HIGHLIGHT(firstname, fragment_size: 150, number_of_fragments: 3) */ firstname , balance FROM accounts\nAnother option could be, add in support only for the REST API and add the ability to pass JSON as the request body and have a \"sql\" field with the sql query and then be able to do a separate \"highlight\" field that allows for the highlight options from elastic to be passed in.\nThen the JSON request could look like...\n{\n   \"sql\": \"SELECT firstname, balance FROM accounts\",\n   \"highlight\" : {\n        \"fields\" : {\n            \"firstname\" : {\n                \"fragment_size\" : 150,\n                \"number_of_fragments\" : 3,\n                \"no_match_size\": 150\n            }\n        }\n    }\n}\nThe JSON option could add some nice functionality for easily adding other elastic features as well.\nI believe this would be a nice addition of functionality, so I am just throwing out some ideas on how it could be implemented.\n. Awesome thanks!\n. Awesome! This is great to hear!\nIs there anywhere in the wiki that documents how to do this?\n. Awesome. Thanks!\n. @ansjsun I am not understanding why the \"-\" cannot be used. Is there some documentation explaining how it is a keyword you can provide me with a link to?\nEither way, having an \"exclude\" function which adds fields to the exclude would work for me as well.\n. @ansjsun, thanks for the explanation.\nThe include/exclude syntax will work for what I need. Thanks!\nIs this change documented in the Wiki?\n. I updated this wiki page to show the syntax for the include/exclude.\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Basic-Queries-And-Conditions\n. So the include/exclude is working great for queries that do not use aggregations; however, in a query like the one below, they do not work.\nCan the logic be updated to allow include/exclude in aggregation queries as well?\nSELECT \n/*! DOCS_WITH_AGGREGATION(0, 20) */\ninclude('*Name'), exclude('lastName') \nFROM table\nGROUP BY gender\nI believe it should be an easy quick change. Basically the changes made in DefaultQueryAction just need to be done also in the AggregationQueryAction.\n. Will Elastic 5.2.0 (and newer versions) be supported going forward as a plugin (without the site)? I am purely looking for the plugin's API support (_sql). Or is all support switching over to the elasticsearch-site?\n@eliranmoyal . ",
    "dmfenton": ":+1: This would be awesome. I'm currently considering installing this package just to use the explain functionality.\n. I would say that you should just default to this search type without exposing it the the end user.\nAlso, the number of results returned in each scroll is shards * scroll size. In testing this, I came up with a scroll size of 40. With 5 shards that gives me 200 rows per request. The performance worked well for the specific type of data I was storing. See this PR: https://github.com/koopjs/koop-escache/pull/5\n. This works for me :+1: \nThanks for the great work!\n. :fireworks: Awesome!!\n. ",
    "robertogyn19": "Great job with the support to GeoShape Filter.\nAre there any plans to add support for Geo Polygon Filter?\n. ",
    "mlc0202": "thanks,it settle up my problem \n. ",
    "raviv": "Hi Omer,\nYou're right. There was a different problem in my query.\nThanks,\nRaviv.\n. ",
    "oryband": ":+1: @motida @ofir-petrushka\n. ",
    "vivekkothari": "Yes.. thats exactly what i need!!\n. ",
    "OpakAlex": "@eliranmoyal thanks for not support :)\nIt's not SQL, it's not DB :))))\n. ",
    "aitanjupt": "yes, its elasticsearch's issue. thank you for your information.\n. ",
    "micxba": "Apologies, I gave a bad query as an example. The index name does not have spaces but the fields so a better RDBMS equivalent would be Select [field name] from index where x=y\n. ",
    "neerajgupta2407": "thanks . It works.\nwhere column not in ('xyz') is also working.\nThanks for this awesome plugin.\n. ",
    "mastizada": "in operator can search for items with 'a' or 'd', but there is no operator for searching 'a' and 'd'\n. Sorry, adding properties = 'a' and properties = 'd' gives exact result. Just got error when tried this one, but  then realized that is was typo error.\n. ",
    "robertsmarty": "Excited. Thanks!\n. Thank you and happy new year!\n. ",
    "cch123": "thank you for yr help,\nmaybe it's because our Chinese network environment,\ni download it and solved by your solution\nthx!\n. ",
    "clover1983": "yes\nI use rest API to query SQL from elasticsearch just like http://xxxx:9200/_sql?sql=select * from x\nbut the result is show in nested json.\nHow I get the result ouput like csv??\n. YES\nalso I want all the results query by rest api show as csv format\n. Thank you for your help, eliranmoyal\n. ",
    "tigerone1": "thanks,I got it after read your code\n. Thanks\n. OK\uff0cThank you very much\n. Thank you very much,I will test it.Proud of your work\n. ",
    "felixbuenemann": "It's probably not worth implementing it if it's not trivial. I'll close this.\n. ",
    "mohaneldia": "i have a constrain that whatever the query is i have to search in particular indexes only. for that i changed the indeces returned from searchDao. but in subquery scenario, this cant be done right?. As of now i have only one work around, which is parse the query string my self and change it before searchDao.explain.\n. any update on this issue?\n. that means it won't work in the release 1.4.7?\n. 1.will this hint will be available in the future releases?\n2.will this hint works in subquries?\n. thanks\n. +1\n. ",
    "chendo": "Hint works for me!\nWe're using 1.4.5 (a bit behind).\nThanks! :D \n. Fantastic, thanks for the quick turnaround! Will hopefully get to try it some time today.\n. Confirmed that it works, thanks again!\n. ",
    "BrettHolton": "ElasticSearch 1.7.3\n. I did not have the latest version, closing and taking a nap :)\n. ",
    "ighack": "If I have more then two fields.\nHow can I do that. {\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"filter\": []\n        }\n    },\n    \"aggregations\": {\n        \"14bb868d\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"term\": {\n                                \"KPI\": \"\u6761\u76ee\u6570\"\n                            }\n                        }\n                    ]\n                }\n            },\n            \"aggregations\": {\n                \"agg_value\": {\n                    \"sum\": {\n                        \"field\": \"Number_Value\"\n                    }\n                }\n            }\n        },\n        \"f1a4e828\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"term\": {\n                                \"KPI\": \"\u4ef6\u6570\"\n                            }\n                        }\n                    ]\n                }\n            },\n            \"aggregations\": {\n                \"agg_value\": {\n                    \"sum\": {\n                        \"field\": \"Number_Value\"\n                    }\n                }\n            }\n        }\n    }\n}\nI want translate this to SQL. Properties properties = new Properties();\n            properties.put(PROP_URL, \"jdbc:elasticsearch://10.3.87.33:9300/\" + \"audit-2018-07-11\");\n            properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n            DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n            Connection connection = dds.getConnection();\n            PreparedStatement ps = connection.prepareStatement(\"SELECT  * from  \" + \"audit-2018-07-11\" + \" where applicationName='jzt'\");\n            ResultSet resultSet = ps.executeQuery();\n            List<String> result = new ArrayList<String>();\nI block on Connection connection = dds.getConnection();\nI don't get error\nversion 5.4.1.0\n\u6211\u963b\u585e\u5728Connection connection = dds.getConnection();\n\u6ca1\u6709\u53cd\u5e94\uff0c\u4e5f\u6ca1\u6709\u629b\u9519\u8bef\n. Properties properties = new Properties();\n            properties.put(PROP_URL, \"jdbc:elasticsearch://10.3.87.33:9300/operator_warehouse_data\");\n            properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n            DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n            Connection connection = dds.getConnection();\n\n2019-01-30 11:40:32.136 ERROR 5216 --- [reate-686591159] com.alibaba.druid.pool.DruidDataSource   : create connection error\njava.lang.NoSuchFieldError: createErrorCount\n  at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:655) ~[elasticsearch-sql-6.5.4.0.jar:na]\n  at com.alibaba.druid.pool.ElasticSearchDruidDataSource$CreateConnectionThread.run(ElasticSearchDruidDataSource.java:1841) ~[elasticsearch-sql-6.5.4.0.jar:na]\n\nelasticsearch 6.5.4\ndurid 1.1.12\ntransport 6.5.4. \u6211\u4e5f\u9047\u5230\u8fd9\u4e2a\u95ee\u9898\u5c31\u662f\u505c\u5728\u4e86Connection connection = dds.getConnection();\n\u6309\u7167shi-yuan\u8bf4\u7684\u7528TransportClient\u8bd5\u4e00\u4e0b\u3002\u662f\u6ca1\u95ee\u9898\n\u8bd5\u5b8c\u4e86\u5728\u53bbdds.getConnection();\u4e00\u6b63\u5e38\u4e86\uff0c\u4e0d\u77e5\u9053\u662f\u4e2a\u4ec0\u4e48\u539f\u7406. culod support SUM(IF(KPI='1',Number_Value,0))?. {\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"filter\": []\n        }\n    },\n    \"aggregations\": {\n        \"14bb868d\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"term\": {\n                                \"KPI\": \"\u6761\u76ee\u6570\"\n                            }\n                        }\n                    ]\n                }\n            },\n            \"aggregations\": {\n                \"agg_value\": {\n                    \"sum\": {\n                        \"field\": \"Number_Value\"\n                    }\n                }\n            }\n        },\n        \"f1a4e828\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"term\": {\n                                \"KPI\": \"\u4ef6\u6570\"\n                            }\n                        }\n                    ]\n                }\n            },\n            \"aggregations\": {\n                \"agg_value\": {\n                    \"sum\": {\n                        \"field\": \"Number_Value\"\n                    }\n                }\n            }\n        }\n    }\n}\nI want translate this to SQL. if I have to fields or more\nlike\nscript('14bb868d','\"\u6761\u76ee\u6570\".equals(doc[\"KPI\"].value)?1:0') \nand \nscript('14bb868d','\"\u6761\u76ee\u65701\".equals(doc[\"KPI\"].value)?1:0'). yes I need add <!-- https://mvnrepository.com/artifact/com.google.guava/guava -->\n<dependency>\n    <groupId>com.google.guava</groupId>\n    <artifactId>guava</artifactId>\n    <version>27.0-jre</version>\n</dependency>\nin pom.xml\n\u662f\u7684\u6211\u9700\u8981\u6dfb\u52a0\u8fd9\u4e2a\u4f9d\u8010\n\u4e3a\u4ec0\u4e485.4.1\u7684\u6ca1\u6709\u653e\u5230maven\u3002\u6211\u662f\u76f4\u63a5\u628a\u4f60\u7684jar\u6dfb\u52a0\u5230\u81ea\u5df1\u7684\u9879\u76ee\u4e2d\u7684\u3002\n\u6240\u4ee5\u603b\u5dee\u5305. `\norg.elasticsearch.client\ntransport\n5.4.1\n\n    <dependency>\n        <groupId>org.elasticsearch</groupId>\n        <artifactId>elasticsearch</artifactId>\n        <version>5.4.1</version>\n    </dependency>\n\n https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-api \n\norg.apache.logging.log4j\nlog4j-api\n2.6.2\n\n    <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-to-slf4j -->\n    <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-to-slf4j</artifactId>\n        <version>2.6.2</version>\n    </dependency>\n\n    <!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-simple -->\n    <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>slf4j-simple</artifactId>\n        <version>1.7.21</version>\n        <scope>test</scope>\n    </dependency>\n    <!-- https://mvnrepository.com/artifact/com.google.guava/guava -->\n    <dependency>\n        <groupId>com.google.guava</groupId>\n        <artifactId>guava</artifactId>\n        <version>27.0-jre</version>\n    </dependency>`\n\n\u8fd9\u6837\u6dfb\u52a0\u53ef\u4ee5\u8fd0\u884c\u4f46\u8fd8\u662f\u6709\n\nc.a.d.p.v.MySqlValidConnectionChecker : Cannot resolve com.mysq.jdbc.Connection.ping method. Will use 'SELECT 1' instead.\njava.lang.NullPointerException: null\nat com.alibaba.druid.pool.vendor.MySqlValidConnectionChecker.(MySqlValidConnectionChecker.java:48) ~[druid.jar:1.0.15]\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.initValidConnectionChecker(ElasticSearchDruidDataSource.java:880) [elasticsearch-sql-5.4.1.0.jar:na]. ` Properties properties = new Properties();\n            properties.put(PROP_URL, \"jdbc:elasticsearch://10.3.87.33:9300,10.3.87.211:9300,10.3.87.209:9300/\" + \"operator_stock_data\");\n            properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n            DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n            Connection connection = dds.getConnection();\n//            String sql1 = \"select Con_Name , sum(Number_Value) from operator_stock_data where (Operation_Type='\u8d2d\u8fdb\u5165\u5e93') and (KPI='\u4ef6\u6570' or KPI='\u6761\u76ee\u6570')\";\n            PreparedStatement ps = connection.prepareStatement(sql);\n            ResultSet resultSet = ps.executeQuery();\n            List> result = new ArrayList<>();\n\n        while (resultSet.next()) {\n            List<String> _data = new ArrayList<>();\n            for(int i=0;i<esResult.getColumnList().size();i++){\n                _data.add(String.valueOf(resultSet.getObject(esResult.getColumnList().get(i).getName())));\n            }\n            result.add(_data);\n        }`\n\n\u6ca1\u6709\u5728application.properties\u914d\u4e1c\u897f. driverClassName\n\u6211\u4e5f\u4e0d\u77e5\u9053\u8fd9\u4e2a\u914d\u4ec0\u4e48\u4e1c\u897f\uff0c\u6240\u4ee5\u5c31\u6ca1\u914d\u4efb\u4f55\u4e1c\u897f\nselect Con_Name,Goods_Type , SUM(Number_Value + Number_Value) AS FF  from operator_warehouse_data where (Operation_Type='\u8d2d\u8fdb\u5165\u5e93') and (KPI='\u4ef6\u6570' or KPI='\u6761\u76ee\u6570') group by Con_Name,Goods_Type\n\u4e0d\u77e5\u9053\u8fd9\u6837\u5199\u5bf9\u4e0d\u5bf9\u3002FF\u5b57\u6bb5\u603b\u662f0\nSUM(Number_Value)\u8fd9\u4e2a\u662f\u6709\u503c\u7684\nSUM(Number_Value) + 1  \u6211\u8fd8\u8fd9\u6837\u8bd5\u4e86\u4e00\u4e0b\uff0c\u4f46\u62a5\u9519\u4e86\n\nError: {\"error\":{\"root_cause\":[{\"type\":\"null_pointer_exception\",\"reason\":null}],\"type\":\"null_pointer_exception\",\"reason\":null},\"status\":500}. \u6211\u60f3\u95ee\u7684\u662f\nselect Con_Name,Goods_Type , SUM(Number_Value + Number_Value) AS FF from operator_warehouse_data where (Operation_Type='\u8d2d\u8fdb\u5165\u5e93') and (KPI='\u4ef6\u6570' or KPI='\u6761\u76ee\u6570') group by Con_Name,Goods_Type\nFF\u5b57\u6bb5\u603b\u662f0\n\n\u8fd9\u4e00\u53e5\u4f1a\u62a5\u9519\nSUM(Number_Value) + 1 \n\nError: {\"error\":{\"root_cause\":[{\"type\":\"null_pointer_exception\",\"reason\":null}],\"type\":\"null_pointer_exception\",\"reason\":null},\"status\":500}\n\n\u662f\u4e0d\u662f\u53ea\u6709\u65b0\u7248\u672c\u624d\u80fd\u7528\u4e0a\u9762\u4e24\u53e5\u8bdd\n\u6211\u7684\u662fES:5.4.1. > c.a.d.p.v.MySqlValidConnectionChecker : Cannot resolve com.mysq.jdbc.Connection.ping method. Will use 'SELECT 1' instead.\n\njava.lang.NullPointerException: null\n\u6211\u4e0d\u60f3\u51fa\u73b0\u8fd9\u4e2a\u9519\u8bef\u6539\u600e\u4e48\u914d\u554a\uff0c\u7f51\u4e0a\u8bf4\u4e0d\u914dspring.datasource.validationQuery\u5c31\u62a5\u9519\nspring.datasource.validationQuery=SELECT KPI FROM operator_warehouse_data limit 1\n\u914d\u6210\u8fd9\u6837\u8fd8\u662f\u4e0d\u884c\nspring.datasource.url=jdbc:elasticsearch://10.3.87.33:9300,10.3.87.211:9300,10.3.87.209:9300/operator_warehouse_data\n\u8fd9\u4e2a\u80fd\u4ee3\u66ff\nproperties.put(PROP_URL, \"jdbc:elasticsearch://10.3.87.33:9300,10.3.87.211:9300,10.3.87.209:9300/\" + \"operator_stock_data\");\n\u8fd9\u4e2a\u5417\uff1f. \n",
    "shi-yuan": "```sql\nselect sum(script('14bb868d','\"\u6761\u76ee\u6570\".equals(doc[\"KPI\"].value)?1:0')) as '14bb868d',sum(script('f1a4e828','\"\u4ef6\u6570\".equals(doc[\"KPI\"].value)?1:0')) as 'f1a4e828' from yourIndex\n`. have a look at issue [SELECT distinct --- Repeat error](https://github.com/NLPchina/elasticsearch-sql/issues/266)\n. try \n`SELECT count(*) FROM jupiter  where ['/user/car_info/budget'] =in_terms(\"a\") group by `/user/car_info/budget\nIssue #254 may help you\n. Do you mean Join  ?\n. Support SQL Order By, see Basic Queries And Conditions\n. Which version? Can you tell me more information?\nI use es 2.3.4, no problem.\n. I try es 2.3.1:\nhttp://localhost:9200/_sql?format=csv&sql=select name from test\nno problem.\nCan you give me es error logs?\n. Thanks! If you want, you can make a pull request!\n. Sorry\uff01I will fix it\uff01\n. Do you startup es? \nDo you install delete-by-query plugin?\n. We plan to support release version.\nIf you want to support ES version 5.0.0-alpha, you can change elasticsearch.version in pom.xml, then package and install it.\n. have a look at the Scriptable Metric Aggregation\n. \u53ef\u4ee5\u4f7f\u7528Pipeline Aggregations\uff0c\u6216\u8005\u5728Scripted Metric Aggregation\u7edf\u8ba1terms\u7684doc_count. Scripted Metric Aggregation ?  Have a look at #490\uff0cmay be of help to you. try\nsql\nSELECT nested(categories.list.persons.details.person_date_registration), \n       nested(categories.list.persons.details.person_date_subscription), \n       nested(categories.list.persons.details.person_id)\nFROM index/type\nWHERE nested(categories.list.persons.details.person_id)=\"50\"\nyou can see query-nested-fields\n. you can have a look at Nested datatype\n. you can set \"_source\": false \nyou can see Source filtering\n. Isn't it select * FROM myindex ?\n. Not supported currently. \nBut you can use ScriptQuery, like:\nSELECT * FROM myindex where script('1 == 1')\n. you can enable script\n. Add script.engine.groovy.inline.search: on to elasticsearch.yml configuration file and restart the node\n. try select count(parts.partId) from cars/car\nHave a look at Object datatype and Nested datatype\n. Thanks ! Which version ? I will modify it:\nprivate List<String> createCSVLinesFromDocs(boolean flat, String separator, List<Map<String, Object>> docsAsMap, List<String> headers) {\n        List<String> csvLines = new ArrayList<>();\n        if (headers == null || headers.isEmpty()) {\n            return csvLines;\n        }\n        for(Map<String,Object> doc : docsAsMap){\n            String line = \"\";\n            for(String header : headers){\n                line += findFieldValue(header, doc, flat, separator);\n            }\n            csvLines.add(line.substring(0, line.length() - 1));\n        }\n        return csvLines;\n    }\n. You can eliminate duplicates using aggregations\nWith terms aggregation the results will be grouped by one field\ntry\nSELECT userId FROM logstash-api-access-2016.08.17 where ip = '112.65.191.239' group by userId\n. es support Finding Distinct Counts\nFind distinct values, use Terms Aggregation. And you need to pay attention to how that field you want to get distinct values on is analyzed, meaning you need to make sure you're not tokenizing it while indexing, otherwise every entry in the aggregation will be a different term that is part of the field content.\n. If you want to get the 'UI''s result or get the result which has the field 'x', you should parse the json result\nby yourself.\n. @allwefantasy  That's cool!\nCould you please add features.md to wiki ?\n. @WilsonHo Maybe it's really related to Node.js\nI think you are wrong to use request\nhave a look at Why one connection per request\n. @missynh not supported now. Now support PreBuiltXPackTransportClient, connectionProperties\uff1a\n```java\npackage org.nlpcn.es4sql;\nimport com.alibaba.druid.pool.DruidDataSource;\nimport com.alibaba.druid.pool.ElasticSearchDruidDataSourceFactory;\nimport org.junit.Test;\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Properties;\nimport static com.alibaba.druid.pool.DruidDataSourceFactory.PROP_CONNECTIONPROPERTIES;\nimport static com.alibaba.druid.pool.DruidDataSourceFactory.PROP_URL;\npublic class JDBCTests {\n@Test\npublic void testJDBC() throws Exception {\n    Properties properties = new Properties();\n    properties.put(PROP_URL, \"jdbc:elasticsearch://127.0.0.1:9300/\" + TestsConstants.TEST_INDEX_ACCOUNT);\n    properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true;xpack.security.user=elastic:elastic\");\n    try (DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n         Connection connection = dds.getConnection();\n         PreparedStatement ps = connection.prepareStatement(\"SELECT  gender,lastname,age from  \" + TestsConstants.TEST_INDEX_ACCOUNT + \" where lastname='Heath'\");\n         ResultSet resultSet = ps.executeQuery()) {\n\n        List<String> result = new ArrayList<>();\n        while (resultSet.next()) {\n            result.add(resultSet.getString(\"lastname\") + \",\" + resultSet.getInt(\"age\") + \",\" + resultSet.getString(\"gender\"));\n        }\n\n        System.out.println(result);\n    }\n}\n\n}\n```. \u55ef\uff0c\u73b0\u5728\u4e0d\u652f\u6301ps.setXXX\u7684. @harveysun \uff0c\u7528\u7684\u90a3\u4e2a\u7248\u672c\uff1f. \u90a3\u4e2a\u7248\u672c\u6709bug\uff0c\u53ef\u4ee5\u53c2\u8003ElasticSearchResultSetMetaDataBase.java\u6539\u6539. \u54c8\u54c8\u54c8\uff0c\u5fd8\u4e86\uff0c\u60a8\u53ef\u4ee5\u5728\u8fd9\u4e2a\u6587\u4ef6\u4e0ashow log\uff0c\u770b\u770b\u54c8. \u4e0d\u80fd\u554a\uff0c\u6ca1\u6709\u6743\u9650\u5462\uff0c :joy:. \u6ca1\u6709\u7684\uff0c\u672c\u63d2\u4ef6\u662f\u501f\u52a9druid\u7684\uff0c\u5b98\u65b9\u7684es-sql\u662f\u7528\u7684antlr4. \u96c6\u6210elasticsearch-sql\u548cmybatis. For example\uff0cjdbc:elasticsearch://192.168.1.10:9300,192.168.1.11:9300,192.168.1.12:9300/index. elasticsearch\u548cx-pack-transport\u7684\u7248\u672c\uff0c\u90fd\u75286.4.1\uff0c\u8bd5\u8bd5. \u67e5\u8be2\uff0ccolumns\u662f\u76f4\u63a5\u53d6\u7684\u8fd4\u56desource\u91cc\u7684key\uff0c\u800c\u4e14\u7528\u7684hashset\u505a\u7684merge\uff0c\u5bfc\u81f4\u987a\u5e8f\u4e0d\u4e00\u81f4. \u8fd9\u4e2a\u53ef\u4ee5\u5355\u72ec\u63d0\u4e2aissue\uff0c\u8003\u8651\u652f\u6301\u4e0b. \u770b\u5f02\u5e38\u5806\u6808\uff0c\u662fcom.alibaba.druid.pool.ElasticSearchConnection#getMetaData\u8fd4\u56denull\u5bfc\u81f4\u7684\n\u5173\u6389management.health.db.enabled\uff0c\u672c\u5730\u6d4b\u8bd5\uff0c\u662f\u53ef\u4ee5\u7684\uff1a\n```java\n@Bean(name = \"esDruidSource\", initMethod = \"init\", destroyMethod = \"close\")\npublic DruidDataSource esDruid() throws Exception {\n    System.setProperty(\"es.set.netty.runtime.available.processors\", \"false\");\n    Properties properties = new Properties();\n    properties.put(\"url\", \"jdbc:elasticsearch://127.0.0.1:9300/elasticsearch/\");\n    properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n    return (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n}\n/\n * \u4ec5\u4e3a\u6d4b\u8bd5\u4f7f\u7528\n /\n@Bean\npublic String test(DruidDataSource druidDataSource) {\n    // \u9a8c\u8bc1esDruidSource\n    new JdbcTemplate(druidDataSource).execute(\"SELECT COUNT() FROM test\", (PreparedStatementCallback) ps -> {\n            try (ResultSet resultSet = ps.executeQuery()) {\n                while (resultSet.next()) {\n                    System.out.println(\"===================================\");\n                    System.out.println(resultSet.getObject(1));\n                    System.out.println(\"===================================\");\n                }\n            }\n        return null;\n    });\n\nreturn null;\n\n}\n. \u672c\u63d2\u4ef6\u662f\u501f\u52a9\u7684[druid](https://github.com/alibaba/druid). org.nlpcn.es4sql.domain.Select#DEFAULT_ROWCOUNT. [2.4.0](https://github.com/NLPchina/elasticsearch-sql/releases/tag/2.4.0.0) is released!\n. Support '<>' operator\uff0cuse '<>' instead\n. Support '<>' operator, see [issue](https://github.com/NLPchina/elasticsearch-sql/issues/289)\n. [Join](https://github.com/NLPchina/elasticsearch-sql/wiki/Join) may be helpful to you\n.sql\nSELECT sum(num_d) as num2, split(newtype, [',']) as nt\nfrom twitter2\ngroup by nt\norder by num2\n. I'll try it, but i'm not sure. plugin version [2.4.2.1](https://github.com/NLPchina/elasticsearch-sql/releases/download/2.4.2.1/elasticsearch-sql-2.4.2.1.zip), support.sql\nselect * from account where name = regexp('ha.', 'INTERSECTION|COMPLEMENT|EMPTY', 10000)\n. Now support elasticsearch 2.x. I'll add it soon! . [regex support](https://github.com/NLPchina/elasticsearch-sql/commit/f03f83742a7045348a922be7e63c7e6c1f52a091).sql\nselect longitude_latitude_name as name,count() as value from event_20161215 group by name order by value desc\n```. fields contains name. see http response:\n\n. Ah, mine is 2.3.1.0. There may be a problem with your version.\nYou can check to branch elastic2.4.2, then change elasticsearch.version to 2.3.5 in pom.xml, and package it.\nMy test: \nhttp://localhost:9200/_sql/_explain?sql=select%20longitude_latitude_name%20as%20name%20from%20event_20161215\n\n. \u8fd9\u4e2a\u8b66\u544a\u4e0d\u5f71\u54cd\u8fd0\u884c\uff0c\u8981\u89e3\u51b3\u7684\u8bdd\uff0c\u53ef\u4ee5\u624b\u52a8\u6dfb\u52a0package.json\u6587\u4ef6\uff0c\u5e76\u52a0\u4e0a\njson\n{\n  \"dependencies\": {\n    \"express\": \"^4.14.0\"\n  }\n}. \u90fd\u662f\u9759\u6001\u9875\uff0c\u4efb\u610f\u4e00\u4e2ahttp\u670d\u52a1\u5668\u5c31\u80fd\u8fd0\u884c\u3002\n\u5982\u679c\u7528golang\u5199\uff0c\u662f\u4e0d\u662f\u5f04\u590d\u6742\u4e86\u5462. Issue#350 may help you. The warning does not affect.\nTo resolve it, you can add es-sql-site/site-server/package.json:\njson\n{\n  \"dependencies\": {\n    \"express\": \"^4.14.0\"\n  }\n}. As far as I know, elasticsearch doesn't support subqueries. \nyou would need to perform your first query, then construct a second query using the results of the first query as an input. sql\nSELECT * FROM test/dog WHERE holdersName IN (SELECT firstname FROM test/account WHERE firstname = 'Hattie') AND age IN (SELECT name.ofHisName FROM test/gotCharacters WHERE name.firstname <> 'Daenerys'). sql\nselect sum(mydata)from ourdata where fullPathForSearch like '\\\\\\\\test\\\\\\\\test&UNDERSCOREdata\\\\\\\\this is test\\\\\\\\*'. enable cors and set http.cors.allow-origin. In my opinion, it's right to enable cors on elasticsearch.yml. It is a good idea. Http request add header: \njavascript\n{\n    headers: {\n        \"Authorization\": \"Basic \" + window.btoa(username + \":\" + password)\n    }\n}. Thanks, I'll add it soon.. you can download elasticsearch-sql-2.3.5.0.zip\nor\nyou can check to branch elastic2.4.0, then change elasticsearch.version to 2.3.5 and package it by youself. now branch \"master\" support elasticsearch v5.x. Issue #349 may help you . Using Elasticsearch HTTP/REST Clients with Shield may be useful to you. https://github.com/NLPchina/elasticsearch-sql/releases/tag/5.2.0.0. have a look at \u6267\u884c delete \u8bed\u53e5\u62a5\u9519. java\npublic class JDBCTests {\n    @Test\n    public void testJDBC() throws Exception {\n        Properties properties = new Properties();\n        properties.put(PROP_URL, \"jdbc:elasticsearch://11.123.523.777:7300/myindex\");\n        properties.put(PROP_CONNECTIONPROPERTIES, \"cluster.name=mycluster\");\n        DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n        dds.setInitialSize(1);\n        Connection connection = dds.getConnection();\n        PreparedStatement ps = connection.prepareStatement(\"SELECT * from myindex\");\n        ResultSet resultSet = ps.executeQuery();\n        while (resultSet.next()) {\n            System.out.println(resultSet.getString(\"username\"));\n        }\n        ps.close();\n        connection.close();\n        dds.close();\n    }\n}. sql\nselect t.id from studentView t where t.id <>''. Join. json\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"_source\": {\n        \"includes\": [],\n        \"excludes\": []\n    },\n    \"script_fields\": {\n        \"IN_DATE\": {\n            \"script\": {\n                \"inline\": \"def date_format_1009785701 = new SimpleDateFormat('yyyyMMddHHmm').format(new Date(doc['a.IN_DATE'].value - 8*1000*60*60));return date_format_1009785701;\",\n                \"lang\": \"painless\"\n            },\n            \"ignore_failure\": false\n        }\n    }\n}. mac\u5b57\u6bb5\uff0c\u7528\u4e86\u54ea\u4e2aanalyzer\uff1f\u4e0d\u662fkeyword\u5427\uff1f. sql\nSELECT * FROM A_index as A\n join B_index as B on A.col3 = B.col3\n where ['B.@timestamp']>1491580800000 AND ['B.@timestamp']<1492444800000. have a look at JDBCTests. The name field uses the standard analyzer\uff1f. \u7528Script Query. sql\nselect * from trip where status.keyword = term('SUCCESS') and script('!Objects.equals(doc[\"startSite\"].value,doc[\"endSite\"].value)'). https://github.com/NLPchina/elasticsearch-sql/wiki/Installation-Guide#for-5x. sql\nSELECT * FROM elasticsearch-sql_test_index_nested_type ORDER BY NESTED('message.info','message')\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"sort\": [\n    {\n      \"message.info\": {\n        \"order\": \"asc\",\n        \"nested\": {\n          \"path\": \"message\"\n        }\n      }\n    }\n  ]\n}. \u6587\u4ef6\u53e5\u67c4\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u5c1d\u8bd5\u7528File Leak Detector\u6392\u67e5\u4e00\u4e0b. https://github.com/NLPchina/elasticsearch-sql/pull/756. Have you add authentication to request headers\uff1f. sql\nSELECT * FROM location WHERE GEO_INTERSECTS(place,'MULTIPOLYGON (((30 20, 45 40, 10 40, 30 20)),\n((15 5, 40 10, 10 20, 5 10, 15 5)))'). sql\nSELECT insert_es_time,event_time FROM log_20170613 where script('doc[\"insert_es_time\"].value - doc[\"event_time\"].value < 180000'). elasticsearch.yml:\nyml\nscript.inline: true\nscript.indexed: true. sql\nselect ne_id, script('ne_type','10004')  from log_20170613. \u662fobject\u8fd8\u662fnested\uff1f. NestedTypes-queries. \u8fd9\u4e2a\u5730\u5740\uff0c\u6539\u4e86\u5417\uff1f\n\n. \u8fd9\u4e2a\u5730\u5740\u80fd\u8bbf\u95ee\u5417\uff1f\nhttp://192.168.68.73:9200/_sql?sql=select * from report_es_receivables_20180323. \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff1f\u6d4f\u89c8\u5668\u7684\u8bf7\u6c42\u80fd\u770b\u770b\u5417\uff0c\u540e\u53f0\u65e5\u5fd7\uff0c\u6709\u5417\uff1f. Support\uff1aUnion and Minus. Do not support aggregation for union. \u53ef\u4ee5\u7528query_string:\nsql\nSELECT * FROM bank where q=query('address:880 Holmes Lane'). have a look at es-sql-site-standalone not working. Did you use the latest\uff1fRequest headers contains \u2018Authorization\u2019\uff1f. \n. my config:\nyaml\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: \"X-Requested-With, Content-Type, Content-Length, Authorization\". \u4f7f\u7528jdbc\u8fde\u63a5mysql\uff0c\u5b57\u6bb5\u4e0d\u5b58\u5728\uff0c\u662f\u4f1a\u62a5\u5f02\u5e38\u7684\u5427\u3002\n\u6211\u89c9\u5f97\uff0c\u662f\u4e0d\u662f\u5e94\u8be5\u5728sql\u8bed\u53e5\u91cc\u628a\u5b57\u6bb5\u52a0\u4e0a\u5462\uff1f\n\u60a8\u89c9\u5f97\u5462\uff1f. \u6211\u7528\u76845.4.0\njson\n{\n    \"from\": 0,\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"filter\": [\n                {\n                    \"bool\": {\n                        \"must\": [\n                            {\n                                \"match_phrase\": {\n                                    \"ne_type\": {\n                                        \"query\": 1000,\n                                        \"slop\": 0,\n                                        \"boost\": 1\n                                    }\n                                }\n                            }\n                        ],\n                        \"disable_coord\": false,\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                    }\n                }\n            ],\n            \"disable_coord\": false,\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n        }\n    },\n    \"_source\": {\n        \"includes\": [],\n        \"excludes\": []\n    },\n    \"stored_fields\": [\n        \"ne_id\",\n        \"ne_name\"\n    ],\n    \"script_fields\": {\n        \"ne_id\": {\n            \"script\": {\n                \"inline\": \"doc['city_id'].value\",\n                \"lang\": \"painless\"\n            },\n            \"ignore_failure\": false\n        },\n        \"ne_name\": {\n            \"script\": {\n                \"inline\": \"doc['city_name'].value\",\n                \"lang\": \"painless\"\n            },\n            \"ignore_failure\": false\n        }\n    },\n    \"aggregations\": {\n        \"city_id\": {\n            \"terms\": {\n                \"field\": \"city_id\",\n                \"size\": 200,\n                \"min_doc_count\": 1,\n                \"shard_min_doc_count\": 0,\n                \"show_term_doc_count_error\": false,\n                \"order\": [\n                    {\n                        \"_count\": \"desc\"\n                    },\n                    {\n                        \"_term\": \"asc\"\n                    }\n                ]\n            },\n            \"aggregations\": {\n                \"city_name\": {\n                    \"terms\": {\n                        \"field\": \"city_name\",\n                        \"size\": 10,\n                        \"min_doc_count\": 1,\n                        \"shard_min_doc_count\": 0,\n                        \"show_term_doc_count_error\": false,\n                        \"order\": [\n                            {\n                                \"_count\": \"desc\"\n                            },\n                            {\n                                \"_term\": \"asc\"\n                            }\n                        ]\n                    },\n                    \"aggregations\": {\n                        \"COUNT(city_id)\": {\n                            \"value_count\": {\n                                \"field\": \"city_id\"\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}. try ScriptQuery:\nsql\nselect * from index A where script(\"doc['a'] == doc['b']\"). you can try Scripted Metric Aggregation. sql\nselect * from xx where content=matchPhrase('xx'). you can edit the url:\n\nOr, if it's possible, you can develop your own, then send http to server and render the response.. you can try chrome extension. \u662f\u4e0d\u662f\u67d0\u6761\u6570\u636e\u91cc\u6ca1\u6709city\u8fd9\u4e2a\u5b57\u6bb5. This plugin just parse sql to elasticsearch dsl, then return the response from elasticsearch. \nI think, you should know that response and parse it yourself !. sql\nSELECT scripted_metric(\n'init_script' = '_agg[\"sum\"]=[];',\n'map_script'='_agg.sum.add(doc[\"column_name\"].value);' ,\n'combine_script'='double sum = 0.0; for (t in _agg.sum) { sum += t; } return sum;', \n'reduce_script'='double sum = 0.0; for (a in _aggs) { sum += a; } return sum/2;') AS actual \nFROM index_name\njson\n{\n    \"from\": 0,\n    \"size\": 0,\n    \"_source\": {\n        \"includes\": [\n            \"scripted_metric\"\n        ],\n        \"excludes\": []\n    },\n    \"aggregations\": {\n        \"actual\": {\n            \"scripted_metric\": {\n                \"init_script\": {\n                    \"inline\": \"_agg[\\\"sum\\\"]=[];\",\n                    \"lang\": \"painless\"\n                },\n                \"map_script\": {\n                    \"inline\": \"_agg.sum.add(doc[\\\"column_name\\\"].value);\",\n                    \"lang\": \"painless\"\n                },\n                \"combine_script\": {\n                    \"inline\": \"double sum = 0.0; for (t in _agg.sum) { sum += t; } return sum;\",\n                    \"lang\": \"painless\"\n                },\n                \"reduce_script\": {\n                    \"inline\": \"double sum = 0.0; for (a in _aggs) { sum += a; } return sum/2;\",\n                    \"lang\": \"painless\"\n                }\n            }\n        }\n    }\n}. sql\nselect col_name_1, col_name_2, script('t','0')  from index_name. sql\nSELECT name,script('t','0') FROM test\njson\n{\n    \"took\": 6,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 5,\n        \"successful\": 5,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": 1,\n        \"max_score\": 1,\n        \"hits\": [\n            {\n                \"_index\": \"test\",\n                \"_type\": \"test\",\n                \"_id\": \"1\",\n                \"_score\": 1,\n                \"_source\": {\n                    \"name\": \"test\"\n                },\n                \"fields\": {\n                    \"t\": [\n                        0\n                    ]\n                }\n            }\n        ]\n    }\n}. Yes !. I think, you can't use script('t','0') with aggregations.\nYou can use :\nsql\nselect col_1,col_2 from index_1 group by col_2, col_1,script('t','0')\nbut it's not well !. Hi! you should program a subquery in your favorite programming language.. \u53ef\u4ee5\u63d0Pull request. \u9700\u8981\u7528master\u5206\u652f\uff0c\u81ea\u5df1\u91cd\u65b0\u6253\u5305\uff0c\u7136\u540e\u91cd\u88c5. \u6ca1\u95ee\u9898\u7684\uff1a\n\n. \u4e5f\u53ef\u4ee5\u4f7f\u7528Chrome\u63d2\u4ef6. pom.xml:\nxml\n<dependency>\n        <groupId>org.nlpcn</groupId>\n        <artifactId>elasticsearch-sql</artifactId>\n        <version>X.X.X.X</version>\n</dependency>\njava\nnew SearchDao(esClient.getClient()).explain(sql).explain().explain(). elasticsearch-sql  & druid. \u6211\u5efa\u8bae\u6362\u6210Scripted Metric\u5427\u3002\nmapping:\n```json\n{\n    \"settings\" : {\n        \"number_of_shards\" : 1,\n        \"number_of_replicas\" : 0\n},\n\"mappings\" : {\n    \"test\" : {\n        \"_all\" : { \"enabled\" : false },\n        \"properties\" : {\n            \"col1\" : { \"type\" : \"keyword\" },\n            \"col2\" : { \"type\" : \"keyword\" },\n            \"pv\":  { \"type\" : \"integer\" }\n        }\n    }\n}\n\n}\ndocs:\n{\"col1\" : \"a\",\"col2\" : \"b\",\"pv\":  2}\n{\"col1\" : \"a\",\"col2\" : \"b\",\"pv\":  3}\n{\"col1\" : \"a\",\"col2\" : \"c\",\"pv\":  1}\nsql:sql\nselect scripted_metric(\n'init_script' = 'params._agg.transactions=[]',\n'map_script'='params._agg.transactions.add(new AbstractMap.SimpleImmutableEntry(doc[\"col1\"].value+\",\"+doc[\"col2\"].value,doc[\"pv\"].value))' ,\n'combine_script'='return params._agg.transactions.stream().collect(Collectors.groupingBy(Map.Entry::getKey, Collectors.summingLong(Map.Entry::getValue))).entrySet()', \n'reduce_script'='return params._aggs.stream().flatMap(Collection::stream).collect(Collectors.groupingBy(Map.Entry::getKey,\nCollectors.summingLong(Map.Entry::getValue)))\n.entrySet()\n.stream()\n.sorted(Comparator.comparingLong(Map.Entry::getValue).reversed().thenComparing(Comparator.comparing(Map.Entry::getKey)))\n.toArray();') as test from test\n```\nresult:\n\n. \u8bf7\u95eees\u548cnode\u6709\u9519\u8bef\u65e5\u5fd7\u5417\uff1f\u6d4f\u89c8\u5668\u7684console\u91cc\u5462\uff1f\u80fd\u90fd\u63d0\u4f9b\u5417\uff1f. Now not supported. https://github.com/NLPchina/elasticsearch-sql/issues/638. \u9700\u8981\u628areindex-client\u653e\u5230es-sql-plugin\u76ee\u5f55\u4e0b. \u4e0d\u652f\u6301\u5220\u9664\u5427. have a look at \u6267\u884c delete \u8bed\u53e5\u62a5\u9519. use SELECT script('n', 'doc[\"name\"].value') from atlas instead\nor\nuse 2.4.6.0. Config\nyml\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nor not ?\n\nno problem. e.g.\nsql\nSELECT COUNT(*) AS count FROM log WHERE _insert_time>='2017-08-22T00:00+08:00'. If dates are converted to UTC, you should add time zone. \u76f4\u63a5\u5c06\u8fd9\u51e0\u4e2a\u6587\u4ef6\u62f7\u8d1d\u8fc7\u53bb\u5c31\u884c\uff1a\n\n. \u5982\u679c\u662fzip\uff0c\u76ee\u5f55\u7ed3\u6784\uff1a\n\n. \u4e0b\u8f7d\u4e0d\u4e86\u5c31\u672c\u5730\u6253\u5305\u5427\uff0c\u7136\u540e\u628a\u4e0a\u9762\u622a\u56fe\u7684\u6587\u4ef6\u653e\u5230\u6307\u5b9a\u4f4d\u7f6e\u5c31\u884c\u4e86. sql\nselect user_id as id from menu where user_id <> '104000'\n\u8fd9\u4e2a\u7528\u7684\u662fScript Fields. \u53ef\u4ee5\u7528Query String Query\u8bd5\u8bd5\uff1a\nsql\nSELECT address FROM bank where q=query('address:\"880 Holmes Lane\"^10'). How to add weight to the field search. try curl -H \"Content-Type: application/json\" -XPOST 'http://localhost:9200/_sql' -d 'SELECT * FROM test LIMIT 10'. See elasticsearch-sql\u89e3\u6790sql\u751f\u6210dsl\u7684\u90e8\u5206\u600e\u4e48\u8c03\u7528\uff0c\u671b\u6307\u6559. \u5206\u9875\uff1a\njava\nnew SearchDao(esClient).explain(\"SELECT * FROM test LIMIT 10,20\").explain().get().toString(). \u8fd9\u662fes\u672c\u8eab\u7684\u9650\u5236\u5427. Scroll. sql\nSELECT * FROM myindex where nested(binaryAnnotations.endpoint.serviceName)=\"coupon\"\nHave a look at NestedTypes queries. \u672c\u5730\u6d4b\u8bd5\uff0c\u6ca1\u6709\u95ee\u9898\u7684\ncmd\nD:\\elasticsearch\\elasticsearch-5.5.2\\bin>elasticsearch-plugin install file:///D:/elasticsearch/elasticsearch-sql-5.5.2.0.zip\nPlugins directory [D:\\elasticsearch\\elasticsearch-5.5.2\\plugins] does not exist. Creating...\n-> Downloading file:///D:/elasticsearch/elasticsearch-sql-5.5.2.0.zip\n[=================================================] 100%??\n-> Installed sql. See issue notEqual.  http://xxxx:9200/_sql?flat=true&separator=%3B&format=csv&sql=select field from index. use elasticsearch-sql version 5.6.2.1. yeah, you should build by yourself.\n:point_right: elasticsearch-sql-5.6.2.1.zip\n. Support Order by Nested Fields\n\n. sql\nSELECT count(DISTINCT nested(a.id)) FROM myindex where (nested(a.b)>0 and nested(a.e) > 0) and nested(c.e) is not null and nested('comments', comments.message = 'hello' and comments.likes > 3) limit 100 ,1000\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"nested\": {\n                        \"query\": {\n                          \"range\": {\n                            \"a.b\": {\n                              \"from\": 0,\n                              \"to\": null,\n                              \"include_lower\": false,\n                              \"include_upper\": true,\n                              \"boost\": 1\n                            }\n                          }\n                        },\n                        \"path\": \"a\",\n                        \"ignore_unmapped\": false,\n                        \"score_mode\": \"none\",\n                        \"boost\": 1\n                      }\n                    },\n                    {\n                      \"nested\": {\n                        \"query\": {\n                          \"range\": {\n                            \"a.e\": {\n                              \"from\": 0,\n                              \"to\": null,\n                              \"include_lower\": false,\n                              \"include_upper\": true,\n                              \"boost\": 1\n                            }\n                          }\n                        },\n                        \"path\": \"a\",\n                        \"ignore_unmapped\": false,\n                        \"score_mode\": \"none\",\n                        \"boost\": 1\n                      }\n                    },\n                    {\n                      \"nested\": {\n                        \"query\": {\n                          \"bool\": {\n                            \"must_not\": [\n                              {\n                                \"bool\": {\n                                  \"must_not\": [\n                                    {\n                                      \"exists\": {\n                                        \"field\": \"c.e\",\n                                        \"boost\": 1\n                                      }\n                                    }\n                                  ],\n                                  \"disable_coord\": false,\n                                  \"adjust_pure_negative\": true,\n                                  \"boost\": 1\n                                }\n                              }\n                            ],\n                            \"disable_coord\": false,\n                            \"adjust_pure_negative\": true,\n                            \"boost\": 1\n                          }\n                        },\n                        \"path\": \"c\",\n                        \"ignore_unmapped\": false,\n                        \"score_mode\": \"none\",\n                        \"boost\": 1\n                      }\n                    },\n                    {\n                      \"nested\": {\n                        \"query\": {\n                          \"bool\": {\n                            \"must\": [\n                              {\n                                \"bool\": {\n                                  \"must\": [\n                                    {\n                                      \"match_phrase\": {\n                                        \"comments.message\": {\n                                          \"query\": \"hello\",\n                                          \"slop\": 0,\n                                          \"boost\": 1\n                                        }\n                                      }\n                                    },\n                                    {\n                                      \"range\": {\n                                        \"comments.likes\": {\n                                          \"from\": 3,\n                                          \"to\": null,\n                                          \"include_lower\": false,\n                                          \"include_upper\": true,\n                                          \"boost\": 1\n                                        }\n                                      }\n                                    }\n                                  ],\n                                  \"disable_coord\": false,\n                                  \"adjust_pure_negative\": true,\n                                  \"boost\": 1\n                                }\n                              }\n                            ],\n                            \"disable_coord\": false,\n                            \"adjust_pure_negative\": true,\n                            \"boost\": 1\n                          }\n                        },\n                        \"path\": \"comments\",\n                        \"ignore_unmapped\": false,\n                        \"score_mode\": \"none\",\n                        \"boost\": 1\n                      }\n                    }\n                  ],\n                  \"disable_coord\": false,\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"disable_coord\": false,\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"disable_coord\": false,\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"a.id@NESTED\": {\n      \"nested\": {\n        \"path\": \"a\"\n      },\n      \"aggregations\": {\n        \"COUNT(DISTINCT nested=org.nlpcn.es4sql.parse.NestedType@355432ef)\": {\n          \"cardinality\": {\n            \"field\": \"a.id\"\n          }\n        }\n      }\n    }\n  }\n}. Sorry\uff01It will be upgraded soon\uff01. sql\nSELECT correspond_brand_name, SUM(store_count) AS total_store FROM es_car_store_query WHERE current_year = 2017 AND week='42' GROUP BY terms(field='correspond_brand_name',size='10',alias='correspond_brand_name') ORDER BY total_store DESC. terms agg\u7684\u5206\u9875\uff0c\u76ee\u524d\u662f\u4e0d\u652f\u6301\u7684\uff0c\u8fd9\u4e2a\u9700\u8981\u5728client\u7aef\u505a\u7684\uff0c\u5982\u679c\u62c5\u5fc3\u8fd4\u56de\u7684\u6570\u636e\u91cf\u5927\uff0c\u53ef\u4ee5\u501f\u7528_filtering_values_with_partitions\u53d6\u5230\u6240\u6709. sql\nSELECT * FROM index GROUP BY terms(field='correspond_brand_name',size='10',alias='correspond_brand_name',include='{\"partition\":0,\"num_partitions\":20}'). my case:\n\n. sql\nselect insert_time from online group by date_histogram(field='insert_time','interval'='1.5h','format'='yyyy-MM','min_doc_count'=5,'order'='desc')\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"insert_time\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": \"insert_time\",\n  \"aggregations\": {\n    \"date_histogram(field=insert_time,interval=1.5h,format=yyyy-MM,min_doc_count=5,order=desc)\": {\n      \"date_histogram\": {\n        \"field\": \"insert_time\",\n        \"format\": \"yyyy-MM\",\n        \"interval\": \"1.5h\",\n        \"offset\": 0,\n        \"order\": {\n          \"_key\": \"desc\"\n        },\n        \"keyed\": false,\n        \"min_doc_count\": 5\n      }\n    }\n  }\n}. Yeah! The demo website use a different version!. sql\nSELECT online FROM online GROUP BY date_histogram(field='insert_time','interval'='1d','alias'='yourAlias','extended_bounds'='1490278007355:1492693607355'). https://github.com/NLPchina/elasticsearch-sql/issues/855. +-*/\uff0c\u53ef\u4ee5\u8bd5\u8bd5Script Fields\nsql\nselect script(\"f1\",\"doc['a'].value==0?doc['b'].value*0.01:doc['b'].value\") from index. Please see fix issues 541. ResultSetMetaData.getColumnCount() get the value is zero??? . ```js\nrequire('request').post('http://localhost:9200/_sql', {body: \"select * from cars\"}, function (error, response, body) {\n    console.log(body);\n});\n``. have a look at [es-sql-site-standalone not working](https://github.com/NLPchina/elasticsearch-sql/issues/364). [Maybe, it's not a good idea](https://github.com/NLPchina/elasticsearch-sql/commit/86f64f2efa3cd3edd8d18d7151f0fe5c47065a1f). Could you please show your mapping and some data ?. Thanks!.http://localhost:9200/_sql?sql=select * from admin where uid like '%25angpin%25'`. \u672c\u673a\u6d4b\u8bd5\uff0c\u6ca1\u95ee\u9898\u7684\n\n\n. \u76ee\u524d\u4e0d\u652f\u6301\u5462\uff0c\u8fd9\u4e2a\u8fd1\u671f\u4f1a\u52a0\u4e0a\u7684\uff0c\u8c22\u8c22. sql\nselect address from bank where address= matchPhrase(query='671 Bristol Street', analyzer='keyword', boost=1.0, slop=0)\njson\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n        \"bool\": {\n            \"filter\": [\n                {\n                    \"bool\": {\n                        \"must\": [\n                            {\n                                \"match_phrase\": {\n                                    \"address\": {\n                                        \"query\": \"671 Bristol Street\",\n                                        \"analyzer\": \"keyword\",\n                                        \"slop\": 0,\n                                        \"boost\": 1\n                                    }\n                                }\n                            }\n                        ],\n                        \"disable_coord\": false,\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                    }\n                }\n            ],\n            \"disable_coord\": false,\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n        }\n    },\n    \"_source\": {\n        \"includes\": [\n            \"address\"\n        ],\n        \"excludes\": []\n    }\n}. Yeah, you may have a look at ElasticSearchResultSetMetaDataBase. elasticsearch-sql-site-chrome. commit for 6.0.0 - compiling but not working, most tests are broken. elasticsearch 6.0.0 support. \u53ef\u4ee5\u8bd5\u8bd5\nsql\nSELECT address FROM bank WHERE q=query('address:\"880 Holmes Lane\"^10'). sql\nSELECT address FROM bank WHERE address=matchPhrase('880 Holmes Lane', 10)\njson\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n        \"bool\": {\n            \"filter\": [\n                {\n                    \"bool\": {\n                        \"must\": [\n                            {\n                                \"match_phrase\": {\n                                    \"address\": {\n                                        \"query\": \"880 Holmes Lane\",\n                                        \"slop\": 0,\n                                        \"boost\": 10\n                                    }\n                                }\n                            }\n                        ],\n                        \"disable_coord\": false,\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                    }\n                }\n            ],\n            \"disable_coord\": false,\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n        }\n    },\n    \"_source\": {\n        \"includes\": [\n            \"address\"\n        ],\n        \"excludes\": []\n    }\n}. mapping\u6307\u5b9akeyword\u7c7b\u578b\uff1a\nbash\ncurl -XPUT 'localhost:9200/my_index?pretty' -H 'Content-Type: application/json' -d'\n{\n  \"mappings\": {\n    \"my_type\": {\n      \"properties\": {\n        \"tags\": {\n          \"type\":  \"keyword\"\n        }\n      }\n    }\n  }\n}\n'. Geographic-Queries. Geo Distance Sorting. en. Maybe, you can try \nsql\nSELECT c,avg(a) as count_a, avg(b) as count_b FROM name group by c\nthen calculate count_a+count_b by yourself. It's http://192.168.145.91:9200/\n\n. NestedTypes queries. Not yet !. sql\nSELECT sum(script(\"published\",\"if (doc['is_published'].value) {1} else {0}\")) as total_published, sum(script(\"unpublished\",\"if (doc['is_published'].value) {0} else {1}\")) as total_unpublished from articles. WHERE script(\"doc['name'].value.length()>=3\"). sql\nSELECT * FROM bank WHERE q=query('880 Holmes Lane', 'standard', 1.0). \u53ef\u4ee5\u7684. site_server\u53ea\u9700\u8981\u653e\u5728\u4e00\u5904\u5c31\u884c\uff0c\u8bbf\u95ee\u7684\u65f6\u5019\uff0c\u586b\u5199es\u7684\u8bbf\u95eeurl\uff1a\n\n. sql\nSELECT * FROM articles WHERE nested(classifications.classification_id) is missing order by created_on desc. No problem!\n\n\n\n. nested\u7c7b\u578b\u5b57\u6bb5\u4e0d\u5b58\u5728\u7684\u60c5\u51b5\u4e0b\uff0c\u7528elasticsearch-sql\u65e0\u6cd5\u67e5\u8be2\u5230. \u76ee\u524d\u652f\u6301Join. connection closing/timeout issue maybe related to client node. \u6267\u884cmvn dependency:tree\uff0c\u770b\u770b\u54ea\u513f\u6709\u4f9d\u8d56\uff0c\u7136\u540eexclude. elasticsearch-sql for elasticsearch 6.0.0. elasticsearch.yml:\nyml\nscript.inline: true\nscript.indexed: true. \u5e94\u8be5\u662f\u4e0d\u652f\u6301\u5220\u9664\u64cd\u4f5c\u7684. \u6700\u65b0\u7248\u672c\u652f\u6301\u7684#347\n  . Sorry, not yet !. sql\nSELECT /*! USE_SCROLL(100,30000)*/ firstname , balance FROM accounts\nsql\nSELECT /*! USE_SCROLL(\"DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFklUS2VfQnVIU2k2U3h4UUVKM1d4ZFEAAAAAAAAAAhZJVEtlX0J1SFNpNlN4eFFFSjNXeGRRAAAAAAAAAAMWSVRLZV9CdUhTaTZTeHhRRUozV3hkUQAAAAAAAAAEFklUS2VfQnVIU2k2U3h4UUVKM1d4ZFEAAAAAAAAABRZJVEtlX0J1SFNpNlN4eFFFSjNXeGRR\" ,30000)*/ firstname , balance FROM accounts. sql\nselect count(*) from idx_test_new\njson\n{\n    \"from\": 0,\n    \"size\": 0,\n    \"_source\": {\n        \"includes\": [\n            \"COUNT\"\n        ],\n        \"excludes\": []\n    },\n    \"aggregations\": {\n        \"COUNT(*)\": {\n            \"value_count\": {\n                \"field\": \"_index\"\n            }\n        }\n    }\n}\nsql\nselect count(1) from idx_test_new\njson\n{\n    \"from\": 0,\n    \"size\": 0,\n    \"_source\": {\n        \"includes\": [\n            \"COUNT\"\n        ],\n        \"excludes\": []\n    },\n    \"aggregations\": {\n        \"COUNT(1)\": {\n            \"value_count\": {\n                \"field\": \"1\"\n            }\n        }\n    }\n}\n. mapping:\njson\n{\n  \"test\" : {\n    \"mappings\" : {\n      \"test\" : {\n        \"properties\" : {\n          \"a\" : {\n            \"type\" : \"text\",\n            \"fields\" : {\n              \"keyword\" : {\n                \"type\" : \"keyword\",\n                \"ignore_above\" : 256\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\ndocument:\njson\n{\n    \"a\":\"store-images.s-microsoft.com\"\n}\ntest:\n\n. Sorry, Not yet !. sql\nSELECT /*! COLLAPSE({\n        \"field\" : \"user\", \n        \"inner_hits\": {\n            \"name\": \"last_tweets\", \n            \"size\": 5, \n            \"sort\": [{ \"date\": \"asc\" }] \n        },\n        \"max_concurrent_group_searches\": 4}) */ * FROM index1,index2 WHERE f=\"xxx\"\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match_phrase\": {\n                  \"f\": {\n                    \"query\": \"xxx\",\n                    \"slop\": 0,\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"collapse\": {\n    \"field\": \"user\",\n    \"max_concurrent_group_searches\": 4,\n    \"inner_hits\": {\n      \"name\": \"last_tweets\",\n      \"ignore_unmapped\": false,\n      \"from\": 0,\n      \"size\": 5,\n      \"version\": false,\n      \"explain\": false,\n      \"track_scores\": false,\n      \"sort\": [\n        {\n          \"date\": {\n            \"order\": \"asc\"\n          }\n        }\n      ]\n    }\n  }\n}. Sorry, Not yet !. sql\nSELECT /*! POST_FILTER({\"term\":{\"gender\":\"m\"}}) */ gender FROM elasticsearch-sql_test_index_account GROUP BY gender\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"post_filter\": {\n    \"wrapper\": {\n      \"query\": \"eyJ0ZXJtIjp7ImdlbmRlciI6Im0ifX0=\"\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"gender\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": \"gender\",\n  \"aggregations\": {\n    \"gender\": {\n      \"terms\": {\n        \"field\": \"gender\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      }\n    }\n  }\n}. java\nProperties properties = new Properties();\nproperties.put(\"url\", \"jdbc:elasticsearch://127.0.0.1:9300/elasticsearch-sql_test_index_account\");\ntry (DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n     ResultSet resultSet = dds.getConnection().prepareStatement(\"SELECT /*! USE_SCROLL(100,30000)*/ lastname, age, gender FROM elasticsearch-sql_test_index_account WHERE lastname='Heath'\").executeQuery()) {\n    while (resultSet.next()) {\n        System.out.println(resultSet.getString(\"lastname\") + \",\" + resultSet.getInt(\"age\") + \",\" + resultSet.getString(\"gender\"));\n    }\n}. \u60a8\u90a3\u4e2a\u7248\u672c\nsql\nSELECT /*! USE_SCROLL(100,30000)*/ lastname, age, gender FROM elasticsearch-sql_test_index_account WHERE lastname='Heath'\n\u80fdexplain\u5417\uff1f\n\u6211\u7528\u7684\u662f\u6700\u65b0\u7684\u7248\u672c\uff0c\u53ef\u4ee5\u63d0\u4f9b\u7ed9\u6211\u4e00\u4e9b\u6570\u636e\u5417\uff0c\u548c\u60a8\u7684query\uff1f. you could add limit:\nsql\nselect * from table2 limit 3000\njson\n{\n    \"from\": 0,\n    \"size\": 3000\n}. Very large terms query!\nI think, you could use Joining queries, or you could submit a series of queries and join the result hits. Thanks, could you please give me some data ?. Aha, Let me see ! . sql\nSELECT * FROM myindex GROUP BY TERMS('field'='a','execution_hint'='global_ordinals'). Now support master branch\uff01. Yes, I'll add it soon!. elasticsearch-sql-2.3.5.2.zip\n. \n. https://github.com/NLPchina/elasticsearch-sql/issues/703. sql\nSELECT round(myfield) FROM myindex. Sorry, Not !. you could explain your sql first\uff1a\nHashJoin  \nfirst query:\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"_source\": {\n    \"includes\": [\n      \"\",\n      \"order_id\"\n    ],\n    \"excludes\": []\n  }\n}\nsecond query:\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"_source\": {\n    \"includes\": [\n      \"\",\n      \"order_id\"\n    ],\n    \"excludes\": []\n  }\n}. sql\nSELECT data FROM index WHERE id = IN_TERMS(SELECT someid FROM index WHERE CONDITION). sql\nSELECT * FROM new_summary_daily-2018.01.22 WHERE is_published=TERM(true)\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"term\": {\n                  \"is_published\": {\n                    \"value\": true,\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. Only support 2 tables join !!!\nI think you can query:\nsql\nSELECT * FROM 4456450v1 t0 INNER JOIN 4456449v1 t1 ON t0.student_id=t1.StudentId WHERE t1.StudentId = IN_TERMS(SELECT t2.StudentId FROM 4456451mv1 t2) limit 5001. json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"a_point_address\": {\n      \"terms\": {\n        \"field\": \"a_point_address\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"b_point_address\": {\n          \"terms\": {\n            \"field\": \"b_point_address\",\n            \"size\": 10,\n            \"min_doc_count\": 1,\n            \"shard_min_doc_count\": 0,\n            \"show_term_doc_count_error\": false,\n            \"order\": [\n              {\n                \"_count\": \"desc\"\n              },\n              {\n                \"_key\": \"asc\"\n              }\n            ]\n          },\n          \"aggregations\": {\n            \"cou\": {\n              \"value_count\": {\n                \"field\": \"_index\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\u4ece\u7ed3\u679c\u770b\uff0c\u662f\u6ca1\u95ee\u9898\u7684\uff0c\u5148\u6309a_point_address\u5206\u7ec4\uff0c\u7136\u540e\u6309b_point_address\u5206\u7ec4\uff0c\u6700\u540e\u6309count\u6570\u5012\u6392. For IP datatype, you could use the CIDR notation or range query. For example\nsql\nSELECT * FROM myindex WHERE NAT_IP=TERM('192.168.0.0/16')\nSELECT * FROM myindex WHERE NAT_IP BETWEEN '192.168.100.0' AND '192.168.103.255'. Why select * from index where msg like '%%111%%'?\nDid you mean select * from index where msg like '%111%'\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"wildcard\": {\n                  \"msg\": {\n                    \"wildcard\": \"*111*\",\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. :point_right:  elasticsearch-sql-6.2.1.1.zip\n. \u628a\u8fd9\u4e24\u4e2a\u6587\u4ef6\u7684\u4e24\u4e2a\u914d\u7f6e\u5220\u9664\uff1a\n\n\u7136\u540e\u91cd\u65b0\u6253\u5305\uff1amvn package -DskipTests. You could import\nxml\n<dependency>\n    <groupId>org.nlpcn</groupId>\n    <artifactId>elasticsearch-sql</artifactId>\n    <version>x.x.x.x</version>\n</dependency>\nThen \njava\nSearchDao searchDao = new SearchDao(esClient);\nString result = searchDao.explain(sql).explain().get().toString();. elasticsearch-site. Start elasticsearch-site, http://localhost:8080/apidoc\n\nThree API\n. For explain api:\nhttp://localhost:8080/api/SqlApi/explain?sql=SELECT * FROM index\n\n. elasticsearch-site connnect to elasticsearch and supports RESTful api, you can send request to elasticsearch-site. Yeah\uff0celastisearch-site use transport client now\uff01. sql\nSELECT * FROM indexName/type1,indexName/type2,.... Sorry, not yet !. sql\nSELECT /*! USE_SCROLL(100,30000)*/ firstname , balance FROM accounts\nsql\nSELECT /*! USE_SCROLL(\"DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFklUS2VfQnVIU2k2U3h4UUVKM1d4ZFEAAAAAAAAAAhZJVEtlX0J1SFNpNlN4eFFFSjNXeGRRAAAAAAAAAAMWSVRLZV9CdUhTaTZTeHhRRUozV3hkUQAAAAAAAAAEFklUS2VfQnVIU2k2U3h4UUVKM1d4ZFEAAAAAAAAABRZJVEtlX0J1SFNpNlN4eFFFSjNXeGRR\" ,30000)*/ firstname , balance FROM accounts. Maybe next elasticsearch release version\uff0c :stuck_out_tongue_winking_eye:. sql\nSELECT * FROM search WHERE q=query('title:*\u9633*^10 area:*\u9633*^5'). explain\u7684dsl\uff0c\u53ef\u4ee5\u68c0\u67e5\u68c0\u67e5query_string\u7684query\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"must\": {\n        \"query_string\": {\n          \"query\": \"title:*\u9633*^10 area:*\u9633*^5\"\n        }\n      }\n    }\n  }\n}. #610 . sql\nSELECT uid FROM table WHERE pk = IN_TERMS(SELECT pk FROM table WHERE pk='115952878#59128218'). sql\nSELECT * FROM my_index WHERE script(\"doc['a'].value>doc['b'].value+1\"). You could explain your sql to get the elasticsearch query dsl, then export search results. java\nSearchDao searchDao = new SearchDao(null);\nString dsl = searchDao.explain(\"SELECT * FROM index\").explain().explain();\nSystem.out.println(dsl);. sql\nSELECT COUNT(age) FROM bank GROUP BY range(age,'-Infinity',20,25,30,35,40,'Infinity')\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"range(age,-Infinity,20,25,30,35,40,Infinity)\": {\n      \"range\": {\n        \"field\": \"age\",\n        \"ranges\": [\n          {\n            \"to\": 20\n          },\n          {\n            \"from\": 20,\n            \"to\": 25\n          },\n          {\n            \"from\": 25,\n            \"to\": 30\n          },\n          {\n            \"from\": 30,\n            \"to\": 35\n          },\n          {\n            \"from\": 35,\n            \"to\": 40\n          },\n          {\n            \"from\": 40\n          }\n        ],\n        \"keyed\": false\n      },\n      \"aggregations\": {\n        \"COUNT(age)\": {\n          \"value_count\": {\n            \"field\": \"age\"\n          }\n        }\n      }\n    }\n  }\n}. \u66f4\u65b0\u5728\u4e86master\u5206\u652f\u4e0a. \u5206\u4e24\u6b21\u67e5\u8be2\u5427\uff0c\n\u9996\u5148SELECT * FROM gd_resource a\uff0c\n\u7136\u540ebulk\u67e5\u8be2\u5224\u65adSELECT count() FROM gd_resource b WHERE b.GOODS_CATE_ID=a.GOODS_CATE_ID \n AND b.RESOURCE_ID>a.RESOURCE_ID)<2. \u4e5f\u53ef\u4ee5\u5206\u7ec4GOODS_CATE_ID,RESOURCE_ID\uff0c\u7136\u540e\u53d6\u51faRESOURCE_ID\u5012\u5e8f\u6392\u7684\u524d\u4e24\u4e2a\uff0c\u7ecf\u5224\u65ad\u540e\u5f97\u5230GOODS_CATE_ID,RESOURCE_ID\uff0c\u4e4b\u540e\u518d\u6765\u83b7\u53d6\u6570\u636e. sql\nSELECT COUNT(*) FROM gd_resource GROUP BY GOODS_CATE_ID, TERMS('field'='RESOURCE_ID','order'='desc'). \u91cf\u4e0d\u5927\u7684\u8bdd\uff0c\u53ef\u4ee5\u8bd5\u8bd5topHits\uff0c\u5426\u5219\u4e8c\u6b21\u641c\u7d22\u5427. https://github.com/NLPchina/elasticsearch-sql/wiki/Installation-Guide#elasticsearch-5x6x. \n. [Feature request]Provide option to get query as locally on client, without connection to ES. Function Score Query. json\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"nested\": {\n                  \"query\": {\n                    \"bool\": {\n                      \"must_not\": [\n                        {\n                          \"exists\": {\n                            \"field\": \"user_orders.order_id\",\n                            \"boost\": 1\n                          }\n                        }\n                      ],\n                      \"adjust_pure_negative\": true,\n                      \"boost\": 1\n                    }\n                  },\n                  \"path\": \"user_orders\",\n                  \"ignore_unmapped\": false,\n                  \"score_mode\": \"none\",\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"user_orders.order_id\",\n      \"user_name\"\n    ],\n    \"excludes\": []\n  }\n}. It's OK now!. https://github.com/NLPchina/elasticsearch-sql/issues/698. sql\nSELECT * FROM d_stat_alert_*. java\nSearchRequestBuilder builder = esClient.prepareSearch(\"d_stat_alert_*\").setFrom(0).setSize(200);\nSystem.out.println(builder);\ndsl\u5c31\u662f\uff1a\njson\n{\n  \"from\" : 0,\n  \"size\" : 200\n}. sql\nSELECT * FROM myindex WHERE script(\"doc['removetime'].value>=System.currentTimeMillis()\"). removetime\u662fDate\u7c7b\u578b\u5417\uff1f. sql\nSELECT script(\"timemills\",\"doc['date'].value.getMillis()\") FROM indexName. sql\nSELECT script(\"timemills\",\"doc['date'].value\") FROM indexName. \n. Elasticsearch 6.2.1. sql\nSELECT * FROM ['15jan-conn-2018.01.09'] limit 10. sql\nSELECT date_format(transaction_timestamp, '%Y-%m-%d %H') AS date_hour,partner_id,service_id,\nservicename,(CASE WHEN service_type=1 THEN 'PPU' WHEN service_type=2 THEN 'Subscription' END)\nAS service_type,servicegroup,SUM(Counts) AS total_requests_count,SUM((CASE WHEN STATUS=0 THEN Counts ELSE 0 END))\nAS Billing_Status_Success,SUM(CASE WHEN STATUS =1 THEN Counts ELSE 0 END)\nAS Billing_Status_Failure FROM reports.diameter_in WHERE transaction_timestamp >= '2018-03-21 00:00:00'\nAND transaction_timestamp <= '2018-03-21 23:59:59' ORDER BY date_hour DESC LIMIT 0,10. The question of date_format. \u4e0d\u597d\u610f\u601d\uff0c\u76ee\u524d\u8fd8\u4e0d\u652f\u6301multiMatchQuery. sql\nSELECT * FROM test WHERE q=multimatch(query='this is a test',fields='subject^3,message',analyzer='standard',type='best_fields',boost=1.0,slop=0,tie_breaker=0.3,operator='and')\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"multi_match\": {\n                  \"query\": \"this is a test\",\n                  \"fields\": [\n                    \"message^1.0\",\n                    \"subject^3.0\"\n                  ],\n                  \"type\": \"best_fields\",\n                  \"operator\": \"AND\",\n                  \"analyzer\": \"standard\",\n                  \"slop\": 0,\n                  \"prefix_length\": 0,\n                  \"max_expansions\": 50,\n                  \"tie_breaker\": 0.3,\n                  \"zero_terms_query\": \"NONE\",\n                  \"auto_generate_synonyms_phrase_query\": true,\n                  \"fuzzy_transpositions\": true,\n                  \"boost\": 1.0\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1.0\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1.0\n    }\n  }\n}. Sorry, @fenian7788 ,fixed. \u6ca1\u6709SQL\u7684\u8bed\u6cd5\u58f0\u660e\u6587\u4ef6\uff0c\u53ef\u4ee5\u770b\u770bwiki\uff0c\u6216\u8005testcase. sql\nSELECT * FROM ['<logstash-{now/d}>']. This method doesn't support to set time zone, \nBut you can try script field. sql\nSELECT date_format(@timestamp,'yyyy-MM-dd HH:mm:ss', '+08:00') FROM test\njson\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"_source\": {\n        \"includes\": [],\n        \"excludes\": []\n    },\n    \"script_fields\": {\n        \"field_736184593\": {\n            \"script\": {\n                \"source\": \"def date_format_827477673 = DateTimeFormatter.ofPattern('yyyy-MM-dd HH:mm:ss').withZone(ZoneId.of('+08:00')).format(Instant.ofEpochMilli(doc['@timestamp'].value.getMillis()));return date_format_827477673;\",\n                \"lang\": \"painless\"\n            },\n            \"ignore_failure\": false\n        }\n    }\n}. elasticsearch.yml\u4e2d\u914d\u7f6e\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"\". sql\nSELECT * FROM my_index where date_format(aa,'yyyy-MM-dd') >'2018-01-01'\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"def date_format_1475564593 = DateTimeFormatter.ofPattern('yyyy-MM-dd').withZone(ZoneId.systemDefault()).format(Instant.ofEpochMilli(doc['aa'].value.getMillis()));date_format_1475564593 > '2018-01-01'\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. sql\nSELECT * FROM ['billions-main.account.relation-admin-@2018.04.02']. Highlight. options\u7684\u8bf4\u660e\uff0c\u53ef\u4ee5\u770b\u770bes\u7684\u5b98\u65b9\u6587\u6863\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-highlighting.html#highlighting-settings. json\u653e\u5230head\u91cc\u9762\u6267\u884c\u7684\uff0c\u5e94\u8be5\u548csql\u63d2\u4ef6\u91cc\u9762\u6267\u884c\u7684\uff0c\u7ed3\u679c\u4e00\u81f4\u5427. \u672c\u673a\u6d4b\u8bd5\uff0c\u672a\u53d1\u73b0\u95ee\u9898\n\n. \u6211\u4fee\u6539\u7684elastic2.4.6\u5206\u652f\uff0c\u6253\u5305\u6d4b\u8bd5\uff0c\u6ca1\u95ee\u9898\u5462\uff0c\u60a8\u662f\u5728\u8fd9\u4e2a\u5206\u652f\u4e0a\u6253\u7684\u5305\u4e0d\uff1f\n\n. \u8bd5\u8bd5elasticsearch-sql-site-chrome\uff0c\u6709\u4f55\u4e0d\u53ef\uff1f. https://www.elastic.co/guide/en/x-pack/current/http-clients.html\n. ScriptQuery. sql\nSELECT * FROM commenta/commenta GROUP BY TERMS(field='eventTime', size='2', alias='terms')\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"aggregations\": {\n    \"terms\": {\n      \"terms\": {\n        \"field\": \"eventTime\",\n        \"size\": 2,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      }\n    }\n  }\n}. sql\nSELECT user_name FROM user WHERE user_name IS NOT MISSING\nsql\nSELECT k,\nCASE WHEN floor(testBase)>=90 THEN 'A'\nWHEN testBase = '80' THEN 'B'\nELSE 'E' END AS testBaseLevel FROM t. \u522b\u540d\u7528\u7684\u662fScript Fields\nyear\u7684\u7c7b\u578b\u662ftext\uff1f\u9700\u8981\u5f00\u542ffielddata. 200\u662f\u63d2\u4ef6\u91cc\u4ee3\u7801\u5199\u7684\uff0c10\u662fes\u9ed8\u8ba4\u7684. 200\u662f\u63d2\u4ef6\u91cc\u4ee3\u7801\u5199\u7684\uff0c10\u662fes\u9ed8\u8ba4\u7684. json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"range\": {\n                        \"startTime\": {\n                          \"from\": 525757149439,\n                          \"to\": null,\n                          \"include_lower\": false,\n                          \"include_upper\": true,\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"range\": {\n                        \"startTime\": {\n                          \"from\": null,\n                          \"to\": 1525757449439,\n                          \"include_lower\": true,\n                          \"include_upper\": false,\n                          \"boost\": 1\n                        }\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"appName.keyword\": {\n      \"terms\": {\n        \"field\": \"appName.keyword\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"size\": {\n          \"cardinality\": {\n            \"field\": \"sourceIP.keyword\"\n          }\n        },\n        \"size_bucket_sort\": {\n          \"bucket_sort\": {\n            \"sort\": [\n              {\n                \"size\": {\n                  \"order\": \"asc\"\n                }\n              }\n            ]\n          }\n        }\n      }\n    }\n  }\n}. \u4e0d\u652f\u6301\u7684. \u63d2\u4ef6\u672c\u8eab\u5904\u7406\u7684\u662fexplain sql\uff0c\u5173\u4e8e\u6df1\u5206\u9875\u7684\u95ee\u9898\uff0c\u60a8\u53ef\u4ee5\u8003\u8651Scroll\u548cSearch After. Keeping the search context alive. sql\nSELECT scripted_metric(\n  'init_script' = 'params._agg.sum=[];',\n  'map_script'='params._agg.sum.add(doc[\"column_name\"].value);' ,\n  'combine_script'='double sum = 0.0; for (t in params._agg.sum) { sum += t; } return sum;', \n  'reduce_script'='double sum = 0.0; for (t in params._aggs) { sum += t; } return sum;') \nFROM index_name. JDBCTests. https://github.com/NLPchina/elasticsearch-sql/issues/701. \u8fd9\u662f\u751f\u6210\u7684dsl\uff1a\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"time_hour\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": \"time_hour\",\n  \"aggregations\": {\n    \"time_hour\": {\n      \"terms\": {\n        \"field\": \"time_hour\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      }\n    }\n  }\n}\n\u80fd\u628amapping\u548c\u6570\u636e\u63d0\u4f9b\u4e0b\u5417\uff1f. bash\ncurl -XPOST http://10.93.18.34:9200/_sql -H 'Content-Type: application/json' -d 'SELECT * FROM audit where dDelay=-2053867461'. \u60a8\u7684sql\u662f\uff1f\u901a\u8fc7rest\u8c03\u7528\u7684\uff1f\u80fd\u63d0\u4f9bmapping\u548c\u6570\u636e\u5417\uff1f. sql\nselect * from index group by TERMS(field='host', size='200', alias='host'),TERMS(field='name', size='3', alias='name')\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"aggregations\": {\n    \"host\": {\n      \"terms\": {\n        \"field\": \"host\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_term\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"name\": {\n          \"terms\": {\n            \"field\": \"name\",\n            \"size\": 3,\n            \"min_doc_count\": 1,\n            \"shard_min_doc_count\": 0,\n            \"show_term_doc_count_error\": false,\n            \"order\": [\n              {\n                \"_count\": \"desc\"\n              },\n              {\n                \"_term\": \"asc\"\n              }\n            ]\n          }\n        }\n      }\n    }\n  }\n}. \u63d2\u4ef6\u662f\u4e0d\u652f\u6301Pipeline\u7684\u54e6. sql\nselect topHits('size'=1,'include'='sku,group_id,group_id_hash','alias'='topHits'),MAX(dy_score) as max_score from products_2 where in_stock='true' group by group_id_hash\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match_phrase\": {\n                  \"in_stock\": {\n                    \"query\": \"true\",\n                    \"slop\": 0,\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"topHits\",\n      \"MAX\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"group_id_hash\": {\n      \"terms\": {\n        \"field\": \"group_id_hash\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"topHits\": {\n          \"top_hits\": {\n            \"from\": 0,\n            \"size\": 1,\n            \"version\": false,\n            \"explain\": false,\n            \"_source\": {\n              \"includes\": [\n                \"sku\",\n                \"group_id\",\n                \"group_id_hash\"\n              ],\n              \"excludes\": []\n            }\n          }\n        },\n        \"max_score\": {\n          \"max\": {\n            \"field\": \"dy_score\"\n          }\n        }\n      }\n    }\n  }\n}. Sorry, not supported!. Alternatively\uff0cuse elasticsearch-sql-site-chrome. have a look at Elasticsearch converting float numbers when aggregating\nyou should choose appropriate Numeric datatypes. if float, then 0.003, else if double, then 0.00300000001234. #638. \u6ca1\u62a5\u9519\u662f\u5417\uff1f\u65b9\u4fbf\u770b\u4e00\u4e0b\u5de5\u7a0b\u5417\uff1f. \u548c\u8bbe\u7f6e\u8fd9\u4e2a\u6ca1\u5173\u7cfb\u7684\u3002\u914d\u7f6e\u8bbf\u95ee\u6743\u9650\u4e86\u5417\uff1f\u53ef\u4ee5\u8bd5\u8bd5TransportClient\u80fd\u4e0d\u80fd\u6b63\u5e38\u8bbf\u95ee. \u5e94\u8be5\u662f\u8fde\u63a5\u7684\u65f6\u5019\u5361\u4f4f\u4e86\uff0c\u4e00\u76f4\u8fde\u4e0d\u4e0a. Why not to use Date Histogram Aggregation, set interval to hour. have a look at date histogram aggregation. yes, you are right, I'll fix it soon.. sql\nSELECT COUNT(age) FROM bank GROUP BY range(alias='xxxx', age, 20, 25, 30, 35, 40)\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"xxxx\": {\n      \"range\": {\n        \"field\": \"age\",\n        \"ranges\": [\n          {\n            \"from\": 20,\n            \"to\": 25\n          },\n          {\n            \"from\": 25,\n            \"to\": 30\n          },\n          {\n            \"from\": 30,\n            \"to\": 35\n          },\n          {\n            \"from\": 35,\n            \"to\": 40\n          }\n        ],\n        \"keyed\": false\n      },\n      \"aggregations\": {\n        \"COUNT(age)\": {\n          \"value_count\": {\n            \"field\": \"age\"\n          }\n        }\n      }\n    }\n  }\n}. Sorry, having isn't supported\uff01. yeah\uff0cbucket_selector not supported now. I really don\u2019t know the exact date yet~. http://mvnrepository.com/artifact/org.nlpcn/elasticsearch-sql\n\u6ca1\u6709v6.2.2\uff0c @ansjsun \u662f\u4e0d\u662f\u53ef\u4ee5\u53d1\u5e03\u4e00\u7248\u65b0\u7684\u5462\uff1f. \u53ef\u4ee5\u7528ScriptQuery. ESJoinQueryAction. https://github.com/NLPchina/elasticsearch-sql/wiki/Join. \u662f\u7684\uff0c\u4e0d\u652f\u6301\u7684. just ignore the warn message. It's OK in mater branch \uff01. Join. Sorry, Inner hits not supported now. SELECT * FROM myIndex where nested('comments', comments.message = 'hello' and comments.likes > 3,'{\"from\":0}')\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"nested\": {\n                  \"query\": {\n                    \"nested\": {\n                      \"query\": {\n                        \"bool\": {\n                          \"must\": [\n                            {\n                              \"bool\": {\n                                \"must\": [\n                                  {\n                                    \"match_phrase\": {\n                                      \"comments.message\": {\n                                        \"query\": \"hello\",\n                                        \"slop\": 0,\n                                        \"zero_terms_query\": \"NONE\",\n                                        \"boost\": 1\n                                      }\n                                    }\n                                  },\n                                  {\n                                    \"range\": {\n                                      \"comments.likes\": {\n                                        \"from\": 3,\n                                        \"to\": null,\n                                        \"include_lower\": false,\n                                        \"include_upper\": true,\n                                        \"boost\": 1\n                                      }\n                                    }\n                                  }\n                                ],\n                                \"adjust_pure_negative\": true,\n                                \"boost\": 1\n                              }\n                            }\n                          ],\n                          \"adjust_pure_negative\": true,\n                          \"boost\": 1\n                        }\n                      },\n                      \"path\": \"comments\",\n                      \"ignore_unmapped\": false,\n                      \"score_mode\": \"none\",\n                      \"boost\": 1\n                    }\n                  },\n                  \"path\": \"comments\",\n                  \"ignore_unmapped\": false,\n                  \"score_mode\": \"none\",\n                  \"boost\": 1,\n                  \"inner_hits\": {\n                    \"ignore_unmapped\": false,\n                    \"from\": 0,\n                    \"size\": 3,\n                    \"version\": false,\n                    \"explain\": false,\n                    \"track_scores\": false\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. bash\ncurl -X POST \"localhost:9200/_sql?pretty\" -H \"Content-Type: application/json\" -d\"SELECT * FROM test LIMIT 100\". \u8fd9\u4e2a\u9700\u8981IP\u5730\u5740\u6570\u636e\u5e93\u7684\u5427. - Install plugin elasticsearch-painlesswhitelist-geoip\n\nUse Script Fields\n. sql\nSELECT script('province', 'GeoIpProcessor.process(doc[\"ip_field\"].value).get(\"region_name\")'),script('city', 'GeoIpProcessor.process(doc[\"ip_field\"].value).get(\"city_name\")') FROM test. \u662f\u53ef\u4ee5\u7684\uff0c\u60a8\u7684names\u7684mapping\u662f\u5565\uff1f\n. \u6211\u7684\u662fkeyword. json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"should\": [\n              {\n                \"bool\": {\n                  \"must_not\": [\n                    {\n                      \"match_phrase\": {\n                        \"code\": {\n                          \"query\": 0,\n                          \"slop\": 0,\n                          \"zero_terms_query\": \"NONE\",\n                          \"boost\": 1\n                        }\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"module\": {\n      \"terms\": {\n        \"field\": \"module.keyword\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"count\": {\n          \"value_count\": {\n            \"field\": \"_index\"\n          }\n        },\n        \"value_count_bucket_filter\": {\n          \"bucket_selector\": {\n            \"buckets_path\": {\n              \"count\": \"count\"\n            },\n            \"script\": \"params.count>10\"\n          }\n        }\n      }\n    }\n  }\n}. sql\nselect topHits('size'=1,create_time='asc') from index group by ip. sql\nselect * from test where values.keyword=TERMS(''). What's your mapping ? . \uff1f\uff1f\uff1f\n. Maybe\uff0cyou can try elasticsearch-sql-site-chrome !. \u5206\u4e24\u6b21\u67e5\u8be2\u5427\uff0c\u5148\u67e5\u8be25\u4e2a\u5ba2\u6237\u540d\uff0c\u518d\u6839\u636e\u5ba2\u6237\u540d\u53bb\u67e5. \u4e0d\u597d\u610f\u601d\u54c8\uff0c\u76ee\u524d\u53ef\u80fd\u6ca1\u6709\u7684. \u8bf4\u5f97\u5bf9\uff0c\u8fd9\u4e00\u5757\u662f\u4e0d\u652f\u6301\u7684\uff0c\u53ef\u4ee5\u6539\u6539\uff0corder\u53ef\u4ee5\u652f\u6301\u5199json\u6570\u7ec4. sql\nSELECT SUM(FAMOUNT)\nFROM batsaleindex\nGROUP BY TERMS(field='FCustomerName', size='5', alias='FCustomerName', order='[{ \"_count\":\"desc\"},{ \"_key\":\"asc\"}]'). \u60a8\u53ef\u4ee5\u53c2\u8003\u793a\u4f8b\u4ee3\u7801\uff1a\nhttps://github.com/NLPchina/elasticsearch-sql/blob/master/src/test/java/org/nlpcn/es4sql/JDBCTests.java. \u6570\u636e\u91cf\u5927\u7684\u8bdd\uff0c\u7528scroll\u53bb\u67e5. sql\nselect * from test where fields <> ''. sql\nSELECT * FROM environmental_safety_inspection where virusApps.keyword<> ''. \u7528&\u5206\u9694\uff0c\u62fc\u63a5\u5728\u8fd9\u513f\n\n\n. java\n...\nproperties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true&xpack.security.user=transport_client_user:changeme\");\n.... \u4e0d\u8fc75.6.3\uff0c\u4e0d\u652f\u6301\u7684\uff0c\u5e94\u8be5\u662f\uff0c\u53ef\u4ee5\u770b\u770bsupport connectionProperties for JDBC. java\nProperties properties = new Properties();\nproperties.put(PROP_URL, \"jdbc:elasticsearch://127.0.0.1:9300/test\");\nproperties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true;xpack.security.user=elastic:5laftq1NilavFTibKOaZ\");\nDruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\nConnection connection = dds.getConnection();\nPreparedStatement ps = connection.prepareStatement(\"SELECT * from  test\");\nResultSet resultSet = ps.executeQuery();\nwhile (resultSet.next()) {\n    System.out.println(resultSet.getString(\"name\"));\n}\nps.close();\nconnection.close();\ndds.close();. \u4e0d\u597d\u610f\u601d\u54c8\uff0c\u662f\u7528 ;  \u5206\u9694\u7684\uff0c :disappointed_relieved:. \u8fd1\u671f\u4f1a\u652f\u6301\uff0c\u8c22\u8c22. \u6700\u65b0\u7248\u672c\u5df2\u53d1\u5e03\uff0c\u8c22\u8c22. \u4f1a\u7ef4\u62a4\u7684\uff0c\u4e3b\u8981\u662f\u4fee\u590d\u4e00\u4e9bbug\u548c\u4e00\u4e9b\u5c0f\u529f\u80fd\u7684\u6dfb\u52a0\u3002\u4e5f\u5f88\u671f\u5f85es\u5b98\u65b9\u7684sql\u529f\u80fd\u8d8a\u6765\u8d8a\u5065\u5168. \u6700\u65b0\u7248\u672c\u5df2\u53d1\u5e03\uff0c\u8c22\u8c22. Join. es\u805a\u5408\u7684\u8bdd\uff0c\u4e0d\u4f1a\u7684\u3002\u805a\u5408\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u6307\u5b9amissing\u6216\u8005\u7d22\u5f15\u7684\u65f6\u5019\u6307\u5b9anull_value. \u5efa\u8bae\u662f\u90fd\u5b89\u88c5\uff0c\u4e0d\u8fc7\u4e5f\u53ef\u4ee5\u53ea\u5b89\u88c5\u90e8\u5206\u8282\u70b9\uff0c\u5b89\u88c5\u4e86\u7684\u8282\u70b9\uff0c\u5ba2\u6237\u7aef\u5c31\u53ef\u4ee5\u8fde\u63a5\u8bbf\u95eesql\u63d2\u4ef6\u63d0\u4f9b\u7684\u529f\u80fd. \u63d2\u4ef6\u672c\u8eab\u662f\u4e0d\u4f1a\u505a\u7684. \u9996\u5148\u5f53\u7136\u5e0c\u671b\u5b98\u65b9\u529f\u80fd\u8d8a\u6765\u8d8a\u5b8c\u5584\uff0c\u8fd9\u4e2a\u9879\u76ee\u8fd1\u671f\u7684\u8bdd\uff0c\u8fd8\u662f\u4f1a\u505a\u540c\u6b65\u5347\u7ea7\u548c\u4e00\u4e9bbug\u7684\u4fee\u590d\uff1b\n\u8fd9\u4e2a\u63d2\u4ef6\u505a\u7684\u53ea\u662f\u5c06sql\u8f6c\u6210es dsl\uff0c\u81f3\u4e8e\u6027\u80fd\uff0c\u4e0d\u597d\u610f\u601d\u54c8\uff0c\u6211\u8fd9\u8fb9\u6ca1\u6709\u505a\u8fc7\u538b\u6d4b\uff0c :sweat:. \u53ef\u4ee5\u7684\uff0c\u4f46\u662f\u6709\u7684sql\u662f\u4e0d\u884c\u7684\uff0c\u6bd4\u5982\u8bf4\uff1ashow index. java\npublic String explain(String sql) throws Exception {\n    SearchDao searchDao = new SearchDao(null);\n    SqlElasticRequestBuilder requestBuilder = searchDao.explain(sql).explain();\n    return requestBuilder.explain();\n}. Yeah\uff0cnot supported\uff0cbut you could use scripted_metric. What't your whole sql ? . Additional\uff0cyou could use Bucket Script Aggregation\uff1a\njson\n{\n...\n\"aggs\": {\n  \"sum_1\": {\n    \"sum\": {\n      \"field\": \"flag_barisolve\"\n    }\n  },\n  \"sum_2\": {\n    \"sum\": {\n      \"field\": \"flag_anagrafe\"\n    }\n  },\n  \"division\": {\n    \"bucket_script\": {\n      \"buckets_path\": {\n        \"my_var1\": \"sum_1\",\n        \"my_var2\": \"sum_2\"\n      },\n      \"script\": \"params.my_var1 / params.my_var2\"\n    }\n  }\n}. ```sql\nSELECT scripted_metric(\n'init_script' = 'params._agg[\"bands\"]=[];params._agg[\"times\"]=[];',\n'map_script'='params._agg[\"bands\"].add(doc[\"band\"].value);params._agg[\"times\"].add(doc[\"time\"].value);',\n'combine_script'='return [params._agg[\"bands\"].stream().mapToLong(i -> i).sum(),params._agg[\"times\"].stream().mapToLong(i -> i).sum()];',\n'reduce_script'='def band_sum=0,time_sum=0;for(item in params._aggs){ band_sum+=item[0];time_sum+=item[1];} return [band_sum,time_sum,(band_sum*1.0/time_sum)];'\n) FROM test\n. \u5176\u5b9e\u8d70\u7684\u662fMultiSearchRequest\uff1ajson\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n      \"bool\": {\n        \"filter\": [\n          {\n            \"bool\": {\n              \"should\": [\n                {\n                  \"match_phrase\": {\n                    \"tag_name\": {\n                      \"query\": \"\u80a1\u7968\",\n                      \"slop\": 0,\n                      \"zero_terms_query\": \"NONE\",\n                      \"boost\": 1.0\n                    }\n                  }\n                }\n              ],\n              \"adjust_pure_negative\": true,\n              \"boost\": 1.0\n            }\n          }\n        ],\n        \"adjust_pure_negative\": true,\n        \"boost\": 1.0\n      }\n    },\n    \"_source\": {\n      \"includes\": [\n        \"tag_name\",\n        \"news_id\"\n      ],\n      \"excludes\": []\n    }\n  }\n  {\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n      \"bool\": {\n        \"filter\": [\n          {\n            \"bool\": {\n              \"should\": [\n                {\n                  \"wildcard\": {\n                    \"news_title\": {\n                      \"wildcard\": \"iphone\",\n                      \"boost\": 1.0\n                    }\n                  }\n                }\n              ],\n              \"adjust_pure_negative\": true,\n              \"boost\": 1.0\n            }\n          }\n        ],\n        \"adjust_pure_negative\": true,\n        \"boost\": 1.0\n      }\n    },\n    \"_source\": {\n      \"includes\": [\n        \"news_title\",\n        \"news_id\"\n      ],\n      \"excludes\": []\n    }\n  }\n\u505a\u7684\u7ed3\u679c\u7684\u5408\u5e76. \u9488\u5bf9join\uff0c\u53ef\u4ee5\u8003\u8651\uff1a\n1\u3001\u5b57\u6bb5\u878d\u5408\u5230\u4e00\u5f20\u8868\n2\u3001nested\uff0cparent/child\uff0cterms-lookup\n3\u3001\u5148\u67e5\u8be2\uff0c\u518d\u6839\u636e\u67e5\u8be2\u7ed3\u679c\u805a\u5408\n4\u3001MultiSearchRequest\u4e24\u4e2a\u67e5\u8be2\uff0c\u81ea\u5df1\u505a\u7ed3\u679c\u5408\u5e76\uff08\u5177\u4f53\u5230\u5408\u5e76\u903b\u8f91\u5b9e\u73b0\uff09\n. THX\uff0cfixed\uff01. \u6ca1\u6709\u4e71\u7801\u7684\uff1a\n![1](https://user-images.githubusercontent.com/8057153/43046588-a6858736-8dfd-11e8-90e7-c69f433e1097.png)\n. \u4e2d\u6587\u67e5\u4e0d\u51fa\u6765\uff1f\u5982\u4f55\u67e5\u7684\u5462\uff1f\n. Sorry\uff0cI don't know.. \u73b0\u5728\u4e0d\u652f\u6301\u7684. \u54c8\u54c8\uff0c\u6682\u65f6\u7b97\u662f\u6ca1\u6709\u7684\u5427.json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"a\",\n      \"b\",\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": [\n    \"a\",\n    \"b\"\n  ],\n  \"aggregations\": {\n    \"a\": {\n      \"terms\": {\n        \"field\": \"a\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"b\": {\n          \"terms\": {\n            \"field\": \"b\",\n            \"size\": 10,\n            \"min_doc_count\": 1,\n            \"shard_min_doc_count\": 0,\n            \"show_term_doc_count_error\": false,\n            \"order\": [\n              {\n                \"_count\": \"desc\"\n              },\n              {\n                \"_key\": \"asc\"\n              }\n            ]\n          },\n          \"aggregations\": {\n            \"c\": {\n              \"value_count\": {\n                \"field\": \"_index\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\nexplain\u540e\u7684dsl\uff0corder\u91cc\u7684\u662f\u7ec4\u5185\u6392\u5e8f\u7684. \u90a3\u5f97\u8003\u8651[Sorting Based on \"Deep\" Metrics](https://www.elastic.co/guide/en/elasticsearch/guide/current/_sorting_based_on_deep_metrics.html). \u4f7f\u7528\u62fc\u97f3\u5206\u8bcd\uff0c\u5173\u4e8e\u62fc\u97f3\u5206\u8bcd\u7684\u95ee\u9898\uff1f\u60a8\u63d0\u9519\u5730\u65b9\u4e86\u5427\uff1f. Why not to use master\uff1f. Already update release [6.3.1.0](https://github.com/NLPchina/elasticsearch-sql/releases/tag/6.3.1.0). Welcome to use it, and contribute it !  :bowtie:. 5.5.0\u7248\u672c\u662f\u6ca1\u6709\u7684\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003[regex support](https://github.com/NLPchina/elasticsearch-sql/commit/1b6b9e11b180efd3b5ee36e53fecd715f1273a20)\uff0c\u81ea\u884c\u6dfb\u52a0\u7684. explain\u770b\u770bquery dsl\u5427. join\u7684\u5b9e\u73b0\u662f\u4e24\u6b21request\uff1ajson\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n      \"bool\": {\n        \"filter\": [\n          {\n            \"bool\": {\n              \"must\": [\n                {\n                  \"bool\": {\n                    \"must\": [\n                      {\n                        \"match_phrase\": {\n                          \"infoOwnerId\": {\n                            \"query\": \"fd4016d301d445b282635ed383a556a3\",\n                            \"slop\": 0,\n                            \"zero_terms_query\": \"NONE\",\n                            \"boost\": 1.0\n                          }\n                        }\n                      },\n                      {\n                        \"wildcard\": {\n                          \"adminDivisionCode\": {\n                            \"wildcard\": \"4201\",\n                            \"boost\": 1.0\n                          }\n                        }\n                      }\n                    ],\n                    \"adjust_pure_negative\": true,\n                    \"boost\": 1.0\n                  }\n                }\n              ],\n              \"adjust_pure_negative\": true,\n              \"boost\": 1.0\n            }\n          }\n        ],\n        \"adjust_pure_negative\": true,\n        \"boost\": 1.0\n      }\n    },\n    \"_source\": {\n      \"includes\": [\n        \"propertyId\",\n        \"estateId\"\n      ],\n      \"excludes\": []\n    },\n    \"sort\": [\n      {\n        \"updatedTime\": {\n          \"order\": \"desc\"\n        }\n      }\n    ]\n  }\n  {\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n      \"bool\": {\n        \"filter\": [\n          {\n            \"bool\": {\n              \"must\": [\n                {\n                  \"match_phrase\": {\n                    \"cityId\": {\n                      \"query\": \"01\",\n                      \"slop\": 0,\n                      \"zero_terms_query\": \"NONE\",\n                      \"boost\": 1.0\n                    }\n                  }\n                }\n              ],\n              \"adjust_pure_negative\": true,\n              \"boost\": 1.0\n            }\n          }\n        ],\n        \"adjust_pure_negative\": true,\n        \"boost\": 1.0\n      }\n    },\n    \"_source\": {\n      \"includes\": [\n        \"estateId\"\n      ],\n      \"excludes\": []\n    }\n  }\n. \u7b2c\u4e8c\u6b21\u4f1a\u6839\u636e\u7b2c\u4e00\u6b21\u7684\u7ed3\u679c\u505afilter\uff0c\u5408\u5e76\u540e\u5f97\u51fa\u6700\u7ec8\u7ed3\u679c.sql\nselect count() from property_sql_bean where estateId in(select /! JOIN_TABLES_LIMIT(null,null) / estateId from estate_sql_bean where adminDivisionCode = '420102' limit 0,30)\n. \u90a3\u5c31\u5206\u4e24\u4e2a\u67e5\u5427. [\u5982\u4f55\u5728site server \u4e2d\u6dfb\u52a0\u8ba4\u8bc1\u4fe1\u606f](https://github.com/NLPchina/elasticsearch-sql/issues/543). \u73b0\u5728\u4e0d\u652f\u6301\u7684\u54e6\uff0c\u53ea\u652f\u6301queryString\uff1asql\nSELECT address FROM bank where q=query('address:880 Holmes Lane')\n\u8fd1\u671f\u4f1a\u8003\u8651\u652f\u6301\u7684.sql\nSELECT * FROM strategy where q=query(query='?',default_field='strategy.st_.st_function')\n.sql\nSELECT * FROM search_index_v1 WHERE q=multimatch(query='s',fields='keyword.FPY,keyword,keyword.IKS')\n. \u6211\u89c9\u5f97\uff0c\u5982\u679c\u7528querystring\u4f20\u53c2\uff0cclient\u7aef\u5e94\u8be5\u505aencode\u7684. \u6211\u7528\u6700\u65b0\u7684\u7248\u672c\u8bd5\u4e86\u8bd5\uff0cexplain\uff1ajson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"term\": {\n                        \"src_ip\": {\n                          \"value\": \"10.18.26.165\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"wildcard\": {\n                        \"data\": {\n                          \"wildcard\": \"aaaaabbbbb\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"range\": {\n                        \"create_time\": {\n                          \"from\": 1534055628585,\n                          \"to\": null,\n                          \"include_lower\": false,\n                          \"include_upper\": true,\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"range\": {\n                        \"create_time\": {\n                          \"from\": null,\n                          \"to\": 1534142028585,\n                          \"include_lower\": true,\n                          \"include_upper\": false,\n                          \"boost\": 1\n                        }\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"date_histogram(field=create_time,interval=15m,extended_bounds=1534055628585:1534142028585)\": {\n      \"date_histogram\": {\n        \"field\": \"create_time\",\n        \"format\": \"yyyy-MM-dd HH:mm:ss\",\n        \"interval\": \"15m\",\n        \"offset\": 0,\n        \"order\": {\n          \"_key\": \"asc\"\n        },\n        \"keyed\": false,\n        \"min_doc_count\": 0,\n        \"extended_bounds\": {\n          \"min\": \"1534055628585\",\n          \"max\": \"1534142028585\"\n        }\n      },\n      \"aggregations\": {\n        \"total\": {\n          \"value_count\": {\n            \"field\": \"_index\"\n          }\n        }\n      }\n    }\n  }\n}\n. \u4e0d\u4f1a\u5427\uff0c\u6211\u7528\u76845.1.1\uff0c\u4e0d\u662f\u8fd9\u4e2a\u95ee\u9898\u7684\n````\norg.nlpcn.es4sql.exception.SqlParseException: date range err or not define field extended_bounds=1534055628585:1534142028585\n````\n\u8fd9\u4e2aextended_bounds\uff0c\u672a\u5b9a\u4e49\u7684\uff0c\u8fd9\u4e2a\u7248\u672c\u4e0d\u652f\u6301\u7684. \u6682\u65f6\u662f\u6ca1\u6709\u8ba1\u5212\u7684\u54e6. \u5c31\u6211\u4e2a\u4eba\u800c\u8a00\u7684\u8bdd\uff0c\u4e00\u4e2a\u987e\u8651\u662f\u6709\u5f85\u5b8c\u5584\u7684\u4e0d\u5c11\uff0c\u518d\u8005\u6539\u52a8\u4e0d\u5c0f\uff0c\u6700\u8fd1\u6ca1\u6709\u592a\u591a\u65f6\u95f4\u6295\u5165\u3002.sql\nSELECT PERCENTILES(a,90.0)  FROM test\n.sql\nSELECT * FROM index WHERE a=TERMS('\u4e2d\u6587')\n. \u5206\u8bcd\u4e86\u5427\uff0c\u9ed8\u8ba4\u662fstandard\u7684. ````\nhttp://localhost:9200/_sql?sql=SELECT%20*%20FROM%20test%20WHERE%20%5B'last%20name'%5D%3D'bar'\n````. Thanks!. ````\nhttp://localhost:9200/_sql?sql=SELECT%20*%20FROM%20%5B'888afc4c-1b45-4e2b-bac7-e51635bd5f70-888afc4c-1b45-4e2b-bac7-e51635bd5f70-abc'%5D\n````. Thanks!. \u95ee\u9898\u89e3\u51b3\u4e86\uff1f. [\u5982\u4f55\u5728site server \u4e2d\u6dfb\u52a0\u8ba4\u8bc1\u4fe1\u606f](https://github.com/NLPchina/elasticsearch-sql/issues/543).sql\nSELECT count(*) FROM log4a-20180817/comptroller WHERE ['function'] = TERM(\"\u51fd\u6570test63\")\n. \u8bf7\u95ee\u60a8\u7528\u7684\u7248\u672c\u662f\uff1f\n. [Elasticsearch 5.x/6.x](https://github.com/NLPchina/elasticsearch-sql/wiki/Installation-Guide#elasticsearch-5x6x). \u914d\u7f6e\u4e86http.cors.enabled\u548chttp.cors.allow-origin\u5417\uff1f. \u5e94\u8be5\u4e0d\u4f1a\u7684\u5427\uff1f\u540e\u53f0\u6709\u9519\u8bef\u65e5\u5fd7\u5417\uff1f\u6216\u8005\u524d\u7aefconsole\u7684\u65e5\u5fd7\u5462\uff1f\u7528\u7684\u54ea\u4e2a\u5305\uff1f. 1.\u914d\u7f6e\u4e86http.cors.enabled\u548chttp.cors.allow-origin\n2.\u5730\u5740\u586b\u5199\u6b63\u786e\n![1](https://user-images.githubusercontent.com/8057153/44456853-491dcc80-a634-11e8-9913-fc55d573601c.png)\n.sql\nselect * from test where field <> term('10')\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must_not\": [\n                    {\n                      \"term\": {\n                        \"field\": {\n                          \"value\": \"10\",\n                          \"boost\": 1\n                        }\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}\n. \u6700\u65b0\u7248\u672c\uff0cmaster\u4e0a. \u60a8\u53ef\u4ee5\u770b\u770b\uff0c\u4fee\u6539\u4ee3\u7801\uff1a\nhttps://github.com/NLPchina/elasticsearch-sql/commit/c69f4d25643e354b6cedac1525de3eea3a24ba27. Thanks\uff01\u8981\u662f\u80fd\u52a0\u4e0atestcase\u5c31\u66f4\u597d\u4e86. update\u4e0d\u652f\u6301\u7684\u5662\uff0c\u60a8\u53ef\u4ee5\u770b\u770bes\u7684\u5b98\u65b9[Update API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html). \u652f\u6301\u7684\u54e6json\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"1 == 1\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}\n```. https://github.com/stopit/elasticsearch-sql/commit/651ffa2e340aaacd05248cef32f035804c161b2c. \u54ea\u4e2a\u7248\u672c\u5462\uff0c\u8bf7\u95ee\uff1f\u8bd5\u4e86\u8bd5\uff0c\u6ca1\u5565\u95ee\u9898\u5462\ncurl -X POST \"localhost:9200/_sql/_explain\" -H \"Content-Type: application/json\" -d\"select * from movies/movie where title like '\u7535\u5f71%'\". \u8c22\u8c22\uff01\u4e0d\u8fc7merge\u7684\u65f6\u5019\u6709\u51b2\u7a81\u54e6\u3002\u3002\u3002. \u51b2\u7a81\u5df2\u89e3\u51b3\uff0c\u5df2\u7ecfmerge\u4e86\uff0c\u8c22\u8c22\u4e86\u54c8. \u8c22\u8c22\uff01\u8fd9\u4e2a\u9879\u76ee\u4e0d\u662f\u6211\u53d1\u8d77\u7684\u54c8\uff0c\u6211\u4e5f\u4ec5\u4ec5\u662f\u5c3d\u81ea\u5df1\u7684\u7ef5\u8584\u4e4b\u529b\u3002. \u51b2\u7a81\u4e86\u3002\u3002\u3002. \u6d4b\u8bd5explain\uff0c\u6ca1\u5565\u95ee\u9898\u5462\u3002elasticsearch-site\u7528\u76845.x\uff0ces\u7528\u76845.6.6\n\n. \u53f3\u4e0a\u89d2\u5730\u5740\u680f\u5730\u5740\u5199\u7684\u4e0d\u5bf9\uff0c\u76f4\u63a5\u5199\uff1ahttp://10.211.121.44:8080/\n\u7528\u6237\u540d\u548c\u5bc6\u7801\u7684\u8bdd\uff0c\u914d\u7f6e\u5728\n\n. \u70b9\u51fbSearch\u6309\u94ae\uff0c\u5c31\u53ef\u4ee5\u663e\u793a\u7ed3\u679c\u4e86\u5427. 9300\u8fde\u4e0d\u4e86\uff1f\u8fd8\u662f\u6743\u9650\u9a8c\u8bc1\uff1fTransportClient\u4e0d\u80fd\u6b63\u5e38\u8bbf\u95ee. explain\u4e0d\u4e00\u5b9a\u4f1a\u771f\u6b63\u7528\u5230client\uff0c\u8fd9\u6761\u8bed\u53e5explain\u5c31\u4e0d\u4f1a. \u652f\u6301\u7684\u5427\uff0c\u505a\u597d\u914d\u7f6e\uff0c\u76f4\u63a5\u67e5\u8be2\uff0c\u6bd4\u5982\uff1a\nsql\nSELECT * FROM cluster_one:twitter,twitter. ~~\u901a\u914d\u7b26\u7684\uff0c\u672c\u8eab\u5c31\u4e0d\u652f\u6301\u7684\u5427~~. \u4e0d\u597d\u610f\u601d\u54c8\uff0c\u786e\u5b9e\u652f\u6301\u7684\uff1a\nsql\nSELECT * FROM ['*:twitter']. Thanks\uff01\n\u8fd9\u4e48\u6539\u6ca1\u6bdb\u75c5\uff0c\u53ef\u4ee5\u89e3\u51b3\u95ee\u9898\u3002\n\u4e0d\u8fc7\u4e2a\u4eba\u8ba4\u4e3a\uff0c\u76ee\u524d\u7684\u5b9e\u73b0\u673a\u5236\u6709\u70b9\u95ee\u9898\uff0cclient\u4e0d\u5e94\u8be5\u653e\u5728connection\u91cc\uff0c\u73b0\u5728\u662f\u6bcf\u6b21new\u4e00\u4e2aconnection\u5c31\u4f1a\u521b\u5efa\u4e00\u4e2aclient\u3002\n\u5176\u5b9e\u4e0d\u7136\uff0c\u5e94\u8be5\u662f\u6bcf\u6b21\u521b\u5efa\u4e00\u4e2adatasource\uff0c\u624d\u521b\u5efa\u4e00\u4e2aclient. \u5df2\u5c06client\u7684\u521b\u5efa\u4e0e\u9500\u6bc1\u653e\u5728\u4e86datasource\u91cc\u4e86\uff1ahttps://github.com/NLPchina/elasticsearch-sql/commit/5d370f15606da940473166c625b85ead391fc8b2. Mine(6.3.0) is ok!\njson\n{\n  \"mappings\": {\n    \"_doc\": {\n      \"properties\": {\n        \"attachments\": {\n          \"type\": \"nested\",\n          \"properties\": {\n            \"name\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"attachments\": [\n    {\"name\": \"AttachmentA\"},\n    {\"name\": \"AttachmentB\"},\n    {\"name\": \"AttachmentD\"}\n  ]\n}\n{\n  \"attachments\": [\n    {\"name\": \"AttachmentA\"},\n    {\"name\": \"AttachmentC\"},\n    {\"name\": \"AttachmentD\"}\n  ]\n}\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"nested\": {\n                  \"query\": {\n                    \"bool\": {\n                      \"must\": [\n                        {\n                          \"match_phrase\": {\n                            \"attachments.name\": {\n                              \"query\": \"AttachmentC\",\n                              \"slop\": 0,\n                              \"zero_terms_query\": \"NONE\",\n                              \"boost\": 1\n                            }\n                          }\n                        }\n                      ],\n                      \"adjust_pure_negative\": true,\n                      \"boost\": 1\n                    }\n                  },\n                  \"path\": \"attachments\",\n                  \"ignore_unmapped\": false,\n                  \"score_mode\": \"none\",\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}\n\n. What's wrong ? mine is ok\n\n. elasticsearch 6.4.0 support. https://github.com/NLPchina/elasticsearch-sql/issues/762. \u662f\u7684\u3002\n\u9488\u5bf9join\uff0c\u53ef\u80fd\u5b9e\u73b0\uff1a\n1\u3001\u4e0d\u8d70join\uff0c\u628a\u5b57\u6bb5\u90fd\u878d\u5408\u5230\u4e00\u4e2aindex\n2\u3001\u8d70nested\uff0cparent/child\uff0cterms-lookup\n3\u3001\u5148\u67e5\u8be2\uff0c\u518d\u6839\u636e\u67e5\u8be2\u7ed3\u679c\u805a\u5408\n4\u3001MultiSearchRequest\u4e24\u4e2a\u67e5\u8be2\uff0c\u81ea\u5df1\u505a\u7ed3\u679c\u5408\u5e76\n\u4e2a\u4eba\u5efa\u8bae\u8fd8\u662f\u5c3d\u91cf\u4e0d\u8981\u8d70join\uff0c\u628a\u5b57\u6bb5\u90fd\u878d\u5408\u5230\u4e00\u4e2aindex. \u55ef\u3002\u53e6\u5916\u51cf\u5c11es\u7684\u6570\u636e\u91cf\u5427\uff0c\u4ec5\u4ec5\u653e\u8981\u7528\u4e8e\u641c\u7d22\u7684\u51e0\u4e2a\u5173\u952e\u5b57\u6bb5\u5373\u53ef. \u597d\u5427\u3002\u3002\u3002 :sweat:. neo4j + es ? . sql\u5728es2\u91cc\u6ca1\u95ee\u9898\uff0c\u5728es5.4.2\u91cc\u51fa\u9519\uff1f. \u8bf7\u95ee\u8fd9\u6761sql\uff0c\u901a\u8fc7rest\u63a5\u53e3\u8c03\u7684\u8bdd\uff0c\u80fd\u6b63\u5e38explain\u5417\uff0c\u80fdsearch\u51fa\u7ed3\u679c\u5417\uff1f\nhttp://localhost:9200/_sql?sql=xxxxx\nhttp://localhost:9200/_sql/_explain?sql=xxxxx. \u7248\u672c\u4e0d\u4e00\u81f4\u7684\u5427\uff0c\u60a8\u5bf9\u9f50\u4e0b\u7248\u672c\u8bd5\u8bd5. \u8bf7\u95eeexplain\u53ef\u4ee5\u5417\uff1f. \u80fd\u63d0\u4f9b\u60a8\u7684sql\uff0c\u8fd8\u6709\u6570\u636e\u548c\u4ee3\u7801\u5757\u5417\uff1f\u7528\u7684jdbc\uff1f. 5.4.2\u9700\u8981\u81ea\u5df1package\u4e86. join\u662f\u5206\u4e24\u6b21\u67e5\u8be2\u5b9e\u73b0\u7684\u5662. \u5148scroll\u67e5\u8be2order_info\uff1a\njson\n{\"from\":0,\"size\":10000}\n\u518dscroll\u67e5\u8be2order_item\uff1a\njson\n{\"from\":0,\"size\":200}\n\u4e4b\u540e\u505a\u7684\u7ed3\u679c\u5408\u5e76\n. \u53ef\u4ee5explain\u5230dsl\u7684\u5427. \u5355\u72ec\u7528spring\u7684\u914d\u7f6e\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\">\n    <bean id=\"esDataSource\" class=\"com.alibaba.druid.pool.ElasticSearchDruidDataSource\" init-method=\"init\"\n          destroy-method=\"close\">\n        <property name=\"url\" value=\"jdbc:elasticsearch://127.0.0.1:9300/order_info\"/>\n    </bean>\n</beans>\n\u7136\u540e\u8c03\u7528\uff0c\u662f\u6ca1\u95ee\u9898\u7684\uff1a\n````\n        ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath*:application.xml\");\n        DruidDataSource dds = context.getBean(ElasticSearchDruidDataSource.class);\n        Connection connection = dds.getConnection();\n        PreparedStatement ps = connection.prepareStatement(\"SELECT * from order_info\");\n        ResultSet resultSet = ps.executeQuery();\n        List result = new ArrayList();\n        while (resultSet.next()) {\n            result.add(resultSet.getString(\"name\"));\n        }\n        System.out.println(result);\n    ps.close();\n    connection.close();\n    dds.close();\n\n````. \u662f\u4e0d\u662f\u54ea\u513f\u7684\u914d\u7f6e\u4e0d\u5bf9\u5462\uff0c\u80fd\u8d34\u4e00\u4e0b\u5b8c\u6574\u7684\u914d\u7f6e\u5417\uff0c\u6d89\u53camybatis\u7684\uff1f. \u96c6\u6210\u6d4b\u8bd5\uff1a\u914d\u7f6e\u6587\u4ef6 + java\u4ee3\u7801\napplication.xml:\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<bean id=\"esDataSource\" class=\"com.alibaba.druid.pool.ElasticSearchDruidDataSource\" init-method=\"init\" destroy-method=\"close\">\n    <property name=\"url\" value=\"jdbc:elasticsearch://127.0.0.1:9300/order_info\"/>\n</bean>\n\n<bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n    <property name=\"dataSource\" ref=\"esDataSource\"/>\n    <property name=\"configLocation\" value=\"SqlMapConfig.xml\"/>\n</bean>\n\n<bean id=\"testDao\" class=\"TestDaoImpl\">\n    <property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"/>\n</bean>\n\n\n```\nSqlMapConfig.xml:\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n\n<plugins>\n    <plugin interceptor=\"MyInterceptor\"/>\n</plugins>\n\n<mappers>\n    <mapper resource=\"Test.xml\"/>\n</mappers>\n\n\n```\nTest.xml:\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n\n<select id=\"test\">\n    SELECT COUNT(*) from order_info\n</select>\n\n\n```\nMyInterceptor.java:\n```java\nimport org.apache.ibatis.executor.statement.StatementHandler;\nimport org.apache.ibatis.plugin.*;\nimport org.apache.ibatis.session.ResultHandler;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.ResultSetMetaData;\nimport java.sql.Statement;\nimport java.util.*;\n@Intercepts({@Signature(type = StatementHandler.class, method = \"query\", args = {Statement.class, ResultHandler.class})})\npublic class MyInterceptor implements Interceptor {\n@Override\npublic Object intercept(Invocation invocation) throws Throwable {\n    PreparedStatement ps = (PreparedStatement) invocation.getArgs()[0];\n    try (ResultSet resultSet = ps.executeQuery()) {\n        String name;\n        ResultSetMetaData md = resultSet.getMetaData();\n        int count = md.getColumnCount(), i;\n        List<Map<String, Object>> result = new ArrayList<>();\n        Map<String, Object> map;\n        while (resultSet.next()) {\n            map = new HashMap<>();\n            for (i = 1; i <= count; ++i) {\n                map.put(name = md.getColumnName(i), resultSet.getObject(name));\n            }\n\n            result.add(map);\n        }\n        return result;\n    }\n}\n\n@Override\npublic Object plugin(Object target) {\n    return (target instanceof StatementHandler) ? Plugin.wrap(target, this) : target;\n}\n\n@Override\npublic void setProperties(Properties properties) {\n}\n\n}\n```\nTestDao.java\n```java\npublic interface TestDao {\nObject test() throws Exception;\n\n}\n```\nTestDaoImpl.java\n```java\nimport org.mybatis.spring.support.SqlSessionDaoSupport;\npublic class TestDaoImpl extends SqlSessionDaoSupport implements TestDao {\n@Override\npublic Object test() throws Exception {\n    return this.getSqlSession().selectOne(\"test.test\");\n}\n\n}\n```\nMain.java\n```java\nimport org.springframework.context.support.ClassPathXmlApplicationContext;\npublic class Main {\npublic static void main(String[] args) throws Exception {\n\n    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"classpath*:application.xml\");\n    TestDao testDao = context.getBean(\"testDao\", TestDao.class);\n\n    System.out.println(testDao.test());\n}\n\n}\n\u8f93\u51fa\uff1a\n````\n{COUNT(*)=1.0}\n````. \u6700\u65b0\u7248\u672c\uff0c\u53ef\u4ee5\u4e0d\u7528\u5199\u62e6\u622a\u5668\u4e86\u54c8. \u7528\u76846.2.4.4\uff1f\u4ee3\u7801\u8fd9\u6837\u7684\uff1f\n````\nProperties properties = new Properties();\nproperties.put(PROP_URL, \"jdbc:elasticsearch://127.0.0.1:9300/test\");\nproperties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true;xpack.security.user=elastic:5laftq1NilavFTibKOaZ\");\nDruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\nConnection connection = dds.getConnection();\nPreparedStatement ps = connection.prepareStatement(\"SELECT * from  test\");\nResultSet resultSet = ps.executeQuery();\nwhile (resultSet.next()) {\n    System.out.println(resultSet.getString(\"name\"));\n}\nps.close();\nconnection.close();\ndds.close();\n````. 9300\u8fde\u63a5\u4e0d\u4e0a\uff1fTransportClient\u7684\u7aef\u53e3\u662f\u3002\u3002\u3002\uff1f. \u53ea\u80fd\u5148\u6d4b\u901aTransportClient\u4e86\u3002\u3002\u3002. Thx\uff01. https://github.com/NLPchina/elasticsearch-sql/releases. [Precision control](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-cardinality-aggregation.html#_precision_control)\uff0c\u91cf\u4e0d\u5927terms\u805a\u5408\u6216\u8005\u5199\u811a\u672c\uff0c\u91cf\u5927\u5355\u72ec\u8ba1\u6570. http://localhost:8080/. https://github.com/NLPchina/elasticsearch-sql/issues/575. \u6709bug\uff0c\u8fd1\u671f\u4f1a\u4fee\u590d\uff0c\u83ab\u6025\u83ab\u6025\u54c8. https://github.com/NLPchina/elasticsearch-sql/commit/3ca7dfcab9f3e3207bf8f6d26a9ee7dbecf82d85json\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must_not\": [\n                    {\n                      \"bool\": {\n                        \"must_not\": [\n                          {\n                            \"exists\": {\n                              \"field\": \"overdue_level\",\n                              \"boost\": 1\n                            }\n                          }\n                        ],\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [],\n    \"excludes\": []\n  },\n  \"script_fields\": {\n    \"bee\": {\n      \"script\": {\n        \"source\": \"if(Function.identity().compose((o)->{def floor_1117674202 = Math.floor(doc['overdue_level'].value);floor_1117674202 == 2}).apply(null)){'a'} else if(Function.identity().compose((o)->{def floor_1613393573 = Math.floor(doc['overdue_level'].value);floor_1613393573 < 2}).apply(null)){'b'} else if(Function.identity().compose((o)->{def floor_1665333394 = Math.floor(doc['overdue_level'].value);floor_1665333394 > 2}).apply(null)){'c'} else {'d'}\",\n        \"lang\": \"painless\"\n      },\n      \"ignore_failure\": false\n    }\n  }\n}\n. [Regexp Query](https://github.com/NLPchina/elasticsearch-sql/issues/345) or [Script Query](https://github.com/NLPchina/elasticsearch-sql/wiki/ScriptQuery).sql\nSELECT firstname , balance FROM accounts WHERE firstname.keyword = REGEXP_QUERY('.[rR][aA][mM].')\nSELECT firstname , balance FROM accounts WHERE script('def firstname=doc[\"firstname.keyword\"].value;firstname!=null&&firstname.toLowerCase().contains(\"ram\")')\n```\nAlternatively, you can lowercase term, then use match query. Not supported now ! I'll add it soon !. Saturday or Sunday. sql\nSELECT * FROM test WHERE q=span_near(boost=10.0,slop=12,in_order=false,clauses='[{\"span_term\":{\"field\":\"value1\"}},{\"span_term\":{\"field\":\"value2\"}},{\"span_term\":{\"field\":\"value3\"}}]')\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"span_near\": {\n                  \"clauses\": [\n                    {\n                      \"span_term\": {\n                        \"field\": {\n                          \"value\": \"value1\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"span_term\": {\n                        \"field\": {\n                          \"value\": \"value2\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"span_term\": {\n                        \"field\": {\n                          \"value\": \"value3\",\n                          \"boost\": 1\n                        }\n                      }\n                    }\n                  ],\n                  \"slop\": 12,\n                  \"in_order\": false,\n                  \"boost\": 10\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. \u53ef\u4ee5\u5e26\u7684. \u7f16\u7801\u7684\u95ee\u9898\u5427\uff0c\u600e\u4e48\u8bf7\u6c42\u7684. \u53ef\u4ee5\u7528post\u7684\uff0c\u4e0d\u8fc7post\u7684\u8bdd\uff0c\u63d2\u4ef6\u63a5\u6536\u53c2\u6570\uff0c\u90a3\u5757\u513f\uff0c\u6709\u70b9\u95ee\u9898\uff0c\u9700\u8981\u6539\u6539. \n. \u8fd9\u4e00\u5757\uff0c\u8fd1\u671f\u4f1a\u6539\uff0c\u517c\u5bb9post\u4f20\u53c2. \n. 5.x\u6ca1\u6709\u554a\uff0c\u53ef\u4ee5\u53c2\u8003\u66f4\u65b0https://github.com/NLPchina/elasticsearch-sql/commit/4bdd75478c65fbfa7c83d01e97fad9597c86e851. \u5982\u4f55\u5728site server \u4e2d\u6dfb\u52a0\u8ba4\u8bc1\u4fe1\u606f. ````\nSettings.Builder settingsBuilder = \n  Settings.builder()\n  .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_KEYSTORE_FILEPATH,\"\")\n  .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_TRUSTSTORE_FILEPATH, \"\")\n  .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_KEYSTORE_PASSWORD, \"\")\n  .put(SSLConfigConstants.SEARCHGUARD_SSL_TRANSPORT_TRUSTSTORE_PASSWORD, \"\")\n  ...\n  Settings settings = settingsBuilder.build();\nTransportClient tc = \n  new PreBuiltTransportClient(settings, SearchGuardPlugin.class)\n  .addTransportAddress(...)\nSearchDao searchDao = new SearchDao(tc);\nSqlElasticRequestBuilder requestBuilder = searchDao.explain(\"SELECT * FROM test\").explain();\n// explain\nSystem.out.println(requestBuilder.explain());\n// execute\nSystem.out.println(requestBuilder..get());\n`. Version inconsistency\uff1f.sql\nSELECT * FROM myindex WHERE ['02E0001']='test'\n.sql\nselect * from index where field like 'test'\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"wildcard\": {\n                  \"field\": {\n                    \"wildcard\": \"test\",\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}\n. \u6709testcase\u5931\u8d25\uff0c\u5904\u7406\u4e0b\u5457\uff1f. \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff1f\u8fd9\u4e2a\u5728\u65b0\u7248\u672c\u91cc\u6709\u4fee\u590d\u7684. https://github.com/NLPchina/elasticsearch-sql/commit/5d370f15606da940473166c625b85ead391fc8b2. \u4e4b\u524d\u662f\u4e00\u4e2aconnection\u4f1a\u6709\u4e00\u4e2aclient\uff0c\u73b0\u5728\u662f\u4e00\u4e2adatasource\u4e00\u4e2aclient. \u53ef\u4ee5\u540c\u6b65\u4e0bmaster\u7684\u4ee3\u7801\uff0c\u66f4\u65b0\u4e0b. \u4e0d\u662f\u7684\uff0ccom.alibaba.druid.pool\uff0c\u8fd9\u4e2a\u5305\u4e0b\u7684\u4ee3\u7801\uff0c\u540c\u6b65\u66f4\u65b0\u4e0b. \u597d\u5427\uff0c\u8fd1\u671f\u7684\u8bdd\uff0c\u6211\u4f1a\u66f4\u65b0\u4e00\u72482.x\uff0c\u5230\u65f6\u5019\uff0c\u60a8\u518d\u770b\u770b. \u4e0d\u597d\u610f\u601d\u5565\uff0c\u6700\u8fd1\u6709\u70b9\u5fd9\uff0c\u8fd8\u6ca1\u6709\uff0c\u66f4\u65b0\u4e86\u901a\u77e5\u60a8. \u4fee\u6539\u4e00\u7248\uff0c\u672c\u5730\u6253\u4e2a\u5305\u5427. \u6700\u4e3b\u8981\u7684\u66f4\u6539\u662f\uff0celasticsearchclient\u7684\u521b\u5efa\u632a\u5230\u4e86datasource\u91cc\uff0c\u800c\u4e14\u4fdd\u8bc1\u5355\u4f8b\uff0c\u5e76\u4e14\u5728datasource\u7684close\u65b9\u6cd5\u91cc\u5173\u6389elasticsearchclient. connection\u5176\u5b9e\u4e3b\u8981\u662f\u6709\u4e00\u4e2a\u5f15\u7528\u4e86datasource\u91cc\u7684elasticsearchclient\u7684field. \u786e\u5b9e\u662f\u4e2abug. \u4f1a\u6539\u7684.json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"SUM\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"CNT\": {\n      \"sum\": {\n        \"script\": {\n          \"source\": \" def add_1621566800 = doc['Rcvd'].value + doc['Sent'].value;return add_1621566800;\",\n          \"lang\": \"painless\"\n        }\n      }\n    }\n  }\n}\n. \u4e0a\u9762\u6709\u53d8\u66f4\u4ee3\u7801\uff0c\u53ef\u4ee5\u770b\u770b\u54c8. \u597d\u7684\uff0c\u5148\u5f00\u7740\u5427. Not supported now\uff01.sql\nselect sum(script('14bb868d','\"\u6761\u76ee\u6570\".equals(doc[\"KPI\"].value)?1:0')) as '14bb868d',sum(script('f1a4e828','\"\u4ef6\u6570\".equals(doc[\"KPI\"].value)?1:0')) as 'f1a4e828' from yourIndex\n. 6.2.2\u7248\u672c\u4e0d\u652f\u6301\u7684\uff0c\u53ef\u4ee5\u53c2\u8003\u6700\u65b0\u5206\u652f\u4e0acom.alibaba.druid.pool\u8fd9\u4e2a\u5305\u4e0b\u7684\u4ee3\u7801. \u6700\u65b0\u5206\u652f\u4e0a\u662f\u652f\u6301\u7684. \u5982\u679c\u662f6.4.0\u7684\u8bdd\uff0c\u5efa\u8bae\u76f4\u63a5clone\u6700\u65b0\u5206\u652fmaster\u7684\u4ee3\u7801\uff0c\u7136\u540e\u4fee\u6539pom.xml\u91cc\u7684elasticsearch.version\u7684\u7248\u672c\u4e3a6.4.0\uff0c\u4e4b\u540e\u672c\u5730\u6253\u5305\u5373\u53ef.sql\nSELECT * FROM my_index where date_format(phDOB,'dd/MM/YYYY') >'22/11/2018'\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"def date_format_1266264528 = DateTimeFormatter.ofPattern('dd/MM/YYYY').withZone(ZoneId.systemDefault()).format(Instant.ofEpochMilli(doc['phDOB'].value.getMillis()));date_format_1266264528 > '22/11/2018'\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}\n. master branch. yeah\uff0cthe version of elasticsearch-sql corresponds to the version of elasticsearch. explain\u7684dsl\uff1ajson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match_phrase\": {\n                  \"id\": {\n                    \"query\": 374,\n                    \"slop\": 0,\n                    \"zero_terms_query\": \"NONE\",\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [],\n    \"excludes\": []\n  },\n  \"script_fields\": {\n    \"id\": {\n      \"script\": {\n        \"source\": \"doc['communityId'].value\",\n        \"lang\": \"painless\"\n      },\n      \"ignore_failure\": false\n    },\n    \"cid\": {\n      \"script\": {\n        \"source\": \"doc['cityId'].value\",\n        \"lang\": \"painless\"\n      },\n      \"ignore_failure\": false\n    }\n  }\n}\n. \u95ee\u9898\u89e3\u51b3\u4e86\uff1f. \u8fd9\u662f\u4e2abug\uff0c\u5148\u5f00\u7740\u54c8. \u6700\u65b0\u7248\u672c\u54c8. [script.max_compilations_rate](https://www.elastic.co/guide/en/elasticsearch/reference/6.5/modules-scripting-using.html)\n. What\uff1f. What\uff1f. In the near future. Have been released\uff01\uff01\uff01.sql\nSELECT * FROM myindex WHERE date_format(@timestamp, \"yyyy-MM-dd\", \"+08:00\")<'2018-11-18'\n```\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"def date_format_1947330295 = DateTimeFormatter.ofPattern('yyyy-MM-dd').withZone(ZoneId.of('+08:00')).format(Instant.ofEpochMilli(doc['@timestamp'].value.getMillis()));date_format_1947330295 < '2018-11-18'\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. +\u53f7\u4e22\u4e86\uff0curl\u7f16\u7801\u7684\u95ee\u9898\uff0c\u5982\u679c\u662fget\u8bf7\u6c42\uff0cencode\u4e00\u4e0b. \u3002\u3002\u3002\u3002\u3002\uff0c\u5b57\u7b26\u4e32\u4e0d\u652f\u6301\u6bd4\u8f83\u8fd0\u7b97\u3002\u3002\u3002\u3002. sql\nSELECT * FROM myindex WHERE date_format(@timestamp, \"yyyy-MM-dd\", \"+08:00\")<'2018-11-18'\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"def date_format_246955781 = DateTimeFormatter.ofPattern('yyyy-MM-dd').withZone(ZoneId.of('+08:00')).format(Instant.ofEpochMilli(doc['@timestamp'].value.getMillis()));((Comparable)date_format_246955781).compareTo('2018-11-18') < 0\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. \u8fd9\u662f\u4e2abug\u54c8\uff0c\u5df2\u4fee\u590d. https://github.com/NLPchina/elasticsearch-sql/commit/e9ed2cd2324aa73ac2b8309564742e016865e7b0. here. \u5b57\u6bb5\u540d. https://github.com/NLPchina/elasticsearch-sql/issues/768. @chenzhenguo   \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff0c\u6700\u65b0\u7248\u7684\u8bdd\uff0c\u62ff\u6570\u636e\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u76f4\u63a5\u901a\u8fc7index\u62ff\u4e86\uff0cgetObject(index). \u90a3\u4e00\u7248jdbc\u8fd9\u4e00\u5757\u7684\u5904\u7406\u4e0d\u592a\u597d\uff0c\u5efa\u8bae\u5728elastic2.4.6\u8fd9\u4e2a\u5206\u652f\u4e0a\u91cd\u65b0\u6253\u4e2a\u5305\u3002\u5177\u4f53\u539f\u56e0\uff0c\u53ef\u4ee5\u770b\u770bhttps://github.com/NLPchina/elasticsearch-sql/issues/790. \u76f4\u63a5resultSet.getObject(i) . getColumnCount \uff0c\u4e0d\u5e94\u8be5\u662f0\u554a\uff0c\u4e4b\u524d\u662f\u6709\u4e2abug\u7684\uff0c\u540e\u6765\u4fee\u590d\u4e86\uff0c\u60a8\u770b\u770b\u6253\u5305\u7684\u7248\u672c\uff0c\ncom.alibaba.druid.pool.ElasticSearchResultSetMetaDataBase\n\u8fd9\u4e2a\u7c7b\u7684\u4ee3\u7801\u548cElasticSearchResultSetMetaDataBase\u662f\u4e00\u81f4\u7684\u5417\uff1f. master\u5206\u652f\u4e0a\u7684\u6ca1\u95ee\u9898\u54c8. \u7528\u7684\u662f\u7236\u7c7b\u7684columns\n\n. \u53ef\u4ee5\u4e0d\u7528\u62e6\u622a\u5668\u63a7\u5236\u4e86\uff0c\u800c\u4e14\u8fd4\u56de\u503c\u53ef\u4ee5\u76f4\u63a5\u6839\u636emapper\u6587\u4ef6\u7684resultType\u8fd4\u56de\u6307\u5b9a\u7684\u7c7b\u578b\uff0c\u5df2\u5728\u6700\u65b0\u7248\u672c\u66f4\u65b0\u4ee3\u7801\uff0c\u8be6\u7ec6\uff0c\u8bf7\u770b\uff1a\nhttps://github.com/NLPchina/elasticsearch-sql/commit/ddddb9ebd6ecc1f0a528c69a259098d63610b65c. \u5df2\u66f4\u65b0\u54c8. \u786e\u4fddtransportclient\u80fd\u8fde\u4e0a\u96c6\u7fa4. \u75282.4.6.3\uff0ces\u7684\u7248\u672c\u662f2.4.6\u4e48\uff1f. TestCase\u90fd\u8dd1\u4e0d\u901a\uff1f\u5982\u679c\u8dd1\u4e0d\u901a\uff0c\u5f97\u68c0\u67e5\u68c0\u67e5\u60a8\u7684\u73af\u5883\u4e86\uff0c\u6211\u672c\u5730\u8bd5\u8fc7\uff0c\u662f\u6ca1\u6709\u95ee\u9898\u7684. \u5df2\u7ecf\u5728master\u4e86\uff0c\u53ef\u4ee5\u5728master\u5206\u652f\u4e0a\uff0c\u6539pom.xml\u91ccelasticsearch.version\u4e3a6.2.2\uff0c\u7136\u540e\u91cd\u65b0\u6253\u5305\uff1amvn clean package -DskipTests\uff0c\u4e0d\u51fa\u610f\u5916\u7684\u8bdd\uff0c\u95ee\u9898\u4e0d\u5927\u7684\n\n. \u5c11\u5305\u4e86\u5427\uff0c\u7f3a\u5c11guava\u5305. \u548cmybatis\u7684\u96c6\u6210\uff0c\u53ef\u4ee5\u53c2\u8003\u53c2\u8003\u8fd9\u4e2aissue\uff1a\nhttps://github.com/NLPchina/elasticsearch-sql/issues/808. curl -X GET \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM index\"\n}\n'. before\uff1a\ncurl -X GET \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\nSELECT * FROM index\n'\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\nSELECT * FROM index\n'. README.md has been updated. curl -X GET \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM my_index LIMIT 10\"\n}\n'\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM my_index LIMIT 10\"\n}\n'. \u652f\u6301\u7684\uff0c\u4e0d\u8fc7Content-Type\u5f97\u662fapplication/json. kibana\u4e5f\u662f\u53ef\u4ee5\u8bbf\u95ee\u7684\u54e6\uff1a\n\n. \u8fd9\u4e2a\u662fes\u7684\u9650\u5236\uff0c\u4e0a\u9762\u7684\u51fa\u9519\u4fe1\u606f\u662fes\u672c\u8eab\u629b\u51fa\u6765\u7684. \u6216\u8005\u53ef\u4ee5\u628a\u6570\u636e\u653e\u5728requestbody\u91cc. curl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\nSELECT * FROM my_index LIMIT 10\n'. \u63a5\u6536\u53c2\u6570\u8fd9\u5757\u513f\u505a\u4e86\u517c\u5bb9\uff1a\n1\u3001\u652f\u6301\uff08\u63a8\u8350\uff09\uff1a\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM my_index LIMIT 10\"\n}\n'\n2\u3001\u652f\u6301\uff1a\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\nSELECT * FROM my_index LIMIT 10\n'\n\n. use scroll query. sql\nSELECT * FROM myindex GROUP BY terms(alias='genres',field='genre',order='{\"_count\":\"asc\"}'). sql\nSELECT avg(price) AS avg_price FROM myindex GROUP BY terms(alias='colors',field='color',order='{\"avg_price\":\"asc\"}'). \u4e0d\u884c\u5427\uff0c\u4e3a\u5565\u4f1a\u7528\u8fd9\u79cd\u9700\u6c42\uff1f. long\u662f\u652f\u6301range\u67e5\u8be2\u7684. Haha\uff0cIn the near future\uff01\uff01\uff01. sql\nSELECT * FROM test2 WHERE _id NOT IN(1,2,3,6). alias\nsql\nSELECT\ncount(distinct url.keyword) as num\nFROM search_log_*\nwhere\nbt.keyword='purity_add_doc'\nand @timestamp>= '2018-12-13'\nand @timestamp<'2018-12-14'\nand purity_add_doc9=98\ngroup by date_histogram(alias='histogram', field='@timestamp','interval'='1d'). \u5f97\u770b\u600e\u4e48\u7528\u4e86\u3002\n\u5982\u679c\u662f\u4ee5\u63d2\u4ef6\u7684\u65b9\u5f0f\u5b89\u88c5\u5230es\u7684\u8bdd\uff0c\u5b89\u88c5\u5230\u90a3\u4e2a\u8282\u70b9\uff0c\u5c31\u80fd\u5728\u90a3\u4e2a\u8282\u70b9\u4f7f\u7528\uff1b\n\u5982\u679c\u662f\u4ee5jar\u5305\u7684\u65b9\u5f0f\uff0c\u96c6\u6210\u5230\u81ea\u5df1\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u8bdd\uff0c\u5c31\u4e0d\u7528\u5728es\u7684\u8282\u70b9\u91cc\u88c5\u4e86\u3002. demo\u7684\u8bdd\uff0c\u53ef\u4ee5\u770b\u770btestcase\uff1a\n```java\nSearchDao searchDao = new SearchDao(client);\nSqlElasticRequestBuilder requestBuilder = searchDao.explain(\"SELECT * FROM test\").explain();\n// explain\nSystem.out.println(requestBuilder.explain());\n// execute\nSystem.out.println(requestBuilder.get());\n```. try elasticsearch-sql-site-chrome\uff1a\n\n. https://github.com/NLPchina/elasticsearch-sql/issues/364. \u6ca1\u6709insert\u54e6. \u5df2\u4fee\u590d\u54c8\uff1ahttps://github.com/NLPchina/elasticsearch-sql/issues/800. sql\nSELECT COUNT(*) FROM property_info WHERE script(\"doc['info_owner_type'].value + doc['share_type'].value + doc['property_life'].value < 30\"). json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"doc['info_owner_type'].value + doc['share_type'].value + doc['property_life'].value < 30\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"COUNT\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"COUNT(*)\": {\n      \"value_count\": {\n        \"field\": \"_index\"\n      }\n    }\n  }\n}. having\u662f\u901a\u8fc7Bucket Script Aggregation\u6765\u5b9e\u73b0\u7684\uff0c\u73b0\u5728\u662f\u4e0d\u652f\u6301\u7684\u54e6. \u76ee\u524d\uff0c\u629b\u4e2a\u5f02\u5e38\u662f\u4e2a\u660e\u667a\u4e4b\u4e3e. sql\nSELECT roletype,userid,connectid,max(logtime) as maxTime,min(logtime) as entryTime FROM sdk_info_2018_12_22 WHERE appid='test900572e02867fab8131651339518' and roomid='987000' and sessionid='10f931ff-7abb-433a-ba00-5597327f1c85' group by roletype,terms(field='userid', alias='userid', size=200),terms(field='connectid',alias='connectid',size=200). size\u53ef\u4ee5\u81ea\u5b9a\u4e49\u54c8. \u73b0\u5728\u4e0d\u652f\u6301\u7684\uff0c\u53ef\u4ee5\u8003\u8651\u6dfb\u52a0\u7684\u54c8. sql\nSELECT /*! STATS(group1, group2) */ * FROM index\njson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"stats\": [\n    \"group1\",\n    \"group2\"\n  ]\n}. \u662f\u7684\u54e6. plugin\u66f4\u65b0\u4e86\u4e48\uff1f\u75286.5.4.7\u8fd9\u4e2a\u7248\u672c\uff0c\u91cd\u65b0\u6253\u4e2a\u5305\u66f4\u65b0\u4e0b\u63d2\u4ef6. \u6ca1\u6709\u54e6\uff0c\u9700\u8981\u81ea\u5df1\u672c\u5730\u6253\u5305\u7684. \u5361\u4e86\uff0c\u4e00\u822c\u662ftransportclient\u8fde\u63a5es\uff0c\u6709\u95ee\u9898. datasource bean\u662f\u5982\u4f55\u914d\u7f6e\u7684\u5462\uff1f\u53c8\u662f\u5982\u4f55\u4f7f\u7528datasource bean\u7684\uff0c\u662f\u76f4\u63a5\u7528\u7684jdbctemplate\u4e48\uff1f. \u4e0d\u9700\u8981\u914d\u7f6edriverClassName\uff0c\u8fd9\u6761\u8bed\u53e5\uff1a\nsql\nselect Con_Name , sum(Number_Value) from operator_stock_data where (Operation_Type='\u8d2d\u8fdb\u5165\u5e93') and (KPI='\u4ef6\u6570' or KPI='\u6761\u76ee\u6570')\nexplain\u540e\uff1a\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"match_phrase\": {\n                        \"Operation_Type\": {\n                          \"query\": \"\u8d2d\u8fdb\u5165\u5e93\",\n                          \"slop\": 0,\n                          \"zero_terms_query\": \"NONE\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"bool\": {\n                        \"should\": [\n                          {\n                            \"match_phrase\": {\n                              \"KPI\": {\n                                \"query\": \"\u4ef6\u6570\",\n                                \"slop\": 0,\n                                \"zero_terms_query\": \"NONE\",\n                                \"boost\": 1\n                              }\n                            }\n                          },\n                          {\n                            \"match_phrase\": {\n                              \"KPI\": {\n                                \"query\": \"\u6761\u76ee\u6570\",\n                                \"slop\": 0,\n                                \"zero_terms_query\": \"NONE\",\n                                \"boost\": 1\n                              }\n                            }\n                          }\n                        ],\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"Con_Name\",\n      \"SUM\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": \"Con_Name\",\n  \"aggregations\": {\n    \"SUM(Number_Value)\": {\n      \"sum\": {\n        \"field\": \"Number_Value\"\n      }\n    }\n  }\n}. \u4f9d\u8d56\u5305\uff1a\norg.elasticsearch:elasticsearch:${elasticsearch.version}\norg.elasticsearch.client:x-pack-transport:${elasticsearch.version}\ncom.google.guava:guava:15.0\ncom.alibaba:druid:1.0.15\norg.nlpcn:elasticsearch-sql:x.x.x.x. sql\nselect Con_Name,Goods_Type , SUM(Number_Value + Number_Value) AS FF from operator_warehouse_data where (Operation_Type='\u8d2d\u8fdb\u5165\u5e93') and (KPI='\u4ef6\u6570' or KPI='\u6761\u76ee\u6570') group by Con_Name,Goods_Type\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"match_phrase\": {\n                        \"Operation_Type\": {\n                          \"query\": \"\u8d2d\u8fdb\u5165\u5e93\",\n                          \"slop\": 0,\n                          \"zero_terms_query\": \"NONE\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"bool\": {\n                        \"should\": [\n                          {\n                            \"match_phrase\": {\n                              \"KPI\": {\n                                \"query\": \"\u4ef6\u6570\",\n                                \"slop\": 0,\n                                \"zero_terms_query\": \"NONE\",\n                                \"boost\": 1\n                              }\n                            }\n                          },\n                          {\n                            \"match_phrase\": {\n                              \"KPI\": {\n                                \"query\": \"\u6761\u76ee\u6570\",\n                                \"slop\": 0,\n                                \"zero_terms_query\": \"NONE\",\n                                \"boost\": 1\n                              }\n                            }\n                          }\n                        ],\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"Con_Name\",\n      \"Goods_Type\",\n      \"SUM\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": [\n    \"Con_Name\",\n    \"Goods_Type\"\n  ],\n  \"aggregations\": {\n    \"Con_Name\": {\n      \"terms\": {\n        \"field\": \"Con_Name\",\n        \"size\": 200,\n        \"min_doc_count\": 1,\n        \"shard_min_doc_count\": 0,\n        \"show_term_doc_count_error\": false,\n        \"order\": [\n          {\n            \"_count\": \"desc\"\n          },\n          {\n            \"_key\": \"asc\"\n          }\n        ]\n      },\n      \"aggregations\": {\n        \"Goods_Type\": {\n          \"terms\": {\n            \"field\": \"Goods_Type\",\n            \"size\": 10,\n            \"min_doc_count\": 1,\n            \"shard_min_doc_count\": 0,\n            \"show_term_doc_count_error\": false,\n            \"order\": [\n              {\n                \"_count\": \"desc\"\n              },\n              {\n                \"_key\": \"asc\"\n              }\n            ]\n          },\n          \"aggregations\": {\n            \"FF\": {\n              \"sum\": {\n                \"script\": {\n                  \"source\": \" def add_754649670 = doc['Number_Value'].value + doc['Number_Value'].value;return add_754649670;\",\n                  \"lang\": \"painless\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}. SUM(Number_Value) + 1\uff0c\u8fd9\u4e2a\u662f\u4e0d\u652f\u6301\u7684\u54e6. \u6069\u6069\uff0c\u8fd1\u671f\u4f1a\u652f\u6301\u7684~. https://github.com/NLPchina/elasticsearch-sql/releases/tag/5.6.14.0. json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"date\",\n      \"MAX\"\n    ],\n    \"excludes\": []\n  },\n  \"stored_fields\": \"date\",\n  \"aggregations\": {\n    \"band\": {\n      \"max\": {\n        \"field\": \"band\"\n      }\n    }\n  }\n}. \u53d6date\u5f97\u8d70tophits\uff1a\nsql\nSELECT topHits('size'=1,'alias'='hits',include='date'), MAX(band) AS band FROM ['table']\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"_source\": {\n    \"includes\": [\n      \"topHits\",\n      \"MAX\"\n    ],\n    \"excludes\": []\n  },\n  \"aggregations\": {\n    \"hits\": {\n      \"top_hits\": {\n        \"from\": 0,\n        \"size\": 1,\n        \"version\": false,\n        \"explain\": false,\n        \"_source\": {\n          \"includes\": [\n            \"date\"\n          ],\n          \"excludes\": []\n        }\n      }\n    },\n    \"band\": {\n      \"max\": {\n        \"field\": \"band\"\n      }\n    }\n  }\n}. explain\u5462\uff1f. sql\nSELECT * FROM myindex WHERE title = matchQuery('quick brown fox', boost = 2)\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match\": {\n                  \"title\": {\n                    \"query\": \"quick brown fox\",\n                    \"operator\": \"OR\",\n                    \"prefix_length\": 0,\n                    \"max_expansions\": 50,\n                    \"fuzzy_transpositions\": true,\n                    \"lenient\": false,\n                    \"zero_terms_query\": \"NONE\",\n                    \"auto_generate_synonyms_phrase_query\": true,\n                    \"boost\": 2\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. Query String Query VS Match Query. boost example\uff1a\nsql\nSELECT * FROM myindex WHERE q=query('field:search^5')\nOr\nsql\nSELECT * FROM myindex WHERE q=query('field:search', boost=5). operator or minimum_should_match not supported now, I'll add it in the future. https://github.com/NLPchina/elasticsearch-sql/wiki/Installation-Guide. \n. Sorry\uff0cI don't know that.. sql\nSELECT * FROM myindex WHERE title = matchQuery('quick brown fox', boost = 2, operator = 'and', minimum_should_match = '75%')\njson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"match\": {\n                  \"title\": {\n                    \"query\": \"quick brown fox\",\n                    \"operator\": \"AND\",\n                    \"prefix_length\": 0,\n                    \"max_expansions\": 50,\n                    \"minimum_should_match\": \"75%\",\n                    \"fuzzy_transpositions\": true,\n                    \"lenient\": false,\n                    \"zero_terms_query\": \"NONE\",\n                    \"auto_generate_synonyms_phrase_query\": true,\n                    \"boost\": 2\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. clone source code\uff0clocal package\uff0creplace elasticsearch-sql-x.x.x.x.jar\uff0cbut you should update codes before package. elasticsearch-sql-6.2.4.0.zip\n. https://github.com/NLPchina/elasticsearch-sql/issues/863. Not supported\uff01. \u4e0d\u4e00\u5b9a\u5bf9\u54c8\uff0c\u4e0d\u8fc7\u60a8\u53ef\u4ee5\u53c2\u8003\u53c2\u8003\u7684\uff1a\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"aggs\": {\n    \"user\": {\n      \"terms\": {\n        \"field\": \"user\"\n      },\n      \"aggs\": {\n        \"kqtime\": {\n          \"terms\": {\n            \"script\": {\n              \"source\": \"doc['kqtime'].value.toInstant().atZone(ZoneId.systemDefault()).format(DateTimeFormatter.ofPattern('yyyy-MM-dd HH:mm:dd'))\",\n              \"lang\": \"painless\"\n            }\n          },\n          \"aggs\": {\n            \"min-kqtime\": {\n              \"min\": {\n                \"field\": \"kqtime\"\n              }\n            },\n            \"kqtime-count\": {\n              \"bucket_script\": {\n                \"buckets_path\": {\n                  \"kqtime\": \"min-kqtime\"\n                },\n                \"script\": \"def kqtime=Instant.ofEpochMilli(params.kqtime.longValue()).atZone(ZoneId.systemDefault()).format(DateTimeFormatter.ofPattern('HH:mm:dd'));kqtime.compareTo('08:30:00')>0?1:0\"\n              }\n            }\n          }\n        },\n        \"sum-kqtime\": {\n          \"sum_bucket\": {\n            \"buckets_path\": \"kqtime>kqtime-count\"\n          }\n        }\n      }\n    }\n  }\n}. just try latest version~. just try latest version~. sql\nSELECT * FROM test3 where nested('message',message.info = matchquery('c') and message.author =matchquery('h') )\njson\n{\n  \"from\": 0,\n  \"size\": 200,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"nested\": {\n                  \"query\": {\n                    \"bool\": {\n                      \"must\": [\n                        {\n                          \"bool\": {\n                            \"must\": [\n                              {\n                                \"match\": {\n                                  \"message.info\": {\n                                    \"query\": \"c\",\n                                    \"operator\": \"OR\",\n                                    \"prefix_length\": 0,\n                                    \"max_expansions\": 50,\n                                    \"fuzzy_transpositions\": true,\n                                    \"lenient\": false,\n                                    \"zero_terms_query\": \"NONE\",\n                                    \"auto_generate_synonyms_phrase_query\": true,\n                                    \"boost\": 1\n                                  }\n                                }\n                              },\n                              {\n                                \"match\": {\n                                  \"message.author\": {\n                                    \"query\": \"h\",\n                                    \"operator\": \"OR\",\n                                    \"prefix_length\": 0,\n                                    \"max_expansions\": 50,\n                                    \"fuzzy_transpositions\": true,\n                                    \"lenient\": false,\n                                    \"zero_terms_query\": \"NONE\",\n                                    \"auto_generate_synonyms_phrase_query\": true,\n                                    \"boost\": 1\n                                  }\n                                }\n                              }\n                            ],\n                            \"adjust_pure_negative\": true,\n                            \"boost\": 1\n                          }\n                        }\n                      ],\n                      \"adjust_pure_negative\": true,\n                      \"boost\": 1\n                    }\n                  },\n                  \"path\": \"message\",\n                  \"ignore_unmapped\": false,\n                  \"score_mode\": \"none\",\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. fixed in the future. json\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"nested\": {\n                  \"query\": {\n                    \"bool\": {\n                      \"must\": [\n                        {\n                          \"bool\": {\n                            \"must\": [\n                              {\n                                \"match_phrase\": {\n                                  \"comments.message\": {\n                                    \"query\": \"hello\",\n                                    \"slop\": 0,\n                                    \"zero_terms_query\": \"NONE\",\n                                    \"boost\": 1\n                                  }\n                                }\n                              },\n                              {\n                                \"range\": {\n                                  \"comments.likes\": {\n                                    \"from\": 3,\n                                    \"to\": null,\n                                    \"include_lower\": false,\n                                    \"include_upper\": true,\n                                    \"boost\": 1\n                                  }\n                                }\n                              }\n                            ],\n                            \"adjust_pure_negative\": true,\n                            \"boost\": 1\n                          }\n                        }\n                      ],\n                      \"adjust_pure_negative\": true,\n                      \"boost\": 1\n                    }\n                  },\n                  \"path\": \"comments\",\n                  \"ignore_unmapped\": false,\n                  \"score_mode\": \"none\",\n                  \"boost\": 1,\n                  \"inner_hits\": {\n                    \"ignore_unmapped\": false,\n                    \"from\": 0,\n                    \"size\": 3,\n                    \"version\": false,\n                    \"explain\": false,\n                    \"track_scores\": false\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. \u683c\u5f0f\u4e0d\u5339\u914d\uff0c\u9ed8\u8ba4\u662fyyyy-MM-dd HH:mm:ss\uff0c\u52a0\u4e2aformat\u5427\uff0c\u6539\u6210\uff1a\ndate_histogram(field='aiops_timestamp','interval'='1d','alias'='aiops_timestamp','min_doc_count'='0','extended_bounds'='1547083500000:1547343000000',format='epoch_millis'). \u751f\u6210\u7684dsl\uff1a\njson\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"aggregations\": {\n    \"aiops_timestamp\": {\n      \"date_histogram\": {\n        \"field\": \"aiops_timestamp\",\n        \"format\": \"epoch_millis\",\n        \"interval\": \"1d\",\n        \"offset\": 0,\n        \"order\": {\n          \"_key\": \"asc\"\n        },\n        \"keyed\": false,\n        \"min_doc_count\": 0,\n        \"extended_bounds\": {\n          \"min\": \"1547083500000\",\n          \"max\": \"1547343000000\"\n        }\n      }\n    }\n  }\n}. extended_bounds\u73b0\u5728\u662f\u4e0d\u652f\u6301\u5199\uff1a2019-01-10 00:00:00\uff0c\u8fd9\u79cd\u683c\u5f0f\u7684\uff0c\u8fd9\u4e00\u5757\uff0c\u8fd1\u671f\u4f1a\u505a\u4f18\u5316\uff0c\u652f\u6301\n\u5199\uff1a{ \"min\": \"1547083500000\",\"max\": \"1547343000000\"}. \u6ca1\u6709\u8fd4\u56de\u7a7a\u6876\uff1f\u8bf7\u95ee\uff0c\u60a8\u662f\u7528\u7684jdbc\u62ff\u7684\u7ed3\u679c\u96c6\u4e48\uff1f. sql\nSELECT * FROM myindex WHERE field = REGEXP_QUERY('hadi s*', 'INTERSECTION|COMPLEMENT|EMPTY', 10000)\njson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"regexp\": {\n                  \"field\": {\n                    \"value\": \"hadi s*\",\n                    \"flags_value\": 7,\n                    \"max_determinized_states\": 10000,\n                    \"boost\": 1\n                  }\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff1f\u6700\u65b0\u7248\u672c\u4e00\u4e2adatasource\u53ea\u4f1a\u6709\u4e00\u4e2aclient\u7684. \u8fd9\u4e2a\u7248\u672c\u4e0d\u884c\u54e6\uff0c\u8fd9\u91cc\u624d\u4fee\u590d\u7684\n\u5efa\u8bae\u60a8clone\u6700\u65b0\u5206\u652f\uff0c\u7136\u540e\u540c\u6b65\u63d2\u4ef6com.alibaba.druid.pool\u5305\u4e0b\u7684\u6240\u6709\u4ee3\u7801\uff0c\u7136\u540e\u672c\u5730\u6253\u5305\uff0c\u66f4\u65b0\u63d2\u4ef6. \u8fd9\u51e0\u4e2a\u5b57\u6bb5\u7684mapping\u80fd\u7ed9\u4e0b\u4e48\uff1f. \u4e0d\u597d\u610f\u601d\u54c8\uff0c\u662f\u652f\u6301\u7684\uff1a\nsql\nselect * from stanlee_decision-engine_2019-01-15 where commitId>0 \nand (timeStamp between 1547501223173 and 1547537223173) \nand (nested(rule,rule.name = 'test_7')) \ngroup by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),\n(nested(rule.name)),\nnested(rule.result.strValue),\nfilter('rule.result.name', rule.result.name=TERM('verdict')). json\n{\n  \"from\": 0,\n  \"size\": 0,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"range\": {\n                        \"commitId\": {\n                          \"from\": 0,\n                          \"to\": null,\n                          \"include_lower\": false,\n                          \"include_upper\": true,\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"range\": {\n                        \"timeStamp\": {\n                          \"from\": 1547501223173,\n                          \"to\": 1547537223173,\n                          \"include_lower\": true,\n                          \"include_upper\": true,\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"nested\": {\n                        \"query\": {\n                          \"bool\": {\n                            \"must\": [\n                              {\n                                \"match_phrase\": {\n                                  \"rule.name\": {\n                                    \"query\": \"test_7\",\n                                    \"slop\": 0,\n                                    \"boost\": 1\n                                  }\n                                }\n                              }\n                            ],\n                            \"adjust_pure_negative\": true,\n                            \"boost\": 1\n                          }\n                        },\n                        \"path\": \"rule\",\n                        \"ignore_unmapped\": false,\n                        \"score_mode\": \"none\",\n                        \"boost\": 1\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"aggregations\": {\n    \"time\": {\n      \"date_histogram\": {\n        \"field\": \"timeStamp\",\n        \"format\": \"yyyy-MM-dd HH:mm\",\n        \"interval\": \"10m\",\n        \"offset\": 0,\n        \"order\": {\n          \"_key\": \"asc\"\n        },\n        \"keyed\": false,\n        \"min_doc_count\": 0\n      },\n      \"aggregations\": {\n        \"rule.name@NESTED\": {\n          \"nested\": {\n            \"path\": \"rule\"\n          },\n          \"aggregations\": {\n            \"rule.name\": {\n              \"terms\": {\n                \"field\": \"rule.name\",\n                \"size\": 1000,\n                \"shard_size\": 20000,\n                \"min_doc_count\": 1,\n                \"shard_min_doc_count\": 0,\n                \"show_term_doc_count_error\": false,\n                \"order\": [\n                  {\n                    \"_count\": \"desc\"\n                  },\n                  {\n                    \"_key\": \"asc\"\n                  }\n                ]\n              },\n              \"aggregations\": {\n                \"rule.result.strValue@NESTED\": {\n                  \"nested\": {\n                    \"path\": \"rule.result\"\n                  },\n                  \"aggregations\": {\n                    \"rule.result.name@FILTER\": {\n                      \"filter\": {\n                        \"bool\": {\n                          \"must\": [\n                            {\n                              \"term\": {\n                                \"rule.result.name\": {\n                                  \"value\": \"verdict\",\n                                  \"boost\": 1\n                                }\n                              }\n                            }\n                          ],\n                          \"adjust_pure_negative\": true,\n                          \"boost\": 1\n                        }\n                      },\n                      \"aggregations\": {\n                        \"rule.result.strValue\": {\n                          \"terms\": {\n                            \"field\": \"rule.result.strValue\",\n                            \"size\": 1000,\n                            \"shard_size\": 20000,\n                            \"min_doc_count\": 1,\n                            \"shard_min_doc_count\": 0,\n                            \"show_term_doc_count_error\": false,\n                            \"order\": [\n                              {\n                                \"_count\": \"desc\"\n                              },\n                              {\n                                \"_key\": \"asc\"\n                              }\n                            ]\n                          }\n                        }\n                      }\n                    }\n                  }\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}. \u4e0d\u652f\u6301\u7684. \u55ef\u55ef\uff0cgroup by nested\u7684\u522b\u540d\u662f\u4e0d\u652f\u6301\u7684. filter\u540e\u9762\u53ef\u4ee5\u63a5\u591a\u4e2a\u6761\u4ef6\u7684\uff1a\nfilter('rule.name',rule.name=TERM('test_7') and rule.result.name=TERM('verdict')). sql\nselect * from stanlee_decision-engine_2019-01-15 where commitId>0 \nand (timeStamp between 1547501223173 and 1547537223173) \nand (nested(rule,rule.name = 'test_rule_7')) \ngroup by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),\nnested(rule.name),\nfilter('rule.name',rule.name=TERM('test_rule_7')),\nnested(rule.result.strValue),\nfilter('rule.result.name', rule.result.name=TERM('verdict')). \u4e0a\u9762\u7684sql\u6267\u884c\u662f\u6709\u95ee\u9898\u7684\uff0c\u5728\u8fd9\u91cc\u505a\u4e86\u4fee\u590d\uff0c\u5982\u679c\u7528\u7684\u8bdd\uff0c\u8bb0\u5f97\u66f4\u65b0\u54c8. \u76ee\u524d\u8fd9\u65b9\u9762\u7684\u6587\u6863\uff0c\u662f\u6ca1\u6709\u7684\u54e6\uff0c\u73b0\u5728\u6709\u7684\u662f\u4e00\u4e9btestcase\uff0c\u91cc\u9762\u6709\u4e00\u4e9bgroup by filter\u7684\u793a\u4f8b\uff0c\u53ef\u4ee5\u53c2\u8003\u53c2\u8003\u54c8. https://github.com/NLPchina/elasticsearch-sql/issues/819. If you want to update changes, you should clone source code, import to IDE, modify elasticsearch.version in pom.xml to 6.2.4, resolve compile failure, package it locally. \n:point_right:  elasticsearch-sql-6.2.4.0.zip  :point_left:\n. ScriptQuery. Oh~~~\uff0climit not supported now\uff01:sweat:. :ok_hand:. https://github.com/NLPchina/elasticsearch-sql/commit/f8ee5b6fc40d40073e76ab80ba35b9e0975e1016. sql\ndelete from myindex limit 3. Alternative\uff0cwhy not to try elasticsearch-sql-site-chrome. \u4e00\u822c\u662ftransportclient\u8fde\u63a5\u6709\u95ee\u9898\uff0c\u5efa\u8bae\u5148\u8c03\u901atransportclient\uff0c\u7136\u540e\u5347\u7ea7essqljdbc\u7248\u672c\u5230\u6700\u65b0. \u6682\u65f6\u6ca1\u6709\u7684\u54c8. \u5982\u679c\u662f\u4f7f\u7528\u7684jdbc\uff0c\u53ef\u4ee5\u7528PreparedStatement\uff0c\u4e0d\u8fc7\u73b0\u5728\u63d2\u4ef6\u4e0d\u652f\u6301PreparedStatement\u7684setparameter\uff0c\u5426\u5219\u53ef\u4ee5\u5bf9sql\u8bed\u53e5\u672c\u8eab\u8fdb\u884c\u4e00\u4e9b\u5b57\u7b26\u7684\u8fc7\u6ee4. https://github.com/NLPchina/elasticsearch-sql/issues/543. \u8bd5\u7740\uff0c\u6ca1\u95ee\u9898\u7684\u54e6\nsql\nselect * from index1,index2 where commitId>0 and (timeStamp between 1548215295788 and 1548301695788) and processCode='aaa' and (nested(multidecisiontable,multidecisiontable.name = 'tongdun_joina'))\njson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must\": [\n                    {\n                      \"range\": {\n                        \"commitId\": {\n                          \"from\": 0,\n                          \"to\": null,\n                          \"include_lower\": false,\n                          \"include_upper\": true,\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"range\": {\n                        \"timeStamp\": {\n                          \"from\": 1548215295788,\n                          \"to\": 1548301695788,\n                          \"include_lower\": true,\n                          \"include_upper\": true,\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"match_phrase\": {\n                        \"processCode\": {\n                          \"query\": \"aaa\",\n                          \"slop\": 0,\n                          \"zero_terms_query\": \"NONE\",\n                          \"boost\": 1\n                        }\n                      }\n                    },\n                    {\n                      \"nested\": {\n                        \"query\": {\n                          \"bool\": {\n                            \"must\": [\n                              {\n                                \"match_phrase\": {\n                                  \"multidecisiontable.name\": {\n                                    \"query\": \"tongdun_joina\",\n                                    \"slop\": 0,\n                                    \"zero_terms_query\": \"NONE\",\n                                    \"boost\": 1\n                                  }\n                                }\n                              }\n                            ],\n                            \"adjust_pure_negative\": true,\n                            \"boost\": 1\n                          }\n                        },\n                        \"path\": \"multidecisiontable\",\n                        \"ignore_unmapped\": false,\n                        \"score_mode\": \"none\",\n                        \"boost\": 1\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}. \u6211\u7528\u7684\u662f\u6700\u65b0\u7248. elasticsearch SQL plugin wiki may be helpful to you. add dependency:\n```xml\n\n\nelasticsearch-releases\nhttps://artifacts.elastic.co/maven\n\ntrue\n\n\nfalse\n\n\n\n\n    ...\n    \norg.elasticsearch\nelasticsearch\n6.5.4\n\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>x-pack-transport</artifactId>\n    <version>6.5.4</version>\n</dependency>\n...\n\n\n.sql\nSELECT firstname, balance FROM accounts where firstname.keyword <> REGEXP_QUERY('robo', 'INTERSECTION|COMPLEMENT|EMPTY', 10000)\njson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"bool\": {\n                  \"must_not\": [\n                    {\n                      \"regexp\": {\n                        \"firstname.keyword\": {\n                          \"value\": \"robo\",\n                          \"flags_value\": 7,\n                          \"max_determinized_states\": 10000,\n                          \"boost\": 1\n                        }\n                      }\n                    }\n                  ],\n                  \"adjust_pure_negative\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"firstname\",\n      \"balance\"\n    ],\n    \"excludes\": []\n  }\n}\n.sql\nselect * from file1 where cast(offset as int) > 20\njson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"script\": {\n                  \"script\": {\n                    \"source\": \"def field_2099360277 = Double.parseDouble(doc['offset'].value.toString()).intValue();((Comparable)field_2099360277).compareTo(20) > 0\",\n                    \"lang\": \"painless\"\n                  },\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  }\n}\n. https://github.com/NLPchina/elasticsearch-sql/issues/819.java\nSearchDao searchDao = new SearchDao(client);\nSystem.out.println(searchDao.explain(\"select * from myindex\").explain().explain());\n. RestSqlAction.java\u52a0\u7684\u6709\u95ee\u9898\uff0c\u53c2\u6570preference\u5f97\u653e\u5230responseParams\u91cc. conflicts hint is needed, like this:sql\nDELETE /! CONFLICTS(proceed) / FROM index LIMIT 100\n. because this hint not supported now. Of course. what\u2018s problem\uff1f.sql\nSELECT filed FROM index  WHERE field_2 LIKE 'a&UNDERSCOREb%'\n. you should use [query_string](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html):sql\nselect filed from index where q=query('field_2:a\\?b\\')\n. I test latest version\uff0cit's ok\uff0cjust return `a*d`. My explain\uff1ajson\n{\n  \"from\": 0,\n  \"size\": 1000,\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"bool\": {\n            \"must\": [\n              {\n                \"query_string\": {\n                  \"query\": \"filed:a\\d\",\n                  \"fields\": [],\n                  \"type\": \"best_fields\",\n                  \"default_operator\": \"or\",\n                  \"max_determinized_states\": 10000,\n                  \"enable_position_increments\": true,\n                  \"fuzziness\": \"AUTO\",\n                  \"fuzzy_prefix_length\": 0,\n                  \"fuzzy_max_expansions\": 50,\n                  \"phrase_slop\": 0,\n                  \"escape\": false,\n                  \"auto_generate_synonyms_phrase_query\": true,\n                  \"fuzzy_transpositions\": true,\n                  \"boost\": 1\n                }\n              }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n          }\n        }\n      ],\n      \"adjust_pure_negative\": true,\n      \"boost\": 1\n    }\n  },\n  \"_source\": {\n    \"includes\": [\n      \"filed\"\n    ],\n    \"excludes\": []\n  }\n}\n. What's yours\uff1f.xml\n\n\nelasticsearch-releases\nhttps://artifacts.elastic.co/maven\n\ntrue\n\n\nfalse\n\n\n\n. add dependency jars, thenjava\nSearchDao searchDao = new SearchDao(esClient);\nSqlElasticRequestBuilder requestBuilder = searchDao.explain(\"SELECT * FROM test\").explain();\n// explain\nSystem.out.println(requestBuilder.explain());\n// execute\nSystem.out.println(requestBuilder.get());\n. \u6ca1\u540c\u6b65\u66f4\u65b0\uff0c\u53ef\u4ee5\u76f4\u63a5\u672c\u5730\u6253\u5305\u7684. [elasticsearch-sql-5.4.1.0.zip](https://github.com/NLPchina/elasticsearch-sql/files/2905095/elasticsearch-sql-5.4.1.0.zip)\n. \u6069\u6069\uff0c\u51c6\u5907\u5f80maven\u4e2d\u592e\u4ed3\u5e93\u91cc\u53d1. \u53ef\u4ee5\u5199\u4e00\u4e2a\u901a\u7528\u7684RowMapper\uff0c\u5982\u679c\u7528\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u501f\u52a9\u6846\u67b6\u672c\u8eab\uff0c\u6bd4\u5982spring jdbc\u3001mybatis.sql\nselect created,customer_first_address \nfrom packages-\nwhere date_format(created,'yyyy-MM-dd HH:mm:ss') >= '2019-02-28 17:00:00' \norder by created desc limit 10\n. \u53ef\u4ee5\u7528group bysql\nselect * from table group by field\n. \u652f\u6301count distinct\u7684\uff1asql\nselect count(distinct field) from myindex\n.sql\nselect /! ROUTINGS(user1,user2)*/ * from myindex\n. ROUTINGS\uff0c\u662f\u901a\u8fc7hint\u6765\u5b9e\u73b0\u7684\uff0c\u5982\u679c\u8981\u9a8c\u8bc1\uff0c\u53ef\u4ee5\u6267\u884csearch\u9a8c\u8bc1\u4e0b\u5373\u53ef. https://github.com/NLPchina/elasticsearch-sql/issues/892. elasticsearch-sql\uff0c\u7531\u4e8e\u4e2d\u592e\u4ed3\u5e93\u6ca1\u6709\u66f4\u65b0\uff0c\u9700\u8981\u81ea\u5df1installxml\n\norg.nlpcn\nelasticsearch-sql\n${essql.version}\n\n\norg.elasticsearch\nelasticsearch\n${elasticsearch.version}\n\n\norg.elasticsearch.client\nx-pack-transport\n${elasticsearch.version}\n\n. \u6069\u6069\uff0c\u9700\u8981\u4f9d\u8d56\uff0cdruid. node.result.numValue\uff0c\u8fd9\u4e2amapping\u80fd\u63d0\u4f9b\u4e0b\u4e48\uff1f.sql\nselect * from stanlee_decision-engine_2019-02-23 where nested(\"node\", nested(\"node.result\", node.result.numValue=1))\n. \u8fd9\u4e48\u5199\u6ca1\u95ee\u9898\u7684\uff0cinputs.name\u5305\u542bname. \u8fd9\u4e2a\u5c31\u662finputs.name\u7684\u503c\u5305\u542b\u67d0\u4e2a\u5b57\u7b26\u4e32. https://github.com/NLPchina/elasticsearch-sql/issues/701. \u6069\u6069\uff0c\u8003\u8651\u8003\u8651. not supported. \u53ef\u4ee5\u7528include/exclude\uff0c\u4f8b\u5982\uff1asql\nSELECT balance, include('*Name'), exclude('lastName') FROM bank\n```. https://github.com/NLPchina/elasticsearch-sql/issues/575. curl -X GET \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'select * from indexName limit 10'. ",
    "knoguchi": "Thanks for your response, and the alternative solution!    Would you please enlighten me why it can't be parsed?  Isn't the columns in WHERE clause expression same as column expressions in the SELECT in terms of AST?\n. It's great if the bracket notation is consistent in any expressions.  Will that work for ORDER BY as well?\n. Thanks for the commit.  I will check out and test away.\n. ",
    "javadevmtl": "Ok maybe needs to be thought of. Basically we need to do my_date >= \"now/d\" and my_date <= \"now/d\"\n. Same goes for conditions and searching seems very similar. Maybe I can help.\n. 2.3.0 and I created a children branch\nOn Apr 15, 2016 11:26 AM, \"Eliran Moyal\" notifications@github.com wrote:\n\nThanks , from which branch did you forked?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/pull/197#issuecomment-210504952\n. I already did no? See the pull request on github children... it's\nthe first time I make a pull request maybe a I did it wrong? But I see it\non your github...\nOn Apr 15, 2016 2:42 PM, \"Eliran Moyal\" notifications@github.com wrote:\nso can u make the pull request to branch 2.3.0?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/pull/197#issuecomment-210588926\n. Ok I get it. I made my pull request against master right?\n. Yeah not sure why it's failing. It's not because of code the documents\nreturned don't match. I can test the query from the front end it works fine\nOn Apr 15, 2016 4:18 PM, \"Eliran Moyal\" notifications@github.com wrote:\nCool, can you add tests?\ncheckout MainTestSuite to add a mapping and a json file with data to load\nafter it add test to TestQuery class like nestedQuery tests.\nI also see it broke one test of nestedqueries tests the \"nestedOnInQuery\"\ntest so it failing the build.\nI will look on it tomorrow if you are having trouble\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/pull/198#issuecomment-210625872\n. Ok I added some tests for children. Not sure why nestedOnInQuery fails for nested tests. But if you take the query and paste into the front end click explain it generates the es dsl correctly. Then you can just paste it in sense and run it works fine...\n\nI commented it out, can you check it please?\n. Cool let me know what you think...\nOn Apr 26, 2016 6:34 AM, \"Eliran Moyal\" notifications@github.com wrote:\n\nMerged #198 https://github.com/NLPchina/elasticsearch-sql/pull/198.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/pull/198#event-641284449\n. \n",
    "classtag": "\u6211\u770b\u652f\u6301\u554a\uff0c\u6211\u76f4\u63a5\u6539\u4e86\u4e0bversion\uff0c\u7248\u672c\u53f7\n. not working \nException like this\non ui show:\nError: {\"error\":\"InvalidIndexNameException[[_sql] Invalid index name [_sql], must not start with '_']\",\"status\":400}\nconsole is here:\norg.elasticsearch.indices.InvalidIndexNameException: [_sql] Invalid index name [_sql], must not start with '_'\n    at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validateIndexName(MetaDataCreateIndexService.java:172)\n    at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.validate(MetaDataCreateIndexService.java:551)\n    at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService.access$200(MetaDataCreateIndexService.java:88)\n    at org.elasticsearch.cluster.metadata.MetaDataCreateIndexService$2.execute(MetaDataCreateIndexService.java:230)\n    at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:374)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:204)\n    at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:167)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n. I restart the service and there is not a index named start with '_'\n. ",
    "sindhusingh": "Actually i am already using NEST C# Plugin and having a lot of code wriiten in that according to my requirements. Now i am trying to find a way with C#, so that i can directly fire SQL to elastic via C#, in that case i don't need to re write my old whole code again. \n. ",
    "Ghost93": "@eliranmoyal what about cardinality aggreagation?\nIt may be used as some kind of distinct...\n. ",
    "yangaoquan": "@eliranmoyal, @ansjsun, Thanks a lot. I was ready to use native DSL statement\n. ",
    "rahuldaskar": "Hi @eliranmoyal \nI think * and ? should also be escaped equivalent to % and _ respectively.\n. As stated here-https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#wildcards\nI used backslash but select query is not working.\nBelow is the query that my code is forming-\n_SELECT * FROM index/documentype WHERE  fieldname like '&STAR&BACKSLASH*&STAR'\nHere I should get only those records having * in their field name. But I am getting all the records instead.\nP.S. I used &STAR for * and &BACKSLASH for \\ since comment formatter is removing them.\n. Thanks @eliranmoyal ! Two backslashes worked for me!. ",
    "lgoldstein": "It is not very important to me for the time being, however it would be nice to fix in some upcoming release if it is not too difficult.\n. ",
    "gkluoe": "Ah, great - I hadn't noticed that. Thanks!\n. ",
    "bassduh": "Thanks for pointing me in the right direction.\nHad tried some things with script-function, but didn't work for me.\nAfter all, it seems groovy was not enabled in ES.\nNow it is working fine:\nTimestamp   myFormat\n2016-01-21T12:09:51.0962625Z    2016-01-21 13:09:51\n2016-01-21T12:09:50.8532531Z    2016-01-21 13:09:50\n. Thanks, i'm using 1.4.8 right now.\nAs i'm using elasticsearch 2.x right now, there is no longer a need for me to get this working on 1.x.\n. ",
    "prof-schacht": "Hey, \nThis would be great.\nBR\n. ",
    "Shashi-GS": "I wanted to achieve the below sql query. \nselect sum(distinct target), sum(amount) from ams group by product\ni.e., here is the data table.\n\nI am able to achieve the sum of grouped elements, but not able to achieve the sum of distinct values from a column.\n. Thank you so much for the info. it is really helpful.\n. Sorry! this question is not specific to elasticsearch-sql. I am using the transport client JAVA API, there it ignores the configuration of the elasticsearch.yml file. I wanted to set all the fields as not_analyzed in while inserting the data into elasticsearch. it is not storing the data with not analyzed and it is splitting as tokens.\n. ",
    "crazrain": "+1\n. ",
    "cdonnellytx": "+1\n. FWIW, I did a fork of the repo and tried doing a naive upgrade (just version bump in .travis.yml, pom.xml), installed Maven, and was unable to build it.  Not sure if it's my setup (Windows 10 /JDK 1.8 / Maven 3.3.9), if there's some other dependency that needs to be bumped somewhere that I am unaware of, or changes to Elasticsearch that need to be accounted for:\nelasticsearch-sql.log.txt\nI suspect it's the last one, but don't have time to debug it myself.\n. They just released a 2.3.2 yesterday (2016-04-28).\nIs there a particular reason you do separate builds for each point release?  Major/minor I understand, but not point releases, since the APIs aren't supposed to change...\n. ",
    "pedrocolon93": "Hi, if you could, push the changes done to support 2.2.0.  I found the source in releases, but I could not find it within the repository\n. Nevermind, must be that I failed switching branches. \n. ",
    "ajqc": "i want to convert sql to elasticsearch dsl, like this:\nsql:\nselect * from a where fielda='b'\ni want to get this dsl by elasticsearch-sql:\n```\n{\n  \"query\": {\n    \"term\": {\n      \"fielda\": \"b\"\n    }\n  }\n}\n```\n. i need dsl,not search result or sql\n. thank you very much!!!\n. ",
    "fpk7660837": "i'm glad to hear that.thanks\n. ",
    "levylll": "@eliranmoyal OK\uff0cThank you very much\uff01\n. ",
    "marksnoopy": "got it , thanks\n. ",
    "githubmui": "Is it possible (in principal) to write an ES-SQL-Plugin in a way, that it's supporting a whole release-tree e.g. 2.1.x or 2.2.x? \nCurrently for each version an individual plugin release is needed.\nWhat are the technical reasons for that: e.g. always changing APIs or Query-DSL changes?\n. Thank you very much for your support! I really appreciate this plugin project.\nAs you explained, the JSON approach would be more universal and would improve the benefits of this plugin. Another advantages would be to have the SQL-To-QueryDSL functionality in a portable way: e.g. for usage on client side.\nDo you think that this could/should be a feature for the roadmap of the plugin?\n. Great roadmap and I like your idea with a Sql2Json-JavaScript ! \nBut first go ahead with your master degree.\n. 1+\n. ",
    "aylwynlake": "move zip outside plugins directory will work. ",
    "Selvinaz1984": "I have put the jars in elasticsearch/lib and then the error is away.\nNow I get the Error: {\"error\":\"ParserException[illegal sql expr : SELECT * FROM 'esh;event;event_0.4;2015-04-20_00-00-00-000;2015-04-26_23-59-59-999'/EventBean WHERE version='1.6']\",\"status\":500}.\nOut indices are created dynamically per week, and if I want to put a sql query for all known indeces, how I can do this? Does the Parser exception occurs due to the name of index containing \".\" and \";\"??\n. Does the index name must follow a specific notation? Do constraints exist?\n. Will I also receive results with for example LINE=880?\nI just want events with BLOCK=880, no LINE=880.\nAnd what is the query notation if I want to combine tweo attribute queries, for example BLOCK=880 and LINE=7?\n. I have tested already this query. \nSELECT * FROM eventindextest1/EventBean where nested('attributes',attributes.paramkey='BLOCK' and attributes.value=880) and nested('attributes',attributes.paramkey='LINE' and attributes.value=7)\nbut receive following error:\nError: {\"error\":\"SqlParseException[AND is err!]\",\"status\":500}??\n. Hi,\nthanks veryy much :) Will it be a newer release 1.4.9 for Elasticsearch 1.X?\n. Hello Eliran,\nI have checked out the code for ES-Plugin 2.3.1 and changed the code in ESActionFactory.create(Client client, String sql), so that in case of DELETE also a SQLFeatureNotSupportedException will be thrown. I want to make this feature configurable but I have seen that there does not exist a configuration file which is used internally in the code, just es-plugin.properties which is generally needed by ES. But I want to commit this change in Git so that at each update we do not want to change this point in code manually each time.\nWhat du you propose?\n. Will there be a fix soon?\n. Hello version 2.3.1.\n. There is no problem if I use the web UI, but I want to have a csv export over REST api via statement format=csv it leads to nullpointerexecption.\n. [2016-07-25 13:00:53,282][WARN ][rest.suppressed          ] /_sql Params: {format=csv, sql=select * from esh;event;event_0.4;2016-06-20_00-00-00-000;2016-06-26_23-59-59-999 where source.sourceType='VEHICLE'}\njava.lang.NullPointerException\n    at org.elasticsearch.plugin.nlpcn.executors.CSVResultsExtractor.findFieldValue(CSVResultsExtractor.java:300)\n    at org.elasticsearch.plugin.nlpcn.executors.CSVResultsExtractor.createCSVLinesFromDocs(CSVResultsExtractor.java:248)\n    at org.elasticsearch.plugin.nlpcn.executors.CSVResultsExtractor.extractResults(CSVResultsExtractor.java:45)\n    at org.elasticsearch.plugin.nlpcn.executors.CSVResultRestExecutor.execute(CSVResultRestExecutor.java:29)\n    at org.elasticsearch.plugin.nlpcn.RestSqlAction.handleRequest(RestSqlAction.java:45)\n    at org.elasticsearch.rest.BaseRestHandler.handleRequest(BaseRestHandler.java:54)\n    at org.elasticsearch.rest.RestController.executeHandler(RestController.java:205)\n    at org.elasticsearch.rest.RestController.dispatchRequest(RestController.java:166)\n    at org.elasticsearch.http.HttpServer.internalDispatchRequest(HttpServer.java:128)\n    at org.elasticsearch.http.HttpServer$Dispatcher.dispatchRequest(HttpServer.java:86)\n    at org.elasticsearch.http.netty.NettyHttpServerTransport.dispatchRequest(NettyHttpServerTransport.java:449)\n    at org.elasticsearch.http.netty.HttpRequestHandler.messageReceived(HttpRequestHandler.java:61)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.elasticsearch.http.netty.pipelining.HttpPipeliningHandler.messageReceived(HttpPipeliningHandler.java:60)\n    at org.jboss.netty.channel.SimpleChannelHandler.handleUpstream(SimpleChannelHandler.java:88)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:145)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.jboss.netty.handler.codec.http.HttpContentDecoder.messageReceived(HttpContentDecoder.java:108)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)\n    at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)\n    at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)\n    at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:435)\n    at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)\n    at org.elasticsearch.common.netty.OpenChannelsHandler.handleUpstream(OpenChannelsHandler.java:75)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)\n    at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:559)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)\n    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)\n    at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:108)\n    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337)\n    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:89)\n    at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)\n    at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)\n    at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n. I Have fixed this bug, it occurrs if the value of the header is null, I have changed the line doc.get(header).toString() to String.valueOf(doc.get(header)). Do I have to make a pull request now?\n. ",
    "nathan-zhu": "i use es 2.2 and es-sql is 2.2\ndownload linke is here: https://github.com/NLPchina/elasticsearch-sql/archive/master.zip\n. @eliranmoyal thanks, very much. i got it works now.\n. @MartinKan \u53d1\u73b0\u4f60\u4e86\uff0c\u54c8\u54c8\n. ",
    "that-dom": "+1 please and thank you.\n. ",
    "userguy": "Rest api works but how to use it from curl command .. can you share with exaple  -- curl -XGET 'http://IP:9200/_sql?'\n. ",
    "madkoala": "You can use elasticsearch-sql with curl.\nUse following command line syntax:\ncurl -XPOST \"http://localhost:9200/_sql\" -d \"SELECT * FROM your_index LIMIT 10\"\n. @GuoYuan-DiYiDan Could you please let me know how to build this against ES 2.4.0? I'm not familiar with maven build system and elastic search plugin architecture. Thanks.\n. Great! Thank you for your effort!!\n. You can build plugin package which supports ES 2.4.2 with very simple changes on pom.xml.\nJust change version of elasticsearch from 2.4.1 to 2.4.2.. ",
    "webgori": "@KangYongKyun thank you\n. ",
    "kevinvn1709": "It worked well. Thanks your works :+1: \n. Thanks all.\nI solved my problem with a helper from programming language. But, I think you should modify format number from source code, because elasticsearch works almost with a huge data and number. So, this feature is really essential.\n. ",
    "WilsonHo": "oh, this is limit the number of row, I would like a min_doc_count. https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-bucket-terms-aggregation.html#_minimum_document_count_3\n. thank you so much... :+1: \n. I'am using elasticsearch-sql 2.2.0.\nThank you\n. Thanks you\n. Maybe it would help you\nDouble value = new Double(1234546789);\nString str = new DecimalFormat(\"#\").format(value);\n. 1. How about if the sub-query same index and not same index? Because sometimes I would like a sub-query same index and sometimes not.\n2. I have a different field, maybe it's deviceId, tripId...\n. Thanks you\n. Oh so now I have a problem, I would like to query FROM a query\nselect count(field2) from  (select field1, field2 from secondIndex where name='A' group by field1, field2) \ngroup by field1\nCan I implement this query?\nThank you\n. And how could I use GROUP BY with no limit ?\nThank you so much.\nI am looking forward for your help.\n. hello, please help me\n. @eliranmoyal yes, thank you, I think so. But when I test by using nodejs to request like this\nconst request = require('request')\nvar url = 'http://test.server:9200/_sql?sql=SELECT * FROM demoIndex';\nfor(let i = 0; i < 10000; i+=1){\n  setTimeout(()=>{\n    request.get(url, (error, response, body) =>{\n      if (error) console.log(error);\n    })\n  }, 100)\n}\nI checked netstat -nat and saw the system use many port and get error  { [Error: read ECONNRESET] code: 'ECONNRESET', errno: 'ECONNRESET', syscall: 'read' }. So how can I have just one connection?\nThank you\n. ",
    "tongchuanwei": "select * from monitor \nwhere result.Content.formattedSql like 'SELECT COUNT(1) AS totalCount FROM (SELECT ID, SYSTEM_NAME, SYSTEM_CODE, SYSTEM_DOMAIN, DEPLOY_POINTS , CACHE_KEY, CACHE_VALUE, CACHE_INDEX, STATUS, DETAILS , CREATE_TIME, UPDATE_TIME FROM DOMAIN WHERE 1 = 1 LIMIT 0, 110 ) _a%'    \n. i  can't  get  this result.\n. {\n    \"from\": 0,\n    \"size\": 200,\n    \"query\": {\n        \"filtered\": {\n            \"filter\": {\n                \"bool\": {\n                    \"must\": {\n                        \"query\": {\n                            \"wildcard\": {\n                                \"result.Content.formattedSql\": {\n                                    \"wildcard\": \"SELECT COUNT(1) AS totalCount FROM (SELECT ID, SYSTEM?NAME, SYSTEM?CODE, SYSTEM?DOMAIN, DEPLOY?POINTS , CACHE?KEY, CACHE?VALUE, CACHE?INDEX, STATUS, DETAILS , CREATE?TIME, UPDATE?TIME FROM DOMAIN WHERE 1 = 1 LIMIT 0, 110 ) ?a*\"\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n. thank you  very  much!\n. ",
    "zhiaixuexi": "@jekey is that effective for kettle ?\n. +1\n. @Diwahars @seanyoo \nhi guys,\nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/2.3.3.0\n2.3.3 supported now ~\n. great,help me too\n. ",
    "lynshang": "@eliranmoyal  i want go get all the records, not only 10000\n. done,i find the error. yes, source is a column, and used the stander analyzer . ",
    "ghost": "@nathan-zhu  \u63e1\u4e2a\u6293~\n. LGDM\n. Maybe you have to uncheck \"Flat Results\" in Options/Show Settings\n. thanks,thats worked!\n. Fixed the problem by manually fixing the elastic query..  - first call \"http://elastic:9200/_sql/_explain\"\n - second\n     - remove terms order\n     - add terms {\"order\": { \"orderbyvalue\": \"desc\" }}\n     - add aggregations \"{\"orderbyvalue\": { \"sum\": { \"field\": \"id\" } }}\" \n - Finally call this query . ",
    "gem360": "from here selected branch 2.3.0 and downloaded zip, unfortunately our server has no internet access.\n. ",
    "thiagomata": "+1\n. ",
    "haroboro": "nice work!\n. ",
    "ruippeixotog": "It would be great to have the plugin published in Maven for people to use as a library. I am not in a position to install new plugins on an existing Elasticsearch instance, but I still want to be able to compile SQL queries to ES queries (basically, to call new SearchDao(client).explain(sqlQuery).explain().toString).\nThanks for the great plugin, this is very useful!\n. ",
    "beta-beta": "Hi, Filter aggregations how to support this sql\uff1a\nselect sum( case label when 'send' then 1 else 0 end) as send_cnt, sum( case label when 'show' then 1 else 0 end) as show_cnt, sum( case label when 'click' then 1 else 0 end) as click_cnt from ad_table group by label ;\nthanks!\n. ",
    "alexott": "Would be very useful to get the new release...\nMaybe there is a way to specify wildcard version, at least inside the major releases?\n. Thank you!\n. ",
    "dadoonet": "Yes. It's a new policy we have. We want to make sure that a plugin has been tested with the version it is supposed to run on.\nIt creates more work for sure for plugin authors but is a way safer for our users.\n. ",
    "anuxs": "\u7528\u4e86\u4e00\u6bb5\u65f6\u95f4\uff0c\u786e\u5b9e\u89e3\u51b3\u4e86\u3002\u8bdd\u8bf4\u6211\u8fd8\u4e13\u95e8\u770b\u4e86\u53d8\u66f4\u8bb0\u5f55\uff0c\u5230\u5e95\u54ea\u4e9b\u5730\u65b9\u9700\u8981\u6539\u7248\u672c\u53f7\u3002\n. ",
    "tingking23": "\u6211\u5728\u672c\u5730\u5355\u8282\u70b9\u6d4b\u8bd5\u6ca1\u6709\u95ee\u9898\u80fd\u7528\uff0c\u4f46\u662f\u4e3a\u5565\u5b50\u653e\u5230\u96c6\u7fa4\u4e0a\u9762\u5c31\u62a5\u9519\u4e86\uff1f \u62a5status 400\u7684\u9519\uff0c\u662f\u4e0d\u662f\u96c6\u7fa4\u8fd8\u6709\u5176\u4ed6\u9700\u8981\u914d\u7f6e\uff1f\n. \u53ef\u4ee5\u4e86\uff0c\u4e0d\u597d\u610f\u601d\uff0c\u96c6\u7fa4\u8fd8\u6709\u5176\u4ed6\u4eba\u5728\u52a8\uff0c\u9648\u6211\u4e0d\u6ce8\u610f\u7ed9\u88c5\u4e86\u4e2ashild\u6743\u9650\uff0c\u4e0d\u8fc7\u8fd9\u4e2asql\u754c\u9762\u8fd8\u662f\u80fd\u8fdb\uff0c\u7136\u540e\u5c31\u662f\u641c\u4e0d\u5230\u7ed3\u679c\uff0c\u8f93\u5165\u96c6\u7fa4\u7684\u5e10\u53f7\u5bc6\u7801\u8fdb\u53bbsql\u754c\u9762\u5c31\u597d\u4e86\n. ",
    "lvshuchengyin": "Hi, could you share your solution? Thanks!. ",
    "Carlos-Mosquera": "Did you have plan add TermsQueries??? https://www.elastic.co/guide/en/elasticsearch/reference/2.1/query-dsl-terms-query.html or https://www.elastic.co/guide/en/elasticsearch/client/net-api/current/terms-lookup-query-usage.html\n. ",
    "lephix": "Thanks for your advice. Problem solved.\n. ",
    "rapoth": "Sorry for opening this issue. I just found some relevant material on the Wiki. \nhttps://github.com/NLPchina/elasticsearch-sql/wiki/NestedTypes-queries\n. ",
    "shruthi0925": "Also to mention we are using Elasticsearch 2.2.1 version\n. ",
    "superqp": "problem has been solved by using :\nhttps://github.com/NLPchina/elasticsearch-sql/releases/tag/2.3.1.0\n. ",
    "cyber4ron": "Got it. Thanks.\n. ",
    "seanyoo": "+1\n. ",
    "Dooy": "I got answer\nsql\nSELECT count(distinct user_id) as user_id,count(distinct school) as school \nFROM bank group by city\nThanks\n. ",
    "happyshows": "sorry , my bad.\n. when I tried\nSELECT * FROM test    <- test is my index name, I saw below error, is this because of wrong installation?\nError: {\"error\":{\"root_cause\":[{\"type\":\"invalid_index_name_exception\",\"reason\":\"Invalid index name [sql], must not start with ''\",\"index\":\"sql\"}],\"type\":\"invalid_index_name_exception\",\"reason\":\"Invalid index name [_sql], must not start with ''\",\"index\":\"_sql\"},\"status\":400}\nThen I tried  http://localhost:9200/_sql?sql=select%20*%20from%20test%20limit%2010\n{\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"No feature for name [_sql]\"}],\"type\":\"illegal_argument_exception\",\"reason\":\"No feature for name [_sql]\"},\"status\":400}\n. ",
    "gunererd": "+1\n. ",
    "zhaochl": "I have the same question,export data less than the query results,do you solved it ?. I know how to export the whole data,\n1) set 'Show Settings' all checked,and set scroll per shard = -1 \n2)set  'Download setting' checked, \n3) when sql select add limit -1(default limit 20)\nIf any problem,give me the message.. yes,the query result is 5000,but export data is still 200. I know how to export the whole data,\n1) set 'Show Settings' all checked,and set scroll per shard = -1 \n2)set  'Download setting' checked, \n3) when sql select add limit -1(default limit 20)\nIf any problem,give me the message.. ",
    "qiao-meng-zefr": "Hi I end up exporting without using this plugin, and didn't use this sql plugin very often.. Excellent! Thank you!. ",
    "avisri": "Can this be done using url / api params ?  \nPS:  _sql/scroll  is not supported . Had to  fall back on  _search/scroll  after the initial _sql?&scroll=1m  call . \n. ",
    "tqyq": "issue still exists in 2.3.5\nsuch as:\nhttp://eshost/_sql?sql=select * from symbol where exchange='nyse'&format=csv\ndata sample:\n\"_source\": {\n\"sector\": \"Consumer Services\",\n\"ipo_year\": null,\n\"market_cap\": 23671428,\n\"name\": \"A.H. Belo Corporation\",\n\"exchange\": \"nyse\",\n\"symbol\": \"AHC\",\n\"last_sale\": 574,\n\"industry\": \"Newspapers/Magazines\"\n}\nyou see, ipo_year is null, it outputs:\n{\n\"error\": {\n\"root_cause\": [\n{\n\"type\": \"null_pointer_exception\",\n\"reason\": null\n}\n],\n\"type\": \"null_pointer_exception\",\n\"reason\": null\n},\n\"status\": 500\n}\n. Thanks!\n. ",
    "gastonwu": "\u540c\u5173\u6ce8\n. ",
    "Danier-Evens": "\u540c\u5173\u6ce8\uff0c\u652f\u6301having\u5426\uff1f\nselect a, count(1) as count from A\nwhere c=\"aaa\"\ngroup by a\nhaving count >10\n. ",
    "michael-ancestor": "\u540c\u5173\u6ce8\uff0c\u652f\u6301having\u5426\uff1f\nselect a, count(1) as count from A\nwhere c=\"aaa\"\ngroup by a\nhaving count >10. crate\u8fd9\u4e2a\u9879\u76ee\u5e95\u5c42\u7528\u7684\u4e5f\u662fes,\u770b\u5b83\u7684document\uff0c\u652f\u6301\u4e86sub query\u3001group by...having\u4ee5\u53cajoin,\u5e0c\u671b[ealsticsearch-sql]\u4e5f\u80fd\u8d76\u4e0a. ",
    "xiaoshao": "same issue. Cloud I install 2.4.1 in ES 2.4? seems it does not work. there is no version 2.4.2 for ES.  I can use 2.4.2 in which ES version?. ",
    "chenyg0911": "push up!. http://localhost:8080/?username=elastic&password=changeme\n2017-07-27 16:29 GMT+08:00 ly853602 notifications@github.com:\n\nanother question confused me,how can i add username and password when i\nvisit web/sql in brower\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/383#issuecomment-318295472,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhIVzLSyl9SuoTOrOQPpJj-qRguQTks5sSEp9gaJpZM4MC0PF\n.\n. https://github.com/NLPchina/elasticsearch-sql/issues/455. Maybe you should enable CORS on elasticsearch.yml and restart ES.. follow the issue #364 \nuse:\nhttp://localhost:8080/?username=elastic&password=changeme&base_uri=encodedURI\nI still can't connect to es correctly!\nWhat's the problem?\nuse elasticsearch_head, the same manner:\nhttp://localhost:9100/?auth_user=elastic&auth_password=changeme\nworking well on es head with CORS defineded.\n. what's u mean? es:5.4.1, sql-site I download it last month.. \n\n. anonymous? no auth on http head.. Will re-download the lastest version to try.. update to  sql_site.It seam auth ok.\nbut still not working as normal.\nshould be add more cors in elasticsearch.yml?\nmy core definition:\n\n---------------------------------- http cors ---------------------------------\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: Authorization\n\n. \u4e0d\u77e5\u9053\u5565\u539f\u56e0\u4e86\u3002\n\n. OK. updated the ES cors config, It work now. Thanks!. \u81ea\u5df1\u7528\u751f\u6210query body\uff0c\u518d\u7a0d\u7a0d\u6539\u4e00\u4e0b\uff0c\u5c31\u53ef\u4ee5\u4e86\u3002\n\u5982\u67e5\u8be2count(*) >2\u7684\u7ed3\u679c\uff1a\n         \"aggs\": {\n            \"make_count\": {\n               \"value_count\": {\n                  \"field\": \"_index\"\n               }\n            },\n               \"make_count_bucket_filter\": {\n                  \"bucket_selector\": {\n                     \"buckets_path\": {\n                        \"makeCount\": \"make_count\"\n                     },\n                     \"script\": \"params.makeCount > 2\"\n                  }\n               }\n     }\n\n. \nwhere script(\"doc['c'] = 'xxx\")\n. \u7528script\n2017-07-13 11:05 GMT+08:00 token01 notifications@github.com:\n\n\u8bf7\u95eeselect * from table where clum1 <> clum2\u600e\u4e48\u67e5\uff1f\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/465, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/APRMhLp3MkCyOmSr3_y27ByAKH9m1eIaks5sNYlsgaJpZM4OWcmi\n.\n. \u7c7b\u4f3c\uff1awhere script(\"doc['clum1'] == doc['clum2'] ). plugin\u8981\u91cd\u88c5\u5417\uff1f. \u6b63\u5e38\u5b89\u88c5\uff0c\u4f7f\u7528\u4e2d\u3002\n\n2017-08-09 10:07 GMT+08:00 shiyuan notifications@github.com:\n\n\u6ca1\u95ee\u9898\u7684\uff1a\n[image: 1]\nhttps://user-images.githubusercontent.com/8057153/29102268-7a309358-7cea-11e7-858b-5eb56e490e05.png\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/483#issuecomment-321131830,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhK7m6dw7zljK_sMI-P39KXsJlleyks5sWRRPgaJpZM4Oxd5r\n.\n. \u8fd9\u4e2a\u5c31\u662f\u4e0b\u8f7d\u89e3\u538b\uff0c\u7136\u540enode node-server.js\uff0cOK\u4e86\u3002\n\n2017-08-09 12:14 GMT+08:00 goodqinjin notifications@github.com:\n\n\u5982\u4f55\u79bb\u7ebf\u5b89\u88c5\u8fd9\u4e2a\u554a\uff1f\u670d\u52a1\u5668\u4e0d\u80fd\u8fde\u63a5\u5916\u7f51\u3002\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/484, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/APRMhPzZONbxm_Y00-C-pUXcnJtkA1oKks5sWTIegaJpZM4Oxkra\n.\n. \u54e6\u3002npm\u662f\u6bd4\u8f83\u9ebb\u70e6\u3002\u4f60\u53ef\u4ee5\u5728\u8054\u7f51\u7684\u5730\u65b9\u5b89\u88c5\u597d\uff0c\u518d\u5168\u76ee\u5f55\u62f7\u8d1d\u8fc7\u53bb\u3002\n\n2017-08-09 13:09 GMT+08:00 goodqinjin notifications@github.com:\n\n@chenyg0911 https://github.com/chenyg0911\ncd site-server\nnpm install express --save\nnode node-server.js\n\u6211\u77e5\u9053\u5b89\u88c5\u6b65\u9aa4\uff0c\u4f46\u662f\u80fd\u5426\u624b\u52a8\u53bb\u5b89\u88c5\u4e0d\u8981\u8fd0\u884cnpm&node\u547d\u4ee4\uff1f\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/484#issuecomment-321154218,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhF9W--qKm88eIeDAmR-y7GxKuN0Qks5sWT8kgaJpZM4Oxkra\n.\n. \u627e\u4e2a\u80fd\u8054\u7f51\u7684\u5730\u65b9\u7684\u88c5\u554a\u3002\u4e0d\u80fd\u8054\u7f51\u53c8\u600e\u4e48\u7ed9\u4f60\uff1f\n\n2017-08-09 13:46 GMT+08:00 goodqinjin notifications@github.com:\n\n@chenyg0911 https://github.com/chenyg0911 \u6211\u6ca1\u6709\u8fd9\u6837\u7684\u73af\u5883\u53bb\u5b89\u88c5\uff0c\u4f60\u80fd\u5e2e\u5fd9\u5b89\u88c5\u4e0b\u5417\uff1f\u8c22\u8c22\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/484#issuecomment-321158819,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhKABPxUgPDVfjuTNhCt_Pvh4UuRWks5sWUe8gaJpZM4Oxkra\n.\n. http.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: \"X-Requested-With, Content-Type, Content-Length,\nAuthorization\"\n\n2017-08-23 10:55 GMT+08:00 Jake Hu notifications@github.com:\n\nHi I'm also have this problem,Using Elasticsearch Port 9200 and SHOW \"\nError: Error occured! response is not avalible.\"\nSorry Where is Config?\nadd down this commend?\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/496#issuecomment-324207016,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhEvsMKQjcocR0TTjhFXx8iWV_gP_ks5sa5S4gaJpZM4O9MN6\n.\n. elasticsearch.yaml\n\n2017-08-23 11:03 GMT+08:00 Jake Hu notifications@github.com:\n\nMany Thanks.\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: \"X-Requested-With, Content-Type, Content-Length,\nAuthorization\"\nThis http.cors.enabled: true adding where PATH or file?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/496#issuecomment-324208032,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhH-psVkV5VtoamG8p65S1EwD_kKAks5sa5aMgaJpZM4O9MN6\n.\n. \u8fd9...\u3002put \u521b\u5efa\u4e00\u4e2a\u65b0\u7d22\u5f15\u4e0d\u884c\u5e26\u4e0amapping?java api\u4e0d\u81f3\u4e8e\u8fd9\u6837\u50bb\u5427\u3002\n\n\u5728 2017\u5e7412\u67087\u65e5 \u4e0a\u534811:55\uff0cwanghu notifications@github.com\u5199\u9053\uff1a\n\n\u6211\u627e\u5230\u4e86\u4e00\u4e2a\u4e0d\u662f\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848(java api)\uff1a\n1\u3001\u5728\u65b0\u5efa\u7d22\u5f15\u7684\u65f6\u5019\uff0c\u5148\u5bfc\u5165\u4e00\u884c\u7a7a\u6570\u636e:\nclient.prepareIndex(\"alert\", \"loginInfo\").setSource(new HashMap()).get();\n\u63d2\u5165\u7a7a\u884c\u7684\u539f\u56e0\u662f\uff1a\u5728\u6ca1\u6709\u6570\u636e\u7684\u65f6\u5019\uff0c\u4e0d\u80fd\u505a\u6620\u5c04\uff0c\u5426\u5219\u62a5\u9519\uff1a\norg.elasticsearch.action.ActionRequestValidationException: Validation\nFailed: 1: source is missing;2: content type is missing;\n\u5728\u6709\u6570\u636e\u7684\u65f6\u5019\uff0c\u6570\u636e\u7c7b\u578b\u5df2\u7ecf\u9ed8\u8ba4\u4e3a\u201ctext\u201d\uff0c\u4fee\u6539\u5b57\u6bb5\u7c7b\u578b\u4e3a\u201ckeyword\u201d\u4f1a\u62a5\u9519\uff1a\njava.lang.IllegalArgumentException: mapper [Application_System] of\ndifferent type, current_type [text], merged_type [keyword]\n2\u3001\u5728\u5bfc\u5165\u6b63\u5f0f\u6570\u636e\u7684\u65f6\u5019\uff0c\u6307\u5b9a\u5b57\u6bb5\u7684\u7c7b\u578b\u4e3akeyword\uff1a\nPutMappingRequestBuilder putMapping = client.admin().indices().preparePutMapping(\"alert\")\n.setType(\"loginInfo\"); putMapping.setUpdateAllTypes(true);\nputMapping.setSource(\"{\\\"properties\\\":{\\\"Application_\nSystem\\\":{\\\"type\\\":\\\"keyword\\\",\\\"index\\\":\\\"not_analyzed\\\"}}}\").get();\n3\u3001\u5220\u9664\u7a7a\u884c\uff1a\n\u627e\u5230\u7a7a\u884c\u7684_id\u7684\u503c\uff0c\u7136\u540e\uff1a\nclient.prepareDelete(\"alert\", \"loginInfo\", rowData.get(\"_id\")+\"\").get();\n\u8fd9\u6837\uff0c\u5bfc\u5165\u7684\u5b57\u6bb5\u7c7b\u578b\u5df2\u7ecf\u88ab\u6307\u5b9a\u4e3a\u201ckeyword\u201d,\u5728\u805a\u5408\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u805a\u5408\u5b57\u6bb5\u5c31\u4e0d\u4f1a\u88ab\u5206\u8bcd\u4e86\u3002\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/555#issuecomment-349855639,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhB1dslZtSz-Q5ERao37UJo0I0Z3Eks5s92GkgaJpZM4Quhtc\n.\n. \u6211\u6ca1\u7528\u8fc7java\napi\u3002\u7528\u8fc7javascript\u548cpython\u90fd\u6709\u76f8\u5e94\u7684api\uff0c\u65e0\u975e\u5c31\u662f\u5305\u88c5\u4e86http\u8bf7\u6c42\u3002\u4f60\u67e5\u67e5api\u6587\u6863\u5427\u3002\u73b0\u5728\u8fd9\u79cd\u65b9\u5f0f\u8bf4\u5b9e\u8bdd\u6709\u70b9.....\u3002\n\n\u5728 2017\u5e7412\u67087\u65e5 \u4e0b\u53482:02\uff0cwanghu notifications@github.com\u5199\u9053\uff1a\n\n@chenyg0911 https://github.com/chenyg0911 \u4e3b\u8981\u662f\u6211\u521a\u63a5\u89e6ElasticSearch\u7684java\napi\u4e0d\u4e45\uff0c\u5bf9\u5f88\u591aapi\u8fd8\u4e0d\u719f\u6089\uff0c\u4e5f\u8bb8\u6709\u66f4\u7b80\u4fbf\u7684\u89e3\u51b3\u65b9\u6cd5\u3002\u5982\u679c\u60a8\u6709\u4ec0\u4e48\u597d\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u4e5f\u8bf7\u4e0d\u541d\u8d50\u6559\u3002\n\u53e6\u5916\uff0c\u770b\u5230\u8bb8\u591a\u5730\u65b9\u90fd\u662f\u7528curl\u8fd9\u79cd\u65b9\u5f0f\u5199\u7684\uff0c\u8fd9\u4e0d\u662f\u547d\u4ee4\u884c\u7684\u4ee3\u7801\u4e48\uff1f\u80fd\u5728\u7a0b\u5e8f\u4e2d\u76f4\u63a5\u8c03\u7528\u8fd9\u4e2a\u547d\u4ee4\u4e48\uff1f\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/555#issuecomment-349871738,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APRMhJ_gAZQosHf4JXndTJCSIANcgslhks5s939jgaJpZM4Quhtc\n.\n. \n",
    "mcollopy": "I think my issue is that the title field is analyzed - how can I group by on an analyzed field as if it was not analyzed?\n. ",
    "kkrugler": "See https://www.elastic.co/guide/en/elasticsearch/guide/current/multi-fields.html for how to use a multi-field to create a second (unanalyzed) field that's suitable for things like grouping/counting. So if you named this second field \"raw\" in the ES field mapping, you'd \"group by title.raw\".\n. ",
    "xuebing1110": "\u770b\u4e86\u4e0bsql\u89e3\u6790\uff0c\u660e\u767d\u4e86\uff1a\ndate_range\u4e0d\u652f\u6301order\uff0c\u5e76\u4e14sql parse\u65f6order\u4f7f\u7528\u5728\u6700\u540e\u7684aggregation \uff0c\u6240\u4ee5\u5f53\u53ea\u6709\u4e00\u4e2adate_rage aggregation \u5e76\u4e14\u6392\u5e8f\u5c31\u62a5\u9519\u4e86\u3002\n\u8c22\u8c22\u56de\u590d\uff01\n. ",
    "Blahhhhh": "Hi @eliranmoyal ,\nSince ES2.0, filter queries are replaced by filter context. Thus \"terms\" clause longer than 1024 should be placed in a \"filter\" parameter, otherwise a \"too_many_clauses\" error would be reported. \n. ",
    "shanielh": "Version 2.1.2\nThanks. \n. Thank you very much!\n. ",
    "chensambb": "thank you! @ansjsun\nI fixed it.\ninstalled this plugins must restart es service. \n. ",
    "theawesomenayak": "Close this issue?\n. ",
    "simonflyto": "Tarry,\n\u5927\u54e5\uff0c\u4e0d\u597d\u610f\u601d\uff0c\u6211\u56de\u7b54\u4e0d\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u9047\u5230\u4e86mycat SLB register error\u8fd9\u4e2a\u95ee\u9898\u4e86\uff0c\u60f3\u8bf7\u6559\u4e0b\u4f60\uff0c\u4f46\u8054\u7cfb\u4e0d\u5230\u4f60\uff0c\u662f\u5426\u53ef\u4ee5\u52a0\u6211wechat simonflyto?\u6216\u90ae\u7bb1simonflyto@163.com ?\u65e0\u8bba\u5982\u4f55 \u611f\u8c22. ",
    "baiyuang": "Have you solved the problem? @Shashi-GS . @shi-yuan \u600e\u4e48\u6837\u5728\u811a\u672c\u805a\u5408scripted_metric\u4e2d\u4f7f\u7528\u4e0a\u6b21terms\u7684doc_count\uff1f. \u7edf\u8ba1terms\u7684doc_count\u65b9\u4fbf\u7ed9\u4e2a\u5177\u4f53\u4f8b\u5b50\u5417. ",
    "honchy": "@eliranmoyal \n``\n    selectfrom` from table_name\n    where appName = 'app_name'\n    and ['from'] like 'u%'\nselect `from\\` from table_name\nwhere appName = 'app_name'\nand ['from'] = 'ucenter'\n\n```\nthese work fine  .  tks ^_^\n. ",
    "gigouni": "Hello @shi-yuan and thank you for your help.\nI already tried this request before and unfortunately, it returns all the objects without considering my WHERE clause. If I remove this clause, the result doesn't change. \nHere your request :\nsql\nSELECT nested(categories.list.persons.details.person_date_registration), \n       nested(categories.list.persons.details.person_date_subscription), \n       nested(categories.list.persons.details.person_id)\nFROM sa_bigbrother/sites\nWHERE nested(categories.list.persons.details.person_id)=\"50\"\nHere the truncated result :\njson\n[\n  {\n    \"list\": [\n      {\n        \"persons\": {\n          \"details\": [\n            {\n              \"person_date_registration\": \"2012-11-05 00:15:01\",\n              \"person_id\": \"50\",\n              \"person_date_subscription\": null\n            },\n            {\n              ...\n            },\n          ]\n        }\n      }\n    ]\n  }\n]\n. After testing it, I begin to think that the problem isn't coming from the request but my system ..\nI tried the following request from your link :\n``` json\nPUT my_index\n{\n  \"mappings\": {\n    \"my_type\": {\n      \"properties\": {\n        \"user\": {\n          \"type\": \"nested\" \n        }\n      }\n    }\n  }\n}\nPUT my_index/my_type/1\n{\n  \"group\" : \"fans\",\n  \"user\" : [\n    {\n      \"first\" : \"John\",\n      \"last\" :  \"Smith\"\n    },\n    {\n      \"first\" : \"Alice\",\n      \"last\" :  \"White\"\n    }\n  ]\n}\nGET my_index/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"user\",\n      \"query\": {\n        \"bool\": {\n          \"must\": [\n            { \"match\": { \"user.first\": \"Alice\" }},\n            { \"match\": { \"user.last\":  \"White\" }} \n          ]\n        }\n      },\n      \"inner_hits\": { \n        \"highlight\": {\n          \"fields\": {\n            \"user.first\": {}\n          }\n        }\n      }\n    }\n  }\n}\n```\nThe documentation says that the last request shouldn't return John but it does. Look\njson\n{\n   \"took\": 111,\n   \"timed_out\": false,\n   \"_shards\": {\n      \"total\": 5,\n      \"successful\": 5,\n      \"failed\": 0\n   },\n   \"hits\": {\n      \"total\": 1,\n      \"max_score\": 1.4054651,\n      \"hits\": [\n         {\n            \"_index\": \"my_index\",\n            \"_type\": \"my_type\",\n            \"_id\": \"1\",\n            \"_score\": 1.4054651,\n            \"_source\": {\n               \"group\": \"fans\",\n               \"user\": [\n                  {\n                     \"first\": \"John\",\n                     \"last\": \"Smith\"\n                  },\n                  {\n                     \"first\": \"Alice\",\n                     \"last\": \"White\"\n                  }\n               ]\n            }\n         }\n      ]\n   }\n}\nI really like ElasticSearch and its performance promises but I have to admit that it drives me crazy ...\nAny ideas @shi-yuan  ?\n. I shut down twice my master node after deleting the my_index index of the example. Then I tried again and then get this result :\njson\n{\n   \"took\": 113,\n   \"timed_out\": false,\n   \"_shards\": {\n      \"total\": 5,\n      \"successful\": 5,\n      \"failed\": 0\n   },\n   \"hits\": {\n      \"total\": 1,\n      \"max_score\": 1.987628,\n      \"hits\": [\n         {\n            \"_index\": \"my_index\",\n            \"_type\": \"my_type\",\n            \"_id\": \"1\",\n            \"_score\": 1.987628,\n            \"_source\": {\n               \"group\": \"fans\",\n               \"user\": [\n                  {\n                     \"first\": \"John\",\n                     \"last\": \"Smith\"\n                  },\n                  {\n                     \"first\": \"Alice\",\n                     \"last\": \"White\"\n                  }\n               ]\n            },\n            \"inner_hits\": {\n               \"user\": {\n                  \"hits\": {\n                     \"total\": 1,\n                     \"max_score\": 1.987628,\n                     \"hits\": [\n                        {\n                           \"_type\": \"my_type\",\n                           \"_id\": \"1\",\n                           \"_nested\": {\n                              \"field\": \"user\",\n                              \"offset\": 1\n                           },\n                           \"_score\": 1.987628,\n                           \"_source\": {\n                              \"first\": \"Alice\",\n                              \"last\": \"White\"\n                           },\n                           \"highlight\": {\n                              \"user.first\": [\n                                 \"<em>Alice</em>\"\n                              ]\n                           }\n                        }\n                     ]\n                  }\n               }\n            }\n         }\n      ]\n   }\n}\nIt's still returning John but the inner_hits answers to my request. Is it possible to avoid to get all the \"_source\" object and just keep the \"inner_hits\" one ? \n. Thank you @shi-yuan\nNow, I applied this to my concrete case. Following this issue (Link), I tried\njson\nPOST index/type/_search\n{\n   \"_source\": false,\n   \"query\": {\n      \"nested\": {\n         \"path\": \"categories\",\n         \"query\": {\n            \"nested\": {\n               \"path\": \"categories.list\",\n               \"query\": {\n                  \"nested\": {\n                     \"path\": \"categories.list.persons\",\n                     \"query\": {\n                        \"nested\": {\n                           \"path\": \"categories.list.persons.details\",\n                           \"query\": {\n                              \"match\": {\n                                 \"categories.list.persons.details.person_id\": \"50\"\n                              }\n                           }\n                        }\n                     }\n                  }\n               }\n            }\n         },\n         \"inner_hits\": {}\n      }\n   }\n}\nbut the server returns\njson\n{\n   \"error\": {\n      \"root_cause\": [\n         {\n            \"type\": \"query_parsing_exception\",\n            \"reason\": \"[nested] nested object under path [categories.list.persons] is not of nested type\",\n            \"index\": \"sa_bigbrother\",\n            \"line\": 10,\n            \"col\": 22\n         }\n      ],\n      \"type\": \"search_phase_execution_exception\",\n      \"reason\": \"all shards failed\",\n      \"phase\": \"query\",\n      \"grouped\": true,\n      \"failed_shards\": [\n         {\n            \"shard\": 0,\n            \"index\": \"sa_bigbrother\",\n            \"node\": \"JGQ5UkznSdKeTJBu8O4Duw\",\n            \"reason\": {\n               \"type\": \"query_parsing_exception\",\n               \"reason\": \"[nested] nested object under path [categories.list.persons] is not of nested type\",\n               \"index\": \"sa_bigbrother\",\n               \"line\": 10,\n               \"col\": 22\n            }\n         }\n      ]\n   },\n   \"status\": 400\n}\nwhile it is :\njson\n{\n   \"sa_bigbrother\": {\n      \"mappings\": {\n         \"sites\": {\n            \"properties\": {\n               \"categories\": {\n                  \"type\": \"nested\",\n                  \"properties\": {\n                     \"list\": {\n                        \"type\": \"nested\",\n                        \"properties\": {\n                           \"persons\": {\n                              \"properties\": {\n                                 \"details\": {\n                                    \"type\": \"nested\",\n                                    \"properties\": {\n                                       \"person_date_registration\": {\n                                          \"type\": \"date\",\n                                          \"format\": \"yyyy-MM-dd HH:mm:ss\"\n                                       },\n                                       \"person_date_subscription\": {\n                                          \"type\": \"date\",\n                                          \"format\": \"yyyy-MM-dd HH:mm:ss\"\n                                       },\n                                       \"person_id\": {\n                                          \"type\": \"string\"\n                                       }\n                                    }\n                                 },\n                                 \"total_customers\": {\n                                    \"type\": \"integer\"\n                                 }\n                              }\n                           },\n                           \"url_site\": {\n                              \"type\": \"string\"\n                           }\n                        }\n                     },\n                     \"name\": {\n                        \"type\": \"string\"\n                     }\n                  }\n               }\n            }\n         }\n      }\n   }\n}\nThanks, it's almost done !\n. Gosh, I'm stupid, it's not ..\nI just have to find how restructure my request to answer to my case\n. My problem doesn't concern elasticsearch-sql anymore. I close the topic.\nThank you very much @shi-yuan\n. ",
    "enilu": "\u60ed\u6127\uff0c\u662f\u6211indexType\u540d\u79f0\u5199\u9519\u4e86\u3002\n. ",
    "srijiths": "ES 2.3.4. Please see the mapping.\n```\ncurl -X PUT \"http://$hostname:9200/$index/$doctype/_mapping\" -d '{\n        \"'$doctype'\" : {\n             \"_all\": { \"enabled\": false },\n             \"_source\": { \"enabled\":false },\n       \"properties\" : {                             \n                \"val\" : {\"type\":\"long\", \"include_in_all\":false},\n                \"bas_id\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"building_id\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"point_id\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"point_name\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"building_name\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"building_city\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"building_state\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"building_country\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"site_id\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"site_name\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"company_id\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"company_name\" : {\"type\":\"string\", \"index\":\"not_analyzed\"},\n                \"sval_max\" : {\"type\":\"long\", \"include_in_all\":false},\n                \"sval_min\" : {\"type\":\"long\", \"include_in_all\":false},\n                \"sensorId\" : {\"type\":\"string\",\"index\":\"not_analyzed\"},\n                \"type\" : {\"type\":\"string\",\"index\":\"not_analyzed\"},\n                \"time\" : {\"type\":\"date\",\"format\":\"dd-MM-yyyy HH:mm:ss.SSS\"},\n                \"geo\" : {\"type\":\"geo_point\"}\n           }\n        }\n}'\n```\nBy default doc_values are enabled by default , even if we say _all and _source as false. https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html\nThank You\n. @eliranmoyal My bad..I tried some other queries like group by a key . Its working. select * from indexName limit 10 , is not working.\n. @eliranmoyal You will not get the fields in _search api, since _all is disabled in mapping. So its not searchable. \n. No, but what is the issue in the above query not working and group by works ? Just to understand. Is it possible to extend your back end query end point to address this situvation ? Is it feasible ?\n. Yes , thats correct. Apart from the basic select query , do you over see any other query failures with this mapping ? If only this one , i can manage. Otherwise need to think of other options.\n. @eliranmoyal Thats great.. Thank You..\n. ",
    "wanglifengwf": "sorry! I Forget to write the version.\nVersion \uff1a 2.3.4.0\n. @shi-yuan \n- sql\n  SELECT distinct(name) FROM user\n- explan\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"_source\": {\n        \"includes\": [\n            \"name\"\n        ],\n        \"excludes\": []\n    }\n}\nDistict  don't has physical execution plan\n. @eliranmoyal @ansjsun   I'm sorry,I forgot es does not support distinct.thanks!\n. hi @ansjsun \nif the result is : \n| _routing | _parent | x |\n| :-- | --: | --: |\n| ....... | ........ |  |\n| ....... | ........ |  |\n| ....... | ........ |  |\n| ....... | ........ | xvalue |\n| ....... | ........ |  |\nThen the sql is : select x from the user limit 3;\nWhen I skip it in my javacode;\nThere is no result output.\nI want to get the result which has the field 'x'.\nI must set the 'where x is not missing' any times,\n. ",
    "jasonliaoxiaoge": "sure, i have commit unit test, thanks\n. ",
    "phingocchi": "CSV is good but is not best for nested document with original data type.\nMap is the best for parsing.\nPlease support the great feature.\n. Thank allwefantasy!\nYour ObjectResultsExtractor class is awesome.\nIt can be perfect with new feature: MapResultsExtractor\n{\n  \"meta\": {\n    \"offset\": 0,\n    \"limit\": 200,\n    \"total\": 10000\n  },\n  \"data\": [\n    {\n      \"_id\": \"document_id\",\n      \"key1\": \"value\",\n      \"key2\": 12345,\n      \"key3\": [\n        \"value\",\n        \"value\"\n      ],\n      \"key4\": {\n        \"sub_key1\": \"value\",\n        \"sub_key2\": \"value\"\n      }\n    },\n    {\n      \"_id\": \"document_id\",\n      \"key1\": \"value2\",\n      \"key2\": 12345,\n      \"key3\": [\n        \"value\",\n        \"value\"\n      ],\n      \"key4\": {\n        \"sub_key1\": \"value\",\n        \"sub_key2\": \"value\"\n      }\n    }\n  ]\n}\nNew features:\n- add document _id\n- add total documents\n- add paging for aggregation query\n. @allwefantasy please add document id to result\n. I don't need caching in memory. Just simple paging on result list by command OFFSET ... LIMIT ...\nEx:\nSELECT *, COUNT(*) FROM users GROUP BY city OFFSET 10 LIMIT 10\nTotal may be 1000 documents but I need the result list must be 10 documents from OFFSET 10 \n. ",
    "FreedomBX": "test again,not start with number,but start with [0-9]e(scientific notation),the error will be occured.\n. select * from 5ed516e548a8458c825ec3655127cd46,any index which start with number + 'e' + any string\n. \u4f46\u662felasticsearch\u7684index\u662f\u53ef\u4ee5\u4ee5\u6570\u5b57\u5f00\u5934\u7684\uff0c\u800c\u4e14\u8fd9\u4e2a\u4e0d\u662f\u6570\u5b57\u5f00\u5934\u7684\u95ee\u9898\uff0c\u6b63\u5e38\u6570\u5b57\u5f00\u5934\u662f\u53ef\u4ee5\u7684\uff0c\u53ea\u662f\u5728\u5199\u6210\u79d1\u5b66\u8ba1\u6570\u6cd5\u7684\u65f6\u5019\u4f1a\u8ba4\u4e3a\u8fd9\u662f\u4e2a\u6570\u5b57\uff0c\u5bfc\u81f4\u9519\u8bef\n. ",
    "wntp": "\u5f53\u4f60\u7684\u8868\u540d\u4ee5\u6570\u5b57\u5f00\u5934\u7684\u65f6\u5019\uff0c\u5728Sql\u8bc6\u522b\u7684\u65f6\u5019\u4f1a\u51fa\u73b0\u5f02\u5e38\u3002\n. ",
    "JichengSong": "good job !\n. ",
    "harbby": "good job !\n. ",
    "weikuo0506": "I run it ,but error occurs below, is there anybody can help me ?\nthe error:\njava.lang.NoClassDefFoundError: org/elasticsearch/common/transport/TransportAddress\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:658)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:623)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource$CreateConnectionThread.run(ElasticSearchDruidDataSource.java:1802)\nCaused by: java.lang.ClassNotFoundException: org.elasticsearch.common.transport.TransportAddress\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:366)\n    at java.net.URLClassLoader$1.run(URLClassLoader.java:355)\n    at java.security.AccessController.doPrivileged(Native Method)\n    at java.net.URLClassLoader.findClass(URLClassLoader.java:354)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:425)\n    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)\n    at java.lang.ClassLoader.loadClass(ClassLoader.java:358)\n. @allwefantasy   many thanks,  I have add elasticsearch  dependency, and that problem seems solved. But another error happends:\nException in thread \"Druid-ConnectionPool-Create-1576809894\" java.lang.NoSuchMethodError: com.alibaba.druid.pool.DruidConnectionHolder.(Lcom/alibaba/druid/pool/DruidAbstractDataSource;Ljava/sql/Connection;)V\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.put(ElasticSearchDruidDataSource.java:1635)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource$CreateConnectionThread.run(ElasticSearchDruidDataSource.java:1831)\nhave any idea?\nps: I have found the solution to the problem:  down the druid version to 1.0.15;\nthans, I can run it successful now!\n. @allwefantasy  I see you have used TransportClient in ElasticSearchConnection.java; and this is a natural way, cause mysql protocol tcp is TCP based, and so transportClient. But there is a limitation: users can only connect to the transport port (default 9300), other than the http port(9200). The limitation is more obvious when in the product environment where many companies demand that searching must be proxyed by Nginx.  Have any idea?\n. ",
    "xiangsiyu": "@allwefantasy If I want to use \u2018join\u2018, how to page\uff1f'LIMIT' cannot do that\uff0cfor example:\n\n. yes, you can do that,for example(elasticsearch.yml):\n\n. ",
    "xinuo": "I want to know can the feather support cluster?\nFor example , i have ES cluster:\"192.168.4.91\",\"192.168.4.92\",\"192.168.4.93\".\nHow can i input the url?. ",
    "will0815": "The es-sql website can run normally\nbut the code(JDBCTests) throw this exception:\nNoNodeAvailableException[None of the configured nodes are available: . ",
    "hungrytortoise": "good job. i meet the same problem,and have no idea for this.. ",
    "sansom": "How to driver?. ",
    "RaniRaven": "It seems like it misses the java.sql.Driver implementation.\nThis is a must if I understand in order to use it as a JDBC driver. I fail to understand ...\nCan I get an example on how to use\nClass.forName() & DriverManager.getConnection in java in order to connect with the mysql driver to elasticsearch ?!\nI would like to have a connection which is feasible to a standard sql query tool trying to connect.. ",
    "stopit": "when i want to select from a type,just like:  'select * from index1.type2 where xxx ' , how can i use this jdbc method?  But the example only show how to select from index. thx~\n. when I use this code to test jdbc pool :\nfor(int i = 0; i<10;i++){\n            try {\n                Connection conn = ESSqlConnPool.getConnection();\n                PreparedStatement pre = conn.prepareStatement(sql);\n                ResultSet resultSet = conn.prepareStatement(sql).executeQuery();\n                Thread.sleep(500);\n                resultSet.close();\n                pre.close();\n                conn.close();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\nthe exception throws:\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)\n    at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\n    at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:62)\nIs there something wrong in conn.close() method ,when i close the conn, it does not return the conn to the datasource pool but really closes the conn..... @wenthywang  \u5df2\u7ecf\u89e3\u51b3\u4e86\u3002\u6211\u8c03\u8bd5\u4e86\u4e0b\uff0c\u5173\u95edconn\u7684\u65f6\u5019\u628a\u7269\u7406conn\u5173\u6389\uff1b\u5347\u7ea7\u4e86\u7248\u672c\uff0c\u89e3\u51b3\u4e86\u8be5\u95ee\u9898\u3002. \u6309\u7167\u666e\u901asql\u7684\u7406\u89e3\u4e0d\u5e94\u8be5\u662f\u6309\u7167a_point_address\uff0cb_point_address\u5206\u7ec4\u540e\uff0c\u518d\u6839\u636e\u5206\u7ec4\u7ed3\u679c\u6309\u7167count\u8fdb\u884c\u5012\u6392\u4e48\uff08\u6392\u5e8f\u540e\u5206\u7ec4\u7ed3\u679c\u5e94\u8be5\u88ab\u6253\u4e71\uff09~ @guanlei1996 \u6709\u6b63\u786e\u7684\u5199\u6cd5\u4e48 \u6211\u60f3\u53c2\u8003\u4e0b\uff0c\u6211\u4e5f\u9047\u5230\u4e86\u76f8\u4f3c\u7684\u95ee\u9898\u3002\u3002. \u611f\u8c22\uff01  es\u91cc\u9762jdbc\u8fd8\u662f\u8981\u6536\u8d39\uff0c\u652f\u6301\u9879\u76ee\u7ee7\u7eed\u53d1\u5c55\uff01. @shi-yuan     \u80fd\u5177\u4f53\u5c55\u793a\u4e0b\u51b2\u7a81\u7684\u5177\u4f53\u5185\u5bb9\u4e48\uff0c\u6211\u68c0\u67e5\u4e00\u4e0b~~\n. \u8c22\u8c22\u4f60\u53d1\u8d77\u4e86\u8fd9\u4e48\u597d\u7684\u9879\u76ee\uff0c\u6211\u4eec\u5df2\u7ecf\u5728\u597d\u51e0\u4e2a\u751f\u4ea7\u7cfb\u7edf\u4e0a\u4f7f\u7528\u4e86\u3002xpack\u7684jdbc\u8c8c\u4f3c\u4f9d\u7136\u6536\u8d39\uff0c\u8fd8\u662f\u79bb\u4e0d\u5f00elasticsearch-sql  ~~. @shi-yuan  \u6211\u548cmaster\u6bd4\u5bf9\u4e86\u4e0b\uff0c\u5e94\u8be5\u53ea\u4fee\u6539\u4e86\u4e00\u884c\u5b58\u5728bug\u7684\u4ee3\u7801. ",
    "coderBaijige": "good job !\nsupport 5.12\uff1f. At first,I think can't support it elasticsearch 5.1.2.\nBut now I'm done,It can support.. ",
    "zhegexiaohuozi": "@allwefantasy How to support the sql like SELECT * FROM (SELECT user_id,sum(amt) as sum_amt from index1/type2  GROUP BY user_id) as a WHERE a.sum_amt < 500 ORDER BY uid desc limit 100,5?\nAnd I get the Exception:\nException in thread \"main\" java.sql.SQLException: Error\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)\n    at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\n    at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:61)\n    at com.xx.test.test.Elastic.jdbc(Elastic.java:79)\n    at com.xx.test.test.Elastic.main(Elastic.java:94)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)\nCaused by: java.lang.ClassCastException: com.alibaba.druid.sql.ast.statement.SQLSubqueryTableSource cannot be cast to com.alibaba.druid.sql.ast.statement.SQLJoinTableSource\n    at org.nlpcn.es4sql.parse.SqlParser.findFrom(SqlParser.java:227)\n    at org.nlpcn.es4sql.parse.SqlParser.parseSelect(SqlParser.java:48)\n    at org.nlpcn.es4sql.parse.SqlParser.parseSelect(SqlParser.java:35)\n    at org.nlpcn.es4sql.query.ESActionFactory.create(ESActionFactory.java:61)\n    at org.nlpcn.es4sql.SearchDao.explain(SearchDao.java:46)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.getObjectResult(ElasticSearchDruidPooledPreparedStatement.java:72)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:46)\n    ... 7 more\nthx!\ndetail info https://github.com/NLPchina/elasticsearch-sql/issues/400. ",
    "cipher-prelude": "Does it support Joins ? \n. ",
    "fenggnay": "springboot \u548c elasticsearch-sql \u7ed3\u5408\u7684\u65f6\u5019 \u51fa\u73b0 \u7c7b\u627e\u4e0d\u5230\u5f02\u5e38 \uff1f\u6709\u4eba\u78b0\u5230\u8fc7. ",
    "wenthywang": "@fenggnay \u51fa\u73b0\u4ec0\u4e48\u5f02\u5e38\uff0c\u4f60\u5e94\u8be5\u6ca1\u6709\u5bfc\u5165\u5b8c\u6574\u7684jar. @stopit \u4f60\u7684\u4ee3\u7801\u6ca1\u8d34\u5b8c\u6574\u3002. @BobEnya \u8ddf\u4f8b\u5b50\u4e00\u6837\u5c31\u884c\u554a \u914d\u7f6ees\u7684\u94fe\u63a5\u5730\u5740\u5c31\u597d\u4e86 . @BobEnya \u770b\u63d0\u793a \u8bf4\u662f\u7248\u672c\u95ee\u9898  es \u662f \u4ec0\u4e48\u7248\u672c  es-sql\u53c8\u662f\u4ec0\u4e48\u7248\u672c\u5462\uff1f \n \u4f60\u53ef\u4ee5\u53c2\u8003\u6211repo\u91cc\u7684es-5.1.2-test\u5de5\u7a0b\u3002. @cyhrosefer  see your jdbc connection code and your es config yml . @cyhrosefer \u4f60\u7684\u96c6\u7fa4\u540d\u8ddfes\u914d\u7f6e\u6587\u4ef6\u7684\u96c6\u7fa4\u540d\u662f\u4e00\u6837\u7684\u5417\uff1f\u8d34\u51fa\u6765\u770b\u4e0b. @cyhrosefer  \u8fd8\u6709\u4f60\u7528\u7684\u662f\u4ec0\u4e48\u7248\u672c\u7684es \u4ec0\u4e48\u7248\u672c\u7684es-sql\n\u5982\u679c\u8fd8\u662f\u4e0d\u884c \u6211\u6709\u4e2arepo \u4f60\u4e0b\u8f7d\u6765\u6d4b\u8bd5\u4e0b. @cyhrosefer  \u6211\u6ca1\u6709\u914d\u7f6expack\u554a . @sunsence  \u6682\u65f6\u662f\u4e0d\u652f\u6301\u7684 . i found the why .\nbecause the AggregationQueryAction.java have the code.\n\n//ES5.0 termsaggregation with size = 0 not supported anymore\n                    if (subAgg instanceof TermsAggregationBuilder && !(field instanceof MethodField)) {\n                        ((TermsAggregationBuilder) subAgg).size(Integer.MAX_VALUE);\n                    }\nbut why dont give it the default value (Integer.MAX_VALUE)\nnow i give the maxlue,my project run normally,all the result it happend.\nso i also confuse the default value. \u53d1\u73b0\u52a0 limit \u5c31\u53ef\u4ee5\u89e3\u51b3\u95ee\u9898\u4e86 \u6240\u6709select\u67e5\u8be2\u4e0d\u52a0limit \u9ed8\u8ba4\u5c31\u662f200. \n",
    "sivadas": "Getting below error:\n2017-07-06 15:31:09,424 [http-nio-9000-exec-1] WARN  MySqlValidConnectionChecker.:53 - Cannot resolve com.mysq.jdbc.Connection.ping method.  Will use 'SELECT 1' instead.\njava.lang.NullPointerException: null\n    at com.alibaba.druid.pool.vendor.MySqlValidConnectionChecker.(MySqlValidConnectionChecker.java:48)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.initValidConnectionChecker(ElasticSearchDruidDataSource.java:880)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.init(ElasticSearchDruidDataSource.java:546)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:897)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:893)\n    at com.ge.dcc.api.service.impl.ElasticService.getEsDataUsingSqlPlugin(ElasticService.java:1090)\n    at com.ge.dcc.api.controller.ElasticDataController.elasticQuery(ElasticDataController.java:115)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)\n    at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:108)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)\n    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)\n    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\n    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)\n    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)\n    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    at java.lang.Thread.run(Thread.java:745)\n2017-07-06 15:31:09,772 [http-nio-9000-exec-1] INFO  ElasticSearchDruidDataSource.init:607 - {dataSource-1} inited\n2017-07-06 15:31:09,775 [http-nio-9000-exec-1] ERROR ExceptionHandlerAdvice.handleException:29 - http://localhost:9000/dcc/api/v1/elastic\norg.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.AbstractMethodError: org.apache.logging.log4j.core.config.ConfigurationFactory.getConfiguration(Lorg/apache/logging/log4j/core/config/ConfigurationSource;)Lorg/apache/logging/log4j/core/config/Configuration;\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:978)\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)\n    at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:622)\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:729)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:230)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:108)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:192)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:165)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:474)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:349)\n    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:783)\n    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\n    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:798)\n    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1434)\n    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.AbstractMethodError: org.apache.logging.log4j.core.config.ConfigurationFactory.getConfiguration(Lorg/apache/logging/log4j/core/config/ConfigurationSource;)Lorg/apache/logging/log4j/core/config/Configuration;\n    at org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:490)\n    at org.apache.logging.log4j.core.config.ConfigurationFactory$Factory.getConfiguration(ConfigurationFactory.java:460)\n    at org.apache.logging.log4j.core.config.ConfigurationFactory.getConfiguration(ConfigurationFactory.java:256)\n    at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:561)\n    at org.apache.logging.log4j.core.LoggerContext.reconfigure(LoggerContext.java:578)\n    at org.apache.logging.log4j.core.LoggerContext.start(LoggerContext.java:214)\n    at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:145)\n    at org.apache.logging.log4j.core.impl.Log4jContextFactory.getContext(Log4jContextFactory.java:41)\n    at org.apache.logging.log4j.LogManager.getContext(LogManager.java:182)\n    at org.apache.logging.log4j.LogManager.getLogger(LogManager.java:455)\n    at org.elasticsearch.common.logging.ESLoggerFactory.getLogger(ESLoggerFactory.java:49)\n    at org.elasticsearch.common.logging.ESLoggerFactory.getLogger(ESLoggerFactory.java:57)\n    at org.elasticsearch.common.logging.Loggers.getLogger(Loggers.java:101)\n    at org.elasticsearch.common.xcontent.support.AbstractXContentParser.(AbstractXContentParser.java:57)\n    at org.elasticsearch.common.xcontent.json.JsonXContentParser.(JsonXContentParser.java:44)\n    at org.elasticsearch.common.xcontent.json.JsonXContent.createParser(JsonXContent.java:103)\n    at org.elasticsearch.common.settings.Setting.parseableStringToList(Setting.java:848)\n    at org.elasticsearch.common.settings.Setting.lambda$listSetting$27(Setting.java:802)\n    at org.elasticsearch.common.settings.Setting.listSetting(Setting.java:807)\n    at org.elasticsearch.common.settings.Setting.listSetting(Setting.java:802)\n    at org.elasticsearch.common.network.NetworkService.(NetworkService.java:50)\n    at org.elasticsearch.client.transport.TransportClient.newPluginService(TransportClient.java:98)\n    at org.elasticsearch.client.transport.TransportClient.buildTemplate(TransportClient.java:126)\n    at org.elasticsearch.client.transport.TransportClient.(TransportClient.java:268)\n    at org.elasticsearch.transport.client.PreBuiltTransportClient.(PreBuiltTransportClient.java:127)\n    at org.elasticsearch.transport.client.PreBuiltTransportClient.(PreBuiltTransportClient.java:113)\n    at org.elasticsearch.transport.client.PreBuiltTransportClient.(PreBuiltTransportClient.java:103)\n    at com.alibaba.druid.pool.ElasticSearchConnection.(ElasticSearchConnection.java:32)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:658)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:623)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.init(ElasticSearchDruidDataSource.java:570)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:897)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:893)\n    at com.ge.dcc.api.service.impl.ElasticService.getEsDataUsingSqlPlugin(ElasticService.java:1090)\n    at com.ge.dcc.api.controller.ElasticDataController.elasticQuery(ElasticDataController.java:115)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)\n    ... 55 common frames omitted\nMy connection properties like :\nProperties properties = new Properties();\nproperties.put(\"url\", \"jdbc:elasticsearch://?stage-es.abcd.com:80?/TEST_INDEX\");\nAnyone have similar issue earlier?. this doesn't work. It only returns col_name_1 and col_name_2 not t alias. Expecting \n\"t\": {\n            \"value\": 0\n        }\n{\n    \"took\": 5,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 5,\n        \"successful\": 5,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": 35323,\n        \"max_score\": 0,\n        \"hits\": []\n    },\n    \"aggregations\": {\n        \"col_name_1\": {\n            \"value\": 4321.34454\n        },\n        \"col_name_2\": {\n            \"value\": 1234.34454\n        }\n    }\n}. Thanks Yuan for helping out. I can see it now. But seems like it's only working with non-aggregation queries where \"_source\" attributes is expected not with \"aggregations\" attributes.\nEx: select col_1,col_2, script('t','0') from index_1 group by col_2, col_1 order by col_1\nThis don't have \"fields\" attributes in response.. Thanks Yuan.  My first query was, can i use script('t','0') with aggregations? if yes, then how? Please give me a sample query.. My requirement is to ignore time part and just compare the only date part. My date is of SQL Timestamp with/without tome zone.\nIs there no way we can do a string comparison? \ndate_format(m_date,'yyyy-MM-dd') >= '2017-01-31' ???. ",
    "chejiangyi": ".net elasticsearch sql to datatable\nhttp://www.cnblogs.com/chejiangyi/p/7217153.html\n.net elasticsearch sql \u6269\u5c55\u7c7b \u6570\u636e\u8f6cdatatable\n\u6b22\u8fce\u4ea4\u6d41\uff0c\u7ee7\u7eed\u5b8c\u5584\u3002. ",
    "BobEnya": "@coderBaijige \u5982\u4f55\u57285.0\u4e0a\u7528elasticsearch-sql \u7684jdbc\u94fe\u63a5. @wenjunyang \u4f46\u662f\u6211\u8fd9\u91cc\u62a5java.lang.IllegalStateException: Received message from unsupported version: [2.0.0] minimal compatible version is: [5.0.0]          \u8fd9\u4e2a\u9519\u600e\u4e48\u89e3\u51b3. ",
    "zizaifeng": "[2017-08-25 17:51:15] [com.alibaba.druid.pool.vendor.MySqlValidConnectionChecker] [WARN] Cannot resolve com.mysq.jdbc.Connection.ping method.  Will use 'SELECT 1' instead.\n\u540e\u9762\u5c31\u62a5\u4e86\u7a7a\u6307\u9488\n\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\u5c31\u662f\nResultSet resultSet = pstmt.executeQuery();// \u8fd4\u56de\u67e5\u8be2\u7ed3\u679c\nResultSetMetaData metaData = resultSet.getMetaData();\nint col_len = metaData.getColumnCount();\ncol_len\u7ed3\u679c\u662f0\uff1b\u4f46\u662f\u8c03\u8bd5\u7684\u65f6\u5019metaData\u91cc\u9762\u662f\u6709\u6570\u636e\u7684\uff0c\u4e3a\u5565. \u4e3a\u4ec0\u4e48sql\u4e0d\u80fd\u4f7f\u7528PrepareStatement\uff0csql\u4e2d\u51fa\u73b0\u66ff\u4ee3\u7b26\u53f7\u2018\uff1f\u2019\u5c31\u4f1a\u62a5\u9519\nCaused by: org.nlpcn.es4sql.exception.SqlParseException: Failed to parse SqlExpression of type class com.alibaba.druid.sql.ast.expr.SQLVariantRefExpr. expression value: ?. ",
    "yezhongye": "java.sql.SQLException: unkow jdbc driver : jdbc:elasticsearch://127.0.0.1:9200\n\u6709\u6ca1\u6709\u51fa\u73b0\u8fd9\u4e2a\u9519\u8bef\u7684\uff1b\u8bf7\u6307\u6559\uff0c\u8c22\u8c22. @zizaifeng \u4f60\u7684\u95ee\u9898\u90fd\u89e3\u51b3\u4e86\uff0c\u6211\u4e5f\u6709\u540c\u6837\u7684\u7591\u95ee. ",
    "cyhrosefer": "The es-sql website can run normally\nbut the code(JDBCTests) throw this exception:\nNoNodeAvailableException[None of the configured nodes are available:\nPS: I used xpack\nString indexName = \"logs-2017105\";\n        Properties properties = new Properties();\n        properties.put(\"url\", \"jdbc:elasticsearch://10.10.11.41:9300/\" + indexName);\n        properties.put(\"cluster.name\",\"es_cluster_sit\");\n        properties.put(\"client.transport.sniff\",true);\n        properties.put(\"xpack.security.transport.ssl.enabled\",false);\n        properties.put(\"xpack.security.user\",\"elastic:changeme\");\n        properties.put(\"username\",\"elastic\");\n        properties.put(\"password\",\"changeme\");\n        DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n        Connection connection = dds.getConnection();\n. @wenthywang ,\u4e0b\u9762\u7684\u4ee3\u7801\u662f\u63a5\u7740\u4e0a\u9762\u7684\uff0c\u5728ps.executeQuery()\u65f6\u62a5\u9519\uff0cES 9300\u7aef\u53e3\u6ca1\u914d\u7f6e\uff0c\u5e94\u8be5\u9ed8\u8ba4\u5c31\u662f\uff0c \u96c6\u7fa4\u540d\u914d\u7f6e\u4e3aes_cluster_sit\uff0c\u662f\u4e0d\u662fxpack\u7684\u539f\u56e0\u5462\uff1f \u6211\u8be5\u600e\u4e48\u8c03\u6574\uff1f \u591a\u8c22\u5927\u4fa0\nPreparedStatement ps = connection.prepareStatement(\"SELECT  logType.keyword,databaseType.keyword,ip.keyword from \" + indexName + \" where databaseType.keyword='/BD/realread'\");\n    ResultSet resultSet = ps.executeQuery();\n. @wenthywang ,\u6211ES\u75285.2.2\uff0c \u4e0b\u8f7d\u7684es-sql\u4e5f\u662f\u5bf9\u5e94\u7684\u7248\u672c\uff0c\u76f4\u63a5\u5728es-sql\u4e2d\u7684\u6e90\u7801\u4e2d\u6539\u6210\u6211\u7684\u73af\u5883\uff0c\u62a5\u7684\u9519\uff0c\u6211\u8fd9\u6837\u914d\u7f6expack\u662f\u4e0d\u662f\u5bf9\u7684\u5462\uff1f\u4f60\u7684repo\u914d\u7f6e\u4e86xpack\u5417\uff1f. \u662f\u6211maven\u7684\u95ee\u9898\uff0csorry, \u5df2\u7ecf\u53ef\u4ee5\u4e86\u3002. ",
    "yunliangshen": "\u8bf7\u95ee\u652f\u6301sql\u8bed\u53e5\u5206\u9875\u5417\uff0c\u5982\u679c\u652f\u6301\uff0c\u9ebb\u70e6\u7ed9\u4e2asql\u793a\u4f8b. @wenthywang \u8bf7\u95ee\u652f\u6301sql\u8bed\u53e5\u5206\u9875\u5417. ",
    "wanghu198343": "@wenthywang \u60a8\u597d\uff0c\u6211down\u7684\u662f5.6.3\u7684\u5206\u652f\u6e90\u4ee3\u7801\uff0c\u5728\u672c\u5730Eclipse\u4e2d\uff0c\u901a\u8fc7 clean install \u547d\u4ee4\uff0cbuild\u6210\u529f\uff0c\u4f46\u662fjar\u5305\u91cc\u6ca1\u6709class\u6587\u4ef6\uff0c\u8bf7\u95ee\u8fd9\u4e2a\u6709\u9047\u5230\u8fc7\u4e48\uff1f. @ansjsun \u60a8\u597d\uff01\u8bf7\u95ee\u5177\u4f53\u600e\u4e48\u628acar_no\u7684\u5206\u8bcd\u65b9\u5f0f\u6539\u6210keyword?\u6211\u662f\u901a\u8fc7java api\u7684\u5f53\u65f6\u628a\u6570\u636e\u5bfc\u5165\u5230ES\u7684\u3002\u9047\u5230\u540c\u6837\u7684\u95ee\u9898\uff0c\u7136\u540e\u6211\u4f7f\u7528index:not_analyzed\u914d\u7f6e\uff0c\u62a5\u9519\uff1a\nmapper [Application_System] of different type, current_type [text], merged_type [keyword]\n\u8c22\u8c22\u6307\u6559\uff01\uff01. @guanlei1996 \u60a8\u597d\uff0c\u8bf7\u95ee\u60a8\u8fd9\u4e2a\u95ee\u9898\u662f\u600e\u4e48\u89e3\u51b3\u7684\uff1f\u600e\u4e48\u8bbe\u7f6ecar_no\u8fd9\u4e2a\u5b57\u6bb5\u7684\u7c7b\u578b\u4e3akeyword\u7684\uff1f. @guanlei1996  \u597d\u7684\uff0c\u8c22\u8c22\u60a8\u7684\u56de\u590d\u3002. \u6211\u627e\u5230\u4e86\u4e00\u4e2a\u4e0d\u662f\u5f88\u597d\u7684\u89e3\u51b3\u65b9\u6848(java api)\uff1a\n1\u3001\u5728\u65b0\u5efa\u7d22\u5f15\u7684\u65f6\u5019\uff0c\u5148\u5bfc\u5165\u4e00\u884c\u7a7a\u6570\u636e:\nclient.prepareIndex(\"alert\", \"loginInfo\").setSource(new HashMap()).get();\n\u63d2\u5165\u7a7a\u884c\u7684\u539f\u56e0\u662f\uff1a\u5728\u6ca1\u6709\u6570\u636e\u7684\u65f6\u5019\uff0c\u4e0d\u80fd\u505a\u6620\u5c04\uff0c\u5426\u5219\u62a5\u9519\uff1a\n     org.elasticsearch.action.ActionRequestValidationException: Validation Failed: 1: source is missing;2: content type is missing;\n\u5728\u6709\u6570\u636e\u7684\u65f6\u5019\uff0c\u6570\u636e\u7c7b\u578b\u5df2\u7ecf\u9ed8\u8ba4\u4e3a\u201ctext\u201d\uff0c\u4fee\u6539\u5b57\u6bb5\u7c7b\u578b\u4e3a\u201ckeyword\u201d\u4f1a\u62a5\u9519\uff1a\njava.lang.IllegalArgumentException: mapper [Application_System] of different type, current_type [text], merged_type [keyword]\n2\u3001\u5728\u5bfc\u5165\u6b63\u5f0f\u6570\u636e\u7684\u65f6\u5019\uff0c\u6307\u5b9a\u5b57\u6bb5\u7684\u7c7b\u578b\u4e3akeyword\uff1a\nPutMappingRequestBuilder putMapping = client.admin().indices().preparePutMapping(\"alert\")\n                    .setType(\"loginInfo\");\nputMapping.setUpdateAllTypes(true);\nputMapping.setSource(\"{\\\"properties\\\":{\\\"Application_System\\\":{\\\"type\\\":\\\"keyword\\\",\\\"index\\\":\\\"not_analyzed\\\"}}}\").get();\n3\u3001\u5220\u9664\u7a7a\u884c\uff1a\n   \u627e\u5230\u7a7a\u884c\u7684_id\u7684\u503c\uff0c\u7136\u540e\uff1a\nclient.prepareDelete(\"alert\", \"loginInfo\", rowData.get(\"_id\")+\"\").get();\n\u8fd9\u6837\uff0c\u5bfc\u5165\u7684\u5b57\u6bb5\u7c7b\u578b\u5df2\u7ecf\u88ab\u6307\u5b9a\u4e3a\u201ckeyword\u201d,\u5728\u805a\u5408\u7684\u65f6\u5019\uff0c\u8fd9\u4e2a\u805a\u5408\u5b57\u6bb5\u5c31\u4e0d\u4f1a\u88ab\u5206\u8bcd\u4e86\u3002. @chenyg0911 \u4e3b\u8981\u662f\u6211\u521a\u63a5\u89e6ElasticSearch\u7684java api\u4e0d\u4e45\uff0c\u5bf9\u5f88\u591aapi\u8fd8\u4e0d\u719f\u6089\uff0c\u4e5f\u8bb8\u6709\u66f4\u7b80\u4fbf\u7684\u89e3\u51b3\u65b9\u6cd5\u3002\u5982\u679c\u60a8\u6709\u4ec0\u4e48\u597d\u7684\u89e3\u51b3\u65b9\u5f0f\uff0c\u4e5f\u8bf7\u4e0d\u541d\u8d50\u6559\u3002\n\u53e6\u5916\uff0c\u770b\u5230\u8bb8\u591a\u5730\u65b9\u90fd\u662f\u7528curl\u8fd9\u79cd\u65b9\u5f0f\u5199\u7684\uff0c\u8fd9\u4e0d\u662f\u547d\u4ee4\u884c\u7684\u4ee3\u7801\u4e48\uff1f\u80fd\u5728\u7a0b\u5e8f\u4e2d\u76f4\u63a5\u8c03\u7528\u8fd9\u4e2a\u547d\u4ee4\u4e48\uff1f. @xumingbei \u60a8\u597d\uff01\u7528\u4e2d\u6587\u63d0\u95ee\u53ef\u4ee5\u4e48\uff1f\u6211\u7528\u7684\u662fjava api\u5bfc\u5165\u6570\u636e\u5230ES5.6.3\uff0c\u8bf7\u95ee\u5982\u4f55\u5728\u5bfc\u5165\u7684\u65f6\u5019\uff0c\u6307\u5b9a\u5b57\u6bb5\u7684\u7c7b\u578b\uff1f\n\u6211\u6709\u4e00\u4e2a\u5b57\u6bb5\uff0cES\u9ed8\u8ba4\u7684\u7c7b\u578b\u662ftext\uff0c\u4f46\u662f\u8be5\u5b57\u6bb5\u9700\u8981\u5728\u805a\u5408\u65f6\u4f7f\u7528\uff0ctext\u7c7b\u578b\u4f1a\u88ab\u5206\u8bcd\uff0c\u6211\u60f3\u5728\u5bfc\u5165\u6570\u636e\u7684\u65f6\u5019\uff0c\u6307\u5b9a\u5b57\u6bb5\u7c7b\u578b\u4e3akeyword\u7c7b\u578b\uff0c\u4e0d\u77e5\u9053\u5728\u54ea\u91cc\u8bbe\u7f6e\u3002\n\u8c22\u8c22\u6307\u6559\uff01\uff01. @xumingbei \u8c22\u8c22\u60a8\u7684\u56de\u590d\uff0c\u6211\u7814\u7a76\u4e00\u4e0b\u5728java api\u4e2d\uff0c\u600e\u6837\u5728\u521b\u5efa\u7d22\u5f15\u7684\u65f6\u5019\u6620\u5c04\u7c7b\u578b\u3002. ",
    "urkl": "What is the driver class name for creating connection in applications using this project as jdbc driver ?\nI created my own implementation of Driver, but gettting \njava.lang.NoClassDefFoundError: org/elasticsearch/client/transport/TransportClient\nAnd yes, I did include jar with TransportClient to path.\nThanks\n. ",
    "chrishoo0803": "@allwefantasy why not upgrade druid pool version?. ",
    "anxzhang": "Did you encouter below error when use elasticsearch JDBC?\njava.sql.SQLException: unkow jdbc driver : jdbc:elasticsearch://10.22.208.41:9300/customer\n. ",
    "sunsence": "@wenthywang \u4f60\u597d\uff0c\u8bf7\u6559\u4e00\u4e0b\uff0c\u652f\u6301sql\u5b50\u53e5\u5417\uff1fselect * from (select event_id from index) as a. @allwefantasy \u4f60\u597d\uff0c\u652f\u6301sql\u8bed\u53e5\u5d4c\u5957\u5417\uff1f. @allwefantasy \u4f60\u597d\uff0c\u8bf7\u95eejdbc\u652f\u6301es5.5.2\u5417\uff1f\u76ee\u524d\u6700\u65b0\u7684\u7248\u672c\u662f\u4ec0\u4e48. @hungrytortoise \u5982\u4f55\u89e3\u51b3\u7684\u8fd9\u4e2a\u95ee\u9898\u5462. ",
    "sunpeihao": "@wenthywang  @allwefantasy \u6211\u5728ES\u7684log\u4e2d\u627e\u5230\u62a5\u9519\uff0c\u8fde\u63a5\u8d85\u65f6\u3002\u7136\u540e\u6211\u5c1d\u8bd5\u6dfb\u52a0\u4e86dds.setMaxWait(3600000)\uff0c\u4f46\u662f\u8fd8\u662f\u6ca1\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u8bf7\u95ee\u8fde\u63a5\u8d85\u65f6\u6539\u600e\u4e48\u529e\uff1f\n[2017-12-22T16:46:48,524][WARN ][o.e.t.n.Netty4Transport  ] [sjyjetl] exception caught on transport layer [[id: 0x64b2977e, L:/192.168.0.45:9300 - R:/124.127.206.77:18828]], closing connection\njava.io.IOException: \u8fde\u63a5\u8d85\u65f6\n    at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[?:?]\n    at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[?:?]\n    at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223) ~[?:?]\n    at sun.nio.ch.IOUtil.read(IOUtil.java:197) ~[?:?]\n    at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:375) ~[?:?]\n    at io.netty.buffer.PooledHeapByteBuf.setBytes(PooledHeapByteBuf.java:261) ~[netty-buffer-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1100) ~[netty-buffer-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:372) ~[netty-transport-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123) [netty-transport-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:644) [netty-transport-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:544) [netty-transport-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:498) [netty-transport-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:458) [netty-transport-4.1.13.Final.jar:4.1.13.Final]\n    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) [netty-common-4.1.13.Final.jar:4.1.13.Final]\n    at java.lang.Thread.run(Thread.java:745) [?:1.8.0_11]. @sunsence  \u5e94\u8be5\u662f\u652f\u6301\u7684\uff0c\uff0c\u6211\u73b0\u5728\u7528\u7684\u662f5.6.3\u3002. ",
    "lrc163": "\u6211\u4f7f\u7528select\u8bed\u53e5\u67e5\u8be2\uff0c\u67d0\u5b57\u6bb5\u4e2d\u7684\u6570\u636e\u5185\u5bb9\u5305\u542b\u6570\u5b57\u548c\u5b57\u6bcd\uff0c\u5982\u679c\u628a\u5305\u542b\u5b57\u6bcd\u7684\u5b50\u5b57\u7b26\u4e32\u4f5c\u4e3a\u67e5\u8be2\u6761\u4ef6\u67e5\u8be2\uff0c\u65e0\u6cd5\u67e5\u8be2\u5230\u7ed3\u679c\uff0c\u4f7f\u7528\u7684sql\u8bed\u53e5\u7c7b\u4f3c\u8fd9\u6837\uff1aSELECT F1, F2, X1, G1 from index/tblname where 1 = 1  and G1 like '%39X2%' limit 0, 5 ORDER BY F1 \n\u4f7f\u7528\u7684\u662f\u6700\u65b0\u7684es-sql 6.1.1 ES\u6570\u636e\u5e93\u4e5f\u662f6.1.1\n\u8bf7\u95ee\u5bf9\u4e8e\u6b64\u7c7b\u67e5\u8be2\u9700\u6c42\uff0c\u8981\u600e\u4e48\u5199sql\uff1f\u8c22\u8c22\uff01. @cyhrosefer \u60a8\u597d\uff0c\u8bf7\u95ee\u60a8\u4f7f\u7528x-pack\u4e4b\u540e\u8fde\u63a5es\u5e93\u7684\u95ee\u9898\u89e3\u51b3\u4e86\u5417\uff1f\u662f\u5982\u4f55\u89e3\u51b3\u7684\uff1f\u8c22\u8c22\u3002. +1. ",
    "xklc": "xpack\u5df2\u7ecf\u57285.x\u7684\u7248\u672c\u4e2d\u52a0\u5165\uff0c \u8bf7\u95ee\u6709\u652f\u6301xpack\u7684\u8ba1\u5212\u4e48. ",
    "yanshuai": "\u4f7f\u7528jdbc4es,\u4f1a\u5728getConnection\u7684\u5730\u65b9hang\u4f4f\uff0c\u8fd9\u662f\u4ec0\u4e48\u9519\u8bef\uff0c\u8be5\u600e\u4e48\u89e3\u51b3\uff1f jstack\u65e5\u5fd7\u5982\u4e0b\uff1a\n\"main\" #1 prio=5 os_prio=31 tid=0x00007f7f27004800 nid=0x1703 waiting on condition [0x0000700004dfd000]\n   java.lang.Thread.State: WAITING (parking)\n    at sun.misc.Unsafe.park(Native Method)\n    - parking to wait for  <0x000000076c784608> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n    at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)\n    at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.takeLast(ElasticSearchDruidDataSource.java:1362)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnectionInternal(ElasticSearchDruidDataSource.java:1004)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnectionDirect(ElasticSearchDruidDataSource.java:917)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:898)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:893). ",
    "cnipr": "1.\u4ee3\u7801\u5206\u652f\u7684\u7248\u672c\u8981\u4e0e\u6570\u636e\u5e93\u7684\u7248\u672c\u4e00\u81f4\n2.from\u540e\u9762\u662findex\u800c\u4e0d\u662ftype. ",
    "DevilQun": "I run it ,occurs error below, please help me \nthe error:\njava.lang.InstantiationError: org.elasticsearch.common.transport.TransportAddress\nat com.alibaba.druid.pool.ElasticSearchConnection.<init>(ElasticSearchConnection.java:40)\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:658)\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:623)\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.init(ElasticSearchDruidDataSource.java:570)\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:897)\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:893).\n",
    "missynh": "How to set \"cluster.name\" when i use ElasticSearchDruidDataSourceFactory.createDataSource?\nIs it right use this configuration like \u2018properties.put(\"cluster.name\",\"myCluster\")\u2018;. ",
    "liganglee1122": "@shi-yuan   \u73b0\u5728\u4e0d\u652f\u6301prepareStatement \u5417\uff1f\n```\n        ElasticSearchDruidPooledPreparedStatement ps = (ElasticSearchDruidPooledPreparedStatement) connection\n            .prepareStatement(\"SELECT c1,c2 from zcestestrecord_index1/zcestestrecord where c1 = ?\");\n        ps.setString(1, \"val20.3215825669390816\");\n```\n\u89e3\u6790\u5f02\u5e38\uff0cElasticSearchConnection \u76f4\u63a5return\u7684 new prepareStatement,\u91cc\u9762\u7684\u65b9\u6cd5\u90fd\u8fd8\u6ca1\u5b9e\u73b0\u3002. ",
    "leo-livis": "6.2.4.0\u652f\u6301search guard \u5417. ",
    "ultralzt1117": "@allwefantasy Hello, if I want to query two or more indexes should write?How should the connection be established?\nHow the following SQL should set up the join and query indexes?\nSELECT  user,pass,age from  \" + indexNames + \" where age>10. ",
    "ReveeWu": "@cyhrosefer \u60a8\u597d\uff0c\u540c\u95ee \u60a8\u4f7f\u7528x-pack\u4e4b\u540e\u8fde\u63a5es\u5e93\u7684\u95ee\u9898\u89e3\u51b3\u4e86\u5417\uff1f\u662f\u5982\u4f55\u89e3\u51b3\u7684\uff1f\u8c22\u8c22\u3002. +1. ",
    "yuhailove11": "\n@allwefantasy Hello, if I want to query two or more indexes should write?How should the connection be established?\nHow the following SQL should set up the join and query indexes?\nSELECT user,pass,age from \" + indexNames + \" where age>10\n\nselect user,pass,age from index1,index2 where age>10. ",
    "harveysun": "\n@zizaifeng \u4f60\u7684\u95ee\u9898\u90fd\u89e3\u51b3\u4e86\uff0c\u6211\u4e5f\u6709\u540c\u6837\u7684\u7591\u95ee\n\n@yezhongye  \u8bf7\u95ee\u4e0b\u662f\u600e\u4e48\u89e3\u51b3\u7684\u5462\uff0c\u9047\u5230\u4e86\u540c\u6837\u7684\u95ee\u9898\uff0c\u8c22\u8c22. @shi-yuan  \u9ebb\u70e6\u5e2e\u5fd9\u770b\u4e00\u4e0b\uff0c\u8c22\u8c22\u4e86\n PreparedStatement ps = connection.prepareStatement(\"SELECT  * from  \" + index );\n        ResultSet rs = ps.executeQuery();\n        ResultSetMetaData metaData = rs.getMetaData();\n    int columnCount = metaData.getColumnCount();\n\n\u8c03\u8bd5\u65f6metaData\u5bf9\u8c61\u4e2d\u80fd\u770b\u5230columns\u662f6\uff0c\u4f46\u662f\u8c03\u7528getColumnCount\u8fd4\u56de\u7684\u662f0\uff0c\u8fd9\u4e2a\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f\u6709\u5176\u5b83\u65b9\u6848\u80fd\u53d6\u5230\u8fd9\u4e2a\u503c\u5417\uff1f. @shi-yuan  5.3.0. @shi-yuan  \u4ece\u54ea\u4e2a\u7248\u672c\u5f00\u59cb\u4fee\u590d\u4e86\u6b64bug\u5462. \u597d\u52d2 thanks again dear. \n@shi-yuan  \u770b\u770b\u4e0a\u9762\u56fe\u7247\u4e2d\u7684\u80fd\u53d1\u5e03\u4e00\u4e0b\u5417. \u5176\u5b83\u5144\u5f1f\u6709\u6743\u9650\u7684\uff0c\u4ee3\u8868\u5e7f\u5927\u7231\u597d\u8005\u53cd\u5e94\u4e0b\u60c5\u51b5\u54e6. @ansjsun  \u5927\u4f6c\u80fd\u53d1\u5e03\u4e0b\u4e0a\u9762\u56fe\u7247\u4e2d\u6ca1\u6709\u7684\u7248\u672c\u5417\uff1f\u5f88\u591a\u4eba\u6709\u6b64\u9700\u6c42\u5566. @shi-yuan  \u672c\u63d2\u4ef6\u6709antlr4\u5bf9\u5e94\u7684sql\u89e3\u6790\u7684g4\u6587\u4ef6\u5417. @shi-yuan  ResultSet\u8fd4\u56de\u7684\u7ed3\u679c\u987a\u5e8f\uff0c\u4e3a\u5565\u548csql\u4e2d\u5199\u7684\u4e0d\u4e00\u6837\u5462\uff0c\u5177\u4f53\u573a\u666f\u5982\u4e0b\u6240\u793a\uff1a\n\nsql=\"select log_type,gameid,opgame_id......\"\nrs\u7684MetaData\u91cc\u9762\u7b2c\u4e00\u4e2a\u662fopgame_id,\u800c\u4e0d\u662flog_type;\nES Sql\u7248\u672c\uff1a5.6.5 \n\u9ebb\u70e6\u95ee\u4e0b\u6709\u4ec0\u4e48\u8bbe\u7f6e\u80fd\u8ba9sql\u8fd4\u56de\u7684\u7ed3\u679c\u662f\u4ece\u5de6\u5230\u53f3\u7684\u987a\u5e8f\u5417\uff1f\u8c22\u8c22. > @harveysun \u4e3a\u4ec0\u4e48\u4e0d\u901a\u8fc7\u5b57\u6bb5\u540d\u79f0\u53bb\u6620\u5c04\u5462\uff1f\n\u8fd9\u4e2a\u4e5f\u8003\u8651\u8fc7\uff0c\u4e3b\u8981\u6709\u5982\u4e0b\u4e24\u4e2a\u95ee\u9898\uff1a\n1.\u8fd9\u4e2asql\u662f\u7528\u6237\u81ea\u5b9a\u4e49\u8f93\u5165\u7684\uff0c\u6709\u53ef\u80fd\u6709\u522b\u540d\uff0c\u8fd9\u4e9b\u90fd\u53ef\u4ee5\u901a\u8fc7\u89e3\u6790sql\u540e\u53d6\u5230Fields\u5c5e\u6027\uff0c\u7136\u540e\u901a\u8fc7field.getName\u6216field.getAlias\u89e3\u51b3\uff1b\n2.\u5982\u679csql\u91cc\u9762\u662f*\u53f7\uff0c\u5982select * from user\uff0c\u6b64\u65f6\u8fd4\u56de\u7ed3\u679c\u5c31\u662f\u968f\u673a\u7684\u4e86\uff0c\u76ee\u524d\u6b63\u5728\u60f3\u529e\u6cd5\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff1b. > \u6211\u4e0d\u77e5\u9053\u4f60\u6700\u7ec8\u60f3\u600e\u4e48\u60f3\u7528\u6237\u5c55\u793a\u6570\u636e\u7684\uff0c\u6211\u6709\u4e2a\u60f3\u6cd5\uff1a\u4f60\u4e0d\u5fc5\u53bb\u89e3\u6790sql\u7136\u540e\u83b7\u53d6\u5b57\u6bb5\u540d\uff0c\n\n\n\u4f60\u53ef\u4ee5\u83b7\u53d6metaData\uff0c\u7136\u540e\u83b7\u53d6\u67e5\u8be2\u51fa\u6765\u7684\u5b57\u6bb5\u540d\n\u6700\u7ec8\u76f4\u63a5\u8fd4\u56de\u4e00\u4e2aList>\u5c31\u53ef\u4ee5\u4e86\n\n\u60f3\u5c55\u793a\u7684\u6548\u679c\u662f\uff0c\u6309\u7167\u7528\u6237sql\u4e2d\u7684\u5b57\u6bb5\u987a\u5e8f\uff0c\u5c55\u793a\u5bf9\u5e94\u7684\u7ed3\u679c\uff1a\n\n\u5982\u56fe\u6240\u793a\uff1a\nsql\uff1aselect name,age,position from player\n\u5c55\u793a\u7684\u65f6\u5019\u60f3\u6309\u7167 name,age,position \u7684\u5b57\u6bb5\u987a\u5e8f\u5c55\u793a\uff0c\u73b0\u5728\u5c31\u662f\u56e0\u4e3aresultSet.getMetaData()\u8fd4\u56de\u7684\u987a\u5e8f\u4e0d\u662fsql\u4e2d\u7684\u5b57\u6bb5\u987a\u5e8f\uff0c\u6240\u4ee5\u5bfc\u81f4\u9519\u4f4d\u4e86. > \u8fd9\u4e2a\u53ef\u4ee5\u5355\u72ec\u63d0\u4e2aissue\uff0c\u8003\u8651\u652f\u6301\u4e0b\nhttps://github.com/NLPchina/elasticsearch-sql/issues/838  \u5355\u72ec\u7684issue\u5df2\u521b\u5efa. sql\u8bed\u6cd5 \u8bcd\u6cd5\u89e3\u6790\n\n\n@shi-yuan   elasticsearch-sql\u4e2d\u6709\u5bf9\u5e94\u7684\u8bed\u6cd5 \u8bcd\u6cd5\u89e3\u6790\u7ec4\u4ef6\u6216\u8005\u5176\u5b83\u5f00\u6e90\u7ec4\u4ef6\uff0c\u80fd\u7cbe\u51c6\u5b9a\u4f4d\u5230sql\u4e2d\u5177\u4f53\u662f\u54ea\u91cc\u9519\u4e86\u7684\uff0c\u7c7b\u4f3c\u7b2c\u4e00\u5f20\u56fe\u4e2d\u7684\u9519\u8bef\u6548\u679c\uff0c\u8c22\u8c22. @shi-yuan  \u6700\u591a\u8fd4\u56de200\u884c\u7684\u8fd9\u4e2a\u9650\u5236\u600e\u4e48\u89e3\u9664\u5462\uff0c\u6025\u7528\uff0c\u5728\u7ebf\u7b49\u5f85\uff0c\u8c22\u8c22. How do you fix it?thank you. @ansjsun   https://mvnrepository.com/artifact/org.nlpcn/elasticsearch-sql  5.1.2.0\u52306.2.2.0 \u4e2d\u95f4\u7684\u90a3\u4e9b\u7248\u672c\u600e\u4e48\u6ca1\u6709\u5462\uff1f\u5230\u54ea\u91cc\u53ef\u4ee5\u5f15\u5165\u4ed6\u4eec\u5462\uff1f\u8c22\u8c22. ",
    "Jacky0312": "jdbc:elasticsearch://localhost:9300  \u8fd9\u4e2a\u540e\u9762\u53ef\u4ee5\u8ddf\u591a\u8282\u70b9\u5417\uff1f. ```\nwhile (rs.next()) {\n                Map row = new LinkedHashMap();\n            for (int i = 0, size = rsMeta.getColumnCount(); i < size; ++i) {\n                String columName = rsMeta.getColumnLabel(i + 1);\n                Object value = rs.getObject(i + 1);\n                row.put(columName, value);\n            }\n\n            rows.add(row);\n        }\n\n```\n\u8fd9\u4e2agetColumnLabel\u5728\u8fd9\u91cc\u52a01,\u540e\u9762\u4f1a\u5728\u51cf1.\n\u800cgetObject\u52a01\u4ee5\u540e, \u540e\u9762\u6ca1\u6709\u51cf,\u5bfc\u81f4\u4e86out index\u9519\u8bef.\u4e0d\u77e5\u9053\u8fd9\u4e2a\u662f\u4e0d\u662f\u4e2abug.. > \u4f7f\u7528jdbc4es,\u4f1a\u5728getConnection\u7684\u5730\u65b9hang\u4f4f\uff0c\u8fd9\u662f\u4ec0\u4e48\u9519\u8bef\uff0c\u8be5\u600e\u4e48\u89e3\u51b3\uff1f jstack\u65e5\u5fd7\u5982\u4e0b\uff1a\n\n\"main\" #1 prio=5 os_prio=31 tid=0x00007f7f27004800 nid=0x1703 waiting on condition [0x0000700004dfd000] java.lang.Thread.State: WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for <0x000000076c784608> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.takeLast(ElasticSearchDruidDataSource.java:1362) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnectionInternal(ElasticSearchDruidDataSource.java:1004) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnectionDirect(ElasticSearchDruidDataSource.java:917) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:898) at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:893)\n\n\u6709\u89e3\u51b3\u65b9\u6848\u5417\uff1f. I solve this problem through workaround.\nSolutions: \n1. For the date_format fucntion will be parsed into a script method, where the source generation rules is: \nif (operator.equals(\"=\")) {\n            operator = \"==\";\n        }\n        String finalStr = v1Dec + v2Dec + v1 + \" \" + operator + \" \" + v2;\n2. So, if use operator to compare string direct will throw an exception\n3. I rewrote this part of the code, such as:\ninalStr = v1Dec + v2Dec + v1 + \".compareTo(\" + v2 + \") >= 0\";. Does it support date_format now?. Ignore, not issue.. > master branch\nSo the bug has been fixed in the latest version.\nBy the way, whether the version of elasticsearch-sql corresponds to the version of elasticsearch.\nThe version of elasticsearch-sql I use is 6.2.2.\nThanks!. > yeah\uff0cthe version of elasticsearch-sql corresponds to the version of elasticsearch\nOk, thank you very much.. @shi-yuan please help?. #809. > \u8fd9\u662f\u4e2abug\uff0c\u5148\u5f00\u7740\u54c8\n\n\u5bf9\u4e8eNESTED_COMPLEX opera\u4f1a\u5728Maker\u91cc\u505a\u4e00\u6b21nestedQuery\n```\ncase NESTED_COMPLEX:\n            if(value == null || ! (value instanceof Where) )\n                throw new SqlParseException(\"unsupported nested condition\");    Where whereNested = (Where) value;\n    BoolQueryBuilder nestedFilter = QueryMaker.explan(whereNested);\n\n    x = QueryBuilders.nestedQuery(name, nestedFilter, ScoreMode.None);\nbreak;\n\n```\n\n\n\u5e76\u4e14\u8fd8\u4f1a\u5728QueryMaker\u91cc\u5728\u505a\u4e00\u6b21nestedQuery\nif (condition.isNested()) {\n                subQuery = QueryBuilders.nestedQuery(condition.getNestedPath(), subQuery, ScoreMode.None);\n            } else if(condition.isChildren()) {\n                subQuery = JoinQueryBuilders.hasChildQuery(condition.getChildType(), subQuery, ScoreMode.None);\n            }\n\u4ece\u800c\u5bfc\u81f4\u4e86nested {query{}} \u91cd\u590d,\u67e5\u8be2\u4e0d\u51fa\u7ed3\u679c. ",
    "leighyu1983": "@shi-yuan  Hi, how to write connection string for es cluster?. ",
    "leo-huangw": "@shi-yuan \u6211\u7528java\u8fde\u63a5\u4e0d\u4e0aes... \u793a\u4f8b\u4ee3\u7801\u8dd1\u5230\u5efa\u7acb\u8fde\u63a5\u5c31\u62a5\u9519\u3002 es\u7248\u672c\u662f6.4.1.  \u4e0d\u77e5\u9053pom.xml\u9700\u8981\u5f15\u5165\u54ea\u4e9b\u5305\u3002\n18:00:08.214 [main] INFO com.alibaba.druid.pool.DruidDataSource - {dataSource-1} inited\nException in thread \"main\" java.lang.NoSuchMethodError: org.elasticsearch.common.settings.Settings$Builder.put([Ljava/lang/Object;)Lorg/elasticsearch/common/settings/Settings$Builder;\n    at org.elasticsearch.xpack.notification.email.Account.<clinit>(Account.java:67)\n    at org.elasticsearch.xpack.XPackPlugin.<clinit>(XPackPlugin.java:191)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n    at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n    at java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n    at org.elasticsearch.plugins.PluginsService.loadPlugin(PluginsService.java:600)\n    at org.elasticsearch.plugins.PluginsService.<init>(PluginsService.java:112)\n    at org.elasticsearch.client.transport.TransportClient.newPluginService(TransportClient.java:108)\n    at org.elasticsearch.client.transport.TransportClient.buildTemplate(TransportClient.java:133)\n    at org.elasticsearch.client.transport.TransportClient.<init>(TransportClient.java:283)\n    at org.elasticsearch.transport.client.PreBuiltTransportClient.<init>(PreBuiltTransportClient.java:133)\n    at org.elasticsearch.xpack.client.PreBuiltXPackTransportClient.<init>(PreBuiltXPackTransportClient.java:55)\n    at org.elasticsearch.xpack.client.PreBuiltXPackTransportClient.<init>(PreBuiltXPackTransportClient.java:50)\n    at org.elasticsearch.xpack.client.PreBuiltXPackTransportClient.<init>(PreBuiltXPackTransportClient.java:46)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:686)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.createPhysicalConnection(ElasticSearchDruidDataSource.java:632)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.init(ElasticSearchDruidDataSource.java:579)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:930)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:926)\npom.xml\n```\n\norg.elasticsearch\nelasticsearch\n${es.version}\n\n    <dependency>\n        <groupId>org.elasticsearch.client</groupId>\n        <artifactId>x-pack-transport</artifactId>\n        <version>6.0.0-alpha2</version>\n    </dependency>\n    <dependency>\n        <groupId>org.nlpcn</groupId>\n        <artifactId>elasticsearch-sql</artifactId>\n        <version>${es.sql.version}</version>\n        <scope>system</scope>\n        <systemPath>${project.basedir}/lib/${es.version}/elasticsearch-sql-6.4.1.0.jar</systemPath>\n    </dependency>\n    <dependency>\n        <groupId>mysql</groupId>\n        <artifactId>mysql-connector-java</artifactId>\n        <version>5.1.35</version>\n    </dependency>\n\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>druid</artifactId>\n        <scope>system</scope>\n        <version>1.0.15</version>\n        <systemPath>${project.basedir}/lib/${es.version}/druid.jar</systemPath>\n    </dependency>\n\n```. ",
    "ws2823147532": "@harveysun \u4e3a\u4ec0\u4e48\u4e0d\u901a\u8fc7\u5b57\u6bb5\u540d\u79f0\u53bb\u6620\u5c04\u5462\uff1f. \u6211\u4e0d\u77e5\u9053\u4f60\u6700\u7ec8\u60f3\u600e\u4e48\u60f3\u7528\u6237\u5c55\u793a\u6570\u636e\u7684\uff0c\u6211\u6709\u4e2a\u60f3\u6cd5\uff1a\u4f60\u4e0d\u5fc5\u53bb\u89e3\u6790sql\u7136\u540e\u83b7\u53d6\u5b57\u6bb5\u540d\uff0c\n\n\u4f60\u53ef\u4ee5\u83b7\u53d6metaData\uff0c\u7136\u540e\u83b7\u53d6\u67e5\u8be2\u51fa\u6765\u7684\u5b57\u6bb5\u540d\n\u6700\u7ec8\u76f4\u63a5\u8fd4\u56de\u4e00\u4e2aList>\u5c31\u53ef\u4ee5\u4e86\n. \u4f46\u662f  \u9700\u8981\u4fee\u6539 \u6e90\u7801\u7684\u4e00\u4e2a\u7c7b com.alibaba.druid.pool.ElasticSearchResultSetMetaDataBase\n\n\u6539\u6210\n\n\u8981\u4e0d\u7136\u7684\u8bdd \u8c03\u7528getMetaData()\u65b9\u6cd5 \u83b7\u53d6\u7684\u7ed3\u679c\u4e00\u76f4\u90fd\u662f\u4e00\u4e2a\u7a7alist. @wuchaooooo \u81ea\u5df1\u7f16\u8bd1\u4e00\u4e0b \uff0cdeploy\u5230\u79c1\u6709maven\u5e93\u6216\u8005install\u5230\u672c\u5730\u4ed3\u5e93\uff0c\u5c31\u80fd\u5f15\u4e86\u554a\u3002\u6211\u5c31\u662f\u8fd9\u6837\u5e72\u7684. \u5728 pom.xml\u91cc\u9762\u6709\u4e00\u4e2a  GPG \u7684\u63d2\u4ef6  \u6ce8\u91ca\u6389\u5c31\u53ef\u4ee5 @wuchaooooo . terms(field='correspond_brand_name',size='10',alias='correspond_brand_name') \u8fd9\u6837\u7684\u5199\u6cd5\u53ef\u80fd\u4f1a\u5bfc\u81f4\u7edf\u8ba1\u7684\u6570\u636e\u4e0d\u5b8c\u6574 @shi-yuan . ",
    "xForMe": "`@Bean(name=\"esDruidSource\")\n    public DruidDataSource esDruid() throws Exception {\n        System.setProperty(\"es.set.netty.runtime.available.processors\", \"false\");\n        Settings esSettings = Settings.builder()\n                .put(\"cluster.name\", \"tp-cluster\") //\u8bbe\u7f6eES\u5b9e\u4f8b\u7684\u540d\u79f0\n                .build();\n        TransportClient client = new PreBuiltTransportClient(esSettings);//\u521d\u59cb\u5316client\u8f83\u8001\u7248\u672c\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u6b64\u65b9\u6cd5\u6709\u51e0\u4e2a\u91cd\u8f7d\u65b9\u6cd5\uff0c\u521d\u59cb\u5316\u63d2\u4ef6\u7b49\u3002\n        //\u6b64\u6b65\u9aa4\u6dfb\u52a0IP\uff0c\u81f3\u5c11\u4e00\u4e2a\uff0c\u5176\u5b9e\u4e00\u4e2a\u5c31\u591f\u4e86\uff0c\u56e0\u4e3a\u6dfb\u52a0\u4e86\u81ea\u52a8\u55c5\u63a2\u914d\u7f6e\n        byte[] arr = new byte[]{(byte)10,(byte)29,(byte)23,(byte)74};\n        client.addTransportAddress(new TransportAddress(InetAddress.getByAddress(arr), 9300));\n        Properties properties = new Properties();\n        properties.put(\"url\", \"jdbc:elasticsearch://10.29.23.74:9300/t_report_precust_b/\");\n        properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n    DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n    return dds;\n}`\n\n\u6211\u5c1d\u8bd5\u7740\u548cSpringboot\u7ed3\u5408\u5728\u4e00\u8d77\u3002\u5728\u5bb9\u5668\u542f\u52a8\u7684\u65f6\u5019\u5c31\u521b\u5efabean\uff0c\u4f46\u662f\u4f1a\u629b\u51fa\u4ee5\u4e0b\u5f02\u5e38\n2018-12-26 11:23:23.432 [main] WARN  o.s.boot.autoconfigure.orm.jpa.DatabaseLookup[80] -Unable to determine jdbc url from datasource\norg.springframework.jdbc.support.MetaDataAccessException: DatabaseMetaData returned by Connection [com.alibaba.druid.pool.ElasticSearchConnection@710ae6a7] was null\n    at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:323) ~[spring-jdbc-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:356) ~[spring-jdbc-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.DatabaseLookup.getDatabase(DatabaseLookup.java:72) ~[spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.JpaProperties.determineDatabase(JpaProperties.java:166) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration.jpaVendorAdapter(JpaBaseConfiguration.java:111) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration$$EnhancerBySpringCGLIB$$9cf8d1be.CGLIB$jpaVendorAdapter$5(<generated>) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration$$EnhancerBySpringCGLIB$$9cf8d1be$$FastClassBySpringCGLIB$$c5dcaa5b.invoke(<generated>) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) [spring-core-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:365) [spring-context-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration$$EnhancerBySpringCGLIB$$9cf8d1be.jpaVendorAdapter(<generated>) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_172]\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_172]\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_172]\n    at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_172]\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:583) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n\u5199\u5355\u5143\u6d4b\u8bd5\u4e4b\u7c7b/\u5355\u4f8b\u90fd\u662f\u987a\u5229\u901a\u8fc7\u7684. \u5728\u5199\u6d4b\u8bd5\u7528\u4f8b\u548c\u5355\u4f8b\u7684\u65f6\u5019\u90fd\u662f\u53ef\u4ee5\u7684\uff0c\u4f46\u662f\u6211\u628a\u8fd9\u4e2a\u96c6\u6210\u5728Springboot\u7684bean\u4e2d\u5c31\u51fa\u95ee\u9898\u4f8b\u3002\n2018-12-26 11:23:23.432 [main] WARN  o.s.boot.autoconfigure.orm.jpa.DatabaseLookup[80] -Unable to determine jdbc url from datasource\norg.springframework.jdbc.support.MetaDataAccessException: DatabaseMetaData returned by Connection [com.alibaba.druid.pool.ElasticSearchConnection@710ae6a7] was null\n    at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:323) ~[spring-jdbc-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:356) ~[spring-jdbc-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.DatabaseLookup.getDatabase(DatabaseLookup.java:72) ~[spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.JpaProperties.determineDatabase(JpaProperties.java:166) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.JpaBaseConfiguration.jpaVendorAdapter(JpaBaseConfiguration.java:111) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration$$EnhancerBySpringCGLIB$$9cf8d1be.CGLIB$jpaVendorAdapter$5(<generated>) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration$$EnhancerBySpringCGLIB$$9cf8d1be$$FastClassBySpringCGLIB$$c5dcaa5b.invoke(<generated>) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) [spring-core-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:365) [spring-context-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaConfiguration$$EnhancerBySpringCGLIB$$9cf8d1be.jpaVendorAdapter(<generated>) [spring-boot-autoconfigure-2.0.7.RELEASE.jar:2.0.7.RELEASE]\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_172]\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_172]\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_172]\n    at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_172]\n    at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:154) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:583) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1246) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1096) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:535) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:495) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:317) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n    at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:315) [spring-beans-5.0.11.RELEASE.jar:5.0.11.RELEASE]\n\u9ebb\u70e6\u5e2e\u6211\u770b\u4e0b\n\u8fd9\u4e2a\u662f\u6211\u96c6\u6210\u7684\u4ee3\u7801\n```\n@Bean(name=\"esDruidSource\")\n    public DruidDataSource esDruid() throws Exception {\n        System.setProperty(\"es.set.netty.runtime.available.processors\", \"false\");\n        Settings esSettings = Settings.builder()\n                .put(\"cluster.name\", \"tp-cluster\") //\u8bbe\u7f6eES\u5b9e\u4f8b\u7684\u540d\u79f0\n                .build();\n        TransportClient client = new PreBuiltTransportClient(esSettings);//\u521d\u59cb\u5316client\u8f83\u8001\u7248\u672c\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u6b64\u65b9\u6cd5\u6709\u51e0\u4e2a\u91cd\u8f7d\u65b9\u6cd5\uff0c\u521d\u59cb\u5316\u63d2\u4ef6\u7b49\u3002\n        //\u6b64\u6b65\u9aa4\u6dfb\u52a0IP\uff0c\u81f3\u5c11\u4e00\u4e2a\uff0c\u5176\u5b9e\u4e00\u4e2a\u5c31\u591f\u4e86\uff0c\u56e0\u4e3a\u6dfb\u52a0\u4e86\u81ea\u52a8\u55c5\u63a2\u914d\u7f6e\n        byte[] arr = new byte[]{(byte)10,(byte)29,(byte)23,(byte)74};\n        client.addTransportAddress(new TransportAddress(InetAddress.getByAddress(arr), 9300));\n        Properties properties = new Properties();\n        properties.put(\"url\", \"jdbc:elasticsearch://10.29.23.74:9300/t_report_precust_b/\");\n        properties.put(PROP_CONNECTIONPROPERTIES, \"client.transport.ignore_cluster_name=true\");\n    DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n    return dds;\n}\n\n```\n. ",
    "Kamelia2000": "hello I used this software is nice working however have a problem when SQL have alot of join can not generate Elastic Query ? Do you have idea for this ? \nThanks,\nKamelia . ",
    "peablog": "mark\n. ",
    "fengshenyuan": "@yenduttjain Do u still need 2.4.0.zip? I just download the project and build one by hand.It seems the package works well with Elasticsearch 2.4.0.\n. @madkoala \n```\n1.Download the master version and modify the pom.xml file:\n\nfind \"2.3.5\" in pom.xml file, change its value to 2.4.0\nfind\n    ...\n    elasticsearch-sql\n2.4.0\njar\n    ...\nchange its value to 2.4.0\n\n2.cd to ../elasticsearch-sql-master/ dir, run cmd \"mvn clean package assembly:single -DskipTests\", then you will get the package you want.\n```\n. @shi-yuan It works.Thanks.\n. ",
    "ikingnet": "+1 \nPlease support the feature. Thanks\n. ",
    "dangxunb": "+1 for this feature!\n. An Elasticsearch related question: I was trying to profile both IN and IN_TERMS query with 1056 distinct word on a not_analyzed String field, and the profiling result of them are identical. It seems to be Elasticsearch rewrite both queries to the same type and execute it the same way). \nIs there some way to optimize this kind of query? I'm confused about this.. Great! Can I get a parent with all child? \n. You can press the \"Explain\" button in the UI to show the corresponding native ES query and query it yourself to identify the problem.\n. Great! Thank you for all of this work! You received my #1 honor!. Can you push the newest artifact to maven central? I can just found the 2.x version:\nhttps://mvnrepository.com/artifact/org.nlpcn/elasticsearch-sql. Hey I still can't see it in maven central, is it normal?. ",
    "vg-github": "+1 (is there an alternative such as NOT IN (), in such way at least we can exclude the docs in the first offset?). ",
    "jianggerong": "+1 I also need paging after aggregation . ",
    "chomenko": "+1 for this feature!. ",
    "opensure": "+1 for this feature!. ",
    "palbiplab": "SELECT * FROM yourIndex/parentType where children(childrenType, childrenField)='value'\n seems to be not working with 6.x (61.1.2,6.4.0) Could you please provide the full syntax to use has_children  and has_parent?. when can we expect support for bucket_selector in SQL Plugin or Having?. Thanks, @shi-yuan it works with the latest version (6.5.3). Thanks, @shi-yuan it works with the latest version (6.5.3).. Thanks, @shi-yuan, it works.. ",
    "dangnhdev": "Wow! Thank you very much! Can you include it in a current or a new minor release? It will be very helpful :+1: \n. ",
    "rockmgh": "Thanks. :)\n. ",
    "yu412346928": "@allwefantasy \n. @allwefantasy  \u4f60\u786e\u5b9a\u80fd\u8f6c\u6362\u6210\u529f\uff1f \u6211\u57281.7\u548c2.3.1\u90fd\u62a5\u540c\u6837\u7684\u9519\u8bef,\u4f60\u6709\u65f6\u95f4\uff0c\u6211\u7535\u8111\u53ef\u4ee5\u8fdc\u7a0b\uff0c\u4f60\u67e5\u770b\u4e00\u4e0b\u3002\n. @allwefantasy  thanks,\u6709\u65f6\u95f4\u6211\u8bd5\u8bd52.4\n. ",
    "unbendingWind": "\u6211\u7528\u7684\u662f5.3.2.\u3002\u3002SELECT uid as id,count(*) as datacount FROM h5log-2017.06.14 where uid > 0 group by uid\nunion\nselect ip as id,count(*) as datacount FROM h5log-2017.06.14  where uid = 0 group by ip\n\u67e5\u8be2\u6ca1\u62a5\u9519\uff0c\u4f46\u662f\u663e\u793a\u7684\u7ed3\u679c\u662f\u9519\u8bef\u7684 @yu412346928 . \u4f60\u597d\u3002\u6211\u6539\u6210\u4e868089\uff0c\u7136\u540e\u8bbf\u95ee\u7684\u662fhttp://ip:8089. \u62b1\u6b49\uff0c\u64cd\u4f5c\u95ee\u9898\uff0c2\u697c\u662f\u5bf9\u7684\uff0c\u5df2\u7ecf\u53ef\u4ee5\u6b63\u5e38\u8bbf\u95ee. \u6309\u71672\u697c\u8bf4\u7684\u770b\u770b\uff0c\u9664\u4e86\u8bbf\u95ee8080\u7aef\u53e3\u5916\uff0c\u9875\u9762\u4e0a\u9762\u8fd8\u8981\u8f93\u5165es\u7684\u8bbf\u95ee\u5730\u5740\uff1ahttp://ip:9200/. \n\n@shi-yuan  but zhe result is error,why?\n. ",
    "stoneLee81": "too many results for first table, stoping at:100000. ",
    "yuxuanh": "this is hardcode in source, you can exchange first table and second table, if second table doesn't exceed 100000 row.\nhttps://github.com/NLPchina/elasticsearch-sql/blob/elastic6.3.2/src/main/java/org/elasticsearch/plugin/nlpcn/ElasticJoinExecutor.java. ",
    "wx7614140": "@ansjsun es\u91cc\u7684mapping\u4e0d\u662fyyyy-MM-dd\u7684\u7ed3\u6784\uff0c\u6211\u9700\u8981format\u6210\u6211\u9700\u8981\u7684\u683c\u5f0f\uff0c\u6211\u60f3\u95ee\u7684\u662f\u600e\u4e48format\n. ",
    "zhaolihe": "any update? i need this feature too.. i find the solution to concat multi fields using concat_ws.\nfor example http://localhost:9200/_sql/_explain?sql=select sum(pv) from pv_index  group by concat_ws('-',province,city) \nand the reponse is \njson\n{\n  \"from\" : 0,\n  \"size\" : 0,\n  \"_source\" : {\n    \"includes\" : [\n      \"SUM\"\n    ],\n    \"excludes\" : [ ]\n  },\n  \"aggregations\" : {\n    \"field_1503741176\" : {\n      \"terms\" : {\n        \"script\" : {\n          \"inline\" : \"def concat_ws_854405200 =doc['province'].value+ '-' +doc['city'].value;return concat_ws_854405200;\",\n          \"lang\" : \"painless\"\n        },\n        \"size\" : 10,\n        \"min_doc_count\" : 1,\n        \"shard_min_doc_count\" : 0,\n        \"show_term_doc_count_error\" : false,\n        \"order\" : [\n          {\n            \"_count\" : \"desc\"\n          },\n          {\n            \"_term\" : \"asc\"\n          }\n        ]\n      },\n      \"aggregations\" : {\n        \"SUM(pv)\" : {\n          \"sum\" : {\n            \"field\" : \"pv\"\n          }\n        }\n      }\n    }\n  }\n}. \u6211\u5df2\u7ecf\u4fee\u590d\u4e86\u8fd9\u4e2abug\uff0c\u4f46\u662f\u6211\u6ca1\u6709\u63d0\u4ea4\u4ee3\u7801\u7684\u6743\u9650. \u6211\u8fd8\u662f\u63d0\u4ea4\u4e0d\u4e86\uff0c\u9519\u8bef\u4fe1\u606f\njava\ngit -c diff.mnemonicprefix=false -c core.quotepath=false -c credential.helper=sourcetree push -v --tags --set-upstream origin refs/heads/fixbug:refs/heads/fixbug \nPushing to https://zhaolihe@github.com/NLPchina/elasticsearch-sql.git\nremote: Permission to NLPchina/elasticsearch-sql.git denied to zhaolihe.\nfatal: unable to access 'https://zhaolihe@github.com/NLPchina/elasticsearch-sql.git/': The requested URL returned error: 403\nCompleted with errors, see above. CI \u5355\u5143\u6d4b\u8bd5\u5931\u8d25\u662f\u56e0\u4e3aorg.nlpcn.es4sql.query.AggregationQueryAction \u4e2d explain()\u65b9\u6cd5\u7684\u4ee3\u7801\u7247\u6bb5\njava\n        // add field\n        if (select.getFields().size() > 0) {\n            setFields(select.getFields());\n//            explanFields(request,select.getFields(),lastAgg);\n        }\nsetFields\u65b9\u6cd5\u5bfc\u81f4\u7684\u3002\n\u8be5\u95ee\u9898\u5e94\u8be5\u4e00\u76f4\u5b58\u5728\uff0c\u5e76\u4e0d\u662f\u6211\u8fd9\u6b21\u4fee\u6539\u5f15\u5165\u7684\u3002. ",
    "fywxin": "thk, all\n. ",
    "UrielRicardo": "@eliranmoyal  Thanks so much bro!!!!!!!!!\n. ",
    "woderia": "i think it's a problem and i see create.io has solve it\n. why need groovy? \nJust two column to '+-*/' . solve it\n1.install groovy\n2.add script.engine.groovy.inline.aggs: on\n          script.engine.groovy.inline.update: on \nin your.yml. ",
    "oreak": "@eliranmoyal  great  work. @allwefantasy plan for es5.0?. @allwefantasy It's time now ,many people have already upgreded to es 5.0. ",
    "kilnamkim": "@eliranmoyal \nI want to know date function without Script-Fields.\nThanks for your comment.. ",
    "elyday": "Is this on a todo list or it isn't planed to implement this?. Okay, thats look really nice. {\n    \"from\": 0,\n    \"size\": 0,\n    \"query\": {\n        \"bool\": {\n            \"must\": {\n                \"bool\": {\n                    \"must\": [\n                        {\n                            \"range\": {\n                                \"column2\": {\n                                    \"from\": 2016,\n                                    \"to\": null,\n                                    \"include_lower\": true,\n                                    \"include_upper\": true\n                                }\n                            }\n                        },\n                        {\n                            \"range\": {\n                                \"column2\": {\n                                    \"from\": null,\n                                    \"to\": 2016,\n                                    \"include_lower\": true,\n                                    \"include_upper\": true\n                                }\n                            }\n                        },\n                        {\n                            \"match\": {\n                                \"column3\": {\n                                    \"query\": \"BIA\",\n                                    \"type\": \"phrase\"\n                                }\n                            }\n                        },\n                        {\n                            \"missing\": {\n                                \"field\": \"amount\"\n                            }\n                        }\n                    ]\n                }\n            }\n        }\n    },\n    \"_source\": {\n        \"includes\": [\n            \"column2\",\n            \"column4\",\n            \"column5\",\n            \"column6\",\n            \"column7\",\n            \"column8\",\n            \"column9\",\n            \"column3\",\n            \"SUM\"\n        ],\n        \"excludes\": []\n    },\n    \"fields\": [\n        \"column2\",\n        \"column4\",\n        \"column5\",\n        \"column6\",\n        \"column7\",\n        \"column8\",\n        \"column9\",\n        \"column3\"\n    ],\n    \"aggregations\": {\n        \"column2\": {\n            \"terms\": {\n                \"field\": \"column2\",\n                \"size\": 200\n            },\n            \"aggregations\": {\n                \"column4\": {\n                    \"terms\": {\n                        \"field\": \"column4\",\n                        \"size\": 0\n                    },\n                    \"aggregations\": {\n                        \"column5\": {\n                            \"terms\": {\n                                \"field\": \"column5\",\n                                \"size\": 0\n                            },\n                            \"aggregations\": {\n                                \"column6\": {\n                                    \"terms\": {\n                                        \"field\": \"column6\",\n                                        \"size\": 0\n                                    },\n                                    \"aggregations\": {\n                                        \"column7\": {\n                                            \"terms\": {\n                                                \"field\": \"column7\",\n                                                \"size\": 0\n                                            },\n                                            \"aggregations\": {\n                                                \"column8\": {\n                                                    \"terms\": {\n                                                        \"field\": \"column8\",\n                                                        \"size\": 0\n                                                    },\n                                                    \"aggregations\": {\n                                                        \"column9\": {\n                                                            \"terms\": {\n                                                                \"field\": \"column9\",\n                                                                \"size\": 0\n                                                            },\n                                                            \"aggregations\": {\n                                                                \"column3\": {\n                                                                    \"terms\": {\n                                                                        \"field\": \"column3\",\n                                                                        \"size\": 0\n                                                                    },\n                                                                    \"aggregations\": {\n                                                                        \"value\": {\n                                                                            \"terms\": {\n                                                                                \"field\": \"value\",\n                                                                                \"size\": 0\n                                                                            },\n                                                                            \"aggregations\": {\n                                                                                \"value\": {\n                                                                                    \"sum\": {\n                                                                                        \"field\": \"points\"\n                                                                                    }\n                                                                                }\n                                                                            }\n                                                                        }\n                                                                    }\n                                                                }\n                                                            }\n                                                        }\n                                                    }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\nI have anonymoused the data but the sense behind the data is the same. Hm.. in my postgresql query box the result is fine but not in the elasticsearch sql result.\nI will try your opinion tomorrow or in the next days when my dev machine is up and ready.. ",
    "justgig8": "Do we have support for HAVING clause now?\nI wish to run the following SQL:- \nselect CUSTMR_ID.keyword, count(1) as count from engaged where ACTION = 'OPEN' group by CUSTMR_ID.keyword having count(1) > 4\nRight now am trying to run this instead:-\nselect * from (select CUSTMR_ID.keyword, count(1) as count from engaged where ACTION = 'OPEN' group by CUSTMR_ID.keyword) a where a.count > 4\nand am getting same exception as:-\n{\"error\":{\"root_cause\":[{\"type\":\"class_cast_exception\",\"reason\":\"com.alibaba.druid.sql.ast.statement.SQLSubqueryTableSource cannot be cast to com.alibaba.druid.sql.ast.statement.SQLJoinTableSource\"}],\"type\":\"class_cast_exception\",\"reason\":\"com.alibaba.druid.sql.ast.statement.SQLSubqueryTableSource cannot be cast to com.alibaba.druid.sql.ast.statement.SQLJoinTableSource\"},\"status\":500}. ",
    "fzh890523": "Ps:\nIt seems that the sql-web-page has done it well. But I want to use it as java API and thus I'd like to know how you handle the infinite value returned from elasticsearch in such situations?\nThanks.. I know it. And I just do not take a deep look into the source code of \"elasticsearch-sql\". Would you mind figuring out the class containing the logic which handle the abnormal interger/float value from es?. ",
    "when520": "I have the same problem,Who has solved it?. @shi-yuan  your share the url can't solve the problem. What version of the Elasticsearch are you using?\nBefore get your message, I thought only Elasticsearch 5.6.3+  can use the getColumnCount function. Are you Chinese? In this I can use \u4e2d\u6587 . ",
    "touch-head-optimistically": "nice!. oh, \"_update_by_query\" is now available in the version 5.0. \nIs there any plan supporting  \"UPDATE\" command ?. it's ok. I thought \"delete_by_query\" api is already not a plugin in version5.0. But now it still looks like something wrong although it's provides as api.\nI hope you can finally solve it : ). oh, if it still be provided as a plugin, may be the problem can't be solved like version2.x.x.... ",
    "ffpeng90": "is there any progress on it?  i have met same problem on elasticsearch 5.2.0.. ",
    "AishwaryaZen": "@eliranmoyal  can I explain a sql query which has REGEXP now with es 2.4 ?. ",
    "allen-zh": "That solve the problem, thanks. ",
    "sanjuktas": "will it work for Elasticsearch 1.7.1 ?. The default value is 200, that is why. You may get a count for your query which is 5000 in your case and use ex. LIMIT 5000 and you will get the 5000 records.. ",
    "CharanSahaj": "@shi-yuan is it supported in 5.6.4? if not is there anyway to be able to do even basic regex like starts with and ends with?. I just asked if it's supported and you made changes such that it is, best thing that ever happened to me on github. Thanks a lot :) \ud83d\udc4d  @shi-yuan . @shi-yuan sure :) \ncurl -XPUT 'localhost:9200/kent.transaction.2017.02/events/1qeg157t-c24f-1234-8527-51e521215me6' -d'\n{\n  \"hd\": {\n    \"org\": \"marvel\",\n    \"ec\": \"transaction\",\n    \"es\": \"\",\n    \"et\": \"SecurityBuy\",\n    \"eid\": \"1qeg157t-c24f-1234-8527-51e521215me6\",\n    \"uid\": \"TonyStark@marvel.com\",\n    \"ts\": \"2017-02-20T19:20:30.45Z\"\n  },\n  \"pl\": {\n    \"price\": 8,\n    \"currency\": \"usd\",\n    \"date\": \"1998-07-16T19:20:30.45+01:00\",\n    \"item\": {\n      \"id\": \"id4\",\n      \"name\": \"Ark-Knight\",\n      \"type\": \"Movie\"\n    }\n  },\n  \"ex\": {\n    \"rts\": 1510043481723,\n    \"hl\": {\n       \"ml\": {\n        \"summary\": \"this is the summary\",\n        \"keywords\": [\"reviews\", \"paragraphs\", \"paragraph\"],\n        \"topics\":  {\"topic1\" : 0.5, \"topic1\" : 0.5},\n        \"entities\": [\"reviews\", \"paragraphs\", \"paragraph\"],\n        \"sentiment\": {\"neg\": 0.5 , \"neu\": 0.712 , \"pos\": 0.145 , \"compound\": 0.2344} ,\n        \"intent\": \"this is the intent\",\n        \"classification\": {\"neg\": 0.5, \"neu\": 0.32, \"pos\": 0.038, \"compound\": 0.18}\n       },\n       \"hl\": {\n       }\n    }\n  }\n}'\ncurl -XPUT 'localhost:9200/kent.transaction.2017.04/events/1trg157t-c24f-1234-8527-51e521215me6' -d'\n{\n  \"hd\": {\n    \"org\": \"marvel\",\n    \"ec\": \"transaction\",\n    \"es\": \"\",\n    \"et\": \"SecurityBuy\",\n    \"eid\": \"1trg157t-c24f-1234-8527-51e521215me6\",\n    \"uid\": \"TonyStark@marvel.com\",\n    \"ts\": \"2017-04-20T19:20:30.45Z\"\n  },\n  \"pl\": {\n    \"price\": 8,\n    \"currency\": \"usd\",\n    \"date\": \"1998-07-16T19:20:30.45+01:00\",\n    \"item\": {\n      \"id\": \"id4\",\n      \"name\": \"Ark-Knight\",\n      \"type\": \"Movie\"\n    }\n  },\n  \"ex\": {\n    \"rts\": 1510043481723,\n    \"hl\": {\n       \"ml\": {\n        \"summary\": \"this is the summary\",\n        \"keywords\": [\"reviews\", \"paragraphs\", \"paragraph\"],\n        \"topics\":  {\"topic1\" : 0.5, \"topic1\" : 0.5},\n        \"entities\": [\"reviews\", \"paragraphs\", \"paragraph\"],\n        \"sentiment\": {\"neg\": 0.5 , \"neu\": 0.712 , \"pos\": 0.145 , \"compound\": 0.2344} ,\n        \"intent\": \"this is the intent\",\n        \"classification\": {\"neg\": 0.5, \"neu\": 0.32, \"pos\": 0.038, \"compound\": 0.18}\n       },\n       \"hl\": {\n       }\n    }\n  }\n}'\nlocalhost:9200/_sql?flat=true&format=csv&sql=SELECT+MAX%28pl.price%29+FROM+kent.transaction*+WHERE+hd.ts%3E%3D%272016-11-11T00%3A00%3A00%2B05%3A30%27+AND+hd.ts%3C%3D%272019-11-11T00%3A06%3A00%2B05%3A30%27++GROUP+BY+date_histogram%28field%3D%27hd.ts%27%2C%27interval%27%3D%27hour%27%29\nyou get the response \ndate_histogram(field=hd.ts,interval=hour),MAX(pl.price)\n2017-02-20 19:00:00,8.0\n2017-02-20 20:00:00,-Infinity\n2017-02-20 21:00:00,-Infinity\n2017-02-20 22:00:00,-Infinity\n2017-02-20 23:00:00,-Infinity\n2017-02-21 00:00:00,-Infinity\n2017-02-21 01:00:00,-Infinity\n2017-02-21 02:00:00,-Infinity\n2017-02-21 03:00:00,-Infinity\n2017-02-21 04:00:00,-Infinity\n2017-02-21 05:00:00,-Infinity\n2017-02-21 06:00:00,-Infinity\n2017-02-21 07:00:00,-Infinity\n.... if you give a avg then you get Nan. If not CSV it gives null in the json response from the plugin but csv is messed up. . @shi-yuan do you need anything else?. ",
    "denghc0607": "I have the same needs , use query context for  ordering by score  in some cases. ",
    "ChengJi": "when i execute \n\nselect longitude_latitude_name as name,count(*) as value from event_20161215 group by longitude_latitude_name order by value desc\n\nreturn columns \n\nlongitude_latitude_name,value\n\nbut not \n\nname,value\n\nwhat's going on?\nplease help me.Thanks.\n. @shi-yuan \nIt didn't work.\n\nselect longitude_latitude_name as name from event_20161215\n\nreturn \n\nlongitude_latitude_name\n\nbut not \n\nname\n\n. @shi-yuan \nI checked it.\nfields dose not contains \u2018name\u2019\n. \n@shi-yuan . @shi-yuan \n\nmy plugin is Version: 2.3.5.0. Seems to be independent of the version.\nDoes the plugin support column alias\uff1f\n@shi-yuan @fxsjy @guettli @perlun @allwefantasy . @eliranmoyal . \n@ansjsun . @shi-yuan OK,thanks.. I have checked the source code,it did not support param 'extended_bounds' when use date_histogram.\n. ",
    "ivancxj": "\u597d\u7684,\u8c22\u8c22,\u56e0\u4e3a\u6211\u770b\u5230\u8fd8\u8981\u5b89\u88c5node\u73af\u5883,\u6240\u4ee5\u6709\u6b64\u60f3\u6cd5- - . \u4e0d\u597d\u610f\u601d,\u6ca1\u4ed4\u7ec6\u770b\u4ee3\u7801,\u5982\u679c\u662f\u7eaf\u9759\u6001\u9875,\u90a3\u6211\u76f4\u63a5\u7528nginx\u6302\u8f7d\u4e0b\u5c31\u53ef\u4ee5\u4e86\n\u4e0d\u8fc7\u4f60\u4eec\u53ef\u4ee5\u5728\u6587\u6863\u4e0a\u8bf4\u660e\u4e0b\u53ef\u80fd\u66f4\u597d\u70b9,\u6211\u8fd8\u53bb\u5b89\u88c5\u4e86node\u73af\u5883- -. ",
    "abd-hasan85": "hello i have same issue, how can i resolve it ?. ",
    "yangsishu": "\u5d4c\u5957\u5b50\u67e5\u8be2\u73b0\u5728\u597d\u50cf\u4e0d\u652f\u6301. @shi-yuan . ",
    "treecy": "@shi-yuan Sorry, but could I ask how to use the results as an input?\nLike temporary table or something?. @shi-yuan Thanks a lot! If I want to do something like: \nsql\nselect sum(gms), A\nfrom (\n    select max(gms) as gms, A, B\n    from test\n    group by A, B\n)\ngroup by A\nIs there any way possible?. I resolved this one by Pipeline aggregations.   @shi-yuan Thank you all the same \ud83d\ude00\nHope you can implement this feature.\n. @shi-yuan Thank you so much! . ",
    "dick318": "@treecy \nselect sum(gms), A\nfrom (\n    select max(gms) as gms, A, B\n    from test\n    group by A, B\n)\ngroup by A\n\u4f60\u4e3e\u7684\u4f8b\u5b50\u4e2d\uff0c\u7528Pipeline aggregations\u600e\u4e48\u5199\u7684  \u80fd\u63d0\u4f9b\u4e0b\u5417. \u77e5\u9053\u89e3\u51b3\u529e\u6cd5\u4e86  \u5bfc\u5165\u6570\u636e\u4e4b\u540e es\u4f1a\u81ea\u52a8\u4ea7\u751f\u4e00\u4e2akeyword\u5b57\u6bb5\uff0c\u6bd4\u5982mac\u5b57\u6bb5\u4f1a\u4ea7\u751f\u4e00\u4e2amac.keyword,\u7528\u8fd9\u4e2a\u5b57\u6bb5\u67e5\u8be2\u5c31\u6ca1\u95ee\u9898\u4e86. ",
    "kevitra": "Any updates on this?  I haven't found a way to make an Elastic prefix query with this API.  Thanks. Thank you.  I had tried using 'like' but I didn't have enough slashes.  . ",
    "SubiRUN": "How about the following solutions?\nsolution 1\nes-sql project: \nAdd Access-Control-Allow-Origin response header in class org.elasticsearch.plugin.nlpcn.RestSqlAction\nes-sql-site project: \nConfig username, password, ip, port of ES in local storage\nAdd Authorization header and modify request url\nsolution 2\nes-sql project don't need to change\nes-sql-site project: \nAdd a config file including username, password, ip, port of ES\nUse backend code to send request to ES. \n. @shi-yuan then es-sql project don't have to change in solution 1. I have implemented solution 2 in java. @shi-yuan this issue still exist. es-sql-site-standalone in this repo is still not working because of authorization problems. My workaround solution may cause security issues if this site deployed on unprotected environment. . es-sql-site-standalone is still not working even if cors enabled on elasticsearch.yml. Standalone means to deploy on a different ip:port, so the \"Authorization\" request header needs to be passed to ES. The value of \"Authorization\" request header is \"Basic base64(username:password)\", so es-sql-site-standalone need to know username, password, ip, port of ES\n@shi-yuan . thx, fixed in 5d19ee3. to use site on es 5.x, \nenable cors and visit \"mydomain:8080?username=xxx&password=xxx&base_uri=encodedURI\" to config es settings. ",
    "BillGrim": "OK. Thank you!. ",
    "kaioken": "@jgshzy at the end did you get this working?\nthanks. ",
    "JafferWilson": "@eliranmoyal  I did restart the service. But still having the same failure output. kindly, let me know what is the problem. thank you in advance. When I clicked the explain button I got this as output:\n\n. @roul-rqf  I have created it. It is there in my ElasticSearch. I have 2 Indices in ElasticSearch. One is .kibana and the second one is bitcoin.. ",
    "roul-rqf": "you didn't create the index: bitcoin. ",
    "ireneqin": "when I have installed it,but the web did not work  .so it appeared above the question.. ",
    "1011641270": "use group by terms. @ansjsun   \u5982\u679c\u6211\u6709\u4e24\u4e2agroup by \u5982\u4f55\u9650\u5b9a\u5927\u5c0f\u5462\u3002 \nselect count(*) as count from commenta/commenta where  eventTime>= '2015-09-05' and  eventTime<= '2017-05-05' group by date_histogram(field='eventTime','alias'='date','interval'='month'),page limit 0\n\u770b\u4e86\u4e0bDSL\uff0c\u8fd9\u79cdlimit\u597d\u50cf\u4e0d\u6210\u529f\u3002 size\u8fd8\u662f10\n\"aggregations\" : {\n    \"date\" : {\n      \"date_histogram\" : {\n        \"field\" : \"eventTime\",\n        \"format\" : \"yyyy-MM-dd HH:mm:ss\",\n        \"interval\" : \"month\",\n        \"offset\" : 0,\n        \"order\" : {\n          \"_key\" : \"asc\"\n        },\n        \"keyed\" : false,\n        \"min_doc_count\" : 0\n      },\n      \"aggregations\" : {\n        \"page\" : {\n          \"terms\" : {\n            \"field\" : \"page\",\n            \"size\" : 10,\n            \"shard_size\" : -1,\n            \"min_doc_count\" : 1,\n            \"shard_min_doc_count\" : 0,\n            \"show_term_doc_count_error\" : false,\n            \"order\" : [\n              {\n                \"_count\" : \"desc\"\n              },\n              {\n                \"_term\" : \"asc\"\n              }\n            ]\n          },\n          \"aggregations\" : {\n            \"count\" : {\n              \"value_count\" : {\n                \"field\" : \"_index\"\n              }\n            }\n          }\n        }\n      }\n    }\n  }. \u989d\uff0c\u770b\u4e86\u4e0b\u6e90\u7801\u3002 \u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u5c31\u53ef\u4ee5\u4e86\nselect * from commenta/commenta group by terms(field='eventTime',size='1000',alias='terms'), date_histogram(field='eventTime','alias'='date','interval'='day'). ",
    "alexartwww": "I mean to remove this \"type\": \"phrase\". ",
    "suncz": "I also have this question,can you tell me how do you solve it. ",
    "ricardoj-br": "Hi suncz I'm still looking for a solution. Since the version 5.X I can not use /sql queries from my browser. I did manage to install \"site-server\" but it's not the same.. In a Meetup event here in Brazil people from Elastic told they are working on a SQL query engine but they can not disclosure if or when it will be available !. Is jdk 1.8 means Oracle jdk ? Mine is 1.8 but openjdk. Thanks.. Hi there ! Answering my own question : YES it must be Oracle jdk. Now it's working. Thank you all !. ",
    "chuanconggao": "Really hope to see the support for 5.2.0 soon. \ud83d\udc4d . ",
    "billmartschenko": "What happens if we install the plugin on a 5.2.x deployment of ES?  Will it fail to install?  Will it install and always fail?  Will it install and work generally but isn't fully tested/supported yet?. ",
    "jaminlai": "when I run the elasticsearch-site and call http://localhost:8080/web/sql/, buy it always return the result below not matter what I enter anying:\n{\n    \"from\": 0,\n    \"size\": 200\n}. @ansjsun I have install es at the same machine, and I have config the es ip port at 'elasticsearch-site/jcoder_home/resource/ioc.js'\nHowever in secury I have settting the authentication for access es. So if visit es by java client, I must settting the 'xpack.security.user ' key value when new PreBuiltXPackTransportClient(ESClient.SETTINGS)\nBut, I don't know  how to config the  'xpack.security.user ' in elasticsearch-site\n. @ansjsun Thank you so much, pls response me when finished. @ansjsun Could I run 'git clone https://github.com/NLPchina/elasticsearch-site' directly and effective?. @ansjsun \nI have checkout the new code and  install the plugin on the step again, but it occour the exception when searched as below:\norg.elasticsearch.plugins.PluginsService-44517 INFO  [2017-02-17 10:06:59]  loaded plugin [org.elasticsearch.script.mustache.MustachePlugin]\norg.elasticsearch.plugins.PluginsService-44517 INFO  [2017-02-17 10:06:59]  loaded plugin [org.elasticsearch.transport.Netty3Plugin]\norg.elasticsearch.plugins.PluginsService-44517 INFO  [2017-02-17 10:06:59]  loaded plugin [org.elasticsearch.transport.Netty4Plugin]\n2017-02-17 10:06:59.444:WARN:oejs.ServletHandler:qtp1927950199-88: /api/SqlApi/execute\norg.nutz.ioc.IocException: [esClient] # FAIL to create Ioc Bean name=[esClient]\n        at org.nutz.ioc.impl.ObjectMakerImpl.make(ObjectMakerImpl.java:149)\n        at org.nutz.ioc.impl.NutIoc.get(NutIoc.java:210)\n        at org.nutz.ioc.impl.NutIoc.get(NutIoc.java:239)\n        at org.nlpcn.jcoder.run.java.JavaRunner._instance(JavaRunner.java:186)\n        at org.nlpcn.jcoder.run.java.JavaRunner.instance(JavaRunner.java:155)\n        at org.nlpcn.jcoder.run.mvc.ApiUrlMappingImpl.createInvoker(ApiUrlMappingImpl.java:162)\n        at org.nlpcn.jcoder.run.mvc.ApiUrlMappingImpl.getOrCreate(ApiUrlMappingImpl.java:142)\n        at org.nlpcn.jcoder.run.mvc.ApiUrlMappingImpl.getOrCreate(ApiUrlMappingImpl.java:108)\n        at org.nlpcn.jcoder.run.mvc.ApiActionHandler.handle(ApiActionHandler.java:33)\n        at org.nlpcn.jcoder.filter.JcoderFilter._doFilter(JcoderFilter.java:80)\n        at org.nlpcn.jcoder.filter.JcoderFilter.doFilter(JcoderFilter.java:44)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1650)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:52)\n        at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:97)\n        at org.eclipse.jetty.server.Server.handle(Server.java:485)\n        at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:290)\n        at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:248)\n        at org.eclipse.jetty.io.AbstractConnection$2.run(AbstractConnection.java:540)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:606)\n        at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:535)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: \norg.nutz.lang.born.BorningException: Fail to born 'org.nlpcn.elasticsearch.site.ESClient'| by args: [|  @(true)|  @(elastic:changeme)|  @([Ljava.lang.String;@675f9b57)] becasue:|java.lang.IllegalArgumentException: unknown setting [xpack.security.user] please check that any required plugins are installed, or check the breaking changes documentation for removed settings\n        at org.nutz.lang.born.ConstructorCastingBorning.born(ConstructorCastingBorning.java:24)\n        at org.nutz.ioc.weaver.DefaultWeaver.born(DefaultWeaver.java:67)\n        at org.nutz.ioc.impl.ObjectMakerImpl.make(ObjectMakerImpl.java:114)\n        at org.nutz.ioc.impl.NutIoc.get(NutIoc.java:210)\n        at org.nutz.ioc.impl.NutIoc.get(NutIoc.java:239)\n        at org.nlpcn.jcoder.run.java.JavaRunner._instance(JavaRunner.java:186)\n        at org.nlpcn.jcoder.run.java.JavaRunner.instance(JavaRunner.java:155)\n        at org.nlpcn.jcoder.run.mvc.ApiUrlMappingImpl.createInvoker(ApiUrlMappingImpl.java:162)\n        at org.nlpcn.jcoder.run.mvc.ApiUrlMappingImpl.getOrCreate(ApiUrlMappingImpl.java:142)\n        at org.nlpcn.jcoder.run.mvc.ApiUrlMappingImpl.getOrCreate(ApiUrlMappingImpl.java:108)\n        at org.nlpcn.jcoder.run.mvc.ApiActionHandler.handle(ApiActionHandler.java:33)\n        at org.nlpcn.jcoder.filter.JcoderFilter._doFilter(JcoderFilter.java:80)\n        at org.nlpcn.jcoder.filter.JcoderFilter.doFilter(JcoderFilter.java:44)\n        at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1650)\n        at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:583)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\n        at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:577)\n        at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:223)\n        at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1125)\n        at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:515)\n        at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)\n        at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1059)\n        at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n        at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:52). ",
    "bsc2xp": "@jaminlai \u5982\u679c\u4f60\u6267\u884c\u7684\u662f\u4e0d\u5e26\u6761\u4ef6\u7684sql\uff0c\u90a3\u5f97\u5230\u7684\u8fd4\u56de\u7ed3\u679c\u91cc\u597d\u50cf\u5c31\u662f\u53ea\u6709 from \u548c size. ",
    "ly853602": "@ansjsun i have configured as your suggest   ,but not work,  and  what does mean \"open http://localhost:8080/ username:admin password:admin\", thanks in advance. another question confused me,how can i add username and password when i visit web/sql in brower. \n\nthanks a lot\n. @chenyg0911 this is my web and configure conditions. \u6539\u540e\u53f0\u914d\u7f6e\u540e\uff0c\u5176\u5b83\u7684\u6b63\u5e38\u8bbf\u95ee\u5c31\u884c\u4e86\uff0c\u662f\u5417. \n\n. ",
    "hooqee": "http://localhost:8080/api/SqlApi/execute?sql=SELECT * FROM myindex where id > 100.0. ",
    "LiveAlone": "so , i have to convert double to Int, . ",
    "EliZheng": "@zhaochl  Any solutions to disable default limit 200 setting ? Thanks.. @changgong  \u4f60\u597d\uff0c\u8bf7\u95ee\u652f\u6301\u5417\uff1f. Any helpful answer? please.. \u8bf7\u95ee\u4e0b\u8fd9\u4e2a\u8bbe\u7f6e\u5728\u54ea\u91cc\u66f4\u6539\u5462\u5927\u795e. \u627e\u5230\u4e86\uff0c\u5728 JoinSelect.java \u91cc\u9762\u3002\u3002\nprivate final int DEAFULT_NUM_OF_RESULTS = 200;\nFYI, default \u4f60\u4eec\u5199\u9519\u4e86\u3002\u3002\n. Sorry guys, didn't figure out the solution, I choose not to use es-sql anymore =_=. ",
    "hangum": "@shiyuan417289076  Did you solve the problem?. ",
    "z56381866": "@hangum \u56e0\u4e3atransportclient\u5982\u679c\u4e0d\u8bbe\u7f6e\u96c6\u7fa4\u540d\uff0c\u9ed8\u8ba4\u662felasticsearch\uff0c\u6240\u4ee5\u8fd9\u91cc\u8981\u4e48\u5728\u5ba2\u6237\u7aef\u8bbe\u7f6e\u96c6\u7fa4\u540d\u5b57\uff0c\u8981\u4e48\u5728\u670d\u52a1\u7aef\u4e5f\u5c31\u662fconfig/elasticsearch.yml\u6587\u4ef6\u4e2d\u4fee\u6539\u96c6\u7fa4\u540d\u4e3acluster.name: elasticsearch. ",
    "TarryHoo": "@eliranmoyal \ncan you help me?. @eliranmoyal @ansjsun What do you think of?. ",
    "olleolleolle": "(The branch name was about me trying to drop the hint that it's possible to do:\nshell\nwget the.zip\nunzip the.zip\ncd es-sql-site/_site\npython -mSimpleHTTPServer 8080\nThat starts a Web server:\nServing HTTP on 0.0.0.0 port 8080 ...\nI am running ES 2.x on my machine, and my Web browser complained about CORS details.\nThis takes some fiddling to get right. )\nIn the end, I only changed docs text.\n. ",
    "changgong": "@EliZheng \u4e4b\u524d\u5728\u7528\u7684\u65f6\u5019\u7814\u7a76\u4e86\u4e0b\uff0c\u8fd9\u63d2\u4ef6\u4e0d\u652f\u6301\uff0c\u60f3\u4e86\u60f3\uff0c\u4e5f\u662f\u7406\u6240\u5f53\u7136\uff0c\u672c\u8eab\u5c31\u662fnosql\uff0c\u5982\u679c\u8981\u5728\u5f3a\u5927\u7684\u652f\u6301\u5173\u7cfb\u578b\u7684\uff0c\u90a3\u4e0d\u5c31\u9006\u5929\u4e86\u4e48\uff0c\u4f5c\u4e3a\u4e00\u4e2a\u5c0f\u767d\u5c31\u662f\u8fd9\u4e48\u7406\u89e3\u7684\u3002. ",
    "zhangzhenhua92": "\u4ec5\u505ajoin\uff0c\u4e0d\u505a\u805a\u5408\uff0c\u8bf7\u95ee\u652f\u6301\u5417\uff1f. \u60a8\u597d\uff0c\u8bf7\u95ee\u5173\u8054\u67e5\u8be2\uff0c\u8fd9\u4e2a\u63d2\u4ef6\u4e0d\u652f\u6301\u5417\uff1f. \u8bf7\u95ee\uff0c\u8be5\u63d2\u4ef6\u662f\u5426\u652f\u6301\u5173\u8054\u67e5\u8be2\uff1f. ",
    "haomer": "Has solved the problem, use POST request, please see #174 . ",
    "MR-JDY": "@ansjsun \u4f60\u597d   \u8fd9\u4e2asql  \u662f\u76f8\u5f53\u4e8e\u5728\u7528\u666e\u901a\u67e5\u8be2\u8bed\u53e5\u7684\u65f6\u5019\u5c31\u5df2\u7ecf\u81ea\u52a8\u8fdb\u884c\u4e86es\u64cd\u4f5c\u5417\uff1f  \u6211\u5f88\u60f3\u77e5\u9053\u5728\u6709\u6570\u636e\u5e93   es   java\u5e94\u7528\u7a0b\u5e8f\u7684\u4e09\u8005\u540c\u65f6\u5b58\u5728\u7684\u65f6\u5019\u7684\u5de5\u4f5c\u539f\u7406  \u671b\u4e0d\u541d\u8d50\u6559  qq 756528875. @ansjsun \u800c\u4e14\u6211\u7684\u662fwindows. ",
    "longshang": "\u4e0d\u597d\u610f\u601d\uff0c\u6211\u77e5\u9053\u95ee\u9898\u4e86\u3002\u662f\u6211\u6ca1\u6709\u6539IP\u5730\u5740. ",
    "zhan-yl": "\u8bf7\u95ee\u60a8\u662f\u600e\u4e48\u89e3\u51b3\u7684\uff1f\u6211\u4e5f\u78b0\u5230\u8fd9\u4e2a\u95ee\u9898\u4e86\n Error: \"<!DOCTYPE html>\\n\\n\\n\\nError\\n\\n\\n \\n\\n\\n\". ",
    "winfys": "\u628aweb\u754c\u9762\u53f3\u4e0a\u89d2\u7684url\u6539\u6210es\u7684\u5730\u5740. ",
    "jmellicker": "Thanks! \ud83e\udd47 . ",
    "pbgxh04007": "in order to use site on elasticsearch 5.x download and extract site[https://github.com/NLPchina/elasticsearch-sql/releases/download/5.0.1/es-sql-site-standalone.zip]\ncd site-server\nnpm install express --save\nnode node-server.js . ",
    "furiousbanana": "there is a limit to limit as well. it seems i cannot go beyond limit 10000. Is there a way to increase the limit beyond 10000?. Never mind. found it. Its <>. ",
    "tade0726": "Try to write your sql with limit, like \nselect * from bank limit 1000\nWith no limit specify, it will return 200 ressults by default.\nThe default limit is mentioned in wiki page:\nhttps://github.com/NLPchina/elasticsearch-sql/wiki/Basic-Queries-And-Conditions\n. ",
    "fanyoujian": "this my mapping \n\n. this issue is ok , think you . ",
    "zivszheng": "select * from logs where logId <> logId2 (logId2 \u5047\u5b9a\u662flogs\u8868\u7684\u53e6\u4e00\u4e2a\u5b57\u6bb5)  \u600e\u4e48\u652f\u6301\u5462\uff1f. \u6211\u73b0\u5728\u6709\u5982\u4e0bSQL\uff1a\nselect * from trip where status.keyword = term('SUCCESS') and startSite <> endSite\uff1b(startSite, endSite \u662ftrip\u8868\u7684\u4e24\u4e2a\u5b57\u6bb5\uff09\u600e\u4e48\u5b9e\u73b0\uff1f\u53ef\u4e5f\u7ed9\u4e2a\u5b9e\u4f8b\u4e48\uff0c\u8c22\u8c22 \uff01. Tks ...... . ",
    "xbkaishui": "\u4e3b\u8981\u6539\u52a8\u5728 552\uff0d558 \u5176\u4ed6\u90fd\u662fformat \u7684\u683c\u5f0f\u95ee\u9898 . ResultSetMetaData metaData = resultSet.getMetaData();\n            int columnCnt = metaData.getColumnCount();\n            for (int i = 0; i < columnCnt; i++) {\n                columnNames.add(metaData.getColumnName(i + 1));\n            }\n. ",
    "xiejin90314": "SearchDao searchDao =new SearchDao(client);\nSqlElasticSearchRequestBuilder select = (SqlElasticSearchRequestBuilder) searchDao.explain(query).explain();\nSearchRequestBuilder searchRequestBuilder = (SearchRequestBuilder) select.getBuilder();\nsearchRequestBuilder.setRouting(queryId);\nreturn ((SearchResponse)select.get());\n\u627e\u5230\u4e86 ths. ",
    "Imred": "sorry , I  made a mistake, it is available..thank you .. I found one question: if using es api _search?ignore_unavailable=true when all indices are not available,  I will not get a mistake and just get no data. but when using /! IGNORE_UNAVAILABLE / , I will get IndexMissingException. I want to know the hint is designed like this ?. ",
    "Lunatictwo": "thanks. ",
    "heyibo8888": "\n. \u53ef\u4ee5\u4e0d\u5b89\u88c5\uff0c\u6211\u89c9\u5f97\u53ea\u8981\u5ba2\u6237\u7aef\u5305\u542belasticsearch sql \u5c31\u53ef\u4ee5\u4e86. ",
    "xiaoxuan220": "You can try,like this    http://sql-server:8080/?username=test_user&password=test_password&base_uri=http://es_server:9200. ",
    "dlhzt": "@shi-yuan  thanks, But create error info :\n Error: {\"error\":{\"root_cause\":[{\"type\":\"script_exception\",\"reason\":\"scripts of type [inline], operation [search] and lang [groovy] are disabled\"}],\"type\":\"search_phase_execution_exception\",\"reason\":\"all shards failed\",\"phase\":\"dfs\",\"grouped\":true,\"failed_shards\":[{\"shard\":0,\"index\":\"log_20170613\",\"node\":\"7bSWK084ROiPak49a3UBqA\",\"reason\":{\"type\":\"script_exception\",\"reason\":\"scripts of type [inline], operation [search] and lang [groovy] are disabled\"}}]},\"status\":500}. Thank you very much !!! @shi-yuan . \u591a\u8c22\uff01. 1\u3001\u591a\u8c22\uff0c\u53ef\u80fd\u573a\u666f\u6ca1\u6709\u63cf\u8ff0\u6e05\u695a\u3002\u6211\u73b0\u5728\u7528try \u6765\u6293\u53d6\u5f02\u5e38\u4e2d\u65ad\uff0c\u4fdd\u8bc1\u7a0b\u5e8f\u6b63\u5e38\u6d41\u8f6c\u4e0b\u53bb\u3002\n2\u3001\u522b\u540d\u7684\u95ee\u9898\u662f\u6211\u7248\u672c\u7684\u95ee\u9898\u5417\uff1f @shi-yuan . \u591a\u8c22\uff0c\u6211\u5c1d\u8bd5\u4e00\u4e0b\u66f4\u65b0\u7248\u672c\u52305.4\u518d\u8bd5\u8bd5\u3002. ",
    "zhaobinnian": "\u540c\u95ee\uff0ces\u5b58\u50a8\u91cc\u6709json\u6570\u7ec4\uff0c\u600e\u4e48\u7528sql\u67e5\u8be2\uff0c\u73b0\u5728 \u90fd\u62a5\u9519. Server error [Server encountered an error [Arrays (returned by [interests.music.keyword]) are not supported]. [SqlIllegalArgumentException[Arrays (returned by [interests.music.keyword]) are not supported]\n. nested   \u4f60\u53ef\u4ee5\u6b63\u5e38\u67e5\u8be2\u51fa\u6765\uff1f. ",
    "ly95": "Same issue.\nes 5.4.1\nhtml\n\"<!DOCTYPE html>\\n<html lang=\\\"en\\\">\\n<head>\\n<meta charset=\\\"utf-8\\\">\\n<title>Error</title>\\n</head>\\n<body>\\n<pre>Cannot POST /_sql/_explain</pre>\\n</body>\\n</html>\\n\". No affect result after enabled CORS.. ",
    "chenzuoli": "\n\u5df2\u7ecf\u6539\u8fc7\u53f3\u4e0a\u89d2\u7684es\u5730\u5740\u7aef\u53e3\uff0c\u4f46\u662fsearch\u65f6\u51fa\u73b0Error occured! response is not avalible.\n\u8bf7\u95ee\u600e\u4e48\u529e\u5462\uff1f. ",
    "sdshw": "\u6211\u4e5f\u51fa\u73b0\u4e86Error occured! response is not avalible.\u7684\u95ee\u9898\nhttp://192.168.26.10:9200/_sql?sql=select * from test_index_exjc\u662f\u53ef\u4ee5\u8bbf\u95ee\u7684\n\n. > \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff1f\u6d4f\u89c8\u5668\u7684\u8bf7\u6c42\u80fd\u770b\u770b\u5417\uff0c\u540e\u53f0\u65e5\u5fd7\uff0c\u6709\u5417\uff1f\n\u6253\u5f00elasticsearch\u7684CORS, \u95ee\u9898\u89e3\u51b3. ",
    "kane-xie": "any progress?. ",
    "niejunhao": "\nselect COUNT(1),a,c from xxx where e>0 group by a having c='xxx';\n\u7c7b\u4f3c\u8fd9\u79cd\u67e5\u8be2\u5982\u4f55\u5b9e\u73b0\u5462? having\u8fc7\u6ee4\u7684\u6570\u636e\u5e76\u4e0d\u5728group by\u91cc\u9762\u3002. \n",
    "ghostcry": "\u6211\u5012\u662f\u5e0c\u671b\u80fd\u591f\u589e\u52a0\u70b9\u513f\u7b80\u5355\u7684\u529f\u80fd\uff0c\u6bd4\u5982show tables/indexes \u5feb\u901f\u663e\u793a\u5df2\u6709\u7684\u7d22\u5f15\uff0cdesc xxx\u5c55\u793a\u67d0\u4e2a\u7d22\u5f15\u7684schema. ",
    "lzwfly": "thank you @shi-yuan  The problem has been solved~. ",
    "maskwang": "thanks , it works for me!  O(\u2229_\u2229)O~. ",
    "DimonHo": "\u80fd\u8bf4\u7684\u5728\u8be6\u7ec6\u4e00\u70b9\u5417\uff1f \u7528script\u600e\u4e48\u4e2a\u5199\u6cd5\uff1f\n{\n  \"script\": \"ctx._source.keywords == ctx._source.keywordsCX\"\n}\n\u8fd9\u6837\u5199\u8c8c\u4f3c\u662f\u4e0d\u884c\u7684\u3002\u8fd8\u8bf7\u6307\u6559\u3002\u3002\u3002. ",
    "jiaquanyu": "@heyibo8888 \u662f\u7684 \u4e4b\u524d\u662fcurl http://hostname:port/_sql?sql= \u8fd9\u4e2a\u8bed\u53e5\u89e3\u6790\u7684\u95ee\u9898  \u67091\u4e2a\u8282\u70b9\u5b89\u88c5\u5c31\u53ef\u4ee5\u4e86. ",
    "goodqinjin": "@chenyg0911 \ncd site-server\nnpm install express --save\nnode node-server.js \n\u6211\u77e5\u9053\u5b89\u88c5\u6b65\u9aa4\uff0c\u4f46\u662f\u80fd\u5426\u624b\u52a8\u53bb\u5b89\u88c5\u4e0d\u8981\u8fd0\u884cnpm&node\u547d\u4ee4\uff1f. @chenyg0911 \u6211\u6ca1\u6709\u8fd9\u6837\u7684\u73af\u5883\u53bb\u5b89\u88c5\uff0c\u4f60\u80fd\u5e2e\u5fd9\u5b89\u88c5\u4e0b\u5417\uff1f\u8c22\u8c22. @shi-yuan \u662felasticsearch.yml\u4e2d\u6ca1\u6709\u914d\u7f6e\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\". \u6211\u8bd5\u8fc7\u8fd9\u4e2a\u65b9\u6cd5\uff0c \u4f46\u662f\u6709\u4e2a\u8bed\u6cd5\u62a5\u9519\uff1aselect script('field', 'painless', 'doc[\\'a\\'].value') from index\n\u6307\u5b9apainless \u6216\u8005 groovy\u5c31\u4f1a\u62a5\u9519 @shi-yuan . \u6211\u770b\u4e86\u4e0b5.4.3\u5206\u652f\u4e0b\u7684\u4ee3\u7801\uff0c \u5728DefaultQueryAction.java\u4e0b\u6709\u4e2ahandleScriptField\u65b9\u6cd5\uff0c \u6709\u4e2a\u5224\u65ad\nelse if(params.size() == 3) {\n   request.addScriptField(......, params:null)\n}\n\u8fd9\u91ccparams\u4e0d\u80fd\u4e3anull\uff0c \u9700\u8981\u6539\u6210Collections.emptyMap() \n@shi-yuan . ",
    "littleWT": "\u975e\u5e38\u611f\u8c22. ",
    "xuziw": "@shi-yuan \u60a8\u597d\nelasticsearch-sql-x.x.x.x.jar\u4ee5\u53cadruid\u7684r\u5305\u5728\u54ea\u91cc\u4e0b\u8f7d\u4e86. @shi-yuan \n\u5982\u679climit\u8d85\u8fc710000\uff0c\u8fd9\u79cd\u65b9\u5f0f\u5c31\u4e0d\u884c\u4e86\u3002. \u6211\u77e5\u9053\uff0ces\u672c\u8eab\u5bf9\u8d85\u8fc710000\u4ee5\u4e0a\u5bf9\u5206\u9875\u4e0d\u652f\u6301\uff0c\u9700\u8981\u4f7f\u7528scroll\uff0c\u6211\u5bf9\u610f\u601d\u662felasticsearch-sql\u91cc\u9762\u6709\u652f\u6301scroll\u5417\uff1f. ",
    "wuchaooooo": "@shi-yuan \u4f60\u597d\uff0c\u6211\u770bmaven\u4ed3\u5e93\u4e2d\uff0c\u53ea\u67095.1.2.0\u7248\u672c\u3002\u6211\u5728\u7528\u7684es\u662f5.4\u7248\u672c\uff0c\u8bf7\u95ee\u600e\u4e48\u5c06\u5176\u5f15\u5165\u6211\u7684java\u5de5\u7a0b\uff1f. @ws2823147532 maven \u7f16\u8bd1\u7684\u65f6\u5019\uff0c\u9700\u8981\u6211\u8f93\u5165\u8fd9\u4e2a\uff1aGPG Passphrase: *\uff0c\u7136\u540e\u70b9\u56de\u8f66\uff0c\u5c31\u62a5\u9519\u4e86\u3002\n*gpg: WARNING: \"--no-use-agent\" is an obsolete option - it has no effect\ngpg: directory '/Users/wuchaooooo/.gnupg' created\ngpg: keybox '/Users/wuchaooooo/.gnupg/pubring.kbx' created\ngpg: no default secret key: No secret key\ngpg: signing failed: No secret key\n. @ws2823147532 \u597d\u7684\uff0c\u8c22\u8c22\uff01\uff01. ",
    "langke93": "\u6211es\u7248\u672c5.1.2\uff0c\u628areindex-client-5.1.2.jar\u653e\u5230elasticsearch/plugins/sql\u76ee\u5f55\u4e0b\uff0c\u91cd\u542f\u540e\u6267\u884c\ndelete play_following wehre id='436_topic_43'\n\u63d0\u793a\u9519\u8bef\uff1a\njava.lang.UnsupportedOperationException: currently not support delete on elastic 2.x\n\u6211\u770b\u91cc\u9762\u4ee3\u7801\u4e5f\u662f\u8fd9\u4e48\u5199\u7684\nhttps://github.com/NLPchina/elasticsearch-sql/blob/elastic5.1.2/src/main/java/org/elasticsearch/plugin/nlpcn/executors/ElasticDefaultRestExecutor.java\n\u597d\u50cf\u6700\u65b06.0\u7248\u672c\u4e5f\u6ca1\u6709\u5b9e\u73b0\u8fd9\u4e2a\u65b9\u6cd5\u5462. ",
    "hongxingwz": "Thanks! Our team have solved that problem by following your advise. ",
    "rajivchodisetti": "Am also facing the same issue, am using 5.5.1 version. ",
    "HuJake": "Hi I'm also have this problem,Using Elasticsearch Port 9200 and SHOW \" Error: Error occured! response is not avalible.\"\nSorry Where is Config?\nadd down this commend?\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\". Many Thanks.\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: \"X-Requested-With, Content-Type, Content-Length,\nAuthorization\"\nThis http.cors.enabled: true  adding where PATH or file?. Hi Chenyg0911, Many thanks a lot.\nModify elasticsearch.yaml and add can using query search.\nNice!. ",
    "skvsree": "Had to change extension from elasticsearch.yml to elasticsearch.yaml, not sure if the issue is due to this.  Can close the issue. ",
    "xinqiyang": "Hi, \ncreateTime type is date: \nwhere createTime>= '2016-05-01T00:00+08:00' and createTime < '2016-05-10T00:00+08:00'\nwhere date_format(createTime,'yyyy-MM-dd')  >= '2016-05-11' and date_format(createTime,'yyyy-MM-dd') < '2016-05-12'\nwhere createTime>= '2016-05-01T00:00+08:00' and createTime < '2016-05-10T00:00+08:00'\nwhere createTime>= '2016-05-01' and createTime < '2016-05-10'\nthere are all not worked, please help me.\n. \n@shi-yuan  \u592a\u611f\u8c22\u4e86\uff0c \u628a\u65f6\u95f4\u683c\u5f0f\u4fee\u6539\u4e86\u4e4b\u540e\uff0c\u5e26\u4e0a\u65f6\u533a\u4e86\u4e4b\u540e\uff0c\u5c31\u53ef\u4ee5\u4e86\u3002 \nwhere createTime>= \"2017-09-01T00:00:00+00:00\" and createTime < \"2017-09-02T00:00:00+00:00\"\n. ",
    "blakdronzer": "Hi,\nMy experience with date is, you set the formats that the date column will\nbe set the data with. And post that, it should be easy for you to deal with\ndate_format in the query...\nOn 23-Oct-2017 3:01 PM, \"xinqiyang\" notifications@github.com wrote:\nHi,\ncreateTime type is date:\nwhere createTime>= '2016-05-01T00:00+08:00' and createTime <\n'2016-05-10T00:00+08:00'\nwhere date_format(createTime,'yyyy-MM-dd') >= '2016-05-11' and\ndate_format(createTime,'yyyy-MM-dd') < '2016-05-12'\nwhere createTime>= '2016-05-01T00:00+08:00' and createTime <\n'2016-05-10T00:00+08:00'\nwhere createTime>= '2016-05-01' and createTime < '2016-05-10'\nthere are all not worked, please help me.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/497#issuecomment-338601825,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB8hmgki4VUHp78LAfdO_oHU3j8cdcLJks5svFzdgaJpZM4O-Dig\n.\n. Unfortunately have not yet got a solution. We had a other way around with\nsome to handle the data relation programatically with more then 1 query. I\ndon't remember much around the final solution .. but that was the way ahead\nwe went on.!\nOn Wed, Jun 6, 2018 at 11:05 PM, ducbot88 notifications@github.com wrote:\n\nHi,\nI got the same isssue. How can we solve this ?\nHope to hear from you soon.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/NLPchina/elasticsearch-sql/issues/511#issuecomment-395151975,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB8hmuMnwkW71CEzh5a8CGHT3kwxQNiUks5t6BLrgaJpZM4PfV_E\n.\n. \n",
    "jnuc093": "https://github.com/NLPchina/elasticsearch-sql/releases/download/5.4.0.0/es-sql-site-standalone.zip\n\u8fd9\u4e2a\u94fe\u63a5\u6211\u4e0b\u8f7d\u4e0d\u4e0b\u6765. \u597d\u7684\u8c22\u8c22\u3002. ",
    "schwicke": "Hi,\nindeed, this works. Thanks a lot!\n. ",
    "leeningli": "\u7b2c\u4e00\u4e2a\u62a5\u9519\u662f\u56e0\u4e3a\u6ca1\u8bbe\u7f6eJAVA\u73af\u5883\u53d8\u91cf\uff0c\u8bbe\u7f6e\u4e4b\u540e\u53c8\u62a5\u8fd9\u4e2a\u9519\uff1a\n[wls81@cnsz141803 plugins]$ ../bin/elasticsearch-plugin install file:/wls/wls81/ELASTICSEARCH5/elasticsearch-5.5.2/plugins/elasticsearch-sql-5.5.2.0.zip \n-> Downloading file:/wls/wls81/ELASTICSEARCH5/elasticsearch-5.5.2/plugins/elasticsearch-sql-5.5.2.0.zip\n[=================================================] 100%\u00a0\u00a0 \nException in thread \"main\" java.lang.IllegalStateException: Could not load plugin descriptor for existing plugin [elasticsearch-sql-5.5.2.0.zip]. Was the plugin built before 2.0?\n        at org.elasticsearch.plugins.PluginsService.getPluginBundles(PluginsService.java:334)\n        at org.elasticsearch.plugins.InstallPluginCommand.jarHellCheck(InstallPluginCommand.java:518)\n        at org.elasticsearch.plugins.InstallPluginCommand.verify(InstallPluginCommand.java:500)\n        at org.elasticsearch.plugins.InstallPluginCommand.install(InstallPluginCommand.java:543)\n        at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:217)\n        at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:201)\n        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:67)\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122)\n        at org.elasticsearch.cli.MultiCommand.execute(MultiCommand.java:69)\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:122)\n        at org.elasticsearch.cli.Command.main(Command.java:88)\n        at org.elasticsearch.plugins.PluginCli.main(PluginCli.java:47)\nCaused by: java.nio.file.FileSystemException: /wls/wls81/ELASTICSEARCH5/elasticsearch-5.5.2/plugins/elasticsearch-sql-5.5.2.0.zip/plugin-descriptor.properties: Not a directory\n        at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)\n        at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)\n        at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)\n        at java.nio.file.Files.newByteChannel(Files.java:361)\n        at java.nio.file.Files.newByteChannel(Files.java:407)\n        at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)\n        at java.nio.file.Files.newInputStream(Files.java:152)\n        at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:114)\n        at org.elasticsearch.plugins.PluginsService.getPluginBundles(PluginsService.java:331)\n        ... 11 more. \u95ee\u9898\u89e3\u51b3\u4e86\u3002\u3002\u3002\u89e3\u51b3\u65b9\u6cd5\u4e5f\u662f\u9189\u4e86. I have check this issue.. ",
    "ducbot88": "Hi,\nI got the same isssue. How can we solve this ?\nHope to hear from you soon.. ",
    "yangjiajun2014": "ES 5.6.2 still has this bug?\n{\n  \"error\": {\n    \"root_cause\": [\n      {\n        \"type\": \"illegal_argument_exception\",\n        \"reason\": \"request [/_sql] contains unrecognized parameter: [separator]\"\n      }\n    ],\n    \"type\": \"illegal_argument_exception\",\n    \"reason\": \"request [/_sql] contains unrecognized parameter: [separator]\"\n  },\n  \"status\": 400\n}. But I can not find this version on the download site.. url\u7f16\u7801\u7684\u95ee\u9898. It doesn't support round(avg(myfield)),right?. But it does not work.I use 5.6.2  version.\n{\n    \"from\": 0,\n    \"size\": 200,\n    \"_source\": {\n        \"includes\": [],\n        \"excludes\": []\n    },\n    \"script_fields\": {\n        \"timemills\": {\n            \"script\": {\n                \"source\": \"doc['timestamp'].value.getMillis()\",\n                \"lang\": \"painless\"\n            },\n            \"ignore_failure\": false\n        }\n    }\n}. Thanks.. The value in PERCENTILES function does not work when I use format=csv in my request.It still return the default percentiles.Is it a bug?. ",
    "csharpworker": "Hi, is it possible to add the parameter \"partition\" to the terms function?. Hi, when do you release this version? Thanks. ",
    "milome": "Hi Shi-yuan,\nMany thanks for your quick fix.\nI tried to run it in the demo website:\nhttp://www.nlpcn.org:9999/web/\nwith the sql:\nselect insert_time from online group by date_histogram(field='insert_time','interval'='1.5h','format'='yyyy-MM','min_doc_count'=5,'order'='desc')\nBut still, there is following error:\n Error:{\"message\":\"date range err or not define field min_doc_count=5\",\"ok\":false}\nSeems you just fixed the branch 5.1.2.1, while this demo website use a different version?\nThanks a lot.. ",
    "vichWei": "@shi-yuan \u8bf7\u5e2e\u5fd9\u770b\u770b\u6267\u884c\u51fa\u9519\nsql\u8bed\u53e5\uff1a\nselect aiops_endpoint.keyword as aiops_endpoint,count() as count from aiops_log where aiops_timestamp >= '2019-01-10T09:25:00.000Z' and aiops_timestamp < '2019-01-13T09:30:00.000Z' group by date_histogram(field='aiops_timestamp','interval'='1d','alias'='aiops_timestamp','min_doc_count'='0','extended_bounds'='1547083500000:1547343000000'),aiops_endpoint\n\nlog4j:WARN No appenders could be found for logger (com.alibaba.druid.pool.vendor.MySqlValidConnectionChecker).\nlog4j:WARN Please initialize the log4j system properly.\nlog4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\nERROR StatusLogger No log4j2 configuration file found. Using default configuration: logging only errors to the console.\njava.sql.SQLException: Error\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)\n    at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\n    at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:61)\n    at org.nlpcn.es4sql.Main2.main(Main2.java:90)\nCaused by: Failed to execute phase [query], all shards failed; shardFailures {[d0r7oc3TS6eR-sR9A_1_gA][aiops_log][0]: RemoteTransportException[[10.10.100.237][10.10.100.237:9300][indices:data/read/search[phase/query]]]; nested: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]]; }{[d0r7oc3TS6eR-sR9A_1_gA][aiops_log][1]: RemoteTransportException[[10.10.100.237][10.10.100.237:9300][indices:data/read/search[phase/query]]]; nested: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]]; }{[d0r7oc3TS6eR-sR9A_1_gA][aiops_log][2]: RemoteTransportException[[10.10.100.237][10.10.100.237:9300][indices:data/read/search[phase/query]]]; nested: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]]; }{[EGg0HOPrTByzU9egjW_fnw][aiops_log][3]: RemoteTransportException[[10.10.100.236][10.10.100.236:9300][indices:data/read/search[phase/query]]]; nested: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]]; }{[d0r7oc3TS6eR-sR9A_1_gA][aiops_log][4]: RemoteTransportException[[10.10.100.237][10.10.100.237:9300][indices:data/read/search[phase/query]]]; nested: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]]; }\n    at org.elasticsearch.action.search.AbstractSearchAsyncAction.onInitialPhaseResult(AbstractSearchAsyncAction.java:223)\n    at org.elasticsearch.action.search.AbstractSearchAsyncAction.access$100(AbstractSearchAsyncAction.java:58)\n    at org.elasticsearch.action.search.AbstractSearchAsyncAction$1.onFailure(AbstractSearchAsyncAction.java:148)\n    at org.elasticsearch.action.ActionListenerResponseHandler.handleException(ActionListenerResponseHandler.java:51)\n    at org.elasticsearch.transport.TransportService$ContextRestoreResponseHandler.handleException(TransportService.java:1032)\n    at org.elasticsearch.transport.TcpTransport.lambda$handleException$17(TcpTransport.java:1411)\n    at org.elasticsearch.common.util.concurrent.EsExecutors$1.execute(EsExecutors.java:109)\n    at org.elasticsearch.transport.TcpTransport.handleException(TcpTransport.java:1409)\n    at org.elasticsearch.transport.TcpTransport.handlerResponseError(TcpTransport.java:1401)\n    at org.elasticsearch.transport.TcpTransport.messageReceived(TcpTransport.java:1345)\n    at org.elasticsearch.transport.netty4.Netty4MessageChannelHandler.channelRead(Netty4MessageChannelHandler.java:74)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:349)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:341)\n    at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293)\n    at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:280)\n    at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:396)\n    at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:248)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:349)\n    at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:341)\n    at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:363)\n    at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:349)\n    at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)\n    at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:129)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:642)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeysPlain(NioEventLoop.java:527)\n    at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:481)\n    at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:441)\n    at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: RemoteTransportException[[10.10.100.237][10.10.100.237:9300][indices:data/read/search[phase/query]]]; nested: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]];\nCaused by: ElasticsearchParseException[failed to parse date field [1547083500000] with format [yyyy-MM-dd HH:mm:ss]]; nested: IllegalArgumentException[Parse failure at index [9] of [1547083500000]];\n    at org.elasticsearch.common.joda.DateMathParser.parseDateTime(DateMathParser.java:213)\n    at org.elasticsearch.common.joda.DateMathParser.parse(DateMathParser.java:66)\n    at org.elasticsearch.search.DocValueFormat$DateTime.parseLong(DocValueFormat.java:170)\n    at org.elasticsearch.search.aggregations.bucket.histogram.ExtendedBounds.parseAndValidate(ExtendedBounds.java:156)\n    at org.elasticsearch.search.aggregations.bucket.histogram.DateHistogramAggregationBuilder.innerBuild(DateHistogramAggregationBuilder.java:329)\n    at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:291)\n    at org.elasticsearch.search.aggregations.support.ValuesSourceAggregationBuilder.doBuild(ValuesSourceAggregationBuilder.java:39)\n    at org.elasticsearch.search.aggregations.AbstractAggregationBuilder.build(AbstractAggregationBuilder.java:126)\n    at org.elasticsearch.search.aggregations.AggregatorFactories$Builder.build(AggregatorFactories.java:333)\n    at org.elasticsearch.search.SearchService.parseSource(SearchService.java:637)\n    at org.elasticsearch.search.SearchService.createContext(SearchService.java:468)\n    at org.elasticsearch.search.SearchService.createAndPutContext(SearchService.java:444)\n    at org.elasticsearch.search.SearchService.executeQueryPhase(SearchService.java:252)\n    at org.elasticsearch.action.search.SearchTransportService$6.messageReceived(SearchTransportService.java:331)\n    at org.elasticsearch.action.search.SearchTransportService$6.messageReceived(SearchTransportService.java:328)\n    at org.elasticsearch.transport.RequestHandlerRegistry.processMessageReceived(RequestHandlerRegistry.java:69)\n    at org.elasticsearch.transport.TcpTransport$RequestHandler.doRun(TcpTransport.java:1488)\n    at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingAbstractRunnable.doRun(ThreadContext.java:638)\n    at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:37)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalArgumentException: Parse failure at index [9] of [1547083500000]\n    at org.elasticsearch.common.joda.DateMathParser.parseDateTime(DateMathParser.java:207)\n    ... 21 more\n{\"msg\":\"FAILURE\",\"code\":-1,\"dataList\":[]}\n. @shi-yuan \u60a8\u597d\uff01\u6211\u5229\u7528es jdbc\u6253\u6210jar\u5305\u5728spark\u73af\u5883\u91cc\u8fd0\u884c\uff0c\u6709\u4e00\u4e2anetty-all-4.1.x.Final.jar\u6216netty-transport-4.1.xx.Final.jar\u7684\u5305\u51b2\u7a81\uff0c\u56e0\u4e3aspark\u7684jar\u5305\u662f\u7528netty-all-4.0.x.Final.jar\n\u6211\u7684\u95ee\u9898\u662f\uff1a\u5728es sql\u91cc\u54ea\u91cc\u4f9d\u8d56\u4e86netty-all-4.1.x.Final.jar\u548cnetty-transport-4.1.xx.Final.jar\uff0c\u5728pom.xml\u91cc\u6ca1\u627e\u5230\n\u62a5\u9519\u5728\u6267\u884c\u4ee5\u4e0b\u7b2c\u4e8c\u884c\u4ee3\u7801\u65f6\u53d1\u751f\uff1a\nSystem.out.println(\"-----------query es sql:\" + sql);\nresultSet = ps.executeQuery();\nSystem.out.println(\"-----------query resultSet--------\");\n\u62a5\u9519\u5982\u4e0b\uff1a\n-----------query es sql:select aiops_endpoint.keyword as aiops_endpoint,count() as value from swp_fmt_log_nginx_cn_ group by date_histogram(field='aiops_timestamp','interval'='1d','alias'='aiops_timestamp'),aiops_endpoint\njava.lang.NoSuchMethodError: io.netty.bootstrap.Bootstrap.config()Lio/netty/bootstrap/BootstrapConfig;\n    at org.elasticsearch.transport.netty4.Netty4Transport.lambda$stopInternal$4(Netty4Transport.java:460)\n    at org.apache.lucene.util.IOUtils.close(IOUtils.java:89)\n    at org.elasticsearch.common.lease.Releasables.close(Releasables.java:36)\n    at org.elasticsearch.common.lease.Releasables.close(Releasables.java:46)\n    at org.elasticsearch.common.lease.Releasables.close(Releasables.java:51)\n    at org.elasticsearch.transport.netty4.Netty4Transport.stopInternal(Netty4Transport.java:443)\n    at org.elasticsearch.transport.TcpTransport.lambda$doStop$4(TcpTransport.java:936)\n    at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:569)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n\u671f\u5f85\u60a8\u7684\u56de\u590d\uff0c\u8c22\u8c22\uff1a\uff09\n. @shi-yuan \u8c22\u8c22\u56de\u590d\uff0c\u6d4b\u8bd5\u4e86\uff0c\u52a0\u4e0aformat\u4e0d\u4f1a\u62a5\u9519\uff0c\u4f46\u662f\u6ca1\u6709\u8fd4\u56de\u7a7a\u6876\n\u5982sql\u8bed\u53e5\uff0c\u6211\u67e5\u8be2\u7684\u8303\u56f4\u662f2019-01-10 00:00:00--2019-01-14 00:00:00\uff0cextended_bounds\u7684\u65f6\u95f4\u6233\u8303\u56f4\u4e5f\u662f\u8fd9\u4e2a\u8303\u56f4\nsql\u5982\u4e0b----\uff1a\nselect aiops_endpoint.keyword as aiops_endpoint,count() as count from aiops_log where aiops_timestamp >= '2019-01-10T00:00:00.000Z' and aiops_timestamp < '2019-01-14T00:00:00.000Z' group by date_histogram(field='aiops_timestamp','interval'='1d','alias'='aiops_timestamp','min_doc_count'='0','extended_bounds'='1547049600000:1547395200000',format='epoch_millis'),aiops_endpoint\n\u6ca1\u6709\u8fd4\u56de01-12\u65e5\u7684\u7a7a\u6876\u6570\u636e\uff0c\u7ed3\u679c\u5982\u4e0b-----:\n{\"msg\":\"SUCCESS\",\"code\":0,\"dataList\":[{\"aiops_timestamp\":\"1547078400000\",\"aiops_endpoint\":\"10.10.100.235:8000\",\"count\":2058},{\"aiops_timestamp\":\"1547164800000\",\"aiops_endpoint\":\"10.10.100.235:8000\",\"count\":9507},{\"aiops_timestamp\":\"1547337600000\",\"aiops_endpoint\":\"10.10.100.235:8000\",\"count\":2458}]}\n\u8fd9\u4e09\u6761\u6570\u636e\u4f9d\u6b21\u4e3a\uff08\u6ca1\u6709\u4ece00\u70b9\u5f00\u59cb\u805a\u7c7b\uff09\uff1a\n2019-01-10 08:00:00\n2019-01-11 08:00:00\n2019-01-13 08:00:00\n\u6211\u7684\u7406\u60f3\u7ed3\u679c\u662f\u8fd9\u6837\uff0c\u4e0d\u5e0c\u671b\u67e5\u8be2\u51fa\u6765\u7684\u6570\u636e\uff0c\u518d\u8f6c\u4e00\u6b21\u65f6\u95f4\uff0c\u5e76\u4e14\u6309\u5929\u662f\u4ece00\u70b9\u5f00\u59cb\uff0c\n\u4f46extended_bounds\u7684\u53c2\u6570\u53ea\u63a5\u53d7long\u578b\n\u6267\u884c\uff1a\nselect aiops_endpoint.keyword as aiops_endpoint,count() as count from aiops_log where aiops_timestamp >= '2019-01-10T00:00:00.000Z' and aiops_timestamp < '2019-01-14T00:00:00.000Z' group by date_histogram(field='aiops_timestamp','interval'='1d','alias'='aiops_timestamp'),aiops_endpoint\n\u8fd4\u56de\uff1a\n{\"msg\":\"SUCCESS\",\"code\":0,\"dataList\":[\n{\"aiops_timestamp\":\"2019-01-10 00:00:00\",\"aiops_endpoint\":\"10.10.100.235:8000\",\"count\":13167},{\"aiops_timestamp\":\"2019-01-11 00:00:00\",\"aiops_endpoint\":\"10.10.100.235:8000\",\"count\":9507},{\"aiops_timestamp\":\"2019-01-13 00:00:00\",\"aiops_endpoint\":\"10.10.100.235:8000\",\"count\":2984}]}\n\u6211\u7528\u7684es sql\u7248\u672c\u4e3a5.6.9\n. @shi-yuan \u8bf7\u770b\u4ee3\u7801\uff1a\uff09\npublic static void main(String[] args){\n        Properties properties = new Properties();\n        String url = \"jdbc:elasticsearch://10.10.100.235:9300\"; \n        properties.put(\"url\", url);\n        String sql = \"select aiops_endpoint.keyword as aiops_endpoint,count() as count from aiops_log where aiops_timestamp >= '2019-01-10T00:00:00.000Z' and aiops_timestamp < '2019-01-14T00:00:00.000Z' group by date_histogram(field='aiops_timestamp','interval'='1d','alias'='aiops_timestamp','min_doc_count'='0','extended_bounds'='1547049600000:1547395200000',format='epoch_millis'),aiops_endpoint\";\n        List> dataList = new ArrayList>();\n        JSONObject json = new JSONObject();\n        String msg = \"SUCCESS\";\n        int code = 0;\n        try( DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory.createDataSource(properties);\n             Connection connection = dds.getConnection();\n             PreparedStatement ps = connection.prepareStatement(sql);) {\n             ResultSet resultSet = ps.executeQuery();\n             ResultSetMetaData md = resultSet.getMetaData();\n             int columnCount = md.getColumnCount();\n             List list = new ArrayList();\n             for (int i = 1; i <= columnCount; i++) {\n                list.add(md.getColumnName(i));\n             }\n             if(list != null && list.size() > 0) {\n                while (resultSet.next()) {\n                    LinkedHashMap rowData = new LinkedHashMap();\n                    Boolean flag = true;\n                     for (int i = 0; i < list.size(); i++) {\n                        String column = list.get(i);\n                        try{\n                            rowData.put(column, resultSet.getObject(column));\n                        } catch (Exception e) {\n                            System.out.println(\"resultSet\u83b7\u53d6\u6570\u636e\u5931\u8d25\uff0c\u7ee7\u7eed\u83b7\u53d6...\");\n                            flag = false;\n                            break;\n                        }\n                     }\n                     if(flag) {\n                        dataList.add(rowData);\n                     }\n             }\n         }\n    } catch (Exception e) {\n        msg = \"FAILURE\";\n        code = -1;\n        e.printStackTrace();\n    }\n     json.put(\"msg\", msg);\n     json.put(\"code\", code);\n     json.put(\"dataList\", dataList);\n     System.out.println(json.toJSONString());\n}. \u5982\u679c\u4e0d\u8bbe\u7f6e'min_doc_count'='0','extended_bounds'='1547049600000:1547395200000',format='epoch_millis'\n\n\u805a\u7c7b\u6309\u5929\uff0c\u8fd4\u56de\u7684\u6570\u636e\u5c31\u662f\u6bcf\u5929\u7684\u657400:00\n2019-01-10 00:00:00\n2019-01-11 00:00:00\n2019-01-13 00:00:00\n\u5982\u679c\u8bbe\u7f6e\u4e86\uff0c\u8fd4\u56de\u7684\u6bcf\u5929\u7684\u6570\u636e\u662f08:00\n2019-01-10 08:00:00 //\u8fd9\u4e2a\u8868\u793a01-09 08:00\u81f301-10 08:00\uff0c\u662f\u5417?\n2019-01-11 08:00:00//\u8fd9\u4e2a\u8868\u793a01-10 08:00\u81f301-11 08:00\uff0c\u662f\u5417?\n2019-01-13 08:00:00////\u8fd9\u4e2a\u8868\u793a01-11 08:00\u81f301-13 08:00\uff0c\u662f\u5417?. ",
    "hjxhjh": "it works with url parameter. Can we support settings in the site_configuration.json?. me too\n[=================================================] 100%\nException in thread \"main\" java.lang.IllegalArgumentException: Unknown properties in plugin descriptor: [jvm, site]\n    at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:297)\n    at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:184)\n    at org.elasticsearch.plugins.InstallPluginCommand.loadPluginInfo(InstallPluginCommand.java:571)\n    at org.elasticsearch.plugins.InstallPluginCommand.installPlugin(InstallPluginCommand.java:707)\n    at org.elasticsearch.plugins.InstallPluginCommand.install(InstallPluginCommand.java:623)\n    at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:223)\n    at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:212)\n    at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86)\n    at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)\n    at org.elasticsearch.cli.MultiCommand.execute(MultiCommand.java:75)\n    at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)\n    at org.elasticsearch.cli.Command.main(Command.java:90)\n    at org.elasticsearch.plugins.PluginCli.main(PluginCli.java:48). \u89e3\u538b\u540e\u76f4\u63a5\u653e\u5230ES_HOME/plugins/sql \u4e0b\u9762\uff0c \u540c\u65f6\u5c06plugin-descriptor.properties \u914d\u7f6e\u6587\u4ef6\u91cc\u9762 jvm \u548c site \u53c2\u6570\u53bb\u9664\u5c31\u53ef\u4ee5\u4e86\u3002\n. ",
    "juanpaulo": "anything else to do to have this merged?. ",
    "wangping886": "maybe i should use _sql by POST . that will be ok. i use http://localhost:9200/_sql by POST that will be ok. ",
    "kosckosc": "After installing 5.6.4. ES, plugin 5.6.4. works fine but \nserver installed od port 8080 still have problem,\ncd site-server\nnpm install express --save\nnode node-server.js\n. ",
    "davidpelfree": "Maybe CORS issue. Run these as root:\necho 'http.cors.enabled: true' >> /etc/elasticsearch/elasticsearch.yml\necho 'http.cors.allow-origin: http://localhost:8080' >> /etc/elasticsearch/elasticsearch.yml\nRead more here: https://www.elastic.co/guide/en/elasticsearch/reference/6.2/modules-http.html. ",
    "yuanxiaoqi": "\u4f60\u597d\uff0c\u6211\u5728paramer\u91cc\u9762\u8bbe\u7f6e\u4e86\u4e00\u4e0b\u5224\u65ad\uff0c\u5f53sqlExpr\u4e0d\u662fSQLIntegerExpr\u7684\u65f6\u5019\u5c31\u628asqlExpr\u5f3a\u8f6c\u4e3aSQLUnaryExpr\uff0c\u7136\u540e\u83b7\u53d6\u5b83\u7684expr\u5f53slop\uff0c\u5728\u6570\u5b57\u524d\u9762\u52a0~\u548c\uff01\u90fd\u88ab\u7b97\u662funary\uff0c\u7136\u540e\u53ef\u4ee5\u6b63\u786e\u53d6\u5230slop\uff0c\u4e0d\u8fc7+\u548c-\u8fd8\u662f\u88ab\u7b97\u4f5c\u662fboost\u7684\u7c7b\u578b\u3002\u8fd9\u6837\u7b80\u5355\u5b9e\u73b0\u4e86\u4e00\u4e0b\u3002\u3002\u8c22\u8c22\uff01. ",
    "zhangwenhao": "i changed the ElasticSearchResultSetMetaDataBase class by others quesstion you answered and use another way ,it has be sloved.. ",
    "huangsusu": "Really appreciate your work \uff01\uff01 !\n\n\u5728 2017\u5e7412\u67085\u65e5\uff0c\u4e0b\u53482:38\uff0cshiyuan notifications@github.com \u5199\u9053\uff1a\nelasticsearch-sql-site-chrome https://github.com/shi-yuan/elasticsearch-sql-site-chrome\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/NLPchina/elasticsearch-sql/issues/552#issuecomment-349210525, or mute the thread https://github.com/notifications/unsubscribe-auth/AM1jDIyXQTO3Lnz46JW-BZzGkOP0-8jtks5s9OT-gaJpZM4QldhD.\n\n\n. ",
    "betarelease": "update on this would be great. ",
    "reportico-web": "HI I use this plugin a lot, and we just upgraded to version 6.0.0 .. any chance Elastic 6.0.0 can be supported?. Very grateful you are looking at this :-) ... I hope you find a fix soon . ",
    "xiangHannibal": "This score is a bit wrong\nselect * from test66 where name.mix = matchPhrase('\u9a6c\u94c3\u85af', 1.0) or common_name.mix = matchPhrase('\u9a6c\u94c3\u85af', 0.1)\nname = {total=2, rows=[{name=\u5f88\u597d, time=2017-12-03 16:23:05, common_name=\u9a6c\u94c3\u85af}, {name=\u9a6c\u94c3\u85af, time=2017-12-03 16:22:31, common_name=ces}]}\n. searchResponse = {\"took\":38,\"timed_out\":false,\"_shards\":{\"total\":5,\"successful\":5,\"failed\":0},\"hits\":{\"total\":2,\"max_score\":0.0,\"hits\":[{\"_index\":\"test66\",\"_type\":\"test66\",\"_id\":\"5bf4b0e5-87d5-40a1-bc6c-ba5128413dba\",\"_score\":0.0,\"_source\":{\"name\":\"\u5f88\u597d\",\"time\":\"2017-12-03 16:23:05\",\"common_name\":\"\u9a6c\u94c3\u85af\"}},{\"_index\":\"test66\",\"_type\":\"test66\",\"_id\":\"6752a9d9-f7a7-441e-acda-ccef59adbaa9\",\"_score\":0.0,\"_source\":{\"name\":\"\u9a6c\u94c3\u85af\",\"time\":\"2017-12-03 16:22:31\",\"common_name\":\"ces\"}}]}}\n\u8bc4\u5206\u548b\u90fd\u662f0 \u54e6\n. select * from test66 where name.mix = matchQuery('\u9a6c\u94c3\u85af', 1.0) or common_name.mix = matchQuery('\u9a6c\u94c3\u85af', 0.1). \u54e6 \u8981\u52a0\u4e0aorder by _score desc\u624d\u8ba1\u5206\nselect * from test66 where name.mix = matchQuery('\u9a6c\u94c3\u85af', 1.0) or common_name.mix = matchQuery('\u9a6c\u94c3\u85af', 0.1) order by _score desc. then i need calculate the two points distance and order by the distance \uff0c how solve this problem. so es-sql not support it yet?. SELECT * FROM bank WHERE address = matchQuery('880 Holmes Lane', 'standard', 1.0)\n\u8fd9\u6837\u53ef\u4ee5\u5426. AggregationBuilder aggregation =\n        AggregationBuilders\n                .range(\"agg\")\n                .field(\"height\")\n                .addUnboundedTo(1.0f)               // from -infinity to 1.0 (excluded)\n                .addRange(1.0f, 1.5f)               // from 1.0 to 1.5 (excluded)\n                .addUnboundedFrom(1.5f);            // from 1.5 to +infinity\n.addUnboundedTo(1.0f)               // from -infinity to 1.0 (excluded)\n .addUnboundedFrom(1.5f);            // from 1.5 to +infinity\n\u5c31\u662f\u5b98\u7f51\u7684\u8fd9\u4e2a\u4e0a\u4e0b\u9650\u600e\u4e48\u8bbe\u7f6e\n. \u8fd9\u4e2a\u597d\u50cf\u4e0d\u884c\u554a\nSELECT COUNT(speed1) FROM table GROUP BY range(speed1, '-Infinity',20,30,40,50,'Infinity')\u67e5\u8be2\u5931\u8d25\u3002\njava.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Number\n    at org.nlpcn.es4sql.Util.KV2DoubleArr(Util.java:142)\n    at org.nlpcn.es4sql.query.maker.AggMaker.rangeBuilder(AggMaker.java:551)\n    at org.nlpcn.es4sql.query.maker.AggMaker.makeRangeGroup(AggMaker.java:206)\n    at org.nlpcn.es4sql.query.maker.AggMaker.makeGroupAgg(AggMaker.java:67)\n    at org.nlpcn.es4sql.query.AggregationQueryAction.getGroupAgg(AggregationQueryAction.java:214)\n    at org.nlpcn.es4sql.query.AggregationQueryAction.explain(AggregationQueryAction.java:63)\n    at org.nlpcn.es4sql.query.AggregationQueryAction.explain(AggregationQueryAction.java:37)\n    at com.dfssi.motorcade.es.SearchCenter.searchSQL(SearchCenter.java:47)\n    at com.dfssi.motorcade.es.SearchCenter.main(SearchCenter.java:81)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147). ",
    "guanlei1996": "\u8c22\u8c22~. @wanghu198343 \u62b1\u6b49.\u53ef\u80fd\u6211\u6682\u65f6\u65e0\u6cd5\u5e2e\u52a9\u60a8.\u56e0\u4e3a\u4e00\u4e9b\u5de5\u4f5c\u539f\u56e0\u6211\u73b0\u5728\u8fd8\u6ca1\u5f00\u59cb\u5b9e\u8df5\ud83d\ude14. @wanghu198343 \u6211\u4f7f\u7528logstash\u540c\u6b65\u7684\u6570\u636e,\u6839\u636e @shi-yuan \u7684\u542f\u53d1\u6211\u5728logstash\u914d\u7f6e\u7684template\u662f\u6ca1\u95ee\u9898\u7684,\u53ef\u80fd\u6211\u73b0\u5728\u89e3\u51b3\u4e0d\u4e86\u4f60\u73b0\u5728\u7684\u95ee\u9898,\u4f46\u662f\u8fd9\u4e5f\u662f\u4e00\u6761\u601d\u8def. ES\u7248\u672c\u4e3a5.6.1. \u73b0\u5728\u7684\u7248\u672c\u611f\u89c9\u8ddfmaster\u4e0a\u662f\u6709\u51fa\u5165\u7684,\u56e0\u4e3a\u62a5\u9519\u7ed9\u6211\u7684\u4fe1\u606f\u662f\u8fd8\u6ca1\u6709extended_bounds\u7684\u5185\u5bb9.\u6211\u6253\u7b97\u5148\u81ea\u5df1\u91cd\u65b0\u6253\u5305\u8bd5\u9a8c\u4e00\u4e0b. \u660e\u767d\u4e86 \u662f\u6211\u5199\u7684\u95ee\u9898~\u8c22\u8c22\u89e3\u7b54~. ",
    "xumingbei": "Thanks. @wanghu198343 \n\u60a8\u597d\uff0cmapping\u6620\u5c04\uff0c\u5728\u521b\u5efa\u7d22\u5f15\u7684\u65f6\u5019\u8fdb\u884cmapping\u6620\u5c04\u64cd\u4f5c\u5373\u53ef\u3002\n\u7f51\u5740\u4e3a\uff1ahttps://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html\n. @wanghu198343\nhttp://www.cnblogs.com/Creator/p/3722408.html. ",
    "kant111": "When can we expect this?. ",
    "amitbsconcept": "It worked like a charm. Cool thanx.. Well i tried the same - but it dose not return any value\nBelow is the result for the same\n{\n  \"took\": 3,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 5,\n    \"successful\": 5,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": 0,\n    \"max_score\": null,\n    \"hits\": []\n  }\n}\nBut when i give in the below query\nSELECT * FROM articles WHERE nested(classifications.classification_id) is not missing order by created_on desc\nI get proper output... i get in the expected result.. Even i was having similar problems with date_format function when tried to apply - but when i arrived looking for the solution i applied the changes and framed up the following query:\nSELECT date_format(mentioned_on,'%Y-%m-%d') as mentioned_on, topic_name, count(*) as total_mentions FROM mentions brand_id = '7' and mentioned_on > '2018-03-27 00:00:00' and mentioned_on <= '2018-04-03 23:59:59' and topic_name <> '' GROUP BY date_format(mentioned_on,'%Y-%m-%d'), topic_name ORDER BY mentioned_on ASC\nNow when i try to execute the same - it gives me the following output\n{\n  \"message\": \"Client request error: socket hang up\",\n\"statusCode\": 502,\n\"error\": \"Bad Gateway\"\n}\nHow can we fix up the same?. ",
    "ihuanru": "@shi-yuan thank you\nI've seen it on Wiki.. ",
    "licz009": "\u611f\u8c22\u60a8\u7684\u53ca\u65f6\u56de\u590d\uff0c\u6211\u73b0\u5728\u7684\u60c5\u51b5\u662f\u8fd0\u884chttp://x.x.x.x:9200/_sql?select...\u80fd\u6b63\u786e\u51fa\u6765\u7ed3\u679c\uff0c\u4f46\u662f\u5728site_server\u8fd4\u56de\u7684\u662f\u201cResponse is not avalible\u201d\uff0csite_server\u7684es\u5730\u5740\u914d\u7f6e\u662f\u6b63\u786e\u7684\uff08http://x.x.x.x:9200/\uff09,\u8bf7\u95eenode node_site.js\u8f93\u51fa\u65e5\u5fd7\u5728\u54ea\u91cc\uff1f \u6211\u7528\u7684es\u53caes_sql\u7528\u7684\u90fd\u662f5.6.4. \u975e\u5e38\u611f\u8c22\uff0cok\u4e86\uff1b. \u8c22\u8c22\u3002\u3002\u3002. ",
    "hanxiaobott": "\u5efa\u8bae\u53ef\u4ee5\u5efa\u7acb\u4e00\u4e2a\u7fa4,\u5927\u5bb6\u4ea4\u6d41\u6bd4\u8f83\u65b9\u4fbf.. group by\u7684\u5b57\u6bb5\u7684\u522b\u540d\u600e\u4e48\u8d77\u5440?. ",
    "qq494679975": "3QQQQQQQQQQQQQQQQQQQQQQQQQQQ,\u5b8c\u7f8e\u89e3\u51b3. \u5bf9\u4e86 2.4\u7248\u672c\u7684ES\ndelete from health_edu_article_patient_test3 where doctorCode=\"xh1D2017031502222\" \u6267\u884cdelete\u62a5\u9519 \n\u6211\u6709\u88c5\u597ddelete-by-query\u63d2\u4ef6  \u4e5f\u91cd\u542f\u4e86 \u4f46\u662f\u8fd8\u662f\u62a5\u9519\njava.lang.UnsupportedOperationException: currently not support delete on elastic 2.x . ",
    "imqishi": "OK~ Thank you~. Well, I test in mysql, LIKE '%some-thing%' with '-' is OK, so is it not compatible?\nThis is my SQL:\nsql\nselect * from urlevent-2018.01.11 where ACCTIME between '2018-01-11T13:42:44+08:00' and '2018-01-11T16:42:44+08:00' and (HOST like '*store-images.s-microsoft.com*') order by @timestamp desc limit 50 offset 0. Wow, thanks! It works when use \".keyword\". Thanks a lot !. ",
    "gtexpanse": "get. ",
    "sujun891020": "\u6211\u4f7f\u7528\u4e86\u4f60\u7684\u4ee3\u7801,\u7528elasticsearch-sql\u76842.3.5.0\u7248\u672c,\u8fd4\u56de\u7684\u7ed3\u679c\u4e3a\u7a7a, \u53bb\u6389USE_SCROLL\u540e\u6210\u529f\u8fd4\u56de\u6570\u636e\uff0c\u8bf7\u95ee\u662f\u7248\u672c\u95ee\u9898\u5417\uff1f. ",
    "coolgrancy": "@shi-yuan yes, when I try then function IN_TERMS, the maximum even can be 10000, but the value is much smaller then I want yet.\nquery result in table2 can also bigger than 10,000,000 , so this solution with limit cannot be useful. ",
    "joseleperez": "Just forgot how elasticsearch worked :). ",
    "chitenderkumar": "@shi-yuan thanks for response.\nif i need to use multiple fields/columns in group by then what should be the statement?. @shi-yuan \nwe are using elasticsearch version 2.3.5 and elasticsearch-sql is 2.3.5.0.\nwhen i executed the query select count(*),x,y from test group by TERMS('field'='x,y','execution_hint'='global_ordinals') having count(*)>1 i got below error response.\nError:{\"error\":{\"root_cause\":[{\"type\":\"sql_parse_exception\",\"reason\":\"terms aggregation err or not define field execution_hint=global_ordinals\"}],\"type\":\"sql_parse_exception\",\"reason\":\"terms aggregation err or not define field execution_hint=global_ordinals\"},\"status\":500}\napologies to not mention the versions details earlier. could you please comment on this.. didn't got you. is this SELECT * FROM myindex GROUP BY TERMS('field'='a','execution_hint'='global_ordinals') not supported in 2.3.5.0?. ok, thanks. can you please let us know, by when we will have it in 2.3.5.0?. we deployed the zip on es version 2.3.5.0. but we are not able to access the ES-ESQL webpage. while accessing the webpage http://127.0.0.1:19200/_plugin/sql/ we are getting HTTP ERROR 404. ok, now it is working. wrongly deployed the zip.\n@shi-yuan if we want to use multiple columns/fields in group by, then what shall be the sql statement?. we got it. SELECT x,y,z FROM test group by TERMS('field'='x','execution_hint'='global_ordinals'),TERMS('field'='y','execution_hint'='global_ordinals'),TERMS('field'='z','execution_hint'='global_ordinals')\n@shi-yuan thanks for your support.. ",
    "dexion": "+1. ",
    "wenfang6": "\u8bf7\u95ee\u8fd9\u4e2a\u7ed3\u679c\u662f\u7ec4\u5185\u6709\u5e8f\u5417\u8fd8\u662f\u5168\u5c40\u6709\u5e8f\uff1f. ",
    "armandxu": "With nginx load balancing, the data returned is larger than nginx's cache size.. ",
    "smsmithee": "I also get that error when trying to upgrade/install 6.2.1.0. ",
    "veronesip": "I have the same errore:\n[root@eladevsolelbr01vm ~]#  /usr/share/elasticsearch/bin/elasticsearch-plugin install file:///elasticsearch-sql-6.2.1.0.zip\n-> Downloading file:///home/paolo.veronesi/elasticsearch-sql-6.2.1.0.zip\n[=================================================] 100%\u00a0\u00a0\nException in thread \"main\" java.lang.IllegalArgumentException: Unknown properties in plugin descriptor: [jvm, site]\n        at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:297)\n        at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:184)\n        at org.elasticsearch.plugins.InstallPluginCommand.loadPluginInfo(InstallPluginCommand.java:571)\n        at org.elasticsearch.plugins.InstallPluginCommand.installPlugin(InstallPluginCommand.java:707)\n        at org.elasticsearch.plugins.InstallPluginCommand.install(InstallPluginCommand.java:623)\n        at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:223)\n        at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:212)\n        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86)\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)\n        at org.elasticsearch.cli.MultiCommand.execute(MultiCommand.java:75)\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)\n        at org.elasticsearch.cli.Command.main(Command.java:90)\n        at org.elasticsearch.plugins.PluginCli.main(PluginCli.java:48). Hello, it seems that https://github.com/NLPchina/elasticsearch-sql/releases/download/6.2.1.0/elasticsearch-sql-6.2.1.0.zip has not been update, has it?. ",
    "lccbiluox2": "\u6211\u4e5f\u9047\u5230\u8fd9\u4e2a\u95ee\u9898\u4e86\uff0c\u800c\u4e14mvn package\u7f16\u8bd1\u4e5f\u51fa\u95ee\u9898\nD:\\elasticsearch\\elasticsearch-6.2.0\\bin>elasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.2.0.0/elasticsearch-sql-6.2.0.0.zip\n-> Downloading https://github.com/NLPchina/elasticsearch-sql/releases/download/6.2.0.0/elasticsearch-sql-6.2.0.0.zip\n[=================================================] 100%??\nException in thread \"main\" java.lang.IllegalArgumentException: Unknown properties in plugin descriptor: [jvm, site]\n        at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:284)\n        at org.elasticsearch.plugins.InstallPluginCommand.loadPluginInfo(InstallPluginCommand.java:571)\n        at org.elasticsearch.plugins.InstallPluginCommand.installPlugin(InstallPluginCommand.java:707)\n        at org.elasticsearch.plugins.InstallPluginCommand.install(InstallPluginCommand.java:623)\n        at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:223)\n        at org.elasticsearch.plugins.InstallPluginCommand.execute(InstallPluginCommand.java:212)\n        at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86)\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)\n        at org.elasticsearch.cli.MultiCommand.execute(MultiCommand.java:75)\n        at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124)\n        at org.elasticsearch.cli.Command.main(Command.java:90)\n        at org.elasticsearch.plugins.PluginCli.main(PluginCli.java:48)\nD:\\elasticsearch\\elasticsearch-6.2.0\\bin>\nD:\\elasticsearch\\elasticsearch-sql-elastic6.2.1>mvn -X package\n[INFO] ------------------------------------------------------------------------\n[ERROR] 14432\njava.lang.ArrayIndexOutOfBoundsException: 14432\n        at org.codehaus.plexus.util.xml.pull.MXParser.parsePI(MXParser.java:2502)\n        at org.codehaus.plexus.util.xml.pull.MXParser.parseEpilog(MXParser.java:1604)\n        at org.codehaus.plexus.util.xml.pull.MXParser.nextImpl(MXParser.java:1434)\n        at org.codehaus.plexus.util.xml.pull.MXParser.next(MXParser.java:1131)\n        at org.apache.maven.model.io.xpp3.MavenXpp3Reader.read(MavenXpp3Reader.java:3856)\n        at org.apache.maven.model.io.xpp3.MavenXpp3Reader.read(MavenXpp3Reader.java:595)\n. ",
    "BoABC": "Thank you very much@shi-yuan \nIt's cool to use the programming API directly.\nBut I'm wondering is that possible to stand up a service by setting up an elasticsearch endpoint like this package https://github.com/lmenezes/cerebro. Thank you. I see elasticsearch-site uses transport client. But aws elasticsearch only supports RESTful api. Is there a way to solve it or I missed anything again?. I don't understand. Did you post on the wrong issue?. ",
    "colourmeamused": "@shi-yuan AWS provides Elasticsearch as a managed service with no access via HTTP transport client or to install plugins. Basically you can't configure ioc.js to connect to the AWS Elasticsearch service.\n@BoABC My understanding is elastisearch-site would need to be modified to use the new Java REST client. I might give it a shot to see how tricky it is.. ",
    "liuzigenius": "Besides, if there is any way that we could get scroll_id from es-sql JDBC?. ",
    "liangpz521": "\u8bd5\u4e86\u4f60\u8bf4\u7684\u8fd9\u4e2a \u52a0\u6743\u91cd\u4e0d\u7ba1\u7528\u7684\u5462 \u6211\u7528\u7684\u7248\u672c\u662f5.6.3. ",
    "siddv29": "Thanks for your reply :-)\nYup, that would be the way forward.\nI was trying to use ExplainTest.searchSanity to get an idea to explain the query. But it requires connection to ES. \nCould you please suggest the way to do that.. Worked like a charm!! \nThanks a lot!!.... ",
    "xuanergg": "\u8fd9\u6837\u7684\u8bdd\uff0c\u67e5\u8be2\u5168\u90e8\uff0c\u8fd8\u4e0d\u5982\u7528\u6bcf\u4e2a\u7684cateId\u53bb\u67e5\u8be2\u524d2\u6761\u5462(\u25cf\u02c7\u2200\u02c7\u25cf)\u3002\u3002\u5509. \u975e\u5e38\u611f\u8c22\u4f60\uff0c\u8fd9\u4e2asql\u662f\u5206\u7ec4\u67e5\u6bcf\u7ec4\u7684\u524d\u51e0\u6761\uff0c\u73b0\u5728\u4f7f\u7528\u6bcf\u4e2acateid\u89e3\u51b3\uff0c\u8fd9\u6837\u7684\u8bed\u6cd5\u662f\u4e0d\u80fd\u652f\u6301\u7684\u554a. @shi-yuan \u53ef\u4ee5\u7684\uff0c\u8fd8\u8981\u5176\u4ed6\u7684\u5c5e\u6027\u600e\u4e48\u529e\u554a\u3002\ud83d\ude1d. \u5927\u4f6c\u4e0d\u5bf9\u554a,.. \u5f53\u524d\u65f6\u95f4\u662f\u5b57\u7b26\u4e32\u662f\u53ef\u4ee5\u67e5\u8be2\u7684 \uff0c\u597d\u5427. ",
    "EndlessTundra": "Sorry but I'm not sure I understand, what did I not do that is in these instructions?. Perhaps I should clarify.  I can get to the Web UI fine, I get that error when I try and run a query through it.. Ah I see what you mean.  It defaults to http://servername:8080.  Thanks for the help it works now!. ",
    "RainTown67": "Same here.  ES cluster is available on port 9200, and this works:\ncurl -s -u elastic:mypassword -H \"Content-Type: application/json\" -XPOST 'http://localhost:9200/_sql' -d 'SELECT * FROM myindex LIMIT 10' \nI can reach webUI on localhost:8080 but search or explain give errors.\nrpm -q elasticsearch\nelasticsearch-6.2.2-1.noarch\ntail -3 /etc/elasticsearch/elasticsearch.yml\nhttp.cors.enabled: true\nhttp.cors.allow-origin: \"*\"\nhttp.cors.allow-headers: \"X-Requested-With, Content-Type, Content-Length, Authorization\"\nUsed latest plugin\nelasticsearch-plugin install https://github.com/NLPchina/elasticsearch-sql/releases/download/6.2.2.0/elasticsearch-sql-6.2.2.0.zip\nwhat are EndlessTundra  and I missng?. ",
    "guoxiaodan": "@shi-yuan es-sql\u76ee\u524d\u4e0d\u652f\u6301\u7528sql\u6765\u5b8c\u6210\u8fd9\u79cd\u64cd\u4f5c\u4e48\uff1f\u53ea\u80fd\u5199es-dsl\u8bed\u53e5\u4e48\uff1f\n\u5c06\u4f60\u63d0\u4f9b\u7684\u8bed\u53e5\u6539\u4e86\u4e0b\uff0c\u5c06must\u548cmust_not\u8c03\u6362\u4f4d\u7f6e\uff0c\u5148must_not\uff0c\u7136\u540emust\uff0c\u5c31\u53ef\u4ee5\u67e5\u8be2\u67e5\u6765\uff0c\u4f46\u662f\u8fd9\u79cd\u64cd\u4f5c\u5c31\u592a\u8fc7\u9ebb\u70e6\uff0c\u4e0d\u5982sql\u6765\u7684\u7b80\u6d01\uff0c\u590d\u6742\u6761\u4ef6\u67e5\u8be2\uff0c\u5199\u7684\u4e5f\u8fc7\u4e8e\u9ebb\u70e6\nget /user_label_1/user_label_1/_search\n   {                                                              \n   \"from\": 0,                                                   \n   \"size\": 200,                                                 \n   \"query\": {                                                   \n     \"bool\": {                                                  \n       \"filter\": [                                              \n         {                                                      \n           \"bool\": {                                            \n\"must_not\": [ \n               {                                                \n                 \"nested\": {                                    \n                   \"query\": {                                   \n                     \"bool\": {                                  \n\"must\": [ \n                         {                                      \n                           \"exists\": {                          \n                             \"field\": \"user_orders.order_id\",   \n                             \"boost\": 1                         \n                           }                                    \n                         }                                      \n                       ],                                       \n                       \"adjust_pure_negative\": true,            \n                       \"boost\": 1                               \n                     }                                          \n                   },                                           \n                   \"path\": \"user_orders\",                       \n                   \"ignore_unmapped\": false,                    \n                   \"score_mode\": \"none\",                        \n                   \"boost\": 1                                   \n                 }                                              \n               }                                                \n             ],                                                 \n             \"adjust_pure_negative\": true,                      \n             \"boost\": 1                                         \n           }                                                    \n         }                                                      \n       ],                                                       \n       \"adjust_pure_negative\": true,                            \n       \"boost\": 1                                               \n     }                                                          \n   },                                                           \n   \"_source\": {                                                 \n     \"includes\": [                                              \n       \"user_orders.order_id\",                                  \n       \"user_name\"                                              \n     ],                                                         \n     \"excludes\": []                                             \n   }                                                            \n }\n. ",
    "leonlu001": "The site just for explain SQL to DSL, you need install this plugin to elastic search, than test it.\u53d1\u81ea\u6211\u7684\u534e\u4e3a\u624b\u673a-------- \u539f\u59cb\u90ae\u4ef6 --------\u4e3b\u9898\uff1a[NLPchina/elasticsearch-sql] Example Site Not working (#629)\u53d1\u4ef6\u4eba\uff1amrshidashrf \u6536\u4ef6\u4eba\uff1aNLPchina/elasticsearch-sql \u6284\u9001\uff1aSubscribed Hi, i want to integrate your plugin into elasitcsearch but needs to test it before but unfortunately your provided link http://essql.nlpcn.org/  not working\n\u2014You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/NLPchina/elasticsearch-sql\",\"title\":\"NLPchina/elasticsearch-sql\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/NLPchina/elasticsearch-sql\"}},\"updates\":{\"snippets\":[{\"icon\":\"DESCRIPTION\",\"message\":\"Example Site Not working (#629)\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/NLPchina/elasticsearch-sql/issues/629\"}}}. Their is a field named xx_to_time , if your field type is date. \u53d1\u81ea\u6211\u7684\u534e\u4e3a\u624b\u673a. aa type is date, by default, the date value is long, your can change the time string '2018-01-01' to unix long time value, then compare them.. \u8fd4\u56de\u7684json \u5bf9\u8c61\u91cc\u9762\u6709\u4e2ahighlights\u7684\u8282\u70b9\uff0c\u5c31\u662f\u4f60\u9700\u8981\u9ad8\u4eae\u7684\u5185\u5bb9\u53d1\u81ea\u6211\u7684\u534e\u4e3a\u624b\u673a-------- \u539f\u59cb\u90ae\u4ef6 --------\u4e3b\u9898\uff1a[NLPchina/elasticsearch-sql] \u9ad8\u4eae\u53ef\u4ee5\u5b9e\u73b0\u4e48\uff1f (#645)\u53d1\u4ef6\u4eba\uff1a\u7a46\u9e4f \u6536\u4ef6\u4eba\uff1aNLPchina/elasticsearch-sql \u6284\u9001\uff1aSubscribed \u641c\u7d22\u7ed3\u679c\u9ad8\u4eae\u600e\u4e48\u5c55\u73b0\uff1f\n\u2014You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/NLPchina/elasticsearch-sql\",\"title\":\"NLPchina/elasticsearch-sql\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/NLPchina/elasticsearch-sql\"}},\"updates\":{\"snippets\":[{\"icon\":\"DESCRIPTION\",\"message\":\"\u9ad8\u4eae\u53ef\u4ee5\u5b9e\u73b0\u4e48\uff1f (#645)\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/NLPchina/elasticsearch-sql/issues/645\"}}}. Es\u6709\u9650\u5236\uff0c\u53ea\u7ed9\u524d10\u4e07\u6761\u6570\u636e\uff0c\u4f60\u53ef\u4ee5\u589e\u52a0\u67e5\u8be2\u6761\u4ef6\uff0c\u6216\u8005\u65f6\u95f4\u5207\u7247\u67e5\u8be2\u3002\u53d1\u81ea\u6211\u7684\u534e\u4e3a\u624b\u673a-------- \u539f\u59cb\u90ae\u4ef6 --------\u4e3b\u9898\uff1a[NLPchina/elasticsearch-sql] elasticsearch-sql \u5982\u4f55\u5904\u7406\u6df1\u5206\u9875\u95ee\u9898\uff0c \u672c\u8eab\u652f\u6301\u5417\uff1f (#659)\u53d1\u4ef6\u4eba\uff1a8plat \u6536\u4ef6\u4eba\uff1aNLPchina/elasticsearch-sql \u6284\u9001\uff1aSubscribed \u6839\u636e\u6761\u4ef6\u7b5b\u9009\u5b8c\u6bd5\u540e \u6709 40\u4e07\u6570\u636e\uff0c\u6211\u9700\u8981\u5206\u9875\u53d6\u51fa\uff0c\u56e0\u4e3a\u5b58\u5728\u6df1\u5206\u9875\u7684\u95ee\u9898\u540e\u9762\u7684\u67e5\u8be2\u8d8a\u6765\u8d8a\u6162\u3002\u6700\u540e\u4e00\u9875\u57fa\u672c\u67e5\u8be2\u4e0d\u51fa\u6765\u3002\nSELECT * FROM member_info  where  IS_PASS_MESS_VERT = '1'  AND APPLY_TYPE ='10'\nLIMIT 399990,400000\n\u2014You are receiving this because you are subscribed to this thread.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/NLPchina/elasticsearch-sql\",\"title\":\"NLPchina/elasticsearch-sql\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95fc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/NLPchina/elasticsearch-sql\"}},\"updates\":{\"snippets\":[{\"icon\":\"DESCRIPTION\",\"message\":\"elasticsearch-sql \u5982\u4f55\u5904\u7406\u6df1\u5206\u9875\u95ee\u9898\uff0c \u672c\u8eab\u652f\u6301\u5417\uff1f (#659)\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/NLPchina/elasticsearch-sql/issues/659\"}}}. ",
    "Zhangyufei123": "explain \u4e2d\u4e3a \n{\n    \"from\": 0,\n    \"size\": 200\n}\n\u5e94\u8be5\u662f\u6709\u95ee\u9898\u7684\uff0c\u80fd\u7ed9\u51fa\u6b63\u786e\u7684explain\u5417. ",
    "ggzone": "Help me.How to resolve this problem?\nhttp://xxxx:9200/_sql?sql=select * from my_date1 limit 10\n{\n  \"took\": 1,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 5,\n    \"successful\": 5,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": 3,\n    \"max_score\": 1,\n    \"hits\": [\n      {\n        \"_index\": \"my_date1\",\n        \"_type\": \"ty\",\n        \"_id\": \"2\",\n        \"_score\": 1,\n        \"_source\": {\n          \"date\": \"2015-01-01T12:10:30Z\"\n        }\n      },\n      {\n        \"_index\": \"my_date1\",\n        \"_type\": \"ty\",\n        \"_id\": \"1\",\n        \"_score\": 1,\n        \"_source\": {\n          \"date\": \"2015-01-01\"\n        }\n      },\n      {\n        \"_index\": \"my_date1\",\n        \"_type\": \"ty\",\n        \"_id\": \"3\",\n        \"_score\": 1,\n        \"_source\": {\n          \"date\": 1420070400001\n        }\n      }\n    ]\n  }\n}\nquery:\nhttp://xxxx:9200/_sql?sql=select date_format(date,'%Y-%m-%d %H') as dt from my_date1 limit 10\nResponse:\n{\n  \"took\": 8,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 5,\n    \"successful\": 2,\n    \"skipped\": 0,\n    \"failed\": 3,\n    \"failures\": [\n      {\n        \"shard\": 2,\n        \"index\": \"my_date1\",\n        \"node\": \"eN5Wc77sTUWWmkxG38tuhw\",\n        \"reason\": {\n          \"type\": \"script_exception\",\n          \"reason\": \"runtime error\",\n          \"script_stack\": [\n            \"date_format_924910292 = new SimpleDateFormat('%Y-%m-%d %H').format(new Date(doc['date'].value - 810006060));\",\n            \"                                                                                       ^---- HERE\"\n          ],\n          \"script\": \"def date_format_924910292 = new SimpleDateFormat('%Y-%m-%d %H').format(new Date(doc['date'].value - 810006060));return date_format_924910292;\",\n          \"lang\": \"painless\",\n          \"caused_by\": {\n            \"type\": \"class_cast_exception\",\n            \"reason\": \"class_cast_exception: Cannot apply [-] operation to types [org.joda.time.MutableDateTime] and [java.lang.Integer].\"\n          }\n        }\n      }\n    ]\n  },\n  \"hits\": {\n    \"total\": 3,\n    \"max_score\": 1,\n    \"hits\": []\n  }\n}\n. @shi-yuan Thanks for your work.. ",
    "m358807551": "\u597d\u7684\u3002\u8c22\u8c22\u3002. ",
    "fenian7788": "\nSELECT * FROM test WHERE q=multimatch(query='this is a test',fields='subject^3,message',analyzer='standard',type='best_fields',boost=1.0,slop=0,tie_breaker=0.3,operator='and')\n\n\n\u8fd9\u4e2afields\u53ea\u5141\u8bb8\u4f202\u4e2a\u5b57\u6bb5\uff0c\u6211\u4f20\u4e863\u4e2a\uff0c\u4f8b\u5982 fields='aa,bb,cc' \u88ab\u89e3\u6790\u6210\n\n \"fields\": [\n                    \"aa\",\n                    \"bb,cc\"\n                  ]\n. ",
    "trumanliu": "@shi-yuan \u5df2\u89e3\u51b3\uff0c\u975e\u5e38\u611f\u8c22\uff01. ",
    "JacksonMu": "@leonlu001 \u90a3\u8bf7\u95ee\u5bf9\u5e94\u7684sql\u600e\u4e48\u5199\uff1f\u4f8b\u5982select * from tableA where name like \"%leonlu%\", \u6211\u5e0c\u671b\u7684\u662fname\u5b57\u6bb5\u5982\u679c\u5305\u542bleonlu\u7684\u8bdd\uff0c\u5c31\u88ab\u641c\u7d22\u51fa\u6765\u4e86\uff0c\u5e76\u4e14\u5c06leonlu\u9ad8\u4eae\u3002. @shi-yuan \n\u6267\u884csql\u5982\u4e0b\uff1a\nselect HIGHLIGHT(title,pre_tags : [''], post_tags : ['']  ) FROM recom_item_property_20170927 where title like '%aa%'\n\u62a5\u9519\u5982\u4e0b\uff1a\n Error: {\"error\":{\"root_cause\":[{\"type\":\"parser_exception\",\"reason\":\"syntax error, expect RPAREN, actual VARIANT :\"}],\"type\":\"parser_exception\",\"reason\":\"syntax error, expect RPAREN, actual VARIANT :\"},\"status\":500}\n\u611f\u89c9\u662f\u5d4c\u5957\u51fd\u6570\u5bfc\u81f4\u7684\uff0c\u5bf9\u5e94\u7248\u672c\u662f2.3.4.0. @shi-yuan \u660e\u767d\u5566\uff0c\u662f\u8981\u653e\u5230\u6ce8\u91ca\u91cc\u9762\uff0c\u591a\u8c22\u4e86. @shi-yuan \u8fd8\u6709\u4e2a\u95ee\u9898\u5c31\u662f\uff0c\u6211\u53ea\u60f3\u5c06\u6211\u7684\u5339\u914d\u8bcd\u9ad8\u4eae\u600e\u4e48\u505a\u5462\uff0c\u4f8b\u5982\u4e0a\u9762sql\u4e2d\u53ea\u9ad8\u4eae\u7ed3\u679c\u4e2d\u7684\u201caa\u201d\uff0c\u90a3\u4e9boption\u6709\u4f7f\u7528\u8bf4\u660e\u4e48\uff1f. @shi-yuan \u6211\u5c06explain\u7684json\u653e\u5230head\u91cc\u9762\u6267\u884c\u662f\u53ef\u4ee5\u505a\u5230\u7684\uff0c\u4f46\u662f\u5728sql\u63d2\u4ef6\u91cc\u9762\u6267\u884c\u5c31\u5c06\u5168\u90e8\u7684\u90fd\u5305\u8d77\u6765\uff0c\u8fd9\u5c31\u5947\u602a\u4e86\u3002\u96be\u9053sql\u6267\u884c\u7684\u65f6\u5019\u4e0d\u662f\u6267\u884c\u7684explain\u4e4b\u540e\u7684sql\uff1f. \n\n@shi-yuan \u8fd9\u4e24\u4e2a\u7ed3\u679c\u5206\u522b\u662f\u6267\u884cSQL\u548cjson\u653e\u5230head\u91cc\u9762\u6267\u884c\u7684\u7ed3\u679c\uff0c\u5305\u7684\u8303\u56f4\u4e0d\u4e00\u6837. @shi-yuan \u4e0a\u9762\u7ea2\u8272\u7684\u662f\u6267\u884cSQL\u7684\u7ed3\u679c\uff0c\u4e0b\u9762\u9ed1\u8272\u7684\u662fhead\u6267\u884c\u7684\u7ed3\u679c\uff0c\u6211\u4eec\u671f\u671b\u4e0b\u9762\u8fd9\u79cd\uff0c\u901a\u8fc7SQL\u80fd\u5b9e\u73b0\u4e48\uff1f. @shi-yuan \u54b1\u4eec\u7684\u7248\u672c\u4e0d\u4e00\u81f4\uff0c\u6211\u7528\u7684\u662f2.3.4\uff08ES\u4e5f\u662f\u8fd9\u4e2a\u7248\u672c\uff09\uff0c\u60a8\u7684\u6bd4\u8f83\u65b0. ",
    "rjm1990": "\u5565\u60c5\u51b5. \u4e07\u5206\u611f\u8c22 \uff01\uff01\uff01\uff01\uff01\uff01\uff01. ",
    "JinCheng-Huang": "@shi-yuan \n\u6211\u4f7f\u7528\u4f60\u7ed9\u7684\u4f8b\u5b50\u53bb\u505acase when,\u5982\u4e0b\uff1a\nSELECT *,\n(case \n  when floor(overdue_level) = 2 then 'A' \n  when floor(overdue_level) < 2 then 'b'\n  when floor(overdue_level) > 2 then 'c'\n  else 'd' end) AS bee\nFROM table_a\nWHERE overdue_level is not missing\nLIMIT 1000\n\u6267\u884c\u540e\u51fa\u73b0\u5982\u4e0b\u9519\u8bef\uff1a\n{\n    \"error\": {\n        \"root_cause\": [{\n            \"type\": \"script_exception\",\n            \"reason\": \"compile error\",\n            \"script_stack\": [\"if((def floor_1301571636 = Math.f ...\", \" ^---- HERE\"],\n            \"script\": \"if((def floor_1301571636 = Math.floor(doc['overdue_level'].value);floor_1301571636 == 2)){'A'} else if((def floor_1736438494 = Math.floor(doc['overdue_level'].value);floor_1736438494 < 2)){'b'} else if((def floor_1870172313 = Math.floor(doc['overdue_level'].value);floor_1870172313 > 2)){'c'} else {'d'}\",\n            \"lang\": \"painless\"\n        }],\n        \"type\": \"search_phase_execution_exception\",\n        \"reason\": \"all shards failed\",\n        \"phase\": \"query_fetch\",\n        \"grouped\": true,\n        \"failed_shards\": [{\n            \"shard\": 0,\n            \"index\": \"table_a\",\n            \"node\": \"aN3h2t_CQyGJ1UFEuHrsYg\",\n            \"reason\": {\n                \"type\": \"script_exception\",\n                \"reason\": \"compile error\",\n                \"caused_by\": {\n                    \"type\": \"illegal_argument_exception\",\n                    \"reason\": \"invalid sequence of tokens near ['floor_1301571636'].\",\n                    \"caused_by\": {\n                        \"type\": \"no_viable_alt_exception\",\n                        \"reason\": \"no_viable_alt_exception: null\"\n                    }\n                },\n                \"script_stack\": [\"if((def floor_1301571636 = Math.f ...\", \" ^---- HERE\"],\n                \"script\": \"if((def floor_1301571636 = Math.floor(doc['overdue_level'].value);floor_1301571636 == 2)){'A'} else if((def floor_1736438494 = Math.floor(doc['overdue_level'].value);floor_1736438494 < 2)){'b'} else if((def floor_1870172313 = Math.floor(doc['overdue_level'].value);floor_1870172313 > 2)){'c'} else {'d'}\",\n                \"lang\": \"painless\"\n            }\n        }],\n        \"caused_by\": {\n            \"type\": \"script_exception\",\n            \"reason\": \"compile error\",\n            \"caused_by\": {\n                \"type\": \"illegal_argument_exception\",\n                \"reason\": \"invalid sequence of tokens near ['floor_1301571636'].\",\n                \"caused_by\": {\n                    \"type\": \"no_viable_alt_exception\",\n                    \"reason\": \"no_viable_alt_exception: null\"\n                }\n            },\n            \"script_stack\": [\"if((def floor_1301571636 = Math.f ...\", \" ^---- HERE\"],\n            \"script\": \"if((def floor_1301571636 = Math.floor(doc['overdue_level'].value);floor_1301571636 == 2)){'A'} else if((def floor_1736438494 = Math.floor(doc['overdue_level'].value);floor_1736438494 < 2)){'b'} else if((def floor_1870172313 = Math.floor(doc['overdue_level'].value);floor_1870172313 > 2)){'c'} else {'d'}\",\n            \"lang\": \"painless\"\n        }\n    },\n    \"status\": 500\n}. @shi-yuan. ",
    "l786170309": "\u55ef\uff0cyear\u662ftext\u7c7b\u578b\uff0c\u5df2\u7ecf\u5f00\u542ffielddata\u4e86\uff0c\u73b0\u5728\u597d\u4f7f\u4e86\uff0c\u591a\u8c22\uff01. \u6211\u53c8\u6709\u53e6\u4e00\u4e2a\u95ee\u9898\u4e86\uff1a\n\u67e5\u8be2\u8bed\u53e5\uff1a\n\n_explain\u7ed3\u679c\uff1a\n\nGROUP BY\u67e5\u8be2\u7ed3\u679c\u6570\u636e\u5c11\u4e86\uff0c\u53ea\u670910\u6761\u6570\u636e\uff0c\u539f\u672c\u5e94\u8be5\u662f4071\u6761\u7ed3\u679c\u3002aggregations\u91cc\u7684\u4e24\u4e2asize\u662f\u56fa\u5b9a\u7684\u4e48\uff1f\u628a\u8fd9\u4e24\u4e2asize\u6539\u5927\u4e00\u4e9b\u540e\uff0c GROUP BY\u7ed3\u679c\u624d\u662f\u6b63\u786e\u7684-4071\u6761\u3002\n. @shi-yuan . \n\u55ef\uff0c\u660e\u767d\u4e86. ",
    "LinkQiao": "\u8fd9\u79cdsql\u7684\u65b9\u5f0f\u76ee\u524d\u652f\u6301\u5417\uff1f @shi-yuan \n\u6709\u8ba1\u5212\u652f\u6301\u4ee5\u4e0b\u5417\uff1f. ",
    "tbbrave": "\u90a3\u6211\u4eec\u6709\u6ca1\u6709\u8ba1\u5212\u652f\u6301\u4e00\u4e0b= =\n\u6211\u53ef\u4ee5\u6284aggregation\u5b9e\u73b0\u8bd5\u8bd5. @shi-yuan . ",
    "8plat": "\u8bf7\u95ee\u4e0b   USE_SCROLL(100,10000) \u4e2d\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4ee3\u8868\u7684 \u662f \u65f6\u95f4\u5417 \uff1f. ",
    "iweisi": "it's ok\uff0cthnaks.. try the sql URLEncoder. ",
    "GoodbyeCode": "\u5514 \u7b26\u53f7\u94fe\u63a5\u8bbe\u4e86\u4e0d\u77e5\u9053\u4e0b\u6b21\u91cd\u542f \u7ba1\u7528. ",
    "phypor": "\u4e0d\u597d\u610f\u601d\uff0c\u6211\u8fd9\u8fb9\u8bbe\u7f6e\u4e86\u5206\u8bcd\uff0c\u81ea\u52a8\u5206\u8bcd\u4e86\u6a2a\u6760\u548c\u7a7a\u683c\u4e86\uff0c\u73b0\u5728\u6ca1\u95ee\u9898\u4e86\u3002 @shi-yuan \u611f\u8c22\u56de\u590d\u3002. \u53ef\u4ee5\u7684\uff0c\u8fdf\u70b9\u4e00\u70b9\u53d1\u7ed9\u4f60\u3002. ",
    "miaojianxin": "thank you \uff0cthat'ok. ",
    "tinh1115": "@shi-yuan : which type should I use to have the correct result (0.003) to be returned if currently the field type is \"float\"?\nis it double or something else?. @shi-yuan : I just had a quick test with below scenario:\n- field1 and field2 are float\n- running an aggs as:\n\"aggs\": {\n    \"sum_field_1\": {\n      \"sum\": {\n        \"field\": \"field1\"\n      }\n    },\n    \"sum_field_2\": {\n      \"sum\": {\n        \"field\": \"field2\"\n      }\n    }\n}\nthe result for sum_field_1 and sum_field_2 are double (0.00300000001234), it's not 0.003.\nbased on the answer here: https://github.com/elastic/elasticsearch/issues/9850 , I think the float value was parsed to double and return as double.\nIn my case, I changed the field type for field1 and field2 to double and I got correct result.\nSo, I think the field type should be \"double\" to get expecting result 0.003\n. ",
    "zhenglu696": "@shi-yuan \u8f9b\u82e6\u770b\u4e00\u4e0b\uff1f. ",
    "bolodanta": "Connection connection = dds.getConnection(1000L);\n\u4e0d\u62a5\u9519\u5361\u4f4f\u662f\u56e0\u4e3a\u6ca1\u6709\u8bbe\u7f6etimeout\u53c2\u6570\uff0c\u4f46\u8bbe\u7f6e\u4e86\u5c31\u4f1a\u62a5\u4e0b\u9762\u9519\u8bef@shi-yuan\uff1a\ncom.alibaba.druid.pool.GetConnectionTimeoutException: wait millis 1001, active 0, maxActive 8\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnectionInternal(ElasticSearchDruidDataSource.java:1053)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnectionDirect(ElasticSearchDruidDataSource.java:917)\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.getConnection(ElasticSearchDruidDataSource.java:898)\n    at com.vansight.api.ESSqlJDBCTests.testJDBC(ESSqlJDBCTests.java:24)\n    at com.vansight.api.EsSqlTest.main(EsSqlTest.java:9)\n. ",
    "belerophon": "@shi-yuan yeah, that's the standard way to solve this with elasticsearch. However (and I should've mentioned this on the issue), I am forced to use standard SQL syntax. My application generates some standard subset of the SQL syntax and I am using it to generate queries on different backends. Elasticsearch is one of those backends.\nThoughts?. ",
    "awm96": "i see the source code, range no way to set alias -_-|||. ",
    "mhsankar": "i have a solution to use having in elastisearch.\nbut who can convert this code into elastic SQL Plugin format?\nanswer link. when do you think add bucket_selector in SQL Plugin?. thanks @shi-yuan \nwhen do you think add to plugin?. what is difference between q=query('field:search')\nand field=matchQuery('quick brown fox')?\nanother question: how to use boost in  q=query('field:search'). How can use operator or minimum_should_match in query?\nHow can see generated query by this plugin?\n. and How can see generated query by this plugin?. Thank you @shi-yuan \nanother question.\nis there any way write elastic query and it convert to sql format query?. i'm using elastic version 6.2.4\nhow can use operator in this version?\nhow can update my elastic sql plugin?. what do you mean local package?\nwhat am i do?\nwhen i clone source code how replace with elasticsearch-sql-x.x.x.x.jar?. Hi @shi-yuan \ni download this  file\nrun with \"Intellj Idea\".\nwhen apply this change it needed previous changes.\ni must get all changes after release \"ElasticSearch SQL Plugin 6.2.4\" . it is a problem.\nsome feature added in new version of elasticsearch.\nhow can ignore all this new elastic feature?\nhow can update changes without update elasticsearch version in \"pom.xml\"?. ",
    "ibc789": "\u4ec0\u4e48\u65f6\u5019 \u53ef\u4ee5\u652f\u6301 bucket_selector\uff1f. \u8fd9\u4e2abug\u8fd8\u4fee\u6539\u4e86\uff1f. ",
    "developer-devPHP": "This issue still exists, even if using mater branch. @shi-yuan sorry, currently it is working for me too.\nThank you so much for quick reply and one more time sorry for wrong alert.. @shi-yuan Can we also update specific branch (elastic6.3.1)?. As master is changed time by time (always latest version). Fixes not in tag 6.3.1.0\nSo I will suggest 2 option.\n1 Push latest version to specific branch (in this case it is elastic6.3.1)\n2. Create new Tag 6.3.1.1\nFor example if elastic will have new version like 6.4 or any other and anyone would like to use 6.3, they could have the latest workable version of 6.3 (in current case it is 6.3.1.1). @shi-yuan sorry, but do you have any estimation, when this future could be exists? \nThis will be very useful future.. any roughly estimation?. Have the following error, when running\n sql \nDELETE /*! CONFLICTS(proceed) */ FROM index LIMIT 100 \nquery or trying to run explain\njson\n{\n    \"error\": {\n        \"root_cause\": [\n            {\n                \"type\": \"parser_exception\",\n                \"reason\": \"syntax error\"\n            }\n        ],\n        \"type\": \"parser_exception\",\n        \"reason\": \"syntax error\"\n    },\n    \"status\": 500\n}. Is this hint support will be implemented nearest future?. @shi-yuan Here is the problem.\nWhen I am doing select like this\nsql\nSELECT filed FROM index  WHERE field_2 LIKE 'a_b%'\nIt's converted to a?b* which means any symbol and not _ so it is converetd _ symbold into ?\nBut in other symbols for example - it is ok \nif my query is \nsql\nSELECT filed FROM index  WHERE field_2 LIKE 'a-b%'\nIt is converted to a-b*.\nSo when you have a time please have a look why _ changed to ? when query with LIKE search\nThanks\n. Thank you, it is working.\nCan you please help one more thing?\nHow can we escape * and ? symbols? I tried standard backslash, but it is not working.\nLIKE a\\\\*b and same way LIKE a\\\\?b but it is not working and show all results between a and b. It is not working.\nHere is example. \nYou have 2 doc\n\nasd\na*d\n\nyour search query is\nsql\nselect filed from index where q=query('field_2:a\\\\*d')\nThis query result output all 2 docs and not only second one. I am using elastic search version 6.6.0, \nplugin version current master (commit c430207)\nin doc have data\n\nasd\na*d\n\nexecuting query \nsql\nselect filed from index where q=query('filed:a\\\\*d')\nresponse object\njson\n{\n    \"took\": 285,\n    \"timed_out\": false,\n    \"_shards\": {\n        \"total\": 4,\n        \"successful\": 4,\n        \"skipped\": 0,\n        \"failed\": 0\n    },\n    \"hits\": {\n        \"total\": 2,\n        \"max_score\": 0,\n        \"hits\": [\n            {\n                \"_index\": \"index\",\n                \"_type\": \"_doc\",\n                \"_id\": \"test_doc_1\",\n                \"_score\": 0,\n                \"_source\": {\n                    \"filed\": \"a*d\"\n                }\n            },\n            {\n                \"_index\": \"index\",\n                \"_type\": \"_doc\",\n                \"_id\": \"test_doc_2\",\n                \"_score\": 0,\n                \"_source\": {\n                    \"filed\": \"asd\"\n                }\n            }\n        ]\n    }\n}\nBut if it works it should return only data a*d\n. ",
    "bookup": "\u53ef\u4ee5\u8ddfingestgeo\u7684\u6a21\u5f0f\u4e00\u6837\uff0c\u7528geolite\u514d\u8d39\u6570\u636e\u5e93\uff0c\u63d0\u4f9b\u4e00\u4e2a\u501f\u53e3https://dev.maxmind.com/geoip/geoip2/geolite2/. ",
    "Yuanxiangz": "\u975e\u5e38\u611f\u8c22\uff0c\u6570\u7ec4\u5b57\u6bb5\u6211\u6ca1\u6709\u8bbe\u7f6emapping\uff0c\u6539\u6210keyword\u540e\u53ef\u4ee5\u641c\u51fa\u6765   \u591a\u8c22. ",
    "gpdream": "\u4e0a\u8ff0sql\u8fd4\u56de\u7684\u6570\u636e\u5927\u6982\u5982\u4e0b\n```\n{\"name\": {\n    \"buckets\": [{\n        \"code\": {\n        \"buckets\": [{\n                \"doc_count\": 19096,\n                \"COUNT(code)\": {\n                    \"value\": 19096\n                }\n            }\n        }]\n}]\n\n}\n```\n\u95ee\u9898\u5728\u4e8e\uff0c\u7b2c\u4e8c\u5c42code\u7684buckets\u603b\u662f\u88ablimit 10\uff0c\u5e94\u8be5\u5982\u4f55\u5199\u624d\u80fd\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u5462. \u5df2\u89e3\u51b3\uff0c\u4f7f\u7528`GROUP BY (name, terms('field'='code','size'=200,'alias'='code'))\u53ef\u8fbe\u5230\u9884\u671f\u6548\u679c. ",
    "yutaolife": "@shi-yuan , not working for me.....\nquery size is 0. \n. ",
    "Jiuyong": "\u600e\u4e48\u67e5\u4e0d\u51fa\uff1f\u597d\u6b79\u8bf4\u660e\u4e0b\u554a\uff0c\u4f60\u8fd9\u6837\u8ba9\u4eba\u5bb6\u600e\u4e48\u5e2e\u4f60\u770b\uff1f. \u4f60\u662f\u8bf4\u73b0\u5728\u6539\u597d\u4e86\u5417\uff1f\n\u8fd9\u4e2a\u6211\u4eec\u4e34\u65f6\u4fee\u590d\u7684\u65f6\u5019\uff0c\u5bfc\u81f4\u4e86\u66f4\u9ad8\u7ea7\u7684\u9519\u8bef\uff0c\u56e0\u6b64\u6ca1\u6562\u63d0PR\u3002. \u55ef\uff0c\u770b\u4e86\uff0c\u4e0d\u8fc7\u5728\u8fd9\u91cc\u63d0\u4ea4\u4e4b\u540e\uff0c\u6211\u4eec\u53d1\u73b0\u4e86\u66f4\u6df1\u5c42\u6b21\u7684\u884d\u751fbug\uff0c\u6240\u4ee5\u8fd9\u4e2aissuse\u6682\u65f6\u522b\u5173\uff0c\u7b49\u6211\u5c06\u540c\u4e00\u4e2a\u95ee\u9898\u9020\u6210\u7684\u5173\u8054bug\u90fd\u6d4b\u8bd5\u4e00\u4e0b\u518d\u56de\u62a5\u7ed9\u4f60\u3002. ",
    "neo0820": "@shi-yuan \u8c22\u8c22\uff0c\u53e6\u5916\u6709\u5d4c\u5957\u67e5\u8be2\u7684\u8ba1\u5212\u5417\uff1f\u5e94\u7528\u573a\u666f\u6bd4\u8f83\u5e7f\u6cdb\u3002. @shi-yuan \u975e\u5e38\u611f\u8c22\uff0c\u6211\u6539\u4e0b\u8bd5\u8bd5\u3002. @hexiaobing5880 \n\u81ea\u5df1\u5148\u5199\u4e86\u4e2aJDBC Driver\u6682\u65f6\u5148\u7528\u6709\u9700\u8981\u518d\u5b8c\u5584\uff0chttps://github.com/neo0820/elasticsearch-sql-JDBCDriver \n@shi-yuan \n\u4eceC#\u8f6c\u8fc7\u6765\u7684\uff0c\u6ca1\u505a\u8fc7java \u53c2\u8003\u4e00\u4e0b\u7f51\u4e0a\u522b\u4eba\u505a\u7684JDBC\uff0cDriver\u4e0d\u77e5\u9053\u8fd9\u6837\u5199\u662f\u5426\u5408\u7406\u3002\u5199\u4e86\u4e00\u4e2atest\u80fd\u8fde\u901a\u3002. ",
    "hexiaobing5880": "@neo0820 \u56e0\u6700\u65b0\u7248\u7684ES\u5185\u7f6e\u4e86SQL\u529f\u80fd\uff0c\u4f46\u662fSQL\u7279\u6027\u5e76\u4e0d\u662f\u5f88\u5b8c\u5168\u3002\u6240\u4ee5\u91c7\u7528\u6b64\u63d2\u4ef6\uff0c\u4f46\u662f\u9047\u89c1\u4e86\u548c\u4f60\u4e00\u6837\u7684\u95ee\u9898\uff0c\u60f3\u5bf9\u62a5\u8868\u8f6f\u4ef6\u914d\u7f6eES\u6570\u636e\u6e90\uff0c\u7ed3\u679c\u53d1\u73b0\u53ea\u80fd\u914d\u7f6ecom.alibaba.druid.mock.MockDriver\uff0c\u867d\u7136\u8fde\u63a5\u6210\u529f\u4e86\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u901a\u8fc7\u8fd9\u4e2a\u63d2\u4ef6\u8fdb\u884c\u89e3\u6790SQL\u3002\u8bf7\u95ee\u4f60\u89e3\u51b3\u4e86\u5417\uff1f. @neo0820 \u5341\u5206\u611f\u8c22\uff0c\u901a\u8fc7\u4f60\u63d0\u4f9b\u7684\u601d\u8def\uff0c\u8bd5\u7740\u5e94\u7528\u5230ES6.3.0\u4e0a\uff0c\u7ed3\u679c\u53d1\u73b0\u53ef\u4ee5\u5e94\u7528\u3002\u4e0d\u8fc7\uff0cES\u8bfb\u53d6\u5927\u6570\u636e\u91cf\u7684\u6570\u636e\u65f6\uff0c\u6709\u4e9b\u7f13\u6162\uff0c\u8bf7\u95ee\u4f60\u6709\u9047\u89c1\u8fc7\u6b64\u7c7b\u95ee\u9898\u5417\u3002. ",
    "fanjun1980": "@hexiaobing5880  \u4f7f\u7528DbVisualizer\u9700\u8981\u52a0\u5165\u54ea\u4e9bjar\uff0c\u6211\u8fd9\u91cc\u52a0\u4e86Driver\u8fd8\u662f\u62a5\u5404\u79cd\u627e\u4e0d\u5230\u7c7b\u3002. \u9700\u8981\u52a0\u5165\u54ea\u4e9bjar\uff0c\u6211\u8fd9\u91cc\u52a0\u4e86Driver\u8fd8\u662f\u62a5\u5404\u79cd\u627e\u4e0d\u5230\u7c7b\u3002. ",
    "flwcy": "```\n        String between_and = \"SELECT * FROM environmental_safety_inspection where virusApps <> ''\";\n    try {\n        SearchHits hits = ((SearchResponse)elasticUtil.getSearchRequestBuilder(between_and).get()).getHits();\n        System.out.println(hits.getTotalHits());\n        for(SearchHit hit:hits){\n            System.out.println(hit.getId());\n            System.out.println(hit.getSourceAsString());\n        }\n    } catch (SqlParseException e) {\n        e.printStackTrace();\n    } catch (SQLFeatureNotSupportedException e) {\n        e.printStackTrace();\n    }\n\n```\n\u8fd8\u662f\u5168\u90e8\u7684\u6570\u636e\uff0c\u6ca1\u6709\u751f\u6548. \u53ea\u80fd\u67e5\u8be2\u4e0d\u4e3a\u67d0\u4e2a\u503c\u7684\u7ed3\u679c\uff0c\u7a7a\u5b57\u7b26\u4e32\u6ca1\u6709\u751f\u6548. \u975e\u5e38\u611f\u8c22\uff0cSELECT * FROM environmental_safety_inspection where virusApps.keyword<> ''\u8fd9\u4e2a\u53ef\u4ee5\u751f\u6548\u4e86. ",
    "Tirsuro": "\u611f\u8c22\u56de\u7b54\uff1a\u8bf7\u95ee\u662f\u8fd9\u6837\u5417\uff1f\nproperties.put(\"xpack.security.user\", \"userName&password\");. \u6839\u636e\u60a8\u7ed9\u7684\u53c2\u8003\uff0c\u66f4\u6539\u4e86\u4ee3\u7801\uff0c\u4f46\u662fxpackTransport\u4e00\u76f4\u8fde\u63a5\u4e0d\u4e0aes\u3002\n\u8bf7\u95ee\u60a8\u53ef\u4ee5\u7ed9\u51fasql\u8f6cdsl\u7684\u65b9\u6cd5\u5417\uff1f \b. ",
    "Birdflying1005": "\u53ef\u5426\u7ed9\u4e00\u4e2a\u786e\u5207\u7684\u56de\u7b54\uff0c\u662f\u4e0d\u662f\u9700\u8981\u5728\u6bcf\u4e00\u4e2a\u8282\u70b9\u4e0b\u5b89\u88c5sql\u63d2\u4ef6\uff1f. @shi-yuan \u8c22\u8c22\u56de\u7b54\u3002\u8fd8\u60f3\u591a\u95ee\u4e00\u4e9b\uff0c \u6211\u662f\u4e0d\u662f\u9700\u8981\u660e\u786e\u7684\u5236\u5b9a\u8bbf\u95ee\u7684url , \u8fd8\u662f\u8bf4\u670d\u52a1\u7aef\u4f1a\u81ea\u52a8\u505a\u8d1f\u8f7d\uff1f. \u73b0\u5728 es 6.3  \u5df2\u7ecf\u5f00\u653e\u4e86 sql \u7684\u529f\u80fd\uff0c \u6211\u4eec\u8fd9\u9879\u76ee\u8fd8\u4f1a\u7ee7\u7eed\u505a\u4e0b\u53bb\u5417\uff1f. @shi-yuan \u53e6\u5916\u4e00\u4e2a\u95ee\u9898\uff0c\u7528\u8fd9\u4e2a\u63d2\u4ef6\u5bf9\u6807es\u7684rest \u63a5\u53e3\uff0c \u6027\u80fd\u6709\u591a\u5c11\u7684\u635f\u8017 \uff1f \u6211\u4eec\u6709\u6ca1\u6709\u6d4b\u8bd5\u548c\u6570\u636e\uff1f. @shi-yuan  \u6211\u8c03\u7814\u4e86\u4e00\u4e0b\u6700\u65b0\u76846.3.2\u7684 xpack/sql \u7684\u4f7f\u7528\u3002 \u53d1\u73b0\u67092\u4e2a\u95ee\u9898\u5f88\u96be\u53d7\n1. \u6ca1\u6709\u8fd4\u56de\u603b\u8bb0\u5f55\u6570\u76ee\n2.cursor\u662f\u5355\u5411\u6e38\u6807\uff0c\u53ea\u80fd\u7528\u4e00\u6b21\uff0c\u5982\u679c\u8df3\u9875\u9009\u62e9\u7684\u5316\uff0c \u9700\u8981\u5728\u5e94\u7528\u7aef\u8fde\u7eed\u7684\u81ea\u5df1\u5904\u7406cursor \u79fb\u52a8\uff0c \u5982\u679c\u6211\u5148\u7528translate\u628asql\u8f6c\u6362\u6210\u4e3adsl\uff0c \u53c8\u9700\u89812\u6b21\u8c03\u7528\uff5e  \u975e\u5e38\u4e0d\u65b9\u4fbf\n\u6240\u4ee5\uff0c \u6211\u89c9\u5f97\u8fd8\u662f\u4f60\u7684\u8fd9\u4e2a\u63d2\u4ef6\u7528\u8d77\u6765\u6bd4\u8f83\u8212\u670d. @shi-yuan \u6709\u4e00\u4e2a\u95ee\u9898\u60f3\u6c42\u6559\uff1a\n\u5982\u679c\u6211\u60f3\u7528\u4f60\u7684parser\u628asql \u8f6c\u5316\u6210dsl\uff0c \u4e0d\u8fdees server \u6709\u6ca1\u6709\u53ef\u80fd\uff1f. @shi-yuan \u8c22\u8c22\u4f60\u7684\u56de\u7b54\uff0c \u90a3\u6211\u600e\u6837\u4f7f\u7528\uff1f \u6709\u6ca1\u6709\u4ee3\u7801\u4f8b\u5b50\uff1f. ",
    "jackcloudmini": "@shi-yuan Could you give me a example for using scripted_metric?. @shi-yuan  select sum(band) as band, sum(time) as time, band/time from test. ",
    "songrd": "explain \u540e\u7684\u7ed3\u679c\n{\n    \"from\": 0,\n    \"size\": 10,\n    \"query\": {\n        \"bool\": {\n            \"filter\": [\n                {\n                    \"bool\": {\n                        \"must\": [\n                            {\n                                \"bool\": {\n                                    \"should\": [\n                                        {\n                                            \"wildcard\": {\n                                                \"news_title\": {\n                                                    \"wildcard\": \"\u4e09\u661f\",\n                                                    \"boost\": 1\n                                                }\n                                            }\n                                        },\n                                        {\n                                            \"wildcard\": {\n                                                \"search_tags\": {\n                                                    \"wildcard\": \"iphone\",\n                                                    \"boost\": 1\n                                                }\n                                            }\n                                        }\n                                    ],\n                                    \"adjust_pure_negative\": true,\n                                    \"boost\": 1\n                                }\n                            }\n                        ],\n                        \"adjust_pure_negative\": true,\n                        \"boost\": 1\n                    }\n                }\n            ],\n            \"adjust_pure_negative\": true,\n            \"boost\": 1\n        }\n    },\n    \"_source\": {\n        \"includes\": [\n            \"news_id\",\n            \"news_title\",\n            \"published_time\",\n            \"search_tags\"\n        ],\n        \"excludes\": []\n    },\n    \"sort\": [\n        {\n            \"published_time\": {\n                \"order\": \"desc\"\n            }\n        }\n    ]\n}. @shi-yuan \u662f\u554a\uff0c\u6211\u770b\u4e5f\u6ca1\u6709\u4e71\u7801\uff0c\u4f46\u662f\u4e2d\u6587\u67e5\u4e0d\u51fa\u7ed3\u679c\uff0c\u662f\u6211\u5c11\u4e86\u4ec0\u4e48\u4e1c\u897f\u5417\uff1f. ",
    "ranranxiaoya": "\u8bf7\u95ee\u540e\u7eed\u6709\u652f\u6301\u8ba1\u5212\u5417\uff1f. ",
    "onlyshow": "\u53ef\u4ee5\u6539\u6210 \u5168\u5c40\u6392\u5e8f\u5417\uff1f. ",
    "mzxjh": "\u597d\u7684\uff0c\u611f\u8c22\uff01. ",
    "hw1992": "@shi-yuan \u6211\u8fd8\u9700\u8981\u83b7\u53d6\u5230\u7b2c\u4e00\u4e2a\u7684 convId,estateId,estateName,estatePics,adminDivisionCode,tradingAreaId,buildYear,avgPrice,subwayInfo\u8fd9\u4e9b\u7ed3\u679c. \u8fd9\u4e2a\u9519\u8bef\u600e\u4e48\u6574. \n. `SELECT\n    a.[user] AS us,\nCOUNT (\nCASE    \n        WHEN CONVERT ( CHAR ( 10 ), kqtime, 108 ) > '08:30:00' THEN\n        CONVERT ( CHAR ( 10 ), kqtime, 108 ) \n    END \n    ) AS [c],\n\n    2 - COUNT (\n    CASE                \n            WHEN CONVERT ( CHAR ( 10 ), kqtime, 108 ) > '08:30:00' THEN\n            CONVERT ( CHAR ( 10 ), kqtime, 108 ) ELSE '-' \n        END \n        ) AS [w] \n    FROM\n        ( SELECT MIN ( kqtime ) AS kqtime, [user] \n        FROM tbl_kaoqin GROUP BY\n            [user], CONVERT ( CHAR ( 10 ), kqtime, 120 )) AS a \nGROUP BY [user]`.\n",
    "huansoo": "\u6211\u7528\u7684\u662f5.1.1\u7248\u672c\uff0c\u7528\u7684elasticsearch-sql \u63d2\u4ef6explain\u8fd8\u662f\u62a5\u9519\u7684\u3002\n\u987a\u4fbf\u8bf4\u4e0bElasticLexer.java\u4e2d\u7684\u7b2c80\u884cToken tok = keywods.getKeyword(stringVal);  \u8fd9\u4e2aToken tok = keywods.getKeyword(stringVal.toUpperCase);\u662f\u4e0d\u662f\u66f4\u597d\u554a\uff0c\u6211\u4eec\u76ee\u524d\u5c31\u662f\u56e0\u4e3a\u4f20\u7684\"like\"\u5173\u952e\u5b57\u662f\u5c0f\u5199\uff0c\u8e29\u4e86\u597d\u5927\u4e00\u4e2a\u5751. ",
    "suhuaguo": "\u4e86\u89e3\u3002\u662f\u56e0\u4e3a\u6027\u80fd\u5dee\u561b\uff1f. ",
    "xinlan": "SELECT * FROM index WHERE a=TERMS('\u4e2d\u6587')   \u8fd8\u662f\u67e5\u4e0d\u51fa\u6570\u636e\uff0c\nSELECT * FROM index WHERE a=TERMS('\u4e2d') \n\u548c\nSELECT * FROM index WHERE a=TERMS('\u6587') \u90fd\u53ef\u4ee5\u67e5\u51fa\u2018\u4e2d\u6587\u2019\u6570\u636e \n\u662f\u4e0d\u662f\u7ed9\u5206\u8bcd\u4e86\uff1f\u5982\u679c\u8bbe\u7f6e\u67e5\u8be2\u7684\u65f6\u5019\u4e0d\u5206\u8bcd?. group by \u540e\u9762\u591a\u4e2a\u5b57\u6bb5\u7684\u65f6\u5019\u6709\u6709bug\u5417  \u67e5\u8be2\u51fa\u7684\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5206\u7ec4\u6700\u591a\u53ea\u80fd10\u6761\u8bb0\u5f55\uff1f. ",
    "zeigernz": "Thank you. That resolves the problem.\nHow does this test pass though?\nhttps://github.com/NLPchina/elasticsearch-sql/blob/38ad264f2838a7d3c92a41ceeaeb5cd8ce50adb3/src/test/java/org/nlpcn/es4sql/QueryTest.java#L65\nIt (and other similar tests) should be updated and some documentation added around this.. Thank you. That resolves the problem.\nThe plugin documentation should probably mention this.. ",
    "FeiLiu0519": "\u7b97\u662f\u5427\u3002\u6211\u7684es\u7248\u672c\u662f2.4.5\n\u7136\u540e\u4e0b\u8f7d\u4e86\u6e90\u7801\u8ddf\u8e2a\u8c03\u8bd5  \u53d1\u73b0\u7ee7\u627f\u963f\u91cc\u8fde\u63a5\u7684\u5b50\u7c7b\u591a\u4e86\u4e00\u4e2acolumn\u5c5e\u6027  \u540e\u6765\u6211\u628a\u6e90\u7801\u6539\u4e86  \u91cd\u65b0\u5c01\u4e86\u4e0b\u5305\ud83c\udf1a. \u611f\u8c22\uff0c\u68c0\u67e5\u4e86\u4e0b  \u53d1\u73b0\u6211\u7684es\u6ca1\u6709\u914d\u7f6escript.engine.groovy.inline.search: on. ",
    "fengme": "6.2.3. ELK\u5168\u5957\u76846.2.3\n\u6211\u60f3\u5728\u8fd9\u4e2a\u73af\u8282\u4e0b\u4f53\u9a8c\u4e0b\u4f60\u4eec\u7684UI. http://essql.nlpcn.org/\n\u5c31\u50cf\u8fd9\u91cc\u7684UI. \u9a8c\u8bc1\u53ef\u884c\uff0c\u4e4b\u524d\u53ea\u770b\u4e86\u9996\u9875\u4e0a\u7684\u6587\u6863\uff0c\u591a\u8c22\uff01. \u8fd9\u4e2a\u5de5\u5177\u4e0d\u9519\uff0c\u4f69\u670d\u5f00\u53d1\u56e2\u961f.  Error:\"<!DOCTYPE html>\\n\\n\\n\\nError\\n\\n\\n \\n\\n\\n\"\n\u676f\u5177\u5728UI\u4e0a\u6267\u884cSQL\u65f6\u63d0\u793a\u8fd9\u4e2a\u9519\u8bef\uff0c\u8bf7\u6559\u8be5\u600e\u4e48\u529e\uff1f\n\n. ",
    "fengnex": "\u8bb0\u5f97\u914d\u7f6e\u4e86\n\u56e0\u4e3a\u8bbf\u95ee_sql\u3001_sql/_explain\u662f\u6b63\u5e38\u7684\uff0c\u6240\u4ee5\u624d\u60f3\u770b\u770bUI. \u5c31\u662f\u6307\u5b9a\u6b63\u786e\u7684SQL\u770b\u67e5\u8be2\u7ed3\u679c\u4ee5\u53ca\u7ffb\u8bd1\u4e86\u7684painless\u6b63\u5e38\uff0c\u4f46\u662f\u65e0\u6cd5\u901a\u8fc7UI\u63d0\u4ea4\u6267\u884cSQL. @shi-yuan \u770b\u5230\u540e\u70e6\u8bf7\u56de\u590d\u4e0b\uff0c\u8c22\u8c22. \u65e5\u5fd7\u8981\u7b49\u7b49\uff0c\u6211\u73b0\u5728\u62ff\u4e0d\u5230\u65e5\u5fd7\uff0c\u5230\u65f6\u5019\u4f1a\u6211\u770b\u770b\n\u7528\u7684\u5305\u662f\u4ece\u9996\u9875\u4e0a\u6307\u5b9a\u7684\u94fe\u63a5\u4e0b\u8f7d\u7684\uff1a\nhttps://github.com/NLPchina/elasticsearch-sql/releases/download/5.4.1.0/es-sql-site-standalone.zip. ",
    "leolv123": "field is not term('10')  \u8fd9\u79cd\u5199\u6cd5\u4e5f\u4e0d\u884c. \u8bf7\u95ee\u662f\u90a3\u4e2a\u7248\u672c\u652f\u6301\u7684\uff0c\u6211\u75286.1.3\u4e0d\u884c. ",
    "meijies": "I think I can reference to https://github.com/Anchormen/sql4es. more completable implemete of jdbc interface.. ",
    "danchaobing": "\u7248\u672c\u662f6.3.2\uff0c\u770b\u7740\u50cf\u662f%\u540e\u9762\u7684\u5355\u5f15\u53f7\u88ab\u8f6c\u4e49\u4e86. \u53e6\u5916\u60f3\u95ee\u4e0b\uff0c\u5728java\u4e2d\u600e\u4e48\u548celasticsearch\u96c6\u6210\u4f7f\u7528. \u54c8\uff0c\u539f\u6765\u662f\u6253\u6210jar\u5305\u5c31\u53ef\u4ee5\u4e86. ",
    "deadjoker": "\u4e0d\u77e5\u9053\u662f\u4ec0\u4e48\u95ee\u9898\uff0c\u867d\u7136\u6ca1\u62a5\u9519\uff0c\u4f46\u5c31\u662f\u663e\u793a\u4e0d\u51fa\u7ed3\u679c\uff0cexplain\u548csearch\u90fd\u4f1a\u8fd4\u56de\u56fe\u91cc\u7684\u7ed3\u679c. \u770b\u4e86\u4e0bconsole\uff0c\u6709\u4e2atypeerror\u7684\u62a5\u9519\n\n. \u901a\u8fc7\u547d\u4ee4\u884c\u6267\u884c \ncurl -s -u elastic:abcdefg -H \"Content-Type: application/json\" -XPOST 'http://10.211.121.44:9200/_sql' -d 'select * from nginx_logs/access limit 10' \n\u8fd4\u56de\u662f\u6b63\u5e38\u7684\u3002\n\u731c\u60f3\u662fes\u5730\u5740\u914d\u7f6e\u53ef\u80fd\u9519\u4e86\uff0c\u60f3\u786e\u8ba4\u4e0b\uff0c\u53f3\u4e0a\u89d2\u7684\u5730\u5740\uff0c\u6211\u5199\u7684\u662f\n http://10.211.121.44:8080/?username=elastic&password=abcdefg&base_uri=http://10.211.121.44:9200 \n\u8fd9\u4e2a\u662f\u6b63\u786e\u7684\u561b. \u641e\u5b9a\u4e86\uff0c\u9875\u9762\u7ec8\u4e8e\u663e\u793a\u6b63\u5e38\u4e86 \u8c22\u8c22. \u9875\u9762\u663e\u793a\u6b63\u5e38\u4e86\uff0c\u8981\u600e\u6837\u624d\u80fd\u663e\u793a\u7ed3\u679c\u800c\u4e0d\u662f\u6570\u91cf\u5462\uff1f\n\n. \u4e0d\u597d\u610f\u601d\u518d\u95ee\u4e0b\uff0csearch\u663e\u793a\u62a5\u9519\uff0c\u8fd9\u4e2a\u662f\u6211\u5728\u54ea\u91cc\u914d\u7f6e\u9519\u4e86\n\n. \n\n\u8fd9\u4e2a\u914d\u7f6e\u6ca1\u95ee\u9898\uff0cexplain\u53ef\u4ee5\u663e\u793a\u3002\u8fd9\u4e2a\u95ee\u9898\u662f\u56e0\u4e3a\u6211es\u8fd9\u8fb9\u914d\u7f6e\u6709\u95ee\u9898\u4e48. \u89e3\u51b3\u4e86\uff0c\u662f\u914d\u7f6e\u7684\u95ee\u9898\uff0c\u6539\u8fc7\u5c31\u80fd\u663e\u793a\u7ed3\u679c\u4e86 \u8c22\u8c22. ",
    "matthew0701": "\u8bd5\u4e86\u4e0b\uff0c\u652f\u6301SELECT * FROM cluster_one:twitter,twitter\u8fd9\u79cd\u6a21\u5f0f\u3002\n\u8bf7\u95ee\uff1a\n\u6bd4\u5982\u6211\u6709\u4e09\u4e2a\u96c6\u7fa4\u3002cluster_one, cluster_two, cluster_three\u3002\u6211\u60f3\u67e5\u51fa\u5206\u5e03\u5728\u8fd9\u4e09\u4e2a\u96c6\u7fa4\u4e0a\u7684\u540c\u4e00\u4e2a\u547d\u540d\u7684\u7d22\u5f15\u6570\u636e\uff0c\u8c8c\u4f3c\u4e0d\u652f\u6301SELECT * FROM *:twitter,twitter \u8fd9\u79cd\u901a\u914d\u7b26\u5199\u6cd5\u3002\u8fd9\u4e2a\u5982\u4f55\u5b9e\u73b0\uff1f. \u8bd5\u4e86\u4e0b\uff0c\u652f\u6301\u901a\u914d\u7b26\u3002\u4f46\u662f\u4e0d\u652f\u6301\u901a\u914d\u7b26\u5f00\u5934\u3002\n\u4e09\u4e2a\u96c6\u7fa4\u3002cluster_one, cluster_two, cluster_three\n\u652f\u6301SELECT * FROM cluster_:twitter\n\u4e0d\u652f\u6301 SELECT * FROM :twitter. ",
    "zzcoding": "close. \u55ef \u8fd9\u4e2a\u9879\u76ee\u8fd8\u662f\u5f88\u4e0d\u9519\u7684\u5462\uff0c \u5728\u7528\u7684\u8fc7\u7a0b\u4e2d\u4e5f\u53d1\u73b0\u4e86\u4e00\u4e9bbug\uff0c\u540e\u7eed\u6709\u65f6\u95f4\u4f1a\u7ee7\u7eedfix\u3002. ",
    "ChunboLI": "\u67e5\u5230\u4e86\uff0c\u6e90\u7801\u6709post\u7684\u76f8\u5173\u5b9e\u73b0\u3002\u652f\u6301post\u8bf7\u6c42\u3002\u5177\u4f53\u65b9\u5f0f\uff1acurl -X POST \"localhost:9200/_sql?pretty\" -H \"Content-Type: application/json\" -d\"SELECT * FROM test LIMIT 100\"\n. ",
    "frontgoo": "\n\u4e2a\u4eba\u5efa\u8bae\u8fd8\u662f\u5c3d\u91cf\u4e0d\u8981\u8d70join\uff0c\u628a\u5b57\u6bb5\u90fd\u878d\u5408\u5230\u4e00\u4e2aindex\n\n\u55ef\u55ef \u6709\u8c03\u7814\u8fc7\u7c7b\u4f3c\u7684\u65b9\u6848\uff0c\u4e00\u79cd\u662f\u6240\u6709\u7684\u6587\u6863\u6c47\u603b\u5230\u540c\u4e00\u4e2aINDEX\uff0c\u4e00\u79cd\u662f\u5efa\u7acb\u591a\u4e2a\u7d22\u5f15\u3002\n\u4f46\u662f\u6587\u6863\u90fd\u653e\u5728\u4e00\u8d77\u4e5f\u4f1a\u5e26\u6765\u4e00\u4e9b\u95ee\u9898\uff0c\u67e5\u8be2\u5230\u65f6\u65b9\u4fbf\u4e86\uff0c\u4f46\u662f\u6587\u6863\u66f4\u65b0\u5f15\u8d77\u7684\u7d22\u5f15\u91cd\u5efa\u5c31\u6709\u70b9\u5f97\u4e0d\u507f\u5931\u4e86\u3010\u53ef\u80fd\u53ea\u662f\u4e00\u5c0f\u5757\u6570\u636e\u7684\u53d8\u5316\u3011\u3002\u6211\u4eec\u76ee\u524d\u7684\u6587\u6863\u8bbe\u8ba1\u6bd4\u8f83\u5927\uff0c\u4e5f\u5728\u7ea0\u7ed3\u4e24\u4e2a\u65b9\u6848\u9009\u54ea\u79cd\u3002. \u6211\u4eec\u7684\u573a\u666f\u662f\u8981\u7528es\u57fa\u4e8e\u6587\u6863\u5b57\u6bb5\u505a\u4e9b\u89c4\u5219\uff0c\u5b57\u6bb5\u8fd8\u662f\u8981\u4fdd\u8bc1\u591a\u4e00\u70b9\uff0c\u4e0d\u7136\u89c4\u5219\u8c03\u6574\u7684\u7075\u6d3b\u6027\u4f1a\u5dee\u4e00\u70b9. > \u597d\u5427\u3002\u3002\u3002 \ud83d\ude13\n\u6211\u4eec\u627e\u5230\u4e86\u65b0\u7684\u65b9\u6848\uff1a\n\u56fe\u6570\u636e\u5e93+ES, \u5173\u7cfb\u7c7b\u7684\u4ea4\u7ed9\u56fe\u6570\u636e\u5e93\uff0c\u5355\u7ef4\u5ea6\u7684\u6570\u636e\u5339\u914d\u4ea4\u7ed9es. ",
    "QingMingXia": "\u8bf7\u95ee\u697c\u4e3b\uff0c\u8fd9\u4e2a\u9519\u8bef\u662f\u5305\u51b2\u7a81\u4e86\u5417\uff0c\u8bd5\u4e86\u5f88\u591a\u79cd\u4ecd\u7136\u65e0\u6cd5\u89e3\u51b3. \u662f\u7684\uff0c\u5347\u7ea7\u7684\u65f6\u5019\u62a5\u9519 \u8fd9\u4e2a\u662f\u6211\u7684\u65b0\u7684\u4f9d\u8d56\n\n. \u7ed3\u679c\u90fd\u53d6\u51fa\u6765\u4e86\uff0c\u5c31\u662f\u83b7\u53d6\u7ed3\u679c\u7684\u65f6\u5019\u89e3\u6790\u51fa\u9519. \u6211\u4eeces\u670d\u52a1\u5668\u7684\u7248\u672c\u662f5.4.2  \uff1bes-sql\u6211\u8bd5\u4e865.1.2.0 \u548c5.5.2.0 \u5176\u4ed6\u7684\u4e09\u4e2a\u90fd\u662f5.4.2 \u4e5f\u4e0d\u884c\n List aggregationList = aggregations.asList();  \u4e3b\u8981\u662f\u8fd9\u53e5 expected class  find interface\uff1b. \u6211\u76ee\u524d\u65e0\u6cd5\u8bbf\u95ee\u6211\u53f8\u7684\u670d\u52a1\u5668\uff0c\u7b49\u793c\u62dc\u4e00\u6211\u518d\u53d1\u4e00\u4e0b\uff1b\u7528\u7684\u963f\u91cc\u7684druid. \u6211\u8c03\u8bd5\u7684\uff0csum\u7684\u503c\u90fd\u67e5\u51fa\u6765\u4e86\uff0c\u5c31\u662f\u5728\u89e3\u6790\u7684\u65f6\u5019\uff0c\u89e3\u6790\u51fa\u9519. \u6253\u53055.4.2 ok\u4e86. > \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff1f\u8fd9\u4e2a\u5728\u65b0\u7248\u672c\u91cc\u6709\u4fee\u590d\u7684\n2.4.3\u7248\u672c.  \n        properties.put(\"maxIdle\", \"3\");\n        properties.put(\"maxWait\",\"5000\");\n        properties.put(\"maxActive\", \"10\");\n2.4.3\u7248\u672c\u7684\u4e0a\u9762\u7684\u53c2\u6570\u5fc5\u987b\u8981\u8bbe\u7f6e\u4e00\u4e0b\u5417 \u4e0d\u8bbe\u7f6e\u597d\u50cf\u51fa\u73b0\u95ee\u9898\nElasticSearchDruidDataSourceFactory.createDataSource(properties);\n. \u8bbe\u7f6e\u4e86\u8fd9\u4e9bproperty\u4e4b\u540e\uff0c\u53ea\u80fd\u67e5\u8be2\u4e00\u6b21\uff0c\u518d\u67e5\u8be2\u7684\n   \u8fd9\u91cc\u4f1a\u62a5\u9519\n. \n\n. > \u7528\u7684\u54ea\u4e2a\u7248\u672c\uff1f\u8fd9\u4e2a\u5728\u65b0\u7248\u672c\u91cc\u6709\u4fee\u590d\u7684\n\n\u4e4b\u524d\u662f\u4e00\u4e2aconnection\u4f1a\u6709\u4e00\u4e2aclient\uff0c\u73b0\u5728\u662f\u4e00\u4e2adatasource\u4e00\u4e2aclient\n\nconnection\u5173\u95ed\u4e86 thread \u8fd8\u5728. \n. \u5168\u90e8\u90fd\u662f\u5b88\u62a4\u7ebf\u7a0b. > \u53ef\u4ee5\u540c\u6b65\u4e0bmaster\u7684\u4ee3\u7801\uff0c\u66f4\u65b0\u4e0b\n\u4f60\u7684\u610f\u601d\u662f\u7528es-sql 6\u53bb\u66ff\u6362es-sql2.3.1.0\u5417. > \u4e0d\u662f\u7684\uff0ccom.alibaba.druid.pool\uff0c\u8fd9\u4e2a\u5305\u4e0b\u7684\u4ee3\u7801\uff0c\u540c\u6b65\u66f4\u65b0\u4e0b\n\u7528\u4e861.1.12 \u7248\u672c\u6ca1\u4ec0\u4e48\u7528\n\n. \u6700\u8fd1\u6709\u66f4\u65b0\u5417. > \u4fee\u6539\u4e00\u7248\uff0c\u672c\u5730\u6253\u4e2a\u5305\u5427\n\u662f\u4e0d\u662f\u4e3b\u8981\u662fcloseStatus\u5c5e\u6027 \u4ee5\u53caclose\u65b9\u6cd5\u548cisClose\u65b9\u6cd5\u4f1a\u5f71\u54cd\uff0c\u6211\u4eec\u73b0\u5728\u5347\u7ea7\u52305.4.2.0 . > \u4fee\u6539\u4e00\u7248\uff0c\u672c\u5730\u6253\u4e2a\u5305\u5427\n\u6211\u4fee\u6539\u4e865.4.2.0\u7684 \u6ca1\u4ec0\u4e48\u4f5c\u7528\n\n. > \u6700\u4e3b\u8981\u7684\u66f4\u6539\u662f\uff0celasticsearchclient\u7684\u521b\u5efa\u632a\u5230\u4e86datasource\u91cc\uff0c\u800c\u4e14\u4fdd\u8bc1\u5355\u4f8b\uff0c\u5e76\u4e14\u5728datasource\u7684close\u65b9\u6cd5\u91cc\u5173\u6389elasticsearchclient\nok. ",
    "hello-wn": "\u975e\u5e38\u611f\u8c22\u56de\u590d\u3002\n\u6240\u4ee5\uff0cjoin\u6ca1\u529e\u6cd5\u4f7f\u7528explain\u8f6c\u5316\u4e3adsl\u5417\uff1f\n\u5982\u679c\u662f\u5206\u4e24\u6b21\u67e5\u8be2\uff0c\u90a3\u6bcf\u6b21\u67e5\u8be2\u7684dsl\u4e3a\u5565explain\u4e5f\u4e0d\u663e\u793a\u5462\uff1f. ",
    "whzhangxw": "\n\n\n\n\u8fd9\u662f\u6211\u7684ES\u6570\u636e\u6e90\u914d\u7f6e. <bean id=\"esDataSource\" class=\"com.alibaba.druid.pool.ElasticSearchDruidDataSource\" init-method=\"init\" destroy-method=\"close\">\n        <property name=\"url\" value=\"${ds.escluster.url}\" />\n        <property name=\"initialSize\" value=\"${ds.initialSize}\" />\n    </bean>. \n\n\n\n\n. ",
    "jeremeyjiang": "\u7528\u7684 6.2.4 \u5206\u652f \u55ef\u55ef \u4ee3\u7801\u957f\u8fd9\u6837 \nJDBCTests\u6d4b\u8bd5\u7c7b\u62a5\u9519 \uff08es kibana\u90fd\u6b63\u5e38 \u4f7f\u7528RestHighLevelClient \u8d709200\u7aef\u53e3\u4e5f\u6b63\u5e38\uff09\njava.sql.SQLException: Error\nat com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1107)\nat com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\nat com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\nat com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:58)\nat org.nlpcn.es4sql.JDBCTests.testJDBC(JDBCTests.java:31)\nat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\nat java.lang.reflect.Method.invoke(Method.java:498)\nat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)\nat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)\nat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)\nat org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)\nat org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)\nat org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)\nat org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)\nat org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)\nat org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)\nat org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)\nat org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)\nat org.junit.runners.ParentRunner.run(ParentRunner.java:309)\nat org.junit.runner.JUnitCore.run(JUnitCore.java:160)\nat com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:68)\nat com.intellij.rt.execution.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:47)\nat com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:242)\nat com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:70)\n\nCaused by: NoNodeAvailableException[None of the configured nodes are available: [{#transport#-1}{h7Uo-DgsSkCgl79Lwa_1cQ}{192.168.5.109}{192.168.5.109:9300}]]\n    at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:347)\n    at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:245)\n    at org.elasticsearch.client.transport.TransportProxyClient.execute(TransportProxyClient.java:60)\n    at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:371)\n    at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:405)\n    at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:394)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:46)\n    at org.elasticsearch.action.ActionRequestBuilder.get(ActionRequestBuilder.java:53)\n    at org.nlpcn.es4sql.query.SqlElasticSearchRequestBuilder.get(SqlElasticSearchRequestBuilder.java:30)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeSearchAction(QueryActionElasticExecutor.java:22)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeAnyAction(QueryActionElasticExecutor.java:55)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.getObjectResult(ElasticSearchDruidPooledPreparedStatement.java:70)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:43)\n    ... 23 more\n. \u5c31\u662f9300\u8fde\u4e0d\u4e0a \u6709\u70b9\u5947\u602a\nkibana\u4e0a\u770b\u4e86\u4e00\u4e0b   GET _nodes/hot_threads\n\u7ed3\u679c\u5982\u4e0b\n::: {node-1}{7dx7XSQHTGuvfhn7Lo_SgQ}{RvSja3tDQNySf_0ho24eqA}{192.168.5.109}{192.168.5.109:9300}{ml.machine_memory=4151914496, ml.max_open_jobs=20, ml.enabled=true}\n   Hot threads at 2018-09-25T01:58:01.634Z, interval=500ms, busiestThreads=3, ignoreIdleThreads=true:\n. ",
    "luofeng1994": "@shi-yuan . ",
    "thamaraikrishnan": "Is there a way to fetch data like MySQL?\nLIKE BINARY '%ram%'\nLIKE '%ram%'\nI am new to this plugin, can you give me a sample to write regexp script using first name field to satisfy \"LIKE and LIKE BINARY\" functions?\n. Thanks, My issue got solved using 'REGEXP_QUERY'.. Thanks for your reply. But it did not solve the problem. I may be wrong on this. Please correct me.\nSELECT firstname, balance FROM accounts where firstname.keyword <> REGEXP_QUERY('robo', 'INTERSECTION|COMPLEMENT|EMPTY', 10000)\nSELECT firstname, balance FROM accounts where firstname.keyword = REGEXP_QUERY('robo', 'INTERSECTION|COMPLEMENT|EMPTY', 10000)\nBoth scripts give the same result. So this operator '<>' is working properly.\n. Hi Shi-yuan,\nThanks for your immediate reply. Now I have solved this issue using normalizer.\nJust shared the article link for reference.\nhttps://www.technetexperts.com/web/case-insensitive-sorting-in-elasticsearch/\n. ",
    "jgq2008303393": "\n\u7f16\u7801\u7684\u95ee\u9898\u5427\uff0c\u600e\u4e48\u8bf7\u6c42\u7684\n\n\u662f\u7684\uff0c\u4f7f\u7528urlencode\u7f16\u7801\u540e\u80fd\u6b63\u5e38\u53d1\u9001\uff0c\u4f46\u662f\u82f1\u6587\u67e5\u8be2\u53ef\u4ee5\u4e0d\u7528\u7f16\u7801\u3002\u8bf7\u6c42\u53d1\u9001\u7684\u65b9\u5f0f\u662f\u5728kibana\u7684dev tools\u4e2d\u76f4\u63a5\u53d1\u9001\u4e0b\u9762\u547d\u4ee4\uff1a\nGET _sql?sql=select id,name from products_index where name=matchQuery('\u957f\u88e4') order by _score desc limit 2\n\u8fd9\u4e2a\u548c\u5177\u4f53\u7684kibana\u7248\u672c\u6709\u5173\u7cfb\u5417\uff1f\u5927\u795e\u5e73\u65f6\u662f\u600e\u4e48\u53d1\u9001\u7684\uff0c\u4e5f\u9700\u8981\u7f16\u7801\u5417\uff1f. \u8d5e. ",
    "hexian55": "\u8fd9\u4e2a\u662f\u5728\u54ea\u4e2a\u7248\u672c\u5f00\u59cbfix\u7684\uff1f\u6211\u8fd9\u8fb9\u662f5.6.3\u7684\u7248\u672c\uff0c\u5b89\u88c5\u5305\u91cc\u9762\u662f\u5426\u6709\u66f4\u65b0\uff1f. ",
    "SDUmzg": "thx,I have already fix it . . \u591a\u6570\u636e\u6e90\u7684\u65f6\u5019\u8981\u91cd\u5199Mybatis\u7684\u62e6\u622a\u5668\uff0c\u8fd9\u4e2a\u95ee\u9898\u4e3b\u8981\u7684\u539f\u56e0\u5728\u62e6\u622a\u5668. @chenzhenguo . @chenzhenguo \n```\n    @Override\n    public Object intercept(Invocation invocation) throws Throwable {\n        Object arg0 =  invocation.getArgs()[0];\n        PreparedStatementLogger invocationHandler;\n        PreparedStatement ps;\n    if (Proxy.isProxyClass(arg0.getClass())){\n        invocationHandler = (PreparedStatementLogger) Proxy.getInvocationHandler(arg0);\n        ps = invocationHandler.getPreparedStatement();\n    }else {\n        ps = (PreparedStatement) arg0;\n    }\n    if (ps instanceof ElasticSearchDruidPooledPreparedStatement){\n        LOGGER.info(\"ElasticSearch sql query by defined logic.\");\n        try (ResultSet resultSet = ps.executeQuery()) {\n            LOGGER.info(\"ResultSet row size = {}\",resultSet.getRow());\n            String name;\n            ResultSetMetaData md = resultSet.getMetaData();\n            int count = md.getColumnCount(), i;\n            List<Map<String, Object>> result = new ArrayList<>();\n            Map<String, Object> map;\n            while (resultSet.next()) {\n                map = new LinkedHashMap<>();\n                for (i = 1; i <= count; ++i) {\n                    map.put(name = md.getColumnName(i), resultSet.getObject(name));\n                }\n                result.add(map);\n            }\n            LOGGER.info(\"Result size = {}\",result.size());\n            result.stream().forEach(itemMap->{\n                LOGGER.info(\"==> {}\",itemMap.toString());\n            });\n            return result;\n        }catch (Exception e){\n            LOGGER.error(\"something error when exe ps.executeQuery()\",e);\n            throw e;\n        }\n    }else {\n        return invocation.proceed();\n    }\n}\n\n``.Object arg0 =  invocation.getArgs()[0]; \u5728\u591a\u6570\u636e\u6e90\u4e2d\uff0carg0\u6709\u53ef\u80fd\u662fProxy\uff0c\u5bfc\u81f4 #768 \u4e2d\u7684\u4ee5\u4e0b\u8bed\u53e5\u62a5\u9519PreparedStatement ps = (PreparedStatement) invocation.getArgs()[0];`\n\u4ee5\u81f3\u4e8e\u67e5\u8be2ES\u7684SQL\u5b9e\u9645\u4e0a\u6ca1\u6709\u8d70\u62e6\u622a\u5668\u903b\u8f91\u3002\n@chenzhenguo @shi-yuan . @chenzhenguo  maven\u7684\u4f9d\u8d56\u7248\u672c\u8981\u4e0eES\u96c6\u7fa4\u7248\u672c\u4e00\u81f4. > \u53ef\u4ee5\u4e0d\u7528\u62e6\u622a\u5668\u63a7\u5236\u4e86\uff0c\u800c\u4e14\u8fd4\u56de\u503c\u53ef\u4ee5\u76f4\u63a5\u6839\u636emapper\u6587\u4ef6\u7684resultType\u8fd4\u56de\u6307\u5b9a\u7684\u7c7b\u578b\uff0c\u5df2\u5728\u6700\u65b0\u7248\u672c\u66f4\u65b0\u4ee3\u7801\uff0c\u8be6\u7ec6\uff0c\u8bf7\u770b\uff1a\n\nddddb9e\n\n\u8bf7\u95ee\u8fd9\u4e9b\u4ee3\u7801\u5df2\u7ecf\u540c\u6b65\u5230master\u5206\u652f\u4e86\u5417\uff1f \u6211\u7684es\u7248\u672c\u662f6.2.2.0\uff0c\u662f\u4e0d\u662f\u66f4\u6362\u4e0b\u4f9d\u8d56\u7684es\u4e2a\u7ec4\u4ef6\u7684\u7248\u672c\u5c31\u53ef\u4ee5\u4e86\uff1f @shi-yuan . @shi-yuan  thx ,\u6700\u8fd1\u6539\u9020\u4e86es-sql\u548csearch-guard\u63d2\u4ef6\u7684java\u6e90\u7801\uff0c\u4f7f\u7528Search Guard\u8ba4\u8bc1\u7684ES\u96c6\u7fa4\u4e5f\u53ef\u4ee5\u7ecf\u7531Mybatis\u4f7f\u7528\u4e86\uff0c\u5efa\u8bae\u5728\u521b\u5efaTransportClient\u7684\u65f6\u5019\u589e\u52a0\u53ef\u63d2\u62d4\u7684\u6269\u5c55\uff0c\u4ee3\u7801\u4f1a\u66f4\u52a0\u7075\u6d3b. @shi-yuan  \u8c22\u8c22. 6.2.2 @shi-yuan . @shi-yuan  \u8c22\u8c22 \uff0c\u4e4b\u524d\u6211\u8bd5\u8fc7\u4e00\u6b21\u7528\u6700\u65b0\u5206\u652f\u505a\u8fd9\u4ef6\u4e8b\u60c5\uff0c\u7531\u4e8e\u65f6\u95f4\u6709\u9650\u803d\u6401\u4e86\uff0c\u9047\u5230\u7684\u6700\u660e\u663e\u7684\u95ee\u9898\u662f\u597d\u50cf\u6700\u65b0\u7248\u672c\u7684\u4e00\u4e9b\u5305 \u57286.2.2\u7248\u672c\u5e76\u6ca1\u6709\uff0c\u9700\u8981\u9002\u914d\u3002 \u611f\u8c22\u60a8\u7684\u89e3\u7b54\uff0c\u8c22\u8c22\u3002. ",
    "coding-hello": "\u7279\u522b\u68d2~ \u611f\u8c22~. ",
    "LongLonger": "\n\u6709testcase\u5931\u8d25\uff0c\u5904\u7406\u4e0b\u5457\uff1f\n\n\u5df2\u7ecf\u5904\u7406\u4e86. > \u5efa\u8bae\u628a wiki \u529f\u80fd\u4e5f\u52a0\u4e0a\u3002\u8fd9\u6837\u66f4\u591a\u7684\u4eba\u80fd\u4f7f\u7528\u65b0\u529f\u80fd\n\u597d\uff0c\u521a\u521a\u5c06\u65b0\u589e\u529f\u80fd\u7684\u63cf\u8ff0\u52a0\u5230wiki\u4e0a\u4e86\uff0c\u5df2\u7ecf\u53d1\u8d77\u4e86pull request. ",
    "wluoer": "\u597d\u7684\uff0c\u611f\u8c22. ",
    "wkjun": "6.4.0\u4e0a\u652f\u6301\u5417\uff1f\u6700\u4f4e\u54ea\u4e2a\u7248\u672c\u5df2\u7ecf\u652f\u6301\u5462\uff1f. \u6069\u6069\uff0c\u501f\u7528\u4e86\u60a8\u63d0\u5230\u7684\u6d4f\u89c8\u5668chrome\u63d2\u4ef6\u65b9\u5f0f\u4e5f\u5b9e\u73b0\u4e86\uff0c\u586b\u5b8c\u94fe\u63a5\u540e\uff0c\u9700\u8981\u5237\u65b0\u4e0b\u9875\u9762\uff0c\u51fa\u6765\u9a8c\u8bc1\u6846\u5373\u53ef\u9a8c\u8bc1,\n\n. \u9ebb\u70e6\u95ee\u4e0b\uff0c\u4f7f\u7528\u4e86x-pack\uff0c\u542f\u7528\u4e86SSL ,\u7528\u6237\u540d\uff0c\u5bc6\u7801\uff0c\u5982\u4f55\u914d\u7f6e\u8fd9\u4e9b\u4fe1\u606f\u5462\uff1f. ",
    "w4n9H": "5.4.1\u7684\u5305\u652f\u6301xpack\u5417\uff0c\u6211\u7528\u672c\u5730es\u4e0d\u5e26xpack\u7684\u53ef\u7528\uff0c\u7528\u7ebf\u4e0a\u6d4b\u8bd5es\u5e26xpack\u7684\u5c31\u4e0d\u884c\uff0c\u62a5\u9519\u662fNoNodeAvailableException[None of the configured nodes are available\uff0c. > elasticsearch-sql-5.4.1.0.zip\n\u611f\u8c22\uff0c\u6309\u7167\u9ad8\u7248\u672c\u7684bugfix\u81ea\u5df1\u9b54\u6539\u4e86\u4e00\u4e0b5.4.1\u4fee\u590d\u4e86\u95ee\u9898\uff0c\u8fd8\u628axpack\u652f\u6301\u4e5f\u52a0\u8fdb\u53bb\u4e86\uff0c\u4f5c\u8005\u662f\u4e0d\u662f\u4e5f\u8003\u8651\u4e00\u4e0b\u5bf9\u4f4e\u7248\u672c\u7684xpack\u4e5f\u652f\u6301\u4e00\u4e0b. > \u6069\u6069\uff0c\u51c6\u5907\u5f80maven\u4e2d\u592e\u4ed3\u5e93\u91cc\u53d1\n\u53d1\u73b0\u4e86\u4e00\u4e2a\u95ee\u9898\uff0c\u67e5\u8be2\u6570\u636e\u662f\u6b63\u5e38\u7684\uff0c\u901a\u8fc7metaData.getColumnTypeName\u62ff\u6570\u636e\u7684\u7c7b\u578b\u7684\u65f6\u5019\u53d6\u51fa\u6765\u7684\u503c\u90fd\u662fnull\uff0c\u62ff\u4e0d\u5230\u7c7b\u578b\u6682\u65f6\u53ea\u80fd\u901a\u8fc7getString()\u53d6\u51fa\u5b57\u7b26\u4e32\u6765\u5e94\u6025\u4e86\uff0c\u6709\u5565\u89e3\u51b3\u529e\u6cd5\u5417. ",
    "jasonrita": "\u4f7f\u7528(@timestamp, \"yyyy-MM-dd\", \"+08:00\")<'2018-11-18'\u8fd8\u662f\u62a5\u76f8\u540c\u7684\u9519\u8bef\uff1a\n\n\n\u6211\u7684elasticsearch\u662f6.4.1\uff0c\u6309\u7167\u4f60\u7ed9\u7684\u65b9\u6cd5\uff0c\u8fd8\u662f\u65e0\u6cd5\u8bc6\u522b+8:00. where\u4f7f\u7528>=\u548c<=\u662f\u4e3a\u4ec0\u4e48\u4f1a\u63d0\u793a\u8fd9\u4e2a\u9519\u8bef\uff0c\u8bf7\u6c42\u53c2\u6570\u5df2\u7ecfencode\u4e86\uff1a\n\n. where\u6761\u4ef6\u91cc\u9762\u65e5\u671f\u8303\u56f4\u67e5\u8be2 \u4e0d\u80fd\u7528>\u3001>=\u3001<\u3001<=\uff0c\u4f60\u7ed9\u7684\u4f8b\u5b50\u4e0d\u662f\u53ef\u4ee5\u8fd9\u4e48\u5199\u5417\uff0c\u6211\u7684\u67e5\u8be2\u6761\u4ef6\u662f\u5e26\u65f6\u5206\u79d2\u7684\uff1f\n\n. \u8bf7\u95ee\u5728\u54ea\u4e2a\u7248\u672c\u5df2\u7ecf\u4fee\u590d\u4e86\uff0c\u6211\u73b0\u5728\u4f7f\u7528\u7684\u662felasticsearch6.4.1\u5bf9\u5e94\u7684\u7248\u672c\uff1f. ",
    "WeiFrank": "\u60f3\u95ee\u4e00\u4e0b\u90a3\u4e2a @timestamp \u662f\u6307\u7684\u4ec0\u4e48\uff1f\u662f\u6307\u5b57\u6bb5\u5417\uff0c . \u8c22\u8c22\uff01\u5f88\u597d\u7528\u7684\u4e00\u4e2a\u7edf\u8ba1\u5206\u7ec4\u529f\u80fd\uff0c\u5e0c\u671b\u540e\u7eed\u53ef\u4ee5\u52a0\u4e00\u4e0b\uff01. @shi-yuan \u8fd9\u4e2a\u529f\u80fd\u5728 6.5.4 \u8fd9\u4e2a\u7248\u672c\u7684\u63d2\u4ef6\u91cc\u5417?. @shi-yuan  curl -X GET \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT /! STATS(group2) / * FROM my_index\"\n }'\n \u8fd9\u6837\u8bf7\u6c42\u5b8c\uff0c\u5728\u54cd\u5e94\u91cc\u6ca1\u6709\u51fa\u73b0 group \u7684\u4fe1\u606f\uff0c\u5728 http://localhost:9200/my_index/_stats?pretty \u91cc\u9762\u4e5f\u6ca1\u6709\u51fa\u73b0 group \u7684\u4fe1\u606f\u5440\uff0c. \u55ef\uff0c\u6211\u7528\u7684\u662f 6.5.4.0 \u8fd9\u4e2a\u7248\u672c\u7684\u63d2\u4ef6\uff0c\u6211\u8bd5\u8bd56.5.4.7\u8fd9\u4e2a\u7248\u672c\u5427\uff0c\u67096.5.4.7\u8fd9\u4e2a\u7248\u672c\u5417. ok\uff01. ",
    "chenzhenguo": "spring-jdbc.xml\n\nmaven  pom.xml\n\n\nTwitterDao.xml\n\nTwitterDao.xml\n\ntest main\n\nconsole \n\n\u65e0\u62a5\u9519\u4fe1\u606f\uff0c\u63a7\u5236\u53f0\u4e00\u76f4\u6253\u5370\n\n. @SDUmzg  \u597d\u7684\uff0c\u8c22\u8c22\uff0c\u53c2\u8003\u4e86#768 \u4f7f\u7528\u4e0a\u9762\u7684\u62e6\u622a\u5668\u7684\u65b9\u6cd5\u52a0\u4e0a\u53d1\u73b0\u53d6\u4e0d\u5230\u6570\u636e\uff0c\u8bf7\u95ee\u600e\u4e48\u91cd\u5199\u62e6\u622a\u5668\u6548\u679c\u80fd\u548cmybatis\u90a3\u6837\u81ea\u52a8\u6ce8\u5165\u6570\u636e\uff1f. @SDUmzg      @shi-yuan \n\u975e\u5e38\u611f\u8c22SDUmzg   \u7ed9\u7684\u4ee3\u7801\u3002\u7ecf\u8fc7\u6d4b\u8bd5\u540e\u8fd8\u662f\u53d1\u73b0\u6709\u5f88\u591a\u95ee\u9898\uff0c\u5177\u4f53\u95ee\u9898\u5982\u4e0b\uff0c\n1\u3001\n\n\n\u6211\u5728\u8d70debug\u7684\u65f6\u5019\u53d1\u73b0\uff0ccount\u7684\u503c\u4e3a0\uff0c\u5176\u5b9e\u662f\u5df2\u7ecf\u67e5\u8be2\u4e86\u6570\u636e\uff0c\u622a\u56fe2\u4e2d\u53d1\u73b0\u6709\u4e24\u4e2acloumns \uff0c\u7b2c\u4e00\u4e2acloumns \u662f\u6709\u6570\u636e\u7684\uff0c\u5e94\u8be5\u662fes\u7684cloumns  \uff0c\u7b2c\u4e8c\u4e2acloumns  \u662f\u65e0\u6570\u636e\u7684\uff0c\u7136\u540emd.getColumnCount()\u8c03\u7528\u540e \u786e\u83b7\u53d6\u5230\u4e86\u662f\u7a7a\u7684\u6570\u636e\uff0c\u8fd4\u56decount\u4e3a0 \uff0c\u540e\u9762\u5c31\u4f1a\u51fa\u73b0\u65e0\u6570\u636e\u7684\u60c5\u51b5\u3002\n2\u3001\u7b2c\u4e8c\u4e2a\u95ee\u9898 \u662ftomcat\u5728\u542f\u52a8\u540e\uff0c\u7b2c\u4e00\u6b21\u4f1a\u8d70\u62e6\u622a\u5668\u7684executeQuery \u65b9\u6cd5\uff0c\u518d\u6267\u884c\u7b2c\u4e8c\u6b21\u62e6\u622a\u5668\u7684\u65f6\u5019\u62a5\u9519\nshi-yuan\nshi-yuan[WARN][2018-12-13 09:41:17] org.springframework.jdbc.support.SQLErrorCodesFactory.getErrorCodes(SQLErrorCodesFactory.java:218) Error while extracting database name - falling back to empty error codes \norg.springframework.jdbc.support.MetaDataAccessException: DatabaseMetaData returned by Connection [com.alibaba.druid.pool.ElasticSearchConnection@1f91c2e5] was null\n    at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:334)\n    at org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:366)\n    at org.springframework.jdbc.support.SQLErrorCodesFactory.getErrorCodes(SQLErrorCodesFactory.java:212)\n    at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.setDataSource(SQLErrorCodeSQLExceptionTranslator.java:134)\n    at org.springframework.jdbc.support.SQLErrorCodeSQLExceptionTranslator.(SQLErrorCodeSQLExceptionTranslator.java:97)\n    at org.mybatis.spring.MyBatisExceptionTranslator.initExceptionTranslator(MyBatisExceptionTranslator.java:89)\n    at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:74)\n    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)\n    at $Proxy25.selectList(Unknown Source)\n    at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:231)\n    at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)\n    at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75)\n    at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:53)\n    at $Proxy99.queryList(Unknown Source)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl.queryListFormet(LibUrlRtlServiceImpl.java:60)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$FastClassBySpringCGLIB$$5bc678cb.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$EnhancerBySpringCGLIB$$282ca7ba.queryListFormet()\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$FastClassBySpringCGLIB$$5bc678cb.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$EnhancerBySpringCGLIB$$cc32d5ea.queryListFormet()\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController.list(LibUrlRtlController.java:56)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$FastClassBySpringCGLIB$$938f87ff.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82)\n    at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$EnhancerBySpringCGLIB$$a697b81e.list()\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$FastClassBySpringCGLIB$$938f87ff.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82)\n    at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$EnhancerBySpringCGLIB$$8c19f846.list()\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)\n    at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:650)\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.filter.TrimFilter.doFilter(TrimFilter.java:38)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.filter.TrimFilter.doFilter(TrimFilter.java:38)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.xss.XssFilter.doFilter(XssFilter.java:22)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)\n    at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\n    at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\n    at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n    at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)\n    at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)\n    at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)\n    at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)\n    at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)\n    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:506)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)\n    at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)\n    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1115)\n    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)\n    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    at java.lang.Thread.run(Thread.java:722)\n\u67e5\u8be2\u5b9e\u65f6url\u8bdd\u5355\u51fa\u73b0\u5f02\u5e38 \norg.springframework.jdbc.UncategorizedSQLException: \nError querying database.  Cause: java.sql.SQLException: Error\nThe error may exist in com/polyinfo/library/dao2/httpcdr/LibUrlRtlGpDao.xml\nThe error may involve defaultParameterMap\nThe error occurred while setting parameters\nSQL: select  rid from t_url  limit 10\nCause: java.sql.SQLException: Error\n; uncategorized SQLException for SQL []; SQL state [null]; error code [0]; Error; nested exception is java.sql.SQLException: Error\n    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)\n    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)\n    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)\n    at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)\n    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)\n    at $Proxy25.selectList(Unknown Source)\n    at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:231)\n    at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)\n    at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75)\n    at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:53)\n    at $Proxy99.queryList(Unknown Source)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl.queryListFormet(LibUrlRtlServiceImpl.java:60)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$FastClassBySpringCGLIB$$5bc678cb.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$EnhancerBySpringCGLIB$$282ca7ba.queryListFormet()\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$FastClassBySpringCGLIB$$5bc678cb.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$EnhancerBySpringCGLIB$$cc32d5ea.queryListFormet()\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController.list(LibUrlRtlController.java:56)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$FastClassBySpringCGLIB$$938f87ff.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82)\n    at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$EnhancerBySpringCGLIB$$a697b81e.list()\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$FastClassBySpringCGLIB$$938f87ff.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82)\n    at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$EnhancerBySpringCGLIB$$8c19f846.list()\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)\n    at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:650)\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.filter.TrimFilter.doFilter(TrimFilter.java:38)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.filter.TrimFilter.doFilter(TrimFilter.java:38)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.xss.XssFilter.doFilter(XssFilter.java:22)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)\n    at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\n    at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\n    at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n    at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)\n    at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)\n    at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)\n    at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)\n    at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)\n    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:506)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)\n    at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)\n    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1115)\n    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)\n    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: java.sql.SQLException: Error\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)\n    at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\n    at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:62)\n    at com.polyinfo.library.test.MyInterceptor.intercept(MyInterceptor.java:33)\n    at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61)\n    at $Proxy162.query(Unknown Source)\n    at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63)\n    at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324)\n    at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156)\n    at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109)\n    at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83)\n    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)\n    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141)\n    at sun.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)\n    ... 114 more\nCaused by: NoNodeAvailableException[None of the configured nodes are available: [{#transport#-1}{192.168.1.182}{192.168.1.182:9301}]]\n    at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:290)\n    at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:207)\n    at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:55)\n    at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:288)\n    at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:86)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:56)\n    at org.elasticsearch.action.ActionRequestBuilder.get(ActionRequestBuilder.java:64)\n    at org.nlpcn.es4sql.query.SqlElasticSearchRequestBuilder.get(SqlElasticSearchRequestBuilder.java:43)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeSearchAction(QueryActionElasticExecutor.java:25)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeAnyAction(QueryActionElasticExecutor.java:53)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.getObjectResult(ElasticSearchDruidPooledPreparedStatement.java:74)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:47)\n    ... 128 more\n[ERROR][2018-12-13 09:41:17] com.polyinfo.library.controller.httpcdr.LibUrlRtlController.list(LibUrlRtlController.java:60) \u67e5\u8be2\u5b9e\u65f6url\u8bdd\u5355\u51fa\u73b0\u5f02\u5e38 \norg.springframework.jdbc.UncategorizedSQLException: \nError querying database.  Cause: java.sql.SQLException: Error\nThe error may exist in com/polyinfo/library/dao2/httpcdr/LibUrlRtlGpDao.xml\nThe error may involve defaultParameterMap\nThe error occurred while setting parameters\nSQL: select  rid from t_url  limit 10\nCause: java.sql.SQLException: Error\n; uncategorized SQLException for SQL []; SQL state [null]; error code [0]; Error; nested exception is java.sql.SQLException: Error\n    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)\n    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)\n    at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)\n    at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)\n    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)\n    at $Proxy25.selectList(Unknown Source)\n    at org.mybatis.spring.SqlSessionTemplate.selectList(SqlSessionTemplate.java:231)\n    at org.apache.ibatis.binding.MapperMethod.executeForMany(MapperMethod.java:137)\n    at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:75)\n    at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:53)\n    at $Proxy99.queryList(Unknown Source)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl.queryListFormet(LibUrlRtlServiceImpl.java:60)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$FastClassBySpringCGLIB$$5bc678cb.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$EnhancerBySpringCGLIB$$282ca7ba.queryListFormet()\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$FastClassBySpringCGLIB$$5bc678cb.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.service.httpcdr.impl.LibUrlRtlServiceImpl$$EnhancerBySpringCGLIB$$cc32d5ea.queryListFormet()\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController.list(LibUrlRtlController.java:56)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$FastClassBySpringCGLIB$$938f87ff.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82)\n    at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$EnhancerBySpringCGLIB$$a697b81e.list()\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$FastClassBySpringCGLIB$$938f87ff.invoke()\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:721)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor$1.proceed(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:82)\n    at org.apache.shiro.authz.aop.AuthorizingMethodInterceptor.invoke(AuthorizingMethodInterceptor.java:39)\n    at org.apache.shiro.spring.security.interceptor.AopAllianceAnnotationsAuthorizingMethodInterceptor.invoke(AopAllianceAnnotationsAuthorizingMethodInterceptor.java:115)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at com.alibaba.druid.support.spring.stat.DruidStatInterceptor.invoke(DruidStatInterceptor.java:72)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:656)\n    at com.polyinfo.library.controller.httpcdr.LibUrlRtlController$$EnhancerBySpringCGLIB$$8c19f846.list()\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:116)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:963)\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)\n    at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:650)\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:731)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.filter.TrimFilter.doFilter(TrimFilter.java:38)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.filter.TrimFilter.doFilter(TrimFilter.java:38)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at com.polyinfo.library.xss.XssFilter.doFilter(XssFilter.java:22)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:61)\n    at org.apache.shiro.web.servlet.AdviceFilter.executeChain(AdviceFilter.java:108)\n    at org.apache.shiro.web.servlet.AdviceFilter.doFilterInternal(AdviceFilter.java:137)\n    at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n    at org.apache.shiro.web.servlet.ProxiedFilterChain.doFilter(ProxiedFilterChain.java:66)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)\n    at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)\n    at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)\n    at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)\n    at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)\n    at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)\n    at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)\n    at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:262)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:218)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:506)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)\n    at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:962)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:445)\n    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1115)\n    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637)\n    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:318)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    at java.lang.Thread.run(Thread.java:722)\nCaused by: java.sql.SQLException: Error\n    at com.alibaba.druid.pool.ElasticSearchDruidDataSource.handleConnectionException(ElasticSearchDruidDataSource.java:1109)\n    at com.alibaba.druid.pool.DruidPooledConnection.handleException(DruidPooledConnection.java:127)\n    at com.alibaba.druid.pool.DruidPooledStatement.checkException(DruidPooledStatement.java:68)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:62)\n    at com.polyinfo.library.test.MyInterceptor.intercept(MyInterceptor.java:33)\n    at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:61)\n    at $Proxy162.query(Unknown Source)\n    at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:63)\n    at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:324)\n    at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:156)\n    at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:109)\n    at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:83)\n    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:148)\n    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:141)\n    at sun.reflect.GeneratedMethodAccessor79.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:601)\n    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)\n    ... 114 more\nCaused by: NoNodeAvailableException[None of the configured nodes are available: [{#transport#-1}{192.168.1.182}{192.168.1.182:9301}]]\n    at org.elasticsearch.client.transport.TransportClientNodesService.ensureNodesAreAvailable(TransportClientNodesService.java:290)\n    at org.elasticsearch.client.transport.TransportClientNodesService.execute(TransportClientNodesService.java:207)\n    at org.elasticsearch.client.transport.support.TransportProxyClient.execute(TransportProxyClient.java:55)\n    at org.elasticsearch.client.transport.TransportClient.doExecute(TransportClient.java:288)\n    at org.elasticsearch.client.support.AbstractClient.execute(AbstractClient.java:359)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:86)\n    at org.elasticsearch.action.ActionRequestBuilder.execute(ActionRequestBuilder.java:56)\n    at org.elasticsearch.action.ActionRequestBuilder.get(ActionRequestBuilder.java:64)\n    at org.nlpcn.es4sql.query.SqlElasticSearchRequestBuilder.get(SqlElasticSearchRequestBuilder.java:43)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeSearchAction(QueryActionElasticExecutor.java:25)\n    at org.elasticsearch.plugin.nlpcn.QueryActionElasticExecutor.executeAnyAction(QueryActionElasticExecutor.java:53)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.getObjectResult(ElasticSearchDruidPooledPreparedStatement.java:74)\n    at com.alibaba.druid.pool.ElasticSearchDruidPooledPreparedStatement.executeQuery(ElasticSearchDruidPooledPreparedStatement.java:47)\n    ... 128 more\n\u53ef\u80fd\u662f\u7531\u4e8e\u8fde\u63a5\u6c60\u53ea\u6709\u8fd9\u4e00\u4e2a\u8fde\u63a5\uff0c\u7b2c\u4e00\u6b21\u80fd\u4f7f\u7528\uff0c\u7b2c\u4e8c\u6b21\u8c03\u7528\u8fde\u63a5\u6c60\u4e3a\u7a7a\u4e86\u5bfc\u81f4\u62a5\u9519\n\u8bf7\u95ee\u8fd9\u4e2a\u95ee\u9898\u8be5\u600e\u4e48\u89e3\u51b3\uff1f. @shi-yuan     \norg.elasticsearch\nelasticsearch\n2.4.0\n\n\norg.nlpcn\nelasticsearch-sql\n2.4.1.0\n   . @shi-yuan    \u5207\u6362\u5230elastic2.4.6 \u7684\u5305\u6253\u5305\u540e \u63d0\u793a NoNodeAvailableException\uff0c es\u7248\u672c\u662f2.4.0\u7684\u7248\u672c  \uff0c\u96be\u9053\u9700\u8981\u5c06es\u4e5f\u5347\u7ea7\u52302.4.6\u5417\uff1f. \u6211\u53c8\u5c1d\u8bd5 \u4f7f\u7528es chenzhenguo\"\u6700\u65b0\u7248 6.5.1\"  \uff0c  maven\u4f7f\u7528\u6700\u65b0\u76846.5.1\u7248\u672c\n\n\u4e5f\u540c\u6837\u62a5\u9519NoNodeAvailableException[None of the configured nodes are available:\n. @shi-yuan @SDUmzg    \u5347\u7ea7\u52302.4.6 \u540e\u53ea\u6709\u4e00\u4e2a\u6570\u636e\u6e90\u7684\u95ee\u9898\u89e3\u51b3\u4e86\uff0c\u4f46\u662f\u4f7f\u7528\u62e6\u622a\u5668\u53d6\u4e0d\u5230\u6570\u636e\u3002     while (resultSet.next()) {     resultSet \u7684\u6570\u636e\u5df2\u7ecf\u80fd\u67e5\u5230\u4e86\uff0c\u4f46\u662f  md.getColumnName(i), resultSet.getObject(name)  \u5e76\u6ca1\u6709\u5f97\u5230\u5bf9\u5e94\u7684\u503c. @shi-yuan @SDUmzg\n\n int count = md.getColumnCount()     . md \u8fd9\u4e2a\u96c6\u5408\u4e2d\uff0c\u6709\u4e24\u4e2acolumns\uff0c\u4f46\u662f\u8c03\u7528 getColumnCount  \u5f97\u5230\u4e3a0\uff0cElasticSearchResult \u8fd9\u4e2a\u96c6\u5408\u7684columns \u662f\u6709\u6570\u636e\u7684\uff0c \u7b2c\u4e8c\u4e2a\u662f\u6ca1\u6709\u6570\u636e\u7684\uff0c. @shi-yuan  @SDUmzg em........\u611f\u8c22\uff0c\u4e0d\u8fc7resultSet.getObject(i) i\u6211\u5e76\u4e0d\u77e5\u9053\u603b\u6570\u662f\u591a\u5c11\uff0c\u6211\u73b0\u5728\u901a\u8fc7 resultSet.getObject(\"rid\") \u83b7\u53d6\u6570\u636e\uff0c  \u4f46\u662f\u8fd9\u6837\u53ea\u80fd\u5199\u6b7b\u83b7\u53d6\u56fa\u5b9a\u7684\u5b57\u6bb5\uff0c\u540e\u7eed\u7ef4\u62a4\u5f88\u9ebb\u70e6\uff0c \u6709\u6ca1\u6709\u529e\u6cd5 \u89e3\u51b3\u6389\u8fd9\u4e2a\u95ee\u9898\uff0c\u80fd\u591f\u81ea\u52a8\u83b7\u53d6\u5bf9\u5e94\u7684\u5b57\u6bb5\u548c\u5bf9\u5e94\u7684\u503c\u3002. @shi-yuan   \u611f\u8c22\uff0c\u89e3\u51b3\u8fd9\u4e2a\u4e3a0\u7684\u95ee\u9898\u4e86\n\u6211\u5728 ElasticSearchResultSetMetaDataBase \u4e2d\u6dfb\u52a0\u4e86\nchenzhenguo\n @Override\n    public List getColumns() {\n        return columns;\n    }\n@Override\npublic int findColumn(String columnName) throws SQLException {\n    ColumnMetaData column;\n    for (int i = 0; i < columns.size(); ++i) {\n        column = columns.get(i);\n        if (column.getColumnName().equals(columnName)) {\n            return i + 1;\n        }\n    }\n\n    throw new SQLException(\"column '\" + columnName + \"' not found.\");\n}\n\n@Override\npublic int getColumnCount() throws SQLException {\n    return columns.size();\n}\n\n@Override\npublic ResultSetMetaDataBase.ColumnMetaData getColumn(int column) {\n    return columns.get(column - 1);\n}\n\n\u6211\u770b\u5230\u652f\u7ebf\u7684\u6709\u4ee3\u7801\u6709\u7684\u6539\u6210\u6b63\u786e\u7684\u4e86\uff0c\u4f46\u662f\u4e3a\u4ec0\u4e48master \u4e0a\u7684 \u7684\u4ee3\u7801\u8fd8\u662f\u9519\u8bef\u7684\u3002\u611f\u89c9\u5206\u652f\u6709\u70b9\u4e71\u3002\u8981\u662f\u80fd\u90fd\u6539\u4e86\u8fd9\u4e2a\u95ee\u9898\u5c31\u80fd\u65e9\u70b9\u89e3\u51b3\u4e86. \u54e6... \u539f\u6765\u5982\u6b64\uff0c\u662f\u6211\u770b\u9519\u4e86\uff0c\u819c\u62dc. @SDUmzg   \u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\u662f\uff0c\u600e\u4e48\u80fd\u8ba9\u62e6\u622a\u5668\u6839\u636emapper\u6587\u4ef6\u7684resultType\u8fd4\u56de\u6307\u5b9a\u7684\u7c7b\u578b\uff0c\u5f53\u524d\u662fmap\u7c7b\u578b\u7684\u6570\u636e\uff0c\u5bfc\u81f4\u7c7b\u578b\u8f6c\u6362\u9519\u8bef\u3002 \u80fd\u5426\u6709\u793a\u4f8b\u4ee3\u7801\u53c2\u8003\u4e00\u4e0b\uff0c\u611f\u8c22 . @shi-yuan    \u4f60\u597d\u3002  \u6211\u53c2\u8003\u4e86ddddb9e \u4e2d\u7684\u4ee3\u7801\n\u4f46\u662f\u51fa\u73b0\u4e86\u5f02\u5e38\uff0c\u5927\u6982\u662f\u6267\u884c\u5230ElasticSearchDruidPooledPreparedStatement \u8fd9\u91cc\n   ((ElasticSearchPreparedStatement) getRawPreparedStatement()).setResults(rs); \n\u51fa\u73b0\u7c7b\u578b\u8f6c\u6362\u5f02\u5e38\u7684\u95ee\u9898\uff0c\u80fd\u5426\u4e3a2.4.6.0  \u66f4\u65b0\u4e00\u7248\u89e3\u51b3 \u4e0d\u7528\u62e6\u622a\u5668\u7684\u8fd9\u4e2a\u8fd9\u4e2a\u95ee\u9898\u5462\n\u975e\u5e38\u611f\u8c22. @shi-yuan \n \u62b1\u6b49\uff0c\u6253\u5305\u6d4b\u8bd5\u53d1\u73b0\u8fd8\u662f\u51fa\u73b0\u4e86\u539f\u6765\u540c\u6837\u95ee\u9898\uff0c\u4e00\u76f4\u6253\u5370   Updates: 0  . elasticsearch-sql   2.4.6.0 \u80fd\u6b63\u5e38\u8fde\u63a5\u96c6\u7fa4\uff0c\u66f4\u6362\u4e3a2.4.6.3\u540e\u62a5\u9519\u5f02\u5e38    NoNodeAvailableException[None of the configured nodes   \u65e0\u6cd5\u8fde\u63a5\u96c6\u7fa4\u3002 es\u96c6\u7fa4\u7248\u672c\u4e3a2.4.6 .   \u6211\u9047\u5230\u4e86\u4e00\u4e2a  \u95ee\u9898\u662f2.4.6.0 \u7684transportclient \u80fd\u8fde\u4e0a\uff0c \u66f4\u65b0\u52302.4.6.3 \u5c31\u8fde\u4e0d\u4e0a\u96c6\u7fa4\u4e86\uff0c\u7136\u800c\u6211\u5e76\u4e0d\u77e5\u9053\u662f\u7531\u4e8e\u4ec0\u4e48\u539f\u56e0\u6ca1\u8fde\u4e0a\uff0c . \u662f\u7684\uff0c\u6211\u7528\u76842.4.6.3\uff0ces\u7684\u7248\u672c\u662f2.4.6  \uff0c\u4f7f\u7528 JDBCTests \u6d4b\u8bd5 \u62a5\u9519NoNodeAvailableException\u3002 \u5f53\u6211\u5207\u6362\u81f32.4.6.0 \u5c31\u4e0d\u4f1a\u62a5\u8fd9\u4e2a\u9519\u8bef. ",
    "PeterSteini": "this works not on 6.4.2\ni get {\"error\":{\"root_cause\":[{\"type\":\"null_pointer_exception\",\"reason\":null}],\"type\":\"null_pointer_exception\",\"reason\":null},\"status\":500\nbut on 6.5.1 it works!\nin the old versions it was possible to get an answer in the browser. now is curl needed.\nis ist possible to get the old behaviour?\nthanx. ",
    "Ethan-Zhang": "@shi-yuan could we make the simple query api correct in 6.4.3, or we edit the readme file, inform user which es version can use simple query sql. \nthx.. ",
    "tanjun2030": "\ncurl -X GET \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM my_index LIMIT 10\"\n}\n'\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM my_index LIMIT 10\"\n}\n'\n\n\u4e0d\u80fd\u901a\u8fc7http\u8bf7\u6c42\u7684\u65b9\u5f0f\u5417\uff1f\u6211\u6253\u7b97\u628a\u8fd9\u4e2a\u3010http://localhost:9200/_sql?sql=select * from my_index limit 10\u3011\u505a\u6210api\u8fd4\u56de\u6570\u636e\uff1f. \u8fd9\u4e2a\u662f\u4e3a\u4ec0\u4e48\u5462\uff1f6.4.2\u7248\u672c\u76f4\u63a5\u901a\u8fc7http://localhost:9200/_sql?sql=select * from my_index limit 10 \u5c31\u80fd\u8fd4\u56dejson\u7ed3\u679c\u4e86\uff0c6.5+\u5c31\u4e0d\u884c\u4e86\u3002\u3002. > kibana\u4e5f\u662f\u53ef\u4ee5\u8bbf\u95ee\u7684\u54e6\uff1a\n\n\n\n\u6211\u8bd5\u4e86\uff0c6.5.1\u7684kibana\u786e\u5b9e\u53ef\u4ee5\uff01\u4f46\u662furl\u7684\u65b9\u5f0f\u76f4\u63a5\u4e0d\u884c\u4e86\u3002. > \u652f\u6301\u7684\uff0c\u4e0d\u8fc7Content-Type\u5f97\u662fapplication/json\n\u6211\u660e\u767d\u4e86\uff0c\u6211\u901a\u8fc7java\u8bf7\u6c42\u8bd5\u8bd5\uff0c\u4f30\u8ba1\u662f\u6d4f\u89c8\u5668\u76f4\u63a5url\u4e0d\u884c\u4e86\u3002. > \u8fd9\u4e2a\u662fes\u7684\u9650\u5236\uff0c\u4e0a\u9762\u7684\u51fa\u9519\u4fe1\u606f\u662fes\u672c\u8eab\u629b\u51fa\u6765\u7684\n\u96be\u602a\uff0c\u6211\u770b\u6e90\u7801\u91cc\u9762\u6ca1\u6709\u8fd9\u4e2a\u62a5\u9519\uff0c\u54c8\u54c8. > curl\n\u8fd9\u4e2a\u76f4\u63a5\u6267\u884c\u4e5f\u53ef\u4ee5\u3002\u3002\u8c22\u8c22\u54c8\u3002\u3002\u90a3\u4f30\u8ba1\u662f6.4.\u7248\u672c\u6ca1\u505a\u8fd9\u4e2a\u9650\u5236\uff0c6.5.\u624d\u6709\u7684\u3002\n\u8f9b\u82e6\u8f9b\u82e6\uff01. > \u63a5\u6536\u53c2\u6570\u8fd9\u5757\u513f\u505a\u4e86\u517c\u5bb9\uff1a\n\n1\u3001\u652f\u6301\uff08\u63a8\u8350\uff09\uff1a\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\n{\n    \"sql\": \"SELECT * FROM my_index LIMIT 10\"\n}\n'\n2\u3001\u652f\u6301\uff1a\ncurl -X POST \"localhost:9200/_sql\" -H 'Content-Type: application/json' -d'\nSELECT * FROM my_index LIMIT 10\n'\n\n\n\u8fd9\u79cd\u65b9\u5f0f\u600e\u4e48\u901a\u8fc7java\u8bf7\u6c42\u5462\uff1f\u6ca1\u6709curl\u7684api\u5462\u3002\u3002\u5c34\u5c2c. ",
    "lychee180": "I have the same question.. ",
    "lindahu1": "thanks! it works now.. thanks. elasticsearch-sql-stei-chrom works!!. ",
    "zhangkunjie": "\u8d5e~\u8c22\u8c22\uff01. ",
    "vitoliuhe": "\u540e\u8005\u96c6\u6210\u7684demo\u6709\u5417,  \u62b1\u6b49\u6ca1\u6709\u5728Wiki\u4e0a\u627e\u5230\u6587\u6863.. \u5341\u5206\u611f\u8c22.. ",
    "aloserman": "\u597d\u7684\uff0c\u5df2\u4e86\u89e3\uff0c\u8c22\u8c22\u56de\u590d\u3002\u672a\u6765\u6709\u652f\u6301\u7684\u5e0c\u671b\u5417\uff1f\u8fd8\u6709\u5c31\u662f\u4e0d\u652f\u6301\u7684\u60c5\u51b5\u4e0b\u53ef\u5426\u629b\u51faHAVING IS NOT SUPPORT EXCEPTION\u7c7b\u4f3c\u8fd9\u79cd\u5f02\u5e38\uff1f\u5426\u5219\u5728\u4e0d\u62a5\u9519\u7684\u60c5\u51b5\u4e0b\u5f88\u5bb9\u6613\u9020\u6210\u4e1a\u52a1\u9519\u8bef\u3002. \n\ngroup by \u540e\u9762\u591a\u4e2a\u5b57\u6bb5\u7684\u65f6\u5019\u6709\u6709bug\u5417 \u67e5\u8be2\u51fa\u7684\u7ed3\u679c\uff0c\u6bcf\u4e2a\u5206\u7ec4\u6700\u591a\u53ea\u80fd10\u6761\u8bb0\u5f55\uff1f\n\n\u76ee\u524d\u8fd8\u6ca1\u6d4b\u8bd5\uff0c\u5982\u679c\u662f\u8fd9\u6837\u7684\u8bdd\uff0c\u90a3\u5c31\u6ca1\u6cd5\u7528\u4e86\u3002\u3002\u3002. > \n\nsize\u53ef\u4ee5\u81ea\u5b9a\u4e49\u54c8\n\n\u975e\u5e38\u611f\u8c22\u56de\u590d\uff0c\u76ee\u524d\u9879\u76ee\u4e2d\u5df2\u7ecf\u96c6\u6210\u4e86ES-SQL\u3002\u89e3\u51b3\u4e86\u5b66\u4e60\u67e5\u8be2\u8bed\u6cd5\u7684\u6210\u672c\u3002\u5f88\u8d5e\u3002. \u662f\u5426\u662f\u56e0\u4e3a\u6211\u7528\u7684\u7c7b\u578b\u662fkeyword\u5f15\u8d77\u7684\uff1f. ",
    "xfyuan": "\u9ebb\u70e6\u4e86\u3002. ",
    "hardyxia2018": "\n. \u6628\u5929\u4e0d\u884c\uff0c\u4eca\u5929\u83ab\u540d\u5176\u5999\u7684\u6b63\u5e38\u5566~~~~~~~~~~~. ",
    "LLeiFeng": "      \"rule\": {\n        \"type\": \"nested\",\n        \"properties\": {\n          \"name\": {\n            \"type\": \"keyword\",\n            \"index_options\": \"freqs\"\n          },\n          \"result\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"name\": {\n                \"type\": \"keyword\",\n                \"index_options\": \"freqs\"\n              },\n              \"strValue\": {\n                \"type\": \"keyword\",\n                \"index_options\": \"freqs\"\n              }\n            }\n          }\n        }\n      }\n\nmapping \u5982\u4e0a @shi-yuan . \u4ee5\u4e0b\u662f\u6211\u5199\u7684sql\nGET _sql?sql=select * from stanlee_decision-engine_2019-01-15 where commitId>0 and (timeStamp between 1547501223173 and 1547537223173)  and (nested(rule,rule.name = 'test_7')) group by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),(nested(rule.name)),nested(rule.result.strValue) limit 0;\n\u83b7\u53d6\u5230\u7684\u7ed3\u679c\n{\n                  \"key\": \"test_rule_7\",\n                  \"doc_count\": 4,\n                  \"rule.result.strValue@NESTED\": {\n                    \"doc_count\": 4,\n                    \"rule.result.strValue\": {\n                      \"doc_count_error_upper_bound\": 0,\n                      \"sum_other_doc_count\": 0,\n                      \"buckets\": [\n                        {\n                          \"key\": \"pass\",\n                          \"doc_count\": 3\n                        },\n                        {\n                          \"key\": \"reject\",\n                          \"doc_count\": 1\n                        }\n                      ]\n                    }\n                  }\n                }\n\u8bf7\u95ee\u6211\u8be5\u5982\u4f55\u5728group by \u7684\u65f6\u5019\u6839\u636e rule.result.name=\"verdict\"\u8fd9\u4e2a\u6761\u4ef6\u53bb\u8fc7\u6ee4\u5462\uff0c\u5e0c\u671b\u5f97\u5230\u7684\u7ed3\u679c\u662f\u5f53rule.result.name=\"verdict\" \u7684\u65f6\u5019 pass\u4ee5\u53careject\u7684\u6570\u91cf    \u8c22\u8c22. \u597d\u7684 \u8c22\u8c22. \u597d\u7684 \u8c22\u8c22\u54c8  \u53e6\u5916\u8bf7\u95ee\u8fd9\u4e2agroup by nested \u652f\u6301\u522b\u540d\u5417 \u8c22\u8c22\u54c8. \u53e6\u5916\u4e00\u79cd\u60c5\u51b5  \u5982\u679cgroup by \u65f6\u5019\u4e0d\u6307\u5b9a(nested(rule.name))\u8fd9\u4e00\u5217 \u4f46\u662f\u60f3\u7b5b\u9009\u51farule.name=\"test_rule\",\u8fd9\u4e00\u5217\u7684\u805a\u5408\u6570\u636e \u8fd9\u4e2a\u6761\u4ef6\u600e\u4e48\u52a0\u5462 \u4e5f\u5c31\u662f\u53ef\u4ee5\u4e0d\u7b5b\u9009\u5176\u4ed6\u7684rule.name\u7b49\u4e8e\u5176\u5b83\u5217\u7684\u6570\u636e  \u8c22\u8c22shi-yuan\nselect * from stanlee_decision-engine_2019-01-15 where commitId>0 \nand (timeStamp between 1547501223173 and 1547537223173) \nand (nested(rule,rule.name = 'test_7')) \ngroup by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),\n(nested(rule.name)),\nnested(rule.result.strValue),\nfilter('rule.result.name', rule.result.name=TERM('verdict')). > \u4e0d\u652f\u6301\u7684\n\u53ea\u4e0d\u652f\u6301group by nested \u65f6\u5019\u8d77\u522b\u540d\u5417\uff1f. \u597d\u7684 \u8c22\u8c22shi-yuan\n\u53e6\u5916\u8bf7\u95ee\u4e0b \u5982\u679c\u662fgroup by \u7684\u591a\u4e2afilter \u6539\u5982\u4f55\u5199\u5462  \u6211\u8fd9\u6837\u5199\u6307\u5b9arule.name='test_7' \u4ee5\u53carule.result.name='verdict'\u662f\u4e0d\u884c\u7684  \u9ebb\u70e6\u4e86 \u8c22\u8c22\nGET _sql/?sql=select * from stanlee_decision-engine_2019-01-15 where commitId>0 and (timeStamp between 1547501223173 and 1547537223173) and (nested(rule,rule.name = 'test_rule_7')) group by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),nested(rule.result.strValue),filter('rule.name',rule.name=TERM('test_7')),filter('rule.result.name', rule.result.name=TERM('verdict'))\n. \u597d\u50cf\u4e0d\u884c \n\u8fd9\u79cd\u65b9\u5f0f\u662f\u53ef\u4ee5\u7b5b\u9009\u51fa\u6570\u636e\u7684\nGET _sql/?sql=select * from stanlee_decision-engine_2019-01-15 where commitId>0 and (timeStamp between 1547501223173 and 1547537223173) and (nested(rule,rule.name = 'test_rule_7')) group by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),nested(rule.result.strValue),filter('rule.result.name',rule.result.name=TERM('verdict'))\n\u8fd9\u79cd\u65b9\u5f0f\u7b5b\u9009\u4e0d\u51fa\u6570\u636e\uff0c\u662f\u56e0\u4e3anested(rule.result.strValue) \u7684nested path \u662frule.result,  rule.name\u7684path\u662fname \u4e48\uff1f\u4e0d\u5728\u540c\u4e00\u5c42\u7684path \u600e\u4e48\u7b5b\u9009\u5462\uff1f\nGET _sql/?sql=select * from stanlee_decision-engine_2019-01-15 where commitId>0 and (timeStamp between 1547501223173 and 1547537223173) and (nested(rule,rule.name = 'test_rule_7')) group by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),nested(rule.result.strValue),filter('rule.name',rule.name=TERM('test_rule_7'))\n. \u8fd9\u4e2agroup by \u7b5b\u9009\u8fc7\u6ee4\u8bed\u6cd5\u6709\u6587\u6863\u5417  wiki\u91cc\u9762\u6ca1\u6709\u770b\u5230\u76f8\u5173\u7684\u6587\u6863\u8bf6~. \u597d\u7684 \u611f\u8c22. \u5df2\u89e3\u51b3\nGET _sql/?sql=select * from stanlee_decision-engine_2019-01-15 where commitId>0 and (timeStamp between 1547501223173 and 1547537223173) and processCode=\"guangbai_test\" group by date_histogram(field='timeStamp','format'='yyyy-MM-dd HH:mm','interval'='10m','alias'='time'),terms(field='rule.name',size='20',alias='ruleName',nested=\"rule\"),terms(field='rule.result.strValue',size='20',alias='ruleName',nested=\"rule.result\"). > \u6211\u7528\u7684\u662f\u6700\u65b0\u7248\n\u55ef \u6211\u4eec\u7528\u76845.4.1\u7248\u672c \u6211\u4eec\u5c1d\u8bd5\u5347\u7ea7\u8bd5\u4e00\u4e0b \u8c22\u8c22\u4e86. maping \u7ed3\u6784\u5982\u4e0b\uff1a\n          \"node\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"name\": {\n                \"type\": \"keyword\",\n                \"index_options\": \"freqs\"\n              },\n              \"result\": {\n                \"type\": \"nested\",\n                \"properties\": {\n                  \"name\": {\n                    \"type\": \"keyword\",\n                    \"index_options\": \"freqs\"\n                  },\n                  \"numValue\": {\n                    \"type\": \"double\",\n                    \"index_options\": \"freqs\"\n                  },\n                  \"strValue\": {\n                    \"type\": \"keyword\",\n                    \"index_options\": \"freqs\"\n                  }\n                }\n              }\n            }\n          }\n\u8c22\u8c22. \u53ef\u4ee5\u4e86 \u8c22\u8c22. ```\ninputs\u7684mapping:\n          \"inputs\": {\n            \"type\": \"nested\",\n            \"properties\": {\n              \"name\": {\n                \"type\": \"keyword\",\n                \"index_options\": \"freqs\"\n              },\n              \"numValue\": {\n                \"type\": \"double\",\n                \"index_options\": \"freqs\"\n              },\n              \"strValue\": {\n                \"type\": \"keyword\",\n                \"index_options\": \"freqs\"\n              }\n            }\n          }\n\u662f\u60f3\u7528inputs.name\u7684\u503c\u53bb\u6bd4\u8f83  \u4e0d\u662f\u7528inputs.name\u8fd9\u4e2a\u5b57\u7b26\u4e32\n```. \u597d\u7684 \u8c22\u8c22\n. ",
    "HernanMora": "@zhangdashu You have a problem in the query, you are not specifying the index.\nsql\nselect * FROM <INDEX> limit 10. Thanks!\nI also had to add:\n```xml\n        \norg.elasticsearch.client\ntransport\n6.5.4\n\n    <dependency>\n        <groupId>org.elasticsearch.plugin</groupId>\n        <artifactId>transport-netty4-client</artifactId>\n        <version>6.5.4</version>\n    </dependency>\n\n```. ",
    "ZQbd": "@hlyaowan \u4f60\u8fd9\u6837\u8bd5\u4e00\u4e0b\uff0c\u53ef\u4ee5\u57fa\u4e8erestclient \u5b9e\u73b0sql\u67e5\u8be2\npublic class TestRestClient {\n    public static void main(String[] args) throws Exception {\n        RestClient restClient = RestClient.builder(\n                new HttpHost(\"10.14.252.50\", 9200, \"http\")).build();\n        String sql = \"select * from yourIndex where xxx\";\n        Map params = Collections.emptyMap();\n        HttpEntity entity = new NStringEntity(sql, ContentType.APPLICATION_JSON);\n        Response response = restClient.performRequest(\"GET\",\"/_sql\",params,entity);\n        String responseBody = EntityUtils.toString(response.getEntity());\n        System.out.println(\"responseBody = \" + responseBody);\n        restClient.close();\n    }\n}\n\n@shi-yuan \u8fd9\u6837\u5199\uff0c\u5982\u4f55\u9632sql\u6ce8\u5165\u5462. @shi-yuan \nselect /* ROUTINGS(user1,user2)*/ * from myindex\n1.ROUTINGS \u524d\u9762\u4e0d\u52a0\uff01\u4e5f\u53ef\u4ee5\u6267\u884c\u6210\u529f\uff0cwhy\uff1f\n2.\u6211\u5982\u4f55\u77e5\u9053\u8fd9\u6837\u5199\uff0crouting\u751f\u6548\u4e86\u6ca1\uff0cexplain\u770b\u4e0d\u5230\u4efb\u4f55routing\u76f8\u5173\u7684. \u6211\u7528JDBCTest\u91cc\u8fb9\u7684\u4ee3\u7801\u8dd1\u4e0d\u901a\uff0c6.3\u7248\u672c\u597d\u50cf\u6709\u95ee\u9898. @shi-yuan \n\u975e\u5e38\u611f\u8c22\u60a8\uff0c\u6211\u8fd8\u6709\u4e00\u4e2a\u95ee\u9898\uff0c\u6211\u770b\u5230JDBCSupport \u7528\u7684\u662ftransport client\uff0c9300\u7aef\u53e3\u3002\u53ef\u4ee5\u63d0\u4f9b\u4e00\u4e2a\u57fa\u4e8erest client\u7684\u5417. @WilliamShen2019 \u6211\u5df2\u7ecf\u8dd1\u901a\u4e86\n<repositories>\n        <!-- add the elasticsearch repo -->\n        <repository>\n            <id>elasticsearch-releases</id>\n            <url>https://artifacts.elastic.co/maven</url>\n            <releases>\n                <enabled>true</enabled>\n            </releases>\n            <snapshots>\n                <enabled>false</enabled>\n            </snapshots>\n        </repository>\n    </repositories>. \u8c22\u8c22\u5927\u795e\uff0c\u611f\u8c22\u611f\u8c22. ",
    "kikil592": "Same! Did you found a solution?. ",
    "liveangel-js": "I put in setting.xml, and still can't resolve. One more question, can we use the plugin standalone - not to install it as elasticsearch built-in, but it as a program to cowork with existing es cluster. Thanks\uff01. ",
    "pramodkumar-dcpl": "Issue was in plugin installation. Its fixed by installing plugin. As for checking plugins installed, I used following URL in browser - http://localhost:9201/_cat/plugins?v. ",
    "julyseven": "group by \u662f\u53ef\u4ee5\u8fbe\u5230\u6548\u679c \n\u95ee\u9898\u5728\u4e8e\u8981\u5bf9group by \u540e\u7684\u6570\u636e \u7edf\u8ba1\u603b\u6570 \u8fd9\u4e2a\u5c31\u6bd4\u8f83\u5c34\u5c2c\u4e86 \u5b50\u67e5\u8be2\u4e5f\u4e0d\u652f\u6301\u3002\u3002\u3002\n. ",
    "WilliamShen2019": "\u6ca1\u8bd5\u8fc76.3\u7248\u672c\uff0c\u6211\u96c6\u7fa4\u91cc\u662f6.1.3\uff0c\u5f15\u5165\u9879\u76ee\u91cc\u7684\u4f9d\u8d56\uff0c\u548czip\u91cc\u7684jar\uff0c\u53ef\u4ee5\u4f7f\u7528\u6587\u672b\u7684\u4ee3\u7801\u8dd1\u8d77\u6765\nxml version=\"1.0\" encoding=\"UTF-8\"?\n\n4.0.0\n<groupId>com.swc</groupId>\n<artifactId>elasticsearch_sql</artifactId>\n<version>6.1.3.0</version>\n\n<developers>\n    <developer>\n        <id>ansj</id>\n        <name>ansj</name>\n        <email>ansj-sun@163.com</email>\n    </developer>\n    <developer>\n        <id>omershelef</id>\n        <name>Omer shelef</name>\n        <email>shlaflaf@gmail.com</email>\n    </developer>\n    <developer>\n        <id>eliranmoyal</id>\n        <name>Eliran Moyal</name>\n        <email>eliran.moyal1@gmail.com</email>\n    </developer>\n</developers>\n\n\n<properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <runSuite>**/MainTestSuite.class</runSuite>\n    <elasticsearch.plugin.name>sql</elasticsearch.plugin.name>\n    <elasticsearch.plugin.site>true</elasticsearch.plugin.site>\n    <elasticsearch.plugin.jvm>true</elasticsearch.plugin.jvm>\n    <elasticsearch.version>6.1.3</elasticsearch.version>\n    <elasticsearch.plugin.classname>org.elasticsearch.plugin.nlpcn.SqlPlug</elasticsearch.plugin.classname>\n</properties>\n\n\n<dependencies>\n    <dependency>\n        <groupId>org.hamcrest</groupId>\n        <artifactId>hamcrest-all</artifactId>\n        <version>1.3</version>\n        <scope>test</scope>\n    </dependency>\n\n    <dependency>\n        <groupId>junit</groupId>\n        <artifactId>junit</artifactId>\n        <version>4.11</version>\n        <scope>test</scope>\n    </dependency>\n\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>fastjson</artifactId>\n        <version>1.1.41</version>\n        <scope>test</scope>\n    </dependency>\n\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>druid</artifactId>\n        <version>1.0.15</version>\n    </dependency>\n\n    <dependency>\n        <groupId>org.locationtech.spatial4j</groupId>\n        <artifactId>spatial4j</artifactId>\n        <version>0.6</version>\n    </dependency>\n\n    <dependency>\n        <groupId>com.vividsolutions</groupId>\n        <artifactId>jts</artifactId>\n        <version>1.13</version>\n    </dependency>\n\n\n    <dependency>\n        <groupId>org.elasticsearch</groupId>\n        <artifactId>elasticsearch</artifactId>\n        <version>${elasticsearch.version}</version>\n    </dependency>\n\n    <dependency>\n        <groupId>org.elasticsearch.client</groupId>\n        <artifactId>transport</artifactId>\n        <version>${elasticsearch.version}</version>\n    </dependency>\n\n    <dependency>\n        <groupId>log4j</groupId>\n        <artifactId>log4j</artifactId>\n        <version>1.2.17</version>\n    </dependency>\n\n    <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-api</artifactId>\n        <version>2.7</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.logging.log4j</groupId>\n        <artifactId>log4j-core</artifactId>\n        <version>2.7</version>\n    </dependency>\n\n    <dependency>\n        <groupId>javax.servlet</groupId>\n        <artifactId>servlet-api</artifactId>\n        <version>2.5</version>\n    </dependency>\n    <dependency>\n        <groupId>com.google.guava</groupId>\n        <artifactId>guava</artifactId>\n        <version>15.0</version>\n    </dependency>\n\n\n</dependencies>\n\n\n<build>\n    <resources>\n        <resource>\n            <directory>src/main/resources</directory>\n            <filtering>true</filtering>\n            <includes>\n                <include>es-plugin.properties</include>\n                <include>plugin-descriptor.properties</include>\n            </includes>\n        </resource>\n    </resources>\n\n    <plugins>\n        <plugin>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <version>2.3.2</version>\n            <configuration>\n                <source>1.8</source>\n                <target>1.8</target>\n                <encoding>UTF-8</encoding>\n            </configuration>\n        </plugin>\n\n        <plugin>\n            <artifactId>maven-jar-plugin</artifactId>\n            <executions>\n                <execution>\n                    <goals>\n                        <goal>jar</goal>\n                    </goals>\n                    <phase>package</phase>\n                </execution>\n            </executions>\n        </plugin>\n        <plugin>\n            <artifactId>maven-source-plugin</artifactId>\n            <version>2.1</version>\n            <configuration>\n                <attach>true</attach>\n            </configuration>\n            <executions>\n                <execution>\n                    <phase>compile</phase>\n                    <goals>\n                        <goal>jar</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-javadoc-plugin</artifactId>\n            <version>2.10.3</version>\n            <configuration>\n                <additionalparam>-Xdoclint:none</additionalparam>\n            </configuration>\n        </plugin>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-dependency-plugin</artifactId>\n            <version>2.10</version>\n            <executions>\n                <execution>\n                    <id>copy</id>\n                    <phase>package</phase>\n                    <goals>\n                        <goal>copy</goal>\n                    </goals>\n                    <configuration>\n                        <artifactItems>\n                            <artifactItem>\n                                <groupId>org.elasticsearch.plugin</groupId>\n                                <artifactId>parent-join-client</artifactId>\n                                <version>${elasticsearch.version}</version>\n                                <overWrite>false</overWrite>\n                                <outputDirectory>${project.build.directory}</outputDirectory>\n                            </artifactItem>\n                            <artifactItem>\n                                <groupId>org.elasticsearch.plugin</groupId>\n                                <artifactId>reindex-client</artifactId>\n                                <version>${elasticsearch.version}</version>\n                                <overWrite>false</overWrite>\n                                <outputDirectory>${project.build.directory}</outputDirectory>\n                            </artifactItem>\n                            <artifactItem>\n                                <groupId>com.alibaba</groupId>\n                                <artifactId>druid</artifactId>\n                                <overWrite>false</overWrite>\n                                <outputDirectory>${project.build.directory}</outputDirectory>\n                                <destFileName>druid.jar</destFileName>\n                            </artifactItem>\n                            <artifactItem>\n                                <groupId>com.google.guava</groupId>\n                                <artifactId>guava</artifactId>\n                                <overWrite>false</overWrite>\n                                <outputDirectory>${project.build.directory}</outputDirectory>\n                                <destFileName>guava.jar</destFileName>\n                            </artifactItem>\n                        </artifactItems>\n                        <outputDirectory>${project.build.directory}</outputDirectory>\n                        <overWriteReleases>false</overWriteReleases>\n                        <overWriteSnapshots>true</overWriteSnapshots>\n                    </configuration>\n                </execution>\n            </executions>\n        </plugin>\n\n        <plugin>\n            <artifactId>maven-resources-plugin</artifactId>\n            <version>2.7</version>\n            <executions>\n                <execution>\n                    <id>copy-resources</id>\n                    <phase>validate</phase>\n                    <goals>\n                        <goal>copy-resources</goal>\n                    </goals>\n                    <configuration>\n                        <outputDirectory>${project.build.directory}</outputDirectory>\n                        <resources>\n                            <resource>\n                                <directory>src/main/resources</directory>\n                                <filtering>true</filtering>\n                                <includes>\n                                    <include>plugin-descriptor.properties</include>\n                                </includes>\n                            </resource>\n                        </resources>\n                    </configuration>\n                </execution>\n            </executions>\n        </plugin>\n\n        <plugin>\n            <artifactId>maven-assembly-plugin</artifactId>\n            <version>2.4.1</version>\n            <configuration>\n                <appendAssemblyId>all</appendAssemblyId>\n                <descriptorRefs>\n                    <descriptorRef>jar-with-dependencies</descriptorRef>\n                </descriptorRefs>\n            </configuration>\n        </plugin>\n\n\n        <plugin>\n            <artifactId>maven-assembly-plugin</artifactId>\n            <version>2.4</version>\n            <configuration>\n                <descriptor>src/assembly/zip.xml</descriptor>\n                <finalName>elasticsearch</finalName>\n            </configuration>\n        </plugin>\n\n\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-surefire-plugin</artifactId>\n            <configuration>\n                <includes>\n                    <include>${runSuite}</include>\n                </includes>\n            </configuration>\n        </plugin>\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-gpg-plugin</artifactId>\n            <version>1.4</version>\n            <executions>\n                <execution>\n                    <id>sign-artifacts</id>\n                    <phase>verify</phase>\n                    <goals>\n                        <goal>sign</goal>\n                    </goals>\n                </execution>\n            </executions>\n        </plugin>\n    </plugins>\n\n</build>\n\n<distributionManagement>\n    <snapshotRepository>\n        <id>sonatype-nexus-snapshots</id>\n        <name>Sonatype Nexus snapshot repository</name>\n        <url>https://oss.sonatype.org/content/repositories/snapshots</url>\n    </snapshotRepository>\n\n    <repository>\n        <id>sonatype-nexus-staging</id>\n        <name>Sonatype Nexus release repository</name>\n        <url>https://oss.sonatype.org/service/local/staging/deploy/maven2</url>\n    </repository>\n</distributionManagement>\n\n\n\u7136\u540e\u518d\u5f15\u5165zip\u5305\u91cc\u7684\u51e0\u4e2a\u9879\u76eejar\u5305\uff0c\u5c31\u53ef\u4ee5\u6d4b\u8bd5\u4e86\uff1a\npackage ela;\nimport java.sql.*;\nimport java.util.Properties;\nimport com.alibaba.druid.pool.DruidDataSource;\nimport com.alibaba.druid.pool.ElasticSearchDruidDataSourceFactory;\npublic class ElaJDBC {\n    public static void main(String[] args) throws Exception {\n        Properties properties = new Properties();\n        properties.put(\"url\", \"jdbc:elasticsearch://192...***:9200/index_name\");\n        DruidDataSource dds = (DruidDataSource) ElasticSearchDruidDataSourceFactory\n                .createDataSource(properties);\n        dds.setInitialSize(1);\n        Connection connection = dds.getConnection();\n        String sql2 = \"SELECT count(0) as count FROM index_name limit 10\";\n        PreparedStatement ps = connection.prepareStatement(sql2);\n        ResultSet resultSet = ps.executeQuery();\n        while (resultSet.next()) {\n            //sql\u5bf9\u5e94\u8f93\u51fa\n            System.out.println(resultSet.getString(\"count\") );\n    }\n    ps.close();\n    connection.close();\n    dds.close();\n}\n\n}\n. > elasticsearch-sql\uff0c\u7531\u4e8e\u4e2d\u592e\u4ed3\u5e93\u6ca1\u6709\u66f4\u65b0\uff0c\u9700\u8981\u81ea\u5df1install\n\n```\n\norg.nlpcn\nelasticsearch-sql\n${essql.version}\n\n\norg.elasticsearch\nelasticsearch\n${elasticsearch.version}\n\n\norg.elasticsearch.client\nx-pack-transport\n${elasticsearch.version}\n\n```\n\n. @shi-yuan \n\norg.elasticsearch.client\nx-pack-transport\n${elasticsearch.version}\n\n\u8fd9\u4e2a\u4f9d\u8d56\u4e2d\u592e\u4ed3\u5e93\u6ca1\u67096.1\u4ee5\u4e0a\u7684\uff0c\u600e\u4e48\u641e. @shi-yuan \n6.1.3\u7248\u672c\u662f\u4e0d\u662f\u8fd8\u8981\u4f9d\u8d56druid.jar. ",
    "cmdares": "\u8003\u8651\u5230\u5e7f\u6cdb\u4f7f\u7528\u7684\u95ee\u9898\u3002\u5b98\u65b9\u662f\u5426\u53ef\u4ee5\u8003\u8651\u91c7\u7eb3\u8fd9\u4e2a\u7279\u6027\u3002\nhttps://github.com/NLPchina/elasticsearch-sql/issues/701\n\u57fa\u672c\u4e0a\u6765\u770b\u5c31\u662f\u589e\u52a0\u4e00\u4e2a\u9a71\u52a8\u7684\u5b9e\u73b0\u3002\n\u611f\u8c22\u3002. ",
    "mrfsong": "merge. "
}