{
    "blair": "Robey pulled these changes into his tree.\n. Robey merged this into his tree.\n. ",
    "robey": "thanks!\n. thanks!\n. agreed, the API would be better this way. (i left it as absolute time because i was in a hurry, not because i like it that way, so your way sounds better.)\n. this is fine, so if you code it up, i will merge it. :)\n. that sounds fine to me. you will also need to add a new variant of ADD in the journal -- maybe ADD_FLAGS. and just always write ADD_FLAGS but still be able to read ADD and ADDX.\n. send me the patch and i'll merge it. :)\n. i think it would be difficult to support, but i'll leave this bug open in case others want to vote on it.\n. hm, i didn't know there were many binary protocol clients. definitely something to consider then.\n. after talking to others about the binary memcache protocol, i don't intend to ever support it. apparently, in some clients, it's actually slower than the text protocol. i think for use cases where the speed of the network protocol has become a bottleneck (in other words, almost zero cases) :), a better story is to use the thrift protocol.\n. we use the same ganglia plugin for our memcached and kestrel servers.\n. if you telnet to port 22133 yourself and type \"stats\", do you get anything? (is it only the python script's connection that stops?)\n. dead bug.\n. patch taken!\n. ah, yeah, the string version is interpreted as a regex. (this API comes from java.) so \".\" means single-char wildcard in that context. :)\n. both of those sound fine. we pick servers at random, and if the queue is empty, sleep for a while (exponential backoff) and then try another.\njkalucki has been experimenting with a much more aggressive client in the \"grabby-hands\" project.\n. having a queue exist on only one (or even a subset) of the kestrels in a cluster would defeat the purpose of having the cluster, though.\n. we still generally have clients pick a server at random in ruby, using kestrel-client (https://github.com/twitter/kestrel-client). in java/scala, we have most clients connect to every server at once and launch a timeout-get on each one to minimize latency. those use grabby-hands (https://github.com/jkalucki/grabby-hands).\nis that what you meant?\n. whoa scary. the scala API docs claim that SuspendActorException is only thrown internal to actors, as a way of scheduling? this might be a scala bug. what version of scala are you using?\nas a workaround, i suspect that what's happening is that the actor library isn't getting initialized correctly. you might try to do something actor-ish before the removeReact call and see if you can trick it into getting initialized.\n. ahh, i see. sorry for the confusion. i think if you want to call the actor-based version from outside an actor, you could also do it from inside an actor Future. though, if you are wanting to do this outside of actors and just wait for the response, you can use the receive variants. \nif you post your branch, i can look at it and merge it.\n. i haven't made a release in a while -- my bad. i'll do that soon.\n. oops, that was me (robey) not twitter. :)\n. good idea -- done! :)\n. you could instead try writing the item to a different queue, with an expiration and a \"move_expired_to\" setting that punts expired items back to the main queue.\n. you can ask kestrel to poll that periodically with \"expiration_timer_frequency_seconds\".\n. ok, documented!\n. the journal is a journal of operations, so removing an item and acking an item are operations that are journaled. those operations should only take a few bytes each, though. eventually the journal is compacted so that it only contains live items.\n. That sounds like a bug. It should erase old journal files as they roll over. Can you file a new issue?\n. how much memory did you give kestrel with -Xmx? how big is the journal file?\n. it should rotate at 16MB if the queue is empty, or at 160MB if there is less than 16MB of stuff in it, but if you always have a lot of stuff in the queue, it won't be able to rotate the journal. was this queue backing up?\n. you can, if you give it more memory (-Xmx) or lower \"max_memory_size\" which is the amount of a queue it will try to keep in memory (default 128MB).\n. :( try turning down the max_memory_size to keep it from keeping much of the journal in memory. [but it will still take a really long time to read 140GB.]\n. try making it even smaller if that's a bottleneck. (it will use that much memory per queue.)\n. closing old issue.\n. what would it mean for a transaction to be open after startup, tho? once a client has disconnected, it has no way to close it, so the transaction is aborted. a restarted server seems to be the same state.\n. i'm not sure i like this idea.\nif the queue is filling up, the system is fundamentally overloaded, because the \"steady state\" of the system should be that there are at least as many consumers as producers, and the queue is empty. so if the system is overloaded, it's better to shed load quickly than to push the backpressure back up toward users.\nkestrel offers a few ways to shed this load: you can limit the queue size, and set a policy of refusing new work or dropping old work (in other words, prioritize old work, or new work). you can also just use your disks as the release valve, let the queues back up for as long as your disk lasts, and hope things recover. if they don't, you can manually flush the queues and throw away a big chunk of work. (we actually used to do this. in a crisis, it's better than going offline.)\n. yep -- thanks!\n. i believe that kestrel should disconnect if it gets a message it doesn't understand, because otherwise the client could get out of sync, and start mismatching requests & responses. we actually ran into this a few times on production memcache servers. but i'm good with adding any missing memcache commands that make it easier for memcache clients to connect to kestrel.\ni was able to reproduce odd behavior with\n$ (echo \"stats\"; echo \"gibberish\"; sleep 2) | telnet localhost 22133\nthat led me to believe that IoSession.close() in mina is sometimes closing the socket before writes are flushed. i made it \"close(false)\" explicitly and was no longer able to reproduce it.\nprobably a better solution would involve setting SO_LINGER, but the mina docs say that java nio behaves oddly when SO_LINGER is set, so maybe it's best to leave that alone for now.\n. forgot to mention: this is pushed to master now. please let me know if you still see bad behavior.\n. it looks like an i/o exception would bounce out to the handler and possibly disconnect the client. i guess we should catch exceptions when writing the journal, and kill the server if they happen, so that queues don't get into this weird state if the disk fills. does that sound okay?\n. i think you're right that it shouldn't try to continue as if nothing happened.\ni'm leaning toward catching i/o exceptions inside the journal code, and writing a fatal log message and calling system.exit. it would be an unambiguous signal that something has gone wrong with the machine, and i think if the machine is hosed, kestrel shouldn't try to paste over it.\n. i don't think pgrep is on linux. :(\nthat's kinda maddening that they expose a --running option that doesn't actually work. do you think we should file a bug?\n. oh! i bet the BSD \"daemon\" is an entirely different beast. that's probably the root problem.\nyou can get the libslack \"daemon\" here: http://libslack.org/daemon/\n. sorry, we just updated where we store the standard-project plugin, and i forgot to update kestrel at the same time.\nit should be fixed now!\n. merged and published as 1.2.6.\n. try the version-1.2.6 tag. it all uses sbt now.\n. weird that \"git push\" doesn't do the right thing. tags are pushed now.\nyou need to do \"sbt update\" to do the maven dependency-fetch phase.\n. weird! is kestrel still responsive to other clients when that happens? i wonder if smile is using up some resource in the actors library.\n. cool! please do let me know how that goes, and if it solves the problem.\n. we've been slowly phasing out smile in favor of grabby-hands, which seems to have more predictable behavior.\n. I seem to remember that stack traces can be dropped if the code was JIT'd by the java runtime. You might be able to turn off JIT with an option like \"-client\".\n. i think it might have been confused by the multiple versions of the actors lib. can you update to master and try again? (i may have fixed it.)\n. reopen if you run into this again!\n. it looks like you're getting a copy of Time from somewhere else besides xrayspecs, but i don't know where that might be. :(\none thing you could do is try the release_2_0 branch, or wait a day for me to switch the branches over myself, after which master will be 2.0.\n. thanks -- applied!\n. i need to go to teatime now, but i'd also like to see more tests around how this affects read-behind, since i'm a little hazy on it. i'll try to hack on it on the train.\n. looks like it will work fine with a newer version of xrayspecs, so i updated the xrayspecs version and pushed. the newer xrayspecs has a pom file.\n. we don't use xrayspecs anymore.\n. i'm sorry for the slow reply.\nthe fact that set worked fine while get slowed down strongly suggests read-behind to me. when the queue gets larger than 128MB (configurable), it stops storing new items in memory and only writes them to the journal. it also opens a new file pointer into the journal to \"read-behind\" as new items are needed. so every get will cause the read-behind pointer to read through the journal, looking for added items, and adding them to memory until it hits 128MB again.\ni suspect you simply ran out of disk bandwidth. you can check \"iostat -x\" on the boxes, but when it drops into read-behind and starts reading & writing to the same journal file, it may cause the disk to do seeks (unless the kernel is aggressively caching the journal).\nwe just ran into a similar problem on new boxes that we accidentally set up with single, small disks. individual disks didn't have enough i/o bandwidth for our traffic, and we had to bump them up to 2 striped disks. adding more kestrels to the pool would also work, by splitting up the bandwidth more.\ni think 2.0 / 2.1 handle large numbers of connections better, but it sounds like that wasn't your problem at all, so i wouldn't bother upgrading yet.\nif you have a ton of memory, and only one queue you worry about, you could set the max-memory-size on that queue really high, and it won't drop into read-behind until it fills up that much memory. so if you have a 16GB box, you could probably bump one queue's max-memory-size up to 4GB, as long as you make sure to give the jvm 8-12 GB. :)\nbtw, thanks for the very thoughtful, thorough description of the problem. \n. can you try again? that url (http://maven.twttr.com/com/twitter/standard-project/0.7.17/standard-project-0.7.17.pom) is working for me.\n. i think that exception is harmless.\nhow many queues do you have running? how many clients typically connect to it?\n. Hm, yeah, none of those are particularly high numbers. You're definitely not running out of fds at 100 clients.\nYou might lower the max_memory_size: with 50 queues, if 10 of them fill up, that's 5GB (which is more than can fit in a 6GB JVM because of the way garbage collection works).\nThings you can check: heap usage; the GC log (is it spending a lot of time in GC when it crashes?); how backed up the queues are.\n. a leak is a possibility. :( [1.2 uses mina instead of netty.] but it's more likely that there just isn't enough heap space for the queues that are backing up.\nyou can try adding more heap space -- when java is given 6GB, it can't actually use all 6GB for the app, because of GC overhead. you can also try reducing the memory size of queues, to keep less stuff in memory.\n. We have our kestrels monitored by ganglia, but any monitoring system will do. At worst, set up a cron to pipe kestrel's \"stats\" output to a file. What you want to do in see (ideally, graph) curr_items and curr_connections and correlate those to misbehavior. We run our kestrels pretty hot, and generally if one crashes, it's due to running out of file descriptors or running out of heap.\nThe logfile you posted makes it pretty clear that the JVM just ran out of heap, and was growing gradually the whole time.\nWe're currently running 1.2.2 on most machines, it looks like, so if regressing to 1.2.4 works, that would be a valuable data point that 1.2.8 has some kind of leak. (We're also in the process of upgrading to 2.1, but I'll post to the mailing list as that happens. We'll almost certainly find a few bugs as it rolls out.)\n. no keep em coming. :)\n. dammit. you're right; this is broken.\n. ok, hopefully fixed.\n. wow, thanks for the detailed info!\ni don't remember anymore why i thought the receive buffer size was important -- maybe i was trying to cut down on memory use when there are tens of thousands of clients (which is how we normally run). i'll remove that line immediately.\n. performance looks good -- committing!\n. #1 should be right. what is your problem with the interface?\n. thanks! also gonna add a test for that.\n. this is the 2.2 branch now.\n. it looks like it's trying to find a special scala-2.8.1 build of sbt.... but why?\ncan you confirm that your build.properties has these versions in it?\nproject.organization=net.lag\nproject.name=kestrel\nsbt.version=0.7.4\nproject.version=2.1.0-SNAPSHOT\ndef.scala.version=2.7.7\nbuild.scala.versions=2.8.1\nproject.initialize=false\n. Ah, yeah, we haven't started trying to deal with sbt 10 yet. :) It's a whole new beast.\n. this usually means that ostrich can't find the build.properties file inside its jar.\nwhich branch are you on? how are you starting kestrel?\n. yeah, that might be true. i think the only reason it happens synchronously right now is for simplicity. in theory, each \"get\" in read-behind mode will lead to approximately one item read back in from disk, but there's no reason to delay client responses for it.\nit could work like the journal-packer thread, just receiving work for refilling queues, and would have the benefit of ensuring that only one queue is being refilled at a time.\n. hm, but a failing test means the server isn't working. what branch are you on?\n. Can you try again? Nested deep inside that error message is a line where ivy is asking you to retry, probably because it got disconnected in the middle.\n. if syncJournal is not 0 or max, the promise should be added to the \"promise list\" (promises). then the periodic timer on line 20 will call fsync, which sets the promise values on line 31.\n. future() causes it to block, waiting for the future to be fulfilled.\n. that's weird. it looks like it crashes when trying to find out what git revision you're building from. is there anything notable about your git checkout folder?\n. i think standard-project 1.0.4 may have just fixed the \"you have no branch\" bug.\n. oh, that might be a known bug with the older version of ostrich i was using.\ni just upgraded to the latest ostrich on master. can you try again?\n. it comes from libslack, and usually has a package name like \"libslack-daemon\".\n. i guess i really only want \"version\" from here. i want to keep the stats on the admin/stats port. i'll copy the \"version\" bit manually but still give you credit. :)\n. done!\n. merged!\n. related feature request from john k:\n\"An ephemeral fanout queue that streams to you. Open a socket and messages. Close the socket, and, like Markinson, you were never there. There is no Markinson.\"\nsounds similar enough to be part of the same feature. (a markinson child queue would just be a child queue with a destruction timeout of zero.)\n. ooh good catch.\n. doh, i think i even fixed this once before. i see the problem: flushExpired is grabbing a lock it doesn't really need.\n. i put a potential fix on branch \"deadlock\". jeff, is that similar to what you did?\n. oof, that certainly explains things.\nHashedWheelTimer is just a relatively fast timer -- it sleeps a constant time (10 msec in our case) between each check, so it fuzzes out accuracy in exchange for speed.\nthe ScheduledThreadPoolExecutor looks like a pretty big change, you're right. :)\nmaybe the expiration timer should be in its own thread. then it wouldn't conflict with the timer events that are just doing an fsync.\n. easily reproduced this by configuring queue \"slow\" to have\nsyncJournal = 10.milliseconds\nand running\n$ sbt \"flood -q slow -n 100\"\n. it's true that the journal shouldn't force you to wait for the fsync on remove since it doesn't do that on add.\n. okay, i moved the timer to a separate thread, and fixed the remaining journal operations to avoid waiting if the fsync is happening on a timer.\nthe timer thread move fixed the \"flood\" test above for me. the fsync change is a little riskier, but i convinced myself that this is remainder code from before you could set fsync on a timer, so it shouldn't hurt anything.\nthe branch is \"futures\". i'd love comments/review.\n. yeah, i think the background thread only makes sense if you have a whole server. my assumption is that people using kestrel as a library are really just using PersistentQueue directly.\n. merged!\n. definitely.\n. oops! we removed it a long time ago, because it's redundant when you can't change config on the fly. docs fixed now!\n. this is becoming a common request -- i'll add it to the roadmap. :)\n. it sounds like the first use-case would be satisfied by checking that the queue is empty, and that it has an age > (some duration).\nthe second use-case, dropping messages that nobody's listening for anymore, would require the check to happen even if the queue isn't empty. but that use-case seems a bit more dubious to me -- i worry about lost jobs.\n. oh yeah, expiring items would solve case 2. :) so i think your implementation would work well. and a check in flushAllExpired sounds like the right place.\n. oh, i see, _currentAge doesn't change when the queue is empty, so you really want to know \"how long has it been since something was read from this queue\".\nmaybe just add a field \"lastReadTime: Time\" and set it whenever something is read (or expired)?\n. i think this got merged in. :)\n. wow, thanks for digging into this!\nyour analysis sounds right to me. i just added options to \"many_clients\" to allow the clients to be transactional and to kill off N% of them on each round. i only had to try that once, with 10% kill rate, to get the test to fail to complete (on master). open transactions just got lost. merging in your first 2 fixes makes the test complete.\ni'm going to merge those into master.\n. the stack-depth problem is pretty interesting. we have a branch of kestrel (release_3_0) that uses finagle instead of netty directly -- since finagle is netty-based, it really just lets us remove some glue code. and finagle has occasionally had this issue with its recursive callbacks.\nhavoc wrote a nice blog post about this problem:\nhttp://blog.ometer.com/2011/07/24/callbacks-synchronous-and-asynchronous/\ni think the right answer is to modify the future library (in util-core) to allow configuring a \"completion\" thread-pool (really, an executor) where completed futures are posted. that way, fulfulling a future would never start another nested call.\n. i think the problem stated in the bug is now fixed.\n. that change sounds great to me!\n. renamed it to removeCounter (because clearing a counter already has a meaning) and merged!\n. just merged it in now, and your branch -- i refactored it a bit to keep all the counter/gauge code in PersistentQueue.\n. nice!\n. yeah, i think the right thing to do there (and the intention) is to stop at the point where the journal ends (or is corrupted). so this is reasonable to me.\n. fixed by 72\n. ok, the version on head should now dump errors to stdout if the server isn't capable of starting (either because of a missing config file, or a broken queue folder).\n. it should be using sbt for scala 2.7, not 2.9.1. did you change something to try to use 2.9.1?\n. no, the tests should work without a kestrel running. attach the failed test info if you can.\n. i think you're right! thanks!\n. hopefully that got fixed in 2.1.4.\n. oh, i didn't know it was optional! but your version works in bash too. :) thanks!\n. thanks!\n. yeah, sorry about that. we fixed it in the 2.2 and 3.0 branches sa that many-clients does a flush just like the others, but it would be hard to backport to master because the load tests changed so much (to factor out the memcache protocol vs thrift protocol).\nfor now, you can flush the queue just by telnet'ing to port 22133 and sending \"flush spam\".\n. mccv is working at porting standard-project over to sbt 11, so there may be a light at the end of the tunnel here soon...\n(hope i didn't jinx it.)\n. ok! release_2_2 and release_3_0 branches are now using sbt 11.\n. that would be cool!\n. hm, i wonder if it's a race.\nif you replace line 297\nkestrel.queueCollection.queue(\"slow\").get.waiterCount mustEqual 0\nwith\nkestrel.queueCollection.queue(\"slow\").get.waiterCount must eventually(be_==(0))\ndoes that fix it?\n. i committed the fix since it at least doesn't make the test any worse. :)\nthe current stable release is master (2.1). sorry about the branch confusion. the 2.2 and 3.0 branches are in active development, and may work fine, but haven't been released yet.\n. in the thrift API, a client passes the timeout along with the GET request.\nover memcache and the text protocol, the item stays open until the client either confirms, aborts, or disconnects. a disconnect is treated as an abort.\n. this might be easier to do in thrift.\n. thanks! :)\n. mostly nitpicky style comments, but i like this overall!\n. good after that!\n. thanks! :)\n. sorry, i totally lost track of this one.\n. merged!\n. the server is crashing, or the client?\nif it's the server, can you post the stack trace from the log?\n. no problem. :)\nyou can see kestrel's internal timings for set latency by hitting the admin port:\n$ curl \"localhost:2223/stats.txt?period=60\"\n...\nmetrics:\nset_latency_usec: (average=20, count=2, maximum=21, minimum=19, p25=19, p50=19, p75=21, p90=21, p95=21, p99=21, p999=21, p9999=21, sum=41)\nif those numbers are big, it's usually because the disk is getting a lot of use. (the slowest thing kestrel does, normally, is write the journal.) you can check that with \"iostat\" on linux.\nif kestrel is reporting low latency, but you see high latency from your client, it might be the network.\n. sorry for taking a while to reply!\n. consider the parrot code to be a \"preview release\". :) sounds like we jumped the gun on publishing that load test, because parrot isn't open-sourced yet. sorry about that.\ni just talked to James Waldrop, and he says they plan to open-source it by june. if you're especially interested in it, he'd love some more beta testers... :)\nuntil then, there are some single-machine load tests in scripts/load/ that at least stress the code in some simple cases.\n. i don't know of any for nodejs, but in theory a nodejs memcache client should work.\n. what version of kestrel is this?\none thing you can do is look at \"stats\" on your running servers. if any of them have a transaction open even when there are no jobs, then something is holding open that transaction.\n. one other thing you can try is: the next time this happens on a queue, make a copy of that queue's journal file.\nthen, dump it with \"qdump.sh\" (in the scripts/ folder), which will show you the operations happening on that queue recently. with \"-d\", it'll also dump out the job contents. if you see the old job in there around the time a consumer got it, that would at least tell us that kestrel perceived the job as being added around the time it handed it to a consumer. if you don't, then something much weirder is going on. :)\n. thanks!\n. closing as duplicate of issue 96.\n. oops, forgot the magic for github autoformat:\nissue #96\n. this is on kestrel 2.1.5?\ni can't see anything obvious in LatchedStatsListener that collects memory. do you have any other clues? is there stuff being reported through the stats API that you don't think should be there (like: is it reporting on more queues than actually exist, or something like that?)\n. I just did a diff from fbc5548 to head, and this change looks relevant:\n```\n@@ -405,6 +427,11 @@ class PersistentQueue(val name: String, persistencePath: String, @volatile var c\n     Stats.clearGauge(statNamed(\"waiters\"))\n     Stats.clearGauge(statNamed(\"open_transactions\"))\n     Stats.clearGauge(statNamed(\"create_time\"))\n+    Stats.removeMetric(statNamed(\"set_latency_usec\"))\n+    Stats.removeMetric(statNamed(\"get_timeout_msec\"))\n+    Stats.removeMetric(statNamed(\"delivery_latency_msec\"))\n+    Stats.removeMetric(statNamed(\"get_hit_latency_usec\"))\n+    Stats.removeMetric(statNamed(\"get_miss_latency_usec\"))\n   }\nprivate final def nextXid(): Int = {\n```\nthat fixed a bug where 5 metrics per queue were not removed from the stats tables when a queue was deleted. if you do have a series of temporary queues, this sounds like it's probably the problem.\nsorry about that.\nthe oldest commit with the fix looks like: 58a75aa42bff81b9ac6b70a82d66b3ce7b1b0be1\ni will try to do a release soon to get these fixes out.\n. well, that's pretty straightforward. thanks! :)\n. well, thanks for filing it anyway. :)\n. Sorry for the delay -- I was out of town for a while.\nThere are two scripts built with kestrel that should help here:\n$ ./dist/kestrel/scripts/qdump.sh --help\nThat will dump out a (sort of) human-readable list of the operations in a journal file, without the associated data. It might be useful for figuring out what's messed up, although if the journal is \"hundreds of gigabytes\", it might be too time-consuming to matter.\n$ ./dist/kestrel/scripts/qpack.sh --help\nThis takes a set of journal files and packs them into their minimal operations (usually one ADD for each item that's currently in the queue). You should take the bad server out of rotation, run this script on its journal files, and then start it back up again with only the new journal file. (You can delete the old ones after it's finished packing the new one.) It might be helpful to \"qdump\" the new file before starting, in case there's something wonky.\n. It is, but I don't think Twitter has upgraded to scala 2.10 yet. :(\n. i think this could be simplified by just copying addWithXid. it looks like writeLarge will copy the buffer over again.\n. i think fillReadBehind needs to track these also.\n. this isn't really used after fixing continue (above).\n. there's a confirmation dialog down here .....\n. here!\n. it should do help if you add \"--help\", don't give a known command, or don't give any command. \"puts parser\" prints out help. (i know, it's a weird API, but that's how they have it doc'd.)\n. indentation, but i can fix it in post... and actually, i think we should use \":\" here since it's returning a string.\n. i'd rather not do stats this way anymore. you can get them from the admin port in json or text, which is much more supportable.\n. if config.maxQueueAge isn't defined, \"get\" will throw an exception. you can omit this line entirely and just start with #154 below...\n. ... which i would start with \"if (config.maxQueueAge.isDefined &&\" to shortcut out right away unless a maxQueueAge is defined.\n. i would move this comment to Kestrel.scala#157 where it makes more sense.\n. sorry to fuss over the wording here, but how about something like\n\"Whole queues can be configured to expire as well. If maxQueueAge is set, expirationTimerFrequency is used to check the queue age. If the queue is empty, and it has been longer than maxQueueAge since it was created, then the queue will be deleted.\"\n. here and elsewhere, use \"if (\" with a space, and remove the blank line at the beginning of the function.\n. this isn't true, since it's an Option. i'd just delete this line.\n. if (\n. delete this line. :)\n. ",
    "matterkkila": "Any thought on supporting this in future version?\n. Reposting with a patch.\n. ",
    "Mistobaan": "I just stumbled upon this error when I tried to use EnymMemcache + Protobuffers. I solved by forcing the client to always deserialize using ProtoBuf\n. ",
    "tenorviol": "This may be related. I've been working on integrating kestrel into a php driven site, using php's memcached class. By default this compresses payloads greater than 100 bytes. In my tests I've noticed a problem in the interaction between the memcached library and Kestrel. It does successfully compress large payloads, but does not decompress them. For now this can be solved by turning off automatic compression, but I suspect there is some underlying problem in the protocol. Will post more as/if I learn it.\n. Er. Actually, the problem described is more likely related to the one in, \"Recognize flag byte in memcache set\".\n. This may not be relevant given the migration to sbt. I was looking at this fragment in ant/package.xml:\n\n\n\n\n\n\n\n\n\n\nThis made me think you might add a:\n<filter token=\"VERSION\" value=\"${where.the.damn.version.is}\" />\nAnd modify scripts/kestrel.sh with:\nVERSION=\"@VERSION@\"\nOr something. It's an idea. Could be crap.\n. Awesome. We're going to try this out and will repost the result. Thank you!\nIncidentally, we already tried the quit fix. Didn't solve the problem, but I like having that command available.\n. We are running this fix on our staging server, and no longer see the WriteToClosedSessionException. Thank you again for addressing this.\n. ",
    "Suhail": "You can kind of hack together a munin plugin via the memcache one.\n. I resolved it to the following:\n- Connect to random queue\n- Read item\n- Continue to read items until queue hits 0, if it hits 0 connect to a NEW queue via round robin. \nWhen all queues are zero, it will simply just bounce between them (which is kind of shitty) so I set a higher /t=/open\n. Sounds like you'd have to continuously poll the \"delayed\" queue; is that what you're suggesting also?\n. Is this in the docs?\n. Can you document how \"move_expired_to\" works and how to use it? Also, can you decide whether it gets added to the head/tail of the queue? That would be good to control that.\n. Journal is massive: 140G and the memory I gave was around 7k MB\n. It's odd that it didn't rotate at the default 160MB level set by my config.\n. yes it was; basically we lost data due to it....you can't restart kestrel in that instance.\n. the journal file got to 140G and I only had 8G of memory...still failed even when I raised it.\n. It's max_memory_size = 134217728 which is 128 MB =\\\n. There's only two queues though. I can try though...\n. ",
    "rtyler": "I had a similar issue that I believe was a regression with Scala 2.7.7, I changed ivy/ivy.xml to use 2.7.5 (see: SHA: 54713ab79197273850adc84a27a0d8657b47628a) instead and everything works fine now.\n. I should also add that we're using \"reliable reads\" in conjunction with the t parameter, i.e.:  get SomeQueue/t=5000/close/open\n. So after a hectic night of debugging this (in production no less), the ultimate solution was to further expand the Kestrel cluster (oof). \nFrom my observations a couple things seemed to be happening:\n- Instance gets overwhelmed with new connections: We only started seeing issues after we switched all publishers and consumers to the instance. As the deployment stepped from 1, to 2, to 3 machines we noticed no issues. Only when everybody opened connections and started transactions did we see issues\n- set commands appeared not to be delayed: All publishers continued working properly without issue, it was only the consumers on backlogged queues that seemed to be throttled.\n- Process did not run out of file descriptors: many of the tell-tale signs that a daemon is being overwhelmed weren't there. Past a few Mina exceptions, the logs and the process looked clean\nAs far as our environment goes, we monitor all queues as well as set and get commands, which look even to me (no fanout queues). Only our high traffic/through-put queues saw issues.\nI'm not sure where to leave this or what to do with this information\n. ",
    "hugohallqvist": "Too bad I didn't find your changes before wasting a couple of hours debugging... :-)\n. ",
    "qhoxie": "These should both behave the same.  Did you see this cause a problem somewhere?\n. ",
    "durana": "My mistake.  I was working in the Scala interactive shell while reading through this code.  I tried to split a string on \".\" and \"blah.blah\".split(\".\") does not appear to behave the same as \"blah.blah\".split('.').  I assumed it was the difference between \".\" being a String and '.' being a Char.  I feel stupid now for not actually trying it with \"/\" before submitting this. ;)\n. ",
    "elephantum": "As far as I understand reading None is not an issue at twitter. AFAIK: they have some (3, I guess) kestrel servers and a lot more workers. Each worker does the following: choose random server, read message, process message, repeat (may be chosen server is used for several iterations since operation like /close/open exists).\nAnyway workers outnumber servers and choose server at random, so, eventually, each server would be read without any complicated logic.\n. ",
    "ebarlas": "Would it make sense to select a kestrel server based on the hash of a queue name?  It seems to me that would be most efficient, though you may end up with small queues on some kestrel servers and large queues on others.\n. It's been a year since this thread was active.  Any news on ways to distribute kestrel?  Preferred or best client policies?\n. Yeah, that's exactly what I was wondering.  I will look into those clients.\n. I am using scala version 2.7.7.  Are you able to reproduce this?  What version of scala are you using?  I'll try doing something actor-ish and report back later.\n. After playing with scala a bit I took another look at this issue.  It seems that when kestrel is accessed as a library, a scala actor contract is violated.  In PersistentQueue.operateReact, reactWithin is invoked.  According to scala docs, the code after a react invocation is unreachable.  In practice, scala achieves this by throwing an exception.  When invoked as a library call, this exception propagates back to the client code.  When invoked through a memcache GET, the call is made by the KestrelHandler actor and things work normally.\n. I added a removeReceive function to QueueCollection that invkokes PersistentQueue.removeReceive so that QueueCollection can be invoked as a library outside of the KestrelHandler.\n. Hmm, I just looked at the history for PersistentQueue and apparently you fixed this.  Why is this not part of the most recent build?\n. Closing.\n. Ah, right.  Jeez, I've been using Kestrel as a library and I forgot about the connection semantics.  I'm using an HTTP front end, so I lost sight of that.\n. Closing.\n. Hmm, possibly.  The best approach, I suppose, would be to rollback journal operations, but it seems to me that simply isn't possible with the current system.  Another approach is to place I/O operations ahead of in-memory data structure operations to raise I/O exceptions before modifying the queue, transaction table, or other PersistentQueue data.  That should keep the PersistentQueue in a consistent state.  Yet another approach is to close and reopen the queue on I/O Exceptions, however this may seemingly result in a huge number of journal reads as the journals are replayed.  Perhaps this is just something to be aware of and need not be addressed?\n. Thoughts?\n. Okay, that does seem reasonable.  One problem is that it might adversely affect folks using Kestrel as a library since the proposed fix would shutdown the JVM.\n. ",
    "twitter": "it looks like it's 1.2 in head (but the version has bumped to 1.2.1, so i fixed that again).\nhow could ant help here? i'd love if there was some way. :) though i've pretty much migrated to sbt now.\n. ",
    "andrewclegg": "I know this issue is long closed, but I can't find an answer anywhere else.\nWe have queues where there are hundreds of gigabytes of old journal files for queues that currently have items=0. Obviously this takes up a lot of disk space, but it also means Kestrel takes ages to start up, as it replays all those old operations.\nHow can we force Kestrel to compact them?\n. We've just had the same situation occur that @kperi described above.\nI'm trying to rescue the situation without losing any data, but when I try to run qpack.sh on the out-of-control journal files, I get errors like these:\nPacking journals...\nPacking: 2.2M   2.2M  Exception in thread \"main\" net.lag.kestrel.BrokenItemException: java.io.IOException: Unexpected EOF\n        at net.lag.kestrel.Journal.readJournalEntry(Journal.scala:414)\n        at net.lag.kestrel.Journal.next$1(Journal.scala:422)\n        at net.lag.kestrel.Journal$$anonfun$next$1$1.apply(Journal.scala:427)\n        at net.lag.kestrel.Journal$$anonfun$next$1$1.apply(Journal.scala:427)\n        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1060)\n        at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1052)\n        at scala.collection.immutable.StreamIterator$$anonfun$next$1.apply(Stream.scala:952)\n        at scala.collection.immutable.StreamIterator$$anonfun$next$1.apply(Stream.scala:952)\n        at scala.collection.immutable.StreamIterator$LazyCell.v(Stream.scala:941)\n        at scala.collection.immutable.StreamIterator.hasNext(Stream.scala:946)\n        at scala.collection.TraversableOnce$FlattenOps$$anon$1.hasNext(TraversableOnce.scala:391)\n        at scala.collection.Iterator$$anon$22.hasNext(Iterator.scala:457)\n        at scala.collection.Iterator$class.foreach(Iterator.scala:772)\n        at scala.collection.Iterator$$anon$22.foreach(Iterator.scala:451)\n        at net.lag.kestrel.JournalPacker.apply(JournalPacker.scala:73)\n        at net.lag.kestrel.tools.QPacker$.main(QPacker.scala:65)\n        at net.lag.kestrel.tools.QPacker.main(QPacker.scala)\nCaused by: java.io.IOException: Unexpected EOF\n        at net.lag.kestrel.Journal.readBlock(Journal.scala:443)\n        at net.lag.kestrel.Journal.readJournalEntry(Journal.scala:382)\n        ... 16 more\nThis suggests one possible reason for the journals not getting packed automatically: the journal packer thread is failing on corrupt journal files because of this exception.\nI couldn't find any direct evidence of this in the log files, but then, the disks were full due to this issue, so maybe the logger couldn't write the appropriate stacktrace. A bit speculative, but it's all I've got so far...\n. Note: there were a lot of timestamped journal files with size 0, but I removed all of these first before trying to run qpack.sh.\n. ",
    "stevej": "I implemented QUIT in a branch called quit_works. Robey, would you mind giving it a quick glance and telling me if you think it's sufficient?\n. tcpdump output and an example script that exercises the bug would be extremely helpful.\n. this is fixed now.\n. ",
    "stevencorona": "interestingly, pgrep is on my gentoo box & daemon is not, heh. I don't know if it's a bug, as far as I can tell FreeBSDs daemon is a different tool than on linux. In fact, it seems like it even ignores the --stdout and --stderr flags. \nWhat if I just replaced pgrep with some \"ps | grep\" action?\n. Thanks, I'll check that out\n. ",
    "skaurus": "Thanks, it works!\n. ",
    "mccv": "I misunderstood the question originally.  Which branch/sha are you trying to build against?  I verified an sbt update against a clean ivy cache on my machine.  Can you try pulling the latest to see if it works?\n. ",
    "twilliam": "I checked out the release-1.2 tag and typed \"ant\", which is what someone on the internet told me to do. It complained about those errors. Someone else told me to run \"sbt +update\" on that branch it that took a long time but it finally compiled.\nWhat is the right way to compile this from scratch?\n. I don't see that tag. Did you push --tags?\n. Looks like it is meant to be on 91bc51d. I get a bunch of errors when I compile that though: \n[info] Compiling main sources...\n[error] /tmp/kestrel/src/main/scala/net/lag/kestrel/Journal.scala:23: value twitter is not a member of package com\n[error] import com.twitter.xrayspecs.Time\n[error]            ^\n[error] /tmp/kestrel/src/main/scala/net/lag/kestrel/Journal.scala:24: value configgy is not a member of package net.lag\n[error] import net.lag.configgy.{Config, ConfigMap}\n[error]                ^\nScala novice here to lmk if I'm doing something wrong.\n. Ok, checking out that tag followed by \"sbt update\" followed by \"sbt compile\" now works successfully, even with a clean ivy cache. Thanks!\n. ",
    "przemek-pokrywka": "Kestrel server works fine - for example if I restart only the Kestrel client's JVM, everything starts to work correctly again. One of used-up resources is certainly my actor's thread - it gets blocked forever, because (as it seems) MemcacheConnection.serverActor does not respond. I have not checked why the serverActor stops to respond - does it get an exception or something? At this moment I'm trying to upgrade to Kestrel 1.2.6, because I've got an impression, that Smile is no longer used there.\n. Hm.. It's a Smile bug of course, I should notice it in the first place. Regardless of that, I can see, that the latest sources of Smile are potentially affected by this bug too. MemcacheConnection still sends !? Store to the serverActor without any timeout. I have patched the most recent release, giving hardcoded 20-second timeout and will see if it's going to help.\n. I've deployed my patch to production this morning. I think it will prevent my threads from hanging, but who knows what else side-effect can be lurking there. I plan to observe it for several weeks, as the described problem has been occuring with a dose of randomness until now.\n. The timeout did the trick - threads stopped to hang.\nHowever it uncovered a deeper problem, which I'm going to post as a separate issue - this time to Smile and Kestrel as well, because both seem to misbehave. In some random moments (few hours up to few days from restart), there are NPE's in MINA at Kestrel's side and some strange \"ArrayIndexOutOfBoundsException null\" without stacktrace at the client. Connections go crazy (up, then down constantly) and client runs gradually out of file descriptors.\nAnyway, should anybody need mine fix, it is at https://gist.github.com/981598\nHaven't made the timeout configurable - it should work for most of people in the current form (20s).\nShould you include the fix in Smile, I think the current issue could be closed.\n. Switched to grabby-hands. That helped, thanks.\n. It's a performance-optimization pattern to throw exceptions without\nstacktrace, because generating stacktrace takes some precious time. You'd\nneed to look at source code, because I'm not sure what's the exact\nmechanics.\n. Good point :) Nevertheless, I don't really know the gory details, the code\nwould answer that.\n. ",
    "tsuna": "Sorry to awaken this old thread, but I'm troubleshooting a similar (but different) issue and I'm wondering how is it possible that get an ArrayIndexOutOfBoundsException without a stack trace?  Is some code catching it and removing the stack trace with setStackTrace or what?\n. I know that, but ArrayIndexOutOfBoundsException is part of the JDK, unless you somehow change the JDK to override ArrayIndexOutOfBoundsException.fillInStackTrace(), how can ArrayIndexOutOfBoundsException not come with a stack trace?\n. ",
    "mw46d": "I'm running 1.2.8 now without any problems. Thanks.\n. ",
    "joshbuddy": "Yeah, the writeLarge was a bit of scaffolding in between two things. Purely vestigial. I've fixed some things, so have you, this should get cherry picked back into release_1_2 as well once you sign off.\n. ",
    "tjulien": "yeah, working for me now as well.\n. ",
    "mihneagiurgea": "We have 50 queue, but most of them (~35) have very low traffic (<1000 per day). The number of clients tipically connected is around 100. \nThe number of operations is around 1.400/second.\n. We noticed that when it crashes, the following error is written to nohup (not the kestrel log, but the nohup.out were it was started from):\n\njava.lang.OutOfMemoryError: Java heap space\n        at java.lang.Class.getDeclaredMethods0(Native Method)\n        at java.lang.Class.privateGetDeclaredMethods(Class.java:2427)\n        at java.lang.Class.getDeclaredMethod(Class.java:1935)\n        at scala.runtime.RichString.format(RichString.scala:240)\n        at net.lag.kestrel.KestrelHandler$$anonfun$get$2.apply(KestrelHandler.scala:218)\n        at net.lag.kestrel.KestrelHandler$$anonfun$get$2.apply(KestrelHandler.scala:212)\n        at net.lag.kestrel.QueueCollection$$anonfun$remove$1.apply(QueueCollection.scala:148)\n        at net.lag.kestrel.QueueCollection$$anonfun$remove$1.apply(QueueCollection.scala:142)\n        at net.lag.kestrel.PersistentQueue.operateReact(PersistentQueue.scala:292)\n        at net.lag.kestrel.PersistentQueue.removeReact(PersistentQueue.scala:334)\n        at net.lag.kestrel.QueueCollection.remove(QueueCollection.scala:142)\n        at net.lag.kestrel.KestrelHandler.get(KestrelHandler.scala:212)\n        at net.lag.kestrel.KestrelHandler.net$lag$kestrel$KestrelHandler$$handle(KestrelHandler.scala:113)\n        at net.lag.kestrel.KestrelHandler$$anonfun$act$1$$anonfun$apply$1.apply(KestrelHandler.scala:68)\n        at net.lag.kestrel.KestrelHandler$$anonfun$act$1$$anonfun$apply$1.apply(KestrelHandler.scala:66)\n        at com.twitter.actors.Reaction.run(Reaction.scala:79)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n        at java.lang.Thread.run(Thread.java:662)\n\nAt the time of the crash all queue sizes were relatively small (a few of them around 20-30 MB, and the rest < 500 KB).\n. We restarted java with -verbose:gc to see what garbage collection was doing.\nThese are the last lines of gc.log, after around 3 hours of running (before crashing). The number of items remained constant throughout these 3 hours.\n\n11298.686: [Full GC 1521716K->1521716K(1578432K), 1.1662680 secs]\n11299.852: [Full GC 1521716K->1520693K(1578432K), 2.0338540 secs]\n11301.901: [Full GC 1521726K->1521726K(1578432K), 1.1637670 secs]\n11303.065: [Full GC 1521727K->1520726K(1578432K), 1.9922750 secs]\n11305.077: [Full GC 1521726K->1521726K(1578432K), 1.1747770 secs]\n11306.252: [Full GC 1521726K->1521726K(1578432K), 1.1726630 secs]\n11307.425: [Full GC 1521726K->1521726K(1578432K), 1.1758330 secs]\n11308.601: [Full GC 1521726K->1520851K(1578432K), 2.0171970 secs]\n11310.622: [Full GC 1521727K->1521727K(1578432K), 1.1734600 secs]\n11311.795: [Full GC 1521727K->1521727K(1578432K), 1.1749680 secs]\n11312.971: [Full GC 1521727K->1521727K(1578432K), 1.1907470 secs]\n11314.162: [Full GC 1521728K->1520970K(1578432K), 1.1750460 secs]\n11315.340: [Full GC 1521727K->1521727K(1578432K), 1.1664440 secs]\n11316.507: [Full GC 1521727K->1521727K(1578432K), 1.1724850 secs]\n11317.679: [Full GC 1521727K->1521007K(1578432K), 1.1712050 secs]\n11318.863: [Full GC 1521727K->1520790K(1578432K), 1.1731550 secs]\n11320.039: [Full GC 1521727K->1521727K(1578432K), 1.1760910 secs]\n11321.216: [Full GC 1521727K->1521727K(1578432K), 1.1724200 secs]\n11322.389: [Full GC 1521727K->1521727K(1578432K), 1.1749710 secs]\n11323.564: [Full GC 1521727K->1520987K(1578432K), 1.1942830 secs]\n11324.761: [Full GC 1521727K->1521727K(1578432K), 1.1956870 secs]\n11325.957: [Full GC 1521727K->1521727K(1578432K), 1.1730420 secs]\n\nThe entire log is here: http://pastie.org/1871509\nAny ideea what this means? We restarted our production environment using 1.2.4 instead of 1.2.8, to see if this changes anything (in case there's a memory leak in 1.2.8).\n. The items on our queues are being constantly processed, and are not clustering up. The queue sizes remain approximately constant while kestrel is running, so I don't see why there would be a need for more heap space.\n. ",
    "imownbey": "Feel free to merge in if you dont care about my comments\n. +1\n. Does this work? I thought would want handler.getItem(...)() must beString(\"one\")\n. Confirm? :/\n. Some kind of help? I can write this myself if you dont want to\n. ",
    "Nyu2Y": "thanks \n. i have a problem , why 'if (allowSync) future() ' futrue with ''()''?\nwhats the different between future() and future at in kestrel / src / main / scala / net / lag / kestrel / Journal.scala  line:471\n. ",
    "eric": "I did a brew install sbt and it looks like someone updated sbt from 0.7.7 to 0.10.0.\nI just did this to get the older recipe:\n$ git checkout 36d0c6211c876312ee7dde4fa87784fc48068b20 -- Library/Formula/sbt.rb\nand am trying this again.\nHere are the build.properties:\n```\nProject properties\nThu Jan 20 11:27:12 PST 2011\nproject.organization=net.lag\nproject.name=kestrel\nsbt.version=0.7.4\nproject.version=2.1.0-SNAPSHOT\ndef.scala.version=2.7.7\nbuild.scala.versions=2.8.1\nproject.initialize=false\n``\n. Yeah, it does look like there are some dragons there...\n. Cool. I've recently been bitten by how RabbitMQ handles a queue getting very far behind so I'm very concerned with performance in this degraded case. I really appreciate the way the hard memory limit works but I'm interested in making sure it does not become slower to dequeue once things get backlogged (or it may become impossible to dig your way out again).\n. Have you experimented with using aBufferedInputStreamfor reading the journals to reduce the number of reads syscalls that are happening inreadJournalEntry()? For sequential reading like this it seems like it could be a big win.\n. I just realized thatBufferedInputStreamdoes not have agetChannel()method, so it wouldn't be possible to use it with the channel operations...\n. Looks like this was solved by #87 and #64. Sweet.\n. I believe I agree that I wouldn't expect to be waiting on an fsync if I set it to non-0.\n. These changes make a lot of sense to me. I like that the journal fsyncing decision is now consistently made inPeriodicSyncFile`.\n:+1:\n. Sweet. Is this going to be 2.1.1?\n. This solution is definitely preferable \u2014 I would much rather err on the side of it being older than it really is than be newer to allow for alerting based on the age.\n. Would it be possible to get a build with 8c95afc03f748aae948f8347723d04ab6087d84b in it?\n. I have a working branch over at https://github.com/papertrail/kestrel that has fixed these sbt problems.\n. You can use Option.apply(the_thing) to instantiate an Option.\n. Also, if you want to fix the problem of seeing %s in the logs, this can help:\nhttps://gist.github.com/eric/13f12b1f044fe8fd9b3a\n. For the expireToQueue setting, you may want to use Option.empty() instead of Option.apply(\"None\") to represent nothing.\n. :+1: Thanks for tracking this down! I've observed the behavior before but haven't had a chance to dig into why.\n. That definitely seems to help, but I run into problems finding specs_2.9.2-1.6.9.\n. Exciting!\n. I've been adding some fixes in a fork over at https://github.com/papertrail/kestrel.\nI would be interested in working with me, I would welcome it. Would creating a kestrel repo in a kestrel org be something people would want?\ncc: @swiftype\n. ",
    "Lytol": "I'm not sure how/why this happened but after a clean rebuild today, it seems to have disappeared. Sorry for the noise, and thanks for the help.\n. ^ Ran into this as well. Also noticed that kestrel hasn't had activity in over 7 months with a lot of unaddressed issues. What's the status of the project?\n. ",
    "jeffstyr": "Heh this started happening to me (with the tip of the master brach, plus an older 2.1.0-series version). Here's what it is:\nThis doesn't work:\njava -server -Xmx1024m -Dstage=development -jar kestrel-2.1.1-SNAPSHOT.jar\nBut this does:\njava -server -Xmx1024m -Dstage=development -jar ./kestrel-2.1.1-SNAPSHOT.jar\nThat is, if you are chdir'd to the directory containing the jar file, you have to have \"./\" at the beginning of the path. Hmm.\n(If you are up another directory, kestrel-2.1.1-SNAPSHOT/kestrel-2.1.1-SNAPSHOT.jar works fine, without a leading dot-slash.)\n. I have a fix for this (I think it's the same issue)--I ran into it recently as well. I'll get the analysis/fix written up today.\n. Heh it's funny, I have that exact same commit off on a branch (came up with it while looking into this too), but I don't think that fixes this problem actually (though it's a good change anyway). In this case the deadlock involves the lock on the PersistentQueue, not the one on the QueueCollection.\nHere's my analysis:\nThe problem comes from three different things colliding, basically:\n1) If you have syncJournal set (not zero and not Duration.MaxValue), then after writing to the journal you block on a future waiting for the fsync to happen. You are holding a lock on the PersistentQueue (appropriately) while this is happening.\n2) If the expiration timer fires at this point, it's going to block on the PersistentQueue lock (again, appropriately), since the above thread is holding the lock.\n3) Since HashedWheelTimer is single-threaded, getting blocked in 2 is preventing it from ever doing the fsync. (Even though expiration has nothing to do with fsync-ing, it's the same single timer thread which is doing both jobs.)\nSo thread 1 is holding a lock and blocking on a CountDownLatch, and thread 2 is blocked on that lock and it's the thread that would decrement the CountDownLatch.\nIt's easy to reproduce actually--if you set syncJournal to larger value that expirationTimerFrequency (say, 2 seconds and 1 second, respectively), then if you do a few adds and then a few removes, you'll hit it right away. (That not the typical config setup of course, but it makes it reproduce basically every time, rather than sporadically.)\nMy fix was to comment out the future() line in Journal.write(); this parallels the similar commented-out line in PersistentQueue.add(). (This is on the \"sync-journal-deadlock-fix\" branch on my jeffstyr/kestrel fork.) Before commenting this out, I think we're in the peculiar position of blocking on the sync for removes but not for adds. (IIRC that's what I concluded--that's why you get stuck in remove but not in add.)\nI think that's the right fix, but an alternative fix is just to use a multi-threaded timer. I have an implementation of that on my \"scheduled-thread-pool-executor\" branch, and it seems to work too, but it also seems like a bigger change. That implements a org.jboss.netty.util.Timer via a java.util.concurrent.ScheduledThreadPoolExecutor (to replace org.jboss.netty.util.HashedWheelTimer). I'm not sure of the point of HashedWheelTimer, so I don't know what the other implications might be.\n. I'll send pull requests for those two branches, to make them easier to get to.\n. Yeah that would work too I'd expect.\nIn concept I'm not sure sure if it makes sense to ever wait on a future for journal fsync. My thinking is that if you, say, set the sync period to be something like 1 minute, with the intention of picking a compromise of performance v. durability favoring the performance side, you'd actually end up going slower than with a fsync period of 0 (if anything waits on the future), because each transaction would wait (up to) 1 minute for its fsync. I'd think that any non-0 fsync period implies not waiting on the fsync, with ever-higher values giving you ever-higher performance. (Right now I think that intermediate values between 0 and Duration.MaxValue actually end up being slower that either extreme--if you wait on the future anywhere.)\nDoes that make sense?\n(I wasn't sure if HashedWheelTimer is supposed to perform better than the java.util.concurrent timer mechanisms, or if it just predated them. It certainly sounds fancy though.) But yeah the ScheduledThreadPoolExecutor was mostly an experiment to see if it would work.\n. It all looks good to me. And PeriodicBackgroundProcess sounds cool, I'll have to check that out.\n(On a side note I just noticed com.twitter.util.ScheduledThreadPoolTimer. It's not the same thing I did, since it doesn't implement the Netty timer interface, but similar in spirit.)\n. One question/thought: How does PeriodicBackgroundProcess play when you are using PersistentQueue in the embedded case (kestrel-as-a-library)?\nActually, looking at the code I guess in the embedded case you don't get background (while-queue-idle) expiration currently anyway, which I think makes sense.\n. BTW I ran into a deadlock (https://gist.github.com/1212071) which I'm pretty sure is fixed by your first fix above (on branch \"deadlock\", about not holding onto a lock during QueueCollection.flushExpired()). We'll see if it stops happening now (I hadn't deployed that fix yet).\nThe way it manifested was that kestrel would run out of FDs (because Netty kept accepting connections but the processor threads where blocked, I guess).\n. Cool sounds good.\nI feel like I've been running into different version of the general problem recently too. Handling it in the core of the future library makes sense, and always calling them asynchronously (as that blog post advises) solves the opposite-of-deadlock problem in that running them in the caller's thread lets them blow through recursive/intrinsic locks held by that thread, and it might be better for them to not. (That is, you might be holding a lock which is supposed to prevent some data structure from changing, and could be taken totally unawares that some action you are taking is triggering a Future which when modifies that data structure. Done async, the Future would be blocked from touching it while you hold the lock, as you'd want.)\nIt's somewhat interesting that while this would solve the stack depth problem, in the current case the Future-callback-execution is sort of only \"half\" the stack, and so lock-holding is still more finicky than if the async part started at the unremove call. But there's not a general way to make that happen, and for a specific-to-this-case solution it would probably be better to have a handler explicitly know about its Futures, so that it can proactively cancel them. (That is, it's sort of icky that when a connection breaks, the corresponding Futures are only cleaned out as side effects of destined-to-be-undone remove()+write() sequences. But, directly keeping track of them in the handler is much less slick than how things work now.)\nAs a side note, I was surprised I couldn't find anywhere the Scala-ized version of an Executor (taking a lambda rather than a Runnable). Trivial to write, but I didn't see one around anywhere already.\nThanks much!\n. Yep. See #72\n. Writing to stderr seems appropriate, in the case where the error is related to not being able to create a log file to write to, and especially when it's a fatal error. A coworker just ran into this. Silent failure is difficult to troubleshoot.\n. ",
    "ghost": "Sorry to bother you, i did not realize that there should be a running server needed to run and pass the test cases during the compile.\n. You need a kestrel queue running on the box to do the tests. Right?\n. ",
    "dungluxcer": "Thank you so much for quick response,\nI tried download ivysvn.jar to my localhost and then change http://maven.twttr.com to my localhost, it worked for me now, seem header of ivysvn.jar have problem at file size.\n. ",
    "xli": "dup with #44, ignore me.\n. ",
    "pivmark": "You're right, I managed to clone it into a folder that was already a git repo. Switched and now it works fine. Closing this issue.\n. ",
    "stuhood": "This also happens when there are no commits in the local git repo (freshly initialized).\n. This is usually because your current git head is not parseable. For example, while you've checked out a particular sha (which puts you in a detached-head state), publish will fail. In the case of a tag, you might not have a corresponding branch name (or something readable) actually checked out.\n. ",
    "mmao": "I got this error from switching to a tag and then triggering the build. My sequence:\ngit clone https://github.com/robey/kestrel.git\npushd kestrel\ngit checkout org=net.lag,name=kestrel,version=2.1.5\n~/bin/sbt clean update package-dist\nThe kestrel path did not exist prior to that first clone.\nIn deference to the last comment, I touched and commited an empty file to my checkout, and reran. Still the same error.\n. ",
    "ccarollo": "Ha ha. It works.  I thought I might see the server or per queue stats here. Oh well.  Thanks for the quick fix.\n. ",
    "gphat": "Ping? :)\n. Thanks!\n. I've got some tuits and thought I might take a shot at implementing this.  Before doing so I thought it might be prudent to check in first.\nExpiration seems easy at first, but after thinking it through I think it's a bit of an iceberg.\nThe queue already keeps up with it's \"age\" (_currentAge, time since last read). Would expiration be the time since the last read or the overall time the queue has been in existence?  The latter would require a new variable.\nAfter solving these little nits the only remaining problem seems to be where to do it.  That seems easier.  The existing background process calls flushAllExpired where a check of the queue's age could result in expiration.  In addition we'd probably need to check on queue operations (add, remove, peek, etc) and expire the queue if applicable.\nAll the above seems reasonable, but I'm suspicious that it's not as simple as creating an expire function in QueueCollection that mirrors delete in all but it's counter increment.\nWhat say you?\n. It being empty is likely legit for our case.  Our messages should also have small expirations, therefore the queue should be empty.\nYour first use-case is spot on!\n. I've written a first pass at adding this behavior and it (sorta, see below) works for me!  You can take a look here if you can look past a couple of misplaced logging statements: (Critiques welcome)\nhttps://github.com/gphat/kestrel/commit/7a68ff3a628cb48b62c748de25c8551e675ee362\nThe issue is that the _currentAge is only updated on reads.  Therefore if nobody reads the queue after it's passed the maximum age, it won't ever be expired.\nI see two ways to fix this:\n- Update the age when an item is expired (which seems a bit hackish, as it would break what that variable means)\n- Add a val for the date the queue was created and use that for comparison (timeCreated + maxQueueAge >= Time.now\nThoughts?\n. Ping?\n. Can do! I'll be back after I finish that. ;)\n. Robey Pointer wrote:\n\ni think this got merged in. :)\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/robey/kestrel/issues/64#issuecomment-5058442\n\nYeah.  For what it's worth I've been running in production since you \naccepted the merge.  It works wonderfully.\n\nCory G Watson\nhttp://www.onemogin.com\n. Excellent.\nI've sent a pull request for ostrich, as there was no clearCounter method.  I've also pushed a partial fix to my stats-clear branch that handles the clear of the gauge stats.\nAs an aside I noticed that this doesn't clear any of the gauges from the /graph/ stuff.  I'll have to look into that.\n. Cool, thanks Robey!\nWhen do you plan to bring that ostrich version over to kestrel?\n. Here's an updated version! Sorry for the mismatched styling. I forgot the space-between-if and wasn't noticing the extra line. I barely managed to keep the 2 space indentation.\nAlso, thanks for the updated guide text. I dunno how many beers I'd had when I wrote the original, it was terrible. :)\nLemme know if this passes muster!\n. Ugh, sorry for missing those. :(\n. Hrm, I didn't really mean to include that master merge, but I don't think it hurts anything.\nThat last commit exposes the create time of the queue as a gauge and documents age_msec, which was already there but undocumented.\n. No problem! Thanks for the help.\nWhen you roll this release, please update to the latest ostrich so my fixes there go in as well. ;)\n. I know you've already got a pile of fixes and stuff to release, but I believe that this problem is causing our ostrich thread to OOM.  We use a lot of transient queues. :(\n. I left out create_time from being purged, so this fixes that.  Also, i noticed that the ostrich release before the current one works fine as a dep, so I included that.  I'm running this version in our infrastructure due to the leaks associated oom'ing things. :(\n. Nevermind, I see it in the plugins now.\n. ",
    "hito-asa": "xmemcached uses 'version' command for heatbeat.\nRedundant empty line occurs TimeoutException on next get/set command.\nThis problem did not occur on kestre-1.2.6.\n. ",
    "nutharsh": "I got the right command to start the kestrel server on windows.\nIt's...\njava -jar ./kestrel-.jar\nwhere ./before the jar file name is very important\n. Already addressed #issue 58.\n. ",
    "phillycoder": "Thanks for the tip, for me i had to include -Dstage param to make it work.\njava -Dstage=development -jar ./kestrel_2.9.1-2.2.0.jar\n. ",
    "matthiasg": "apart from obviously changing the  paths in the config file also make sure the  logger is setup correctly since Policy.SigHup is not supported on windows. I am using Policy.Hourly instead. Policy.Never as in the development.config might not be practical for actual installations.\n. after some more investigation, i would say that kestrel only supports reliable writes when waiting for the ack before sending new messages. i.e. wait one hit to the disk, thus one should use batching when sending from one sender only. in the case of multiple senders kestrel might combine flushes internally, though i haven't checked that it does.\n. this was caused by a .gitignore file inside the data folder (this being a test we kept kestrel in a git repo). Obviously  kestrel does not take kindly to unknown files inside its data folder :) .. we just moved that the ignore file out of it.\n. it seems it isnt. we are using it in a beta project though and will likely need to rewrite this project as i already mentioned in some other issues... the original author will likely concede development to another maintainer since he doesn't seem to have the required time as he told me.\nThere are a number of issues (missing tests are one) such as some header parsing issues as well as gaps in strict protocol adherence (order of acks against messages etc) that have to be addressed (e.g. using a simple state machine)\nI am likely to do it anyway, but it will have to wait until after our beta (which will end at the end of july) before doing any real work. if anybody else would like to tackle it we could certainly test it :) ...\nthat said the project is closely related to memcache of course so maybe some overlap with existing projects could be exploited. all in all it should not take a whole lot of time to do it right.\n. ",
    "nkvoll": "+1 on this.\nMy use case is using kestrel for distributed RPC. In this scenario, I'd like to open a \"transient\" queue for responses.\nClients pull from a transient queue with an unique name (uuids etc), and adds the name of the response queue to outgoing messages.\nServers poll from the queue the clients sends to and replies by adding a message to the clients response queue. If the queue does not exist, kestrel should drop the message.\nMaybe this functionality can come through the unused \"fields\" parameter? fields={transient:true} to create a non-persistent queue, fields={passive:true} to not create a queue if the queue doesn't already exist etc.\nThis is largely similar to how AMQP, but without the exchanges, message properties and headers.\n. On second thought, I dont think the fields parameter is right for this, and maybe SET/GET should be extended instead :)\n. ",
    "jkalucki": "Servers shouldn't write to stdout. The error should be in the error log.\nOn Wed, Oct 19, 2011 at 9:15 PM, Joe Lauer \nreply@reply.github.comwrote:\n\nOn my Ubuntu machine, I tried running the following command:\njava -server -Dstage=development -jar ./dist/kestrel/kestrel-2.1.3.jar\nKestrel would fail to start and not print out any sort of error to my\nconsole.  Since Kestrel writes to /var/run, /var/log, etc. and the user I\nwas attempting to run it under didn't have permissions, Kestrel failed to\nstart.  That makes sense, but I didn't expect that to happen silently.   The\nonly way to get around this is to run via sudo:\nsudo java -server -Dstage=development -jar ./dist/kestrel/kestrel-2.1.3.jar\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/robey/kestrel/issues/74\n. \n",
    "jjlauer": "That's the problem though -- without valid permissions an error wasn't able to be printed out to a log.  By default, /var/log/kestrel wasn't writable by my default account.  Any errors prior to the valid opening up of a logfile should be printed out to at least stderr, otherwise its a mystery why it failed to start.\n. ",
    "bgsmalls": "yes, you're right. i was working with the wrong version.\nnow got 0.7.4 from here http://code.google.com/p/simple-build-tool/downloads/list\nthe tests at the end of build fail though...\n[info] == copy-scripts ==\n[info] == copy-scripts ==\n[info]\n[info] == test-finish ==\n[error] Failed: : Total 112, Failed 18, Errors 0, Passed 94, Skipped 0\n[info] == test-finish ==\n[info]\n[info] == test-cleanup ==\n[info] == test-cleanup ==\n[error] Error running : One or more subtasks failed\n[error] Error running net.lag.kestrel.JournalSpec: Test FAILED\n[error] Error running net.lag.kestrel.PersistentQueueSpec: Test FAILED\n[error] Error running net.lag.kestrel.ServerSpec: Test FAILED\n[error] Error running net.lag.kestrel.QueueCollectionSpec: Test FAILED\n[error] Error running net.lag.kestrel.ReadBehindSpec: Test FAILED\n. ",
    "lalitkapoor": "@robey thanks! Everything is looking good.\n. ",
    "zuercher": "latest master support something similar: there is now a STATUS command that can be used to switch the server between up (read/write), read-only, and quiescent states. This can be configured with service discovery via zookeeper, but also works by itself, rejecting the appropriate commands given the current server state.\n. I'm going to remove the loadtests. Parrot has been open sourced (under the name iago: https://github.com/twitter/iago) but is still evolving rapidly enough that exposing the tests in kestrel's repo via a JAR dependency isn't viable. Kestrel support is baked into Iago, so it is possible to build that project and configure it to loadtest Kestrel by writing a custom RecordProcessor.\n. There isn't a notion of transactional put in kestrel. I gather you've configured kestrel to fsync immediately, so when you get a result of \"STORED\" from the server it means the item has successfully been written to disk. NOT_STORED would indicate it wasn't stored (though this only occurs if you configure kestrel to limit queue sizes or if you catch it at shutdown). A disconnect or error response gives you no information: The item may have been enqueued or not, depending on when the error in the put operation. (A client error, however, would mean the item was not enqueued.)\nFurthermore, invoking the put method on a GrabbyHands sendQueue (as in the example in the GrabbyHands README file) is just handing an item to a java.util.concurrent.LinkedBlockingQueue. Depending on the configured value of sendQueueDepth, your producing thread may block waiting for a slot to open in the LinkedBlockingQueue, but once the item is in the LinkedBlockingQueue, there's no way to know if the item was ever sent to kestrel, let alone whether the item made it or not.\nHaving written all that, I can't think of any reason that a publisher being restarted would suddenly cause a message to reappear on a queue, unless the publisher itself is re-publishing it. If it is a bug, it would likely be in the networking code, which was heavily modified in kestrel 2.2.0 or in grabbyhands.\nRobey's suggestion was to copy the queue's journal to a directory outside the one you use for your queues (e.g., using cp on linux). So if the queue's name is FOO and your kestrel config's queuePath is \"/var/spool/kestrel\", then \"cp /var/spool/kestrel/FOO /tmp/\". At that point you can run qdump.sh from the scripts directory of the kestrel distribution and it should dump out the contents of the journal. If there's a recent ADD operation for the old item, then the producer wrote it recently. You may need to copy more than one file if the journal is being rotated frequently.\n. So are there can canceled (CAN) items in there? Those are being returned to kestrel and then you would subsequently see a new RSV and then ACK for the item. If the payloads are text (or close enough) you can add the -d flag to see them dumped as well, which might help you find the item you're trying to track down.\nThere is no newer version of grabby-hands available. Most JVM-based applications using kestrel within Twitter have migrated to the finagle-kestrel client. The public repo for finagle is https://github.com/twitter/finagle, and I believe the most recently published version is 5.3.22.\n. The format of those lines is:   \nSo yes, something is starting a transaction with id 333735 (decimal) and subsequently the transaction is being canceled. Cancellation occurs either explicitly if your app calls GrabbyHands' Read.cancel() or automatically if there is an open transaction on a connection and that connection is clsoed. This could happen if Read.close() is never called by your app.\nLooking at the GrabbyHands code, it offers a Read object on the BlockingQueue[Read] obtained via GrabbyHands.getRecvTransQueue (and will wait for effectively forever for the application code to call poll on the BlockingQueue). Once the item has been handed off, it waits on a CountDownLatch for the application code to call cancel() or close() on the Read object. It seems pretty bullet proof. I'd make sure your logic for transactional reads always calls cancel() or close() in a timely fashion.\nGrabbyhands uses java.util.logging with a Logger named \"grabbyhands\". If you crank up the logging to \"finest\" you will see log messages for each reader thread, including when it receives an item and when the item is handed off to your application. Depending on the rate of messages in your system it may not be feasible to turn this on, but should help you track down when this happens.\n. I'm not aware of any project using kestrel as a library from Java. (Which doesn't mean there isn't.)\n. Kestrel 2.2.0 and higher use sbt 0.11. From the error message, it\nlooks like you're using sbt 0.7.\nStephan\nOn May 28, 2012, at 9:14 AM, vladvintila\nreply@reply.github.com\nwrote:\n\nI've been using kestrel for a while now. Every time I followed the documented install process without any hitches.\nHowever when trying to install the newest version today I ran into some problems.\nWhen running bin/sbt clean update package-dist I first get a prompt with:\nProject does not exist, create new project? (y/N/s)\nand after that I get :\nNo action named 'package-dist' exists\nI don't know scala or sbt methods, but it seems that sbt does not recognize it is in a project and does not run project/Build.scala and plugins.sbt.\nI always ran bin/sbt from the directory I cloned kestrel in.\nI'm running ubuntu 10.04 and openjdk-6.\nRegards,\nVlad\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/robey/kestrel/issues/100\n. Sorry. I've just now realized that sbt plugins are published with the sbt version embedded as an attribute. We're still using sbt 0.11.2 so the plugins haven't been published for 0.11.3.\n\nYou should be able to see the currently published versions of the plugins here:\nhttp://maven.twttr.com/com/twitter/sbt-package-dist_2.9.1_0.11.2/\nhttp://maven.twttr.com/com/twitter/sbt11-scrooge_2.9.1_0.11.2/\n. You're correct that it presently only works with sbt 0.11.2.\nThere's a debian package of 0.11.2 here:\nhttp://scalasbt.artifactoryonline.com/scalasbt/sbt-native-packages/org/scala-sbt/sbt-launcher/0.11.2/\nDebian packages are \"ar\" archives, so \"ar -x sbt.deb\" on a mac or\nlinux box will extract the contents of the package. The resulting\ndata.tar.gz file contains sbt-launch.jar for sbt 0.11.2.\nThat's the best I have for you right now.\nStephan\nOn Mon, Jun 25, 2012 at 4:43 PM, rp-pwright\nreply@reply.github.com\nwrote:\n\nI've downloaded the kestrel zip from https://github.com/robey/kestrel and am attempting to build it locally before packaging it for my site.  Following the directions I am installing \"sbt\" as per this site:\nhttp://www.scala-sbt.org/download.html#manual\nWhich results in my downloading version 0.11.3. of sbt.  I begin by running \"sbt clean\" which eventually errors out like so:\n[error] {file:/home/pwright/src/kestrel/robey-kestrel-eeba5af/project/}default-cfb522/*:update: sbt.ResolveException: unresolved dependency: com.twitter#sbt-package-dist;1.0.5: not found\n[error] unresolved dependency: com.twitter#sbt11-scrooge;1.0.0: not found\nSearching through previous issues I came across this one:\nhttps://github.com/robey/kestrel/issues/100\nWhich seems to indicate that version 0.11.2 of sbt will work.  Unfortunately this does not seem to be available @ http://scalasbt.artifactoryonline.com/\nBrowsing artifactory over there it only shows a 0.11.2 .deb package as being available.  Am I barking up the wrong tree thinking that I need to use sbt 0.11.2?\nCheers!\n-pete\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/robey/kestrel/issues/102\n. Sorry for the slow response. The formatting issue is because your patch uses tabs -- we'd prefer spaces only.\n\nFor the tests related to stats, I don't see much benefit in pattern:\nfor(i <- 0 to 2) i match {\n  case 0 => ...\n  case 1 => ...\n  case 2 => ...\n}\nI think it's just confusing. If you call toMap on the result of dumpStats, you could loose the for block and replace it with 3 lines that look like:\nstats(\"put_items\") mustEqual \"0\"\nI don't think the order of the stats is of particular importance.\n. Always happy for more tests. Thanks!\n. Master has a change that partially fixes this. Instead of updating the age per remove, it now tracks the timestamp of the last removed item and computes the age when requested (by stats or otherwise).\nStill doesn't reflect the true age of the head of the queue, so if you remove a very old item and then stop reading for a while it will report a larger age than is strictly true. I'll look into peeking at the head.\n. this is 2.3.4\n. this is fixed in master now, thanks\n. Thanks!\n. That's not presently a feature of kestrel.\n. You are correct that kestrel is currently still using finagle 1.11.1.\nThe next version of kestrel will use scala 2.9.2 and will upgrade to finagle 5.3.x. I'll push the relevant commits to github once the version of finagle I'm using is publicly released.\nI'm not sure I follow your question about scala 2.9.1.\n. To my knowledge, the most recent public version of finagle is 5.3.9 and work continues on the 5.3.x series.\nThe work to convert kestrel to a modern finagle version has already been done. It is awaiting the release of artifacts for the specific version of finagle it actually uses. Once they are available, I will publish the kestrel source to github.\nIf you're having trouble using finagle from Java, I suggest getting on the finaglers google group (see http://twitter.github.com/finagle/).\n. They are. I pulled it forward to a 5.3.17 build, which isn't available. I'll probably drop back to the 5.3.9 version if 5.3.17 doesn't make it to the externally facing repository soon.\n. 5.3.19 was released publicly yesterday, so I've bumped up to that on master.\n. ",
    "vogelito": "I was having the same problem, but your change definitely solves the issue in branch release_2_2\nI'm confused though, which branch is the current stable release branch? I see a release_3_0 branch in github, but in your homepage (http://robey.github.com/kestrel/) it looks like kestrel 2.1.4 is the latest stable release.\nMany thanks!\n. +1 this would be great!\n. Per my comment on #96, I think these are separate issues.\nLet me know if I can provide any more information that would be useful for you. Please notice that I was looking at the retained size (not the shallow size) of these objects when doing my debugging.\n. We were on 2.1.4 and noticed that after our servers had been up and running for about 3 days, performance would be significantly affected and that a restart of the software would solve the issue.\nWe started our servers with GC logging on, and realized that the size of the Perm pool was growing steadily up to a point where we were doing Full GC cycles more than once a second\nOur queue names are slightly transient (around 100 active queues at all times, but names are changed about 5 - 10 times a day depending on live configuration), and some googling yielded this\nWe also have about 300 other queues that don't change names.\nSo currently we're currently running up commit fbc5548172153a466ea84999e073eab4b488c12e\nUnfortunately, this didn't solve our issue, so we started taking memory snapshots using yourkit. It was evident that there was a big leak in com.twitter.ostrich.admin.TimeSeriesCollector since our first snapshot showed one object with a size of 12MB, 2 hours later the same object was 40MB, and it kept growing steadily.\nPer this, we eliminated the TimeSeriesCollectorConfig and that alleviated our problem. The size of the Perm generation is still growing but nowhere close to what it was doing before.\nHowever, from the memory snapshots I noticed the size of LatchedStatsListener has more than doubled in size in about 60 hours (5MB to 12MB).\nThis isn't a big concern for us anymore (our servers will most likely be restarted before this becomes an issue), but thought I'd share the findings.\n. I'm pretty sure that won't fix the problem since we had merged that change in (that's the link in my previous post)\n. I apologize for misreporting. We're actually running up to 419009cc2091f5ce445e8b274dbc5699f8cf90cc\n. ",
    "Teudimundo": "I'm using kestrel with apache camel that is based on memcached protocol. Is there any way to avoid having kestrel completely open to everyone that can access the host?\n. ",
    "Jell": "It's the client, but when I said crash I just meant a timeout exception is raised. Bad choice of words, sorry...\n. Also the timeout is set to trigger after 500ms.\n. I ran some more tests, so it seems that it takes sometimes between 500ms and 1s for me to put an element in a queue, although 99% of the time it takes less than 10ms.\nIs that a behavior that should be expected?\n. Ok the problem actually came from the client. Sorry about that! :s\n. Ah! Thanks for the useful tip, I'll be using that for monitoring. Thank you!\n. ",
    "s17t": "It's a while I am looking for 'parrot' but I couldn't find it on maven repositories. Where can I find it? Thx.\n. Thanks for your answer. I noticed the load test shortly after I dived into the project.\n. +1 for this. \n. ",
    "etucker": "+1 This would be quite handy.\n. ",
    "gpass": "GrabbyHands works very well in java: https://github.com/twitter/grabby-hands\n. This is Kestrel 2.1.5 . Unfortunately, our queues never have a dull moment where we could reliably glimpse that stat.\n. ",
    "gregpassmore": "I'm just getting back to this issue - it happens everytime my publishers are restarted ( I get an old message drained at the consumer). I'm not sure how to do what you are describing in the last comment. It seems the issue happens when the producer first starts - some of the first queue puts get stuck. Then when I restart that process ( a java vm) they come through in the queue to the consumer. I'm not clear on when/how I could do this dump. Maybe I need to stop using transactional puts w/ grabbyhands? I do like the certainty that the item is in the queue. \n. Ok I will try this (copying the journal file). It is easy to reproduce, but a pain to remedy ( I have hundreds of queues, and it is never clear to me whether I am past this mode, or if real users are going to lose data).  Just restarted servers because of a new code deployment and had a few hundred items come through that were a week old. I think they must be getting stuck in the grabby hands layer, because kestrel queue sizes are 0 based on stats. It's very strange because I had the queue depth set to 1 (the LinkedBlockingQueue) and I also can get through other messages on all the queues, it's not as if they are stuck, they just tend to lose things at the beginning (that come back as zombies on restart). \n. Hi zuercher,\nThanks for helping. I did a qdump and I see a lot of interesting data, but I'm not sure how to interpret it. How can I see \"if there's a recent ADD for an old item\". The dump looks like this:\n002406a6  ADD 425\n00240864  RSV 336354\n00240869  ACK 336354\n0024086e  ADD 425\n00240a2c  RSV 336355\n00240a31  ACK 336355\nI'm going to upgrade to kestrel 2.4.1 to see if this helps. I'm starting to suspect grabby-hands as being the culprit, and the dev on that hasn't done a commit in two years, so I don't have much hope there. Does anyone know if the current github version of grabby-hands what twitter still uses?\n. So is CAN from a transactional read being cancelled? The order I see is, about 10 times in my snapshot of the current logfile. I'm not sure if items are \"stuck\" in here, but I do have cancels:\n00116cdb  RSV 333735\n0011da63  CAN 333735\nNever anything after the can. Is the number the ID ? or is the hex the ID? \nI will certainly look at finagle-kestrel , didn't even know about that. I would much rather be on something more modern that is maintained. \n. ",
    "ikaplunvmc": "We've integrated PersistentQueue as a library in a java project, and it's been working well so far. It also seems like https://github.com/robey/libkestrel/ will provide a nicer way to do it.\n. ",
    "dperetz": "My Bad :)\n. ",
    "vladvintila": "Got sbt 0.11.3, solved the initial problem, but still having trouble with the two plugins:\n[warn]  module not found: com.twitter#sbt-package-dist;1.0.5\n.\n.\n.\n[warn]  module not found: com.twitter#sbt11-scrooge;1.0.0\n.\n.\n[warn]  Note: Some unresolved dependencies have extra attributes.  Check that these dependencies exist with the requested attributes.\n[warn]      com.twitter:sbt-package-dist:1.0.5 (sbtVersion=0.11.3, scalaVersion=2.9.1)\n[warn]      com.twitter:sbt11-scrooge:1.0.0 (sbtVersion=0.11.3, scalaVersion=2.9.1)\n. Worked, I just used sbt 0.11.2 so it would automatically download from the urls you specified.\nThanks for the help, you should update the docs(i.e they state you should use sbt 0.7.4) so you don't get tickets like this.\n. ",
    "rp-pwright": "On 7/1/12 10:24 PM, Stephan Zuercher wrote:\n\nYou're correct that it presently only works with sbt 0.11.2.\nThere's a debian package of 0.11.2 here:\nhttp://scalasbt.artifactoryonline.com/scalasbt/sbt-native-packages/org/scala-sbt/sbt-launcher/0.11.2/\nDebian packages are \"ar\" archives, so \"ar -x sbt.deb\" on a mac or\nlinux box will extract the contents of the package. The resulting\ndata.tar.gz file contains sbt-launch.jar for sbt 0.11.2.\nThat's the best I have for you right now.\nThanks Stephan for getting back to me.  I'll give this a sping this week.\n\nCheers,\n-pete\n\nPete Wright\nSenior Infrastructure Engineer\nRubicon Project\npwright@rubiconproject.com\n310.309.9298\n. I am going to close this issue out.  This is a pebkac error - I was backgrounding my process via \"nohup\" which is obviously a pretty dumb thing to do if you want to trap SIGHUP :/\nI suspect once I fix my initscript things will work as expected.  Sorry for the noise!\n. ",
    "rvoicilas": "Sorry, I am just starting out with Scala so I am not yet writing idiomatic code - I thought adding some specs to kestrel is a good starting point. Anyways, the code is much cleaner now using a map instead of that pattern and hopefully the tabs are now replaced by spaces.\n. ",
    "itissid": "Hmm actually in my java code I was looking to use finagle, but the libs where the feature I want to use are in 5.9.1 and the libs are kind of messed up.\n Now I have been wanting for a long time to learn scala and I think this is as good a place as any to start. If you are not planning to move to 2.9.2 anytime soon can I give it a shot? Let me know what you think.. I specifically want to use finnagle to not worry about things like retry policies, timeouts,  back pressure and stuff like that..\n. Sorry to bug you about this but aren't the 5.3.9 artifacts already here: http://maven.twttr.com/com/twitter/finagle-core/5.3.9/ \nUnless I am completely missing something and you are working on a newer finagle version than 5.3.9? \n. Very awesome now I  can use a lot of finagle goodness..\nOn Thu, Oct 18, 2012 at 2:08 PM, Stephan Zuercher\nnotifications@github.comwrote:\n\n5.3.19 was released publicly yesterday, so I've bumped up to that on\nmaster.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/robey/kestrel/issues/111#issuecomment-9574820.\n. \n",
    "copiousfreetime": "closing as kestrel is deprecated.\n. ",
    "chuckadams": "kestrel is dead.  getting this out of my active issues list. ",
    "technoweenie": "We're seeing similar issues.  The logs look like this:\nINF [20130508-11:42:49.780] kestrel: Rewriting journal file for 'booya' (qsize=0)\nINF [20130508-11:42:50.375] kestrel: Rewriting journal file for 'booya' (qsize=0)\nINF [20130508-11:42:51.004] kestrel: Rewriting journal file for 'booya' (qsize=0)\nINF [20130508-11:42:51.448] kestrel: Rewriting journal file for 'booya' (qsize=0)\n(with a lot more entries every second until the event is over)\nHere's the open transactions from collectd:\n\nWe do have 16 workers across 6 nodes.  So I wonder if we're getting close to the open transaction limit.\nThe collectd graph for expired items is flat, so that doesn't seem to be an issue.\nIdeas:\n- Increase the default journal size\n- Increase the open transaction limit\nI'm just worried that increasing the journal size will make this problem occur less frequently, but longer.\nEDIT: We're on Kestrel 2.4.1.\n. We fixed this for ourselves with two things:\n- Increasing the syncJournal setting from 100.milliseconds to 1.second.  Not sure why it was set so low.  This seemed to reduce the frequency of these issues.\n- We started compressing the data before inserting into Kestrel.\n. ",
    "agargenta": "We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. We appreciate your contribution, but we've deprecated this project and no longer accept pull requests. Please see https://github.com/twitter-archive/kestrel/blob/master/README.md#status for more info.\n. ",
    "flosell": "Closing this issue as project is deprecated and PR was closed.. ",
    "alexkehayias": "I also have this same error even with using sbt 0.11.2 as recommended elsewhere. \n. I haven't looked at this in years sorry! \n. ",
    "MarsYoung": "..did u solve it?\n. ",
    "kperi": "Hi,\nThanks for the reply.\nI've tried qdump on some of the files and I am getting something like:\n\nqdump.sh my_queue.1373865238490\n\n\n00000000  ADD 2601\n00000a3e  ADD 2641\n000014a4  REM\n000014a5  REM\n000014a6  ADD 2597\n00001ee0  ADD 2616\n0000292d  ADD 2437\n000032c7  REM\n000032c8  ADD 2572\n00003ce9  ADD 2624\n...............\n0199cf  REM\n000199d0  REM\n000199d1  ADD 2649\n0001a43f  ADD 2649\n0001aead  ADD 2631\n0001b909  REM\n0001b90a  REM\n0001b90b  REM\n0001b90c  REM\n\n\nException in thread \"main\" java.util.NoSuchElementException: queue empty\n    at scala.collection.mutable.Queue.dequeue(Queue.scala:65)\n    at net.lag.kestrel.tools.QueueDumper.dumpItem(QDumper.scala:102)\n    at net.lag.kestrel.tools.QueueDumper$$anonfun$apply$2.apply(QDumper.scala:47)\n    at net.lag.kestrel.tools.QueueDumper$$anonfun$apply$2.apply(QDumper.scala:45)\n    at scala.collection.Iterator$class.foreach(Iterator.scala:772)\n    at scala.collection.Iterator$$anon$22.foreach(Iterator.scala:451)\n    at net.lag.kestrel.tools.QueueDumper.apply(QDumper.scala:45)\n    at net.lag.kestrel.tools.QDumper$$anonfun$main$1.apply(QDumper.scala:201)\n    at net.lag.kestrel.tools.QDumper$$anonfun$main$1.apply(QDumper.scala:199)\n    at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59)\n    at scala.collection.immutable.List.foreach(List.scala:76)\n    at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:30)\n    at scala.collection.mutable.ListBuffer.foreach(ListBuffer.scala:44)\n    at net.lag.kestrel.tools.QDumper$.main(QDumper.scala:199)\n    at net.lag.kestrel.tools.QDumper.main(QDumper.scala)\n\nOther files in the same queue seem not to have a problem with qdump, ie I am getting a full list of ops and qdump exits without exceptions.\n\nAdditionally, the overal queue + journal size was reduced from 154G to 500m just after start pushing new data to the queue\nThanks,\nKostas\n. ",
    "deric": "I'm having the same issue with oracle java 1.7.0_25-b15 and sbt_2.9.1 0.11.2\n. ",
    "jaingaurav1990": "I am also having the same issue with oracle java 6 and sbt 0.11.2\n. ",
    "dexterbt1": "I'm trying to build a dockerfile for this but i'm having the same issue with @deric \ndebian + oracle java 1.7 + scala 2.9.1 + sbt 0.11.2\n. +1\nI'm currently evaluating this tech and but #125 is breaking my initial build.\nThis project badly needs active maintenance.\n. ",
    "rajeevgoel": "Eric, Thanks a ton for the tip of Option.apply(), it worked. Provided all 14 arguments and could start the queue. \nI don't  understand  why %s shows up. Is it due to bad logger configuration?\nBTW found that jul-over-slf4j has horrible performance, it is 60 times slower. Please see here http://www.slf4j.org/legacy.html\nThanks again !\nPosting java code which worked for me:\n```\n    Duration oneSecond = new Duration(1000000000);  // 1sec\n    Duration forever = Duration.forever() ;\n    QueueConfig qc = new QueueConfig(50000, new StorageUnit(1024102450), new StorageUnit(1024102410), \n            Option.apply(forever), / defaultJournalSize/ new StorageUnit(1024102450), / maxMemorySize /new StorageUnit(10241024), \n            / maxJournalSize / new StorageUnit(1024102450), false, true, \n            oneSecond, Option.apply(\"None\"), / doesn't matter as expireQueue is false */ 1, false, Option.apply(forever));\n    System.out.println(\"config: \" + qc.toString());\n    // creating timer and service\n    java.util.concurrent.ScheduledExecutorService service = java.util.concurrent.Executors.newSingleThreadScheduledExecutor();\n    Timer timer = new JavaTimer();\n    PersistentQueue queue = new PersistentQueue(\"test\", \"./kestreltmp\", config, timer, service);\n    queue.setup();\n// finally\nqueue.close();\ntimer.stop(); // else JVM will wait on this thread.\n\n```\n. ",
    "vongosling": "final result is \"Server access Error: Connection timed out url=http://maven.twttr.com/com/twitter/sbt-package-dist_2.10_0.13/1.0.6/sbt-package-dist-1.0.6.pom\n. solve this problem through proxy setting and sbt version restriction,please see #137 \n. can also solve this problem https://github.com/twitter/kestrel/issues/128\n. ",
    "banker": "commit e7a39d7c57595b2234a92856d56ec1d5f86bf515\nAh. I just found the commit where this restriction was removed:\nAuthor: Robey Pointer robey@twitter.com\nDate:   Thu Oct 28 16:01:26 2010 -0700\npass the QueueCollection through to KestrelHandler so it's less tightly coupled. remove the restriction on \"one outstanding transaction per connection\"\nI'll submit a pull request for a documentation update.\n. ",
    "matthewrk": "+1, last update to Kestrel was over a year ago, is it still maintained?\n. ",
    "amartinsn": "Any heads up on this one? \nI'm considering using Kestrel and am not sure it's being maintained. \nThe last commit is from 2012.\n. ",
    "DavidFishman": "To further illustrate the issue (and explain why it may not have been caught given the default configuration):\nWith a default of maxMemorySize=128mb and defaultJournalSize=16mb, we have a low risk of hitting this case as we're likely to have a current journal file size that is greater than 16mb by the time the queue length = 0 (since rotation occurs when the current journal file size is greater than the maxMemorySize). However, as the difference between these numbers decreases, we become more likely to to have a current journal file that is less than the defaultJournalSize when the queue length = 0.\nMore so, if defaultJournalSize>maxMemorySize the journal file will never be compacted when the queue length = 0, (since rotation would occur at a file size less than the defaultJournalSize, making it impossible for the current journal file size to ever be greater than the defaultJournalSize).\n. ",
    "ragnareklund": "+1\n. ",
    "MartinWickman": "+1\n. ",
    "mbabineau": "Twitter has upstream changes that were never merged here. You can see the subsequent versions and source jars here:\nhttp://maven.twttr.com/net/lag/kestrel_2.9.2/\nIf it helps, I've got a Docker image building from the pre-compiled binaries:\nhttps://github.com/thefactory/docker-kestrel\nIt's available on the Docker Hub:\nhttps://registry.hub.docker.com/u/thefactory/kestrel/\nconsole\n$ docker run -i -t -v /var/lib/kestrel:/data thefactory/kestrel\nINF [20140924-22:19:03.250] stats: Starting LatchedStatsListener\nINF [20140924-22:19:03.305] admin: Starting TimeSeriesCollector\nINF [20140924-22:19:03.307] admin: Admin HTTP interface started on port 2223.\nINF [20140924-22:19:03.314] kestrel: Kestrel config: listenAddress=0.0.0.0 memcachePort=Some(22133) textPort=Some(2222) queuePath=/data expirationTimerFrequency=Some(1.seconds) clientTimeout=Some(30.seconds) maxOpenTransactions=100 connectionBacklog=None statusFile=/tmp/.kestrel-status defaultStatus=Up statusChangeGracePeriod=0.seconds enableSessionTrace=false zookeeper=<None>\nINF [20140924-22:19:03.350] kestrel: no status stored at '/tmp/.kestrel-status'; status remains 'Up'\nINF [20140924-22:19:03.446] kestrel: kestrel-memcache server started on /0.0.0.0:22133\nINF [20140924-22:19:03.450] kestrel: kestrel-text server started on /0.0.0.0:2222\nINF [20140924-22:19:03.457] kestrel: kestrel-thrift server started on /0.0.0.0:2229\nINF [20140924-22:19:03.462] kestrel: Starting up background expiration task.\nINF [20140924-22:19:03.463] kestrel: Starting background-expiration\nINF [20140924-22:19:03.465] kestrel: Kestrel 2.4.2 started.\n. ",
    "Srinathc": "Full log:\n\nINF [20140406-01:47:13.431] stats: Starting LatchedStatsListener\nINF [20140406-01:47:13.716] admin: Starting TimeSeriesCollector\nINF [20140406-01:47:13.719] admin: Admin HTTP interface started on port 2223.\nINF [20140406-01:47:13.732] kestrel: Kestrel config: listenAddress=0.0.0.0 memcachePort=Some(22133) textPort=Some(2222) queuePath=/var/spool/kestrel expirationTimerFrequency=Some(1.seconds) clientTimeout=None maxOpenTransactions=100 connectionBacklog=None statusFile=/tmp/.kestrel-status defaultStatus=Up statusChangeGracePeriod=0.seconds zookeeper=\nINF [20140406-01:47:14.030] kestrel: no status stored at '/tmp/.kestrel-status'; status remains 'Up'\nINF [20140406-01:47:15.019] kestrel: kestrel-memcache server started on /0.0.0.0:22133\nINF [20140406-01:47:15.023] kestrel: kestrel-text server started on /0.0.0.0:2222\nINF [20140406-01:47:15.103] kestrel: kestrel-thrift server started on /0.0.0.0:2229\nINF [20140406-01:47:15.108] kestrel: Starting up background expiration task.\nINF [20140406-01:47:15.109] kestrel: Starting background-expiration\nINF [20140406-01:47:15.113] kestrel: Kestrel 2.4.1 started.\nINF [20140406-01:59:11.905] kestrel: Setting up queue PEP: maxItems=2147483647 maxSize=9223372036854775807.bytes maxItemSize=9223372036854775807.bytes maxAge=None defaultJournalSize=16777216.bytes maxMemorySize=134217728.bytes maxJournalSize=1073741824.bytes discardOldWhenFull=false keepJournal=true syncJournal=100.milliseconds expireToQueue=None maxExpireSweep=2147483647 fanoutOnly=false maxQueueAge=None (via ip-172-31-40-91.us-west-2.compute.internal:32901)\nINF [20140406-01:59:11.968] kestrel: Replaying transaction journal for 'PEP'\nINF [20140406-01:59:12.000] kestrel: No transaction journal for 'PEP'; starting with empty queue.\nINF [20140406-01:59:12.001] kestrel: Finished transaction journal for 'PEP' (0 items, 0 bytes) xid=0\nINF [20140406-01:59:12.095] kestrel: Setting up queue PR: maxItems=2147483647 maxSize=9223372036854775807.bytes maxItemSize=9223372036854775807.bytes maxAge=None defaultJournalSize=16777216.bytes maxMemorySize=134217728.bytes maxJournalSize=1073741824.bytes discardOldWhenFull=false keepJournal=true syncJournal=100.milliseconds expireToQueue=None maxExpireSweep=2147483647 fanoutOnly=false maxQueueAge=None (via ip-172-31-40-91.us-west-2.compute.internal:32902)\nINF [20140406-01:59:12.099] kestrel: Replaying transaction journal for 'PR'\nINF [20140406-01:59:12.101] kestrel: No transaction journal for 'PR'; starting with empty queue.\nINF [20140406-01:59:12.101] kestrel: Finished transaction journal for 'PR' (0 items, 0 bytes) xid=0\nINF [20140406-01:59:12.102] kestrel: Setting up queue SERVER: maxItems=2147483647 maxSize=9223372036854775807.bytes maxItemSize=9223372036854775807.bytes maxAge=None defaultJournalSize=16777216.bytes maxMemorySize=134217728.bytes maxJournalSize=1073741824.bytes discardOldWhenFull=false keepJournal=true syncJournal=100.milliseconds expireToQueue=None maxExpireSweep=2147483647 fanoutOnly=false maxQueueAge=None (via ip-172-31-40-91.us-west-2.compute.internal:32903)\nINF [20140406-01:59:12.104] kestrel: Replaying transaction journal for 'SERVER'\nINF [20140406-01:59:12.105] kestrel: No transaction journal for 'SERVER'; starting with empty queue.\nINF [20140406-01:59:12.106] kestrel: Finished transaction journal for 'SERVER' (0 items, 0 bytes) xid=0\nINF [20140406-01:59:12.147] kestrel: Setting up queue SERVICE: maxItems=2147483647 maxSize=9223372036854775807.bytes maxItemSize=9223372036854775807.bytes maxAge=None defaultJournalSize=16777216.bytes maxMemorySize=134217728.bytes maxJournalSize=1073741824.bytes discardOldWhenFull=false keepJournal=true syncJournal=100.milliseconds expireToQueue=None maxExpireSweep=2147483647 fanoutOnly=false maxQueueAge=None (via ip-172-31-40-91.us-west-2.compute.internal:32906)\nINF [20140406-01:59:12.148] kestrel: Replaying transaction journal for 'SERVICE'\nINF [20140406-01:59:12.153] kestrel: No transaction journal for 'SERVICE'; starting with empty queue.\nINF [20140406-01:59:12.154] kestrel: Finished transaction journal for 'SERVICE' (0 items, 0 bytes) xid=0\nFAT [20140407-14:24:57.950] kestrel-memcache: A server service  threw an exception\nFAT [20140407-14:24:57.950] kestrel-memcache: java.lang.IndexOutOfBoundsException: 1\nFAT [20140407-14:24:57.950] kestrel-memcache:     at scala.collection.LinearSeqOptimized$class.apply(LinearSeqOptimized.scala:51)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at scala.collection.immutable.List.apply(List.scala:76)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at net.lag.kestrel.MemcacheHandler.handle(MemcacheHandler.scala:117)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at net.lag.kestrel.MemcacheHandler.apply(MemcacheHandler.scala:63)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at net.lag.kestrel.MemcacheHandler.apply(MemcacheHandler.scala:34)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Service$$anon$1.apply(Service.scala:14)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Filter$$anon$1.apply(Filter.scala:111)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Filter$$anon$2$$anon$3.apply(Filter.scala:53)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.service.StatsFilter.apply(StatsFilter.scala:24)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Filter$$anon$2.apply(Filter.scala:52)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Filter$$anon$4.apply(Filter.scala:69)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Service$$anon$1.apply(Service.scala:14)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.filter.MkJvmFilter$$anon$1.apply(JvmFilter.scala:19)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Filter$$anon$2$$anon$3.apply(Filter.scala:53)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.tracing.TracingFilter$$anonfun$apply$1.apply(TracingFilter.scala:21)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.tracing.TracingFilter$$anonfun$apply$1.apply(TracingFilter.scala:16)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.tracing.Trace$.unwind(Trace.scala:128)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.tracing.TracingFilter.apply(TracingFilter.scala:16)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.Filter$$anon$2$$anon$3.apply(Filter.scala:53)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.filter.MonitorFilter$$anonfun$apply$1.apply(MonitorFilter.scala:16)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.finagle.filter.MonitorFilter$$anonfun$apply$1.apply(MonitorFilter.scala:16)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Future$$anonfun$monitored$1.apply$mcV$sp(Future.scala:128)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$$anonfun$apply$1.apply$mcV$sp(Monitor.scala:39)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$$anonfun$apply$1.apply(Monitor.scala:39)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$$anonfun$apply$1.apply(Monitor.scala:39)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$$anonfun$using$1.apply(Monitor.scala:104)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$.restoring(Monitor.scala:111)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$.using(Monitor.scala:102)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$class.apply(Monitor.scala:38)\nFAT [20140407-14:24:57.950] kestrel-memcache:     at com.twitter.util.Monitor$$anon$1.apply(Monitor.scala:132)\nFAT [20140407-14:24:57.950] kestrel-memcache:     (...more...)\n\n. ",
    "caniszczyk": "@eric kestrel right now is low priority for us and the community can definitely fork it if it wants, however, let me check internally do see what we can do here. If the community wants to run with kestrel and take ownership, we can potentially support.\nGive me some time to talk with folks\n. ",
    "kovyrin": "@caniszczyk Any chance you have some news to share regarding this issue (or, maybe, regarding Twitter's general plans for opensource Kestrel version)? Thanks for any information you could provide!\n. ",
    "cobbzilla": "+1\nI would be thrilled and very grateful if someone has the time and energy maintain a community fork.\n. I think you reversed the link order. The link text goes in square brackets, the link itself goes in parens.\n. ",
    "leighst": "We're releasing our latest including a bunch of bug fixes this week.\n. They were released back in September - look for a big change we committed around that time.\n. ",
    "ro31337": "@cobbzilla oops. Fixed!\n. ",
    "andypiper": "@agargenta looks like the link in the project description, and in the README, should be updated to https://twitter-archive.github.io/kestrel\n@paomian I think you'll find that link works for you. Note that this project is no longer active.. ",
    "paomian": "Thanks a lot.We use it in out projetc.But some times ago,I lost the package accidentally.. "
}