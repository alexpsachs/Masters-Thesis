{
    "tatsuhiro-t": "Thank you for the nice patch!\n. Thanks. I just merged your change.\n. I think it will be accomplished to log download progress summary in notice level.\n. I just merged your change. Thank you.\n. Merged. Thank you for contributing to aria2 project!\n. Thank you for quick update.\n. I used cmake for other forked project and it feels good.\nThe reason I use autotools is when I started the project I just used to autotools and not considered other options.\nNow we don't have any big issues with autotools. Cmake or other tools can make configuration simpler but I think the cost to move to the new tools does not greater value than the effort.\n. Thank you for quick updates. I think this is the last change in man page for the next release.\n. Thank you for quick update!\n. In RPC request, option values are always string. So use \"true\" for True.\nI think {'allow-overwrite': 'true', 'auto-file-renaming': 'false'} works.\n. I just merged your changes. Thanks!\n. Thank you for quick updates. I just merged your changes.\n. Thank you for quick updates!\n. I agree. I'll work for this.\n. Fixed in 5751961\n. Thank you. I've just merged your changes.\n. On Wed, May 2, 2012 at 3:49 PM, pumbur\nreply@reply.github.com\nwrote:\n\nmake DESTDIR=\"$pkgdir\" install\n....\n\u00a0 \u00a0Making install in en\n\u00a0 \u00a0make[3]: Entering directory /home/pb/aria2-git/src/aria2/doc/manual-src/en'\n\u00a0 \u00a0make[4]: Entering directory/home/pb/aria2-git/src/aria2/doc/manual-src/en'\n\u00a0 \u00a0make[4]: Nothing to be done for install-exec-am'.\n\u00a0 \u00a0mkdir -p /usr/share/doc/aria2/manual/en && \\\n\u00a0 \u00a0cp -r ../../manual/en/html /usr/share/doc/aria2/manual/en && \\\n\u00a0 \u00a0rm -f /usr/share/doc/aria2/manual/en/html/.buildinfo\n\u00a0 \u00a0mkdir: cannot create directory \u2018/usr/share/doc/aria2/manual\u2019: Permission denied\n\u00a0 \u00a0make[4]: *** [install-data-local] Error 1\n\u00a0 \u00a0make[4]: Leaving directory/home/pb/aria2-git/src/aria2/doc/manual-src/en'\n\u00a0 \u00a0make[3]: * [install-am] Error 2\n\u00a0 \u00a0make[3]: Leaving directory /home/pb/aria2-git/src/aria2/doc/manual-src/en'\n\u00a0 \u00a0make[2]: *** [install-recursive] Error 1\n\u00a0 \u00a0make[2]: Leaving directory/home/pb/aria2-git/src/aria2/doc/manual-src'\n\u00a0 \u00a0make[1]: * [install-recursive] Error 1\n\u00a0 \u00a0make[1]: Leaving directory `/home/pb/aria2-git/src/aria2/doc'\n\u00a0 \u00a0make: *** [install-recursive] Error 1\n\nI found that $(DESTDIR) is missing in local rules in Makefile.am. I'll fix this.\nThank you for reporting a bug.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/tatsuhiro-t/aria2/issues/17\n. Fixed in 5323fa1\n. Thank you. Merged and pushed.\n. Thank you. I merged your patch with some modifications.\n. Thank you for the quick updates. Merged.\n. I think that indicator may go beyond 100% if piece containing the beginning of the or end of the file is shared by another file. But piece size is relatively small, aria2 will go into seeding mode in short time.\n\nAll I can reproduce is:\n[#1 SIZE:49.5MiB/49.0MiB(101%) CN:1 SEED:1 SPD:767.6KiBs]\nand in no time:\n[#1 SEEDING(ratio:0.0) CN:0 SEED:0]\n\nDownload at one point reaches 100%, but then goes beyond 100% and is not complete: Neither is the download stopped\n(or put into seeding mode) nor is it actually complete; there are still pieces missing.\n\nCould you give me some more info:\n- file size\n- piece size\n- actual indicator output\n- possibly, torrent URI\n. Thank you for the additional info.\nI found the bug that aria2 wrongly adds up the completed length of incomplete pieces which is not in the current selection, but is in the previous selection. I think this explains the >>100% issue.\nThe bug fix is pushed in master branch.\n. I think 1.15.2 fixes this problem. If you still experience this issue, please re-open.\n. Merged and pushed. Thank you!\n. Thanks. Merge and pushed.\n. Thank you! Merged and pushed.\n. Thank you! Merged and pushed.\n. I think bt-seed-unverified should work. You may need to supply correct directory path for the files using dir option.\nWhat kind of error did you get when you tried?\n. Do you mean aria2.pause RPC command? Then, yes, currently when aria2.pause is issued to seeding torrent, it is not paused but it goes to stopped state, so aria2.unpause can not be used. I think it should go to pause state and aria2.unpause can resume seeding. I'll fix it in the next release.\n. Fixed in 763c7a0.\n. With --enable-mmap, files are mapped onto memory and aria2 just writes the data to that mapped region. The actual write to the disk will be done by kernel. If kernel wisely schedules the disk IO, it will reduce disk seek. Actually, I observed that the disk access was much reduced. So if you have a bunch of RAM, yes it will work like a cache.\nPlease note that the option is marked as experimental because currently aria2 does not ask the kernel to flush the unwritten data to the disk during the download. It totally relays on the kernel when to write the data. This means that if accidental power loss happens, the unwritten downloaded data will be lost. If the download is BitTorrent or Metalink with piece hash, the download can be repaired with -V option.\n. Thank you!  This is awesome.  Could you send PR for this once you finish the patch?  We can discuss this in detail there.\n. Fix committed, closing.\n. Thank you! Just merged and pushed.\n. I checked current dev version and 1.15.2 PPA and found that they both exhibited some spikes when max-overall-download-limit was used, but overall they sited around the ratio aria2 was told to limit, just like  timsjoberg presented.\nFor marcbowes's case, it seems to me that aria2 behaved as if max-overall-download-limit change is ignored because its huge difference of expected value and actual one.\nWhat kind of RPC library or tool to communicate with aria2?\nHow many simultaneous downloads when you corrected these values?\nAlso was bittorrent involved in them?\nI admit that aria2c's speed regulation implementation is not so accurate right now. I think it leaves some improvements. But I think 700KB/s when limited to 200K is not what I expected from the current implementation.\n. Thank you for updates and I could reproduce the issue.\nThe problem is that the occasional spike is amplified with many connections (16 in this case).\nI pushed the fix in master branch (46bdaf0).\nThe fix only covers HTTP/FTP part, so I have to do the similar fix for BitTorrent.\n. Usually, PPA is updated on each new release.\nI think you can build aria2 fairly easily if you are using Ubuntu or Debian.\nThere is how to build instructions in README.rst.\nMaybe you can use curl in shell script to GET/POST GID to Web server?\n. I can load my Linux Chrome (ver22) Cookies fine.\nFrom aria2 log:\nLoaded cookies from '/path/to/google-chrome/Default/Cookies'.\nOn some systems, aria2 may not be able to open Chrome cookie file because Chrome got file lock.\nCould you check that you can open Cookies file using sqlite3 command?\n. Thank you for quick update!\n. Interesting. I don't see any use case of this new option other than seeding torrents, but I don't disagree to make the option applicable to all types of downloads.\n. Added --force-save option. If it is used with --save-session option, the completed (including BitTorrent seed)/removed download is saved to the file.\n. Replacing AC_PREREQ([2.67]) with AC_PREREQ([2.63]) in configure.ac might make autoconf 2.63 work though I have never done this before. Is there any updated autoconf package for openIndiana? Autoconf 2.63 is a little bit old to me now.\n. No updates for a year. Considered as closed.\n. Thank you for quick update. Merged and pushed.\n. Currently mmap availability is checked by AC_FUNC_MMAP. Perhaps it might not work well on openwrt.\nCould you replace it with AC_CHECK_FUNCS([mmap]) and run autoreconf and ./configure again to see that mmap is found?\n. Thanks, I'll do this change to the master branch.\nFor mmap on smal RAM machine, if available physical memory becomes low, OS will swap out (write) the mapped, not-yet- written data to the disk and free up the memory. So I think in theory, mmap disk cache works on the low memory machine. To cache the data, we need some RAM space non the less.\n. Thank you for reporting detailed information.\nfile-allocation is needed to mmap a file, because it requires the whole file allocated in disk.\nThe current implementation is relatively easy one and maps all opened files in memory region.\nSo I think it is true that if the total size of file downloaded concurrently exceeds 4GB on 32-bit OS, then all virtual address (VSZ) run out and the process will be killed by OS.\nIt means that enable-mmap is not suitable for 32-bit OS at the moment. I think 64-bit OS is ok.\nI have an idea for disk cache not using mmap, so I'll keep trying to experiment it.\n. I added --disk-cache option. It takes the upper bound of memory to use as memory cache of downloaded data and it is shared by all downloads in one aria2 instance. The data is flushed to the disk when a piece is completed, so it may reduce the disk seek time (thus disk activity). I observed that, with this option, the disk activity is clearly decreased on Windows with old hard disk. Because the routers have less RAM, this memory cache is not so attractive, but if you interested, please give it a try.\n. Grad to hear that it worked. Let's close the issue now.\n. Thank you for quick update! Merged and pushed.\n. Thank you for reporting bug. This was fixed in 04586f5\n. Thank you! Merged and pushed just now.\n. How did you add torrent download via rpc? There are possible scinarios: (1) the http link to .torrent file, (2) torrent file upload (3) magnet link.\n\nBy the way, if I can't connect to trackers via udp, does it mean I'm not connected to as many peers as I could be?\n\nIt is because aria2 does not support udp tracker.\n. I noticed that \"check-unverified\" in your config but there is no such option in aria2. aria2 ignores these lines so it is not the cause of this issue though.\nCould you check that console output of aria2 by running it in foreground (not daemon mode)? If it is seeding something, it shows \"SEED\" there.\n. I think uploading torrent only shows one actual download, without metadata.\nSo you saw aria2 was working fine and seeding all downloads but somehow you didn't show all of them in webui?\n. Good, let's close this issue.\n. It is indeed very strange. Did you check that configure.ac exists in aria2-1.16.1 directory?\nInstalling autotools-dev, gettext and make packages might help.\n. Have you tried release version of aria2 1.16.1 tar ball?\n. Just clarify: Can you build aria2 using aria2-1.16.1.tar.bz2 from http://sourceforge.net/projects/aria2/files/stable/aria2-1.16.1/ without autoreconf stuff?\n. Can you use autoreconf for other source programs on xubuntu? If not, then it is the xubuntu issue.\n. Reopen if you still have a problem.\n. There is --bt-tracker-interval option. --bt-request-peer-speed-limit option may also help if you mind low speed.\n. With DHT and tracker enabled, and assuming you are downloading torrent, not seeding, it is very strange that there is no connection. Could you grab aria2 log and check that tracker announce is made correctly?\nBecause this issue needs few hours to occur, log file gets too big. So you can enable logging after the connection becomes 0 using RPC command and wait for tracker announce (minimum 1200+ secs for your settings).\nTo enable logging via RPC, you can do it using aria2rpc:\ndoc/xmlrpc/aria2rpc changeGlobalOption -l /tmp/log.txt\n. Thank you. The debug level log is very helpful for debugging.\n. Thank you for the log. From the log, aria2 corrected peers from DHT (trackers are all udp but aria2 does not support them) and its peer list was full (1024 peers), but for unknown reason, aria2 did not initiate connection to those peers. The code to initiate connection is src/ActivePeerConnectionCommand.cc but unfortunately it does not have meaningful log message at the moment.\nI'll make a patch to add log message and post the link here.\nCould you apply the patch and do the same procedure again?\n. The affected source file has not changed since last release (1.16.1), so you can apply the patch to 1.16.1 tar ball. It is a little bit easier to build from git.\n. Patch is here: http://sourceforge.net/p/aria2/patches/61/\n. Thank you for the log. With your help, I found the bug which potentially causes this issue. It was fixed in 550ac8c.\n. Do you think including query component (after '?') of the URI in filename solves the issue? Or do you have another idea to solve this?\n. Thank you! Merged and pushed just now.\n. ...because aria2 supports DHT and works without UDP trackers?\nBTW, do you know a good open-source UDP tracker, which runs on Linux?\n. Well, I'm fine to add UDP tracker support, but testing with UDP tracker in development environment is crucial.\n. With quick google search, I found http://code.google.com/p/udpt/\n. UDP tracker support was added. For now, it is only enabled when DHT is enabled (DHT is on by default).\n. > Why is it supported for IPv4 only? IIRC there were some (standard) hack to let it work with IPv6.\nIt is still \"hack\", right? We need the proper specification in bittorrent.org or somewhere.\nAt the moment, IPv4 is still main stream, so there is no problem for the time being.\n\nlooks like pthread.h gets imported before that redeclaration and signal.h after it.\n\nWhich OS/platform are you using? I've never seen it on linux.\n\nStatus line somehow starts with some hexadecimal stuff:\n\nYes, since 1.16.x\n\nAs I understand, BitTorrent lines are about TCP port for incoming connections, right? I guess, there should be a mention of TCP there. Like \"listening on TCP port 6907\".\n\nGood catch. I'll fix it.\n. I'll do IPv6 UDP tracker things when IPv6 extension is documented because without ip parameter support (hack?) external IP does not work.\nHm, I don't have mac but will do compile aria2 on *bsd to see that it shows the same issue.\nOther than that, did UDP tracker work for you?\n. Since the UDP tracker support, which is the original subject of this thread, was added, I close this issue for now.\n. 2nd parameter of addTorrent is array of URI. The option is 3rd parameter.\nSee http://aria2.sourceforge.net/manual/en/html/aria2c.html#aria2.addTorrent\n. Thank you for reporting bug. This is the regresssion introduced by 07bb779e\nThe simple way to fix this is just call downloadResults_.pop_front() at the end of loop.\nThe counting removedErrorResult_ may be misleading without comment (I'll add that). It just hold error value of the last evicted\nDownloadResult so that we get last error code at the end of run even if downloadResults_ contains no error item.\n. Fixed in a49397e \n. Ah, OK, pop_front works because user expects download results are kept stored at least maxDownloadResult_ ( can be acessed via RPC) if the results are more than that. So we want to keep download result as much as possible under the restriction.\n. Great! Merged and pushed just now.\n. Nice patch. Thank you!\n. Thank you very much! Merged and pushed just now. Detecting unused members is really neat.\n. Yeah, cross-compiling is still dominant part of gcc.\n. I got the following error:\nsphinx-build -b man -d _build/doctrees   -c .  _build/man\nSphinx v1.1.3\nUsage: /usr/bin/sphinx-build [options] sourcedir outdir [filenames...]\nOptions: -b <builder> -- builder to use; default is html\n         -a        -- write all files; default is to only write new and changed files\n         -E        -- don't use a saved environment, always read all files\n         -t <tag>  -- include \"only\" blocks with <tag>\n         -d <path> -- path for the cached environment and doctree files\n                      (default: outdir/.doctrees)\n         -c <path> -- path where configuration file (conf.py) is located\n                      (default: same as sourcedir)\n         -C        -- use no config file at all, only -D options\n         -D <setting=value> -- override a setting in configuration\n         -A <name=value>    -- pass a value into the templates, for HTML builder\n         -n        -- nit-picky mode, warn about all missing references\n         -N        -- do not do colored output\n         -q        -- no output on stdout, just warnings on stderr\n         -Q        -- no output at all, not even warnings\n         -w <file> -- write warnings (and errors) to given file\n         -W        -- turn warnings into errors\n         -P        -- run Pdb on exception\nModi:\n* without -a and without filenames, write new and changed files.\n* with -a, write all files.\n* with filenames, write these.\nmake[3]: *** [man] Error 1\n. I may be missed something, but what is the use case of  \"out-of-tree Sphinx builds\"?\n. Ah, I got the error above because I ran make -C doc in primary aria2 directly. I think it is not the intended use case of this feature.\nWhat the content of /home/me/build-aria2? Does it also contain aria2 source tree?\n. OK, I understand the use case. The example you presented works for me.\nBut make html in original aria2 source fails as I wrote earlier.\nYes, VPATH is empty in the latter case.\nAnd substituting $(VPATH) with @srcdir@ makes both cases work.\n. Great patch thanks. I have couple of questions and I commented inline on the code. Please look at them.\n. Thank you, merged and pushed now.\n. Thank you. Merged and pushed now. I found some problems I didn't noticed yesterday and fixed them in the following commits.\n. I think you want a explanation of \"[ERROR] Failed to load trusted CA certificates ...\".\nIt means aria2 (actually SSL library it linked to) tries to load system wide CA certificates but failed (you see that reason in the error line).\nIf you want to make the error disappear, specify CA certificate file using --ca-certificate option.\nAlternatively you can use --check-certificate=false, but it is insecure because it turned off certificate checks for HTTPS sites.\n. The situation in Mac is not good for certs at the moment.\nIf you have Linux installation, copy ca-certificates.crt to Mac and use it with --ca-certificate.\n. I think it works. Still it is a bit fragile because we don't have Mac OS compile platform. We have several Mac OS X only code in aria2, but when they were written, I could use Mac OS machine in compiler farm hosted by sf.jp. But it was gone. If we cannot compile and test on that platform, things can be easily broken.\n. Thank you! That is awesome.\n. I heard that curl once bundled ca certificates but it was deprecated. I checked debian's ca-certificate package and it has update script but it relies on the certain directory structure suitable for Debian or Ubuntu.\nI agree that abstracting TLS code in SocketCore is a good first step.\n. I think yes, if it just only need few lines of code.\n. TLS interface abstraction was complete. See src/TLSSession.h\n. Thank you. Merged and pushed now.\n. Thank you. Merged and pushed just now.\n. Thank you! Merged and pushed now.\n. Thank you! Merged and pushed just now.\n. Awesome!\n. Thank you. Merged and pushed now. I fixed one typo in configure script which breaks openssl e6d75020.\n. I also made log level info in addTrustedCACertFile(), since, with WARN level, they will be always printed on Mac OS and old GNUTLS build which does not have its API. ddad275\n. Actually, we had generated configure and related files on repository before, but they have been dropped because it is hard to determine which is used or not and it is a bit awkward to check in auto-generated stuff as you wrote, though it is true that it is convenient in this circumstances. If the only problem is autopoint, then homebrew gettext should be fixed?\n. I just thought that the keychain stores trusted CAs to check (incoming) server certificate, not for creating secure server context.\nIf it is true, then is there any way to specify server's private key and certificate to create RPC secure server in aria2 instance?\n. > That's why I initially asked not to have this merged just yet. I'll look into that.\nI missed the last statement and rushed to merge the patch. Sorry about that. I was just excited about Apple TLS support.\n\n@tatsuhiro-t, do you think 'aria2 --v' should list the libraries it uses like curl does?\n\nYeah, I think it is a good idea.\n. The log means the one download item requested aria2 DownloadEngine to check when the socket is writable.\nThis happens when download item has pending outgoing data, which is determined by checkDirection() for TLS sockets. I documented the return value of checkDirection() is undefined when session is neither want-read or want-write state, but SocketCore code only checks it returns TLS_WANT_READ, and otherwise set wantWrite_ = true. So, because, AppleTLSSession::checkDirection()  returns 0 for undiefned case, it effectively causes wantWrite_ = true, which causes lots of write-ready logging because typically most of the time write is ready.\nI think the workaround is return TLS_WANT_READ for undefined cases. I think this is safe because network application's default behavior is reading sockets.\nIt is a bit strange Apple TLS lacks this direction check API, because it is for the TLS renegotiation and application cannot know without API.\n. @antbryan, I just added a feature to print linked libraries in aria2c -v\n. I plan to release the next version of aria2 the next weekend (April 20-21).\n@nmaier, if you have changes regarding Apple TLS stuff which should make it into the next release, please send me the pull request before the day.\n. That's BitTorrent DHT. It continues to work without any downloads.\n. Awesome. Ping me when the merge is ready.\n. Alright, merged and pushed now. Thank you!\n. Merged and pushed now. Thank you! I'll update TLSSession::checkDirection() doc to make it clear that WANT_READ must be a default.\n. When #64 is implemented, can we use --rpc-certificate and --rpc-private-key in the same way with the other TLS libraries?\n. Currently, I have no plan to integrate web UI to aria2 at the moment. I think their development work fine in separate entity.\n. Can we close this now?\n. If I understand this issue correctly, this issue is document how to use aria2 HTTPS RPC with self-signed certificate with major browsers.  Do you really explain it in our documentation?  Stackoverflow like service has many info about them already.\n. So finally OpenSSL 1.0.2 snapshot has wildcard hostname check function.\nIt seems OpenSSL 1.0.2 X509_check_host implements RFC 6125, which is the same algorithm used in aria2, so it is good.\nBut GNUTLS implementation is old RFC 2818 based, so I think it is better to stick with our own implementation at the moment.\n. As for file size, the latest version performs gzip to session file if you add \".gz\" extension after the session filename.\nAt the moment, aria2 internally does not differentiate options from config file and from command-line, also it sometimes changes options on the course of downloads.\n. Ah, that would be easier than I think. It would be good to add an option to toggle this because some people may like original behavior.\n. In aria2, option values are overwritten in the following order:\n1. default values\n2. conf file\n3. cmd-line\n(See option_processing.cc for the order of option application)\nFor input file, its accompanied options overwrites the result of 3 (or merged into 3).\nI understand that the originator wants to just save options specified by 3 and later stage.\nThe most options are not specified by command-line and hence input file, saving only those options will save significant amount of space.\nTo implement this stuff, the obvious choice is introduce parent-child relationship in Option class.\nEach download item has its own Option object which fills options specified by cmd-line and input-file.\nIt has the association to Option object which includes options filled by conf file, which in turn has the association to Option object with default value.\nWhen a certain option value is queried, Option object checks its own option values. If it does not have one, it then asks parent Option object and so on.\nOn serialization, we just asks Option not to consult parent Objects, so the overhead is almost zero.\n. I'll create a patch based on my idea.\n. I pushed the change 4070113. Please test it. I decided not to add option to toggle this because the content of conf file seems to be rather stable and size reduction is drastic.\n. Thank you! Merged and pushed.\n. It seems that uv_run(loop, UV_RUN_ONCE) does not wait for timeout, it just returns immediately, resulting 100% CPU usage. (On Debian Linux)\n. Yeah, it works fine for me too.\n. I know this is WIP, but I'll accept the patch if you are ready.\nBTW, I'm thinking about the default of --event-poll.\nFor mingw build, it is libuv is definitely the default, although the building libuv with mingw seems difficult (I have not tried that yet).\nFor Linux and other *BSD families, including Mac OS X, we have epoll and kqueue implementation for years and they work well. Libuv is still a fast moving target, so using our epoll and kqueue as default is a good choice.\nBut libuv is not largely packaged as of now and those who try to use it with aria2c may want to use it. In this case, choosing libuv as default is better choice. What do you think about this?\n. OK, merged pushed just now. Thank you very much.\n. I fixed configure script so that pkg-config can output static linking libs. But still build fails with gnutls and libxml2.\nUse openssl and libexpat instead:\n./configure --with-openssl --without-gnutls --with-libexpat --without-libxml2 ARIA2_STATIC=yes\n. aria2 first check the configured IP address families and only send those families of IP address lookup to DNS server. This is because some IPv4 only DNS servers just drop AAAA lookup query and it takes aria2 to want for the long timeout. Now I look into your log file, aria2 failed to detect any address. It seems aria2 launched before IP address configured. \n. I made a change to check configured address again if none of those were found in the previous check.\nSee 2e39fd6\nStill it is a workaround, because addresses can come and go in any time. If we can hook an event when interfaces are up or down, we can use it as a trigger to perform check again.\n. Did the change work for you?\n. Thank you! Merge and pushed just now.\n. Thank you. Merged and pushed. FYI, I fixed sphinx warnings in f326955\n. Capitalization done. Thank you for the suggestion.\n. Please upgrade automake, autoconf, gettext stuff to the reasonably latest ones. Or download source package which has configure generated. Or wait for the next aria2 version release which will be out in a few days.\n. Now aria2-1.17.0 was released. Use its tar ball, which does not require to invoke autoreconf things.\n. Please check that the file \"/Volumes/My Passport/untitled folder/untitled folder2/6a002c0f0d00808dab5b5bcfe40800cace6b945e.torrent\" exists.\n. May the spaces in the path cause this?\nWhat happens if running aria2c with the path directly?\n$ aria2c '/Volumes/My Passport/untitled folder/untitled folder2/6a002c0f0d00808dab5b5bcfe40800cace6b945e.torrent'\nIf it works on internal drive and only happens with external disk, then there may be some differences in tuxera stuff.\n. The external hard disk might not be mounted at the time when aria2 tried to read file?\n. Could you tweak aria2 init script to wait for the hard drive plug in?\n. Does that mean StartOnMount is not working as advertised or aria2 emits same error even after the hard disk is completely successfully mounted and its files can be accessed by other programs?\n. No progress on this. If OS feature does not help, writing script which repeatedly checks filesystem is mounted (e.g., try to read file on that partition and if failed, sleep 1 seconds), and after success, launch aria2c, might work.\nEven if .torrent files are copied into other locations, the actual file is still in extern drive and it cannot be read before mounting that file system.\n. It works for me. command-line option and configuration?\naria2 may take some time to contact to tracker before exit.\n. Use --seed-time=0\n. It sounds like a bug. Did you have reproducible test case for this? (e.g., URI and cmd-options)\n. I found a possible execution path which causes cache data loss. Fix committed in b054546\n. Thank you for the info, I'll try with that settings. Meanwhile, could you try the fix in b054546?\n. Reopen this issue if it still happens with 1.17.1\n. I think alias works well here. Also shell will expand partial input, in my system, type 'ari' and hitting tab leads to 'aria2c'.\nBTW, why not just a or a2 ? :)\n. I could not see the point. Could you elaborate your issue in more detailed?\n. Use --force-save option\n. --header option cannot be specified per URI, but for cookie case, you can export cookie text file from browser (e.g., Firefox) or write cookie text file and import it to aria2 using --load-cookies option.\n. Nice catch. Thank you. Merged and pushed now.\n. OK, merged and pushed. Thank you!\n. To support large file, just hacking that line is not enough.\nI pushed the commit 5bc5665, which includes support for large file on Android.\n. Here is the android build for testing: https://docs.google.com/file/d/0B8qYMk_Gn7y6X0YyaDFocFlVaVU/edit?usp=sharing\n. Please test with --file-allocation=trunc\n. It seems this works fine, so let's close the issue.\n. If this is the same issue discussed in #80, please close this issue and continue to use #80 instead.\n. Thank you for the valuable information. Enabled TLS 1.1 just now. I experienced gnuttls's buggy behavior for TLS1.1 in the past, but it was long time ago and I didn't remember the error message.\n. Can we close this now?\n. Sorry, I completely missed it.\nIf download was failed after trying all available URIs, aria2 does not save it, because restarting such download will also fail. Do you think we should save such download with failed URIs?\n. OK, save error downloads with all failed URIs then.\n. Fix committed fde376e\n. @multiSnow Could you check that the above commit works for you?\n. Thanks. Let's close the issue.\n. Is this OS X version related issue?\n. Thank you, merged now.\n. It seems I broke that way. Thanks again.\n. Fix committed in 13e064e\n. Thank you for prompt update!\n. Yeah, that's a horrible bug. Thank you, merged and pushed just now.\n. With -k1M, aria2 can split files in more chunks but I don't know it is really related to this issue.\nI found many EOF in the log, so that is the server dropping the connection.\nIf you want to keep the download running, -m option may help.\n. Reopen if you still have a problem.\n. It may be BOM issue.\nCould you save config file in utf-8 without BOM and try it again?\nPlease note that windows notepad mindlessly add BOM to utf-8 encoded file, so don't use it.\n. Currently, there is no way to load input file while aria2 is running.\n. Thank you! Merged and pushed.\n. Commit date Apr 28 is a bit weird, but its ok for now.\n. Thank you. Your change is clear and definitely an improvement for documentation. Merged and pushed just now.\nI'll apply the same change to --follow-metalink option, since it works in the same way.\n. Use --check-integrity and --checksum option.\n. Maybe I didn't understand your issue properly. Do you want an option to just ignore the item in input file? Or else?\n. --allow-overwrite behavior is already complicated and I don't want to add another one.\nBTW, why do you want to keep item in input file which just get skipped?\n. --force-save option is per item and you can specify it only for torrents. Maybe it is the MANUAL work you want to avoid, but generally you know the item is torrent or not when adding it.\n. If the high memory use is caused by lots of downloads, consider to reduce download history using --max-download-result. Also RPC method aria2.purgeDownloadResult() will clear all download history.\n. Is this still in work-in-progress?\n. Should it be handled in configure (e.g., checking clang can compile shared_ptr and if not add flags to CXXFLAGS) ?\n. Thank you. Merged and pushed now.\n. Thank you. Merged now.\n. Thank you. Merged and pushed now.\nIt looks like i686-w64-mingw-g++ 4.6 does not support override keyword. I'll define macro for override keyword in case that compiler does not understand it.\n. Thanks. Merged and pushed now.\nI hoped this work because std::move is just a \"cast\" to rvalue reference. But in this case the function argument is passed by value, so if the move is taken place before the function call and httpRequest->createRequest(), then crash is expected. If the argument type is std::unique_ptr<...>&&, then it may be OK.\n. Quick check with Linux gcc4.7.3 and gcc4.8.1 with -Ofast, both tests passed and runs fine with downloads.\n. This change fixes the compile error with clang:\nhttps://github.com/tatsuhiro-t/aria2/commit/6bcf33a69e1bfa9f7679b78f9f287d84798015aa#src/IndexedList.h\n. The control file contains uploaded bytes but once the download finished, control file is removed, so this situation happens (correct me if I'm wrong).\nThe solution may be save control file unconditionally if --force-save is used.\n. Not entirely.. because the solution is not implemented yet.\n. Fix committed in de55569\n. 140% compared to which version? And was the footprint measured with two versions with exactly same parameters, same torrent and same running time?\n. What about the RSS (which is non-swapped physical memory used by aria2)? I don't think slightly larger VSZ is a problem.\nAlso could you narrow down the options to see which one causes this issue?\n. Are you still experiencing this issue?\n. Thank you for reporting bug. Fix committed in 8d62682\n. Sorry, I fixed the bug in the same way you did but before I noticed your merge request (mail notification does not include this merge request..)\n. There are 459 occurrence of std::move in the source code, it seems that it would be better to check all of them.\n. Did you try --disk-cache option? It does power of 2 buffers and aligned\nwrites\n2013/08/11 22:55 \"Nils Maier\" notifications@github.com:\n\nI loaded a couple of thousand smallish (<1MB) files with 6 concurrent\ndownloads to an NTFS partion on Win7 and had plenty of consecutive free\nspace. The downloaded files had a little over 8 fragments per file after\nthe queue completed as analyzed by contig.exe.\nThe main reason seems to be that aria2 does not buffer writes at all (not\neven stdlib buffers) and leaves this entirely to the OS. ProcessMonitor saw\ndirect WriteFile calls with usually 1400 length, i.e one per received TCP\nsegment, which is bad for a couple of reasons:\n- Many small writes cause many syscalls, which isn't exactly great\n  performance-wise.\n- Many small writes may cause excessive fragmentation, as demonstrated\n  here.\n- The non-power-of-two size of the writes doesn't play nicely with\n  cluster sizes and file system implementations.\nI actually implemented a PoC write buffer in AbstractDiskWriter, which\nindeed reduces the fragmentation significantly. That PoC still has a couple\nof problems, such as AbstractDiskWriter being a suboptimal place for\nbuffers and thus not working well when using --split.\nThere should be some buffering, ideally a per-connection receive buffer\n(instead of per-file write buffer).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/115\n.\n. --disk-cache does 4KB aligned writes and uses 16KB buffer.\nThe code in AbstractSingleDiskAdaptor::writeCache and MultiDiskAdaptor::writeCache.\n. Well, 4K/16K are certainly  not from the careful experiments. I'm open to\nchange those values.\n\nOn Mon, Aug 12, 2013 at 10:58 PM, Nils Maier notifications@github.comwrote:\n\nI totally missed disk-cache so far. However, from the man page I cannot\nreally gather what a good value for this would be. I just started a --s6\n-x6 --disk-cache=10M 204M download, and it appears to write in 256k\nchunks, so where did your 4KB/16KB come from?\nLet's re-target this issue then from \"provide disk cache\" to \"provide a\nsensible default for the disk-cache option other than 0\".\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/115#issuecomment-22494745\n.\n. Thank you. I agree that 16MB cache for windows build, but I wonder other build (e.g., linux) needs disk cache. When implementing disk cache, I conducted tests on both linux and windows. On Windows, it has dramatic effect on disk access, but for Linux, it is not noticeable. I don't know what mac os x behaves about this.\n. Fair enough. The only concern is memory consumption because aria2 seems to be used in embedded system which does not have lesser memory than desktop. But as you wrote the disk cache can be disabled explicitly.\nWe needs some big notice that next release will require 16MB memory for disk cache, then will do accordingly based on the reflection from the users.\n. BTW, I added @nmaier  as collaborator in aria2 project given that the contributions made in the recent period. If you don't want that, please notify me about that.\n. Checked all occurrences of std::move in src/*.{h,cc}. Fixed one bug in  7f049dc\n\nIn CookieStorage.cc,\nreturn cookie && store(std::move(cookie), now);\nis suspicious, but I think it is ok, since right-hand side of && is only evaluated when cookie is evaluated non-zero.\n. I welcome the fixing ctrl-c handling on Windows.\nI don't know much about Windows SetConsoleCtrlHandler and Windows binary execution, but aria2 is single threaded application and we don't need any locks.\n. No objection. Merging now.\n. Did you get any error message when you did autoreconf -i? What OS you are using and do you compile aria2 from git repo or tar ball (and which version)?\n. Added gettext-devel and cppunit to fedora package list in README.\n. +1 to AM_GNU_GETTEXT([external])\n. Merged now. Thank you!\n. Agreed\n. I didn't see the comment carefully, so I meant AUTOMAKE_OPTIONS, but I'm fine with AM_INIT_AUTOMAKE too, as long as it works.\n. @kax4 Thanks. I removed suspicious edits and unwanted ones back to 2010/10.\n. The thing is the changes we made for C++11 are mainly in the internal API, which are not exposed to the outside of aria2 codebase. I do not strongly oppose to 2.0. In the current progress, we never release 2.0 if we think it is brand new, whole rewrite program. But from the outside, aria2 trunk is not much changed from 1.17.1.\n. Done.\n. Thank you! Merged and pushed just now.\n. Could you run aria2c on gdb and get stack trace when it crashed?\n. With gdb, we can track down to the line number of source code.\n. I could not reproduce this issue on opensolaris: i386-pc-solaris2.11.\naria2c started with --enable-rpc and I telnetted to 6800 port and hit ENTR but aria2c didn't crash.\nI did the same thing on x86_64 linux, but no avail.\n. Just quick ldd to working aria2c executable and it shows libgcc_s.so is linked:\nlibgcc_s.so.1 =>         /usr/sfw/lib/libgcc_s.so.1\n. i386-pc-solaris2.11\n. Note that gcc on my solaris is awfully out-dated: it is version 3.4.3.\n. I'm not absolutely sure but it seems to me that the library used to get compiled/linked are different from the ones used in the runtime. In this case, /usr/sfw/lib/amd64/libgcc_s.so.1 is used in compilation, but somehow dynamic linker sees aria2c executable is linked against  /opt/local/gcc47/x86_64-sun-solaris2.11/lib/amd64/libgcc_s.so.1.\nIf you just type g++, is it the gcc47 under /opt/local/gcc47? Or else? Maybe it is not configured properly?\n. I got similar problem with freebsd 9.1. It has gcc 4.2 by default, so I installed gcc 4.8 using ports and it was installed under /usr/local/gcc48. The first problem was linker failure on build step. The linker searched libraries under  default library location first and got wrong libs other than the ones which came with gcc 4.8. The result was linker error. It was fixed by adding LDFLAGS=-L/usr/local/lib/gcc48.\nAfter successful build, running aria2c made another error: \n/usr/lib/libstdc++.so.6: version GLIBCXX_3.4.10 required by /path/to/aria2-1.17.1/src/aria2c not found\nAgain dynamic linker searched wrong one. The obvious workaround is use LD_LIBRARY_PATH=/usr/local/lib/gcc48.\n. We got similar report from a user for --on-download-complete. Actually, we have no idea why because we could not reproduce the problem. It may be due to permissions or privilege issue.\nWhen command could not run, that process outputs the error message like \"Could not execute user command...\" in the stdout. When you run aria2c by command line with --on-download-complete, do you see this error message or just simply nothing happens?\n. OK, so this is toolchain related issue.  Closing.\n. What kind of option do you like to add?\n. If the feature is appealing to the user in general (i.e., it is not too specific to the youtube stuff), we may accept the patch.\n. English please\n. 16 is plenty. Too easy to do DOS.\nIf you want more, change the source code as you like.\n. Sounds interesting. Is is advantageous over websocket, which is implemented aria2 and offers event notification?\n. Plain HTTP is good. I still see not much difference between it and websocket. Because aria2 supports websocket already and browsers support both EventSource and websocket. In proxy wise, both are not so good in clear HTTP. I have no strong objection to EventSource, but I don't see much gains in doing so.\n. BTW, you should add your name to AUTHORS file.\n. Is this in work-in-progress state?\n. LGTM now. Thank you very much.\n. Thank you, merged now.\n. See DefaultBtAnnounce::processAnnounceResponse and DefaultBtAnnounce::processUDPTrackerResponse in src/DefaultBtAnnounce.cc\n. Thank you. Merged now.\n. I found a problem, and fixed in 7f18494a8\n. BTW, please put `{' of function body at beginning of the line if you write new code for aria2.\n(this is not applied to the class or struct definition).\nvoid somefunc(int x)\n{\n    // ... function body ...\n}\n. Great work. Merged and pushed, thank you.\n. I don't remember any change regarding this, but periodical session saving feature has been implemented a while ago. Check out --save-session-interval option.\n. Thank you for quick updates. Merged and pushed now.\n. It turns out that debian mingw-w64 cross compiler toolchain does not provide required libraries for wintls.\nI'm new to SChannel and without compiler, it is hard for me to review the code.\nIf you are ok, I'll just merge this stuff, since it seems not to break anything if it is disabled.\nYou may add more commits to make it stable.\nOne question, wintls only supports pkcs12 format and --rpc-private-key is always ignored?\n. Alright, I reviewed the code (without consulting SChannel doc, so it is very \"right\" one).\nI found that WinTLSSession::writeData() has some issues. Also my concern is that wintls::Buffer is really necessary. std::string is a good candidate for its use.\n. If you got my writeData comment, which was deleted from this thread, don't mind, it was a mistake.\nThank you for the mingw-w64 debs, I'll try that.\n. Looks like recent configure.ac fix now enables current version of debian mingw toolchain can compile wintls stuff. And now I found some issues.\nIs have_wincrypt broken now?\nAlso it seems that we need configure.ac: L414 looks like this:\nif test \"x$have_openssl\" != \"xyes\" && test \"x$have_appletls\" != \"xyes\" && test \"x$have_wintls\" != \"xyes\"; then\n. OK, using --without-libgcrypt will avoid the problem.\n. No bug reports so far. Closing.\n. I mean the ordinal Mingw32 builds with openssl are still the main download target for Windows.\nI'm ok not to publish wintls build.\nOther than new wintls stuff, the commits include internal message digests and several cleanups.\nFor internal message digests, aria2 is usually built with gnutls or openssl, so it is not a problem.\nI wonder just reviewing cleanup things than cherry-pick may be constructive choice.\n. Now documentation under doc/manual-src/*/aria2.rst are freezed until the next release, which is slated for Oct. 13. Typo fix is OK.\n. Thank you for quick updates. Merged and pushed now.\n. > I'm filtering IPs and all the peers which I connect get banned.\n\nWhy this happen?\n\nThe log is a bit confusing. It says \"banned\", but it only means the peer has just disconnected.\nThere are several reasons that connection is broken. Maybe peer disobeys protocol, there are no interaction between the peer and local peer in a certain time, etc.\n\nI have this error:\n\nThis is interesting error message. We'll check it out.\n. Which version of aria2 are you using?\n. > The time that peers do not interact with each other and they are banned, is defined by aria2?\nYes\nDid you encounter assertion failure error frequently? Or is it a rare occasion?\n. Thank you for the info. I'll look into it.\n. Do you have complete log file when the assertion error occurred? Could you send it to me?\n. Yes. My e-mail address is the first line in AUTHORS file in the repo just in case.\n. Thank you for the log.\nThe source code line number from the log is a bit strange. It does not match the relevant location of the line number in 1.18.0 source code.\nDid you compile aria2 from 1.18.0 tar ball? Or was it the modified source code somehow or binary package?\n. aria2 connects to peer in last-in-first-out manner. Because the order of incoming peer is undefined, it is random in a sense.\n. Thank you. Merged now.\n. There is no such feature right now.\n. The document is out dated and needs to be fixed.\nYes, -C option is merged into -s option and removed. We did this long time ago with some migration period.\ncommit 19b5b7e214a3d29e1579af4504ba5c90e1dc3e36\nDate:   Tue Apr 2 00:12:24 2013 +0900\nRemove deprecated options: --enable-direct-io and --metalink-servers\ncommit 84b19f154af821696c7507cefc192e08d1ca161e\nDate:   Sun Oct 30 21:36:36 2011 +0900\nDeprecated --metalink-server option. Use --split option instead.\n. Wiki was fixed now.\n. gcc version?\n. Please use later version gcc, 4.7 or 4.8 are recommended. The minimum is around 4.6.4.\n. We migrated into C++11 language features after #75. For older OS, 1.17 series is not so bad. Apparently there is no major bug in it.\n. Could you give us an example entry in the input file with options?\n. OK, I can reproduce the issue.\nUnfortunately, there is no good solution for this, because there are complexities involved in determining file name.\nAs a workaround, you can add unique out option in the input file like this:\nhttp://r6---sn-5go7ln7l.googlevideo.com/videoplayback?.....\n    out=file1\nhttp://r6---sn-5go7ln7l.googlevideo.com/videoplayback?.....\n    out=file2\n. Adding an option to include query part of the URI in the filename may solve this issue. What do you think of this idea?\n. You are right, length is an issue.\naria2 supports Content-Disposition header field quite well.\n. It is not restricted to --input-file option case. You could get this error with the following command-line:\n$ aria2c -Z http://a/b http:/a/b\nCurrently, auto file renaming only works after aria2 makes sure that the same filename is not downloaded concurrently. This is needed to only one download can acquire .aria2 control file.\n. Maybe we could do something like that. I'll look into this and report back here.\n. I made a commit  e1e6bb1 to make it work. Please test it if you can.\n. Uploaded windows binary at https://drive.google.com/file/d/0B8qYMk_Gn7y6RC1MMXZQLWJLU0U/edit?usp=sharing\nPlease report back here to tell us whether it works or not.\n. Could you tell us legal magnet links to reproduce this issue?\n. It seems the compiler is not setup in the right way. From the error message, configure script failed to detect getaddrinfo, but it is unlikely if the toolchain is installed successfully. Maybe bug of NDK 9b.\n. It seems to me that compiled 3rd party libraries are not compiled or archived in the right way:\nconfigure:19316: arm-linux-androideabi-g++ -o conftest -Os -g -std=c++11  -I/Users/litao/Myprojects/Android/android-ndk-r9b/usr/local/include   -I/Users/litao/Myprojects/Android/android-ndk-r9b/toolchain/sysroot/usr/include  -L/Users/litao/Myprojects/Android/android-ndk-r9b/usr/local/lib conftest.cpp -L/Users/litao/Myprojects/Android/android-ndk-r9b/usr/local/lib -lssl -lcrypto  -lexpat -lz  >&5\n/Users/litao/Myprojects/Android/android-ndk-r9b/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.8/../../../../arm-linux-androideabi/bin/ld: error: ssl: no archive symbol table (run ranlib)\n/Users/litao/Myprojects/Android/android-ndk-r9b/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.8/../../../../arm-linux-androideabi/bin/ld: error: crypto: no archive symbol table (run ranlib)\nconftest.cpp:68: error: undefined reference to 'EVP_DigestInit_ex'\ncollect2: error: ld returned 1 exit status\nconfigure:19316: $? = 1\nFYI, android binary for 1.18.1 is available for download in sf.net.\n. How did you build and install openssl? The cross compiling is still black magic stuff and gets wrong easily.\nWe usually do this:\n```\nPREFIX=$ANDROID_HOME/usr/local\nTOOLCHAIN=$ANDROID_HOME/toolchain\nPATH=$TOOLCHAIN/bin:$PATH\nexport CROSS_COMPILE=$TOOLCHAIN/bin/arm-linux-androideabi-\n./Configure --prefix=$PREFIX android\n``\n. Use arm-linux-androideabi-strip to remove all symbols from the executable. Then it would be 2MB-3MB or so.\n. You don't lose anything without libuv at the moment. Actually, I'm not sure libuv can be compiled with android NDK.\n. This is a missing feature in aria2. aria2 has--bt-max-open-filesoption to limit the number of open files but its scope is per torrent, not global. It is sub-optimal, but you can reduce it to smaller numbers to mitigate the issue somewhat.\n. With the commit 4d105a2,--bt-max-open-filesnow limits the number of opened files globally, not per each download.\n. aria2 is alive and running program and it is very natural to use more memory if needed.\nHow do you determine that aria2 leaks memory?\nCould you provide us the result of memory leak detection tool like valgrind.\nWithout that, it is very difficult to us to track down this kind of issue.\n. For low memory device, use --disk-cache=0 to disable disk cache in memory, which is by default 20MB.\n. Please use English here. I'm warning you gently.\n. It may be due to heap fragmentation.  jemalloc might help.\n. Thank you for quick update. Merged and pushed now.\n. Regarding f117909, there is an issue when truncation occurs inside the ANSI escaping sequence.\nIf that occurs, there next output is also colored wrongly and some garbage characters in the console.\n. Still does not work.\nThe thing is, when resizingreadout, we can only extendcolorcharsonly inside thecolwhen printed.\nCurrent code extends allcolorchars, which may contains the numbers beyond thecol`.\nIn the past, I thought of this idea, but it seemed to be a bit tricky so I didn't.\n. It may be well enough for you. But for me, the code is broken and does not work as expected. I think you understand why.\nAs you inferred in your comment, we surely don't want overkill and inefficient object for this tiny extra feature.\nI want simpler code. The follow piece of code can do the job:\n```\nenum {\n  S_LITERAL, S_ESC\n};\nnamespace {\nvoid truncateOutput(std::string& out, size_t max)\n{\n  if(max == 0) {\nout.resize(0);\nreturn;\n  }\n  int state = S_LITERAL;\n  size_t n = 0;\n  bool need_endesc = false;\n  for(size_t i = 0; i < out.size(); ++i) {\nswitch(state) {\ncase S_LITERAL:\n  if(out[i] == '\\033') {\n    state = S_ESC;\n    need_endesc = !need_endesc;\n    break;\n  }\n  ++n;\n  if(n == max) {\n    out.erase(i + 1);\n    if(need_endesc) {\n      out += \"\\033[0m\";\n    }\n    return;\n  }\n  break;\ncase S_ESC:\n  if(out[i] == 'm') {\n    state = S_LITERAL;\n    break;\n  }\n  break;\ndefault:\n  // unreachable\n  assert(0);\n}\n  }\n  return;\n}\n} // namespace\n```\nWith this code, we don't even have to track the number escape characters.\nIf you are not care about truncation, then I'd like to pull 95fc2d4 only and leave the colorize readout to me.\nI'll handle that.\n. Fair enough. Let's use your stream class.\nBut please don't edit unnecessary bits of code like this:\n```\n-} // namespace\n-namespace {\n```\nI won't merge with these unnecessary changes.\n. Please define ColorizedStreamBuf::str() in .cc file.\n. Merged and pushed now. Thank you.\n. Could you please be more specific?\n. I failed to see a good use case for this. Probably be WONTFIX.\n. What is \"torrent url contents\" ?\n. -S option only works with local file.\n. Because it does not fit into the way aria2 works. aria2 can download multiple files at once. It is not obvious when those contents are shown when multiple downloads are involved. We could show its content right after the download but I'm not comfortable with that.\n. If the cause is the missing symlink, then this is a homebrew issue.\n. So homebrew does not create a link on purpose.\nCurrently we have no description about homebrew in README. If this issue affects many mac os users, it would be good to add a note about it. I'm willing to accept a patch about this.\n. > it would be a good idea to update http://sourceforge.net/apps/trac/aria2/wiki/Download to ...\nAgreed. Will do.\n\nAlso, providing static-linked binaries like you do for Windows and Android, ...\n\nThe problem is I don't have mac, so I cannot offer the binary build.\nIf you could provide them, I'll offer you the uploading permission to the sf.net.\n. OK, updated wiki page.\nI'll close this issue cause we are going to provide OSX binary, issue tracked in #159.\n. I don't have mac, but have FreeBSD9 which has kqueue the log says a lot of times.\nBut the issue has not been reproduced so far. I saw couple of kqueue failure message, but they existed in 1.17.1 log too.\n. Thank you for bisecting.\nSo 9e7579b475 is the last good commit?\n. OK, I found a possible bug in 8e6e46d.\nThe return value of fork() handling is completely wrong.\nCode cleanup should be done with care.\n. I successfully reproduced this error with --on-download-complete option. I think the commit 2c566ccb68c should fix this issue.\n. Thank you! Merged and pushed.\n. I have not yet read .mk file, but I think osx-package should be located at the root (along side of doc, src..), cause we have already put some build files there and not in doc.\nI wonder we really need binary DS_Store thingy in the repository.\n. OK, I was convinced. Thank you for the effort. You can now merge this stuff.\n. I think yes because it would avoid some autoreconf related problem some users would have.\n. I'm planning next release (see #167). Maybe it could feature Mac OS X binary.\n. Great. Do you have sf.net account? If you don't have it and don't want to get one, I can upload the binary to sf.net on behave of you.\n. Nothing other than style stuff.\n. Merged and pushed. Thank you. \n. The crash was fixed in 705dadb.\nWe can support relative path in metalink file, by specifying the base URI with --metalink-base-uri option.\nBut aria2 totally does not support file URI scheme, so currently no way to deal with local file here.\n. Screenshot? How are the characters badly printed in that terminal?\n. I think you need to use terminal emulator with bidi support, such as mlterm.\n. It would be an option. But we recommend you to use bidi supported terminal emulator at the moment.\n. > Pls cancel, ...\nI get this as \"please close this issue\". If you mean the opposite, please reopen.\n. Thank you. Uploaded 2 files to sf.net. And make .dmg file as Mac default.\n. OK, will do. Due to equipment issue, the edit will be done in next week.\n. web site updated.\n. Use --allow-overwrite=true to prevent file being renamed.\n. The reason why we use .torrent format is that we don't know the actual file name when aria2.addTorrent() is used.  It just uploads content of file without file name.\n. UDP tracker support is piggybacked on IPv4 DHT feature (sharing same UDP port).\nDHT initialization failure will result in lack of UDP tracker support.\nCheck the log to see that DHT is fully functional.\n. Also it would be recommended to check aria2 version using aria2c -v, cause many users install several versions of aria2 and they sometimes invoke older one.\n. Is the torrent marked private?\nIf so, c881f9f may fix the issue.\n. utp is very interesting protocol. I wonder it is a dominant protocol in BitTorrent traffic now. TCP based original protocol quite works well for me.\n. Please reopen this if you still encounter this issue.\n. @nmaier The build uses openssl 0.9.8y, do you encounter the same issue in mac osx platform?\n. Thanks. So this is the problem of linker.\n. --allow-overwrite truncates file before --check-integrity kicks in. As a result, --check-integrity is effectively ignored.\nThe thing is that --check-integrity with a checksum for entire file only works when the file size matches.\nThis is described in the manual of --check-integrity option.\nThe piece hash works even if the file size differs. So if you can produce piece hashes in metalink file, you can do the following command-line to achieve what you want:\n$ aria2c --check-integrity=true big.metalink\n. From http://aria2.github.io/manual/en/html/aria2c.html#cmdoption-V, it looks like YES.  Have you tried that?\n. I can reproduce this bug. I'm working on it.\n. I believe 8216bdb fixes this issue.\n. Yeah, just tagging it is easy. But we usually are required to create Windows and android builds and now Mac OSX build and also have to write release notes. Due to equipment issue, I'm away from the PC I used to do these works.\nIt will be done in a few days, though. Also I note that it is a bit advantageous to wait several days to collect more bugs and release the fixes in one package instead of making a release for each bug. It will save our time and energy.\nUsers have a choice to use older version of aria2 to workaround the issue.\n. 1.18.3 has been released just now.\n. Upload completed. Thank you.\nBTW, aria2 could not download the above links with gnutls. I got TLS handshake failure.\naria2 with openssl, wget and chrome work fine.\n. I use debian libgnutls28 which is 3.2.4. The interesting part is that the bundled gnutls-cli can connect to tn123.org. aria2 with the same gnutls version fails.\n. I added that call in GnuTLSSession::init(), but aria2 still fails. \nOCSP may still be related to this issue, since I observed that gnutls emits fatal alert after getting certificate status message from server, which includes OCSP response.\nI tested several gnutls libraries; here is the result:\nlibgnutls-dev  2.12.23 : works\nlibgnutls-dev  3.0.22 : works\nlibgnutls-dev  3.2.4 : does not work\n. Non-blocking socket stuff breaks this handshake?\nBTW, another gnutls version test result:\nlibgnutls-dev 3.2.3: does not work, this is the default of ubuntu 13.10\n. Great! So we hit gnutls bug.\nI moved that line to after _gnutls_recv_handshake in gnutls-3.2.8 and it fixed the problem.\nI'll check that wget exhibits same symptom if it uses non-block socket\n. And yes, wget also fails:\nsrc/wget --connect-timeout=5 https://tn123.org/aria2/aria2-1.18.3-osx-darwin.tar.bz2\n--2014-01-06 23:05:36--  https://tn123.org/aria2/aria2-1.18.3-osx-darwin.tar.bz2\nResolving tn123.org... 94.23.160.241\nConnecting to tn123.org|94.23.160.241|:443... connected.\nGnuTLS: An unexpected TLS handshake packet was received.\nUnable to establish SSL connection.\nThis is wget from git repo, built by myself, against gnutls 3.2.4\n. I'm under the same impression. GnuTLS guys will take care of the rest ;)\nFurther info about wget: the current version of wget 1.14 does not make socket non-block during SSL/TLS handshake at least with GnuTLS, so it does not suffer from this bug. But the git version has enabled non-block to incorporate connect timeout, and it also hit the bug.\nThank you very much for debugging this bug.\n. I think it would be better to make gnutls debug level 0 by default, cause it will force gnutls to do additional work. I think build time option works.\n. > We could make it so that if the aria2 log level changes (e.g. by option processing) we would change the gnutls log level accordingly.\nThe thing is usually we don't want gnutls debug log in aria2 debug log output.\nSo it would be good to enable them separately.\n\nBut the overhead should be mostly some string-formatting, which is kinda negligible, and of which we have a bunch in aria2 already (every time A2_LOG_*(fmt()) is called, no matter what the level is).\n\nLog itself is pretty heavy already, yes.\nBut gnutls code uses unlikey macro, which resolves into __builtin_expect((x), 0), which indicates it should not be called unless we really need debug log.\n. > We could do the same...\n\nAt least for known-problematic gnutls versions\n\nWe won't. aria2 uses non-blocking socket entirely. If gnutls functions block, aria2 itself blocks, which violates the fundamental design of aria2.\n. The workaround would be use GNUTLS_NO_EXTENSIONS flag in gnutls_init() to disable OCSP stapling for buggy library version.\n. We'll first identify the first version the bug was introduced and for those versions, give GNUTLS_NO_EXTENSIONS to gnutls_init() and enables session ticket (if ever needed) using API.\nI think this bug only affects client side code (correct me if I'm wrong).\nFor the good version gnutls, we don't do anything.\n. Thank you for the info.\nThe fix committed in 2f02946\n. Yes, let's close this issue.\n. Alright, I was convinced, let's do this.\n. It sounds like a serious flaw. I think we should remove JSON-RPC using HTTP GET.\n. Thank you for detailed analysis, I will read that today.\nI have a bit simpler view. Since this is some kind of xsrf, checking\nreferer would help. We can define acceptable referer prefix. I am not sure\nwebsocket handshake carries referer, if it does not, we can check its\norigin header field.\n. Yes, we require referer (and origin for websocket) but it can be toggled by\noption. We just try to prevent malicious web sites perform rpc stuff. User\ncan explicitly specify the trusted oigin. For non browser client, if you\nare not going to use aria2 with browser, just turn off the origin check.\nOtherwise, it is easy to add required header field in script.\nThat said, it may be an issue if web client is written so that it is not\nsent referer.\nI now read your proposal and it sounds reasonable to me. Did you check that\nthis mehod works with current chrome and firefox? And possibly, their\nmobile versions?\n. > Extend the JSON-RPC stuff to allow specifying a user/pass combo in the request json per call in case the trick does not work for whatever reason.\nIt sounds like this is the most reliable solution to me.\nOne way to achieve this without breaking anything is introduce new access token. It is actually a shared secret, and if it is given to aria2c, all RPC methods takes this access token as the first parameter.\nIf access token is not defined, RPC method signatures do not change.\nNote that this new scheme is orthogonal to the existing HTTP basic auth, which will be deprecated after a reasonable transitioning period. Extending JSON is relatively easy, but XML-RPC is strictly defined and there may be not possible to add our needed metadata in terms of library implementations. Using parameter list works both JSON-RPC and XML-RPC. For WebSocket, it is basically JSON-RPC over WebSocket, so it works without problem.\nIf you care about the token flying around, use SSL/TLS.\n. We should not abuse Sec-WebSocket-Protocol for our security purpose, because such hack could be broken unexpected way. Actually, we don't need any header field stuff for websocket because we are going to add access token to the each json-rpc payload.\nFor access token, we are going to deprecate HTTP basic authorization after short period of transition time. Our new security scheme requires just one single secret token, and we don't need user/pass pair anymore. In your theory, remembering 1 thing is easier than 2 things.\nWe should not autodetect access token parameter in RPC method. We use token as security measure, so we have to be explicit about it. That's why I proposed new auth token option, which enables new security mechanism and makes token parameter in RPC method mandatory. And \"token:\" prefix is unnecessary without autodetection.\nActually, I don't want to spend much energy for backward compatibility.  The current scheme is insecure, so we are going to add new scheme. Then deprecate old HTTP basic auth. Just leave it as is for transition period. After all, UI devs would not start adopting new scheme until they find that latest aria2 does not work with their UI.\nSo my argument is:\n- Leave HTTP basic auth stuff untouched as much as possible\n- Avoid to abuse Sec-WebSocket-Protocol\n- Don't perform autodetection for access token parameter in RPC method\n- Introduce new option to specify access token, which enables new security mechanism and it explicitly requires access token as the first parameter in all RPC method.\nFor JSON-RPC GET, if we include access token in the URI, which might be logged in unexpected places, so we should deprecate it nonetheless.\n. > The protocol stuff is in the RFC and shipped with browsers, so it is\n\nunlikely to be broken at this point. Just saying.\nIt is defined for announcing subprotocol. Not for sending something rather.\nWe should not autodetect access token parameter in RPC method. We use\ntoken as security measure, so we have to be explicit about it.\nThis will break the API and all clients with it. There is no point then\nin keeping HTTP auth around, at all, as all clients will have to adapt\nanyway.\nNo. I wrote that 1st parameter of RPC method must be access token only when\nnew auth scheme is enabled. If not enabled, the methods do not take access\ntoken parameter and behaves just like before.\nUnless you proposing to make the token the last optional parameter to all\nAPI calls. But that sucks. because then users will have to provide values\nfor all optional parameters that come before that. And also it wouldn't be\nexplicit.\nI wrote that its 1st parameter that is mandatory only when new auth scheme\nis enabled.\nThen lets be swift about it and just rip out the the Http Auth stuff\nentirely now incl. rpc-user and rpc-password, and change the API to have an\nexplicit token parameter, always and add --rpc-token.\nI still think that we shouldn't break all clients, and we don't have to\nwith my proposal. My proposal does just break browser users, and deservedly\nso, as in a browser context it is insecure right now to access aria2.\nSo I'm still favoring my approach.\nNew scheme is not enabled, then it is completely backward-compatible (well,\nactually it is not changed at all).\n. > OK, I misunderstood you there. I didn't expect that you meant to enable\nthe new auth stuff only in certain circumstances, as it contradicts your\n\"don't want to spend much energy\" point.\nI said that because we don't touch HTTP basic auth stuff.\nAfter transitional period over, we throw away HTTP basic auth and make new\nauth scheme mandatory.\nBy default, CORS POST is disabled, so the attack vector is coming from\nJSON-RPC GET and WebSocket.\nWe may have an option just to disable these 2 if new auth is not used.\nBut still it is debatable to continue to support JSON-RPC GET because\nsecret token is in URI.\nYes, and as insecure as before!\nYes it is because old implementation is insecure in anyway, so the\nbackward-compatible mode is.\nAnd aria2 would use it as such. If you use the \"token\" subprotocol, you\nswitch to a sub protocol where you don't need to specify tokens in the RPC\nrequests. I fail to see how my use contradicts the spec.\nAnyway, as I said the WebSocket stuff is just an optional way to auth.\nSo you append token parameter to our subprotocol scheme, ok I just\nunderstand it.\nYou say it is optional, then we don't have to pay cost for it, right?\n. > We may have an option just to disable these 2 if new auth is not used\n\nReconsidering about this, no, we should mandate new auth, this is a good time to do that once it for all.\n. My idea does not break rpc client in the transition period.\nAfter that, it is all fine to break them. That is the purpose of the transition period as a whole.\n. Because I don't have time for this these days and you already have running code, I leave this to you.\nBefore commit, please remove websocket subprotocol sutff from the change.\nIt is a new thing and is not for backward compatibility and we can live without that.\n. OK, I have some time for this in this weekend. Will do merge and do some extra and make it go forward.\n. The fix committed in 7f6987a and 7d1aa88.\nI end up implementing my idea, but borrowed some ideas from c6b9bb9, for example, prefixing token parameter as \"token:\" so that we remove it if --rpc-secret is not used in server side.\nThank you .\n. Although there are several timeout and disconnects in the log, the download from a peer goes on quite well with probably a good speed. Did you observe 0mbps while this log is written or after this log?\n. The first log contains only bittorrent download and --realtime-chunk-checksum does not affect bittorrent download. Please send another log if you get that, maybe I'm missing something.\n. > As a note, these clients are on a LAN together and when not in WinPE typically achieve transfer speeds of 50-60MB/s using Aria2\nWhich means that aria2 compiled for linux can do 50MB/s? And only WinPE build is affected?\n\nAs an aside, should it be normal for them to be pegging a 3.4ghz single core for 10-20MB/s? I'll work on uploading a new log first thing tomorrow.\n\nI don't think hashing 8MB data in 20MB/s consumes 100% CPU all the time in bittorrent download case, although typically the hashing is the most CPU intensive operation in download.\n. I observed that there is spikes in the CPU usage, and it goes high when disk I/O is performed.\nI still see that it can go on 50MB/s on Windows without problem.\n. We have nothing special in this area. In each release, we packaged source tar balls and several compiled verions (Mac OSX, android and Windows).\n. Fix committed in 30e4077\n. Thank you. Merged and pushed now.\n. Too small value is degrade performance, since it may cause more TCP connection establishment.\n. Thank you for the patch.\nTo specify arbitrary values from the command-line option is not good idea to me.\nIs there good default value for download client?\nAlso it would be nice to add help messages to the option to tell user what this option does for them.\n. Thanks.\nWhy is dscp value left-shifted by 2? I think without reasonable explanation the users have really no idea what value they have to specify.\n. Well, then those details have to be described in the help message.\nIt should be considered whether we take value and left shift it by 2 or take a value as is and specify it with clearing lower 2bits (or print error if those 2 bits are nonzero). The end user may not know \"left-shift by 2\".\n. It would be good to add text  about what you wrote in the previous post to the help message. Specifying CS4 is a good example to add. I'm sure it greatly helps people new to DSCP like me.\n. It sounds good. Thank you.\n. Thank you. Merged and pushed now.\n. The big issue is that aria2 can download multiple files simultaneously and out-of-order in its original file position. In that condition, output to stdout is somewhat hard to use.\n. To specify different file name for each downloads, currently one has to use -i file option.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption-i\nInside it you can set options per download item: http://aria2.sourceforge.net/manual/en/html/aria2c.html#input-file\n. For example, suppose you created the following file:\nhttp://localhost/foo/bar\n    out=buzz\nhttp://localhost/index.html\n    out=file.html\nand save it to list.txt.\nThen aria2c -ilist.txt makes aria2 download 2 files and file from http://localhost/foo/bar is saved as buzz and file from http://localhost/index.html is saved as file.html.\nIn list.txt, you can write URI per line for each download. Options for each download can be specified after the URI line and preceded by one or more spaces.  In the above example, out option is specified, which is the same as --out option in command-line. You can also write multiple URIs per line delimited by TAB to download a resource from multiple URIs.\n. Use -k option. -s 20 is too much. Should be used with care.\n. Check out http://mingw-w64.sourceforge.net/ We abandoned mingw usage some time ago and now use mingw-w64 to produce windows binary for each release, which does not require any changes to the code to build aria2.\n. Update README file to add the text stating that MinGW may not be able to build aria2 for now. Thank you.\n. It looks like you need to specify \"referer\" using --referer option.\n--referer 'http://libgen.org/scimag/index.php'\n. Strange, this is typical works for me situation.\nAnyway, you made it in your own way, can we close this issue?\n. The numStopped counts the number of stopped downloads kept in memory, which can be altered by --max-download-result option and it is default to 1000.\nFor memory constrained environment like RaspberryPi, it is not practical to set large values to --max-download-result. I think it would be generally useful to add the number of cumulative stopped downloads to the response of aria2.getGlobalStat().\n. Fix committed in 1462d65\n. Thank you. Merged and pushed now!\n. Documentation is frozen now for translation. The release day is Mar 23.\n. I encountered some issues with relatively new mingw-w64 compiler 4.8.2 in debian sid.  It looks like its C++ compiler unconditionally defines __USE_MINGW_ANSI_STDIO to 1, while historically aria2 defines it to 0.  I made some changes to use __USE_MINGW_ANSI_STDIO=1 because we have no other choice.  Quick tests on windows 7 looks good, but there may be some glitches.\nThe good news is that we have now all required compilers above gcc 4.8, so we can use more advanced C++11 features.\nI'm now building releases now.\n. OK, 1.18.4 is out now.\n. Thank you! Uploaded them to sf.net.\n. It looks like g++ from CentOS is old enough not to support C++11. I don't know CentOS has the updated g++ packages, but if it is not available, then the options are 1) build g++ 4.8 2) install more modern distribution, e.g., Ubuntu 13.10, which comes with g++-4.8\n. The last release not using C++11 is aria2 1.17.1 which includes UDP tracker/DHT support.\n. If you don't need sqlite3, give --without-sqlite3 to configure script\n. If you still have a problem, please comment here\n. aria2 can be redistributed in GPLv2 or later, which effectively includes GPLv3.\nThis program is free software; you can redistribute it and/or modify it under\nthe terms of the GNU General Public License as published by the Free Software\nFoundation; either version 2 of the License, or (at your option) any later\nversion.\n. Yeah, that might be an issue, but we've developed aria2 in 8 years and we have not this kind of issue so far. Only one occasion, an user from BSD world suggested that aria2 should change the license but the suggested license was something other than GPL.\n. Good point. Fix committed in de4cd8b\n. Windows build supports numeric IP address only.\n. I tested Windows 7 PC, which has 2 interface. Both 192.168.0.100 and 10.0.0.100 worked fine for me.\n. Yes.\n. I saw that --interface works on Win7, using only the specified NIC. Does this happen on Windows2008? Do you have win7 to test this issue?\n. Thank you. Merged now.\n. Thank you. Merged and pushed now.\n. Thank you. Merged now.\n. Thank you. Merged and pushed now.\n. We found that 1.18.4 have a bug to cause torrent download to immediately abort on windows build.  We'll do quick fix and release 1.18.5.\n. Fix committed in f0473dc\n. Fixed in 1.18.5\n. Could you describe the details about \"continous download retries with 0bytes\"?\nDo you have a public URL or steps to reproduce this issue?\n. I ran that package and got 0 bytes download issue only once.  After I configured aria2c to output log (--log option), I could not reproduce it after I ran more than 10 times.  It seems it is affected by remote server, but I'm not sure what happens at the first time.\nIf you have aria2c log file when 0 bytes issue happened, could you upload it somewhere?\nAnd this is not the workaround of this issue, if you are downloading many files at once, it is more efficient to specify them in text file and load it to aria2c using -i option (or use Metalink XML file).  This is because aria2 can download several files at once and if some downloads go to the same remote host, aria2 can reuse connection.\n. Thank you for the log.  It looks like aria2 suddenly lost reception of DATA from remote server.\nTLS handshake has done right to me.\n. 1.18.5 is out now.\n. Thank you! Uploaded them to sf.net.\n. -Z option is not supported by RPC method at the moment.\n. The workaround is directly specify cookie using --header option.\n. --header options cannot load cookie files.  It specifies HTTP header field \"Cookie\" directly, and it can include multiple cookie name/value pairs.\n. aria2 only supports Basic authorization.  What authorization does the site use?  What HTTP error did you get? Maybe aria2 log (--log) option may help.  Please don't forget to mask your username and password if you paste the contents of the log here.\n. It seems HTTP status code is missing:\n2014-04-04 15:52:25.700195 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\nCache-Control: private, no-cache, no-store, must-revalidate\nContent-Type: text/html; charset=utf-8\n. Log says server returns 200 OK (success code) and download completed just fine.\nWhat is the problem exactly?\n. Are you sure that facebook supports Basic authorization?\nThe screen shot shows form based authentication, but it does not necessarily mean facebook offers Basic authorization.\n. For 64bit linux, downloading >2GB file should not be a problem.\nDo you have URL to cause this issue? Could you also tell us all aria2 options you used?\n. Also Stack trace would be very helpful.\n. Thank you for the info.  aria2 uses 32bit integers to download unknown length file, that's the serious limitation right now.  The whole motivation about this is it would be rare to download so large files without knowing file size in advance since this kind of download is not repairable.\nThat said, it would be much better to use 64bit integers everywhere to fix this problem.\n. Thank you, sir!  It looks good to me.\n. Thank you for reporting.  This bug was fixed in  a82f087.  The next release will have this fix.\n. There is no rush. I'll wait for your review.\n. Thank you.\nSo we need to build gmp with --enable-fat for windows as well?\nCurrently we build Mingw32 build using following 3rd party libraries:\n- openssl\n- expat\n- sqlite3\n- zlib\n- c-ares\nopenssl does 3 roles: SSL/TLS work, big integer calculation (for BitTorrent encryption) and message digest.  With new build configuration, SSL/TLS work will be done by WinTLS.  Big integer stuff is done by gmp and message digest by also windows native implementation.\nSo the new library configuration becomes like this:\n- gmp\n- expat\n- sqlite3\n- zlib\n- c-ares\n. Understood.\n. Updated Mingw32 build script 83691981e\n. Good catch. Fix committed via 67aa993\n. Yes!\n. Because each user has their own preferences.  Your automatic calculation has some assumptions: max connection per server and lowest piece length.  They may not suite to other people'use.\n. I have not read entire diff, but the direction is acceptable.\nI understand that PBKDF2 is used to limit the number of attempt of guessing per given time.\nWe do this by computing again and again.  While doing this, the other ongoing downloads are paused.\nI wonder it is possible to interleave this calculation into other activity.\nIf it really needs too much complex extra code, then it is not worth trying though.\n. I have no hard feeling about interleaving. So you can proceed in the current form. I count on you in this area.\n. Please use array version make_unique.  Instead of:\nstd::unique_ptr<char[]> work(new char[hmac_length]());\nwrite\nauto work = make_unique<char[]>(hmac_length);\n. validateToken is in DownloadEngine, so it is better to define iterations in validateToken as member variable of DownloadEngine. We did the same for tokenHMAC_ and tokenExpected_ already.\n. When building aria2 from released tar ball, docutils is not used, this is because we includes generated html and man pages from rst in tar ball.  We checked its availability in configure, but it is not an error if it is not found.\n. Ah, I see.  README.html was generated and included in tar ball, but is not going to be installed if rst2html is absent.  I'll fix it.\n. Via 6020756d2e, README.html is always installed regardless of rst2html availability.\n. Thank you for reporting this bug.\nThis issue was fixed via commit 13a202df070d.\nThe code in 1.18.5 was only valid for gnutls >= 3.0.0.  It failed with gnutls 2.x.\n. Could not reproduce this issue both 32bit and 64bit binaries.\nThe assertion failure was due to fail to create TCP socket, which means fundamentally something wrong in networking stack.\n. If you do conditional-get, I think --allow-overwrite should be true, because without that,  aria2 does not download modified content and throws the error you mentioned.\n. Can you propose the better wording in documentation?  We'd like to upgrade documentation.\n. on-download-* event is fired for each download.  Does this clear your concern?\n. I checked on-download-start after on-download-complete, but both commands ran fine.  Do your scripts have some dependency with each other?\n. Still not reproducible with --enable-rpc.  Are you using Windows version?\n. Duplicate of #227 \n. Use TAB instead of SPACE\n. Normally, aria2 does not create .aria2 directory in user home directory.\nIt creates it when it tries to save BitTorrent DHT file.\n. If .aria2 is not found, aria2 runs with default values.  This is all we do for years now.\nIf you need configuration file read from the standard location, then you have to manually create .aria2 and copy aria2.conf, just like you did.\n. I have Win7 but no Win8.1, so I cannot reproduce it.  Did you get any error in log file?\n. That is a reasonable explanation.  @sambul13  can you confirm?\n. So you need to use local user credential to avoid system credential popup?\nAbout path issue, windows API accepts both '/' and '\\'.  But Command (DOS) prompt does not accept '/' for some reason I don't know.\n. I close this issue since the point of this issue was fixed by --enable-rpc.  Credentials or permission is windows specific, and can be workarounded by --conf option.\n. Overall, this is good. After fixing the commented section, feel free to merge. Thank you.\n. Agreed.\naria2 has already  been registered in coverity opensource scan project.\nBut recently, I have an issue with cov-build.  It reports only about 40% analysis complete, so I cannot upload data to the coverity analysis.\n. Sure.  Approved.\n. @nmaier You are now Maintainer/Owner of aria2 coverity project.  I think you can submit build now.\n. Please don't change coding style of existing file.\nI did not check everything but noticed following:\n-  T& a -> T &a\n- if(... -> if (\nCould you revert these changes?.  Othetwise I just revert the commits.\n. Thank you.  It makes reading diff easier too..\n. I reverted some changes regarding changed coding style to exiting style in adeead6\nI don't want to use my time to do this again.\n. I just landed travis integration.  To use container-based infrastructure on travis, we have to whitelist all the libraries we depend on.  I raised the issue to travis, and everything was resolved today.  Awesome.\nNow I pushed .travis file to master branch, and integration completed.  Closing issue.\n. Looking relevant source code, yes, it looks strange.\nBoth compilers (gcc and clang) compile the code fine and I cannot find any reference this is wrong, but I have no strong desire to leave this as is, and it is much better to make cov-build work.\nThe patch looks good to me.\n. @tleepa BitTorrent DHT continues to work after BitTorrent download was completed.  Currently, we save DHT routing table to a file in every 30 minutes, this matches what you observed.  And no option to configure this timeout nor to stop DHT.\n@sdysj I think it would be desirable only save session file if there is diff.  Could you raise new issue for this?\n. It would work.  Alternatively, we can check the queue status since the last serialization.  If it is in dirty state, we save. Otherwise, we don't.\n. @sdysj If you want to save session on its own timing, consider to use aria2.saveSession RPC method and specify longer interval to --save-session-interval option.\n. Commit 1944d8d does what I wrote.\n. For DHT things.  Shutdown DHT subsystem after all bittorrent downloads completed would solve the problem.  The thing is I've not written the code to expect this.\n. I think disabling auto saving aria2.dht when no bittorrent download takes place is a good start, though it is not a optimal.\n. Thank you!\n. Is this HTTP/FTP download or BitTorrent?\n. Thanks.  I can reproduce it now.\n. Fix committed via 83f4bce\n. The above mentioned commit fixes the issue, but I found that changing directory is fundamentally flowed in aria2 codebase.  Currently, it does not work correctly if Metalink is involved.\n. The proposed fix is remember the suffix of the path, which is only available in BitTorrent and Metalink download.  So that we can change directory with this suffix path.\nSetting FileEntry::setLength(0) should be done in ProcessStoppedRequestGroup (or on restart, which is better actually) if it is not generated from BitTorrent or Metalink.\n. Commit 4f3c526 fixes Metalink issue as well as this bug.  I think we can close this issue now.\n. I prefer GPLv2 for souces in src directory to public domain, but this time the crypto_* is fairly standalone, so I'm fine with the presented license.\n. Yep\n. I don't know how you invoke aria2c executable (not android app), aria2c executable must have permission create directory under /storage/sdcard0/Download.  There may be fancy characters in directory path, which file system does not like, but I cannot tell from what you described.\n. If root permission can solve the issue, then this is not an aria2 issue.\nI don't know the Android permission system.\n. In simplest case, there is no need to create directory, yes.\nIf you download torrent, it may create directory hierarchy.\nMaybe android is so special, some assumptions we made for normal Linux does not apply.\nI think the user using aria2 on android is not only you and we have not hear this kind of issue, so there may be resolution.\n. libuv support is experimental, and not maintained regularly.\nlibuv is going fast and we don't have good incentives to keep it up.\n. workaround is disable libuv in configure.\nAs far as I know, there is no particular benefit using libuv with aria2 because we only use it as socket event notification.  In this regard, it is far more reliable to just use built-in epoll backend.\n. Thank you.  Merged now.\n. Documentation has been frozen as of now.  We expect 13 Jul release as planed.\n. Released.\n. Thank you!  Uploaded to sf.net.\n. Ah, sorry, for the delay.  I just did that.\n. Works for me.  Could you check that RPC request does not contain file-allocation option?  If it does, then it overrides the default configuration.\n. I thought so  But there is curl port to pnacl\nhttps://code.google.com/p/naclports/source/browse#svn%2Ftrunk%2Fsrc%2Fports%2Fcurl\nIt seems nacl_io provides standard C API, such as standard I/O and BSD sockets.\nhttps://developer.chrome.com/native-client/devguide/coding/nacl_io\n. Yeah, you cannot download DVD images in chrome for sure.\n. Right, we have no plan to work with this issue, so close it now.\n. Use -V option.  If you are really sure files are correct, use --bt-seed-unverified to skip hash check.\n. Did you set --seed-ratio to 0?  By default, seeder exits when seed-ratio goes to 1.0.\n. .. and would be better to start a new thread.\n. Aria2 supports large file but your file system doesn't.\n. There is no plan to split torrent part to something else.\n. There is several C/C++ BitTorrent libraries.  They are meant to be reusable.  I think using it is better than making effort to split feature from aria2.\n. Agreed.  Fix committed via e55b543\n. Yes, it is pseudo random.  I'm fine with this, but if you think random order is not what you want, please update patch.\nSince we plan to release next version this weekend and I'd like to avoid last minutes changes if possible, so merge will be done after the release.\n. Please note that regardless of what ever IP address aria2 choose in findAllCachedIPAddresses(), it prefers pooled connection which is searched with all IP addresses designated to a target host.\nI don't plan to change this behavior since reusing connection is much preferable than complete round robin-ing IP addresses which may require additional TCP connection.\n. I found that the fix for #215 may not be good enough.  We still int32_t variables in Piece class:\nclass Piece {\nprivate:\n  ...\n  int32_t length_;\n  int32_t blockLength_;\n  int32_t nextBegin_;\n  ...\n. It appears that it does not affect download file integrity, but it makes download information retrieved by RPC method corrupt.  I also found a performance issue.  I'll make minimal fixes for this toward the next release, which will be done in couple of days.\n. Thank you! Merged and pushed now.\n. @nmaier any idea?\n. Fixed in 98681552fc\n``` diff\nFrom 98681552fc811b797045851ff5b921d31dc5ca5f Mon Sep 17 00:00:00 2001\nFrom: Tatsuhiro Tsujikawa tatsuhiro.t@gmail.com\nDate: Mon, 14 Jul 2014 21:32:48 +0900\nSubject: [PATCH] Fix compile error on big endian platform\n\nsrc/util_security.cc | 3 +--\n 1 file changed, 1 insertion(+), 2 deletions(-)\ndiff --git a/src/util_security.cc b/src/util_security.cc\nindex a6faf1e..c7984cf 100644\n--- a/src/util_security.cc\n+++ b/src/util_security.cc\n@@ -37,7 +37,6 @@\n#include \"FatalException.h\"\n #include \"util.h\"\n-#include \"crypto_endian.h\"\nnamespace {\n using namespace aria2;\n@@ -166,7 +165,7 @@ HMACResult PBKDF2(HMAC* hmac,\nfor (uint32_t counter = 1; key_length; ++counter) {\n     hmac->update(salt, salt_length);\n-    const uint32_t c = crypto::__crypto_be(counter);\n+    const uint32_t c = htonl(counter);\n     hmac->update((char*)&c, sizeof(c));\n auto bytes = hmac->getResult().getBytes();\n\n-- \n2.0.0\n``\n. Duplicate of #254 \n. Or instead of burning cpu, we can delay response if authentication is failed, which does not affect overall performance.\n. Well, but 30ms is a lot to me and it is still arbitrary chosen number.\nGenerally, aria2 is single threaded application and CPU intensive PBKDF2 does not suite well.\n. Thank you.  Looks good to me.\n. Looks good to me. Thank you.\n. No, I'd like to make 1.18.7 bug fix only release without no documentation change.\nThe RLIMIT and auth stuff deserve a \"proper\" release.\n. 1.18.7 was out.\n. I forgot to push tag.  I pushed to the github just now. Other than tags, everything was pushed.\nThank you for Mac packages, I'll upload them to sf.net. Will be done in a few minutes.\n. Thank you!  Merged and pushed now.\n. Fix committed via bd0a396\n. No progress at the moment.\n. English please.  Edit your comment or I will delete it.\n. @ghostry Is your comment related to this thread?  I don't see any relation.  If this is an another separate issue, please raise a new issue.\n. Could you please create new issue?  This thread is for openwrt + cpu 100%, not saving session issue.\n. thanks.\n. Could not reproduce.\nCould you get log and stack trace?\n. Still could not reproduce this issue with http_proxy and --http-proxy option.\nCould you provide us stack trace?\n. Thank you for the info.  I could reproduce problem.\nThe fix was committed via c659fe9.\n. It seems that firefox refuses to connect to the websocket server from a page of the different domain.\naria2 does not have nothing to workaround for this.\n. Try./configure --disable-nls`, which prevents compiling source files under intl directory.\nThen run make again.\n. We are already late, but pending WinTLS issue was finally fixed and OSX issue is still not fixed.\nGiven that we have no clue about the latter, I go ahead to release 1.18.8, since it contains good improvement for Win users.\n. Done.\n. Upload done. Thank you!\n. I agree with you, it is safe at this stage. Merged now.\n. Turn off -P, --parameterized-uri option.  It treats [ ] in URI as loop construct and there are no escape mechanism in this option.\n. Reopen if turning off -P option does not fix the problem.\n. Thank you for quick update. Merged now.\n. Which platform/OS are you using?\nIt seems that configure found that your OS lacks gettimeofday, so it starts compile our own gettimeofday and failed to compile it.\nIt seems that our gettimeofday is too windows specific.  This is understandable because most of the *nix OS provides gettimeofday.\n. Could you send me config.log ?\n. Could you try the following patch?\n```\ndiff --git a/configure.ac b/configure.ac\nindex 337ba99..bc6392a 100644\n--- a/configure.ac\n+++ b/configure.ac\n@@ -170,6 +170,14 @@ fi\n# Checks for libraries.\n+AC_SEARCH_LIBS([clock_gettime], [rt])\n+\n+case \"$host\" in\n+  solaris)\n+    AC_SEARCH_LIBS([getaddrinfo], [nsl socket])\n+    ;;\n+esac\n+\n # Check availability of libz\n if test \"x$with_libz\" = \"xyes\"; then\n   PKG_CHECK_MODULES([ZLIB], [zlib >= 1.2.3], [have_zlib=yes], [have_zlib=no])\n@@ -613,14 +621,6 @@ AM_CONDITIONAL([HAVE_ZLIB], [test \"x$have_zlib\" = \"xyes\"])\n # Set conditional for sqlite3\n AM_CONDITIONAL([HAVE_SQLITE3], [test \"x$have_sqlite3\" = \"xyes\"])\n-AC_SEARCH_LIBS([clock_gettime], [rt])\n-case \"$host\" in\n-  solaris)\n-    AC_SEARCH_LIBS([getaddrinfo], [nsl socket])\n-    ;;\n-esac\n-\n # Checks for header files.\n AC_FUNC_ALLOCA\n AC_HEADER_STDC\n```\nAfter patching, run autoreconf -i, which requires autotools.\n. It seems every checks g++ involved failed because of undefined reference to `clock_gettime@GLIBC_2.17'.\nI think this is a bit unusual and it seems compiler configuration error to me.\n. Are you using aria2 OSX binary download from sf.net?\n@nmaier Any idea?\n. I wonder that this issue is only limited to https URI.  Do http URI also cause this crash?\nIs there any way to get good stash trace on OSX?\n. We can treat OSX specially and make clang as default, but it may confuse people who expects default compiler is gcc.\n. Thank you for backtrace.  I think 9a931e7 fixes it.  This is yet another careless \"std::move()\" use.\nIs this issue the same with the original one?\n. @eedlund Are you using proxy to access https URL?\n. Alright, I believe this issue was fixed now.  Thank you.\n. I think this is normal.  From the log, the metadata was 174 bytes.\nAfter metadata was downloaded, aria2 started to download file the metadata describes, which is 2.1 MB.\n Since aria2 just started to download it, its size is 0.  It takes some time for the download to begin.\n. @nmaier Any idea?\n. I think e7e80e5 fixes the issue.\n. I reproduced this issue exactly the same way the reporter wrote on Windows 7.\nI used aria2rpc script as RPC client.\n. Thanks.\n. So, it is something like adding adler32 type to --checksum option, like:\naria2c --checksum=adler32=11E60398 URL\n. I should mention clearly that adler32 is not supported at the moment.\n. It is do able since its calculation is very easy, but we would like to know how you use this feature.\nUsing --checksum is simplest usecase and you can use it in text file and feed the file to aria2 using -i option.\n. Great to header that you are using Metalink4.\nThen we can add adler32 hash type to Metalink4 code, then you just fill adler32 value in hash element and aria2 will perform verification using it:\nxml\n<hash type=\"adler32\">11E60398</hash>\n. Added adler32 support in e18e8ae\n. You can use --header option to send cookie.\ne.g. --header=\"cookie: a=b\" --header=\"cookie: c=d\"\n. Are you still having this issue?\nLatest aria2 binary release should work.\n. Thank you for confirming this is working. Closing.\n. In the past, aria2 uses aria2/$VERSION prefix as peer-id.  But we shortened to current scheme (A2-1-18-8-...).  I think it is just a matter of picture and does not cause interop problem.\n. I understand your point.  But rolling back to old peer ID just for a particular tracker is counter productive.  I think that tracker would eventually be updated to support current peer ID prefix of aria2.\n. Thanks. Fixed via ddee21c\n. Wiki is now offline since sf.net pulled the plug of it.\nPlease check packages in particular Linux distribution you are planning to use.\nI know at least debian has it.\n. wiki is gone now.  I thin most linux distribution has aria2 package now.\n. Absolutely yes!  Patch is welcome.\n. Thank you! Merged now.\n. Thank you. Merged and pushed now.\n. Please describe what the problem is.\n. BitTorrent download could stall in several ways: not enough peers, port is not properly forwarded, DHT entry point is not given and its routing table is empty, etc.\nCould you upload aria2 log file during the time this issue happened?\n. aria2 does not distinguish seed only and downloading.  After seed period completed, it finally removed and next job will start.  By default, aria2 performs seeding until seed ratio reaches 1.0.  If you think it is too slow, then use --seed-time to specify how long seeding continues.\n. I just added --bt-detach-seed-only option to fix this issue via commit f72a303.\n. Thank you! Merged and pushed now.\n. Any character content of XML element has significant meaning and it is considered as part of URI.\nOnly URI should be appeared in  tag.\n. \"token:\" is correct.  Thank you for reporting this bug. Fixed via commit 3b68e1d\n. Yeah, close it now\n. I agree with you, aria2 should not crash with invalid data.\nFix committed via 2cec9df\n. I believe this was fixed the above commit. Closing.\n. Use aria2.pause instead of aria2.remove if you want to restart download.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html?highlight=aria2.pause#aria2.pause\nTo restart (or make it eligible to start depending on the size of concurrent downloads), use aria2.unpause.\n. Thank you for reporting this.  Fixed committed via ae50b93\n. The translated manuals will be updated by individual translator.\n. In aria2, file name is determined after download was started. Because of this, it is hard to delete files in waiting or paused state. Active state items are also sensitive.  So only file in completed downloads can be safely deleted. But we should be careful when deleting files... because it is an one way ticket.\n. OK, closing now.\n. There are many items in sf.net trackers and no automatic migration path to github, which means it is practically impossible for our very small dev team to do this by hand.\nSo we keep open sf.net tracker in read-only mode.  If someone is keen to items in old tracker and attract attention, raise it here.\n. Unfortunately, we have no plan to migrate sf.net issues.\n. aria2 does not block until rehashing or file allocation are completed.\nRPC response may a bit bit slow down if file system is slow, but usually not much delay.\n. Do you mean you repeatedly call aria2.tellActive to get some progress information? But rehashing will block starting download, so it does not contain progress info?\nI don't think aria2.tellActive blocks until all rehashing completed.\n. Can you attach log file here?\nIf too many files are in session file, start up time of aria2 is slowing down and you may get unresponsive RPC call.\nAnother possible blocking behaviour is when file allocation is not used (--file-allocation=none) with old file system like VFAT or FAT32. aria2 usually writes in random part of the file rather than sequentially from the start of the file. If a write is required then, those file system allocates the space up to that point in blocking manner.\n. Why did you open new issue while you closed #296 which is completely the same?\n. Please don't do this. Can you imagine if everyone does this too?\nWe don't change any priority based on the relative ordering of the issue; new or old it does not matter.\n. Do you use relatively slow disk drive and see lots of disk activities?\n. There were not many changes between these versions.\n\nEDIT: It seems that I am experiencing the same issue after downgrading.\n\nSo you experienced this issue even when aria2 is not busy?\n. If aria2 was built with OpenSSL or GNUTLS, SSLv2 is disabled by default, so there is no chance it is selected. If server only supports SSLv2, handshake will fail.\nFrom this issue title \"[SocketCore.cc:897] errorCode=1 SSL I/O error\", I think you use a bit old aria2 version. Which version are you using? If this is on linux, aria2 has 2 SSL/TLS backend: GNUTLS and OpenSSL.  Which one is linked to aria2 object file?\nFor log file upload, if log is relatively small, you can past it on your gist.\nYou can also use Google drive or something similar to share the file.\nIf you want to share it privately, you can send it to my e-mail account.\nEither way, please make sure that confidential information is deleted or obfuscated.\n. In 1.15.2, error comes in SSL/TLS handshake, so something happens in handshake, yes.\n. To build latest aria2, gcc >= 4.8.3 is recommended due to the requirement of C++11 futures.\nI have not seen the error \"libstdc++.so: error adding symbols: File in wrong format\" before.\n. Please reopen this issue if you still experience this issue.\n. BitTorrent uses peer ID instead of user-agent for its primary protocol communication.\nUse  --peer-id-prefix to change default peer ID.\nOr else, are you referring user-agent when accessing BitTorrent tracker?\n. --user-agent option is per download. You can set it to specific value for BitTorrent download.\nDoes it solve the issue?\n. This is by design. The message from aria2 is one way and not request. ID is not useful in this context.\n. > id\n\nAn identifier established by the Client that MUST contain a String, Number, or NULL value if included. If it is not included it is assumed to be a notification. The value SHOULD normally not be Null [1] and Numbers SHOULD NOT contain fractional parts\n\nThe message from aria2 is notification and the above text clearly says that id is not necessary for notification.  It also discourages Null.\n. I am not interested in sftp support right now, but we are open to accept patches.\nlibssh2 looks promising.\n. Because of popular demand, we added basic sftp support.  Check out latest master branch.\nsftp support depends on libssh2.  For debian and ubuntu users, install libssh2-1-dev package via apt-get.\nCurrently, we don't check server's fingerprint for known hosts.\nWe'll add feature to validate it against local file (e.g., $(HOME)/.ssh/known_hosts).\nSince we added sftp, I close this issue.\nPlease submit sftp specific issues in separate thread.  Thank you.\n. aria2 performs checksum checking before actually downloading torrent.\nIf it discovers errors, it continues to download the missing pieces.\nIf torrent is not popular, then it may take long time to download files.\n. It is a good argument at this particular time.\nWe can have general option, say, --enable-tls-proto, and by default enable TLSv1.2, TLSv1.1 and TLSv1.0.  Users can additionally enable SSLv3 with their own risk.\nIs this over-engineering for this type of application?\n. > aria2 already over-engineering, ...\nIt does not justify we happily add new needlessly complicated stuff.\n. @sdysj  Does 62fba76 work for you?\n. Added --min-tls-version option and disable SSLv3 by default.  73d752f\n. Thank you! Merged now.\n. We have no plan to add recursive download feature.\n. See #310 \nI agree that adding SSLv3 warning stuff is useful.\nCould you make a PR for this?\nAlso could you take a look at AppleTLS I modified to implement --min-tls-version?\nI don't have OSX, so I wrote carefully, but I neither have compiled nor run it.\n. Is this PR ready for merge?\n. No objection from me.  Will merge soon.\n. Merged Now. Thank you!\n. This is because compiler is too old to support C++11 features aria2 requires.\nAnd configure check for C++11 feature is a bit weak.\nAt the moment, gcc >= 4.8.3 or clang >= 3.4 compile aria2 fine. gcc 4.6 or 4.7 may also work. But less than that probably fails.\n. It seems to me that compiler is not installed or detected properly.\nDid you re-run ./configure script after upgrading gcc?\n. RedHat guys usually apply their own patches and I don't know what they back ported correctly or fully.\nIt seems back porting is not complete.\nI believe that C++11 support is better for newer version of OS and recommend to use it as much as possible.\nCan we close this issue?\n. Could you git bisect between release-1.16.5 and release-1.17.0 and find the suspicious commit?\n. Thank you.  Are you using TLS connection in downloads, including webui via TLS?\n. Fantastic!\n. One question: which library are you using OpenSSL or GNUTLS?\n. Fix committed via d755df25057e6 based on your patch.\nI only use relevant portion of the diff to fix memory leak.\nFor LibgnutlsTLSSession.cc, the diff causes double-free crash; it looks like gnutls backend is OK.\nPlease confirm that this fix solves the issue.\n. Thank you!\n. There is no versioning in BitTorrent protocol.  It has extensions.  Is IP filtering one of those extensions?\n. They are bit confusing because they share \"crypto\" words.\nAs I understand it, BitTorrent calls Obfuscation handshake as crypto connection, so we named the option --bt-requre-crypto, which only accepts crypto connections. But it does not mean it encrypts data in ARC4, which is in turn controlled by --bt-min-crypto-level option.\nIf you can suggest some texts for clarification, we are happy to accept pull request for this.\n. Thank you for the suggestion.\nI finally read the related code and can give the more details.\nFor outgoing connection, aria2 always try encrypted handshake first.\nIf it fails and --bt-require-crypto is false, aria2 try unencrypted, legacy handshake.\nFor incoming connection, if --bt-require-crypto is false, aria2 accepts both encrypted and unencrypted handshake.  Otherwise, it only accepts encrypted one and reject unencrypted.\n--bt-min-crypto-level is only considered when encrypted handshake is used.\nFor outgoing connection, if --bt-min-crypto-level is plain, aria2 includes both plain and arc4.\nOtherwise only arc4 is included (thus encryption is enforced).\nFor incoming connection, aria2 always choose arc4 if peer offers it regardless of --bt-min-crypto-level option.  aria2 only choose plain If --bt-min-crypto-level is plain and arc4 is not offered by peer.\nSo both options affects both outgoing and incoming connections and they are orthogonal.\nI don't know how other client implements prefer encryption, but the default behavior of aria2 prefers encryption if it is available.\n. The document looks good.\nPlain mains no encryption. arc4 is encryption method used in BitTorrent MSE (message stream encryption, http://en.wikipedia.org/wiki/BitTorrent_protocol_encryption).\n. If you call \"encrypted handshake\"  as just \"encryption\", there is not much difference.\nBut we have message payload encryption separately and it will be negotiated in encrypted handshake and peers agree on whether plain or arc4 is used.\n--bt-min-crypto-level changes behavior of this negotiation.\n1. --bt-require-crypto=false and --bt-min-crypto-level=plain:\n   Both encrypted handshake and legacy handshake are accepted and tried.\n   If encrypted handshake is used, plain method is acceptable.\n2. --bt-require-crypto=false and --bt-min-crypto-level=arc4:\n   Both encrypted handshake and legacy handshake are accepted and tried.\n   If encrypted handshake is used, plain method is not acceptable. arc4  is the only choice.\n3. --bt-require-crypto=true and --bt-min-crypto-level=plain:\n   Only encrypted handshake is accepted and tried.\n   Plain method is acceptable.\n4. --bt-require-crypto=true and --bt-min-crypto-level=arc4:\n   Only encrypted handshake is accepted and tried.\n   Plain method is not acceptable. arc4 is the only choice.\nRephrase my comment:\n--bt-min-crypto-level is only considered when encrypted handshake is used.\nFor outgoing connection, if --bt-min-crypto-level is plain, aria2 includes both plain and arc4.\nOtherwise only arc4 is included (thus encryption is enforced).\nFor incoming connection, aria2 always choose arc4 if peer offers it regardless of --bt-min-crypto-level option. aria2 only choose plain If --bt-min-crypto-level is plain and arc4 is not offered by peer.\n. > So for --bt-require-crypto=false --bt-min-crypto-level=arc4 with an unencrypted handshake, it'll still use an unencrypted payload?\nYes.  Because unencrypted handshake (i.e. legacy handshake) does not have encryption option at all and --bt-min-crypto-level works with encrypted handshake only.\n\nAnd for --bt-require-crypto=true --bt-min-crypto-level=plain it means that handshake is encrypted, but payload may be unencrypted?\n\nYes, only if peer offers only plain method.  If peer offers arc4, aria2 selects it.\n. I'm fine with the first solution.\nWe left these 2 options for backward compatibility and may add deprecated warning.\n. Added --bt-force-encryption option (c653c72), which does the first solution.\n. I'd like to defer deprecation of these options, since they are valid working options, just rather too technical.\n. Good work.  Merged now.  Thank you!\n. Thank you. Looks good to me.\n. Please do squash/rebase/commit\n. Thank you!\n. Thank  you.  Looks like we need to build android binary with android-16.\n. Check latest 1.18.9 released just now.  We built android binary with NDK r10d and Android 16 API.\n. Thank you for testing.  I built another binary with -fPIE and -pie flags set.\nhttps://sourceforge.net/projects/aria2/files/debug/gh-321/\nCould you test it again?\n. Thanks.  I'll upload new binary to proper download section.\n. Finally I upload PIE build to sf.net.\n. --log-level info logs download complete message:\n2015-01-12 14:08:08.719551 [NOTICE] [RequestGroup.cc:1161] Download complete: /foo/bar\n. Forgot to mention that documentation freeze has started at 1/26 after #320 was merged. Sorry for responding late. The release date is 2/1. Next month is 9th anniversary of aria2 project!\n. Thanks.  I'll upload them to sf.net.\n. Done!\n. Thank you!  Merged now.\n. Thank you for quick updates.  Merged now.\n. Thank you for reporting this issue.  I'm now looking into this.\n. Did you specify --metalink-location and/or --metalink-preferred-protocol?\nIf they are given, those resources have precedence over others.\nIn metalink4 specification, 0 is the highest priority and lowest value is 999999.\nIf above options are given, priority of matched resources is subtracted by 999999 so that they have higher priority.\n. Thank you for PR #327,which was merged just now.\n. Thank you.  Merged now.\n. Thanks. Merged and pushed now.\n. HTTP date ending +0000 is rather rare and not preferred according to RFC7231, but anyway fixed in d5d21d2\n. I don't know.  RFC7231 says we expect GMT only.\n. Did you install zlib1g-dev? and configure found it correctly?\n. I compiled aria2 with the same configure options and build was successful.\nDoes Adler32MessageDigestImpl.cc exist under src directory?\n. aria2 shuffles URLs with same priority value in metalink file.  What does your metalink file look like?\n. So you have several base URLs in torrent file, want to shuffle them so that aria2 distributes load among them, right?\n. Fix committed via 4cf0bb742f079dcd75f676391a4e0af1bb176bdd\nCould you test this?\n. Thanks for additional information.\naria2 currently selects URL based on piece in entire torrent (in other words, contiguous space resulted in concatenating all files).\nThe possible enhancement is add new piece selection algorithm available to --stream-piece-selector, say \"random\", to randomize piece selection so that aria2 can pick up associated URL for selected piece.\n. I added --stream-piece-selector=random option in https://github.com/tatsuhiro-t/aria2/tree/random-webseeding\nCould you test it?  Use --stream-piece-selector=random to randomize the file to request.\n. I've merged master into random-webseeding. It was clean merge actually.\n. OK, will do the merge.  We have merge conflict, probably due to clang-format thing, but not much a problem.\n. Merged. 88f20e4\n. Thank you for reporting bug.\n@nmaier any idea about this issue?\n. As a quick workaround, comment out the following 2 lines from config.h after running configure:\n```\ndefine HAVE_GETRANDOM 1\ndefine HAVE_GETRANDOM_INTERFACE 1\n```\n. No objection if it fixes this issue.\n. @Haocen thank you. #823 will fix it.. You can use --save-session option to make aria2 save uncompleted file list in given file.\nThat file can be an input to next aria2 invocation using -i.\n. Agreed.  Maybe split it into half mechanically?\n. I once consider that once.  For example, string_util which only contains string related functions.\nBut if only test is in our concern, then just splitting UtilTest.cc is low risk and quick.\n. OK, just split UtilTest.cc into half mechanically and we are done.  Agreed?\n. Fix committed via 9cbbe9f\n. Duplicate of #336 and already fixed in master branch.\n. I cannot read Russian, so don't know it is displayed correctly or not, but comparing output with web page (http://aria2.sourceforge.net/manual/ru/html/aria2c.html), it looks like displayed correctly:\n```\n$ man -l doc/manual-src/ru/_build/man/aria2c.1\nARIA2C(1)                            aria2                           ARIA2C(1)\nNAME\n       aria2c - \u0441\u0432\u0435\u0440\u0445\u0431\u044b\u0441\u0442\u0440\u0430\u044f \u0443\u0442\u0438\u043b\u0438\u0442\u0430 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438\n\u041e\u0411\u0417\u041e\u0420\n       aria2c     [<\u041f\u0410\u0420\u0410\u041c\u0415\u0422\u0420\u042b>]    [|||] ...\n\u041e\u041f\u0418\u0421\u0410\u041d\u0418\u0415\n       aria2 - \u044d\u0442\u043e \u0443\u0442\u0438\u043b\u0438\u0442\u0430  \u0434\u043b\u044f  \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438  \u0444\u0430\u0439\u043b\u043e\u0432.  \u041f\u043e\u0434\u0434\u0435\u0440\u0436\u0438\u0432\u0430\u0435\u043c\u044b\u0435  \u043f\u0440\u043e\u0442\u043e\u043a\u043e\u043b\u044b:\n       HTTP(S),  FTP,  BitTorrent  \u0438  Metalink.  aria2  \u043c\u043e\u0436\u0435\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\u0438\u0442\u044c \u0444\u0430\u0439\u043b \u0441\n       \u0440\u0430\u0437\u043d\u044b\u0445  \u0438\u0441\u0442\u043e\u0447\u043d\u0438\u043a\u043e\u0432/\u043f\u0440\u043e\u0442\u043e\u043a\u043e\u043b\u043e\u0432  \u0438  \u043f\u044b\u0442\u0430\u0435\u0442\u0441\u044f   \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e   \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\n       \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043d\u0443\u044e   \u0441\u043f\u043e\u0441\u043e\u0431\u043d\u043e\u0441\u0442\u044c  \u043a\u0430\u043d\u0430\u043b\u0430.  \u0415\u0441\u0442\u044c  \u043f\u043e\u0434\u0434\u0435\u0440\u0436\u043a\u0430  \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438  \u0444\u0430\u0439\u043b\u0430  \u043f\u043e\n       \u043f\u0440\u043e\u0442\u043e\u043a\u043e\u043b\u0430\u043c  HTTP(S)/FTP  \u0438   BitTorrent   \u043e\u0434\u043d\u043e\u0432\u0440\u0435\u043c\u0435\u043d\u043d\u043e,   \u043f\u043e\u043a\u0430   \u0434\u0430\u043d\u043d\u044b\u0435\n       \u0437\u0430\u0433\u0440\u0443\u0436\u0430\u044e\u0442\u0441\u044f  \u043f\u043e  HTTP(S)/FTP,  \u043e\u043d\u0438  \u0442\u0443\u0442  \u0436\u0435 \u043c\u043e\u0433\u0443\u0442 \u0432\u044b\u0433\u0440\u0443\u0436\u0430\u0442\u044c\u0441\u044f \u0432 BitTor\u2010\n       rent-\u0440\u043e\u0439. \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044f \u043a\u043e\u043d\u0442\u0440\u043e\u043b\u044c\u043d\u044b\u0435 \u0441\u0443\u043c\u043c\u044b \u0431\u043b\u043e\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043b\u044f Metalink,  aria2\n       \u0430\u0432\u0442\u043e\u043c\u0430\u0442\u0438\u0447\u0435\u0441\u043a\u0438 \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u0435\u0442 \u0447\u0430\u0441\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0432\u043e \u0432\u0440\u0435\u043c\u044f \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0444\u0430\u0439\u043b\u0430.\n\u041f\u0410\u0420\u0410\u041c\u0415\u0422\u0420\u042b\n   \u041e\u0441\u043d\u043e\u0432\u043d\u044b\u0435 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b\n       -d, --dir=\n              \u041a\u0430\u0442\u0430\u043b\u043e\u0433 \u0434\u043b\u044f \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u044f \u0437\u0430\u0433\u0440\u0443\u0436\u0435\u043d\u043d\u044b\u0445 \u0444\u0430\u0439\u043b\u043e\u0432.\n```\n. So in my environment, Russian man pages are displayed correctly but in your environment, it is not displayed correctly because your tool does not detect UTF-8 correctly, possibly old man page program?\n. Right, it seems it does not harm the output, so I added following one liner to add encoding specifier (see above commit).\n. I have fixed UDP tracker bug, which prevents aria2 from getting peers from UDP tracker.  Try master branch, or wait for the next release.\n. Done\n. Thank you!  Uploaded to sf.net just now.\n. As I recall, we do not rate limit RPC response.  I'll look into this issue.\n. Yes, there is no throttling.\nIf the size of RPC response is a problem and your issue may be solved or eased by decreasing it, then consider to use key parameter of RPC request: http://aria2.sourceforge.net/manual/en/html/aria2c.html#aria2.tellActive\nand only request the data you need.\n. I reproduced this issue with two machines in same LAN. I created 5000 download entries which are all paused and when I query aria2.tellWaiting(1,5000), aria2 sends some chunk of data once per second.\nI identified the offending code and fixed in cb5ccf6.  @i336 , could you test it?\n. Aria2 is single threaded application and event based, it polls socket\nread/write readiness all the time.  RPC process takes time, other download\nitems are affected, but usually download is not so fast that it is not much\nslowed down.\n2015/03/17 15:59 \"i336\" notifications@github.com:\n\nI figured I wouldn't be waiting too long to test aria2c under the exact\nsame conditions of my original issue - downloading slowly from a remote\nmachine over shaped internet - so I thought I'd hold for a couple extra\ndays before I replied. (I'm switching ISPs soon. =P lol)\nI just fired aria2c back up after verifying I had the latest checkout\nthen rebuilding, and I now receive 1MB-4MB RPC responses over the LAN\nwithin 700ms-1 second, and over lo with equivalent speed as well. I'm\nguessing the remaining delay is caused by aria2c collecting the requisite\ndata and compiling the JSON/XML response on the slow CPU in question - the\noutput itself is delayless now, regardless of whether I query\naria2.tellWaiting(1,3000) or aria2.tellActive().\nI consider this now fixed, and I've taken the liberty of closing it.\nThanks very much! :)\n(Also, I'm curious - I took a look at the committed code fragment... and\nif I understand it correctly, was the code responsible for sending RPC\nresponses doing so with noticeable delays because the same process space\nwas servicing all of the actual download requests in question, but without\nchecking whether RPC response data was queued...?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/345#issuecomment-82615984.\n. Thank you!\n. Did you change --bt-max-open-files option  dynamically via RPC method?\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--bt-max-open-files\n. Thanks.  Do you often experience this issue?  What's the situation like when you experienced this issue? (how many downloads, number of files in torrents, etc)\n. Apparently, I have no idea why assertion was failed.\n. Thanks.  It is strange that the assert line is executed even though total number of files (150) is less than the limit (200).  There must be something messed up.\n. Do you have  working version of aria2?\nCould you do git bisect to find the commit which introduced thid bug?\n. Recent commits may fix this issue.  Could you try the latest master branch?\n. @Denisov39 We'd like to hear the result of the test.  Are you still experiencing the crash?\n. Thank you for confirmation!  Closing\n. I support @nmaier 's decision.\n. Thank you!  Merged now.\n. Thank you for noticing this.  Documentation was updated to incorporate that.\n. Option values are all strings.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#id3\n\nWe'll look into the remaining issues.\n. As for numSeeders, it is the number of connected peers which are seeding torrent, excluding the local client itself.  I think the current display is correct.  First case, there is still 1 seed peer, so numSeeders=1 is corrent. Second case, since the number of connections is 0, numSeeders should be 0.\n. In this case, no, since number of connection is 0:\n\"connections\":\"0\",\nWe count number of seeders in connected peers, with no other knowledge involved.\n. That depends on the situation and implementation of torrent client.  Some client may drop connection if peer gets seeder, some might not.\n. OK, aria2 drops connection if both local client and peer are seeder.\nThere are some delays this disconnection occurs (probably 1 second).\nI tried some experiments, after download completion, with 1 second, numSeeders gets 0.\nI now fully understand why you wrote https://github.com/tatsuhiro-t/aria2/issues/355#issuecomment-84325850, this thread is a bit convoluted.\n. And.. the delay is not always 1 second.  In other words, it is less than about 1 second.\nI think the remaining issue is aria2 does not call the command specified in on-bt-download-complete, right?  I confirmed this behaviour. Since on-download-complete hook is invoked with -V option, I think on-bt-download-complete should be invoked too.\n. Fixed on-bt-download-complete issue.\nDoes my explanation of numSeeders make sense?  Then I think we can close this issue.\n. Thank you for letting us know.  The source code was fixed just now.\n. Sorry for late response.  I just merged this PR.  Thank you!\nI did build tests for both x86 and x64_86 with debian mingw-w64, and both went fine.  Did not encountered conflicting declaration error.\n. There are some issues regarding windows specific types (specifically socket).\nCould be resolved using static_cast<int>(...).\n. It is acceptable.\nBut we'd like to avoid using it inside translation text (encoded with _(..)) since that would break translation if it ever happened, although it seems mostly we don't output socket file descriptor in translated text.\n. It looks like gnutls.pc provides invalid LDFLAGS.  I saw following error in config.log:\nconfigure:19267: checking for gnutls_certificate_set_x509_system_trust\nconfigure:19267: g++ -o conftest -g -O2 -pipe -std=c++11  -I/usr/include/p11-kit-1   -I/usr/include/libxml2    conftest.cpp -L/usr/lib/x86_64-linux-gnu -lgnutls -lz -R/usr/lib/x86_64-linux-gnu -lp11-kit -lgmp -lhogweed -lgmp -lnettle -ltasn1 -lp11-kit -lz  -lsqlite3 -ldl -lpthread  -lxml2 -L/usr/lib/x86_64-linux-gnu -lz   >&5\ng++: error: unrecognized command line option '-R'\nThat could be gnutls bug.  The workaround is build with OpenSSL.\n. Looks like we use !SocketRecvBuffer::bufferEmpty() to force read from the buffer.\nWe can probably add code along side it to check that TLS record data is buffered in SSL object.\n. It looks like aria2 is not suffered from this.\nSocketRecvBuffer has 16KiB buffer, which is the same size of maximum TLS record.\nWe only read data from TLS stack if buffer is empty, so never left pending data in TLS object.\nI close this issue without further action.\n. ... and also make sure that aria2 was built with HTTPS support.\nRun aria2c -v and check Libraries:.  If you don't see \"GnuTLS\" or \"OpenSSL\", then aria2 was not built with HTTPS.\n. Tracker URI could be https.  Can you check that torrent file was downloaded correctly?\n. > PS Those torrents was from some private trackers, so DHT was disabled in them and they were described by files, not magnet links.\nWhat kind of data is described in .torrent file?\n. I asked because you wrote \"DHT was disabled in them and they were described by files.\"\nI guess that utorrent uses the some kind of data \"described by files\" to connect to them and start downloads.  .torrent file is encoded JSON-like encoding called bencoding.  Probably a key described to bootstrap download is contained there.\n. I'd like to see the content of .torrent file.  Could you upload it to somewhere I can download from?\n. Thanks.  That would probably be the case of this issue.\nWe should enable UDP part of the subsystem to use UDP tracker even if DHT is disabled.\n. I checked the code, and found that DHT is always up by default (unless user disables it) but private torrent download does not use it.  So UDP tracker should work regardless of private torrent or not.\n. Ah, I missed that use case; user disables DHT explicitly.  Then udp tracker support does not work.\n. Please give us the torrent file or its URI or magnet link.\nPlease note that we only investigate about legal torrent, just in case.\n. Thanks.  I'll look into it.\n. Confirmed aria2 does not work in this torrent.\nI first thought that this swarm is uTP only, so I tried with transmission.  Interestingly it also didn't work either.\naria2 error log only shows peer does not send anything, and after few seconds, it just dropped connection.\n. Similar issue #343\n. It works for me.  Make sure that DHT is working.  Perhaps, you need to open DHT/BitTorrent port on router since aria2 does not do it automatically.\n. The above torrent configures udp tracker.  If it is not working, aria2 uses DHT to get peers.\nBut aria2 initially does not know any DHT peers.  In this case, DHT does not work.\naria2 can learn peers while downloading another torrents without DHT using working HTTP/udp trackers.\nOr you can use well-known dht endpoint to bootstrap DHT. https://trac.transmissionbt.com/ticket/2280#comment:10\n. I could not reproduce this on my Debian box.\nDo you see anything suspicious in log message?\naria2 shows error when it failed to save files.\n. You can use -l option to specify log file name.\n. OK.\n. Thank you for PR.  This looks very interesting.  At a glance, it chooses interface in round robin manner, right?  I'll review this and comment if any.\n. OK, no problem.  PR looks good.  Could you squash commits into one?  Then I'll merge this PR.  Thank you.\n. Thank you very much.  Merged now.\n. Thank you! Merged now.\n. Please don't mind about travis error; I tested travis but forgot to disable it.\nSince we are a bit picky about netrc file permission, it would be better to limit it to command-line option only (op->setInitialOption(true);).\nAlso we have to define TEXT_NETRC_PATH in usage_text.h and describe its usage.\n. If all options available in command-line except for --conf option is also available in config file for free.\n. Please remove 2 lines below:\n+    op->setChangeGlobalOption(true);\n+    op->setChangeOptionForReserved(true);\n. Sorry, op->setInitialOption(true); should be also removed, since --netrc is global option and parsed from command-line and configuration file only.\n. After everything, please squash commits into one, then I'll do merge. Thank you.\n. I squashed and editted a bit (removing the suggested line above), and merged this PR via ceee04cfe8b870021a7964acb68bce00d74490db.\nThank you.\n. I think we can use SocketCore::bind(const struct sockaddr* addr, socklen_t addrlen) to bind socket to the interface we like, regardless of --interface (or recently added --multiple-interface) option.\nThe RPC server socket is created and bounded in https://github.com/tatsuhiro-t/aria2/blob/1f3667a1ee168d50d978f0aad2c56e1313fb67a6/src/HttpListenCommand.cc#L106\nSo probably you can create new option that only affects RPC listener socket, and pass that sockaddr structs and its real length to SocketCore::bind(const struct sockaddr* addr, socklen_t addrlen).\nTo get sockaddr struct from given interface, you can use getInterfaceAddress() defined in SocketCore.h.\n. Use http://aria2.sourceforge.net/manual/en/html/aria2c.html?highlight=http-proxy#cmdoption--http-proxy\nOr environment variables: http://aria2.sourceforge.net/manual/en/html/aria2c.html?highlight=http-proxy#environment\nPlease read manual about proxy\n. I've never used uTorrent so don't know how its agent works.\nYou asked us how to use http proxy to connect BitTorrent tracker, and I showed you how to.\nIt seems it works from your saying \"BT only use a proxy\".\nSo I think this issue can be closed.  Does it work for you?\n. Closed since we have option to specify HTTP proxy.\n. --realtime-chunk-checksum works with chunk checksum, which are available via .torrent file or .metalink file.  The checksum specified by --checksum is not \"chunk checksum\", so --realtime-chunk-checksum is irrelevant.\nUsually, --checksum is checked after transfer completed.\nWith -V option, validation will run, before the transfer, against the existing file, so that  if validation fails, aria2 will download the file again.\nWithout -V option, by default, if control file (*.aria2) does not exist, aria2 automatically rename the file appending \".\" + numeric value, and download the file and verify its integrity.  If control file exists, aria2 resumes download, and after completion, validate the checksum.\n. Usually, piece and chunk have the same meaning.  Originally, \"piece\" came from BitTorrent terminology, and it only used for BitTorrent download.  In early days, they may have different meanings, but aria2 unified BitTorrent and HTTP/FTP downloads later on, so mostly they are identical.\n. --min-split-size exists to prevent HTTP range request from being too small.\n--min-split-size and --piece-length can be set independently.\nThe smallest HTTP range request becomes max(min-split-size, piece-length).\nIf piece-length < min-split-size, split still occurs in piece-length boundary, but aria2 does not make split smaller than min-split-size.\n. Yes, you can set arbitrary size for these options.  I think default value is good enough for most cases.\n. Of course, you can do in the range you are allowed.\nThe reason why we put the this limitation is avoid misuse, e.g., too small segment to request web server, which degrades performance.\n. May be or may be not.\n1M is small enough these days, and splitting into smaller pieces is not necessarily faster; it is even slower due to several reasons, e.g., connection setup cost, and tcp slow start, etc.\n. Currently, no plan to add rsync to aria2.\n. That's because file path can be specified there and it can contain spaces.  OTOH, tab is most likely not included there. \n. There is no way to control concurrent connections between multiple instance of aria2c.\nOne instance of aria2 can handle multiple downloads.  So if you want to control concurrency limit, you need to push all downloads into 1 aria2 instance.\n. Basically, adaptive select fastest one first, just like feedback, but to discover better server from unused servers, it speculatively selects unused one as secondary URI.\n. Some servers suddenly choke the transfer speed drastically, especially if several connections are made.\nCould you give me URLs included in  aria2-dmirror.sh?\n. Thank you for the info.\nIt is difficult to deal with this kind of problem.  Given the diversity of the server domain, it is sometime faster and sometimes slower.\naria2 just checks socket is readable, and if it is, aria2 reads it.\n. Thank you! Merged and pushed now.\n. Probably you should use -d option instead of -o in this case.\n. Try with aria2c in command-line, and see what error it says.\nProbably, the format is not right, or given message digest type is not supported.\nCould you tell us how you set that option in RPC method?\n. OK, so you are talking about exit status.  I misunderstood that RPC method returns error code when you specified checksum option.\nI agree that specific error code for checksum validation failure is useful.\nCurrently, we don't have such category in error code, so we just return unknown error.\n. Technically not so difficult.  We first add error code to error_code.h, then RequestGroup::setLastErrorCode(code) to set error code.  Calling place probably is in CheckIntegrityCommand.cc when checksum validation failed.\nAnd write the document.\n. Fixed committed via 3855205.\nPlease test latest master.\n. This is duplicate of #284 \nI have no objection to add this feature, but we have no plan to add this at the moment.\n. Closing since this is duplicate\n. Thank you for reporting this issue.\nThis sounds like gmp issue.\nAs for autoreconf -i, you need autopoint installed on your system.\n. Probably, we can do the same thing as we did in SessionSerializer, hopefully, reusing some part of code from it.\n. The above commit implements this requested feature.\n. @tommyziegler run autoreconf -i to generate configure script first.\ntravis integration is tracked at #232.\n. #367 was merged, and --ssh-host-key-md option is added to set expected SSH host public key fingerprint.  Now we can enter documentation freeze, and expected release date is May 24.\n. 1.19.0 is now out.\n. Thank you!  Merged now.\n. We have no plan to add c# wrapper.\n. Tracker URI is stored in AnnounceTier class in just string, so first probably we have to create new class or struct to hold this URI and other metadata (seeders, leechers, etc).\nProcessing tracker response is done in two places:\nFor traditional HTTP tracker: https://github.com/tatsuhiro-t/aria2/blob/c1417f08ceb48ba374e74f48957488add81e3611/src/DefaultBtAnnounce.cc#L283\nFor UDP tracker: https://github.com/tatsuhiro-t/aria2/blob/c1417f08ceb48ba374e74f48957488add81e3611/src/DefaultBtAnnounce.cc#L352\nThen, you can get metadata from there, and store it in correct place in AnnouncetTier.\nTo return these information in PRC method, we have to add new key for this, since we don't want to break compatibility.\n. @ivan98 There is no such method ATM.  Currently you need to first pause or stop download, and use --bt-tracker and/or --bt-exclude-tracker options.\n. Thank you!  Merged and pushed now.\n. config.downloadEventCallback is pure C function pointer.  If we capture anything in C++ lambda, they cannot be used as function pointer anymore.  Ideally, we should provide callback using std::function<> so that these lambda works.  But currently, it isn't.  Usually, we assign pointer to some user defined struct or class to SessionConfig.userData, and it is then passed in callback as userData parameter.\nWe can add new download in the callback.  So if it is feasible, you can parse downloaded HTML in callback, and then use aria2::addUri to add extracted links to aria2 session.  Then aria2 continues to download these things, and once they are all downloaded, it will stop.\n. Could you tell us the request header aria2 issues when this error happens?  Also content-length of downloading file also helps.\nProbably, aria2 sets request range one past beyond the file size, or server may understand the request badly.\n. Thank you. It would be best to re-produce on the local environment, but sometimes that is very difficult if it depends on the remote server.\n. If I understand correctly, trailing \";\" is illegal.  The following content-disposition header should be ignored:\nContent-Disposition: attachment; filename=foo.html ;\nSee http://greenbytes.de/tech/tc2231/#attwithasciifilenamenqs for the reasoning behind this.\n. Unfortunately, yes.\nIn my opinion, parsing header field should be strict rather than permissive these days, to prevent possible security bug.\n. We use SECURE128 priority settings for gnutls, and it seems that it disables RSA-SHA1 signature algorithm support.  I think you can reproduce this with gnutls-cli with --priority SECURE128 parameter.\nThe following patch would fix this:\ndiff\ndiff --git a/src/LibgnutlsTLSSession.cc b/src/LibgnutlsTLSSession.cc\nindex ab3daf2..81f3720 100644\n--- a/src/LibgnutlsTLSSession.cc\n+++ b/src/LibgnutlsTLSSession.cc\n@@ -127,7 +127,7 @@ int GnuTLSSession::init(sock_t sockfd)\n   // It seems err is not error message, but the argument string\n   // which causes syntax error.\n   const char* err;\n-  std::string pri = \"SECURE128\";\n+  std::string pri = \"SECURE128:+SIGN-RSA-SHA1\";\n   switch(tlsContext_->getMinTLSVersion()) {\n   case TLS_PROTO_TLS12:\n     pri += \":-VERS-TLS1.1\";\n. Thank you.  From my attempt to connect to that site, I see signature algorithm RSA-SHA1.  Even your first post prove it:\n- Server Signature: RSA-SHA1\nAnyway, latest gnutls includes SIGN-RSA-SHA512 support, so it might help here.\n. We fixed this in master branch.  Next release will have this fix.\n. Thanks.  Could you tell us which software needs to be re-installed to make bcrypt.dll available?  Can we  download that software from Microsoft web site?\n. Thanks.  Probably we deprecate XP support for now, since it is too old and insecure.\n. OK, then we just agreed that aria2 support on XP platform is over.  Closing the issue.\n. One reason is we don't have a machine XP installed.  We cannot do any debugging on it.\nI think this issue is only raised if aria2 is built with Windows native TLS library (schannel).\nIf aria2 is built with openssl, then probably it works without offending dll.  But you have to manage CA certificates.\nI have to say this is opensource project, and we do this in completely voluntary basis.\nIf you want Windows native TLS support for XP, write a patch and send us PR, or find someone to do that.\n. We choose Win TLS because CA is managed by OS.\nIf you don't like that, you can build windows build with openssl.\nFor Linux, it depends on the distribution.  In Debian/Ubuntu, aria2 package is built with GNUTLS, and it looks up /etc/ssl/certs/ca-certificates.crt.\n. We only build Win TLS version only.  That's too much work for us to build many configurations and testing them.\n. Well, then I don't want to waste my precious time with the person who calls us \"retarded\". I'm done with this.\n. We only build one configuration of windows build.\nSo if you all don't want sftp, then we kill it in windows build, and not distribute sftp enabled version of windows binary.\nBut then sftp user on windows may complain about lack of it.  So it would be better to let someone build custom binary and distribute it on their own.\n. Thank you.  From you description, it looks like memory leak bug.  We have to first reproduce it in our development environment.\nI think you are using latest version of aria2 (1.19.0), is that correct?  Also ftp is plain ftp, not sftp, is that correct?\nCould you tell us the command-line parameter for aria2c, and options values for aria2.addUri() ?\n. I observed that if there was an error while downloading file, the memory usage was increasing.\nThis behaiour is only seen for FTP download, not for HTTP.\n. Thanks.  After further investigation, the huge memory usage is caused by the 3M downloads registered into aria2c.  The each download object is rather large in aria2, and when RPC is used, all queued downloads are kept in memory.  It quickly fills up memory if you requests 3M downloads.\nYou mentioned that clearing download results does not decrease memory.  This is the expected behaviour of the standard memory allocator for libc.  There seems to be complicated story behind that, but it seems that aria2's memory allocation pattern is not suitable for this allocator.  aria2 supports alternative allocator, jemalloc, using --with-jemalloc, which can be more responsive for freeing memory.\nSo adding 3M downloads at once to aria2c via RPC is not feasible at the moment.  If RPC is a must, we have to split them into groups, say, each 10000 downloads.\nIf RPC is not must, and you can run aria2 in command-line directly, --input and --deferred-input options would work.\n. Yes.  I forgot to proper name for the option I added several years ago ;)\n. Thank you!\nThe translated documents (under doc/manual-src/{ru,pt}) are maintained by translators based on English document, so please leave it unchanged.\n. I'm reviewing now.  Probably, will leave some comments.\n. Documentation only refers to XDG directory.  But actually we first check traditional $(HOME)/.aria2/ first, which is good and necessary for backward compatibility reason.  I think this behaviour should be documented at least in aria2.conf and dht.dat subsection in aria2c.rst.  We can guide new user to XDG directory, but we'd like to also notify the underlying changes to existing users.\n. According to http://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html, it lists $XDG_CACHE_HOME, but we use $XDG_CACHE_DIR.  Which is correct?\n. Thanks.  The updated document is a bit different to what actually implemented.  The current implementation first check ~/.aria2/, and if it is not present, then check ~/.config/aria2/.\nSo it is not fallback.\nIn other words, if we have both files, then we use file under ~/.aria2/, which contradicts to the documentation.\n. Perfect!\n. Could you squash commits into one?  Then I'll merge this PR as soon as possible.\n. Thank you!  Merged now.\n. Closed now.\n. Usually @nmaier kindly offered us Mac OS X packages, and is probably busy now.  I don't have Mac, so I cannot help you here.  You may find aria2 in homebrew or other prepackaged registry.\n. Thank you, and welcome back @nmaier.  I just uploaded 2 files to sf.net.\n. Basically, yes.  Some download type may contain several files to download (e.g., multi-file torrent).\n. In that particular case, yes.\n. I prefer future import print to just sticking to python2.\nCould you send us PR for this?\n. > 1. When the control file (*.aria2) exists, the ``--continue=true'' option will be disabled automatically even I have used it in the aria2c commandline?\nYes\n\n\nIf I've somefiles to be resumed -- some of them have the control file (*.aria2) and some of them are obtianed by a browser or other sequential download manager -- in this case, must I use the ``--continue=true'' option?\n\n\nThe decision to use *.aria2 control file is done per download item.  Usually, each file is checked for its own control file.\n. Yes.\n. aria2 does not support IDN yet, and we have no immediate action plan to support it.  But we have no objection to add it.\n. We accept both lower and upper M and K for convenience.  The official one is upper case ones here, so stick to them.\n. We have different calculations when calculating mc_avg_speed from dl_speed.  It is a bit complex, this is due to the fact that it originates a well-known Linux distro's package manager integration code.  In short, mc_avg_speed is conservative to the new speed updates.\n. Thank you!  Merged now.\n. Thank you!\nI got error after applying this patch.  If I replace \"print\" with \"print_function\" it works.\n``` diff\ndiff --git a/doc/manual-src/en/mkapiref.py b/doc/manual-src/en/mkapiref.py\nindex fdf2a65..0354594 100755\n--- a/doc/manual-src/en/mkapiref.py\n+++ b/doc/manual-src/en/mkapiref.py\n@@ -33,7 +33,7 @@\n #\n # Generates API reference from C++ source code.\n import re, sys, argparse\n-from future import print\n+from future import print_function\nclass FunctionDoc:\n     def init(self, name, content, domain):\n``\n. Thanks.  I forgot to mention that we have to putfrom _future__ imports` before any imports.\n. LGTM.  Merged now. Thank you!\n. Using --file-allocation=trunc can set file length, but actually not consuming disk space.  Both require file system which supports sparse files.\n. > [1] Considering that the file length is determined by the contents of a file and is a attribute of file itself, so what's the purpose of setting file length?\nfile length is determined by the content-length or meta-data from remote server or something.  If you want this length is applied to local file, then use trunc, otherwise use something else.\n\n[2] If you setting the file length, the length must be given as a digital string as the argument, anyway, --file-allocation=trunc doesn't accept the argument of the file's length string.\n\nfile length is determined by the content-length or meta-data from remote server, and user cannot set it by hand.\nIf you are using, linux and recent file system (like ext4), just use \"falloc\", which is default.\nFor WIndows users and NTFS fs, \"falloc\" works fine too.\nFor VFAT users, they must use prealloc, since it lacks sparse file support.\nIf you don't want to allocate fully disk space, use none or trunc.  If you don't care the provisional length of a file, use none, otherwise use trunc.\n. Use RPC interface.  http://aria2.sourceforge.net/manual/en/html/aria2c.html#rpc-interface\n. Thank you.  The download volume is not a lot nowadays, just less than 2,000 per week, which I think can be handled quite well in github release page.\n. The one publicly visible change is web site URL.  For years, we use aria2.sourceforge.net, we can redirect to our new home.  Using github pages could be handy.  Perhaps, we move aria2 repo to aria2 organization, and get aria2.github.io, which is nicer than put them under my account.\n. Thank you all for comments.  No one want to stay with sf.net, so let's move to github.\nFrom sf.net stats, we have 1000+ download/week, and it is not that big.  I think we can host files on github.  If we have any problem, then consider another, such as bintray.\nWe have used aria2.sourceforge.net as project web site, which is offline now due to sf.net maintenance.\nOn github, it will become https://tatsuhiro-t.github.io/aria2, or https://aria2.github.io/aria2 after creating aria2 organization.  Alternatively, we can move to under metalinker-dev org, and gets the address https://metalinker-dev.github.io/aria2.   Either is fine for me.\nWe don't migrate issues from sf.net to here, because it is too much manual labor.\nWe also don't migrate past downloads.  Perhaps, we can just add latest release here.\n. @sonnyp Thank you!\nWe'd like to limit the member of aria2 org for core developers only, so we are going to remove you.  Sorry about that.\n. Things are going a bit slow about this issue.\nBut recent downloads are already hosted in github.\nI will do migration to aria2 org when I have time.\nWe also need the associated documentation updates.\n. I manged to move aria2 website to https://aria2.github.io/.\nAll useful contents are redirected to the corresponding new pages.\n. Now that we have moved all contents from sourceforge to github, let's close this issue.\nMoving this repository to aria2 org is an another issue.\n. When it is accessed, client is redirected to new page.  We will add some notice in the next release.  Do you think it is not enough?\n. Done!\n. We have no guarantee about correctness nor accuracy.  We record the value we just measured.\n. Use -d /dev -o null  for HTTP/FTP downloads.  You cannot achieve this in BitTorrent download.\nAlso you cannot disable control file creation in aria2.\nYou created lots of issues these days (which itself is valid and good), and if you satisfied with the answer, please close the issues.\n. http://aria2.sourceforge.net/manual/en/html/technical-notes.html#control-file-aria2-format\n. Using RPC method is a way to go.  It is XML or JSON based RPC, we just use Python language as an example.  Please read manual carefully.  I think we don't use advanced aspect of Python.\n. Documentation could be improved in this area.\nIf you keep your lowest-speed-limit in tact, please don't use adaptive.\n. > [1]\nActually, the code to save/load .aria2 file is https://github.com/tatsuhiro-t/aria2/blob/master/src/DefaultBtProgressInfoFile.cc\nYou can read .aria2 file by mostly any modern programming language.  I don't know fortran.\n\n[2]\n\nlibaria2 API is described in http://aria2.sourceforge.net/manual/en/html/libaria2.html\nAs far as I know, there is no dedicated API function to read/write *.aria2 file.\n. For resume, the completedLength reported by aria2.tellStatus() is used.  We use 16 KiB block as  the smallest unit to keep track of downloaded data, so that is used for resuming.  Normally, you don't need to care about this.\n. Yes, if I understand correctly.  But don't rely on this, because this is aria2 internal mechanism, and subject to change without notice.  Again, you don't need to care about this.\n. As clearly described in manual http://aria2.sourceforge.net/manual/en/html/aria2c.html#json-rpc-over-websocket, aria2.onDownloadComplete is notification, only available in JSON-RPC over WebSocket.\n. Your example is JSON-RPC over HTTP, not WebSocket.\nAnd notification is just pushed from aria2 server, and you cannot request it like that.\nTo see how WebSocket RPC work, run aria2c with --enable-rpc, and open browser (e.g., chrome).\nThen open page http://localhost:6800/, which only shows blank page, which is fine.\nThen open developer console, and type the following to create WebSocket object:\njs\nws = new WebSocket('ws://localhost:6800/jsonrpc')\nws.onmessage = function(msg) { console.log(msg); }\nThen from terminal, add some downloads, say, using aria2rpc under doc/xmlrpc.\nThen you will see the incoming message in developer console like this:\nMessageEvent {data: \"{\"jsonrpc\":\"2.0\",\"method\":\"aria2.onDownloadStart\",\"params\":[{\"gid\":\"1788293a61b65168\"}]}\"}\nMessageEvent {data: \"{\"jsonrpc\":\"2.0\",\"method\":\"aria2.onDownloadComplete\",\"params\":[{\"gid\":\"1788293a61b65168\"}]}\"}\n. I could not reproduce it.  Did you use --force-save option?\n. It is per connection, so we could have several statistics for the same hosts.  In that case, we use fastest one.\n. You can create download with 1 URI, and then it failed, issue new download item with another URI, and so on.  We don't have no facility to automate this.  Probably, you can hack around URISelector, but you have to track which URI is failed or not, so it could be complex.\n. Why did you change title to just \".\" ?  That is unclear and not readable.  Can we close this issue?\n. Platform?  Linux, Windows, or something else?\nIf you are using Windows version and your file system is legacy VFAT, and you don't use --file-allocation=prealloc, then aria2 may pause because it will write at the random location of file, and VFAT requires all bytes from beginning of the file to the writing position is zero filled, which could take a time.\n. Thanks.  Are you using --file-allocation=prealloc?\nReading file from remote file system could be slow, due to network delay or overhead etc.\naria2 always performs disk I/O in synchronous manner, and it may not work well with slow disk drive.\n. Thanks for detailed information.  We have never had an issue in checking piece hash, so probably it is because of the interaction between aria2 and remote file system.  Currently, I have no idea about this.  But I'm curious what's happening while aria2 is freezing.  Did it consuming lots of CPU?  Or just waiting for something, say, network I/O?\n. web-ui periodically queries aria2 to get statistics including download speed.  If aria2 was completely frozen, web-ui could not access to aria2.  I'm not sure how web-ui behaves in that case, possibly it could show the old data.  That explains the flat graph.  All aria2 does when calculating hash is reading data from file in random access mode.  If aria2 program execution really stopped, I think it may be beyond the problem of aria2 itself, but I'm not sure at this moment.\n. No.\n. > [1] Are these two options effective all of the HTTP(S)/FTP /SFTP and BitTorrent downloadings?\nYes\n\n[2] Are these two options based on the per each download and all of the downloading items instead of per each connction to do the speed conrolling?\n\n--max-overall-download-limit is per aria2 instance.\n--max-download-limit is per download item.\n\n[3] Why not also give the following two options:\n\n--min-overall-download-limit does not make sense, since each download is separate entity.\n--lowest-speed-limit may be the alternative for --min-download-limit.\n. Thanks. I understood your issue, and it is a feature request.\nI cannot promise this feature will be implemented, but it is better to open new issue for this specific feature request, and close this thread.\n. > Another issue: why not also give the saveServerStat mthod via the rpc method, as you have give the saveSession method for the rpc mode.\nProbably, because no one cared it.\n\nI've tried some more, it seems that in the daemon mode, all of the files must be use the absolute path, otherwise they may not be gererated.\n\nGenerally, yes.  When aria2 entered daemon mode, pwd is set to /, in order to not hold current directly.\nYou have to use absolute path for everything in daemon mode.\n. In general, input-file, command-line, aria2.conf, in the order of precedence.\n. In general, last one overwrites previous one, in the same way curl does.\nSeveral options are treated differently, and it gathers all given parameters and treats them as list (e.g., --header)\n. ... or \"concatenated\" in the option specific way.\n. Then probably, I misunderstand the curl way.  I don't see any problem in the current behaviour of aria2.\n. There are 2 variations for Content-Disposition header field.\n- 1. Content-Disposition: Attachment; filename=example.html\nIn this case, filename parameter can carry iso8859-1 characters only.  No multi byte characters are allowed.\n- 2. Content-Disposition: attachment; filename*= UTF-8''%e2%82%ac%20rates\nThis uses RFC 5987, can specify encodings.  In the above example, UTF-8 is used.\naria2 supports UTF-8 and iso8859-1 just described in RFC 6266.\n. I'm not sure whether it is common or not.  We have implemented several features which violates RFC in order to support \"real\" web.  So this could be one of those things.\nBut I'd like to get away from encoding issue as long as I can, because it is nasty thing and it is hard to get it right.\nI myself have no plan to add this feature, but we are ready to accept a patch if someone is really interested in this.\n. Is MUSL some kind of libc replacement?  Are there cross compiler toolchain available for Linux?\n. I assume MUSL is located at http://www.musl-libc.org/.  Is that correct?\n. Thanks.  I need C++ compiler, and I found one.  Will try that.\n. Could you tell us the error message you got while compiling with musl?\n. And architecture.  Is it arm, mipsel or x86?\n. If compiles fine, then it may not be an issue of aria2.  Could you ask openwrt or musl community for help?\n. If falloc is used with --file-allocation, and got this error,then file system does not support fallocate.\nIn Linux, --file-allocation=prealloc is recommended, since it automatically detects that fallocate can be used for the target file system, and if not, fallback to zero fill method.\n. This seems that cookie file was not passed to aria2c properly using --load-cookies option.\nHow did you specify this file, in command-line or .aria2 configuration file?  How they look like?\n. You also need to specify request URI.  Does this work?\n. Sorry, so this works for you?  Or you still have the problem?\n. ```\n    aria2c_cookie_arg=\"--load-cookies \\\"$cookieFile\\\"\"\n...\naria2c $aria2c_cookie_arg \"$resourcesPage\"  --dir \"$(dirname \"$tempFile\")\" -o \"$(basename \"$tempFile\")\"\n\n```\nI think the above lines does not work.  The double quote surrounding cookie filename is also passed to aria2c as a part of filename, which means it cannot read the file.\n. It works for me, so chrome's cookie file can be read by aria2.\n. Just I have to mention this, chrome now encrypts cookie in its sqlite db file, and aria2 does not support it.\n. Thank you for reporting this issue.  Fix committed via 7e3d82c\n. Have you tried --save-session option?  aria2 saves unfinished download items in the file specified with --save-session in the format --input-file option can accept.  So next time, you can supply the new file to aria2 with --input-file option to resume unfinished ones.\n. Yes\n. c3b89d37e12ee69cd7968c048ffc30fafbf46049 increased the upper limit to ~1,000,000\n. I'm not sure I understand the issue correctly, probably, --bt-external-ip is what you are looking for.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--bt-external-ip\n. aria2 does not support upnp.  I'm not sure specific router settings, but in seeding, aria2 can actively connect to the peer, so it can work.\n. Thank you.  Your patch was merged in master via 4b924702bc740c3cd8f64caa48ff815ebb0a8924 \n. I think this is probably due to older compilers. Could you try gcc >= 4.8.3 or clang-3.4?\n. We check C++11 availability using -std=c++11 or -std=c++0x, but compiler that passes that check still lack nullptr.  We have to add this test.  Thank you.\n. Done 008aba6\n. d0ccb39 adds system.listMethods which just returns the available RPC method names.\nThis is an existing extension for XML-RPC which is supported by many RPC server implementations.\n. We'll do the next release in the next month.\n. Thank you for reporting this issue.  I fixed this issue by the commit 52c68c43\n. Yes, it is intended.  There is no harm about it.\n. Thank you for reporting this issue.  This probably comes from some bug in rate throttling code. I'll look into it.\n. I have not reproduced this issue, but found the code which potentially causes busy loop.\nFix was committed via 925b5ce\n. Are you experiencing this issue with only HTTPS URIs?  Or do you think HTTP URIs also produce this issue?\n. Thank you.  I still could not reproduce this issue.  I found a problem related to WinTLS, but it probably does not cause busy loop.\nCould you show us how to easily reproduce this issue?\n. The bug mentioned in the previous post was fixed by the comment cf2fa33fe0d73f7001d262beee5e8aba03544126.\nThis bug may cause hang when download HTTPS URI, but without busy loop.  If this symptom is the same one you experienced, then this is the bug we are looking for.\n. Thank you for heads up.  Will do more testing.  My windows environment is quite poor, and very slow, so it might not catch the bug.\nIf anyone has descent Windows build environment and successfully reproduced this issue, please do some debugging and find the cause.  We are very appreciated for that.\n. BTW, which windows version are you using?  64 or 32-bit?\n. Thank you. I was talking about aria2 binary, but probably my words were quite ambiguous.  We are distributing 2 binaries 64 bit aria2 and 32 bit aria2.  32 bit aria2 can run both 32 bit windows and 64 bit windows.  Which aria2 binary are you using?\n. Thank you. I will do test with aria2 64-bit version.\n. As far as I know, there is no news about this issue.\nAre you experience with this issue with plain HTTP?  Or only with HTTPS?\nmax-overall-download-limit is the only way to throttle across entire aria2 instance.\n. We have the following text in README:\n\nIf you want libaria2 dll with --enable-libaria2, then don't use\nARIA2_STATIC=yes and prepare the DLL version of external\nlibraries.\n\nThis means that you need all .dll for third party libraries, and effectively you cannot create static binary.\n. I managed to build libaria2-0.dll with docker.\nHere is the part of modified Docker script:\n```\nRUN tar xf gmp-6.0.0a.tar.lz\nRUN cd gmp-6.0.0 && \\\n    ./configure \\\n    --enable-shared \\\n    --disable-static \\\n    --prefix=/usr/local/$HOST \\\n    --host=$HOST \\\n    --disable-cxx \\\n    --enable-fat \\\n    CFLAGS=\"-mtune=generic -O2 -g0\" && \\\n    make install\nRUN tar xf expat-2.1.0.tar.gz\nRUN cd expat-2.1.0 && \\\n    ./configure \\\n    --enable-shared \\\n    --disable-static \\\n    --prefix=/usr/local/$HOST \\\n    --host=$HOST \\\n    --build=dpkg-architecture -qDEB_BUILD_GNU_TYPE && \\\n    make install\nRUN tar xf sqlite-autoconf-3080803.tar.gz\nRUN cd sqlite-autoconf-3080803 && \\\n    ./configure \\\n    --enable-shared \\\n    --disable-static \\\n    --prefix=/usr/local/$HOST \\\n    --host=$HOST \\\n    --build=dpkg-architecture -qDEB_BUILD_GNU_TYPE && \\\n    make install\nRUN tar xf zlib-1.2.8.tar.xz\nRUN cd zlib-1.2.8 && \\\nCC=$HOST-gcc \\\nAR=$HOST-ar \\\nLD=$HOST-ld \\\nRANLIB=$HOST-ranlib \\\nSTRIP=$HOST-strip \\\n./configure \\\n--prefix=/usr/local/$HOST \\\n--libdir=/usr/local/$HOST/lib \\\n--includedir=/usr/local/$HOST/include && \\\nmake install\nRUN tar xf c-ares-1.10.0.tar.gz\nRUN cd c-ares-1.10.0 && \\\n    ./configure \\\n    --enable-shared \\\n    --disable-static \\\n    --without-random \\\n    --prefix=/usr/local/$HOST \\\n    --host=$HOST \\\n    --build=dpkg-architecture -qDEB_BUILD_GNU_TYPE \\\n    LIBS=\"-lws2_32\" && \\\n    make install\nRUN tar xf libssh2-1.5.0.tar.gz\nRUN cd libssh2-1.5.0 && \\\n    ./configure \\\n    --enable-shared \\\n    --disable-static \\\n    --prefix=/usr/local/$HOST \\\n    --host=$HOST \\\n    --build=dpkg-architecture -qDEB_BUILD_GNU_TYPE \\\n    --without-openssl \\\n    --with-wincng \\\n    LIBS=\"-lws2_32\" && \\\n    make install\n```\nI commented zlib build because it seems we need to use win32/Makefile.gcc to build zlib dll.\n$ export BINARY_PATH/$HOST/bin\n$ export INCLUDE_PATH/$HOST/include\n$ export LIBRARY_PATH/$HOST/lib\n$ make install -f win32/Makefile.gcc PREFIX=$HOST- SHARED_MODE=1\n$HOST should be the same value we use in Dockerfile.\nNow I use the following mingw configuration to configure aria2 build script:\n```\ntest -z \"$HOST\" && HOST=i686-w64-mingw32\ntest -z \"$PREFIX\" && PREFIX=/usr/local/$HOST\n./configure \\\n    --host=$HOST \\\n    --prefix=$PREFIX \\\n    --without-included-gettext \\\n    --disable-nls \\\n    --with-libcares \\\n    --without-gnutls \\\n    --without-openssl \\\n    --with-sqlite3 \\\n    --without-libxml2 \\\n    --with-libexpat \\\n    --with-libz \\\n    --with-libgmp \\\n    --with-libssh2 \\\n    --without-libgcrypt \\\n    --without-libnettle \\\n    --with-cppunit-prefix=$PREFIX \\\n    --enable-libaria2 \\\n    CPPFLAGS=\"-I$PREFIX/include\" \\\n    LDFLAGS=\"-L$PREFIX/lib\" \\\n    PKG_CONFIG_PATH=\"$PREFIX/lib/pkgconfig\"\n```\n. Did you strip debug symbol?\ni686-w64-mingw32-strip or x86_64-w64-mingw32-strip do this depending on OS.\n. I think stripping debug symbol fixes the issue.  Please reopen this if it is not a fix.\n. What does the rpc request URI look like?\naria2 requires specific query parameters encoded, and they are described in http://aria2.sourceforge.net/manual/en/html/aria2c.html#json-rpc-using-http-get\n. The request \"http://raspberrypi_ip:6800/jsonrpc?jsoncallback=1\" does not work.  Please read documentation.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#json-rpc-using-http-get\n. I think this issue is fixed by following manual cited above.  If you still experience the issue even after following the manual, please reopen it.\n. If you are using GNUTLS, then v1.19.0 disables SHA1 signature, and handshake with some servers fail.\nWe relaxed the implementation to allow SHA1 signature in dd277b33af2a5a58c39142097c3ede5df7f5655d, which will be included in the next release.\nIf you are in a hurry, building aria2 with openssl does not have this problem.\n. Next month.  I don't have much time in August.\n. Agreed.  Let's wait and see how they respond..\n. We have no plan to create Firefox extension in this project.\n. #393 will fix this issue.\n. I think this could be solved by building openssl with default ca location /etc/security/cacerts/.\n. I think the workaround is extract all contents between -----BEGIN CERTIFICATE----- and -----END CERTIFICATE-----, including these lines, from files under /etc/security/cacerts/ and concatenate all of them in one file, and give it to aria2 using --ca-certificate option.\n. I compiled openssl with the parameter to load certificates under /etc/security/cacerts, but it did not work.  The debug was too much painful.\nSo I think your workaround is better than my idea.\n. Not sure about openssl's parser, but your workaround worked for me just fine.  So probably it does not matter.\n. This could be a duplicate of #392.\nIf so, the fix was committed into master branch.\n. Reopen this if you still experience this issue with the latest version.\n. Generally, android has less computational power compared to laptop or desktop PC.  That could affect SSL/TLS performance.  This is still speculation though.\nActually, we have used same code path for http over SSL/TLS and sftp.\nUnderlying libraries, OpenSSL and OpenSSH2, may have dedicated code for Android, but I'm not sure.\n. Use ftps://...\nCurrently, we have no functionality to use user's key.\nThe only option we have is validate server's public key: http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--ssh-host-key-md\n. I was wrong, it should be \"sftp\" not \"ftps\".\n. Thank you!  Merged now.\n. You are right.\nThe easiest workaround is allow multiple --ssh-host-key-md option, and we assumes that server is trusted if its key is in the set of specified host keys.\nMore elaborate way to solve this problem is extend --ssh-host-key option to allow user to specify host name.\n. First aria2 requested http://security.kali.org/kali-security/pool/main/s/screen/screen_4.2.1-3+deb8u1_amd64.deb, and server returns metalink file.\naria2 then checked given checksum against this metalink file, and failed.\nIf you omit --checksum option, download should work: by default aria2 detects metalink file, and read it, and download file described in metalink file.\nMetalink file can contain checksums in it to achieve integrity protection.\n. In this case, yes, it is annoying.\nThe thing is this feature is there for several years, someone may depend on this \"feature\".\nSo we cannot simply change this behaviour.\n. I think ignoring checksum when --follow-metalink=mem is given is safe, since checksum calculation always fails if --follow-metalink=mem is used and metalink file is downloaded.  Will do this.\n. I could not spent enough time for this recently.  Release is postponed to the next week.\n. aria2 1.19.1 has just released.\n. Thank you!\nThe idea is that I don't have to update link every time I make a release, and latest release always comes top.\nBut perhaps, you may argue that if release note is long, we have to scroll down to find download links.\nIf we link to the separate page, then we can just hit \"End\" key to get there.\nSo I agree with you, I'll do update the link momentarily.\n. I agree that it would be nice to have the console readout to show only global statistics when downloading many files in a batch.\n. OK, let's close this issue.\n. I think --follow-metalink=mem does the job in this case.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html?highlight=#cmdoption--follow-metalink\ndownload.gnome.org returns content-type: application/metalink4+xml, then aria2c processes the response as metalink file in memory, and continues to download the content it describes.\n. Please reopen this if --follow-metalink=mem does not fix this issue.\n. Thank you for reporting this bug.  Yes, this is a bug.\nThe fix was committed via 85faafc\n. $XDG_CACHE_HOME defaults to $HOME/.cache.  What happens if you place dht.dat file under $HOME/.cache/aria2/ ?\n. Looking up old directory is done for compatibility reason.  If we found files at old location, we use them.\nIf not, we check new locations.\n. OK, let me check more..\n. In my environment, dht.dat is correctly loaded:\n2015-09-29 23:47:45.632894 [INFO] [DHTRoutingTableDeserializer.cc:79] Loading DHT routing table from /home/alpha/.cache/aria2/dht.dat.\n. Thank you @nmaier !\n. Is this still in work-in-progress?\n. 1.19.2 has released just now.\n. @nmaier Could you do this?\n. aria2 does not support HTTP POST for downloading purpose.\nIt is the RPC feature that aria2 accepts POST request from client.\n. aria2 can connect to tcp tracker via HTTP proxy.  There is no proxy support for UDP traffic.\n. Thank you for reporting this.\nI committed 4bbc71c to fix this.  But you need to specify --max-file-not-found > 0 to retry on getting 404.\nNote that --max-tries is generally for timeout.\n. Recent version of aria2 requires newer versions of gcc >= 4.8.3 or clang >= 3.4.\nI'm afraid Ubuntu 12.04 is a bit too old.\nAlternatively, you may patch the old version of aria2 with the diff.\n. @futuretechmag Thank you for telling me that. 029d689 fixes it.\n. Yes, mostly they are the same.  The difference is that error code value.\nI think you also need to specify --max-tries=100 in this case.\n. Closing, since original issue was fixed.\n. It works for me.  Please note that event notification only works with WebSocket connection.\n. Thank you for reporting this.  It looks like the server sends both Content-Length and Transfer-Encoding: chunked, which is prohibited by RFC 7230.  In anyway, aria2 should ignore Content-Length in this case.  There could be a bug somewhere handling this situation.\n. Fix committed via 5ccd5b6\n. Because the file is gzipped. Try gunzip it first.\n. It turns out that the torrent file contains invalid integer: i-2.6960757756466E+18e\nAs far as I know, torrent file's integer encoding does not allow this scientific format.\n. This has fixed in the latest release.\n. > ... into my config file, then aria2c daemon quits almost immediately after started.\nDid you specify --enable-rpc option?\nDid you get any error message from aria2?\n\nFurther, if I use aria2rpc to add this option, for a particular torrent, then I get an error message about --on-bt-download-complete, and the download does not start.\n\nCurrently --on-bt-download-complete cannot be specified per download. It can only be specified in config file or command-line.\n. Log says that aria2 failed to bind socket to port 6800, which probably means aria2c or another process uses port 6800.  Could you check that another aria2 is not started already?\n. I could not reproduce this even if I wrote on-bt-download-complete option in my config file along with enable-rpc=true.\nCould you paste your config file here?  Please mask any confidential information it contains.\n. Thank you for providing configuration file.\nUnfortunately, I still could not reproduce this issue even with the above configuration file.\nIn my environment, aria2 started as RPC daemon successfully, with on-bt-download-complete option line in configuration file.\n. I have no idea at this point.  But your log file was really strange.\n\n2015-11-06 12:59:35.688707 [ERROR] [HttpListenCommand.cc:114] IPv4 RPC: failed to bind TCP port 6800\nException: [SocketCore.cc:301] errorCode=1 Failed to bind a socket, cause: Address is already in use\n2015-11-06 12:59:35.803255 [ERROR] [MultiUrlRequestInfo.cc:292] Exception caught\nException: [DownloadEngineFactory.cc:215] errorCode=1 Failed to setup RPC server.\n\nDo you really get this error log only when adding \"on-bt-download-complete\" option?\n. Since #382 was closed and fixed, let's close this issue without further action as you wrote.\n. HTTP/2 stream can be cancelled easily, so probably we don't have to enforce 16 max parts limit.  1M min size is just an architecture limit of aria2.  It could be less, say, 256KiB, but 1 byte is too small for the current aria2 architecture.\nHTTP/2 is good for downloading many relatively smaller files, since we can request them at once, minimizing request latency.  For large files, the benefits may be reduced, since the reduced latency is too small against the actual downloading time.  OTOH, fixing damaged downloads using metalink hashes could be efficient in HTTP/2, since we can issue multiple ranges at once.\n. Thank you for reporting this issue.\nIt seems that this bug is caused by pooled file descriptor.\naria2 by default pools file descriptor for reuse.  The thing is we only evict timed out file descriptor when we pool another file descriptor.  In this issue, we no longer pool anything, so no eviction, and no close.  I'm working on the fix.\n. The above commit fixes this issue.  Please confirm.\n. Yes, 30 seconds interval to run eviction.  I know we can go even smarter, but this is a simple fix without changing many part of aria2 codebase.\nThank you for donation, but it is a difficult time for OSS developer living in Japan.  Japanese law effectively prohibits donation without registering myself as some kind of organization eligible for donation.  Probably tax related regulation, but I don't know details.\n. OK, I close this issue.\nMore than 1 month passed from the last release, so I think it is good idea to make a new release.\nWill schedule next release.  I think we can make it in this month or latest in this year.\n. Could you tell us about configuration/options and public torrents when this crash happened?\nAre you experiencing this issue every time when you are downloading torrent?\n. Thank you.\nYou mentioned this issue occurs when downloading big files.  Could you tell us the file size which  crashes aria2?\n. Thank you.  Yes, this is definitely mmap related.\nI could not reproduce this so far.  If file size is changed by external program, it is a cause of the crash, but without that I could not still figure out why aria2 accessed region which is not memory mapped.\n. 3974c1223b19a8647d7e361fa130d0fa78a41026 may reduce the possibility of this issue happening, but I'm not sure about that.\n. Yes, insufficient disk space could cause this bus error.\nI thought that --file-allocation=falloc fully allocates required disk space, but it seems it is not the case here.\nWe have no way to handle this error with mmap.  For normal disk write, we can know it from error code, but with mmap, the process exits with bus error, which does not leave us any method to continue the operation.  I think we can close this issue as wont-fix, and the workaround is not to use --enable-mmap if disk space is not fully allocated.\n. OK, e934f177fff09dd74ae418b4fd623d82dada2f13 will add couple of packages required to build aria2 from git repository.\n. Thank you for notice this.  Fix committed via 9bce4eb\n. Thank you!  Merged now.\n. Probably, this is limitation of NTFS + sparse files, or some sort.\nFor me, sparse files on NTFS (or Windows API in general) is still rather black magic.\nThe relevant part of the code is\nhttps://github.com/tatsuhiro-t/aria2/blob/9bce4eb925794528b21b4cdb0f7777ac24ffd7c2/src/AbstractDiskWriter.cc#L473\n. A control file is removed when download was finished.\nBut if --force-save is used, they are not removed.\n. We use same code to allocate space for both single and multi file torrent.\nBTW, do you symlink to each file, or just a top level directory?\n. So if you have 100 files in multi torrent, do you create 100 symlinks?\n. c2157e608e8225040cf3cc0d288a2c641d33f14c fixes the bug that file allocation gets stuck at 100%.\nI could not reproduce \"Incorrect function.\" error since I don't have necessary environment.\n. With 432675e, aria2 now correctly get file size for target file of symlink.\n. OK, let's close the issue.\n. Here is workaround for this specific problem: https://gcc.gnu.org/gcc-4.9/porting_to.html\n. What do you mean \"Masked\"?\n. Thank you.  I'm not sure why aria2 is masked and how to solve this.  You're better to ask gentoo developers.\n. check-integrity=true triggers on-bt-download-complete, and it is by design.\n. I think it is possible to add additional parameter, but there may be some scripts or programs that strictly check the number of arguments.  If they do, we are breaking them.\nBTW, this on-bt-download-complete invocation was added in #355\n. Another workaround is add option not to call on-bt-download-complete after verification success.\n. The option was added via commit 35f08f0\n. We have had this feature quite some time: http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption-R\n. Please reopen this if -R option does not fix this issue.\n. aria2 has configuration option to set concurrent downloads.  See -j option.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption-j\nYou might be also interested in http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--bt-detach-seed-only\n. Ah, sorry, you have already set -j option higher.\n. DHT has very limited number of concurrency at the moment.  It could delay things.\nBut you have UDP tracker configured.  Usually, UDP tracker is much faster than gathering peers from DHT.  Unless UDP tracker is unresponsive (or packet loss), getting metadata should be fast enough.\n. Have you made sure that increasing receive buffer in aria2 codebase solves this issue?\n. Added --socket-recv-buffer-size option.\nFrom your description, it is sufficient to change receive buffer size.\nDo you need to change send buffer size as well to fix this issue?\n. Please re-open this issue if --socket-recv-buffer-size is not enough for your use case.\n. Can you reproduce this with just one failing URI?\nI'd like see the aria2 log (-l option) to know what happened the behind the scenes.\n. OK, let's close this issue.\n. I don't say uTP support is not coming.  But we have no progress at the moment in this regard.\nFor myself, I don't have urgent need for uTP at the moment.\n. \"waiting\" state means it is waiting in queue, and download has not started yet.\nSeeding torrents are treated as active downloads, and it is counted toward maximum concurrent downloads (-j option).  You might be interested in --bt-detach-seed-only\n. The statement in manual just means that \"status\" contains \"active\" label in aria2.tellStatus RPC method.\n\nAnd some offtop - it is possible to place control and torrent files in separate folder.\n\nfiles downloaded and control files are written under the same directory given in -d option.\n. --bt-detach-seed-only works for me.  Not sure which option prevents your aria2 from doing things correctly.\n. Do you have easy reproduction steps?\n. Thank you.\nI followed your steps.  Only difference was I used 5 torrents.\n1. add 5 torrents using -i list option, and -j2 and --bt-detach-seed-only\n2. pause 2 active torrents, and then unpause them\n3. let downloads go.\nFirst 2 torrents were done, then unpaused 2 torrents were started, which is expected behaviour.\nThen last 1 torrent was started.\nAll downloads went fine; Because I used --bt-detach-seed-only, all 5 downloads got SEED state.\nStill could not reproduce this issue.\n. I paused 2 active torrents, which were started at startup.\n. active means it is being downloaded, not seeding.\nSo you paused/unpased torrent in seeding state?  Re-reading your comment, I think that is the case.\nWill try again..\n. Thanks.  I successfully reproduced this bug.\n. The above commit should fix this issue.\n. If control file (*.aria2 file) is present, you don't have to do anything, just run aria2 with the same arguments.\nIf control file is missing, use -V option.\n. It looks like aria2 only supported uppercase letters in base32 decoding.\nd0b6a88 fixes this issue.\n. Could not reproduce this.\nIs main_list.gz__temp corrupted?\nIn the successful write, aria2 renames it to main_list.gz to avoid truncation of file due to disk full.\n. Thank you for detailed information.\nWe have identified several problems when save-session and deferred-input are used together.\nWith deferred-input=true, it only reads input file to fill active download slots so that it saves memory usage.  If one of the download goes into inactive state, new one is read from file.\nMeanwhile, with save-session option, we only saves downloads kept in memory.  But because of deferred-input behaviour, all downloads are not read to memory, so we lose some of downloads left in input file.\nAnd there is locking issue in Windows machine in general, and it requires us to rewrite BufferedFile and IOFile classes.\nAs a workaround, I'd like to disable deferred-input if save-session is used, and if aria2 detected this combination of options, it will print warning.\n. No particular number, but it can reduce memory usage for example 5000 items in download list.\n. Done 8fbfb3ac84f53839de486a9748679bdf21e010ac\n. It looks like chrome's cookie value is now encrypted.  aria2 does not support this.\nSince there is no reference to decrypt these things, we have no way to implement it.\nPerhaps, there might be some scripts or some way to decrypt them using sqlite3 library.\n. Done!\n. Does --truncate-console-readout help?\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--truncate-console-readout\nIf you want all active downloads, you have to use RPC.\n. Thanks.  Can we close this issue?\n. Thank you!  Merged now.\n. It should run on download has completed.\nIf you download .torrent file, aria2 run --on-download-complete when it is done, and then continues to download torrent itself.  This may be viewed as command is executed twice.\n. OK, let's close the issue.\n. Fix committed via fb4310e\nThank you!\n. It works for me.  I got the same error if I use --dry-run option (HEAD request).  curl -I also failed, so this seems to be an expected behaviour of amazon.\nDid you use --dry-run?\n. With the exact the same command line, it works for me...\n. aria2 did not retry for 403 error.  The reason why we see multiple 403 errors in the log is because aria2 issued multiple range requests, and all or part of them were responded by server with 403.  aria2 did not retry against them.\n. It seems FILE_FLAG_NO_BUFFERING needs special treatment, like O_DIRECT in linux counterpart, which is a bit hard to use in aria2 code base.  Just specifying the flag probably is not enough.\nIf the memory usage is just a file cache, then if Windows requires memory, it should free the cached space (not sure windows is really clever in this regard).  Did you experience disk slashing or slowness of PC when aria2 was used in this way?\n. We usually don't aligned read in aria2.  But with disk cache enabled, it does 4KiB aligned write as much as possible.  In my experience, enabling disk cache on Windows decreases disk activity a lot.\n. aria2 Windows version has been there for several years, but we don't have this kind of bug report.  I'm wondering why.  Do you have any particular memory related \"optimization\" software on Windows?\n. Are you using --enable-mmap option?\n. Thank you.  BTW, are you using Windows binary we distribute or the one you built for your own?\n. Could you share the torrent or magnet URI you encountered with this trouble? (just in case, we only investigate if they are legal torrents).\nDHT requires routing table which includes the address of known peers, and it takes some time to build such routing table, aria2 saves it in a file.   Initially, aria2 does not know any peers, and there is no file.  The log says this situation.\nWhen downloading torrent using .torrent file, DHT routing table is not required, and download should work.  While downloading, aria2 may get DHT peer information from connected peers, then it will save them in a file.\nWith magnet URI, usually aria2 has to use DHT to first get peer address, and then get torrent meta data from them. Some magnet URI has udp tracker address, which can skip DHT access.\nIf magnet URI does not udp tracker, then you need to specify bootstrap DHT peer with --dht-entry-point option.  See also http://stackoverflow.com/questions/1181301/how-does-a-dht-in-a-bittorent-client-get-bootstrapped\n. OK, closing this issue.\n. aria2 already has similar feature using metalink file.  We defined the piece size, similar to BitTorrent, and for each piece size, expected digest value is recorded in metalink file.  aria2 can check this digest piece by piece, and only download the missing ones.\nIn general, to reduce metalink file size, and for efficiency, the piece size is power of 2, such as 256KiB, or 4MiB for larger files.\nThe piece size is recorded in aria2 control file (http://aria2.sourceforge.net/manual/en/html/technical-notes.html#control-file-aria2-format).\nThe class to read/write control file is DefaultBtProgressInfoFile.{h,cc}.\n. No\n. Probably, it waited for the response from UDP tracker.  UDP tracker is only enabled when DHT is enabled.\n. It is a common behaviour of bittorrent client to report tracker when it exits from swarm.\nWe have 15 seconds reset UDP packet timeout, and 1 minute \"give up\" timeout.  Probably, we can reduce these numbers.\n. Probably, bittorrent is not suitable for super responsive interactive tool you imagine.  It has a protocol that client should obey.\nAnyway, reduced timeout should improve the situation.\n. Please use TAB to split URIs in the same line when using input file.\n. Could you paste the response headers from the web site here?\n. The cause is this:\nContent-Range: bytes=0-2096103423/2096103424\nThis is violation of RFC 7233.  This kind of representation is for client request (and still it is wrong for client too...), not response from server.  I think this server implementation misunderstood this.\nAnyway, HTTP/1.1 is full of legacy implementation, we will do some hack to support this...\n. Fixed in 8512fe9\n. You don't need -c option for BitTorrent.\nIn generally, if you have corresponding control file (*.aria2 file), then you don't need -c option.\nIf you don't have one, use -V option for BitTorrent to validate current downloaded file, and then aria2 continues to download the missing pieces.\n. I don't know the torrent file without piece hash.\naria2 shows error and does not process such broken torrent file.\n. It is OK to see \"Checksum error detected\" with -V.  It tells that aria2 found some missing pieces (missing piece will emit checksum error), and aria2 is going to resume the download.\nI agree that the message could be improved in this case.\nThe thing is the functionality is shared in multiple code path, and in some code path, error message is appropriate. Will see how to improve this. \n. Thank you for PR.\nUnfortunately, doing this would break compatibility.  aria2 has been there almost 10 years, and third-party scripts may rely on the standard output.\n. \"Authorization failed\" means usually basic authorization is required and failed.  Did you set username/password?\n. 0a63a7e adds proposed .clang-format file, and make clang-format. (set git config --add clangformat.binary to clang-format executable).\n@nmaier Any recommendations for .clang-format file?\n. Good, so if you are ok, then I'll perform make clang-format and push.\nNote that we use clang-format-3.6 until ubuntu gets 3.7 as default (clang-format formats code differently between versions unsurprisingly).\n. Which version are you using?\n. The slight formatting deviation is not critical, and we can manage that.\nI'll make clang-format and push them into master.\n. Done. \n. The documentation is correct, since out=file.img is given, the output file name becomes file.img.\n. Did you see any error in aria2 log (-l option) ?\nCould you tell us the steps to reproduce this issue, including how many rpc requests are in-flight concurrently?\nDoes returning nothing mean that aria2 responds normal HTTP status code, but the response body is empty?\n. Thank you.  So to reproduce this issue, issue 50 concurrent HTTP POST requests by curl to aria2 RPC server, right?\n. I did 50 concurrent curl command, but they all succeeded.\n. Implemented.  Closing.\n. This could be rounding error of floating point number.\nBut in practice, this kind of error is not significant in this seed ratio, since aria2 is one of a client in the swarm.  Probably, you have a specific setup to rely on the exact seed ratio, or some sort?\n. Rounding error is inevitable when we use floating point seed ratio, such as 10.0.\nIf total length of download gets large, the round error could be worse.\nI'm interested in the total length of the torrent which causes this issue.  Can you share it with us?\nSeed ratio is not the feature to control the exact the amount of the upload transfer.  It  is there to encourage the seeder to upload at least what it downloaded.  There is some cases client may request the same piece (or its partial block) twice, such as network is down or client crashed or something.\n. Thank you.  I have to ask you which version you are using.  I remember that old version has a bug of this kind of problem.  Did you try the latest version of aria2?\n. Thank you.  Could you apply the following patch, and see the issue still happens?\n``` diff\ndiff --git a/src/BtPieceMessage.cc b/src/BtPieceMessage.cc\nindex 80026b2..91fe1c5 100644\n--- a/src/BtPieceMessage.cc\n+++ b/src/BtPieceMessage.cc\n@@ -175,8 +175,9 @@ size_t BtPieceMessage::getMessageHeaderLength()\nnamespace {\n struct PieceSendUpdate : public ProgressUpdate {\n-  PieceSendUpdate(std::shared_ptr peer, size_t headerLength)\n-      : peer(std::move(peer)), headerLength(headerLength)\n+  PieceSendUpdate(DownloadContext dctx, std::shared_ptr peer,\n+                  size_t headerLength)\n+      : dctx(dctx), peer(std::move(peer)), headerLength(headerLength)\n   {\n   }\n   virtual void update(size_t length, bool complete) CXX11_OVERRIDE\n@@ -187,7 +188,9 @@ struct PieceSendUpdate : public ProgressUpdate {\n       length -= m;\n     }\n     peer->updateUploadLength(length);\n+    dctx->updateUploadLength(length);\n   }\n+  DownloadContext dctx;\n   std::shared_ptr peer;\n   size_t headerLength;\n };\n@@ -218,10 +221,8 @@ void BtPieceMessage::pushPieceData(int64_t offset, int32_t length) const\n   if (r == length) {\n     getPeerConnection()->pushBytes(\n         buf.release(), length + MESSAGE_HEADER_LENGTH,\n-        make_unique(getPeer(), MESSAGE_HEADER_LENGTH));\n-    // To avoid upload rate overflow, we update the length here at\n-    // once.\n-    downloadContext_->updateUploadLength(length);\n+        make_unique(downloadContext_, getPeer(),\n+                                     MESSAGE_HEADER_LENGTH));\n   }\n   else {\n     throw DL_ABORT_EX(EX_DATA_READ);\n```\n. If peer downloads pieces from multiple peers, then it may request same piece from different peers, to accelerate the last stage of the download (end game mode).  For duplicated pieces, peer will send cancel message.  If that happened, seeder may overcommit upload size, but it is completely normal.  So, I think there is no way to achieve your goal in this case.\n. Since I have not reproduced this so far in my environment, I have no idea why this happens.\nI tested 10m torrent, and did many tests, but they all succeeded; 100 % download.\nI don't want to add said option, since share ratio is really not the feature intended to be used in this way.\n. Thank you for the news.\nThe interesting part is that I used 256KiB piece size, and total 315MiB single file torrent, and could not reproduce this issue.\nAnd aria2 actually checks how many bytes are uploaded against completed size (this seed ratio check gets started when torrent download finished, so completed size == total file size.  This may not be true if --select-file is used, and partial downloads are done).\nSo.. are you suggesting that we should use the number of pieces we uploaded, instead of the number of bytes uploaded?\n. Do you mean package == piece?\nI'm not sure I fully understand your comment, but probably you insisted that number of pieces should be used to calculate share ratio.\nIt is different from the share I know of.  My understanding is that it just the number of bytes uploaded.\nFrom https://en.wikipedia.org/wiki/Glossary_of_BitTorrent_terms#Share_ratio\n\nShare ratio\nA user's share ratio for any individual torrent is a number determined by dividing the amount of data that user has uploaded by the amount of data they have downloaded. Final share ratios over 1.0 carry a positive connotation in the BitTorrent community, because they indicate that the user has sent more data to other users than they received. Likewise, share ratios under 1 have negative connotation. \n. Use -V or --bt-seed-unverified option.  Also make sure that directory specified in -d option contains fully seeded files.\n. If I understand correctly, tracker does some logging, and prints some hash value?   Which hash value it prints out?  info-hash?\nWhat kind of tracker are you using?\n. Thank you.  Did you see that aria2 does not get any response from tracker?  Or is it just hash value missing from console output?\n. And aria2 got good response from tracker, yes?\n. I checked UDP tracker specification, and we are sure that we sent all required fields to tracker: http://www.bittorrent.org/beps/bep_0015.html\n\nOne possibility is scrape request, which aria2 does not perform.  If other clients do, then the output of udp tracker may be caused by this.  Still I'm not sure about that.\nAnyway, as long as UDP tracker works, I think this is not an urgent problem.\n. Right, I found a bug which prevents seeding with udp tracker.  Fix will be committed very soon.\n. Fix committed via ddb94eb.  This will make things easier.\n. Doing sleep in event hook does not work, since they are in the separate processes.\nIf you have mirror URIs, then you can give them all to aria2, and it chooses the URIs so that the load is distributed to given servers. Other than that we have no mechanism to sleep between requests.\nReducing -j option could reduce the frequency.\nYou can also do some programming with RPC, and provide the request with some intervals.  Obviously it requires some scripting.\n. It looks like \u2212\u2212ftp\u2212user=monsi is treated as URI.  This suggests that there is a problem in quotation in command-line arguments.\n. I'm quite not sure what is wrong.\nDo you get any log message?  What rpc client are you using?\n. Thank you for reporting this bug.\nI think this probably caused by the fact that BitTorrent LPD requires IPv4 address.  With multiple interfaces, IPv6 may be wrongly used.\n. The above commit should fix this issue.\n. Content-MD5 is not supported.  Instead, aria2 supports Digest header field (https://tools.ietf.org/html/rfc3230).\nAlso aria2 does not support trailer fields at all.\n. Use -d option to set directory (without filename).  Then, use -o option to set file name relative to -d option.\n. Please reopen this issue if -d and -o options do not work as I expected.\n. I can cross-compile Android ARM build using Android NDK and c-ares statically compiled for that architecture.\nc-ares is not required library.  Pass --without-libcares to configure.\n. The failed test uses IPv4 multicast.  The error was caused probably because your OS did not enable IPv4 Multicast.   If you don't use BitTorrent Local Peer Discovery feature, then you can ignore this error.\n. This is rather intentional.  aria2 has segmented downloading feature, and it relies on the exact calculation of range header field.  aria2 is a bit higher level application for download files.\nIf you are interested in lower level HTTP tools, curl is the best.\n. Thank you for explaining the use case.  I fully understood what you mean.\n. Thank you for reporting this.  I think 0282899bfa fixes this problem.\n. duplicate of #530\n. This was fixed in 1.19.1.\n. Can you provide info about signature algorithm the server supports?\n. gnutls-cli prints signature algorithm.\nTry gnutls-cli --port PORT HOST, replacing PORT and HOST with actual port number and host\ne.g.:\ngnutls-cli --port 443 github.com\n. Thanks.  It seems your gnutls installation is a bit old, and the necessary field is not show.\nThe second host works very well with my aria2 build.\nThe strange thing is that your log says that gnutls-cli and googlevideo.com negotiated now insecure cipher suites.  When I tested, I got more secure cipher.  So probably this may suggest that gnutls installation is very old.  That's version 2.12.20.\nCould you build aria2 with latest version of gnutls?  You can compile aria2 using openssl too.\n. First please read https://aria2.github.io/manual/en/html/README.html#how-to-build\nSince your gnutls is old, you have to install newer gnutls version first.\nIt seems this is the newest version of gnutls available to wheezy: https://packages.debian.org/wheezy-backports/libgnutls28-dev\n. Can you confirm that aria2 binary on the working server is the same one on the not-working machine?\n. If they use the exact same binary, bit by bit, then it is very strange.  I'm not sure there is some configuration files to change gnutls behaviour that I'm not aware of.  Anyway, I suggest to build aria2 with newer gnutls.\n. Thank you for the information.\nAt some point between 1.18.3 and 1.18.5, we made cipher suite preference of GNUTLS secure.  Probably, during handshake, weaker algorithm is somehow chosen in your environment.\nI don't think we should down the bar about security, but if you think the backward compatibility is most import, change the following code makes aria2 accept weaker ciphers.\nhttps://github.com/tatsuhiro-t/aria2/blob/8b93b12488d12820470e14f0ebbb656728f7df83/src/LibgnutlsTLSSession.cc#L131\nReplace SECURE128 with NORMAL, then aria2 is degraded to 1.18.3 level.  I really do not recommend this though.\n. duplicate of #532 \n. With scene1 and scene2, they work for me just fine.  I tested with both gnutls and openssl version.\nFor scene1, make sure that it has empty passphrase for pkcs12 file itself.\nFor scene2, make sure that they are really in PEM format.\n. ECDSA key pair works well in my aria2.\n. I think this is duplicate of #359 if you are trying to build aria2 statically.  gnutls.pc file included in older version of gnutls includes deprecated flags, which makes compiler fail.  It seems fixed in Debian sid, but I'm not sure other versions.  Try openssl if you want statically linked binary, and gnutls does not work for you.\n. Great stuff. Thank you!\n. I did that in some extent.  Did you find the remnants?\n. Yes.  We finally moved to github after that release.  It has been corrected.\n. Thank you for spotting them.  They are fixed now.\n. Thank you!\n. Try -V option.\n. Please ask the question at aria2 webui issues.\n. -V is per download option.  You can specify it when you add an download item to aria2 per item basis.\n. See also #556\n. aria2 cannot seed if different torrents share the same file, and its file path is the same.\n. Have you tried --max-tries option?\n. ad6d799 enables retry for 504 status code.  --retry-wait may help depending on server.  We have --timeout option, but it probably does not help, since the timeout happens on backend of server side.\n. D state means uninterruptible sleep, and aria2 was calling system call.\nAre you using network file system to store downloaded files, or is that device very slow?\naria2 does not use asynchronous write to disk, so using slow device causes aria2 to slow down or block. Also note that BitTorrent download highly utilizes random read/write to disk.  Looks like you turned off file allocation.  In this case, make sure that file system you are using to store files supports sparse files.  FAT file system is known not to support it.\nTo further debug this issue, you can run aria2 with gdb (debugger).  And if you see this issue happen, hit Control-C.  Then run run 'bt' command there.  It shows stack trace when aria2 is paused.\nTry latest release if you can, the bug might be fixed in the latest release.\n. I don't use USB storage for downloaded files.  I still use hard disk for this purpose.  So I have no recommendation about USB devices suitable for aria2.\n. #304 has similar symptom.\n. Thank you for the log.\nI'd like to know where aria2 gets crashed.  Could you get stack trace for this purpose?  If aria2 gets crashed, you can tweak the system to produce core file.  Then you can use gdb to get the stack trace, which enables us to determine where aria2 gets crashed.  This requires aria2 is compiled with debug symbols.  This is done by default, unless you do strip these symbols to reduce file size.\n. How do you invoke aria2c?  If you are running aria2c from terminal, then it is rather simple:\n$ # at the directory where you have write permission\n$ ulimit -c unlimited\n$ <run aria2c..>\nWhen aria2 crashes, it will write a file named \"core\" in the current working directory.\nTo get stack trace, run:\n$ gdb /path/to/aria2c core\n...\n(gdb) bt\n(stack trace is printed here)\nAnd paste the stack trace here.  Please mask any confidential information, such as password if it is visible in the stack trace.\nPlease first check that aria2 has debug symbol.  If aria2 executable is few MB size, then it has no debug symbol, and with that, stack trace is very little use.\n. Core file location depends on settings on the host.  It could be current working directory, or it could be determined by  /proc/sys/kernel/core_pattern.  Nevertheless, if aria2 froze, then it is not a crash, so no core file was produced.\n. As far as I know, if mmaped memory is written to the disk and purged from physical RAM in the case of low memory situation.  mmap is not faster than ordinary read/write system call.  If mmap causes an issue, could you try --disk-cache option?  It uses 16MB memory per aria2 instance for disk cache by default.\n. The disk cache size is configurable.  Try --disk-cache option.\n. file-allocation=falloc is independent from mmap or disk cache.  If it blocks with disk-cache, then it also blocks with mmap. BTW, what file system do you use?\n. And are you using aria2 on windows?\n. I have also experienced similar problem with NTFS with falloc before.  aria2 blocked after file allocation completed, somehow operation system was doing something funny.\nMy knowledge of Windows is limited and still not sure how to fix this properly.\nMy comment about mmap is for Linux.  Windows mmap counterpart may not as smart as Linux's, and might blow up if memory is short.\nProbably the safe bet is use --file-allocation=prealloc.  If you use --file-allocation=prealloc, do you have the same problem?  NTFS supports sparse files, so you may try --file-allocation=trunc, which is faster, but could be resulted in a fragmented file.\n. We use SetEndOfFile to allocate file space, but it seems it performs zero-fills.\nInstead, documentation suggests that SetFileValidData avoids zero-fills, but it also suggests security implications:\nhttps://msdn.microsoft.com/en-us/library/windows/desktop/aa365544%28v=vs.85%29.aspx\n. fc95a91eb617beb9130a6b1c7ed7c14a61189f8e will make --file-allocation=falloc faster by eliminating zero-fill.\nCrash does not sound good, so I'm now considering to add option to set maximum file size for mmap.\n. --max-mmap-limit options was added by commit 8f51793b19c751bde0e41448aaeb9eb54d2fdbb1\n. Great to hear that.  Thank you.\n. I'm not sure about Windows Cygwin internals.  As for Linux, when memory is required for another processes, kernel will flush data into disk as needed.\n. Released!\n. Thank you!  Merged now.\n. Thank you!  Merged now.\n. aria2 allocate file in file system before download by default.  The actual file size does not necessarily means the file is downloaded completely.  The actual downloaded size is \"completedLength\", which is 1068302336.  It is less than 1073741824, so download is incomplete.\nWe have similar bug report in #517.  We have fixed relevant bug since the last release.  If you can compile aria2 from git repository, then it is worth trying.\nPlease note that aria2 by default sets seed-ratio 1.0, which means aria2 exists as soon as the upload size equals file size (in this case, 1GB).  Try --seed-ratio option to set bigger size, or 0 which means unlimited.\n. Thank you for suggestion.  Since we don't provide any binary except for windows or mac os x, doing this in other platform is a bit hard.\n. This is because incomplete downloads first get stopped, and counted toward max-download-result limit.\n. Did you quote your URI with single quotes (') or double quotes (\") when you entered it in terminal?  Since your URI includes \"&\", which has special meaning in shell, it must be quoted.\n. It means aria2 gets either SIGINT, SIGTERM or SIGHUP signal twice.  Can you check this possibility?\n. If you intend to run aria2 in background, try -D option.  Without that, aria2 may get SIGHUP when associated shell exits.\n. @kkartaltepe thank you for answering the question!\n. 25615fcb1744e94f4774aaee24ed4db172af397f adds \"seeder\" key to tellStatus response.  It becomes \"true\" if the local endpoint is seeder, otherwise \"false\".\n. OK, let's close the issue.\n. Thank you for super quick update!\n. If my understanding is correct, you are in the closed network, and you have 4 aria2 daemon enabling DHT.\nFirst, you need one aria2c as seeder.  You can run aria2 as seeder with -V option and enable DHT.\nFor other aria2 daemons, run --dht-entry-point to the IP address of bootstrap node of DHT network.  Since your DHT network is in your closed network, and your only node is aria2 seeder, specify seeder's IP address and DHT port in --dht-entry-point option.  You need magnet URI to these leechers.  You can see magnet URI using aria2c -S /path/to/file.torrent.\nWe have no discussion forum.  Use this issue for anything related to aria2.\n. Ah, no, you have .torrent file, then you can use it.  No need to use magnet URI.\n. It works for me for both prefix or whole GID string.\n. This is interesting suggestion.  Showing progress definitely improves UX.\n. It is very interesting.  We would happily accept a patch.\n. The error indicates that file /etc/aria2/aria2.session is missing.  Create the file, and try again.\n. Thank you.  Guessing from the change log, is this from a linux distribution like CentOS or something similar?\n. Thank you for reporting this.  Unfortunately, I could not reproduce this issue.\nCould you get stack trace using gdb when aria2 crashes?\n. Awesome! Thank you.  Will review this PR in this weekend.  Please note that we are now in feature/documentation freeze period now (next release is February 15).  The actual merge will be done after the release.\n. Overall, this is very good PR.  Thank you.  I like this idea.  @luokar has the point for the tiny file downloads, but this feature is optional, and optimizing relatively large downloads would be also plus.  Let's see how this feature does not go well with smaller downloads, and get some idea to improve it if it is ever required.\nFor options, it is OK as long as the usage is documented there.\n. Thank you!  I commented inline.  Could you check them out?\nTo make the branch up to date, you can merge aria2 master into your branch.\nI think you can do git pull https://github.com/tatsuhiro-t/aria2.git on your local branch.\n. Looks like your branch can be merged cleanly.\n. make clang-format is good thing.  If clang-format is not available, then we can do it for you.\nOther than that, PR looks good and ready for merge.\nI'd like to avoid too many diff introduced in the build directory (which was fixed). Can you rebase and squash the commits into one?  If you are OK, we can do it on my side before merge.  It does not change the authorship of the commit, but only the first commit comment is retained.\n. Thank you.  OK, then we'll rebase the commits when everything is OK.\nUnfortunately, we entered feature/documentation freeze period (again), so merge will be done after the next release date, March 15.\n. Thank you.  Sorry, we have now in documentation/feature freeze period, which started March 5.  Since we have coordinated manual translation, we cannot add extra feature in this stage.\n. Merged as 9e05371fb6a70d7d5e9d49db31b879e79c1b56e7\nThank you very much!\n. Great, thanks! \n. Could you describe what was wrong and what you fixed in this PR?\n. Thank you for explanation.  I agree that existing code confuses index and color reference.\n. Thank you.  Indeed this is better in my opinion.  Will merge this PR soon.\n. Thank you.  Merged now.\n. There is --force-save option to save an item even if it is finished or removed.  But it does not consider seed-ratio.\nI think it would be nice to add an option to save BitTorrent item if it is still seeding.\n. It is by spec.  force-save is per download item option. Just setting it in global option does not apply to the existing downloads.\n. aria2.tellStatus RPC method has followedBy attribute.\nhttps://aria2.github.io/manual/en/html/aria2c.html#aria2.tellStatus\nGID 012345 has followedBy attribute which includes db980a.\nPerhaps, it is better to add reverse link from generated download item to make getting producer easier.\n. We added folloing key as a reverse link for followedBy via commit 21754fa\n. What is  DLC CCF RSDF?\n. Thank you.  Probably this crypto policy could be helpful for other distribution.  Will merge this PR soon.\n. Run console as adminitrator privilege.  This warning is harmless if you don't use --file-allocation=falloc.\nIn other words, adminitrator privilege is required to make --file-allocation=falloc work properly on Windows.\n. Thank you for telling me that.  Fix committed via 8985d66e71f980e7d2765753800078f47761f1ba\n. I'm not sure what this PR brings.  It contains too many merged commits.  I close this PR now.  Could you make a new PR to contain only your contribution?\n. The original issue was https://github.com/tatsuhiro-t/aria2/issues/544#issuecomment-176061548\nIn short, without privilege escalation, explorer shows us that file is allocated, but actually it isn't.  We observed that there is high disk activity, and writing files while downloading was severely degraded.\nAfter several hours of debugging, I found that we needed certain kind of privilege to properly allocate files on NTFS instantly.  And this is the result.\nIf you don't want privilege escalation, falloc does not work perfectly, it is the same as pre-1.19.0 release.  We want to do this without privilege, but there seems to be no way on Windows.  If you know how to achieve this without privilege, please let us know.\n. It is hard coded.  See https://github.com/tatsuhiro-t/aria2/blob/8985d66e71f980e7d2765753800078f47761f1ba/src/OptionHandlerFactory.cc#L422\nChange it to whatever value you want, and compile aria2 for yourself.\n. Thank you for reporting this.  99e7d98 fixes this bug.\n. I forgot to add this information leak.  Will add that.\nDo you have any idea to achieve fallocate in Windows without SetFileValidData?\n. Thank you.  Zero fill caused lots of disk activity and it makes fallocate ineffective in windows.\nI'd like to keep falloc name in Windows to avoid additional ifdef.\nIf SetFileValidData is really a matter of security, I will remove it once for all, and also remove falloc from Windows code, since it does not work as we expected.\n. Actually, we have note in README.mingw about falloc.\n. Added additional warning when --file-allocation=falloc is used in 74811dd\n. aria2 uses NTFS sparse file when allocating file with \"trunc\".  But it does not remove the flag.. Make sure that libraries are given to linker with -l option.\n. We'd like to keep public API unchanged if possible.  Changing API is the last thing the existing applications can expect.\nSo I'm ok to add new API function without std::string and std::vector, but it should be toggled with configure flags to support existing application.  I also think it is not easy to just replace them with C-counterpart, since we need to implement strings and arrays and should think about their life time (new and delete).\n. It should read March 15th, 2016.\n. See the ChangeLog file in the archive.\n. aria2 1.21.0 was released.  Closing the issue.\n. Thank you!  Merged now.\n. I think this was fixed in https://github.com/tatsuhiro-t/aria2/commit/8985d66e71f980e7d2765753800078f47761f1ba\n. We have not released the version which contains that fix.  Or else, did you this error after you pulled latest master branch?\n. There is no such feature in aria2.\n. It is usually %USERPROFILE% points to.\n. It is not created automatically.  You have to create .aria2 directory, and place aria2.conf inside it.\n. This means that server refused to accept range request, which means you cannot resume downloads.  This is not aria2 bug.\n. So why we got that kind of error message:  we really don't know server supports range request (resuming), so we just issue request expecting server supports it.  Since this is resume, the expected content-length is smaller than total length (file length).  But it turns out that server does not support resume, and it returns full file content.  Then aria2 complains because the expected file size does not match.  We don't overwrite user's file in this case, since deleting file is the last thing user wants.\n. I found that that sever returns random content length.  In this case, we cannot resume download.\n. Thank you for reporting this bug.  We've fixed this by the commit 4595aa7.\n. I don't know much about OpenWrt.  Perhaps, you can talk to aria2 package maintainer on OpenWrt to update their package?\nFor logging, the default log level is debug, which is very verbose.  Try --log-level=notice or --log-level-warn.\n. I tested with git master, and it just worked with only -c option.\n. OK, then please reopen this if you get this issue again.\n. trunc does not allocate file space.  It just set file length in metadata.  So it could be fragmented if aria2 write data in random order.\nFor warning, we chose the easiest way for now.  Since user can specify falloc in RPC we don't know privilege is required in advance.  Perhaps, we can do this on demand.\n. The warning now deferred until falloc is specified by option as of 1126722.\nThe implication of fragmentation with trunc has already been described in http://aria2.github.io/manual/en/html/aria2c.html#cmdoption--file-allocation\nClosing this issue.\n. Thank you!  Merged now.\n. Thank you for quick update!\n. aria2 could not parse the bencode since it contains floating point integer which is not in BitTorrent specification.  Not sure which client is creating these kind of stuff, but since this has been reported in several times here, we probably should consider to handle this at least to ignore them, and continue to read.\n. f316c94 fixes this issue.\n. Thank you for PR!  Could you debug the unit test error found in travis?\n. Sorry for the late reply.  Is this PR ready for merge?\n. This PR has been merged with some amends.  Thank you!\n. @nmaier Did you notice anything related to this issue?  Is this related to the removal of universal build?\n. This sounds interesting, but I'm afraid to say that we don't want to add another maintenance cost for yet another TLS backend to aria2.\n. Well, relocation will happen before release 1.23.0.\n. As you can see, migration has been done.\n. aria2 does not support ed2k, and we have no plan to support it at the moment.\n. Regarding \"Bencode decoding failed\", we have fixed the similar issue, see #598.\nThe possible reason why download was not automatically started is that its filename does not end with \".torrent\", or its content-type is not \"application/x-bittorrent\".\n. As far as I know, we search content-encodng in case insensitive manner.  Did you observe that aria2 can download torrent if the incoming header is \"content-encoding: gzip\" instead of \"Content-Encoding: gzip\"?\nNote that aria2 does not inflate gzipped file by default.  --http-accept-gzip will do.\n. I confirmed torrent with content-encoding: gzip works if --http-accept-gzip is used.\nIf it does not work, it is probably due to 1) without .torrent extension, or 2) content-type does not indicate it is torrent file.\n. Please don't paste the URI which is potentially illegal (guessing from the URI).\n. 2a8522f6a5d14fa3a1493abc1aa80160feab4c99 may fix this issue.  Could you try that?\n. Thank you for telling me this.  I think 395b8e9 fixes this bug.\n. > After the download the directory and the other file from the torrent still exists on the machine. Is it possible to just download the single file from the torrent rather than the collection of files? This might not be possible but I just don't know because I don't fully understand torrents. If not, should we clean up the other files and the directory after download?\nThis is by design at the moment.  Due to the arrangement of piece hash of torrent files, we need adjacent files to download a wanted file.  It could be implemented more elegantly, but there is no effort to make it happen so far.\n\nDoes aria2c verify the contents match checksum from the metalink? I don't see any indication of that from the output:\n\nIf checksums are available from both metalink and torrent file, only the ones from torrent file is used.\n. I close this issue, since the original issue has been fixed.\n. This may be a duplicate of #600, which is WONTFIX.\n. This may be caused by GMP 6.1.0 bug.  See https://gmplib.org/#STATUS\nWe have similar crash bug report in Mingw build, and building gmp with the suggested patch fixed the crash bug.\n. on-download-complete cannot be specified per download.  See https://aria2.github.io/manual/en/html/aria2c.html#id3\n. Crash has been confirmed.  Thank you for reporting this.\n. It looks like the crash was caused by gmp bug: https://gmplib.org/#STATUS\n\nIssues with GMP 6.1.0:\nAn assembly file which is used for Intel Broadwell and Intel Skylake (except crippled Pentiums and Celerons without BMI2) will not work correctly for Windoze. Patch.\n\nBuilding gmp with the suggested patch fixes this issue.\n. Rebuilt aria2 with patched gmp, which is available as aria2-1.21.0-win-64bit-build2.zip under https://github.com/tatsuhiro-t/aria2/releases/tag/release-1.21.0\nCould you confirm that this fixes this issue?\n. It is true that bittorrent key is missing in stopped or removed item.  I agree that it is nice to have for BitTorrent downloads.\n. Fix committed via c9e2223\n. Have you tried --async-dns=false option?\n. It works for me.  Perhaps, path is not correct or something permission issue?\n. Thank you!  Merged now.\n. 1.22.0 has been released!\n. What kind of error message did you get when download failed?\n. Are you using --file-allocation option?  Probably, you need to set --file-allocation=prealloc, which is safe but slow, or --file-allocation=trunc which is fast, but it could lead to fragmentation.\n. falloc does not work with all file systems.\nIf you don't care about the slowness, prealloc is the best option, and it is the default.  If disk is formatted as FAT32 or something that does not support sparse file, actually prealloc is the only option that works properly.\n. If you have another issue, please create new issue. aria2 has no feature to detect spontaneous power loss.  You'd better to use shorter interval using --save-session-interval.  I think the original issue was fixed, is that correct?\n. I think there is a confusion here.  The summary that --summary-interval=0 suppresses is the download progress information which is periodically shown while download is in progress:\n*** Download Progress Summary as of Fri Apr  8 23:36:35 2016 ***               \n================================================================================\n[#647cfb 14MiB/33MiB(47%) CN:1 DL:81KiB ETA:3m16s]\nFILE: /path/to/file\n--------------------------------------------------------------------------------\nIt is not a download result at the end of the program execution.\n. My previous comment may be bogus.\nThe path to configuration file is wrong or not passed to aria2 explicitly.\nSee http://aria2.github.io/manual/en/html/aria2c.html#cmdoption--conf-path\n. The path to configuration file is wrong or not passed to aria2 explicitly.\nSee http://aria2.github.io/manual/en/html/aria2c.html#cmdoption--conf-path\n. Thank you for the PR!\n. Thank you. Looks good. Will merge after 1.22.0 is released.\n. Thank you.  Merged now.\n. input-file={directory}/input.txt\nsave-session={directory}/input.txt\nsave-session-interval=1\nYes, these are the options you are looking for.  Did that work for you?\nAs for name resolution error, this could be a system level misconfiguration, or if aria2 has async-DNS enabled, it may not work well with your system.  Try --async-dns=false.\n. Currently aria2 does not support socks.\n. Read the manual.\n. For the record, there is no -S counterpart in RPC method.\naria2.tellStatus will return some information contained in .torrent file, and the list of the files.  For those functionality, read the manual. https://aria2.github.io/manual/en/html/aria2c.html#rpc-interface\n. Fix committed via 1ce6ac0b238b653d9b49a1c9f913d08db2b74c69\n. The difference between these two is that batch call is only available to JSON-RPC, and it has slightly different request/response format.  Basically, they perform in the same way.  Personally, if JSON-RPC is used, I prefer batch method since it looks more like a JSON.\nThe documentation seems out of date now.  We penalize the failed authorization, but there is no penalty in successful one.\nUsing batch/multicall is potentially more efficient since the all requests in batch call can be sent in fewer packets, which could reduce latency.  This still holds true for WebSocket.  If you know the set of requests to send in advance, using batch/multicall is a good choice.   In general, batching multiple requests is good thing in RPC call because networking is considered as high cost operation.\n. aria2 RPC response is supposed to be non-blocking, and it means it should be done 'quickly'. If you really need super fast response for a single request, regular non-batch RPC may be faster.  But unless you pack hundreds of RPC requests in a single batch, the difference may not be noticeable.\nWith low latency, yes, there may be no difference at all.  But in these days, everyone uses mobile, right?  Probably it is not the use case of your js lib, though.\n. Try openssl instead of gnutls (pass --without-gnutls --with-openssl to configure script).  The static linker flags from gnutls pkg-config looks a bit string.\n. As suggested, try expat instead of libxml2.\n. Great!\n. Thank you for super quick update!\n. Fix committed via afccc903b9b42c657994d343026b8d1a82cd9e7a\n. Thank you for PR!   Squashed and cherry picked via af107b8.\n. Yes.  Didn't it work for you?\n. Probably, you pulled master branch from github.  If so, you have to generate configure and other scripts using autoreconf -i.\nI think it would be easier to download release source archive from release page, which includes all generated scripts.\n. @lexbrugman This bug was fixed in b76435fe779ca67d2b1cc794ebb7fafc4d0955ff.  Thank you.. Thank you for telling us.  We'll look into it.\n. It works for me at least on Linux\n04/23 17:45:42 [NOTICE] Download complete: /downloads/dir/becreated/file.saved\n. It also works for me on Windows.\n. Are you using aria2 latest version?\n. What is the expected result compared to what you actually get?\n. Thank you.  They came from the download of torrent files (e.g., https://s3-ap-northeast-1.amazonaws.com/allstars-personal/content/class/bat/eng.bat/ch1-1.bat?torrent).  But it is a bug that it shows the actual path since they are processed in memory.\nFix committed via 3c637fa\n. I tend to leave exist status code as is.  aria2 has relatively long history, so changing zero status code to nonzero may break existing third party code, and we'd like to avoid that.\n. I'd like to make this WONTFIX.  This is because if we change the device, the existing script might not work anymore.\n. Yes, we can send all stuff currently written to stdout to stderr with new --stderr option.\nBut it only happens after --stderr is parsed correctly.  Before options are parsed, still stdout is used for backward compatibility.\n. Fix committed via db239c2853cb2982260be39a521fb5672c7e8245\n. Because of the backward compatibility, we cannot change stdout to stderr to display the download result.  You may redirect stderr to stdout, and redirect stdout to file or /dev/null as a workaround.\n. We have --download-result option.  It currently accepts \"default\", and \"full\".  Perhaps, we can add \"hide\" (or something like that) to disable download result.\n. Fix committed via aa863fa4d11e93f8363e70cda0e558776485a7b9\n. Please check out #644 \nIt still first pauses the download, and then restart it, but it can be completely automated.\nThe restart is automatically done if aria2.changeOption includes options which are previously only applicable to the waiting or paused downloads.\n. No additional settings are required to enable this feature.\n. There is some delay before the restart since aria2 may have to contact a bittorrent tracker. It might be good to add option to faster restart.  The default should be conservative.\n. I tested it with aria2rpc cli script. It is found under doc/xmlrpc directory.\n. I merged master to #644 \n. It would be better to ask YAAW dev for this.\n. Closing since the feature has been implemented and will be available in 1.24.0.\n. Thank you!  Merged now.\n. Fixed in e174b90\n. 1.23.0 was released just now!\n. This probably suggests that C++ compiler is a bit old.  aria2 requires at least gcc >= 4.8.3 or clang >= 3.4.\n. Merged now.  Thank you for PR!\n. Thank you!  Merged now.\n. Thank you for the PR.  Unfortunately this would be WONTFIX.  We think 16 limit is already plenty.  128 is too much, and it could overload the remote server, and having too many tcp connection had detrimental effect.\n. I meant latter, but if lots of people use many parallel connections, it would become a DOS.\nIf server operator found that this is done by aria2, they might ban aria2.  You can still fake UA, but it is not desirable outcome.  We have to consider the case where many people uses 128 connections to one server.  It may easily surpass the limit of one server if user is large.  Many people use aria2 through frontend UI, and they tend to ignore warnings, they are most likely useless.  I think we should not increase number of parallel connections.\n. It could be an option, but at the moment we leave the limit as is.  This is the consistent answer from our side in the past few years when we get similar question.  We might revisit this in the future.\n. At the moment, we have --rpc-save-upload-metadata option not to save these files, but there is no dedicated option to remove them.\n. > I was able to arrive at the same filename by applying hash1 to the original torrent file. Maybe it would make sense to add the name of the metafile into the output of the RPC call?\nI'm not sure what you really meant here.  Could you describe this in detail?\n\nAlso, I've been able to compile aria successfully but the binary is rather large (~80M) statically or dynamically built.\n\nDid you run strip command to remove debug symbols?\n. Thank you for the reply.  Now I understand it.\nIf you are installing aria2 using make install, run make install-strip instead.\n. Thank you for reporting this issue.  Is there any easy reproduction step for it?\n. debug level log may help.  Thank you.\n. Also, could you tell us the platform you experience this issue, and additionally compiler and standard c++ library which you compiled aria2 with if you built it by yourself?\n. I heard that Windows API suffers from short PATH_MAX problem (around 260 characters), but usually Linux platform has much longer limit, usually PATH_MAX is defined as 4096.\n. When I designed this, I didn't expect large number of BitTorrent downloads.\nIt is probably better to use more concurrency here.\n. This defines concurrency of DHT task:\nhttps://github.com/aria2/aria2/blob/566cac5023b665662d69a8840a3bb22fa8626f1e/src/DHTTaskQueueImpl.cc#L43\nIf you are building aria2 from source code, change this value to something larger, and play around it.  If it works, then we will increase that value in the 1.24.0 release.\n. It is normal.  DHT continues to communicate the peer even after torrent downloads finish.  In general, DHT is another layer of overlay network.\n. Increased concurrency to 15 in 9486663.  Thank you!\n. It works for me on Linux.\nWhat kind of error did you get?\nHTTP request in aria2 log may help debugging.\n. Thank you for heads up.  Closing.\n. Thank you for reporting this issue.  Looks like chrome puts subsecond time in expires date, and aria2 does not understand it.\n. Fix committed via bafbbe7\n. We are doing it already: http://aria2.github.io/manual/en/html/aria2c.html#aria2-conf\n. Confirmed.  It looks like we have to gain privilege before opening file.\n949a580a14cd3afcdf9904acd1d32397c344dd28 will fix this issue.\nBecause of --no-file-allocation-limit option, by default, file of less than 5 MiB does not trigger file allocation, so there is no warning.\n. Please reopen this bug if you still have this issue.\n. Sadly, answers are all NO.\n. The closest thing I can think of is that you can manually change the order of downloads waiting in the queue using aria2.changePosition RPC method.  http://aria2.github.io/manual/en/html/aria2c.html#aria2.changePosition\n. Please ask Web UI developers about this.\n. According to the commit log, this is intentional:\n\n2006-08-12  Tatsuhiro Tsujikawa \nTo handle the case where some BitTorrent tracker requires all letters  except for [A-Za-z0-9] is URL encoded.\n\nPerhaps, torrent tracker is now more matured, and we don't have to do this trick.  Have you seen any problem with this eagerly percent-encoded form?\n. As far as I know, in olden days, bittorrent tracker's HTTP implementation is broken at best.\nWe'd like to correct our implementation based on HTTP, so we'll do this in standard way, and see how it breaks.\n. Fix committed via c57259f\n. Have you installed pkg-config package?  If not, first install it, and then run autoreconf -i again.\n. It looks like gcc is too old to compile aria2.  It requires at least gcc >= 4.8.3 or clang >= 3.5.\n. Thank you for the PR.  Could you check my comment?\n. Thank you!  Merged now.\n. >  what tool I should use to generate the .torrent file and if it is really needed. (why do I need one at all?)\naria2 could not create .torrent file.  You need other program, say, btmakemetafile, to create .torrent file.  In DHT, we don't use tracker.  You can just pass fake tracker URI.  aria2 may complain about it, but it can be safely ignored.  If you really don't want this error, use --bt-exclude-tracker='*'\u200b\nIn DHT, only seeder requires .torrent file.  Clients can use magnet URI to pull the data.  You can see the magnet URI by running aria2c  -S /path/to/torrent.file.\n\nI was not able to understand why the -V option should be used on the seeder process.\n\nTo seed files, aria2 first make sure that it is not broken.  -V option checks piece hashes of a file against the hashes described in .torrent file.\nIf you are sure that file is OK, then you can use --bt-seed-unverified instead of -V to speed up the start up time.\n. I made an important fix to make DHT work in private network: 3e00be26e8f8fe44c7344a3e8026031a99b22400\n. It works for me.  Check the patch is correct, and options are correctly written in the file.  Make sure that options are not really loaded.  Some options are very subtle, and you may not notice the change they produce.\n. If you are going to update OSX build, please consider to upgrade expat version to 2.1.1. http://expat.sourceforge.net/\n. Are you using slow device to save files, like SD card?  aria2 requires faster storage for faster speed.\nIn my case, 8MiB/s is achieved without a problem on my desktop with SATA HDD.\n. 66MiB memory at start up is a bit large to me.  Are you downloading more than 3 items?\nFor embedded devices, it would be better to use --disk-cache=0 to save memory usage.\nThe memory usage on OpenWRT is known issue, and we have no idea why it consumes such a large memory at the moment.\nIt may be related to the heap fragmentation.  In that case, using jemalloc may remedy this situation.\nTo build aria2 with jemalloc, install jemalloc development package, and run ./configure --with-jemalloc, and run make.\n\nI added two BitTorrent task, my 'bt - Max - open - files' option is 1, but this two tasks at the same time in the download, why?\n\nWhen writing data to a file, aria2 closes the other to keep the number of open file descriptors at the same time less than or equal to 1.\n. Yes, metadata is downloaded again.  Do you have a problem on restarting downloads?\n. Check out http://aria2.github.io/manual/en/html/aria2c.html#cmdoption--on-download-complete\naria2 does not support socks5 at the moment.  There are some software to replace regular socket functions with socks5 aware ones to transparently enable socks on the fly.  I don't use them these days, so I'm not sure it still works.\n. It works for me.  Did you mean --summary-interval?\n. It is not download result.  The download result is shown when aria2 exits.\n. aria2 1.24.0 released just now.\n. Thank you for PR!  Merged.\n. Thank you for PR.  Merged.  Sorry for the late response.\n. We changed URI since they are different.\nPerhaps, you can parameterize the build as well as version number?\n. Do you have lots of concurrent downloads?  It looks like the aria2 process ran out of file descriptor (sockets + opened file), which is capped by 1024.  Try to reduce the number of downloads.\n. The next version, v1.24.0 is released today, and we'd like to avoid last minutes change.\nIf you can build aria2, try increase value of FD_SETSIZE macro:\nhttps://github.com/aria2/aria2/blob/09e7cfc4c088b239050ca8ec1a8da18e208ae669/src/common.h#L61\n. Based on what?\nFD_SETSIZE is compile time constant.  You cannot change it in runtime.\n. We use epoll for Linux, which is not limited by 1024 file descriptor.\nWe have Dockerfile.mingw to compile windows binary.  It clones master branch, so you have to change it to your copy to include the change.\n. I made a commit to increase FD_SETSIZE to 32768.\nNow you can build aria2c windows binary using our stock Dockerfile.mingw.\nPlease test the build and see that it does not show the error message you encountered before.\n. Thank you.  I think this issue has been fixed.\n. Make sure that port forwarding is done for both UDP and TCP to aria2 through firewall since aria2 does not have capability such as upnp.\nThe above log suggests that no tracker URI is found.  If torrent only contains udp tracker, you have to wait for DHT to look up for peers.  udp tracker support has been added since v1.16.4.\n. Can you provide aria2 log file for both seed and peer?\nIt seems they can find each other, but metadata is not transferred for some reason.\n. Thank you.  The log helps us a lot.\nIt turns out that aria2 only allowed 1MiB metadata.  Your metadata for large case exceeded that limit.\nWith f6f672f, we've increased the maximum metadata size.  It should work now.\n. This is related to --max-download-result option.\nhttp://aria2.github.io/manual/en/html/aria2c.html#cmdoption--max-download-result\naria2 keeps all completed/failed downloads in the memory, and saves it as session file.  By default, aria2 remembers 1000 latest downloads.  If the limit reached, the oldest entry is removed.  This means that failed download is kicked from memory if the number of downloads is larger than the limit.  In your case, you have more than 70,000 downloads, and if these FTP downloads are not in the last 1000 downloads, they are just gone, and not saved in the session file.  The purpose of --max-download-result is reduce memory usage.  I suggest to increase the limit using that option.\nIt might be better to add new functionality to keep failed downloads in memory regardless of --max-download-result to save them in session file.\n. 55f311a adds --keep-unfinished-download-result to keep unfinished download in memory, and they are saved in --save-session.\n. From the point of user, yeah, you are right.  Error downloads should be kept by default.\nStill I'm concerned unbounded memory, so I'd like to leave --keep-unfinished-download-result option.\nPerhaps, we should mention this in --max-download-result option.\n. I say unbounded because we have RPC mode.  User can throw any number of downloads to it.\n. ae78d7f enables --keep-unfinished-download result by default.\n. Thank you.  Fix committed via 1e59e35\n. It is by design.  -o is always relative to the directory given in --dir.  We'll add new some text to manual page to describe this.\n. Thank you for comments.  Due to task management for upcoming v1.25.0, I keep open this issue until we document the current behaviour of --out and -d option.\n. Fix committed via 2365c91\n. There is no way to do that.\n. I make 2 commits to try to fix this issue.\nIt is still strange since timeout should be triggered where there is no network activity.\n. Thank you for confirmation.  Let's close the issue.\n. I have no idea about openwrt stuff.  Please ask openwrt developer.\n. metaurl element should have name attribute which includes a path inside torrent for a file.\nSee https://tools.ietf.org/html/rfc5854#section-4.2.8.3\n. Ah, finally I understand this issue.  So you want to describe same content under the different name using same torrent.  Unfortunately, aria2 does not support it.\n. Is there no log between 02:04:28 - 02:04:57?  I'm interested in the operation started in aria2 when it entering to that period.\nYou mentioned traffic shape set for 475mbps.  Is it done by router or aria2 option (--max-download-limit)?\nDue to aria2's architecture limitation, lacking 1 or 2 seconds of debug level logging is normal.  But lacking more than 10 seconds is suspicious.\n. Thank you for the data.\nThe debug log is indeed interesting.  It says it took nearly 16 seconds to write 16KiB data into disk.\nI'm wondering it has to do with btrfs.  I have not used it, so not sure what it looks like, but have you heard that it is not suitable for this disk heavy application?\n. I think yes.  I assume that MacBook Pro 15, which is not suffered from this issue does not use btrfs.  Is that  correct?\n. I have no idea of the mechanism of btrfs.  For aria2 part, it does not depend on specific file system when it writes something to a disk.  It just use write(2) system call.\nThere are some Apple specific I/O code in aria2.\n- https://github.com/aria2/aria2/blob/9cee162716d0be894e1b87fad78e9737e30356ed/src/AbstractDiskWriter.cc#L227\n- https://github.com/aria2/aria2/blob/9cee162716d0be894e1b87fad78e9737e30356ed/src/AbstractDiskWriter.cc#L519\nThe latter is called when --file-allocation=falloc is used.  I'm not saying these are the cause of the problem, but just shed a light on the Apple specific code which might affect the behaviour.\n. If I understand correctly, growing memory is used for file caches, and not memory aria2 directory allocated for its use, right?\nI thought that those cached memory is managed kernel, and if additional memory is required, kernel is just reuse that inactive memory.\n. Are you using asynchronous DNS (--async-dns=true) ?  If not, aria2 uses blocking version of DNS, which may take long time before it failed.  In this case, no timeout is configured for DNS.\n. It means that it lacks asynchronous DNS support.\nTry to build aria2 with c-ares library.\n. You should use async-dns=true to avoid blocking.\n2016/06/28 7:17 \"Sepehr Mohaghegh\" notifications@github.com:\n\nClosed #691 https://github.com/aria2/aria2/issues/691.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/691#event-705607486, or mute the\nthread\nhttps://github.com/notifications/unsubscribe/AAYsgl3PRg5BYXTaaeUPWlE4cEQzQFiNks5qQEvpgaJpZM4I-i0u\n.\n. I don't know about your TV.  But by default, aria2 RPC only listens for local address.  To accept connections from another PCs, use --rpc-listen-all option.\n. Please ask android application developer how to use the app.\nI haven't used that app, and have no idea about its directory structure, and where it installs aria2c.\n. Thank you.  Merged now.\n. Does 1.24.0 Mac OS X build fix this issue?\n. I can share your concern, but there is no known conversion between yaml/json and Metalink XML.\n\nIf you just want to get rid of manual editing of XML, there are several Metalink editor projects: https://github.com/metalink-dev\n. Fix committed via 295affe\nNow it should start up normally without --disable-ipv6 option.\n. At the moment, we have no plan to add another protocol.\n. Thank you for telling us.\nFix committed via a9fe783\n. This is most likely because your system does not enable multicast.\nSee #528 for relevant issue.\n. 1.25.0 was released just now https://github.com/aria2/aria2/releases/tag/release-1.25.0\n. Thank you for the PR.  Since we are in feature/documentation freeze period for upcoming release, we will discuss this after that.\n. Merged with some adjustment.  Thank you!\n. Thank you all.  Let's close the issue.\n. Thank you.  I made a commit as you suggested.  See 3220989f56818a4aa949a026453b3b7bd97c9ca9\n. Which version did you use when this happened?\n. Thank you.\nUnfortunately, windbg cannot accept debug symbols compiled with gcc -g, so we don't know where the program crashed.\nIf this is a frequent crash, we expect more bug report (possibly, from other platform if it is not specific to Windows build).\n. Thank you.  If the crash frequently occurs, could you run aria2 1.25.0 with debug logging on (-l option)?  We still don't have stack trace, but we have at least the last log message just before the crash.\n. Thank you for the log.  I found that interesting pattern in the log:\nWe normally see:\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskQueueImpl.cc:57] Updating periodicTaskQueue1\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskExecutor.cc:77] Executing 15 Task(s). Queue has 19 task(s).\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskQueueImpl.cc:59] Updating periodicTaskQueue2\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskExecutor.cc:77] Executing 7 Task(s). Queue has 0 task(s).\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskQueueImpl.cc:61] Updating immediateTaskQueue\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskExecutor.cc:77] Executing 1 Task(s). Queue has 0 task(s).\nBut the last log is:\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskQueueImpl.cc:57] Updating periodicTaskQueue1\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskExecutor.cc:77] Executing 15 Task(s). Queue has 19 task(s).\n2016-07-28 13:11:53.846063 [DEBUG] [DHTTaskQueueImpl.cc:59] Updating periodicTaskQueue2\nSo it looks like aria2 crashed while executing some task in periodicTaskQueue2.\n. At the moment, it is a bit hard for us to debug on Windows.\nI am wondering if the crash is still observed without optimize-concurrent-downloads option.  Have you seen crash without optimize-concurrent-downloads option?\n. Thank you.\nWe uploaded aria2c windows x64 binary with debug symbol attached.\n aria2-1.25.0-win-64bit-build1-debug.zip in https://github.com/aria2/aria2/releases/tag/release-1.25.0\nHope that it can produce more meaningful stack trace in dump file.\n. Thank you for updates!\n. Thank you.  This could be a platform dependent problem, but actually I have no idea.\nPlease use aria2 in a way whatever you like, and if you encounter the bug again, please let us know.\n. I got crash in the similar location.  8cdcb71308b79719d5834b485392558d7cdfab77 may fix this bug.\n. Thank you for PR.\nI think we should do this from the beginning.  The preservation of extension is nice especially, for torrent or metalink files, and server does not send correct content-type.\nSince we have had the current renaming scheme for many years, I'm wondering changing renaming method could potentially affect the user application code, say, a script which expects the certain renaming method.\nWhat do you think about this?  Should we care about it?  Or just add new flag to change behaviour?\n. Fair enough.  Let's do this and let's see the response from users.\nPlease merge this PR when you are ready.\n. Have you checked that it speeds up build?\n. Sounds good.\n. No objection, of course.\nThis is great for those who don't have Mac OS X development environment.  We have hard time to edit Mac OS X specific code since we don't have compilers for it.\n. Thank you for PR.  Looks good.\n. If I understand correctly, you want new RPC method to send back a client that option definitions which describes which value or type option takes, say, boolean, or multi-value, right?\nAnd now you are doing this by parsing documentation, but you think it is not good enough?\n. By the way, we have https://github.com/aria2/aria2/blob/master/doc/bash_completion/make_bash_completion.py to generate bash completion from aria2c --help#all, and there we handles options which takes multiple-choices, and boolean values.\n. Yes.\nStill you can do similar things to automatically generate your source code.\n. There is no notification when item is added to waiting list.\nkeys is array of top level name contained in aria2.tellStatus reply.  You can add all names that you want in a response.  So if you don't want urls, and add all names you want in keys other than files.\n. duplicate of #716, closing\n. min-split-size=50M means aria2 only splits file more than 50MiB.  Have you tried to decrease that option value?\n. Thank you.  Are you writing debug level log?  Disabling log or decreasing log verbosity (--log-level option) could improve performance.\n. Merged.  Thank you!\n. load-cookies cannot be used in RPC call.  The workaround is directly passing cookie header field using --header option.\n. Assuming you know how to set option in RPC method, I'll show how to use --header option for cookies.\n--header option takes a form \": \", where  is a HTTP header field name, and  is its value.  For cookies,  is \"cookie\", and value is value of cookie, which depends on your real cookie value.  For example, to send cookie, named as \"foo\", and its value \"bar\", do this:\n--header \"foo: bar\"\n. Sanitized cookie value just in case.\nProbably it has missing cookie values or expired, but I'm not sure since it is application specific.\n. Thank you!  Merged now.\n. 1.26.0 released just now.\n. Yes, if you mean BT seeder by BT upload.\nBut you can use --bt-detach-seed-only to exclude seed only item from max number of concurrent download.\n. Thank you for PR.\nI confirm that the current position is wrong.  And I think the correct position is under --file-allocation option.  Could you make this change?  It is fine for us to do it ourselves.\nThe translated versions are maintained by collaborators, and normally we just edit English version only.\n. Thank you. LGTM!\n. Thank you! Merged now.\n. RPC is disabled by default.  If you find RPC is enabled by aria2c for some reason, use --enable-rpc=false to disable it explicitly.\n. Thank you for reporting this issue.\nFix committed via  65b7205dfdc182a0d6a694547b2d5710dfd7466d\n. Reverted the above commit, and fixed it in another way to leave assertion there.  See 7a31f9bf29c6b89aed2a216d0159d6f43369e8a2\n. Try --force-save option\n. Do you mean \"host\" is included in magnet link?  I don't know about such parameter.\n. Ah, so you argues that aria2 discards all peers after bittorrent metadata is downloaded, and then contact tracker again to download content described in bittorrent metadata.\nYes, it is how aria2 performs right now because of architectural limitation.\nIt would be good enhancement.\n. If I understand it correctly, \"records\" mean *.aria2 file, and you suggest that it is better to add a RPC method to delete downloaded files.  Am I correct?\n. We have decided not to increase this value.  There are several request for this, but we rejected them all.\nWe have Dockerfile for mingw build.  You can edit it so that automade build process.\n. There is a reason we don't do this.  aria2 can download a file from multiple locations.  If some server returns 408, and some server doesn't, then it corrupts file.  For this reason, aria2's ability to become Swiss army knife tool like curl is not feasible.\n. aria2 can compile with OpenSSL 1.1.0 just fine.\n. Agreed.\n. @nmaier Could you review this PR?\n. Green light.  No objection from me.\n. Thank you!  Merged now\n. Thank you!  Merged now.\n. Thank you for PR!  Merged now.\n. aria2 1.27.0 was released just now.\n. By default, BitTorrent download stays until its share ratio reaches 1.0.  It is counted toward concurrency limit.  You can change share ratio by --seed-ratio or --seed-time, or perhaps, --bt-detach-seed-only\n. What is the expect result, and what did you got instead?\n. As far as I've tested, aria2 correctly sends peer ID based on --peer-id-prefix.\n. Adding another backend increases maintenance cost. Perhaps, we need to know how much mbed TLS cuts footprint against OpenSSL and GNUTLS builds to justify the benefits outweigh the added cost.\n. --allow-overwrite, perhaps?\n. I'm ok to add NOTICE level logging for file name.\nThe above image looks a bit strange, since file name is missing after \"Downlaod has already completed:\" and \"Download complete:\".\n. It looks like a bug that file name is missing in these logs.\n. Fix committed via a31e73d\n. I was a bit confused, but I think the above commit fixes this issue.\n. Currently, there is no such feature in aria2.\n. Thank you for clarifying.\n. Thank you for letting us know.  Will fix them up.\n. 1.27.1 fixes this issue.\n. Fix committed via e31f537\n. Did you check HTTP request path and header fields?  Are they correctly formatted?\n. Thank you for PR.  Merged now.\n. Thank you for PR!  Merged.\n. @nmaier Are you interested in this?\n. The control file does not contain URI, and aria2 just matches file name, so you can use different URI without problem.\n. v1.28.0 has been released.\n. Thank you. Closing the issue.. I don't have Android 6.0.1, but it sounds like the process which aria2 started has no permission to create file on external drive.  If that is correct, this is not aria2 issue, and I have no idea how to fix it.\n. The permission denied error is usually caused by the lack of permission of aria2 process.  Imagine that a process without root permission tries to create a directory which requires root permission.  It surely fails.  This kind of issue is not from aria2 itself.  Rather, it is how aria2 is invoked on a device.\nWe are maintaining aria2, and distributes android binary, but it is just a C program.  And we don't develop any kind of Apps which runs on Android device, and invokes aria2c.  If the App does not have necessary permission to create directly, then its child process aria2c cannot too.  I don't know how you run aria2c on your device.  Are you using those kind of App?  If it works on the older Android, then Android 6 has changed something? But I don't know much about Android development, and also don't own newer Android device, I really don't know what has changed since then.\n. How do you send PING frame?  As far as I know, no browser allows user to send WebSocket PING frame.  I'm talking about PING frame described in RFC 6455 https://tools.ietf.org/html/rfc6455#section-5.5.2\n. I haven't used that library, but did you send PING using like so:\njava\n// Send a ping frame.\nws.sendPing(\"Are you there?\");\n. Thank you.  I send suggested 6 bytes to aria2, but it responds Pong frame as expected.  In other words, aria2 correctly identified Ping frame, and responded Pong frame.  It didn't treat it as RPC request.  Could you confirm that WebSocket handshake is correctly made?\n. I sent Ping frame to aria2, but I haven't got any error message.\nMake sure that you only sent Ping frame.\n. I sent Ping frame using wslay library https://tatsuhiro-t.github.io/wslay/index.html\n. Can you confirm that without encryption, aria2 does not freeze?\n. I successfully reproduced this issue with pkcs12 file and on Windows 10 64bit.  aria2 is v1.28.0 64bit binary.\n2016-11-08 23:06:21.062066 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 4 buffered: 0\n2016-11-08 23:06:21.065100 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 3596 buffered: 0\n2016-11-08 23:06:21.067739 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 3596 buffered: 0\n2016-11-08 23:06:22.064622 [DEBUG] [WinTLSSession.cc:432] WinTLS: Read request: 4096 buffered: 0\n2016-11-08 23:06:22.080217 [INFO] [rpc_helper.cc:103] Executing RPC method system.multicall\n2016-11-08 23:06:22.083612 [DEBUG] [WinTLSSession.cc:432] WinTLS: Read request: 4096 buffered: 0\n2016-11-08 23:06:22.085617 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 4 buffered: 0\n2016-11-08 23:06:22.088624 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 4 buffered: 0\n2016-11-08 23:06:22.090629 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 3596 buffered: 0\n2016-11-08 23:06:22.091632 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 3596 buffered: 0\n2016-11-08 23:06:23.094939 [DEBUG] [WinTLSSession.cc:432] WinTLS: Read request: 4096 buffered: 0\n2016-11-08 23:06:23.096912 [DEBUG] [WinTLSSession.cc:432] WinTLS: Read request: 4096 buffered: 0\n2016-11-08 23:06:23.096912 [INFO] [rpc_helper.cc:103] Executing RPC method system.multicall\n2016-11-08 23:06:23.098918 [DEBUG] [WinTLSSession.cc:432] WinTLS: Read request: 4096 buffered: 0\n2016-11-08 23:06:23.099920 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 4 buffered: 0\n2016-11-08 23:06:23.100928 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 4 buffered: 0\n2016-11-08 23:06:23.100928 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 3596 buffered: 0\n2016-11-08 23:06:23.101939 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 3596 buffered: 0\n2016-11-08 23:06:23.148049 [DEBUG] [WinTLSSession.cc:432] WinTLS: Read request: 4096 buffered: 0\n2016-11-08 23:06:23.149051 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 2 buffered: 0\n2016-11-08 23:06:23.149051 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 2 buffered: 0\n2016-11-08 23:06:23.149051 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 2 buffered: 0\n2016-11-08 23:06:23.150055 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 2 buffered: 0\n2016-11-08 23:06:23.150055 [DEBUG] [WebSocketSessionMan.cc:64] WebSocket session removed.\n2016-11-08 23:06:23.150055 [DEBUG] [WinTLSSession.cc:190] WinTLS: Closing connection\n2016-11-08 23:06:23.150055 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 31 buffered: 0\naria2 froze after the log.  No more additional logging.  Ctrl-C did not work.  Closing browser didn\u2019t help.\n@nmaier Do you have any insight about this?\n. I got another suspicious log.  This might not be related to this issue directly.\n2016-11-08 23:02:13.370176 [DEBUG] [WinTLSSession.cc:493] WinTLS: Connection abruptly closed!\n2016-11-08 23:02:13.370176 [DEBUG] [WinTLSSession.cc:190] WinTLS: Closing connection\n2016-11-08 23:02:13.370176 [DEBUG] [WinTLSSession.cc:284] WinTLS: Write request: 31 buffered: 0\n2016-11-08 23:02:13.370176 [DEBUG] [WinTLSSession.cc:422] WinTLS: Write result: 31 buffered: 0\n2016-11-08 23:02:13.370176 [DEBUG] [WinTLSSession.cc:242] WinTLS: Closed Connection\n2016-11-08 23:02:13.370176 [INFO] [HttpServerCommand.cc:275] CUID#23 - Error occurred while reading HTTP request\nException: [HttpServer.cc:180] errorCode=1 Got EOF from peer.\n2016-11-08 23:02:13.370176 [DEBUG] [WinTLSSession.cc:185] WinTLS: Cannot close connection\n. I fixed this issue with commit d289dc1108324ff5589ab103ef0863faaa3c5de1\n. This will be merged in 1.30.0.   We have fixed WinTLS issue in upcoming 1.29.0.  We'd like to see the bug is really fixed in the 1.29.0.\n. Thank you for PR.  It looks good to me. We will merge this PR after v1.29.0 is released.\n. Which OS are you running aria2 on?\nPerhaps, --async-dns=false may workaround the issue.\n. I've heard this issue for quite some time, and still hasn't figured out the cause.  It may depend on c-ares version.  I suspect that it might not support advanced configurations in /etc/resolv.conf.. @alexanderadam \nI have similar /etc/resolv.conf in my fully updated Ubuntu 17.04.\nAnd aria2c works with libc-ares2 on it perfectly.\nDo you have any special DNS configuration?. No.  My setup is pretty simple, and it only has dnsmasq-base, which merely just does DHCP stuff.\nI'll test aria2c with dnsmasq installed.. libaria2 is not thread safe. You have to use it from a single thread at a time.\n. Documented that libaria2 is not thread safe via commit 9d58ad912a8da9e25725d053598c8f5fdf76e41b\n. I think almost all network applications ignore SIGPIPE.  So, yes, you should ignore it.\n. Could you give us the output of aria2c -v?. Both of you have missing HTTPS support.\nAssuming you are using Linux, you need to install gnutls or openssl to enable HTTPS support.\nWe documented required libraries at https://aria2.github.io/manual/en/html/README.html#how-to-build. Easiest way to install aria2 is package offered by Linux distribution.\nHave you built aria2 by yourself?  Or did you install aria2 from package?\nFor Ubuntu or Debian, apt-get install aria2 will install HTTPS enabled aria2.\nI don't know much about other Linux distribution.\n. Yeah, this is known issue.  The variable substitution is done by shell, not aria2c.\nPerhaps, you can use sed to substitute $HOME first?\nProbably, the best way to fix this is let aria2 expand the variables using wordexp library function, with new switch to turn it on.\n. PR #782 only expands ${HOME} to user's directory.  It fixes this issue.. It works for me.  What kind of error did you get?. The error means that aria2 could not verify server's certificate.\nAre you using aria2 on Linux?  If so, try --ca-certificate /etc/ssl/certs/ca-certificates.crt. --ca-certificate, not -ca-certificate. Looks like your system does not have the file.\n\nhow about adding option similar to wget, \"--no-check-certificate\" ?\n\naria2 already has one: --check-certificate=false\nBut this is a last resort, since this is insecure.  Perhaps, it would be better to ask router OS (openwrt?) developer or community that where the CA certificate file is.. Well, aria2 help system actually suggested the option.... -o option does not work with -i option.\nAnd aria2 does have a feature to save into single file, cause it could destroy the content with multiple write.. Because aria2 does not necessarily write files from front.. It works for me: echo \"http://localhost\" | aria2c -i-. That is interesting.  Some OS does not have /dev/stdin.  Android is one of them.. We use /dev/stdin (and con for windows) explicitly in the source code, which causes this issue.  Using libc stdin could solve this issue.\n. Thank you!  Merged now.. Use \"tr=\" instead of \"tr.N=\"\n. Usually, it means that client does not submit correct username/password, and/or RPC secret.. Is the file size 1713860608 correct?\nSometimes server does not send content-length with ranged request.\nWhat are the actual request header and response header?\n. Without actual .aria2 file, I have no idea what happened then.\nIn some cases, dynamically generated files cannot be resumed.\n. See #779. aria2 creates a file whose name is the same as the file you are downloading and has a suffix \".aria2\" (e.g., foo.txt.aria2).  It is called control file.\nIt contains all information to resume download.  Note that control file must exist in the same directory with the downloading file.. When you hit ctrl-C while downloading is still in progress, aria2 leaves control file.  Running the same command line, aria2 starts resuming last download.. Changing tracker is no problem as long as the info hash stays the same.\n. https://aria2.github.io/manual/en/html/technical-notes.html describes the format of .aria2 control file.\nOnce the info hash is obtained, then creating magnet link is easy.. If you are using --dht-entry-point option or torrent file which includes nodes data, then #794 fixes this issue.\n. Could you tell us how to reproduce this issue, including aria2 version, logs (-l option), and exact command line options?. From the log, it looks like seeder did not send \"unchoke\" message to aria2, and it was unable to request any piece. Do you constrain the number of concurrent peer or similar limit to transmission server?. aria2 will download file if peer allows aria2 to pull pieces.  There is no limitation in aria2 side.\nWhat will happen if transmission server is replaced with other BitTorrent client?. BitTorrent code has not changed much since v1.27.0.  I'm interested in what's happening when download stuck.  Could you capture aria2 log when it occurs?\n. Thank you.  Agreed that it can pause aria2c.  Let's close the issue.. Nice!. We need more information to figure out what is going on.\nSo what error did you get when you ran aria2 by non-root user?\nWhen aria2 is invoked with --enable-rpc, usually it does not \"anything\".  When you add URI to it via RPC, it then starts downloading it.\nNot sure what you expected instead when \"nothing is happened\".. Thank you.  So it is really nothing.  I'm afraid that I have no idea what happened without no information. Build problem, perhaps?. @nmaier Could you work on this issue?. Thank you.  Yeah, we are still living in 70s for such an area.. @qwe14789cn How do you want to see the remaining capacity of disk space?  Could you elaborate the use case?. @qwe14789cn thank you.  We have PR in #807, and there are several ways to achieve this.\n\"dir\" in aria2.conf can be overridden by individual dir option, so just returning capacity of directory in aria2.conf is not good enough.\nPerhaps, querying aria2 by sending specific path may be a good compromise to fit into most of case.\nOr returning all drives disk capacity may still be an option (could be overkill).\ncc @nmaier . You can pass proxy related options to addUri options parameter.  See https://aria2.github.io/manual/en/html/aria2c.html#cmdoption--all-proxy. We rewrote configure script to use pkg-config to detect some libraries.  They may wrongly find native libraries, and pull those linker paths.\nThe affected libraries are:\n\ncppunit\nlibxml2\nlibexpat\nlibnettle\n\nYou configuration rules out libexpat and libnettle.\nSetting PKG_CONFIG_PATH to the cross compiled library path might solve the issue.\n. It works for me.  Which version of aria2 are you using?. I think this is caused by older C++ compiler.\nWe used to require gcc 4.8.3 or clang-3.5, but recent changes may require more recent ones.\nWhich version of compiler are you using?. You have to undoing 366e2e8f795e82e2c8472bcf1cd0a892550789a9\nThat is basically replace \"= default\" with \"{}\".. Thank you for making PR quickly!\nI imagined that the information user expected is file system disk space usage returned by df command, that is the space available on all currently mounted file system, rather than per given directory.\nIt is most likely that we will inspect the free space before download, so returning free space per gid might be a bit hard to use.. Passing arbitrary path is possibly a way, but user has first choose the directory without no information about disk space.  Showing free disk space for mounted volumes gives that ability to users.  But I have to agree that it might have too much information.\nLet's hear the reporter about what they think reasonable.\n. > However, passing the API a path might be an idea. That way a RPC-based UI can check or display the disk space before adding a download.\nThe reporter indicated this.\n. At the moment, aria2 uses one proxy server per download.  If proxy server issues backend connection using different source address, it can achieve the same goal.. OK, let's close the issue.. If I understand correctly, you tried building aria2 on Mac OS.  This error probably means that header files for libxml2 is not installed in the standard directory.  There is many ways to specify the custom directory (e.g., CPPFLAGS), we have Mac OS X binary in this gihub release page.  Have you tried that?. What kind of error did aria2 daemon actually report?. Issue should be written in English, thereby I close those issues not written in English unconditionally.\n. > BTW, utf8dfa is actually not used correctly there,\nNice catch.  Will fix later.\n. Issue should be written in English, thereby I close those issues not written in English unconditionally.\n. Closing since this seems to be the issue for the another project.. Thank you for PR.  Now I am reviewing this.. Cherry picked with some amends via b9e51e9b1509f2d7d379608755fa0503ee7a64d1.  Thank you!. Is that mean aria2 tried 100 times, and server responded 404 100 times?. You can inspect how many times aria2 issued HTTP request using --log option.. It is 400 Bad Request, and not 404 Not Found.  In general, 400 Bad Request means that something is wrong in request, and cannot be corrected by just retrying it many times.  Therefore, aria2 does not retry the request in this case.. It depends on the service you requested (in this case baidu).  There is no generic answer for that question.. I've never used baidu before, so absolutely no idea at all.. It looks like you have found the workaround. Closing this issue.. That is true that I have listed several webui on aria2 web site, but now I lean not to add another, since it will end up any project without proper evaluation.  Please do some other routes to advertise your work.. I haven't heard the way to perform BitTorrend download through http proxy.  Is that wildly used practice?  Can you change ISP?. Related issue: https://github.com/aria2/aria2/issues/153. Thank you!  Merged now.. aria2 has -P option, which has limited capability to parameterize (wildcard) URI, but in general, it does not have the ability to download all files under the certain directory.\n\nP.S. BTW, Aria normally recognizes only Github links preceded with raw (https://raw.githubusercontent.com),...\n\naria2 downloads the response body the server sends.  Some server performs special handling depend on specific user agent (e.g., wget).  Not sure how github does in this case.. It looks like PKG_PROG_PKG_CONFIG macro is missing.  Usually, it is installed with pkg-config.  Not sure how you installed it.\nBTW, you can download aria2 tar ball or even Mac OS X binary from release page.  Then you don't have to worry about this issue.. max-concurrent-downloads limits the number of concurrent download item.  split and min-split-size functions inside the item.  Imagine that you have input file (see -i option) like this:\nhttp://example.com/foo\nhttp://example.com/bar\nHere is 2 download items.  aria2 can download these items concurrently, and the number of the concurrency is controlled by max-concurrent-downloads.  OTOH, in each download item, you can configure the number of connections using split or min-split-size, etc.\n. That said, I found that current max-concurrent-downloads is a bit ambiguous.  Since we are in documentation freeze period for the next release, we will handle it after next release.. Thank you.  #836 fixes error message issue.\n. Yes, you can do polling to get the progress of downloads.  Use aria2.tellStatus or aria2.tellActive.. Those methods can be used with WebSocket.  Is that the answer you expected?. WebSocket can push events such as download start, stop, etc but not progress (e.g., completed N%).\nPlease read the manual http://aria2.github.io/manual/en/html/aria2c.html#json-rpc-over-websocket. If I understand your comment correctly, you'd like to say that progress push notification can cover the features that current event notification methods.  That's probably true for your use case.  Current push notifications are not useless, they have their own purposes, and besides that we don't have progress notification now.\n. HTTP status code is 403.  It usually means that server refused to access the requested resource.  Can you download the same file using wget, and browser?  Does it require authentication?. OK, close now.. I'm not familiar with RedHat, doesn't it have certificates under /etc/ssl/certs?  Or another place?. Somehow aria2 is configured to load  /etc/ssl/certs/ca-certificates.crt.\nYou can pass --ca-certificate option to read CA files from different path.\nCA certificates are either /etc/ssl/certs/ca-bundle.crt  or /etc/ssl/certs/ca-bundle.trust.crt.\n. It just skips server authentication.  It does not influence --ca-certificate option.. The default path to certificates are compile time option.  I don't know how your aria2c binary was built, it seems to me that it was not built using correct configuration for RedHat system.  To fix this issue cleanly, when building aria2, run ./configure without --with-ca-bundle option, or points it to the correct path.\nIf rebuilding aria2 is not an option, create aria2 configuration file, and write ca-certificate option to the correct path.\n. aria2 can download selected files (see http://aria2.github.io/manual/en/html/aria2c.html#cmdoption--select-file).\naria2 has limited prioritization capability (see http://aria2.github.io/manual/en/html/aria2c.html#cmdoption--bt-prioritize-piece), but it is not based on file.\nDoes it make sense?. --load--cookie options is not available in RPC request.. Currently, it is unlimited.. Metalink could be an alternative.  https://tools.ietf.org/html/rfc5854. The error seems to come from gnutls.  Have you built aria2 by yourself?\nIt may be because gnutls is old.  I'm not sure it is the cause of the issue.\nI use gnutls 3.5.8, and have no problem.\nIf you could, try building aria2 with openssl.. I couldn't reproduce it.. No.  There is no such functionality in aria2.. Have you tried \"./configure ARIA2_STATIC=yes --enable-libaria2\"?. Ah, I missed that.  That means I have no idea how to fix this issue.. aria_seeder_initial log started at 13:24:37 and ended 13:31:23, on the other hand, aria_puller_client log started at 14:24:42.  Perhaps, former should read 14:24:37 to 14:31:23 as you wrote ? (may be clock is set to UTC?)\nAssuming the time is OK, I found interesting stuff.  From the client puller log, client puller told trackers that its port number is 6936.  On the other hand, from aria_seeder_initial log, seeder got port number 6907.  restarted seeder got correct port number 6936.\naria seeder also got its own port number 6974 instead of 6920.\nDid you run seeder and puller using random port number?\nIt looks like they didn't know each other in the first attempt.  puller sent tracker request very frequently (did you use --bt-tracker-interval option?). \nIt would be nice to get DEBUG level log for puller client as well.  It shows us the peers returned from tracker.\n. Thank you.  Now time stamps are synced.  The behaviour is similar to the first one.  In the first attempt, tracker does not store aria2 seeder, and aria2 puller cannot know seeder's existence.\nThe possible reason is that tracker could not verify the aria2 seeder is actually BitTorrent client.  This sounds very strange, but BitTorrent tracker verifies the peer is really BitTorrent capable by connecting back to the peer.  aria2's listening backlog is historically limited to 1, and if there are too many simultaneous connections from trackers, some of them cannot establish their connections.\nFrom aria_seeder_initial log, there are ~50 tracker requests, but only ~30 connections accepted from tracker.  If the torrent which aria2 puller wants to download is not included in this established connections, tracker probably does not associate seeder to the info hash.\n6289aafaf850e854e5b03710726db984df7cf82b increases listener backlog to 1024.  This might help in this situation.\n. aria_seeder.log starts at 11:58:59.  It looks like a different log.  Could you check this out?\nPerhaps, using shorter tracker interval may help.  Could you try --bt-tracker-interval ?. Thank you.  I found that seeder failed to contact tracker many times, and could not get puller's address, and at the same time, could not register its address to tracker.\nIt finally found the puller around 18:06:25.\nI think --bt-tracker-interval=1 is too short.  From the log, it is clear  that tracker is overloaded.\nIt might be better to consider UDP tracker, which is supposed to be more resilient against load.\nTCP tracker's SOMAXCONN could be too low, and it might not accept connections form seeder.. > Thanks for this analysis. I'll try to increase bt-tracker-interval, do you advise any particular value or shall I explore the parameter space ?\nI have no recommended value.  If I say, it is the lowest value which does not overload tracker, but it is what we are looking for..\n\nI am surprised the tracker is overloaded in a 1:1 scenario, I guess it will not improve when I run the same command with 300 servers.\n\nFrom the log, aria2 got many EOF from tracker.  It would help to check the maximum file descriptor and somaxconn value of tracker process.  The default value may be quite low (128 for somaxconn), and increasing it helps stabilizing tracker.\n. It works for me.\nHave you checked https://github.com/aria2/aria2/blob/master/examples/libaria2ex.cc ?. There is no way to completely turn off BitTorrent uploading at the moment.. Thank you for reporting this issue.  The error code should be 9, but the error code is not propagated to the last error field.  #857 fixes it.. There are several ways to achieve this.\nUse -i input file option.\nExample:\n```\n/path/to/1.torrent\n/path/to/2.torrent\n  select-file=1\n```\nSee https://aria2.github.io/manual/en/html/aria2c.html#input-file\nIf -i input file does not work, try aria2.addTorrent RPC method.\naria2.addTorrent RPC method\nSee https://aria2.github.io/manual/en/html/aria2c.html#aria2.addTorrent. I think it would be nice to write .aria2 control file as early as possible.  First such chance is when we determined the file size.  For metalink, and torrents, we know the file size in advance, so we can immediately write .aria2 file.\nIt sounds nice to save --save-session file when a download finishes.\nOne thing I'm concerned is that people use to put thousand of lines in input file.  If there are lots of tiny files, writing session file per file could take some time, which pauses actual download processing, and causes download slower.  Perhaps, explicit toggle option for this feature would be nice.\n. #861 implements early save of control file.  Since the number of save operation of the control file is limited by concurrency, it is expected to within the small number.  I think no toggle option is necessary.. Thank you!  Merged now.. Multiple interface option is --multiple-interface.  --interface option is found in your log.\nIs the used interface setup correctly?. Thank you.  I tried the machine which has multiple interfaces (eth0, and wlan0), and it worked well.\nI setup a web site which can be reached only through wlan0.  --multiple-interface=wlan0,eth0 finished instantly cause wlan0 was used first.  --multiple-interface=eth0,wlan0 took some time before its connection establishment timed out because eth0 was used first.  Then wlan0 was used, and file was downloaded correctly.\nIn the implementation, the socket is bounded to the particular interface.  And the packet goes through it.  It is then very strange to see the packet with one address go through another interface.  Sounds like a kernel bug or some sort.  Have you checked to reach the web site from both interfaces?\n. Thank you for PR!  Merged now.. Thank you for PR!  Merged now.\nmisspell_fixer looks good BTW.. @SumatraPeter Thank you. Fix committed via 79a20e04. @nmaier Any updates for 1.31 mac binaries?. It should work.  A torrent file whose name is hex string of info hash should be created in the directory which -d option specifies.  Did you get any errors?\n. When you are downloading a large number of images, each downloading of image is considered as an \"item\" (this might not be the case for BitTorrent, but forget it for now).\nThese items are put into a single \"queue\".  aria2 takes one item from queue, and performs download for it, then takes another, and so on.  -j option specifies how many items are being processed concurrently.  So by default, 5 items are processed concurrently.\n-x option specifies the number of connections to the same server in one item.\nWhen you do aria2c -i imageurls.txt -j 100, aria2 will process at most 100 items.  If -x option is left to default value, aria2 will establish at most 100 connections, 1 connection per item.\nServer might not like 100 connections from a single peer, and it may drop excessive connections as they want.\n. So what error did you get from systemd?. aria2 uses newly generated gid(s) to download files described in Metalink file.\nYou can query these gid by checking \"followedBy\" (see https://aria2.github.io/manual/en/html/aria2c.html#aria2.tellStatus).. Thank you for PR.  Merged now.. The closest feature aria2 already have is --dry-run.. Yes.  I rather recommend to use curl for this kind of stuff.  aria2 is just a tool to download some files, not a something to inspect protocol stuff.\n. I confirmed that --dry-run follows HTTP redirects.\n\"0B\" shown in the above output is the download speed (byte per second), not a file size.\n. That console indicator might not be shown when we get the size, since aria2 just stops immediately if it gets final response header fields.\n. It would be nice to add NOTICE level log message to show the file size.\n. Currently, we have the following INFO level log:\n2017-04-09 16:57:21.359724 [INFO] [HttpResponse.cc:169] CUID#7 - Redirecting to http://localhost/foo/. I'm fine to change log level form INFO to NOTICE for this particular log.\n. aria2 normally retries on error.  I'm interested in the error \"Bad Status-Line: missing status-code\".  This means server sent corrupted HTTP response.  If that the case, it is not surprising that download file is corrupted since HTTP frame is also corrupted.. This looks like gcc bug, not aria2.. Yes, it should work.. I don't recommend to use --check-certificate=false because it breaks TLS server authentication, and you are subject to MITM attack.\nI don't know how to install CA certificates to your system. Ubuntu has /etc/ssl/certs/ca-certificates.crt which aria2c can read.  You can install Ubuntu somewhere, and pull that file, and put it on your system.\nAnd use --ca-certificate option to point to it.\n. I think if you just run aria2c, it refers to the older version installed previously.  For example, it is /usr/bin/aria2c.\nAccording to your log, new aria2c is installed under /usr/local/bin.  Try /usr/local/bin/aria2c --version.\n. I couldn't read Chinese.\naria2c -h only shows basic options.  To show all options, use aria2c -h#all\nOr consult online documentation: https://aria2.github.io/manual/en/html/aria2c.html\nUnknown option warning means that there are deprecated, removed, or just wrong options are used elsewhere.  Please make sure that file given in --conf-path is correct.\n. FYI, aria2 already supports If-Modified-Since.. None.  aria2 does not support it.. I think it is possible to build aria2 mac binary using https://github.com/aria2/aria2/blob/master/makerelease-osx.mk\n. Try commenting out that line of code.. Please use English here.. OK, let's close the issue.. Thank you for PR.  Fixing English version is enough in this case.. Cherry picked as e07356a502fc7bad3cfefb27a0077625ea93a7bf. PREF_USER_AGENT is HTTP user-agent, and is not intended to be used in BitTorrent protocol.\nIt would be desirable to add new option to define the value sent in extended handshake client version.. If you are concerned with the memory usage, also try --disk-cache=0.. Follow the GID included in \"followedBy\".\nhttps://aria2.github.io/manual/en/html/aria2c.html#aria2.tellStatus. There is no way to use downloaded torrent file when magnet URI is saved in session file at the moment.\nSince the downloaded torrent file has the particular name (hex string of infohash + .torrent), it can be used to by pass initial bootstrap with new toggle option.. #916 fixes this issue by reading saved .torrent file (by --bt-save-metadata), and skip the metadata fetch from DHT if it is successful.\n. What do you mean by \"serving known infohashes\"?  Is it directly related to this issue?. Thank you!  Merged now.. At the moment, there is no way to enforce the ordering of piece.\naria2 has abstraction for selecting pieces, so this is possible if the new algorithm is implemented.\n. Thank you for telling us.  #918 fixes this issue.. Thank you.  Merged.. There is no single RPC method does do that.  The combination of aria2.tellActive and aria2.tellWaiting will do.. It looks like the redirected site refuses HEAD request.  curl also exhibits this.. The special characters {}[] aria2 uses to unfold parameters should be escaped if they are intended to be used literally in URI.  So instead of {, you should write %7B.\n. @nmaier thank you!. I think new settings are not applied to the existing downloads.  Try adding new download item. . Thank you. Looks good.  I should have write aria2::KeyVals::value_type, but the PR works.. Adding RPC method to save session could solve this issue.. Use --listen-port and --dht-listen-port options to specify a single port number to reduce port exposure.\n. Port 6800 is RPC server port.  If you don't want RPC functionality, use --enable-rpc=false.\nTorrent metadata is fetched from DHT network.  aria2 uses port 6900 UDP in your case to do DHT operation.\n. https://aria2.github.io/manual/en/html/aria2c.html#cmdoption--rpc-listen-port. Thank you.  PR is on the right track.  Could you remove the code you comment out?. Thank you.  Looks good to me.. Modern file system performs fallocate very fast.  It looks like you are talking about the case where user accidentally use --file-allocation=falloc against file system which does not support it (e.g., vfat)?\nFor those legacy file system, --file-allocation=prealloc should work, and its does not stop the world.. Thank you for sharing this.  I haven't used aria2 in such a condition, and you know more about it than me.\nI'm fine to add this feature as long as it works reliably (it's a thread!).. Sounds interesting.  Thank you @nmaier . Thank you.  Merged now.. aria2 uses neither /dev/urandom or /dev/random directly.\nBut its dependencies and/or standard library may use them.\n. Thank you!  Merged now.. I use mingw-w64 cross compiler.  https://github.com/aria2/aria2/blob/master/README.mingw. Thank you.  Merged now.. curl also gets 403.  Perhaps, it is server issue?. One way is build only a static library, and just link it as usual.\n. It means that that download is not running at the moment, so it cannot be paused.\n. No.. Primary reason is because I'm not interested in ed2k.   Don't get me wrong, but I'm busy for the other projects these days, and adding completely different protocol will not gonna happen from my side.\n. It means that the third party library aria2 depends on must be installed under $ANDROID_HOME/usr/local.  Usually, this means that install prefix should point to $ANDROID_HOME/usr/local.. Some examples to build and install library for android: https://nghttp2.org/documentation/building-android-binary.html. Which line can I find the error that aria2 failed to process tracker response in the above log?\n. Could you share the log lines around it?  I want to see the logs 20 lines of before/after the line where you find this message.\n. Thank you.  So if I understand correctly, the issue here is that error code is not propagated to the exit status, right?  If so, I'll fix that up.. Thank you for suggestion.  I think #999 fixes this issue.. Try specifying absolute path in on-download-complete. Try to use OpenSSL.. -s option is not deprecated.  -s and --max-connection-per-server have their own meanings.. There may be error in source code which lacks ending sequence of characters to make color default.\nI haven't checked yet.. Does it fix your issue?\nThat commit is not included in 1.33.1.  It will be included in 1.34.0.\n. Is your aria2c executable compiled for x86?. It is for ARM, not for x86.. Are you talking about HTTP BASIC authentication?  If so, aria2 supports it.. I think the combination of --rpc-listen-all and --interface work.\nNote --interface also affects the outgoing request.. A workaround is make aria2 listen on 127.0.0.1, and deploy the reverse proxy which listens on the desired interface, and let the proxy forward the request to aria2.. aria2 allocates a file in the file system before a download starts in order to reduce fragmentation.  If you are trying to download 40GiB file, aria2 writes 40GiB file in a file system, and its content is all zero.\nOn the other hand, aria2 shows the console readout that how many bytes are actually downloaded.\nYou can turn off pre-allocation of file space by using --file-allocation option.. If you can do it with RPC interface, it should be possible with command-line.\nHave you tried that?  Perhaps, the documentation is not updated.. Try this:\n$ aria2 -Tfiles.torrent https://home/files/. Documentation has been fixed by the commit 31a2f5cd1b1293c0d08efb38a0b9cfff0df38976. Which version are you using?\n. I think aria2 should handle connection: close just fine.\nIf --max-connection-per-server=1 is used, is file downloaded fine?. Can downloading the file from the link reproduce this issue?. Thank you.  I will debug aria2c windows build using that server.. It looks like aria2 wrote TLS encrypted data to a disk without decrypting it.\n0x1503030050 is actually TLS record header:\n0x15 = alert\n0x0303 = protocol version (3,3) which means TLSv1.2\n0x0050 = record length, which is 80 bytes.. I hope #1021 fixes this issue.. The fix I made is windows specific, and if I understand correctly, it only occurs on Windows platform.\naria2 uses different TLS stack on Linux, and it does not produce same issue.\nIf you are experience corrupted downloads, it is probably the different issue. I think it would be better to open an new issue.. Thank you for confirmation.. Perhaps, underlying mechanism is changed in high sierra.\naria2 uses dedicated file allocation code for Mac OS X using fnctl.\nI don't have Mac OS, so cannot diagnose the situation.\nI'd appreciate if anyone who owns Mac OS can debug this code, and makes a patch.\nPerhaps, Mac OS finally supports posix_fallocate?. #1012 might be related to this issue.. Yes, if you know all URIs you want to download.  Write them down in a file, and feed it to aria2c.  Use -j1 to sequentially download a file one by one.. We are working on it.. It looks like aria2 does not have this kind of configuration.  --quiet hides summary interval as well.. Changing Ubuntu release might change toolchain, so aria2 binary might be slightly or vastly different.  Compiler bug might affect them.\nBut these binaries should provide the same functionality.. try --async-dns=false. --file-allocation=falloc might not work depending on the file system.  Try other file allocation method.. Thank you for PR!  Merged now.. https://github.com/aria2/aria2/blob/master/COPYING. I would appreciate it if anyone performs 'git bisect' to find a commit which causes high CPU usage.\n. Thank you for PR.  Could you fix the errors reported by travis?. Please install pkg-config.. I think this is typo.. aria2 has already supported POST-style RPC request for both XML-RPC and JSON-RPC.  It looks like you are using JSONP?. https://aria2.github.io/manual/en/html/aria2c.html#rpc-interface. You should strip \"--\" from option name:\ncpp\noptions.push_back(std::pair<std::string, std::string> (\"enable-rpc\", \"true\"));. The proper way to use TLS on Windows is compile aria2 with native Windows TLS backend, namely, schannel.  You can download the pre-compiled windows binaries from release section.\n. Thank you for PR!  Merged now.. Thank you for PR. Merged now.. Thank you for PR!  Merged now.. Thank you for pointing this out. Could you check my comment?. How about this patch?\n```patch\ndiff --git a/src/SelectEventPoll.cc b/src/SelectEventPoll.cc\nindex 824c5088..732a4596 100644\n--- a/src/SelectEventPoll.cc\n+++ b/src/SelectEventPoll.cc\n@@ -174,6 +174,12 @@ void SelectEventPoll::poll(const struct timeval& tv)\nmemcpy(&rfds, &rfdset_, sizeof(fd_set));\n   memcpy(&wfds, &wfdset_, sizeof(fd_set));\n+\n+#ifdef MINGW32\n+  fd_set efds;\n+  memcpy(&efds, &wfdset_, sizeof(fd_set));\n+#endif // MINGW32\n+\n #ifdef ENABLE_ASYNC_DNS\nfor (auto& i : nameResolverEntries_) {\n@@ -190,11 +196,9 @@ void SelectEventPoll::poll(const struct timeval& tv)\n   do {\n     struct timeval ttv = tv;\n #ifdef MINGW32\n-    // winsock will report non-blocking connect() errors in exceptfds, unlike\n-    // posix, which will mark such sockets as writable.\n-    // So just pass in our write socket set to exceptfds, too, to get connect()\n-    // error notifications on Windows.\n-    retval = select(fdmax_ + 1, &rfds, &wfds, &wfds, &ttv);\n+    // winsock will report non-blocking connect() errors in efds,\n+    // unlike posix, which will mark such sockets as writable.\n+    retval = select(fdmax_ + 1, &rfds, &wfds, &efds, &ttv);\n #else // !MINGW32\n     retval = select(fdmax_ + 1, &rfds, &wfds, nullptr, &ttv);\n #endif // !MINGW32\n@@ -209,6 +213,11 @@ void SelectEventPoll::poll(const struct timeval& tv)\n       if (FD_ISSET(e.getSocket(), &wfds)) {\n         events |= EventPoll::EVENT_WRITE;\n       }\n+#ifdef MINGW32\n+      if (FD_ISSET(e.getSocket(), &efds)) {\n+        events |= EventPoll::EVENT_WRITE;\n+      }\n+#endif // MINGW32\n       e.processEvents(events);\n     }\n   }\n```\n. Thanks.  Could you confirm that https://github.com/aria2/aria2/pull/1060#issuecomment-341968755 still causes high CPU usage?\nI still could not reproduce this issue so far.  Could you share how to reproduce it?. Thank you.  I think the following patch fixes this issue:\n```patch\ndiff --git a/src/SelectEventPoll.cc b/src/SelectEventPoll.cc\nindex 824c5088..5f6f3309 100644\n--- a/src/SelectEventPoll.cc\n+++ b/src/SelectEventPoll.cc\n@@ -174,6 +174,12 @@ void SelectEventPoll::poll(const struct timeval& tv)\nmemcpy(&rfds, &rfdset_, sizeof(fd_set));\n   memcpy(&wfds, &wfdset_, sizeof(fd_set));\n+\n+#ifdef MINGW32\n+  fd_set efds;\n+  memcpy(&efds, &wfdset_, sizeof(fd_set));\n+#endif // MINGW32\n+\n #ifdef ENABLE_ASYNC_DNS\nfor (auto& i : nameResolverEntries_) {\n@@ -190,11 +196,9 @@ void SelectEventPoll::poll(const struct timeval& tv)\n   do {\n     struct timeval ttv = tv;\n #ifdef MINGW32\n-    // winsock will report non-blocking connect() errors in exceptfds, unlike\n-    // posix, which will mark such sockets as writable.\n-    // So just pass in our write socket set to exceptfds, too, to get connect()\n-    // error notifications on Windows.\n-    retval = select(fdmax_ + 1, &rfds, &wfds, &wfds, &ttv);\n+    // winsock will report non-blocking connect() errors in efds,\n+    // unlike posix, which will mark such sockets as writable.\n+    retval = select(fdmax_ + 1, &rfds, &wfds, &efds, &ttv);\n #else // !MINGW32\n     retval = select(fdmax_ + 1, &rfds, &wfds, nullptr, &ttv);\n #endif // !MINGW32\n@@ -209,6 +213,11 @@ void SelectEventPoll::poll(const struct timeval& tv)\n       if (FD_ISSET(e.getSocket(), &wfds)) {\n         events |= EventPoll::EVENT_WRITE;\n       }\n+#ifdef MINGW32\n+      if (FD_ISSET(e.getSocket(), &efds)) {\n+        events |= EventPoll::EVENT_ERROR;\n+      }\n+#endif // MINGW32\n       e.processEvents(events);\n     }\n   }\n```. Thank you for helping us.  I'll commit the patch.. Thank you for PR.  Merged now.. @myfreeer Thank you for telling me.  Fix committed via a005f294482d7764c7d4cb3683b015247787f922. Thank you.  It looks like it is working fine.. Merged now.  Thank you!. Yes, it is known issue.  It looks like a third party library uses the deprecated macro.. It works for me.  Could you check that aria2c server receives RPC request?. For example, you can use -l option to show aria2 log.. Even though the version is 1.33.0, Dockerfile pulls aria2 master, and it contains the same fix.. It works for me as expected.  --continue does not truncate file.. There are several options for regular downloads:\nhttps://aria2.github.io/manual/en/html/aria2c.html#event-hook\n. Thank you for bringing this topic.  It looks like Windows _wutime adjusts time with DST.\nCurl source code has the following comment:\nc\n/* Windows utime() may attempt to adjust our unix gmt 'filetime' by a daylight\n   saving time offset and since it's GMT that is bad behavior. When we have\n   access to a 64-bit type we can bypass utime and set the times directly. */\nIt looks like using SetFileTime is a right approach for Windows.. I think aria2 compiles on Ubuntu 16.04.  What kind of error did you get?. Try --bt-detach-seed-only https://aria2.github.io/manual/en/html/aria2c.html#cmdoption-bt-detach-seed-only. I have no idea what happened from the picture above.. aria2 itself does not have scheduling feature.. Sorry, but I don't understand this issue.  Could you elaborate it more?. -S works for local file only.\nFor magnet URIs, first download torrent metadata using --bt-save-metadata and --bt-metadata-only, and then use -S option against the downloaded torrent file.. I don't know the peer verification specification for Local Peer Discovery.  As far as I know, it uses HTTP like request in plaintext UDP packet.  There is no encryption involved at all.\nCould you point to the specification?. So this is a feature request to download a file using BitTorrent from its beginning rather than downloading  pieces randomly. . It woks for me.  Perhaps, configuration file is badly formatted?. The log says that aria2 attempted to connect to ::ffff:*.198.138.94:6933, but it was timed out.\nIs it qbittorrent's address?. It looks like aria2 requires libssh v2.0.0 or later, but you only have v1.0.0.  Perhaps, there are multiple libssh2 version installed?  I'm not sure how to selectively load library on Mac.  On Linux, LD_LIBRARY_PATH does the trick.. If download is not affected, it might happen on the very end of the connection where TLS session is teared down.. aria2 has -i and --save-session to resume list of downloads on the next run.  I'm not sure how it can be integrated into youtube-dl.. The log only shows tracker which aria2 failed to connect.  There may be successful tracker requests hidden from the log.. I think they are 0 if you run the function before the actual download starts.. What is the size of the resource?  Are you saying that aria2 does not request the last byte?. It is public IP which the tracker or DHT peer can access.  So it is 128.100... in your case.\n. IPv6 is disabled by default for Windows build.  It can be enabled using --disable-ipv6=false. Fix committed via d791d0b6c3c086a8523f727d9d7aab550688a599\nThank you!. Thank you.  Merged now.. It looks like aria2 doesn't resolve hostname to ipv6 address if no ipv6 address is configured (loopback address is excluded).  --async-dns=false will make aria2 reolve ipv6 address as a last resort.\n. -V is the right option to check file content.. aria2 supports content-disposition header field, and the value which server sent is syntactically incorrect.  The trailing \";\" must not be there.  The server is broken.\n. I suggest that using RPC will provide all progress information in machine friendly way.. https://aria2.github.io/manual/en/html/aria2c.html#cmdoption-show-console-readout. Perhaps is https://aria2.github.io/manual/en/html/aria2c.html#cmdoption-deferred-input the option you are looking for?. We have couple of bug fixes since the last release.  I think it is good to release new one.  No exact release date at the moment.. Because it is very hard for me to support for every combinations of LibreSSL, and OpenSSL versions, I'm wondering that it is possible that we just support latest release of LibreSSL.\n. There is no way to show the size of download files in download result table at the moment.. I think this issue has been fixed in the current master branch.. I didn't have spare time yesterday.. It went live again.. Try to build aria2 with OpenSSL instead of GNUTLS.. Thank you.  Merged now.. This bug should be fixed by e8e04d6f22a507e8374651d3d2343cd9fb986993.\nThe workaround is build aria2 with one of OpenSSL, gmp, or gcrypt.. I think you should build aria2 with openssl statically linked.\n. Do you follow the instruction described in https://aria2.github.io/manual/en/html/README.html#cross-compiling-android-binary ?. Could you share your site URL?. Thank you.  #1214 fixes this issue.. You have to create it manually.  https://aria2.github.io/manual/en/html/aria2c.html#cmdoption-conf-path\n. It looks like posix_fallocate fails if the underlying local file system does not support it.  Not sure this is the case.. It works for me.  aria2 only downloads broken parts on retry.\naria2 outputs log using -l option and I saw that it did a range request.. Thank you for PR.  Merged now.. I think the latest master branch fixes this issue.. I think documentation is wrong.  It should be [0-9a-fA-F]. Fix committed via 7e5757c2. Sorry for late reply.  Thank you for PR!. grep \"Verifing\" returned empty result.  Which version are you using?. I coudn't find any change regarding this typo fix.\nI am wondering that it might come from uupdump or something wrapping aria2c.. aria2 by default follows metalink.  Doesn't aria2c https://download.gnome.org/sources/meld/3.18/meld-3.18.3.tar.xz work for you?. You are right that Accept header for metalink is sent regardless of whether metalink feature is built-in or not.. Thank you.  Fix committed via 879e4a8 . aria2 only masks credentials which follows \"Authorization: Basic \".  No masking is made for userinfo subcomponent in URI.\nI will change the code so that all authorization and cookie header fields are masked.\nI have no plan masking userinfo in URL because it has been deprecated and considered insecure.\n. Fix committed via 37368130ca7de5491a75fd18a20c5c5cc641824a. In order to receive notification, JSON-RPC over WebSocket must be used: https://aria2.github.io/manual/en/html/aria2c.html#json-rpc-over-websocket. perhaps, this would be deffg_ = kForeground[i]?\nThe color seems not to be just consecutive integer.\n. OK, so defbg_ is index to kBackground.  Then, this assignment is a bit confusing.  I think it is clearer to use local variable to store these temporary values.\n. It seems this is not used. If yes, please remove this.\n. Usually, we use setSomething to set parameter to private field.  Since this function has no parameters, perhaps, something like setupOptimizeSimultaneousDownloads would sound more like it.\n. maxSimultaneousDownloads_ is always more than or equals to 1, so checking >0 is not necessary.\n. We can first check this condition before the above if statement to make the intention clear.  Something like:\ncpp\nif (maxSimultaneousDownloads < 1) {\n  maxSimultaneousDownloads = 1;\n} else if (maxSimultaneousDownloads > maxSimultaneousDownloads_) {\n  maxSimultaneousDownlaods = maxSimultaneousDownloads_;\n}\nor just go in one-liner:\ncpp\nmaxSimultaneousDownloads = std::min(std::max(1, maxSimultaneousDownloads), maxSimultaneousDownloads_);\n. Perhaps, it would be nice to use util::abbrevSize(speed).c_str(), and replace speed (%d B/s) with speed (%s B/s) in case where speed gets faster.\n. The above 3 lines should be put before numActive_(0),.   Compiler shows warnings like field 'numActive_' will be initialized after field 'optimizeSimultaneousDownloads_' [-Werror,-Wreorder]\n. The initial value of PREF_MAX_CONCURRENT_DOWNLOADS is 5 (https://github.com/tatsuhiro-t/aria2/blob/2a0b4751f4bccb198899be52b2c45249a79de5ab/src/OptionHandlerFactory.cc#L414), and its acceptable lowest value is 1.  And its value is passed to RequestGroupMan constructor.  So it has always be explicitly defined.  The maximum value gets quite big, and users can specify big value if they want.\n. If possible, please use global::wallclock(), which saves many syscalls to get time stamp.\n. We set argType_ to OptionHandler::OPT_ARG in constructor L592, so we don't have to check that value here.\n. We usually use {} even with single line.\n. We are referring first NUM as A, and second NUM as B.  I think it would be clearer to say A:B rather than NUM:NUM. \n. We are referring first NUM as A, and second NUM as B in help message.  I think it would be clearer to say A:B rather than NUM:NUM. \n. Could you explain the theory behind these calculations?\n. I think we should return the sum of received bytes including first slot.  If all slots are within given seconds, all slots should be considered.\n. You are completely right.  I was wrong, probably was confused about rbegin() thing.  Sorry for that.  This hunk is all good.\n. Trailing whitespaces are just a junk. Thank for cleaning them up.\n. Yes, please.\n. I may be missing something, but we want to check filesize is larger than size_t right?  Then is static_cast<uint64_t>(std::numeric_limits<size_t>::max()) < static_cast<uint64_t>(filesize) enough?\n. In my opinion, these tests should go their own function, say, testTryAutoFileRenaming().\n. If we have file path \"/tmp.txt/.txt\", it is renamed as \"/tmp.txt/.1.txt\".  In my opinion, it should be renamed as \"/tmp.txt/.txt.1\".\n. Perhaps, this is accidental left over?\n. For consistency, it should take into account saveError_.\n. This may leave utf-8 string which is prematurely truncated.  dfa_state must be verified that it is UTF8_ACCEPT in somewhere, for example, in CD_AFTER_VALUE.. Perhaps, it should also say: This only applies to quoted string in non-extended version of content-disposition.. CamelCase.  Could you add comment about new parameter?. aria2 project prefers CamelCase for variables and function names.  Perhaps, contentDispositionUTF8?. Accept. CamelCase. Use function parameter name here.. CamelCase. Thank you.  I think it is better than mine.. Good idea.  Will do.. Fix committed via 2e8c866. Since we use peer agent as std::string, it would be nice to return std::string rather than const unsigned char*. I think you don't have to do const_cat<> here.  Just return peerAgent.  Caller will see const std::string & as per function return type.. As far as I know, the convention in aria2 source code is negate condition on \"#else\".  So the original code is right.\nIt should be // !__MINGW32__. // !__MINGW32__. Can you fix it?. I'd like to know what happens if memcpy(&efds, &wfdset_, sizeof(fd_set)); is inserted here.\nDoes it still cause high cpu usage?. Isn't this block still required if TLS version other than TLSv1.3 is negotiated?. Sorry for the delay.   The intention of my question is that if the block is removed, it may enable unsafe cipher suite if TLSv1.2 or lower is negotiated.  It looks it is not an issue at this time.. It would be nice to add comment \"// fall through\" here. ",
    "barrkel": "Here's what I want out of aria2c logging: to be able to infer incomplete downloads from a prior terminated session, in order to figure out whether I need to invoke aria2c again.\nTo do that, I need (a) the path of the file being saved to (since the source may be 302 redirect, or may have session-specific gunk attached to URL, etc.); (b) enough information to then test the file on disk to see if it is complete, in something simple like wget I'd compare content-length with file size; and (c) notifications when files are complete.\nAt the NOTICE level we do get Download complete:. But we don't get enough information for (a) or (b); not at INFO level either.. ",
    "navidR": "I think this has got to be reopened. With the recent push from Google (NDK compilation with CMake Toolchain file they provide with NDK is easy as using your default toolchain, their integration of CMake to gradle, etc), Microsoft (Integrating CMake to VS, providing CMake based package management solution for C++) and other big companies to CMake. CMake has become de facto build system for most projects and companies. Despite its bad syntax, CMake gets the job done. The fact QtCreator, VisualStudio, Clion (and none of them do support Autotools at all) are trying to become better CMake based library shows how much attention it got in the recent year.\nI am not going to talk about the hardness of Autotool usage because there is no point. We all know how tedious it is to use autotools, especially for newcomers.\nWhether we like it or not, Autotools is going to die. And I am happy about it. It was very useful and advanced tool for its time. But now CMake is the build system which industry settles in.. ",
    "YenForYang": "Agree 100% with @navidR. \nIt is time.. ",
    "inCHOK": "I'm working on the cross compiling of aria2, and I'd like to say that using autotools with android ndk is just like a shit, hoping move to cmake as quick as possible.. @tatsuhiro-t \nI also meet the same problem, it seems like all the new downloads added after the first call of aria2::run() will be in DOWNLOAD_WAITING all the time.. @jophxu Do you solved the problem? I meet the same problem.. ",
    "iven": "Oh sorry, it's my fault.\n. ",
    "nmaier": "\nI think that indicator may go beyond 100% if piece containing the beginning of the or end of the file is shared by another file. \n\nThat's what I thought as first, too, but the file was only ca. 85% complete after manually checking the hashes.\n\nBut piece size is relatively small, aria2 will go into seeding mode in short time.\n\nThat didn't happen. In the end I waited for it to go to 112%.\n(This one was select-file=39-41, followed by select-file=39)\n```\nInfo Hash: b238cc6188ef249472ebda2c749a7b0807a58347\nPiece Length: 4.0MiB\nThe Number of Pieces: 14387\nTotal Length: 57,547.8MiB (60,343,264,566)\n[#1 SIZE:399.0MiB/356.0MiB(112%) CN:280 SEED:36 SPD:665.4KiBs UP:153.7KiBs(10,411.6MiB)]\naria2 version 1.15.1\n Configuration \nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5\n```\nI did a similar thing with another torrent, where I\n- started to download files 3,11,17\n- then CTRL-C\n-  then resumed only 3 and waited for it to hit ca. 200%\n- CTRL-C\n-  restarted with 3,11,17.\nUsing the original selection 3,11,17 again made the torrent finish successfully.\n. Yeah I considered .pop_front(), but want to kill error results while there are still good results.\nThen again your fix is far more readable.\n. > Detecting unused members is really neat.\nYes, it is indeed. Although I'm still skeptical of the BSD license combined with Apple already doing their own closed source modifications on top of it. And the lack of proper support to build cross-compilers :(\n. What does your VPATH (@srcdir@) contain? Seems your VPATH is empty in the generated Makefile... Does it help if you used @srcdir@ instead of VPATH in the Makefile.am?\nThe reason for this is that I do multiple builds (e.g. linux gcc44, linux gcc47, mingw-w64 cross) from a single aria2 common source (git clone).\nThe actual build will be performed outside of the source directory in newly created, blank build directories.\nWhen doing the same in the source tree, each time you switch toolchains you need a full rebuild, regenerate all the .o, etc.\nJust try it yourself:\nsh\n$ cd\n$ git clone ... aria2\n$ cd aria2 && autoreconf -fiv\n$ cd ..\n$ mkdir build-aria2-native\n$ cd build-aria2-native\n$ ../aria2/configure && make\nThis will build aria2 outside of the source tree. \n. Well, one should first define a common interface for TLS as an abstraction, instead of interleaving OpenSSL/GnuTLS code all throughout the socket core code.\nOnce that is done, one might implement other stuff like OSX ST, Win SChannel/CryptoAPI, NSS bindings.\nAlso, as a fast work-around for (home)brew users and maybe others, one could teach aria2 configure or runtime to use the CA file brew curl-ca-bundle or other packages provide, just like the aria2 formula https://github.com/mxcl/homebrew/blob/master/Library/Formula/aria2.rb\nThat is, in the absence of an explicit --with-ca-bundle, check for the CA file in commonly used locations:\n- http://mercurial.selenic.com/wiki/CACertificates (Nice list regarding linux distros)\n- https://github.com/mxcl/homebrew/blob/master/Library/Formula/aria2.rb (OSX brew)\n. Yeah, well, the Apple API, while somewhat limited, is not such a clusterfuck as the OpenSSL stuff :p\n. > Using brew link gettext -force after run autoreconf you can unlink it.\nYeah, but brew explicitly warns against this, so it is more of a \"last resort and prepare for the possibility it might break stuff\" kind of thing.\n@tatsuhiro-t, it might be a good idea to keep a generated configure in the repo. Because auto* portability kinda sucks. Losts of projects do just that already. The drawback is that commits modifying build-system files will get a lot more noisy, but the benefit outweighs the cost by far IMO.\n. > Need to update manpage how to use --rpc-secure with Keychain [WARN] [AppleTLSContext.cc:51] TLS credential files are not supported. Use the KeyChain to manage your certificates.\nYeah, I missed to actually write the setup code for ssl-server mode :p\nThat's why I initially asked not to have this merged just yet. I'll look into that.\n\nnow I get:\n$ autoreconf -i\nconfigure.ac:114: warning: macro 'AM_PATH_XML2' not found in library\n\nhmm, what version of OSX do you use?\nI still use Lion and that one comes with a libxml2 pre-installed. I think Mountain Lion does not ship it anymore and the brew formula is keg_only, meaning you need to brew link --force it or create symlinks yourself again. However, symlinking this yourself is a bitch, as there are quite a few links, so this one I would brew force and not even unlink it again as this one isn't shipped anyway and cannot conflict that easily.\n. @kax4, for the ssl server creds see #63 and #64\n. > I use 10.8 & 'brew link --force libxml2' worked for me. thanks again @nmaier!\nBTW: Does the appletls stuff work for you?\n. > it appears to. (5.1 MB log file for a 13k https download tho?)\nAnything particularly repetitive in there?\n. > I missed the last statement and rushed to merge the patch. Sorry about that. I was just excited about Apple TLS support.\nNo worries. If stuff isn't ready for the next release, one can still turn if off by either making it an explicit --with, removing it from configure althoughter, or even reverting the commits. \n\nit appears to. (5.1 MB log file for a 13k https download tho?)\n18150 2013-04-08 14:37:51.038891 [DEBUG] [../../src/AbstractCommand.cc:149] CUID#6 - socket: read:0, write:1, hup:0, err:0\n\nEach, lots of socket \"event\" logging. @tatsuhiro-t, any idea why this might be. In GnuTLS there is far less such logging going on....\n. darwin-ssl sucks as a name IMO. It isn't really a darwin library, but a Apple library. With some prodding one might even produce iOS builds from that.\nSharing a name would be nice, but I wouldn't put too much emphasis on that, especially considering that aria2 will auto-select appletls on mac currently. \n. Would assign to myself, but not a collab\n. Alrighty, pull request.\nLet me add some docs before merge.\nShort for @kax, if you want to build and try this:\n- In the Key management GUI, Use the cert wizard to Create a cert Self-signed/SSL-Server (or import an existing one)\n- Double click the new cert and copy the sha1 fingerprint.\n- Start aria2c with --rpc-certificate=fingerprint-without-spaces\n. @kax4 OSX Version? Did you wizard create the cert or import an existing one?\nIt just works for me on Lion and creating one with the wizard. My cert it is my Login chain (Is that what it is called in English?) not System chain.\n. Ah, you were using Safari. As I'm a mozilla fanboi, I only added a cert exception (because the thing is self-signed)\nhttp://support.mozilla.org/en-US/kb/connection-untrusted-error-message\nI could have added the cert to my Firefox trust store instead.\nSo this is not an issue with my implementation, but a (Safari/) configuration problem or docs problem at best.\n. I think it is as good as it gets and can be merged. Somebody might want to enhance/amend the new docs, though\n. One drawback: Only supported in OSX 10.6+. Compiling on earlier systems should just disable finger-printing support.\n. I did use firefox, but navigated https://localhost:6800/ directly. Does Chrome use the KeyChain?\nBut yeah, it probably would help to have some docs, or links to external docs, on how add cert exceptions and/or add self-signed certs to your System store. But then again, the docs are very sparse already anyway. Using OpenSSL/GnuTLS you also would need to add the cert to KeyChain in order for Safari/Chrome to trust it.\n. Assigned /me\n. http://developer.apple.com/library/mac/#documentation/Security/Conceptual/SecTransformPG/SigningandVerifying/SigningandVerifying.html\n. Pkcs12 can be loaded, and this is probably as good as it'll ever get...\n. See comments in: #63 \n. That's the plan, at least. I don't know yet if it is entirely possible, as I didn't try it yet, but the Apple API docs look promising\n. > But GNUTLS implementation is old RFC 2818 based, so I think it is better to stick with our own implementation at the moment.\nI finally had a look at the GnuTLS code, and WOW, yeah, lets keep aria2 doing it's own verification :p\nConsider f2239e8 withdrawn.\n. Let me rethink this stuff...\n. You cannot simply ignore options from the global config, as the global config is anything except \"permanent\". Users may change it all the time.\nWhat would work, however, is de-duplicating option values within the saved session file. You would first store all the values that are common to all session items (e.g. in a special session item) and then ignore them when storing individual items. You might even be less strict and consider all options for de-duplication which \"most\" individual items share.\nWhen restoring, you would first read the global options. Then for each individual item you would first set all global options and afterwards all individual item options (Also works with the \"most\" option).\nThis shouldn't be too hard to do either.\nRemember that this is to reduce redundancy and minimizing the file size. So de-duplication has not to be perfect (but slow), but good enough (and fast enough).\nAnother simple big win would be to use short-option names instead of the long option names. Basically you would assign all PREF_* a new short-option string which is still unique. When reading back options from a serialized session you would then compare against the short and traditional long option names (for backwards compatibility).\nAlso, @guedouari or @tatsuhiro-t, can you reopen this. I would be interested in this, too.\n. Should be noted that the short-option string idea probably won't have much effect when serializing as .gz, though. \n. Just UV_RUN_ONCE actually does wait indefinitely until some fd polls (at least it should).\nThe busy looping is due to descriptors being writable most of the time, so uv_run() returns always immediately, and my code failing to remove event bits in deleteEvents so so that writable is requested always :p\nI'll push some commits to rectify this and a lot of other issues this (European) evening/night. I already have a build that seems to work as desired and now just need to clean up all the debugging and extra stuff that came up until I reached deleteEvents-is-broken enlightenment.\n. Ok, this is supposed to work now...\nThe *nix configure stuff is a mess, but meh!\n. >  For mingw build, it is libuv is definitely the default, although the building libuv with mingw seems difficult (I have not tried that yet).\nNot that difficult actually, but maybe a little unconventional, having only a makefile and no configure or other build system around it.\n\nFor Linux and other *BSD families, including Mac OS X, we have epoll and kqueue implementation for years and they work well. Libuv is still a fast moving target, so using our epoll and kqueue as default is a good choice.\n\nI agree.\n\nBut libuv is not largely packaged as of now and those who try to use it with aria2c may want to use it. In this case, choosing libuv as default is better choice. What do you think about this?\n\nWell, I'd build it by default where available, but make the pref default to epoll/kqueue. It's easy enough to change it in the config if you want to use it/play with it.\n. Alright, I think this can be merged now.\nThe last commit essentially makes libuv the default on Windows, while keeping epoll/kqueue on *nix the default\n. Culprit: https://github.com/tatsuhiro-t/aria2/blob/0bcbd947b47d8f3af6c04508f7d493edc901dfdc/src/LibgnutlsTLSSession.cc#L74\naria2 disables TLS 1.1 for whatever reason. However, gnutls will still send a client_hello annoucing the not-disabled TLS 1.2 (0x303). ftp.mozilla.org hence responds with a server_hello version of TLS 1.1 (0x303) which aria2/gnutls then refuses because it was specifically disabled.\nI guess the line above should be dropped, of if there was a valid reason to include it, should be expanded to also disable TLS 1.2, so that the client_hello will announce max TLS 1.0.\n. It appears that only OSX prior to Lion is affected, so yes.\n. Turns out Snow Leopard required a bit more work than just includes.\nUsing SecIdentitySearch*() on 10.6. Not using it everywhere, because these functions are deprecated since 10.7\n(Also setting up a Snow Leopard VM has become quite nasty :p)\n. Sorry, wanted to attach.\n. > Commit date Apr 28 is a bit weird, but its ok for now.\nThat's because this is when the patch was originally written. I wasn't quite comfortable with it back then, and just now took another stab at it, polished it a bit and also merged in the more recent changes. ;)\n. It would make sense to have configure test for the compiler requiring -stdlib=libc++ requirement e.g. by compiling a shared_ptr test without and then with -stdlib, I guess.\n. Fixed by 22e414dbb0263a87029d14b0bd3da4a83f743567 and augmented by b888088dc3de4828897b6c9062cb75e1cd665d19\n. Well, it works for me ;)\n. Damn. I hoped it would be reproducible on a native target.\nMight be a compiler bug after all. There are a couple of 4.8 regressions fixed in 4.8.1. that might be the cause. I really should upgrade my cross-compiler stack and retry once I find some time.\nOr might be mingw-w64 (or gcc for that target) specific.\n. Anyway, likely a low-priority thing. Compiling random stuff with -Ofast is discouraged for a reason, and it's unlikely many of the already few Windows people doing their own builds will use that.\n-O3 works as expected BTW.\n. /worksforme now\n. What is the actual compile error?\n. Seems to be fixed.\n. ``` bash\n$ git bisect run ...\n\n59e63d956ee63d99202b67a32e8a277f3b04650d is the first bad commit\n```\n\n59e63d956ee63d99202b67a32e8a277f3b04650d\n. Alright, another bad std::move\n. Alright. Yeah, it would be a good idea to audit the rest of the std::move() uses\n. I totally missed disk-cache so far. However, from the man page I cannot really gather what a good value for this would be. I just started a --s6 -x6 --disk-cache=10M 204M download, and it appears to write in 256k chunks, so where did your 4KB/16KB come from?\nLet's re-target this issue then from \"provide disk cache\" to \"provide a sensible default for the disk-cache option other than 0\". \n. I was more taking about the default for --disk-cache ;)\nHaving a disk cache enabled would be advisable in most situations and therefore there should be one by default.\nAlso, it is too easy to miss the option, as indicated by me totally missing it (or maybe forgetting about it in between).\n. Alrighty, a 16M disk cache by default seems reasonable, /methinks. This is somewhat in line with what other download tools do (actually, it is more conservative than most, i.e. uses a smaller cache than most)\n. Well, it won't hurt on linux (or you could still turn it off). Even on linux with file systems often supporting online-defragmentation, and with the kernel doing a great job with disk caches, there should be a very noticeable difference with non-preallocated (small) files.\nAnd there are many (exotic) file systems on *nix, often not doing a particularly good job without disk-caches.\nAnd also a lot of remote file systems (smb/cifs, nfs, afs, ...) where I/O is even far more expensive. \nI'd make it the same on all platforms, if not just for not confusing users with different per-platform settings.\nDoing some fast, not-very-scientific experiments on OSX seem to indicate that a disk-cache helps there as well.\nMy point is: Unless you can prove the underlying OS + file system is good without a disk-cache, don't disable it ;)\n. > BTW, I added @nmaier as collaborator in aria2 project given that the contributions made in the recent period. If you don't want that, please notify me about that.\nFine with me. Expect me to still throw you pull requests on anything that is not just a small and obvious bugfix ;)\n. > The only concern is memory consumption because aria2 seems to be used in embedded system which does not have lesser memory than desktop.\nWe could also add a configure switch... This would make it easier to configure aria2 once or an embedded build instead of having to mess around with all installation configurations. I know that a lot of embedded folks (such as the settop box crowd) use some form of package managers. The person building the package would then know bets what is a sensible default for a platform...\n. The handler set via SetConsoleCtrlHandler will be invoked on a newly created thread, hence the locks. This cannot be avoided.\nPlease note that signal() on Windows uses the same SetConsoleCtrlHandler mechanism. MSDN states:\n\nSIGINT is not supported for any Win32 application. When a CTRL+C interrupt occurs, Win32 operating systems generate a new thread to specifically handle that interrupt. This can cause a single-thread application such as one in UNIX to become multithreaded, resulting in unexpected behavior. \n\nSo aria2 is in fact multi-threaded (to this limited extend on Windows) today. ;)\nMy point being: Yeah we need Locks, sometimes ;)\n. OK to merge? Or do you have any objections?\n. Either use the release tarball, which comes with a pre-generated configure, or provide us with the output of autoreconf -fiv. Also make sure you have all depencies for an autoreconf installed first, like autopoint (from gettext)\n. @oceballos \n\nmy OS is Fedora 17 64-bit\n autoreconf: autopoint is needed because this package uses Gettext\"\n\nautopoint should be part of the gettext-devel package in fedora.\nThe depencies listed are for building aria2, not for autoreconf'ing.\n. Ah, right. You need a cppunit package as well \n. @tatsuhiro-t These changes should to to switch to external. \n. @tatsuhiro-t\n\nAgreed\n\nOn AUTOMAKE_OPTIONS or AM_INIT_AUTOMAKE?\n. Depending on what you consider the API, the many, many changes and rewrites and C++11 requirement would probably warrant a 2.0 (per http://semver.org/)\n. What version and/or commit, what compiler, what configuration (confgure and any special runtime config)?\n. Also, it would help to know the exact request (Wireshark it, or something)\n. Mac /worksforme. After reading the docs on smartos, I decided not to spend many newbie-hours on get one running in a VM. Maybe \nIf memory serves right, __cxa_throw is just the stlibc++ way of throwing user exceptions, of which there are plenty in aria2c. But these would normally be caught. Googling after that and _SUNW_Unwind_RaiseException makes me believe, that smartos libc and gnu stdlibc++ are incompatible. https://forums.oracle.com/thread/2193106 suggests to LD_PRELOAD libgcc.so. I'd imagine explicitly linking -lgcc/-lgcc_s might do the trick as well.\n. On smartos or opensolaris?\n. Yeah, OpenSolaris 11 is from 2009 if memory serves right. And EOL.\nWe need to either setup a real smartos to reproduce Which sounds like a PITA from glancing over the docs. Articles like \"How to install our pkgsrc fork\" are very off-putting.\nOr find something equivalent. Maybe OpenIndiana...\n. You don't happen to know of have written a step-by-step copy-pasta receipt to set up a smartos incl. compiler, for the lazy newbie?\n. Seems like the smartos gcc is broken. You should report this issue upstream.\nDoes something simple like this\n``` c++\ninclude \ninclude \nint main() {\n  try {\n    throw std::string(\"huh?\");\n  }\n  catch (const std::string& ex) {\n    std::cerr << ex << std::endl;\n  }\n  return 0;\n}\n```\ncompiled with g++-4.7 -o test test.cc work?\n. It uses plain HTTP and a very simple line-based eventing protocol, so I'd say yes ...\n. You're likely just lucky. Maybe aria2 just got a bit faster saving the session, terminating before the system SIGKILLs it. There were a couple of changes that made aria2 write less data (no unchanged global options and duplicate urls), and as file I/O is the bottleneck, this may very well caused aria2 to terminate in time now.\n. Well, I'd welcome it if you reviewed the code for obvious mistakes. My C++ got a bit rusty over the years, and C++11 is new anyway.. ;)\nI can merge that stuff after that (and some more tests) myself.\nRegarding pkcs12: Yes, only pkcs12 is supported in WinTLS at the moment. PEM could be supported as well, but that might get really nasty. I meant to update the manual, but obviously forgot.\nIt's a shame debian mingw is that outdated... Rebuilding the debs to use a more recent version, and you only need to rebuild mingw-w64* IIRC, isn't too hard, though. If you like I can whip up something...\n. Alright, the writeData stuff is supposed to work now, and I also fixed library detection and some other annoyances.\nI also uploaded my mingw-w64 debs (wheezy-amd64) here, if you like to build the stuff yourself: https://tn123.org/deb/\nTo build these yourself:\n- apt-get source mingw-w64\n- sudo apt-get build-dep mingw-w64\n- sudo aptitude install debhelper devscripts\n- Get the latest release mingw-w64 release tar and untar, and move to mingw-w64-2.0.8\n- cd mingw-w64-2.0.8\n- Copy the debian directory rsync -av ../mingw-w64-2.0.3/debian .\n- dch -v 2.0.8-1 -U\n- dpkg-buildpackage -us -uc -tc -b\n- cd ..\n- sudo dpkg -i mingw-w64*.deb\n. Oh, yeah. Overlooked that instance of have_wincrypt for MD.\nRegarding L414: I'ts OK to have nettle, gmp and gcrypt and build against that for ARC4 and DHExchange when if there is AppleTLS or WinTLS... Unless you want to use the Internal* variants always (in that configuration).\n. 00dd83b461d03fabdc83a5c9fc4a6009acc8da4a\n. I wouldn't enable wintls just yet. And some other stuff might not have been dogfood'ed enough, IMO. Also the interface (as in command line switches) changed slightly...\nPersonally, I'd branch off the 1.8.0 tag and cherry-pick the fix for the regression bug, and then release from that branch.\n. Post the full config.log somewhere (gist, pastebin, etc).\n. OK, I wasn't really carrying about truncation within color codes...\nAnyway, how about now?\n. Worked well enough for my understanding :p\nAnyway, here is now the full blown version: A colorized stringstream-like stream with built-in truncation. Pretty overkilly and not the most efficient thing to do (but negligible performance-wise I think).\n. >  As you inferred in your comment, we surely don't want overkill and inefficient object for this tiny extra feature.\nBelieve it or not, I don't consider this a tiny feature. It speeds up reading the most important bits quite a lot because of the visual cues.\n\nI want simpler code. The follow piece of code can do the job\n\nWell, I like my code better, because  it isn't that inefficient, like I said, and enables you to do stuff like this:\no << \" ETA:\" << colors::yellow << util::secfmt(eta) << colors::clear;\nAnd still can get back the string back without colors.\nAnd also, my code in simpler to understand in the end, I think, compared to another custom, hand-rolled state-machine lexer at least. ;)\nAlthough I wouldn't like to see my code go to waste, I can live with it either way.\nPS: I actually thought about doing something like your code, but decided to implement it my way in the end, because it makes using colors a lot easier in the end.\n. Lets continue in #152.\n. Yeah, brew doesn't link gettext (keg-only in brew-speech). We had this reported in another issue already IIRC and this is also my own experience.\nhttps://github.com/mxcl/homebrew/blob/master/Library/Formula/gettext.rb\nWe could state this in the docs:\n- On OSX with homebrew, either run PATH=$PATH:/usr/local/opt/gettext/bin autoreconf -fiv\n- Or run brew link --force gettext before running autoconf\n. PS: This is not only mavericks, aame is true for all OSX versions + homebrew\n. Well, the README still points to build_osx_release.sh, which is horrible broken due to still using gcc, which is gcc-4.2 on mac (well, actually gcc-frontend with llvm backend) and thus cannot even compile aria2 anymore. We should probably replace that build script with one that actually works, or just remove it.\nhomebrew seems to be the dominant \"package manager\" for developers on mac these days, while MacPorts suffered a lot in popularity.\nBoth, have aria2 in their repositories, though :D\nSo, @tatsuhiro-t , it would be a good idea to update http://sourceforge.net/apps/trac/aria2/wiki/Download to include homebrew instructions along with MacPorts and Fink.\n- MacPorts - http://macports.org\n  sudo port install aria\n- Homebrew - http://brew.sh/\n  brew install aria2\n- Fink - http://www.finkproject.org/ - No idea how to install there; never been a user.\nAlso, providing static-linked binaries like you do for Windows and Android, for all those folks not having a compiler installed might be a good idea.... But that is probably getting to off-topic now.\n. Cannot reproduce either, on OSX Lion.\nYou say 1.17.1 is good for you? Do you happen to build aria2 yourself and could attempt a git-bisect?\nElse, where did you get that package and what version of OSX?\n. Actually I have a couple of \"Bad file descriptor\" in my log, exactly 5, one for each time an nslookup completes (cares):\n512 2013-12-03 17:12:43.787081 [DEBUG] [../../src/KqueueEventPoll.cc:239] Failed to delete socket event:Bad file descriptor\n513 2013-12-03 17:12:43.787220 [INFO] [../../src/DHTEntryPointNameResolveCommand.cc:187] CUID#6 - Name resolution complete: dht.transmissionbt.com -> 91.121.60.42\n. So, does this mean you'd be willing to git-bisect this?\n. Damn, I fail at forking. Honestly no idea what my brain was up to at that point... This indeed would make a lot of sense as the cause.\n. @kax4 Also wanted to say thanks for you talking the time to bisect.\nDoes @tatsuhiro-t commit resolve your issue? That commit is also present in my static build linked in #159, which needs some testing hinthint\n. First static build (master) in case anybody reading this is interested:\nhttps://tn123.org/aria2/aria2-1.18.1%2b-osx-darwin.tar-x86_64-build1.tar.bz2\nShould run on a vanilla Lion or later (x86_64). Tested on Lion and Mountain Lion (need to setup a Mavericks box....)\n** Configuration **\nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5\nLibraries: zlib/1.2.8 expat/2.1.0 sqlite3/3.8.1 appleTLS c-ares/1.10.0\n. Great. Thanks for testing!\n. @tatsuhiro-t Could you have a quick look over the makerelease-osx.mk and associated files. I had to add some files for the osx-package to the tree, and wasn't really sure where to put those, so I put them into doc...\n. Also, not sure if the new files should be in dist source archives or not. I did not hook up any automake stuff for that so far.\n. Oh, the installers will install aria2 into /usr/local/aria2 and hook up in /etc/paths.d and /etc/manpaths.d, because I found that is what a lot of comparable packages do, incl. the git OSX installer. \n. > I wonder we really need binary DS_Store thingy in the repository.\nI tried to avoid that, but it turns out that the alternative is to use some AppleScript to dynamically script the Finder to generate an appropriate .DS_Store, which is just too fragile. \nBut we'd be in good company. Even mozilla has .DS_STORE files for their DMG packaging in their tree\n. Should I hook it up with automake, so it will be in source dist archives (EXTRA_DIST)? Or whould you prefer to have it in git only?\n. Yeah, I'll have some time to finish this issue until then. Give me a nudge after you push the release tag and when you start builds, so I can contribute an OSX package.\n. Pushed now.\nRe: sf account. Yeah I do have an account. But I rarely use it and I'd rather not have any special privileges associated with it. I'd prefer if you did the sf uploads... \n. Any other objections except for the style stuff?\n. Merged\n. dc757f49b63a192e265160897ab785c833166a58\nProbably only out-of-tree build affected...\n. OSX installer: https://tn123.org/aria2/aria2-1.18.2-osx-darwin.dmg\nOSX binaries archive: https://tn123.org/aria2/aria2-1.18.2-osx-darwin.tar.bz2\nTested: unit + libreoffice meta4 + libreoffice torrent\n@tatsuhiro-t Should be nice if you could cross-load these to sf.net\n. sf.net says:\n\n... Windows and Android binaries...\n\n@tatsuhiro-t Would be nice if it would say \"OS X\" as well. ;)\n. Yeah. The build was using the 0.9 headers (as indicated by the aria2c -v output) but was linking against 1.0. That sounds rather crashy, indeed. Seems like a problem with the library installation, not aria2... Unless there is something messed up in our configure. I'll check what happens if I brew link a non-system openssl...\n. Works for me:\nLibraries: zlib/1.2.5 libxml2/2.7.3 sqlite3/3.8.0.2 OpenSSL/1.0.1e c-ares/1.10.0\nBut mind a44c71586a42a2521dc9a0c6bd36f7aebe773c7c, which I previously forgot to push, in case you're using master.\n. You already fixed that, right? If you don't know of anything else that is pressing, I say: Just tag it now and release. Why wait?\n. https://tn123.org/aria2/aria2-1.18.3-osx-darwin.tar.bz2\nhttps://tn123.org/aria2/aria2-1.18.3-osx-darwin.dmg (default download)\nAs before, built with makerelease-osx.mk and further tested with a https, a metalink and a torrent download on a vanilla OSX 10.8.\nPlease cross-load to sf.net\n. Yeah, that seems to be a bug in gnutls, somewhere deep in the DER parser. The version that is currently on OSX brew 3.1.10 (they need to update :p) fails to parse the cert for me as well.\nIt appears they fixed that in 3.1.11 (while the latest 3.1.x is 3.1.18)\n. This is due to OCSP stapling that the aria2 GnuTLS configuration does not support.\n. The fix is to call gnutls_ocsp_status_request_enable_client(session, nullptr, 0, nullptr) where available (and verify_peers3)\n. I was wrong. gnutls_ocsp_status_request_enable_client is called in gtls_init anyway.\nI can see that stuff breaks after CERTIFICATE STATUS (OCSP stapling) in aria2 but not in gnutls-cli...\n. The handshakes in aria2 and g-cli (/usr/local/gnutls/bin/gnutls-cli -V -d9999 --x509cafile=/usr/local/share/ca-bundle.crt tn123.org) look exactly the same under WireShark and the GnuTLS logging (7777e1cb37c49bd3263df7c4b837816b4ebba341) up until CERTIFICATE STATUS...\nI guess I have to really debug the stuff now :p\n. OK. GnuTLS has a bug where non-blocking sockets together with CERTIFICATE STATUS don't work. I was able to fix that bug in my gnutls build. I don't think there is a viable work-around.\nhttps://gitorious.org/gnutls/gnutls/source/1b5fce89c569e4abf9784e6a2944b3ccf9dd61f8:lib/ext/status_request.c#L581\nThey are setting  priv->expect_cstatus = 0; before checking that they received a packet. If _gnutls_recv_handshake later fails (because it wasn't completely received yet), this causes subsequent calls, where the packet would be complete to bail without processing the packet, leaving it in the queue. Which causes the logic to skip out of STATE6 into STATE7 and then STATE8, where it expects a key exchange, but only finds the unprocessed CERTIFICATE STATUS.\nI'll ping bugs@gnutls.org now\n. >  I moved that line to after _gnutls_recv_handshake in gnutls-3.2.8 and it fixed the problem.\nYeah, I checked that myself and that seems to work. I'm not a GnuTLS expert though, so I don't know what else might break when doing so.\n. We could make it so that if the aria2 log level changes (e.g. by option processing) we would change the gnutls log level accordingly.\nBut the overhead should be mostly some string-formatting, which is kinda negligible, and of which we have a bunch in aria2 already (every time A2_LOG_*(fmt()) is called, no matter what the level is).\n. Affected: Likely all GnuTLS versions supporting OCSP stapling. Tested\nwith 3.1.18 and 3.2.8.\nSTR:\n- Program client using non-blocking sockets. Or if you're lazy, use\n  aria2, where we discovered this.\n  http://aria2.sourceforge.net/\n  https://github.com/tatsuhiro-t/aria2/issues/179\n  Or wget master, which is affected as well, or something like that.\n- Try to connect to a TLS server that uses stapling. E.g. https://tn123.org/\n- The connection will fail (more often than not), right after the full\n  CERTIFICATE STATUS packet is received, with:\n  \"An unexpected TLS handshake packet was received.\"\n- It fails in STATE8 of the handshake (kx) not STATE6 (CERTIFICATE STATUS).\nReasons:\nhttps://gitorious.org/gnutls/gnutls/source/1b5fce89c569e4abf9784e6a2944b3ccf9dd61f8:lib/ext/status_request.c#L581\n_gnutls_recv_server_certificate_status() does not handle incomplete\npackets (EGAIN) correctly.\nIt sets |priv->expect_cstatus = 0;| before actually checking if there\nwas already a full packet received. If there wasn't (and this is likely\nwith non-blocking I/O), the method will later exit, to be called again\nwhen additional data is received.\nHowever, in that subsequent call the function will bail without further\nprocessing as |priv->expect_cstatus| was already set in the first call,\nleaving the unprocessed CERTIFICATE STATUS packet in the buffers.\nAfter bailing, the STATE in _gnutls_recv_server_certificate_status()\ntransitions from STATE6 -> STATE7 -> STATE8. In STATE8,\n_gnutls_recv_server_kx_message() is called, with the CERTIFICATE STATUS\nstill in the buffer, and therefore fails as it rightfully didn't expect\nthat packet, aborting the connection attempt entirely.\nFix:\nA preliminary test indicates the attached patch (against 3_1_x, because\nI'm to lazy to build a nettle-2.7 right now) fixes the problem, by\nmoving |priv->expect_cstatus = 0;| after the |_gnutls_recv_handshake|\ncall. I'm not a GnuTLS expert, so I have no idea what it might break in\nturn.\nCheers\nNils\nPS: Please CC me if you need something, as I'm not watching the lists.\nFrom d6d4a177e9e705c4bbac0eaa689fa80025f52f71 Mon Sep 17 00:00:00 2001\nFrom: Nils Maier maierman@web.de\nDate: Mon, 6 Jan 2014 15:15:58 +0100\nSubject: [PATCH] Fix CERTIFICATE STATUS processing when using non-blocking I/O\n_gnutls_recv_server_certificate_status() must wait for the first full\npacket before setting priv->expect_cstatus = 0, or else CERTIFCATE\nSTATUS packets won't be processed in subsequent calls at all, leaving\nthem in the buffer and therefore causing later connection aborts.\nlib/ext/status_request.c | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\ndiff --git a/lib/ext/status_request.c b/lib/ext/status_request.c\nindex ac512c2..267ba5d 100644\n--- a/lib/ext/status_request.c\n+++ b/lib/ext/status_request.c\n@@ -574,28 +574,28 @@ _gnutls_recv_server_certificate_status (gnutls_session_t session)\n     _gnutls_ext_get_session_data (session, GNUTLS_EXTENSION_STATUS_REQUEST,\n                                   &epriv);\n   if (ret < 0)\n     return 0;\npriv = epriv.ptr;\nif (!priv->expect_cstatus)\n     return 0;\n-  priv->expect_cstatus = 0;\nret = _gnutls_recv_handshake (session, \n                                 GNUTLS_HANDSHAKE_CERTIFICATE_STATUS,\n                                 0, &buf);\n   if (ret < 0)\n     return gnutls_assert_val_fatal(ret);\n-  priv->expect_cstatus = 0;\n  +\n  data = buf.data;\n  data_size = buf.length;\n/* minimum message is type (1) + response (3) + data */\n  if (data_size == 0)\n   return 0;\n  else if (data_size < 4)\n   return gnutls_assert_val (GNUTLS_E_UNEXPECTED_PACKET_LENGTH);\n## if (data[0] != 0x01)\n1.8.5.2\n. That was the report I sent, FWIW.\n. > the current version of wget 1.14 does not make socket non-block during SSL/TLS handshake at least with GnuTLS, so it does not suffer from this bug.\nWe could do the same...\nAt least for known-problematic gnutls versions\n. FWIW, I'm not the only one using stapling:\nhttp://blog.cloudflare.com/ocsp-stapling-how-cloudflare-just-made-ssl-30\nhttps://wiki.mozilla.org/Security/Server_Side_TLS\n. > We won't. aria2 uses non-blocking socket entirely. If gnutls functions block, aria2 itself blocks, which violates the fundamental design of aria2.\nI know. I was just pondering if using blocking I/O just for affected gnutls versions and only during the handshake. After all, being blocking for short periods of time (in seconds) might be better than completely failing downloads...\n\nThe workaround would be use GNUTLS_NO_EXTENSIONS flag in gnutls_init() to disable OCSP stapling for buggy library version.\n\nMaybe, but this sounds like it might disable some other useful stuff...\n. From a GnuTLS developer.\n\nThank you. The fix seems correct and I'll apply it. As a work-around you may call gnutls_init() with the GNUTLS_NO_EXTENSIONS flag (when defined). The side effect would be to disable the OCSP status extension and the session ticket extension being enabled by default.\nregards,\nNikos\n. > We'll first identify the first version the bug was introduced and for those versions\n\nThey committed my patch to 3_2_x and 3_1_x, so versions starting with 3.2.9 and 3.1.19 should be good.\nThe stuff was first implemented and released in 3.1.3 and 3.2.0, meaning everything before that, incl. all branches before that, is unaffected.\nHence affected are only:\n- 3.1.3 - 3.1.18\n- 3.2.0 - 3.2.8\n\nI think this bug only affects client side code (correct me if I'm wrong).\n\nYep, only client side.\n. Works for me after 2f02946\nI guess this bug can be closed now?\n. > It sounds like a serious flaw. I think we should remove JSON-RPC using HTTP GET.\nEven then, you can still create a POST form and just submit...\n. > Even then, you can still create a POST form and just submit...\nScratch that. JSON-RPC is a plain JSON \"DSL\", which you cannot generate using simple form-post.\n. Lets not forget that WebSocket is affected as well. They start out as GET requests, after all...\n. Although it is not technically the problem of aria2 that web browsers suck (for historical reasons) when it comes to HTTP Auth, we should nonetheless close this attack vector.\n1. We should disable HTTP GET/jsonp. You cannot get this secure.\n2. HTTP Auth with WebSockets has the same problems.\n   1. So don't use it and don't accept it.\n   2. WebSockets do not allow to set arbitrary headers. However using the protocol parameter, it can pass Sec-WebSocket-Protocol, which we can (ab)use.\n   3. The application would have to send the credentials in the Sec-WebSocket-Protocol header instead of Authorization.\n3. Using CORS XHR POST (instead of that jsonp crap, like webui does right now) does not work in current browsers, as you cannot use credentials.\n   1. The XHR spec disallows using username and password for CORS requests, so this won't fly.\n   2. The XHR spec requires the server to have Access-Control-Allow-Credentials: true in the headers when using .withCredentials.\n   3. Therefore you cannot right now do CORS XHR POST requests in a browser to aria2 when running with --rpc-user.\n   4. Hence implement Access-Control-Allow-Credentials: true.\n4. Running aria without --rpc-user is insecure no matter what.\n   1. We should change it so that aria2 refuses to enable RPC if no user/pass are specified\n   2. For user freedom and enhanced shoot-yourself-in-the-foot-ness lets create a new option switch that lets override this behavior.\nThe proposed changes would not affect existing HTTP POST users incl. XML-RPC users, would enable browser application to use HTTP POST in the first place, would require existing WebSocket users to adapt the Authorization stuff, which shouldn't be too hard, and will require HTTP GET/jsonp users to choose another method.\n@tatsuhiro-t Thoughts?\n. > Since this is some kind of xsrf, checking referer would help.\nThe referrer is not a security mechanism.\nThe referrer is not always sent\n- It is not sent with WebSocket requests. (There might be an Origin header instead)\n- It is not sent with certain types of HTTPS traffic\n- It is not sent for requests originating from the file: and data: and blob: protocols\n- It is not sent with certain types other requests, and it is not sent when the user disables sending it.\nEssentially it sucks.\nE.g. here is how to do a browser request without a referrer:\njs\nfunction framescript() {\n  var s = document.createElement(\"script\");\n  s.setAttribute(\"src\", \"http://localhost:6800/jsonrpc?jsoncallback=abc&method=aria2.addUri&id=foo&params=W1siaHR0cDovL3MuYmludXgubWUvYXJpYTIvcmVzb2x2LmNvbmYiXSx7Im91dCI6InJlc29sdi5jb25mIn1d\");\n  document.documentElement.appendChild(s);\n}\nvar data = \"data:text/html,<!doctype html><script>(\" + encodeURIComponent(framescript.toString() + \")()</sc\" + \"ript>\");\nvar iframe = document.createElement(\"iframe\");\niframe.setAttribute(\"src\", data);\ndocument.body.appendChild(iframe);\n(Same would work for XHR, of course)\nSo you could require clients to send a referrer.\nWhich would immediately break all non-browser clients (aka. my python scripts) and some browser clients (as described above). And still does not solve the WebSocket stuff ;)\n. > For non browser client, if you are not going to use aria2 with browser, just turn off the origin check.\nThat's the problem: It is not up to you to decide if the browser \"uses\" aria2. A rogue website may always forge requests to localhost. So if you turn off the origin check so that stuff works again with your non-browser client, you also expose yourself to browser-based attacks.\nI'm not opposed to having an additional option to check the referrer. But this would be just a small additional wall to climb.\n\nI now read your proposal and it sounds reasonable to me. Did you check that this mehod works with current chrome and firefox?\n\nI just finished implemented 1. - 3. and checked that POST and WebSocket works in Firefox and Chrome Deskop and it does.\nIt not a lot of code...\nDid not test any mobile versions, but at least in the case of Firefox, there should be no problem as it uses the same implementation. I'd think the same is true for chrome.\nIt's late now... I'll post a first pull request tomorrow or something like that.\n. PS: I'll also implement the required changes for webui-aria2 to see if stuff really works.\n. I came to the conclusion by now that CORS XHR POST is just as dangerous as HTTP GET when it comes to Authorization, unless you construct the header like you do. Not sure if this is a browser bug, that allows to do so, or not...\nI'll probably implement the POST stuff differently:\n- Do not define Access-Control-Allow-Credentials: true, as this would enable cached credentials.\n- Allow clients to (ab)use the manual Authorization header trick above.\n- Extend the JSON-RPC stuff to allow specifying a user/pass combo in the request json per call in case the trick does not work for whatever reason.\n. We already kinda got a shared secret for this... username + password. ;)\nThis is something users can understand and remember. Creating another type of shared secret/token might have some upsides, but the big drawback is that you need to remember it.\nLet me make this proposal, that is also as backwards-compatible, as it gets.\n1. Implement WebSocket Sec-WebSocket-Protocol based auth the way I already proposed. (I already implemented this, and verified this works as a concept).\n2. Implement the RPC enhancements, so that each RPC method get a new implicit optional parameter token.\n3. The HTTP Server does not really authorize anything anymore. Instead the authorization happens in the RPC methods (RPC authorizer).\n4. The HTTP Server still parses HTTP POST Authorization and HTTP WebSocket Sec-WebSocket-Protocol and provides it in public method, like string getRequestToken().\nThe application token (shared secret):\n1. If either <rpc-user> or <rpc-password> or both are set, where both are global configuration options, let the application token be the string value of base64(\"<rpc-user>:<rpc-password>\").\n2. Otherwise let the application token be the empty string.\n3. Backward compatibility The token is composed the same way as HTTP Basic Auth.\nThe request token:\n1. Backward compatibility Have the HttpServer parse the request to produce a request token, if provided.\n   1. If the request is a POST, let the request token be the base64-encoded user:password combination from the Authorization header, verbatim.\n   2. If the request is a WebSocket Upgrade, let the request token be the result of replace(protocol, \"-\", \"=\"), where protocol should be the value of the Sec-WebSocket-Protocol header. If there are multiple such headers, the result is undefined. The replacement is made to work around some restrictions to the charset of SWSP some browsers impose (aka. Chrome).\n   3. Otherwise, let the request token be the empty string.\nThe RPC token:\n1. All RPC methods get an implicit token parameter of type string added to their signature in the first parameter position.\n   - E.g. aria2.addUri(uris[, options[, position]]) -> aria2.addUri([token,] uris[, options[, position]])\n   - Prepending the new parameter to the list has the upside that methods with trailing optional parameters are easier to use.\n2. The value of the token parameter must be token:<value>.\n3. The RPC parser will inspect the call arguments. If the first argument is a string and that string starts with token:\n   1. Chop off the token: prefix and put the remainder into RPC token.\n   2. Pop the first parameter (the token parameter) from the parameter list.\n4. Otherwise, do nothing.\n5. The default value of the RPC token is the empty string.\n(I opted for this instead of creating two version of each RPC call, one with and one without token)\nThe RPC authorizer will use the following algorithm to authorize requests:\n1. Let userToken be the string value RPC token.\n2. Let hasTokenParameter be a boolean result of empty(userToken).\n3. Backward compatibility If hasTokenParameter is false, assign userToken the string value of request token\n4. Compare case-sensitive string equality of userToken and the application token.\n   1. If both string are empty, the result is true (equality).\n5. If the result of the comparison is false (non-equal), then abort the call.\n   1. If hasTokenParameter is true, return an RPC failure response.\n   2. Backward compatibility Otherwise, let the HttpServer either return HTTP 401 for POST or 403 for WebSocket.\n6. Otherwise, the results match, continue with the RPC call.\nThis still allows to auth POST the usual way with HTTP Basic auth, and WebSocket the alternative way with Sec-WebSocket-Protocol \"auth\".\nThis proposal would allow allow to keep GET/JSONP in place, as it would disregard HTTP auth for GET and rely solely on RPC token for authorization.\nDiscuss! ;)\n. I got a working implementation of the above solution now that I tested did some preliminary tests, incl. patching up webui-aria2 to work with websockets and jsonp with auth.\nSo far: 22 files changed, 322 insertions(+), 118 deletions(-)\nThat's just the implementation. The test suite is somewhat broken right now, as I didn't fixup the tests yet and also didn't write new one for the auth stuff. And also documentation is still missing. My allotted aria2 time for today is exhausted now, so I'm gonna look into the remainder tomorrow.\n. > We should not abuse Sec-WebSocket-Protocol for our security purpose, because such hack could be broken unexpected way. Actually, we don't need any header field stuff for websocket because we are going to add access token to the each json-rpc payload.\nThe protocol stuff is in the RFC and shipped with browsers, so it is unlikely to be broken at this point. Just saying.\nAnd even if it broken, you could still use RPC tokens with WebSocket.\n\nWe should not autodetect access token parameter in RPC method. We use token as security measure, so we have to be explicit about it. \n\nThis will break the API and _all_ clients with it. There is no point then in keeping HTTP auth around, at all, as all clients will have to adapt anyway.\nUnless you proposing to make the token the last optional parameter to all API calls. But that sucks. because then users will have to provide values for all optional parameters that come before that. And also it wouldn't be explicit.\n\nActually, I don't want to spend much energy for backward compatibility. The current scheme is insecure, so we are going to add new scheme.\n\nThen lets be swift about it and just rip out the the Http Auth stuff entirely now incl. rpc-user and rpc-password, and change the API to have an explicit token parameter, always and add --rpc-token.\nI still think that we shouldn't break _all_ clients, and we don't have to with my proposal. My proposal does just break browser users, and deservedly so, as in a browser context it is insecure right now to access aria2.\nSo I'm still favoring my approach.\n. > No. I wrote that 1st parameter of RPC method must be access token only when new auth scheme is enabled. If not enabled, the methods do not take access token parameter and behaves just like before.\nOK, I misunderstood you there. I didn't expect that you meant to enable the new auth stuff only in certain circumstances, as it contradicts your \"don't want to spend much energy\" point.\n\nNew scheme is not enabled, then it is completely backward-compatible (well, actually it is not changed at all).\n\nYes, and as insecure as before!\n\nIt is defined for announcing subprotocol. Not for sending something rather.\n\nAnd aria2 would use it as such. If you use the \"token\" subprotocol, you switch to a sub protocol where you don't need to specify tokens in the RPC requests. I fail to see how my use contradicts the spec.\nAnyway, as I said the  WebSocket stuff is just an optional way to auth.\n. Just so that we know what we're talking about:\nhttps://github.com/tatsuhiro-t/aria2/commit/c6b9bb919a949318aa779bf5fcf593eeebac0768 is the full implementation of my proposal incl. docs and auth unit tests.\nAs you can see, the required code changes are minimal and not very intrusive.\nIt also wouldn't be hard to adapt this to your counter proposal: Rip out the WebSocket protocol and HTTP auth stuff and make the token parameter mandatory instead of optional.\nI still don't think breaking all RPC clients is the way to go.\n. Gimme an 1.18.4 tag, and I'll give you an OSX build. ;)\n. OSX build:\nhttps://tn123.org/aria2/aria2-1.18.4-osx-darwin.dmg\nhttps://tn123.org/aria2/aria2-1.18.4-osx-darwin.tar.bz2\n. To be honest, it is undesirable for me to contribute under GPLv3 only, to give an opposite opinion to GPLv3. You might say I'm more in the Torvalds camp than in the Stallman camp. I also kinda like MIT/BSD licenses (for libraries, anyway).\nAs I said, just wanted to give my opinion, given that I'm one of the few people listed in AUTHORS.\nI'll gladly follow any reasonable changes the maintainer and primary author (@tatsuhiro-t) proposes.\n. https://tn123.org/aria2/aria2-1.18.5-osx-darwin.dmg\nhttps://tn123.org/aria2/aria2-1.18.5-osx-darwin.tar.bz2\n. Facebook does not support Basic-Auth, neither for their actual site, nor for their API endpoints.\nYou might have better luck with cookies: aria2c --help=cookie.\nClosing as this is not actually a bug.\n. Should be noted that some old httpds (apache 1.x e.g., which is still in production) do not handle large files correctly themselves. E.g. Content-Length: -1203881. This is more of a problem with download resuming/segmented downloads (Http Range requests) than with \"unknown length\" downloads, which usually are a result of of some dynamic backend. Then again old PHP versions also have issues handling large files and/or aren't even compiled against large file support.\nSo aria2 should make sure it handles large files correctly whenever it can, but there are some instances where large file handling is not possible because the server (backend) is broken...\n. @tatsuhiro-t Could you review the code. With the code I'm able to complete large transfers (>4GB tested) lacking a Content-Length header, at least on OSX.\n. And on Debian squeeze...\n. There is an API change as the gnutls_init signature changed between GnuTLS 2.x and GnuTLS 3.x. The current code will not compile with 2.x. I already have a fix that seems to be working... Need to test some configurations and will then commit.\n. Yes. it uses the system cert store. In theory it should be good to go. In practice I'd like to re-review my code and do some formal testing to make sure everything works as expected first. I wouldn't be opposed to experimental builds at this point, however.\n. - Alright, played a bit with https://github.com/iSECPartners/tlspretense and WinTLS/AppleTLS, At least those 24 tests pass.\n- I found an issue with CRL/OCSP handling: When there is no provider url in a root certificate, WinTLS will reject the cert chain. This is contrary to what our other SSL implementations do and what browser do (IE, Firefox, Chrome).\n- I verified via https://test-sspev.verisign.com:2443/test-SSPEV-revoked-verisign.html that revoked certificates will still be rejected.\n- I verified that --check-certificate=false works with self-signed and revoked certs.\n- I now turned on SCH_USE_STRONG_CRYPTO, which will effectively disable suites that Windows considers weak (on supported Windows versions), Right now it will disable the RC4 suites. Those Windows versions that support this flag also use BEAST mitigation, so this is a non-issue AFAIK.\n- The suite aria2 advertises in ClientHello is now the same as IE11 (sans RC4), which is not surprising given both WinTLS and IE11 use Schannel.\n- On an unrelated note, I also improved AppleTLS cipher suite selection.\n- I re-reviewed the WinTLS* and WinMessageDigestImpl.cc (also enabled by WinTLS) code, and found some smallish things to improve but no real issues.\nI think WinTLS is good to go now.\nI'd still recommend to have the Windows build link libgmp for a faster and maybe more secure DH KeyEx (any SSL/TLS related DH stuff is performed by Windows, this just matters for BitTorrent). More secure as in: I committed mpz_powm_sec support, available in GMP6, which should make it harder to perform timing attacks (not that timing attacks in the BitTorrent DH KeyEx stuff would be really grave to begin with).\nAlthough you need to make sure not to compile GMP CPU specific (IIRC by specifying an explicit -march) and maybe doing a FAT gmp build (--enable-fat, mutli-CPU, runtime targetted)...\n. > So the new library configuration becomes like this:\nYes.\n\nSo we need to build gmp with -enable-fat for windows as well?\n\nWell... \"need\" is overstated.\nAt the very least you need to specify some CFLAGS at configure-time, or else gmp will target either the build CPU (which will crash on older CPUs) or in case of cross-compiles, will target pentiumpro for x86 and k8 for x86_64 specifically, which isn't optimal in any way.\nSo better use something like CFLAGS=\"-mtune=generic -O2 -g0\".\n--enable-fat will turn on runtime CPU detection, and therefore compile all available optimizations. That makes a \"fat\" binary (hence the name), but will outperform the default binaries on most CPUs, the more modern the better as a rule of thumb.\nSo here is some stupid micro benchmark I did:\nFirst build GMP:\nsh\n../gmp-6.0.0/configure --prefix=/Users/maierman/dev/aria2/build-win32 --host=i686-w64-mingw32 --enable-static --disable-shared --disable-cxx CFLAGS=-mtune=generic -O2 -g0\nmake -sj5 install-strip\nSame thing a 2nd time with --enable-fat.\nThen build aria2c so I can benchmark the actual code (DHKeyExchange):\nsh\n../configure --prefix=/Users/maierman/dev/aria2/build-win32 --host=i686-w64-mingw32 ARIA2_STATIC=yes --enable-static --disable-shared --enable-libaria2 --with-wintls --with-libgmp --without-libxml2 --without-libexpat CPPFLAGS=\"-isystem /Users/maierman/dev/aria2/build-win32/include\"\nmake -sj5 install-strip\nNow a micro benchmark bench.cc, based on the unit test:\n``` c++\n// Stupid micro-benchmark\ninclude \"DHKeyExchange.h\"\ninclude \"util.h\"\ninclude \"aria2/aria2.h\"\ninclude \ninclude \ninclude \ninclude \ninclude \ninclude \nusing namespace aria2;\nstatic bool test()\n{\n  DHKeyExchange dhA;\n  DHKeyExchange dhB;\nconst unsigned char* PRIME = reinterpret_cast(\"FFFFFFFFFFFFFFFFC90FDAA22168C234C4C6628B80DC1CD129024E088A67CC74020BBEA63B139B22514A08798E3404DDEF9519B3CD3A431B302B0A6DF25F14374FE1356D6D51C245E485B576625E7EC6F44C42E9A63A36210000000000090563\");\nconst size_t PRIME_BITS = 768;\nconst unsigned char* GENERATOR = reinterpret_cast(\"2\");\ndhA.init(PRIME, PRIME_BITS, GENERATOR, 160);\n  dhB.init(PRIME, PRIME_BITS, GENERATOR, 160);\ndhA.generatePublicKey();\n  dhB.generatePublicKey();\nunsigned char publicKeyA[96];\n  unsigned char publicKeyB[96];\n  dhA.getPublicKey(publicKeyA, sizeof(publicKeyA));\n  dhB.getPublicKey(publicKeyB, sizeof(publicKeyB));\nunsigned char secretA[96];\n  unsigned char secretB[96];\n  dhA.computeSecret(secretA, sizeof(secretA), publicKeyB, sizeof(publicKeyB));\n  dhB.computeSecret(secretB, sizeof(secretB), publicKeyA, sizeof(publicKeyA));\nreturn util::toHex(secretA, sizeof(secretA)) == util::toHex(secretB, sizeof(secretB));\n}\nclass Timer {\n  LARGE_INTEGER start, persec;\npublic:\n  Timer() {\n    QueryPerformanceFrequency(&persec);\n    QueryPerformanceCounter(&start);\n  }\n  double time() {\n    LARGE_INTEGER end;\n    QueryPerformanceCounter(&end);\n    return (double)(end.QuadPart - start.QuadPart) / persec.QuadPart;\n  }\n};\nint main()\n{\n  static const auto kIterations = 1000u;\n  static const auto kRuns = 10u;\naria2::libraryInit();\nif (!test()) {\n    throw std::exception();\n  }\nstd::set runs;\n  for (auto r = 0u; r < kRuns; ++r) {\n    std::cerr << \"Run: \" << (r+1) << \"... \";\n    double s;\n    {\n      Timer t;\n      for (auto i = 0u; i < kIterations; ++i) {\n        test();\n      }\n      runs.insert(s = t.time());\n    }\nstd::cerr << \"done in \" << std::fixed << s << std::endl;\n\n}\nruns.erase(runs.begin());\n  runs.erase(runs.begin());\n  runs.erase(runs.rbegin());\n  runs.erase(runs.rbegin());\ndouble avg = std::accumulate(runs.begin(), runs.end(), 0.0) / runs.size();\nchar cpu[0x20];\n  memset(cpu, 0, sizeof(cpu));\n  char brand[0x40];\n  memset(brand, 0, sizeof(brand));\n  int info[4];\n__cpuid(info, 0);\n  ((int)cpu) = info[1];\n  ((int)(cpu+4)) = info[3];\n  ((int)(cpu+8)) = info[2];\n__cpuid(info, 0x80000002);\n  memcpy(brand, info, sizeof(info));\n  __cpuid(info, 0x80000003);\n  memcpy(brand + 16, info, sizeof(info));\n  __cpuid(info, 0x80000004);\n  memcpy(brand + 32, info, sizeof(info));\nstd::cout << cpu << \" - \" << brand << std::endl;\n  std::cout << kIterations << \" iterations took \" << std::fixed << avg << \" seconds on average\" << std::endl;\n  return 0;\n}\n```\nBuild bench.exe:\nsh\ni686-w64-mingw32-g++ -std=c++11 -O2 -g0 -I../src -Isrc -I. -Iinclude -DHAVE_CONFIG_H -L/Users/maierman/dev/aria2/build-win32/lib -Wl,--allow-multiple-definition -Wl,--nxcompat -Wl,--dynamicbase -static-libgcc -static-libstdc++ -o bench.exe bench.cc lib/libaria2.a lib/libgmp.a -lws2_32 -lwsock32 -lgdi32 -lwinmm -liphlpapi -lpsapi -lcrypt32 -lsecur32 -ladvapi32\nAnd the results:\n``` text\nResults GenuineIntel - Intel(R) Core(TM)2 Quad CPU    Q9650  @ 3.00GHz\nBaseline\n1000 iterations took 1.858717 seconds on average\nFat\n1000 iterations took 1.314031 seconds on average\nDifference\n~141%\nResults GenuineIntel -        Intel(R) Core(TM) i7-2677M CPU @ 1.80GHz\nBaseline\n1000 iterations took 1.633014 seconds on average\nFat\n1000 iterations took 1.088859 seconds on average\nDifference\n~150%\n```\nSo in conclusion WIN32 --enable-fat is up to 1.5x as fast (the more modern a CPU is).\nOn WIN64 the gap should be less significant, as AMD64 includes at least SSE2 and the compiler and gmp knows that.\n. Since this will be in the official builds now, wintls should be enabled in a default configure (right now you need to explicitly --with-wintls) and remarks about the experimental status should be stripped.\n. Can be closed now, can it?\n. Same as #216 \n. Please tell me if this is OK in general, but don't push yet. I'd like to fix some typos in the comments and stuff first (the code should be OK, though)\n. Well, it certainly would be possible to make PBKDF2 into an operation that can be executed in steps. I mean, it has iterations... ;) It would require some additional stuff though, like creating an per-request HMAC instance, which would have some additional CPU and memory overhead.\nBut I wouldn't split it into interleavable chunks, for a couple of reasons:\n1. You can already DoS the RPC server by flooding it with requests and other means. PBKDF2 would certainly make things a bit worse, as requests would take longer to clear, but the underlying problem still is the same.\n2. PBKDF2 is a crypto and therefore kinda critical code in general. I would want to avoid to stray too much from the reference implementation. You must be still able to reason concisely about the code and split+interleave doesn't make things easier...\n3. There is little gain. You can do pretty good guesses as to how long the operation will take for a given HMAC and iteration count. That's what the initial setup in DownloadEngine already does, where I have it at about 0.06 - 0.12 seconds per attempt. I also have some code I'll push short shortly to this PR branch that will use a rolling average to make sure the operation still performs within the desired time limits or re-setup, should the system get faster or slower (other programs cause more or less load). We can pretty much tune it to any reasonable time limits. I just initially chose 10-15 attempts per second.\n4. There is ought to be little gain performance wise generally, especially compared to the file I/O performed on same main thread, which can be in the seconds range and also pauses everything else.\n5. The more important thing to do is making sure at the Engine level that HTTPServer commands (auth or not) do not starve downloads and vice versa. E.g. you could have \n. Forgot to close this ticket ;)\n. @sambul13 it appears that aria2 does start. But since it was called only with the default config and without any additional configuration (config file or command line), it does what it is supposed to do and just prints the short usage text and exits.\nYou need to use e.g. --enable-rpc or make sure there is a preexisting readable config file doing the same. \n. Pushed with typos fixed.\n. Just out of curiosity: What is your OS and compiler?\n. I requested access to the aria2 coverity project in a contributor role. Would be nice if you granted it. ;)\n. @tatsuhiro-t I did just that: submit a new build and it went through fine. Right now I'm fixing the low-hanging fruits.\n. Alrighty.\n\n. The former was a mistake in my formatting rules. Will fix.\nThe latter: I'll fix the if stuff where it is inconsistent with the rest of the file.\n. I don't really know if it is OK or not per C++11, either... But yeah, getting Coverity coverage again seems more important.\n. The easiest thing for now would adding an option. Additionally one could think about automatically using longer intervals when the active/waiting queues are empty and the only thing keeping the aria2c process alive is the rpc server.\n. E.g. --version\ntext\nCompiler: Apple LLVM 5.1 (clang-503.0.40)\n  built by   x86_64-apple-darwin13.2.0\n  on         May 30 2014 00:09:10\nSystem: Darwin Kernel Version 13.2.0: Thu Apr 17 23:03:13 PDT 2014; root:xnu-2422.100.13~1/RELEASE_X86_64\ntext\nCompiler: clang 3.3 (tags/RELEASE_33/final 183502)\n  built by   amd64-unknown-freebsd10.0\n  on         May 30 2014 03:23:35\nSystem: FreeBSD 10.0-RELEASE FreeBSD 10.0-RELEASE #0 r260789: Thu Jan 16 22:34:59 UTC 2014     root@snap.freebsd.org:/usr/obj/usr/src/sys/GENERIC amd64\ntext\nCompiler: gcc 4.7.2\n  built by   x86_64-unknown-linux-gnu\n  on         May 30 2014 03:33:50\nSystem: Linux 2.6.32-5-amd64 #1 SMP Mon Feb 25 00:26:11 UTC 2013 x86_64\ntext\nCompiler: mingw-w64 4.0 (alpha) / gcc 4.8.2\n  built by   x86_64-apple-darwin13.2.0\n  targetting i686-w64-mingw32\n  on         May 30 2014 03:35:35\nSystem: Windows 7 (Service Pack 1)\n. That should be mostly due to the PBKDF2 test with 16777216 iterations.  It should be OK to disable; the other tests should still suffice.\n. So this is OK to be merged then?\n. Probably a good idea to make this a -with-default-off switch\n. @tatsuhiro-t Here are the osx binaries, freshly build and tested against the LibreOffice meta4 and torrent (along with make check of course):\nhttps://tn123.org/aria2/aria2-1.18.6-osx-darwin.dmg\nhttps://tn123.org/aria2/aria2-1.18.6-osx-darwin.tar.bz2\nThese are smaller than the previous ones because they are not universal anymore (dropped support for very old 32-bit-only macs) and use LTO for most things.\n. @tatsuhiro-t Since you commented elsewhere, I wonder if you missed the notification for the OSX builds? If you didn't and I'm just nagging, please excuse that ;)\n. LOL, so nevermind my last comment :p\n. Same as #241\n. Probably not, because that would require patching large areas of the code.\n\nThe NaCl sandbox ensures that code accesses system resources only through safe, whitelisted APIs, and operates within its limits without attempting to interfere with other code running either within the browser or outside it.\n\nAnd (from their FAQ):\n\nThe following kinds of code may be more challenging to port:\n-  Code that does direct TCP/IP or UDP networking. For security reasons these APIs are only available to packaged applications, not on the open web, after asking for the appropriate permissions. Native Client is otherwise restricted to the networking APIs available in the browser.\n-  Code that creates processes, including UNIX forks. Creating processes is not supported for security reasons. However, threads are supported.\n-  Code that needs to do local file I/O. Native Client is restricted to accessing URLs and to local storage in the browser (the Pepper file I/O API has access to the same per-application storage that JavaScript has via Local Storage). HTML5 File System can be used, among others. For POSIX compatabiliy the Native Client SDK includes a library called nacl_io which allows the application to interact with all these types of files via standard POSIX I/O functions (e.g. open/fopen/read/write/...). See Using NaCl I/O for more details.\n\nSo, you'd need to throw out all of the custom networking code and switch to NaCl APIs, throw out all of the file I/O stuff and switch to NaCl APIs and probably more.\n. Ah, they created a compat-lib by now. Interesting... Anyway you still have no access to the actual file system... So that kinda sucks ;)\n. I second the idea.\nHowever, this implementation isn't round-robin, it is some random distribution...\n. And actual round-robin implementation would be better IMO\nI got curious what rand() % num would actually mean in this context.\nA common rand() % num will cause about 1 / num \"repetitions\", where a repetition means that the result of the call will be the same as the result from the last call [1]. Given that most dns servers will reply with 3 - 4 entries for a given name at most, this means no good things:\nE.g. when split=6 and you got 3 dns entries for a name this will quite often produce sequences like 2,2,1,2,2,3, where 2 is clearly over-represented. A true round robin would produce 1,2,3,1,2,3 instead, giving equal representation.\nI guess, it would be easy enough to just shift the addresses in findAllCachedIPAddresses and do a round robin by this. But rand() is still better than nothing, though.\nMoreover aria2 does not (necessarily) seed rand() anymore, so it would be better get a number from SimpleRandomizer::getInstance().\n[1]\n``` c\ninclude \ninclude \ninclude \ninclude \nstatic const int iterations = 100000;\nint main() {\n  // aria2 does not seed anymore btw.\n  srand(getpid());\nfor (int n = 2; n < 20; ++n) {\n    int repeated = 0;\n    int last = rand() % n;\n    for (int i = 0; i < iterations; ++i) {\n      int new = rand() % n;\n      if (new == last) {\n        ++repeated;\n        continue;\n      }\n      last = new;\n    }\ndouble expected = 100.0 / n;\ndouble actual = repeated * 100.0 / iterations;\ndouble diff = fabsl(expected - actual);\nprintf(\"%2d: %6d (%5.2f%%, expected %5.2f, d %5.3f) repetitions\\n\",\n        n,\n        repeated,\n        actual,\n        expected,\n        diff\n        );\n\n}\n  return 0;\n}\n```\ntext\n$ cc -std=c99 rand.c && ./a.out \n 2:  49824 (49.82%, expected 50.00, d 0.176) repetitions\n 3:  33495 (33.49%, expected 33.33, d 0.162) repetitions\n 4:  24929 (24.93%, expected 25.00, d 0.071) repetitions\n 5:  20093 (20.09%, expected 20.00, d 0.093) repetitions\n 6:  16553 (16.55%, expected 16.67, d 0.114) repetitions\n 7:  14330 (14.33%, expected 14.29, d 0.044) repetitions\n 8:  12553 (12.55%, expected 12.50, d 0.053) repetitions\n 9:  11266 (11.27%, expected 11.11, d 0.155) repetitions\n10:   9790 ( 9.79%, expected 10.00, d 0.210) repetitions\n11:   9078 ( 9.08%, expected  9.09, d 0.013) repetitions\n12:   8250 ( 8.25%, expected  8.33, d 0.083) repetitions\n13:   7780 ( 7.78%, expected  7.69, d 0.088) repetitions\n14:   7290 ( 7.29%, expected  7.14, d 0.147) repetitions\n15:   6725 ( 6.72%, expected  6.67, d 0.058) repetitions\n16:   6319 ( 6.32%, expected  6.25, d 0.069) repetitions\n17:   5891 ( 5.89%, expected  5.88, d 0.009) repetitions\n18:   5626 ( 5.63%, expected  5.56, d 0.070) repetitions\n19:   5310 ( 5.31%, expected  5.26, d 0.047) repetitions\n. Might be a duplicate of #215. Any change you could provide a --log=?\n. The point is to not answer too fast, so 3ms is not a good idea.\nReliably delaying the auth response if it is a failure for at least a certain amount of time is an option, though.\n. I'm working on it now...\n. Alright, initial implementation of a DelayedCommand to full auth-failure delays, and said auth-failure delays instead of PBKDF2. Right now, the delay is hard-coded at 1s, which is the smallest value the underlying TimeBasedCommand supports.\n. Should I merge the RLIMIT and auth stuff now, or do you want to wait?\n. I'm building the darwin release right now: Related to this I found that the release tag is missing in the repo. Since the darwin build script relies on it, this is a bit inconvenient. So I created on locally, but didn't push it.\n. For sf.net:\nhttps://tn123.org/aria2/aria2-1.18.7-osx-darwin.dmg\nhttps://tn123.org/aria2/aria2-1.18.7-osx-darwin.tar.bz2\n. Cannot reproduce on Fedora x86_64 using the repo-provided gcc. Also, it's a linker error. Do you link with binutils-ld or gold?\nPlease do fully a clean build (fresh clone if you have to). Sometimes when the Makefile etc. changes some things get \"stuck\" in the make/automake generated dependency files.\n. @tatsuhiro-t Agreed, #275 shouldn't be a blocker.\nI'm not sure about the OSX issue at all and cannot reproduce at the moment as on 10.9 I cannot reproduce and I don't have a 10.7 VM handy anymore. Might be even a compiler bug or a bug in the somewhat older libc++ that comes with 10.7 (I'm using the 10.9 toolchain targeting 10.7).\n. @tatsuhiro-t OSX builds:\nhttps://tn123.org/aria2/aria2-1.18.8-osx-darwin.dmg (default download)\nhttps://tn123.org/aria2/aria2-1.18.8-osx-darwin.tar.bz2\n. No real idea here... Never saw anything like this. Looks like it might be dereferencing some kind of shared_ptr that is a nullptr. Or not. The binary is stripped, so there is no debug information, and the toolkit on 10.7 sucked anyways.\n@eedlund Does it also happen when you build from source?\n. @eedlund You'll need to build using clang, so configure ... CC=clang CXX=clang++ should always work (when you have XCode or at least the command line tools installed). The gcc that Apple ships is actually some llvm-gcc compatibility layer with gcc-4.2 compatibility what does not support C++11 at all (and never will). This is the easiest thing and also how I build the binaries. (An alternative real gcc is also possible, but getting this even to work is kinda a PITA and doesn't worth the fuzz).\n@tatsuhiro-t Maybe we should teach configure to check for cc/c++ instead of gcc/g++ by default? Proper linux distros should have these symlinked to gcc anyway, and OSX symlinks these to clang. (Hmm.. There might be problems on old/arcane Solaris where cc symlinks to SunCC instead of gcc/clang, not sure..)\nOr at the very least do this for OSX?\n. @eedlund Nope, the warnings shouldn't be relevant and I know they are there. This is just some compatibility stuff so code compiles on OSX 10.7 and 10.8 at the same time.\n. @eliezedeck What's the problem with compiling master on OSX10.9? I just did the same, and it worked? Maybe broken configure script (due to missing configure.ac dependencies?)\n. Interesting. Didn't see this on Win7. Or maybe I was just using the wrong clients? But yeah, the recv() == 0 handing is bad. Anyway, I'm going to push a polished fix based on @tatsuhiro-t's fix once I verify stuff.\n. Yeah. I finally reproduced this myself.\n. Alright. Turns out closeConnection is actually broken as well, in the || vs && sense :p\n. Uh, I see you were busy already via 73d752fb1cd01a9092191c9ac52ddb8fa378065f \n. I still think aria2c should issue a warning when SSLv3 is actively in use.\n. Yeah, I was planning to test the stuff myself this weekend.\n. Over to #314.\n. Yeah, if you got no objections...\n. Let me know if it looks good to you, and I'll squash/rebase/commit\n. Since you tagged the release, I produce the builds already.\nmake check and a manual meta4 and a manual magnet and a manual https download where successful.\n- https://tn123.org/aria2/aria2-1.18.9-osx-darwin.dmg (default download)\n- https://tn123.org/aria2/aria2-1.18.9-osx-darwin.tar.bz2\n. Sounds like you should just do something like aria2c --rpc-secret=\"$(runsomecommand)\"?\n. Are there servers returning +0200 etc and is that handled?\n. Sorry, I removed the offending code already.\n. @akashihi  Sounds like you forgot to run autoreconf -fiv again after pulling...\n. Seeing that, it would be good to know what rv actually was at that point...\nIn theory, since we call getrandom in urandom and blocking mode, the call should not fail. Turns out that there are four instances where this is not the case:\n1. The kernel is totally borked. (E?)\n2. The buffer is bogus (outside of address space) (EFAULT)\n3. The pool is not initialized AND there was an interrupt (EINTR)\n4. The request is a large request (>256b) AND there was an interrupt (EINTR)\nI developed the initial patch on Arch as well, but was not seeing this problem there, hmm.\nAnyway, I'll write some code to handle EINTR and \"short\" returns (although short returns should not happen at all) and add some additional output to the failure case.\n. @nkhdiscovery Do you have any more details on step to reproduce?\n. @tatsuhiro-t Any objections?\n. @nkhdiscovery Any chance you can try this branch yourself?\n. hmm. interesting. 38 should be ENOSYS aka. not implemented. That shouldn't happen unless the linux headers and the kernel are a mismatch.\n. Alright, I'll write some more code to handle ENOSYS gracefully and fall back to the generic implementation if encountered.\n. @ClaudiaJ Yeah, that's the problem right there. You got the usual 3.18 linux headers, but the kernel is in fact only 3.16 (from Linode). Looking closely at the output from @nkhdiscovery it says Linux 3.15.8-1-ARCH, so same issue.\n@ClaudiaJ and/or @nkhdiscovery can you retry this branch? I pushed again and hope this latest commit handles the missing syscall/implementation gracefully now.\n. Either that, or split it by (broad) topic.\n. util.cc itself seems to compile fine for me for now. It's just UtilTest.cc, which additionally pulls in cppunit headers and has all that nifty test-code, ofc, that is a problem.\n. Sure\n. It's not really sequential in that it will wait for later pieces to finish, but the following patch will make aria2 prefer earlier pieces, always.\nUsing this patch might have adverse effects on the swarms or might even get you banned by trackers and/or peers, so you have been warned.\nIt's also a 2 minute hack and might be inefficiently coded because I'm myself unfamiliar with the torrent code.\ndiff\ndiff --git a/src/RarestPieceSelector.cc b/src/RarestPieceSelector.cc\nindex a561c34..e55ffa8 100644\n--- a/src/RarestPieceSelector.cc\n+++ b/src/RarestPieceSelector.cc\n@@ -52,11 +52,21 @@ bool RarestPieceSelector::select\n   const std::vector<int>& counts = pieceStatMan_->getCounts();\n   int min = std::numeric_limits<int>::max();\n   size_t bestIdx = nbits;\n+  for (size_t i = 0; i < nbits; ++i) {\n+    size_t idx = order[i];\n+    if (bitfield::test(bitfield, nbits, idx) && idx < bestIdx) {\n+      bestIdx = idx;\n+    }\n+  }\n+  if (bestIdx != nbits) {\n+    index = bestIdx;\n+    return true;\n+  }\n   for(size_t i = 0; i < nbits; ++i) {\n     size_t idx = order[i];\n     if(bitfield::test(bitfield, nbits, idx) && counts[idx] < min) {\n       min = counts[idx];\n-      bestIdx = idx;\n+      index = bestIdx = idx;\nThis patch is not endorsed or supported in any way. If you got questions or other issues, you're out of luck.\n. @tatsuhiro-t \nhttps://tn123.org/aria2/aria2-1.18.10-osx-darwin.dmg\n. @tatsuhiro-t and\nhttps://tn123.org/aria2/aria2-1.18.10-osx-darwin.tar.bz2\n. We do not intensionally rate limit the rpc responses, except in the case the secret token is incorrect.\nHowever, there is of course a natural limit, as the neither the CPU nor the network is infinite speed. Seeing that the rate drops for non-local requests suggests that the network equipment or configuration is at fault.\n@i336 you didn't exactly tell us what kind of system you're using except for CPU... What kind of network card, OS, etc. And what version of aria2 you're using? And whether you're using plain http or https (--rpc-secure)\n. Might be enough to just explicitly include the errno headers, or else need to check ENOTSUP is actually defined at all. I got a tentative patch doing both, but haven't had the time to test it actually fixes the issue when building against uClibc\n. The one on my local disk only... Some patience please ;)\n. You could always build aria2 on your own using the OpenSSL or GnuTLS TLS backend instead of WinTLS... Or use a linux build in the first place...\nIt seems to me that wine's Schannel implementation is incomplete or buggy, and seeing that this affects the context state flags, working around this would require not checking the channel integrity at all... Which might be actually an option for the --check-certificate=false case. Need to ponder on this.\n. XP is not supported with WinTLS for various reasons, most importantly because XP is not supported any longer and the underlying Schannel in XP lacks a lot of features so that it is impossible to use it securely.\nEssentially Schannel on XP, is broken crypto and with it all software that uses it for anything except to access the certificate store, e.g. Internet Explorer.\nAs such, I won't be \"fixing\" WinTLS to be compatible with XP, nor will I accept patchs or recommend to accept patches that do so.\nPlease consider using either a vendor-supported OS, or build aria2 yourself with the OpenSSL or GnuTLS backend.\n. I can suppress the warnings, but it still won't work because Schannel, the OS-level TLS implementation WinTLS uses, does not have the features aria2c needs under XP.\n. Yeah, I was off for a while...\nAnyway, @tatsuhiro-t and @tommyziegler here is my darwin build, freshly compiled:\nhttps://tn123.org/aria2/aria2-1.19.0-osx-darwin.dmg\nhttps://tn123.org/aria2/aria2-1.19.0-osx-darwin.tar.bz2\n. It's in the repo already, see https://github.com/tatsuhiro-t/aria2/blob/master/makerelease-osx.mk\n. Yeah.\nAlso there are services like https://bintray.com/ which handle binary distribution quite well and are free for open source projects\n. If you get the org you can have https://aria2.github.io/ ;)\nRegarding downloads, rehosting (most of) the old downloads here wouldn't be not much of a problem either, there is a release API so it can be scripted. But that isn't much of a concern, I agree.\n. Might be that musl has some API just stub'ed, returning always an error?\n. Yeah, @tatsuhiro-t the fix looks about right\n. Two things, you're in the wrong bug tracker mate, and SimpleDLNA is no-support ware, and since I do not know the answer to your problem, I cannot commit time finding out what is going on.\n. A real mitigation - e.g. the token approach the authors suggest - would require protocol changes, which we cannot do by ourselves. I guess this has to wait until Mainline and utorrent and/or transmission force any such changes by market share.\nOnly thing we could do is limit find_node and get_peers per requesting IP. I don't know the aria2 BT code at all but it might be feasible to allow only x query in y time for IP z. This however opens us up to poisoning attacks where an attacker sends fake queries for another IP making us not respond to queries from that IP anymore. Also, this requires storing the information, so this has the potential of memory DoS against aria2 as well by an attacker spamming us with many different fake IPs/peer-ids. Both could be somewhat mitigated by having a global x queries in y time interval limit as well. This then would allow to attack DoS aria2 with fake queries so it is always limited and therefore drops out of the DHT entirely.\nSo the mitigations we can do ourselves to not become part of the DDoSing peers/net would in return open us up to DoS attacks against ourselves...\nI think it would be better to just wait at this point and see how the other major players address this, in particular Bittorrent Inc and transmission.\n. @tatsuhiro-t OSX builds:\nhttps://tn123.org/aria2/aria2-1.19.1-osx-darwin.dmg (default download)\nhttps://tn123.org/aria2/aria2-1.19.1-osx-darwin.tar.bz2\n. Just noticed I can update the release myself since it is now on github... And did so\n. @tatsuhiro-t It probably would be better to link to https://github.com/tatsuhiro-t/aria2/releases/tag/release-1.19.1 instead of the release overview page...\n. There are multiple options that influence the behavior:\n- --split -s Maximum number of concurrent splits (connections) per download. Defaults to 5, so unless you changed it, you will get max 5 connections for a single download no matter what -x.\n- --min-split-size -k A split should only be initiated when the split would be bigger than this. Defaults to 20M, meaning that when you download a 100M file, the time the download is split some data is already retrieved which means less slightly less than 100MB is remaining, meaning 4 splits (5 splits would create splits slightly less than 20MB).\nThere you have it. Please check out the manual for more information on the various options.\n$ aria2c -k 1M -s 10 -x 10 http://mirror.sg.leaseweb.net/speedtest/100mb.bin\n[#1325f1 7.4MiB/95MiB(7%) CN:10 DL:1.2MiB ETA:1m8s]\n. Everything that RAMMAP says is \"Standby\" and not \"Active\" in the files tab is the Windows disk cache. That stuff should be thrown out as soon as it is required for something else. However indeed almost 1GB of \"files\" is active and therefore not just cached, which seems like a lot and judging from the screenshot it indeed is mostly seeded files.\n. Also, you're running at least Plex, and it seems media files are most \"Active\", so it might be Plex keeping the files in memory.\nAlso, AntiVirus software is always a good suspect when hunting down file-related memory consumption issues.\n. Seems to closely resemble the .clang-format I've been using.\n. > Note that we use clang-format-3.6 until ubuntu gets 3.7 as default (clang-format formats code differently between versions unsurprisingly).\neek.... I'll manage.. somehow\n. works for me on OSX 10.11.2 using the release aria2-1.19.3-darwin build\n. Adding something that checks for updates might be enough for starters, but such a feature better be configureable as distros would patch it out anyway.\n. > Files changed 4,422\nSomething went wrong here...\n@oliviercommelarbre, seems you committed your build directory?\n. make clang-format is probably a good idea.\nIn general, white space is king; if (abc == def) for (ghi; ghi < jkl; jkl) mno = pqr;\n. There is none really. Windows simply has no concept of reserved zero \"holes\", that is the file \"valid data\" is a length, not a map.\nThere is only SetFilePointer + SetEndOfFile, with the known limitations that it will actually write zeros if you seek past the valid data point and write from there.\nTo avoid writing those zeros later on, one might SetFilePointer and then write a single 0 so that this write will cause the zero filling.\n. Added OSX binaries\n. OSX minimal version for my binaries is now 10.10 (released in 2014). I won't support below that due to lack of time and resources. If you want to run aria2 on such an outdated (and insecure) OSX version, you'll have to build it yourself.\n. Interesting, cannot reproduce locally\n. I wonder if it is gcrypt (dependency of libssh)...\n. @wao1201 and @mts749 can you try this build please? Pulled in the gmp patch @tatsuhiro-t mentioned and fiddled with the gcrypt configs...\nhttps://tn123.org/aria2/aria2-1.21.0-i608-1-osx-darming.dmg\n. At least I now know gmp is to blame... \n\n0 aria2c 0x0000000106636931 __gmpn_submul_1 + 81\n. Actually, my bad, when ripping out the multi-arch stuff I accidentally disabled enable-fat in gmp it seems...\n. @wao1201 Can you check this build too, pls?\nhttps://tn123.org/aria2/aria2-1.21.0-26-g3322a84-osx-darwin.dmg\n. @nasht00 thanks for the feedback\n. OSX binaries added\n. Added OSX releases just now... Better late than never\n. > #1  0x000000000046a678 in aria2::callGetaddrinfo (resPtr=resPtr@entry=0x7fff4180ca08, host=0x4 , service=service@entry=0x0, family=family@entry=0, \n    sockType=sockType@entry=0, flags=flags@entry=4, protocol=0) at SocketCore.cc:1446\n\nSpecifically\n\nhost=0x4\n\nhost is ip.c_str() from https://github.com/aria2/aria2/blob/master/src/SocketCore.cc#L1506, where ip in this is stack is a DHTNode::ipAddr_ \ud83d\ude2e \n. Not it  :grimacing:\n. What's wrong with configure?\n. You might not like it, but other users like having aria2 in their path after installation. As you did yourself, you can remove the paths.d entry and symlink if you want for yourself, or build aria2 yourself in the first place.\nThere is also a reason for not installing directly in /usr/local/bin, and that is to avoid interference with brew, which is quite popular (at least among the crowd that is likely to use the terminal at all)\n. @tatsuhiro-t I actually think it would be a good idea to default=true this new option. Most users will be interested in keeping unfinished downloads (in their session files), rather than keeping finished ones for starters, so I think default=true would be the sane, \"obvious\" default.\nActually, it might be a good idea to change max-download-result to only ever consider finished downloads when purging (not errored, not seeding), and remove the --keep-unfinished-download-result option again... my two cents.\n. It's not exactly unbound... You cannot amplify a single download into infinite download results. So it is effectively bound by the number of downloads in the session. If you add 70000 downloads, you should expect to get quite a few download results ;)\nOption or not, the default should be to keep unfinished downloads (at least when a session file is confirgured)\n. Oh yeah, my good old friend, the missing #inlcude <array>. Had to do the same change when building the 1.24.0 release.\nWorks for me on master after your commit, so closing.\n. yes, but I just noticed I forgot to push this to master\n. @loompa345 if you're just after feeding aria2 more efficiently, it might be a good idea to just write an aria2 input/session file yourself, which is plain text and somewhat similar to yaml even: https://aria2.github.io/manual/en/html/aria2c.html#input-file\nOf course, that is aria2 specific then\n. I considered if it would break some code, but really, I saw the likelihood of that to be so small that I don't think we should address this. Either way, the benefits outweigh the potential drawback by this wide a margin, that this new behavior should be the default.\nAlso, the work and maintenance costs of us adding a pref to revert to the old behavior isn't worth it even if we broke a tiny fraction of scripts; it would be easier for authors just to update their scripts and reap the benefits of a proper extension, or patch out the change if they really have to, so IMO there shouldn't be a compat switch/config option either\n. This should do the trick then, @tatsuhiro-t \n. ok, I'll address the minor thing you mentioned, squash it together with a more descriptive log message (for the changelog) and push it once I get home\n. It does for me when I do make; make clean; make, enormously. Since most commits will not invalidate a lot of units and travis says it shares the cache between builds as far as I understand, it should speed up builds too; only compile what was changed instead of everything\nhttps://docs.travis-ci.com/user/caching/#Cache-content-can-be-accessed-by-pull-requests\n. I just tried it...\nDid an initial cached-enabled build, build time was about 1min slower since the cache was empty, this is expected and more or less the worst case.\nThen I pushed again, changing a single \".cc\" file, which is kinda the best case: https://travis-ci.org/aria2/aria2/builds/145922491\nThe build for gcc went from about 23min to about 3min and for clang from about 14min to about 4min. This is better than expected.\nFor somewhat more involved commits (e.g. changing a common header) the savings will less but still sizable most of the time\n. That's... surprising. Still, need to check for API compatibility especially regarding return values (error codes now where there was void before)\n. The instructions say to virtualenv, so no sudo necessary, also the inserted space is bogus. As there is nothing left to merge after that, I am closing this PR. Thanks for your contribution anyway\n. I'll make the saveError_ change and commit\n. https://github.com/aria2/aria2/commit/414dd14decff7429ce94f18721f4c1afe607b6ea\n. That's using the released binary, right?\n. hmmm... somehow libssh2 managed to pick up an openssl dependency that shouldn't be there\n. yip, libssh now links openssl if you do not specify --without-openssl\n. @sonic84 I updated the release dmg and tar as well\n. We already support openssl, gnutls, Apple Secure Transport, Windows Schannel, so I see no reason why it cannot be supported too... It's just somebody has to actually write the code.\n. Of course, when I said write the code, I really meant write and maintain the code.\n. mbedTLS has financial backing and developer resources by ARM now, is highly configurable it seems to strip stuff you don't need/want and is designed to have a low memory (both binary and runtime) footprint they say.\nA quick google turned up people creating mTLS libary configurations as small as 30KB and trying to get even smaller, another result showed people having a runtime (heap+stack, but not the image) of about 4K which includes any global/shared structures and a connection if I understood it correctly. A typical OpenSSL connection weights at about 128K it seems, while the binary size is in the megabytes.\nMeasuring what this means in practice is a chicken and egg problem tho: You cannot measure without having an implementation, and making the implementation dependent on what you measured... you see the problem.\nHowever, I think one could do some similar measurements if one tests OpenSSL vs mTLS vs GnuTLS curl builds, as curl supports them all already, to get a general idea how much they differ.\nI might actually look into it _if I find some time_, as I run aria2 on a low-powered, low-memory Atom SoC sometimes (not really comparable with even tinier ARMs, but still)\n. hehe\n. just tried via XMLRPC (via python3 xmlrpc.client.ServerProxy), with and without a token... Both worked.\nCould you provide more details?\n``` text\nIn [5]: a.aria2.addUri(['https://github.com/aria2/aria2/archive/master.zip'])\nOut[5]: '015d7c7eed598092'\n09/24 11:57:17 [NOTICE] Download complete: /Users/.../dev/aria2/aria2-master.zip\n```\n``` text\nIn [8]: a.aria2.addUri(\"token:test\", ['https://github.com/aria2/aria2/archive/master.zip'])\nOut[8]: 'bce1e93e501c81e0'\n09/24 11:59:12 [NOTICE] Download complete: /Users/.../dev/aria2/aria2-master.1.zip\n```\n. yeah, the wonders of messing up signedness, good catch @tatsuhiro-t \n. This time even with more timely OSX binaries. Could it be something like SELinux, AprpAmor or the like interfering because you're trying to bind to all interfaces?. On one hand this is off topic... On the other hand... I want this too \ud83d\ude01 . Yes, let me whip up something. Too bad the std::file_system stuff is not really available yet (will be with c++17).... Well, just proving information on all mount point seems problematic to me (too much (useless) information), that's why you can call it without gids and get back the global PREF_DIR space (after I change that from PWD). Returning space for gids is a bonus you can use to query per download free space to check if a running download is gonna run out of space.\nHowever, passing the API a path might be an idea. That way a RPC-based UI can check or display the disk space before adding a download.. https://github.com/aria2/aria2/issues/936#issuecomment-308696829. https://github.com/aria2/aria2/issues/747. https://github.com/aria2/aria2/issues/936#issuecomment-308696829. Indeed, you need to either specify at least one URL, or use --enable-rpc.. The last binaries I produced are here:\nhttps://github.com/aria2/aria2/releases/tag/release-1.30.0\nAfter that I had to deal with some family stuff in my real life etc, and then some technical issues like my mac breaking which did not allow me to do builds. I'll try to resume that shortly tho. ok, 1.32.0 darwin binaries are now available. I got .12, which I also use to build, tho the SDK version is set to .10 for that.\nWorks for me.\nCan you provide your aria2.conf?\nWould it be possible for you to do your own build and compare results?. >i try to run the version 1.32 with osx version 10.10 and same result segmentation fault 11\nOh, did you managed to build it on your own now?. oh. Yeah, if you're using make-release-osx.mk\n\npip install Sphinx for sphinx-build\nYou need to generate the configure script if you didn't. autoreconf -fi\nmake a directory e.g. build, change into it and symlink ln -s ../make-release-osx.mk Makefile\nThen make (or gmake)\n\nI'll look into running 10.11 in a VM now. Oh, that does it sometimes... usually another make will then pass.\nBut I got a VM running now and can reproduce the issue myself.\nSeems it crashes in c-ares, I'll investigate...\nlldb\n(lldb) bt\n* thread #1: tid = 0x5af6, 0x0000000000000000, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)\n  * frame #0: 0x0000000000000000\n    frame #1: 0x000000010029192d aria2c`ares__tvnow + 23\n    frame #2: 0x00000001001639d8 aria2c`aria2::AsyncNameResolverMan::startAsyncFamily(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int, aria2::DownloadEngine*, aria2::Command*) + 198\n    frame #3: 0x000000010016386b aria2c`aria2::AsyncNameResolverMan::startAsync(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, aria2::DownloadEngine*, aria2::Command*) + 95\n    frame #4: 0x0000000100081593 aria2c`aria2::AbstractCommand::resolveHostname(std::__1::vector<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, std::__1::allocator<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned short) + 491\n    frame #5: 0x00000001000eb445 aria2c`aria2::InitiateConnectionCommand::executeInternal() + 157\n    frame #6: 0x000000010007d556 aria2c`aria2::AbstractCommand::execute() + 1848\n    frame #7: 0x00000001000a7eb0 aria2c`aria2::(anonymous namespace)::executeCommand(std::__1::deque<std::__1::unique_ptr<aria2::Command, std::__1::default_delete<aria2::Command> >, std::__1::allocator<std::__1::unique_ptr<aria2::Command, std::__1::default_delete<aria2::Command> > > >&, aria2::Command::STATUS) + 242\n    frame #8: 0x00000001000a7c15 aria2c`aria2::DownloadEngine::run(bool) + 305\n    frame #9: 0x00000001000f3f91 aria2c`aria2::MultiUrlRequestInfo::execute() + 57\n    frame #10: 0x000000010007ca48 aria2c`main + 264\n    frame #11: 0x00007fff902b15ad libdyld.dylib`start + 1. Turns out SDK that comes XCode 8 incorrectly specifies clock_gettime which is not available on 10.11. might be fixed in https://github.com/c-ares/c-ares/commit/fbf1b4b3d6e5c663ddcebfbf61c9a323ca1f8bd0. yes, upgrading to c-ares 1.13.0 fixes the issue. I used the non-stripped version from my release build directory and lldb, then it showed me the crash was a nullptr dereference from ares__tznow, then I looked at the code of that function and only clock_gettime make sense. A bit of google then showed it's kinda a known issue with the SDK.\nI'm verifying a new build right now. Added new binaries to: https://github.com/aria2/aria2/releases/tag/release-1.32.0. no, I am actually talking about fallocate on ext4 which supports fallocate. The larger and high use, the longer it will take the file system to figure out where to place extents (the max extent size on ext4 is 160MB or something like that, so a multi-megabyte file will use many extents even without fragmentation, and if the file system is in high use, the number of extents required may increase even more due to fragmentation).\nI'm running aria2 on an i686 Atom SoC NAS, and it might sometimes take up to a minute to fallocate a multi-gigabyte file there.. @sebalos314 you might want to read: https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/drivers/char/random.c?id=refs/tags/v4.10-rc5#n159 which offers a solution to save some entropy when the system goes down (or you could save the seed at an earlier stage too). If you initialize the entropy pool with a seed like that, it should make subsequent startups a lot faster. . It will install into '/usr/local/aria2/bin/aria2c' but will be in the PATH of new terminals so just aria2c <param> should work.. Can repo. Honestly, daemon() is kinda deprecated, and not properly implemented a lot of times. We should remove that feature and advice users to run aria2 with some kind of init script or even in a screen/tmux. @stangri I don't even think you need --daemon in that init script. It should work fine without it. You have to enable the additional features in your openwrt .config e.g. by re-running make menuconfig going to Network/File Transfers/aria2 Configuration and then rebuild the aria2 package.\nIf you aren't actually familiar with building openwrt yourself, I suggest you contact the openwrt package maintainers of aria2 (listed in that makefile) and ask them to actually build aria2 in a sane manner.. Yeah, High Sierra (or maybe apfs) broke some stuff.... What's the output of autreconf -fiv. good point... makes more sense when you think about it in the terms of \".bashrc.1\" vs \".1.bashrc\". I'll address this.\n. no problem\n. uh, clang-format did that.... ",
    "ravageralpha": "My mistake , now i can resume seeding via RPC , but not that convenience .\nWhen a torrent finished and i paused the task , next time i have to reupload the same torrent to resume .\n. Great , What is the new option enable-mmap do , disk cache ?\n. I found that when enable this option on small RAM machine (router), the aria2 process will be kill by kernel when downloading large file , and i noticed the VSZ of aria2 was huge.\nMaybe mmap is not the proper way to be the disk cache feature ?\n. When enable-mmap option use with file-allocation=none,It's OK but seems enable-mmap not work anymore.\nBut when file-allocation=falloc , trunc or some other value, and download file large >  4G, aria2 process will be killed by kernel.\n. RTFM...\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--follow-torrent\n. add configure.ac:\nAM_INIT_AUTOMAKE([subdir-objects])\nshould do the trick.\n. ",
    "wasamasa": "Here's a patch to make use of XDG for the config file:\n``` diff\n3 files changed, 22 insertions(+), 1 deletion(-)\n src/OptionHandlerFactory.cc |  2 +-\n src/util.cc                 | 17 +++++++++++++++++\n src/util.h                  |  4 ++++\nModified   src/OptionHandlerFactory.cc\n\ndiff --git a/src/OptionHandlerFactory.cc b/src/OptionHandlerFactory.cc\nindex 768d847..077fc4f 100644\n--- a/src/OptionHandlerFactory.cc\n+++ b/src/OptionHandlerFactory.cc\n@@ -174,7 +174,7 @@ std::vector OptionHandlerFactory::createOptionHandlers()\n     OptionHandler* op(new DefaultOptionHandler\n                       (PREF_CONF_PATH,\n                        TEXT_CONF_PATH,\n-                       util::getHomeDir()+\"/.aria2/aria2.conf\",\n+                       util::getConfigFile(),\n                        PATH_TO_FILE));\n     op->addTag(TAG_ADVANCED);\n     handlers.push_back(op);\n    Modified   src/util.cc\ndiff --git a/src/util.cc b/src/util.cc\nindex 68310aa..16a9ab0 100644\n--- a/src/util.cc\n+++ b/src/util.cc\n@@ -1336,6 +1336,23 @@ std::string getHomeDir()\n }\n #endif // MINGW32\n+std::string getXDGConfigHomeDir()\n+{\n+  const char p = getenv(\"XDG_CONFIG_HOME\");\n+  if (p) {\n+    return p;\n+  }\n+  return getHomeDir()+\"/.config\";\n+}\n+\n+std::string getConfigFile() {\n+  std::string filename = getXDGConfigHomeDir() + \"/aria2/aria2.conf\";\n+  if (File(filename).exists()) {\n+    return filename;\n+  }\n+  return getHomeDir()+\"/.aria2/aria2.conf\";\n+}\n+\n int64_t getRealSize(const std::string& sizeWithUnit)\n {\n   std::string::size_type p = sizeWithUnit.find_first_of(\"KMkm\");\n    Modified   src/util.h\ndiff --git a/src/util.h b/src/util.h\nindex 6e5eb8c..a71dbaf 100644\n--- a/src/util.h\n+++ b/src/util.h\n@@ -349,6 +349,10 @@ void setGlobalSignalHandler(int signal, sigset_t mask,\nstd::string getHomeDir();\n+std::string getXDGConfigHomeDir();\n+\n+std::string getConfigFile();\n+\n int64_t getRealSize(const std::string& sizeWithUnit);\nstd::string abbrevSize(int64_t size);\n```\nI'll have to look into corresponding changes for ~/.aria2/dht.dat. ~/.aria2/dht6.dat and the docs.\n. See https://github.com/tatsuhiro-t/aria2/pull/395.\n. Does this require new tests? How about the documentation, what files should I exactly change?\n. Anything else?\n. My bad, it's $XDG_CACHE_HOME.\n. Fixed that, too.\n. OK, I'm ready to go.\n. Guess #27 can be closed then.\n. Closing in favour of the linked PR.\n. OK, fixed.\n. Anything else?\n. ",
    "marcbowes": "http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--max-overall-download-limit claims:\n\n--max-overall-download-limit=\nSet max overall download speed in bytes/sec. 0 means unrestricted. You can append K or M (1K = 1024, 1M = 1024K). To limit the download speed per download, use --max-download-limit option. Default: 0\n\nSo following that I would expect that limit >= sampled should always hold true. However, for the lowest speed I ever recorded, the equation 20 * 1024 >= 241659 is clearly a lie.\n. Upgrading to 1.15.2 doesn't fix this either. \nruby\naria2_client.call(\"changeGlobalOption\", {\"max-overall-download-limit\" => \"10K\"})\n => \"OK\" \naria2_client.call(\"getGlobalStat\")\n => {\"downloadSpeed\"=>\"111348\", \"numActive\"=>\"1\", \"numStopped\"=>\"3\", \"numWaiting\"=>\"0\", \"uploadSpeed\"=>\"0\"} \n111348 / 1024.0\n => 108.73828125\n/cc @timsjoberg\n. I suspect it's got nothing to do with the version and everything to do with the way aria is compiled. Maybe this is a bug with the ppa-vended binary.\n. > What kind of RPC library or tool to communicate with aria2?\nI'm using Ruby via the XMLRPC::Client just like @timsjoberg. The only reason there is sugar on the syntax is because of a wrapper which just prepends aria2. to the calls. Looking in the aria logs I do see it's receiving the request successfully and, given the response to getGlobalStat reflects my request, I think we can safely say it's not the RPC tool.\n\nHow many simultaneous downloads when you corrected these values?\n\nI can reproduce this with a single metalink being downloaded with split set to 16. My aria2.conf looks like:\ndir=/home/marc/archive/\nlog=/tmp/aria.log\ncheck-integrity=true\nmax-connection-per-server=16\nmax-concurrent-downloads=5\nmin-split-size=1M\nfollow-torrent=mem\nmax-overall-upload-limit=30K\nfollow-metalink=mem\nsplit=16\nrpc-listen-all=false\nrpc-listen-port=6800\nrpc-passwd=aria2\nrpc-user=aria2\nallow-piece-length-change=true\nsave-session=/home/marc/.leecher/session.aria2\n\nAlso was bittorrent involved in them?\n\nAll metalinks using HTTP (not S) with the above settings\n\nI admit that aria2c's speed regulation implementation is not so accurate right now.\n\nThat's fine. If spikes are a problem I can always lower the throttling to account for it. At the moment I'm just looking for some mechanism to 'renable browsing' during downloads :-)\n. Thanks! You rock!\nI commented on your commit to make sure I understood what was going on. In my opinion, it looks like your fix will work. When will this be available via the PPA? I'm eager to upgrade since automated downloads currently brown out my browsing experience :-)\n\nOn a completely different note (feel free to ignore):\nWhat do you think about having a web-hook as an option to aria's callback system. Currently I configure aria to invoke a shell script which lets my workflow know the download has changed state. It'd be nice if it could just deliver a payload via HTTP to some endpoint -- even if that payload is just a notice saying GID 1 has changed state: the receiver can always poll over the RPC interface to determine what the change is.\nFeel free to close.\n. Yes, doing that in a script is pretty easy. Having it as a built-in would be pretty nice too since it's one less moving part to manage. Closing this out.\nThanks again.\n. ",
    "timsjoberg": "Mines closer to the mark. It seems to sit at roughly 10K  and spikes occasionally when limited to 10K\nruby\nserver = XMLRPC::Client.new2(\"http://#{user}:#{password}@127.0.0.1:6800/rpc\")\nserver.call(\"aria2.changeGlobalOption\", {\"max-overall-download-limit\" => \"10K\"})\nloop do\n  puts server.call(\"aria2.getGlobalStat\")[\"downloadSpeed\"]\n  sleep 0.2\nend\n11673\n10591\n9776\n9776\n9098\n13115\n13115\n11781\n11176\n10637\n12249\n11699\n11699\n11268\n10870\n10221\n9861\n9573\n9573\n11882\n11261\n10954\n10663\n10388\n10092\n9854\n9624\n9624\n11331\n10864\n10626\n10401\n10182\n9947\n9750\n9750\n9564\n10702\n10503\n10503\n10316\n17913\n11167\n10976\n10761\n10761\n10586\n10273\n10111\n9957\n10962\n10788\n10624\n10624\n10468\nrunning gentoo with aria 1.14.1\n. ",
    "nimish": "Sorry this took so long but yes, I can use sqlite3. Even if I create a copy of Cookies, it still refuses to load. This is with the latest aria2\n. OK i figured it out: the homebrew install of aria2 doesn't have sqlite3 support\n. @tatsuhiro-t There doesn't seem to be a reasonable choice for --ca-certificate on OSX since certs are handled via Keychain. \n. ",
    "jsntay": "SOLVED! Modified as you said, mmap now can be found!  Thanks!\nI still have a question, the RAM of a router is very limited, mine is 64MB. Could mmap take effect under this circumstance? Cuz from what you explained in https://github.com/tatsuhiro-t/aria2/issues/26, mmap would work as disk cache only if you have lots of RAM. Is there any better solution for disk cache?\n. After changed the file system of flash disk from fat32(for the windows compatible reason) to ext4, I've noticed the writing access of disk has been significantly reduced! And I checked the VSZ of aria2 as addison mentioned, yes, the VSZ value is extremely high, the value is approximately equals to the file size that you're downloading, and also the %VSZ even exceeds 100%. But when I checked with free, there's still some free RAM left, and aria2 is rarely killed by kernel, which usually happens before I changed 32M RAM to 64M when aria2 had no mmap option yet. So I think it might just be some message output error. addison, you could try with disabled mmap to see what would happen. So far so good for me, I've tried with 2GB large file downloading.\n. Sorry that I was kind of busy those days. I tested it on my 64 RAM router, I set the cache to 8M, and it works pretty well! Disk activity has been largely reduced. Thanks for all your efforts!\nJason\n. ",
    "farnoy": "I add magnet links and .torrent via simple link (without downloading them first and uploading a file to aria). There is output for all the jobs in the console.\n. I'll check pure rpc for all the jobs, because webui is throwing some errors.\n. I'm confused, the RPC returns 5 jobs with proper data, but earlier, before this problem, webui showed 2 jobs for every torrent (one for metadata, one for actual download). Right now I can see only metadata jobs in webui, so there's probably a problem on it's side.\n. Yes, it seeds fine but only the metadata is visible in the webui.\n. I've set -j 200 and I see more output in the webui now, but still only metadata is visible, even though it shows seeding in the CLI.\n. Ok it was a webui problem, it was fixed in the upstream.\n. Thank you, I will try those options.\n. Nope, It still dies after a few hours, connections go back to zero, and when I pause&continue, I have 145 shortly after.\nI'm using these settings:\nbt-request-peer-speed-limit=100K\nbt-tracker-interval=1200\n. Ok, I will do that next time I encounter the problem, but what about log\nlevel? Most of my current logs are errors about not supporting UDP protocol.\nOn 22 January 2013 13:40, Tatsuhiro Tsujikawa notifications@github.comwrote:\n\nWith DHT and tracker enabled, and assuming you are downloading torrent,\nnot seeding, it is very strange that there is no connection. Could you grab\naria2 log and check that tracker announce is made correctly?\nBecause this issue needs few hours to occur, log file gets too big. So you\ncan enable logging after the connection becomes 0 using RPC command and\nwait for tracker announce (minimum 1200+ secs for your settings).\nTo enable logging via RPC, you can do it using aria2rpc:\ndoc/xmlrpc/aria2rpc changeGlobalOption -l /tmp/log.txt\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/41#issuecomment-12542690.\n. Sure, I will include debug information also.\n\nOn 22 January 2013 14:05, Tatsuhiro Tsujikawa notifications@github.comwrote:\n\nThank you. The debug level log is very helpful for debugging.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/41#issuecomment-12543417.\n. Ok, this happened again, I've executed the command to save the log, I will wait at least 20 minutes and then post it here.\n. Where should I send you the logs? There's 4M of them.\n. Compressed logs are here, starting around 10.53am to around 11.20. I've paused&unpaused Darksiders2 around 11.18, and two minutes later it was going full speed. There may be some noise from the RPC, since I've checked the webui a few times.\n. Full config:\n\ncontinue\ndir=/home/kuba/Downloads\nfile-allocation=falloc\nmax-connection-per-server=4\nmin-split-size=5M\nenable-rpc\nenable-dht\nbt-save-metadata\nrpc-save-upload-metadata\nforce-save\nbt-seed-unverified\nbt-max-peers=0\nbt-request-peer-speed-limit=100K\nbt-tracker-interval=1200\nsave-session=/home/kuba/.aria2/session\ninput-file=/home/kuba/.aria2/session\njobs=20000\nmax-concurrent-downloads=99999\nlog-level=debug\nlog=/home/kuba/aria2_log\n. I would have to compile aria2 from git master and then run it the same way?\nOn 23 January 2013 16:25, Tatsuhiro Tsujikawa notifications@github.comwrote:\n\nThank you for the log. From the log, aria2 corrected peers from DHT\n(trackers are all udp but aria2 does not support them) and its peer list\nwas full (1024 peers), but for unknown reason, aria2 did not initiate\nconnection to those peers. The code to initiate connection is\nsrc/ActivePeerConnectionCommand.cc but unfortunately it does not have\nmeaningful log message at the moment.\nI'll make a patch to add log message and post the link here.\nCould you apply the patch and do the same procedure again?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/41#issuecomment-12600115.\n. Ok, I've cloned the repo and applied the patch, building manpages fails but the binary is intact\n[WARN] Unknown option: jobs=20000.\nI'll find some big download and leave it for the night. Hopefully, it will happen again and I will post logs tomorrow.\n. This time, the scenario was kind of different, because I've had two bigger jobs that were not downloading since I added them (maybe the traffic from other jobs caused them to lose tracker messages) and they stayed at zero progress for about 9 hours. Here are the last 500k lines from the log.\n. No problem, happy to help. I will pull the fix and see how that works, thanks for your time.\n. It has been verified by me twice since my last reply, and it maintains speed after several hours, thank you.\n. This is weird, I have force-save enabled for some time now. Maybe some options in my config file conflict somehow?\n\ndir=/home/kuba/Downloads/aria2\nfile-allocation=falloc\nmax-connection-per-server=4\nmin-split-size=5M\nenable-rpc\nrpc-listen-all=true\nrpc-allow-origin-all\nenable-dht\nbt-save-metadata\nrpc-save-upload-metadata\nforce-save\nbt-seed-unverified\nbt-max-peers=0\nbt-request-peer-speed-limit=100K\nbt-tracker-interval=120\nsave-session=/home/kuba/.aria2/session\ninput-file=/home/kuba/.aria2/session\nmax-concurrent-downloads=99999\nseed-ratio=0\nallow-overwrite=true\nconditional-get=true\n. Since it worked the whole time under the assumption that the control file is removed, will it be hard to implement keeping it?\n. Thank you, I will confirm when a new release comes out.\n. Anyway, everything's been fine ever since!\n. Can it be implemented the way I described above? It seems to me that correct implementation of closing and reopening on demand would make the option --bt-max-open-files redundant, as it would always open the least possible amount of files.\n. Couldn't this work so that when using this call, aria activates the download job to evaluate what files are selected to be downloaded and which have already been created on the filesystem and remove them?\n. I've actually written a bunch of scripts to help me with that. They look at the active .torrent files I have in a directory and generate the aria session file.\nThis declarative approach makes me not need this new RPC method, so you're free to close this I guess.\n. I've seen libtorrent do it (https://github.com/libtorrent/libtorrent/blob/master/src/upnp.cpp) and was wondering if aria does it too.\nI haven't forwarded ports for aria and it doesn't seem to have any problems seeding. How is that possible though, if peers can't initiate a connection to me?\n. I read up on the protocol, thanks for the information. If I understand correctly, the situation is: I'm unreachable on my listen ports from the outside, so the tracker does not give out my IP+port to other peers. Every interval seconds aria queries the tracker and initiates the connection to them (and serves them data if they still need it). The only true solution would be to obtain a public IP so people can reach me.\n. ",
    "MarginalGame": "Hi tatsuhiro-t:\nconfigure.ac exists in aria2-1.16.1 directory.as the below pictrue\n\nI have install  autotools-dev, geittext,autoconf automake libcppunit-dev autopoint openssl libtool sphinx-common sphinxsearch libgcrypt11-dev libxml2-dev pkg-config on xubuntu.\nwhen i run \"autoreconf \u2013i\", it show like this\n\nand when i run \"autoconf\", feedback as below\n\nfeedback information\n[code]david@david:~/aria2-1.16.1$ autoconf\nconfigure.ac:12: error: possibly undefined macro: AM_INIT_AUTOMAKE\n      If this token and others are legitimate, please use m4_pattern_allow.\n      See the Autoconf documentation.\nconfigure.ac:13: error: possibly undefined macro: AM_PATH_CPPUNIT\nconfigure.ac:68: error: possibly undefined macro: AM_CONDITIONAL\nconfigure.ac:112: error: possibly undefined macro: AM_PATH_XML2\nconfigure.ac:123: error: possibly undefined macro: AM_PATH_LIBEXPAT\nconfigure.ac:207: error: possibly undefined macro: AM_PATH_LIBGCRYPT\nconfigure.ac:411: error: possibly undefined macro: AM_GNU_GETTEXT\nconfigure.ac:412: error: possibly undefined macro: AM_GNU_GETTEXT_VERSION\ndavid@david:~/aria2-1.16.1$ \n[/code]\n. I just want get aria2 1.16.tar.ba2 from your aira2 master.zip.\nfor this aim, i must do the above order.\n. yes, using aria2-1.16.1.tar.bz2 from http://sourceforge.net/projects/aria2/files/stable/aria2-1.16.1/ without autoreconf.\nbut your aria2 is the newest edition than any other.\ni can get  aria2-1.16.1.tar.bz2 from your aria2 master.zip on Ubuntu 12 04, but can't successfully on xubuntu 12 04.\n. ",
    "antbryan": "maybe you need to install the -dev packages for libxml2 etc?\n. perhaps we could enlist the help of @nickzman who enabled native OS X crypto features in curl?\n. I'm happy to do any testing. maybe we can find more Mac users who will also help.\n. comment from Nick:\n\"What TLS engine does it use? If it uses OpenSSL or GnuTLS or even NSS, then you need to provide it with a collection of trusted root certificates or they won't work. Apple doesn't ship such a collection with OS X anymore outside of the certificates in the system roots keychain.\nIf you want to use the system roots keychain instead of a certificate bundle, then you either need to use Secure Transport as the TLS engine (best), or write a certificate validation callback that uses the Security framework to evaluate the trust (okay). Apple has deprecated their OpenSSL library in OS X, and iOS doesn't include OpenSSL at all, so it would be better if you use ST instead.\"\n. Nick did the Secure Transport (OS X specific) stuff for curl & Marc Hoersken did the schannel (Windows specific) parts for curl.\nmaybe it is worth looking how curl does these & implementing them for aria2? it seems like there are a number of users on each platform.\nhttps://developer.apple.com/library/mac/#documentation/security/Reference/secureTransportRef/Reference/reference.html\nalso, how does curl handle ca-certificates.crt? doesn't it provide some update mechanism (update-ca-certificates)? or maybe you could add some documentation for users on platforms that don't include it. http://curl.haxx.se/ca/\n. would it be worth temporarily having build_osx_release.sh grab CA certs from http://curl.haxx.se/docs/caextract.html ?\n. awesome! that was quick...\n. thanks @nmaier! ln -s /usr/local/opt/gettext/bin/autopoint /usr/local/bin worked for me\nnow I get:\n$ autoreconf -i\nconfigure.ac:114: warning: macro 'AM_PATH_XML2' not found in library\nconfigure.ac:114: warning: macro 'AM_PATH_XML2' not found in library\nconfigure.ac:465: warning: The 'AM_PROG_MKDIR_P' macro is deprecated, and will soon be removed.\nconfigure.ac:465: You should use the Autoconf-provided 'AC_PROG_MKDIR_P' macro instead,\nconfigure.ac:465: and use '$(MKDIR_P)' instead of '$(mkdir_p)'in your Makefile.am files.\nthe end of ./configure gives me:\nchecking for ZLIB... no\nconfigure: WARNING: No package 'zlib' found\n./configure: line 17428: syntax error near unexpected token 2.6.24,'\n./configure: line 17428:  AM_PATH_XML2(2.6.24, have_libxml2=yes)'\nlibxml2 2.9.0 is installed via homebrew\n. I use 10.8 & 'brew link --force libxml2' worked for me. thanks again @nmaier!\n@tatsuhiro-t, do you think 'aria2 --v' should list the libraries it uses like curl does?\ncurl 7.29.0 (x86_64-apple-darwin12.3.0) libcurl/7.29.0 SecureTransport zlib/1.2.5\nProtocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp smtp smtps telnet tftp \nFeatures: IPv6 Largefile NTLM NTLM_WB SSL libz \n. it appears to. (5.1 MB log file for a 13k https download tho?)\n2013-04-08 00:56:07.668634 [INFO] [AppleTLSSession.cc:532] AppleTLS: Connected to getcomposer.org with TLSv1.2 (TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384)\n. thank you @tatsuhiro-t I think that will be useful!\ncurl uses Secure Transport and ---with-darwin-ssl for listing & configure options while \naria2 uses appleTLS and --with-appletls\nwould it be worth using similar terms & configure options, @nmaier?\n. just an idea :)\nthanks for working on it\n. cc @kax4\n. this could be an advocacy bug for getting kernel.org & other sites to adopt Metalink/HTTP :)\n. any feedback @tommyziegler ?\n. Filed for Ubuntu downstream at https://bugs.launchpad.net/ubuntu/+source/aria2/+bug/1553778\n. @ST9527 they're at https://github.com/tatsuhiro-t/aria2/releases\n. @tian-le & @mostafa88, can you verify if aria2 1.33.0 fixes your issues?\nhttps://github.com/aria2/aria2/releases/tag/release-1.33.0. @q158073378252010 can you give a test link? is it HTTP or HTTPS?\ncan you check if aria2 1.33.0 (which includes #1012 fix mentioned by @tatsuhiro-t ) fixes your issue?\nhttps://github.com/aria2/aria2/releases/tag/release-1.33.0.  -l, --log=LOG                The file name of the log file. If '-' is\n                              specified, log is written to stdout.. Try https://github.com/ziahamza/webui-aria2. ",
    "ChrisLundquist": "installing libxml2-dev and such will solve this.\n. ",
    "baybal": "As a temporary measure it would.\nBut it will be better if aria2 will be able to have more flexible output name behaviour like using regex pattern for output names or automatically appending number to same name files.\n. ",
    "YorikSar": "Unfortunately, DHT is not enough sometimes.\nI ran into .torrent that is hosted on UDP trackers and DHT, but the number of seeders is very low, so they never appeared among my DHT neighbors. So I have noone to download from.\nNo, I don't know any server-side UDP tracker software. Never tried to look for it, actually.\n. Cool. I haven't used C++ for years, but might try to do it someday.\n. FTR: commit d68741697a\nGreat! I'll try to run it right now.\nWhy is it supported for IPv4 only? IIRC there were some (standard) hack to let it work with IPv6.\n. Finally. Had some troubles with portage. Solved them (worked around), ran into declaration of sigset_t in util.h. It caused failure like this:\n/usr/include/signal.h:85: error: declaration of C function \u2018int pthread_sigmask(int, const int*, int*)\u2019 conflicts with\n/usr/include/pthread.h:384: error: previous declaration \u2018int pthread_sigmask(int, const sigset_t*, sigset_t*)\u2019 here\nlooks like pthread.h gets imported before that redeclaration and signal.h after it.\nStatus line somehow starts with some hexadecimal stuff:\n[#3b2add 4.9MiB/5.8MiB(84%) CN:2 SD:2 DL:11KiB ETA:1m23s]\nIs it OK?\nAnd one more. I got this log in the begining:\n[NOTICE] IPv4 DHT: listening to port 6927\n[NOTICE] IPv4 BitTorrent: listening to port 6907\n[NOTICE] IPv6 BitTorrent: listening to port 6907\nAs I understand, BitTorrent lines are about TCP port for incoming connections, right? I guess, there should be a mention of TCP there. Like \"listening on TCP port 6907\".\n. > It is still \"hack\", right? We need the proper specification in bittorrent.org or somewhere.\n\nAt the moment, IPv4 is still main stream, so there is no problem for the time being.\n\nWell, the hack itself is about passing IPv6 address through this protocol since only 32 bits are left for address. But it should be OK to use UDP over IPv6 as a transport for tracker protocol.\n\nWhich OS/platform are you using? I've never seen it on linux.\n\nMacOS 10.5 and gcc from Gentoo Prefix. Mb this mix causes configure script to fail to check properly.\n. > Hm, I don't have mac but will do compile aria2 on *bsd to see that it shows the same issue.\nI guess, it might be specific to some libraries installed as dependencies by Gentoo Prefix or gcc itself. If you won't be able to reproduce this tell me, I'll try to see how did I got that.\n\nOther than that, did UDP tracker work for you?\n\nYes, sure! It worked and game I downloaded took away half of my weekend :)\n. This problem bugs me for some time now: I can download stuff using magnet links, but every time I restart aria2c after that it takes a lot of time to fetch all metadata from DHT again. Is it possible for aria2c to store some database of known torrent files and check it when magnet link is being added (and serve them via DHT as well)?. @tatsuhiro-t Great, thanks!\nAnd what do you think about also serving known infohashes?. @tatsuhiro-t No, it is not directly related to this issue. I'm talking about serving known torrent files over DHT to other magnet link users.. Shouldn't we also check that infohash in file is the same as requested in magnet link? This would protect user from accidentally overwriting torrent with another torrent, for example.. ",
    "multiSnow": "OK, I see it.\nThanks.\n. It is not easy to reproduce it.\nI have tried three times in downloading\nhttp://ftp.debian.org/debian/pool/main/c/chromium-browser/chromium-browser_26.0.1410.43.orig.tar.xz\nto an ext4 partition with option\ndisk-cache=40m\nfile-allocation=falloc\nmax-connection-per-server=16\nmin-split-size=1M\nand four times with\ndisk-cache=40m\nfile-allocation=trunc\nmax-connection-per-server=16\nmin-split-size=1M\nonly two of the first and one of the second raised the warning.\nAnd not seen warning yet with option\ndisk-cache=0\nfile-allocation=falloc\nmax-connection-per-server=16\nmin-split-size=1M\n``\n. It seems fixed, for over 10 times tried with both of the option above.\n. what about the second part of this issue, or I should just creat it as a new issue?\n. hmm...\nIf a temporary wrong DNS record received or temporary site down (e.g. site maintance), and of cource it causes download failed, it would not be saved.\nBut it is a temporary wrong, would be fixed in a short time.\nI should re-get the URIs of these download or they are just lost.\nOf cource I can re-get it by hands, but don't you think it would be more convenient if they are saved at somewhere, especially they are not only one or ten URIs?\n. It works.\n. Something like below download the torrent file and download the page from http link, but not do like web-seeding, tested:\n$ aria2 files.torrent https://home/files/. Yes, it works. Thanks. ",
    "zhuangya": "problem fixed, thanks guys! :)\nclosing this now.\n. awesome!!!\n. ",
    "kax4": "@antbryan Using brew link gettext -force after run autoreconf  you can unlink it.\n. I think no problem with --force (just like macport install) as long as you remember to unlink it.\nNeed to update manpage how to use --rpc-secure with Keychain [WARN] [AppleTLSContext.cc:51] TLS credential files are not supported. Use the KeyChain to manage your certificates.\n. Here log file with using purgeDownloadResult: https://gist.github.com/kax4/4d3fde3790b1dc861803\n. Ah thank for the explanation was a bit confuse because i don't see it happen with other torrent client.\n. Just try with your branch but it can't lookup the fingerprint: \n[DEBUG] [AppleTLSContext.cc:170] Looking for cert with fingerprint 70abaa7d03803a67cf8c46b3b3901f890cf701e5\n2013-04-08 12:45:41.791197 [ERROR] [AppleTLSContext.cc:234] Failed to lookup 70ABAA7D03803A67CF8C46B3B3901F890CF701E5 in your KeyChain\n. Move the cert to System keychain solve the problem \n2013-04-08 13:08:03.077126 [INFO] [AppleTLSContext.cc:228] Found cert with matching fingerprint\n2013-04-08 13:08:03.077262 [NOTICE] [DownloadEngineFactory.cc:183] RPC transport will be encrypted.\nedit: need to set Cert SSL trust to always trust or client can't connect.\n. Im using OS X 10.8.2\n\nCert need to be in system for me or safari open with webui-aria2 can't connect.\nedit: cert create with Certificate Assistant, not wizard (see lot of them on Windows).\n. Thank you, but i have a question are you you using web server like apache to connect to aria2 i only try secure connect out of curiosity so open file with \"file:///\" in Firefox i don't see \"This Connection Is Untrusted\" alert page, and i see a tut mention cert should move to system for using with Chrome too.\n. Yeah, Chrome does use Keychain according to this \nThanks now i can use webui-aria2 in Firefox.\n. Sorry, i'm a bit busy lately.\nAs for Safari just set cert setting: SSL to alway trust, for other browsers just connect to https://ip-address:6800 before using any web ui.\n@tatsuhiro-t are you planing to integrated some kind of web-ui like transmission-daemon, maybe you can ask some aria2 web-ui dev cooperate.\n. Can you write a patch if those check fail aria2 will try to recheck when user add a download link.\nHere what i can find with launchd:\nNetwork Availability\nIf your daemon depends on the network being available, this cannot be handled with dependencies because network interfaces can come and go at any time in OS X. To solve this problem, you should use the network reachability functionality or the dynamic store functionality in the System Configuration framework.\n. It work fine now, thank you!\n. File exists and torrent file when add in /Users hard drive using ntfs with Tuxera NTFS (ntfs-3g).\n. Spaces not a problem torrent download fine with it, may be tuxera suff right now i don't have other usb drive format to native file system report later in few days.\n. Hello, i want to report there nothing wrong with tuxera still same problem with HFS+ file system.\n. May be because external hard drive alway plug in when reboot.\n. Ok, i will give it a try.\n. StartOnMount \n  This optional key causes the job to be started every time a filesystem is mounted.\nSill same problem, Apple document mention:\nIf your daemon depends on the availability of a mounted volume (whether local or remote), you can determine the status of that volume using the Disk Arbitration framework \n. StartOnMount is a only thing mentioned filesystem mounted i could find on launchd manpage add it to init script do not solve the problem aria2 emits same error, may be it work as advertised started aria2 when filesystem mounted (local one) and aria sit there with --enable-rpc so it not execute aria again when external hard drive mounted.\nI think the Disk Arbitration thing can help.\n. @tatsuhiro-t Any news on this, i see that transmission and utorrent make copy of torrent files to config folder if aria behave the same can it help? \n. Thank you for replying. Will try your suggestion.\n. @tatsuhiro-t http://sourceforge.net/apps/trac/aria2/wiki someone edit the hyperlink to nonsense blog and forum.\n. I build aria2 form git try everything delete then clone again even use homebrew still have same problem.\n\nOS X 10.8.5\nBuild with:\nPKG_CONFIG_PATH=\"/usr/lib/pkgconfig:/build_tmp/aria2.min/lib/pkgconfig\" ./configure CC=\"cc\" CXX=\"c++\" --disable-dependency-tracking --disable-nls --with-sqlite3 --with-libxml2 --with-appletls --without-openssl --without-gnutls --without-libexpat --without-libnettle --without-libgmp --without-libnettle --without-libgcrypt\nNothing exotic in build_tmp/aria2.min only static c-ares and a fake sqlite3.pc so aria2 can linking with osx sqlite3.\n. OK i can try that will post result later.\n. Bisecting: 0 revisions left to test after this (roughly 0 steps)\n[9e7579b475e322ec86ff986e3371fea3fd5c857e] Set old cookie's creation-time to new cookie on replacement \ngit bisect start\n# bad: [03d5b4627b86c09fdbca3227e21efb5251ac0043] ColorizedStreamBuf::str: Append character prefix to stream directly\ngit bisect bad 03d5b4627b86c09fdbca3227e21efb5251ac0043\n# good: [dc8ed34cb014a0bdf22168fc73563086c8d8d1f2] Update pre compiled build README\ngit bisect good dc8ed34cb014a0bdf22168fc73563086c8d8d1f2\n# good: [bf5a940ed48e2baaca8cd8305d0b631fb81ca118] Define a type for signal handlers\ngit bisect good bf5a940ed48e2baaca8cd8305d0b631fb81ca118\n# bad: [450677f2bbf1bd6ce2672930143d013b8c32e2cb] Mention --without-appletls for checksumming\ngit bisect bad 450677f2bbf1bd6ce2672930143d013b8c32e2cb\n# good: [51bbdbb085cdbb7ada9989f2994bcc73ca6403b8] Update NEWS\ngit bisect good 51bbdbb085cdbb7ada9989f2994bcc73ca6403b8\n# bad: [a4e29303efe846bb891e8b146bcf5e12c8c338ce] WinTLS: Implement messsage digest using the Cryptography Provider\ngit bisect bad a4e29303efe846bb891e8b146bcf5e12c8c338ce\n# bad: [8e6e46dfcfdd269538e6c3070e6eea4b624d74fe] More code cleanups\ngit bisect bad 8e6e46dfcfdd269538e6c3070e6eea4b624d74fe\n# good: [fa09dc9115c4d34da6c5797287ee2ba61d6f162e] Clean up if defined style\ngit bisect good fa09dc9115c4d34da6c5797287ee2ba61d6f162e\n# good: [c6eb9701731c8edf5b8b1525cef12014e7cd8ad6] Update README.rst\ngit bisect good c6eb9701731c8edf5b8b1525cef12014e7cd8ad6\n. Yes 9e7579b475e322ec86ff986e3371fea3fd5c857e is the last good commit i forgot to mark it.\n. Latest git commit fix the issue thanks.\n. Your build running well on my old macbook air cpu spike a bit when download torrent other than that it seem fine.\n. ",
    "guedouari": "i thought it should be an easy task, i'll see if i can do something about it probably recheck the config file for each save session (i guess this will drain more processor time)\n. looking at SessionSerializer, it shouldn't be that hard. the way i see it. is checking the config file for each save session operation. that way options passed as cmd arguments will be saved since they are not permanent while general config option are ignored. (this works pretty good manually, and i was able to resume download across windows and linux)\nany suggestion on the option is much appreciated (if i make it this far)\n. since you're familiar with the code. i guess you're the best choice. still i've been trying to find onother way with less code. given the existence of a function that returns global-options (like the rpc one) it's shouldn't take more than a couple lines of code and it will be light weight. the only downside is the config file and the cmd arguments will be treated alike and ignored from the session file\n. tested with config file only and with cmd args , perfect!\nhope i could be of real help next time :)\n. i was hoping for an automation of the process:\naria2  saves all downloads to session-file even complete ones\nsession-file gets loaded as input file on aria2 start/restart\ncompleted downloads get redownloaded or fails dependin on force-save\nso i was thinking maybe if we add an option that gets saved in the session file to help prevent that\n. this is no big deal really jut a few tweak with a simple aria option\n. yep but considering that the input file is the same file saved by --save-session and --force-save\nso i don't have to add options manually\n. maybe a simple change to --allow-overwrite=false will show downloads as complete not failed\n. i have force-save enabled to save my completed torrents and aria starts up when i login using the session file as input file and all completed http/ftp files fails so i get too much errors like : \n  -> [RequestGroup.cc:785] errorCode=13 File /home/guedouari/Downloads/** exists, but a control file(*.aria2) does not exist. Download was canceled in order to prevent your file from being truncated to 0. If you are sure to download the file all over again, then delete it or add --allow-overwrite=true option and restart aria2.\n. i'm using aria2 aria2-webui and a lil code i wrote to automatically do things it would be prettier to have all the downloads listed but --force-save per download seems fair enough\nplz find my lil peace of code and try to make it as a peace of aria itself it would be awesome adding downloads to a running instance easally\naria2c --SOME-OPTION somthing.file => downloads the file with the already running aria\n. ",
    "JMSwag": "Well done my friend.  Thank you :)\n. ",
    "gsavix": "hi.\nplease, on sourceforge.net site where we read 'documenta\u00e7\u00e3o' change first\nchar to 'D' for read 'Documenta\u00e7\u00e3o'  like 'Documentation' in english.\nthanks.\nI will revise too sphinx warnings messages for pt_BR.\n2013/4/15 Tatsuhiro Tsujikawa notifications@github.com\n\nThank you. Merged and pushed. FYI, I fixed sphinx warnings in f326955https://github.com/tatsuhiro-t/aria2/commit/f326955\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/pull/74#issuecomment-16381411\n.\n\n\ngilberto dos santos alves\n+55.11.98646-5049\nsao paulo - sp - brasil\n. ",
    "netroby": "[root@ancientrocklab aria2-1.16.5]# autoreconf -i\nautopoint: * The AM_GNU_GETTEXT_VERSION declaration in your configure.ac               file requires the infrastructure from gettext-0.18 but this version               is older. Please upgrade to gettext-0.18 or newer.\nautopoint: * Stop.\nautoreconf: autopoint failed with exit status: 1\ntry to autoreconf it, but it failed\n. No way sir. CentOS 5.9 is enterprise enviroment. we can not upgrade these dependency easily. we shall keep the old but stable libraries , we need stable enviroment.\n. Aira2 is faster than the CentOS default download tools wget.\nwe using aria2c to download files to our production enviroment. if we can let it easily compile under CentOS 5.9 and CentOS 6.x, we will using aria2 in each of our production enviroment.\n. Thanks , great work. i will gave it a try.\n. Have done this way. but really want default command decrease it's name from aria2c  to a2c\n. Short words may save our time, getting better efforts.\n. If download files or multiple file via ssh, suggest you using rsync, very fast and very nice.\n. Make an options, some download site will still need SSLv3, so we can default disable SSLv3 , Using TLS  1.0 + by default.\n. aria2 already over-engineering, so do not care about this.\nMore or less, is less harmful.\n. ",
    "qiuzi": "How to turn off seed-time \uff1f\n. \nCan not be recorded after the completion of the task\n. Thank you\n. Thank you\n. Thank you\n. Routing only 64MB of memory openwrt system\n. 1.7.1 VS 1.6.5 \n\n\n1.6.5 Memory is not more than 50%\n. How tracking?\nConfiguration options I have posted out\nRouting system used in openwrt\n\n. \u662f\u554a \u6211\u5c31\u662f\u60f3\u95ee\u8fd9\u4e2a\u95ee\u9898\n. feature request: add option to limit the maximum size of log file\n. \u4f60\u4e5f\u9047\u5230\u8fc7\u4e0bbt\u5360\u7528vsz 170%\u7684\u95ee\u9898\u5417\uff1f\n. \u4f46tr\u6ca1aria2\u652f\u6301\u7684\u534f\u8bae\u591a\uff0c\u4e3b\u8981\u662f\u4e00\u4e9b\u7f51\u76d8\u4ec0\u4e48\u7684\u652f\u6301tr\u4e0d\u80fd\u5b9e\u73b0\n2014-4-29 \u4e0b\u53488:29\u4e8e \"semigodking\" notifications@github.com\u5199\u9053\uff1a\n\n\u6709\u554a\uff0c\u6839\u636e\u89c2\u5bdf\uff0c\u5185\u5b58\u5360\u7528\u662f\u6162\u6162\u589e\u52a0\u7684\uff0c\u76f4\u5230\u641e\u6302\u3002\u6240\u4ee5\u6211\u8fd8\u662f\u8f6c\u56detransmission\u4e86\u3002\u800c\u4e14tr\u7684\u5ba2\u6237\u7aef\u4e5f\u4e30\u5bcc\u591a\u4e86\n2014-4-29 \u4e0a\u53489:59\u4e8e \"qiuzi\" notifications@github.com\u5199\u9053\uff1a\n\n\u4f60\u4e5f\u9047\u5230\u8fc7\u4e0bbt\u5360\u7528vsz 170%\u7684\u95ee\u9898\u5417\uff1f\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41635145>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41669507\n.\n. I'm sorry, I and he is a friend\n2014-4-29 \u4e0b\u53488:52\u4e8e \"Tatsuhiro Tsujikawa\" notifications@github.com\u5199\u9053\uff1a\nPlease use English here. I'm warning you gently.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41671556\n.\n. @nmaier  What patch?\n. BT only use a proxy, http remain directly connected\nSimilar to uTorrent agent\n. Compiled using the MUSL aria2 doesn't run correctly using uClibc can work\nproperly\n\n2015-06-22 20:06 GMT+08:00 Tatsuhiro Tsujikawa notifications@github.com:\n\nIs MUSL some kind of libc replacement? Are there cross compiler toolchain\navailable for Linux?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/427#issuecomment-114080576.\n. yes\n. mips24KE \nCompiles without error, but fails to run\n. Has normally Thank you!\n\n2015-07-22 6:50 GMT+08:00 Nils Maier notifications@github.com:\n\nMight be that musl has some API just stub'ed, returning always an error?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/427#issuecomment-123501676.\n. UTorrent can use the maximum speed to download, but Aria2 has been 0KB / s. UTorrent has HTTP, SOCKE5 proxy options. \n",
    "kartikm": "alias a2c='aria2c'\n:)\n. ",
    "s2marine": "Different account download the file from the Same URI, so it can't be done by using cookie.\n. ",
    "raybinson": "thx for reply. I'll check out the new code for testing!\n. ",
    "robbielj": "BOM issue indeed.\nI just found that the encoding was set to utf-8 with signature in Emeditor. Removing signature solves the issue.\nThank you.\n. On a relevant note, any plan to support utp protocol? It is a udp-based protocol. There are several clients having adopted it lately.\n. Try libuv-0.11.16.\nI encountered similar issues and tried a few of old releases. This version works fine.\n. ",
    "cron410": "read the docs. It states --input-file=/path/to/wherever is the proper option for saving your session.\n. Ill try that again thanks for the help.\n. ",
    "LeeroyDing": "There is a gist link in that issue, containing the configure results and compile outputs.\nThe exact error is: https://gist.github.com/LeeroyDing/6025744\n. ",
    "oceballos": "I've the same problem, and my OS is Fedora 17 64-bit, Kernel Linux 3.3.4-5.fc17.x86_64 . And Aria2 version is 1.17.1\n. Sorry I didn't explain myself properly, when I execute $autoreconf -i , I get the following output\n\"Can't exec \"autopoint\": No existe el fichero o el directorio at /usr/share/autoconf/Autom4te/FileUtils.pm line 345.\nautoreconf: failed to run autopoint: No existe el fichero o el directorio\nautoreconf: autopoint is needed because this package uses Gettext\"\nWhich its weird because I've installed all the aria2 dependencies specified in README.rst. And also have installed automake, autoconf and gettext packages.\nI hope you can help me out, and thanks for your time.\n. Thanks for your answer, I'm using the repo clone from git, and after installing gettext-devel I get the folloging output when using\nsh\n$ autoreconf -fiv\nautoreconf: Entering directory `.'\nautoreconf: running: autopoint --force\nautoreconf: running: aclocal --force -I m4 --install\nconfigure.ac:19: warning: macro 'AM_PATH_CPPUNIT' not found in library\nautoreconf: configure.ac: tracing\nautoreconf: configure.ac: adding subdirectory deps/wslay to autoreconf\nautoreconf: Entering directory `deps/wslay'\nautoreconf: configure.ac: not using Gettext\nautoreconf: running: aclocal --force -I m4\nautoreconf: running: libtoolize --copy --force\nlibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, `.'.\nlibtoolize: copying file `./ltmain.sh'\nlibtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4'.\nlibtoolize: copying file `m4/libtool.m4'\nlibtoolize: copying file `m4/ltoptions.m4'\nlibtoolize: copying file `m4/ltsugar.m4'\nlibtoolize: copying file `m4/ltversion.m4'\nlibtoolize: copying file `m4/lt~obsolete.m4'\nautoreconf: running: /usr/bin/autoconf --force\nautoreconf: running: /usr/bin/autoheader --force\nautoreconf: running: automake --add-missing --copy --force-missing\nautoreconf: Leaving directory `deps/wslay'\nlibtoolize: putting auxiliary files in `.'.\nlibtoolize: copying file `./ltmain.sh'\nlibtoolize: putting macros in AC_CONFIG_MACRO_DIR, `m4'.\nlibtoolize: copying file `m4/libtool.m4'\nlibtoolize: copying file `m4/ltoptions.m4'\nlibtoolize: copying file `m4/ltsugar.m4'\nlibtoolize: copying file `m4/ltversion.m4'\nlibtoolize: copying file `m4/lt~obsolete.m4'\nconfigure.ac:19: warning: macro 'AM_PATH_CPPUNIT' not found in library\nconfigure.ac:19: error: possibly undefined macro: AM_PATH_CPPUNIT\n      If this token and others are legitimate, please use m4_pattern_allow.\n      See the Autoconf documentation.\nautoreconf: /usr/bin/autoconf failed with exit status: 1\n. Yes i've realized that XD, i've compiled successfully thank you very much for your help, really!\n. I'm working in a vimeo - youtube multiconnection downloader using aria2. I don't know if you want that stuff included in your program but once I finish you can add this functionallity aswell, and collaborate in your project if you want.\n. I already found a way to use youtube-dl to make a cookie and give it to aria2 as input for downloading in segmented mode using metalink \u00a1\u00a1\u00a1It's outstandingly fast!!!\nBy the way I've some doubts, what is the difference between UnitNumberOptionHandler and NumberOptionHandler, yes I know it's a inherited class from NumberOptionHandler, but I cannot find a difference in its implementation in OptionHandlerImpl.\nThank you\n. ",
    "jjlawren": "Sorry, obviously should have attached those before.\naria 1.17.1 release\ngcc 4.7.3\nAnd here's the configure log. Only option was to set the prefix appropriately:\n\nconfigure: summary of build options:\nversion:        0.1.1 shared 0:0:0\nHost type:      x86_64-pc-solaris2.11\nInstall prefix: /opt/local\nC compiler:     gcc\nCFlags:         -g -O2\nLibrary types:  Shared=yes, Static=yes\nCUnit:          no\nBuild:          x86_64-pc-solaris2.11\nHost:           x86_64-pc-solaris2.11\nTarget:         x86_64-pc-solaris2.11\nInstall prefix: /opt/local\nCC:             gcc\nCXX:            g++\nCPP:            gcc -E\nCXXFLAGS:       -g -O2\nCFLAGS:         -g -O2\nCPPFLAGS:       -I$(top_builddir)/deps/wslay/lib/includes -I$(top_srcdir)/deps/wslay/lib/includes -I/opt/local/include  -I/opt/local/include  -I/opt/local/include/libxml2 -I/opt/local/include  -D_REENTRANT\nLDFLAGS:\nLIBS:           -lgmp -lnettle -L/opt/local/lib -Wl,-R/opt/local/lib -lgnutls  -L/opt/local/lib -Wl,-R/opt/local/lib -lsqlite3  -Wl,-R/opt/local/lib -L/opt/local/lib -R/opt/local/lib -lxml2 -lz -lpthread -lrt -L/opt/local/lib -liconv -lm -lsocket -lnsl -lz\nDEFS:           -DHAVE_CONFIG_H\nLibUV:          no\nSQLite3:        yes\nSSL Support:    yes\nAppleTLS:\nGnuTLS:         yes\nOpenSSL:\nCA Bundle:\nLibXML2:        yes\nLibExpat:\nLibCares:       no\nZlib:           yes\nEpoll:\nBittorrent:     yes\nMetalink:       yes\nXML-RPC:        yes\nMessage Digest: yes\nWebSocket:      yes\nLibaria2:       no\nbash_completion dir: ${datarootdir}/doc/${PACKAGE_TARNAME}/bash_completion\nStatic build:\n. Sorry if I'm not understanding your request, but I thought that's what the core stack showed? Here's the stack when running under mdb (Illumos/Solaris), which is identical to the core stack:\n::stack\n0x32d8dd()\nlibc.so.1_SUNW_Unwind_RaiseException+0x50(84bf50)\nlibstdc++.so.6.0.17__cxa_throw+0x59()\n_ZN5aria219HttpHeaderProcessor5parseEPKhm+0x5b1()\n_ZN5aria210HttpServer14receiveRequestEv+0x6c()\n_ZN5aria217HttpServerCommand7executeEv+0x144()\n_ZN5aria212_GLOBAL__N_114executeCommandERSt5dequeIPNS_7CommandESaIS3_EENS2_6STATUSE+0x6f()\n_ZN5aria214DownloadEngine3runEb+0xed()\n_ZN5aria219MultiUrlRequestInfo7executeEv+0x43()\n_ZN5aria24mainEiPPc+0x4f()\nmain+0x2c()\n_start+0x6c()\n. It's reproducible with a simple telnet connection to the rpc port and by sending a carriage return.\u00a0\n\nAlso, I'm working on getting gdb installed if the mdb output is not considered helpful.\n--jason\nOn Wed, Sep 4, 2013 at 9:47 PM, Nils Maier notifications@github.com\nwrote:\n\nAlso, it would help to know the exact request (Wireshark it, or something)\nReply to this email directly or view it on GitHub:\nhttps://github.com/tatsuhiro-t/aria2/issues/123#issuecomment-23840720\n. I've used OpenIndiana in the past and that worked without issue. The aria2c binary compiled on SmartOS linked to the binary provided packaged libs:\n\n$ ldd /opt/local/bin/aria2c | grep gcc\n        libstdc++.so.6 =>        /opt/local/gcc47/x86_64-sun-solaris2.11/lib/amd64/libstdc++.so.6\n        libgcc_s.so.1 =>    /opt/local/gcc47/x86_64-sun-solaris2.11/lib/amd64/libgcc_s.so.1\nI'll test against the equivalent libs in /usr/sfw/lib and report back.  \n--jason\nOn Thursday, September 5, 2013 at 10:53 AM, Nils Maier wrote:\n\nYeah, OpenSolaris 11 is from 2009 if memory serves right.\nWe need to either setup a real smartos to reproduce Which sounds like a PITA from glancing over the docs. Articles like \"How to install our pkgsrc fork\" are very off-putting.\nOr find something equivalent. Maybe OpenIndiana...  \n\u2014\nReply to this email directly or view it on GitHub (https://github.com/tatsuhiro-t/aria2/issues/123#issuecomment-23878332).\n. Launching with this no longer causes a coredump:\n\nLD_PRELOAD=/usr/sfw/lib/amd64/libgcc_s.so.1 aria2c --enable-rpc\nI'm now able to connect via RPC and add downloads without issue.\nNow, what is the proper way to configure/compile so I don't need to override startup with an environment variable?\n. Seems fine:\n$ vi test.cc\n$ g++ -o test test.cc\n$ ./test\nhuh?\n--jason\nOn Thursday, September 5, 2013 at 11:48 AM, Nils Maier wrote:\n\nSeems like the smartos gcc is broken. You should report this issue upstream.\nDoes something simple like this\ninclude  #include  int main() { try { throw std::string(\"huh?\"); } catch (const std::string& ex) { std::cerr << ex << std::endl; } return 0; }\ncompiled with g++-4.7 -o test test.cc (http://test.cc) work?\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/tatsuhiro-t/aria2/issues/123#issuecomment-23883036).\n. I've raised this question on the SmartOS mailing lists and there's a suspicion that it's a problem with the binary packaged gcc libraries. By the maintainers' request, I've created a bug report in their system to investigate further (https://github.com/joyent/pkgsrc/issues/74).\n\nI've noticed one other problem which somehow I hope is an additional side-effect of the compiler. The --on-download-complete actions seem to get triggered but never actually executed. I've created dummy bash scripts which only write the time and arguments to a log file and it's never triggered. However, there are log entries at INFO level like this:\n2013-09-06 12:55:34.679521 [INFO] [util.cc:1720] Executing user command: /home/user/scripts/oncomplete.sh 147bcc4e5b97e712 1 /downloads/testfile.txt\nCopying and pasting that command as it's displayed in the log entry runs the script without issue. Could this somehow be related to the previous GCC lib issues? I have used these commands extensively on other systems.\n. Looks like it is related to the library override:\n09/09 08:49:24 [NOTICE] Download complete: /downloads/testing123.out\n09/09 08:49:24 [INFO] Executing user command: /home/user/scripts/oncomplete.sh 1e8778bbff2b2f38 1 /downloads/testing123.out\nld.so.1: bash: fatal: /usr/sfw/lib/amd64/libgcc_s.so.1: wrong ELF class: ELFCLASS64\nHowever, trying to load with the 32 bit version fails immediately:\n$ LD_PRELOAD=/usr/sfw/lib/libgcc_s.so.1 aria2c --conf-path=/home/user/aria.cfg\nld.so.1: aria2c: fatal: /usr/sfw/lib/libgcc_s.so.1: wrong ELF class: ELFCLASS32\nEither way, sounds like I need to solve the compiler issue on SmartOS before this is going to work...\n. This was an issue in the packaged version, resolved in SmartOS pkgsrc 2018Q2 and later.. ",
    "pyed": "before you do anything, give 'youtube-dl' a try, it has it's own downloader and I don't expect you to use it, i just want you to use it's great lib of extractors for a lot of video sites, so you can do 'youtube-dl -g [videourl]' the '-g' option will return the download url and quit without doing anything more.\nnow it's your job to write little script that will get the download url and download it via aria2. this is how i use it.\nor maybe you'll find a way to combine youtube-dl in your version of aria2, that would be something.\n. I tried ftps and sftp both are giving me the is not supported yet error.\nhere's what i am doing\n``` bash\n~/Desktop $ aria2c --ftp-user=user --ftp-passwd=pass ftps://122.2.222.226:34432/home/user/files/hello\n08/30 12:08:19 [ERROR] CUID#6 - Download aborted. URI=ftps://122.2.222.226:34432/home/user/files/hello\nException: [AbstractCommand.cc:350] errorCode=1 URI=ftps://122.2.222.226:34432/home/user/files/hello\n  -> [InitiateConnectionCommandFactory.cc:90] errorCode=1 ftps is not supported yet.\n08/30 12:08:19 [NOTICE] Download GID#339b13b99182dd54 not complete:\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n339b13|ERR |        n/a | ftps://122.2.222.226:34432/home/user/files/hello\nStatus Legend:\n(ERR):error occurred.\naria2 will resume download if the transfer is restarted.\nIf there are any errors, then see the log file. See '-l' option in help/man page for details.\n``\n. Aha, I see now, I didn't compile it with--with-libssh2, I recompiled it and it is working now, and yes it issftp` of course.\nThanks\n. ",
    "djmattyg007": "@oceballos any chance you could share your solution?. ",
    "binux": "\"feature request: add option to limit the maximum size of log file\" by guessing\n. aria2 supports more protocols than transmission, especially file sharing.\n2014-4-29 \u4e0b\u534811:19\u4e8e \"qiuzi\" notifications@github.com\u5199\u9053\uff1a\n\n\u4f46tr\u6ca1aria2\u652f\u6301\u7684\u534f\u8bae\u591a\uff0c\u4e3b\u8981\u662f\u4e00\u4e9b\u7f51\u76d8\u4ec0\u4e48\u7684\u652f\u6301tr\u4e0d\u80fd\u5b9e\u73b0\n2014-4-29 \u4e0b\u53488:29\u4e8e \"semigodking\" notifications@github.com\u5199\u9053\uff1a\n\n\u6709\u554a\uff0c\u6839\u636e\u89c2\u5bdf\uff0c\u5185\u5b58\u5360\u7528\u662f\u6162\u6162\u589e\u52a0\u7684\uff0c\u76f4\u5230\u641e\u6302\u3002\u6240\u4ee5\u6211\u8fd8\u662f\u8f6c\u56detransmission\u4e86\u3002\u800c\u4e14tr\u7684\u5ba2\u6237\u7aef\u4e5f\u4e30\u5bcc\u591a\u4e86\n2014-4-29 \u4e0a\u53489:59\u4e8e \"qiuzi\" notifications@github.com\u5199\u9053\uff1a\n\n\u4f60\u4e5f\u9047\u5230\u8fc7\u4e0bbt\u5360\u7528vsz 170%\u7684\u95ee\u9898\u5417\uff1f\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41635145>\n.\n\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41669507>\n.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41689850\n.\n. maybe authenticate with a parameter like http://localhost:6800/jsonrpc?auth=dXNlcm5hbWU6cGFzc3dvcmQ%3D& method=aria2.tellStatus&id=foo&params=WyIyMDg5YjA1ZWNjYTNkODI5Il0%3D ?\n. > Using CORS XHR POST (instead of that jsonp crap, like webui does right now) does not work in current browsers, as you cannot use credentials.\n\nActually, Access-Control-Allow-Credentials is not necessary to CORS XHR POST. Just set Authorization header before send()\nvar xhr = new XMLHttpRequest;\nxhr.onload = function() { console.log(xhr.response) };\nxhr.open(\"POST\", \"http://localhost:6800/jsonrpc\");\nxhr.setRequestHeader(\"Authorization\", \"Basic \"+btoa(\"username:password\"));\nxhr.send('{\"jsonrpc\":\"2.0\",\"method\":\"aria2.getGlobalStat\",\"id\":1,\"params\":[]}');\nBut as it is not working with XHR GET, it may be misuse.\n. http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption-k\n. Read the manual before ask.\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption-s\n. Tested, it works.\nIt may take around 5 seconds to take effect (not fully tested, the size of files / # of connected peers may  affect the time)\nthanks for the feature!\n. @stangri \nThe save button is hidden in online demo of YAAW, you can enable it by remove the 'display: none' style. \nIf you are testing with the disabled options, it will not work, there is a active_task_allowed_options check in yaaw.js, you cannot submit them only by removing the disable attribute.\n. maybe try aria2c --enable-rpc --rpc-listen-all --no-conf=true on normal user.\nAnd which aria2c on both.. It's another project: https://github.com/znetstar/aria2ui/search?q=verifing&unscoped_q=verifing. Or https://github.com/ziahamza/webui-aria2/search?q=verifing&unscoped_q=verifing. ",
    "chrisandrewcl": "This would be great! I've just deleted a 4gb log file on a clean up before ending up in this thread looking for a fix\n. ",
    "nathaliarebolledo": "I have this error:\n[#74e3a3 0B/99MiB(0%) CN:44 SD:0 DL:0B]aria2c: Peer.cc:381: int64_t aria2::Peer::getCompletedLength() const: La declaraci\u00f3n res_' no se cumple.            \nAbortado (core' generado)\n. I'm using aria2 version 1.18.0.\nThe time that peers do not interact with each other and they are banned, is defined by aria2?\n. it is a rare occasion, but it follows a pattern. \nIn the log always fails here.\n2013-10-14 11:35:48.201215 [DEBUG] [DefaultPeerStorage.cc:266] Peer 179.252.193.177:56569 returned from CUID#0\n2013-10-14 11:35:48.201242 [DEBUG] [DefaultPeerStorage.cc:273] Cannot find peer 179.252.193.177:56569 in usedPeers_\nIt's  always when returned peer has CUID#0, and cannot be found in usedPeers_ list.\n. I'm sorry,\nWas open a session github from a college partner.\nI send to  you the log by email?\n. ",
    "romario74": "Es werden eingebaute Spezifikationen verwendet.\nZiel: x86_64-redhat-linux\nKonfiguriert mit: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-languages=c,c++,objc,obj-c++,java,fortran,ada --enable-java-awt=gtk --disable-dssi --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-1.5.0.0/jre --enable-libgcj-multifile --enable-java-maintainer-mode --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --disable-libjava-multilib --with-ppl --with-cloog --with-tune=generic --with-arch_32=i686 --build=x86_64-redhat-linux\nThread-Modell: posix\ngcc-Version 4.4.7 20120313 (Red Hat 4.4.7-3) (GCC)\n. Yeah this means quite likely RHEL5 support has also ceased. So all RedHat enterprise linuxes are now unsupported, which I thought was not your intention thinking of bugreport https://github.com/tatsuhiro-t/aria2/issues/75\nBut then again RHEL7 will hopefully be out soon.\n. ",
    "Nisto": "The argument line that was used for the session above:\n--no-conf=false --conf-path=.\\aria2.conf --input-file=C:\\urlist.txt --dir=C:\\\nAnd my .conf file looks like this:\nreferer=*\nsplit=5\nmax-connection-per-server=16\nmin-split-size=1M\nstream-piece-selector=inorder\nenable-http-pipelining=true\nremote-time=true\ncheck-certificate=false\nuser-agent=Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0)\nno-file-allocation-limit=100M\nsummary-interval=0\ndownload-result=full\nThe contents of the input file was:\nhttp://r6---sn-5go7ln7l.googlevideo.com/videoplayback?ipbits=0&upn=Uj9IoTJ9A24&ip=[I EDITED THIS OUT FOR GITHUB]&key=yt5&fexp=924615%2C914504%2C916626%2C924616%2C907231%2C907240&itag=43&id=f501e602d9a8cc71&ratebypass=yes&ms=au&mt=1383582502&mv=m&expire=1383607238&sver=3&source=youtube&sparams=id%2Cip%2Cipbits%2Citag%2Cratebypass%2Csource%2Cupn%2Cexpire&signature=1BF98A872203D4F53E020FAEAD543B84EE03EE62.E7D7040B1138A96C3E6EB08EAB61F56CFFAB68B1\nhttp://r6---sn-5go7ln7l.googlevideo.com/videoplayback?ipbits=0&upn=Uj9IoTJ9A24&ip=[I EDITED THIS OUT FOR GITHUB]&key=yt5&fexp=924615%2C914504%2C916626%2C924616%2C907231%2C907240&itag=22&id=f501e602d9a8cc71&ratebypass=yes&ms=au&mt=1383582502&mv=m&expire=1383607238&sver=3&source=youtube&sparams=id%2Cip%2Cipbits%2Citag%2Cratebypass%2Csource%2Cupn%2Cexpire&signature=3FA911E8A09DD201968E47AC306ABD22D689155A.3E764877D240A378E0F26D3A74A93CE593429713\n. Unfortunately, that's not something I can control (not the way I'd like to at least), because the input files comes directly from a file generated by the Firefox add-on FlashGot.\nBut either way.. it WAS intended for the auto rename functionality to change the names of the files so that they could both be downloaded. I'm not really bothered by \"incorrect\" file names, as long as they can be downloaded quickly via an input file. So is there no way for auto rename to just append \".x\" for --input-file downloaded files, like in normal mode?\n. In the cases above, that wouldn't work (at least not on Windows XP and probably newer Windows systems as well), because the query string is longer than 255 characters. Is there not a header you can read to get the suggested file name? In some cases I've seen\nContent-disposition: attachment; filename=...\nMaybe not all sites use that method for suggested file names though?\n. Could you perhaps explain why appending \".x\" doesn't work for --input-file cases?\n. Aha, I see.\nI don't know exactly how the --input-file works behind the scenes (and I probably wouldn't understand much of the source code if you told me where to look), but could it be done by checking if opening a handle for the file worked or not maybe? And then ask for a new filename if unsuccessful?\n. I don't know how to compile under Windows XP, especially since there are no instructions on how to build aria2c under Windows systems. And usually I'm unsuccessful when compiling programs anyway (I've tried a few times in the past). Could you make a quick and dirty win32 build? You don't need to check it for errors or anything, I'll take the risk. If not, I'll let you know if it works, here, when you release the next official release on Sourceforge.\n. It works. The Unicode path issue I reported on Sourceforge appears to be resolved as well. Thank you so much!\n. You can't add an option to at least suppress these TLS/SSL encryption warnings/errors by any chance? Like maybe a new --console-log-level= option?\n.  The suppression of the warnings was all I asked for. I hope you can add it in the next release.\n. ",
    "barraponto": "Is there an option to prevent this from happening? I'd rather just skip the repeating URL altogether.\n. Figured out that --auto-file-renaming=false does it, but outputs error code 13. That's fine, but it'd be nice to have somehting like --never-redownload.\n. I think it does append .aria2 while it's still downloading...\n. ",
    "scythargon": "@tatsuhiro-t \nhttp://r6---sn-5go7ln7l.googlevideo.com/videoplayback?.....\n    out=file1\nhttp://r6---sn-5go7ln7l.googlevideo.com/videoplayback?.....\n    out=file2\nhow exactly to do that?\nout=file2 should be on the next line? cant get it to work. ",
    "torgelee": "thank you very much for your quick answer, i'll check the compile tool again\n\u00d4\u00da 2013-11-12 \u00cf\u00c2\u00ce\u00e79:47\u00a3\u00ac\"Tatsuhiro Tsujikawa\" notifications@github.com\u00d0\u00b4\u00b5\u00c0\u00a3\u00ba\n\nIt seems the compiler is not setup in the right way. From the error\nmessage, configure script failed to detect getaddrinfo, but it is unlikely\nif the toolchain is installed successfully. Maybe bug of NDK 9b.\n\u00a1\u00aa\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/147#issuecomment-28294093\n.\n. i have tried many times, it still not working, i doubt the configure script\nis wrong, because there's no --with-openssl-prefix in there, i wanna\ncompile for android on osx10.9, is the way generate configure script just\n\"autoreconfig -i\"?  tks\n\u00d4\u00da 2013-11-12 \u00cf\u00c2\u00ce\u00e79:47\u00a3\u00ac\"Tatsuhiro Tsujikawa\" notifications@github.com\u00d0\u00b4\u00b5\u00c0\u00a3\u00ba\nIt seems the compiler is not setup in the right way. From the error\nmessage, configure script failed to detect getaddrinfo, but it is unlikely\nif the toolchain is installed successfully. Maybe bug of NDK 9b.\n\u00a1\u00aa\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/147#issuecomment-28294093\n.\n. the config.log as below:\nhttps://gist.github.com/tohy/7458377\n. I got the problem, the configure script cannot find openssl c-ares and expat, but i've already cross compile these three libs and install then in the ANDROID_HOME/usr/lib, but configure script still cannot find them. it seems that \"--with-openssl-prefix=$PREFIX\" \"--with-libcares-prefix=$PREFIX\" and \"--with-libz-prefix=$PREFIX\" do not work, after modified android-config to delete these three libs, compile aria2 success, but i wanna support openssl, what can i do now? What is the right way to cross compile \"openssl expat c-ares\" on mac os x 10.9 for aria2 ?\n\nthank you very much!\n. How can i fix this? what is the right way to compile third party libraries? I love your product so much and wanna to compile by myself, from which to learn something. So could you please help me point out how to compile third party libraries on Mac OSX 10.9 using Android NDK ? \nAnd I'll keep trying to find out how to compile them.\nthank you!\n. apologies for slow response, follow your suggestion compile the openssl successful, and i compile aria2 for android after add \"PKG-CONFIG=/opt/local/bin/pkg-config\" option to android-config script, i really appreciated your help.\nBut there comes another problem, the size of compiled result \"aria2c\" is 54M, that is so big, what is wrong?\n. Done, thank u very much.\nIf i didn't compile libuv with it, what will be affected?\n. ",
    "semigodking": "I run it on embbed devices, so no tool for analysis available. I'll see if\nany proof can be collected.   Before that, you could treat this issue with\nlow priority.\n2013-11-17 \u4e0b\u53486:46\u4e8e \"Tatsuhiro Tsujikawa\" notifications@github.com\u5199\u9053\uff1a\n\naria2 is alive and running program and it is very natural to use more\nmemory if needed.\nHow do you determine that aria2 leaks memory?\nCould you provide us the result of memory leak detection tool like\nvalgrind.\nWithout that, it is very difficult to us to track down this kind of issue.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-28646259\n.\n. Forget to let you know how it behaves.\nWhen it starts by root and BT downloading starts, its memory footprint is\n11M. Then the memory footprint keeps increasing. Finally, not enough\nmemory, other processes started with nobody get killed. Now it is about\n25MB. And it is still increasing.\n\nI run it on embbed devices, so no tool for analysis available. I'll see if\nany proof can be collected.   Before that, you could treat this issue with\nlow priority.\n2013-11-17 \u4e0b\u53486:46\u4e8e \"Tatsuhiro Tsujikawa\" notifications@github.com\u5199\u9053\uff1a\n\naria2 is alive and running program and it is very natural to use more\nmemory if needed.\nHow do you determine that aria2 leaks memory?\nCould you provide us the result of memory leak detection tool like\nvalgrind.\nWithout that, it is very difficult to us to track down this kind of issue.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-28646259\n.\n. I set it to 2m.\n2013-11-17 \u4e0b\u53488:09\u4e8e \"Tatsuhiro Tsujikawa\" notifications@github.com\u5199\u9053\uff1a\nFor low memory device, use --disk-cache=0 to disable disk cache in memory,\nwhich is by default 20MB.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-28647365\n.\n. \u6709\u554a\uff0c\u6839\u636e\u89c2\u5bdf\uff0c\u5185\u5b58\u5360\u7528\u662f\u6162\u6162\u589e\u52a0\u7684\uff0c\u76f4\u5230\u641e\u6302\u3002\u6240\u4ee5\u6211\u8fd8\u662f\u8f6c\u56detransmission\u4e86\u3002\u800c\u4e14tr\u7684\u5ba2\u6237\u7aef\u4e5f\u4e30\u5bcc\u591a\u4e86\n2014-4-29 \u4e0a\u53489:59\u4e8e \"qiuzi\" notifications@github.com\u5199\u9053\uff1a\n\u4f60\u4e5f\u9047\u5230\u8fc7\u4e0bbt\u5360\u7528vsz 170%\u7684\u95ee\u9898\u5417\uff1f\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/149#issuecomment-41635145\n.\n. \n",
    "xubuntu4iran": "I also confirm lack of this feature.\n. use privoxy\n. En example:\naria2c http://cdimage.debian.org/debian-cd/7.2.0/i386/iso-cd/debian-7.2.0-i386-lxde-CD-1.iso\n[#2e6f15 160KiB/648MiB(0%) CN:8 DL:46KiB ETA:3h56m30s] \nI want an argument that only prints 648MiB and exit and doesn't download this file\n. En example:\naria2c -S http://cdimage.debian.org/debian-cd/7.2.0/i386/bt-cd/debian-7.2.0-i386-lxde-CD-1.iso.torrent\n\n\n\nPrinting the contents of file 'http://cdimage.debian.org/debian-cd/7.2.0/i386/bt-cd/debian-7.2.0-i386-lxde-CD-1.iso.torrent'...\nThis file is neither Torrent nor Metalink file. Skipping.\n. I know, but why  should not this option  work with urls \n. I also added screenshot in first post, they are printed left to right, while Persian is right to left  and some letters join together in words\n. But you can correct this problem for most terminals not supporting bidi with considering an option like --bidi-workaround, please take a look at https://github.com/rg3/youtube-dl/issues/1912\n. \n\n\n",
    "eMBee": "socks support has been rejected before because it is possible to use other tools to socksify aria2.\nhowever, not supporting socks directly makes it difficult to integrate aria2 with other tools such as browser download extensions that can hand off downloads to aria2.\ni would have to create a wrapper script, and somehow force the download extension to use that script.\n. i have not actually tried it. on the commandline i can use tsocks.\nwhat tsocks does is to force all connections made by aria2 through a single connection, this reducing the advantage aria2 has by opening multiple connections to different sites. it would still work, if you have a fast socks tunnel though.\nto use this from a browser, you'd have to write a script that wraps around aria2 which then is called from your download extension. that script then calls tsocks with aria2.\ni don't use browser downloaders, so i have not tried that myself.\nideally, aria2 would support a different socks tunnel per connection. the reason for that is that, at least here, bandwidth is shared across all connections from the people in this neighborhood. if the local link here is busy, then with aria2 i can say download a file with 5x100KB/s by downloading from 5 sites, but if i use tsocks, my speed is reduced to 1x100KB/s.\n. no, because that would require support from aria2c.\nalternatively, i think a proxy that opens a new tcp connection for each request might work too. \ni think http proxies do that, but for socks i am not aware that such a proxy even exists.\n. Socks is a different protocol than HTTP\n. the fallback reason is always: someone needs to do the work.\nif someone can submit an implementation, the chance of getting this feature in will rise.. ",
    "leecade": ":+1: \n. ",
    "orliesaurus": "@eMBee how do you socksify aria? any tips or names of tools for this job?\n. I'm using it from command line, trying to get aria2 to work throught my personal ssh-VPN to keep my traffic \"clean\" leaving my household. so I think I'll have a look at tsocks, unless someone has done it before and has a pointer. thx\n. :( damn\n. ",
    "renne": ":thumbsup:\n. Does torify really use a new circuit per connection when downloading concurrent ranges? Otherwise the speed will be limited like ONE SINGLE connection.\n. @pickfire \nBittorrent is quite chatty. But if you just want anonymous concurrent HTTP downloads TOR is quite useful.\n@andrew-aladev \nPlease use \"socks5 127.0.0.1 9050\" to prevent DNS leaks. SOCKS5 uses DNS via SOCKS5 (->TOR) while SOCKS4 uses an external DNS-resolver (usually the system resolver).\n. You can use a TCP load balancer like haproxy (*nix).\nExample:\n/etc/tor/torrc:\nSOCKSPort 40000\n   .\n   .\n   .\nSOCKSPort 41023\n/etc/haproxy/haproxy.cfg:\n```\nlisten tor\n    bind    127.0.0.1:9050\n    mode    tcp\n    option  tcplog\n    balance roundrobin\nserver  tor40000    127.0.0.1:40000 check\n       .\n       .\n       .\nserver  tor41023    127.0.0.1:41023 check\n\n```\nThis configuration will robin round 1024 TOR circuits.\n. ",
    "pickfire": "You can use a wrapper around aria2 such as torify aria2c with the package tor.\n. I tried torify aria2c and torsocks aria2c, and it doesn't seem to work now.\n. There is a way to use tor with aria2c which is to route the traffic through polipo first then through tor. But using tor for bittorrent is not secure.\n. @renne TOR warn us to not use it for bittorrent.\n. ",
    "andrew-aladev": "proxychains aria2c --bt-max-peers=1 file.torrent\nProxy chain for example:\nsocks4 127.0.0.1 9050\nhttp 212.80.30.2 8080\nIt works fine and it is secure (incoming port should be closed)\n. @renne proxychains has it's own workaround for any chain: \"proxy_dns\" option. But anyway socks5 is good tone. Thank you.\n. > @renne TOR warn us to not use it for bittorrent.\nYes, that's why we need to use --bt-max-peers=1, it will works like regular secure download.. ",
    "shoaly": "@eMBee so do you find a way to use aria2c with multiply proxies at one download URI?\n. ",
    "mantovani": "I miss this feature too.. ",
    "Tony-il-Capo": "+1\nIt would be great to have socks proxy support in aria2 just like curl.. ",
    "alireza-amirsamimi": "+1\nI miss this feature too.\nThis feature can help tor users to use aria2 more easily. Tor users must use privoxy or polipo to convert socks proxy to http proxy now.\nIt would be great to have socks proxy support in aria2 like curl and wget.. I searched and tested someting but I coudn't handle the problem\nHow can I directly pass cookie header field (using header option)\nCan you say an example please\nthanks\n. thanks\naccording to this page :\nhttps://aria2.github.io/manual/en/html/aria2c.html#id6\nand your guides I wrote codes to make headers\nfor example this (GMail):\n'header' : ['S:gmail:***', 'COMPASS:gmail:***', '***']\nor this (dropbox)\n'header' : ['uc_session:***']\nbut still not working same as before\n. sorry!\nI was made a mistake\nIt worked for gmail\nbut not worked for dropbox\nI tried to download one of this files\nhttps://www.dropbox.com/sh/vj4k3czj60jg7hf/AAAxGQJ8ZXRwlvFfeGUiQHG7a?dl=0&preview=1.file_and_folder_structure.mkv\ndo you have any idea to solve this problem?\n. Thank you very much :)\nI'll work on it.\n. I think yes! because it works for the other sites(gmail , mediafire , and many sites)\nI have this problem only with few websites (for example github)\n. Sorry!\nIt was my mistake!I was sended http-user whith https link!\nproblem solved\nthanks for replays\n. Thank you \ud83d\udc4d . ",
    "leleobhz": "Miss this feature +1. ",
    "JackofSpades707": "+1 for this feature.\nThere are workarounds, but direct support is always better than hacky solutions. ",
    "Mygod": "So are there any REAL reasons not to support this feature?. So I'm trying to add socks5 proxy and it seems that adding it for (s)ftp and http(s) wouldn't be too much work. One just needs to implement handshakes with AbstractProxyRequestCommand and other classes. Making it work for torrenting is another story. However I'm working very slowly due to lack of familiarity to the codebase. Can somebody more experienced with the codebase work out this feature please? I don't think I'll be bothered to finish this.\nHere's some progress I made:\n```cc\ndiff --git a/src/AbstractCommand.cc b/src/AbstractCommand.cc\nindex bf307b7..fa4d7d2 100644\n--- a/src/AbstractCommand.cc\n+++ b/src/AbstractCommand.cc\n@@ -677,7 +677,8 @@ std::string getProxyUri(const std::string& protocol, const Option* option)\n                              PREF_FTP_PROXY_PASSWD, option);\n   }\n\nreturn A2STR::NIL;\nreturn makeProxyUri(PREF_ALL_PROXY, PREF_ALL_PROXY_USER,\nPREF_ALL_PROXY_PASSWD, option);\n }\n\nnamespace {\ndiff --git a/src/OptionHandlerImpl.cc b/src/OptionHandlerImpl.cc\nindex 6214e84..24ad2e5 100644\n--- a/src/OptionHandlerImpl.cc\n+++ b/src/OptionHandlerImpl.cc\n@@ -508,7 +508,8 @@ void HttpProxyOptionHandler::parseArg(Option& option,\n     std::string uri;\n     if (util::startsWith(optarg, \"http://\") ||\n         util::startsWith(optarg, \"https://\") ||\n-        util::startsWith(optarg, \"ftp://\")) {\n+        util::startsWith(optarg, \"ftp://\") ||\n+        util::startsWith(optarg, \"socks5://\")) {\n       uri = optarg;\n     }\n     else {\n``\nAlsoAbstractCommand::resolveProxyMethodneeds to return a new constantV_SOCKSforsocks5. And add handshake code atHttpInitiateConnectionCommand::createNextCommand`.. I self-built the latest commit and it seems to fix this issue.. ",
    "softwarevamp": "socks proxy save a lot of $$$ than http.. ",
    "MadhavChoudhary": "I am trying to redirect both udp and tcp traffic of aria2 through my ssh tunnel. It is not working. Sometimes, a channel #: open failed: connect failed: Connection refused message comes in my ssh server. Can someone guide me?. ",
    "benwaffle": "@tatsuhiro-t it's not an issue, its a caveat when using homebrew. It doesn't link gettext likely because it doesn't want to override the tools that OSX provides.\n. ",
    "chapinb": "Thanks @nmaier solution # 2 helped perfectly\n. ",
    "dluciv": "Thank you very much for the explanation! Hope some day local files will be supported.\n. ",
    "sambul13": "Also wanted to add that some files are never completed in a single session, i.e. if a download session being interrupted, and they MUST have a different extension, so a user can open a File Manager and see what files need to be resumed or restarted once their source is online again.\n. Thanks, I'll try that. It appears, .torrent renaming is a part of broader strategy to be able to resume downloads despite the torrent aria2 control file is damaged or absent? I guess, the same can be achieved by re-checking downloaded torrent piece hashes?\n. Hi  Tatsuhiro,\nBut aria2 can't start as a Win8.1 Service via NSSM without creating .aria2\ndir, even so a torrent link is not entered yet. Also, where in this case\naria2 stores logs, session, dht and config files?\nOn Tue, 20 May 2014 08:30:37 -0400, Tatsuhiro Tsujikawa\nnotifications@github.com wrote:\n\nNormally, aria2 does not create .aria2 directory in user home directory.\nIt creates it when it tries to save BitTorrent DHT file.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi Tatsuhiro,\n\nI think there is misunderstanding here. The problem is, aria2 can't start\nas a service in Win8.1 if there is no config file. Its supposed to use\ndefault config values as you say, but it does NOT. Pls try it yourself\nstarting aria2 in Win8.1 via NSSM as a service. That was the subject of my\nbug report - aria2 doesn't use default values as it should, when started\nas a service, instead it looks for a config file in standard location, and\nfails to find it. Can you fix that - namely make aria2 use default values\nwhen started as a service in Win8.1 64-bit? Thanks.\nOn Wed, 21 May 2014 08:47:29 -0400, Tatsuhiro Tsujikawa\nnotifications@github.com wrote:\n\nIf .aria2 is not found, aria2 runs with default values. This is all we\ndo for years now.\nIf you need configuration file read from the standard location, then you\nhave to manually create .aria2 and copy aria2.conf, just like you did.\n\u2014\nReply to this email directly or view it on GitHub.\n. I checked that, starting aria2 with --enable-rpc  from a non-system drive to avoid extra permission issues, and it worked, with .torrent and downloaded movie file being saved in aria2 program startup dir. Looking at  webui-aria2 GUI - Settings, aria2 attempted to create .aria2 settings folder and config in\nC:\\Windows\\system32\\config\\systemprofile/.aria2/aria2.conf . Whether because it didn't have permissions (such action requires confirmation, as Win 8.1 is stricter with that compare to Win7) or also since the Linux style path is wrong for Windows, it  couldn't create the folder and files in it. This means, session, config, logs etc. were not saved even in program startup dir. So the issue still needs author's attention. :)\n\nWhat would be the right format to add several startup parameters when creating aria2 NSSM service -- list them comma separated without spaces? This way it may be possible to add the path for Settings folder. Still, the issue with \"/\" in default config needs fixing.\n. ",
    "Magissia": "Good idea\n. Wasn't able to reproduce, don't know what happened\n. Hello, so 192.xxx.xxx.xxx isn't\nvalid ? This is what i used.\n. I will retry then. I should use the local ip, not the gateway ip or anything else, correct ?\n. Hello, while the logs says it was bind to the correct interface, when downloading a file, there's no network activity on said NIC, and the default NIC (192.168.xxx.xx) is used instead.\nMy configuration file do have \"interface=192.168.xxx.xy\" and the configuration file is loaded correctly as the download dir and logging file path are respected.\nIn case it is important, files to download are added via aria2-webui on localhost.\n2014-02-28 23:10:53.835599 [INFO] [Context.cc:178] aria2 1.18.3 x86_64-w64-mingw32\n2014-02-28 23:10:53.835599 [INFO] [Context.cc:179] Logging started.\n2014-02-28 23:10:53.835599 [INFO] [SocketCore.cc:1215] Checking configured addresses\n2014-02-28 23:10:53.839599 [INFO] [SocketCore.cc:1278] Found configured address: 192.168.xxx.xy\n2014-02-28 23:10:53.839599 [INFO] [SocketCore.cc:1278] Found configured address: 192.168.xxx.xx\n2014-02-28 23:10:53.839599 [INFO] [SocketCore.cc:1280] Not considered: ::1\n2014-02-28 23:10:53.839599 [INFO] [SocketCore.cc:1280] Not considered: 127.0.0.1\n2014-02-28 23:10:53.839599 [INFO] [SocketCore.cc:1288] IPv4 configured=1, IPv6 configured=0\n2014-02-28 23:10:53.839599 [DEBUG] [SocketCore.cc:986] Finding interface 192.168.xxx.xy\n2014-02-28 23:10:53.840599 [DEBUG] [SocketCore.cc:977] Sockets will bind to 192.168.xxx.xy\n2014-02-28 23:10:53.840599 [INFO] [HttpListenCommand.cc:109] CUID#6 - Using port 59500 for accepting new connections\n2014-02-28 23:10:53.840599 [NOTICE] [HttpListenCommand.cc:111] IPv4 RPC: listening on TCP port 59500\n2014-02-28 23:10:53.841599 [INFO] [HttpListenCommand.cc:109] CUID#7 - Using port 59500 for accepting new connections\n2014-02-28 23:10:53.841599 [NOTICE] [HttpListenCommand.cc:111] IPv6 RPC: listening on TCP port 59500\nfull log at https://s.gks.gs/paste/?e8ff2c52362f3289#XsJViXwjT+AYeTo96Fv+On5ifk8Mz7CkgyGijiaWwH8= (will expire in one month)\n. Hello, i tested with my W7 rig, download was bound to the first NIC and not the NIC i specified on the config file.\nTried with --interface directly and removing the config file, but it still downloaded with the first NIC.\nHere's my config file\nlog=C:\\Users\\Trololo.aria2\\Aria2.log\ncheck-integrity=true\nmax-connection-per-server=3\nmin-split-size=10M\nhttp-accept-gzip=true\ndisk-cache=1024M\ninterface=192.168.xxx.xx\ndir=C:\\Users\\Trololo\\Downloads\ncheck-certificate=false\nfile-allocation=falloc\nFirst NIC is 192.168.xxx.xy\n. Problem was due to the way Kaspersky handle web scanning.\nOpened a ticket directly at Kaspersky's support telling them Kaspersky breaks interface binding (tested with other binding capable software, they all broke but \u00b5Torrent and IIS for who knows reason)\n. ",
    "jirib": "+1 as i don't know a way to see which files are completed and which haven't been yet.\n. ",
    "pepa65": "Should be easy to tack .aria2 onto the incomplete filenames, and rename them when done.\n. You mean March 2016\n. ",
    "Deadooshka": "I think the best name for .torrent is like <original_name>-<hash>.torrent. It helps to visually associate the related files.\n. aria starts with this config\n```\nfile-allocation=falloc\nfile-allocation=none\nlog-level=info\nmax-connection-per-server=10\nlog=c:\\logs\\aria2c.log\ndir=c:\\Downloads\nsummary-interval=0\nshow-console-readout=true\nquiet=false\ndisk-cache=3M\ncheck-certificate=false\nfollow-torrent=false\nallow-overwrite=true\n```\nnot as a daemon\n. fixed in 1.18.6\n. I think it is a matter of the aria2 popularization. When users see the aria2 logo in clients list, they probably will use it.\n. please update an item here http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--peer-id-prefix\n. udp trackers requires dht enabled. See about private flag http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--enable-dht\n. DHT makes big udp-flood, so i enable it only to download torrents with udp:// announcement URLs or magnets. It seems udp announcement not works with enable-dht=false. Assumed that we allowed udp-traffic to the dht-listen-port in firewall.\n. aria --out=filename.part --on-download-complete=\"/script to remove .part\" url\n. this option is --on-download-complete\n. Consider to remove this annoying warning and add it to the manual. Because it's not default value for the --file-allocation.\n. ffmpeg. v1.33 win32 win7 ~50% on old 2-core cpu.. ",
    "mndt": "DHT has no problems.\nI have version 1.18.1. I compiled it myself. Maybe there is a trigger or a special library that should be enabled during compilation!?\n```\naria2c -v\naria2 version 1.18.1\nCopyright (C) 2006, 2013 Tatsuhiro Tsujikawa\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n Configuration \nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5\nLibraries: zlib/1.2.3 libxml2/2.7.6 sqlite3/3.6.20 GnuTLS/2.8.5 libgcrypt/1.4.5 c-ares/1.7.0\nReport bugs to t-tujikawa@users.sourceforge.net\nVisit http://aria2.sourceforge.net/\n```\nI installed version 1.16.4 using yum, but it had the same issue.\nAny help would be much appreciated.\n. ",
    "mario-grgic": "Actually, the crash happens with any URL not just bittorrent. For example:\naria2c http://www.google.com/ will crash aria2c as well. \nI don't seem to have issues with other software using OpenSSL (e.g. curl).\n$ openssl version\nOpenSSL 0.9.8y 5 Feb 2013\n$\nFrom the crash log it looks like there is NULL pointer access somewhere in MessageDigestBase when trying to evaluate sha1 digest?\n. Ok, I managed to fix this. Basically, my build was linking against wrong libcrypto (I have one in /usr/local/lib in addition to the system one).\n. Yes, it looks like a problem with libraries on my system only. This issue can be closed.\n. This goes away after I upgraded GMP to version 6.1\n. ",
    "AndCycle": "@tatsuhiro-t \nmay I ask a question about how should I do it?\nas you suggest allow-overwrite will truncate file first,\nso if I only use check-integrity, will it update the file that exist but have different checksum?\nthe scenario here is I use aria2 as a content update program,\nI need it to download content that been updated.\n. @tatsuhiro-t \ntried on small file which is hardly confirm the behavior because it finish in secs, just wanna make sure.\n. current version, I think I provide a invalid sample for this, \nbecause I spot this symptoms on a custom made meta4 file which contain thousands of file,\nwhich is not suitable for a bug report,\nI will refine a correct sample on this.\n. sorry for the invalid sample, here is a working one,\nwhich you can spot there is extra download complete notice\n<?xml version=\"1.0\" ?>\n<metalink xmlns=\"urn:ietf:params:xml:ns:metalink\">\n    <file name=\"bat/eng.bat/ch1-1.bat\">\n        <url>https://s3-ap-northeast-1.amazonaws.com/allstars-personal/content/class/bat/eng.bat/ch1-1.bat</url>\n        <metaurl mediatype=\"torrent\">https://s3-ap-northeast-1.amazonaws.com/allstars-personal/content/class/bat/eng.bat/ch1-1.bat?torrent</metaurl>\n    </file>\n    <file name=\"bat/eng.bat/ch2-1.bat\">\n        <url>https://s3-ap-northeast-1.amazonaws.com/allstars-personal/content/class/bat/eng.bat/ch2-1.bat</url>\n        <metaurl mediatype=\"torrent\">https://s3-ap-northeast-1.amazonaws.com/allstars-personal/content/class/bat/eng.bat/ch2-1.bat?torrent</metaurl>\n    </file>\n</metalink>\n\nD:\\test>aria2c.exe --seed-time=0 test-b.meta4\n04/23 17:20:36 [WARN] Gaining privilege SeManageVolumePrivilege failed.\n04/23 17:20:36 [WARN] --file-allocation=falloc will not work properly.\n04/23 17:20:37 [NOTICE] Download complete: D:/test/ch2-1.bat\n04/23 17:20:37 [NOTICE] IPv4 DHT: listening on UDP port 6963\n04/23 17:20:37 [NOTICE] IPv4 BitTorrent: listening on TCP port 6947\n04/23 17:20:37 [NOTICE] Download complete: D:/test/ch1-1.bat\n04/23 17:20:37 [NOTICE] Seeding is over.\n04/23 17:20:37 [NOTICE] Seeding is over.\n04/23 17:20:37 [NOTICE] Download complete: D:/test/bat/eng.bat/ch1-1.bat\n04/23 17:20:37 [NOTICE] Your share ratio was 0.0, uploaded/downloaded=0B/135B\n04/23 17:20:37 [NOTICE] Download complete: D:/test/bat/eng.bat/ch2-1.bat\n04/23 17:20:37 [NOTICE] Your share ratio was 0.0, uploaded/downloaded=0B/135B\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n601672|OK  |   1.2KiB/s|D:/test/bat/eng.bat/ch1-1.bat\n06db07|OK  |     849B/s|D:/test/bat/eng.bat/ch2-1.bat\nStatus Legend:\n(OK):download completed.\n. > 04/23 17:20:37 [NOTICE] Download complete: D:/test/ch2-1.bat\n04/23 17:20:37 [NOTICE] Download complete: D:/test/ch1-1.bat\n\njust wondering about this two line, why they are there?\ndoes the file actually save there once then moved to the destination?\nif it is so is there any filename conflict issue?\n. thanks for the fix\n. @tatsuhiro-t \nsorry, I don't get it, \nthose torrent file are generate by amazon S3 which I have no control at all,\nI just rely on them to simplify file distribution.\neven if I describe that name attribute, they still got the same BT source origin which raise errorCode 12 during concurrent download.\na.key.mp4 and b.key.mp4 share the same source is because I dedup before upload to amazon S3.\n. if I specific name within torrent,\nit only do one file\n<?xml version=\"1.0\" ?>\n<metalink xmlns=\"urn:ietf:params:xml:ns:metalink\">\n    <file name=\"video1/a.key.mp4\">\n        <size>141983438</size>\n        <hash type=\"md5\">62b45e29f94ba8d95f4aedd6daa3dae9</hash>\n        <hash type=\"sha-1\">c5dfe67ac00f39e8ced7059408c665f0691ed455</hash>\n        <hash type=\"sha-256\">40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1</hash>\n        <url>https://s3-ap-northeast-1.amazonaws.com/allstars-personal/Jnr/deploy/4/0/6/9/40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438</url>\n        <metaurl mediatype=\"torrent\" name=\"Jnr_deploy_4_0_6_9_40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438\" pri=\"1\">https://s3-ap-northeast-1.amazonaws.com/allstars-personal/Jnr/deploy/4/0/6/9/40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438?torrent</metaurl>\n    </file>\n    <file name=\"video2/b.key.mp4\">\n        <size>141983438</size>\n        <hash type=\"md5\">62b45e29f94ba8d95f4aedd6daa3dae9</hash>\n        <hash type=\"sha-1\">c5dfe67ac00f39e8ced7059408c665f0691ed455</hash>\n        <hash type=\"sha-256\">40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1</hash>\n        <url>https://s3-ap-northeast-1.amazonaws.com/allstars-personal/Jnr/deploy/4/0/6/9/40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438</url>\n        <metaurl mediatype=\"torrent\" name=\"Jnr_deploy_4_0_6_9_40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438\" pri=\"1\">https://s3-ap-northeast-1.amazonaws.com/allstars-personal/Jnr/deploy/4/0/6/9/40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438?torrent</metaurl>\n    </file>\n</metalink>\n```\nD:\\test\\a>aria2c.exe -V --seed-time=0 issue3.meta4\n06/24 16:16:49 [NOTICE] Download complete: [MEMORY]40699f4a238953959e89682c539f42a5e1c1bd3fac130453916cffdfc63a79c1-141983438\n06/24 16:16:49 [NOTICE] IPv4 DHT: listening on UDP port 6968\n06/24 16:16:49 [ERROR] Checksum error detected. file=D:/test/a/video2/b.key.mp4\n06/24 16:16:49 [NOTICE] Allocating disk space. Use --file-allocation=none to disable it. See --file-allocation option in man page for more details.\n06/24 16:16:49 [NOTICE] IPv4 BitTorrent: listening on TCP port 6907\n[#5d8818 135MiB/135MiB(99%) CN:2 SD:1 DL:3.5MiB]\n06/24 16:17:25 [NOTICE] Seeding is over.\n[#5d8818 SEED(0.0) CN:2 SD:1]\n06/24 16:17:26 [NOTICE] Download complete: D:/test/a/video2/b.key.mp4\n06/24 16:17:26 [NOTICE] Your share ratio was 0.0, uploaded/downloaded=0B/135MiB\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n5d8818|OK  |   3.7MiB/s|D:/test/a/video2/b.key.mp4\nStatus Legend:\n(OK):download completed.\n```\n. ",
    "fenix01": "It seems to be a problem with my computer, maybe my firewall or something like this. I run my torrent on my server and it works like a charm. Sorry ..\n. ",
    "strawgate": "I set --realtime-chunk-checksum to false and performance pretty much doubled (to 20 MB/s) and I haven't seen any disconnects since. I believe it dropped to 0mbps during that log but I captured a bunch of logs that day. I've been able to reproduce it in VMs and on physical hardware 100% of the time, so I'll go ahead and capture another one tomorrow and post it.\nAs a note, these clients are on a LAN together and when not in WinPE typically achieve transfer speeds of 50-60MB/s using Aria2\nThanks!\n. Now that you mention it I've remove that option and they appear just as fast. I just remembered that at the same time as adding that option we switched the distributed seeds to using aria2 instead of utorrent for their client.\nAs an aside, should it be normal for them to be pegging a 3.4ghz single core for 10-20MB/s? I'll work on uploading a new log first thing tomorrow.\n. ",
    "chavenor": "Ok sounds good.   Thank you very much.   Do you take donations via bitcoin?\nOn Mon, Jan 20, 2014 at 8:39 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\nWe have nothing special in this area. In each release, we packaged source\ntar balls and several compiled verions (Mac OSX, android and Windows).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/184#issuecomment-32764274\n.\n. \n",
    "iavael": "\nTo specify arbitrary values from the command-line option is not good idea to me.\n\nOther torrent clients usually do it so, because...\n\nIs there good default value for download client?\n\nIt's not possible, since desired DSCP value depends on routers' configuration in every specific network and desired shaping policy for traffic. So, there cannot be any default non-zero values for specific types of applications.\n\nAlso it would be nice to add help messages to the option to tell user what this option does for them.\n\nOk\n. Help message was improved\n. Because setsockopt(2) with IPTOS parameter sets whole TOS field in IP packets, while DSCP value is located in higher 6 bits of this field and lower 2 are dedicated for ECN.\nhttps://en.wikipedia.org/wiki/Type_of_service#DS_field_and_ECN\n. > Well, then those details have to be described in the help message.\nThe only only place, where user may see left-shifted values is /usr/include/netinet/ip.h, where whole TOS field is defined, not it's DSCP part only.\nWhen user would like to set DSCP, he will look in the documentation, where values are non-shifted, but not in system headers. Mentioning of low-level API usage details like leftshifting will only confuse users.\n\ntake a value as is and specify it with clearing lower 2bits (or print error if those 2 bits are nonzero)\n\nOS clears 2 lower bit of TOS automatically.\n\nThe end user may not know \"left-shift by 2\".\n\nWhen user would like to set CS4 class for he's traffic, he'll look in DSCP documentation and set 32. But, if we won't shift the value the effective class would turn into 8 (CS1). Leftshifting is just a way to place desired DSCP value to the right part of IP packet, it's totally internal and user's don't have to know about it.\n. Would it be good enough to mention, that\n\"DSCP parameter sets only DSCP bits in TOS field of IP packets, not the whole field. If you take values from /usr/include/netinet/ip.h divide them by 4 (otherwise values would be incorrect, e.g. your CS1 class would turn into CS4). If you are take commonly used values from RFC, network vendors' documentation, Wikipedia or any other source, use them as they are.\"\n?\n. Here it is.\n. ",
    "dch": "libswift is now on github at https://github.com/libswift/libswift\n. ",
    "seanfisk": "OK, so it sounds like it would be pretty difficult and possibly in conflict with typical use of the tool. A couple other things I noticed that would make it difficult to implement:\n- Progress is printed to stdout by default. Obviously this wouldn't be possible if the file is being output \n  to stdout, so that would have to change (presumably to stderr or /dev/tty). That might be a breaking change for others' scripts if they expected progress to be output to stdout.\n- The -o option isn't considered a path, it's the basename for the downloaded file.\nI tried a named pipe (FIFO) approach, but the issue is that aria2 has no way of writing to a file descriptor that is known before the command is executed. Yes, you can make sure that foo.1 doesn't happen and predict the file name, but you can't create a file that aria2 then writes to. That makes it \"impossible\" to do the simultaneous download/untar with the current aria2 and standard tools (it's probably possible, but I'm no UNIX whiz).\nMaybe this isn't the right fit for this particular tool.\n. @AnselmD Possibly, but I think that if this feature was implemented, it should be implemented internally rather than externally.\n. ",
    "AnselmD": "I am interested in it. It is possible to determine outside from aria, how much from the \"head\" of the file is downloaded? Is is possible to to determine it with the controle file of aria2? \nhttp://aria2.sourceforge.net/manual/en/html/technical-notes.html#control-file-aria2-format\n. close please, this was an out of disk space.\n. Thank you very much, this helps. Is it allowed to take the same name for the --save-session and the  --input-file?\nI think yes, because the serialized session is stored  as a last action.\n. Maybe you do not have enough memory?\nSee: c++: internal compiler error: Killed (program cc1plus) \u00b7 Issue #224 \u00b7 Valloric/ycmd \u00b7 GitHub\nhttps://github.com/Valloric/ycmd/issues/224\nluascript.cpp.o Warning: end of file in string Ubuntu 14.04x64 - SOLVED \u00b7 Issue #1408 \u00b7 otland/forgottenserver \u00b7 GitHub\nhttps://github.com/otland/forgottenserver/issues/1408\n. ",
    "yarikoptic": "I would like to chime another 1c for the ability to specify output file name.  ATM, I see no ability to download from multiple URLs into a differently named file.  Usecase -- use by git-anex  see http://git-annex.branchable.com/todo/extensible_addurl/#comment-40a1d58630f56dd744d56dc56a68770e\n. On Fri, 05 Dec 2014, Tatsuhiro Tsujikawa wrote:\n\nTo specify different file name for each downloads, currently one has to\n   use -i file option.\n   http://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption-i\n   Inside it you can set options per download item:\n   http://aria2.sourceforge.net/manual/en/html/aria2c.html#input-file\n\nsorry if I am blind but I don't see an option for specifying the output\nfilename among those options ... could you please point me further or\njust provide an example?  Thanks in advance!\n. ",
    "osmoc": "That's the major showstopper for me as well. I think it would be rather easy to determine internally if we're currently downloading single file or multiple and enable \"--output2stdout\" (or whatever you might call it) only for single-file downloads. There're already options which work differently for single- and multi- file downloads (--download-result for example).\nI really hope one day aria2c will be able to catch up with wget's features.. ",
    "icodeforlove": "I needed this as well because we were pulling 500GB, up to 1TB snapshot files from cloud storage to a machine which did not have double the physical space. Resumability is not required as if the pipe breaks the whole operation is broken, this does not mean that the underlying process cant keep retrying on parts (and it does this).\nI threw together https://github.com/icodeforlove/npm_fatpipe.\nIt's only for piping output, so if you are looking for resumable features I'd stick to aria2. As for how the concurrency is handled It downloads multiple parts, and pipes to stdout in order. One of the big issues you will run into is handling back pressure, so having the ability to fine tune this is very useful.  \nMaybe something like this can be added into aria2c, if not you can use fatpipe for this edgecase.\n. ",
    "sergeevabc": "Meow.. +1. ",
    "jalr": "I want to regularyly restore compressed database backups. A drop-in replacement for the curl $dumpurl | lzop -dc | mysql would solve my problems I currently have with aborted downloads. . ",
    "lm8": "On Tue, February 11, 2014 8:08 am, Tatsuhiro Tsujikawa wrote:\n\nCheck out http://mingw-w64.sourceforge.net/ We abandoned mingw usage some\ntime ago and now use mingw-w64 to produce windows binary for each\nrelease, which does not require any changes to the code to build aria2.\n\nOur development environment requires use of the official and original\nmingw, not mingw64.  I guess we will need to look for another program that\ndoes the job of aria2.  Using mingw64 is not a viable solution for us.\n. Would it be too much trouble to specify the platforms you support at your\nweb site and especially mention that you only support mingw64 on Windows? \nIt would save developers a lot of time if they knew that up front.  Thank\nyou.\n. ",
    "jjgomera": "dont work, going download as get.php\nI finallly use a script to generate a file with link and name to launch aria2c with -i option\n. Of course you can, really its not fixed, but i found a workaround for me\n. Maybe that's solved in new versions, i forget say i use aria2c version 1.15.1, install from raspbian repositories in a RaspberryPi.\n. ",
    "manfire": "Is it possible for me to change distribution ... I need only the aria2c support torrent UDP do you have version work with udp tracker for torrent without C++11 ?\n. Thx for your help ... now the ./configure working well, but not the make / make install\nconfigure: summary of build options:\nversion:        0.1.1 shared 0:0:0\nHost type:      x86_64-unknown-linux-gnu\nInstall prefix: /usr/local\nC compiler:     gcc\nCFlags:         -g -O2\nLibrary types:  Shared=yes, Static=yes\nCUnit:          no\nBuild:          x86_64-unknown-linux-gnu\nHost:           x86_64-unknown-linux-gnu\nTarget:         x86_64-unknown-linux-gnu\nInstall prefix: /usr/local\nCC:             gcc\nCXX:            g++\nCPP:            gcc -E\nCXXFLAGS:       -g -O2\nCFLAGS:         -g -O2\nCPPFLAGS:       -I$(top_builddir)/deps/wslay/lib/includes -I$(top_srcdir)/deps/wslay/lib/includes -I/usr/kerberos/include     -I/usr/include/libxml2\nLDFLAGS:\nLIBS:           -lrt -L/usr/kerberos/lib64 -lssl -lcrypto -ldl -lz   -lsqlite3   -lxml2 -lz -lm -lz\nDEFS:           -DHAVE_CONFIG_H\nLibUV:          no\nSQLite3:        yes\nSSL Support:    yes\nAppleTLS:\nGnuTLS:         no\nOpenSSL:        yes\nCA Bundle:\nLibXML2:        yes\nLibExpat:\nLibCares:       no\nZlib:           yes\nEpoll:          yes\nBittorrent:     yes\nMetalink:       yes\nXML-RPC:        yes\nMessage Digest: yes\nWebSocket:      yes\nLibaria2:       no\nbash_completion dir: ${datarootdir}/doc/${PACKAGE_TARNAME}/bash_completion\nStatic build:\nSqlite3CookieParser.cc: In constructor 'aria2::Sqlite3CookieParser::Sqlite3CookieParser(const std::string&)':\nSqlite3CookieParser.cc:55: error: 'SQLITE_OPEN_READONLY' was not declared in this scope\nSqlite3CookieParser.cc:55: error: 'sqlite3_open_v2' was not declared in this scope\nmake[3]: * [Sqlite3CookieParser.lo] Error 1\nmake[3]: Leaving directory /aria2-1.17.1/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory/aria2-1.17.1/src'\nmake[1]: * [all-recursive] Error 1\nmake[1]: Leaving directory `/aria2-1.17.1'\nmake: *** [all] Error 2\n. issue fixed :+1:  thx for your help bro\n. ",
    "zabbal": "Yes, it includes both GPL v2 and v3 which also forces anyone who would like to contribute to license under GPLv2 as well. If this is undesirable (v3 and above only) than there's no chance to merge with upstream.\n. The first step would be to merge https://github.com/GutenYe/systemd-units/tree/master/aria2\nThe 2nd - to add native socket activation support (or, even better - dbus activation).\n. ",
    "jakoch": "Sure, it's reproducible.\nI've packaged the things to reproduce the issue.\nhttps://www.dropbox.com/s/2n5rtcx8mlxcvh8/aria2c-issue-209.zip\nThe archive contains: nant, aria2c, download-list.csv, build.xml, start-downloads.bat\nAlso my last run (0b-loop again) is documented in the file build.log.\nI have a feeling that it could be a clowny SSL handshake or something.\nIt often (not always) fails on \"memadmin\" and/or \"xhprof\".\n. Hey!\nI've added <arg value=\"--log=aria.log\"/> to generate the aria2c log file.\nThe following download contains build.log and aria.log:\nhttps://www.dropbox.com/s/e09vkpdlkqb7cug/aria2c-issue-209-logs.zip\nThank you for the advise to use one file for specifying the downloads. \nI will give \"Download files listed in a file concurrently\" a try: aria2c -ifiles.txt.\nIt's easier to generate a CSV file containing only one column, then to generate the Metalink XML.\n. Thank you! \nI solved it by removing --check-certificate=false.\n. ",
    "tabebqena": "Thanks.\n. > I have no idea about the authorization does facebook use.\n\nNo error on the terminal \n\nI have tried to use --header --http-user and http-passwd  : \naria2c  --header=\"username:******\" --header=\"password:******\" --header=\"submit:Masuk\"  --load-cookies=/home/dr/testcookies.db --save-cookies=/home/dr/testcookies.db --http-user=\"********\" --http-passwd=\"*******\" https://www.facebook.com/photo.php?fbid=793183740709672&set=oa.658544530849278&type=1&theater\nThis is the log file (some repeated lines have been deleted)\n\n2014-04-04 15:52:22.957189 [INFO] [main.cc:203] Logging started.\n2014-04-04 15:52:22.957212 [INFO] [SocketCore.cc:1301] Checking configured addresses\n2014-04-04 15:52:22.957465 [INFO] [SocketCore.cc:1350] Not considered: 127.0.0.1\n2014-04-04 15:52:22.957491 [INFO] [SocketCore.cc:1348] Found configured address: 10.98.151.55\n2014-04-04 15:52:22.957508 [INFO] [SocketCore.cc:1350] Not considered: ::1\n2014-04-04 15:52:22.957608 [INFO] [SocketCore.cc:1350] Not considered: fe80::26ec:99ff:fe1a:2d0b%eth2\n2014-04-04 15:52:22.957630 [INFO] [SocketCore.cc:1355] IPv4 configured=1, IPv6 configured=0\n2014-04-04 15:52:22.958040 [INFO] [HttpListenCommand.cc:110] CUID#7 - Using port 6800 for accepting new connections\n2014-04-04 15:52:22.958099 [NOTICE] [HttpListenCommand.cc:112] IPv4 RPC: listening on TCP port 6800\n2014-04-04 15:52:22.958400 [INFO] [MultiUrlRequestInfo.cc:172] Loaded cookies from '/home/dr/testcookies.db'.\n2014-04-04 15:52:23.285837 [INFO] [LibgnutlsTLSContext.cc:132] 164 certificate(s) were imported.\n2014-04-04 15:52:23.286159 [DEBUG] [RequestGroupMan.cc:521] 1 RequestGroup(s) added.\n2014-04-04 15:52:23.286227 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n2014-04-04 15:52:23.286323 [DEBUG] [FeedbackURISelector.cc:161] Selected from normCands\n2014-04-04 15:52:23.286372 [DEBUG] [FeedbackURISelector.cc:85] FeedbackURISelector selected https://www.facebook.com/photo.php?fbid=793183740709672\n2014-04-04 15:52:23.286465 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n2014-04-04 15:52:23.543616 [DEBUG] [EpollEventPoll.cc:261] Failed to delete socket event:Bad file descriptor\n2014-04-04 15:52:23.543697 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n[HttpInitiateConnectionCommand.cc:136] CUID#8 - Connecting to 31.13.64.145:443\n2014-04-04 15:52:25.239570 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 15:52:25.417928 [INFO] [HttpConnection.cc:107] CUID#8 - Requesting:\nGET /photo.php?fbid=793183740709672 HTTP/1.1\nUser-Agent: aria2/1.17.0\nAccept: /,application/metalink4+xml,application/metalink+xml\nHost: www.facebook.com\nAuthorization: Basic **\nCookie: datr=n5o-U83B2pOP7_xY-9mL_MuG;reg_fb_gate=https%3A%2F%2Fwww.facebook.com%2F%3Fsk%3Dwelcome;reg_fb_ref=https%3A%2F%2Fwww.facebook.com%2Fphoto.php%3Ffbid%3D793183740709672;\nusername:*\npassword:*\nsubmit:Masuk\n2014-04-04 15:52:25.700195 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\nCache-Control: private, no-cache, no-store, must-revalidate\nContent-Type: text/html; charset=utf-8\nDate: Fri, 04 Apr 2014 13:51:56 GMT\nExpires: Sat, 01 Jan 2000 00:00:00 GMT\nP3P: CP=\"Facebook does not have a P3P policy. Learn why here: http://fb.me/p3p\"\nPragma: no-cache\nSet-Cookie: reg_ext_ref=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT; path=/; domain=.facebook.com\nX-Content-Type-Options: nosniff\nX-Frame-Options: DENY\nX-XSS-Protection: 0\nX-FB-Debug: Xoo25XiJ7jovQ1wjKK8HqJj8Z1j5sh+q5rtySe1JDT8=\nTransfer-Encoding: chunked\nConnection: keep-alive\n2014-04-04 15:52:25.700564 [DEBUG] [RequestGroup.cc:1034] Finding PreDownloadHandler for path /home/dr/photo.php.\n2014-04-04 15:52:25.700578 [DEBUG] [RequestGroup.cc:1048] No PreDownloadHandler found.\nThe download for one segment completed successfully.\n2014-04-04 15:52:26.141432 [INFO] [DownloadEngine.cc:284] Pool socket for 31.13.64.145(443)\n2014-04-04 15:52:26.141527 [DEBUG] [RequestGroup.cc:973] GID#84501d70dc9db9ae - Request queue check\n2014-04-04 15:52:26.141615 [DEBUG] [ServerStat.cc:117] ServerStat:www.facebook.com: singleConnectionAvgSpeed_ old:0.00KB/s new:42.54KB/s last:42.54KB/s\n. Sorry, Some lines was deleted.\n\nthis is smaller command : \naria2c --http-auth-challenge=false --http-user=\"***********\" --http-passwd=\"*******\" https://www.facebook.com/photo.php?fbid=793183740709672&set=oa.658544530849278&type=1&theater\nthis is the complete log : \n\n2014-04-04 16:18:28.036303 [INFO] [main.cc:199] <<--- --- --- ---\n2014-04-04 16:18:28.036607 [INFO] [main.cc:200]   --- --- --- ---\n2014-04-04 16:18:28.036638 [INFO] [main.cc:201]   --- --- --- --->>\n2014-04-04 16:18:28.036658 [INFO] [main.cc:202] aria2 1.17.0 i686-pc-linux-gnu\n2014-04-04 16:18:28.036682 [INFO] [main.cc:203] Logging started.\n2014-04-04 16:18:28.036706 [INFO] [SocketCore.cc:1301] Checking configured addresses\n2014-04-04 16:18:28.036966 [INFO] [SocketCore.cc:1350] Not considered: 127.0.0.1\n2014-04-04 16:18:28.036992 [INFO] [SocketCore.cc:1348] Found configured address: 10.98.151.55\n2014-04-04 16:18:28.037010 [INFO] [SocketCore.cc:1350] Not considered: ::1\n2014-04-04 16:18:28.037112 [INFO] [SocketCore.cc:1350] Not considered: fe80::26ec:99ff:fe1a:2d0b%eth2\n2014-04-04 16:18:28.037133 [INFO] [SocketCore.cc:1355] IPv4 configured=1, IPv6 configured=0\n2014-04-04 16:18:28.037540 [INFO] [HttpListenCommand.cc:110] CUID#7 - Using port 6800 for accepting new connections\n2014-04-04 16:18:28.037600 [NOTICE] [HttpListenCommand.cc:112] IPv4 RPC: listening on TCP port 6800\n2014-04-04 16:18:28.366356 [INFO] [LibgnutlsTLSContext.cc:132] 164 certificate(s) were imported.\n2014-04-04 16:18:28.366646 [DEBUG] [RequestGroupMan.cc:521] 1 RequestGroup(s) added.\n2014-04-04 16:18:28.366701 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n2014-04-04 16:18:28.366772 [DEBUG] [FeedbackURISelector.cc:161] Selected from normCands\n2014-04-04 16:18:28.366803 [DEBUG] [FeedbackURISelector.cc:85] FeedbackURISelector selected https://www.facebook.com/photo.php?fbid=793183740709672\n2014-04-04 16:18:28.366866 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n2014-04-04 16:18:28.368705 [INFO] [AsyncNameResolverMan.cc:86] CUID#8 - Resolving hostname www.facebook.com\n2014-04-04 16:18:28.628559 [DEBUG] [EpollEventPoll.cc:261] Failed to delete socket event:Bad file descriptor\n2014-04-04 16:18:28.628643 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n2014-04-04 16:18:28.628700 [INFO] [AbstractCommand.cc:758] CUID#8 - Name resolution complete: www.facebook.com -> 31.13.64.145\n2014-04-04 16:18:28.628757 [INFO] [HttpInitiateConnectionCommand.cc:136] CUID#8 - Connecting to 31.13.64.145:443\n2014-04-04 16:18:28.868566 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:1, hup:0, err:0\n2014-04-04 16:18:28.868697 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:1, hup:0, err:0\n2014-04-04 16:18:29.870353 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:0, write:0, hup:0, err:0\n2014-04-04 16:18:30.038746 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.298474 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.480135 [INFO] [HttpConnection.cc:107] CUID#8 - Requesting:\nGET /photo.php?fbid=793183740709672 HTTP/1.1\nUser-Agent: aria2/1.17.0\nAccept: /,application/metalink4+xml,application/metalink+xml\nHost: www.facebook.com\nAuthorization: Basic **\n2014-04-04 16:18:30.819354 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.819634 [INFO] [HttpConnection.cc:147] CUID#8 - Response received:\nHTTP/1.1 200 OK\nCache-Control: private, no-cache, no-store, must-revalidate\nContent-Type: text/html; charset=utf-8\nDate: Fri, 04 Apr 2014 14:18:01 GMT\nExpires: Sat, 01 Jan 2000 00:00:00 GMT\nP3P: CP=\"Facebook does not have a P3P policy. Learn why here: http://fb.me/p3p\"\nPragma: no-cache\nSet-Cookie: reg_fb_gate=https%3A%2F%2Fwww.facebook.com%2Fphoto.php%3Ffbid%3D793183740709672; path=/; domain=.facebook.com\nSet-Cookie: reg_fb_ref=https%3A%2F%2Fwww.facebook.com%2Fphoto.php%3Ffbid%3D793183740709672; path=/; domain=.facebook.com\nSet-Cookie: reg_ext_ref=deleted; expires=Thu, 01-Jan-1970 00:00:01 GMT; path=/; domain=.facebook.com\nSet-Cookie: datr=Gb8-U_sXujIGGL-w5BV5I0Lb; expires=Sun, 03-Apr-2016 14:18:01 GMT; path=/; domain=.facebook.com; httponly\nX-Content-Type-Options: nosniff\nX-Frame-Options: DENY\nX-XSS-Protection: 0\nX-FB-Debug: puhG6rPU8lXQZLjjBC+LW+vsSohd3MA8WlzjQ76kMI4=\nTransfer-Encoding: chunked\nConnection: keep-alive\n2014-04-04 16:18:30.819768 [DEBUG] [RequestGroup.cc:1034] Finding PreDownloadHandler for path /home/dr/photo.php.\n2014-04-04 16:18:30.819783 [DEBUG] [RequestGroup.cc:1048] No PreDownloadHandler found.\n2014-04-04 16:18:30.819919 [NOTICE] [RequestGroup.cc:776] File already exists. Renamed to /home/dr/photo.php.8.\n2014-04-04 16:18:30.820071 [DEBUG] [SegmentMan.cc:139] Attach segment#0 to CUID#8.\n2014-04-04 16:18:30.820094 [DEBUG] [SegmentMan.cc:164] index=0, length=0, segmentLength=0, writtenLength=0\n2014-04-04 16:18:30.820175 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.820258 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.830488 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.830808 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.831168 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.831423 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.838596 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.838776 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.858823 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.859106 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.859302 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.859399 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.868529 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.868736 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.968840 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.969104 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.969319 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.978807 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.979061 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.979383 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.989038 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.989448 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.989666 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.989957 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.990208 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.990371 [DEBUG] [AbstractCommand.cc:149] CUID#8 - socket: read:1, write:0, hup:0, err:0\n2014-04-04 16:18:30.990494 [INFO] [DownloadCommand.cc:244] CUID#8 - The download for one segment completed successfully.\n2014-04-04 16:18:30.990585 [INFO] [DownloadEngine.cc:284] Pool socket for 31.13.64.145(443)\n2014-04-04 16:18:30.990681 [DEBUG] [RequestGroup.cc:973] GID#5abc1685fe48d88f - Request queue check\n2014-04-04 16:18:30.990771 [DEBUG] [ServerStat.cc:117] ServerStat:www.facebook.com: singleConnectionAvgSpeed_ old:0.00KB/s new:109.47KB/s last:109.47KB/s\n2014-04-04 16:18:30.990841 [NOTICE] [RequestGroup.cc:1202] Download complete: /home/dr/photo.php.8\n2014-04-04 16:18:30.990960 [DEBUG] [RequestGroup.cc:1056] Finding PostDownloadHandler for path /home/dr/photo.php.8.\n2014-04-04 16:18:30.991020 [DEBUG] [RequestGroup.cc:1069] No PostDownloadHandler found.\n2014-04-04 16:18:30.991049 [DEBUG] [RequestGroup.cc:1164] GID#5abc1685fe48d88f - Creating DownloadResult.\n2014-04-04 16:18:30.991212 [DEBUG] [RequestGroupMan.cc:420] 1 RequestGroup(s) deleted.\n2014-04-04 16:18:46.561570 [NOTICE] [DownloadEngine.cc:232] \u0628\u062f\u0623\u062a \u062e\u0637\u0648\u0627\u062a \u0627\u0644\u0625\u063a\u0644\u0627\u0642 \u0627\u0644\u0625\u0636\u0637\u0631\u0627\u0631\u064a / \u0627\u0644\u0625\u062c\u0628\u0627\u0631\u064a ....\n2014-04-04 16:18:46.562375 [NOTICE] [ServerStatMan.cc:108] ServerStat file /home/dr/.aria2/serverstat.ssof saved successfully.\n2014-04-04 16:18:46.562798 [NOTICE] [MultiUrlRequestInfo.cc:289] Serialized session to '/home/dr/.aria2/session.ini' successfully.\n. the downloaded file is the php file present at this url : \nhttps://www.facebook.com/login.php?m=m\n\nthis is not the requested : https://www.facebook.com/photo.php?fbid=793183740709672\nthis means that authenication had failed.\n\n. I have no idea about that but wikipedia says \"Facebook use2 factor authenication`\".\n. ",
    "A-Shahbazi": "@tatsuhiro-t \nWould you mind explain exactly how to use --header option to load multiple cookie files?\n. ",
    "kuerzn": "No options.\nSorry, The file is gone. And I also cannot produce a stack trace.\nThe only thing I know, is that it was a file where aria cold not determine\nthe filesize while downloading. Smaller files from the server worked.\nOn Fri, Apr 4, 2014 at 3:35 PM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\nAlso Stack trace would be very helpful.\n\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/215#issuecomment-39565115\n.\n. \n",
    "lizhengyong": "version 1.18.5\nLinux NDC-HN-F02 2.6.18-164.el5 #1 SMP Thu Sep 3 03:28:30 EDT 2009 x86_64 x86_64 x86_64 GNU/Linux\nThe stack trace: \n0  0x0000003bec430265 in raise () from /lib64/libc.so.6\n1  0x0000003bec431d10 in abort () from /lib64/libc.so.6\n2  0x0000003bec4296e6 in __assert_fail () from /lib64/libc.so.6\n3  0x0000000000506d17 in aria2::FileEntry::gtoloff (this=0x4d8e520, goff=-2147482848) at FileEntry.cc:114\n4  0x00000000006eaeda in aria2::DownloadCommand::executeInternal (this=0x50a7870) at DownloadCommand.cc:212\n5  0x000000000061dc10 in aria2::AbstractCommand::execute (this=0x50a7870) at AbstractCommand.cc:273\n6  0x00000000004877ab in aria2::(anonymous namespace)::executeCommand (commands=std::deque with 361 elements = {...},\nstatusFilter=aria2::Command::STATUS_ACTIVE) at DownloadEngine.cc:133\n\n7  0x0000000000487941 in aria2::DownloadEngine::run (this=0x4c9e060, oneshot=false) at DownloadEngine.cc:171\n8  0x000000000047226d in aria2::run (session=0x4c917f0, mode=aria2::RUN_DEFAULT) at aria2api.cc:158\n9  0x000000000043eca4 in MyAria2::run_by_default (this=0x4c7b300) at ../public/aria2/my_aria2.h:235\n10 0x000000000043d688 in run_downloading (arg=0x0) at main.cpp:24\n11 0x0000003bed0064a7 in start_thread () from /lib64/libpthread.so.0\n12 0x0000003bec4d3c2d in clone () from /lib64/libc.so.6\n. ",
    "elnoxgdl": "I'm getting the same problem, but mine is 1.18.5 and gcc 4.7.2, let see if they find out the problem.\n. ",
    "bacalit": "Yes I built 1.18.5 with gcc 4.7.2 and 4.8.2 with same problem\n. Yes, your output displayed correctly and http://aria2.sourceforge.net/manual/ru/html/aria2c.html looks very good.\nBut here is solution for my situation, need to put this line as first line of Russian man file:\n.\\\" -*- mode: troff; coding: utf8 -*-\n. It's problem for all users of ALT Linux (Main Russian distribution), so I corrected aria2 rpm package for it.\nAny other Russian and/or UTF8 man pages from other packages displayed  correctly. Maybe It's specific for ALT Linux only.\n. Thank you!\n. ",
    "juanfra684": "The file is only installed when docutils is also installed. So, the OpenBSD port generates different lists of \"installed files\" if docutils is installed or not. It's not a big problem but is a little annoying for some porters.\nThe \"configure option\" is just an idea. I just want a proper fix :)\n. Thanks!. I applied a similar patch to Makefile.in in the OpenBSD port.\n. ",
    "acdha": "Ah, the documentation doesn't make that clear but it does appear to work. It doesn't help if the remote server doesn't send a Last-Modified header, of course, but in my case that's not an issue.\n. ",
    "ghost": "I know its for each download event, but on-download-start event was ignored after on-download-complete being executed in a download queue which is confused me.\n. Oh, something forgot to mention, my issue occured when running aria2 in RPC mode.\nI can confirm my scripts run fine which is only turn on the LED.\n. My bad, after some testing I found the issue was unrelated aria2 itself, sorry for bothering.\n. sorry, I explained it wrongly. It is my code that blocks on aria2.tellActive untill it can get file info from aria. If it could only answer ie. 'come back later dude, now Im busy hashing' all would be great. Would it be possible to do so?\n. It looks like it does block to me. I see in my debug log, json I've send, but don't see any response. Those files were loaded from session file if it helps.\n. It appears it was a mistake on my part actually, sorry for the noise. I just figured out where I made a bug.\n. i want to use GDB debugger. is there a fix for Sony Xperia Z3 Comapct?\n. As the macro 'AM_PATH_CPPUNIT' and 'AM_PATH_LIBGCRYPT' not  found in library. So I install cppunit and libgcrypt.\nThat's OK.\n. I will try it, thanks.\nOn Fri, Mar 25, 2016 at 11:35 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\n2a8522f\nhttps://github.com/tatsuhiro-t/aria2/commit/2a8522f6a5d14fa3a1493abc1aa80160feab4c99\nmay fix this issue. Could you try that?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/606#issuecomment-201334406\n. The input file option seems to work. Thanks!. I use aria2 by commond line on Juicessh. Thank you very much!. [--remove-control-file=true] and [--allow-overwrite=true] might be one of possible solutions but it only applies to the archives(*.rar, 7z) split to volume with same file size. Then copy and paste the file one by one. . \n",
    "Dialga": "in addition to this it reads the whole thinking it is one link, replacing space with %20\n. Oh right, my mistake.\n. ",
    "alkumaish": "I run slackware 14.0.  The compile used was gcc/g++ 4.7.1\n. ",
    "Haocen": "Can you put build status icon in readme?\n. Run into similar problem since version 1.26.1:\n1.25.0 is fine.\n```\n[/Aria2] # ./bin/aria2c -v\naria2 version 1.30.0\nCopyright (C) 2006, 2016 Tatsuhiro Tsujikawa\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n Configuration \nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 expat/2.1.0 sqlite3/3.11.0 OpenSSL/1.0.2g c-ares/1.10.0 libssh2/1.5.0\nCompiler: gcc 5.4.0 20160609\n  built by   x86_64-pc-linux-gnu\n  on         Jan  5 2017 23:33:21\nSystem: Linux 3.12.6 #1 SMP Wed Dec 14 04:23:22 CST 2016 x86_64\nReport bugs to https://github.com/aria2/aria2/issues\nVisit https://aria2.github.io/\n<-conf-path=./Aria2/a.conf \naria2c: SimpleRandomizer.cc:117: void aria2::SimpleRandomizer::getRandomBytes(unsigned char*, size_t): Assertion `rv >= 0 && (size_t)rv == len' failed.\nAborted\n```. Thank you for confirming that.\n. Thank you, I tried --without-libcares but some redefinition error turned up instead, I'll keep looking into it.\n. For anybody interested in this topic please see:\n\nhttps://github.com/lancethepants/aria2-arm-musl-static\n. Try compile without libxml2 and libssh2, these two gave me the most headaches.\n. \n",
    "sdysj": "I have just about to post the similar issue. I though that the command \"save-session-interval\" is a little bit overkill method. When aria2 run as daemon on NAS which is often long time running, the command \"save-session-interval\" will interrupt the hard disk sleeping mechanism.\nMy willing of the \"save-session\" function is when the task added then save session first, when some task error or stopped, finished also save the session.\n. Well, nice tweak. Thanks for your work.\n. Compile error on OpenWRT.\nLibsslTLSContext.cc: In constructor 'aria2::OpenSSLTLSContext::OpenSSLTLSContext(aria2::TLSSessionSide)':\nLibsslTLSContext.cc:122:60: error: 'EC_KEY_new_by_curve_name' was not declared in this scope\n   auto ecdh = EC_KEY_new_by_curve_name(NID_X9_62_prime256v1);\n                                                            ^\nLibsslTLSContext.cc:128:21: error: 'EC_KEY_free' was not declared in this scope\n     EC_KEY_free(ecdh);\n                     ^\n. ",
    "tleepa": "@tatsuhiro-t Thank you for explanation :)\nI forgot to mention, that even if you make some changes to somehow mitigate this issue, I would not benefit from it anyway...\nThe problem is, that optware repo I use on my NAS holds Aria2 version 1.14.2 and I do not know if this is going to change...\nSo, I though I would be just stopping Aria2 daemon when downloads are finished and start it up again if I want to download any new torrent. Good, it can be done via quick SSH exec methods...\n. ",
    "ziahamza": "Its a HTTP download added through a single URI. I paused the download through WebUI while it was in progress, changed the dir option of the download. and when it resumed aria2 stopped with an assertion failure. \n. Yep, this was an issue. I have updated the master so that it should only overrides the settings which the user explicitly changes from the UI. \n. ",
    "kazemnejad": "aria2c executable is invoked by this code\npublic void launch() {\n        corePath = \"/data/data/moduleName/files/aria2c\";\n        runCommand = new String[]{corePath, \"--enable-rpc\", \"-D\",\"-d \\\"/storage/sdcard0/Download\\\"\"};\n        try {\n            Process coreProcess = Runtime.getRuntime().exec(runCommand);\n            coreProcess.waitFor();\n        } catch (IOException e) {\n            e.printStackTrace();\n            //TODO\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n            //TODO\n        }\n    }\nThis isn't caused by fancy characters (because when i test it with superuser permission, the error will disappear ). uses permission:\n<uses-permission android:name=\"android.permission.INTERNET\" />\n<uses-permission android:name=\"android.permission.WRITE_EXTERNAL_STORAGE\" />\nBut why does aria2 want to create directory? Could i create that directory by Android/Java methods before aria2's launch?\n. Do you know why does it need create directory there? (in pc doesn't need for a simple download), May be it is related to config file or something like that?\n. ",
    "fedya": "I got same result with CLANG 3.4\nno matching function for call to 'uv_timer_start'\nFull build log\nhttp://file-store.rosalinux.ru/api/v1/file_stores/86c386a5929693c11190ae5d45a6d9c5359b6f36.log?show=true\n. ",
    "moonman": "This fix no longer works on openwrt. libuv version was updated to 1.4.2 https://github.com/openwrt/packages/blob/master/libs/libuv/Makefile \nminor is 4 which is less than 10 so code falls back to old behavior.\n. @tatsuhiro-t thank you, this worked. I always thought it was a required library so I never tried to disable it. @nmaier has a point.\n. ",
    "OEvgeny": "Yes, it was. Thanks!\n. I'm using NTFS. Depending on wikipedia and my experiments it allows to use files larger than 4gb.\nPiece of blkid command output on my android device:\n/dev/block/sda1: UUID=\"E8C40AC0C40A90CC\" LABEL=\"storage\" TYPE=\"ntfs\"\n. I'm using external hard drive with my tvbox. But it's an firmware issue. \nI test it with dd command and it cuts file too. \nI'm sorry, aria didn't have this issue.\n. I think in this case id must contain NULL value because of www.jsonrpc.org/specification#request_object\nRequests or responses without id can be ignored depending on protocol implementation.\n. Ok, thanks. Btw it looks like rpc request :)\n. ",
    "joelmo": "Thank you :) this works now.\n. @tatsuhiro-t I'm trying to set up a node to seed a tracker-less torrent so I use local peer discovery (LPD) with --bt-enable-lpd=true. I should get ok throughput but the seeder uploads about 1MB every minute or so. When I start a lecher node it discovers the seed some second later and starts downloading for some second but then just stops. Do you know where the problem could be?\n. I didn't set that setting but the seeder doesn't exit. I tested that setting too but it didn't work, it appeared the checksums in the torrent didn't match the file I was trying to seed, I made a new torrent and that worked.\n. ",
    "ruizzz": "I don't think Android support R/W NTFS. You might want to check again. Usually the file system on SD cards or flash drives of mobile devices are FAT, which has file size limit of exactly 4GB.\n. ",
    "Noitidart": "Aw dang\n. Thanks so much @tatsuhiro-t for the idea! :)\n. ",
    "orivej": "This also enables parallel download from multiple torrent web seeds (with --split > 1), which is not supported otherwise.\n. ",
    "kwkam": "Maybe something like this?\n``` diff\ndiff --git a/src/AbstractCommand.cc b/src/AbstractCommand.cc\nindex c2ead09..773f14d 100644\n--- a/src/AbstractCommand.cc\n+++ b/src/AbstractCommand.cc\n@@ -758,6 +758,7 @@ std::string AbstractCommand::resolveHostname(std::vector& addrs,\ne_->findAllCachedIPAddresses(std::back_inserter(addrs), hostname, port);\n   if (!addrs.empty()) {\n+    e_->shiftCachedIPAddresses(hostname, port);\n     auto ipaddr = addrs.front();\n     A2_LOG_INFO(fmt(MSG_DNS_CACHE_HIT, getCuid(), hostname.c_str(),\n                     strjoin(std::begin(addrs), std::end(addrs), \", \").c_str()));\ndiff --git a/src/DNSCache.h b/src/DNSCache.h\nindex 18eb393..e43e163 100644\n--- a/src/DNSCache.h\n+++ b/src/DNSCache.h\n@@ -90,6 +90,13 @@ private:\n       }\n     }\n\nvoid shift()\n{\nstd::rotate(addrEntries_.begin(),\naddrEntries_.begin() + 1,\naddrEntries_.end());\n\n}\n+\n     void markBad(const std::string& addr);\nbool operator<(const CacheEntry& e) const;\n@@ -114,13 +121,22 @@ public:\n   void findAll(OutputIterator out, const std::string& hostname,\n            uint16_t port) const\n   {\n-    std::shared_ptr target(new CacheEntry(hostname, port));\n+    auto target = std::make_shared(hostname, port);\n auto i = entries_.find(target);\n if (i != entries_.end()) {\n   (*i)->getAllGoodAddrs(out);\n }\n   }\n\n\nvoid shift(const std::string& hostname, uint16_t port) const\n\n{\nauto target = std::make_shared(hostname, port);\nauto i = entries_.find(target);\nif (i != entries_.end()) {\n(*i)->shift();\n}\n}\n+\n   void put(const std::string& hostname, const std::string& ipaddr,\n            uint16_t port);\n\ndiff --git a/src/DownloadEngine.h b/src/DownloadEngine.h\nindex b6228a7..2db4182 100644\n--- a/src/DownloadEngine.h\n+++ b/src/DownloadEngine.h\n@@ -310,6 +310,11 @@ public:\n     dnsCache_->findAll(out, hostname, port);\n   }\n\nvoid shiftCachedIPAddresses(const std::string& hostname, uint16_t port) const\n{\ndnsCache_->shift(hostname, port);\n}\n+\n   void cacheIPAddress(const std::string& hostname, const std::string& ipaddr,\n                       uint16_t port);\n.\n   for (const int a : args) {\n     if (a == 0) {\n       fg_ = deffg_;\n       bg_ = defbg_;\n       bold_ = underline_ = reverse_ = false;\n     }\n     else if (30 <= a && a <= 37) {\n       fg_ = a - 30;\n     }\n     ...\n   }\n   WORD attribute = 0;\n   if (reverse_) {\n     attribute = kForeground[bg_] | kBackground[fg_];\n   }\n   else {\n     attribute = kForeground[fg_] | kBackground[bg_];\n   }\n```\n\nThe problem is, deffg_, fg_ and defbg_, bg_ are being used as reference to the colour\n- colour code differences\nIf default font colour were red (\\033[31m in ANSI):\nFOREGROUND_RED = 0x04 so that deffg_ = 4, but kForeground[4] is FOREGROUND_BLUE\n- out of bounds read\ndeffg_ and defbg_ contains the XXXXGROUND_INTENSITY bit, which means their value could be 0x00~0x0F, but the size of kForeground and kBackground is 0x07\n. This might be better.\n. Yes cpu usage is still high even efds is a different set.. I can confirm that https://github.com/aria2/aria2/pull/1060#issuecomment-341968755 still causes high cpu.\nThis issue occurs when using BitTorrent.. Yes https://github.com/aria2/aria2/pull/1060#issuecomment-341981822 fixed the issue.\nThank you very much.. This also seems to work. Would it be better than memcpy?\n```diff\ndiff --git a/src/SelectEventPoll.cc b/src/SelectEventPoll.cc\nindex 38f9de4b..f661865a 100644\n--- a/src/SelectEventPoll.cc\n+++ b/src/SelectEventPoll.cc\n@@ -169,15 +169,10 @@ SelectEventPoll::~SelectEventPoll()\nvoid SelectEventPoll::poll(const struct timeval& tv)\n {\n-  fd_set rfds;\n-  fd_set wfds;\n-\n-  memcpy(&rfds, &rfdset_, sizeof(fd_set));\n-  memcpy(&wfds, &wfdset_, sizeof(fd_set));\n-\n+  fd_set rfds = rfdset_;\n+  fd_set wfds = wfdset_;\n #ifdef MINGW32\n-  fd_set efds;\n-  memcpy(&efds, &wfdset_, sizeof(fd_set));\n+  fd_set efds = wfdset_;\n #endif // MINGW32\n#ifdef ENABLE_ASYNC_DNS\n. How about this?diff\ndiff --git a/configure.ac b/configure.ac\nindex b638a058..730f84fb 100644\n--- a/configure.ac\n+++ b/configure.ac\n@@ -2,7 +2,7 @@\n # Process this file with autoconf to produce a configure script.\n #\n AC_PREREQ([2.67])\n-AC_INIT([aria2],[1.33.0],[https://github.com/aria2/aria2/issues],[aria2],[https://aria2.github.io/])\n+AC_INIT([aria2],[m4_esyscmd_s([git describe])],[https://github.com/aria2/aria2/issues],[aria2],[https://aria2.github.io/])\nAC_CANONICAL_HOST\n AC_CANONICAL_TARGET\nThe result will be:\naria2 version release-1.33.0-23-gc882ae3d\nCopyright (C) 2006, 2017 Tatsuhiro Tsujikawa\n...\nPerhaps remove the prefix `release-` from the tag?. Are you using 1.33.1?\nPlease try to build from latest source. I believe it is fixed by #1058\n. A simple workaround for this:diff\ndiff --git a/src/util.cc b/src/util.cc\nindex be73a6e4..ffa4236b 100644\n--- a/src/util.cc\n+++ b/src/util.cc\n@@ -1555,6 +1555,12 @@ ssize_t parse_content_disposition(char* dest, size_t destlen,\n   case CD_AFTER_VALUE:\n   case CD_TOKEN:\n     return destlen - dlen;\n+  case CD_BEFORE_DISPOSITION_PARM_NAME:\n+    if ((flags & CD_FILENAME_FOUND) == 0 &&\n+        (flags & CD_EXT_FILENAME_FOUND) == 0) {\n+      return -1;\n+    }\n+    return destlen - dlen;\n   case CD_VALUE_CHARS:\n     if (charset == CD_ENC_UTF8 && dfa_state != UTF8_ACCEPT) {\n       return -1;\n``. https://aria2.github.io/manual/en/html/aria2c.html#cmdoption-o\nIn your case,--dir=\"/Users/balupton\" --out=\".vimrc\"`. ",
    "jsalatiel": "@kwkam , thanks ! it worked great!. ",
    "kuh3h3": "thanks for comment. clean new build( rm -rf aria2 git directory ) resolved my error. now compile ok. but this error seems to occur repeatedly. make system is not for clean new build .\n. ",
    "cadesalaberry": "Would love it to happen too !\n. ",
    "amirotin": "Any news about uTP implemetation? It will be very nice feature.\n. Well.. the problem is with open(entry['location']).read(). Python reads only part of file :(\n. Please update documentation. In python example put xmlrpclib.Binary(open('file.torrent', mode='rb').read())\n. With additional log i got this\n2015-11-18 19:16:56.555068 [WARN] [AbstractDiskWriter.cc:470] Making file sparse failed or pending: Incorrect function.\n. I think the problem is with the control file. When i pause finished torrent - control file still exists. And probably when symlink is created aria2 decided that torrent is not compled and is trying to allocate files again.\nI've read documentation, but i don't understand when control file is deleted?\n. I've tested multiple combination of options. In all cases when torrent is multi-file, after i unpause torrent aria2 is trying to allocate files.\nSingle-file torrent has no problems with allocate, it just starts seeding after unpause.\nThe only way i got it working with multi-file - set file-allocation=none.\nThis error Making file sparse failed or pending: Incorrect function. occurs only when symlink is on another drive. When it is symlinking on the same drive - it stucks on FileAlloc 100%.\n. Only files inside folder and any subfolder. So folder structure stays as is.\n. Yes :) But in most cases I had 3-5 files in the torrent. \n. I've build aria2 with your fix. After testing all day i got following:\n1. The problem is not with aria2, it with pooling software \"DriveBender\". When i symlink to another drive (not in pool) - it's ok.\n2. Your fix is working great - no problem with symlink to same drive\n3. When i enable check-integrity - aria2 shows \"checksum\" in console. And it's ok. Right after checksum it writes error. So the file is determined normal\n4. You added log in MultiFileAllocationIterator.cc. It shows \"current size=0\". I think file size detection is wrong :(\nHere is logs from single-file torrent\n2015-11-22 22:51:15.720686 [NOTICE] [CheckIntegrityCommand.cc:77] Verification finished successfully. file=T:/Finished/\u041f\u0435\u0440\u0435\u0432\u043e\u0437\u0447\u0438\u043a \u041d\u0430\u0441\u043b\u0435\u0434\u0438\u0435..2015.D.HDRip.745MB..avi\n2015-11-22 22:51:15.721686 [INFO] [FileAllocationDispatcherCommand.cc:57] Dispatching FileAllocationCommand for CUID#20.\n2015-11-22 22:51:15.721686 [WARN] [AbstractDiskWriter.cc:476] Making file sparse failed or pending: Incorrect function.\n2015-11-22 22:51:15.722686 [DEBUG] [FileAllocationCommand.cc:78] 0 seconds to allocate 780572672 byte(s)\nlogs from multi-file torrent\n2015-11-22 23:02:26.677551 [NOTICE] [CheckIntegrityCommand.cc:77] Verification finished successfully. file=T:/Finished/Ash vs Evil Dead (Season 01) Goblin\n2015-11-22 23:02:26.677551 [INFO] [FileAllocationDispatcherCommand.cc:57] Dispatching FileAllocationCommand for CUID#19.\n2015-11-22 23:02:26.677551 [INFO] [MultiFileAllocationIterator.cc:99] Allocating file T:/Finished/Ash vs Evil Dead (Season 01) Goblin/Ash.vs.Evil.Dead.S01E01.XviD.Goblin.[qqss44].avi: target size=524339200, current size=0\n2015-11-22 23:02:26.677551 [WARN] [AbstractDiskWriter.cc:476] Making file sparse failed or pending: Incorrect function.\n2015-11-22 23:02:26.677551 [INFO] [MultiFileAllocationIterator.cc:99] Allocating file T:/Finished/Ash vs Evil Dead (Season 01) Goblin/Ash.vs.Evil.Dead.S01E02.XviD.Goblin.[qqss44].avi: target size=367988736, current size=0\n2015-11-22 23:02:26.677551 [WARN] [AbstractDiskWriter.cc:476] Making file sparse failed or pending: Incorrect function.\n2015-11-22 23:02:26.677551 [INFO] [MultiFileAllocationIterator.cc:99] Allocating file T:/Finished/Ash vs Evil Dead (Season 01) Goblin/Ash.vs.Evil.Dead.S01E03.XviD.Goblin.[qqss44].avi: target size=349990912, current size=0\n2015-11-22 23:02:26.677551 [WARN] [AbstractDiskWriter.cc:476] Making file sparse failed or pending: Incorrect function.\n2015-11-22 23:02:26.677551 [INFO] [MultiFileAllocationIterator.cc:99] Allocating file T:/Finished/Ash vs Evil Dead (Season 01) Goblin/Ash.vs.Evil.Dead.S01E04.XviD.Goblin.[qqss44].avi: target size=349949952, current size=0\n2015-11-22 23:02:26.677551 [WARN] [AbstractDiskWriter.cc:476] Making file sparse failed or pending: Incorrect function.\n2015-11-22 23:02:26.677551 [DEBUG] [FileAllocationCommand.cc:78] 0 seconds to allocate 1592268800 byte(s)\nBut finaly torrents starts seeding. So the only problem is - why checksum is OK, but aria starts file allocation?\n. Great! It's working! No errors and torrents are seeding! Many thx!\n. Maybe it is possible to add some additional argument to on-bt-download-complete which will determine is it integrity check or realy download complete?\nusually on complete event is used to do something with files (move, rename and etc). And if on each start/stop it will be fired - this can damage data.\n. Yeap, option will be better solution!\n. It is sad to hear, hopefully in the near future you will have time to make it.\n. But be aware that seeding item is still recognized as active download in RPC method. it means if i add torrent via rpc - it will not start if queue is full?\nOr that seeding torrent will be displayed as active download?\nAnd some offtop - it is possible to place control and torrent files in separate folder.\n. If it is olny status, than something in my config is wrong.\n```\nrpc\nrpc-secret=zzz\nenable-rpc=true\nrpc-listen-all=true\nrpc-allow-origin-all=true\nrpc-listen-port=6800\nrpc-save-upload-metadata=true\nsession\ncontinue=true\ninput-file=D:\\Soft\\aria2\\main_list.gz\nsave-session=D:\\Soft\\aria2\\main_list.gz\nsave-session-interval=60\ndeferred-input=true\ngeneral\ndir=T:\\Finished\nlog=D:\\Soft\\aria2\\aria.log\nlog-level=warn\ndisk-cache=256M\nenable-mmap=false\nfile-allocation=trunc\ndisable-ipv6=true\npeer-id-prefix=-UT2210-\nuser-agent=uTorrent/2210(25130)\nconnection\nmax-connection-per-server=5\nmax-concurrent-downloads=5\nmax-download-result=10000\nmin-split-size=1M\nsplit=5\nmax-overall-download-limit=8M\nmax-overall-upload-limit=8M\ncheck-certificate=false\ntorrents\nbt-enable-lpd=true\nbt-max-peers=130\nbt-max-open-files=100\nbt-request-peer-speed-limit=100K\nenable-peer-exchange=true\nenable-dht=true\nenable-dht6=false\ndht-file-path=D:\\Soft\\aria2\\dht.dat\nfollow-torrent=true\nfollow-metalink=true\nforce-save=true\nbt-detach-seed-only=true\nbt-seed-unverified=true\nbt-save-metadata=true\nbt-hash-check-seed=true\nbt-stop-timeout=900\ncheck-integrity=true\nseed-ratio=0.0\nbt-exclude-tracker=http://retracker.local/announce\non-bt-download-complete=D:\\Soft\\aria2\\oncomplete.bat\nconsole\nenable-color=false\nshow-console-readout=false\nsummary-interval=0\n```\nWith this configuration i still get new torrents in status \"waiting\". Maybe i miss something?\n. Is there any information why torrent is in waiting status if i'll enable debug logs?\n. Update:\nEven after torrent is completed it moves in waiting status.\n. Still getting problem with waiting status. a little bit annoying to restart aria2 to start new downloads that are in waitnig status.\nStill can not determine what is wrong with the settings.\n. OK. I finally found what happens!\nMy config is in above comment.\nSteps to reproduce:\n1. Add torrents more than max-concurrent-downloads. To speed up testing i set max-concurrent-downloads=2. I use 10 torrent files. It does not matter what size, type (single, multi).\n2. When first 2 torrents are downloaded aria2 start next 2.\n3. While downloading next torrents - pause, unpause first 2 torrents (or what count you set in max-concurrent-downloads). They got waiting status.\n4. After aria2 downloads current torrents it does not start next uncompleted torrents. It starts previously unpaused torrents. And thats all. No new torrents are downloaded until i restart.\nIt other words: if we have some unpused torrents - they use download slots (and does not free them) instead of uncompleted torrents.\nI got this situation becouse my on-bt-download-complete command is moving files after download. And to move them it needs to pause/unpause torrent.\n. Torrents you have paused was active and completed? Or downloading?\nIn my case i paused active and completed torrents.\n2 \u0434\u0435\u043a. 2015 \u0433. 4:44 PM \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \"Tatsuhiro Tsujikawa\" \nnotifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nThank you.\nI followed your steps. Only difference was I used 5 torrents.\n1. add 5 torrents using -i list option, and -j2 and\n   --bt-detach-seed-only\n2. pause 2 active torrents, and then unpause them\n3. let downloads go.\nFirst 2 torrents were done, then unpaused 2 torrents were started, which\nis expected behaviour.\nThen last 1 torrent was started.\nAll downloads went fine; Because I used --bt-detach-seed-only, all 5\ndownloads got SEED state.\nStill could not reproduce this issue.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/490#issuecomment-161293643.\n. What do you mean under \"active\"? The problem accurs only if you paused\ncompleted torrents, that are seeding only.\n2 \u0434\u0435\u043a. 2015 \u0433. 4:58 PM \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \"Tatsuhiro Tsujikawa\" \nnotifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\nI paused 2 active torrents, which were started at startup.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/490#issuecomment-161301396.\n. Yeap. Torrents was in seeding state. \n. In my case torrents are paused by oncomplete command. In most cases they are seeding in moment of pause. \n. Hooray! :) \n. Tested! Thx!\n. You must set force-save=true\n\nSave download with --save-session option even if the download is completed or removed. This option also saves control file in that situations. This may be useful to save BitTorrent seeding which is recognized as completed state.\n. Is check-integrity eneabled? If yes - it will recheck torrents.\n. realtime-chunk-checksum - checksum of file part while downloading\ncheck-integrity - checks entire file/torrent after download\n. Couple updates:\n1. sesson file is gzip\n2. file was not corrupted.\n3. how does deferred-input work? I mean time intervals to load urls.\n. Ok. I get this error again. What i've done:\n1. 32 torrent was active. Only seeding, no downloads\n2. I've added 5 torrent files to download\n3. 3 was active, 2 waiting\n4. i added another 5 torrents, they also become status \"waiting\"\n5. 3 active download finished. Waiting torrents hasn't changet their status.\n6. I've restarted aria2. Instead of 7 waiting torrents i get only 5, but active\n7. I get error 2015-11-25 10:53:53.928158 [ERROR] [SaveSessionCommand.cc:84] Failed to serialize session to 'D:\\Soft\\aria2\\main_list.gz'.\n8. In D:\\Soft\\aria2\\main_list.gz i see all torrents, including 2 torrents i've lost in step 6.\n9. There is no more log entries about session serialize. And aria2 created file main_list.gz__temp\n. Both files are correct. I can open them and read data. main_list.gz is locked, main_list.gz__temp - not.\nI think that deferred input did not finish adding torrents and that is why file is locked and not readable.\nI'll try to reproduce this with debug logs, maybe it will be more informative.\n. Well.. Clean virtual system, windows 7. aria2 build from source. Reproduce steps:\n1. Start aria2. max-concurrent-downloads=5, deferred-input=true\n2. Add 5 torrents. All are active\n3. Add 2 torrents. Status waiting\n4. Restart aria2. Only 5 torrents are in list\n5. Add 2 torrents again\n6. Get error 2015-11-25 19:02:39.869162 [ERROR] [SaveSessionCommand.cc:84] Failed to serialize session to 'D:\\1\\main_list.gz'.\n7. Stop aria2 - get error 2015-11-25 19:03:10.287038 [NOTICE] [MultiUrlRequestInfo.cc:339] Failed to serialize session to 'D:\\1\\main_list.gz'.\nSame steps with deferred-input=false - no problems.\n. Only 1 difference in this cases - when deferred-input=true main_list.gz is locked all time. When it is false - file is not locked.\nI think you need to check if session file is locked before you try to serialize data. If yes - unlock it. Or read data in memory when aria starts and unlock it.\n. glad I could help you with the definition of the problem. I hope you will be able to fix it.\nmeanwhile, wanted to clarify for deferred-input. On how many downloads it is designed. I mean starting from what count of downloads it improves the performance?\n. Thx!\n. Found some information on technet.com:\nhttp://blogs.technet.com/b/askperf/archive/2011/09/23/getting-to-know-the-mmst-pool-tag.aspx\nGetting to know the MmSt Pool Tag\nCustom Applications\nApplication developers often write their applications to open thousands or millions of files simultaneously causing I/O stress\nUse the unbuffered flag when opening files to reduce pool memory usage\nhttp://support.microsoft.com/kb/99794\nhttp://msdn.microsoft.com/en-us/library/cc644950(v=VS.85).aspx\n. There is some useful flags in CreateFile to improve I/O.\nFILE_FLAG_NO_BUFFERING - no system cache (the main problem with Paged pool)\nFILE_FLAG_OVERLAPPED - asynchronous I/O If this flag is specified, the file can be used for simultaneous read and write operations\nFILE_FLAG_SEQUENTIAL_SCAN - Specifying the FILE_FLAG_SEQUENTIAL_SCAN flag can increase performance for applications that read large files using sequential access.\nMore is here https://msdn.microsoft.com/en-us/library/aa363858(v=vs.85).aspx#caching_behavior\n. Windows in case of memory is like a black hole. Don't know what is it doing with memory at all)) At this moment memory is used by 99%. I can't see any freeze or slowness, but this PC is used only for downloading and storing torrents. Disk activity is very very slow.\nAs for FILE_FLAG_NO_BUFFERING, there is only one condition that you need to meet - disk I/O requests must have sizes divisible by sector size (512 to 4096 bytes). Don't know if it is realy big work :(\n. Yeap. With disk writes it helps. Well, if you'll have some free time to update code for FILE_FLAG_NO_BUFFERING flag in file reads - it would be great. At this moment it's not critical, as windows does not alert about insufficient memory.\n. @tatsuhiro-t , again i stuck with this problem. With only aria2 running on pc there is no problem. But any application (firefox, plex, filebot and etc) i run are crashed with \"out of memory\" error.\n. Really strange bug :) I've no software for \"memory optimization\". The only software that can be responsible for this leak - DriveBender. It's drive pooling software, but disk read cache is disabled.\nAlso i've disabled windows disk cache (in disk managment console).\nOn the other hand another torrent clients (like Tixiti, transmission-qt, deluge) - works fine. No memory consumption.\n. disk-cache=0\nenable-mmap=false\ntryed multiple combinations of both options. same situation\n. I build binary from source using docker. Right before your last release.\n. I've downloaded lastest release. Will check situation with memory. Maybe it is docker build issue.\n. With your build same situation.\n. @nmaier thx for information. i've checked plex and antivirus (at this moment it is windows defender).\nWhat i've found:\n1. Some files that are \"Standby\" in RAMMAP - are opened in Plex. But they don't use any memory at all (in task manager i've 28% memory usage). Here you can see files, that are used by plex (or something else), but not aria2 (i stopped it)\n\nAnd here is task manager screen. In the momemnt of taking screeenshot plex is analysing movies (93% cpu usage)\n\n2. When aria2 is active i've many files with \"Active\" data in RAMMAP\n\nBut only 1 file is realy seeding (i mean it have some upload speed and in my understanding of torrents only such files are reading from drive).\n3. When i stop aria2 - memory frees in 1 moment, so i don't think that memory is used by another software.\nI do not know much about such things, but my understanding of the problem is that aria2 does not release files. When i open aria2 gui i see only 3 torrents active (each is single-file), but in RAMMAP i've about 30 active files. When i restart aria2 - all active files in RAMMAP are removed.\n. ",
    "Jimmy-Z": "+1\n. +1\n. that makes sense, I think we should have that info about trunced file been fragmented in the documentation.\n. yeah I have exactly the same question, it still works but cost some extra time.\n. If that's a remote download box, aren't you supposed to have a way to access downloaded files? like FTP or SMB share? use that.\nI vote against this feature, out of the scope of a download tool.\n. I suppose a \"delete-files-too\" option when canceling a download makes sense.\nIf you want it that much, this is open source software, you can always make pull requests.\nBTW if you are trying to \"integrate aria2 into my application\", I can't see why you can't do that on your end. @nosmokingbandit . OK, for anyone interested in this, https://github.com/Jimmy-Z/aria2c1k/\n. related to #813 . The one comes with debian 7, 4.7.2\nhttps://packages.debian.org/wheezy/gcc. I tried to fix this by adding \"noexcept(true)\" to those declarations, only ended with this:\nCXX      download_handlers.lo\nIn file included from BencodeDiskWriter.h:38:0,\n                 from BencodeDiskWriterFactory.h:39,\n                 from MemoryBencodePreDownloadHandler.h:39,\n                 from download_handlers.cc:45:\nValueBaseDiskWriter.h: In instantiation of \u2018class aria2::ValueBaseDiskWriter<aria2::bittorrent::BencodeParser>\u2019:\ndownload_handlers.cc:105:66:   required from here\nValueBaseDiskWriter.h:51:11: error: function \u2018aria2::ValueBaseDiskWriter<ValueBaseParser>::~ValueBaseDiskWriter() [with ValueBaseParser = aria2::bittorrent::BencodeParser]\u2019 defaulted on its first declaration with an exception-specification that differs from the implicit declaration \u2018aria2::ValueBaseDiskWriter<aria2::bittorrent::BencodeParser>::~ValueBaseDiskWriter()\u2019\nI'd admit I know almost nothing about C++. thanks, never knew there was a ARIA2_STATIC=yes. google aria2 Mac \u6559\u7a0b. Sure, thank you for detailed comments.. You're welcome :). I'm not familiar with that toolchain but it looks like some libraries you used was not built with static linking support.. you can use header to accomplish something similar.. cookies are transported as additional HTTP headers, and addUri do support the header parameter.. May I ask why you don't want per N seconds saving? could save you some trouble if there were some uncaught-able exceptions like a power failure.. https://aria2.github.io/manual/en/html/aria2c.html#cmdoption--stream-piece-selector. Glad to help :). https://aria2.github.io/manual/en/html/aria2c.html#aria2.addUri\noptions is a struct and its members are pairs of option name and value. See Options below for more details.. I believe you should fire this to Git instead, AFAIK Git doesn't have the option to use an external retriever.. In my test Chrome works and wget/curl/aria2 doesn't, but it seems just like a UA test, a simple --user-agent=Chrome is enough to make wget/curl/aria2 work.. Glad to help :). by \"run the exe files\" do you mean double click on them?\nby \"nothing happens\" do you mean a black window flashes but disappears immediately?. https://aria2.github.io/manual/en/html/aria2c.html#synopsis\nAnd maybe you should google about what is a command line program first.. Glad to help :) I suppose you should click on that \"close issue\" button below.. Thank you for the extensive answer!\nBut how do I static link only some libraries? the configure script only comes with a ARIA2_STATIC option.\nAs for why I'd need a static build, my main problem is one of my target system is still debian 7, too old(or me been too lazy) to build aria2.\nPlus building aria2 is a relatively time consuming task, with static build I can build it in one place and just copy around.\nAnyway despite the warnings, the binary built on arch runs fine on debian 7 as far as I can tell.. Thanks, I'll try that.. https://aria2.github.io/manual/en/html/README.html#libaria2\nhttps://aria2.github.io/manual/en/html/libaria2.html. can't reproduce, maybe a --version dump?\n````\n$ aria2c --follow-torrent=false https://yts.ag/torrent/download/30913830AD3C0EE714320B47D58C0485783855F2\n08/08 11:12:07 [NOTICE] Downloading 1 item(s)\n[#982acc 0B/0B CN:1 DL:0B]\n08/08 11:12:08 [NOTICE] Download complete: /tmp/King Arthur: Legend of the Sword (2017) [720p] [YTS.AG].torrent\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n982acc|OK  |    21KiB/s|/tmp/King Arthur: Legend of the Sword (2017) [720p] [YTS.AG].torrent\nStatus Legend:\n(OK):download completed.\n````. I can download HTTPS on Android fine, more information? how do you compile/get/run it?. ~You used JuiceSSH to connect to an Android device?~ (just realized JuiceSSH can act as a terminal emulator)\nAny log or screenshot?\nupdate: I just tried that myself, by default yes it will have problem supporting HTTPS since you have to specify where CAs are stored manually, see:\nhttps://aria2.github.io/manual/en/html/aria2c.html#cmdoption--ca-certificate\nOn my phone it was /etc/cacert_location.perm, I guess it varies based on device vendor.\nOr you could use --check-certificate=false, beware this is less secure.\nhttps://aria2.github.io/manual/en/html/aria2c.html#cmdoption--check-certificate. Glad to help, I suppose you can press the \"close\" button below.. for RPC, from the document, there is only a --rpc-listen-all option, you should just let it default to listen on loopback and use iptables to forward from wlan0 to loopback\nhttps://aria2.github.io/manual/en/html/aria2c.html#cmdoption--rpc-listen-all\nfor download, I don't understand, if you want it to use wwan0, interface=wwan0\nhttps://aria2.github.io/manual/en/html/aria2c.html#cmdoption--interface. I don't understand, if it has never seen any seeder, how could it get to 99% in the first place?. I'd admit I didn't read your whole post, just first few sentences.\nI believe your \"alternative\": \"percentage of pieces that have been seen\" makes sense.. It actually affects all quoted strings in Content-Disposition, not limited to filename, so how about \"Handle quoted string in Content-Disposition header as UTF-8 instead of ISO-8859-1, for example, the filename parameter, but not the extended version filename*\". ",
    "prietus": "It would be a nice feature.\n. ",
    "ghostry": "This version can not save the download list. Even if I use the parameter\n\nsave-session-interval=5\nforce-save=true\ninput-file=/mnt/sda1/.aria2/aria2.session\nsave-session=/mnt/sda1/.aria2/aria2.session\nrpc-save-upload-metadata=true\n. Relationship we use a version. I can re-send a, if you want.@tatsuhiro-t \n. ok.@tatsuhiro-t\n. Diary of aria2 where to find?\n. Sorry, because of lack of competence\n. Sorry, because I did not write to the session file permissions, it can not be saved. You can turn off this issue.\n. \n",
    "recolic": "I have a Respberry pi with 600 MHz ARMv7 CPU. The aria2c rpc process responses my jsonrpc request really really slow and the CPU is 100%. I don't believe an RPC downloader will consume so much CPU resource... It's really strange.. #603 . Could you please read the manual before asking? man aria2c tells that you can aria2c path/to/seed1.torrent path/to/seed2.torrent. It works well on aria2c 1.18.10.\nBy the way, if you need to implement more complicated logic, shellscript is what you're looking for.. Fresh-installed ubuntu 18.04, reproduced.\nConfigure:\n```\nconfigure: summary of build options:\nversion:        1.0.1-DEV shared 0:1:0\nHost type:      x86_64-pc-linux-gnu\nInstall prefix: /usr/local\nC compiler:     gcc\nCFlags:         -g -O2\nLibrary types:  Shared=yes, Static=yes\nCUnit:          no\nNettle:         yes\nBuild examples: yes\n\nconfigure: summary of build options:\nBuild:          x86_64-pc-linux-gnu\nHost:           x86_64-pc-linux-gnu\nTarget:         x86_64-pc-linux-gnu\nInstall prefix: /usr/local\nCC:             gcc\nCXX:            g++\nCPP:            gcc -E\nCXXFLAGS:       -g -O2\nCFLAGS:         -g -O2\nCPPFLAGS:     \nLDFLAGS:      \nLIBS:         \nDEFS:           -DHAVE_CONFIG_H\nCXX1XCXXFLAGS:\nEXTRACXXFLAGS:   -pipe\nEXTRACFLAGS:     -pipe\nEXTRACPPFLAGS:\nEXTRALDFLAGS:    -all-static\nEXTRALIBS:       -lpthread -ldl -lrt\nWARNCXXFLAGS: \nLibUV:          no (CFLAGS='' LIBS='')\nSQLite3:        yes (CFLAGS='' LIBS='-lsqlite3 -lm -ldl -lz -lpthread')\nSSL Support:    yes\nAppleTLS:       no (LDFLAGS='')\nWinTLS:         no (LIBS='')\nGnuTLS:         no (CFLAGS='' LIBS='')\nOpenSSL:        yes (CFLAGS='' LIBS='-lssl -ldl -lcrypto -ldl')\nCA Bundle:    \nLibNettle:      no (CFLAGS='' LIBS='')\nLibGmp:         no (CFLAGS='' LIBS='')\nLibGcrypt:      no (CFLAGS='' LIBS='')\nLibXML2:        yes (CFLAGS='-I/usr/include/libxml2' LIBS='-lxml2 -licui18n -licuuc -licudata -lz -llzma -lm')\nLibExpat:       no (CFLAGS='' LIBS='')\nLibCares:       yes (CFLAGS='' LIBS='-lcares')\nZlib:           yes (CFLAGS='' LIBS='-lz')\nLibssh2:        yes (CFLAGS='' LIBS='-lssh2 -lgcrypt -lgpg-error -lz')\nTcmalloc:       no (CFLAGS='' LIBS='')\nJemalloc:       no (CFLAGS='' LIBS='')\nEpoll:          yes\nBittorrent:     yes\nMetalink:       yes\nXML-RPC:        yes\nMessage Digest: openssl\nWebSocket:      yes (CFLAGS='-I$(top_builddir)/deps/wslay/lib/includes -I$(top_srcdir)/deps/wslay/lib/includes' LIBS='$(top_builddir)/deps/wslay/lib/libwslay.la')\nLibaria2:       no (shared=yes static=no)\nbash_completion dir: ${datarootdir}/doc/${PACKAGE_TARNAME}/bash_completion\nStatic build:   yes\n```. You're more likely to be ignored if you're using chinese while everyone else is in english. It will be horrible if a project is mixed with english, chinese, french, spanish, russian, germany, and many other languages.. ",
    "frisbee00": "Same issue here. If this is of any help, the system is behind a proxy and the environment variables http_proxy, https_proxy, etc. are set. The error doesn't come up when these variables are unset.\n. Sorry didn't check that thoroughly. The problem is setting the no_proxy environment variable as specified in ArchWiki (https://wiki.archlinux.org/index.php/Proxy_settings). Tried unsetting that alone and download works.\n. ",
    "Saren-Arterius": "Oh, my problem get solved by changing the host from mydomain.tld to aria2.mydomain.tld which is the same as my page.\nIt seems that firefox's security guideline is more strict.\n. +1 for this.\nMy CPU got crazy when downloading files inside Plex Media Server's library folder because the incomplete video files confuse Plex.\n. Or even better, add a temp-dir option for all incomplete downloads.\n. No, the HDD is sufficient.\n. I think I have this problem since 1.18.8\n[2014-09-12 18:36] [PACMAN] upgraded aria2 (1.18.7-2 -> 1.18.8-1)\n\nEDIT: It seems that I am experiencing the same issue after downgrading.\nIt needs further debugging\n. Aria2 won't ever enter D state when idle or just seeding.\n. ",
    "marcsaegesser": "Never mind. Not sure how I missed the aria2.changeGlobalOption method. Sorry.\n. ",
    "SebastianSUN": "Great! Thanks a lot bro! The compile passed!\n. ",
    "facat": "I'm using debian wheezy. I compiled aria2 on a ARM board.\n. This is the summary of configure. Any thing wrong?\nconfigure: summary of build options:\nversion:        0.1.1 shared 0:0:0\nHost type:      armv7l-unknown-linux-gnueabihf\nInstall prefix: /home/cubie/App/aria2\nC compiler:     gcc\nCFlags:         -g -O2\nLibrary types:  Shared=yes, Static=yes\nCUnit:          no\nBuild:          armv7l-unknown-linux-gnueabihf\nHost:           armv7l-unknown-linux-gnueabihf\nTarget:         armv7l-unknown-linux-gnueabihf\nInstall prefix: /home/cubie/App/aria2\nCC:             gcc\nCXX:            g++\nCPP:            gcc -E\nCXXFLAGS:       -g -O2 -pipe -std=c++11\nCFLAGS:         -g -O2 -pipe\nCPPFLAGS:       -I$(top_builddir)/deps/wslay/lib/includes -I$(top_srcdir)/deps/wslay/lib/includes -DCARES_STATICLIB    -\nI/usr/include/p11-kit-1\nLDFLAGS:         -all-static\nLIBS:           -lcares -lrt   -L/lib/arm-linux-gnueabihf -lgcrypt -lgnutls -lgcrypt -lgpg-error -ltasn1 -lz -lp11-kit\n -lsqlite3 -ldl -lpthread   -lz    -lpthread -ldl -lrt\nDEFS:           -DHAVE_CONFIG_H\nLibUV:          no\nSQLite3:        yes\nSSL Support:    yes\nAppleTLS:\nWinTLS:         no\nGnuTLS:         yes\nOpenSSL:\nCA Bundle:\nLibXML2:\nLibExpat:\nLibCares:       yes\nZlib:           yes\nEpoll:\nBittorrent:     yes\nMetalink:       no\nXML-RPC:\nMessage Digest: libgcrypt\nWebSocket:      yes\nLibaria2:       no\nbash_completion dir: ${datarootdir}/doc/${PACKAGE_TARNAME}/bash_completion\nStatic build:   yes\n. https://gist.github.com/facat/099cd6013b70242ae538\nHere's my config.log\n. I used you patch. It doesn't solve the problem.\nHere's config.log\nhttps://gist.github.com/facat/2e0cd7f23eebd639e75f\n. I figure it out. My gcc 4.9.1 is looking for a newer glibc.so, so it encountered undefined reference error.\n. ",
    "wjz2047": "@facat , how did you fix this problem?. ",
    "eedlund": "Yes, I'm using the latest binary from sf.net.\n. I ran the program with GDB and got the following output:\n```\n(gdb) run\nStarting program: /usr/local/aria2/bin/aria2c https://dnastar-web-pub.s3.amazonaws.com/20140624/C.elegans-WS195-dbSNP138.zip\nunable to read unknown load command 0x24\nunable to read unknown load command 0x26\nunable to read unknown load command 0x24\nunable to read unknown load command 0x26\nunable to read unknown load command 0x29\nthe above lines repeat many more times\nReading symbols for shared libraries ++++...................................... done\nProgram received signal EXC_BAD_ACCESS, Could not access memory.\nReason: KERN_INVALID_ADDRESS at address: 0x0000000000000000\n0x0000000000000000 in ?? ()\n(gdb) bt\n0  0x0000000000000000 in ?? ()\n1  0x00000001000ca79e in std::__1::shared_ptr::shared_ptr ()\n2  0x0000000100059200 in std::__1::pair > >::~pair ()\n3  0x00000001000026f9 in _mh_execute_header ()\n4  0x000000010002ef18 in _mh_execute_header ()\n5  0x000000010002ad40 in _mh_execute_header ()\n6  0x000000010007a961 in std::__1::__vector_base >::~__vector_base ()\n7  0x0000000100001174 in _mh_execute_header ()\n8  0x0000000100001034 in _mh_execute_header ()\n```\n. I'm unable to build from source with default settings:\n$ ./configure\n...\nconfigure: error: *** A compiler with support for C++11 language features is required.\nAny suggestions? Do I need to install a different version of gcc?\n. I'm still unable to build, despite having clang installed. I do have Xcode installed, but no clang++ executable:\n$ CC=clang CXX=clang++ ./configure\n...\nchecking for gcc... clang\nchecking whether the C compiler works... no\nconfigure: error: in `/Users/edlunde/Downloads/aria2-1.18.7':\nconfigure: error: C compiler cannot create executables\n$ clang --version\nApple clang version 1.6 (tags/Apple/clang-70)\nTarget: x86_64-apple-darwin11\nThread model: posix\n$ clang++\n-bash: clang++: command not found\n. OK, I was able to install the clang++ package by going to Apple and downloading their CLI tools for XCode. After running make I got the following warnings that seem like they might be relevant:\nAppleTLSSession.cc:91:8: warning: case value not in enumerated type\n      'SSLProtocol' [-Wswitch]\n  case kTLSProtocol11:\n       ^\nAppleTLSSession.cc:93:8: warning: case value not in enumerated type\n      'SSLProtocol' [-Wswitch]\n  case kTLSProtocol12:\n       ^\n. @tatsuhiro-t - building from source fixes the crash for me. I'm not using a proxy. Thanks for your help!\n. ",
    "eliezedeck": "I am on Mavericks and experiencing this same exact problem on all aria2 versions from SF and from brew (version 1.18.7).\nI built using clang with success. It did not work using the default GCC. Reason for others not being able to compile using CLang is unknown to me, might be a lack of C++11 support:\n./configure CC=clang CXX=clang++ --prefix=/opt/aria2\n@tatsuhiro-t, here is a backtrace of the problem, I tried to simply download from Google via HTTPS. It is true this problem seems to be only appearing in HTTPS.\nelie \"~/Downloads/aria2-1.18.8\" 1$ lldb -- /opt/aria2/bin/aria2c --all-proxy=192.168.1.140:3128 https://www.google.com\nCurrent executable set to '/opt/aria2/bin/aria2c' (x86_64).\n(lldb) r\nProcess 57072 launched: '/opt/aria2/bin/aria2c' (x86_64)\nProcess 57072 stopped\n* thread #1: tid = 0x3550f, 0x0000000100071957 aria2c`aria2::HttpRequest::createProxyRequest() const [inlined] std::__1::shared_ptr<aria2::Request>::get() const at memory:3930, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x30)\n    frame #0: 0x0000000100071957 aria2c`aria2::HttpRequest::createProxyRequest() const [inlined] std::__1::shared_ptr<aria2::Request>::get() const at memory:3930\n   3927         reset(_Yp* __p, _Dp __d, _Alloc __a);\n   3928 \n   3929     _LIBCPP_INLINE_VISIBILITY\n-> 3930     element_type* get() const _NOEXCEPT {return __ptr_;}\n   3931     _LIBCPP_INLINE_VISIBILITY\n   3932     typename add_lvalue_reference<element_type>::type operator*() const _NOEXCEPT\n   3933         {return *__ptr_;}\n(lldb) bt\n* thread #1: tid = 0x3550f, 0x0000000100071957 aria2c`aria2::HttpRequest::createProxyRequest() const [inlined] std::__1::shared_ptr<aria2::Request>::get() const at memory:3930, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x30)\n  * frame #0: 0x0000000100071957 aria2c`aria2::HttpRequest::createProxyRequest() const [inlined] std::__1::shared_ptr<aria2::Request>::get() const at memory:3930\n    frame #1: 0x0000000100071957 aria2c`aria2::HttpRequest::createProxyRequest() const [inlined] std::__1::shared_ptr<aria2::Request>::operator bool() const at memory:3941\n    frame #2: 0x0000000100071957 aria2c`aria2::HttpRequest::createProxyRequest(this=0x0000000000000000) const + 23 at HttpRequest.cc:277\n    frame #3: 0x0000000100069337 aria2c`aria2::HttpConnection::sendProxyRequest(this=0x0000000100701aa0, httpRequest=<unavailable>) + 39 at HttpConnection.cc:133\n    frame #4: 0x000000010000793d aria2c`aria2::AbstractProxyRequestCommand::executeInternal(this=0x0000000100702020) + 141 at AbstractProxyRequestCommand.cc:82\n    frame #5: 0x00000001000021e8 aria2c`aria2::AbstractCommand::execute(this=0x0000000100702020) + 1976 at AbstractCommand.cc:259\n    frame #6: 0x0000000100034ab4 aria2c`aria2::(anonymous namespace)::executeCommand(commands=0x00000001007009d8, statusFilter=STATUS_ACTIVE) + 324 at DownloadEngine.cc:135\n    frame #7: 0x000000010003483e aria2c`aria2::DownloadEngine::run(this=0x00000001007008e0, oneshot=<unavailable>) + 254 at DownloadEngine.cc:173\n    frame #8: 0x000000010008bb87 aria2c`aria2::MultiUrlRequestInfo::execute(this=0x0000000100700190) + 39 at MultiUrlRequestInfo.cc:354\n    frame #9: 0x0000000100000b7e aria2c`aria2::main(argc=<unavailable>, argv=<unavailable>) + 142 at main.cc:78\n    frame #10: 0x0000000100000c2a aria2c`main(argc=3, argv=0x00007fff5fbffc18) + 42 at main.cc:91\n(lldb)\nAt this point, since I actually use aria2 on a very very regular basis, I had resorted to really old 1.14.2 which is the only one that had a Mac DMG before 1.18.x.\nHope that helps and will be fixed in 1.18.9 :-) ... Cheers.\n. Thanks @tatsuhiro-t. That indeed fixed the crash.\nEDIT: By the way, I could not compile from master, I simply edited the 1.18.8's src/HttpConnection.cc to incorporate the changes you made. Then compiled that instead.\n. @nmaier I get an error related to libxml2. Had some struggle with autoconf while trying to generate the necessary config* scripts. Ended-up with some sort of errors, and I guess that was the reason why I did not get a complete configure script.\nI'm sure I did some terrible mistakes, so, no big deal. Not an aria2 bug.\n. ",
    "vlavorini": "Yes, i think... \n. You mean that we can just use this options, and aria2c will do the job?\nWe are using a metalink4 to download files via https, where a xxxxx tag is present.\nSure, if aria2c can parse automatically the metalink and do the checksum it will be great, but waiting for that, if I have just to parse manually the xml and use --checksum options, it is also good\n. We owe you a pizza! :pizza: \n. Great!\n. adding info: with a curl command it works:\ncurl -E /tmp/x509up_u45324 --capath /etc/grid-security/certificates/ -L https://fal-pygrid-30.lancs.ac.uk:443/dpm/lancs.ac.uk/home/atlas/atlasscratchdisk/rucio/user/gangarbt/22/2a/user.gangarbt.1113151737.41980.3918.lib.tgz -o user.gangarbt.1113151737.41980.3918.lib.tgz\n. Maybe i found the problem.\nIf, in the previous curl command, I force to use sslv2 (-2), then I get a SSL connection error. \nWe already found this problem before: in some server, when using curl without any options, the sslv2 is choose, and it fails. We solved by imposing a tls handshake (-1) from client side.\nDo you think this can be the case?\n. So probably the problem is with the sslv2. I wait for the reply of admins.\nYes, our version is a bit old (1.15.2).\nI am trying to compile the newest one, but i have some problem in that (libstdc++.so: error adding symbols: File in wrong format)\n. ok, so I try to get the newer gcc. Thank you!\n. ",
    "kim0": "Is it possible to hack around this with something like\n--bt-prioritize-piece=head=999M\n. ",
    "willemijns": "same bug occurs on a windows 10 preview under vmware player.....\n. ",
    "voltagex": "2014-10-25 22:00:09.066554 [INFO] [Context.cc:182] aria2 1.18.8\n    2014-10-25 22:00:09.066902 [INFO] [Context.cc:183] mingw-w64 3.1 (stable) / gcc 4.9.0\n      built by   x86_64-unknown-linux-gnu\n      targetting x86_64-w64-mingw32\n      on         Sep 12 2014 01:38:58\n    2014-10-25 22:00:09.067904 [INFO] [Context.cc:184] Windows 6.2 (x86_64) (6.2)\n    2014-10-25 22:00:09.068906 [INFO] [Context.cc:185] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.4.1 GMP/6.0.0 c-ares/1.10.0\n    2014-10-25 22:00:09.068906 [INFO] [Context.cc:186] Logging started.\n    2014-10-25 22:00:09.069907 [INFO] [SocketCore.cc:1237] Checking configured addresses\n    2014-10-25 22:00:09.074911 [INFO] [SocketCore.cc:1302] Not considered: \n    2014-10-25 22:00:09.075974 [INFO] [SocketCore.cc:1302] Not considered: \n    2014-10-25 22:00:09.076978 [INFO] [SocketCore.cc:1302] Not considered: \n    2014-10-25 22:00:09.077980 [INFO] [SocketCore.cc:1302] Not considered: \n    2014-10-25 22:00:09.078980 [INFO] [SocketCore.cc:1302] Not considered: \n    2014-10-25 22:00:09.079981 [INFO] [SocketCore.cc:1300] Found configured address: \n    2014-10-25 22:00:09.079981 [INFO] [SocketCore.cc:1302] Not considered: ::1\n    2014-10-25 22:00:09.080981 [INFO] [SocketCore.cc:1302] Not considered: 127.0.0.1\n    2014-10-25 22:00:09.081982 [INFO] [SocketCore.cc:1310] IPv4 configured=1, IPv6 configured=0\n    2014-10-25 22:00:09.082983 [DEBUG] [RequestGroupMan.cc:522] 1 RequestGroup(s) added.\n    2014-10-25 22:00:09.083983 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:09.084984 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n    2014-10-25 22:00:09.084984 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected http://github.com/msysgit/msysgit/releases/download/Git-1.9.4-preview20140929/Git-1.9.4-preview20140929.exe\n    2014-10-25 22:00:09.085984 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:09.091989 [INFO] [AsyncNameResolverMan.cc:89] CUID#6 - Resolving hostname github.com\n    2014-10-25 22:00:10.096200 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:11.098547 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:12.102323 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:13.106728 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:14.111343 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:15.115083 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:16.119685 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:17.126403 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:18.129578 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n    2014-10-25 22:00:19.133015 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\nAlso on Windows 10 preview\n. Any update on this?\n. Sorry, I didn't see the new release - confirming 1.18.10 works fine. You can close this now, thanks!\n. I'm looking into getting this done as paid development (not by me). Does anyone want to chip in and is this ok, @tatsuhiro-t?\n. Confirming these patches are also needed on Fedora 22 with mingw64 - I am unsure of the version but it's newer than Debian's.\nHowever the binary that's built doesn't run for me, although that's probably not related.\n. I'm still getting errors like conflicting declaration of 'char* asctime_r(const tm*, char*)' with 'C' linkage\n char * asctime_r (const struct tm*, char*); using i686-w64-mingw32 on Fedora 22.\n. I'm not sure - it's a cross-toolchain on Fedora 22. I will just use the\ndocker image for now.\n. It's just a filename fix - pull coming soon.\n. Have to run out, but here's the patch.\n`` diff\ndiff --git a/Dockerfile.mingw b/Dockerfile.mingw\nindex d21c15d..8012925 100644\n--- a/Dockerfile.mingw\n+++ b/Dockerfile.mingw\n@@ -53,8 +53,8 @@ RUN cd expat-2.1.0 && \\\n     --build=dpkg-architecture -qDEB_BUILD_GNU_TYPE` && \\\n     make install\n-RUN tar xf sqlite-autoconf-3080700.tar.gz\n-RUN cd sqlite-autoconf-3080700 && \\\n+RUN tar xf sqlite-autoconf-3080803.tar.gz\n+RUN cd sqlite-autoconf-3080803 && \\\n     ./configure \\\n     --disable-shared \\\n     --enable-static \\\n```\n. ",
    "LiYefei": "+1, good idea for append .aria2\n. ",
    "noctuid": "+1 I'm finding this to be a problem as well when downloading images. Downloading to a temporary directory and then moving afterwards with --on-download-complete works but is verbose and kind of ugly. I think it would be great to have an option to use a temporary extension or directory (or options for both) builtin.\n. ",
    "voodoo486": "+1 Plz append extension while downloading or allow temp directory. At least on windows, files are actually writable while in download and this make synchronizing steps difficult. \nThanks for a great program.\n. ",
    "itsjoke": "+1, good idea for append .aria2. ",
    "zingaburga": "Made an extremely hacky modification to do something like this.  Am also hoping a more proper implementation is made (or someone here can contribute improvements :P )\nTo use, you actually need to supply --use-tempname=true.  Incomplete files have .tmp_ appended.  Actually, this rename is done everywhere internally, so log entries etc will have that extension there as well (for my use case, it doesn't matter, but do take it into consideration).  After the download is complete, it then just renames the file, removing the temporary extension.\nAgain, really hacky, but if the drawbacks aren't an issue, maybe it's useful:\n---\n src/OptionHandlerFactory.cc | 11 +++++++++++\n src/RequestGroup.cc         | 25 +++++++++++++++++++++++++\n src/RequestGroup.h          |  2 ++\n src/RequestGroupMan.cc      |  1 +\n src/prefs.cc                |  2 ++\n src/prefs.h                 |  2 ++\n src/usage_text.h            |  4 ++++\n 7 files changed, 47 insertions(+)\n\ndiff --git a/src/OptionHandlerFactory.cc b/src/OptionHandlerFactory.cc\nindex b8f0777..88c8053 100644\n--- a/src/OptionHandlerFactory.cc\n+++ b/src/OptionHandlerFactory.cc\n@@ -120,6 +120,17 @@ std::vector<OptionHandler*> OptionHandlerFactory::createOptionHandlers()\n     handlers.push_back(op);\n   }\n   {\n+    OptionHandler* op(new BooleanOptionHandler(\n+        PREF_USE_TEMPNAME, TEXT_USE_TEMPNAME, A2_V_FALSE,\n+        OptionHandler::OPT_ARG));\n+    op->addTag(TAG_ADVANCED);\n+    op->addTag(TAG_FILE);\n+    op->setInitialOption(true);\n+    op->setChangeGlobalOption(true);\n+    op->setChangeOptionForReserved(true);\n+    handlers.push_back(op);\n+  }\n+  {\n     OptionHandler* op(new NumberOptionHandler(\n         PREF_AUTO_SAVE_INTERVAL, TEXT_AUTO_SAVE_INTERVAL, \"60\", 0, 600));\n     op->addTag(TAG_ADVANCED);\ndiff --git a/src/RequestGroup.cc b/src/RequestGroup.cc\nindex 379029e..d30b230 100644\n--- a/src/RequestGroup.cc\n+++ b/src/RequestGroup.cc\n@@ -679,6 +679,13 @@ void RequestGroup::adjustFilename(\n     // OK, no need to care about filename.\n     return;\n   }\n+  if(option_->getAsBool(PREF_USE_TEMPNAME)) {\n+    std::string filepath = getFirstFilePath();\n+    if(!filepath.empty()) {\n+      downloadContext_->getFirstFileEntry()->setPath(File(filepath).getPath() + \".tmp_\");\n+    }\n+  }\n+\n   // TODO need this?\n   if (requestGroupMan_) {\n     if (requestGroupMan_->isSameFileBeingDownloaded(this)) {\n@@ -823,6 +830,24 @@ void RequestGroup::tryAutoFileRenaming()\n       error_code::FILE_RENAMING_FAILED);\n }\n\n+void RequestGroup::completionRename()\n+{\n+  if (!option_->getAsBool(PREF_USE_TEMPNAME)) return;\n+\n+  std::string filepath = getFirstFilePath();\n+  int fLen = filepath.length();\n+  if (filepath.empty() || fLen <= 5) {\n+    throw DOWNLOAD_FAILURE_EXCEPTION2(\n+        fmt(\"File renaming failed: %s\", getFirstFilePath().c_str()),\n+        error_code::FILE_RENAMING_FAILED);\n+  }\n+  \n+  auto newfilename = filepath.substr(0, fLen - 5);\n+  File(filepath).renameTo(newfilename);\n+  downloadContext_->getFirstFileEntry()->setPath(File(newfilename).getPath());\n+}\n+\n+\n void RequestGroup::createNextCommandWithAdj(\n     std::vector<std::unique_ptr<Command>>& commands, DownloadEngine* e,\n     int numAdj)\ndiff --git a/src/RequestGroup.h b/src/RequestGroup.h\nindex 6698f93..da2dd89 100644\n--- a/src/RequestGroup.h\n+++ b/src/RequestGroup.h\n@@ -410,6 +410,8 @@ public:\n     return uriSelector_;\n   }\n\n+  void completionRename();\n+  \n   void applyLastModifiedTimeToLocalFiles();\n\n   void updateLastModifiedTime(const Time& time);\ndiff --git a/src/RequestGroupMan.cc b/src/RequestGroupMan.cc\nindex 28a3e54..e81b9d5 100644\n--- a/src/RequestGroupMan.cc\n+++ b/src/RequestGroupMan.cc\n@@ -388,6 +388,7 @@ public:\n           else {\n             group->saveControlFile();\n           }\n+          group->completionRename(); // do this as late as possible as it's a dodgy hack'\n           std::vector<std::shared_ptr<RequestGroup>> nextGroups;\n           group->postDownloadProcessing(nextGroups);\n           if (!nextGroups.empty()) {\ndiff --git a/src/prefs.cc b/src/prefs.cc\nindex 4f213f2..ec1ecd6 100644\n--- a/src/prefs.cc\n+++ b/src/prefs.cc\n@@ -232,6 +232,8 @@ PrefPtr PREF_FORCE_SEQUENTIAL = makePref(\"force-sequential\");\n // value: true | false\n PrefPtr PREF_AUTO_FILE_RENAMING = makePref(\"auto-file-renaming\");\n // value: true | false\n+PrefPtr PREF_USE_TEMPNAME = makePref(\"use-tempname\");\n+// value: true | false\n PrefPtr PREF_PARAMETERIZED_URI = makePref(\"parameterized-uri\");\n // value: true | false\n PrefPtr PREF_ALLOW_PIECE_LENGTH_CHANGE = makePref(\"allow-piece-length-change\");\ndiff --git a/src/prefs.h b/src/prefs.h\nindex 91fa876..d6b60a9 100644\n--- a/src/prefs.h\n+++ b/src/prefs.h\n@@ -185,6 +185,8 @@ extern PrefPtr PREF_FORCE_SEQUENTIAL;\n // value: true | false\n extern PrefPtr PREF_AUTO_FILE_RENAMING;\n // value: true | false\n+extern PrefPtr PREF_USE_TEMPNAME;\n+// value: true | false\n extern PrefPtr PREF_PARAMETERIZED_URI;\n // value: true | false\n extern PrefPtr PREF_ALLOW_PIECE_LENGTH_CHANGE;\ndiff --git a/src/usage_text.h b/src/usage_text.h\nindex 19817bc..b4ee812 100644\n--- a/src/usage_text.h\n+++ b/src/usage_text.h\n@@ -177,6 +177,10 @@\n     \"                              The new file name has a dot and a number(1..9999)\\n\" \\\n     \"                              appended after the name, but before the file\\n\" \\\n     \"                              extension, if any.\")\n+#define TEXT_USE_TEMPNAME                                         \\\n+  _(\" --use-tempname[=true|false] Download file to a temporary name\\n\" \\\n+    \"                              and rename on complete.\\n\" \\\n+    \"                              This option works only in http(s)/ftp download.\")\n #define TEXT_PARAMETERIZED_URI                                          \\\n   _(\" -P, --parameterized-uri[=true|false] Enable parameterized URI support.\\n\" \\\n     \"                              You can specify set of parts:\\n\"     \\\n-- \n2.6.2.windows.1\n\nAll improvements welcome!. Ah, I didn't know about that header.  Thank you for the information!\n. It just came to me, but it may also be beneficial to also have an option to auto save the session file (if --save-session has been specified) whenever a download completes, otherwise attempting to resume can result in the process failing if a download has completed, but the updated session has yet been written to disk (--save-session-interval option specified).  If such an option is added, the session should be saved before the control file is removed.\nAs there is an RPC call to explicitly force it, I suppose one could make use of the on-complete hook to call a program, connect to RPC and force a session save, but it's a bit cumbersome and probably less reliable than doing it in the same process.\nThanks for reading!. > I think it would be nice to write .aria2 control file as early as possible. First such chance is when we determined the file size.\nMakes sense, since you can only falloc the file after you know the file size (so you can write control file before main file is written).\nAnd yeah, I can see I/O being a problem if there are lots of small files, so an option is ideal.  This is also the same for the control file (lots of small files can cause unnecessary .aria2 files to be written), so an option for that (or maybe combine the two) could be useful.\nThanks for sharing your thoughts!. Finally managed to get a build working, and it looks great!\nThanks for the change :). Official builds >= 1.19 don't seem to work on XP.\nTry these builds instead: https://github.com/q3aql/aria2-static-builds. ",
    "HaleTom": "My vote is to support a separate directory:\nWhen downloading torrents, it would be great to be able to specify a \"partial\" or \"in progress\" directory. as the in-progress download's directory looks complete, the only clue it isn't is the existence of a .aria2 file also.\nIt would be a lot cleaner if both .aria2 file and in-progress torrent directory could be stored somewhere until the download is fully \"cooked\", and then moved to the destination directory.. Is it possible to restart the download without the original link, but only the .aria2 file? I want to resume my torrent and can't find the tracker.... How do I use the info hash in the .aria2 to resume the download without finding a new magnet/download link?. @IamCarbonMan Yup, a user shouldn't need to dig into a file-format specification to resume a magnet download.. @stefanos82 I use uget as a front-end to aria2c, so I can't use my bash history :(. @stefanos82 I'm using Manjaro linux. I've temporarily switched to using deluge for torrents. Still, I am interested in your suggestion, and others may be, too.\n. ",
    "riverscn": "+1 That will be very helpful.. ",
    "Ealireza": "patch not working , possible add new patch ?. ",
    "elieux": "It's caused by libintl redefining vprintf to libintl_vprintf, but just in OutputFile, not in WinConsoleFile nor IOFile because the latter two include <string> which undefines the macro.. The override keyword caught it early -- removing it causes pure virtual method calls. Including the libintl macro in WinConsoleFile and IOFile causes build errors about missing vprintf methods.\nIf I include <string> in OutputFile, I can build successfully. Is there a chance of you accepting such a patch?\n. Heh, sorry for my late reply. I have been super busy and didn't get to do what I promised.\n@voltagex, what mingw-w64 version is this?\n. Would it be okay to\n```\nifdef HAVE_WINSOCK2_H\ndefine PRI_SOCKET \"%llu\"\nelse\ndefine PRI_SOCKET \"%d\"\nendif\n```\nand then use that macro in the formatting strings?\n. ",
    "hemantmits": "I have uploaded logs to box.com \nhttps://app.box.com/s/n3s7l9knnpgfkbv29iqq\nSteps to repro:\n1. set download queue size to 2\n2. add three torrents ( download size doesnot matter )\n3. after first two download completed and should be moved to seeding third torrent should start download.\nFollowing is my aria2 conf file:\ndir=/media/usb3/rpi/dl/\nfile-allocation=falloc\ncontinue\nlog-level=debug\nmax-connection-per-server=9\nsummary-interval=120\ndaemon=true\nenable-rpc=true\nrpc-listen-port=6800\nrpc-listen-all=true\nmax-concurrent-downloads=2\nsave-session=/media/usb3/rpi/dl/sessions.txt\ninput-file=/media/usb3/rpi/dl/sessions.txt\nlog=/media/usb3/rpi/dl/aria.log\ndisable-ipv6=true\ndisk-cache=25M\ntimeout=600\nretry-wait=30\nmax-tries=50\nsave-session-interval=10\ncheck-certificate=false\nLet me know if more details required. \n. seed-time solved this issue.\nAre you planning to fix this in future release ?\nI think seeding should not be counted as downloading queue.\n. Thanks for the quick fix. I will test and close the case.\n. works fine thanks for fix.\n. ",
    "sonnyp": "close this?\n. @tatsuhiro-t I have created the organization and invited you as owner\nhttps://github.com/aria2\nhttp://aria2.github.io/\nFeel free to remove me from owners once you're setup;\n. @tatsuhiro-t no worry there is no reason for me to be owner of the project\n. Any news ? Ublock origin (and possibly others) now blocks sourceforge.net\n. @tatsuhiro-t great! thanks, is there any way to close http://aria2.sourceforge.net/ or maybe notice about the change?\n. @tatsuhiro-t hmm index doesn't redirect, only links (documentation, ....) but I guess that's good enough \n. For the repository, a simple github move repository should do the trick easily, github will take care of all redirections.\n. @tatsuhiro-t can you change the repo website on https://github.com/tatsuhiro-t/aria2 , it still shows sf.net on the right of the repo description ?\n. additionally it would be very helpful to return a description of the method and its signature (accepted arguments and types), maybe using JSON schema ?\n. @tatsuhiro-t thanks, that's useful\n. aria2 rpc cli https://github.com/sonnyp/aria2.js/blob/master/bin/README.md if it's of any help to you / the project\n. the methods description/signature is an other story, will open a new issue if needs be.\n. @tatsuhiro-t could you make a new release including the listMethods method?\n. :+1: \n. @tatsuhiro-t no, thank you :smile_cat: \n. Thanks\n\nUsing batch/multicall is potentially more efficient since the all requests in batch call can be sent in fewer packets, which could reduce latency.\n\nIn theory yes (specially in the case of HTTP where the overhead is significant) but if one of the request of the batch takes 100ms more than any other within the same batch, you'll get a 100ms latency increase compared to individual request (because you'll have to wait for that longer operation to finish to receive the responses for the shorter operations) but maybe it's untrue in the case of aria2 and all operations are simply queued providing the same response time for all of them?\n. Right, in any case it won't make a big difference but I find the topic interesting.\nI'll simply make the multicall/batch helper always use JSON-RPC batch and let the users decide.\n. should I add a #ifdef ENABLE_BITTORRENT for this one?\n. let me know if I should leave those whitespaces\n. done\n. ",
    "menixator": "Um. I forgot to mention it in the comment, but the typo is also present in the documentation for the other languages as well.\ndoc/manual-src/ru/aria2c.rst#L2442:\n.. function:: aria2.forcePause([secret], pid)\ndoc/manual-src/pt/aria2c.rst #L2256\n.. function:: aria2.forcePause(pid)\nIn doc/manual-src/pt/aria2c.rst #L2256, the secret parameter seems to be missing too.\n. ",
    "natiq2004": "Yes it is 23 days that i opened this topic, but there was not any respond. That's why i created this topic again to remind you. This program is my mostly used program. Please add this option which i write to this program.\nThank you!\n. I am using this program everyday for few hours. That's why i need this option urgently. Please add this option to this program, i am ready to pay for it.\n. ",
    "cuckoohello": "Thanks, I mean user-agent when accessing BitTorrent tracker.\n. ",
    "zkanda": "+1 I would love this feature as well.\n. ",
    "Gelob": "I'd love to have this supported as well\n. ",
    "scottjl": "old issue, but i'd love to see it added too.\n. ",
    "f18m": "great thanks for letting me know. Then I think I just have to wait :)\n. ",
    "javierurien": "+1 this feature please!!\n. ",
    "MrParham": "I managed to install a new version of gcc but still facing issue\n\nIndexedList.h:588: error: 'end' is not a member of 'std'\nIndexedList.h: In member function 'aria2::IndexedListIterator, std::allocator > >, ValuePtrType, ValuePtrType&, ValuePtrType_, typename std::deque, std::allocator > >::iterator> aria2::IndexedList::begin()':\nIndexedList.h:607: error: 'begin' is not a member of 'std'\nIndexedList.h: In member function 'aria2::IndexedListIterator, std::allocator > >, ValuePtrType, ValuePtrType&, ValuePtrType_, typename std::deque, std::allocator > >::iterator> aria2::IndexedList::end()':\nIndexedList.h:612: error: 'end' is not a member of 'std'\nIndexedList.h: In member function 'aria2::IndexedListIterator, std::allocator > >, ValuePtrType, const ValuePtrType&, const ValuePtrType_, typename std::deque, std::allocator > >::const_iterator> aria2::IndexedList::begin() const':\nIndexedList.h:617: error: 'begin' is not a member of 'std'\nIndexedList.h: In member function 'aria2::IndexedListIterator, std::allocator > >, ValuePtrType, const ValuePtrType&, const ValuePtrType_, typename std::deque, std::allocator > >::const_iterator> aria2::IndexedList::end() const':\nIndexedList.h:622: error: 'end' is not a member of 'std'\nIn file included from util.h:60,\n                 from AbstractCommand.cc:60:\nSegList.h: At global scope:\nSegList.h:56: error: 'aria2::SegList::SegList(aria2::SegList&&)' cannot be defaulted\nSegList.h: In member function 'void aria2::SegList::normalize()':\nSegList.h:71: error: 'begin' is not a member of 'std'\nSegList.h:71: error: 'end' is not a member of 'std'\nIn file included from DownloadContext.h:47,\n                 from AbstractCommand.cc:62:\nValueBase.h: In constructor 'aria2::DowncastValueBaseVisitor::DowncastValueBaseVisitor()':\nValueBase.h:323: error: 'nullptr' was not declared in this scope\nIn file included from AbstractCommand.cc:66:\nFileEntry.h: In function 'std::shared_ptraria2::FileEntry aria2::getFirstRequestedFileEntry(InputIterator, InputIterator)':\nFileEntry.h:304: error: 'nullptr' was not declared in this scope\nAbstractCommand.cc: In function 'bool aria2::::inNoProxy(const std::shared_ptraria2::Request&, const std::string&)':\nAbstractCommand.cc:709: error: expected initializer before ':' token\nAbstractCommand.cc:962: error: expected primary-expression at end of input\nAbstractCommand.cc:962: error: expected ';' at end of input\nAbstractCommand.cc:962: error: expected primary-expression at end of input\nAbstractCommand.cc:962: error: expected ')' at end of input\nAbstractCommand.cc:962: error: expected statement at end of input\nAbstractCommand.cc:962: error: expected '}' at end of input\nAbstractCommand.cc: At global scope:\nAbstractCommand.cc:962: error: expected '}' at end of input\nAbstractCommand.cc:962: error: expected '}' at end of input\nmake[3]: * [AbstractCommand.lo] Error 1\nmake[3]: Leaving directory /root/aria2-1.18.8/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory/root/aria2-1.18.8/src'\nmake[1]: * [all-recursive] Error 1\nmake[1]: Leaving directory `/root/aria2-1.18.8'\nmake: *** [all] Error 2\n\nHere is my gcc version\n\n[root@ns340211 aria2-1.18.8]# gcc --version\ngcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15)\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n. Yes I have ....\n. Strange fact, using the same GCC version on Centos 7 I could install aria2 latest version so it seems like aria2 would not work on Centos 6.x anymore.\n[root@aria2test aria2-1.18.8]# gcc --version\ngcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-16)\nCopyright (C) 2013 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n[root@aria2test aria2-1.18.8]# \n. Yeap we can close the issue as I got it working :) Thanks\n. ",
    "midnight2k": "will try. run 1.18.8 two days on QNAP, mem usage 344MB\n. 1.18.8 run 3days, killed by kernel in QNAP platform.\ntry bisect, get below results,\ntp1 short time mem usage ok, keep run over night \nSHA-1: 10a19b138209fde31841a4271582b51940e607d4\n- Update README.rst\ntp6  memory usage high, 3hours up to 53MB\nSHA-1: 35d00f6b7f046f227e0d7058a41bdd8378d3ca17\n- Remove meta directive for now since it breaks manpage generation\nSo the suspected commit narrow down to \"Abstract TLS session implementation\" commit\nif tp1 commit above no problem running long time, I will try below one to double confirm.\ntp8  wait to check\nSHA-1: 8580c98bce8e5b85c1cf7be150d9315cd663db93\n- Abstract TLS session implementation\n. I am using optware deault openssl 0.98v.  webui is via no secure http, and only used at aria2 startup to check download jobs are normally started.\ntp1 running over 8 hours, still keep ~27MB, think this commit is last fine version.\nSHA-1:  10a19b1 \nMerry Chrismas!\n. confirmed It is commit 8580c98bce8e5b85c1cf7be150d9315cd663db93 lead to high memory usage.\ncommit 10a19b138209fde31841a4271582b51940e607d4 is the last fine. run 24hours. total mem using still keep ~27MB\n. Hi, looks like I find root cause. \nin 1.16.5 sockcore.cc have called ssl session release functions. but in 1.17.0 not\nvoid SocketCore::closeConnection()\n{\n...\nifdef HAVE_OPENSSL\n// for SSL\n  if(secure_) {\n    SSL_free(ssl);\n  }\nendif // HAVE_OPENSSL\nifdef HAVE_LIBGNUTLS\nif(secure_) {\n    gnutls_deinit(sslSession_);\n  }\nendif // HAVE_LIBGNUTLS\n}\nadd SSL_free() to LibgnutlsTLSSession.cc,     and gnutls_deinit() to LibgnutlsTLSSession.cc\n1.17.1 memory using become normal. I will try to mod 1.18.8\n. use below patch on  latest 1.18.8 commit. it still works. mem using solid at ~27MB. at least for openssl, the issue is solved \n src/LibgnutlsTLSSession.cc | 1 +\n src/LibsslTLSSession.cc    | 1 +\n 2 files changed, 2 insertions(+)\ndiff --git a/src/LibgnutlsTLSSession.cc b/src/LibgnutlsTLSSession.cc\nindex 273d82b..b33d202 100644\n--- a/src/LibgnutlsTLSSession.cc\n+++ b/src/LibgnutlsTLSSession.cc\n@@ -184,6 +184,7 @@ int GnuTLSSession::setSNIHostname(const std::string& hostname)\n int GnuTLSSession::closeConnection()\n {\n   rv_ = gnutls_bye(sslSession_, GNUTLS_SHUT_WR);\n-  gnutls_deinit(sslSession_);\n  if(rv_ == GNUTLS_E_SUCCESS) {\n   return TLS_ERR_OK;\n  } else if(rv_ == GNUTLS_E_AGAIN || rv_ == GNUTLS_E_INTERRUPTED) {\n  diff --git a/src/LibsslTLSSession.cc b/src/LibsslTLSSession.cc\n  index 854e41b..5d7fec8 100644\n  --- a/src/LibsslTLSSession.cc\n  +++ b/src/LibsslTLSSession.cc\n  @@ -59,6 +59,7 @@ OpenSSLTLSSession::~OpenSSLTLSSession()\n  {\n   if(ssl_) {\n     SSL_shutdown(ssl_);\n-    SSL_free(ssl_);\n  }\n  }\n. ```\nsrc/LibgnutlsTLSSession.cc | 1 +\n src/LibsslTLSContext.cc    | 2 ++\n src/LibsslTLSSession.cc    | 1 +\n 3 files changed, 4 insertions(+)\ndiff --git a/src/LibgnutlsTLSSession.cc b/src/LibgnutlsTLSSession.cc\nindex 273d82b..b33d202 100644\n--- a/src/LibgnutlsTLSSession.cc\n+++ b/src/LibgnutlsTLSSession.cc\n@@ -184,6 +184,7 @@ int GnuTLSSession::setSNIHostname(const std::string& hostname)\n int GnuTLSSession::closeConnection()\n {\n   rv_ = gnutls_bye(sslSession_, GNUTLS_SHUT_WR);\n+  gnutls_deinit(sslSession_);\n   if(rv_ == GNUTLS_E_SUCCESS) {\n     return TLS_ERR_OK;\n   } else if(rv_ == GNUTLS_E_AGAIN || rv_ == GNUTLS_E_INTERRUPTED) {\ndiff --git a/src/LibsslTLSContext.cc b/src/LibsslTLSContext.cc\nindex 70c13a6..f83e2e3 100644\n--- a/src/LibsslTLSContext.cc\n+++ b/src/LibsslTLSContext.cc\n@@ -104,7 +104,9 @@ OpenSSLTLSContext::OpenSSLTLSContext(TLSSessionSide side, TLSVersion minVer)\n   long ver_opts = 0;\n   switch(minVer) {\n   case TLS_PROTO_TLS12:\n+#ifdef SSL_OP_NO_TLSv1_1\n     ver_opts |= SSL_OP_NO_TLSv1_1;\n+#endif  //SSL_OP_NO_TLSv1_1\n     // fall through\n   case TLS_PROTO_TLS11:\n     ver_opts |= SSL_OP_NO_TLSv1;\ndiff --git a/src/LibsslTLSSession.cc b/src/LibsslTLSSession.cc\nindex 854e41b..5d7fec8 100644\n--- a/src/LibsslTLSSession.cc\n+++ b/src/LibsslTLSSession.cc\n@@ -59,6 +59,7 @@ OpenSSLTLSSession::~OpenSSLTLSSession()\n {\n   if(ssl_) {\n     SSL_shutdown(ssl_);\n+    SSL_free(ssl_);\n   }\n }\n```\n. I am using openssl 0.98v, not use a gnuTLS libary. The most Marvell arm based NAS install NSLU optware and work with openssl 0.98v.\nRun d755df2 commit, memory usage go back to normal. with 16MB disk cache setting, total mem usage is ~27MB. the download speed has no much different from I patched version.\nsurely this issue resoved!\nThanks\n. ",
    "wernight": "If I understood correct here is a suggestion:\n--bt-require-crypto to only accept encrypt incoming connections (outgoing connection may still remain un-encrypted, see --bt-min-crypto-level for that).\n--bt-min-crypto-level specify the encryption level for incoming and outgoing connections; can be either clear (no encryption) or XXX (requires encrypted).\nMay be I missed something. I don't understand the reason one would want to set --bt-require-crypto, especially supposing that --bt-min-crypto-level implies --bt-require-crypto. Also the standard apps have an option prefer encrypted which seems missing.\n. Ah yes of course, thinking of it you may want to allow unencrypted in and force encryption out; that would be if --bt-min-crypto-level is only for outgoing connections\n. I made a table from your comment: https://docs.google.com/a/beroux.com/spreadsheets/d/1rIpfH5AZ7wQ5RBQ3U2rXkvoUVPo_fM3WiEZTZM6o9_E/edit?usp=sharing\nAm I to understand that 'plain' is actually that \"simple\" encryption level of torrent, and arc4 is a newer and stronger encryption?\n. Updated the sheet; if plain means non-encrypted, I don't see the difference in --bt-min-crypto-level\n. aria2 prefers encryption in all cases which is good.\nSo for --bt-require-crypto=false --bt-min-crypto-level=arc4 with an unencrypted handshake, it'll still use an unencrypted payload?\nAnd for --bt-require-crypto=true --bt-min-crypto-level=plain it means that handshake is encrypted, but payload may be unencrypted?\n. Thanks it's a lot clearer. Technically it probably makes sense, but for a user it seems to make little sense to have --bt-require-crypto=false --bt-min-crypto-level=arc4. Forcing encrypted handshake while allowing unencrypted payload (ie, --bt-require-crypto=true --bt-min-crypto-level=plain) can make some sense though it seems like a rare case.\nSo in short --bt-require-crypto force an encrypted handshake, while --bt-min-crypto-level forces an encrypted payload (currently only for encrypted handshakes).\nWhat I would suggest is to simplify by either:\n- Having a single flag to simply force all encryption (ie, --bt-require-crypto=true --bt-min-crypto-level=arc4), or\n- A solution where --bt-min-crypto-level=arc4 implies --bt-require-crypto so that  --bt-min-crypto-level would actually mean to force payload encryption (which means that handshake has also to be encrypted).\n- A third solution, would be to remove --bt-require-crypto flag and have --bt-min-crypto-level which can one of plain, handshake, or arc4 (or whatever name you find good).\nAmong those solution, I'd go for the simplest, the first, as in no case I would go for encrypting only the header if 99% of clients which can and are willing to encrypt header can and are willing to also encrypt the payload in ARC4. The last solution is also good as it allows later to support strong encryption protocol.\nPS: I may keep existing flags hidden for backward compatibility or mark them as deprecated.\n. Very nice. Should the old fields be marked as deprecated?\n. ",
    "ffallah": "Yes. I also believe you need to compile using the latest android NDK.\nIf you had time to do that, I would be happy to test it and report back :)\n. It still gives this error :\nerror: only position independent executables (PIE) are supported.\nI highly recommend you to read the stackoverflow link. may be some other changes are required for it to work on Android 5+\n. It works fine now. Good job :)\n. ",
    "dfandrich": "I've discovered by dumping entry->resources immediately after the call entry->reorderResourcesByPriority(); in Metalink2RequestGroup::createRequestGroup that the URLs aren't actually sorted by priority. They don't have any obvious order that I can tell at that point.\n. I see the order not\u2014except for the first, the remainder are sorted by priority (there are only 3 priorities). It's just that the first URL was specified with the highest priority (30) in the XML file, but somehow it got turned into -999969 by the time it reached the resources list (with an interesting equation being -999969=30-MetalinkResource::getLowestPriority()).\n. No, I didn't use those command-line options, but wouldn't you know it, I had a 6 year old ~/.aria2/aria2.conf file I had forgotten about with metalink-location set. One of the locations even matched that of the site that was promoted first. I did some more testing including changing that flag and aria2c seems to do the right thing here after all. Sorry about the noise. Some logging of the selection process would have helped in this case; the process is completely opaque in the logs right now.\n. I've created PR#327 to add a log of possible Metalink URLs and their final priority values.\n. ",
    "gbcox": "I'm talking about the setting in the aria2 configuration file.\n. I agree...I think aria2 is the greatest thing since sliced bread, but I think the encryption mechanism used by MEGA complicates things a bit.  There is another tool called appropriately enough \"MEGATOOLS\" which can be used:  http://megatools.megous.com/\nIt however uses curl rather than our favorite downloader.\n. There are front-end apps which can help with that...\n1.  Chrome Aria2c integration:\nhttps://chrome.google.com/webstore/detail/aria2c-integration/cnkefpcjiolhnmhfpjbjpidgncnajlmf?utm_source=chrome-app-launcher-info-dialog\n2.  webui-aria2\nhttps://github.com/ziahamza/webui-aria2\n3.  uGet Download Manager\nhttp://ugetdm.com/\nThose are just a few... I'm sure there are others.\nI wouldn't choose the word \"unfriendly\".  Is it powerful?  Yes... Does it have alot of options you can use?  Yes... IMHO that is the attractiveness of the application - but you don't have to tweak it... you can just use the defautts.  If you begin to \"dumb it down\" you might as well use one of the other many FTP apps which are available.  \n. ",
    "ehmo": "Seems like it's an old version of aria that creates this issues.\n. ",
    "akashihi": "dpkg -l zlib1g-dev\n[skipped headers]\nii  zlib1g-dev:amd64                 1:1.2.7.dfsg-13       amd64                 compression library - development\nconfigure: summary of build options:\nversion:        0.1.1 shared 0:0:0\nHost type:      x86_64-unknown-linux-gnu\nInstall prefix: /usr\nC compiler:     gcc\nCFlags:         -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2\nLibrary types:  Shared=yes, Static=yes\nCUnit:          no\nBuild:          x86_64-unknown-linux-gnu\nHost:           x86_64-unknown-linux-gnu\nTarget:         x86_64-unknown-linux-gnu\nInstall prefix: /usr\nCC:             gcc\nCXX:            g++\nCPP:            gcc -E\nCXXFLAGS:       -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 -pipe -std=c++11\nCFLAGS:         -g -O2 -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 -pipe\nCPPFLAGS:       -I$(top_builddir)/deps/wslay/lib/includes -I$(top_srcdir)/deps/wslay/lib/includes    -I/usr/include/p11-kit-1     -I/usr/include/libxml2   -D_FORTIFY_SOURCE=2\nLDFLAGS:        -Wl,-z,relro -Wl,-z,defs,--as-needed\nLIBS:           -lrt -lcares   -L/lib/x86_64-linux-gnu -lgcrypt -lgnutls   -lsqlite3   -L/usr/lib -lxml2 -lz\nDEFS:           -DHAVE_CONFIG_H\nLibUV:          no\nSQLite3:        yes\nSSL Support:    yes\nAppleTLS:\nWinTLS:         no\nGnuTLS:         yes\nOpenSSL:\nCA Bundle:      /etc/ssl/certs/ca-certificates.crt\nLibXML2:        yes\nLibExpat:\nLibCares:       yes\nZlib:           yes\nEpoll:          yes\nBittorrent:     yes\nMetalink:       yes\nXML-RPC:        yes\nMessage Digest: libgcrypt\nWebSocket:      yes\nLibaria2:       no\n. with 1.8.10 problem just disappeared. \n. Well, I'm not sure, what answer you are expecting :) But if i say 'a single\nfile', will it be enough?:)\n17 \u0430\u043f\u0440. 2015 \u0433. 16:28 \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u0435\u043b\u044c \"Tatsuhiro Tsujikawa\" \nnotifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b:\n\nPS Those torrents was from some private trackers, so DHT was disabled in\nthem and they were described by files, not magnet links.\nWhat kind of data is described in .torrent file?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/362#issuecomment-93985910.\n. Could you please point me, what should i do with that torrent file? May be\nyou can recommend some dumping tools?\n\n2015-04-17 17:28 GMT+03:00 Tatsuhiro Tsujikawa notifications@github.com:\n\nI asked because you wrote \"DHT was disabled in them and they were\ndescribed by files.\"\nI guess that utorrent uses the some kind of data \"described by files\" to\nconnect to them and start downloads. .torrent file is encoded JSON-like\nencoding called bencoding. Probably a key described to bootstrap download\nis contained there.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/362#issuecomment-93996744.\n. Well, the problem is that i've downloaded that torrent and deleted it\nbefore opening an issue :( Starting from that time, i haven't seen any\ntorrents, that behave like that.\n\n2015-04-18 15:24 GMT+03:00 Tatsuhiro Tsujikawa notifications@github.com:\n\nI'd like to see the content of .torrent file. Could you upload it to\nsomewhere I can download from?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/362#issuecomment-94162424.\n. Finally i found a new torrent with the problem: magnet:?xt=urn:btih:d33b8035e2113fecc29d88e8f5aa58847b66d79b&dn=Jeppesen+Jeppview+Data+Cycle+1513&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Fopen.demonii.com%3A1337&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Fexodus.desync.com%3A6969\n. \n",
    "imoverclocked": "On further inspection, I'm getting a torrent file with a base URL embedded into it so aria knows how to fallback to an http backend. It falls back for each file in the order listed in the torrent. So, this has nothing to do with metalink even though mentioned it previously. \n. I tried it but it still seems to be the same order. I have only one base URL. Here is my scenario:\nI have a torrent with (say) 10000 files and a single baseURL which is an http cache server that has a high latency connection to its source. If I start 100 aria2 clients and they all request the files in the same order then the cache server grabs a single file at a time from its source. Since it's latency bound, this takes a really long time.\nIf we randomize the order that aria2 requests the files (not the backend) then the cache server will get 100 different files at the same time. In the case of no overlapping requests, this will make the overall transfer roughly 100 times faster.\n. That sounds correct.\n. @dignabbit You might retry the tests with /bigfile1 ... /bigfileN because (AFAICR) the selector code chooses a random file rather than a random \"block\" from the torrent. In this case the old code would satisfy all blocks for /bigfile1 and then move onto /bigfile2 and so forth. The new code should choose a random file in the torrent to satisfy first.\nI didn't get to test thoroughly/at scale so I haven't commented until now.\n. @tatsuhiro-t It seems this algorithm works well at scale. Thanks for the patch!\n. ",
    "dignabbit": "Hey @tatsuhiro-t , I'd like to pick up the effort of testing this feature. Would you mind rebasing the branch random-webseeding onto master? That would be great! Thanks!\n. @tatsuhiro-t \nI merged master (basically 1.19.2) into randomwebseeding and tested it with --stream-piece-selector=random.\nHere are the results:\n```\nx.x.x.1 [05/Oct/2015:21:57:41 +0000] \"GET /bigfile HTTP/1.1\" 206 3475200  \"aria2/1.19.2\" bytes=195582624-229284543\nx.x.x.1 [05/Oct/2015:21:57:43 +0000] \"GET /bigfile HTTP/1.1\" 206 524288   \"aria2/1.19.2\" bytes=3693216-4217503\nx.x.x.1 [05/Oct/2015:21:57:47 +0000] \"GET /bigfile HTTP/1.1\" 206 524288   \"aria2/1.19.2\" bytes=5266080-5790367\nx.x.x.1 [05/Oct/2015:21:57:56 +0000] \"GET /bigfile HTTP/1.1\" 206 857216   \"aria2/1.19.2\" bytes=12081824-14178975\nx.x.x.1 [05/Oct/2015:21:57:58 +0000] \"GET /bigfile HTTP/1.1\" 206 524288   \"aria2/1.19.2\" bytes=220224160-220748447\nx.x.x.1 [05/Oct/2015:21:58:01 +0000] \"GET /bigfile HTTP/1.1\" 206 23200    \"aria2/1.19.2\" bytes=0-23199\nx.x.x.2 [05/Oct/2015:21:57:42 +0000] \"GET /bigfile HTTP/1.1\" 206 2974192  \"aria2/1.19.2\" bytes=25713312-229284543\nx.x.x.2 [05/Oct/2015:21:57:52 +0000] \"GET /bigfile HTTP/1.1\" 206 1865024  \"aria2/1.19.2\" bytes=195058336-211311263\nx.x.x.2 [05/Oct/2015:21:57:54 +0000] \"GET /bigfile HTTP/1.1\" 206 524288   \"aria2/1.19.2\" bytes=28859040-29383327\nx.x.x.2 [05/Oct/2015:21:57:58 +0000] \"GET /bigfile HTTP/1.1\" 206 524288   \"aria2/1.19.2\" bytes=178805408-179329695\nx.x.x.2 [05/Oct/2015:21:58:03 +0000] \"GET /bigfile HTTP/1.1\" 206 524288   \"aria2/1.19.2\" bytes=220224160-220748447\nx.x.x.2 [05/Oct/2015:21:58:06 +0000] \"GET /bigfile HTTP/1.1\" 206 23200    \"aria2/1.19.2\" bytes=0-23199\nx.x.x.3 [05/Oct/2015:22:17:52 +0000] \"GET /bigfile HTTP/1.1\" 206 27934752 \"aria2/1.19.2\" bytes=201349792-229284543\nx.x.x.3 [05/Oct/2015:22:17:59 +0000] \"GET /bigfile HTTP/1.1\" 206 80216064 \"aria2/1.19.2\" bytes=121133728-201349791\nx.x.x.3 [05/Oct/2015:22:18:02 +0000] \"GET /bigfile HTTP/1.1\" 206 33030144 \"aria2/1.19.2\" bytes=88103584-121133727\nx.x.x.3 [05/Oct/2015:22:18:15 +0000] \"GET /bigfile HTTP/1.1\" 206 88103584 \"aria2/1.19.2\" bytes=0-88103583\n```\nSo in general it works. But it doesn't seem to look very much different from this run with an old version:\n```\nx.x.x.1 [05/Oct/2015:22:18:26 +0000] \"GET /bigfile HTTP/1.1\" 206 6012096 \"aria2/1.17.1\" bytes=48820796-229223879\nx.x.x.1 [05/Oct/2015:22:19:05 +0000] \"GET /bigfile HTTP/1.1\" 206 863008  \"aria2/1.17.1\" bytes=154202684-229223879\nx.x.x.1 [05/Oct/2015:22:19:06 +0000] \"GET /bigfile HTTP/1.1\" 206 863008  \"aria2/1.17.1\" bytes=28897852-48820795\nx.x.x.1 [05/Oct/2015:22:19:08 +0000] \"GET /bigfile HTTP/1.1\" 206 863008  \"aria2/1.17.1\" bytes=31519292-48820795\nx.x.x.1 [05/Oct/2015:22:19:10 +0000] \"GET /bigfile HTTP/1.1\" 206 1361120 \"aria2/1.17.1\" bytes=38859324-48820795\nx.x.x.1 [05/Oct/2015:22:19:11 +0000] \"GET /bigfile HTTP/1.1\" 206 48012   \"aria2/1.17.1\" bytes=229175868-229223879\nx.x.x.1 [05/Oct/2015:22:19:11 +0000] \"GET /bigfile HTTP/1.1\" 206 62012   \"aria2/1.17.1\" bytes=0-62011\nx.x.x.1 [05/Oct/2015:22:19:11 +0000] \"GET /bigfile HTTP/1.1\" 206 860112  \"aria2/1.17.1\" bytes=46199356-48820795\nx.x.x.2 [05/Oct/2015:22:26:26 +0000] \"GET /bigfile HTTP/1.1\" 206 4494592 \"aria2/1.17.1\" bytes=48820796-229223879\nx.x.x.2 [05/Oct/2015:22:26:54 +0000] \"GET /bigfile HTTP/1.1\" 206 5198320 \"aria2/1.17.1\" bytes=54063676-229223879\nx.x.x.2 [05/Oct/2015:22:27:01 +0000] \"GET /bigfile HTTP/1.1\" 206 1375600 \"aria2/1.17.1\" bytes=143192636-229223879\nx.x.x.2 [05/Oct/2015:22:27:03 +0000] \"GET /bigfile HTTP/1.1\" 206 860112  \"aria2/1.17.1\" bytes=177271356-229223879\nx.x.x.2 [05/Oct/2015:22:27:17 +0000] \"GET /bigfile HTTP/1.1\" 206 3478096 \"aria2/1.17.1\" bytes=27324988-48820795\nx.x.x.2 [05/Oct/2015:22:27:19 +0000] \"GET /bigfile HTTP/1.1\" 206 860112  \"aria2/1.17.1\" bytes=31519292-48820795\nx.x.x.2 [05/Oct/2015:22:27:21 +0000] \"GET /bigfile HTTP/1.1\" 206 524288  \"aria2/1.17.1\" bytes=34665020-35189307\nx.x.x.2 [05/Oct/2015:22:27:29 +0000] \"GET /bigfile HTTP/1.1\" 206 62012   \"aria2/1.17.1\" bytes=0-62011\nx.x.x.3 [05/Oct/2015:22:26:56 +0000] \"GET /bigfile HTTP/1.1\" 206 8169616 \"aria2/1.17.1\" bytes=48820796-229223879\nx.x.x.3 [05/Oct/2015:22:26:59 +0000] \"GET /bigfile HTTP/1.1\" 206 871696  \"aria2/1.17.1\" bytes=121696828-229223879\nx.x.x.3 [05/Oct/2015:22:27:03 +0000] \"GET /bigfile HTTP/1.1\" 206 1002016 \"aria2/1.17.1\" bytes=123269692-229223879\nx.x.x.3 [05/Oct/2015:22:27:12 +0000] \"GET /bigfile HTTP/1.1\" 206 1891088 \"aria2/1.17.1\" bytes=179892796-229223879\nx.x.x.3 [05/Oct/2015:22:27:25 +0000] \"GET /bigfile HTTP/1.1\" 206 2525312 \"aria2/1.17.1\" bytes=19460668-48820795\nx.x.x.3 [05/Oct/2015:22:27:28 +0000] \"GET /bigfile HTTP/1.1\" 206 62012   \"aria2/1.17.1\" bytes=0-62011\n```\nHow does aria map a torrent block to a range request? It looks like it is grouping them together (with both the old and the new version)? Would be great if you could explain that process a bit.\nThanks!\n. @tatsuhiro-t @imoverclocked\nFYI, this was well tested on my side here now and yes, it does only randomize the files. But it does speed up our downloads by a significant percentage!\nMaybe the randomizing block approach might be feasible in the future, given that it probably would speed up multiple concurrent downloads even more..\n@tatsuhiro-t Do you think you can merge this into mainline?\n. Awesome, thanks!\n. ",
    "nkhdiscovery": "@tatsuhiro-t @nmaier I've a total broken system these days as I was upgrading my archlinux, I try to test this as soon as possible.\n. @ClaudiaJ @nmaier @tatsuhiro-t  I updated my kernel and it works fine now, I think I can't risk to reproduce the error right now by downgrading my kernel as I'm in the middle of my master project... Thank you guys for your quick response :) \n. ",
    "ClaudiaJ": "Branch built successfully on my Arch vm through Linode, fails with following error number:\n\ngetrandom returned an unhandled error: 38\naria2c: SimpleRandomizer.cc:93: void aria2::SimpleRandomizer::getRandomBytes(unsigned char*, size_t): Assertion `rv >= 0 && (size_t)rv == len' failed.\n. I wonder if it might be directly relating to how the kernel is managed on Linode configurations. I haven't reboot into anything newer than the following in almost a month and a half:\nLinux dev 3.16.7-x86_64-linode49 #3 SMP Fri Nov 14 16:55:37 EST 2014 x86_64 GNU/Linux\n\nA description of how Linode's kernels are handled can be found here\n. Branch is built successfully on my Linode vm, and a quick test download of some diff from gist is also successful.\nI'll also pick up a newer kernel this weekend.\n. ",
    "remitamine": "i'm sorry i didn't know about it,thanks.\n. ",
    "balta2ar": "I'd like that feature too.\n. Thanks a lot! It works indeed with that option.\nEDIT: Do you think it could be emphasized somewhere? Maybe a separate paragraph about Tor in a docs, or a hint from the aria2c itself?\n. ",
    "IGI-111": "I have been searching for this feature, i know sequential downloads mess up the swarm but it's needed for streaming media.\nI'd go as far as try to implement it, but i'm not familiar enough with the codebase to know if that'd be hard to add.\n. ",
    "rabbitsmith": "same problem here. somebody please help us.\n. no torrents work for me. the torrent has a public tracker but does not work in windows 64bit official aria2.exe. works fine in utorrent running from the same machine. any help will be greatly appreciated.thanks\n. magnet:?\nxt=urn:btih:7E0EFAA92EA265041F422A36410ED00FE59B4CB5&dn=\nmicrosoft+visual+studio+community+2015+rc+fr3aky\n+phantom&tr=udp%3A%2F%2Fopen.demonii.com%3A1337%\n2Fannounce\nbtw it is legal torrent. ms vs2015 community edition iso is free. it is also available on mictosoft website.\n. You're right, I found an answer. But my question is, could you name another BitTorrent client which accepts magnets \n, downloads metadata, but on restart, redownloads it again?\nWhy not implement this simple replacement while saving the session data?\n. Using a separate directory like .aria2 to store control files and metadata files would be nice.. Try creating an empty log file manually and then starting aria2. ",
    "mouradski": "same problem :( \nwhen i download a .torrent file from kick ass, it works, but the magnet lik of the same torrent never starts download and seed = 0\nhelp please \n. Fixed : add --follow-torrent=mem option :)\n. ",
    "dofine": "Same problem ...\n. ",
    "scytalezero": "I am having this problem as well and have tested with several magnets that worked fine in qBittorrent. Adding the \"follow-torrent=mem\" option did not solve the problem for me.\n. I am having this problem as well and have tested with several magnets that worked fine in qBittorrent. \n. I think that you should move away from sf.net. Personally, I just don't trust them anymore and I always second-guess files I download from them.\n. Here are the last moments of the log file before the process ran away:\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCacheEntry.cc:96] WrDiskCacheEntry cache goff=266238728, len=16384\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCache.cc:100] Update cache entry size=965384, delta=16384, clock=196378\n2015-08-03 23:24:20.865082 [DEBUG] [AbstractCommand.cc:187] CUID#1339 - socket: read:1, write:0, hup:0, err:0\n2015-08-03 23:24:20.865082 [DEBUG] [WinTLSSession.cc:452] WinTLS: Read request: 16384 buffered: 4067\n2015-08-03 23:24:20.865082 [DEBUG] [Piece.cc:356] updateWrCache entry=0000000002116520\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCacheEntry.cc:96] WrDiskCacheEntry cache goff=266255112, len=16384\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCache.cc:100] Update cache entry size=981768, delta=16384, clock=196379\n2015-08-03 23:24:20.865082 [DEBUG] [AbstractCommand.cc:187] CUID#1339 - socket: read:1, write:0, hup:0, err:0\n2015-08-03 23:24:20.865082 [DEBUG] [WinTLSSession.cc:452] WinTLS: Read request: 16384 buffered: 4067\n2015-08-03 23:24:20.865082 [DEBUG] [Piece.cc:356] updateWrCache entry=0000000002116520\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCacheEntry.cc:96] WrDiskCacheEntry cache goff=266271496, len=16384\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCache.cc:100] Update cache entry size=998152, delta=16384, clock=196380\n2015-08-03 23:24:20.865082 [DEBUG] [AbstractCommand.cc:187] CUID#1339 - socket: read:1, write:0, hup:0, err:0\n2015-08-03 23:24:20.865082 [DEBUG] [WinTLSSession.cc:452] WinTLS: Read request: 16384 buffered: 4067\n2015-08-03 23:24:20.865082 [DEBUG] [Piece.cc:356] updateWrCache entry=0000000002116520\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCacheEntry.cc:96] WrDiskCacheEntry cache goff=266287880, len=16384\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCache.cc:100] Update cache entry size=1014536, delta=16384, clock=196381\n2015-08-03 23:24:20.865082 [DEBUG] [AbstractCommand.cc:187] CUID#1339 - socket: read:1, write:0, hup:0, err:0\n2015-08-03 23:24:20.865082 [DEBUG] [WinTLSSession.cc:452] WinTLS: Read request: 16384 buffered: 4067\n2015-08-03 23:24:20.865082 [DEBUG] [Piece.cc:356] updateWrCache entry=0000000002116520\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCacheEntry.cc:96] WrDiskCacheEntry cache goff=266304264, len=16384\n2015-08-03 23:24:20.865082 [DEBUG] [WrDiskCache.cc:100] Update cache entry size=1030920, delta=16384, clock=196382\n2015-08-03 23:24:20.865082 [DEBUG] [AbstractCommand.cc:187] CUID#1339 - socket: read:1, write:0, hup:0, err:0\n2015-08-03 23:24:20.865082 [DEBUG] [WinTLSSession.cc:452] WinTLS: Read request: 16384 buffered: 4067\n2015-08-03 23:24:20.866082 [DEBUG] [WinTLSSession.cc:513] WinTLS: Connection abruptly closed!\n2015-08-03 23:24:20.866082 [DEBUG] [WinTLSSession.cc:193] WinTLS: Closing connection\n2015-08-03 23:24:20.866082 [DEBUG] [WinTLSSession.cc:301] WinTLS: Write request: 31 buffered: 0\n. I've been playing with my settings to see what I might have changed that started this issue occurring. After playing around with file allocation and some other settings, I found that after commenting this line in my config I cannot reproduce the hang:\nmax-overall-download-limit=3M\n. No, thank you. Did I mention that I love Aria2? It really is awesome, especially for people like me that do lots of scripting and automation. The RPC interface is super - I have it integrated into my home automation UI and can easily send downloads to it from anywhere. The event hooks let me run a script that renames and categorizes things on my server. This is actually the first time I've ever noticed any bug in Aria2 at all, and I use the hell out of it.\nAnyway, I just wanted to say thanks for the time you spend on this awesome utility.\n. Thanks for the fast response!\n. I installed the latest release and did some testing today. So far I'm not able to recreate the loop after re-enabling max-overall-download-limit, so I'm closing this issue.\n. Sorry to say that I am still experiencing this problem. It definitely only happens when I have max-overall-download-limit set in my config.\n. I have only seen this happen with HTTPS, but that is mostly what I download through Aria2.\n. As of the latest release, I am still experiencing this issue. For reproduction, I suggest the following:\n1) Set 'max-overall-download-limit' in your config file to some percentage of your full bandwidth.\n2) Allow for a few concurrent downloads (I use 3).\n2) Run Aria2 in RPC listen mode.\n3) Throw a lot of Youtube video links at it. They will all be HTTPS. At some point during the process, Aria2 will likely enter a loop and become unresponsive.\n. I'm on Windows Server 2012 R2 x64.\n. Oh sorry! I am using aria2 x64.\n. Personally I've had to discontinue using max-overall-download-limit.\n. ",
    "i336": "Thanks for following this up, and thanks for the update! :)\n@nmaier: Yeah, I've noticed the rate throttling when an invalid secret token is used :) it's a good security feature!\nI'll admit my setup is notably older than most people's but the PCs and router in question appear to be able to sustain 10.7MB/s network throughput so my LAN is definitely capable of handling this.\nIt's the 100-300KB/s local (loopback/lo0) speed that has me stumped. One might conclude that it's a hardware processing speed limit - the box I had aria2c running on (slowly leeching files from a remote server while my internet was shaped to unlimited 256kbps last month :P) was an old spare PC I cobbled together from random parts that were lying around, including 100MHz SDRAM - but that said, aria2c WAS only using 1-6% CPU time at the most (ie, I never saw it use 7%), and asking aria2c repeatedly for RPC data didn't push the figure any higher. And so when I saw the RPC response was being quite visibly, noticeably throttled, I immediately thought of software rate-limiting.\n@tatsuhiro-t: I actually submitted this issue after learning how to use the key parameter, but finding the RPC reponse was still sufficiently large to trigger... whatever was happening here... because I needed to include the filename information (which of course lists the full path... repeatedly, for as many splits as have been configured); I found that if the RPC response was less than 10KB or so (IIRC) it returns instantaneously, but if it's over that it seems to throttle the output, leading me to believe some part of the code was implementing a form of response chunking.\nI'll be away from the computer for the next couple/few days, but before I go, I'm happy to setup SSH access if poking around and testing on the actual hardware in question sounds like a constructive idea (it's always my own preference, at least). When I come back I'll probably do some further testing/analysis myself too.\nOh, and I was using aria2c Git revision 649c49dcc675a26dd2b7598c09fc3e3539b5ef88, dated Feb 21 2015 - the old version of aria2c I'd installed via my package manager was segfaulting when I repeatedly executed aria2.pauseAll and aria2.unpauseAll for dozens of simultaneous downloads. The Git version had no such issues. :D\n. I figured I wouldn't be waiting too long to test aria2c under the exact same conditions of my original issue - downloading slowly from a remote machine over shaped internet - so I thought I'd hold for a couple extra days before I replied. (I'm switching ISPs soon. =P lol)\nI just fired aria2c back up after verifying I had the latest checkout then rebuilding, and I now receive 1MB-4MB RPC responses over the LAN within 700ms-1 second, and over lo with equivalent speed as well. I'm guessing the remaining delay is caused by aria2c collecting the requisite data and compiling the JSON/XML response on the slow CPU in question - the output itself is delayless now, regardless of whether I query aria2.tellWaiting(1,3000) or aria2.tellActive().\nI consider this now fixed, and I've taken the liberty of closing it. Thanks very much! :)\n(Also, I'm curious - I took a look at the committed code fragment... and if I understand it correctly, was the code responsible for sending RPC responses doing so with noticeable delays because the same process space was servicing all of the actual download requests in question, but without checking whether RPC response data was queued...?\n. ",
    "Denisov39": "No, bt-max-open-files=200 statically in config file.\n. Today.\nActive torrents - 5\nFiles total in torrents - 150\nbt-max-open-files=200\nCrash.\n```\nProgram received signal SIGABRT, Aborted.\n0x00007f6dd22d0165 in *__GI_raise (sig=) at ../nptl/sysdeps/unix/sysv/linux/raise.c:64\n64      ../nptl/sysdeps/unix/sysv/linux/raise.c: \u041d\u0435\u0442 \u0442\u0430\u043a\u043e\u0433\u043e \u0444\u0430\u0439\u043b\u0430 \u0438\u043b\u0438 \u043a\u0430\u0442\u0430\u043b\u043e\u0433\u0430.\n(gdb) bt\n0  0x00007f6dd22d0165 in *__GI_raise (sig=) at ../nptl/sysdeps/unix/sysv/linux/raise.c:64\n1  0x00007f6dd22d33e0 in *__GI_abort () at abort.c:92\n2  0x00007f6dd22c9311 in *__GI___assert_fail (assertion=0x75e515 \"left == 0\", file=, line=100,\nfunction=0x75e5a0 \"void aria2::OpenedFileCounter::ensureMaxOpenFileLimit(size_t)\") at assert.c:81\n\n3  0x00000000004f7617 in aria2::OpenedFileCounter::ensureMaxOpenFileLimit (this=0x1d15d68, numNewFiles=1) at OpenedFileCounter.cc:100\n4  0x00000000005d20e9 in aria2::MultiDiskAdaptor::openIfNot (this=0x1d24c30, entry=0x1d2f410, open=\n(void (aria2::DiskWriterEntry::*)(aria2::DiskWriterEntry * const)) 0x5d1374 <aria2::DiskWriterEntry::openFile()>) at MultiDiskAdaptor.cc:231\n\n5  0x00000000005d21cc in aria2::MultiDiskAdaptor::openFile (this=0x1d24c30) at MultiDiskAdaptor.cc:250\n6  0x00000000004899b2 in aria2::RequestGroup::createInitialCommand (this=0x1fe8678, commands=..., e=0x1c6c630) at RequestGroup.cc:425\n7  0x00000000004a3125 in aria2::(anonymous namespace)::createInitialCommand (requestGroup=..., e=0x1c6c630) at RequestGroupMan.cc:455\n8  0x00000000004a34f8 in aria2::RequestGroupMan::fillRequestGroupFromReserver (this=0x1c60510, e=0x1c6c630) at RequestGroupMan.cc:501\n9  0x00000000005c1894 in aria2::FillRequestGroupCommand::execute (this=0x1e3da50) at FillRequestGroupCommand.cc:71\n10 0x00000000005a7ed0 in aria2::(anonymous namespace)::executeCommand (commands=..., statusFilter=aria2::Command::STATUS_ALL) at DownloadEngine.cc:135\n11 0x00000000005a807c in aria2::DownloadEngine::run (this=0x1c6c630, oneshot=false) at DownloadEngine.cc:175\n12 0x000000000046b08e in aria2::MultiUrlRequestInfo::execute (this=0x1c60c48) at MultiUrlRequestInfo.cc:358\n13 0x000000000042700e in aria2::main (argc=2, argv=0x7fffb7105698) at main.cc:78\n14 0x0000000000427094 in main (argc=2, argv=0x7fffb7105698) at main.cc:91\n```\n. I see this bug permanently for last 2 years.\n. I will try on this week.\n. 2 days without incident. Watch.\n. 6 days without incidents. Fixed !\n. No, I still can not reproduce the problem. but I can enable log-level=debug if it will help you.\n. Debian GNU/Linux stable\nUsing built-in specs.\nCOLLECT_GCC=gcc\nCOLLECT_LTO_WRAPPER=/usr/lib/gcc/x86_64-linux-gnu/4.9/lto-wrapper\nTarget: x86_64-linux-gnu\nConfigured with: ../src/configure -v --with-pkgversion='Debian 4.9.2-10' --with-bugurl=file:///usr/share/doc/gcc-4.9/README.Bugs --enable-languages=c,c++,java,go,d,fortran,objc,obj-c++ --prefix=/usr --program-suffix=-4.9 --enable-shared --enable-linker-build-id --libexecdir=/usr/lib --without-included-gettext --enable-threads=posix --with-gxx-include-dir=/usr/include/c++/4.9 --libdir=/usr/lib --enable-nls --with-sysroot=/ --enable-clocale=gnu --enable-libstdcxx-debug --enable-libstdcxx-time=yes --enable-gnu-unique-object --disable-vtable-verify --enable-plugin --with-system-zlib --disable-browser-plugin --enable-java-awt=gtk --enable-gtk-cairo --with-java-home=/usr/lib/jvm/java-1.5.0-gcj-4.9-amd64/jre --enable-java-home --with-jvm-root-dir=/usr/lib/jvm/java-1.5.0-gcj-4.9-amd64 --with-jvm-jar-dir=/usr/lib/jvm-exports/java-1.5.0-gcj-4.9-amd64 --with-arch-directory=amd64 --with-ecj-jar=/usr/share/java/eclipse-ecj.jar --enable-objc-gc --enable-multiarch --with-arch-32=i586 --with-abi=m64 --with-multilib-list=m32,m64,mx32 --enable-multilib --with-tune=generic --enable-checking=release --build=x86_64-linux-gnu --host=x86_64-linux-gnu --target=x86_64-linux-gnu\nThread model: posix\ngcc version 4.9.2 (Debian 4.9.2-10)\n. Since i set 15 (https://github.com/aria2/aria2/issues/653) - error is gone.\n. I try set 15, build it and run. I add 1 magnet to aria2c. Downloaded. Active downloads are no more. But in log i see this\n016-05-19 11:08:29.965827 [INFO] [DHTMessageDispatcherImpl.cc:79] Message sent: dht query find_node TransactionID=e1f9a9c3 Remote:95.147.61.41(42480), id=b3b023f1e786d84406215a02405556849ddb3352, v=A2%00%03, ta\nrgetNodeID=b3b0236f12ff5aeb1f04cc7f0b9af4d4af68a3e2\n2016-05-19 11:08:29.965836 [DEBUG] [DHTMessageDispatcherImpl.cc:111] 0 dht messages remaining in the queue.\n2016-05-19 11:08:29.969271 [DEBUG] [DHTTaskQueueImpl.cc:57] Updating periodicTaskQueue1\n2016-05-19 11:08:29.969293 [DEBUG] [DHTTaskExecutor.cc:77] Executing 15 Task(s). Queue has 39 task(s).\n2016-05-19 11:08:29.969299 [DEBUG] [DHTTaskQueueImpl.cc:59] Updating periodicTaskQueue2\n2016-05-19 11:08:29.969305 [DEBUG] [DHTTaskExecutor.cc:77] Executing 0 Task(s). Queue has 0 task(s).\n2016-05-19 11:08:29.969310 [DEBUG] [DHTTaskQueueImpl.cc:61] Updating immediateTaskQueue\n2016-05-19 11:08:29.969315 [DEBUG] [DHTTaskExecutor.cc:77] Executing 0 Task(s). Queue has 0 task(s).\n2016-05-19 11:08:29.969353 [DEBUG] [DHTMessageTracker.cc:79] Searching tracker entry for TransactionID=a6168f3f, Remote=95.147.61.41:42480\n2016-05-19 11:08:29.969361 [DEBUG] [DHTMessageTracker.cc:84] Tracker entry found.\n2016-05-19 11:08:29.969379 [DEBUG] [DHTMessageTracker.cc:94] RTT is 52\n2016-05-19 11:08:29.969386 [DEBUG] [DHTMessageTracker.cc:103] Node ID has changed: old:b3b023f1e786d84406215a02405556849ddb3352, new:b3b02132c3359ca1979238f66024025835effde2\n2016-05-19 11:08:29.969408 [INFO] [DHTMessageReceiver.cc:123] Message received: dht response find_node TransactionID=a6168f3f Remote:95.147.61.41(42480), id=b3b02132c3359ca1979238f66024025835effde2, v=UT%A4n, no\ndes=8\n2016-05-19 11:08:29.969417 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b0235f4ac685df7e4fc3e28358a0a47324a582, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:29.969426 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b0230011bfc18af1e3475e8151e50c21b722ca, Host=95.134.211.191(15706), Condition=1, RTT=0\n2016-05-19 11:08:29.969434 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b023f1e786d84406215a02405556849ddb3352, Host=95.147.61.41(42480), Condition=1, RTT=0\n2016-05-19 11:08:29.969475 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b02385943e6e46b304f759b5890b7a7cf5bc32, Host=95.147.61.41(42480), Condition=1, RTT=0\n2016-05-19 11:08:29.969486 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b0226fa5901dbc78276303982e5d2d1600468a, Host=95.147.61.41(42480), Condition=1, RTT=0\n2016-05-19 11:08:29.969494 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b022602fa93886da9ad4a6e09017b0878e847a, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:29.969501 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b022df31eb593174b77b79d23864bb50354b3a, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:29.969509 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b022ac3bf7370ef952a77cb06ed89a84a6487a, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:29.969516 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b02132c3359ca1979238f66024025835effde2, Host=95.147.61.41(42480), Condition=0, RTT=52\n2016-05-19 11:08:29.969524 [DEBUG] [DHTRoutingTable.cc:104] Cached node=DHTNode ID=b3b02132c3359ca1979238f66024025835effde2, Host=95.147.61.41(42480), Condition=0, RTT=52\n2016-05-19 11:08:29.969533 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b0235f4ac685df7e4fc3e28358a0a47324a582, ip=95.147.61.41\n2016-05-19 11:08:29.969545 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b0230011bfc18af1e3475e8151e50c21b722ca, ip=95.134.211.191\n2016-05-19 11:08:29.969551 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b023f1e786d84406215a02405556849ddb3352, ip=95.147.61.41\n2016-05-19 11:08:29.969556 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b02385943e6e46b304f759b5890b7a7cf5bc32, ip=95.147.61.41\n2016-05-19 11:08:29.969562 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b0226fa5901dbc78276303982e5d2d1600468a, ip=95.147.61.41\n2016-05-19 11:08:29.969567 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b022602fa93886da9ad4a6e09017b0878e847a, ip=95.147.61.41\n2016-05-19 11:08:29.969573 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b022df31eb593174b77b79d23864bb50354b3a, ip=95.147.61.41\n2016-05-19 11:08:29.969578 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b022ac3bf7370ef952a77cb06ed89a84a6487a, ip=95.147.61.41\n2016-05-19 11:08:29.969584 [DEBUG] [DHTAbstractNodeLookupTask.h:196] 8 node lookup entries added.\n2016-05-19 11:08:29.969595 [DEBUG] [DHTAbstractNodeLookupTask.h:204] 9 node lookup entries are unique.\n2016-05-19 11:08:29.969604 [DEBUG] [DHTAbstractNodeLookupTask.h:111] 3 in flight message for node ID b3b0236f12ff5aeb1f04cc7f0b9af4d4af68a3e2\n2016-05-19 11:08:29.969655 [INFO] [DHTMessageDispatcherImpl.cc:79] Message sent: dht query find_node TransactionID=35ce01f6 Remote:95.147.61.41(42480), id=b3b023f1e786d84406215a02405556849ddb3352, v=A2%00%03, ta\nrgetNodeID=b3b0236f12ff5aeb1f04cc7f0b9af4d4af68a3e2\n2016-05-19 11:08:29.969665 [DEBUG] [DHTMessageDispatcherImpl.cc:111] 0 dht messages remaining in the queue.\n2016-05-19 11:08:30.012638 [DEBUG] [DHTTaskQueueImpl.cc:57] Updating periodicTaskQueue1\n2016-05-19 11:08:30.012673 [DEBUG] [DHTTaskExecutor.cc:77] Executing 15 Task(s). Queue has 39 task(s).\n2016-05-19 11:08:30.012688 [DEBUG] [DHTTaskQueueImpl.cc:59] Updating periodicTaskQueue2\n2016-05-19 11:08:30.012695 [DEBUG] [DHTTaskExecutor.cc:77] Executing 0 Task(s). Queue has 0 task(s).\n2016-05-19 11:08:30.012701 [DEBUG] [DHTTaskQueueImpl.cc:61] Updating immediateTaskQueue\n2016-05-19 11:08:30.012706 [DEBUG] [DHTTaskExecutor.cc:77] Executing 0 Task(s). Queue has 0 task(s).\n2016-05-19 11:08:30.012764 [DEBUG] [DHTMessageTracker.cc:79] Searching tracker entry for TransactionID=e1f9a9c3, Remote=95.147.61.41:42480\n2016-05-19 11:08:30.012775 [DEBUG] [DHTMessageTracker.cc:84] Tracker entry found.\n2016-05-19 11:08:30.012806 [DEBUG] [DHTMessageTracker.cc:94] RTT is 47\n2016-05-19 11:08:30.012813 [DEBUG] [DHTMessageTracker.cc:103] Node ID has changed: old:b3b023f1e786d84406215a02405556849ddb3352, new:b3b02132c3359ca1979238f66024025835effde2\n2016-05-19 11:08:30.012826 [INFO] [DHTMessageReceiver.cc:123] Message received: dht response find_node TransactionID=e1f9a9c3 Remote:95.147.61.41(42480), id=b3b02132c3359ca1979238f66024025835effde2, v=UT%A4n, no\ndes=8\n2016-05-19 11:08:30.012835 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b0235f4ac685df7e4fc3e28358a0a47324a582, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:30.012844 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b0230011bfc18af1e3475e8151e50c21b722ca, Host=95.134.211.191(15706), Condition=1, RTT=0\n2016-05-19 11:08:30.012852 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b023f1e786d84406215a02405556849ddb3352, Host=95.147.61.41(42480), Condition=1, RTT=0\n2016-05-19 11:08:30.012859 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b02385943e6e46b304f759b5890b7a7cf5bc32, Host=95.147.61.41(42480), Condition=1, RTT=0\n2016-05-19 11:08:30.012867 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b0226fa5901dbc78276303982e5d2d1600468a, Host=95.147.61.41(42480), Condition=1, RTT=0\n2016-05-19 11:08:30.012874 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b022602fa93886da9ad4a6e09017b0878e847a, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:30.012882 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b022df31eb593174b77b79d23864bb50354b3a, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:30.012890 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b022ac3bf7370ef952a77cb06ed89a84a6487a, Host=95.147.61.41(13486), Condition=1, RTT=0\n2016-05-19 11:08:30.012897 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b02132c3359ca1979238f66024025835effde2, Host=95.147.61.41(42480), Condition=0, RTT=47\n2016-05-19 11:08:30.012919 [DEBUG] [DHTRoutingTable.cc:104] Cached node=DHTNode ID=b3b02132c3359ca1979238f66024025835effde2, Host=95.147.61.41(42480), Condition=0, RTT=47\n2016-05-19 11:08:30.012929 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b0235f4ac685df7e4fc3e28358a0a47324a582, ip=95.147.61.41\n2016-05-19 11:08:30.012935 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b0230011bfc18af1e3475e8151e50c21b722ca, ip=95.134.211.191\n2016-05-19 11:08:30.012947 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b023f1e786d84406215a02405556849ddb3352, ip=95.147.61.41\n2016-05-19 11:08:30.012953 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b02385943e6e46b304f759b5890b7a7cf5bc32, ip=95.147.61.41\n2016-05-19 11:08:30.012959 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b0226fa5901dbc78276303982e5d2d1600468a, ip=95.147.61.41\n2016-05-19 11:08:30.012964 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b022602fa93886da9ad4a6e09017b0878e847a, ip=95.147.61.41\n2016-05-19 11:08:30.012970 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b022df31eb593174b77b79d23864bb50354b3a, ip=95.147.61.41\n2016-05-19 11:08:30.012975 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b022ac3bf7370ef952a77cb06ed89a84a6487a, ip=95.147.61.41\n2016-05-19 11:08:30.012981 [DEBUG] [DHTAbstractNodeLookupTask.h:196] 8 node lookup entries added.\n2016-05-19 11:08:30.013005 [DEBUG] [DHTAbstractNodeLookupTask.h:204] 9 node lookup entries are unique.\n2016-05-19 11:08:30.013015 [DEBUG] [DHTAbstractNodeLookupTask.h:111] 3 in flight message for node ID b3b0236f12ff5aeb1f04cc7f0b9af4d4af68a3e2\n2016-05-19 11:08:30.013039 [DEBUG] [DHTMessageTracker.cc:79] Searching tracker entry for TransactionID=5768314a, Remote=95.147.61.41:13486\n2016-05-19 11:08:30.966528 [INFO] [DHTMessageDispatcherImpl.cc:79] Message sent: dht query find_node TransactionID=ef5fdc2b Remote:95.147.61.41(42480), id=b3b023f1e786d84406215a02405556849ddb3352, v=A2%00%03, ta\nrgetNodeID=b3b0236f12ff5aeb1f04cc7f0b9af4d4af68a3e2\n2016-05-19 11:08:30.966539 [DEBUG] [DHTMessageDispatcherImpl.cc:111] 0 dht messages remaining in the queue.\n2016-05-19 11:08:30.975644 [DEBUG] [DHTTaskQueueImpl.cc:57] Updating periodicTaskQueue1\n2016-05-19 11:08:30.975668 [DEBUG] [DHTTaskExecutor.cc:77] Executing 15 Task(s). Queue has 38 task(s).\n2016-05-19 11:08:30.975675 [DEBUG] [DHTTaskQueueImpl.cc:59] Updating periodicTaskQueue2\n2016-05-19 11:08:30.975681 [DEBUG] [DHTTaskExecutor.cc:77] Executing 0 Task(s). Queue has 0 task(s).\n2016-05-19 11:08:30.975686 [DEBUG] [DHTTaskQueueImpl.cc:61] Updating immediateTaskQueue\n2016-05-19 11:08:30.975691 [DEBUG] [DHTTaskExecutor.cc:77] Executing 0 Task(s). Queue has 0 task(s).\n2016-05-19 11:08:30.975721 [DEBUG] [DHTMessageTracker.cc:79] Searching tracker entry for TransactionID=e400dfe2, Remote=176.189.65.230:40500\n2016-05-19 11:08:30.975730 [DEBUG] [DHTMessageTracker.cc:84] Tracker entry found.\n2016-05-19 11:08:30.975750 [DEBUG] [DHTMessageTracker.cc:94] RTT is 70\n2016-05-19 11:08:30.975763 [INFO] [DHTMessageReceiver.cc:123] Message received: dht response find_node TransactionID=e400dfe2 Remote:176.189.65.230(40500), id=b3b9131da72d4b24c32661ad689009bc85f60fd7, v=LT%01%00\n, nodes=8\n2016-05-19 11:08:30.975771 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b91345f633a6c040c88640ee1d214f0a2c23ff, Host=212.253.129.230(27965), Condition=1, RTT=0\n2016-05-19 11:08:30.975780 [DEBUG] [DHTRoutingTable.cc:85] Added DHTNode.\n2016-05-19 11:08:30.975797 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b913c20aa4f45e00a58819aa56a768faf46848, Host=46.242.52.53(19728), Condition=1, RTT=0\n2016-05-19 11:08:30.975806 [DEBUG] [DHTRoutingTable.cc:85] Added DHTNode.\n2016-05-19 11:08:30.975813 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b9131da72d4b24c3267649f6de788d0515b898, Host=69.30.199.170(6881), Condition=1, RTT=0\n2016-05-19 11:08:30.975819 [DEBUG] [DHTRoutingTable.cc:85] Added DHTNode.\n2016-05-19 11:08:30.975826 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b9131da72d4b24c32631d9b6399cf69252ba10, Host=85.25.237.46(6883), Condition=1, RTT=0\n2016-05-19 11:08:30.975832 [DEBUG] [DHTRoutingTable.cc:85] Added DHTNode.\n2016-05-19 11:08:30.975839 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b913c3ad33f92fbabb76a5c7c8110fe2e52558, Host=2.50.52.53(6881), Condition=1, RTT=0\n2016-05-19 11:08:30.975846 [DEBUG] [DHTRoutingTable.cc:85] Added DHTNode.\n2016-05-19 11:08:30.975852 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b9131da72d4b24c32628fbe983b9e31021f5eb, Host=142.54.178.178(6881), Condition=1, RTT=0\n2016-05-19 11:08:30.975861 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b9131da72d4b24c326819125c847d86d73b296, Host=195.154.170.46(6881), Condition=1, RTT=0\n2016-05-19 11:08:30.975869 [DEBUG] [DHTRoutingTable.cc:76] Trying to add node:DHTNode ID=b3b9131da72d4b24c32661ad689009bc85f60fd7, Host=176.189.65.230(40500), Condition=0, RTT=70\n2016-05-19 11:08:30.975875 [DEBUG] [DHTRoutingTable.cc:85] Added DHTNode.\n2016-05-19 11:08:30.975885 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b91345f633a6c040c88640ee1d214f0a2c23ff, ip=212.253.129.230\n2016-05-19 11:08:30.975891 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b913c20aa4f45e00a58819aa56a768faf46848, ip=46.242.52.53\n2016-05-19 11:08:30.975897 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b9131da72d4b24c3267649f6de788d0515b898, ip=69.30.199.170\n2016-05-19 11:08:30.975903 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b9131da72d4b24c32631d9b6399cf69252ba10, ip=85.25.237.46\n2016-05-19 11:08:30.975909 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b913c3ad33f92fbabb76a5c7c8110fe2e52558, ip=2.50.52.53\n2016-05-19 11:08:30.975915 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b9131da72d4b24c32628fbe983b9e31021f5eb, ip=142.54.178.178\n2016-05-19 11:08:30.975921 [DEBUG] [DHTAbstractNodeLookupTask.h:190] Received nodes: id=b3b9131da72d4b24c326819125c847d86d73b296, ip=195.154.170.46\n2016-05-19 11:08:30.975927 [DEBUG] [DHTAbstractNodeLookupTask.h:196] 7 node lookup entries added.\n2016-05-19 11:08:30.975944 [DEBUG] [DHTAbstractNodeLookupTask.h:204] 11 node lookup entries are unique.\n2016-05-19 11:08:30.975953 [DEBUG] [DHTAbstractNodeLookupTask.h:111] 3 in flight message for node ID b3b913b3b9cd0a4026ab44abfed8ce05ab34db30\n2016-05-19 11:08:30.976016 [INFO] [DHTMessageDispatcherImpl.cc:79] Message sent: dht query find_node TransactionID=7551d1ac Remote:69.30.199.170(6881), id=b3b9131da72d4b24c3267649f6de788d0515b898, v=A2%00%03, ta\nrgetNodeID=b3b913b3b9cd0a4026ab44abfed8ce05ab34db30\nA lot of almost identical records\n [DEBUG] [DHTTaskQueueImpl.cc:57] Updating periodicTaskQueue1\n [DEBUG] [DHTTaskExecutor.cc:77] Executing 15 Task(s). Queue has 39 task(s).\nThis queue is reduced to 0, but then again becomes 111, and so it goes again and again\n. I set 15 - became much more fun. Thank you so much !\n. Two addresses in the interface can not be specified, I tried.\nIf I have many addresses and I want to download files on one external address\nAt the same time, I do not want the RPC to listen at the external address\nI want the RPC to listen at the internal address, but not at the localhost. How can I do it ?. I think that it would be more logical to make the option rpc-interface separately. . ",
    "sickHamm": "529\n. As as my primary downloader, please understand me want aria2 do everything, because aria2 use file pre-allocation, I could play the partly video file, although the video file is  downloading and not completely. but if want seek forward,aria2 will behind of player, so if aria2c support range option, I could manual select the range that I want download,\nwhen i want seek play video.\nSure, it may a too special  feature request;\n\nSorry , My English is poor. I don't know is I  expression clearly what I want.\n. ",
    "mfischer-zd": "After re-issuing the request, aria2 seems to think there are no seeders:\nFinal status of initial download (immediately after we receive an aria2.onBtDownloadComplete notification):\n``` json\n{\n   \"bitfield\":\"fffff0\",\n   \"bittorrent\":{\n      \"announceList\":[\n         [\n            \"http://10.0.0.133:6881/announce\"\n         ]\n      ],\n      \"creationDate\":1426936234,\n      \"info\":{\n         \"name\":\"git-2.3.3.tar.gz\"\n      },\n      \"mode\":\"single\"\n   },\n   \"completedLength\":\"5187306\",\n   \"connections\":\"1\",\n   \"dir\":\"/home/centos\",\n   \"downloadSpeed\":\"516406\",\n   \"files\":[\n      {\n         \"completedLength\":\"5187306\",\n         \"index\":\"1\",\n         \"length\":\"5187306\",\n         \"path\":\"/home/centos/git-2.3.3.tar.gz\",\n         \"selected\":\"true\",\n         \"uris\":[\n     ]\n  }\n\n],\n   \"gid\":\"222c1085fcbc7abe\",\n   \"infoHash\":\"a34ed4d8817c5d0673c04b1e417ea38aabd5b373\",\n   \"numPieces\":\"20\",\n   \"numSeeders\":\"1\",\n   \"pieceLength\":\"262144\",\n   \"status\":\"active\",\n   \"totalLength\":\"5187306\",\n   \"uploadLength\":\"0\",\n   \"uploadSpeed\":\"0\"\n}\n```\nStatus of subsequent torrent request (which never makes progress, and for which a aria2.onBtDownloadComplete notification is never fired):\n``` json\n{\n   \"bitfield\":\"fffff0\",\n   \"bittorrent\":{\n      \"announceList\":[\n         [\n            \"http://10.0.0.133:6881/announce\"\n         ]\n      ],\n      \"creationDate\":1426936234,\n      \"info\":{\n         \"name\":\"git-2.3.3.tar.gz\"\n      },\n      \"mode\":\"single\"\n   },\n   \"completedLength\":\"5187306\",\n   \"connections\":\"0\",\n   \"dir\":\"/home/centos\",\n   \"downloadSpeed\":\"0\",\n   \"files\":[\n      {\n         \"completedLength\":\"5187306\",\n         \"index\":\"1\",\n         \"length\":\"5187306\",\n         \"path\":\"/home/centos/git-2.3.3.tar.gz\",\n         \"selected\":\"true\",\n         \"uris\":[\n     ]\n  }\n\n],\n   \"gid\":\"09e061e7190a936d\",\n   \"infoHash\":\"a34ed4d8817c5d0673c04b1e417ea38aabd5b373\",\n   \"numPieces\":\"20\",\n   \"numSeeders\":\"0\",\n   \"pieceLength\":\"262144\",\n   \"status\":\"active\",\n   \"totalLength\":\"5187306\",\n   \"uploadLength\":\"0\",\n   \"uploadSpeed\":\"0\"\n}\n```\nQuestions: \n1. Why is numSeeders still \"1\" after the initial download is complete?  The client is now a seeder; shouldn't the value be \"2\"?\n2. Why is numSeeders \"0\" during the subsequent download?  The client is now a seeder, and the original seeder is still in the swarm; shouldn't the value be \"2\"?\n. aria2 logs during second download request:\n```\n2015-03-21 12:04:45.681800 [INFO] [AbstractHttpServerResponseCommand.cc:118] CUID#15 - HttpServer: all response transmitted.\n2015-03-21 12:04:45.685483 [INFO] [rpc_helper.cc:102] Executing RPC method aria2.addTorrent\n2015-03-21 12:04:45.685692 [INFO] [RpcMethodImpl.cc:299] Uploaded torrent data was saved as /home/centos/2240aca3b685f90196beb265fb0c72755dbdb71e.torren\nt\n2015-03-21 12:04:45.685893 [INFO] [DefaultBtProgressInfoFile.cc:393] The segment file /home/centos/git-2.3.3.tar.gz.aria2 does not exist.\n2015-03-21 12:04:45.685905 [INFO] [DefaultBtProgressInfoFile.cc:393] The segment file /home/centos/git-2.3.3.tar.gz.aria2 does not exist.\n2015-03-21 12:04:45.685938 [INFO] [CheckIntegrityDispatcherCommand.cc:60] CUID#3 - Dispatching CheckIntegrityCommand CUID#16.\n2015-03-21 12:04:45.732696 [INFO] [rpc_helper.cc:102] Executing RPC method aria2.tellStatus\n2015-03-21 12:04:45.793388 [NOTICE] [CheckIntegrityCommand.cc:77] Verification finished successfully. file=/home/centos/git-2.3.3.tar.gz\n2015-03-21 12:04:46.734936 [INFO] [rpc_helper.cc:102] Executing RPC method aria2.tellStatus\n2015-03-21 12:04:46.735129 [INFO] [TrackerWatcherCommand.cc:381] Creating tracker request group GID#1efcee11b16c14c8\n2015-03-21 12:04:46.735143 [INFO] [BtSeederStateChoke.cc:150] Seeder state, 0 choke round started\n2015-03-21 12:04:46.735176 [INFO] [HttpInitiateConnectionCommand.cc:130] CUID#20 - Connecting to 10.0.0.133:6881\n2015-03-21 12:04:46.735939 [INFO] [HttpConnection.cc:116] CUID#20 - Requesting:\nGET /announce?info_hash=%A3N%D4%D8%81%7C%5D%06s%C0K%1EA%7E%A3%8A%AB%D5%B3s&peer_id=A2%2D1%2D18%2D10%2DG%FC%3C%04%EA%2A%F6%D7%F6&uploaded=0&downloaded=0&left=0&compact=1&key=%FC%3C%04%EA%2A%F6%D7%F6&numwant=50&no_peer_id=1&port=6883&event=started&supportcrypto=1 HTTP/1.1\nUser-Agent: aria2/1.18.10\nAccept: /\nHost: 10.0.0.133:6881\n2015-03-21 12:04:46.736769 [INFO] [HttpConnection.cc:154] CUID#20 - Response received:\nHTTP/1.1 200 OK\nDate: Sat, 21 Mar 2015 12:04:46 GMT\nContent-Length: 76\nContent-Type: text/plain; charset=utf-8\nConnection: close\n2015-03-21 12:04:46.736843 [INFO] [DownloadCommand.cc:233] CUID#20 - The download for one segment completed successfully.\n2015-03-21 12:04:46.736857 [INFO] [DefaultPieceStorage.cc:477] The download was complete.\n2015-03-21 12:04:46.736918 [INFO] [DefaultBtAnnounce.cc:342] No peers6 received.\n``\n. I've noticed that aria2 no longer writes the metadata file to disk if I change the value of therpc-save-upload-metadatato\"false\"(string) instead offalse(boolean).  That solves one problem, but it's not clear from the documentation what the expected value types for each option in the JSON-RPC request are.\n. I tried changing the values ofcheck-integrityfromtrueto\"true\"andseed-ratiofrom0to\"0\"` but that didn't solve my problem.\n. Here are the options for the subsequent download, as reported by aria2.getOption:\njson\n{\n   \"allow-overwrite\":\"false\",\n   \"allow-piece-length-change\":\"false\",\n   \"always-resume\":\"true\",\n   \"async-dns\":\"true\",\n   \"auto-file-renaming\":\"true\",\n   \"bt-enable-lpd\":\"false\",\n   \"bt-force-encryption\":\"false\",\n   \"bt-hash-check-seed\":\"true\",\n   \"bt-max-peers\":\"55\",\n   \"bt-metadata-only\":\"false\",\n   \"bt-min-crypto-level\":\"plain\",\n   \"bt-remove-unselected-file\":\"false\",\n   \"bt-request-peer-speed-limit\":\"51200\",\n   \"bt-require-crypto\":\"false\",\n   \"bt-save-metadata\":\"false\",\n   \"bt-seed-unverified\":\"false\",\n   \"bt-stop-timeout\":\"0\",\n   \"bt-tracker-connect-timeout\":\"60\",\n   \"bt-tracker-interval\":\"0\",\n   \"bt-tracker-timeout\":\"60\",\n   \"check-integrity\":\"true\",\n   \"conditional-get\":\"false\",\n   \"connect-timeout\":\"60\",\n   \"continue\":\"false\",\n   \"dir\":\"/home/centos\",\n   \"dry-run\":\"false\",\n   \"enable-http-keep-alive\":\"true\",\n   \"enable-http-pipelining\":\"false\",\n   \"enable-mmap\":\"false\",\n   \"enable-peer-exchange\":\"false\",\n   \"file-allocation\":\"prealloc\",\n   \"follow-metalink\":\"true\",\n   \"follow-torrent\":\"true\",\n   \"force-save\":\"false\",\n   \"ftp-pasv\":\"true\",\n   \"ftp-reuse-connection\":\"true\",\n   \"ftp-type\":\"binary\",\n   \"hash-check-only\":\"false\",\n   \"http-accept-gzip\":\"false\",\n   \"http-auth-challenge\":\"false\",\n   \"http-no-cache\":\"false\",\n   \"lowest-speed-limit\":\"0\",\n   \"max-connection-per-server\":\"1\",\n   \"max-download-limit\":\"0\",\n   \"max-file-not-found\":\"0\",\n   \"max-resume-failure-tries\":\"0\",\n   \"max-tries\":\"5\",\n   \"max-upload-limit\":\"0\",\n   \"metalink-enable-unique-protocol\":\"true\",\n   \"metalink-preferred-protocol\":\"none\",\n   \"min-split-size\":\"20971520\",\n   \"no-file-allocation-limit\":\"5242880\",\n   \"no-netrc\":\"false\",\n   \"parameterized-uri\":\"false\",\n   \"pause-metadata\":\"false\",\n   \"piece-length\":\"1048576\",\n   \"proxy-method\":\"get\",\n   \"realtime-chunk-checksum\":\"true\",\n   \"remote-time\":\"false\",\n   \"remove-control-file\":\"false\",\n   \"retry-wait\":\"0\",\n   \"reuse-uri\":\"true\",\n   \"rpc-save-upload-metadata\":\"false\",\n   \"seed-ratio\":\"0\",\n   \"split\":\"5\",\n   \"stream-piece-selector\":\"default\",\n   \"timeout\":\"60\",\n   \"uri-selector\":\"feedback\",\n   \"use-head\":\"false\",\n   \"user-agent\":\"aria2/1.18.10\"\n}\n. Thank you - looking forward to a fix.\n. In the second case, shouldn't the number of connections also be 1, then?  My expectation is that the behavior when the second time the torrent is added (even though it's now just seeding since it didn't need to be re-downloaded) should be identical to the state after the first time the torrent has completed downloading and is seeding.\n. I'm puzzled, then, because the number of connections after the peer transitioned to seeding mode on the first download was 1, not 0.\n. The only two peers in this test are both Aria2 clients (same version).\n. Correct.  Looking forward to a fix.\n. Yes - I only mentioned numSeeders as I suspected that its value and the lack of notification were related, but I was apparently incorrect.\nI applied your patch to the CentOS 7 extras RPM.  It appears to resolve the problem.  Many thanks for the quick response.\n. ",
    "Javran": "Thanks!\n. ",
    "umair84": "Hi fuqet, \nWould you please paste here the complete command you are running and error message? It would be more helpful to debug the issue then.\n. ",
    "fuqet": "Im add torrent file to download. Im using debian, and im geting this error  [InitiateConnectionCommandFactory.cc:86] errorCode=1 https is not supported yet.\nAddress in my torrent file is https not http. \nHow can I fix it? Thanks for your help.\n. ",
    "adaaaaaa": "I'm suffering the same problem too. Have you solved that? help me.... aria2version.txt\nlike this? @tatsuhiro-t . after \n1\\fix missing libraries \n2\\make uninstall aria2\n3./configure\n4\\make && make install\ni successfully solve the problem!!haha!. where is 1.33?\n\n. it's OK to download with other tool...\naria2 error output below:\n[root@PandoraBox_7D29:/usr]#aria2c ftp://ygdy8:ygdy8@y201.dygod.org:1224/[ww\nw.ygdy8.com]..BD.720p..rmvb\n10/18 16:29:49 [NOTICE] Downloading 1 item(s)\n10/18 16:29:49 [ERROR] CUID#7 - Download aborted. URI=ftp://ygdy8:ygdy8@y201.dygod.org:1224/[%E9%98%B3%E5%85%89%E7%94%B5%E5%BD%B1www.ygdy8.com].%E5%B8%95%E4%B8%81%E9%A1%BF%E7%86%8A.BD.720p.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97%E5%B9%95.rmvb\nException: [AbstractCommand.cc:351] errorCode=19 URI=ftp://ygdy8:ygdy8@y201.dygod.org:1224/[%E9%98%B3%E5%85%89%E7%94%B5%E5%BD%B1www.ygdy8.com].%E5%B8%95%E4%B8%81%E9%A1%BF%E7%86%8A.BD.720p.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97%E5%B9%95.rmvb\n  -> [AbstractCommand.cc:792] errorCode=19 CUID#7 - Name resolution for y201.dygod.org failed:DNS server returned answer with no data\n10/18 16:29:49 [NOTICE] Download GID#e49a359122a192b6 not complete:\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\ne49a35|ERR |       0B/s|ftp://ygdy8:ygdy8@y201.dygod.org:1224/[%E9%98%B3%E5%85%89%E7%94%B5%E5%BD%B1www.ygdy8.com].%E5%B8%95%E4%B8%81%E9%A1%BF%E7%86%8A.BD.720p.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97%E5%B9%95.rmvb\nStatus Legend:\n(ERR):error occurred.\naria2 will resume download if the transfer is restarted.\nIf there are any errors, then see the log file. See '-l' option in help/man page for details.\n. with AriaNg i got this log file:aria2.log\n@adam1x . log is here...@tatsuhiro-t \n[root@PandoraBox_7D29:/root]#aria2c ftp://ygdy8:ygdy8@y201.dygod.org:1224/[w\nww.ygdy8.com]..BD.720p..rmvb --async-dns=false\n10/19 08:57:48 [NOTICE] Downloading 1 item(s)\n10/19 08:57:48 [ERROR] CUID#7 - Download aborted. URI=ftp://ygdy8:ygdy8@y201.dygod.org:1224/[%E9%98%B3%E5%85%89%E7%94%B5%E5%BD%B1www.ygdy8.com].%E5%B8%95%E4%B8%81%E9%A1%BF%E7%86%8A.BD.720p.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97%E5%B9%95.rmvb\nException: [AbstractCommand.cc:351] errorCode=19 URI=ftp://ygdy8:ygdy8@y201.dygod.org:1224/[%E9%98%B3%E5%85%89%E7%94%B5%E5%BD%B1www.ygdy8.com].%E5%B8%95%E4%B8%81%E9%A1%BF%E7%86%8A.BD.720p.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97%E5%B9%95.rmvb\n  -> [NameResolver.cc:60] errorCode=19 Failed to resolve the hostname y201.dygod.org, cause: Name or service not known\n10/19 08:57:48 [NOTICE] Download GID#6ce7fdd1957c5831 not complete:\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n6ce7fd|ERR |        n/a|ftp://ygdy8:ygdy8@y201.dygod.org:1224/[%E9%98%B3%E5%85%89%E7%94%B5%E5%BD%B1www.ygdy8.com].%E5%B8%95%E4%B8%81%E9%A1%BF%E7%86%8A.BD.720p.%E4%B8%AD%E8%8B%B1%E5%8F%8C%E5%AD%97%E5%B9%95.rmvb\nStatus Legend:\n(ERR):error occurred.\naria2 will resume download if the transfer is restarted.\nIf there are any errors, then see the log file. See '-l' option in help/man page for details.\n. with AriaNg i got this log file:aria2.log\n@tatsuhiro-t \n. http://r6---sn-a5meknel.googlevideo.com/videoplayback?ipbits=0&lmt=1505638935671216&sparams=dur,ei,expire,id,initcwndbps,ip,ipbits,itag,lmt,mime,mip,mm,mn,ms,mv,pl,ratebypass,source&key=cms1&expire=1508668193&itag=22&ei=wR7sWcLfFNHSVuLvksAE&dur=7330.957&ip=192.117.146.110&pl=21&id=o-ANhyCe5DEJ9x05nNyQCvfGh8qYtSHGCNHlDGZSIKVRJq&ratebypass=yes&source=youtube&signature=1F38FFF503E1EA7DE759DD3ABEC06C0E9E794F09.0F8DF54D7F6A1C75882D63878E7EE9F4548EB1A9&mime=video%2Fmp4&title=%E7%AC%AC%E4%BA%8C%E8%AF%BE%EF%BC%9A%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%81%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA%E3%80%81GPU%E5%92%8C%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&redirect_counter=1&cm2rm=sn-aigess7s&req_id=6d85dc3133b2a3ee&cms_redirect=yes&mip=97.64.44.72&mm=34&mn=sn-a5meknel&ms=ltu&mt=1508647823&mv=m\ncan you download this video file in aria2 1.33.0 ?  @adam1x . https://www.youtube.com/watch?v=x9u4kZvI2ew&t=58s\ni get the video file in this link.... \nthe first file it download almost from (mirror accelerate)? a little bit from P2P...\nthis is thunder download tool , not aria2. it means aria2 can only download from source? @adam1x . maybe it's mining bitcoin......\n. wow? Mars have already release aria2 1.34.0...\nWhy Earth so late??. ",
    "tony5614": "try to add this argument \"--check-certificate=false\"\n like this:\naria2c -x 4 -s 4 https://wfffmark.tgz --check-certificate=false. ",
    "Suncatcher": "\n\nIf you don't see \"GnuTLS\" or \"OpenSSL\", then aria2 was not built with HTTPS\n\n\nAnd if it was built without HTTPS, then how can it be rebuilt?. >> try to add this argument \"--check-certificate=false\"\nlike this:\naria2c -x 4 -s 4 https://wfffmark.tgz --check-certificate=false\nThat didn't help.. And here is my output:\naria2 version 1.29.0\nCopyright (C) 2006, 2016 Tatsuhiro Tsujikawa\n...\nbla-bla-bla\n...\n** Configuration **\nEnabled Features: BitTorrent, GZip, Message Digest\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 libgcrypt/1.6.5\nCompiler: gcc 5.4.0 20160609\n built by   x86_64-pc-linux-gnu\n on         Nov 20 2016 15:07:06\nSystem: Linux 4.4.0-36-generic #55-Ubuntu SMP Thu Aug 11 18:01:55 UTC 2016 x86_64\n\nAnd I want to repeat my question from issue 361:\nif Aria was built without HTTPS, then how can it be rebuilt to add this support?\n. >> Assuming you are using Linux, you need to install gnutls or openssl to enable HTTPS support.\nWe documented required libraries at https://aria2.github.io/manual/en/html/README.html#how-to-build\nSo I need to uninstall the current aria2 then build again (my previous build files are deleted already) and install again? There is no easy way?\nHow can I uninstall it? I didn't found anything in the documentation, and simple apt-get purge doesn't work.\nExcuse me for dummy questions, I am still newbie in installing soft from sources.. Nothing means nothing, i.e. I see no visual activity and cannot access it via WebUI.\n\nEven starting with sudo doesn't help. And only when I log in as root it starts to listen\n\n. In both modes which aria2c gives \n/usr/bin/aria2c\n\n\nmaybe try aria2c --enable-rpc --rpc-listen-all --no-conf=true on normal user.\n\nYes, with --no-conf=true switch it started! \nBut what does it mean? It cannot read conf file from default directory /$HOME/.aria2/aria2.conf?\n. > Could it be something like SELinux, AprpAmor or the like interfering because you're trying to bind to all interfaces?\nHow to check that? I know none of the words you used here). UPD, I can't even download anything in usual-mode. I execute\naria2c -j5 --input-file=file.txt\n\nand get the same result, it works only under root. Any suggestions? . Thanks, now it's clear.. And does Aria use TCP or UDP or both?. I start Aria like this \naria2c --enable-rpc --rpc-listen-all --listen-port=6900 --dht-listen-port=6900 --pause-metadata=true --dir=/media/Downloads\n\nBut it again listens both for 6800 and 6900. \n\nHow to fix this?\n. It does download when I enable 6900th port, but doesn't fetch magnet metadata with only 6900 enabled, so it seems to use another port for fetching torrent metadata. But what?. No, I need RPC-server. The problem is in DHT port. Even if I specify \n  --dht-listen-port=6900\n\nmetadata are not retrieved via it, and it works only with disabled firewall. What else ports does it need for DHT?. So, RPC-server port is not changeable? Did I understand you correctly? Even if I start Aria with\n--listen-port=6900\n\nit still listen on 6900 port.. ",
    "cqzhao": "I got the same error. aria2c -v shows that aria2 was not built with HTTPS. How to rebuild?. ",
    "tftm": "+\n. ",
    "abbradar": "Another one:\nhttp://www.ancardia.com/download/adom_noteye_linux_debian8_64_r60_pub.tar.gz.torrent\nDeluge downloads this one fine.\nP.S.: Aria2 1.22.0\n. Hm, it's interesting -- I have opened ports via upnpc (they show up as forwarded in router's settings), binded them via --dht-listen-port and --listen-port and still have no luck. lsof shows that Aria2 listens to those ports that I specified, so this far it looks okay. Maybe there is some verbose logging which I can enable? (I'm fine with recompiling if it's needed)\n. A-ha! Indeed, indeed,\naria2c --dht-entry-point=dht.transmissionbt.com:6881 --dht-listen-port=1234 --listen-port=4321 http://www.ancardia.com/download/adom_noteye_linux_debian8_64_r60_pub.tar.gz.torrent\nworked like a charm. Thank you very much for your time!\n. ",
    "sarim": "Yes, round robin. It just loops through the interface list when a new connection is being established. Ratio based load balancing can be implemented, but too complex for me :P Given enough thread, I use 8 (-s 8 -x 8)   i don't think it'll be an issue.\nIn my case, my two connection are both of same speed. \n. Ok, squashed commits into one. I think i did it. Please check now. \n. it has a c++ library, maybe use SWIG on that?\n. Ah, thanks. I'll try to hack the source and will let you know where i do end up.\n. ",
    "hostmaster": "Awesome! Thank you.\n. ",
    "zi0r": "Id prefer that we are able to specify this in the config file as well as the command-line.\n. I did not understand the last comment.  Are you expecting action from me?\n. ",
    "hongyi-zhao": "Got it, thanks a lot.\nMy another confusion is on the differences and relationship among the terminologies of  piece/chunk/min-split-size used by aria2.\nI've tried to figure out them clearly based the manual, but still not-so-clearly on them.\nAny hints?\nRegards\nH.Zhao\n. Ok, thanks.\nBut I'm still not so sure about the following thing:\nIf I setting the following two arguments at the same time:\n--piece-length=\nand\n-k, --min-split-size=\nFrom the manpage, I can find the following description:\n--piece-length=<LENGTH>\n          Set  a piece length for HTTP/FTP downloads. This is the boundary\n          when aria2 splits a file. All splits occur at multiple  of  this\n          length.\n[snip]\nSo, it seems that the the following relation holds:  = n*\nAm I right?\nIn addition, you didn't told that the value for   of `--piece-length' must obey tha above relationship in the manual.  So if setting these two arguments not according to  = n*, then what will happen?\nRegards\n. Sorry for my not-using markdown.\nI mean the  it seems that the the following relation holds: \n   SIZE_of_min-split-size   = n * LENGTH_piece-length\nIf I don't obey this relation to setting these two arumtents, then what will happen?\n. Thanks for your hints.\nAs you mentioned in the manual, the default --piece-length=1M',\nand the also the default--min-split-size=1M' too.\nBut, according to your previous depiction, in fact, I can use any size for --piece-length' theoretically  and use 1M -1024M size of--min-split-size', am I right?\nRegards\n. By saying that `set arbitrary size for these options',    still they must first confirm to the possiable range you have setted in the default range, i.e., as follows:\n--piece-length=LENGTH\n   [snip]\n                                Possible Values: 1048576-1073741824\n                              Default: 1M\n-k, --min-split-size=SIZE\n   [snip]\n                              Possible Values: 1048576-1073741824\n                              Default: 20M\n I want to know why you let the miminal value of  `--piece-length' to 1M, instead of more little values, say, 64K, and so on?\nOr ,why not let the user can setting a more flexiable range for  `--piece-length' below 1M?\nRegards\n. But, considering the following case:\nIf I have a huge of lilltle files with the size ranges from 0-2M which I want to retrieve them from serveral mirrors. In this case, I must let the --piece-length'  and-k, --min-split-size' have the chances to be set  `<= 1M', so that I can parallelly using all of these sites will appropriate paralleziation performance.\nRegards\n. Thanks for your hints.\n. Dear\nThe  aria2-dmirror.sh is a script which I used to generate the input-file for aria2c and then invoking the aria2c from this script.\nFor the URLs included for the above example, in fact, it's read in from another url.list file and assigned to each file to download by some rule of thume.  For my case, I assign the number of urls to each file according to its size, say, every 1M-2M giving a mirror-url for using.  \nSo, in this csae, the file to be downloaded has a size approximately 39MiB, and I assign 20 mirror urls for using by aria2c to downloading this file.\nSee the following for detail:\n http://artfiles.org/debian/\nhttp://be.mirror.eurid.eu/debian/\nhttp://buaya.klas.or.id/debian/\nhttp://carroll.aset.psu.edu/pub/linux/distributions/debian/\nhttp://cdimage.debian.org/debian/\nhttp://debian.advalem.net/debian/\nhttp://debian.anexia.at/debian/\nhttp://debian.asis.io/debian/\nhttp://debian.balt.net/debian/\nhttp://debian.bhs.mirrors.ovh.net/debian/\nhttp://debian.bjtu.edu.cn/debian/\nhttp://debian.bononia.it/debian/\nhttp://debian.bsnet.se/debian/\nhttp://debian.c3sl.ufpr.br/debian/\nhttp://debian.cabletel.com.mk/debian/\nhttp://debian.carnet.hr/debian/\nhttp://debian.cc.lehigh.edu/debian/\nhttp://debian.cites.illinois.edu/pub/debian/\nhttp://debian.co.il/debian/\nhttp://debian.csail.mit.edu/debian/\nI must also told you that, even with same urls, sometimes,  the speed of aria2c are good, but sometimes are so bad. It seems its so unstable.  And I cann't figure out debug it and told you the information for analysis.\nCould you please give me some more hints?\nThanks. \n. By saying that: --input   and --deferred-input options would work.\nDo you mean: --input-file   and --deferred-input options would work?\nRegards\nH.Zhao\n. So, do you mean, in this case, one queue item will corresponding to several files?\nRegards\n. Thanks, got it.\n[1] For a specific  download item, if the  corresponding *.aria2 control file exists, then the ``--continue=true'' option will be disabled automatically if it has been set that way.\n[2] If the desination file already exists and the corresponding *.aria2 control file doesn't exist,  and --file-allocation=none been set, and the file's size is little than the real size it shoul be, only in this case, the ``--continue=true'' option will take effect  if it has been set that way.\n[3] If the  the desination file already exists and it has the same size as it should be, in this case, if the -Vtrue --checksum='' is used, then the file will be checked with the given checksum and decide to skip it or redownloading it from scratch.  If-Vtrue --checksum='' doesn't used, and the ``--continue=true'' option used, aria2c will start a new downloading   for that file and rename the latter's filename to *.1 \nRegards\n. Thanks for that hints.\nAnother issue:  \nIt seems the following two commands are equivalent:\n$ aria2c -x2 -k1M \"http://host/file.zip\"\nand\n$ aria2c -x2 -k1m \"http://host/file.zip\"\nBut, the manal page only says the usage of  -k1M.\nAny hints?\nRegards\n. I do the further testing with the following commands:\nwerner@debian:~$ aria2c -k1M -x5 -j1 -m1 -t60 --lowest-speed-limit=10K --download-result=full  http://ftp.uk.debian.org/debian/dists/jessie/main/installer-amd64/current/images/hd-media/boot.img.gz http://ftp.cn.debian.org/debian/dists/jessie/main/installer-amd64/current/images/hd-media/boot.img.gz http://ftp.us.debian.org/debian/dists/jessie/main/installer-amd64/current/images/hd-media/boot.img.gz http://ftp.kr.debian.org/debian/dists/jessie/main/installer-amd64/current/images/hd-media/boot.img.gz http://ftp.tw.debian.org/debian/dists/jessie/main/installer-amd64/current/images/hd-media/boot.img.gz http://ftp.jp.debian.org/debian/dists/jessie/main/installer-amd64/current/images/hd-media/boot.img.gz\n[#cea971 14MiB/39MiB(37%) CN:5 DL:152KiB ETA:2m44s]^C\n06/04 11:07:47 [NOTICE] Shutdown sequence commencing... Press Ctrl-C again for emergency shutdown.\n06/04 11:07:47 [NOTICE] Download GID#cea971a0851ecfd7 not complete: /home/werner/boot.img.gz\nDownload Results:\ngid   |stat|avg speed  |  %|path/URI\n======+====+===========+===+===================================================\ncea971|INPR|   145KiB/s| 28|/home/werner/boot.img.gz\nStatus Legend:\n(INPR):download in-progress.\naria2 will resume download if the transfer is restarted.\nIf there are any errors, then see the log file. See '-l' option in help/man page for details.\nwerner@debian:~$ \nWhy this time I will obtian the CN:5, I still cann't figure out this issue.\nAny hints?\nRegards\n. Thanks,\nEven so, the -k1m don't mentioned in the manpage, but it still can be used just as the same as -k1M.\nRegards\n. But, it seems all of these speeds may be fluctuated in a very large range when I testing with a little file.\nRegards\n. I still not so clear on the purpose of  --file-allocation=trunc, especially for the following things:\n [1] Considering that the file length is determined by the contents of a file and is a attribute of file itself, so what's the purpose of setting file length?\n[2] If you setting the  file length, the length must be given as a digital string as the argument, anyway,  --file-allocation=trunc doesn't accept the argument of the file's length string.\nAny hints?\n. In fact, I want to obtain the real downloaded bytes of a file at the specific time point.\nIt seems all of the file-allocation methods don't reflect the  real downloaded bytes of a file at that moment.  Of course, the file-allocation methods are designed for high efficient for allocating real-time data into the destination files. So, the purpose I wanted to obtain  real-time downloaded bytes of a file at the specific time point, cann't be obtained by this method.\nBTW, according to your depictions, all of the file-allocation methods which supporting sparse file are similar to the operations done by dd's --conv=notrunc options.\nRegards\n. One more issue:\nJust as I've posted in another threads, is there some convenient method for me to konw the real-time downloaded bytes of a file at the specific time point?\nRegards\n. Thanks a lot, I'll check these issues, some of them has follow-ups which posted by me for still not-clear issues.  If not so, I will close them.\nRegards\n. Thanks a lot, I've looked it, and some further things which I want to obtained are as follows based on your above technical-notes on control-file-aria2-format:\n[1] It seems that the critical stuff for figuring out the real-time completedLength of a file is BITFIELD relative parts in the control-file.  But, the file itself is a binary one, even can be readout, I still must to do futher calculation for figure out the  real-time completedLength of a file based on the technical-notes.\nSo, is there some convenient method for me to obtain the real-time completedLength of a file?\n[2] I've noticed that you mentioned the following thing in the manpage:\naria2.tellStatus([secret], gid[, keys])\nand\naria2.getFiles([secret], gid)\nBoth of the above two methods can return the completedLength information.\nI've tried to use of them but failed due to I'm lacking on the knowledge about python.\nCould you please give me some more hints for my purpose: obtain the real-time completedLength of a file?\nRegards\n. I think that let `adaptive' algorithm to adjust the speed dynmically is a good idea, but still it should aviod to let aria2 picking out the  very low speed for using a long period of time.\nRegards\n. Basically I have got it based on the manual.\nThanks again.\nRegards\n. Thanks a lot, do you mean, for a specific partially completed piece, its size must be interger times of  16 KiB?  Otherwise, the block which has size little than 16 KiB in a partially completed piece must be treated as garbage and thus be discarded away from that piece?\nRegards\n. Got it, thanks a lot.\nRegards\n. Then, based on the example given in the manual, I tried like the following but still failed:\n```\n$ python\nPython 2.7.3 (default, Mar 13 2014, 11:03:55) \n[GCC 4.7.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nimport urllib2, json\nfrom pprint import pprint\njsonreq = json.dumps({'jsonrpc':'2.0', 'id':'', 'method':'aria2.onDownloadComplete(\"a1083f56cd243af5\")'})\nc = urllib2.urlopen('http://localhost:6800/jsonrpc', jsonreq)\nTraceback (most recent call last):\n  File \"\", line 1, in \n  File \"/usr/lib/python2.7/urllib2.py\", line 127, in urlopen\n    return _opener.open(url, data, timeout)\n  File \"/usr/lib/python2.7/urllib2.py\", line 407, in open\n    response = meth(req, response)\n  File \"/usr/lib/python2.7/urllib2.py\", line 520, in http_response\n    'http', request, response, code, msg, hdrs)\n  File \"/usr/lib/python2.7/urllib2.py\", line 445, in error\n    return self._call_chain(args)\n  File \"/usr/lib/python2.7/urllib2.py\", line 379, in _call_chain\n    result = func(args)\n  File \"/usr/lib/python2.7/urllib2.py\", line 528, in http_error_default\n    raise HTTPError(req.get_full_url(), code, msg, hdrs, fp)\nurllib2.HTTPError: HTTP Error 500: Internal Server Error\npprint(json.loads(c.read()))\nTraceback (most recent call last):\n  File \"\", line 1, in \nNameError: name 'c' is not defined\n```\n\n\n\nI'm newbie on phthon/json/rpc, so sorry for bothering.\nRegards\n. Thanks a lot.\n. Thanks a lot.\n. The maximum concurrent download for different items/entries are controlled by -j ( --max-concurrent-downloads= ); the  maximum concurrent download for each  item/entry are controlled by -s, -k, and -x.\nIt seems that you are want to obtian the following thing:\naria2c -jN -x1 uris\nBut, the -x has the default value of 1, in addition, the -s, -k, and -x are interactive aruments.  And the manual has said a lot of thing on the relationship on them.\nRegards \n. Oops, I misunderstand you, the thing you want is as follows:\naria2c -j1 -xN -sN  uris.\nOf course, you also should set approriate -k value to let the N possible for that file.\nBut, I think this scheme using the uris is ineffecitve.  Aria2c's power is lies in the multiple uris/soureces with the most supplementary of performances / fault-tolerance among these uris. The uri-selector algorithm + speedlimit + timeout + other relative arguments can be used for selecting the uris for your case.  If you don't force the uris used that way.   \nRegards\n. Even so, IMO, the effectiveness won't be high.\n. The issue is: --lowest-speed-limit evaluate the speed based on per each connection.  When I download a file with several connections, it will drop these connections when they are observed with low speed than the limit. But still I maybe  wait the download with the total low speed with the last one connection which just has the speed higher than the speed limit.  This is what I want to obtain.  I want to abort the downloading when the total speed is lower that some limit, so that I can restart the downloading with more good connections instead of waiting for the downloading using the few connections which have the speed higher then speed limit.\nRegards\n. I've tried some more, it seems that in the daemon mode, all of the files must be use the absolute path, otherwise they may not be gererated.\nRegards\n. What about the rules using by curl: \nIf a option is used several times, the last one will be used.\nRegards\n. I've tried the --daemon option as follows:\nSet it in the aria2.conf file, and at the same time, using a different value in the command-line for this option.\nAnd, I found that the setting in the command-line will always overwrite the one set in the aria2.conf file regardless of the order of the appearance of the them in the invoking sequece for this option.\nI mean, this behaviour is violate with your above depictions: \nIn general, last one overwrites previous one, in the same way curl does.\nRegards\n. Yes, thanks.\n.  From the manpage:\nfalloc may not be available if your system doesn't have  posix_fallocate(3)  function.\nRegards\n. Thanks a lot.\n. Thanks for your reply.\n. ",
    "q3aql": "@Dialga The parameter \"-o\" is for set the file name, if you want set the download directory you must use \"-d\". In this case, the correct command is the following:\n$ aria2c [URL] -d ~/Downloads\nIf for example, you want download a file with the name \"movie.avi\" in \"~/Downloads\" directory, the command is the following:\n$ aria2c [URL] -d ~/Downloads -o movie.avi\n. @antbryan This is maybe a problem with certificates. You can try disable it with the following command:\n$ aria2c --check-certificate=false https://sourceforge.net/projects/xbian/files/release/XBian_2016.03.01_rpi.img.gz/download\nAlso, you can use my ca-certificates (ca-certificates.crt):\n$ aria2c --ca-certificate=ca-certificates.crt https://sourceforge.net/projects/xbian/files/release/XBian_2016.03.01_rpi.img.gz/download\n. @tatsuhiro-t The problem with \"bcrypt.dll\" isn't WinTLS or OpenSSL. The problem is with sftp support, when you disable sftp (libssh), aria2 works in Windows XP because doesn't need bcrypt.dll library.\nIf you want keep the compatibility with Windows XP, only is necessary a package with sftp support (Windows Vista and Later) and other without sftp (Windows XP). I think the same that you, XP is an insecure and obsolete OS, is better upgrade to other Windows OS, but is easy to continue to maintain the compatibility with Windows XP with this simple step.\n. @lollita I added new builds of aria2 1.19.2. Now, the size of binaries are correct (5,8MB is the size for Windows XP build).\naria2 1.19.2 builds (with OpenSSL):\n- aria2-1.19.2-linux-gnu-32bit-build1.tar.bz2\n- aria2-1.19.2-linux-gnu-64bit-build1.tar.bz2\n- aria2-1.19.2-win-32bit-build1.7z\n- aria2-1.19.2-win-64bit-build1.7z\n- aria2-1.19.2-win-xp-build1.7z\nAll builds: https://github.com/q3aql/aria2-static-builds/releases\n. @kazalex From now on, when released a new version of aria2, the builds will be published in https://github.com/q3aql/aria2-static-builds. I'm glad that work well in your XP!\n. @kazalex I have recompiled aria2 1.19.2 and now I have a generic binary with SFTP support that should run on all Windows versions (XP included). Can you try it and tell me if really run correctly on XP?\n- aria2-1.19.2-win-32bit-build2.7z\n. @kazalex Perfect! Thanks.\n. @neoedmund The instructions and certificates are here -> https://github.com/q3aql/aria2-static-builds\nAsk me if you have doubts or do not understand something.\n. @neoedmund :+1: \n. @blato Windows Embedded POSReady 2009 have the same problem that Windows XP, this issue was commented #393.\n. @tatsuhiro-t Thanks for fix the bug!\n. Wow! Quick response and quick solution as usual in you, thanks @tatsuhiro-t \n. @2vrh Already exists with \"-o\" parameter. Example: aria2c http://link/file.txt -o file2.txt\n. Chrome OS uses the Linux kernel, maybe the following static packages works on x86 architectures:\n- aria2-1.20.0-linux-gnu-32bit-build2.tar.bz2\n- aria2-1.20.0-linux-gnu-64bit-build2.tar.bz2\nAs well, the android package maybe works on ARM architecture:\n- aria2-1.20.0-android-build1.zip\nTry it and tell us if really works, xD\n. Exactly, aria2 works correctly if don't use 'falloc' allocation. I tried run console as administrator privilege and effectively has disappeared the error message.\nThanks @tatsuhiro-t !\n. @haikubox This issue was commented very recently https://github.com/tatsuhiro-t/aria2/issues/574\n. @Biggulu aria2 Static builds:\nLibraries: zlib/1.2.8 expat/2.1.1 sqlite3/3.12.0 OpenSSL/1.0.2g c-ares/1.11.0 libssh2/1.7.0\n- aria2-1.22.0-linux-gnu-32bit-build1.tar.bz2\n- aria2-1.22.0-linux-gnu-64bit-build1.tar.bz2\n. @aljazzair For compiling, you need install \"gnutls-devel\" and \"libssh2-devel\" too.\n. @Jimmy-Z You can try these static builds:\n\naria2-1.30.0-linux-gnu-32bit-build1.tar.bz2\naria2-1.30.0-linux-gnu-64bit-build1.tar.bz2. \n",
    "mferrier": "+1\n. ",
    "jeisoncg": "+1\n. https://www.npmjs.com/package/udp-proxy\n. ",
    "vefve": "+1\n. ",
    "vk496": "+1. ",
    "cyaconi": "+1. ",
    "Juanmabs22": "+1 Also, it will be amazing the posibility to use megatools with aria2c. echo \"deb-src http://archive.raspbian.org/raspbian/ jessie main contrib non-free rpi\" >> /etc/apt/sources.list \necho \"deb http://mirror.netcologne.de/raspbian/raspbian/ wheezy main contrib non-free rpi firmware\" >> /etc/apt/sources.list \necho \"deb-src http://mirror.netcologne.de/raspbian/raspbian/ wheezy main contrib non-free rpi firmware\" >> /etc/apt/sources.list \nsudo apt-get install libssl-dev libssh2-1-dev libc-ares-dev libxml2-dev zlib1g-dev libsqlite3-dev libexpat1-dev libxml2-dev libcppunit-dev libtool -y\napt-get install -y libgnutls-dev nettle-dev libgmp-dev libssh2-1-dev libc-ares-dev libxml2-dev zlib1g-dev libsqlite3-dev pkg-config libgpg-error-dev libgcrypt-dev libssl-dev libexpat1-dev libxml2-dev libcppunit-dev autoconf automake autotools-dev autopoint libtool sphinx gnutls-bin\n./configure\nmake\n. ",
    "slim8shady9": "+1. ",
    "salvatoretrimarchi": "+1. ",
    "rexx0520": "+1\n. ",
    "tillcash": "+1. ",
    "BirkhoffLee": "+1. ",
    "nascarsayan": "+1\n. ",
    "WireCrazii": "+1000. ",
    "matteopiccioni": "+1. ",
    "naafx8": "+1. ",
    "harckan": "+1. ",
    "Baneeishaque": "+1. +1. +1. Is the workaround ok?. +1. ",
    "anonaii": "+1. ",
    "rudevdr": "+2. ",
    "sebma": "+1. @tatsuhiro-t \nHi,\nYour Porting to GCC 4.9 document says : \n\nA workaround until libraries get updated is to include  or  before any headers from that library.\n\nTherefore I change this in the file /usr/include/c++/4.9/cstddef : \n```\ninclude \ninclude \nto this :\ninclude \ninclude \n```\nBut the same compilation is still there, can you help me ?. @tatsuhiro-t Thanks :-). ",
    "tommyziegler": "The Aria Command line says also Error-Code value 1. (Unknown error in Documentation)\nSee Terminal:\n```\n[12:45][TZiegler@tzieglers-mbp:~]$ aria2c --checksum=sha-256=CA11AEF69E65FBF666F6A5ABC73DCC9CCC28596642D52A2415965A319A190574 https://s3.eu-central-1.amazonaws.com/siu-large-download-test/jdk-8u45-windows-x64.exe\n05/11 12:47:00 [NOTICE] Allocating disk space. Use --file-allocation=none to disable it. See --file-allocation option in man page for more details.\n  Download Progress Summary as of Mon May 11 12:48:00 2015  \n====================================================================================================================================================\n[#bce7e8 130MiB/180MiB(72%) CN:1 DL:2.3MiB ETA:21s]\nFILE: /Users/TZiegler/jdk-8u45-windows-x64.exe\n----------------------------------------------------------------------------------------------------------------------------------------------------\n[#bce7e8 180MiB/180MiB(100%) CN:0] [Checksum:#bce7e8 157MiB/180MiB(87%)]                                                                          \n05/11 12:48:23 [NOTICE] Verification finished successfully. file=/Users/TZiegler/jdk-8u45-windows-x64.exe\n05/11 12:48:23 [NOTICE] Download complete: /Users/TZiegler/jdk-8u45-windows-x64.exe\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\nbce7e8|OK  |   2.2MiB/s|/Users/TZiegler/jdk-8u45-windows-x64.exe\nStatus Legend:\n(OK):download completed.\n[12:48][TZiegler@tzieglers-mbp:~]$ echo $?\n0\n[12:48][TZiegler@tzieglers-mbp:~]$ aria2c --checksum=sha-256=CA11AEF69E65FBF666F6A5ABC73DCC9CCC28596642D52A2415965A319A190573 https://s3.eu-central-1.amazonaws.com/siu-large-download-test/jdk-8u45-windows-x64.exe\n05/11 12:48:37 [NOTICE] File already exists. Renamed to /Users/TZiegler/jdk-8u45-windows-x64.exe.1.\n05/11 12:48:37 [NOTICE] Allocating disk space. Use --file-allocation=none to disable it. See --file-allocation option in man page for more details.\n  Download Progress Summary as of Mon May 11 12:49:37 2015  \n====================================================================================================================================================\n[#3cab33 139MiB/180MiB(77%) CN:1 DL:2.5MiB ETA:16s]\nFILE: /Users/TZiegler/jdk-8u45-windows-x64.exe.1\n----------------------------------------------------------------------------------------------------------------------------------------------------\n[#3cab33 180MiB/180MiB(100%) CN:0] [Checksum:#3cab33 140MiB/180MiB(77%)]                                                                          \n05/11 12:49:58 [ERROR] Checksum error detected. file=/Users/TZiegler/jdk-8u45-windows-x64.exe.1\n05/11 12:49:58 [NOTICE] Download GID#3cab338af41ae41b not complete: /Users/TZiegler/jdk-8u45-windows-x64.exe.1\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n3cab33|ERR |   2.3MiB/s|/Users/TZiegler/jdk-8u45-windows-x64.exe.1\nStatus Legend:\n(ERR):error occurred.\naria2 will resume download if the transfer is restarted.\nIf there are any errors, then see the log file. See '-l' option in help/man page for details.\n[12:49][TZiegler@tzieglers-mbp:~]$ echo $?\n1\n```\nI use the option checksum with correct type when I add the URI to Aria. That works also if the checksum is correct. When the checksum is not correct Aria tells me over the info API that there was an error, and if I ask aria2 via the API for the error code I receive the same error like over the command line.\nchecksum=sha-256=CA11AEF69E65FBF666F6A5ABC73DCC9CCC28596642D52A2415965A319A190573\nBut I think when you have this checking possibility, for me as an user it's important to know that the error was the wrong checksum. Or what's your view to that?\nThanks and many greetings\nTommy \n. Yes exactly. But I ask for the error code via the RPC API.\nDo you have any idea how hard it would be to solve? Or where in the source this mapping is done that I could fork it or make an pull request?\nThx Tommy \n. When I try to compile Aria2 on Mac OS X I receive following message:\n...\n( cd aria2.x86_64 && ../../configure \\\n        --prefix=/Volumes/DevelopmentDisk/Git/aria2/build-release/aria2-1.18.10-35-g3855205 \\\n        --bindir=/Volumes/DevelopmentDisk/Git/aria2/build-release/aria2.x86_64 \\\n        --sysconfdir=/etc \\\n        --with-cppunit-prefix=/Volumes/DevelopmentDisk/Git/aria2/build-release/x86_64 \\\n        --enable-static --disable-shared --enable-metalink --enable-bittorrent --disable-nls --with-appletls --with-libgmp --with-sqlite3 --with-libz --with-libexpat --with-libcares --without-libuv --without-gnutls --without-openssl --without-libnettle --without-libgcrypt --without-libxml2 ARIA2_STATIC=yes \\\n        CFLAGS=\"-mmacosx-version-min=10.7 -Os -flto -ffunction-sections -fdata-sections -arch x86_64 -I/Volumes/DevelopmentDisk/Git/aria2/build-release/x86_64/include\" \\\n        CXXFLAGS=\"-mmacosx-version-min=10.7 -Os -flto -ffunction-sections -fdata-sections -arch x86_64 -I/Volumes/DevelopmentDisk/Git/aria2/build-release/x86_64/include\" \\\n        LDFLAGS=\"-Wl,-dead_strip -mmacosx-version-min=10.7 -Os -flto -ffunction-sections -fdata-sections -L/Volumes/DevelopmentDisk/Git/aria2/build-release/x86_64/lib\" \\\n        PKG_CONFIG_PATH=/Volumes/DevelopmentDisk/Git/aria2/build-release/x86_64/lib/pkgconfig \\\n        )\nbash: ../../configure: No such file or directory\nmake: *** [aria2.x86_64.build] Error 127\n(build-release)[04:51][TZiegler@TZieglers-MBP:/Volumes/DevelopmentDisk/Git/aria2/build-release(master)]$\nI tried following two ways how to compile Aria2\n1st way, use Makefile direct:\n$ export NON_RELEASE=1\n $ make -f makerelease-osx.mk\nBefore I needed to install still dependencies:\n$ pip install -U Sphinx\n2nd way, use a virtualenv folder with Makefile symlink:\n$ export NON_RELEASE=1\n $ mkdir build-release\n $ cd build-release\n $ virtualanv .\n $ . bin/activate\n $ ln -s ../makerelease-osx.mk Makefile\n $ make\nInstall VirtualEnv dependency before\nsudo pip install virtualenv\nBut in both cases I receive the error. What is missing? By the way do you have a continious integration server which builds always automatic the SNAPSHOT Builds? Do you know TravisCI, Jenkins etc? Maybe we should setup a project there for Aria2!?\nGreetings\nTommy\n. Thx a lot \nIs it possible that you can give your build script / manual?\nI would Love to automate it when i habe more Details how.\nThx\nTommy \n. But the problem is that there are no informations about the dependencies on a fresh Mac OS X 10.10.\nI have the newest Xcode and I try to install the dependencies like Sphinx, autoreconf etc. via brew.\nA description for a blank system would be great.\nThx\n. ",
    "zelid": "Looks like that. Just realised that brew on mac installs autopoint but doesn't add it to the path.\nhttp://arielvb.readthedocs.org/en/latest/docs/mac/commandline.html#gettext\n. ",
    "hungaborhorvath": "Thank you. I am trying to compile it, but somehow I cannot, see https://github.com/tatsuhiro-t/aria2/issues/479\n. Yes, looking at the last modification dates of the .aria2 files, it seems to be working. Thanks. \n. Yes, I did specify enable-rpc=true in the config file. \nI just cleared the log and tried it again, here is the error message if I have on-bt-download-complete=/usr/local/bin/aria2_restart in my config file:  \n2015-11-06 12:59:35.688707 [ERROR] [HttpListenCommand.cc:114] IPv4 RPC: failed to bind TCP port 6800\nException: [SocketCore.cc:301] errorCode=1 Failed to bind a socket, cause: Address is already in use\n2015-11-06 12:59:35.803255 [ERROR] [MultiUrlRequestInfo.cc:292] Exception caught\nException: [DownloadEngineFactory.cc:215] errorCode=1 Failed to setup RPC server.\nIf I comment out the line about on-bt-download-complete, then aria2c starts properly in rpc mode. I can access it with both aria2rpc and with webui-aria2. \n. I checked. No other aria2 processes run. In fact, I tried several times after each other: aria2 starts, and after a couple seconds quits with the error message above. If I comment out on-bt-download-complete line from config file, then it starts and remains online as it is supposed to. \n. I paste it here, however I am not sure how to turn Markdown off.... :-(\n```\nconfiguration file for aria2c\ncheck-integrity=true\nbt-detach-seed-only=true\nsame as bt-force-encryption=true\nbt-require-crypto=true\nbt-min-crypto-level=arc4\n\nbt-max-peers=25\nbt-max-open-files=2\nmax-concurrent-downloads=1\nmax-connection-per-server=1\ndisable-ipv6=true\nenable-dht=false # default is true\nenable-peer-exchange=false # deafult is true\ndht-file-path=/media/USBHDD1/.aria2/dht.dat\ndht-file-path6=/media/USBHDD1/.aria2/dht6.dat\ndir=/media/USBHDD1/Torrent/\nlog-level=warn\nlog=/media/USBHDD1/.aria2/aria2.log\nca-certificate=/etc/ssl/certs/ca-certificates.crt\ncheck-certificate=false\nsplit=2\ncontinue=true\nforce-save=true\nbt-save-metadata=true\nrpc-save-upload-metadata=true\nsave-session=/media/USBHDD1/.aria2/aria2_session.txt\ninput-file=/media/USBHDD1/.aria2/aria2_session.txt\nsave-session-interval=60\nauto-save-interval=0\ndaemon=true\nenable-rpc=true\nrpc-listen-all=true\nrpc-user=.........\nrpc-passwd=.........\nlisten-port=.........\ndht-listen-port=.........\nbt-enable-lpd=true\nmax-overall-upload-limit=16K\nmax-upload-limit=12K\nmax-overall-download-limit=128K\nmax-download-limit=64K\nfile-allocation=falloc\nbt-external-ip=\nthis is needed ###\non-bt-download-complete=/usr/local/bin/aria2_restart\non-download-complete=\nseed-ratio=0.0\nseed-time=2880\nbt-remove-unselected-file=true\nbt-request-peer-speed-limit=4K # default=50K\n```\n. I use it on a raspberry pi, os is raspbian jessie. I have compiled the version 1.19.2 from source as a simple user (the same user who runs it), and I should still have the log files if you tell me where to look. I could post them if that would help, just tell me which files. \n. If I comment out the line about on-bt-download-complete, then I get exactly this error. I know, because I cleared the log file completely before testing. \nWould the make/install logs help? Where can I find those? \nThank you for looking into this. \nAs a sidenote: the reason I need this is that currently the control file is either written to disk every N seconds, or only when aria exits gracefully. And the problem is that the torrent files are considered downloaded files, even if they are complete, so having seeded files in the list would constantly use the disk, even if e.g. there is no network activity. Therefore currently control files for me are only written to disk when aria2 exits. And then there are a lot of powercuts in our neighbourhood, and then when aria2 restarts, then it complains about already downloaded files I need to manually add them with check-integrity, etc.....\nI reported this in issue #382, that maybe control files could be written to disk only if changed, just as with the session file. Then I would not need this option with on-bt-download-complete.\n. Never mind, I figured it out. After I installed the\nlibtool\npackage, autoconf -i worked, and I could run ./configure. I am waiting for the end of the compilation. \nIt might be worth to write about the libtool package into the README, though..... Then this issue can be closed. \n. ",
    "7sDream": "Need this option too.\nOr a option like -6 like wget.\n. ",
    "ivan98": "I'm looking for the RPC method to add/remove trackers while BT d/load is in progress. Did I miss it or is it not available?\n. ",
    "jasonVeld": "On re-downloading the file the error did not recur, gladly.  It will likely occur again though on another file, as it's happened a number of times before, so will keep a trace of http, and when it does send the header and length info you mentioned. thanks\n. ",
    "HarukaMa": "Some tests. Tried to print some logs locally. Printed \"Step\" parameter is the state BEFORE parsing the next character.\nNormal servers: \n```\n05/24 02:10:13 [WARN] Step = CD_QUOTED_STRING, p = t\"\n05/24 02:10:13 [WARN] Step = CD_QUOTED_STRING, p = \" // next state is CD_AFTER_VALUE\n05/24 02:10:13 [WARN] state = 7 // CD_AFTER_VALUE\n05/24 02:10:13 [WARN] destlen = 1024, dlen = 966\n05/24 02:10:13 [WARN] rv = 58\n05/24 02:10:13 [WARN] contentDisposition = (correct filename)\n```\nProblematic server:\nBefore applying fix:\n```\n05/24 02:02:04 [WARN] Step = CD_QUOTED_STRING, p = t\";\n05/24 02:02:04 [WARN] Step = CD_QUOTED_STRING, p = \";\n05/24 02:02:04 [WARN] Step = CD_AFTER_VALUE, p = ; // nest state is CD_BEFORE_DISPOSITION_PARM_NAME\n05/24 02:02:04 [WARN] state = 3 // CD_BEFORE_DISPOSITION_PARM_NAME\n05/24 02:02:04 [WARN] rv = -1\n05/24 02:02:04 [WARN] contentDisposition = \n```\nAfter:\n```\n05/24 02:06:30 [WARN] Step = CD_QUOTED_STRING, p = t\";\n05/24 02:06:30 [WARN] Step = CD_QUOTED_STRING, p = \";\n05/24 02:06:30 [WARN] Step = CD_AFTER_VALUE, p = ;\n05/24 02:06:30 [WARN] state = 3\n05/24 02:06:30 [WARN] destlen = 1024, dlen = 955\n05/24 02:06:30 [WARN] rv = 69\n05/24 02:06:30 [WARN] contentDisposition = (correct filename)\n```\n. There are some servers doing this though, and all major browsers don't ignore that.\nSo this could be regard as Wont-fix and those servers should be fixed instead?\n. I understand it. I'm now trying to contact website owner to see if they are willing to fix it on their's end.\nMeanwhile I may use a local modified version though...\niPhone\u001b$B$+$iAw?.\u001b(B\nH27/05/24 17:51\u001b$B!\"\u001b(BTatsuhiro Tsujikawa notifications@github.com \u001b$B$N%a%C%;!<%8\u001b(B:\n\nUnfortunately, yes.\nIn my opinion, parsing header field should be strict rather than permissive these days, to prevent possible security bug.\n\u001b$B!=\u001b(B\nReply to this email directly or view it on GitHub.\n. It seems some non-English content garbled when parsing email content...\n\nClosing PR.\n. ",
    "pheerai": "For the site I visit (ftp.f3l.de), the Signature Algorithm is, in fact, SHA512.\nAfter digging around some more with your diff in mind, I stumbled upon this neat little Bug within GnuTLS on Debian/Wheezy:\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=737921\nMeans, this isn't related to aria2 Client-Side, but to gnuTLS Server-Side.\n. ",
    "sledges": "All servers with - Server Signature: RSA-SHA1 that I tried to download from with aria2-1.19.0 fail, curl works just fine.\nOlder aria2 versions never had this problem, so it looks like a security-driven regression, which are very hard to handle.\nWe can't ask the world to upgrade their gnuTLS; is there a compromise the aria2 team would make most https servers downloadable again?\n. Thank you ever so much, waiting patiently for the next release :) I use ArchLinux, so will get it really early :)\n. ",
    "agentcobra": "Same problem for me, I'm under:\n\nDistributor ID:    Debian\nDescription:   Debian GNU/Linux 8.6 (jessie)\nRelease:   8.6\nCodename:  jessie\n\naria was installed from depot\naria2 version 1.18.8\n. ",
    "tobwen": "Problem still exists in Debian Jessie. \"check-certificate=false\" is ignored as parameter and in config-file.\nEven on websites with modern certificates and signature: aria2c https://www.hidrive.strato.com/. ",
    "lollita": "The bcrypt.dll doesn't exist on XP, but it does on Vista.\nThere is no redist version of the bcrypt.dll or its dependencies that can be deployed to a Windows XP or older system.\nhttps://supportxpdotcom.wordpress.com/2013/02/23/casablanca-c-rest-sdk-xp-support/\n. And I deprecate Aria2 update since it not support XP solid OS for geeks ;)\n. 123M is very high size.\nI hope you will keep even a normal version.\n. ",
    "lorien-mudak": "We just agreed that you are a retard. Is there a real reason for dropping Xp?\nAs for insecurity - go try attack windows behind NAT/built-in firewall.\n. > If aria2 is built with openssl, then probably it works without offending dll. But you have to manage CA certificates.\nSo? That's exactly how wget and curl work. How do you work on lunix? Use openssl? Why not to do it on windows?\nI think you mix opensource with open development. Opensource only means there are sources available.\n. Windows users don't build anything, dude, they download an installer. Can you build both?\nWhat can an user do if he is not an administrator and CA he needs is not listed in Windows' settings?\n. And you are building wrong the one, that's why you are retarded.\n. There is no reason to lose users. I would understand if there were a real reason, but you behave like microsoft - drop XP support because of 1 Mb DLL\n. ",
    "kazalex": "I will have to replace aria2 by other downloader :( It is a pity. --userCount;\n. @clamsawd Fine works on mine XP. Many thanks!\n. @clamsawd It a good news, thank!\n. @clamsawd Checked on XP SP3. OK.\n. ",
    "ievgen-baida": "Hi guys,\nI am sorry to see this discussion went to nowhere.\nWe have the same issue on our Windows Home Server (based on Windows 2003).\nIs there any way to have Aria2 running on Windows 2003?\nPleeeeeease :)\n. ",
    "neoedmund": "@clamsawd  hi, thank you for your aria2-1.19.2-win-32bit-build2.7z\nI tried to download from a HTTPS url with it on Windows XP machine but it complains:\nException: [AbstractCommand.cc:350] errorCode=1 URI=https://xxxxxx\n  -> [SocketCore.cc:975] errorCode=1 SSL/TLS handshake failure: unable to get local issuer certificate\nDo I need to install some CA file and how to ?\nThanks in advance.\n. @clamsawd On my windows xp machine, the file aria2.conf and the dir are not existed, I manually created and edited it.  It worked! It also works with aria2c --ca-certificate=<PATH-TO-CERTIFICATE> <URL> in command line.\nThe problem is solved and thank you for your help!\n. ",
    "firstrose": "aria2-1.19.2-win-32bit-build1.7z works on Win2003\nThank you!\n. ",
    "webdev20": "XP is still widely used, not supporting XP means ignoring part of the market!\n. ",
    "justingoldberg": "Just download it:\nhttps://www.google.com/search?client=opera&q=%22index+of%22+bcrypt.dll&sourceid=opera&ie=utf-8&oe=utf-8&channel=suggest&gws_rd=ssl\nEdit:\nOk, scratch that, \"application failed to initialize properly\" 0x0000007b. But these static builds, mentioned above, work:\nhttps://github.com/clamsawd/aria2-static-builds/releases\n. ",
    "hagrid-the-developer": "I used aria from github, commit 89c1916fa57d87ea09142cc3588044c691d1928f.\nI used plain ftp, arai2c was started this way:\n$ /opt/aria2/bin/aria2c --enable-rpc=true\naddUri command (part of python code):\nuri = 'ftp://user:pass@...'\njsonreq = json.dumps({'jsonrpc':'2.0', 'id':'qwer', 'method':'aria2.addUri', 'params':[[uri]]})\nc = urllib2.urlopen('http://localhost:6800/jsonrpc', jsonreq)\n. Everything seems to be working to me. Thanks for the hint with jemalloc.\n. Thanks, so far I have been able to live with 1 URI solution. In the future I would like to try to hack URISelector, but it is not necessary now.\n. ",
    "Alex131089": "IDN are spreading, if it can help : \nhttp://en.wikipedia.org/wiki/Internationalized_domain_name\nhttp://en.wikipedia.org/wiki/Punycode\nhttp://tools.ietf.org/html/rfc3490\nhttp://www.gnu.org/software/libidn/doxygen/punycode_8c_source.html\nhttp://opensource.apple.com/source/ICU/ICU-400.42/icuSources/common/punycode.c\nseems to be simple to implement : idn detection and then decoding before resolving.\n. ",
    "bagder": "That mirroring system is most likely not something you need very much anyway (I'm guessing). If you need help to host download files for aria2 I'm convinced you will find volunteers to help you. Just let us know!\nAnd yes, the curl project finally moved the last service off SF a while ago. I think their services have degraded over the years and their site is mostly annoying to navigate, so it drove us away. Then this abuse case surfaces and I'm glad we already left them...\n. ",
    "rocdeng": "Yes, I used the --force-save option, after disable it, control file could be deleted! Thanks a lot!\n. ",
    "leandroong": "Using different folder, not assigned download directory, I was able to get file downloaded. Ff sample fails:\nhttp://gateway.play44.net/videos/vids4/from_vegas_to_macau_ii_2015_-_part2.mp4?st=qjTyWoW3Thpp-BmCYmkFZQ&e=1433833451&server=videobug\nhttp://gateway.play44.net/videos/vids4/from_vegas_to_macau_ii_2015_-_part3.mp4?st=6JWkcdDanBZXwWLpUSToBQ&e=1433833507&server=videobug\nhttp://gateway.play44.net/videos/vids4/from_vegas_to_macau_ii_2015_-_part4.mp4?st=rt6kd81_HdsXo6t9Tjf-nw&e=1433833539&server=videobug\nhttp://gateway.play44.net/videos/vids4/from_vegas_to_macau_ii_2015_-_part5.mp4?st=JCg226Soun2BLL6YDDRypw&e=1433833581&server=videobug\nhttp://gateway.play44.net/videos/vids4/from_vegas_to_macau_ii_2015_-_part6.mp4?st=nVfSh-xnjulE21W-1cgc8A&e=1433833618&server=videobug\nhttp://gateway.play44.net/videos/vids4/from_vegas_to_macau_ii_2015_-_part7.mp4?st=nmjJ-eaFoKaEocOlA3LkLw&e=1433833658&server=videobug\n. It turned out the problem is due to usb flash drive format (fat32) is the issue from my router FW. After changing it to ext4, issue writing is solved. \nI deleted the title, since it is not aria2 issue\n. working in my case, just add it at the end\nexample: aria2c http://adblock.gjtech.net/?format=hostfile --check-certificate=false --out=gjtech_net\n. well, no error in gui, File that should be download is master,zip file with filesize of 575,836KB.\n. Go to site: https://github.com/lancethepants/tomatoware and click \"clone or download\"\n. I think file downloaded was not even written.. I use this aria2 server, https://github.com/ziahamza/webui-aria2. anyway, i do it manually, wget https://codeload.github.com/lancethepants/tomatoware/zip/master. Error I got from terminal:\n/media/myssd/aria2_downloads/test # aria2c https://codeload.github.com/lancethep\nants/tomatoware/zip/master\n11/23 22:58:49 [NOTICE] Downloading 1 item(s)\n[#07403f 0B/0B CN:1 DL:0B]\n11/23 22:58:51 [ERROR] CUID#7 - Download aborted. URI=https://codeload.github.com/lancethepants/tomatoware/zip/master\nException: [AbstractCommand.cc:351] errorCode=1 URI=https://codeload.github.com/lancethepants/tomatoware/zip/master\n  -> [SocketCore.cc:1015] errorCode=1 SSL/TLS handshake failure: unable to get local issuer certificate\n11/23 22:58:51 [NOTICE] Download GID#07403f4c95468029 not complete:\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n07403f|ERR |       0B/s|https://codeload.github.com/lancethepants/tomatoware/zip/master\nStatus Legend:\n(ERR):error occurred.\n. im running it from router using static binary compiled, source taken from https://github.com/lancethepants/aria2-mipsel-static\nwith aria2 server taken from https://github.com/ziahamza/webui-aria2\ntest run:\n/media/myssd/aria2_downloads/test # aria2c https://codeload.github.com/lancethep\nants/tomatoware/zip/master -ca-certificate /etc/ssl/certs/ca-certificates.crt\nException: [AbstractOptionHandler.cc:69] errorCode=28 We encountered a problem while processing the option '--continue'.\n  -> [OptionHandlerImpl.cc:95] errorCode=1 continue must be either 'true' or 'false'.\nUsage:\n -c, --continue[=true|false]  Continue downloading a partially downloaded\n                              file. Use this option to resume a download\n                              started by a web browser or another program\n                              which downloads files sequentially from the\n                              beginning. Currently this option is only\n                              applicable to http(s)/ftp downloads.\n                          Possible Values: true, false\n                          Default: false\n                          Tags: #basic, #http, #ftp\n\n/media/myssd/aria2_downloads/test #\n. my router dont have the certificate folder, only have 1 file /etc/ssl/openssl.cnf\n. curious, wget works w/out any certification supplied. still error, i dont have certificate\n/media/myssd/aria2_downloads/test # aria2c https://codeload.github.com/lancethep\nants/tomatoware/zip/master --ca-certificate /etc/ssl/certs/ca-certificates.crt\n11/23 23:34:51 [NOTICE] Downloading 1 item(s)\n11/23 23:34:51 [ERROR] Failed to load trusted CA certificates from /etc/ssl/cert                                                                                                                     s/ca-certificates.crt. Cause: error:02001002:system library:fopen:No such file o                                                                                                                     r directory\n[#fda40c 0B/0B CN:1 DL:0B]\n11/23 23:34:52 [ERROR] CUID#7 - Download aborted. URI=https://codeload.github.co                                                                                                                     m/lancethepants/tomatoware/zip/master\nException: [AbstractCommand.cc:351] errorCode=1 URI=https://codeload.github.com/                                                                                                                     lancethepants/tomatoware/zip/master\n  -> [SocketCore.cc:1015] errorCode=1 SSL/TLS handshake failure: unable to get l                                                                                                                     ocal issuer certificate\n11/23 23:34:52 [NOTICE] Download GID#fda40c43ebecac65 not complete:\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\nfda40c|ERR |       0B/s|https://codeload.github.com/lancethepants/tomatoware/zip                                                                                                                     /master\nStatus Legend:\n(ERR):error occurred.\naria2 will resume download if the transfer is restarted.\nIf there are any errors, then see the log file. See '-l' option in help/man page                                                                                                                      for details.\n/media/myssd/aria2_downloads/test #772 . how about adding option similar to wget, \"--no-check-certificate\" ?\n/media/myssd/aria2_downloads/test # aria2c https://codeload.github.com/lancethep\nants/tomatoware/zip/master --no-check-certificate\naria2c: unrecognized option `--no-check-certificate'\nUsage: aria2c [OPTIONS] [URI | MAGNET | TORRENT_FILE | METALINK_FILE]...\nSee 'aria2c -h'.\nDid you mean:\n        --check-certificate\n/media/myssd/aria2_downloads/test #\n. --check-certificate=false working. Thanks.. kindly close issue ..... Here is script portion for compiling aria\n```\n###\nARIA2 #\n###\nmkdir -p $SRC/aria2 && cd $SRC/aria2\n$WGET https://github.com/aria2/aria2/releases/download/release-1.30.0/aria2-1.30.0.tar.gz\ntar zxvf aria2-1.30.0.tar.gz\ncd aria2-1.30.0\nLDFLAGS=\"-zmuldefs $LDFLAGS\" \\\nCPPFLAGS=$CPPFLAGS \\\nCFLAGS=$CFLAGS \\\nCXXFLAGS=$CXXFLAGS \\\n$CONFIGURE \\\n--enable-libaria2 \\\n--enable-static \\\n--disable-shared \\\n--without-libuv \\\n--without-appletls \\\n--without-gnutls \\\n--without-libnettle \\\n--without-libgmp \\\n--without-libgcrypt \\\n--without-libexpat \\\n--with-xml-prefix=$DEST \\\nZLIB_CFLAGS=\"-I$DEST/include\" \\\nZLIB_LIBS=\"-L$DEST/lib\" \\\nOPENSSL_CFLAGS=\"-I$DEST/include\" \\\nOPENSSL_LIBS=\"-L$DEST/lib\" \\\nSQLITE3_CFLAGS=\"-I$DEST/include\" \\\nSQLITE3_LIBS=\"-L$DEST/lib\" \\\nLIBCARES_CFLAGS=\"-I$DEST/include\" \\\nLIBCARES_LIBS=\"-L$DEST/lib\" \\\nLIBSSH2_CFLAGS=\"-I$DEST/include\" \\\nLIBSSH2_LIBS=\"-L$DEST/lib\" \\\nARIA2_STATIC=yes \n$MAKE \\\nLIBS=\"-static -lz -lssl -lcrypto -lsqlite3 -lcares -lxml2 -lssh2\"\nmake install DESTDIR=$BASE/aria2_ipkg_install-commit-121616\n```\n. Tatsuhiro-t, Thanks a lot. Cross-compilation went successful after added the ff:\nNote2: Fixed, added the ff:\n...\nexport PKG_CONFIG_PATH=$DEST/lib/pkgconfig:$PKG_CONFIG_PATH\n...\n\nARIA2\n\n...\nLIBXML2_CFLAGS=\"-I$DEST/include/libxml2\" \\\nLIBXML2_LIBS=\"-L$DEST/lib\" \\\n.... oops, my mistake. correct now and resolved\n/opt/bin # aria2c --version\naria2 version 1.34.0\n. ",
    "teknogeek": "I'm on Linux, Debian 7. As for the filesystem, it's actually writing to an\nsshfs mounted folder from a different server with more space.\nOn Jun 9, 2015 12:26 PM, \"Tatsuhiro Tsujikawa\" notifications@github.com\nwrote:\n\nPlatform? Linux, Windows, or something else?\nIf you are using Windows version and your file system is legacy VFAT, and\nyou don't use --file-allocation=prealloc, then aria2 may pause because it\nwill write at the random location of file, and VFAT requires all bytes from\nbeginning of the file to the writing position is zero filled, which could\ntake a time.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/420#issuecomment-110422399.\n. btw that file system is defined as fuse.sshfs in mount and df -Th\n. now that I am using prealloc, it no longer seems to be freezing however it is not showing anything in the web-ui. blank speeds and downloaded amounts\n. just directly going to the remote server\n. The CPU and memory usage did not get high. I will look to see whether it is\nsending network data at that point in a bit.\nOn Jun 10, 2015 8:22 AM, \"Tatsuhiro Tsujikawa\" notifications@github.com\nwrote:\nThanks for detailed information. We have never had an issue in checking\npiece hash, so probably it is because of the interaction between aria2 and\nremote file system. Currently, I have no idea about this. But I'm curious\nwhat's happening while aria2 is freezing. Did it consuming lots of CPU? Or\njust waiting for something, say, network I/O?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/420#issuecomment-110728685.\n. After some thought, I have fixed the issue! disk-cache was set to 0 therefore disabling it. This meant that aria2 was having to do a lot of I/O during hash calculation etc causing it to hang. By setting disk-cache to 16M it fixed it immediately. I did not experiment with lower amounts but if anyone else experiences this problem, feel free to.\n\nCheers!\n. ",
    "boywanders": "Using prealloc caused the server to send data to the remote server and allocate disk space for it, after this, the torrent started to download and displayed the same error as mentioned in the original comment. ~Owner of the remote server\n. While aria2 is freezing, there is no network data being transferred to or from the download server. What we observe is the web panel graph running horizontally for the freeze period followed by a substantial dip. It is important to note that while the graph freezes at a particular speed, this speed is not accurate and not representative of any transfer speed (As previously mentioned, the actual interface on the download server and the remote filesystem server show no transfer of data). When frozen, the process appears to consume no more CPU resources or memory.\n. ",
    "Kagami": "I realize this probably violates RFC, but look for example at this page.\nIf we check Content-Disposition header of first photo, we will see:\n```\n$ curl -I http://cfile9.uf.tistory.com/original/142D493F506557F31182F6\nHTTP/1.1 200 OK\nExpires: Tue, 22 Mar 2016 10:44:02 GMT\nDate: Sun, 21 Feb 2016 10:44:01 GMT\nServer: Apache\nContent-Disposition: inline; filename=\"%EC%82%AC%EB%B3%B8_-DSC02499.jpg\"\nLast-Modified: Fri, 28 Sep 2012 07:55:33 GMT\nContent-Type: image/jpeg\nContent-Length: 792416\nAge: 198\nVia: 1.1 Wcache(2.0)\nConnection: keep-alive\n```\n```\n\n\n\nimport urllib.parse\nurllib.parse.unquote('%EC%82%AC%EB%B3%B8_-DSC02499.jpg')\n'\uc0ac\ubcf8_-DSC02499.jpg'\n```\n\n\n\nSo it uses UTF-8 encoded Content-Disposition filename, but doesn't specify encoding. I think such cases might be rather common in real web? What about additional option for this, e.g. --content-disposition-encoding=utf8?\n. ",
    "dark1256": "Found another way \"trunc\" works\n. ",
    "peyyman": "I specify cookie file in command-line : \n  $: aria2c --load-cookies \"/home/theuser/.config/google-chrome/Default/Cookies\" \n. yes, I did, I just did not copy it here.\nActually i run a script for downloading coursera videos that uses aria2c. \n. Sorry, I should point out that it doesn't work. \nthe script that i use is \"https://github.com/abiyani/coursera-downloader\", and i think that everything with this script is fine, I logged in to coursera and set the cookie parameter to the path of my browser and etc.\nis it possible that aria2c is not compatible with google chrome cookies??( my chrome version is 43.0.2357.130 )\n. I have removed the double quotes, but it doesn't work! \n. ",
    "etmatrix": "Well with this patch now I can select without problems.\nThank you\n. ",
    "fourzerofour": "@Deadooshka I don't see how that option is even remotely related to what I'm proposing here. What I'm suggesting here is more like auto --dir\n. ",
    "rc4991": "Hi Folks. Has there been any progress on this issue? \nI also see this issue with 64 bit when using max-overall-download-limit option.\nAny recommended alternative (other then not setting a limit)?\nThanks.\n. I'd have to check on if the issue is with HTTP as well. I would think WinTLS is not really involved in HTTP, but I'm no expert.\nHas anyone tried the per download throttling approach? does that also suffer similar issue?\nR\n. ",
    "eyalfishler": "same problem here. \nmingw-config:\ntest -z \"$HOST\" && HOST=i686-w64-mingw32\ntest -z \"$PREFIX\" && PREFIX=/usr/local/$HOST\n./configure \\\n    --host=$HOST \\\n    --prefix=$PREFIX \\\n    --without-included-gettext \\\n    --disable-nls \\\n    --with-libcares \\\n    --without-gnutls \\\n    --without-openssl \\\n    --with-sqlite3 \\\n    --without-libxml2 \\\n    --with-libexpat \\\n    --with-libz \\\n    --with-libgmp \\\n    --with-libssh2 \\\n    --without-libgcrypt \\\n    --without-libnettle \\\n    --with-cppunit-prefix=$PREFIX \\\n    --enable-libaria2 \\\n    --enable-static \\\n    ARIA2_STATIC=no \\\n    ENABLE_LIBARIA2=yes \\\n    CPPFLAGS=\"-I$PREFIX/include\" \\\n    LDFLAGS=\"-L$PREFIX/lib\" \\\n    PKG_CONFIG_PATH=\"$PREFIX/lib/pkgconfig\"\nroot@25420fd9dc48:/aria2# \n. as u can see from the mingw-config file \n--enable-libaria2 \nARIA2_STATIC=no \nENABLE_LIBARIA2=yes \ni tried also removing \n--enable-static \nalso tried in the Dockerfile.mingw to remove the disable-shared (for all the projects of course) as by default it builds both static and shared files & compiled the libs for shared dlls - that didnt help making the aria2 dll.\nRUN cd gmp-6.0.0 && \\\n    ./configure \\\n    --prefix=/usr/local/$HOST \\\n    --host=$HOST \\\n    --disable-cxx \\\n    --enable-fat \\\n    CFLAGS=\"-mtune=generic -O2 -g0\" && \\\n    make install\n. @tatsuhiro-t thanks for the elaborate response,\ni was able to build the DLL, the output dll file is 120MB\nis that correct?\nhttps://dl.dropboxusercontent.com/u/36645939/libaria2-0.dll.gz\ntried also running it with the flag \n--disable-bittorrent\nand that deceased the size to 78MB\ni must be doing something wrong here...\ni'v followed your instructions \n(one change was \nexport BINARY_PATH=$HOST/bin\nexport INCLUDE_PATH=$HOST/include\nexport LIBRARY_PATH=$HOST/lib \njust a typo)\ntest -z \"$HOST\" && HOST=i686-w64-mingw32\ntest -z \"$PREFIX\" && PREFIX=/usr/local/$HOST\n./configure \\\n    --host=$HOST \\\n    --prefix=$PREFIX \\\n    --without-included-gettext \\\n    --disable-nls \\\n    --with-libcares \\\n    --without-gnutls \\\n    --without-openssl \\\n    --with-sqlite3 \\\n    --without-libxml2 \\\n    --with-libexpat \\\n    --with-libz \\\n    --with-libgmp \\\n    --with-libssh2 \\\n    --without-libgcrypt \\\n    --without-libnettle \\\n    --with-cppunit-prefix=$PREFIX \\\n    --enable-libaria2 \\\n    --disable-bittorrent \\\n    CPPFLAGS=\"-I$PREFIX/include\" \\\n    LDFLAGS=\"-L$PREFIX/lib\" \\\n    PKG_CONFIG_PATH=\"$PREFIX/lib/pkgconfig\"\n. i want to solve this (and add couple more changes) and do a PR for building a windows DLL.\n. @Juanmabs22 r u sure these would install the libs for dll ?\nim still working on getting it all compile, as for the missing libs it added \nhttps://github.com/eyalfishler/aria2/commit/b8049a66636a03ba7146484b9952fa4c75dce8db\nonce im done with all the changes i'll do a PR.\nanother important issue for me relates to the fact that the DLL is a mingw dll (added also output of def file which i turn to a lib that can be used in msvc) that cant can compile with any VC++ project.\nas u can only perform get C code to compile between mingw and msvc i had to make changes to the actual code of the aria2api code (and header) mainly with functions that were returning vectors or accepting vectors as input. (std:string...)\nim now sure how @tatsuhiro-t would accept this kind of a patch, but if we want to have support for msvc the api needs to change or add new functions that would allow such interface.\n. ",
    "bindiry": "may be need to install libxml2-dev package\n. source code compiling...\n. find 2.17.0 from here\n. @tatsuhiro-t \nlike http://raspberrypi_ip:6800/jsonrpc?jsoncallback=1\nmy aria2 version is : 1.15.1\n. i installed it use apt-get install aria2 command.\n. ",
    "renweibo": "update with latest manual link\nhttps://aria2.github.io/manual/en/html/aria2c.html. ",
    "artikell": "\nThe Error Info:\n2018-10-05 10:29:54.702714 INFO - [HttpServerBodyCommand.cc:206]CUID#8 - Failed to parse JSON-RPC request\nException: [json.cc:450] errorCode=30 JSON decoding failed: Unexpected EOF in term context.\nThe request: \nSkyfireMacBook-Pro% curl 'http://192.168.31.198:6800/jsonrpc'\n{\"error\":{\"code\":-32700,\"message\":\"Parse error.\"},\"id\":null,\"jsonrpc\":\"2.0\"}%\nI don't know how to deal with this problem. Is the way I use it wrong?. ",
    "Yamakaky": "Ok, thanks. Do you know when it will be released ?\n. Ok, thanks\n. ",
    "matiffeder": "@zendalee I think maybe this program include some features you want.. I'm also looking for the solution of resume without link, please tell me if anyone knows. Thank you!. ",
    "amtlib-dot-dll": "Thank you!\nBy the way, is there any temporary solution by adjusting the command-line parameters or environment variables?\n. That's very nice of you.\nThe workaround looks like this cat /etc/security/cacerts/* | aria2c --ca-certificate=/proc/self/fd/0 $@\n. OwO\n. There are extra data after the -----END CERTIFICATE----- statement, and thus although it doesn't matter when simply passing the concatenated files as a command-line argument, would it affect the OpenSSL source code or the complier or something else? Only a guess\n. OwO\n. You're welcome!\n. ",
    "aoeuh": "I understood the reason for the error, but I think that this is the wrong behavior of the program, and it should not check the md5 from metalink file.\n. ",
    "ZeekHuge": "Hi, I would like to take on this and convert this into a PR. I dived into the code and figured this is where the checksum validation actually starts (please correct me if I am wrong) and so, there should be the actual check.\nThe check could be implemented using  getRequestGroup->getPendingOption()->get(PREF_FOLLOW_METALINK) and compare for value \"mem\".\nWhat I am confused is, how should this be implemented ? a simple if case over that entry_->validateChunk() statement ? or maybe some function in RequestGroup like bool shouldValidateOnCompletion() ?\nPlease help me if I have got all this wrong.\n. ",
    "sunthx": "+1. ",
    "wanghz": "same here.. ",
    "lgh06": "aria2 support bittorrent but not magnet\u2026\u2026 what a pity\u2026\u2026. ",
    "ryankeefe92": "same here. ",
    "XhstormR": "Awesome\uff01\n. I have not tried.I'm just not sure.Thanks.\n. \u80fd. ",
    "whjstc": "Expecting it for #392 .\n. ",
    "lukasmrtvy": "Nevermind, it can be done with:\nProxyPass /mycustomjsonrpc ws://127.0.0.1:6800/jsonrpc  \n    ProxyPassReverse /mycustomjsonrpc ws://127.0.0.1:6800/jsonrpc\nNow it is up to web interface to be able to choose jsonrpc path correctly\n. ",
    "Thell": "Here's an example; using apt-fast during docker image building.\nThis is the output using --console-log-level=error...\n```\n--->8---\n[apt-fast 20:08:20] \n Working... this may take a while.\n[DL:1.2MiB][#b02a30 320KiB/445KiB(71%)][#552e91 80KiB/179KiB(44%)][#59c4b6 80KiB/126KiB(63%)][#8beee2 64KiB/211KiB(30%)][#bf2171 0B/0B]\n[DL:2.0MiB][#95146e 288KiB/705KiB(40%)][#c33b5f 480KiB/2.1MiB(22%)][#5d9663 576KiB/789KiB(72%)][#652740 480KiB/1.8MiB(24%)][#82398e 256KiB/4.9MiB(5%)]\n[DL:2.9MiB][#95146e 688KiB/705KiB(97%)][#c33b5f 1.5MiB/2.1MiB(73%)][#652740 1.2MiB/1.8MiB(64%)][#82398e 1.6MiB/4.9MiB(33%)][#674711 608KiB/1.9MiB(29%)]\n[DL:3.3MiB][#652740 1.4MiB/1.8MiB(76%)][#82398e 3.4MiB/4.9MiB(70%)][#674711 1.5MiB/1.9MiB(76%)][#b1194f 768KiB/5.3MiB(13%)][#95acfd 0B/0B]\n[DL:3.6MiB][#82398e 4.9MiB/4.9MiB(99%)][#b1194f 2.4MiB/5.3MiB(45%)][#c35073 858KiB/1.0MiB(78%)][#4fcac5 48KiB/16MiB(0%)][#40eecf 0B/0B]\n[DL:3.9MiB][#b1194f 4.3MiB/5.3MiB(79%)][#4fcac5 2.4MiB/16MiB(14%)][#c8b966 128KiB/145KiB(87%)][#ffe4d4 16KiB/744KiB(2%)][#7b59ab 0B/0B]\n[DL:3.9MiB][#4fcac5 4.9MiB/16MiB(29%)][#ffe4d4 192KiB/744KiB(25%)][#650d90 0B/33KiB(0%)][#8e5169 48KiB/1.7MiB(2%)]\n[DL:3.9MiB][#4fcac5 8.0MiB/16MiB(48%)][#ffe4d4 576KiB/744KiB(77%)][#8e5169 704KiB/1.7MiB(38%)]\n[DL:3.9MiB][#4fcac5 11MiB/16MiB(66%)][#8e5169 1.5MiB/1.7MiB(86%)]\n[#4fcac5 14MiB/16MiB(85%) CN:4 DL:2.8MiB]\n[#4fcac5 15MiB/16MiB(94%) CN:2 DL:2.6MiB]\n[#4fcac5 16MiB/16MiB(98%) CN:1 DL:2.3MiB]\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n5fa3f0|OK  |   4.4MiB/s|/var/cache/apt/archives/apt-fast/libatomic1_4.9.2-10ubuntu13_amd64.deb\nf6998c|OK  |   196KiB/s|/var/cache/apt/archives/apt-fast/libcilkrts5_4.9.2-10ubuntu13_amd64.deb\nb6cb43|OK  |   246KiB/s|/var/cache/apt/archives/apt-fast/libcloog-isl4_0.18.2-3_amd64.deb\nb5514d|OK  |   196KiB/s|/var/cache/apt/archives/apt-fast/libgomp1_4.9.2-10ubuntu13_amd64.deb\na42045|OK  |   317KiB/s|/var/cache/apt/archives/apt-fast/libitm1_4.9.2-10ubuntu13_amd64.deb\nf8e1b6|OK  |   377KiB/s|/var/cache/apt/archives/apt-fast/liblsan0_4.9.2-10ubuntu13_amd64.deb\n0c8450|OK  |   283KiB/s|/var/cache/apt/archives/apt-fast/libasan1_4.9.2-10ubuntu13_amd64.deb\nbf2171|OK  |   781KiB/s|/var/cache/apt/archives/apt-fast/libubsan0_4.9.2-10ubuntu13_amd64.deb\n--->8---\n```\nThe progress portion isn't very helpful and it would be nice to get output that looks like this...\n```\n--->8---\naria2 rpc progress\n[apt-fast 19:57:04] \n Working... this may take a while.\n  00:12 ( 39 of 39 ) [ 3627 : 0 KiB/s ]\n\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\nc1ed00|OK  |   8.8MiB/s|/var/cache/apt/archives/apt-fast/libatomic1_4.9.2-10ubuntu13_amd64.deb\n3f983b|OK  |   327KiB/s|/var/cache/apt/archives/apt-fast/libcilkrts5_4.9.2-10ubuntu13_amd64.deb\n0675d8|OK  |   333KiB/s|/var/cache/apt/archives/apt-fast/libcloog-isl4_0.18.2-3_amd64.deb\n9eefb6|OK  |   370KiB/s|/var/cache/apt/archives/apt-fast/libgomp1_4.9.2-10ubuntu13_amd64.deb\n6c306e|OK  |   9.6MiB/s|/var/cache/apt/archives/apt-fast/libitm1_4.9.2-10ubuntu13_amd64.deb\nd8375e|OK  |   667KiB/s|/var/cache/apt/archives/apt-fast/libasan1_4.9.2-10ubuntu13_amd64.deb\n--->8---\n```\nwhich I can do now by setting --enable-rpc --show-console-readout=false --on-download-stop=aria2c-rpc-progress with this...\n``` bash\n!/bin/sh\nfile: aria2c-rpc-progress\nURL=http://localhost:6800/jsonrpc\nTYPE='content-type: text/plain;'\nJSON='{\"jsonrpc\": \"2.0\", \"id\":\"qwer\", \"method\": \"aria2.getGlobalStat\"}'\nresults=$(curl -sS --data-binary \"${JSON}\" -H \"${TYPE}\" $URL | jq '.result')\nURI queue numbers\nA=$( echo $results | jq -r '.numActive')\nS=\"$( echo $results | jq -r '.numStopped')\"\nW=\"$( echo $results | jq -r '.numWaiting')\"\nT=$(( A + S + W ))\nDown/Up load speed\nDL=$( echo $results | jq -r '.downloadSpeed')\nUL=\"$( echo $results | jq -r '.uploadSpeed')\"\nDL=$(( DL / 1024 ))\nUL=$(( UL / 1024 ))\nDuration time.\nt=$(ps -p $(pgrep -f '^aria2c*') -o etime=)\nPrint out status information\nprintf \"\\r$t ( $S of $T ) [ $DL : $UL KiB/s ]\"\nShutdown when queue is exhausted.\nif [ \"$S\" = \"$T\" ]; then\n    JSON='{\"jsonrpc\": \"2.0\", \"id\":\"qwer\", \"method\": \"aria2.shutdown\"}'\n    curl -sS --data-binary \"${JSON}\" -H \"${TYPE}\"  $URL > /dev/null\nprintf \"\\n\"\n\nfi\n```\nSurely there must be a better way (perhaps that included eta).\n. The script has been cleaned up and posted as a gist with a slightly different output.\n```\n[apt-fast 21:50:21] \n Working... this may take a while.\n Downloading 47MiB of archives from 71 packages.\n00:03   3% [ 1.7MiB / 47MiB @ 1.1MiB/s ][ W: 50 A: 5 S: 16 / 71 (22%) ]\n``\n. @tatsuhiro-t , I'm going to consider this issue closed from my end as the [solution via the api](https://github.com/Thell/dockerfiles/blob/master/scripts/apt-fast-progress.sh) I've been using withapt-fast` has been doing a fantastic job for a few months now.\n. ",
    "vBm": "I wonder if there's a similar way to do it on windows xD\n. I'm sorry for not including the needed info.\nI'm on the latest version, 1.25.0 x64.\nThis is Windows 7 with all the available updates.\n. Just had another crash.\naria2c.exe.9028.zip\nFaulting application name: aria2c.exe, version: 0.0.0.0, time stamp: 0x0048f5d8\nFaulting module name: aria2c.exe, version: 0.0.0.0, time stamp: 0x0048f5d8\nException code: 0xc0000005\nFault offset: 0x0000000000130bca\nFaulting process id: 0x2344\nFaulting application start time: 0x01d1e1b636b04a7e\nFaulting application path: E:\\toolz\\appZ\\aria2c.exe\nFaulting module path: E:\\toolz\\appZ\\aria2c.exe\nReport Id: 762e0209-4daa-11e6-8313-00241dca3466\nI'll downgrade to 1.24.0 for now since that one never crashed. There isn't much that has changed since 1.24.0 and from noob's point of view at the commit logs i don't see any drastic change that could lead to crashing.\n. It took me a while to get a new crash, but here it is. This time tho, it seems it's in ntdll. Logs don't say much unfortunately.\naria2c.exe.5764.dmp.zip\nFaulting application name: aria2c.exe, version: 0.0.0.0, time stamp: 0x0048f5d8\nFaulting module name: ntdll.dll, version: 6.1.7601.23455, time stamp: 0x573a54b7\nException code: 0xc0000374\nFault offset: 0x00000000000bf262\nFaulting process id: 0x1684\nFaulting application start time: 0x01d1e8bf4c1f6515\nFaulting application path: E:\\toolz\\appZ\\aria2c.exe\nFaulting module path: C:\\Windows\\SYSTEM32\\ntdll.dll\nReport Id: 17ede4ad-54b4-11e6-bcec-00241dca3466\nThis is last half a second worth of log. I've masked IPs in the log btw. If you wan't complete log, from starting until the crash (652 MB uncompressed or 26 MB 7z ultra compressed) let me know so i can upload it to some 3rd party hosting.\n. aria2.conf is as follows\n```\ndir=f:/\ndisk-cache=128M\ndht-listen-port=6881\nlisten-port=53001\nenable-dht=true\nenable-peer-exchange=true\nmax-overall-upload-limit=100K\nmax-concurrent-downloads=5\noptimize-concurrent-downloads=true\nbt-min-crypto-level=arc4\nbt-require-crypto=true\nfollow-torrent=true\nseed-time=1000\nsummary-interval=0\nenable-rpc=true\nrpc-listen-all=true\nbt-enable-lpd=true\ncheck-integrity=true\nbt-save-metadata=true\nrpc-save-upload-metadata=true\nsessionfile.txt must exist beforehand IT WONT BE CREATED BY ARIA2. you can use any filename.\ncontinue=true\ninput-file=C:\\Users\\vBm.aria2\\sessionfile.txt\nsave-session=C:\\Users\\vBm.aria2\\sessionfile.txt\nsave-session-interval=300\nlog=C:\\Users\\vBm.aria2\\log.txt\ntruncate-console-readout=false\n```\nI forgot to share that info as well. \nAnything that can be done on my end that would help catching exact problem which would lead to fix?\n. Disabled it. Will reported back as soon as i catch the crash or in case it doesn't happen in lets say next 10 days or so. Thanks for your time.\n. So it's been a good two weeks without the crash ever since I've disabled optimize-concurrent-downloads. I guess it's safe to say that problem must be somewhere in that part of the code.\n(Yes, I've used your debug build for those past two weeks)\nGuess I'll try to turn that option ON again and try with debug build so I can get a dump file that would maybe help you out finding the exact issue.\n. Unfortunately due to hardware failure I've upgraded to Windows10 week ago. I'm unable to reproduce the problem even with enabled optimize-concurrent-downloads. Issue doesn't happen anymore on debug build.\nI can keep trying thou. Or should I just upgrade to latest build and move on since environment isn't the same anymore :/\n. Still haven't had any crashes.\nBeen doing tests with 1.27.1 but nothing.\nThanks for your hard work on this lovely app.\n. ",
    "endormos": "Yes, I know that aria2 is looking in the old dir for compatibility reasons. The problem is that, when looking for dht.dat, it never checks $HOME/.cache/aria2/. It only checks the old dir.\nWhen the strace output above was captured, I had already put my dht.dat in $HOME/.cache/aria2/ and it is there. But aria2 doesn't look for it there. Or at least strace doesn't show aria2 trying to stat the file in the new dir.\nThat's why I thought this behavior might be a bug. :)\n. OK, you're right, it works correctly. I just weren't looking for it the right way. I now realized that aria2 doesn't stat dht.dat until a torrent download is requested. My bad :)\n. ",
    "TonyStark": ":+1:  @nmaier \n. ",
    "everbird": "@tatsuhiro-t  Please add --with-libssh2 in makerelease-osx.mk to support SFTP by default. Thanks.\n. ",
    "nE0sIghT": "Also http://opensource.lge.com/ website requires all download HTTP requests to be POST requests.\nThis is weird, but GET requests are not accepted.. ",
    "edtechd": "OK, thanks guys for your advice, I will try to implement a proxy-tracker and add it to each link, It seems to be the easiest way of organizing proxy for UDP trackers.\n. I have investigated the issue and found that if there is a lot of UDP traffic, receive buffer for the socket may overflow, so some UDP packets can be lost.\nI have solved the issue by increasing default kernel values for receive buffer:\n\nnet.core.rmem_default = 2097152\nnet.core.wmem_default = 2097152\n\nIt should be enough for Gigabit connection. What do you think, does it makes sense to increase socket receive buffer in aria2 depending on some conditions? You can do that by this setsockopt() call:\nsetsockopt(sockfd, SOL_SOCKET, SO_RCVBUF, &newsize, sizeof(int))\n. I didn't change aria2 code.\nI just checked that when you create a socket in aria2, it is created with buffer of net.core.rmem_default size. The fact of buffer overflow can be detected by netstat -su command (number of receive buffer errors). Socket buffer size can be changed by calling setsockopt() function.\nUnfortunately, I don't know how to determine that we need to extend the socket buffer size and how much we need to allocate, but I think that such feature might improve the downloader.\nAlso, before buffer extension I had hostname resolving issues sometimes\n\n11/26 13:14:50 [ERROR] Exception caught\nException: [NameResolver.cc:59] errorCode=19 Failed to resolve the hostname tracker.ccc.de, cause: System error\n\nBut now, they disappeared.\n. Rtorrent has  'send_buffer_size' and 'receive_buffer_size' settings, maybe it would be a good solution to add the same to aria2.\n. Hi Tatsuhiro,\nThanks for this update!\nI also checked send buffer size and found that its use by aria2 is not hard. so I think it is not needed to change this value.\n. There is a private tracker siambit.tv which doesn't allow aria2 but accepts BitComet. But it seems that it checks the exact Peer ID header match. Urlencoded value doesn't work.\nAs a workaround, I can alter function torrentPercentEncode() in my fork for my specific case, I didn't know that some trackers require Peer ID fully urlencoded.\n. Thank you.\n. ",
    "iongion": "This was awesome! Thank you!\nI will build it asap, did not dedicate too much time, but on my old Ubuntu 12.04, the build complaints:\nIn file included from AbstractAuthResolver.cc:37:0:\na2functional.h:193:38: error: expected type-specifier before string constant\nDon't worry, will try to fix it myself and come back with report.\n. ",
    "futuretechmag": "Does --retry-wait get thrown out with using this? It seems to spam the server every ~0.2s for each try. I tried --retry-wait=5 but it doesn't seem to do anything?\n. @tatsuhiro-t  Just to make sure, 'aria2c  --max-file-not-found=100 --retry-wait=5 -Z URI1 UR2 UR3' would then try getting each of those 3 URI's 100 times, waiting 5 seconds between attempts?\n. Just to make sure, 'aria2c --max-file-not-found=100 --retry-wait=5 -Z URI1\nUR2 UR3' would then try getting each of those 3 URI's 100 times, waiting 5\nseconds between attempts? I \"fixed\" it by doing which I BELIEVE always\nretries 404 infinitely, waiting --retry-wait seconds between retries. At\nleast from the looks of it that is exactly what happens anyway.\n} else if(statusCode == 404) {\n   `if(getOption()->getAsInt(PREF_RETRY_WAIT) > 0) {\n     throw DL_RETRY_EX2(fmt(EX_BAD_STATUS, statusCode),\n                        error_code::HTTP_SERVICE_UNAVAILABLE);\n } else if(statusCode == 503) {\nOn Fri, Dec 18, 2015 at 9:05 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\n@futuretechmag https://github.com/futuretechmag Thank you for telling\nme that. 029d689\nhttps://github.com/tatsuhiro-t/aria2/commit/029d6897f2b0d7d2f2bad904dd145cc33f6d35cf\nfixes it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/471#issuecomment-165785277.\n\n\n-Chris A. Gilroy\n. ",
    "mohsenhe": "Hi,\nIt is not gzipped. I always gunzip and this time I did a less to make sure that its not gzipped.That is the reason why I download the torrent file first. Here's the full logs of the same file:\n\n[~/tmp] mv 6E0F6FFB0908FD215EF2A8BCDD1DFBA019CCA2B8.torrent 6E0F6FFB0908FD215EF2A8BCDD1DFBA019CCA2B8.torrent.gz\n[~/tmp] gunzip 6E0F6FFB0908FD215EF2A8BCDD1DFBA019CCA2B8.torrent.gz\n[~/tmp] ls 6\n6E0F6FFB0908FD215EF2A8BCDD1DFBA019CCA2B8.torrent\n[~/tmp] less 6E0F6FFB0908FD215EF2A8BCDD1DFBA019CCA2B8.torrent\nd8:announce36:udp://open.demonii.com:1337/announce13:announce-listll36:udp://open.demonii.com:1337/announceel38:udp://tracker.publicbt.com:80/announceel44:udp://tracker.openbittorrent.com:80/announceel35:udp://tracker.istole.it:80/announceel43:udp://fr33domtracker.h33t.com:3310/announceee26:azureus_private_propertiesd13:obtained_from326:magnet:?xt=urn:btih:6e0f6ffb0908fd215ef2a8bcdd1dfba019cca2b8&dn=The.Kite.Runner.2007.720p.BluRay.x264.anoXmous&tr=udp%3A%2F%2Ftracker.publicbt.com%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Ffr33domtracker.h33t.com%3A3310%2Fannounce&tr=udp%3A%2F%2Ftracker.istole.it%3A80%2Fannounce10:peer_cached13:tracker_peersld2:ip14:197.35.232.2084:porti10051e4:proti1eed2:ip11:41.79.71.114:porti1040e4:proti1eed2:ip14:115.248.123.774:porti51932e4:proti1eed2:ip11:189.74.42.54:porti41618e4:proti1eed2:ip14:45.114.121.1004:porti20757e4:proti1eed2:ip14:112.198.103.754:porti33346e4:proti1eed2:ip11:92.6.18.1884:porti56716e4:proti1eed2:ip12:89.77.129.134:porti11373e4:proti1eed2:ip14:27.106.123.1324:porti15759e4:proti1eed2:ip14:105.103.96.2324:porti15326e4:proti1eed2:ip14:76.184.250.2434:porti60190e4:proti1eed2:ip14:27.106.123.1764:porti15759e4:proti1eed2:ip13:52.26.135.2534:porti18233e4:proti1eed2:ip13:85.23.163.1864:porti24351e4:proti1eed2:ip10:39.54.1.384:porti16235e4:proti1eed2:ip15:177.133.126.2104:porti18879e4:proti1eed2:ip13:41.133.186.414:porti26329e4:proti1eed2:ip14:78.243.204.1604:porti1024e4:proti1eed2:ip13:138.88.42.2434:porti26085e4:proti1eed2:ip15:201.113.113.2454:porti38537e4:proti1eed2:ip13:5.107.126.1414:porti24874e4:proti1eed2:ip12:52.11.39.1794:porti17335e4:proti1eed2:ip13:83.150.17.2004:porti39379e4:proti1eed2:ip13:183.90.37.1234:porti18032e4:proti1eed2:ip13:183.90.37.1234:porti18050e4:proti1eed2:ip14:117.212.74.1574:porti13646e4:proti1eed2:ip13:183.90.37.1234:porti18055e4:proti1eed2:ip15:217.208.215.1974:porti54622e4:proti1eed2:ip11:41.79.71.114:porti19662e4:proti1eed2:ip14:189.81.216.1324:porti26867e4:proti1eed2:ip13:212.251.18.714:porti22898e4:proti1eed2:ip13:178.84.125.374:porti49727e4:proti1eed2:ip13:201.33.178.984:porti24874e4:proti1eed2:ip13:183.90.37.1234:porti27233e4:proti1eed2:ip12:39.42.125.444:porti43481e4:proti1eed2:ip13:182.189.46.174:porti41236e4:proti1eed2:ip13:183.90.37.1234:porti27234e4:proti1eed2:ip15:112.198.103.1154:porti6881e4:proti1eed2:ip14:95.211.190.2054:porti55251e4:proti1eed2:ip14:189.35.139.2344:porti52325e4:proti1eed2:ip14:113.193.48.2034:porti16031e4:proti1eed2:ip13:117.199.52.574:porti30257e4:proti1eed2:ip12:189.40.41.104:porti44747e4:proti1eed2:ip11:46.1.239.254:porti6881e4:proti1eed2:ip13:93.159.143.444:porti22256e4:proti1eed2:ip14:37.130.117.2204:porti38789e4:proti1eed2:ip15:182.186.121.2424:porti17696e4:proti1eed2:ip14:112.198.103.754:porti43414e4:proti1eed2:ip15:182.178.175.1414:porti23113e4:proti1eed2:ip11:41.137.12.24:porti26182e4:proti1eed2:ip12:89.23.238.994:porti14020e4:proti1eed2:ip14:115.248.123.774:porti50380e4:proti1eed2:ip11:80.43.12.924:porti3061e4:proti1eed2:ip15:178.149.229.1084:porti59921e4:proti1eed2:ip14:189.46.159.1804:porti6881e4:proti1eed2:ip15:151.228.144.1624:porti53493e4:proti1eed2:ip14:67.173.241.1064:porti47118e4:proti1eed2:ip13:177.18.251.684:porti60957e4:proti1eed2:ip12:39.57.115.394:porti35097e4:proti1eed2:ip14:175.110.84.1084:porti57175e4:proti1eed2:ip12:176.63.8.1504:porti35334e4:proti1eed2:ip15:203.218.219.1394:porti62348e4:proti1eed2:ip14:138.51.242.2174:porti42685e4:proti1eed2:ip15:179.105.121.1704:porti30348e4:proti1eed2:ip13:94.69.232.2304:porti39751e4:proti1eed2:ip13:158.181.41.914:porti21790e4:proti1eed2:ip13:138.36.32.1644:porti61024e4:proti1eed2:ip13:81.97.222.2064:porti36894e4:proti1eed2:ip14:197.97.101.1504:porti62721e4:proti1eed2:ip11:95.7.35.2534:porti3931e4:proti1eed2:ip12:52.11.39.1794:porti6881e4:proti1eed2:ip13:188.27.23.1564:porti52405e4:proti1eed2:ip14:213.57.253.2534:porti25565e4:proti1eed2:ip12:85.75.65.1824:porti55802e4:proti1eed2:ip15:182.183.237.1444:porti13086e4:proti1eed2:ip13:158.181.41.914:porti4073e4:proti1eed2:ip14:112.198.103.754:porti23278e4:proti1eed2:ip13:109.228.74.554:porti17090e4:proti1eed2:ip13:177.40.178.774:porti27829e4:proti1eed2:ip14:177.68.217.1464:porti26795e4:proti1eed2:ip13:92.99.199.1174:porti38824e4:proti1eed2:ip13:183.90.37.1234:porti26655e4:proti1eed2:ip14:173.238.179.364:porti59534e4:proti1eed2:ip13:183.90.37.1234:porti26892e4:proti1eed2:ip14:71.204.183.2104:porti22159e4:proti1eed2:ip14:175.139.202.774:porti20540e4:proti1eed2:ip13:196.207.77.154:porti28687e4:proti1eed2:ip15:177.158.172.2524:porti57832e4:proti1eed2:ip15:124.189.137.2524:porti35885e4:proti1eed2:ip15:205.250.122.2044:porti63931e4:proti1eed2:ip15:122.172.173.1824:porti50225e4:proti1eed2:ip12:121.54.40.564:porti6881e4:proti1eed2:ip13:85.250.221.784:porti1042e4:proti1eed2:ip12:39.47.16.2554:porti51687e4:proti1eed2:ip12:89.153.5.1754:porti59696e4:proti1eed2:ip12:81.12.209.584:porti58485e4:proti1eed2:ip15:182.185.249.2204:porti24605e4:proti1eed2:ip15:103.252.201.1454:porti16327e4:proti1eed2:ip14:189.68.149.1374:porti26795e4:proti1eed2:ip14:89.177.101.1704:porti63525e4:proti1eed2:ip13:190.172.9.1634:porti43611e4:proti1eed2:ip13:183.90.37.1234:porti26635e4:proti1eeee16:peer_cache_validi-2.6960757756466E+18ee7:comment61:Torrent downloaded from torrent cache at http://torcache.net/4:infod13:file-durationli0ei7663ei0ei0ei0ei0ei0ee10:file-mediali-1ei0ei-1ei-1ei-1ei-1ei-1ee5:filesld6:lengthi1965e4:pathl5:i.nfoeed6:lengthi1439461945e4:pathl51:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous_.mp4eed6:lengthi71489e4:pathl54:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous_dan.srteed6:lengthi85863e4:pathl54:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous_eng.srteed6:lengthi66916e4:pathl54:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous_fin.srteed6:lengthi74723e4:pathl54:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous_nor.srteed6:lengthi69151e4:pathl54:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous_swe.srteee4:name46:The.Kite.Runner.2007.720p.BluRay.x264.anoXmous12:piece lengthi2097152e6:pieces13740:Gt<8C>^R}<98>(\n<97><98><83>!<99><85>eqFV:^N<87><86>^Q<9B>yb~uS#?X=|y<89><FB><EA><AF>^NQNz4<B9>t^<99><EC>K<8C><E7>RC<E4><8D>c\n<AA><F0>^L<F8>}<D7><C2>n$9^^<A2><89>|^P_h<CD>\"D<BE>u<D2><8A>X:]N<B6>%}<FF><99>\n<E9>A<96>'^Y<FB>m<D4><81><A3>YN0<F0>/s<B6>^R=<98><AA><8A>)<^@S^G<C4>^L<91><A6>F7<90>{<E9>*<CD><A3><A8><A0>6<A3>^])^O<AB>^A}<FB><C5><C8><8D><F0>Z<A7>^H+<EB><D4>\n<BA>^Y<B2>I^Q<D4><FA>kC@<F3><9E><FE><AC><A6><F7>m<F4>T6Nt^B4^N<85><DB>*G<B9>VD(s[<CB>6<DC><B1>>2<9C>Ng<BC>D<D7><8B><ED><CB><83><B5><CB><8D>6<E9><AE>\\<A4><FE>\n<A9><E1><E5>E<CD><DD>,e<95>e<A4><89><9C>(f<AE><DE><CD><AA><A5><C1>Z?6<8C><82>^X]<E8><A6>,<F0><CF><BA><B5>D<9D>k06<CE>XPD<F6><A9><C9><8F><C6>^\"-<97><96><99>^LHm\n<91>^B/<9B><C3><E7><94><D1>z<8B><P^G<A1><85><F9><E3><9F><EF>M<9A>}^B|^LQ<92>|\n<BA><DB><85>&^OHV0,Vp^_^C<99><8B><99>3\n<8A><82>V;(^L^^l(^<82><9B>Cc^DI<89>^C<90>\n<99>6^]P^<93>v<9D>\n<95>G=y;d2i<88>G%^@k?5y^N^R^RT'U^_a\n     ^C0Z<9B>)^A^A<80><90>Ei<93><9F>..fn^S[.Rz42F^?L8^Vv<87><85>W{<9C>N<86>jWCg|oidI=^Fx<87>On-b\n^C3K}xQ^?f<9D>^^W)<8D><=\n<96>ESCFe^O<8F>^O5D^AJ<9F>-}0<95><8F>c<8A>AM^ZS6^EVa^H$<9B>q<88>+r:$=<9F><95>\n{7^P<F7><8C><C7>\n<D0>j^U<C0>2<D5>^\\<A8><C6><A1>,^]<CB>YNr^S^U<B7>(^<BA><91>@<89><84><93>^]\n<98>>\nh,<8C>hESCY^Ad^?z2<88>8j<9E>-<9B>\nKeb^K>_@<B7>}^<D2><CB><EC><88><F1>1<AE><AB><FF>^Z<AE><C5><F0><CA><83>(@<DD>%^S<B8>Q!^Xi<9F><AD>><B7><D5><C6>'^Nz<F3><B8>^}q<C9><AD><83>\n<97><83>#f<C1>^E4WD^O<AA><B0><D3>Z<]<AD>d^BN<87>^CX^Qi<FF><D3>^Qwx2f#<DA><F2>^VU^]a:E>^Q<E0>dAN<DD><D7><E9>;T<9E>    <ED>C<E4>3<C9>&<B2><A9><A7><CF><F7>.<C3>>\n<F7><C9>K<B9><93><BD><C6>^Z<9D><A9><C9>I<86><D0>v<86><D2>2<DD><F4><B0><CF>^K^Fb\n<C6>D^Y<C2>^F<DF><F1><83><BC>   <F3><D8>^B?a*<8D><C9>^]C^C<C5><C9><B6>;^E<9B><E9><BA>6^U<CA><B3><E1><A0><8B><85><A9><E4><C3>@^T<92>+0B<F9><D7>MHL^L\n<90><A3>'^L)^]]7<D4><FF>M'JJ<E4>^C^XV:2<AD><FB><AB><F8><AC>9<A3><E9>m<A5><C5>D\n<CC><B0>~^Y#<C5><C2><E2>w#<FB>[(<F6><C7>m<C1><BE>A<BB>0<8F>2^T<E8>Nm<E0><95><9E>f7<CA>^D<86>]<C6>5<F7><99><91>T|<E6>j<A0><E5>h\ntO<CB><F1>m/^@R<F2><87>=<94><8F><9B><BF><B7><F1><9F><F3>J<C6>W<85>-6<99>/.W(<C2>;<F8><81><81><C9><DF><DD><8C>D)<90>F^Zd<9C>\n/<9A>o<F1>w<E9>+'|5^L<8C>[<BA><DB>.7<DD>D<F1><D4><D8>$^D^Hs(^Lc!Xps      )<9E>S{<9D>iL?p^D^G^@O      ;O<9C>^^X20<8C>2'u}^Ed<82>^S<9F>B_\n[~/tmp] aria2c -T 6E0F6FFB0908FD215EF2A8BCDD1DFBA019CCA2B8.torrent -S\nException caught\nException: [bittorrent_helper.cc:416] errorCode=26 torrent file does not contain a root dictionary.\n[~/tmp]\n. I am not too familiar with the standard but the same file works perfectly fine on utorrent and other bit torrent clients.\n\nCan you please fix it so that it works.\nThanks\n. ",
    "txtsd": "Since http/2 doesn't need multiple TCP connections, multipart downloading behavior can be modified to dynamically split and request parts of a file, instead of having a 1M minimum size and 16 maximum parts as hard limits.\n@tatsuhiro-t What do you think?\n. Those are excellent reasons for HTTP/2 support :)\n. What is the switch to create a control file? I'd like to add it to my conf because there's no control file being created in the torrent's top level directory.\n. @amirotin It still rechecks the entire torrent when I use force-save=true\n. Ah! So realtime-chunk-checksum is the only flag it needs to check pieces while downloading?\nAnd I should only use check-integrity when I want to verify the entire torrent?\n. Great! Thanks for clearing this up!\n. You will have to run aria2c on your VPS, and connect to it via a web interface using the built-in RPC.. I think you mean May 14, 2018 . ",
    "shamidrasool": "\n1M min size is just an architecture limit of aria2. It could be less, say, 256KiB, but 1 byte is too small for the current aria2 architecture.\n\nSorry to jump in on an age old issue. How can I lower this limit, in perhaps a custom build to say 100 KiB. I am having difficulty finding it in the source code. This is for the general case, not related to HTTP/2.\n. ",
    "bremby": "Perfect, thank you. If I understand the code correctly, you attempt to evict descriptors every 30 seconds, am I right?\nAnyway, thanks for such quick resolution. I would donate, but I didn't find any donation info.\n. Sorry to hear that, that sucks.\nWill you be making a new release? I am using Arch Linux, so no problem if you don't. Also, if you tested the fix, you can close the issue. I'll reopen it if necessary.\n. ",
    "bigcat26": "thank you for the quick reply.\nThis problem occurs more frequently when I download big files (with BT or magnet).\nMy computer is running ubuntu 14.04 x86_64, kernel version 3.16.0-52. \npartition format of download dir: ext4\nconfiguration as follows:\nRPC Setting\n\nenable-rpc=true\nrpc-listen-all=true\nrpc-allow-origin-all=true\nrpc-listen-port=6800\nrpc-user=rpc_user\nrpc-passwd=rpc_passwd\nrpc-save-upload-metadata=true\nsession\ncontinue=true\ninput-file=/root/.aria2/aria2.session\nsave-session=/root/.aria2/aria2.session\nsave-session-interval=60\ngeneral settings\n\ndir=/root/.aria2/downloads\nlog=/root/.aria2/aria2.log\nlog-level=warn\nevent-poll=select\ndisk-cache=256M\nenable-mmap=true\nfile-allocation=falloc\npeer-id-prefix=-UT2210-\nuser-agent=uTorrent/2210(25130)\ndisable-ipv6=true\nconnection settings\n\nmax-connection-per-server=5\nmax-concurrent-downloads=5\nmin-split-size=1M\nsplit=5\nmax-overall-download-limit=0\nmax-overall-upload-limit=30K\nmax-upload-limit=30K\nlowest-speed-limit=0\nauto-save-interval=60\ncheck-certificate=false\nBT settings\n\nlisten-port=53160\nbt-enable-lpd=true\nbt-require-crypto=true\nbt-max-peers=200\nbt-max-open-files=100\nbt-request-peer-speed-limit=100K\nenable-peer-exchange=true\nenable-dht=true\ndht-listen-port=53160\ndht-file-path=/root/.aria2/aria2.dht\nfollow-torrent=true\nfollow-metalink=true\nforce-save=true\nbt-seed-unverified=true\nbt-save-metadata=true\nbt-hash-check-seed=true\nbt-remove-unselected-file=true\nbt-stop-timeout=900\ncheck-integrity=true\n. I was running 4 BT tasks, 1GB, 4GB, 7GB and 24GB(multiple files), the largest file is a 7GB zip.\nI don't know which task cause the crash exactly.\nAfter I wrote down last comment I changed the configuration \"enable-mmap\" from \"true\" to \"false\" and run aria2 again, works fine so far.\n. PS: \nBefore I open this issue, I compiled aria2 myself instead of install by apt-get, to get the crash backtrace. git commit: af98861aff50737f87d9c251ee9a68280bba3e64\nroot@E8400:~/work/aria2/aria2# aria2c -v\naria2 version 1.19.2\nCopyright (C) 2006, 2015 Tatsuhiro Tsujikawa\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n* Configuration *Enabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 libxml2/2.9.1 sqlite3/3.8.2 GnuTLS/2.12.23 nettle GMP/5.1.3 c-ares/1.10.0 libssh2/1.4.3\nCompiler: gcc 4.8.4\n  built by   x86_64-unknown-linux-gnu  on         Nov 12 2015 16:01:43\nSystem: Linux 3.16.0-52-generic #70~14.04.1-Ubuntu SMP Tue Oct 20 18:24:26 UTC 2015 x86_64\n. Is that possible if insufficient disk space or bad track may cause the crash?\nAnyway, disable mmap does works. Shall I close the issue?\nThanks for your help.\n. ",
    "donly": "\"Masked\" from Gentoo emerge search shows\n\nnet-misc/aria2 [ Masked ]\nSome software packages are masked so that users can be properly warned before installing them.\n\nhttps://wiki.gentoo.org/wiki/Knowledge_Base:Unmasking_a_package\n. I'll do that, thanks!\n. ",
    "andrea-bigi": "obiouvsly also the first file exists...\n. Here you are\nThank you\nAndrea (from Italy)\nDa: Tatsuhiro Tsujikawa [mailto:notifications@github.com]\nInviato: sabato 21 novembre 2015 16:51\nA: tatsuhiro-t/aria2 aria2@noreply.github.com\nCc: Bigi Andrea abigi@ferrettogroup.com\nOggetto: Re: [aria2] problem with simple input file (#488)\nCan you reproduce this with just one failing URI?\nI'd like see the aria2 log (-l option) to know what happened the behind the scenes.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/488#issuecomment-158657469.\n2015-11-21 18:57:34.205313 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 18:57:34.206313 [INFO] [Context.cc:184] Logging started.\n2015-11-21 18:57:34.206313 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 18:57:34.209313 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 18:57:47.053048 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 18:57:47.054048 [INFO] [Context.cc:184] Logging started.\n2015-11-21 18:57:47.054048 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 18:57:47.060048 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 18:57:47.061048 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 18:57:47.061048 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 18:57:47.061048 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 18:57:47.061048 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 18:57:47.061048 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 18:57:47.061048 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 18:57:47.062049 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 18:57:47.062049 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 18:57:47.062049 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 18:57:47.062049 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 18:57:47.062049 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 18:57:47.062049 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 18:57:47.062049 [DEBUG] [RequestGroup.cc:931] GID#02fc6a4ed7334eb6 - Request queue check\n2015-11-21 18:57:47.062049 [NOTICE] [RequestGroupMan.cc:401] Download GID#02fc6a4ed7334eb6 not complete: \n2015-11-21 18:57:47.062049 [DEBUG] [RequestGroup.cc:1125] GID#02fc6a4ed7334eb6 - Creating DownloadResult.\n2015-11-21 18:57:47.063049 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n2015-11-21 18:58:52.306780 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 18:58:52.307780 [INFO] [Context.cc:184] Logging started.\n2015-11-21 18:58:52.307780 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 18:58:52.314781 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 18:58:52.315781 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 18:58:52.317781 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 18:58:52.317781 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 18:58:52.317781 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 18:58:52.317781 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 18:58:52.318781 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 18:58:52.318781 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 18:58:52.318781 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 18:58:52.318781 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 18:58:52.318781 [DEBUG] [RequestGroup.cc:931] GID#b57f2c1e771ce28d - Request queue check\n2015-11-21 18:58:52.318781 [NOTICE] [RequestGroupMan.cc:401] Download GID#b57f2c1e771ce28d not complete: \n2015-11-21 18:58:52.318781 [DEBUG] [RequestGroup.cc:1125] GID#b57f2c1e771ce28d - Creating DownloadResult.\n2015-11-21 18:58:52.319781 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n2015-11-21 19:00:18.340701 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 19:00:18.341701 [INFO] [Context.cc:184] Logging started.\n2015-11-21 19:00:18.341701 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 19:00:18.346702 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 19:00:18.347702 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 19:00:18.347702 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 19:00:18.347702 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 19:00:18.347702 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 19:00:18.347702 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 19:00:18.347702 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 19:00:18.348702 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 19:00:18.348702 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 19:00:18.348702 [DEBUG] [RequestGroup.cc:931] GID#7d650c85aab92787 - Request queue check\n2015-11-21 19:00:18.348702 [NOTICE] [RequestGroupMan.cc:401] Download GID#7d650c85aab92787 not complete: \n2015-11-21 19:00:18.348702 [DEBUG] [RequestGroup.cc:1125] GID#7d650c85aab92787 - Creating DownloadResult.\n2015-11-21 19:00:18.348702 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 19:00:47.351361 [INFO] [Context.cc:184] Logging started.\n2015-11-21 19:00:47.352361 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 19:00:47.354361 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 19:00:47.354361 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 19:00:47.354361 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 19:00:47.354361 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 19:00:47.355361 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 19:00:47.355361 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 19:00:47.355361 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 19:00:47.355361 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 19:00:47.355361 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 19:00:47.355361 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 19:00:47.355361 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 19:00:47.355361 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 19:00:47.355361 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 19:00:47.356361 [DEBUG] [RequestGroup.cc:931] GID#f292dfe8cc8333db - Request queue check\n2015-11-21 19:00:47.356361 [NOTICE] [RequestGroupMan.cc:401] Download GID#f292dfe8cc8333db not complete: \n2015-11-21 19:00:47.356361 [DEBUG] [RequestGroup.cc:1125] GID#f292dfe8cc8333db - Creating DownloadResult.\n2015-11-21 19:00:47.356361 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n2015-11-21 19:00:50.128519 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 19:00:50.129519 [INFO] [Context.cc:184] Logging started.\n2015-11-21 19:00:50.129519 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 19:00:50.132520 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 19:00:50.133520 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 19:00:50.133520 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 19:00:50.133520 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 19:00:50.133520 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 19:00:50.133520 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 19:00:50.133520 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 19:00:50.133520 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 19:00:50.133520 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 19:00:50.133520 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 19:00:50.134520 [DEBUG] [RequestGroup.cc:931] GID#e4cb52443b81783a - Request queue check\n2015-11-21 19:00:50.134520 [NOTICE] [RequestGroupMan.cc:401] Download GID#e4cb52443b81783a not complete: \n2015-11-21 19:00:50.134520 [DEBUG] [RequestGroup.cc:1125] GID#e4cb52443b81783a - Creating DownloadResult.\n2015-11-21 19:00:50.134520 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 19:00:51.274585 [INFO] [Context.cc:184] Logging started.\n2015-11-21 19:00:51.274585 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 19:00:51.278585 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 19:00:51.279585 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 19:00:51.279585 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 19:00:51.279585 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 19:00:51.279585 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 19:00:51.279585 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 19:00:51.279585 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 19:00:51.279585 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 19:00:51.279585 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 19:00:51.279585 [DEBUG] [RequestGroup.cc:931] GID#754f3f2df86ec367 - Request queue check\n2015-11-21 19:00:51.279585 [NOTICE] [RequestGroupMan.cc:401] Download GID#754f3f2df86ec367 not complete: \n2015-11-21 19:00:51.281585 [DEBUG] [RequestGroup.cc:1125] GID#754f3f2df86ec367 - Creating DownloadResult.\n2015-11-21 19:00:51.281585 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n2015-11-21 19:00:56.169865 [INFO] [Context.cc:177] <<--- --- --- ---\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:178]   --- --- --- ---\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:179]   --- --- --- --->>\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:180] aria2 1.19.2\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:181] mingw-w64 4.0 (stable) / gcc 4.9.2\n  built by   x86_64-unknown-linux-gnu\n  targetting x86_64-w64-mingw32\n  on         Oct  4 2015 18:13:42\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:182] Windows 7 (Service Pack 1) (x86_64) (6.1)\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:183] zlib/1.2.8 expat/2.1.0 sqlite3/3.8.11.1 GMP/6.0.0 c-ares/1.10.0 libssh2/1.6.0\n2015-11-21 19:00:56.170865 [INFO] [Context.cc:184] Logging started.\n2015-11-21 19:00:56.170865 [INFO] [SocketCore.cc:1520] Checking configured addresses\n2015-11-21 19:00:56.175865 [INFO] [SocketCore.cc:1585] Not considered: fe80::7976:82ae:e71d:aade%14\n2015-11-21 19:00:56.175865 [INFO] [SocketCore.cc:1585] Not considered: 169.254.170.222\n2015-11-21 19:00:56.175865 [INFO] [SocketCore.cc:1585] Not considered: fe80::34ef:4fd6:b593:a26f%13\n2015-11-21 19:00:56.175865 [INFO] [SocketCore.cc:1585] Not considered: 169.254.162.111\n2015-11-21 19:00:56.175865 [INFO] [SocketCore.cc:1585] Not considered: fe80::84d2:58e1:6286:724f%12\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: 169.254.114.79\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: fe80::2946:5e32:9091:be0e%11\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.0.8\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: fe80::498f:14fc:4d1f:16ea%25\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: 169.254.22.234\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: fe80::f432:4447:c88e:4af8%26\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1583] Found configured address: 192.168.88.1\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: ::1\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1585] Not considered: 127.0.0.1\n2015-11-21 19:00:56.176865 [INFO] [SocketCore.cc:1593] IPv4 configured=1, IPv6 configured=0\n2015-11-21 19:00:56.176865 [DEBUG] [RequestGroupMan.cc:536] 1 RequestGroup(s) added.\n2015-11-21 19:00:56.176865 [DEBUG] [AbstractCommand.cc:187] CUID#6 - socket: read:0, write:0, hup:0, err:0\n2015-11-21 19:00:56.176865 [DEBUG] [FeedbackURISelector.cc:159] Selected from normCands\n2015-11-21 19:00:56.176865 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected %EF%BB%BFftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n2015-11-21 19:00:56.176865 [DEBUG] [FileEntry.cc:437] Found 0 reusable URIs\n2015-11-21 19:00:56.177865 [DEBUG] [AbstractCommand.cc:357] Exception caught\nException: [CreateRequestCommand.cc:108] errorCode=-1 No URI available.\n2015-11-21 19:00:56.177865 [DEBUG] [AbstractCommand.cc:475] CUID#6 - Aborting download\n2015-11-21 19:00:56.177865 [DEBUG] [AbstractCommand.cc:421] CUID#6 - Not trying next request. No reserved/pooled request is remaining and total length is still unknown.\n2015-11-21 19:00:56.177865 [DEBUG] [RequestGroup.cc:931] GID#c7f79b1866f0bd6f - Request queue check\n2015-11-21 19:00:56.177865 [NOTICE] [RequestGroupMan.cc:401] Download GID#c7f79b1866f0bd6f not complete: \n2015-11-21 19:00:56.177865 [DEBUG] [RequestGroup.cc:1125] GID#c7f79b1866f0bd6f - Creating DownloadResult.\n2015-11-21 19:00:56.177865 [DEBUG] [RequestGroupMan.cc:438] 1 RequestGroup(s) deleted.\n\ufeffftp://ftp.ferrettogroup.com/Download/7z920-x64.msi\n. ok, I found the problem. it was a strange file encoding. sorry for disturb you.\n. Ok, but it seems that .aria2 control files keep track of the download of the single file.\nThe question is: is there a pre-download-start-phase that computes how many total bytes are requested for the download of all the files specified in the input-file ?\nBye\nAndrea\nDa: BeketovOleksii [mailto:notifications@github.com]\nInviato: marted\u00ec 1 dicembre 2015 14:32\nA: tatsuhiro-t/aria2 aria2@noreply.github.com\nCc: Bigi Andrea abigi@ferrettogroup.com\nOggetto: Re: [aria2] C# graphical wrapper to Aria2c (#497)\nhi,\ni've used .aria2 control files for that purpose. They contain info on the whole file's size and a bitfield section which active bits represents downloaded fragments of file, that gives possibility to count out the download progress.\nsincerely,\nOleksii\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/497#issuecomment-160969174.\n. I\u2019ve seen --truncate-console-readout option, and I set it to false to show all the data about active download.\nThe matter is \u201cactive download\u201d, I\u2019d like to see the total size of ALL the files to download.\nBut I\u2019ve understood that Aria2 doesn\u2019t compute this before starting downloading (this is not a disapproval\u2026.aria2 is a great software !!!)\nThanks\nAndrea Bigi\nDa: Tatsuhiro Tsujikawa [mailto:notifications@github.com]\nInviato: marted\u00ec 1 dicembre 2015 16:12\nA: tatsuhiro-t/aria2 aria2@noreply.github.com\nCc: Bigi Andrea abigi@ferrettogroup.com\nOggetto: Re: [aria2] C# graphical wrapper to Aria2c (#497)\nDoes --truncate-console-readout help?\nhttp://aria2.sourceforge.net/manual/en/html/aria2c.html#cmdoption--truncate-console-readout\nIf you want all active downloads, you have to use RPC.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/497#issuecomment-160996799.\n. Sure\nInviato da Samsung Mobile\n-------- Messaggio originale --------\nDa: Tatsuhiro Tsujikawa notifications@github.com\nData: 02/12/2015 15:00 (GMT+01:00)\nA: tatsuhiro-t/aria2 aria2@noreply.github.com\nCc: Bigi Andrea abigi@ferrettogroup.com\nOggetto: Re: [aria2] C# graphical wrapper to Aria2c (#497)\nThanks. Can we close this issue?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/tatsuhiro-t/aria2/issues/497#issuecomment-161302177.\n. ",
    "droid-Q": "ok,thanks.it is  encrypted.The value field is empty.\n. ",
    "KANGOD": "Shall we update the #load-cookies doc? Since it's not real now.. ",
    "o-beketov": "hi,\ni've used .aria2 control files for that purpose. They contain info on the whole file's size and a bitfield section which active bits represents downloaded fragments of file, that gives possibility to count out the download progress.\nsincerely,\nOleksii\n. I've got the point. The first execution takes place in case if the .meta4 file is being loaded first.\nThx!\n. ",
    "Spider-Mann": "or you start Aria2 with the following line in an VB-Script:\nCreateObject(\"WScript.Shell\").Run \"aria2c.exe --conf-path=aria2.conf\",0,True\n. Something like a torrent file, but especially from One-Click-Hoster for downloads with an download manager (e.g. JDownloader or CryptLoad ) used.\nCCF = CryptLoad Container File\nDLC = Download Link Container\nRSDF = RapidShare Download File\n. I have found the following:\nhttp://www.netcoders.cc/forum/showthread.php?405-Release-nCdecontainer-(DLC-CCF-RSDF-container-decrypter)\nand\nhttp://dcrypt.it/\nBut when aria2 could also would be easier.\n. ",
    "jashking": "Run aria2c.exe without console window. @tatsuhiro-t \nAccording to the document:\n\nIf you want libaria2 dll with --enable-libaria2, then don't use ARIA2_STATIC=yes and prepare the DLL version of external libraries.. \n",
    "ShyPixie": "tatsuhiro-t: No, here is my command line:\n/usr/bin/aria2c -j 5 -x 5 -k 5M --async-dns=false https://github.com/atom/atom/releases/download/v1.2.3/atom-amd64.deb\n. I'm testing again. About every 5 attempts 1 receives this error. Maybe it's something related to the connection speed. But the aria should not retry at least once in case this error occurs?\n. All right. Thank you. \n. ",
    "thorsummoner": "You can also create the file ~/.aria2/aria2.conf and add the line: to it.\n#~/.aria2/aria2.conf\nasync-dns=false\n\n. ",
    "alienx2": "anyway i found out.. i did switched to entware from optware bec optware look old version... now its working =)\n. @tatsuhiro-t Does this feature released out Aria2c v1.20?\n. Thanks to @jackjm \nits working with aria2\u2026 i use code like this:\nfor f in /your/path/folder/*.torrent; do diana add \"$f\";mv \"$f\" \"$f.1\"; done;for d in /your/path/folder/watch/*.1; do mv \"$d\" \"/your/path/folder/done\"; done;\nthen use with cronjob every 30mins\u2026\nget diana file from https://github.com/baskerville/diana\n. same here Aria2 went frozen on Asuswrt Merlin then Aria2 kill self (not found aria2 on TOP)... nzbget and rutorrent was okay..\n. @tatsuhiro-t \nlog:\n2016-02-01 09:22:24.611598 [ERROR] [AbstractCommand.cc:377] CUID#3240 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%17%5E%D6%F76%5F%C5%9D%7DO%B1%EB%3Be2%87%81%F38%08&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=32768&downloaded=177881088&left=389222164&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=50&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 09:24:17.079139 [ERROR] [AbstractCommand.cc:377] CUID#3541 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%CB%1C%85C%E2%B8%5C%3D%D4%FE%08%F3%5C%EC%B2A%C5W%C6%25&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=0&downloaded=50102272&left=337449504&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 09:27:25.216052 [ERROR] [AbstractCommand.cc:377] CUID#3966 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%10%18%00%2A%06%E8%02%EBZ%E4%87%16a%0C%11%D4%B2U%B9%1E&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=0&downloaded=56000512&left=375394872&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 09:49:32.517631 [ERROR] [AbstractCommand.cc:377] CUID#8213 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=j%C9r%CEM%07Yn%7D%D4%0Cd%01%DC%EB%F6%E03c%BD&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=0&downloaded=154107904&left=337510400&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 09:55:16.931849 [ERROR] [AbstractCommand.cc:377] CUID#9252 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%17%5E%D6%F76%5F%C5%9D%7DO%B1%EB%3Be2%87%81%F38%08&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=32768&downloaded=341327872&left=319950612&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 10:43:14.885413 [ERROR] [AbstractCommand.cc:377] CUID#16898 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=j%C9r%CEM%07Yn%7D%D4%0Cd%01%DC%EB%F6%E03c%BD&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=0&downloaded=332365824&left=251838464&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 10:47:15.613536 [ERROR] [AbstractCommand.cc:350] CUID#17908 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%974%EA%F2%CB%14%C1%3C%3A%A1%18%5E%A5%F7%0Aw%7F6%BA%8D&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=524288&downloaded=767736613&left=144195584&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [AbstractCommand.cc:350] errorCode=19 URI=http://open.nyaatorrents.info:6544/announce?info_hash=%974%EA%F2%CB%14%C1%3C%3A%A1%18%5E%A5%F7%0Aw%7F6%BA%8D&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=524288&downloaded=767736613&left=144195584&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\n  -> [NameResolver.cc:59] errorCode=19 Failed to resolve the hostname open.nyaatorrents.info, cause: Name or service not known\n2016-02-01 10:47:26.159063 [ERROR] [AbstractCommand.cc:377] CUID#17855 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%8B%2C%CC5%995P%5Eq%CAC%5E%F6%2Fc2%88%CE%84%19&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=49152&downloaded=506986496&left=163430400&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [AbstractCommand.cc:867] errorCode=1 Failed to establish connection, cause: Connection timed out\n2016-02-01 10:47:26.217216 [ERROR] [AbstractCommand.cc:377] CUID#17809 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%17%5E%D6%F76%5F%C5%9D%7DO%B1%EB%3Be2%87%81%F38%08&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=212992&downloaded=493780992&left=243797780&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [AbstractCommand.cc:867] errorCode=1 Failed to establish connection, cause: Connection timed out\n2016-02-01 10:47:26.261279 [ERROR] [AbstractCommand.cc:377] CUID#17818 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%CB%1C%85C%E2%B8%5C%3D%D4%FE%08%F3%5C%EC%B2A%C5W%C6%25&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=65536&downloaded=515482688&left=119144448&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [AbstractCommand.cc:867] errorCode=1 Failed to establish connection, cause: Connection timed out\n2016-02-01 10:48:11.158662 [ERROR] [AbstractCommand.cc:377] CUID#17922 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%A4%DD%5B%B4%DE%09%9A%AF%F1%CC3x%5D%E3%8F%9F%5F%F2%A8z&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=114688&downloaded=470037943&left=158056448&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [AbstractCommand.cc:867] errorCode=1 Failed to establish connection, cause: Connection timed out\n2016-02-01 11:02:49.312729 [ERROR] [AbstractCommand.cc:377] CUID#22051 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%FB%17%2C%B2s%B0%AF%3B%EA%C6%D2%20l1b%A6%DC%96%A2%0C&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=557056&downloaded=571063902&left=193101824&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 11:10:44.844393 [ERROR] [AbstractCommand.cc:377] CUID#23350 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%8B%2C%CC5%995P%5Eq%CAC%5E%F6%2Fc2%88%CE%84%19&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=49152&downloaded=603422720&left=112476160&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 11:12:20.835688 [ERROR] [AbstractCommand.cc:377] CUID#23646 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%974%EA%F2%CB%14%C1%3C%3A%A1%18%5E%A5%F7%0Aw%7F6%BA%8D&peer_id=A2%2D1%2D18%2D7%2D0%7E%3E%2D%D8r%C7a%BCH&uploaded=524288&downloaded=894909221&left=86540288&compact=1&key=%3E%2D%D8r%C7a%BCH&numwant=0&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\n2016-02-01 11:43:30.616125 [ERROR] [AbstractCommand.cc:377] CUID#1489 - Download aborted. URI=http://open.nyaatorrents.info:6544/announce?info_hash=%10%18%00%2A%06%E8%02%EBZ%E4%87%16a%0C%11%D4%B2U%B9%1E&peer_id=A2%2D1%2D18%2D7%2D%97%B6%9DEk%AA%107%DD%E4&uploaded=0&downloaded=10436608&left=152801848&compact=1&key=%9DEk%AA%107%DD%E4&numwant=50&no_peer_id=1&port=6801&supportcrypto=1\nException: [HttpConnection.cc:144] errorCode=1 Got EOF from the server.\nafter this, then remote got lost connection\n. @tatsuhiro-t  What do i do ? Can you give us instruction for debug mode? i want to help you.\n. @EmpressFiona you use optware-ng? am i right? i use entware-ng i just type \"opkg install aria2c\" download from entware-ng package... im currently aria2 version 1.20 but now i dont know when it will freeze.. still okay long... i will wait for it will freeze i will report immediately.\n. +1\n. change log?\n. same here problem. it went wipe after restart.. ",
    "nasht00": "I have a computer with aria2c working.\nI just got a new computer and installed aria2c on it.\nI tried downloading the exact same torrent on both computer. On the old one, it works (13 seeds).\nOn the new one, I get \n[ERROR] Exception caught while loading DHT routing table from /Users/nathanh/.cache/aria2/dht.dat\nException: [../../../src/DHTRoutingTableDeserializer.cc:83] errorCode=1 Failed to load DHT routing table from /Users/nathanh/.cache/aria2/dht.dat\n. I'm just jumping on board now. I've been having the same issue, and that last link that @nmaier provided seems to fix the issue!\n. Are you saying that the user should make this copy? Or that aria would do this automatically?\nI don't want to manually have to think about it every time.\nAlso, I most often use magnet links.\n. ",
    "Zenexer": "Now encountering this issue on Bash on Windows (Lxss).  MinGW seems to be having the same problem: https://github.com/Alexpux/MINGW-packages/issues/245  Working fine with same version on standard Ubuntu.. Also encountering this issue with aria2c installed from Chocolatey repos.. ",
    "AntonFriberg": "Experienced this problem as well using the latest 1.34.0 version. It seems to have been caused by not having enough available disk space to download the torrent in my case at least. Once I made more disk space available the problem resolved itself.. ",
    "johnypony3": "This is a great tool, but without this type of basic functionality it is hard to integrate with other system.\n. ",
    "jackjm": "https://wiki.archlinux.org/index.php/aria2\nIt is convenient to append a monitor function based on diana in your shell configuration file:\nda(){\nwatch -ctn 1 \"(echo -e '\\033[32mGID\\t\\t Name\\t\\t\\t\\t\\t\\t\\t%\\tDown\\tSize\\tSpeed\\tUp\\tS/L\\tTime\\033[36m'; \\\ndiana list| cut -c -112; echo -e '\\033[37m'; diana stats)\"\n}\n. ",
    "Waifod": "I'd love to switch from rtorrent to aria2, however I really miss this feature.\n. ",
    "ibizaman": "A bit involved but quite generic, here is what I have:\n/etc/aria2.conf file with accompanying /etc/systemd/system/aria2.service.\n/usr/local/bin/torrentwatch.sh file with accompanying /etc/systemd/system/torrentswatch@.service.\nWatched directories:\n /srv/torrents/movies\n /srv/torrents/series\nDownloaded files are respectively in:\n /srv/movies\n /srv/series\n/etc/aria2.conf\n```\ncontinue\ndir=/srv/movies\nlog-level=info\nconsole-log-level=info\nbt-detach-seed-only\nbt-enable-lpd\nbt-force-encryption\nbt-prioritize-piece=head=10M\nbt-save-metadata\nseed-ratio=0\nenable-rpc\nrpc-listen-all\nrpc-secret=$rpc_secret\nsave-session=/var/lib/aria2/session.lock\nsave-session-interval=60\ninput-file=/var/lib/aria2/session.lock\nfile-allocation=falloc\n```\n/etc/systemd/system/aria2.service\n```\n[Unit]\nDescription=Aria2 Service\nAfter=network.target\nAssertPathExists=/var/lib/aria2/session.lock\nAssertPathExists=/etc/aria2.conf\n[Service]\nExecStart=/usr/bin/aria2c --conf-path /etc/aria2.conf\n[Install]\nWantedBy=default.target\n```\n/usr/local/bin/torrentwatch.sh\n```sh\n!/bin/sh\ntorrent_dir=\"$1\"\nif ! [ -d \"$torrent_dir\" ]; then\n    echo \"No directory to watch called $torrent_dir\"\n    exit 1\nfi\ndownload_dir=\"$2\"\nif ! [ -d \"$download_dir\" ]; then\n    echo \"No directory to download called $download_dir\"\n    exit 1\nfi\necho \"Watching $torrent_dir and downloading in $download_dir.\"\nexport DIANA_SECRET_TOKEN=\"$rpc_secret\"\n/usr/bin/inotifywait --monitor --quiet --event create --format \"$torrent_dir/%f\" \"$torrent_dir\" | xargs -n1 diana --dir=\"$download_dir\" add\n```\n/etc/systemd/system/torrentswatch@.service\n```\n[Unit]\nDescription=Automatically add torrents to aria2 using diana\nAfter=aria2.service\nBindsTo=aria2.service\n[Service]\nExecStart=/usr/local/bin/torrentwatch.sh /srv/torrents/%i /srv/%i\nKillMode=control-group\nUser=diana\nGroup=torrent\n[Install]\nWantedBy=default.target\n```\nFinally, run:\nsystemctl start torrentswatch@movies\nsystemctl start torrentswatch@series\nsystemctl enable torrentswatch@movies\nsystemctl enable torrentswatch@series. ",
    "cykerway": "Yes I'm using UDP trackers. But I think aria2c can feel free to disconnect when the download is complete given that I explicitly set --seed-time=0. So this waiting seems to be unnecessary.\nI'm using aria2c to download multiple files one by one interactively and this kind of waiting is not acceptable. What I currently do is to use a hook script to kill aria2c on the -on-bt-download-complete event. It works but adds additional code complexity. Therefore I'm interested in why this waiting is necessary and how to avoid it. Thank you.\n. If you use it as a daemon then these timeouts don't really matter. But if you use it as an interactive tool then any non-trivial timeout doesn't look nice. Think about downloading 100 files and each file requires 10 seconds to download. If we add another 10 seconds timeout then it doubles the total time. \n. All right, I'll just use the trick to finish my task at hand. But if you are interested in offering users an option to exit when download completes, then you an always do it in a future version - and it won't break compatibility if not set as default. Issued closed since the story is clear. Thank you for explanation.\n. I did some experiments.\nIf I have .aria2 file, then aria2c can resume from last download. Good.\nIf I don't have .aria2 file, then I have two options:\n1.  Without -V options, aria2c restarts from the very begining.\n2.  With -V, it can resume from last download. However, it displays an error message:\n[ERROR] Checksum error detected. file=...\nThis is confusing since I don't know whether the resume is successful or not. If the resume is guaranteed to be correct, knowing how to disable the error message will be helpful.\nBy the way, my torrent file doesn't have piece hash.\n. OK I recreated another torrent file and double checked the piece hash. It looks OK and I can download using this torrent with both aria2c and deluge. However, aria2c still outputs an error message when resuming a partial download without the help of *.aria2 file. I don't understand where it comes from. For all completed chunks, it can verify using piece hash. If the last chunk is incomplete, then its hash is of course not the same as in the torrent file. Is this where the error comes from?\n. Thank you for acknowledgement. I think it may be helpful if you use cerr for log messages so that users can write 2>/dev/null if not interested. Created a patch for it: https://github.com/tatsuhiro-t/aria2/pull/511.\n. I see. It won't break compatibility if we use an option --log-to-stderr to control. But this requires better examination of the code so I won't do it now in case bug is introduced. Anyway, I now have a modified version that works now so I'll close the issue. Thank you for your explanation.\n. ",
    "kennel209": "@tatsuhiro-t  Thanks. It works. Sorry for misunderstanding for the manual. I only use TAB to split options.\n. ",
    "sky93": "I used curl to get response header: \n```\n$ curl -i \"http://tb27.trainbit.com:8080/files/6135087884/v3664B3059785465766E6956736877307A45416C68372B436636594F6E67487445615441447930764B2B54673D\n/\"\nHTTP/1.1 200 OK\nContent-Type: application/octet-stream\nConnection: keep-alive\nAccept-Ranges: bytes\nContent-Disposition: attachment; filename=The_Game_Awards_2015.part1.rar\nContent-Length: 2096103424\nContent-Range: bytes=0-2096103423/2096103424\n```\n\n. Thanks for the fix :+1: \n. Thank you so much!\n. I didn't change --async-dns so it should be set to true (default). I just ran aria2c --enable-rpc.\nBy the way I can't even use this argument. It doesn't exist at all. I don't know why:\n\nMy aria2 version is 1.22.0 with BitTorrent, GZip, HTTPS, Message Digest, Metalink, XML-RPC\n. Nice. I built aria2 with c-ares library and changed async-dns to false. It's now working without any problem. Thanks\n. Yes you said this. But I set it to true and I didn't see any difference. When I changed it ti false, everything went okay :/ I don't know why. I tried it several times.\n. ",
    "allo-": "ah, sorry the uri.txt contains the filename in the example. I overlooked that it is .img there as well.\n. ",
    "Animis09": "Thank you for your anwser.\nThe more requests there are, the more the problem happens. It begins after around 50 concurrently requests\nI have not activated the log for now but here is what i get with the curl command:\ncurl http://127.0.0.1:6800/jsonrpc -H \"Content-Type: application/json\" -H \"Accept: application/json\" --data '{\"jsonrpc\": \"2.0\",\"id\":1, \"method\": \"aria2.getGlobalStat\", \"params\":[\"token:***\"]}' --verbose\n- About to connect() to 127.0.0.1 port 6800 (#0)\n-   Trying 127.0.0.1...\n- connected\n- Connected to 127.0.0.1 (127.0.0.1) port 6800 (#0)\n\nPOST /jsonrpc HTTP/1.1\nUser-Agent: curl/7.26.0\nHost: 127.0.0.1:6800\nContent-Type: application/json\nAccept: application/json\nContent-Length: 98\n\nupload completely sent off: 98 out of 98 bytes\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nadditional stuff not fine transfer.c:1037: 0 0\nRecv failure: Connection reset by peer\nClosing connection #0\n  curl: (56) Recv failure: Connection reset by peer\n\n\nWhen it works, i get this : \ncurl http://127.0.0.1:6800/jsonrpc -H \"Content-Type: application/json\" -H \"Accept: application/json\" --data '{\"jsonrpc\": \"2.0\",\"id\":1, \"method\": \"aria2.getGlobalStat\", \"params\":[\"token:***\"]}' --verbose\n- About to connect() to 127.0.0.1 port 6800 (#0)\n-   Trying 127.0.0.1...\n- connected\n- Connected to 127.0.0.1 (127.0.0.1) port 6800 (#0)\n\nPOST /jsonrpc HTTP/1.1\nUser-Agent: curl/7.26.0\nHost: 127.0.0.1:6800\nContent-Type: application/json\nAccept: application/json\nContent-Length: 98\n\nupload completely sent off: 98 out of 98 bytes\nadditional stuff not fine transfer.c:1037: 0 0\nHTTP 1.1 or later with persistent connection, pipelining supported\n  < HTTP/1.1 200 OK\n  < Date: Mon, 28 Dec 2015 09:59:11 GMT\n  < Content-Length: 157\n  < Expires: Mon, 28 Dec 2015 09:59:11 GMT\n  < Cache-Control: no-cache\n  < Content-Type: application/json-rpc\n  <\nConnection #0 to host 127.0.0.1 left intact\n  {\"id\":1,\"jsonrpc\":\"2.0\",\"result\":{\"downloadSpeed\":\"12084203\",\"numActive\":\"44\",\"numStopped\":\"7\",\"numStoppedTotal\":\"74143\",\"numWaiting\":\"0\",\"uploadSpeed\":\"0\"}}* Closing connection #0\n. Yes indeed, at least on my server.\n. Perhaps it's more. \n\n\nI will activate the log option to see if something is wrong.\n. Sorry, i made a mistake in the log. The version I use is 1.19.3. \n. Is there a command on debian wheezy for this ?\n. root@server:~# gnutls-cli --port 443 github.com \nResolving 'github.com'...\nConnecting to '192.30.252.128:443'...\n- Certificate type: X.509\n  - Got a certificate list of 2 certificates.\n  - Certificate[0] info:\n  - subject businessCategory=Private Organization,jurisdictionOfIncorporationCountryName=US,jurisdictionOfIncorporationStateOrProvinceName=Delaware,serialNumber=5157550,STREET=548 4th Street,postalCode=94107,C=US,ST=California,L=San Francisco,O=GitHub\\, Inc.,CN=github.com', issuerC=US,O=DigiCert Inc,OU=www.digicert.com,CN=DigiCert SHA2 Extended Validation Server CA', RSA key 2048 bits, signed using RSA-SHA256, activated 2014-04-08 00:00:00 UTC', expires2016-04-12 12:00:00 UTC', SHA-1 fingerprint a0c4a74600eda72dc0becb9a8cb607ca58ee745e'\n  - Certificate[1] info:\n  - subjectC=US,O=DigiCert Inc,OU=www.digicert.com,CN=DigiCert SHA2 Extended Validation Server CA', issuerC=US,O=DigiCert Inc,OU=www.digicert.com,CN=DigiCert High Assurance EV Root CA', RSA key 2048 bits, signed using RSA-SHA256, activated2013-10-22 12:00:00 UTC', expires2028-10-22 12:00:00 UTC', SHA-1 fingerprint7e2f3a4f8fe8fa8a5730aeca029696637e986f3f'\n- The hostname in the certificate matches 'github.com'.\n- Peer's certificate issuer is unknown\n- Peer's certificate is NOT trusted\n- Version: TLS1.2\n- Key Exchange: RSA\n- Cipher: AES-128-CBC\n- MAC: SHA256\n- Compression: NULL\n- Handshake was completed\n- Simple Client Mode:\n- Peer has closed the GnuTLS connection\nThe aria2 command which fails:\naria2c --max-connection-per-server=8 --split=10 --min-split-size=1M --allow-overwrite=true  --referer=\"https://www.youtube.com/\" \"https://r1---sn-25ge7nls.googlevideo.com/videoplayback?ms=au&mt=1453123373&mv=m&source=youtube&requiressl=yes&key=yt6&mm=31&mn=sn-25ge7nls&id=o-AJOLLmv-bnlbby7mJpEbqhN5suB1sPxXe1GkFyDSU4eO&upn=yzlPgnU_BZc&initcwndbps=3057500&lmt=1452842322067259&ip=213.251.182.110&sparams=dur,id,initcwndbps,ip,ipbits,itag,lmt,mime,mm,mn,ms,mv,nh,pl,ratebypass,requiressl,source,upn,expire&fexp=9408522,9416126,9417741,9418203,9420452,9422596,9423573,9423662,9424135,9425351,9425447,9426047,9426214,9426722,9426727,9426754&dur=891.808&expire=1453145130&sver=3&pl=18&nh=IgpwcjAxLnBhcjEwKgkxMjcuMC4wLjE&ratebypass=yes&itag=22&ipbits=0&signature=083A7935F41B34623B19B145BE32DAB1D7D89F4A.82A10A5604F250263A2505F784643EFE8DF3E8D3&mime=video/mp4&title=Adele+Carpool+Karaoke\"\n-> [SocketCore.cc:1006] errorCode=1 SSL/TLS handshake failure: The signature algorithm is not supported.\nroot@server:gnutls-cli --port 443 \"r1---sn-25ge7nls.googlevideo.com\"                                              \nResolving 'r1---sn-25ge7nls.googlevideo.com'...\nConnecting to '2a00:1450:4007::7:443'...\n- Certificate type: X.509\n  - Got a certificate list of 3 certificates.\n  - Certificate[0] info:\n  - subject C=US,ST=California,L=Mountain View,O=Google Inc,CN=*.c.docs.google.com', issuerC=US,O=Google Inc,CN=Google Internet Authority G2', RSA key 2048 bits, signed using RSA-SHA256, activated 2015-12-09 15:59:22 UTC', expires2016-03-08 00:00:00 UTC', SHA-1 fingerprint 443a717c28f87829414bb067b53c3f50cbeb291a'\n  - Certificate[1] info:\n  - subjectC=US,O=Google Inc,CN=Google Internet Authority G2', issuerC=US,O=GeoTrust Inc.,CN=GeoTrust Global CA', RSA key 2048 bits, signed using RSA-SHA256, activated2013-04-05 15:15:56 UTC', expires2016-12-31 23:59:59 UTC', SHA-1 fingerprint178f7e93a74ed73d88c29042220b9ae6e4b371cd'\n  - Certificate[2] info:\n  - subject C=US,O=GeoTrust Inc.,CN=GeoTrust Global CA', issuerC=US,O=Equifax,OU=Equifax Secure Certificate Authority', RSA key 2048 bits, signed using RSA-SHA1, activated 2002-05-21 04:00:00 UTC', expires2018-08-21 04:00:00 UTC', SHA-1 fingerprint `7359755c6df9a0abc3060bce369564c8ec4542a3'\n- The hostname in the certificate matches 'r1---sn-25ge7nls.googlevideo.com'.\n- Peer's certificate issuer is unknown\n- Peer's certificate is NOT trusted\n- Version: TLS1.2\n- Key Exchange: RSA\n- Cipher: ARCFOUR-128\n- MAC: SHA1\n- Compression: NULL\n- Handshake was completed\n- Simple Client Mode:\n* Fatal error: A TLS packet with unexpected length was received.\n* Server has terminated the connection abnormally.\n. Thank you for your help.\nHow can I correctly build aria2 ? \nHere are the commands that i typed:\nwget https://github.com/tatsuhiro-t/aria2/releases/download/release-1.19.3/aria2-1.19.3.tar.gz -O aria2.tar.gz \ntar -zxvf aria2.tar.gz\ncd aria2-1.19.3\n./configure\nmake && make install\nINFO: \n- GCC version: 4.8\n- gnutls-cli (GnuTLS) version: 2.12.20\n. It's strange because on another debian wheezy server it works with aria2-1.19.3 and GnuTLS 2.12.20.\n. Yes indeed. This is the 1.19.3 version.\n. After some tests on my server, here is what I found  : \nIt works with aria2.1.18.3 and before. \narchive-> http://sourceforge.net/projects/aria2/files/stable/aria2-1.18.3/aria2-1.18.3.tar.gz/download\nIt doesn't with aria2.1.18.5 and after.\narchive-> http://sourceforge.net/projects/aria2/files/stable/aria2-1.18.5/aria2-1.18.5.tar.gz/download\nWith aria2.1.18.4 i get an error during the \"make\" command\narchive-> http://sourceforge.net/projects/aria2/files/stable/aria2-1.18.4/aria2-1.18.4.tar.gz/download\n. Now, it works thanks to your indication. \nThanks again for your help.\n. Any idea ?. ",
    "motypas": "I would like to send the file only once that is why I would like to use this setting. I try the download with utorrent, deluge, qbittorrent, transmission client the result is same every time... \nI use this command:\naria2c --check-integrity=\"true\" --bt-enable-lpd=true --no-conf --enable-dht=\"true\" /media/test/Torrent/TORRENT_test.torrent --seed-ratio=1.0 -d /media/test/Torrent\nIll try to increase the seed  ratio number to 1.01 this is works the seed 100% but then not close the connection from tracker. Any Idea? \n. I wait this question :) I mean the file size... In my test I try to send 4 different size file. 150Mb, 1Gb, 5Gb, 15Gb, and if I set the ratio to 1.0 the client received - in every diff size file - only 99,9% if I set the ratio to 1.01 or 1.0001 or 1.0000000000001 (does not matter) the client received 100% :) \n. My program version is 1.19.0 under Ubuntu 15.10\n. Hi\nHappy New Year!\nI update the program with the patch. This patch is working with the large file, but with the small file does not. I try to send 100, 200, 500, 700 Mb files and the downloader receive only 99.9%.\nFor big files upper 1Gb receive 100%.\n. OK... I understand your explanation but not. If I use other software like qbittorrent, utorrent, deluge this problem does not happend I can send small size file with 1.0 ratio, but for me the gui is not good only the CLI that is why I choose the aria2...\nIn this situation only ONE seeder and ONE receiver available not more. And why working if I seed large size file? If I seed 331.3 Mb (331.306.368 byte) why not send the 100%? And why send 3,8Gb  in 100%? This ratio means:  download X MB file size and  upload same X MB and then the ratio 1.0 and/or if I want to share a file only once for one downloader I can control with ratio how many times can download it. If the receiver has download the file 100% the aria is disconnect from tracker and the receiver never can download again for more or other download they need to request for new torrent file.\nSo is it possible to add a \"after x.x ratio wait X second before disconnect from tracker?\" Maybe if the aira is connected to the tracker for X second after the 1.0 ratio they can send it the missing part. What do you think?\n. Experience why not work the seed ratio for small file:\nIf any torrent creator create the file split for a small file (under 1Gb) - in automatic mode - the creator use 128-768kb split. This split is too small for seeding because the seed ratio control does not watch how many package was sent to the client, they watch only the file size, Is the file size is match (ratio 1.0) the aria is disconnect from the tracker and the end is loss 2 or 3 package(split)  that is why sent only 99.92%.\nIf we incrase the split in manual mode for small size file to 1024kb (or bigger) the seed ratio control is 100% working the seeder sent the all package.\n. From the torrent file we know the package/piece number and one package size in byte, we know all info vice versa, 2500x1024Kib = 2,560,000 Kib=1.0 Ratio (the last package/piece is always smaller if the file size is not equal to the spliter size.)\nIf we want to download or seed, we send and receive not just bytes, packages too.\n1 package/piece upload/download\nIF package/piece                                (2500)\nupload/download -OK or Finish\nTHEN                                                  (1024Kib)\nupload/download size is XMb\nTHEN                                                   (2,560,000 Kib)\nour seed ratio is X.X                            1.0 = 2500 piece\n. Sorry for late reply.. yes package=piece.\nAnd your right the number of pieces equal the ratio. I read the wiki and this is clear but not clear... but never mind now\nThe seed radio problem is fixed with the bigger piece size.\nI have one more question about the seed. How can I configure the aria2 in seed only mode... I mean I create a xxxx.torrent file and I would like to seed only. If I use this command:\naria2c --check-integrity=\"false\" --bt-enable-lpd=true --seed-ratio=1.0 --no-conf --enable-dht=\"true /home/test/test.torrent -d /home/test/\nWith this command the aria2 is not seed just listen,\nI mean not seeder just peer. If they get any request then seed like a peer.\nAnd I did not find any switch to seed only mode like in GUI torrent clients (after the torrent file creation seed file immediately) there I see the torrent in seed mode.\nAny idea?\n. Thank you, it works fine... one more and I hope last question. If I seed a torrent with utorrent, transmission etc etc and then I push the button then the client connect to the tracker and the tracker print out the hash value of the torrent. If I seed with aria2c I did not see the hash value after the tracker connection. required for this to use a switch? I did not find.\n. Print out the info hash\nudpt tracker\n. If I connect to the tracker with utorrent, transmission etc etc I see in the tracker consol\n1 client connect\na4075bbd516a7d9736739771e92668d9\nif aria connect\n1 client connect\nno hash\n. UDPT received CONNECT reply from x.x.x.x:6969 transaction_id=1001331254,connection_id=-4763401030874431489\nUDPT sent ANNOUNCE to x.x.x.x:6969 transaction_id=811394366, connection_id=-4763401030874431489, event=STARTED, infohash=55183224304b99cda891166cf2b5b4bbab320846\nUDPT received ANNOUNCE reply from x.x.x.x:6969 transaction_id=811394366,connection_id=-4763401030874431489, event=STARTED, infohash=55183224304b99cda891166cf2b5b4bbab320846, interval=1800, leechers=0, seeders=0, num_peers=0\n. OK thanks for your feedback.. but the problem is aria2c is connected with the tracker but if other client is connect with download request (peer)  aria2c is not seed, just wait...\nAria2c is start seeding If I seed on same machine the same torrent with other software... enough only the first 1 bite. From that point aria2c is seed anytime that torrent.\nIll try with udpt tracker and Opentracker too.  Same result.\n. ",
    "ST9527": "I installed  it by brew install aria2. And I am not using any RPC client yet because I can not even enable the RPC. How you install aria2 and enable the rpc?Mind to shared?@nmaier\n. ",
    "sotoahs": "+1 I am also looking for execute a script before the download is started. I already do something tricky pausing and adding a new download and it works partially well but should be better to have the ability to change link with a script before it starts to request the file.\n. ",
    "ryansito": "Thank you very much for your fast response. I'm closing the issue now, have a nice day!!\n. aria2c.log.txt\nSorry to reopen the issue. I'm running Archlinux X86_64 with linux ck kernel and multicast is enabled. Also tried compiling with linux kernel and it won't let me compile with the same error every time. Also tried in another pc. I want the local peer discovery feature but if there's nothing to do, how can I skip this chek so it compile? Maybe the aria2c.log could help. In the log I see - [TIMEOUT] No Multicast packet received, but as you see multicast is enabled.\ngrep CONFIG_IP_MULTICAST '/usr/lib/modules/4.3.3-2-ck/build/.config' \nCONFIG_IP_MULTICAST=y\n. I was blocking the multicast port so I've opened it in the firewall. Now it's compiled succesfully. Thanks for your awesome time.\n. ",
    "xderoche": "I have the same need ! aria2 helps me a lot handling my recurrent download batches. The lack of a partial download support forces me to write everything from scractch for some of them.\nIt would be very useful to have this feature.\n. ",
    "haodong": "@tatsuhiro-t Thanks! I redeployed the server and everything fine now. :+1: \n. Hi @tatsuhiro-t, error made again.\n```\naria2c\n01/19 13:10:59 [ERROR] Failed to load certificate from /etc/ssl/example.com.pem and private key from /etc/ssl/example.com.key. Cause: Base64 unexpected header error.\n01/19 13:10:59 [ERROR] Exception caught\nException: [MultiUrlRequestInfo.cc:198] errorCode=1 Loading private key and/or certificate for secure RPC failed.\n```\nThis time, however, I've probably got the point. Here it is.\nWhen using RSA as private/public key's algorithm, the .key, .pem and .p12 can be recognized.\nWhen using EC (Elliptic Curve) as the key's algorithm, those files would not be recognized.\nIf my assumption was true, I hope aria2 could support the advanced algorithm. Thank you!\n. Hi @tatsuhiro-t . I solved it by recompiling aria2.\n./configure --prefix=/usr --without-gnutls --with-openssl --with-openssl-prefix=/usr/local/ssl\nUsing OpenSSL is very important. :)\nAria2 is really powerful! :+1: \n. I figured it out!\nIt's because of this > ./configure --prefix=/usr --with-ca-bundle=/etc/ssl/server.crt.\n. Update:\nReplace the p12 file to a pair of cer + prikey files, then connect fine.\nBut both p12 and cer files are chain pems.\n. @recolic True, you're right. Probably because of the popularity of its usage in China, @cilicilili may treat the author as a Chinese. :). ",
    "kkartaltepe": "I just noticed in the help text (1.19.3) it mentions\n\"Report bugs to https://github.com/tatsuhiro-t/aria2/issues\nVisit http://aria2.sourceforge.net/\"\nOn Thu, Jan 21, 2016 at 3:30 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\nI did that in some extent. Did you find the remnants?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/issues/539#issuecomment-173514447.\n. I see the places i happened upon in the code base were\nhttps://github.com/tatsuhiro-t/aria2/blob/master/src/libaria2.pc.in#L38\nhttps://github.com/tatsuhiro-t/aria2/blob/master/po/Makevars#L37\nhttps://github.com/tatsuhiro-t/aria2/blob/master/doc/xmlrpc/README.txt#L3\n\nOf these im not sure if any actually show up somewhere else, but these are the ones that seemed like they might have needed to be changed. If they are all fine you can go ahead and close the issue.\n. Thanks ill go ahead and close this as I never found any more references.\n. I simply run aria2 with check-integrity=true in my config. Then to seed a torrent I have already downloaded I simply use the addTorrent rpc call and set the directory (using the options parameter) to where ever the files already exist. It should check integrity and then begin seeding. You could also set the check-integrity=true in the options parameter instead of setting it globally.\n. Thanks, that was amazingly quick!\n. So I kind of ripped the aria2 command line status report of hashing progress and added it to the tellStatus Rpc call in\nhttps://github.com/kkartaltepe/aria2/tree/RpcTellStatus-Hashing\nI wanted to know if you would be willing to accept a pull request for this issue and your thoughts on how current progress of hashing should be reported.\nThis branch was just a simple proof of concept that it could be reported as part of the RPC interface (and for me to brush up on my C++ while learning the aria2 code base).\n. Thanks for the info on force-save ill have to add that to my config. Im glad a workaround exists.\n. Just tried this out. I had an existing session started with force-save as false. I set force-save=true with the setGlobalOption rpc command. I issued the saveSession rpc call which returned \"OK\", but my session file remained empty (I am seeding a number of active torrents).\nRestarted aria2 with force-save and then re-added torrents, and then my session file was populated properly.\n. Ahh, found i was missing cppunit, sorry if the failed builds caused any email spam. Hopefully I can get a passing build now that I can run the tests locally.\n. Yes, I was thinking about some other ways to get around being unable to\ncheck the references as I'm having issues due to SequentialPicker using\nunique_ptr's. I will work on it again this coming weekend.\nOn Sun, Mar 20, 2016 at 5:06 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\nThank you for PR! Could you debug the unit test error found in travis?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/pull/599#issuecomment-198888586\n. Looks like there was a case where getCheckIntegrityMan could return null which was causing the segfaults. At this point I have all the info I want being reported in tellStatus except whether a download has had its integrity checked or not. I think I can just use 'Seeding' for my purposes but it was something I thought about when writing this PR.\n. Thank you for the merge!\n\nOn Fri, Apr 15, 2016 at 11:03 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\nThis PR has been merged with some amends. Thank you!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/tatsuhiro-t/aria2/pull/599#issuecomment-210496194\n. aria2 requires you specify the download directory when you start the download. You could write a script that wraps aria2 and checks the mimetype in the headers before sending the download request to aria2 with the correct download directory. Or as you mentioned you can download to a temporary or generic directory and then move the files with an after download script.\n\nThere really isn't much of a reason to try and do it before download if you only care about the mimetype. The mimetype wont change and moving files is a fast operation so even if it's something huge it will move very quickly.\nI personally did the wrapper method for sending torrents from various trackers to their individual folders, since the .torrent info isnt in the downloaded files. It works quite well.. Just checking in to see if there was any feedback on this PR.. I have updated the PeerAgent to be a std::string and removed the commented code. I also added a simple test for the PeerAgent functions. I have also rebased it to the current head commit.. Hmm, must have had some typo that made me add that cast, removing the cast worked fine. . You can probably resolve the  gethostbyname by compiling glibc with static nss. See https://www.gnu.org/software/libc/manual/html_node/Configuring-and-compiling.html\nNot sure if there is any similar method of resolving getpwuid which has pretty much the same issues for the same reasons as gethostbyname (maybe you can call out to getent if you want to trade dynamic linking for IPC).\nI'm not sure why you would want to statically link glibc, but as stated in the stackoverflow answers these calls are highly dependent on runtime configuration and libraries and static linking will almost guarantee they return wrong results in any system that isnt completely default.. It's also worth noting that the OpenSSL license used by aria2c is incompatible with the GPL so be sure to take care to follow licensing restrictions of the LGPL used by glibc when static linking if you intend on redistributing your build.. %2F is a '/' which cant be represented on most file systems as part of a name. As such it is left in encoded form, and even if it could I dont think it should be decoded. This seems correct to me.\nIf you wanted it inside a folder consider storing it in a container format like zip.\nAlso please do not link potentially copyright infringing content here.. As per the documentation the various peer exchange mechanisms are disabled for torrents with the private flag set.\nFeel free to audit the source and create an issue if you find any cases where peers are leaked. Id gladly write the PR myself if any cases such are identified.. Use the -V, --check-integrity option to check integrity before attempting to redownload a file. You can also use the --bt-seed-unverified option to seed without verifying the integrity of your download though I would discourage against it.. @underlaw you can already selectively download files with -S/--show-files to show files in the torrent and then selectively download them with the --select-file option\nYou can probably automate this torrent file moving yourself using the event hooks described here\nhttps://aria2.github.io/manual/en/html/aria2c.html#event-hook\nI do think it would be useful to store torrent/metadata/control files in a separate location to prevent cluttering download locations.. the only valid on-download-complete you listed was \non-download-complete=/Users/wk/.aria2/torrent.sh\nThis option takes a single executable as its argument. In your first example you tried to pass it the text of a shell script, which is incorrect. Your third example is similarly incorrect.\nAnd if you are running this under windows you will need to ensure things are executable by windows natively (I think).. libaria2 is available and can be built with --enable-libaria2 for embedding aria2. It is a C++ library however so interop might be a bit more tricky than a C library. \nThe python wiki includes links to quite a few tools which should help in generating bindings to the libaria2 library\nhttps://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#C.2FC.2B-.2B-_Binding_Generators. The bit torrent protocol only allows granularity at the Piece level. You can see that the Piece Size is 512k and you selected the first file of size 46K. Since aria2 must download a full 512K Piece it gets the next files as part of that piece containing the file you wanted.\nIts been suggested that aria2c delete the extra files that were downloaded as part of the piece and not selected but currently is not implemented.\n. ",
    "ChuLiqiang": "I have try check-integrity true or false use  Aria2 WebUI. the error message is . Aria2 WebUI is suppot this feature? How can i set this feature to a special task.\nI want not setting this feature for all tasks.\n. Can you tell me how to set this setting for some task.-V is a global setting.\n. are you sure aria2 can seed same file in diffrent torrent?diffrent torrent can run same time with same file?\n. Can you add this feature for new aria2 version? Thank you very much. PT also use this feature to seed same file to different site.\n. ",
    "roooneey": "No, I didn't notice that option, but I gonna try, thanks. Does the HTTP status make a difference, or it's retrying anyway? I saw the command line output was full auf 504 errors, but also a lot of 403. \n. I tested with --max-tries=0 and so far there were 5 connections dropped and in the output I see this message 5 times: \n01/25 19:36:00 [ERROR] CUID#26 - Download aborted. URI=***\nException: [AbstractCommand.cc:350] errorCode=22 URI=***\n  -> [HttpSkipResponseCommand.cc:228] errorCode=22 The response status is not successful. status=504\nSo I guess there is no retry on http 504, or do I have to set --retry-wait as well?\n. Thanks for your update. I have difficulties to build it on os x, so I guess I have to wait for a release.\n. ",
    "userxd": "I was testing with a 32GB flash drive (15 reading and recording 8). in exFAT, ext2 and ext4\nI tested here are some things you said and it seemed that the problem is the same in the storage unit!\nWith an external hard drive and a USB stick 64GB 3.0 (60MBs recording) I did not see the problem (file-allocation = trunc)!\nI have rarely download rates in excess of 1 MBs, but the USB stick that was in the router's USB port supported recordings to 8MBs.\nSo, I think I'll have to buy a new stick to make always connected, if so, what would be recommended to meet the requirements of aria2 to a smooth running (more or less how many MBs to avoid crashes)?\n. ",
    "EmpressFiona": "I can confirm that a similar issue is happening to me. While my device is a slow hard disk, it's formatted in ext4, so file allocation shouldn't be an issue. My CPU is faster at 1200 MHz, but I have a similar amount of RAM, so...\nThe program sometimes seems to recover and sometimes doesn't, and when it's sufficiently frozen it won't respond to hangup or terminate calls, at around 90% CPU. I'd give you a core file, but I'm not sure where it would be - it isn't in aria2's config folder, its download folder, or anything else, possibly because it never crashed, just froze.\nCould it just be a performance issue, or something solved in the upstream versions outside of OpenWrt? I wouldn't think so, it seems like NAS devices of similar power have little trouble. I already asked about compiling for OpenWrt, and I'm pretty sure I found their repository for the software, which hasn't been updated in a year and change...who knows if you could build the current version on OpenWrt intact.\nIf it matters, I'm running aria2 as a daemon, but I'm not sure why it would...\n. I went ahead and compiled 1.20.0 on my own for OpenWrt by editing the makefile slightly to account for new options and dependencies. It's based on bleeding edge Designated Driver trunk, so there might be some issues with earlier OpenWrt or kernel versions, but I managed to install it just fine with opkg. (It'll install all the dependencies for you just fine, and I compiled this version with support for all protocols.)\nIt seems to be working just fine for me, but I've yet to really put it through its paces. I'll see how it does during my unlimited bandwidth window, but I haven't noticed any freezing thus far.\nIf userxd and alienx2 are still out there, let me know how it works so I can make a pull request on OpenWrt's repository! (It seems like it was assigned to a maintainer who has been MIA for months, which is why it hasn't been updated...)\nHonestly, I'm kind of considering abandoning OpenWrt as a torrent system, since it seems to perform exceptionally poorly. In fact, the only reason I haven't already is because the only piece of equipment I could use 24/7 relatively noise-free is promised to someone else unless I can't get the screen working again. (After multiple issues with reformatting drives and data loss...oh well. Sometimes these little experiments take over your common sense.)\n. ",
    "qianjiahao": "@Chen-Sir how dose you fix it , it was happened on me and i don't know how to fix it ... , so could you share your way ?\n. ",
    "Chen-Sir": "It should be \u201chow do you fix it\u201d but not \"how dose you fix it \" .         haha\n\u4e0d\u597d\u610f\u601d\uff0c\u8fd9\u662f\u597d\u4e45\u4e4b\u524d\u89e3\u51b3\u7684\u95ee\u9898\u4e86\uff0c\u6211\u4e5f\u5fd8\u4e86\u600e\u4e48\u5904\u7406\u7684\u3002\u4e0d\u8fc7\u8fd9\u91cc\u6709\u4e00\u7bc7\u535a\u5ba2\uff0chttps://zhuanlan.zhihu.com/p/20563721 https://zhuanlan.zhihu.com/p/20563721\uff0c\u535a\u5ba2\u4e0b\u9762\u7684\u8bc4\u8bba\u91cc\u8bf4\u660e\u4e86\u89e3\u51b3\u7684\u529e\u6cd5\uff1a\n\u201c \u5b89\u88c5 aria2 \u540e\uff0c\u6ca1\u6709\u8c8c\u4f3c\u6ca1\u6709\u81ea\u52a8\u8f6f\u94fe\u5230 /usr/local/bin \u4e0b\uff0c\u76f4\u63a5\u8fd0\u884c aria2c \u4f1a\u63d0\u793a command not found\n    \u770b\u4e86\u4e0baria2c\u7684\u6587\u4ef6\u4f4d\u7f6e\uff0c\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u53ef\u4ee5\u89e3\u51b3\uff1a\n    cd /usr/local/bin; \n    sudo ln -s ../aria2/bin/aria2c aria2c\n\u5e0c\u671b\u80fd\u5bf9\u9047\u5230\u540c\u6837\u95ee\u9898\u7684\u670b\u53cb\u6709\u5e2e\u52a9\u3002\n\u201d\n\n\u5728 2016\u5e747\u670821\u65e5\uff0c\u4e0a\u53489:17\uff0cqianjiahao notifications@github.com> \u5199\u9053\uff1a\n@Chen-Sir https://github.com/Chen-Sir how dose you fix it , it was happened on me and i don't know how to fix it ... , so could you share your way ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/aria2/aria2/issues/543#issuecomment-234130564, or mute the thread https://github.com/notifications/unsubscribe-auth/AIK4WXBGxA_FTS-Le9d0GO7jC2a2gwQMks5qXsiNgaJpZM4HNNky.\n. \n",
    "Art2Cat": "Mac version: 10.13\nAria2 version: 1.32.0\nuse soft link:\nsudo ln -s /usr/local/aria2/bin/aria2c aria2c. ",
    "ZeRuTian": "\u60a8\u597d\uff0c\u6211\u6309\u7167\u60a8\u4e0a\u9762\u7ed9\u51fa\u7684\u89e3\u51b3\u529e\u6cd5\uff0c\u4ecd\u65e7\u63d0\u793acommand not found \uff0c\u8bf7\u95ee\u60a8\u77e5\u9053\u662f\u4ec0\u4e48\u539f\u56e0\u5417\uff1f. ",
    "WuHarry": "\n\u60a8\u597d\uff0c\u6211\u6309\u7167\u60a8\u4e0a\u9762\u7ed9\u51fa\u7684\u89e3\u51b3\u529e\u6cd5\uff0c\u4ecd\u65e7\u63d0\u793acommand not found \uff0c\u8bf7\u95ee\u60a8\u77e5\u9053\u662f\u4ec0\u4e48\u539f\u56e0\u5417\uff1f\n\n\u53ef\u80fd\u7684\u539f\u56e0\u662f\uff0c\u73b0\u5728brew\u5b89\u88c5aira2\u4e4b\u540e\u7684\u8def\u5f84\u662f\u5728 /usr/local/Cellar/ \u5e95\u4e0b\uff0c\u4f60\u53ef\u80fd\u5f97\u4fee\u6539\u4e00\u4e0b\u547d\u4ee4\u7684\u8def\u5f84. ",
    "luokar": "@tatsuhiro-t \nDisk-cache works, but it performance much worse than mmap on a fast line. \nDownloading http://ubuntu.hkets.org/14.04.3/ubuntu-14.04.3-desktop-amd64.iso \non window with 1000m broadband and file-allocation=falloc\nwith mmap : 15 second without hang\nwithout mmap & disk-cache=1000M: 25 second and hang\nI guess there are two reason for the difference in performance between cache and mmap\n1) 16M cache is too small for >50MBps\nHDD might work like this:\ncache full, wait for flushing 16MB, cache full ...\nwith mmap: keep downloading, flush 1G file into disk sequently\n2)file-allocation works better with mmap on windows\naria2 always hang when file-allocation. I didn't observe hanging anymore after turning on mmap.\nAs I know, people are getting decent broadband for a affordable price. People living including me in Hong Kong pay 23USD for 1000m 20USD for 500m per month. \nTo prepare for the future(high network throughput but slow disk), I believe aria2 should have a larger cache for single instance or make mmap less dangerous. Anyway, thanks for your quick response.\n. @tatsuhiro-t Sorry, I might misunderstood what you mean by per aria2 instance as per task, but i have set disk-cache=1000M. Aria2 still hang during file-allocation and it spending more time at downloading a 1G file.\n. @tatsuhiro-t I use NTFS on Windows 7. falloc should take only a few milliseconds for a large file, but instead it works like zero filling on Windows 7 with NTFS\n. @tatsuhiro-t  I have tested file-allocation=trunc for a while. The outcome is depressing. It yields even lower performance(maybe problem related to fragmentation) and hanging still appears sometime. I think I better keep using mmap with caution. If this won't be fixed, please tell me and I will close this issue.\n. Excellent, I know closed source stuffs like windows is somehow weird and broken(being forced to use it by my job). I am so glad you are willing to fix these problems for people in pain. Nicely done. I will compile and test it tomorrow.\n. The patch does its job.\nThe performance gain of using mmap is probably from tricking NTFS not to do zero fills by writing sequentially. But since the root cause have been fixed, I am closing this issue.\n. @sky93 \nYou could use header for this purpose:\naria2c --header=\"Cookie:session=3f543ac31fc092bd\" http://example.com/1.zip\n. Sorry it is a configuration error. I accidently set max-download-result=0, but why unfinished task won't be serialized into session when max-download-result=0?\n. I agree some sort of download number optimization is great, but I still don't understand why using\nthe formula N = A + B Log10(speed in Mbps) to determine N. Sometimes, we might need to download  a large number of small file which will slow down current total speed, but decreasing N will just make things worse. \nI propose instead of using N = A + B Log10(speed in Mbps), we should compare the number of download and its effect on total speed or something like an AIMD algorithm.\n. ",
    "zizhengwu": "Hi, I am wondering what will happen if mmap runs out of memory. Will the memory be flushed to the disk or the process be killed by kernel? I am using aria2 on Windows with Cygwin. \n. ",
    "yxliang01": "I think it would be nicer to have an option for it. Instead of manually crafting the header.. ",
    "gerases": "Thanks much for a quick response. I think I solved the problem. When I set the ratio to 0.0 on the original seeder, it worked fine. I will definitely compile using the git repo though just in case.\nThanks again.\n. Ahh, very nice! It does seem to work. What also worked was setting bt-seed-unverified to true. But it sounds like not the best idea. Once I specified check-integrity=true, it started working.\nThanks a ton, Kurt!!\n. I was just going to ask for that. Currently I'm comparing the length of the file and the downloaded length.\n. Whoot!\n. Nice!! \nYes, that's a closed network of 4 machines for testing purposes.\n\nFirst, you need one aria2c as seeder. You can run aria2 as seeder with -V option and enable DHT.\nFor other aria2 daemons, run --dht-entry-point to the IP address of bootstrap node of DHT network. Since your DHT network is in your closed network, and your only node is aria2 seeder, specify seeder's IP address and DHT port in --dht-entry-point option.\n\nThat's what I did kind of except I didn't specify the DHT port. I will try that. \n\nYou need magnet URI to these leechers.\n\nI'm a bit unclear on why I need a magnet URI in this case?\nThanks!!\n. Perfect! Thank you, I will give it a try!\n. This is great already! I was able to arrive at the same filename by applying hash1 to the original torrent file. Maybe it would make sense to add the name of the metafile into the output of the RPC call?\nAlso, I've been able to compile aria successfully but the binary is rather large (~80M) statically or dynamically built. Just curious why it's so large. No big deal, just curious. \n. > I'm not sure what you really meant here. Could you describe this in detail?\nWell, I was talking about the output of RPC calls like tellActive. It returns a structure describing each torrent. The current fields are the file path, guid, etc. I was saying that maybe it makes sense to include the name of the corresponding meta file in that structure as well.\n\nDid you run strip command to remove debug symbols?\n\nI wasn't aware I needed to do that. Can I specify an option at build time not to include the debug symbols?\nAt which point should I run strip?\n. Ah, got it. Yep, reduced it to 4.4M. Nice! Thanks!!\n. ",
    "Reedwarbler": "I am using version: aria2 version 1.34.0, with the following command:\naria2c --auto-file-renaming=false  -i url.txt\nAnd the jobs stuck at 99%. One example url: http://ftp.sra.ebi.ac.uk/vol1/fastq/ERR258/003/ERR2585113/ERR2585113.fastq.gz\nAre there any suggestions to solve this? Thanks!. ",
    "yagami1234": "no,i'm not quote my url with single quotes/double quotes\nbut after try it just now,the download is working right now :D thank you so much for your help \n. ",
    "roulis2844sasha": "Thanks, it works\n. ",
    "gky99": "thank you a lot! It's fixed\n. ",
    "wmlex": "This is the scenario for the package build for CentOS 7. Run as a service and works through a web interface webui-aria2.\n. ",
    "oliviercommelarbre": "to Tatsuhiro: Thanks! and no pb about missing the 15/02 release, it would get a chance in the next one\nwhen you review could you please take a specific look at the option, i have proposed the following template for the final implementation (see in usage_text.h): \n--optimize-concurrent-downloads[=true|false|NUM:NUM]\nbut i've only implemented it as a simple boolean (true | false) for the time being (at present A and B are hardcoded). \nthe NUM:NUM case would mean essentially 'true' while customizing the A and B parameters of the optimization function at the same time.\nbefore completing this part, I wanted to get first your advice on it e.g. does it fit enough the standard of aria2c options? or would you recommend  setting A and B through a separate option? or may be you would have yet another recommendation.\nthanks\n. To Luokar:\nit is a good point and in fact initially i was more looking for something in the idea that you mention, like an adaptive/progressive algo that assesses/reacts on the effect on the overall download speed of adding/removing parallel downloads. \nhowever i found out that it would be extremely complex to get a good value somehow, here the rationale in a few words:\n- assessing the benefits of adding a parallel download will be very complex. first it will depend on the initial latency to open the connection before you receive the first byte that will have a chance to influence the download speed in a tangible manner. e.g.  you would have to wait some time before you could conclude on whether it was a good thing or bad thing. This wait time will depend on the protocol you use and on the latency of the network you are on, which will make the real-time algo even more complex. also, waiting would imply that the algo will be less reactive at the beginning. e.g. if you have a 50mbps link, you aim at going straight to several 10s of parallel downloads to saturate your inbound bandwith and optimise the overall session. going step by step after a careful adaptive algorithm might result in getting to saturate the inbound bandwith only after several 10s of seconds or more. Also i found that it will be difficult to know whether the speed increase you could measure is effectively due to your additional parallel download(s), or just a result of your available bandwith augmenting for other reasons which brings additional complexity.\n- second, i found out that the gain on the overall download speed of adding parallel downloads does not necessarily require a fine control. Practically what we want to achieve is \n  (1) to use effectively the idle time between successive downloads (end a connection, start a new one) during which the inbound bandwith is not well used. having a parallel download at the time of these idles of the other connections ensures that the inbound bandwidth is always used to some extent.\n  (2) to slow down every single TCP connection so that the effect of its latency has less impact on the overall download throughput we get out of it.\n  (3) to avoid client congestion and server timeouts that go in pair when too many parallel downloads are set (the many parallel connections end up going so slowly by sharing the same inbound bandwidth that the corresponding servers aborts before the download completes)\n  My conclusion here was that the number of parallel downloads we should be using is more a function of the class of performance of the network we are using, rather than requiring a fine control loop. \n  the reason for using the logarithm is exactly following this rationale. Adding a degree of magnitude to your inbound network bandwidth should result into adding parallel downloads nearly linearly to the difference in degrees of magnitude.\nThe other good thing is that the range of performance of the network can be sensed nearly immediately after a download starts. i.e. a second is enough to figure out roughly the right range, which is an asset to ensure the dynamics of the intended optimization.\nHaving said that you are right that the download of very small files will lead to reaching less easily the available bandwidth (because of the latency and the connection overhead), hence the number of parallel downloads should be sustained slightly higher than the actual need for big ones. Puting it slightly higher than needed will have i think very little negative impact on the download performance for big files, the important thing in my view is to get it roughly right (to achieve the goals 1, 2 and 3) and slightly more than stricly needed (to sustain a good performance in all cases). I've proposed very draft default values for A and B. in fact i have tested the algo on files of a few megabytes each (2 to 6 MB typically) and on 1 to 100Mbps networks typically. \nWe could try to see whether we should expect a big dependency of these A&B settings wrt the size of the individual files, it would be in fact interesting to validate the approach and may be tune the default parameters.\n. Hi Tatsuhiro, i'm glad you like it and thks for giving credit. In the meantime I've been test bedding the case highlighted by @luokar, and doing that i found out that the speed measurements i get are sometimes inconsistent, as they vary unexpectedly jumping from hundreds of KiB/s to suddenly tens or few KiB/s within the same second of invoking the calculateSpeed method. This is in fact not specifically linked to the case of very small files although the case happens more often in that case since we get more often in the loop due to downloads finishing quickly.\nI've debugged a bit and i think i found out the source of the problem. The SpeedCalc class which is in charge of computing the speed uses a timetag for the speed measurement updates (now = global::wallclock()) that is refreshed only once in between every command execution (within DownloadEngine::run). I need to study a little more to understand a good way round to avoid the inconsistency i observed. I'll come back to you...if you see an easy way round please don't hesitate to comment\n. Hi Tatsuhiro, i think i have completed as per the thread sofar + the option processing + an improvement to the algo to cover better for the case of small file downloads. I'm quite happy sofar with the results of my tests. i let you take a look.\n. small addendum: i'm not very familiar with github.  i've commited in my initial branch (issued from 1.19.3) which is no more the aria2c master since the last merge of the 15/02. please let me know if that's ok or if i should do it differently, thks\n. yes it seems so... and unexpectedly so. It seems my build-release directory under /aria2 went all in for whatever reason... i'll try to do a new commit that removes it.\n. @nmaier it should be ok now, sorry about that\n. Hi Tatsuhiro and nmaier, sorry for the silence, i'm in a middle of a house restructuration so my week ends are a bit busy... i've no problem about merging all commits into one and i understand it can make it cleaner after the spurious commit of the build directory...\nFor revieweing the code according to the last comment of nmaier no pb either, i think i can find a bit of time tomorrow if that's ok.\n. Hi Tatsuhiro and Nils, i've just commited the syntax corrections, so it should be ready for the rebase. i wonder if we can make it on time for the merge before 15/03? otherwise no pb, we should be ready for the next period. cheers to both\n. Thank You Tatsuhiro, it's been a real pleasure, we'll be eager to do more, thanks also for managing this so nicely and easily\n. agreed with that, will do\n. you are right. in fact i remember this was temporary... what i intended initially was to check whether --max-concurrent-downloads had been explicitly defined, but i did not find the right way to do it and left this in. \nThe idea would be that if max-concurrent-downloads is not explicitly set, then there is no absolute maximum for the optimization. I would find it useful, please tell me your opinion and i would  complete. I found later on that every option implements a defined() method and i guess it returns false if not explicitly defined.\n. good point, will update\n. thanks for the tip, much nicer, will do\n. ok, strange i don't remember my compiler giving me the warning\n. true it is not used (only the other one, now renamed with 'setup' as per your suggestion is used), i had just put it for completeness of set/get, but i will remove. \n. ok!\n. done\n. you are right (i just copied the case of the Boolean handler and left that in), will correct\n. ok will do, i had a doubt myself on the convention to take\n. ok, will follow the convention\n. you are quite wise in raising that question ;-), it made me do some additional tests and these tests made me conclude that i don't have a good answer!\nIf you are curious, please read along. otherwise you can ignore since my new proposal would be to remove this part. i found out since then that the concept i was trying to model is actually not necessary to meet the objective it was supposed to contribute to...\nthe original objective was to take into account the 'overhead'  imposed by each of the file transfers on the speed measured, noting that the speed reached by aria2 in the case of small files is much lower compared to that of large files, even in the case of a high number of parallel downloads, which in turns makes the algo conclude on a too small number of parallel dowloads at the next iteration (the case highlighted by luokar).\nthe rationale for this calculation was hence to compute the actual bandwidth utilized instead of just measuring the effective download speed. As a matter of fact, the 'speed' computed by aria2 in SpeedCalc is measuring the actual number of 'useful' file bytes received by the client in a second of time after the first 'useful' byte has been received for every file download active, which is not necessarily linear with the actual bandwidth utilized if one is to consider the initial traffic necessary to initialise each transfer (e.g.ftp or http connection initialisation overhead) before the first 'useful' byte is received.\nThe speedUndervalueRatio was here to measure this overhead on the principle that every file transfer, regardless of the size of the file, would impose a fixed traffic on the link of N initialisation bytes before the first useful byte is received and accounted for in SpeedCalc.\nAlong this principle:\n speedUndervalueRatio = bandwidth/speed-1 \n= (bytesWindow_ + N_(number of downloads active in the speed elapsed period))/bytesWindow_ -1 \n= N_(number of downloads active in the speed elapsed period)/bytesWindow_\nin turn, and on the assumption that the overhead would have limited variability in a session (sizes of files equally distributed along the session time), the overhead could be approximated as:\nspeedUndervalueRatio ~ N*(total number of downloads since the start of the session)/(total number of bytes received since the start of the session)\nafter my empirical tests, i had concluded for a value for N in the order of 4 KiB so that the bandwidth computed on 1KiB parallel ftp file transfers could be comparable to that of 1MiB parallel ftp file transfers.\n\nNow, back to reality after my additional tests:\n- i found out that in case of http, the overhead would need to be much less than the 4KiB which i had benchmarked on ftp transfers. \n- trying to reach a higher number of parallel downloads for small files as compared to the case of large files is not necessarily a good thing since it can tire up the server(s) which have to process too many requests too frequently (the frequency of requests in a scenario with many small files is larger since they are downloaded quickly)\n- finally and more importantly, the main unwanted scenario in the case of small files is already taken care of by the Timer of 5 seconds that waits for the parallel downloads to ramp-up the speed while ignoring possible drops of speed while the steady state is being reached. Also, monitoring that the speed keeps up well before decreasing number of parallel downloads is warrant that the steady state is maintained even for small file downloads.\nin conclusion, i propose to roll back to using the speed directly which gives equally good results in both ftp and http cases.\n. i'm not sure to understand. \nall slots that have a timetag in the range are considered.\nthe 'if' on rbegin is there in case the timeSlots_ list is empty or if the while loop exits immediately (it is actually unlikely but one never knows). Note that the while loop exits normally with one position ahead on the iterator, hence if the iterator has not moved from its first rbegin position, then we are in this case and we have no slot to compute the speed upon.\nplease comment back if i missed something, thanks\n. ",
    "Edo78": "A reverse link should make it a lot easier but I'll try to use the followedBy attribute.\nThank you very much\n. ",
    "dxzhan": "@Haocen yes,compile pass,3Q!\n. ",
    "haikubox": "@clamsawd , thank you for linking issues. Unfortunately, I have found the old one after I submitted mine. However, something still looks wrong here: aria displays warning, but still able to use falloc properly (see 12G file created instantly - on regular HDD, not SSD). Another thing - why prior version 1.20 aria was able to use falloc without admn permissions and now it does not? Believe running downloader in elevated prompt is a bit of \"overhead\" (leaving aside Windows security quirks). Just to add - my user is administrator, but I still need elevated prompt. I even tried to add my user directly to this permission in GPO editor, but it did not seem to have any effect.\n. Tatsuhiro, thank you for the explanation. Looks like there is no way around to bypass elevation.\n. ",
    "zsrinivas": "thank you very much, i'm searching with case sensitive flag,\nsorry to waste your time.\n:100: \n. ",
    "boly007": "anyone compiled it for windows with 32 connection? can I have it ? thanks. ",
    "Kyle-Kyle": "After changing the number 16 to 32 in OptionHandlerFactory.cc as mentioned and rebuilding, the max connection per server is still 16. I wonder whether this configuration is overwritten somewhere else.. ",
    "BladeMight": "right referrer and it works.\n. ",
    "mehrdadn": "@tatsuhiro-t Have you looked into NTFS's \"sparse file\" feature? It may be what we're looking for here. (Note that, at the end of the download, the sparse flag should be removed.). ",
    "cololi": "But I reinstall  ubuntu 14.04 LTS  still generating this error again\n. Yes , I successed  Thank you for reply my question .\n. ",
    "amiter": "well.....most of the time,we remove a download in order to free up some space!\n. ",
    "i3p9": "But I couldn't find it anywhere, not even in %userprofile% :|\n. That worked. Thank you!\nTo add something here, normally creating a folder named .aria2 will not work in Windows. To create, just write .aria2. (yes, dot in both prefix and suffix to create the folder.\n. ",
    "locchi93": "Thank you for this awesome project!\n. ",
    "Szunti": "Can't access the google uri anymore. And it works now.\n. ",
    "gynet": "this is great!. ",
    "starless72": "For the record, I'm trying the new version of aria2 because I experienced problems with the previous 1.19.3, too, on the same OSX version 10.7.4: I got the following message whenever I tried to download an HTTPS URL (e.g. https://www.google.com):\nSegmentation fault: 11\nI attach again Console lines and crash report.\nSegmentation_fault_11_Console.txt\naria2c_2016-03-18-130020_VirtualOSX_crash.txt\nThis is similar to #275, but I'm not using any proxy, and that issue is rather old and should be fixed by now.\nAnyway, the new version made things even worse, because aria2c cannot start at all now.\nIs there a minimum supported version of OSX?\n. Fixed for 1.29.0\n. ",
    "joeshae": "ed2k is very useful when downloading some resources from some forums. \nAria2 is my favorite downloader. I'm using it to download almost everything I need, except the ed2k resources, which I have to switch to amule to deal with. \nSo I hope ed2k could be supported in aria2. \nThank you @tatsuhiro-t !\n. ",
    "underlaw": "+1. \u52a0\u4e0abt\u670d\u52a1\u5668\u5730\u5740. +1. good idea,You might also add a function to select files when you download. Best to achieve the front desk to delete files, but also to delete files on the hard disk. @kkartaltepe thx. +1. \u90a3\u57fa\u672c\u4e0a\u662f\u79cd\u5b50\u7684\u539f\u56e0\u4ee5\u53ca\u4f60\u81ea\u5df1\u7f51\u7edc\u7684\u539f\u56e0\u4e86. \u5982\u679c\u4f60\u8bbe\u7f6e\u90fd\u6b63\u786e\uff0c\u53bbBT\u5927\u7ad9\u4e0b\u8f7d\u4e00\u4e2a\u70ed\u95e8\u79cd\u5b50\uff0c\u4e0b\u8f7d\u5b8c\u3002\u4f60\u4f1a\u53d1\u73b0\u4f60\u7684DHT.dat\u8fd9\u4e2a\u6587\u4ef6\u4f1a\u53d8\u5927\uff0c\u4ee5\u540e\u4f60\u4e0b\u8f7d\u5c31\u6709\u901f\u5ea6\u4e86\n\u901f\u5ea6\u4e0e\u79cd\u5b50\u70ed\u5ea6\u6709\u5173\uff0c\u65f6\u95f4\u592a\u4e45\u65e0\u4eba\u505a\u79cd\u4ee5\u53ca\u4f60\u7684\u7f51\u7edc\u90fd\u6709\u5f71\u54cd\uff0c\u5f71\u54cd\u6700\u5927\u7684\u662f\u4f60\u7684\u7f51\u7edc\u3002. > `## ###################RPC\u76f8\u5173\u8bbe\u7f6e ###################\n\n\u542f\u7528RPC, \u9ed8\u8ba4:false\nenable-rpc=true\n\u5141\u8bb8\u6240\u6709\u6765\u6e90, \u9ed8\u8ba4:false\nrpc-allow-origin-all=true\n\u5141\u8bb8\u975e\u5916\u90e8\u8bbf\u95ee, \u9ed8\u8ba4:false\nrpc-listen-all=true\n\u4e8b\u4ef6\u8f6e\u8be2\u65b9\u5f0f, \u53d6\u503c:[epoll, kqueue, port, poll, select], \u4e0d\u540c\u7cfb\u7edf\u9ed8\u8ba4\u503c\u4e0d\u540c\nevent-poll=select\nRPC\u76d1\u542c\u7aef\u53e3, \u7aef\u53e3\u88ab\u5360\u7528\u65f6\u53ef\u4ee5\u4fee\u6539, \u9ed8\u8ba4:6800\nrpc-listen-port=6800\n\u8bbe\u7f6e\u7684RPC\u6388\u6743\u4ee4\u724c, v1.18.4\u65b0\u589e\u529f\u80fd, \u53d6\u4ee3 --rpc-user \u548c --rpc-passwd \u9009\u9879\nrpc-secret=www.vxget.com\n###################### \u57fa\u672c\u8bbe\u7f6e\n\u4e0b\u8f7d\u8def\u5f84\ndir=C:\\Users\\zh.w\\Downloads\n\u6700\u5927\u540c\u65f6\u4e0b\u8f7d\u6570\nmax-concurrent-downloads=10\n\u68c0\u67e5\u5b8c\u6574\u6027\ncheck-integrity=false\n\u65ad\u70b9\u7eed\u4f20\ncontinue=true\n##################HTTP/FTP/SFTP\u8bbe\u7f6e\n\u5355\u670d\u52a1\u5668\u6700\u5927\u8fde\u63a5\u6570\nmax-connection-per-server=16\n\u6700\u5c0f\u6587\u4ef6\u5206\u7247\u5927\u5c0f\nmin-split-size=1M\n\u5355\u4efb\u52a1\u8fde\u63a5\u6570\nsplit=20\n#######################HTTP\u8bbe\u7f6e\n\u542f\u7528 HTTP \u7ba1\u7ebf\u5316\nenable-http-pipelining=true\n#######################BitTorrent\u8bbe\u7f6e\n\u542f\u7528\u672c\u5730\u8282\u70b9\u53d1\u73b0 (LPD)\nbt-enable-lpd=true\n\u505a\u79cd\u524d\u68c0\u67e5\u6587\u4ef6\u54c8\u5e0c\nbt-hash-check-seed=true\n\u52a0\u8f7d\u5df2\u4fdd\u5b58\u7684\u5143\u6570\u636e\u6587\u4ef6\nbt-load-saved-metadata=true\n\u6700\u591a\u6253\u5f00\u6587\u4ef6\u6570\nbt-max-open-files=100\n\u6700\u5927\u8fde\u63a5\u8282\u70b9\u6570\nbt-max-peers=0\n\u4ec5\u4e0b\u8f7d\u79cd\u5b50\u6587\u4ef6\nbt-metadata-only=false\n\u5220\u9664\u672a\u9009\u62e9\u7684\u6587\u4ef6\nbt-remove-unselected-file=true\n\u671f\u671b\u4e0b\u8f7d\u901f\u5ea6\nbt-request-peer-speed-limit=50K\n\u4fdd\u5b58\u79cd\u5b50\u6587\u4ef6\nbt-save-metadata=false\n\u4e0d\u68c0\u67e5\u5df2\u7ecf\u4e0b\u8f7d\u7684\u6587\u4ef6\nbt-seed-unverified=true\nBT \u670d\u52a1\u5668\u5730\u5740\nbt-tracker=\n\u542f\u7528 DHT (IPv4)\nenable-dht=true\n\u542f\u7528 DHT (IPv6)\nenable-dht6=true\n\u542f\u7528\u8282\u70b9\u4ea4\u6362\nenable-peer-exchange=true\n\u4e0b\u8f7d\u79cd\u5b50\u4e2d\u7684\u6587\u4ef6\nfollow-torrent=true\n\u5168\u5c40\u6700\u5927\u4e0a\u4f20\u901f\u5ea6\nmax-overall-upload-limit=50k\n\u6700\u5c0f\u5206\u4eab\u7387\nseed-ratio=0.01\n\u6700\u5c0f\u505a\u79cd\u65f6\u95f4\nseed-time=0\n###############################\u9ad8\u7ea7\u8bbe\u7f6e\n\u5141\u8bb8\u8986\u76d6\nallow-overwrite=false\n\u5141\u8bb8\u5206\u7247\u5927\u5c0f\u53d8\u5316\nallow-piece-length-change=true\n\u59cb\u7ec8\u65ad\u70b9\u7eed\u4f20\nalways-resume=true\n\u81ea\u52a8\u4fdd\u5b58\u95f4\u9694\nauto-save-interval=30\n\u6587\u4ef6\u5206\u914d\u65b9\u6cd5\nfile-allocation=falloc\n\u4fdd\u7559\u672a\u5b8c\u6210\u7684\u4efb\u52a1\nkeep-unfinished-download-result=true\n\u4f18\u5316\u5e76\u53d1\u4e0b\u8f7d\noptimize-concurrent-downloads=true\n\u8bfb\u53d6\u4e0b\u8f7d\u4efb\u52a1\ninput-file=G:\\AriaNgGUI-win32-x64\\resources\\app\\aria2\\aria2.session\n\u4fdd\u5b58\u4e0b\u8f7d\u4efb\u52a1\nsave-session=G:\\AriaNgGUI-win32-x64\\resources\\app\\aria2\\aria2.session\n\u4fdd\u5b58\u72b6\u6001\u95f4\u9694\nsave-session-interval=30\n\u78c1\u76d8\u7f13\u5b58\ndisk-cache=32M\n\u5168\u5c40\u6700\u5927\u4e0b\u8f7d\u901f\u5ea6\nmax-overall-download-limit=0\n\u6700\u5927\u4e0b\u8f7d\u901f\u5ea6\nmax-download-limit=0\n`\n\n. \u5e94\u8be5\u662f\u8fd9\u4e2abug,\u6709\u65f6\u5019\u5220\u9664\u4e86\u7684\u4efb\u52a1\uff0c\u91cd\u542f\u540e\u4e5f\u4f1a\u52a0\u4e0a. ",
    "cnsimo": "+1. ",
    "Windows10010": "+1. ",
    "pingshunhuangalex": "Thanks for the reply. The version 1.21 I used is directly downloaded from project page. The folder I have looks much simpler than the master folder, i.e. there is no src folder nor BencodeParser.cc for me to tweak.\nI also try to update everything using the files in master branch, but it seems simply adding those file doesn't do anything to the utilities. Some more guidance would be much appreciated. Thanks. \n. I kind of understand my problem now. I think the link I captured is not really the real path for my torrent. When chrome open the link it download something else directed by the link, which brings me to another problem...\nIs there a way to associate .torrent file somehow with aria2 (or aria2UI)? i.e. when I open (double click) the torrent file, aria2 starts the BT tasks accordingly? Thanks.\n. I did have --http-accept-gzip set to true already, but the problem remains. I think it's just Chrome API then. I don't know if there's a way to describe or to fix it. Thanks anyway.\nI'm just curious that nobody else in the feedback section seems to be bothered with this issue. How do you guys deal with torrent file? Just download it and load it into aria2 via ui or cmd? Thanks.\n. Thanks. That narrows the issue to chrome API then. Like what I reported in the previous thread, some urls will redirect users to torrents' true path before downloading it. So simply sending the url to aria2 will only download a webpage file or files that are irrelevant. Good examples would be:\nThere are a lot of cases like this, but I'm not sure if there's anything you can do if it's a chrome api issue. If you are still interested, you can have a go with the urls above. Thanks.\n. Sorry, just some random url I searched using google. Well, you get the idea now, and I don't know how else I can pass the message.\n. Thanks @xjbeta for the hints.\nI'm sure aria2.onDownloadComplete(event), aria2.onDownloadError(event), aria2.onBtDownloadComplete(event) are the ones I'm after, but could you please give me an example on how to use these 3 command? I'm currently just using a config file and webui for aria2, not sure where and how these command can be fit into the process. Thanks.\n. Cool. Thanks @xjbeta \n. ",
    "dustymabe": "That seems to do the trick. I applied the patch to the version and fedora and it works now.\nA few questions:\n- After the download the directory and the other file from the torrent still exists on the machine. Is it possible to just download the single file from the torrent rather than the collection of files? This might not be possible but I just don't know because I don't fully understand torrents. If not, should we clean up the other files and the directory after download?\n- Does aria2c verify the contents match checksum from the metalink? I don't see any indication of that from the output:\n```\n  Download Progress Summary as of Sun Mar 27 17:48:47 2016  \n==============================================================================================================================================================================================================================================================================\n[#921325 1.9GiB/2.0GiB(97%) CN:45 SD:42 DL:4.0MiB ETA:10s]\nFILE: /root/foo/Fedora-Server-DVD-x86_64-23.iso\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n[#921325 2.0GiB/2.0GiB(99%) CN:44 SD:41 DL:3.9MiB]                                                                                                                                                                                                                          \n03/27 17:49:06 [NOTICE] Download of selected files was complete.\n  Download Progress Summary as of Sun Mar 27 17:49:48 2016  \n==============================================================================================================================================================================================================================================================================\n[#921325 SEED(0.0) CN:2 SD:0]\nFILE: /root/foo/Fedora-Server-DVD-x86_64-23.iso\n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n[#921325 SEED(0.0) CN:2 SD:0]^C                                                                                                                                                                                                                                             \n03/27 17:50:08 [NOTICE] Shutdown sequence commencing... Press Ctrl-C again for emergency shutdown.\n```\n. ",
    "wao1201": "rolled back to 1.20.0, works well.\nFYI, I used the DMG installer to install aria2 on my machine.\n. @nmaier \nStill got crash\nProcess:               aria2c [33038]\nPath:                  /usr/local/aria2/bin/aria2c\nIdentifier:            aria2c\nVersion:               0\nCode Type:             X86-64 (Native)\nParent Process:        ??? [1]\nResponsible:           aria2c [33038]\nUser ID:               501\nDate/Time:             2016-04-09 14:04:21.091 -0600\nOS Version:            Mac OS X 10.11.4 (15E65)\nReport Version:        11\nAnonymous UUID:        2373E446-31EA-F356-6240-FA7717C04EB0\nSleep/Wake UUID:       EB7F0E4F-3BDA-496C-8D39-C7AC89E7CB69\nTime Awake Since Boot: 390000 seconds\nTime Since Wake:       53000 seconds\nSystem Integrity Protection: enabled\nCrashed Thread:        0  Dispatch queue: com.apple.main-thread\nException Type:        EXC_BAD_INSTRUCTION (SIGILL)\nException Codes:       0x0000000000000001, 0x0000000000000000\nException Note:        EXC_CORPSE_NOTIFY\nApplication Specific Information:\ncrashed on child side of fork pre-exec\nThread 0 Crashed:: Dispatch queue: com.apple.main-thread\n0   aria2c                          0x0000000106636931 __gmpn_submul_1 + 81\nThread 0 crashed with X86 Thread State (64-bit):\n  rax: 0xffffffffffffffa0  rbx: 0x00007fff597d8f70  rcx: 0x0000000000000000  rdx: 0x0000000000000000\n  rdi: 0x00007fff597d8f08  rsi: 0x00007fff597d8f70  rbp: 0x0000000000000003  rsp: 0x00007fff597d8c98\n   r8: 0x0000000000000004   r9: 0x00007fff597d8f70  r10: 0x0000000000000001  r11: 0x00007f9d1ad00000\n  r12: 0x0000000000000002  r13: 0x00007fff597d8f08  r14: 0x0000000000000001  r15: 0x0000000000000000\n  rip: 0x0000000106636931  rfl: 0x0000000000010206  cr2: 0x0000000106636a40\nLogical CPU:     0\nError Code:      0x00000000\nTrap Number:     6\nBinary Images:\n       0x106426000 -        0x10674cfcf +aria2c (0) <6205577F-13BF-3D06-A352-1FEC9068E8B2> /usr/local/aria2/bin/aria2c\n    0x7fff6b1dc000 -     0x7fff6b2130d7  dyld (360.21)  /usr/lib/dyld\n    0x7fff8584d000 -     0x7fff85850ffb  libdyld.dylib (360.21) <8390E026-F7DE-3C32-9486-3DFF6BD131B0> /usr/lib/system/libdyld.dylib\n    0x7fff8663b000 -     0x7fff8666affb  libsystem_m.dylib (3105) <08E1A4B2-6448-3DFE-A58C-ACC7335BE7E4> /usr/lib/system/libsystem_m.dylib\n    0x7fff86823000 -     0x7fff8682efff  libkxld.dylib (3248.40.184) <6F776D34-D06C-3C48-B753-D0FB375A4A8A> /usr/lib/system/libkxld.dylib\n    0x7fff878db000 -     0x7fff878dbff7  liblaunch.dylib (765.40.36) <1CD7619D-AF2E-34D1-8EC6-8021CF473D9B> /usr/lib/system/liblaunch.dylib\n    0x7fff87921000 -     0x7fff87996fff  com.apple.framework.IOKit (2.0.2 - 1179.40.20)  /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit\n    0x7fff88672000 -     0x7fff88676fff  libcache.dylib (75) <9548AAE9-2AB7-3525-9ECE-A2A7C4688447> /usr/lib/system/libcache.dylib\n    0x7fff8a0c0000 -     0x7fff8a0c1fff  libDiagnosticMessagesClient.dylib (100) <4243B6B4-21E9-355B-9C5A-95A216233B96> /usr/lib/libDiagnosticMessagesClient.dylib\n    0x7fff8a6fe000 -     0x7fff8a6fffff  libsystem_secinit.dylib (20) <32B1A8C6-DC84-3F4F-B8CE-9A52B47C3E6B> /usr/lib/system/libsystem_secinit.dylib\n    0x7fff8c1af000 -     0x7fff8c1f5ff7  libauto.dylib (186) <999E610F-41FC-32A3-ADCA-5EC049B65DFB> /usr/lib/libauto.dylib\n    0x7fff8c1f6000 -     0x7fff8c1f7fff  libsystem_blocks.dylib (65) <1244D9D5-F6AA-35BB-B307-86851C24B8E5> /usr/lib/system/libsystem_blocks.dylib\n    0x7fff8c870000 -     0x7fff8c8d6ff7  libsystem_network.dylib (583.40.20) <269E5ADD-6922-31E2-8D55-7B777263AC0D> /usr/lib/system/libsystem_network.dylib\n    0x7fff8d374000 -     0x7fff8d375ffb  libSystem.B.dylib (1226.10.1)  /usr/lib/libSystem.B.dylib\n    0x7fff8db90000 -     0x7fff8db98fff  libsystem_networkextension.dylib (385.40.36) <66095DC7-6539-38F2-95EE-458F15F6D014> /usr/lib/system/libsystem_networkextension.dylib\n    0x7fff8ec88000 -     0x7fff8ec9fff7  libsystem_coretls.dylib (83.40.5)  /usr/lib/system/libsystem_coretls.dylib\n    0x7fff8f1d1000 -     0x7fff8f46bfff  com.apple.security (7.0 - 57337.40.85) <7C5B8DEF-3D02-3410-9BD3-2B1251F84D4B> /System/Library/Frameworks/Security.framework/Versions/A/Security\n    0x7fff8f664000 -     0x7fff8f66cffb  libsystem_dnssd.dylib (625.40.20) <86A05653-DCA0-3345-B29F-F320029AA05E> /usr/lib/system/libsystem_dnssd.dylib\n    0x7fff8fde6000 -     0x7fff8fe0fff7  libxpc.dylib (765.40.36) <2CC7CF36-66D4-301B-A6D8-EBAE7405B008> /usr/lib/system/libxpc.dylib\n    0x7fff902a3000 -     0x7fff90330fff  libsystem_c.dylib (1082.20.4)  /usr/lib/system/libsystem_c.dylib\n    0x7fff90f0b000 -     0x7fff90f0efff  libsystem_sandbox.dylib (460.40.33) <30671DCC-265F-325A-B33D-11CD336B3DA3> /usr/lib/system/libsystem_sandbox.dylib\n    0x7fff91472000 -     0x7fff91474ff7  libquarantine.dylib (80) <0F4169F0-0C84-3A25-B3AE-E47B3586D908> /usr/lib/system/libquarantine.dylib\n    0x7fff91859000 -     0x7fff91860ff7  libcompiler_rt.dylib (62)  /usr/lib/system/libcompiler_rt.dylib\n    0x7fff91885000 -     0x7fff91974ffb  libxml2.2.dylib (29.5) <4096C2EA-6659-3F22-AC60-1E2F30BDD2B7> /usr/lib/libxml2.2.dylib\n    0x7fff924fb000 -     0x7fff9250bfff  libbsm.0.dylib (34) <7E14504C-A8B0-3574-B6EB-5D5FABC72926> /usr/lib/libbsm.0.dylib\n    0x7fff9282c000 -     0x7fff9282dffb  libremovefile.dylib (41) <552EF39E-14D7-363E-9059-4565AC2F894E> /usr/lib/system/libremovefile.dylib\n    0x7fff92f65000 -     0x7fff92f6aff7  libmacho.dylib (875.1) <318264FA-58F1-39D8-8285-1F6254EE410E> /usr/lib/system/libmacho.dylib\n    0x7fff93382000 -     0x7fff9338afff  libcopyfile.dylib (127)  /usr/lib/system/libcopyfile.dylib\n    0x7fff9338b000 -     0x7fff9338dfff  libsystem_coreservices.dylib (19.2) <1B3F5AFC-FFCD-3ECB-8B9A-5538366FB20D> /usr/lib/system/libsystem_coreservices.dylib\n    0x7fff9338e000 -     0x7fff9339fff7  libz.1.dylib (61.20.1)  /usr/lib/libz.1.dylib\n    0x7fff933f3000 -     0x7fff93600fff  libicucore.A.dylib (551.51) <35315A29-E21C-3CC5-8BD6-E07A3AE8FC0D> /usr/lib/libicucore.A.dylib\n    0x7fff93609000 -     0x7fff93636fff  libdispatch.dylib (501.40.12)  /usr/lib/system/libdispatch.dylib\n    0x7fff9363f000 -     0x7fff93648ff7  libsystem_pthread.dylib (138.10.4) <3DD1EF4C-1D1B-3ABF-8CC6-B3B1CEEE9559> /usr/lib/system/libsystem_pthread.dylib\n    0x7fff93a5f000 -     0x7fff93a7bff7  libsystem_malloc.dylib (67.40.1) <5748E8B2-F81C-34C6-8B13-456213127678> /usr/lib/system/libsystem_malloc.dylib\n    0x7fff93a81000 -     0x7fff93a8ffff  libxar.1.dylib (302) <03207F66-2C4A-3DBD-8D81-70F4C85903C4> /usr/lib/libxar.1.dylib\n    0x7fff94535000 -     0x7fff94535ff7  libunc.dylib (29)  /usr/lib/system/libunc.dylib\n    0x7fff945d2000 -     0x7fff946effff  libsqlite3.dylib (216.4)  /usr/lib/libsqlite3.dylib\n    0x7fff95883000 -     0x7fff95883ff7  libkeymgr.dylib (28) <8371CE54-5FDD-3CE9-B3DF-E98C761B6FE0> /usr/lib/system/libkeymgr.dylib\n    0x7fff95d6e000 -     0x7fff95d97fff  libc++abi.dylib (125)  /usr/lib/libc++abi.dylib\n    0x7fff95d98000 -     0x7fff95da1ff3  libsystem_notify.dylib (150.40.1)  /usr/lib/system/libsystem_notify.dylib\n    0x7fff9616c000 -     0x7fff9616cfff  libOpenScriptingUtil.dylib (169.1)  /usr/lib/libOpenScriptingUtil.dylib\n    0x7fff9650b000 -     0x7fff96513fef  libsystem_platform.dylib (74.40.2) <29A905EF-6777-3C33-82B0-6C3A88C4BA15> /usr/lib/system/libsystem_platform.dylib\n    0x7fff96542000 -     0x7fff96553ff7  libsystem_trace.dylib (201.10.3) <25104542-5251-3E8D-B14A-9E37207218BC> /usr/lib/system/libsystem_trace.dylib\n    0x7fff97511000 -     0x7fff9751fff7  libbz2.1.0.dylib (38) <28E54258-C0FE-38D4-AB76-1734CACCB344> /usr/lib/libbz2.1.0.dylib\n    0x7fff9759f000 -     0x7fff9790a657  libobjc.A.dylib (680)  /usr/lib/libobjc.A.dylib\n    0x7fff9790b000 -     0x7fff97922ff7  libsystem_asl.dylib (323.40.3) <007F9094-317A-33EA-AF62-BAEAAB48C0F7> /usr/lib/system/libsystem_asl.dylib\n    0x7fff97b70000 -     0x7fff97fe6fff  com.apple.CoreFoundation (6.9 - 1258.1) <943A1383-DA6A-3DC0-ABCD-D9AEB3D0D34D> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    0x7fff9937f000 -     0x7fff993f6feb  libcorecrypto.dylib (335.40.8) <9D300121-CAF8-3894-8774-DF38FA65F238> /usr/lib/system/libcorecrypto.dylib\n    0x7fff99898000 -     0x7fff9989dff3  libunwind.dylib (35.3)  /usr/lib/system/libunwind.dylib\n    0x7fff9a8da000 -     0x7fff9a903fff  libsystem_info.dylib (477.40.5) <6B01C09E-A3E5-3C71-B370-D0CABD11A436> /usr/lib/system/libsystem_info.dylib\n    0x7fff9a909000 -     0x7fff9a90dfff  libpam.2.dylib (20)  /usr/lib/libpam.2.dylib\n    0x7fff9ab60000 -     0x7fff9ab6bff7  libcommonCrypto.dylib (60075.40.2)  /usr/lib/system/libcommonCrypto.dylib\n    0x7fff9ab6d000 -     0x7fff9ab6dfff  libenergytrace.dylib (10.40.1) <0A491CA7-3451-3FD5-999A-58AB4362682B> /usr/lib/libenergytrace.dylib\n    0x7fff9bda6000 -     0x7fff9bdc4ff7  libsystem_kernel.dylib (3248.40.184) <88C17B7F-1CD8-3979-A1A9-F7BDB4FCE789> /usr/lib/system/libsystem_kernel.dylib\n    0x7fff9be34000 -     0x7fff9be36ff7  libsystem_configuration.dylib (802.40.13) <3DEB7DF9-6804-37E1-BC83-0166882FF0FF> /usr/lib/system/libsystem_configuration.dylib\n    0x7fff9be51000 -     0x7fff9bea4ff7  libc++.1.dylib (120.1) <8FC3D139-8055-3498-9AC5-6467CB7F4D14> /usr/lib/libc++.1.dylib\nExternal Modification Summary:\n  Calls made by other processes targeting this process:\n    task_for_pid: 18\n    thread_create: 0\n    thread_set_state: 0\n  Calls made by this process:\n    task_for_pid: 0\n    thread_create: 0\n    thread_set_state: 0\n  Calls made by all processes on this machine:\n    task_for_pid: 251120\n    thread_create: 0\n    thread_set_state: 0\nVM Region Summary:\nReadOnly portion of Libraries: Total=114.9M resident=0K(0%) swapped_out_or_unallocated=114.9M(100%)\nWritable regions: Total=82.7M written=0K(0%) resident=0K(0%) swapped_out=0K(0%) unallocated=82.7M(100%)\nVIRTUAL   REGION\nREGION TYPE                        SIZE    COUNT (non-coalesced) \n===========                     =======  ======= \nKernel Alloc Once                    8K        3 \nMALLOC                            72.4M       11 \nMALLOC guard page                   16K        4 \nProcess Corpse Info               2048K        2 \nSTACK GUARD                       56.0M        2 \nStack                             8192K        2 \nVM_ALLOCATE                          4K        2 \n__DATA                            3336K       57 \n__LINKEDIT                        92.3M        4 \n__TEXT                            22.6M       57 \n__UNICODE                          552K        2 \nshared memory                       12K        4 \n===========                     =======  ======= \nTOTAL                            257.2M      138 \n. ",
    "mts749": "I don't think so. Ran into the same issue \n`2016-03-30 21:58:32.811140 [NOTICE] [../../../src/DHTConnectionImpl.cc:82] IPv4 DHT: listening on UDP port 6881\n2016-03-30 21:58:32.811426 [NOTICE] [../../../src/PeerListenCommand.cc:79] IPv4 BitTorrent: listening on TCP port 6881\n2016-03-30 21:58:32.811478 [NOTICE] [../../../src/PeerListenCommand.cc:79] IPv6 BitTorrent: listening on TCP port 6881\nIllegal instruction: 4`\non OSX 10.11.3\n. ",
    "xros": "\nupdate I found Sample XML-RPC Client Code\nhttps://aria2.github.io/manual/en/html/aria2c.html#sample-xml-rpc-client-code\nI tried this line: \"onDownloadComplete\": \"touch /tmp/done\" but it still does not work.\n. @tatsuhiro-t So here you meat: \nTrial 1\nif I create a file uri.txt\nhttp://downloads.openwrt.org.cn/openwrtcn/cngeoip.tar.gz                                                                                                                                                                                     \n  continue                                                                                                                                                                                                                                   \n  dir=/srv/harvester                                                                                                                                                                                                                         \n  out=test.gz                                                                                                                                                                                                                                \n  on-download-complete=/tmp/do_it.sh\ncat do_it.sh\n```\n!/bin/bash\ntouch /tmp/done\n```\nThe aria2c can start to download, but it did not execute the do_it.sh.\nTrial 2\nI only can execute the command script in this way?\nhttps://aria2.github.io/manual/en/html/aria2c.html?highlight=on-download#event-hook\naria2c --on-download-complete hook.sh http://example.org/file.iso\nI tried the command above, it worked. \nSummery\nOnly trial 2 works in this scenario. \nSo do you mean there is only one way to execute scripts after downloading using Aria2?\n. ",
    "raeesbhatti": "Fix confirmed with both magnet links and torrent files. Much thanks, you're awesome :)\n. ",
    "TheVillageIdiot0": "Oh i would love this. Sorting files by Date Added is a necessity. Can't believe it hasn't been completed yet.\nPlease please throw this simple request in asap. :)\nThanks. ",
    "austin987": "Yes, works here as well, thanks.\n. ",
    "lautis0503": "~~When I place it in \"E:\\Downloads\", it works fine. But when I place it in \"E:\\Tools\\aria2\", it cannot save any file. So does release-1.20.0.~~\n~~I've tried to run aria2c.exe in other directories. Maybe aria2c.exe cannot run in second level directories.~~\n~~Run in \"E:\\Tools\\aria2\" in administrator mode, then it works fine.~~\nAfter many times of trying, it works all fine now. But I still don't know why.\nClose this issue. Thanks!\n. What about creating a hidden file which is an exact copy of torrent file and aria2 will use this copy to download?\n. The file size is correct.\nAnd if I delete the old file and download again, everything goes well.\nI can pause and resume now.\nI've lost the request header and response header as it's dynamically generated.\nBut I've tried severl times and the error only occurred\nwith old file and file.aria2.\nThe only difference I found is that the old .aria2 file is filled with all zero\nI think it's a issue about aria2.\nMaybe in some situation aria2 doesn't work good\nand the operating system overrides the .aria2 file?. ",
    "kokotonix": "Can't wait ...\n:)\n. ",
    "saifsmailbox98": "2016-04-08 20:14:07.426175 [ERROR] [FileAllocationCommand.cc:93] CUID#10 - Exception caught while allocating file space.\nException: [AbstractDiskWriter.cc:515] errNum=95 errorCode=17 fallocate failed. cause: Operation not supported\n2016-04-08 20:14:07.427309 [ERROR] [FileAllocationCommand.cc:97] CUID#10 - Download not complete: /media/SAIF32GB/shares/downloads/files/vlc-2.2.2-win64.exe\n. I was having\nfile-allocation=falloc\nShould I change it to prealloc?\nWhich option would be best in performance, I don't care if it slow?\n. Okay, thank you.\n. Also,whenever I have a power cut. The session is not saved.\n. I tried this but I am getting name resolution failed error on restarting the device.\nHere is the file that is used to save the session and input:\ninput.txt:\nhttp://www.sample-videos.com/video/mp4/720/big_buck_bunny_720p_10mb.mp4 \n gid=c3b564c55aff5e44\nHere is the log:\n2016-04-09 00:17:07.752397 [ERROR] [AbstractCommand.cc:350] CUID#9 - Download aborted. URI=http://www.sample-videos.com/video/mp4/720/big_buck_bunny_720p_10mb.mp4\nException: [AbstractCommand.cc:350] errorCode=19 URI=http://www.sample-videos.com/video/mp4/720/big_buck_bunny_720p_10mb.mp4\n  -> [AbstractCommand.cc:811] errorCode=19 CUID#9 - Name resolution for www.sample-videos.com failed:No address returned\n. ",
    "Dingo64": "Hello,\nDoes it suppoert socks 4/5 now?. I regenerated by list.txt with only 500 000 links. Now aria2 started and uses almost 6 GB of RAM. \nSo I think it needs about 24 GB of RAM for 2 000 000 links.. Thank you, it helped. \nOne thing was quite bothering. It started with 8 MB and was eating 1 MB more every 7 seconds. But it stopped at 18 MB so it's great. About 1 million links loaded.. Not really a good solution. But thanks anyway. . Thanks. I'll try to run more instances of aria2.. ",
    "elfring": "Thanks for your small source code improvement.\n. ",
    "abcfy2": "Same issue here. Did you find the reason?. ",
    "Biggulu": "if i use --without-gnutls --with-opensslconfigure script\n\nCXXLD    aria2c\n/usr/lib/x86_64-linux-gnu/libsqlite3.a(sqlite3.o): In function unixDlOpen':\n(.text+0x8839): warning: Using 'dlopen' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n./.libs/libaria2.a(util.o): In functionaria2::util::getHomeDir()':\n/home/study/github/aria2/src/util.cc:1358: warning: Using 'getpwuid' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n./.libs/libaria2.a(SocketCore.o): In function aria2::callGetaddrinfo(addrinfo**, char const*, char const*, int, int, int, int)':\n/home/study/github/aria2/src/SocketCore.cc:1446: warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libxml2.a(nanohttp.o): In functionxmlNanoHTTPConnectHost':\n(.text+0x8a4): warning: Using 'gethostbyname' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libxml2.a(xzlib.o): In function xz_decomp':\n(.text+0x5dc): undefined reference tolzma_code'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libxml2.a(xzlib.o): In function xz_make':\n(.text+0x9f5): undefined reference tolzma_properties_decode'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libxml2.a(xzlib.o): In function xz_make':\n(.text+0xc29): undefined reference tolzma_auto_decoder'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libxml2.a(xzlib.o): In function __libxml2_xzclose':\n(.text+0x16c5): undefined reference tolzma_end'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-misc.o): In function _gcry_fatal_error':\n(.text+0x22a): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-misc.o): In function _gcry_divide_by_zero':\n(.text+0x8da): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-misc.o): In function _gcry_divide_by_zero':\n(.text+0x8e6): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function do_malloc.constprop.4':\n(.text+0x1f2): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_err_make_from_errno':\n(.text+0xd46): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_error_from_errno':\n(.text+0xd75): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_realloc':\n(.text+0xfb9): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_calloc':\n(.text+0x1068): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_calloc_secure':\n(.text+0x10d8): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xmalloc':\n(.text+0x11b7): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xrealloc':\n(.text+0x1232): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xmalloc_secure':\n(.text+0x12ba): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xcalloc':\n(.text+0x1317): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xcalloc':\n(.text+0x1323): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xcalloc_secure':\n(.text+0x1377): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xcalloc_secure':\n(.text+0x1383): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_xstrdup':\n(.text+0x1403): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function do_malloc.constprop.4':\n(.text+0x1fe): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_strerror':\n(.text+0xd01): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_strsource':\n(.text+0xd11): undefined reference togpg_strsource'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_err_code_from_errno':\n(.text+0xd21): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_err_code_to_errno':\n(.text+0xd31): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function _gcry_free':\n(.text+0xf61): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-sexp.o): In function vsexp_sscan':\n(.text+0x691): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-sexp.o): In function vsexp_sscan':\n(.text+0x1814): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-sexp.o): In function make_space':\n(.text+0x2db): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-stdmem.o): In function _gcry_private_malloc':\n(.text+0xd6): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-stdmem.o): In function _gcry_private_malloc_secure':\n(.text+0x156): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-secmem.o): In function _gcry_secmem_malloc_internal':\n(.text+0x43c): undefined reference togpg_err_set_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function _gcry_fips_run_selftests':\n(.text+0x569): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function _gcry_fips_run_selftests':\n(.text+0x5db): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function _gcry_fips_run_selftests':\n(.text+0x647): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function _gcry_fips_run_selftests':\n(.text+0x6db): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function _gcry_fips_run_selftests':\n(.text+0x6fe): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(cipher.o): In function _gcry_cipher_open':\n(.text+0x2196): undefined reference togpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(dsa.o): In function dsa_generate_ext':\n(.text+0x14f3): undefined reference togpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(dsa.o): In function dsa_generate_ext':\n(.text+0x1645): undefined reference togpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(kdf.o): In function pkdf2':\n(.text+0x603): undefined reference togpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function md_enable.isra.3':\n(.text+0x6a6): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function md_open':\n(.text+0x8c5): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function md_open':\n(.text+0x8e8): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function _gcry_md_copy':\n(.text+0x10ab): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function _gcry_md_copy':\n(.text+0x1131): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o):(.text+0x1148): more undefined references to gpg_err_code_from_errno' follow\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function_gcry_md_hash_buffer':\n(.text+0x13c5): undefined reference to gpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function_gcry_md_setkey':\n(.text+0x1534): undefined reference to gpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In functionprime_generate_internal':\n(.text+0x169b): undefined reference to gpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In functionprime_generate_internal':\n(.text+0x16b3): undefined reference to gpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In functionprime_generate_internal':\n(.text+0x1701): undefined reference to gpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In functionprime_generate_internal':\n(.text+0x1cd8): undefined reference to gpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function_gcry_generate_fips186_2_prime':\n(.text+0x2a11): undefined reference to gpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function_gcry_generate_fips186_3_prime':\n(.text+0x327e): undefined reference to gpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o): In functionsexp_to_key':\n(.text+0xb39): undefined reference to gpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o): In functionoctet_string_from_mpi.part.2':\n(.text+0xf59): undefined reference to gpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o): In functionpss_verify_cmp':\n(.text+0x1109): undefined reference to gpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o):(.text+0x1ed3): more undefined references togpg_err_code_from_syserror' follow\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-module.o): In function _gcry_module_add':\n(.text+0xf4): undefined reference togpg_err_code_from_errno'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function scanval':\n(.text+0xa9c): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function ec2os':\n(.text+0x1064): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function ec2os':\n(.text+0x107c): undefined reference togpg_strerror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function compute_keygrip':\n(.text+0x17c1): undefined reference togpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function ecc_generate_ext':\n(.text+0x2274): undefined reference togpg_err_code_from_syserror'\n/usr/bin/../lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(random-fips.o): In function _gcry_rngfips_init_external_test':\n(.text+0x1180): undefined reference togpg_err_code_from_syserror'\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nmake[3]: * [aria2c] \u9519\u8bef 1\nmake[3]:\u6b63\u5728\u79bb\u5f00\u76ee\u5f55 /home/study/github/aria2/src'\nmake[2]: *** [all-recursive] \u9519\u8bef 1\nmake[2]:\u6b63\u5728\u79bb\u5f00\u76ee\u5f55/home/study/github/aria2/src'\nmake[1]: * [all-recursive] \u9519\u8bef 1\nmake[1]:\u6b63\u5728\u79bb\u5f00\u76ee\u5f55 `/home/study/github/aria2'\nmake: *** [all] \u9519\u8bef 2\n\nstudy@study-VirtualBox:~/github/aria2$ dpkg -l | grep gpg\nii  gpgv                                                        1.4.16-1ubuntu2.3                       amd64        GNU privacy guard - signature verification tool\nii  libgpg-error-dev                                            1.12-0.2ubuntu1                         amd64        library for common error values and messages in GnuPG components (development)\nii  libgpg-error0:amd64                                         1.12-0.2ubuntu1                         amd64        library for common error values and messages in GnuPG components\nstudy@study-VirtualBox:~/github/aria2$ dpkg -l | grep lzma\nii  liblzma-dev:amd64                                           5.1.1alpha+20120614-2ubuntu2            amd64        XZ-format compression library - development files\nii  liblzma5:amd64                                              5.1.1alpha+20120614-2ubuntu2            amd64        XZ-format compression library\n. OK Thanks to all ! Compile passed\n. ",
    "lexbrugman": "I'm getting a similar error after running configure with --disable-websocket:\n\nmake  all-recursive\nmake[1]: Entering directory /tmp/aria2-1.29.0'\nMaking all in po\nmake[2]: Entering directory/tmp/aria2-1.29.0/po'\nmake[2]: Leaving directory /tmp/aria2-1.29.0/po'\nMaking all in lib\nmake[2]: Entering directory/tmp/aria2-1.29.0/lib'\nmake[2]: Nothing to be done for all'.\nmake[2]: Leaving directory/tmp/aria2-1.29.0/lib'\nMaking all in deps\nmake[2]: Entering directory /tmp/aria2-1.29.0/deps'\nMaking all in wslay\nmake[3]: Entering directory/tmp/aria2-1.29.0/deps/wslay'\nmake[3]:  No rule to make target all'.  Stop.\nmake[3]: Leaving directory/tmp/aria2-1.29.0/deps/wslay'\nmake[2]:  [all-recursive] Error 1\nmake[2]: Leaving directory /tmp/aria2-1.29.0/deps'\nmake[1]: *** [all-recursive] Error 1\nmake[1]: Leaving directory/tmp/aria2-1.29.0'\nmake: *** [all] Error 2\n\nAll is good without --disable-websocket. ",
    "AladW": "Well, I don't have a suggestion to fit both cases. Thanks for considering.\n. As with #639, you could keep the existing behaviour by making the new one optional, e.g via --stderr. \n. Works for me, thanks. Though it seems the option is not included in aria2c --help.\nedit: works with aria2c '-h#advanced'\n. Well, adding a switch to disable the download results wouldn't break backwards compability.\n. That sounds good to me.\n. Works, thank you!\n. ",
    "stangri": "Thanks! I've checked out the code, merged it locally with the dynamic-select-file and ran both configure and make. Do I need to update any of my settings? Or just daemonize this new binary? \n. Tatsuhiro, I can't get it to work with YAAW. :(\n1. How can I confirm if the resulting binary supports this new feature? \n2. Have you tested it by manually creating RPC calls or thru some web front-end?\n. Now that the 1.2.3 is out, could you please instruct me how can I build the most up-to-date version with this patch applied?\n. Cloned and compiled master, still can't get this to work with YAAW. :(\n. I am using an init script below. If there's a better one I should use, please advise.\n```sh\ncat /etc/init.d/aria2\n!/bin/sh\nBEGIN INIT INFO\nProvides: aria2cRPC\nRequired-Start: $network $local_fs $remote_fs\nRequired-Stop: $network $local_fs $remote_fs\nShould-Start: $network\nShould-Stop: $network\nDefault-Start: 2 3 4 5\nDefault-Stop: 0 1 6\nShort-Description: aria2c RPC init script.\nDescription: Starts and stops aria2 RPC services.\nEND INIT INFO\nUSER=\"*\"\nDAEMON=/usr/bin/aria2c\nCONF=/etc/aria2/aria2.conf\nARGS=\"--daemon --conf-path=$CONF\"\nstart() {\nif [ -f $CONF ]; then\nlogger -st ARIA2C \"Starting aria2c daemon...\"\nstart-stop-daemon -S -c $USER -x $DAEMON -- $ARGS\nelse\nlogger -st ARIA2C \"Couldn't start aria2 daemon (no $CONF found)\"\nfi\n}\nstop() {\nlogger -st ARIA2C \"Stoping aria2c daemon...\"\nstart-stop-daemon -o -c $USER -K -u $USER -x $DAEMON\n}\nstatus() {\ndbpid=pgrep -fu $USER $DAEMON\nif [ -z \"$dbpid\" ]; then\nlogger -st ARIA2C \"aria2c daemon not running.\"\nelse\nlogger -st ARIA2C \"aria2c daemon running...\"\nfi\n}\ncase \"$1\" in\nstart)\nstart\nsleep 1\n;;\nstop)\nstop\nsleep 1\n;;\nrestart)\nstop\nsleep 2\nstart\n;;\nstatus)\nstatus\n;;\n*)\necho \"Usage: {start|stop|restart|status}\"\nexit 1\nesac\nexit 0\n```. ",
    "Artoria2e5": "Try -std=c++11 or -std=gnu++11. Custom literal is a C++11 thing, and older compilers may either don't support this feature or don't use this language standard by default (which is the case for g++ 4.7 where user-defined literals has already been implemented).\nFor building with confidence, my suggestion is to explicitly include language standard definitions (C & C++) in the project-default c{,xx}flags (AM_CFLAGS?).\n. ",
    "sas": "Hey Tatsuhiro, thanks for the review.\nI just want to make sure I understand the problem here: are you worried\nabout people using aria2 to DOS servers purposefully? Or rather do you\nthink some clueless users will just specify a higher number of parallel\nconnections hoping to transfer faster but will just end up shooting\nthemselves in the foot and damage performance?\nIf it's the latter, do you think we could still allow higher connection\ncount but display a warning to the user or something like that?\nThanks.\nOn Monday, May 9, 2016, Tatsuhiro Tsujikawa notifications@github.com\nwrote:\n\nThank you for the PR. Unfortunately this would be WONTFIX. We think 16\nlimit is already plenty. 128 is too much, and it could overload the remote\nserver, and having too many tcp connection had detrimental effect.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/aria2/aria2/pull/648#issuecomment-217971648\n\n\nStephane Sezer\n. Ah yeah, I understand now. Faking UA is not great and and warnings are going to be ignored by users, especially if they use a frontend UI.\nDo you think we could do something like add a --unsafe (not sure about the name, feel free to propose something better) flag that would allow going over 16? Arguably it will make it harder for users to do something wrong, especially if they are using a frontend UI that might not expose these settings.\nSorry if I come off as insistent, I'm just trying to see if there's any way we can allow greater connection parallelism as I did see multiple people around me facing the same issues downloading files from crappy ISPs.\nIf you think there's absolutely no way to merge something that would offer a way to go above 16 I'll happily abandon this PR.\nThanks :)\n. ",
    "tuduongquyet": "I've used uTorrent once and got this error too. The reason is maybe @Denisov39  was downloading torrent directly to External HDD\n. ",
    "g0dless": "yes linux by default have 4k for paths\n\n~$ getconf NAME_MAX /data/media\n255\n~$ getconf PATH_MAX /data/media\n4096\n. I found the answer! This is not an issue of aria2c!\n\nFrom here: https://forum.transmissionbt.com/viewtopic.php?p=55918#p55918\n\nLength of filename is 377 bytes (this is length of raw C string). It is encoded in UTF-8. If we transcode it to UTF-16, we will get length of 206 wide characters. It easily fit onto Windows NTFS, as it use UCS-2 encoding and allows 255 wide characters, effectively 510 bytes.\nBut utf-8 presentation requires 377 bytes, so cannot be used as filename in unixes, as they limit name by 255 bytes, and, I repeat, modern OS'es doesn't use national codepages and do write utf-8 filenames to disk structures as-is.\n. \n",
    "mfredrick": "I was testing using a batch script and forgot to escape %20 to %%20.\naria2 is great!\nthank you tatsuhiro-t\n. ",
    "nils-werner": "Oh right, I must have found an older version of the manual then.\n. ",
    "jabardast": "Thanks tatsuhiro-t  for taking time to answer them.\nToo bad none of them can be done.\nLast question, if I have 10 different files in download queue (bittorrent, url etc).\nCan I prioritize them in the queue ?\nMy concurrent download limit is 1.\nIf I add file 1 at 10 AM, it starts downloading it.\nAdd another file at 10:05 , its in waitlist queue.\nAdd another file at 10:15, added to waitlist queue.\nSo can I change the download priority of the files which are in queue. \nApologies in advance, If it's not allowed to add another question.\nI will open a new thread if required.\nKeep up the good work\n. again thanks for your prompt reply. I guess it has to be done via a python script.\nCan this be done via webui or yaaw ? These are the frontend I am using right now.\nI am open to use any other gui , if it has this feature.\n. will do sir. thanks for your time\n. thanks for the tip sir. I will see what I can do.\nMay be it will be easier to upgrade aria2. Right now apt-get on pi only installs 1.15.1 version.\nI appreciate your help. I will come back with the results\n. After a failed attempt to compile latest aria2 , I started looking into routing of pi.\nApparently, my routing table needed few more entries.\nWhile setting up Wifi Router + Access point - I had enabled NAT via\n iptables \u2013t nat \u2013A POSTROUTING \u2013o eth0 -j MASQUERADE\nI needed following entries too\nTell it to forward all traffic to the Internet:\niptables -A FORWARD -i wlan0 -o eth0 -j ACCEPT\nFinally, tell it to forward returning Internet data to the appropriate client:\niptables -A FORWARD -i eth0 -o wlan0 -m state --state RELATED,ESTABLISHED -j ACCEPT\nI also disabled rpc-listen-all=true in my conf file\n Now aria2 is listening on my internal IP address not on External IP.\nThanks for the Author of this website - http://makezine.com/projects/browse-anonymously-with-a-diy-raspberry-pi-vpntor-router/\nThanks to tatsuhiro-t  for the pointer.\n. ",
    "Kenmmm": "sorry\uff01\uff01\uff01\n. ",
    "Aaron20127": "I am sure pkg-config has installed\n. This time, I did not execute the command \u201cautoreconf -i\u201d, just executed \u201c./configure\u201d, This operation was successful. but when I executed the command \u201dmake\u201c, Another problem occurred.I was a novice, please help me\uff1a         \nMaking all in src\nmake[5]: Entering directory /home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/src'\nMaking all in includes\nmake[6]: Entering directory/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/src/includes'\nmake[6]: Nothing to be done for all'.\nmake[6]: Leaving directory/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/src/includes'\nmake[6]: Entering directory /home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/src'\ndepbase=echo A2STR.lo | sed 's|[^/]$|.deps/&|;s|.lo$||';\\\n        /bin/sh ../libtool  --tag=CXX   --mode=compile ccache_cxx -DHAVE_CONFIG_H -I. -I..  -I../lib -I../intl -I./includes -I./includes -DLOCALEDIR=\\\"/usr/share/locale\\\" -DHAVE_CONFIG_H -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include/libxml2 -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I../deps/wslay/lib/includes -I../deps/wslay/lib/includes  -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/include  -std=c++0x   -pipe -Os -pipe -march=armv7-a -mtune=cortex-a9 -fhonour-copts -Wno-error=unused-but-set-variable -msoft-float  -MT A2STR.lo -MD -MP -MF $depbase.Tpo -c -o A2STR.lo A2STR.cc &&\\\n        mv -f $depbase.Tpo $depbase.Plo\nlibtool: compile:  ccache_cxx -DHAVE_CONFIG_H -I. -I.. -I../lib -I../intl -I./includes -I./includes -DLOCALEDIR=\\\"/usr/share/locale\\\" -DHAVE_CONFIG_H -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include/libxml2 -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I../deps/wslay/lib/includes -I../deps/wslay/lib/includes -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/include -std=c++0x -pipe -Os -pipe -march=armv7-a -mtune=cortex-a9 -fhonour-copts -Wno-error=unused-but-set-variable -msoft-float -MT A2STR.lo -MD -MP -MF .deps/A2STR.Tpo -c A2STR.cc  -fPIC -DPIC -o .libs/A2STR.o\ndepbase=echo AbstractAuthResolver.lo | sed 's|[^/]$|.deps/&|;s|.lo$||';\\\n        /bin/sh ../libtool  --tag=CXX   --mode=compile ccache_cxx -DHAVE_CONFIG_H -I. -I..  -I../lib -I../intl -I./includes -I./includes -DLOCALEDIR=\\\"/usr/share/locale\\\" -DHAVE_CONFIG_H -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include/libxml2 -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I../deps/wslay/lib/includes -I../deps/wslay/lib/includes  -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/include  -std=c++0x   -pipe -Os -pipe -march=armv7-a -mtune=cortex-a9 -fhonour-copts -Wno-error=unused-but-set-variable -msoft-float  -MT AbstractAuthResolver.lo -MD -MP -MF $depbase.Tpo -c -o AbstractAuthResolver.lo AbstractAuthResolver.cc &&\\\n        mv -f $depbase.Tpo $depbase.Plo\nlibtool: compile:  ccache_cxx -DHAVE_CONFIG_H -I. -I.. -I../lib -I../intl -I./includes -I./includes -DLOCALEDIR=\\\"/usr/share/locale\\\" -DHAVE_CONFIG_H -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include/libxml2 -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I../deps/wslay/lib/includes -I../deps/wslay/lib/includes -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/usr/include -I/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/staging_dir/toolchain-arm_v7-a_gcc-4.6-linaro_uClibc-0.9.33.2_eabi/include -std=c++0x -pipe -Os -pipe -march=armv7-a -mtune=cortex-a9 -fhonour-copts -Wno-error=unused-but-set-variable -msoft-float -MT AbstractAuthResolver.lo -MD -MP -MF .deps/AbstractAuthResolver.Tpo -c AbstractAuthResolver.cc  -fPIC -DPIC -o .libs/AbstractAuthResolver.o\nIn file included from AbstractAuthResolver.cc:37:0:\na2functional.h:173:38: error: expected type-specifier before string constant\na2functional.h:178:38: error: expected type-specifier before string constant\na2functional.h:183:38: error: expected type-specifier before string constant\na2functional.h:188:38: error: expected type-specifier before string constant\na2functional.h:193:40: error: expected type-specifier before string constant\na2functional.h:198:40: error: expected type-specifier before string constant\na2functional.h:203:45: error: expected type-specifier before string constant\nmake[6]: *** [AbstractAuthResolver.lo] Error 1\nmake[6]: Leaving directory/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/src'\nmake[5]: * [all-recursive] Error 1\nmake[5]: Leaving directory /home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/src'\nmake[4]: *** [all-recursive] Error 1\nmake[4]: Leaving directory/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0'\nmake[3]: * [all] Error 2\nmake[3]: Leaving directory /home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0'\nmake[2]: *** [/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/build_dir/target-arm_v7-a_uClibc-0.9.33.2_eabi/td_aria2-1.0.0/.built] Error 2\nmake[2]: Leaving directory/home/LACZF/Workplace/tenda_wifiv1.0/develop/master/package/td_aria2'\nmake[1]: * [package/td_aria2/compile] Error 2\nmake[1]: Leaving directory `/home/LACZF/Workplace/tenda_wifiv1.0/develop/master'\nmake: * [package/td_aria2/compile] Error 2\n. Thank you\uff0cthe gcc is too old. I installed the gcc 4.9, and compiled successfully.\n.  I use USB  storage device, it storage sizes is 16MB. The file system is FAT32, Here is my device speed which I have tested in windows 7 system.  \nfile size  /  write speed   /   read speed\n16MB    15.31MB/s   29.46MB/s\n8MB        16.79MB/s    29.56MB/s\n4MB        17.03MB/s    29.64MB/s\n2MB        17.63MB/s    29.32MB/s\n1MB        16.39MB/s    29.67MB/s\n512KB   14.22MB/s   29.72MB/s\n256KB   6.35MB/s            29.31MB/s\n128KB   5.35MB/s             29.89MB/s\n64KB    4.23MB/s    27.69MB/s\n32KB    2.52MB/s    24.26MB/s\n16KB    1.49MB/s            19.19MB/s\n8KB          0.74MB/s   10.76MB/s\n4KB          0.41MB/s   6.41MB/s\n2KB          0.21MB/s   3.63MB/s\n1KB          0.11MB/s   1.93MB/s\nI also tested speed in my linux system. I used shell command, like this\n\ntime dd if=/dev/zero of=/mnt/sda1/device bs=1K count=80000;\n80000+0 records in\n80000+0 records out\nreal    0m 3.97s\nuser    0m 0.04s\nsys     0m 0.96s\n\nThe first line is my shell command, the other is the result. You can see the real time value is 3.97s, and I write data size is 80000*1K=78.1MB. So the write speed is about 19.52MB/s. If my test method  is right, I think this write speed is not slow.\n. I also used NTFS files system with my usb device. I found this to be a little nicer, but the freezing problem still exists. When process freezes,  the I/O utilization rate becomes very high, and the state of the process into a D.\n. Another problem bothered me, that is, was soon run out of memory, when the process to download after a certain period of time. Here is the top command result\nMem: 114152K used, 11428K free, 0K shrd, 3560K buff, 65316K cached\nCPU:   3% usr   8% sys   0% nic  53% idle  33% io   0% irq   1% sirq\nLoad average: 1.53 1.14 1.08 1/72 29153\n  PID  PPID USER     STAT   VSZ %VSZ %CPU COMMAND\n25643 15166 root     D     8484   7%   3% /usr/bin/aria2c --conf-path=/etc/plug\n  693     1 root     S     1188   1%   1% /sbin/klogd\n 1236     1 root     S     2780   2%   1% /usr/bin/bcmwlconfd -d\n15204     1 root     S      720   1%   1% luci-bwc 8\n 1387  1385 nobody   S     3876   3%   1% nginx: worker process\n 1116     1 root     S     1168   1%   0% td-watchdogd -dV\n  299     2 root     SW       0   0%   0% [mtdblock2]\n15968 15944 root     R     1204   1%   0% top\n  733     1 root     S     1100   1%   0% /sbin/netifd\n 1377     1 root     S     8180   7%   0% /usr/sbin/collectd\n 1385     1 root     S     2956   2%   0% nginx: master process /usr/sbin/nginx\n 1220     1 root     S     2756   2%   0% /usr/sbin/nmbd -D\n 1218     1 root     S     2672   2%   0% /usr/sbin/smbd -D\n 1123     1 root     S     1688   1%   0% /usr/bin/fcgi-cgi -c 2\n 1302     1 root     S     1296   1%   0% /usr/sbin/bcmnas\n  602     1 root     S     1232   1%   0% {rcS} /bin/sh /etc/init.d/rcS S boot\n  691     1 root     S     1224   1%   0% /sbin/syslogd -l 8 -C32\n14270 14269 root     S     1212   1%   0% -ash\n14387 14386 root     S     1212   1%   0% -ash\n14614 14613 root     S     1208   1%   0% -ash \nYou can see the memory has used 114152KB , But before the process started, memory use only about 66000KB. Free and buffer has quickly running out, only cached is increasing. I wonder if this is a bug or not.\n. I don't kown how to use these option '-k, --min-split-size='  and  '--file-allocation='. Will  these  affect the disk write speed ?\n. I added two BitTorrent task, my 'bt - Max - open - files' option is 1, but this two tasks at the same time in the download, why?\n. Thank you. But my jemalloc compile failed, I will continue to find new method to compile it. \n. ",
    "monotykamary": "I've only compiled this with Cygwin, but I've tried to make sure that I installed these dependencies:\n- Cppunit\n- bison\n- byacc\n- lcrypt\n- libgnutls\n- libssh2\nCygwin doesn't have the c-ares library (libcares) so I wasn't able to install that, but it still worked fine. Try to start from scratch and install those dependencies before ./configure and make.\n. ",
    "c3V6a2Vy": "found one more problem in the later mmap check. \nInstead of returning null, mmap will return the MAP_FAILED flag, which is (void * )-1.\n\nReturn Value\nOn success, mmap() returns a pointer to the mapped area. On error, the value MAP_FAILED (that is, (void *) -1) is returned, and errno is set appropriately. On success, munmap() returns 0, on failure -1, and errno is set (probably to EINVAL).\n. You are right, I want to check if filesize is greater than max of size_t.\n\nYour change looks more standardized. I will make the change.\n. ",
    "SSSSeb": "Thank you very much ! \n. I confirm I managed to download a file between two servers on a local LAN with a rebuild of 3e00be2\n. Thank you !\n. ping on that issue, I am in the process of rebuilding a big set of physical machines to reproduce... just want to let you know this issue is not abandonned.. ",
    "Cyberoliv": "Oh... I had one mistake in one option....\nCorrect conf file, loaded, it works !\nthanks :+1: \n. ",
    "shomid": "I found a solution in following ::\n`http://media.mehrnews.com/d/2015/12/20/3/1945148.jpg\n           dir=/home/multimedia/picture\n           out=111222.jpg\nhttp://media.mehrnews.com/d/2015/12/16/3/1941595.jpg\n    dir=/home/multimedia/picture\n    out=111333.jpg\nhttp://www.shana.ir/shanacontent/media/image/2007/04/48318_orig.jpg\n    dir=/home/multimedia/video\n    out=111444.jpg`\n. ",
    "tcely": "The brew Formula doesn't appear to specify anything in /usr/local/bin.\nhttps://github.com/Homebrew/homebrew-core/blob/master/Formula/aria2.rb\nWe are still dealing with a single symbolic link either way. Adding an entire directory for a single binary is still wasteful.\n. ",
    "rexdf": "Thanks so much.\n. ",
    "mengyyy": "you can try this   pproxy need python3\nexample:\nhttp proxy listen at 127.0.0.1:8800\nremote socks5 proxy is 123.123.123.123:8899 auth is (username password)\npproxy  -i http://127.0.0.1:8800 -r socks://123.123.123.123:8899#username:password. ",
    "samtron1412": "I saw this in the manual:\n\nBut when I ran three commands with different values of <OPT>, it showed me the same download result like this:\n\n. I got it, my bad! Thanks for your replies.\n. ",
    "dtgm": "I agree changing the URI was the right move. I use checksum to verify the binary hasn't changed during install of all programs I maintain so programs that silently update bins will fail.\nThanks for the suggestion, I parameterized the build number to try to anticipate if you decide to leave out \"build#\".\naria2-1.24.0-win-64bit-build1.zip\nwill use version string 1.24.0.1\naria2-1.24.0-win-64bit.zip\nwill use version string 1.24.0\nActually, it's a bit dumber than that; it matches 'd\\d', so letter \"d\" followed by \"digit\".... I guess I should improve the regex in case you change to using a hyphen or require double digits in your build, but I expect that to be unlikely.\nFYI, there have been 3,319 installs of this package since it was first created in 2013 so if you're interested, you may want to update your Readme with a section on how to install binary on various platforms. On windows with chocolatey it would be\nchoco install aria2\nI think that's also the debian package name (we require packages to be same name as those on other package managers like Debian/Arch/etc).\nAlso, I was wrong above. I check subpath latest daily (https://github.com/aria2/aria2/releases/latest) so if you mark a release a prerelease in github, a corresponding chocolatey package won't be built. \n. ",
    "Nullfati": "Yes, I have lots of concurrent downloads because I test aria2 with a lots of downloads. Can you fix this problem in next vesion?\n. Can you do auto select of value?\n. I read that for Windows fd_setsize can be changed and more then 1024 but for Linux hardcore 1024.\nHow compile aria2 for windows?\n. Okey. Thanks.\nHave any idea how to behave aria2 if I shall increase FD_SETSIZE?\n. Okay.\nIn the near future results.\n. I tested aria 2 with FD_SETSIZE 32768, and after 2 days work with 20 torrents all okay. No have any error.\n. Can add this function?\nIts very useful thing.\n. ",
    "rbos": "I did another test with a 1.8 gigabyte download (225*8192kb chunks, 114 files), and it's transferring metadata fine to my peer test and completing the full download.\nI bet it's the number of files in the SAS 9.4 package, maybe it's overwhelming some built-in limit. The exact number of files is 16,486\n. Okay, I did three tests; sas with magnet and torrent file, notepad++ with magnet. Logs attached. I hope it's clear. The SAS torrent-file download works, but the magnet link doesn't get the metadata, and the notepad++ magnet link does work.\nWeird, I can't attach a zip. Well, easy fix.\nhttp://www.sfu.ca/~rbos/aria2clogs.zip\n. Cool. I'll test it when 1.25.0 comes out. :)\n. Are there dev builds anywhere for Windows that I can use to test? I've given a crack at cross-compiling, but I'd have to build a bunch of other libraries for win64 and that's a little more effort than I'd like to go to.\n. Hi,\nI finally got around to cross-compiling the dependency libraries for aria2c and compiling a static Windows executable.\nMetadata transferred without issue with my SAS test torrent. Thanks!\n. ",
    "gatl": "I see. Thank you for the information. I guess that if I add -d / I can get the behaviour I was expecting.\n. ",
    "Stebalien": "Any chance this issue could be renamed? I almost submitted a duplicate.\n\nBasically, I would like to be able to save all metadata (e.g., torrent files) and control files to $XDG_DATA_HOME/aria2/metadata/URL_ENCODED_PATH_TO_FILE.{torrent,aria2} to keep my downloads directory clean.\n. All fixed. Thanks!\n. ",
    "fawkes": "thank you so much for your fast response. I'll get the latest code, build and test it for couple of days and will report the results\n. I've tested it during the past 2 days and it doesn't seem to be happening anymore. Thanks for the fix.\n. ",
    "Nymerea": "According to the readme file : \n'o option is used to change the file name of .torrent file itself, not a file name of a file in .torrent file. For this purpose, use --index-out option instead.'\n. ",
    "unsystemizer": "@Nymerea a variant of this problem is path/directory length (under which the torrent file is saved) and I haven't been able to fix this with either -index-out or -o.. Okay, I'll try. In the console, there's nothing but the usual, it's just that the numbers aren't moving.\nI suspect that aria2c may stop when I accidentally press Enter or some other key (because I think that pressing enter sometimes helped), but I couldn't cause it to stop, I could only \"unpause\" it, and not always. \nNext time I spot this issue I'll try to capture more details.. Ran into this again. Here's how it happens:\n Click with mouse anywhere in Windows console where aria2c is downloading a torrent\n Now download is stopped and (if you look with TCP viewer or tail the aria log), the download is paused - the log stops moving and aria's TCP connections gradually get closed.\n* To unpause, put mouse in the console window and press ENTER. Now the log is being created again and network activity appears\nI think this may be because a while ago I changed some console properties. Just in case someone wants to repro or comes across this, here's what they're like now.\n\nNow I don't think this is an aria2c issue, so you may close this if you agree.\n. I played with the Command Prompt properties and found that Quick Edit Mode can create this problem. \nIf someone needs to have Quick Edit Mode enabled and doesn't want it to interfere with aria2c, they could consider submitting a patch. (I disabled mine as I didn't use it a lot).\nHow to disable Quick Edit Mode from within a program: https://msdn.microsoft.com/en-us/library/windows/desktop/ms686033(v=vs.85).aspx\n. ",
    "Domini": "@tatsuhiro-t shaper is on router. \nSorry, I've accidentally removed that log but here is another one.\nWhole aria2.log is 2.3G big. Is there a way to give it to you without posting it publicly? Or tell me how big extracts before and after freeze you need.\nThis is a log for downloading 10 most popular torrents from one popular tracker (thousands of seeders for each) just for the sake of experiment. \nThis time aria2.conf was aria2.conf.txt\nnetstats.log.txt\nYou may notice that the problem occurs quite often.\nHere are aria2 logs for some timestamps with freezes aria2c log gaps.log.txt\nAnd here is overall gaps in logs aria2c log timestamps.txt\n. Here is the same download with --log-level=debug --no-conf (although only 5 torrents got downloaded this time, then they started seeding and I Ctrl-C'ed).\naria2c log timestamps.txt\n. And one more example, downloading 1 popular torrent (1500+ seeders) containing 9 4GiB files and 25 50KiB files, this time along with vmstat -t -w -a 1 and vmstat -t -w -d 1.\naria2c --no-conf --file-allocation=falloc --log-level=debug --seed-ratio=0.1 --seed-time=0 *.torrent\nnetstats.txt\naria2c log timestamps.txt\nvmstat -t -w -d 1.txt\nvmstat -t -w -a 1.txt\nForgot to mention earlier - aria2c version is 1.19.3 (from official Fedora 23 repos).\n. It's not reproducible on MacBook Pro 15\" late 2015 (Core i7-4870HQ, 16GB RAM, 512GB PCI-E SSD) under OS X El Capitan 10.11.5 with aria2c 1.23.0 from MacPorts wired (no Wi-Fi) to the same router. \nSame torrent as in previous comment - aria2c --no-conf --file-allocation=falloc --log-level=debug --seed-ratio=0.1 --seed-time=0 *.torrent\naria2c log timestamps.txt\n. I've installed aria2c 1.24.0 from http://koji.fedoraproject.org/koji/buildinfo?buildID=775538 - still freezes. \naria2 log timestamps.txt\nHowever debug logs look a little more interesting. \naria2c.log.txt\nCould I/O be bottleneck on a PCI-E SSD? \n. @tatsuhiro-t, I haven't heard such things about BTRFS and it has shown itself to be quite efficient under different heavy I/O loads so far. However it being a rather new FS this might well be its bug, I've already encountered other bugs, why not one more. \nIt's quite hard for me to shrink current partition to create an ext4 one to test on Mac mini itself. But I also have MacBook Air 13\" late 2011 (Core i5-2557M, 4GB RAM, 128GB SATA SSD) where I can install Fedora 24 on ext4 without additional layers (be it LVM or LUKS) and check the same torrent via the same router. Should it suffice to see if the problem is in BTRFS? \n. Yes, but it is also non-Linux. OS X is BSD-based which is different enough in my opinion. MacBook Air with Fedora and ext4 would be better comparison in that it's similar OS (Fedora vs Fedora), similar component base (Mac vs Mac) and only FS differs (BTRFS vs ext4). I'm just not sure it's performant enough to handle 500 Mbps.\nI'll try to check in the evening.\n. @tatsuhiro-t since BTRFS is Copy on Write FS could it be that aria2 actually duplicates each sector every time it writes? Like write info in new sector without clearing the old one and then detach metadata from old sector and attach to the new one. Maybe some specific params necessary to write inplace? \n. @tatsuhiro-t \nI've rebalanced (i. e. something slightly similar to defragmentation) BTRFS on Mac mini and it started working much better. There are only freezes for 1-2 seconds at most. \nI've tried to test both BTRFS and ext4 on MacBook Air with SSD (see above) - on both there were similar 1-2 seconds freezes. \nOn one hand this is a big improvement. However it still works significantly worse than on OS X. \nOn the other hand it seems there are two problems: \n1. inefficiency of BTRFS long used without rebalance;\n2. allegedly inefficiency of either Linux or aria2 on Linux at least on high speeds (500 Mbps) compared to OS X. \nI'm going to investigate further in several weeks period and maybe provide some more meaningful details. Just wanted to say I haven't forgotten about this issue, just a busy work schedule prevented me from dedicating a lot of time it.\nAt least I can use it after I've rebalanced BTRFS. :) Thank you!\n. @tatsuhiro-t\nI've been investigating this problem slowly since then. Recently I've tried to reproduce it on another machine with 4 GB RAM, SATA SSD and HDD with Linux (Fedora 24) and same high speed internet connection (500 Mbps). \nI've tried downloading a big enough torrent with a lot (thousands) of seeders onto ext4, ext4 without journal, zfs, btrfs, tmpfs with and without encryption beneath both on SSD and HDD. The problem is seen on all of them, on some worse than on others. \nCoincidentally I've noticed via vmstat regular freezes start once all of the free memory except last 100M is cached. And this happens for any filesystem. \nBoth SSD and HDD are performant enough to write 500 Mbps sequentially and with disk-cache=128M one would expect most of the writes to be sequential so I'd not expect IO throughput to be the bottleneck. \nAlso grep -F Dirty /proc/meminfo shows that dirty pages are flushed on disk continuously, amount of dirty pages does not grow indefinitely, instead it's almost on the same level all the time. \nWhat grows is grep -F 'Inactive(file)' /proc/meminfo - it reaches almost 90% of available memory and does not fall back. My (layman) assumption is that once it gets filled the contention for free memory becomes unbearable and aria2 actually waits for free memory (?) and not for IO. \nI launch aria2 this way\naria2c --no-conf --disk-cache=128M --file-allocation=falloc --dir=/path/to/ext4/without/journal/mounted/partition torrent.torrent\nHere are logs of vmstat.txt, meminfo.txt, netstats.txt. One can clearly see by timestamps that freezes start when there is no more free memory left. \nI've found a somewhat similar problem discussed long ago https://sourceforge.net/p/aria2/bugs/264/ for OS X, could it be similar for Linux? \nWhy is aria2 spending so much memory when I clearly used disk-cache=128M? Or is it kernel and not aria2? Could aria2 advise kernel that the files it downloads are not to be cached? Or is this a non-issue and I'm missing anything? \nIf you need any more details, feel free to ask. I'm not that good in debugging but I'll try my best to provide them. \nThank you for the help! . This looks to be the case.\nHowever\n1. caching downloaded torrents will likely unnecessarily evict all other things from the cache;\n2. coincidentally the freezes start once there is no free memory left and cached memory starts being reused. \nMy assumption is that reusing memory once you have no more left becomes somewhat more computationally difficult than just reusing it while you have plenty left e. g. as new allocations start being blocked until old are freed, something like using the filesystem more than 90% filled. Totally speculation though, I'm not a kernel developer to know this for sure. \nI understand F_NOCACHE was added in OS X to target this specific issue. I couldn't find direct alternative in Linux, Linux has O_DIRECT which will not use caches at all which seems to be excessive to this issue, fadvise with DONTNEED which will evict the torrents from caches even if they're being used by another application and fadvise with NOREUSE which seems to be what is needed per description but was a no-op in 2010 and is now (looked at current linux-stable repo). \nhttps://www.percona.com/blog/2010/04/02/fadvise-may-be-not-what-you-expect/. ",
    "evilkong": "I have a similar problem in centos7\uff0cIs there a solution yet?. ",
    "demokedes": "You're probably right. But I have problem, because I am not familiar with linux commancd. I use terminal emulator on my tv. When I type rpc, I get rpc not found. Do I have to be in the specific folder?\n. ",
    "denysbutenko": "@demokedes I have the same issue with the app. You can't change the rpc-listen-all option through web-interface on TV. I found the alternative app for torrent on android tv box, called zetaTorrent, it makes possible to use the remote control of torrents on TV.. ",
    "brainstorm": "I used this python wrapper which uses aria2c underneath: \nhttps://github.com/banbanchs/pan-baidu-download\n. Known bug with Baidu: https://github.com/banbanchs/pan-baidu-download/issues/19, closing.\n. ",
    "rogerlee6411": "Got problems , for aria2c . msg displayed \"IPv4 RPC: failed to bind TCP port 6800\" \nanyone can help this one  ?\n\n[root@myxxx .aria2]# killall aria2c\n[root@myxxx .aria2]# aria2c --conf-path=/root/.aria2/aria2.conf -D\n[root@myxxx .aria2]# aria2c\n10/16 09:53:45 [ERROR] IPv4 RPC: failed to bind TCP port 6800\nException: [SocketCore.cc:293] errorCode=1 Failed to bind a socket, cause: Address already in use\n10/16 09:53:45 [ERROR] Exception caught\nException: [DownloadEngineFactory.cc:215] errorCode=1 Failed to setup RPC server.\n. ",
    "rmg": "FWIW, I found aria2 after looking for something wget-like that supports ipfs since ipget is ipfs-only.. ",
    "hepha": "Thank you fix\n. @tatsuhiro-t \nI told him also installed linux -ck default is open ip_multicast ,but make check error\ngrep 'CONFIG_IP_MULTICAST\\|CONFIG_NET_IPIP\\|CONFIG_IP_MROUTE\\|CONFIG_IP_ROUTER' usr/lib/modules/4.6.3-1-ck/build/.config\nCONFIG_IP_MULTICAST=y\nCONFIG_NET_IPIP=m\nCONFIG_IP_MROUTE=y\nCONFIG_IP_MROUTE_MULTIPLE_TABLES=y\nhttp://repo-ck.com/x86_64/ \nlinux-ck-headers-4.6.3-1-x86_64.pkg.tar.xz \nI recompile the IP_MULTICAST  -related settings removed , The same make check error\nzgrep 'CONFIG_IP_MULTICAST\\|CONFIG_NET_IPIP\\|CONFIG_IP_MROUTE\\|CONFIG_IP_ROUTER' /proc/config.gz \nCONFIG_IP_MULTICAST is not set\nCONFIG_NET_IPIP is not set\nI do not know there is no way to make check skipped multicast, Just make or do not check too\nconfig.zip\nfull config  for linux-ck.config and my.config \n. ",
    "aljazzair": "Thank you for your feedback. After installing these packages and re-compiling, there were no more warnings and the installation result is:\n\naria2c -v\naria2 version 1.25.0\nCopyright (C) 2006, 2015 Tatsuhiro Tsujikawa\n(...)\n* Configuration *\nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 libxml2/2.9.3 sqlite3/3.13.0 GnuTLS/3.4.14 nettle GMP/6.1.0 c-ares/1.11.0 libssh2/1.7.0\nCompiler: gcc 6.1.1 20160621 (Red Hat 6.1.1-3)\n  built by   x86_64-pc-linux-gnu\n  on         Jul 15 2016 23:08:26\nSystem: Linux 4.6.3-300.fc24.x86_64 #1 SMP Fri Jun 24 20:52:41 UTC 2016 x86_64\n\nSo SFTP is now enabled .\nThanks again for your kind feedback.\n. ",
    "patinthehat": "http://stackoverflow.com/questions/9738712/connect-to-remote-mysql-server-with-ssl-from-php\nOn Wed, Jul 20, 2016 at 9:31 AM, Tatsuhiro Tsujikawa \nnotifications@github.com wrote:\n\nMerged #712 https://github.com/aria2/aria2/pull/712.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/pull/712#event-728975041, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/AFQOY2s4RZ0GjWpmagAqKKwGaWxQTlfiks5qXiMygaJpZM4JQY7E\n.\n. \n",
    "devgianlu": "Yes! It's exactly want I meant.\n. Seems interesting, but I can't use this from RPC. Right?\n. Well, I'm using this library on Android: https://github.com/TakahikoKawasaki/nv-websocket-client. The library says \"A WebSocket frame whose FIN bit is true, opcode is 0x9 and payload is null.\" \n. No, I'm using \nws.sendPing();\n. @tatsuhiro-t I've updated the original question clarifying some things.\n. Those are the handshake headers:\nGET /jsonrpc HTTP/1.1\nHost: 192.168.1.50:2789\nConnection: Upgrade\nUpgrade: websocket\nSec-WebSocket-Version: 13\nSec-WebSocket-Key: cjBVPYYinUCbqaz5sAM2CA==\nI should also note that I'm correctly receiving the PONG frame, but the error message is sent too.\n. Can you tell me how you sent those bytes so I can test on my own and investigate further \n. Use pkill to kill all the aria2c instances and then start it again.. I'm using this one: https://github.com/aria2/aria2/releases/download/release-1.32.0/aria2-1.32.0-android-build1.zip. Not sure what it's built for.. Got it. I'll compile my own for x86. . I'm not using JSONP. Could you explain how should I send POST  requests? It's not mentioned in the docs. . I tried sending some requests with POST but the server always responded with 500 (parse error). I am trying to send data putting the URL parameters in the body of the request, but putting them in the URL doesn't work either. Do I have to send JSON?. I solved this issue by sending POST requests, which contain the JSON request in their body.. Different websites use different authentication mechanisms. You can try to start the download from the browser and see if there is any header called Authorization, then add it to aria2 and start the download immediately.. When you start a torrent download with a magnet aria2 downloads the metadata first and then creates a new download with the real torrent. Maybe you're looking at the wrong download. Try retrieving all of them with aria2.tellActive . The URL should be http://www.baidu.com. Use a client, there are plenty of web and Android clients. I would suggest https://ziahamza.github.io/webui-aria2/ and https://play.google.com/store/apps/details?id=com.gianlu.aria2app. Maybe this will help, never used it before but looks promising.\nhttps://aria2.github.io/manual/en/html/libaria2.html . This must be an issue with the firewall.. ",
    "xjbeta": "Thanks, i hope i can receive a notification when a task add to waiting list or paused list. \nUse tellactive for every second is too much trouble.\n. #### I think you can change the notification json\nbrfore\n{\n  \"jsonrpc\" : \"2.0\",\n  \"method\" : \"aria2.onDownloadStart\",\n  \"params\" : [\n    {\n      \"gid\" : \"xxxxxx\"\n    }\n  ]\n}\nafter\n{\n  \"jsonrpc\" : \"2.0\",\n  \"method\" : \"aria2.onDownloadStatusChange\",\n  \"params\" : [\n    {\n      \"gid\" : \"xxxxxx\"\n      \"status\": {\"before\": \"active\", \"after\": \"pause\" \n}}\n  // if here is a list for gid is better]\n}\nCan you prvide the date when a task status last changed, or other key you sort the tasklist.\n. https://aria2.github.io/manual/en/html/aria2c.html#json-rpc-over-websocket\ntry to use websocket\n. You can try it in WebSocket Terminal(Chrome app) \nconnect websocket of aria2\n/connect ws://localhost:12345/jsonrpc\nWhen the task finish you can receive the notification.\n. 1. pause \u65e0\u6cd5\u7acb\u5373\u6682\u505cbt \u4efb\u52a1  \u4f7f\u7528forcepause \u5177\u4f53\u53c2\u8003\nhttps://aria2.github.io/manual/en/html/aria2c.html#aria2.forcePause\n2. \u4e0d\u77e5\u9053\n3. bt \u4efb\u52a1\u4e0b\u8f7d\u5b8c\u6210\u540e\u9700\u8981\u624b\u52a8remove \u505c\u6b62\u4e0a\u4f20. ",
    "yueyingjuesha": "Yes,I have tried.and it don't work....Plus usually the size of my file are more than 1GB so I don't think it's the \"min-split-size\" affects my speed.\n. Hi,I have followed your instruction to change the log-level to error ,and then I also disable log record option,the speed comes up a little bit,but still stuck in 19MB/s compared to other download software like Free Download Manager or IDM that can maximuize the download speed\nThe following are two screenshots comparisons between Free Download Manager and Aria2, both are using 10 connections to download the same file from the same server:\nAria2:\n\nFreeDownloadManager:\n\n. ",
    "ardecvz": "Rebased under --file-allocation option and without translations.\nOf course, you could change it further yourself if you'll find more suitable position.\n. ",
    "hboetes": "No, the magnet link includes trackers, the trackers send aria2c hosts which have the bittorrent file. They are the same hosts that have the requested data as well, Unless I'm totally mistaken.\nIn the current set up, the trackers are asked twice for the same hosts.\n. Exactly! Of course it's not a big issue, just nice to have. I'm glad you take my request into consideration.\n. ",
    "9E307": "Can be understood, it is to allow aria2 can delete the downloaded file.\n. ",
    "avdhoot": "For aria2 lot web interface are available but to delete downloaded file we have ssh then delete file. It is must have feature to delete file using RPC. @mayswind\n. ",
    "jiangjiangflies": "@Jimmy-Z\nJimmy-Z \ncommented 2 months ago\nIf that's a remote download box, aren't you supposed to have a way to access downloaded files? like FTP or SMB share? use that.\nI vote against this feature, out of the scope of a download tool.\ntoo cumbersome\uff01\uff01\uff01inconvenient!\n. ",
    "yyz1989": "+2147483647 for this feature.\nIf we have such an API, then we can have a downloaded file deletion checkbox in the task deletion dialog of YAAW or WebUI.\nCannot agree with the narrow perspective of someone upstairs that a download software should only focus on downloading. \n. ",
    "nosmokingbandit": "I'd like to request this feature as well. The api call could be as simple as aria2.remove(\"token:token\", \"0123456789abcdef\", \"true\")\nBeing able to cancel a download through the api without being able to remove leftover half-downloaded files kind of defeats the purpose.\nUntil this is an option I can't fully integrate Aira2 into my application, which is a bummer because I like Aria2 and I'd love to see it gain more popularity.. Because I can't be guaranteed that my application has write access to the\ndownload directory of a torrent client.\nIf I knew more C++ I'd consider diving into the code.\nOn Fri, Sep 1, 2017 at 2:38 PM, Jimmy-Z notifications@github.com wrote:\n\nI suppose a \"delete-files-too\" option when canceling a download makes\nsense.\nIf you want it that much, this is open source software, you can always\nmake pull requests.\nBTW if you are trying to \"integrate aria2 into my application\", I can't\nsee why you can't do that on your end. @nosmokingbandit\nhttps://github.com/nosmokingbandit\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/728#issuecomment-326654682, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AKX1STzY8BL_HacirKJzddKaATiNW39lks5seE8ugaJpZM4JrkWw\n.\n. \n",
    "no1xsyzy": "against this feature.\nit is nonsense to have rm without ls, mv, cp, and other things, and aria2 can be neither better nor safer at file operations than those more professional at file operating, e.g., shells through ssh, owncloud or something like that.\nRemember KISS, it is not a good idea to have a omni-tool without any customization. If there is really a requirement, just make downstream projects.. If you are trying to access to ws:// with https:// page, it's the case (prohibited by most browsers for safety)\n1. Use http:// page (easy and unsafe), or\n2. Register a certificate and configure aria2 to use it to setup the server (difficult and safe)\n3. Register a certificate and configure reverse proxy to use it (tricky and safe, but much easier if you want more than an aria2 rpc server). OK, it is firefox's problem.\nIn about:config, pull up network.websocket.timeout.ping.request and network.websocket.timeout.ping.response. Around 100 will work.. # Caution: NOT satisfying GPLv2 while providing aria2 bundled in the installer. NOT satisfying MIT license while including AriaNg in it as electron app.\nCaution: Source codes are proprietary (NOT FOSS) so there can be malicious codes inside.\nFor more information, check https://github.com/hugetiny/negibox/issues/6, or this gist in case deleted.. @hugetiny after illegal movements comes personal attack? It sounds like downgrading..",
    "dhanjit": "\nBeing able to cancel a download through the api without being able to remove leftover half-downloaded files kind of defeats the purpose\n\nThis is exactly what's required. Every bittorrent client supports this, ranging from utorrent to rtorrent. If I am removing a torrent file for example, I would definitely want the option to remove it's downloaded content. . ",
    "DDoSolitary": "@tatsuhiro-t Hello, may I ask for the reason why you rejected such requests? Is there any technical problems?. ",
    "0xxxD": "But, \"https://pypi.python.org/simple/sphinx-build/ \"   is not found. @nmaier \n. ",
    "Enpheebled": "Thanks for the quick response. Adding 'bt-detach-seed-only=true' to the 'aria2c.conf' file solved the issue.\n. ",
    "sonic84": "Thank you very much!\n-Sonic84\n\nOn Sep 6, 2016, at 7:16 AM, Nils Maier notifications@github.com wrote:\n@sonic84 https://github.com/sonic84 I updated the release dmg and tar as well\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/aria2/aria2/issues/739#issuecomment-244963911, or mute the thread https://github.com/notifications/unsubscribe-auth/ABkso4r-0Qya4h8UdpVPCl7f9y8bos56ks5qnXXOgaJpZM4J1Xub.\n. \n",
    "qwerty369": "On 1.19 i can download from that site with --peer-id-prefix=-TR2820- with new version it just stuck after file allocation.\n. You're right compile new version on os x it run fine with same config file turn out firejail sandboxing is the culprit when async-dns=true, i'm sorry for bothering you.\n. ",
    "shawnkhall": "Thank you. allow-overwrite with conditional-get does allow clobber when the file at the URL is newer:\naria2c http://www.skype.com/go/getskype-msi --allow-overwrite=true --conditional-get=true\nBut it still doesn't output the local filename that was used. Is there a way to get the log or output table to display this somehow?\n\n. ",
    "azhar0100": "But it is possible to implement right?\nI mean, you do have a --select-file option, and you do have the option to\ncontrol number of files.\nWhy not also add another option which works like -Z but works for\ntorrents?\nI could script around it, but that will obviously be a hack.\nOn Sep 15, 2016 6:55 PM, \"Tatsuhiro Tsujikawa\" notifications@github.com\nwrote:\n\nCurrently, there is no such feature in aria2.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/743#issuecomment-247334790, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AKu96FlY3By96169Jy0ceLL45LmodG01ks5qqU5HgaJpZM4J9kvc\n.\n. I want to clarify,\nI don't want to download each file sequentially, i.e byte after byte, I want to download a number of files such that aria2c only downloads a single file at a time, in the default order, or the one specified by --select-file\n. \n",
    "swgrhck": "+1. ",
    "linglung": "Really useful and i think this is an important feature for the future. \n. ",
    "0xABD": "If using the older SetThreadExecutionState() API, the skeleton code might look like:\n```\nifdef _WIN32\nnamespace {\n// Call once on startup\nvoid win32PreventSleep(void)\n{\n  SetThreadExecutionState(ES_CONTINUOUS | ES_SYSTEM_REQUIRED | ES_AWAYMODE_REQUIRED);\n}\n// Call once on shutdown (or ignore and let the OS clear the flag on process exit/crash\nvoid win32AllowSleep(void)\n{\n  SetThreadExecutionState(ES_CONTINUOUS);\n}\n}\nendif\n```. ",
    "diversenok": "@0xABD, according to MSDN:\n\nES_AWAYMODE_REQUIRED should be used only by media-recording and media-distribution applications that must perform critical background processing on desktop computers while the computer appears to be sleeping.\n\nES_SYSTEM_REQUIRED should be quite enough to prevent a computer from sleeping.. ",
    "louy2": "Is there a way to do that via RPC or do I launch another process?\n. Okay, I see. I can just add URI. Strange that I've met \"download successful\" error in the past. I'll report if I meet them again.\n. ",
    "Efreak": "Just finished compiling aria2c on trusty.\n```\nroot@Win10-vm-2:/home/Efreak/sources/aria2-1.27.1# src/aria2c -v|head -n 1\naria2 version 1.27.1\nroot@Win10-vm-2:/home/Efreak/sources/aria2-1.27.1# src/aria2c http://google.com\n10/10 18:58:10 [NOTICE] Downloading 1 item(s)\n10/10 18:58:10 [ERROR] CUID#7 - Download aborted. URI=http://google.com\nException: [AbstractCommand.cc:350] errorCode=19 URI=http://google.com\n  -> [AbstractCommand.cc:800] errorCode=19 CUID#7 - Name resolution for google.com failed:No address returned\n```\nXenial is still compiling, I'll update this post when it finishes.\nEdit: strace reveals an issue with AF_NETLINK:\nbind(5, {sa_family=AF_NETLINK, pid=0, groups=00000000}, 12) = -1 EINVAL (Invalid argument)\nThis is probably related to Microsoft/BashOnWindows#69, so you can close this if you want.\n. ",
    "truboxl": "Seems like the author's Android recommendation can be applied as a workaround for WSL too...\nFrom README.android:\n\nSince Android does not have /etc/resolv.conf, c-ares (asynchronous DNS resolver) is disabled by default. But name resolution is sometimes a little bit slow, so I recommend to enable c-ares. You can enable it using --async-dns and specify DNS servers using --async-dns-server option, like this:\n--async-dns --async-dns-server=`getprop net.dns1`,`getprop net.dns2`\n\nIn WSL case, instead of missing resolve.conf which is present anyway, just that NETLINK sockets aren't there yet as mentioned in https://github.com/Microsoft/BashOnWindows/issues/69#issuecomment-208574945, so no support for async DNS.\nI guess we have to use the slower --async-dns=false for now.... This has been fixed in Creators Update, you can close this bug now.... ",
    "Francishefeng": "I am so sorry and disappointed to hear. If the developer is unware of why and how, then no one knows. Not compatible?\n. It works well on android 4.4. Maybe you are right there might be some changes to 6.0. But an app should be made compatible with all versions\n. ",
    "indrakaw": "bump. ",
    "jc3213": "@tatsuhiro-t Yes, it seems aria2 won't freeze without encryption. Or at least my aria2.p12 will freeze.\nI've read some other manuals though, they all based on Linux systems. I arranged some code and configurations, and generated some more .p12 files based on them. With the new .p12 files, I can't access Aria2 RPC via Aria2 WebUI or any other download manager.\nI get no idea how could I use encryption with Aria2.\n. ",
    "SoreGums": "Ubuntu 16.10.\naria2c downloaded a few files, then added a bridge adapter and rebooted, now aria2c doesn't download anymore...\n\n[AbstractCommand.cc:791] errorCode=19 CUID#7 - Name resolution for github-cloud.s3.amazonaws.com failed:no address returned or address conversion failed\n\nadding --async-dns=false does help workaround the issue.\nnew alias\nalias a2ch='aria2c --max-connection-per-server=4 --min-split-size=1M --async-dns=false'. ",
    "alexanderadam": "I have the same problem in Ubuntu 17.04. Maybe this could help: Ubuntu 17.04 is using systemd-resolved and addiontally installed dnsmasq.\nThe aria bug happened for me when I tried to installed to install a Ruby version with ruby-build.\ncurl and wget work out of the box and I can confirm that adding --async-dns=false to aria works as well.\nSo in case somebody found this ticket because rbenv / ruby-build uses it, try something like\n$ RUBY_BUILD_ARIA2_OPTS=--async-dns=false rbenv install 2.4.2. @tatsuhiro-t is there anything I could do that could help or add some missing pieces of information?\nI have libc-ares2 version 1.12.0-1ubuntu0.1 installed.\n/etc/resolv.conf isn't any special as it just points to localhost:\n```ruby\nDynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)\nDO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\n127.0.0.53 is the systemd-resolved stub resolver.\nrun \"systemd-resolve --status\" to see details about the actual nameservers.\nnameserver 127.0.0.1\n```\nStrange! I ~~restarted dnsmasq~~ 've done something(?) and it changed to 127.0.0.53.. So you have installed dnsmasq as well?\nBesides from this I have prax.cr installed which adds the following file for dnsmasq (so that .dev domains point to localhost):\n/etc/dnsmasq.d/prax\nlocal=/dev/\naddress=/dev/127.0.0.1\naddress=/dev/::1. ",
    "soulomoon": "I know the reason,  it is using as a tmp configuration for downloading a file or as server, not making any indefinite change\n. ",
    "RicterZ": "New aria2c binary not be installed. Closed.. ",
    "hzpc-joostk": "Have a look at this: https://github.com/timonier/aria2/\nIt installs the latest aria2 version as a Docker image and runs it in a temporary container. It just works, no need to think of dependencies and build on top of a minimal Alpine. \nThe startup overhead (tested with --version is about 0.2 seconds on my system. The size overhead is about 11 MB as compared to a local build.. ",
    "optomux": "Why? Append could work just fine. >> operator. Order should not matter anyways atleast for files containing text. Key feature.. ",
    "shincurry": "Is it possible to download a single video file provided by multiple urls in current version?\nI tried to use aria2 to download mutiple urls from you-get --url, and failed. \ud83d\ude30. ",
    "pasha-zzz": "This works fine too:\necho 'http://v4.ident.me'>url.txt\naria2c -i ./url.txt. Its a router with DD-WRT firmware. Some people checked on PC Linux (Debian) - works too. And I dont know how to debug this case. Even if log-level=debug there are no interesting info.\nMaybe compile config...\n Configuration \nEnabled Features: BitTorrent, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 libxml2/2.9.4 OpenSSL/1.0.2j libssh2/1.7.0\nCompiler: gcc 5.4.0\n  built by   x86_64-pc-linux-gnu\n  targetting arm-openwrt-linux-gnu\n  on         Nov  2 2016 00:21:25. zyxmon user found solution: we must create /dev/stdin and all works ln -s /proc/self/fd/0 /dev/stdin. And I check many utils and all works fine w/o this workaround. Only aria2 affected. Very strange.. ",
    "lengyue524": "@tatsuhiro-t \ncan aria support \"tr.N=\"?\nsome magnet format like this.. ",
    "shangxinbo": "when i download from a magnet it throw an error about DHT.My environment is Windows10 aria2 1.31.0\n```\naria2c \"magnet:?xt=urn:btih:d26914cd44ca55da87f495f49a5df7c1e3c06af5&dn=Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8%5Boscars%5D&tr=http%3A%2F%2Ftracker.trackerfix.com%3A80%2Fannounce&tr=udp%3A%2F%2F9.rarbg.me%3A2710%2Fannounce&tr=udp%3A%2F%2F9.rarbg.to%3A2710%2Fannounce\"\n01/30 17:19:43 [NOTICE] Downloading 1 item(s)\n01/30 17:19:43 [ERROR] Exception caught while loading DHT routing table from C:/Users/shangxinbo/.cache/aria2/dht.dat\nException: [DHTRoutingTableDeserializer.cc:83] errorCode=1 Failed to load DHT routing table from C:/Users/shangxinbo/.cache/aria2/dht.dat\n01/30 17:19:43 [NOTICE] IPv4 DHT: listening on UDP port 6941\n01/30 17:19:44 [NOTICE] IPv4 BitTorrent: listening on TCP port 6991\n01/30 17:19:44 [NOTICE] IPv6 BitTorrent: listening on TCP port 6991\n  Download Progress Summary as of Mon Jan 30 17:20:49 2017 \n======================================================================================================================\n[#0940c3 0B/0B CN:0 SD:0 DL:0B]\nFILE: [MEMORY][METADATA]Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]\n----------------------------------------------------------------------------------------------------------------------\n Download Progress Summary as of Mon Jan 30 17:21:49 2017 \n[#0940c3 0B/0B CN:0 SD:0 DL:0B]\nFILE: [MEMORY][METADATA]Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]\n\n[#0940c3 0B/0B CN:0 SD:0 DL:0B]\n01/30 17:21:49 [ERROR] CUID#17 - Download aborted. URI=http://tracker.trackerfix.com:80/announce?info_hash=%D2i%14%CDD%CAU%DA%87%F4%95%F4%9A%5D%F7%C1%E3%C0j%F5&peer_id=A2-1-31-0-%3D0%E9%C8V%0D%29I%8Bh&uploaded=0&downloaded=0&left=0&compact=1&key=%E9%C8V%0D%29I%8Bh&numwant=50&no_peer_id=1&port=6991&event=started&supportcrypto=1\nException: [AbstractCommand.cc:340] errorCode=2 Timeout.\n  Download Progress Summary as of Mon Jan 30 17:22:49 2017 \n======================================================================================================================\n[#0940c3 84KiB/116KiB(72%) CN:44 SD:11 DL:0B]\nFILE: [MEMORY][METADATA]Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]\n----------------------------------------------------------------------------------------------------------------------\n[#0940c3 116KiB/116KiB(100%) CN:42 SD:11]\n01/30 17:22:51 [NOTICE] Download complete: [MEMORY][METADATA]Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]\n01/30 17:22:51 [NOTICE] Allocating disk space. Use --file-allocation=none to disable it. See --file-allocation option in man page for more details.\n  Download Progress Summary as of Mon Jan 30 17:23:50 2017 \n======================================================================================================================\n[#659283 0B/1.4GiB(0%) CN:0 SD:0 DL:0B]\nFILE: C:/Users/shangxinbo/Downloads/aria2-1.31.0-win-64bit-build1/Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]/Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8.avi (2more)\n----------------------------------------------------------------------------------------------------------------------\n Download Progress Summary as of Mon Jan 30 17:24:50 2017 \n[#659283 0B/1.4GiB(0%) CN:0 SD:0 DL:0B]\nFILE: C:/Users/shangxinbo/Downloads/aria2-1.31.0-win-64bit-build1/Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]/Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8.avi (2more)\n\n[#659283 0B/1.4GiB(0%) CN:0 SD:0 DL:0B]\n01/30 17:25:15 [ERROR] CUID#150 - Download aborted. URI=http://tracker.trackerfix.com:80/announce?info_hash=%D2i%14%CDD%CAU%DA%87%F4%95%F4%9A%5D%F7%C1%E3%C0j%F5&peer_id=A2-1-31-0-%3D0%E9%C8V%0D%29I%8Bh&uploaded=0&downloaded=0&left=1565294519&compact=1&key=%E9%C8V%0D%29I%8Bh&numwant=50&no_peer_id=1&port=6991&event=started&supportcrypto=1\nException: [AbstractCommand.cc:340] errorCode=2 Timeout.\n  Download Progress Summary as of Mon Jan 30 17:25:50 2017 \n======================================================================================================================\n[#659283 0B/1.4GiB(0%) CN:0 SD:0 DL:0B]\nFILE: C:/Users/shangxinbo/Downloads/aria2-1.31.0-win-64bit-build1/Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8[oscars]/Edge.of.Seventeen.2016.DVDScr.XVID.AC3.HQ.Hive-CM8.avi (2more)\n-------------------------------------------------------------------------------------------------------------------\n````\n. oh my god.if I polling to do that, the websocket is usefull to me.it's useless for websocket ,is it?. I guess the websocket can push the info of progress for a download.I wonder what's the advantage for websocket to http? . How I wish I could get the progress to push, so I don't have to polling. In my opinion,push is more elegant than the poll, what do you think?Would you like to add this feature to the new version?. I read the doc.I think download start is a trigger,so I needless a push.So do the stop trigger.And complete status can resolved by progress,Isn't it? So I think the push of events by now is useless.. that is just one of my opinion. The most important in my case is real-time progress info. I mean the progress is important than the start/stop/complete event.. ",
    "naturecurly": "Thank you, I have figured out what mistake I made.. ",
    "iahu": "Thanks @tatsuhiro-t . I really searched how to do the resume job, but could not got a example.\nCould you give a example usage of it for me ?\nThanks again.. ",
    "IamCarbonMan": "I think @HaleTom is looking for a command line option or something similar to resume a download without knowing the original download link, using only the .aria2 file.. ",
    "stefanos82": "@HaleTom That is exactly what I thought .aria2 files were supposed to do. \nUNIX-like systems users are privileged in this case, because the majority of them use bash by default that comes with history and it's pretty easy to re-enter the original command to resume your download.\nWhat about those poor Windows users?\nIndeed it would be more than awesome to have such an option by default as you have suggested.\nWhat it would be nice, would be to have something like a new flag that builds config settings for each download: \nbash\naria2c --build-config <magnet-link>\nAfter you interrupt it and want to resume, all you must do would be something like:\nbash\naria2c --use-config <aria2-file>.aria2\nThis config should reside in the same location where the file is downloaded and as soon as the file gets downloaded successfully to get deleted automatically.\n@tatsuhiro-t Does it sound silly as an idea?\n. @HaleTom no worries.\nMay I ask what operating system are you using? I could suggest an alternative to your issue as a workaround.. Perfect! The workaround is rather simple: just install ClipIt clipboard manager in case you haven't installed it already and use the link(s) from your clipboard manager history to resume any link you want.\nJust make sure you have your link(s) copied to clipit; that's how I roll to be honest with you. It's easier to press Ctrl+C than having to look into my browser history to find that website I downloaded that file.. @HaleTom I have downloaded uget and played a bit with it. It's a pretty straight-forward application and lets you resume your magnet links by default.\nIt comes bundled with clipboard monitoring support and not only that, it logs everything you download or delete.\nThe only way aria2 would not resume your magnet link with uget would be when you delete the folder that contains the downloaded content without deleting your .aria2 file; this way will restart the download from the start.\nIs this your case?. ",
    "alphatr": "Hi @HaleTom , I write a tools to transform .aria2 file to a magnet link http://alphatr.github.io/aria2-reader.html. ",
    "markmark1": "I need to resume aria2c files as well how do I resume from cmd line.       \nThank you for your help! Wow how to use this   \n\nOn Nov 19, 2017 at 1:44 AM,    wrote:\ni write cmd tool to parse the .aria2 file with python. it can extract magnet link from the control file.\n check  https://github.com/smasterfree/aria-control-file-parser  :)\n\u2014\n You are receiving this because you commented.\n Reply to this email directly,  view it on GitHub (https://github.com/aria2/aria2/issues/792#issuecomment-345504191), or   mute the thread (https://github.com/notifications/unsubscribe-auth/AGHom5rdpWx21EQIlZ_Ao9yBuv_Wt1suks5s3_iWgaJpZM4LCWNS).\n\n .\n\nThanks, I'll check it out.   \n\nOn Nov 19, 2017 at 4:08 AM,    wrote:\ni update readme and add a cmd line warpper.\nhow to run\npython aria2_to_magnet.py -f dahufa.aria2    \noutput\nmagnet:?xt=urn:btih:959E2ECEB954313D3869EFF7924CA7CD8DE739\n\u2014\n You are receiving this because you commented.\n Reply to this email directly,  view it on GitHub (https://github.com/aria2/aria2/issues/792#issuecomment-345511710), or   mute the thread (https://github.com/notifications/unsubscribe-auth/AGHom76ZTc7qjJeOQ4JVQ7cGLiInunmOks5s4BpUgaJpZM4LCWNS).\n\n .\n",
    "smasterfree": "i  write cmd tool to parse the .aria2 file with python. it can extract magnet link from the control file.\ncheck https://github.com/smasterfree/aria-control-file-parser  :). i update readme and add a cmd line warpper.\nhow to run\n```\npython aria2_to_magnet.py -f dahufa.aria2\n```\noutput\nmagnet:?xt=urn:btih:959E2ECEB954313D3869EFF7924CA7CD8DE739\n. @kiinoo\nyes, maybe a broken control file?. ",
    "kiinoo": "Could not find the magnet link from aria2 using your tools @alphatr  @smasterfree , does that mean it is impossible to resueme downloading from .aria2 file?\nsee attachment for example\nS.mp4.aria2.zip\n. no, it is a regular file. but maybe it is not a 'magnet' file so we can extrac the link? (im not familiar with magnet/bittorrent concepts). ",
    "leonghui": "Yes, was using --dht-entry-point option. Will retest with v1.30.0. Thanks!. Issued resolved with v1.30.0. Thanks again!. ",
    "tanzeelalam": "Hi,\nFollowing is our scenario,\nEnvironment\nWe have a transmission server and a tracker (running on the server)\nWe have a client machine, thats running aria2c.exe \nScenario 1\ncommand line\n                aria2c.exe DesignPatterns.torrent --log=First.log\n            result : File (DesignPatterns.pdf) gets downloaded\n\nScenario 2\nwe delete the downloaded file from the location and run the same command line (as shown below)\ncommand line\n              aria2c.exe DesignPatterns.torrent --log=Second.log\n         result : No download happens\n\nAttached are the log files, Request you to have a look and guide us.\nAria Logs.zip\n. Just to mention, our environment is Windows (both server and client). In our scenario, we only have a server and a single recipient machine. we do not have any other seeder.\nCan you please confirm, if aria2c will redownload the same file (after deletion) from the transmission server, if there is only the transmission server (and no other seeders) to provide the data?\nor Aria depends on seeding logic after the first download of the file?. ",
    "mxvin": "+1 \ud83d\ude1e . ",
    "elsonwx": "in my config file,the default config is input-file=/opt/var/aria2/session.dat,there is no /opt/var/aria2/session.datfile.\nI run \ntouch /opt/var/aria2/session.dat\n to create it.\nAnd it finally works.. ",
    "pawamoy": "Do you have a daemonized instance of aria2c running in the background? Or an instance with RPC enabled running in the foreground? I needed --no-conf=true as well to launch new instances of aria2c. I would say that maybe aria2c sees that there is another instance running in daemon/rpc mode and thus returns 0 and does nothing.. Then the --dir option to specify the output directory?. So, if you know the output directory (and by default it's the current one I guess), the file name is simply the \"basename\" of the URL no?\nhttp://example.com/path/to/some-long-filename.iso -> /output/directory/some-long-filename.iso.\nIn Bash, you could then use something like\nbash\nfunction dl-and-stream() {\n  url=\"$1\"\n  aria2c \"$url\" &\n  mpv \"$(basename \"$url\")\"\n  # or mpv /output/directory/\"$(basename \"$url\")\"\n}. Download in a directory that is not used by any other programs, and you will be able to get the downloaded file path by listing the contents of the directory and sorting by time:\nbash\nfunction dl-and-stream() {\n  aria2c \"$1\" &\n  file=\"$(ls -1t | head -n1)\"\n  mpv \"$file\"\n}\nHacky but it should work.. I guess you need to set this option to \"true\":\n--force-save[=true|false]\n    Save download with --save-session option even if the download is completed or removed.\n    This option also saves control file in that situations. This may be useful to save\n    BitTorrent seeding which is  recognized  as  completed state.  Default: false\nAnd when restarting, pass the saved session file as the --input-file.. ",
    "sfcapital": "In my case, since I ran it with root first, the /var/log/aria2.log file is created by root.\nWhen I try to use my user to start aria2, aria2 can not start correctly since it cannot access the aria2.log created by root.\nAfter chown aria2.log to my user, it finally started correctly.. ",
    "qwe14789cn": "@tatsuhiro-t I use yaaw to manage aria2. for example, I set \"dir=E:\\Downloads\" in aria2.conf.\nmaybe we can add a command like   \"aria2c -showspace\", and it will return the E disk's capacity like \"301G/500G\" to know the remote download server's space.\nSo, we can edit the yaaw or webui-aria2 to show it on the manage page, to make sure that we have enough remaining capacity to download some new resources such as HD films, videos or something else.\n. @tatsuhiro-t Thanks for your work, I think the former is better.\nfor example:\ncommand:  aria2c http://example/image.iso\nand it will return default capacity set in aria2.conf \nor\ncommand: aria2c http://example/image.iso -d e:/abc\nand it will return the capacity of E.\nI agree your idea by sending specific path to aria2, this function is used for aria2 without download task.\n. ",
    "ThePolarCat": "v. 1.29.0. ",
    "canarem33": "For your information,\nI found my mistake, MIME::Base64 module shall not be used to encode torrent file. Just reading the file and sending it with addTorrent method works:\nopen(FILE, '/opt/aria/aria2-master/src/testtest/config.log.torrent') or die \"$!\";\nmy $torrent = <FILE>;\nclose FILE;\nmy $result = $xmlrpc->call('aria2.addTorrent', $torrent)->result;\ncanarem33. ",
    "Rivsen": "You can run xcode-select --install fix this error.. ",
    "pandada8": "please report issues to related repo\naria2 is only a simple downloader and have nothing can do with your\nextension\nOn Tue, 27 Dec 2016 at 12:03 denvisd notifications@github.com wrote:\n\nthe access of setting in baidunetdisk and thunder lixian is closed..\nall the extensions is failed..so, how to fix it....\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/815, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ADJu1t_Isn3PDjueSZWypE15gNY3tTvaks5rMI34gaJpZM4LWA8j\n.\n. \n",
    "kang0024": "tried adjusting max-file-not-found=100, max-tries=100, retry-wait=5, not working. . not sure, how to check whether it has tried 100 times? setting max-file-not-found=0 also doesn't work too, same error message. . Below is the error message:\n01/08 23:51:52 [ERROR] CUID#7 - Download aborted. URI=http://d.pcs.baidu.com/file/7c57a840ddd7cbda21c8998f0f7e3305?fid=2925877581-250528-545373117771008\nException: [AbstractCommand.cc:351] errorCode=22 URI=http://d.pcs.baidu.com/file/7c57a840ddd7cbda21c8998f0f7e3305?fid=2925877581-250528-545373117771008\n  -> [HttpSkipResponseCommand.cc:239] errorCode=22 The response status is not successful. status=400\n01/08 23:51:52 [NOTICE] Download GID#3885f41719f36ef3 not complete:\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n3885f4|ERR |       0B/s|http://d.pcs.baidu.com/file/7c57a840ddd7cbda21c8998f0f7e3305?fid=2925877581-250528-545373117771008\nStatus Legend:\n(ERR):error occurred.. I see, what should I do in this case then? . With your experience, in the case of baidupan what could cause the error in request and how to prevent it? . ",
    "oliutiano": "I meet the same problem when using baiduyun,I set max-file-not-found=0,max-tries=0\uff0cbut failures occurred intermittently with the message aria2 saw the specified number of \"resource not found\" error. See --max-file-not-found option,what should I do?. ",
    "fatdrag0n": "tried another magnet  and seems like torrent file created can't be uploaded to trackers! maybe bad metadata processing!\n./aria2c --bt-metadata-only=true --bt-save-metadata=true 'magnet:?xt=urn:btih:8eed728523a7034df427ada254fa4487997db55d&dn=Frontline.S2016E15.Exodus.1080p.WEB-DL.AAC2.0.H.264-QUEENS&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969&tr=udp%3A%2F%2Fzer0day.ch%3A1337&tr=udp%3A%2F%2Fopen.demonii.com%3A1337&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Fexodus.desync.com%3A6969'\nPassword:\n12/30 16:34:36 [NOTICE] Downloading 1 item(s)\n12/30 16:34:36 [NOTICE] IPv4 DHT: listening on UDP port 6995\n12/30 16:34:36 [NOTICE] IPv4 BitTorrent: listening on TCP port 6997\n12/30 16:34:36 [NOTICE] IPv6 BitTorrent: listening on TCP port 6997\n[#b8bf8a 84KiB/84KiB(100%) CN:14 SD:2]                                                         \n12/30 16:34:40 [NOTICE] Download complete: [MEMORY][METADATA]Frontline.S2016E15.Exodus.1080p.WEB-DL.AAC2.0.H.264-QUEENS\n12/30 16:34:40 [NOTICE] Saved metadata as /usr/local/aria2/bin/8eed728523a7034df427ada254fa4487997db55d.torrent.\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\nb8bf8a|OK  |       0B/s|[MEMORY][METADATA]Frontline.S2016E15.Exodus.1080p.WEB-DL.AAC2.0.H.264-QUEENS\nStatus Legend:\n(OK):download completed.\n. I found another way to convert instead of using aria2. ",
    "viharm": "@tatsuhiro-t , thank you for taking the time to consider this.. ",
    "stephanie80": "I also have that problem.\nBut when I download with a direct IPv6 address it works great.\nftp://speedtest6.tele2.net/100MB.zip doesn't work.\nftp://[2a00:800:1010::1]/100MB.zip  works great. ",
    "xg590": "I encountered the same problem in Ubuntu18.04.1 while I have compiled aria2 in 16.04 successfully before.\nI think it's because the autoreconf complained 'The 'AM_PROG_MKDIR_P' macro is deprecated, and its use is discouraged'. Any advice? . ",
    "manisoftwartist": "Also, what happens when we use this parameter for a small list of image files which are not huge? That is, to download a list of N_IMGS image files with --max-concurrent-downloads 100, how does this option work? Is there an effect when N_IMGS is very small or very large?. ",
    "asmolero": "Invalid. There were permission issues, although the error wasn't specific about them.. ",
    "patchper": "I found some early comments on this issue. #579. Now I understand what happens.. ",
    "HulkTan": "Well actually I asked a friend of mine to write a beginner's setup.exe to help you setup aria2 for the first time. You can get it here:\nhttps://mega.nz/#!r0FmjSKR!j8ASyCL6HilyhJNf_rnMzunN8VjX3XSE4TsJdni9U7U. ",
    "liliass": "root@XiaoQiang:/etc/misstar/applications/aria2/bin# /etc/misstar/applications/ar\nia2/bin/aria2c http://verify.iso.mirrors.ustc.edu.cn/ubuntu-releases/16.04.1/ubu\nntu-16.04.1-desktop-amd64.iso\n01/25 00:52:37 [ERROR] CUID#7 - Download aborted. URI=http://verify.iso.mirrors.ustc.edu.cn/ubuntu-releases/16.04.1/ubuntu-16.04.1-desktop-amd64.iso\nException: [AbstractCommand.cc:345] errorCode=22 URI=http://verify.iso.mirrors.ustc.edu.cn/ubuntu-releases/16.04.1/ubuntu-16.04.1-desktop-amd64.iso\n  -> [HttpSkipResponseCommand.cc:239] errorCode=22 The response status is not successful. status=403\n01/25 00:52:37 [NOTICE] Download GID#0e8b0ec465c1f652 not complete: \nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n0e8b0e|ERR |       0B/s|http://verify.iso.mirrors.ustc.edu.cn/ubuntu-releases/16.04.1/ubuntu-16.04.1-desktop-amd64.iso\nStatus Legend:\n(ERR):error occurred.\n.  Configuration \nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 expat/2.1.0 sqlite3/3.9.2 OpenSSL/1.0.2e c-ares/1.10.0 libssh2/1.5.0\nCompiler: gcc 5.2.0\n  built by   i686-pc-linux-gnu\n  targetting arm-none-linux-uclibcgnueabi\n  on         Apr 17 2016 00:45:14\nSystem: Linux 2.6.36 #1 SMP PREEMPT Thu Jul 7 19:22:17 CST 2016 armv7l\n. issue can be closed. solved by restarting the router. \nThanks. ",
    "sebalos314": "Hello Tatsuhiro,\nthanks for your reply.\non my system, I have:\n```\nls /etc/ssl/certs/\nca-bundle.crt  ca-bundle.trust.crt  make-dummy-cert  Makefile  renew-dummy-cert\n```\nis that necessary/mandatory to actually have a certificate ? \n. thanks, this works with ca-bundle.trust.crt\nHowever, for my understanding, what is the point of option ' --check-certificate=false ' then ?\n. so it is normal that despite specifying check-cerficiate=false, I still have the ERROR message showing ?  I was hoping to not use the certificate at all and optionally use it if considered necessary.. thank you. your explanation was correct. I did compile it myself a very long time ago and I did specify --with-ca-bundle='/etc/ssl/certs/ca-certificates.crt' because this was automatically done on my ubuntu system at that time... I am running the binary compiled on the ubuntu system on redhat, which explains all the problems... I will rebuild without the option now and update my findings.. I confirm that after recompilation and removing the --with-ca-bundle from configure, the ERROR message is not there anymore.. thank you very much. I'll finish my prototype based on my 'basic' idea first. I'll definitely have a look at Metalink.. ~~When I swapped the aria2c seeder binary to an older version, I do not see the problem anymore, so I believe this is a regression. (note, I did not change the aria2c client binary).~~\n~~Unfortunately, I am not sure which git commit I used to build this older version of aria2c I found in my archive~~\n. I repeated the experiment similar to above with version 1.25 and version 1.31 and I see the same behaviour with two possible performance values. One very fast and one with nothing happening for a few minutes and then very fast download starts and finishes.. Thank you for this analysis.\nYou are correct with regards to the clocks, the timezone was not the same on all systems, my apologies. The systems are connected to the same NTP server and synchronized though, so the timings and analysis you did are correct.\nthe aria2 flagset used on the seeder ( which is also the tracker) machine are:\naria2c --enable-dht=false --dir=/opt/cmu/image/cmu_bt_pool --disable-ipv6=true -V -i /opt/cmu/tmp/cmu_bt_URIs --seed-ratio=0.0 --log-level=debug --log=/opt/cmu/log/cmu_aria_seeder.log --bt-external-ip=x.y.z.t --check-certificate=false --bt-max-peers=128 --file-alloc=none --listen-port=6881-6999 --bt-seed-unverified=true --daemon -j33\nso the port parameter specified here is 6881-6999\nOn the other side, the 'clients' node start aria2 without any port specification (I am planning to specify ports there too later).\naria2c --dir=/tmp/cmu_bt_pull-30960 http://x.y.z.t/image/cmu_bt_pool/rpm-50470.tar.torrent -V --seed-time=0.1 --disable-ipv6=true --enable-dht=false --bt-max-peers=128 --file-alloc=none --log-level=info --log=/tmp/cmu_bt_pull-30960/30960.log --daemon\nas you can see, I did not specify --bt-tracker-interval option.\n. I have fixed the timezone setup, double checked NTP and now the clocks are correct on both systems, I have set the debug logs to debug. I am still using the same flag set as described in my previous post...\nthen, I restarted the same experiment multiple times (a dozen time) before the problem happened again.\n11:04:02, the seeder(tracker) machine is running aria2 on port 6902 and the pulling machine is running aria2 on port 6972.\n11:14:15: after ten minutes of waiting since the pulling machine still has zero bytes transfered locally, I stopped the seeder aria2 process and restarted at 11:15:07. Transfer was fast and fine and everything was finished withing a few seconds.\naria_seeder_restart.log.gz\naria_puller_full.log.gz\naria_seeder_initial.log.gz\n. thank you, I am trying this patch now. . After rebuilding at 6289aaf, things are going better, but I still see an approx two minutes stall randomly... Attaching the logs of a session I did:\nstart time is roughly: 11:55:23\nthe file is allocated on the client (the puller) at 11:55:27 (which is great).\nbut the real download starts at 11:57:32 roughly.\nthis does not happen like this all the time... I think the more files shared in the URI file, the more likely this problem to happen.\naria_puller.log.gz\naria_seeder.log.gz\nIf needed I could attach the logs from a 'fast' session too.\n. very sorry for that, apologize... I double checked but still failed to provide the right logs probably.\nI'll try --bt-tracker-interval too.. I did a new experiment with the same binary build of 6289aaf, \nI enabled --bt-tracker-interval=1 on both sides, seeder and puller.\nI very often do the same download in 27 seconds.\nBut, sometimes, it is done in 1min42 seconds instead, and I captured the log of one such 'slow' session.\nsession started at 18:05:14 for the seeder\npuller was started at approximately the same time.\naria_seeder.log.gz\naria_puller.log.gz\n. Thanks for this analysis. I'll try to increase bt-tracker-interval, do you advise any particular value or shall I explore the parameter space ? \nMy understanding is that the tracker functionnality is not proposed by the aria2 project, just checking I have correct understanding. \nI am surprised the tracker is overloaded in a 1:1 scenario, I guess it will not improve when I run the same command with 300 servers.. ",
    "jdarias": "Jimmy-Z please be more specific. ",
    "huangqingchao": "tks \ud83d\udc4d , i try to build aria2 --without-gnutls --with-openssl, it can work. And i try to install gnutls 3.5.8, build aria2 with gnutls, it can also work.\n\u7ffb\u8bd1\u82f1\u6587\u771f\u96be\u3002\u3002\u3002\u3002  :-D\n[root@localhost tmp]# /etc/aria2-1.31.0/bin/aria2c -v\naria2 \u7248\u672c 1.31.0\nCopyright (C) 2006, 2016 Tatsuhiro Tsujikawa\n \u914d\u7f6e \n\u5df2\u5f00\u542f\u7684\u7279\u6027: BitTorrent, HTTPS, Message Digest\n\u54c8\u5e0c\u7b97\u6cd5: sha-1, sha-224, sha-256, sha-384, sha-512, md5\n\u5e93: GnuTLS/3.5.8 nettle GMP/6.1.2\n\u7f16\u8bd1\u5668: gcc 6.3.0\n  built by   x86_64-pc-linux-gnu\n  on         Feb  8 2017 16:18:40\n\u7cfb\u7edf: Linux 2.6.32-042stab116.1 #1 SMP Wed May 4 16:21:02 MSK 2016 x86_64\n[root@localhost tmp]# /etc/aria2-1.31.0/bin/aria2c https://google.com\n02/08 16:24:58 [NOTICE] Downloading 1 item(s)\n02/08 16:24:59 [NOTICE] \u4e0b\u8f7d\u5df2\u5b8c\u6210\uff1a/tmp/index.html\n\u4e0b\u8f7d\u7ed3\u679c\uff1a\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n151688|OK  |    41KiB/s|/tmp/index.html\n\u72b6\u6001\u6807\u8bc6\uff1a\n(OK)\uff1a\u4e0b\u8f7d\u5df2\u5b8c\u6210\u3002. ",
    "chucklvip": "add this extra setting when aria2c start (Perhaps it should be written to the configuration file)\ncheck-certificate=false\n. ",
    "ipmeel": "I am also facing same issue if there is only one seeder and one leecher.\nIf there are more than one seeders in network it is working with a delay of about 30 seconds. Also, the leecher should not initiate at same time.. ",
    "harrylwc": "according https://mail.gna.org/public/cryptodev-linux-devel/2013-08/msg00000.html\nchange /etc/modules.d/50-cryptodev to\ncryptodev cryptodev_verbosity=-1\nto ignored the debug messages. ",
    "ninjachen": "Meet the same problem, I found it locate at /usr/local/Cellar/aria2/1.32.0/bin/aria2c, and have not been linked.. ",
    "kcolford": "Use the -c option to continue existing downloads which will not redownload anything. I have this set to an alias since it's so useful. . Not all sequential downloaders leave a .part file lying around. So the most general thing is to check if the whole file is there and if not, just download chunks to finish the file. It's not perfect though, downloading github releases doesn't work quite right because the \"Content-Disposition\" header sets a particular filename that confuses aria2, but I'm pretty sure there's an issue for that in the works right now...\nMaybe it should be documented better, I suggest submitting a patch for it since it's just documentation and doesn't require much technical skill. . @sumatrapeter ah, that's a good suggestion, I think I'll add it to my alias, hopefully we can leave this issue open as documentation. @nightmachinary because it's simple and convenient, see K.I.S.S.\nIf someone wants to go ahead and improve the docs or an FAQ, then go ahead so we can close this issue. But aria2 is still being largely developed so I don't think anyone is interested at this point. . ",
    "CMCDragonkai": "@kcolford \nThe docs says that option does:\n\nContinue downloading a partially downloaded file. Use this option to resume a download started by a web browser or another program which downloads files sequentially from the beginning. Currently this option is only applicable to HTTP(S)/FTP downloads.\n\nSo it also doesn't download if the file is already \"downloaded\"? (And am I interpreting that to mean that it just checks if the filename exists, and there's no filename.part or something like that) That should be added to the docs!. ",
    "SumatraPeter": "Simply adding --auto-file-renaming=false should be sufficient IMO. If a control file (.aria2) exists then the download will resume, otherwise if no control file exists then since --allow-overwrite is false by default the file will not be re-downloaded.. Do you mean one has to use --dry-run and then check the log for the headers? Would it be possible to have a similar (less cumbersome) feature that returns only the headers?. >  \"0B\" shown in the above output is the download speed (byte per second), not a file size.\nI was taking about the [#fac963 0B/0B CN:1 DL:0B] line. Isn't the second 0B after the '/' supposed to be the file size? Unless I'm missing something, what's the use of --dry-run if it doesn't even display the file size in case of HTTP redirects?\nEdit: Actually, looks like I was slightly mistaken. Even when --dry-run is used with the actual followed URL (in the example above it is this) it still doesn't display the file size. Looks like that is displayed only when the download actually starts. So here's my suggestion: since the server returns something like Content-Length: 1185800 even in case of --dry-run, why not use that to populate the file size field so that one can immediately check the file size without needing to actually start the download (or check the log for HTTP headers, which an average user will know nothing about)? That way we can simply use --dry-run and immediately get to know the file size.\nWhat do you think?. > It would be nice to add NOTICE level log message to show the file size.\nThat would be acceptable. Can you add it as a feature request please? Thank you.. IMO a download utility should display important info. like the actual file URL as part of its normal output instead of burying it away in a huge log. So moving that INFO message to aria2's normal output would be my preferred option.\nIf you don't want to do that for some reason (although I can't think why), then my second suggestion would be this: cURL for example has a verbose option (-v) that prints certain messages to stdout. Would it be possible to have a similar -v option for aria2 that displays only certain important messages from the log (such as actual redirected download URL) as part of the normal output? That would be far better than for example than using --log=- and searching the entire huge log for useful info. such as this.. It's very clearly mentioned in the documentation:\n\n--select-file=\\<INDEX>...\nNote\nIn multi file torrent, the adjacent files specified by this option may also be downloaded. This is by design, not a bug. A single piece may include several files or part of files, and aria2 writes the piece to the appropriate files.. Did you look at the docs first and try setting --download-result or --summary-interval?. Attaching the detailed log might help the dev figure out the problem.\n\nAlso, is only aria2 failing  or other tools too?. > I can post some part of it here if that helps.\nIt might help the dev of aria2 to diagnose the issue. However if other tools are failing too then how do you know the problem is at your end?. I'm not sure whether this program is even being maintained/updated now. :(. ",
    "fcgouveia": "Thanks a lot for that! . ",
    "monktastic": "Yes, thanks! -c didn't do what I wanted but --auto-file-renaming=false seems to.. ",
    "NightMachinary": "@kcolford Why is an open issue a better fit for documentation?. I need this, too.. Can anybody help me on this :(. I don\u2019t want to lose the default name.\nOn Fri, Dec 28, 2018 at 11:14 AM hs notifications@github.com wrote:\n\nwhy not pass option \"--out\" to aria2?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/1255#issuecomment-450309975, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/Aii--rWbkDJpNEwKRZIzrkIi4fck0UWkks5u9cvzgaJpZM4WXqoM\n.\n. I currently use the dir option with a hash of the url, but I much prefer a\nsimple command \u201caria2c \u2014get-output-name.\u201d\n\nOn Mon, Jan 14, 2019 at 6:41 PM Timoth\u00e9e Mazzucotelli \nnotifications@github.com wrote:\n\nThen the --dir option to specify the output directory?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/1255#issuecomment-454038023, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/Aii--pBHtIGSn-3hyizdz2cRhlIR70GTks5vDJ4cgaJpZM4WXqoM\n.\n. No, the filename is not in the url necessarily.\n\nOn Tue, Jan 15, 2019 at 5:00 PM Timoth\u00e9e Mazzucotelli \nnotifications@github.com wrote:\n\nSo, if you know the output directory (and by default it's the current one\nI guess), the file name is simply the \"basename\" of the URL no?\nhttp://example.com/path/to/some-long-filename.iso ->\n/output/directory/some-long-filename.iso.\nIn Bash, you could then use something like\nfunction dl-and-stream() {\n  url=\"$1\"\n  aria2c \"$url\" &\n  mpv \"$(basename \"$url\")}\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/aria2/aria2/issues/1255#issuecomment-454392110, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/Aii--njxGO5vT9DrKizoTGVvE6Hk_SGzks5vDdfkgaJpZM4WXqoM\n.\n. \n",
    "RobberPhex": "@tatsuhiro-t \nThe interface list:\n$ ip link\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: enp0s31f6: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000\n    link/ether c8:5b:76:2f:4d:4a brd ff:ff:ff:ff:ff:ff\n3: wlp3s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000\n    link/ether e4:b3:18:ab:26:60 brd ff:ff:ff:ff:ff:ff\nwith multiple-interface options:\n````\n$ aria2c --console-log-level=debug --multiple-interface=wlp3s0,enp0s31f6 http://bigota.d.miui.com/7.3.9/miui_MI5SPlusGlobal_7.3.9_d703117d50_6.0.zip\n03/21 10:19:10 [INFO] <<--- --- --- ---\n03/21 10:19:10 [INFO]   --- --- --- ---\n03/21 10:19:10 [INFO]   --- --- --- --->>\n03/21 10:19:10 [INFO] aria2 1.25.0\n03/21 10:19:10 [INFO] gcc 6.1.1 20160621 (Red Hat 6.1.1-3)\n  built by   x86_64-redhat-linux-gnu\n  on         Jul 21 2016 23:38:51\n03/21 10:19:10 [INFO] Linux 4.9.13-201.fc25.x86_64 #1 SMP Tue Mar 7 23:47:11 UTC 2017 x86_64\n03/21 10:19:10 [INFO] zlib/1.2.8 libxml2/2.9.3 sqlite3/3.13.0 GnuTLS/3.5.2 nettle GMP/6.1.1 c-ares/1.11.0\n03/21 10:19:10 [INFO] Logging started.\n03/21 10:19:10 [DEBUG] Not setting rlimit NO_FILE: 1024 >= 1024\n03/21 10:19:10 [INFO] Checking configured addresses\n03/21 10:19:10 [INFO] Not considered: 127.0.0.1\n03/21 10:19:10 [INFO] Found configured address: 10.249.9.69\n03/21 10:19:10 [INFO] Found configured address: 10.249.16.191\n03/21 10:19:10 [INFO] Found configured address: 192.168.122.1\n03/21 10:19:10 [INFO] Not considered: ::1\n03/21 10:19:10 [INFO] Not considered: fe80::c887:a49d:94c4:4725%enp0s31f6\n03/21 10:19:10 [INFO] Not considered: fe80::d69c:faf4:2bf6:5504%wlp3s0\n03/21 10:19:10 [INFO] IPv4 configured=1, IPv6 configured=0\n03/21 10:19:10 [DEBUG] Finding interface wlp3s0\n03/21 10:19:10 [DEBUG] Sockets will bind to 10.249.16.191\n03/21 10:19:10 [DEBUG] Sockets will bind to fe80::d69c:faf4:2bf6:5504%wlp3s0\n03/21 10:19:10 [DEBUG] Finding interface enp0s31f6\n03/21 10:19:10 [DEBUG] Sockets will bind to 10.249.9.69\n03/21 10:19:10 [DEBUG] Sockets will bind to fe80::c887:a49d:94c4:4725%enp0s31f6\n03/21 10:19:10 [DEBUG] GnuTLS: <2> Initializing PKCS #11 modules\n03/21 10:19:10 [DEBUG] GnuTLS: <2> p11: Initializing module: p11-kit-trust\n03/21 10:19:10 [DEBUG] GnuTLS: <2> p11: Initializing module: gnome-keyring\n03/21 10:19:10 [DEBUG] GnuTLS: <3> ASSERT: pkcs11.c[compat_load]:673\n03/21 10:19:10 [DEBUG] GnuTLS: <3> p11 attrs: CKA_CLASS (CERT), CKA_CERTIFICATE_TYPE\n03/21 10:19:10 [DEBUG] GnuTLS: <3> p11 attrs: CKA_TRUSTED\n03/21 10:19:10 [DEBUG] GnuTLS: <3> p11 attrs: CKA_CERTIFICATE_CATEGORY=CA\n03/21 10:19:10 [DEBUG] GnuTLS: <3> p11 attrs: CKA_CLASS (CERT), CKA_CERTIFICATE_TYPE\n03/21 10:19:10 [DEBUG] GnuTLS: <3> p11 attrs: CKA_TRUSTED\n03/21 10:19:10 [DEBUG] GnuTLS: <3> p11 attrs: CKA_CERTIFICATE_CATEGORY=CA\n03/21 10:19:10 [DEBUG] GnuTLS: <3> ASSERT: pkcs11.c[find_objs_cb]:2742\n03/21 10:19:10 [DEBUG] GnuTLS: <3> ASSERT: pkcs11.c[gnutls_pkcs11_obj_list_import_url3]:3063\n03/21 10:19:10 [INFO] 172 certificate(s) were imported.\n03/21 10:19:10 [DEBUG] 1 RequestGroup(s) added.\n03/21 10:19:10 [DEBUG] CUID#7 - socket: read:0, write:0, hup:0, err:0\n03/21 10:19:10 [DEBUG] Selected from normCands\n03/21 10:19:10 [DEBUG] FeedbackURISelector selected http://bigota.d.miui.com/7.3.9/miui_MI5SPlusGlobal_7.3.9_d703117d50_6.0.zip\n03/21 10:19:10 [DEBUG] CUID#7 - socket: read:0, write:0, hup:0, err:0\n03/21 10:19:10 [INFO] CUID#7 - Resolving hostname bigota.d.miui.com\n03/21 10:19:10 [DEBUG] Failed to delete socket event:Bad file descriptor\n03/21 10:19:10 [DEBUG] CUID#7 - socket: read:0, write:0, hup:0, err:0\n03/21 10:19:10 [INFO] CUID#7 - Name resolution complete: bigota.d.miui.com -> 112.80.23.6\n03/21 10:19:10 [INFO] CUID#7 - Connecting to 112.80.23.6:80\n03/21 10:19:10 [DEBUG] CUID#7 - socket: read:0, write:0, hup:0, err:0\n[#db4230 0B/0B CN:1 DL:0B]  \n````\n\nI used wireshark, it seems that aria send ip package via enp0s31f6 with wlp3s0's address.. ",
    "hy-l": "I don't think it is a bug. Maybe because your default gateway is not connected via this interface. Try ip route, and make sure the first default gateway uses dev wlp3s0. Also if you want to use --multiple-interface ,you must set tow default gateways https://www.thomas-krenn.com/en/wiki/Two_Default_Gateways_on_One_System, and try to ping from the tow interfaces:\nping -I wlp3s0 8.8.8.8\nping -I enp0s31f6 8.8.8.8\nbut if you want to gain double bandwidth like that, then you are wrong. aria2 won't use the tow ifaces at the same time, I think. In other words, it's \"iface1 || iface2\" not \"iface1 && iface2\".\nhope this helps. :-). ",
    "fornwall": "There are actually two parts of the cleanup here:\n\n\nRemove src/android/android.c which contains a2_set_errno(), which is no longer used after the removal of ftruncate64 syscall wrappers in https://github.com/aria2/aria2/commit/5ca9cb69599e2b92b2cf721f179d9376fbf860e2.\n\n\nRemove -lstdc++ (which is the default) and -lsupc++ (which is not needed nowadays).. \n\n",
    "myfreeer": "You may use multiple aria2c processes to download multiple files. This patch might help.\npatch\ndiff --git a/src/DownloadCommand.cc b/src/DownloadCommand.cc\nindex 91042ef..f777dec 100644\n--- a/src/DownloadCommand.cc\n+++ b/src/DownloadCommand.cc\n@@ -306,7 +306,7 @@ void DownloadCommand::checkLowestDownloadSpeed() const\n           startupIdleTime_) {\n     int nowSpeed = peerStat_->calculateDownloadSpeed();\n     if (nowSpeed <= lowestDownloadSpeedLimit_) {\n-      throw DL_ABORT_EX2(fmt(EX_TOO_SLOW_DOWNLOAD_SPEED, nowSpeed,\n+      throw DL_RETRY_EX2(fmt(EX_TOO_SLOW_DOWNLOAD_SPEED, nowSpeed,\n                              lowestDownloadSpeedLimit_,\n                              getRequest()->getHost().c_str()),\n                          error_code::TOO_SLOW_DOWNLOAD_SPEED);. #747 would help. #747 . try appending --enable-rpc to the command. try adding case 404: after HttpResponse.cc#L76 and re-compile it.. OptionHandlerFactory.cc#L435\n-1, infinite, or probably INT_MAX, but also limited by your cpu's single core performance, relating to #869 . Why not send this patch via a pull request instead?. The default value of min-split-size is 20M instead of auto-generated. If the size of your file is less then min-split-size, aria2 will download it single-threaded.. Also, connections are affected by split, referring to https://github.com/aria2/aria2/issues/465#issuecomment-144376633. Translation: \n\nAny plans to support ed2k ?. Check #126 #577 #580 #648 #729 \n. Have a patch like that:\n```patch\ndiff --git a/src/SocketBuffer.cc b/src/SocketBuffer.cc\nindex 62862ff..1906173 100644\n--- a/src/SocketBuffer.cc\n+++ b/src/SocketBuffer.cc\n@@ -39,6 +39,7 @@\n\n#include \"SocketCore.h\"\n #include \"DlAbortEx.h\"\n+#include \"DlRetryEx.h\"\n #include \"message.h\"\n #include \"fmt.h\"\n #include \"LogFactory.h\"\n@@ -158,7 +159,7 @@ ssize_t SocketBuffer::send()\n     }\n     ssize_t slen = socket_->writeVector(iov, num);\n     if (slen == 0 && !socket_->wantRead() && !socket_->wantWrite()) {\n-      throw DL_ABORT_EX(fmt(EX_SOCKET_SEND, \"Connection closed.\"));\n+      throw DL_RETRY_EX(fmt(EX_SOCKET_SEND, \"Connection closed.\"));\n     }\n     // A2_LOG_NOTICE(fmt(\"num=%zu, amount=%d, bufq.size()=%zu, SEND=%d\",\n     //                   num, amount, bufq_.size(), slen));\n. Cannot build on msys2 after this, any idea?cpp\ncrypto_hash.cc: In function 'std::unique_ptr crypto::hash::create(crypto::hash::Algorithms)':\ncrypto_hash.cc:1059:12: error: 'make_unique' was not declared in this scope\n     return make_unique();\n            ^~~~~~~~~~~\ncrypto_hash.cc:1059:12: note: suggested alternatives:\nIn file included from E:/ProTools/media-ab/msys64/mingw64/include/c++/7.2.0/memory:80:0,\n                 from crypto_hash.h:10,\n                 from crypto_hash.cc:5:\nE:/ProTools/media-ab/msys64/mingw64/include/c++/7.2.0/bits/unique_ptr.h:836:5: note:   'std::make_unique'\n     make_unique(_Args&&...) = delete;\n     ^~~~~~~~~~~\nE:/ProTools/media-ab/msys64/mingw64/include/c++/7.2.0/bits/unique_ptr.h:824:5: note:   'std::make_unique'\n     make_unique(_Args&&... __args)\n     ^~~~~~~~~~~\ncrypto_hash.cc:1059:27: error: expected primary-expression before '>' token\n     return make_unique();\n                           ^\ncrypto_hash.cc:1059:29: error: expected primary-expression before ')' token\n     return make_unique();\n                             ^\ncrypto_hash.cc:1062:28: error: expected primary-expression before '>' token\n     return make_unique();\n                            ^\ncrypto_hash.cc:1062:30: error: expected primary-expression before ')' token\n     return make_unique();\n                              ^\ncrypto_hash.cc:1065:30: error: expected primary-expression before '>' token\n     return make_unique();\n                              ^\ncrypto_hash.cc:1065:32: error: expected primary-expression before ')' token\n     return make_unique();\n                                ^\ncrypto_hash.cc:1068:30: error: expected primary-expression before '>' token\n     return make_unique();\n                              ^\ncrypto_hash.cc:1068:32: error: expected primary-expression before ')' token\n     return make_unique();\n                                ^\ncrypto_hash.cc:1071:30: error: expected primary-expression before '>' token\n     return make_unique();\n                              ^\ncrypto_hash.cc:1071:32: error: expected primary-expression before ')' token\n     return make_unique();\n                                ^\ncrypto_hash.cc:1074:30: error: expected primary-expression before '>' token\n     return make_unique();\n                              ^\ncrypto_hash.cc:1074:32: error: expected primary-expression before ')' token\n     return make_unique();\n. patch master with [this patch](https://github.com/aria2/aria2/commit/b9d74ca88bb8d8c53ccbfc7e95e05f9e2a155455.patch) before compile. Have you stripped that?\n`strip -s aria2c`. https://github.com/aria2/aria2/issues/393#issuecomment-106295939. @Kanjima \nCheck https://github.com/clamsawd/aria2-static-builds/releases\nhttps://github.com/aria2/aria2/issues/393#issuecomment-174195354. Do you mean `--file-allocation=falloc`?. https://github.com/aria2/aria2/blob/master/src/includes/aria2/aria2.h. That's called `static`, build all your deps as static and check https://github.com/aria2/aria2/blob/431fcde29a5361adc916f2bd095c1f337663af19/mingw-config#L78. Apply this patch and rebuild aria2.patch\ndiff --git a/src/HttpSkipResponseCommand.cc b/src/HttpSkipResponseCommand.cc\nindex a722d77..1446678 100644\n--- a/src/HttpSkipResponseCommand.cc\n+++ b/src/HttpSkipResponseCommand.cc\n@@ -222,6 +222,8 @@ bool HttpSkipResponseCommand::processResponse()\n                          error_code::RESOURCE_NOT_FOUND);\n     case 502:\n     case 503:\n+    case 520:\n+    case 521:\n       // Only retry if pretry-wait > 0. Hammering 'busy' server is not\n       // a good idea.\n       if (getOption()->getAsInt(PREF_RETRY_WAIT) > 0) {\n```. ",
    "whtiehack": "see release changes . please close this issue. ",
    "jimsrc": "Ok, now it works if I add a \"-d\" argument. Specifically:\nbash\naria2c -d ~/torrents --bt-metadata-only=true --bt-save-metadata=true --listen-port=6881 \"magnet link url\" ## Works nice. ",
    "majkelos01": "Mine works, and it looks like that:\n```\n[Unit]\n Description=Aria2c download manager\n Requires=network.target\n After=dhcpcd.service\n[Service]\n Type=forking\n User=root\n RemainAfterExit=yes\n ExecStart=/usr/bin/aria2c --conf-path=/root/.aria2/aria2.conf --daemon\n ExecReload=/usr/bin/kill -HUP $MAINPID\n RestartSec=1min\n Restart=on-failure\n[Install]\n WantedBy=multi-user.target\n```\ncheers\n. ",
    "Larx": "I had to add the following line to get it working as non-root user:\nExecStartPre=/sbin/setcap cap_net_admin+ep /usr/bin/aria2c. ",
    "hbendalibraham": "thx, work fine :+1: . ",
    "joyfun": "sorry for bothering    I slove the problem.\nwhen i add task with rpc , add wrong http header. ",
    "zlf179": "My router is based on Openwrt and donot have the etc/ssl/certs/ this kind of folder. So i donot know how to solve it now.... check-certificate=no,  set it in .config file. Then you can download without problem.. ",
    "imgk": "You can try to install packages with names of ca-bundle/ca-certificates. These two are for lede. I think a solution for OpenWRT is similar.. ",
    "pzxbc": "@imgk \nafter run command opkg install ca-certificates, aria2 works for https, thanks. ",
    "KwToPA": "@tatsuhiro-t Thanks for your reply.  I finally uploaded another aria2 compiled from my computer to my vps /usr/bin\nIs there any possible to compile aria2 to  /usr/bin in centos7 directly?\nI'm looking forward to your reply.\nThank you.. ```\nsudo find / -name 'aria2' | xargs sudo rm -rf\nI remove aria2\nThen recompile like before, got new errors\n...\n{standard input}: Assembler messages:\n{standard input}:40849: Warning: end of file not at end of a line; newline inserted\n{standard input}:39192: Error: invalid operands (UND and .gcc_except_table sections) for -'\n{standard input}:39195: Error: invalid operands (*UND* and .gcc_except_table sections) for-'\ng++: internal compiler error: Killed (program cc1plus)\nPlease submit a full bug report,\nwith preprocessed source if appropriate.\nSee http://bugzilla.redhat.com/bugzilla for instructions.\nmake[3]:  [OptionHandlerFactory.lo] Error 1\nmake[3]: Leaving directory /home/account/aria2/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory/home/account/aria2/src'\nmake[1]:  [all-recursive] Error 1\nmake[1]: Leaving directory `/home/account/aria2'\nmake: *** [all] Error 2\n/usr/local/bin/aria2c --version\nbash: /usr/local/bin/aria2c: No such file or directory\nwhich aria2c\n/usr/bin/which: no aria2c in (/sbin:/bin:/usr/sbin:/usr/bin)\nfind / -name aria2c\n/home/account/aria2/doc/bash_completion/aria2c\n/home/account/aria2/osx-package/etc/paths.d/aria2c\nfind / -name aria2\n/home/account/aria2  #that is a directory \n/home/account/aria2/src/includes/aria2\n/home/account/aria2/osx-package/etc/manpaths.d/aria2\n```\n```\nconfigure.ac:798: warning: The 'AM_PROG_MKDIR_P' macro is deprecated, and its use is discouraged.\nconfigure: WARNING: No package 'cppunit' found \nconfigure: WARNING: No package 'sqlite3' found\nconfigure: WARNING: No package 'gnutls' found \nconfigure: WARNING: No package 'libssh2' found\nconfigure: WARNING: No package 'libcares' found\nyum install libcares libssh2 gnutls  sqlite3  cppunit -y\nLoaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: centos.s.uw.edu\n * elrepo: ftp.ne.jp\n * epel: mirrors.cat.pdx.edu\n * extras: centos.s.uw.edu\n * nux-dextop: mirror.li.nux.ro\n * updates: centos.s.uw.edu\nNo package libcares available.\nPackage libssh2-1.4.3-10.el7_2.1.x86_64 already installed and latest version\nPackage gnutls-3.3.24-1.el7.x86_64 already installed and latest version\nNo package sqlite3 available.\nPackage cppunit-1.12.1-11.el7.x86_64 already installed and latest version\nNothing to do\n```. ",
    "minimax4233": "enable-rpc=true\nrpc-allow-origin-all=true\nrpc-listen-all=true\nmax-concurrent-downloads=5\ncontinue=true\nmax-connection-per-server=5\nmin-split-size=10M\nsplit=10\nmax-overall-download-limit=0\nmax-download-limit=0\nmax-overall-upload-limit=256\nmax-upload-limit=0\ndir=D:\\aria2\\Downloads\\\nfile-allocation=prealloc\nThey are my aria2c.conf,I type aria2c --conf-path=aria2.conf in CMD,it return some warn which  following picture has shown.\nhttp://imgur.com/cbpwKY1. ",
    "rampageX": "@minimax4233 Try remove your aria2.conf file BOM header, save as ANSI or UTF-8 format file. . ",
    "ketankr9": "I had tried aria2c -o song.mp3.part1 --header=\"Range: bytes=0-2500000\" \"http://url/song.mp3\" as an alternative but I seems like the process waits even after downloading a part of file. Say Range: bytes=0-2500000 is equivalent to 47% of file, then process will halt at 47% percent luckily but it terminates only after failed attempt to download the remaining file.\nWhat I want is that the process should terminate immediately and successfully after downloading desired part of file(here 47%).. ",
    "devildant": "+1. hello, i see that inside the read me : \nWe use 3 numbers for aria2 version: MAJOR.MINOR.PATCH. We will ship MINOR update on 15th of every month. We may skip a release if we have no changes since the last release.\nhe mac version can not be impacted by the changes of the 1.31,\nmaybe or maybe not :). thx for your reply, and sorry for your problem (family, mac) ,  i hope everything will work out. hello,\ni search an options for set the proxy for all download.\ni aria on portable computer and when i change the network who use proxy, \nI am obliged to kill aria2 and restarted it so that the proxy is supported. i use 0SX 10.11\nand i look the min version with otool -l and it's equals with version 1.30 (which works). hello,\ni don't have a aria2.conf i just extract the tar.bz2 and run.\nfor test i use an VM, But I was able to test directly with an mac (friend) with exactly same version and the result it's same.\ncan you explain how build ?\n. i block : \npip install sphinx-build\nCollecting sphinx-build\n  Could not find a version that satisfies the requirement sphinx-build (from versions: )\nNo matching distribution found for sphinx-build\n. What is strange is that version 1.30 works very well but not the 1.32\nIt seems to have been compiled in the same way. i can finish the build i get error : \nbash: ../../configure: No such file or directory\nmake:  [aria2.x86_64.build] Error 127. i try to run the version 1.32 with osx version 10.10 and same result segmentation fault 11. hello, no i already have the error : \nbash: ../../configure: No such file or directory. hello,\nFAIL: bench-slope\nSKIP: hashtest-256g\n======================================\n1 of 24 tests failed\n(1 test was not run)\nPlease report to http://bugs.gnupg.org\n======================================\nmake[3]:  [check-TESTS] Error 1\nmake[2]:  [check-am] Error 2\nmake[1]:  [check-recursive] Error 1\nmake: *** [libgcrypt.x86_64.build] Error 2\n. arf, and you can reproduce the segmentation fault 11 with version 1.32  ?. Hooo thx a lot, good jobs :)\nFor my personal culture, how did you find the anomaly?\nI tried to put in debug aria2 but apart from the segfault I did not see anything particular.\nSo, your patch will be available for the next version?\nIn any case, thank you for the time spent on the bug. i try this. just perfect good job :)\nthx. hello,\nI install pkg-config but it's same\ni run this commands : \nruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\" < /dev/null 2> /dev/null\nbrew install pkg-config\nautoreconf -fi\nmkdir build-release\ncd build-release\nvirtualenv .\n. bin/activate\npip install sphinx\nln -s ../makerelease-osx.mk Makefile\nexport NON_RELEASE=1\nmake\ni found the problem i get pkg-config 0.29.2\nil try with this file : https://pkg-config.freedesktop.org/releases/pkg-config-0.20.tar.gz. i can't install pkg-config 0.20 how get this version ?. itry to change the version on configurre.ac to 0.29.2 but i take same error : \nchecking for sphinx-build... /Users/devildant/Desktop/aria2/aria2/build-release/bin/sphinx-build\nchecking for rst2html.py... /Users/devildant/Desktop/aria2/aria2/build-release/bin/rst2html.py\n../../configure: line 18064: syntax error near unexpected token `0.29.2'\n../../configure: line 18064: `PKG_PROG_PKG_CONFIG(0.29.2)'\nmake: *** [aria2.x86_64.build] Error 2\npkg-config is install i don't understand. hello,\nthx for your reply, and thx for the build osx.\nresult of the commande : autoreconf -fiv\n(build-release) devildants-Mac:aria2 devildant$ autoreconf -fiv\nautoreconf: Entering directory `.'\nautoreconf: running: /opt/local/bin/autopoint --force\nautoreconf: running: /opt/local/bin/aclocal --force -I m4 --install\nautoreconf: configure.ac: tracing\nautoreconf: configure.ac: adding subdirectory deps/wslay to autoreconf\nautoreconf: Entering directory `deps/wslay'\nautoreconf: configure.ac: not using Gettext\nautoreconf: running: /opt/local/bin/aclocal --force -I m4\nautoreconf: running: /opt/local/bin/glibtoolize --copy --force\nglibtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, '.'.\nglibtoolize: copying file './ltmain.sh'\nglibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.\nglibtoolize: copying file 'm4/libtool.m4'\nglibtoolize: copying file 'm4/ltoptions.m4'\nglibtoolize: copying file 'm4/ltsugar.m4'\nglibtoolize: copying file 'm4/ltversion.m4'\nglibtoolize: copying file 'm4/lt~obsolete.m4'\nautoreconf: running: /opt/local/bin/autoconf --force\nautoreconf: running: /opt/local/bin/autoheader --force\nautoreconf: running: /opt/local/bin/automake --add-missing --copy --force-missing\nconfigure.ac:26: installing './compile'\nconfigure.ac:40: installing './missing'\nlib/Makefile.am: installing './depcomp'\nautoreconf: Leaving directory `deps/wslay'\nglibtoolize: putting auxiliary files in '.'.\nglibtoolize: copying file './ltmain.sh'\nglibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.\nglibtoolize: copying file 'm4/libtool.m4'\nglibtoolize: copying file 'm4/ltoptions.m4'\nglibtoolize: copying file 'm4/ltsugar.m4'\nglibtoolize: copying file 'm4/ltversion.m4'\nglibtoolize: copying file 'm4/lt~obsolete.m4'\nconfigure.ac:731: warning: The 'AM_PROG_MKDIR_P' macro is deprecated, and its use is discouraged.\nconfigure.ac:731: You should use the Autoconf-provided 'AC_PROG_MKDIR_P' macro instead,\nconfigure.ac:731: and use '$(MKDIR_P)' instead of '$(mkdir_p)'in your Makefile.am files.\nconfigure.ac:13: installing './compile'\nconfigure.ac:10: installing './missing'\nsrc/Makefile.am: installing './depcomp'\nautoreconf: Leaving directory `.'. \nI must miss something, but I can not find what. ",
    "hreichert": "This would be cool!. ",
    "WuErMaO": "\u4e3a\u4ec0\u4e48\u6211\u95ea\u9000\u5462 . ",
    "lizongzeshunshun": "@WuErMaO Please use cmd to run it.. ",
    "guanjianli": "@tatsuhiro-t  He say that why i can not work in windows 10.. ",
    "smdhz": "Windows server 2016 runs it perfectly.. chmod +w /etc/aria2/aria2.log. ",
    "424778940z": "The OP is asking can win10 run aria2.\nSeems he don't know aria2 is a cmdline program, and there is no gui popup so he is confused.\nThere is no issue here, close please.\nFor the OP:\nAria2\u662f\u4e00\u4e2a\u547d\u4ee4\u884c\u7a0b\u5e8f, \u5e76\u4e0d\u63d0\u4f9b\u56fe\u5f62\u754c\u9762, \u4f60\u70b9\u5f00\u770b\u5230\u4e00\u4e2a\u9ed1\u8272\u7a97\u53e3\u4e00\u95ea\u800c\u8fc7\u662f\u6b63\u5e38\u7684. \u8be6\u7ec6\u4f7f\u7528\u65b9\u6cd5\u8bf7\u641c\u7d22\u4e00\u4e9b\u4e2d\u6587\u8d44\u6599\u5b66\u4e60.. ",
    "tsekityam": "I found that my PR includes trimming on all white space at the end of lines, so the changes in doc/manual-src/pt/aria2c.rst is huge. Shall I close the pull request and create a new one without these trimming??. ",
    "BrutalSimplicity": "Aria2 saves the status of each download in memory, which is likely why you are having this issue. You may want to try using the --deferred-input option.\n\n--deferred-input[=true|false]\nIf true is given, aria2 does not read all URIs and options from file specified by --input-file option at startup, but it reads one by one when it needs later. This may reduce memory usage if input file contains a lot of URIs to download. If false is given, aria2 reads all URIs and options at startup. Default: false. Awesome, thanks for the help.. It sounds like you've solved your problem. Is this a question?\n\nI would say do exactly that, if you restart during the middle of a download, just check for torrents with a .aria2 file (incomplete download), and then re-add the saved torrent metadata.. I'm guessing because the metadata for the torrent is not included in the .aria2 file. DISREGARD It actually is included in the .aria2 file based on this https://aria2.github.io/manual/en/html/technical-notes.html#control-file-aria2-format. The infohash property should allow a torrent download to be resumed methinks.\n@tatsuhiro-t This could be a useful feature. Unless, we're missing something and it's actually already implemented somewhere.. ",
    "robati": "I have the same problem here. the exception is:\nException: [AbstractCommand.cc:403] errorCode=1 URI=https://api.ariogames.ir/fileuploader/static/games/6ccc823983efb49fb3343caec0fddcb6/be9efef6d1c7139969280e77f932a110/compressed/Faceless/Faceless_Data/sharedassets1.resource.7z\n  -> [RequestGroup.cc:760] errorCode=1 Download aborted.\n  -> [DefaultBtProgressInfoFile.cc:300] errorCode=1 total length mismatch. expected: 20797413, actual: 0\nand downloading the file with IDM is fine. also I don't have this problem every time, well i have deleted the whole directory and downloaded again with aria2 and it was OK. I'm using aria2 version 1.33.1 and I've got the same problem but the arguments I set are different\nthe arguments are an input and log file and \n continue\n force-sequential=true\n max-tries=3\n truncate-console-readout=false\n auto-file-renaming=false\n auto-save-interval=1\n save-session-interval=1\n deferred-input=true\n file-allocation=none\nthe log file exception:\nException: [AbstractCommand.cc:403] errorCode=1 URI=https://api.ariogames.ir/fileuploader/static/games/e12d158c42ae53f3de9b9ea25665a334/29a8c201baa277caf2f8ef293e956b67/compressed/DarkSummer/data.dcp.7z\n  -> [RequestGroup.cc:760] errorCode=1 Download aborted.\n  -> [DefaultBtProgressInfoFile.cc:300] errorCode=1 total length mismatch. expected: 921150137, actual:0. ",
    "LBYPatrick": "It's recommended to use aria2 with commands instead of configs. Here's a reference of parameters for using aria2c with commands:\n```\n -v, --version                Print the version number and exit.\n                          Tags: #basic\n\n-h, --help[=TAG|KEYWORD]     Print usage and exit.\n                              The help messages are classified with tags. A tag\n                              starts with \"#\". For example, type \"--help=#http\"\n                              to get the usage for the options tagged with\n                              \"#http\". If non-tag word is given, print the usage\n                              for the options whose name includes that word.\n                          Possible Values: #basic, #advanced, #http, #https, #ftp, #metalink, #bittorrent, #cookie, #hook, #file, #rpc, #checksum, #experimental, #deprecated, #help, #all\n                          Default: #basic\n                          Tags: #basic, #help\n\n-l, --log=LOG                The file name of the log file. If '-' is\n                              specified, log is written to stdout.\n                          Possible Values: /path/to/file, -\n                          Tags: #basic\n\n-d, --dir=DIR                The directory to store the downloaded file.\n                          Possible Values: /path/to/directory\n                          Default: C:\\Windows\\system32\n                          Tags: #basic, #file\n\n-o, --out=FILE               The file name of the downloaded file. It is\n                              always relative to the directory given in -d\n                              option. When the -Z option is used, this option\n                              will be ignored.\n                          Possible Values: /path/to/file\n                          Tags: #basic, #http, #ftp, #file\n\n-s, --split=N                Download a file using N connections. If more\n                              than N URIs are given, first N URIs are used and\n                              remaining URLs are used for backup. If less than\n                              N URIs are given, those URLs are used more than\n                              once so that N connections total are made\n                              simultaneously. The number of connections to the\n                              same host is restricted by the\n                              --max-connection-per-server option. See also the\n                              --min-split-size option.\n                          Possible Values: 1-*\n                          Default: 5\n                          Tags: #basic, #http, #ftp\n\n--file-allocation=METHOD     Specify file allocation method.\n                              'none' doesn't pre-allocate file space. 'prealloc'\n                              pre-allocates file space before download begins.\n                              This may take some time depending on the size of\n                              the file.\n                              If you are using newer file systems such as ext4\n                              (with extents support), btrfs, xfs or NTFS\n                              (MinGW build only), 'falloc' is your best\n                              choice. It allocates large(few GiB) files\n                              almost instantly. Don't use 'falloc' with legacy\n                              file systems such as ext3 and FAT32 because it\n                              takes almost same time as 'prealloc' and it\n                              blocks aria2 entirely until allocation finishes.\n                              'falloc' may not be available if your system\n                              doesn't have posix_fallocate() function.\n                              'trunc' uses ftruncate() system call or\n                              platform-specific counterpart to truncate a file\n                              to a specified length.\n                          Possible Values: none, prealloc, trunc, falloc\n                          Default: prealloc\n                          Tags: #basic, #file\n\n-V, --check-integrity[=true|false] Check file integrity by validating piece\n                              hashes or a hash of entire file. This option has\n                              effect only in BitTorrent, Metalink downloads\n                              with checksums or HTTP(S)/FTP downloads with\n                              --checksum option. If piece hashes are provided,\n                              this option can detect damaged portions of a file\n                              and re-download them. If a hash of entire file is\n                              provided, hash check is only done when file has\n                              been already download. This is determined by file\n                              length. If hash check fails, file is\n                              re-downloaded from scratch. If both piece hashes\n                              and a hash of entire file are provided, only\n                              piece hashes are used.\n                          Possible Values: true, false\n                          Default: false\n                          Tags: #basic, #metalink, #bittorrent, #file, #checksum\n\n-c, --continue[=true|false]  Continue downloading a partially downloaded\n                              file. Use this option to resume a download\n                              started by a web browser or another program\n                              which downloads files sequentially from the\n                              beginning. Currently this option is only\n                              applicable to http(s)/ftp downloads.\n                          Possible Values: true, false\n                          Default: false\n                          Tags: #basic, #http, #ftp\n\n-i, --input-file=FILE        Downloads URIs found in FILE. You can specify\n                              multiple URIs for a single entity: separate\n                              URIs on a single line using the TAB character.\n                              Reads input from stdin when '-' is specified.\n                              Additionally, options can be specified after each\n                              line of URI. This optional line must start with\n                              one or more white spaces and have one option per\n                              single line. See INPUT FILE section of man page\n                              for details. See also --deferred-input option.\n                          Possible Values: /path/to/file, -\n                          Tags: #basic\n\n-j, --max-concurrent-downloads=N Set maximum number of parallel downloads for\n                              every static (HTTP/FTP) URL, torrent and metalink.\n                              See also --split and --optimize-concurrent-downloads options.\n                          Possible Values: 1-*\n                          Default: 5\n                          Tags: #basic\n\n-Z, --force-sequential[=true|false] Fetch URIs in the command-line sequentially\n                              and download each URI in a separate session, like\n                              the usual command-line download utilities.\n                          Possible Values: true, false\n                          Default: false\n                          Tags: #basic\n\n-x, --max-connection-per-server=NUM The maximum number of connections to one\n                              server for each download.\n                          Possible Values: 1-16\n                          Default: 1\n                          Tags: #basic, #http, #ftp\n\n-k, --min-split-size=SIZE    aria2 does not split less than 2SIZE byte range.\n                              For example, let's consider downloading 20MiB\n                              file. If SIZE is 10M, aria2 can split file into 2\n                              range [0-10MiB) and [10MiB-20MiB) and download it\n                              using 2 sources(if --split >= 2, of course).\n                              If SIZE is 15M, since 215M > 20MiB, aria2 does\n                              not split file and download it using 1 source.\n                              You can append K or M(1K = 1024, 1M = 1024K).\n                          Possible Values: 1048576-1073741824\n                          Default: 20M\n                          Tags: #basic, #http, #ftp\n\n--ftp-user=USER              Set FTP user. This affects all URLs.\n                          Tags: #basic, #ftp\n\n--ftp-passwd=PASSWD          Set FTP password. This affects all URLs.\n                          Tags: #basic, #ftp\n\n--http-user=USER             Set HTTP user. This affects all URLs.\n                          Tags: #basic, #http\n\n--http-passwd=PASSWD         Set HTTP password. This affects all URLs.\n                          Tags: #basic, #http\n\n--load-cookies=FILE          Load Cookies from FILE using the Firefox3 format\n                              and Mozilla/Firefox(1.x/2.x)/Netscape format.\n                          Possible Values: /path/to/file\n                          Tags: #basic, #http, #cookie\n\n-S, --show-files[=true|false] Print file listing of .torrent, .meta4 and\n                              .metalink file and exit. More detailed\n                              information will be listed in case of torrent\n                              file.\n                          Possible Values: true, false\n                          Default: false\n                          Tags: #basic, #metalink, #bittorrent\n\n--max-overall-upload-limit=SPEED Set max overall upload speed in bytes/sec.\n                              0 means unrestricted.\n                              You can append K or M(1K = 1024, 1M = 1024K).\n                              To limit the upload speed per torrent, use\n                              --max-upload-limit option.\n                          Possible Values: 0-*\n                          Default: 0\n                          Tags: #basic, #bittorrent\n\n-u, --max-upload-limit=SPEED Set max upload speed per each torrent in\n                              bytes/sec. 0 means unrestricted.\n                              You can append K or M(1K = 1024, 1M = 1024K).\n                              To limit the overall upload speed, use\n                              --max-overall-upload-limit option.\n                          Possible Values: 0-*\n                          Default: 0\n                          Tags: #basic, #bittorrent\n\n-T, --torrent-file=TORRENT_FILE  The path to the .torrent file.\n                          Possible Values: /path/to/file\n                          Tags: #basic, #bittorrent\n\n--listen-port=PORT...        Set TCP port number for BitTorrent downloads.\n                              Multiple ports can be specified by using ',',\n                              for example: \"6881,6885\". You can also use '-'\n                              to specify a range: \"6881-6999\". ',' and '-' can\n                              be used together.\n                          Possible Values: 1024-65535\n                          Default: 6881-6999\n                          Tags: #basic, #bittorrent\n\n--enable-dht[=true|false]    Enable IPv4 DHT functionality. It also enables\n                              UDP tracker support. If a private flag is set\n                              in a torrent, aria2 doesn't use DHT for that\n                              download even if true is given.\n                          Possible Values: true, false\n                          Default: true\n                          Tags: #basic, #bittorrent\n\n--dht-listen-port=PORT...    Set UDP listening port used by DHT(IPv4, IPv6)\n                              and UDP tracker. Multiple ports can be specified\n                              by using ',', for example: \"6881,6885\". You can\n                              also use '-' to specify a range: \"6881-6999\".\n                              ',' and '-' can be used together.\n                          Possible Values: 1024-65535\n                          Default: 6881-6999\n                          Tags: #basic, #bittorrent\n\n--enable-dht6[=true|false]   Enable IPv6 DHT functionality.\n                              Use --dht-listen-port option to specify port\n                              number to listen on. See also --dht-listen-addr6\n                              option.\n                          Possible Values: true, false\n                          Default: false\n                          Tags: #basic, #bittorrent\n\n--dht-listen-addr6=ADDR      Specify address to bind socket for IPv6 DHT.\n                              It should be a global unicast IPv6 address of the\n                              host.\n                          Tags: #basic, #bittorrent\n\n-M, --metalink-file=METALINK_FILE The file path to the .meta4 and .metalink\n                              file. Reads input from stdin when '-' is\n                              specified.\n                          Possible Values: /path/to/file, -\n                          Tags: #basic, #metalink\n\n```\n\u9898\u5916\u8bdd: \u5982\u679c\u4f60\u6709\u70b9\u641e\u4e0d\u660e\u767d\u800c\u4e14\u82f1\u8bed\u8868\u8fbe\u6ca1\u90a3\u4e48\u65b9\u4fbf\u7684\u8bdd\uff0c\u76f4\u63a5\u56de\u590d\u4e2d\u6587\u4e5f\u884c\u3002\n. ",
    "Edelwiess": "\u8c22\u8c22\uff0c\u6211\u5728\u672c\u5730127.0.0.1\u5f00\u4e86web ui  \u73b0\u5728\u4e0d\u5b58\u5728\u8fd9\u4e2a\u9700\u8981\u4fdd\u5b58\u914d\u7f6e\u6587\u4ef6\u7684\u9700\u6c42\u4e86\u3002. ",
    "mozbugbox": "https://gitlab.com/mozbugbox/aria2daemon. I have the need for the similar function so here is my try:\nhttps://gitlab.com/mozbugbox/aria2daemon\nIt launch an aria2 rpc daemon for each download directory and further download in that directory will be submitted to the same daemon.\n. ",
    "mpco": "Thank you.. ",
    "mostafa88": "I have the save issue, but the message is \n\n[DefaultBtProgressInfoFile.cc:300] errorCode=1 total length mismatch. expected: 1223079221, actual: 0\n\n@LessCat, Did your problem fixed?\nPlease specify how do you fix the issue?. I think my problem is related to this issue.\nOur server supports both http and https for downloading files.\nWhen i try download a large file (about 1.4GB) with https, always 31 bytes in the file are different from the original file. As @tian-le  mentioned, the differents are in the specific pattern.\nThe start address of different in my case in 3 unsuccessfull downloads are the following list( 51269E2A,40461E57,4045DE57) that xxxxxExx.\nI try to download with https and  \"--max-connection-per-server=1\", but the result is the same. And when I download with http, the file download completes without any problem.\nYou can download my test file from here with https.\n**Tested on\n-windows 10, \n-aria2c version 1.31.0 and 1.32.0. @tatsuhiro-t: yes every time i download the file with aria2c on https, the file has some changes.\nmd5 of original file is: \"4b81addf4d2c3b57ec729629608a52db\". @antbryan: the problem has fixed in version 1.33.1\nThanks. I have this problem too. It seems that Aria2c face this issue when downloading large files. In my case, there is a binary file that is about 1.4 GB. I download it twice and compare them to the original file. It seems that only 31 bytes are different, but the location of the diffs are not same it both files. \nI attach comparison results.\nIn the following results the \"SOUND.DCP.IDM\" is the original file and the other one is the downloaded file.\ndiff1.txt\ndiff2.txt\n. This issue occured becase of a proxy was already set on the system and in the time of starting download, the porxy not running and aria2 cannot download the file.\nSo the issue should be closed.\n. ",
    "ShenHongFei": "I came accross the same problem .\nWithout the configuration file everything works just fine , then I tried commenting this line \n\ninput-file=aria2.session\n\naria2 works.. I think you can run the same command (by look up console history)  and aria2 will automatically continue without losing progress.When you hit ctrl-C while downloading is still in progress, aria2 leaves control file. Running the same command line, aria2 starts resuming last download.(you can see a .aria2 file in the same dir as your download file).\n. https://aria2.github.io/manual/en/html/aria2c.html#input-file\nThis is what the input-file use for. ",
    "Sg4Dylan": "@ShenHongFei \nIf I comment this line, aria2 goes to forget every task after the restart.. Well, I know about the command to restore task manually. Usually, I use WebUI to remote control aria2 and keep it auto startup by systemd, therefore what I need is auto complete all of these operations, then all download tasks would be auto restored after the system restarted.. ",
    "quamis": "apparently aria2.session has to exist, empty on the first run, and it will then get filled in as needed during downloads. I'm using an absolute path ( as in /home/user/aria2.session ) to avoid ambiguities. Took me 1 hour to get this, maybe it will help someone else.. ",
    "Happyfeet01": "I have the same Problem that the downloads purged after server, or docker image restart. . ",
    "moralrebuild": "suffered this issue twice in last year. any fixing?. ",
    "fcicq": "@myfreeer I'm also doing other tests, and seems all of changes may break other current behaviors, and requires the author's comment/decision.. 6 seems resolved.. ",
    "ewwink": "I think min-split-size should be optional becuase I still dont understand why default min-split-size should be 20M, prevent this tool used as ddos tool?. ",
    "Caribpa": "So maybe, as an enhancement, if the download using HEAD fails, it should be retried using GET.\nMaybe the best is to keep this behavior (error if the server refuses HEAD requests) for --use-head=true, and implement a new option: --use-head=auto where if the HEAD request fails, aria2 will try again with a GET request.\nWhat do you think?. ",
    "edrozenberg": "This would be useful for portability. trunc is portable but trunc doesn't actually allocate space, it just pretends to, and the space may not actually be available when attempting to use it.. ",
    "testcaoy7": "@nmaier Thank you !!!. ",
    "shinecurve": "where is 1.34.0 darwin binaries?. ",
    "Windywind": "And I checked on my CentOS server, It IS run by normal user \"wind\", in deed, not user \"root\".\n\n. Hi @rabbitsmith ,\nI don't think that could be a solution, I knew that a empty session file is needed, but not a log file. Moreover, I found a log file already exist in the path prompted. see below\n\n. @rabbitsmith \nAnd I recreated the log file, as I have expected, this did not work.\n\n. The way to work around is, to make the log file and session file both writable for \"others\".\nSo now, these two files are look like this:\n-rw-rw-rw- 1 root root 21980 Jun 12 03:51 aria2.log\n-rw-rw-rw- 1 root root     0 Jun  7 18:56 aria2.session\n. Alright, I have found the cause.\nI have no log configuration on my CentOS server, but I do have log configure on my Ubuntu GNOME. And for a normal user, of course it has no access to a owned by root.\nsolved.. ",
    "waeshang": "seeding torrent options must follow behand:\ncheck-integrity=true\ncontinue=true\nbt-hash-check-seed=true\nbt-seed-unverified=false\nallow-overwrite=false\nand you need enable rpc too.\nthe issue is that re-seeding need by-hand to add torrent  after restart aria2... ",
    "samumist": "@smilebox I had the exact same problem. \n@Gianlu01 pkill and restart does help. \nStill the same problem.. ",
    "compyy": "UP, I can't install it from source, and PPA is very old. Not sure, i used following its working now.\nhttps://github.com/q3aql/aria2-static-builds/releases. ",
    "markx": "Exactly what I needed. Thanks!. ",
    "nafmee": "Yes, please we need RSS Feed to be supported.. ",
    "kvser": "I think it would be good extending for the API of libaria2, because it is very useful for the clients of library to let them know specific errors. Are there plans about that? . ",
    "eladkarako": "I've could not add a manifest as an embedded resource to aria2c.exe,\nusing my manifest tool,\nsince the data sections are not standard, so mt.exe from Windows-SDK can't identify aria2c.exe as a valid binary, something wrong with its pe-headers...\nI would probably fix the makefile(s) but for now I've used a workaround to have an external manifest file.\nthen I've used a generic manifest, renamed it to aria2c.exe.manifest and placed it in the same folder as aria2c.exe, windows 10 allows it to run out side of the file/registry-virtualization, and it runs a lot faster too.\nI don't have a workaround for the VersionInfo part, it should be an embedded resource (compilation time, before any packet-protectors etc...)\nwhat compiler do you use for the releases?\nsince the result is not identifiable and any change to the binary file result in corruption of the binary file...\n\n. I'll try to see if this gcc command will work with the make file.\n. I'm using a slightly modified version of the statically link version from github.com/q3aql/aria2-static-builds/. It allows rewriting the manifest and VERSIONINFO binary blocks without corrupting the binary execute. You might as well run a quick diff or close this one all together (and maybe https://github.com/aria2/aria2/issues/1075 too?). could you try those those switches and report back, if there was any change?\n--file-allocation=\"prealloc\" (reduce real-time allocation)\nand --save-session-interval=3 (dump session to disk more frequently).\n. nice try with https://github.com/aria2/aria2/commit/a45390c80bf3510a3eac384a286c44b5d9af8af1 ;)\nit still happens on 1.33.1\n. fixed in https://github.com/aria2/aria2/releases/tag/release-1.34.0\n(or static builds at https://github.com/q3aql/aria2-static-builds/releases/tag/v1.34.0 ). edit: \nit seems that adding --continue=\"true\" will overwrite the file back to 0, regardless of having --allow-overwrite=\"false\" --auto-file-renaming=\"false\".\nbug?\nit wasn't in previous versions (.30?). ",
    "sachk": "Yeah, I've tried this personally by doing it manually and it works very well in some cases.. ",
    "nhunting": "Thanks. It seems very library-specific:\nThese do not work:\n  * aria\n  * curl\n  * Chrome \nThese do:\n  * WinINet funtions built into Windows \n  * uGet for Windows \nInteresting. I'd rather use aria because the interface is so great and scriptable. aria is a great program.. Cool, thank you! I should have thought of that. I appreciate your help!. ",
    "sy19890515": "@Jimmy-Z Yes, and I also try run it as admin, but still.... @Jimmy-Z Oh I see! Thank you so much! I didn't realize it was for command lines only. @Jimmy-Z Oh sorry. I am new to here and not familiar with the features. Thanks for reminding me!. ",
    "hillz2": "Thank you, in the .config you have to enable these options:\n```\nCONFIG_PACKAGE_aria2=y\n\nAria2 Configuration\n\nCONFIG_ARIA2_OPENSSL=y\nCONFIG_ARIA2_GNUTLS is not set\nCONFIG_ARIA2_NOSSL is not set\nCONFIG_ARIA2_BITTORRENT=y\nCONFIG_ARIA2_SFTP is not set\nCONFIG_ARIA2_ASYNC_DNS is not set\nCONFIG_ARIA2_COOKIE is not set\nCONFIG_ARIA2_METALINK=y\nCONFIG_ARIA2_LIBXML2=y\n```. ",
    "chihung93": "@tatsuhiro-t \nI use Java\nI set Interval 1 second for update progress bar, but when the user stops the download, I must call aria2.pause and stop interval, I will call aria2.unpause when user wanna resume it.\nBut when call aria2.unpause I got this message \"No URI available.\" : \nINFO: \nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: {\"method\":\"aria2.unpause\",\"params\":[\"d01045afcf78b75d\"],\"id\":8098525445477824827}\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: --> END POST (81-byte body)\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: <-- 200 OK http://localhost:6800/jsonrpc (8ms)\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: Date: Wed, 09 Aug 2017 16:51:50 GMT\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: Expires: Wed, 09 Aug 2017 16:51:50 GMT\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: Cache-Control: no-cache\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: Content-Type: application/json-rpc\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: \nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: {\"id\":8098525445477824827,\"jsonrpc\":\"2.0\",\"result\":\"d01045afcf78b75d\"}\nAug 09, 2017 11:51:50 PM okhttp3.internal.platform.Platform log\nINFO: <-- END HTTP (70-byte body)\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: --> POST http://localhost:6800/jsonrpc http/1.1\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: Content-Type: application/json\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: Content-Length: 84\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: \nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: {\"method\":\"aria2.tellStatus\",\"params\":[\"d01045afcf78b75d\"],\"id\":8497925954108106352}\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: --> END POST (84-byte body)\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: <-- 200 OK http://localhost:6800/jsonrpc (3ms)\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: Date: Wed, 09 Aug 2017 16:52:03 GMT\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: Expires: Wed, 09 Aug 2017 16:52:03 GMT\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: Cache-Control: no-cache\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: Content-Type: application/json-rpc\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: \nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: {\"id\":8497925954108106352,\"jsonrpc\":\"2.0\",\"result\":{\"bitfield\":\"00\",\"completedLength\":\"507904\",\"connections\":\"0\",\"dir\":\"C:\\\\Users\\\\alex\\\\downloads\",\"downloadSpeed\":\"0\",\"errorCode\":\"8\",\"errorMessage\":\"No URI available.\",\"files\":[{\"completedLength\":\"0\",\"index\":\"1\",\"length\":\"537780\",\"path\":\"C:\\\\Users\\\\alex\\\\downloads\\/10799076132\",\"selected\":\"true\",\"uris\":[{\"status\":\"used\",\"uri\":\"https:\\/\\/initiate.alphacoders.com\\/download\\/wallpaper\\/653613\\/images4\\/jpg\\/1079907613\"},{\"status\":\"used\",\"uri\":\"https:\\/\\/initiate.alphacoders.com\\/download\\/wallpaper\\/653613\\/images4\\/jpg\\/1079907613\"}]}],\"gid\":\"d01045afcf78b75d\",\"numPieces\":\"1\",\"pieceLength\":\"1048576\",\"status\":\"error\",\"totalLength\":\"537780\",\"uploadLength\":\"0\",\"uploadSpeed\":\"0\"}}\nAug 09, 2017 11:52:03 PM okhttp3.internal.platform.Platform log\nINFO: <-- END HTTP (734-byte body)\nDo you have a solution for this case?\nThank you so much.\n. ",
    "iLibra": "@tatsuhiro-t I think this should be a FAQ, but I didn't find the answer. Why there is no plan for ED2k? Could you explain your concern? ED2K is really as popular as BT and metalink.\n. Thanks for your explanation.^_^. translation: Why I cannot download the BT and metalink files? . ",
    "leewi9": "any update to support ed2k ??. ",
    "zuohuadong": "+1. ",
    "GeonChen": "\naria2 \u6211\u5df2\u7ecf\u79bb\u4e0d\u5f00\u4e86\uff0c\u4f46\u662f\u552f\u4e00\u9057\u61be\u7684\u4e0d\u652f\u6301 ed2k\n\n\u53ef\u4ee5\u7528\u767e\u5ea6\u7f51\u76d8\u79bb\u7ebf\u4e0b\u8f7ded2k\uff0c\u7136\u540e\u4f7f\u7528BaiduExporter\u5de5\u5177\u63d0\u53d6\u94fe\u63a5\u5230aria2\u4e0b\u8f7d\u3002\n\u8fc5\u96f7\u4e5f\u6709\u5bf9\u5e94\u7684\u5de5\u5177\u3002. ",
    "peerless2012": "\n\naria2 \u6211\u5df2\u7ecf\u79bb\u4e0d\u5f00\u4e86\uff0c\u4f46\u662f\u552f\u4e00\u9057\u61be\u7684\u4e0d\u652f\u6301 ed2k\n\n\u53ef\u4ee5\u7528\u767e\u5ea6\u7f51\u76d8\u79bb\u7ebf\u4e0b\u8f7ded2k\uff0c\u7136\u540e\u4f7f\u7528BaiduExporter\u5de5\u5177\u63d0\u53d6\u94fe\u63a5\u5230aria2\u4e0b\u8f7d\u3002\n\u8fc5\u96f7\u4e5f\u6709\u5bf9\u5e94\u7684\u5de5\u5177\u3002\n\n\u8fd9\u4e5f\u662f\u76ee\u524d\u6bd4\u8f83\u597d\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u53ea\u662f\u6bd4\u8f83\u7e41\u7410. ",
    "HashLiver": "\u4e0d\u77e5\u9053\u5927\u5bb6\u6709\u6ca1\u6709\u53d1\u73b0\uff0c\u63d0\u5230ed2k\u5168\u90fd\u662f\u4e2d\u56fd\u4eba\u3002\n\u771f\u662f\u7b11\u6b7b\u6211\u4e86\uff0c\u4f60\u4eec\u96be\u9053\u771f\u7684\u8ba4\u4e3a\u90a3\u6240\u8c13\u8fc5\u96f7\u7b49\u56fd\u4ea7BT\u4e0b\u8f7d\u8f6f\u4ef6\u4f1a\u4f7f\u7528\u771f\u6b63\u7684eDonkey\u7f51\u7edc\uff1f\n\u975e\u4e5f\uff01\u5b83\u4eec\u53ea\u4e0d\u8fc7\u901a\u8fc7ed2k\u94fe\u63a5\u6240\u5217\u51fa\u7684\u54c8\u5e0c\u503c \u76f4\u63a5\u94fe\u63a5\u5230\u5b83\u4eec\u670d\u52a1\u5668\u81ea\u8eab\uff08\u5982\u8fc5\u96f7\u3001\u767e\u5ea6\uff09\u6240\u5b58\u50a8\u7684\u6587\u4ef6 \u6216\u94fe\u63a5\u5230BitTorrent\u534f\u8bae\u7684\u79cd\u5b50\u548c\u78c1\u529b\u94fe\u63a5\u4e0a\u3002\u4f60\u4eec\u7528\u7684\u8f6f\u4ef6\u4e0d\u662fP2P\uff08Peer to Peer\uff09\uff0c\u800c\u662fP2SP\uff08Peer to Server and to Peer\uff09\uff01\n\u5982\u679c\u4f60\u4eec\u7528\u8fc7\u771f\u6b63\u7684ed2k\u4e0b\u8f7d\u5668\uff08\u5982eMule\u3001aMule\uff09\u7684\u8bdd\uff0c\u4f60\u4eec\u4f1a\u53d1\u73b0\uff0c\u771f\u6b63\u7684eDonkey\u7f51\u7edc\u65e9\u5df2\u6d88\u4ea1\uff0c\u622a\u81f3\u76ee\u524d\u5168\u7403\u7528\u6237\u4e5f\u5c3150-60\u4e07\u7684\u6837\u5b50\u3002\n\u6700\u540e\uff0c\u4f5c\u4e3a\u66fe\u7ecf\u7684eMule\u8001\u7528\u6237\uff0c\u6211\u53ef\u4ee5\u8bf4\u660e\u771f\u6b63\u7684eDonkey\u7f51\u7edc\u4e0d\u4ec5\u6709\u7e41\u7410\u7684\u6392\u961f\u673a\u5236\uff0c\u8fd8\u6709\u6587\u4ef6\u4f18\u5148\u7ea7\u7f51\u7edc\u4f18\u5148\u7ea7\u7b49\u590d\u6742\u7684\u8bbe\u5b9a\uff0c\u8fdc\u6bd4\u4f60\u4eec\u60f3\u50cf\u4e2d\u96be\u7528\u7684\u591a\u3002. ",
    "RalphCorderoy": "Now you've got me doubting I understand how it all works.\u2002:-)\u2002I could have met nine peers that all had a distinct 11% each.\u2002But in this particular case, my bitfield has now reached\n$ fold -1 <<<$bitfield | uniq -c\n    220 f\n      1 8\n      1 0\n$\n\nwhich given numPieces is 882 means I'm missing the last piece:\u2002220*4 + 1 = 881.\u2002And at least one peer that connects has precisely that bitfield too.. ",
    "jakehelf": "Thank you very much.. The third party library build successful, but there was an error when run 'android-make -j8' for aria2. \nCXX      main.o\n  CXXLD    libaria2.la\n  CXXLD    aria2c\n/Users/.../Tools/android/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: z: no archive symbol table (run ranlib)\n/Users/.../Tools/android/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../include/c++/4.9.x/bits/shared_ptr_base.h:666: error: undefined reference to 'aria2::A2STR::NIL'\n/Users/.../Tools/android/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../include/c++/4.9.x/bits/basic_string.h:547: error: undefined reference to 'aria2::A2STR::NIL'\nGZipEncoder.cc:69: error: undefined reference to 'deflateEnd'\nGZipEncoder.cc:60: error: undefined reference to 'deflateInit2_'\nGZipEncoder.cc:85: error: undefined reference to 'deflate'\n/Users/.../Tools/android/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../include/c++/4.9.x/bits/stl_vector.h:1045: error: undefined reference to 'aria2::A2STR::NIL'\n/Users/.../Tools/android/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../include/c++/4.9.x/bits/stl_vector.h:1045: error: undefined reference to 'aria2::A2STR::NIL'\nGZipDecodingStreamFilter.cc:69: error: undefined reference to 'inflateInit2_'\nGZipDecodingStreamFilter.cc:77: error: undefined reference to 'inflateEnd'\nGZipDecodingStreamFilter.cc:102: error: undefined reference to 'inflate'\ncomp.c:313: error: undefined reference to 'inflateEnd'\ncomp.c:311: error: undefined reference to 'deflateEnd'\ncomp.c:256: error: undefined reference to 'inflate'\ncomp.c:198: error: undefined reference to 'deflate'\ncomp.c:159: error: undefined reference to 'inflateInit_'\ncomp.c:156: error: undefined reference to 'deflateInit_'\nFileEntry.cc:451: error: undefined reference to 'uri_split'\nFileEntry.cc:131: error: undefined reference to 'uri_split'\nFileEntry.cc:298: error: undefined reference to 'uri_split'\nFileEntry.cc:372: error: undefined reference to 'uri_split'\nGZipFile.cc:62: error: undefined reference to 'gzdopen'\nGZipFile.cc:90: error: undefined reference to 'gzclose'\nGZipFile.cc:101: error: undefined reference to 'gzerror'\nGZipFile.cc:105: error: undefined reference to 'gzeof'\nGZipFile.cc:115: error: undefined reference to 'gzread'\nGZipFile.cc:132: error: undefined reference to 'gzwrite'\nGZipFile.cc:143: error: undefined reference to 'gzgets'\nGZipFile.cc:145: error: undefined reference to 'gzflush'\nGZipFile.cc:171: error: undefined reference to 'gzwrite'\nAdler32MessageDigestImpl.cc:46: error: undefined reference to 'adler32'\nAdler32MessageDigestImpl.cc:52: error: undefined reference to 'adler32'\nAdler32MessageDigestImpl.cc:57: error: undefined reference to 'adler32'\nclang38++: error: linker command failed with exit code 1 (use -v to see invocation)\nmake[3]: *** [aria2c] Error 1\nmake[3]: Leaving directory `/Users/.../Dev/aria2/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory `/Users/.../Dev/aria2/src'\nmake[1]: *** [all-recursive] Error 1\nmake[1]: Leaving directory `/Users/.../Dev/aria2'\nmake: *** [all] Error 2. ",
    "stepanbujnak": "Here's the log:\n[DEBUG] [AbstractSingleDiskAdaptor.cc:101] Cache flush goff=98300, len=16383\n[DEBUG] [AbstractSingleDiskAdaptor.cc:101] Cache flush goff=114683, len=16383\n[ERROR] [WrDiskCacheEntry.cc:83] Error when trying to flush write cache\nException: [AbstractDiskWriter.cc:454] errNum=28 errorCode=9 Failed to write into the file /opt/downloads/4a6521b3-b034-407d-aeeb-0bc09dfae682.chunks/2235, cause: No space left on device\n[DEBUG] [AbstractCommand.cc:184] CUID#159304 - socket: read:1, write:0, hup:0, err:0\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=14232, delta=1120, clock=6049799\n[DEBUG] [Piece.cc:342] updateWrCache entry=0x7ef3ff5179d0\n[DEBUG] [WrDiskCacheEntry.cc:95] WrDiskCacheEntry cache goff=212542, len=15264\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=29496, delta=15264, clock=6050046\n[DEBUG] [AbstractCommand.cc:184] CUID#159305 - socket: read:1, write:0, hup:0, err:0\n[DEBUG] [Piece.cc:342] updateWrCache entry=0x7ef65fd10fc0\n[DEBUG] [WrDiskCacheEntry.cc:95] WrDiskCacheEntry cache goff=341476, len=3880\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=113920, delta=3880, clock=6049800\n[INFO] [DownloadCommand.cc:242] CUID#159305 - The download for one segment completed successfully.\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=113920, delta=-113920, clock=6050048\n[DEBUG] [AbstractSingleDiskAdaptor.cc:101] Cache flush goff=231436, len=16384\n[ERROR] [WrDiskCacheEntry.cc:83] Error when trying to flush write cache\nException: [AbstractDiskWriter.cc:454] errNum=28 errorCode=9 Failed to write into the file /opt/downloads/daaf18a1-2368-4dbe-a8e6-5c2088577cc2.chunks/2412, cause: No space left on device\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=0, delta=0, clock=6050049\n[ERROR] [AbstractCommand.cc:403] CUID#159305 - Download aborted. URI=<reducted>\nException: [AbstractCommand.cc:403] errorCode=9 URI=<reducted>\n  -> [DownloadCommand.cc:127] errorCode=9 Write disk cache flush failure index=0\n[DEBUG] [RequestGroup.cc:982] GID#b7f7e2c3f9391d6b - Request queue check\n[DEBUG] [AbstractCommand.cc:184] CUID#159307 - socket: read:1, write:0, hup:0, err:0\n[DEBUG] [Piece.cc:342] updateWrCache entry=0x7efc020998e0\n[DEBUG] [WrDiskCacheEntry.cc:95] WrDiskCacheEntry cache goff=256632, len=16383\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=72231, delta=16383, clock=6049801\n[DEBUG] [AbstractCommand.cc:184] CUID#159309 - socket: read:1, write:0, hup:0, err:0\n[DEBUG] [Piece.cc:342] updateWrCache entry=0x7efa61012930\n[DEBUG] [WrDiskCacheEntry.cc:95] WrDiskCacheEntry cache goff=361017, len=16383\n[DEBUG] [WrDiskCache.cc:972017-08-28 18:05:42.852444 [DEBUG] [RequestGroup.cc:1067] Finding PostDownloadHandler for path /opt/downloads/6952ad89-8bac-472b-9fed-9eb9bc7dd3f8.chunks/2265.\n[DEBUG] [RequestGroup.cc:1080] No PostDownloadHandler found.\n[DEBUG] [RequestGroup.cc:1172] GID#96643b4f21b650d4 - Creating DownloadResult.\n[DEBUG] [DefaultPieceStorage.cc:745] Removed 0 have entries.\n[DEBUG] [ServerStat.cc:111] ServerStat:<reducted>: singleConnectionAvgSpeed_ old:262.10KB/s new:266.41KB/s last:283.65KB/s\n[DEBUG] [WrDiskCache.cc:97] Update cache entry size=0, delta=0, clock=6050050\n[DEBUG] [WrDiskCache.cc:81] Removed cache entry size=0, clock=6050227\n[NOTICE] [RequestGroupMan.cc:427] Download GID#b7f7e2c3f9391d6b not complete: /opt/downloads/daaf18a1-2368-4dbe-a8e6-5c2088577cc2.chunks/2412\n[DEBUG] [RequestGroup.cc:1172] GID#b7f7e2c3f9391d6b - Creating DownloadResult.\n[DEBUG] [DefaultPieceStorage.cc:745] Removed 0 have entries.\n\nIt appears that the application is running out of disk space. However, I was under the impression that once there's not enough space to download a file, the download fails with the exit status 9 but won't throw any (undocumented) exception. Is this expected behavior?. I believe that the issue is that aria2 crashes when this happens. I would rather have aria2 passing aria2::EVENT_ON_DOWNLOAD_ERROR to the downloadEventCallback and DownloadHandle::getErrorCode() returning sensible error code, e.g. 9 for indication that I've run out of space.. ",
    "zmni": "My bad, completely skipped Event Hook example doc.\nThanks a lot.. aria & external command run without problem now.. ",
    "korzhyk": "You can find here https://downloads.openwrt.org/chaos_calmer/15.05.1/. ",
    "cy493069173": "Yes, i download the magnetic chain file and the seed file will appear above error. ",
    "wu67": "publicbt.com \u8fd9\u4e2a\u57df\u540d\u6ca1\u6cd5\u89e3\u6790\u3002\n- \u4e5f\u8bb8\u4f60\u53ef\u4ee5\u6362\u4e2a\u79cd\u5b50\u8bd5\u8bd5. @kkartaltepe \nI try:\n```\naria2.conf\non-download-complete=mv /Users/wk/Downloads/*.torrent /Users/wk/.torrent/\nbut get a message that:\ncli\n[NOTICE] Saved metadata as /Users/wk/Downloads/6dc1c37e69576426a63570dd3642c7d4e6f4c082.torrent.\nCould not execute user command: mv /Users/wk/Downloads/*.torrent /Users/wk/.torrent/: No such file or directory\n```\n\nThen I try:\n```\naria2.conf\non-download-complete=/Users/wk/.aria2/torrent.sh\n// or \non-download-complete=sh /Users/wk/.aria2/torrent.sh\n\ntorrent.sh\nmv /Users/wk/Downloads/*.torrent /Users/wk/.torrent/\n```\nand i get the same message above.. But actually, i try the second way, and it doesn't work(In my Mac mini).\nThanks for your comments. I've given up .... ",
    "xzl2021": "@tatsuhiro-t \nDid you mean use this option?\n./configure ARIA2_STATIC=yes --without-gnutls --with-openssl --with-ca-bundle='/etc/ssl/certs/ca-certificates.crt'\nAnd configure summary as follows:\n```\nconfigure: summary of build options:\nversion:        1.0.1-DEV shared 0:1:0\nHost type:      x86_64-unknown-linux-gnu\nInstall prefix: /usr/local\nC compiler:     gcc\nCFlags:         -g -O2\nLibrary types:  Shared=yes, Static=yes\nCUnit:          no\nNettle:         yes\nBuild examples: yes\n\nconfigure: summary of build options:\nBuild:          x86_64-unknown-linux-gnu\nHost:           x86_64-unknown-linux-gnu\nTarget:         x86_64-unknown-linux-gnu\nInstall prefix: /usr/local\nCC:             gcc\nCXX:            g++\nCPP:            gcc -E\nCXXFLAGS:       -g -O2\nCFLAGS:         -g -O2\nCPPFLAGS:\nLDFLAGS:\nLIBS:\nDEFS:           -DHAVE_CONFIG_H\nCXX1XCXXFLAGS:   -std=c++11\nEXTRACXXFLAGS:   -pipe\nEXTRACFLAGS:     -pipe\nEXTRACPPFLAGS:\nEXTRALDFLAGS:    -all-static\nEXTRALIBS:       -lpthread -ldl -lrt\nWARNCXXFLAGS:\nLibUV:          no (CFLAGS='' LIBS='')\nSQLite3:        yes (CFLAGS=' ' LIBS='-lsqlite3 -ldl -lpthread  ')\nSSL Support:    yes\nAppleTLS:       no (LDFLAGS='')\nWinTLS:         no (LIBS='')\nGnuTLS:         no (CFLAGS='' LIBS='')\nOpenSSL:        yes (CFLAGS=' ' LIBS='-lssl -lcrypto -ldl  ')\nCA Bundle:      /etc/ssl/certs/ca-certificates.crt\nLibNettle:      no (CFLAGS='' LIBS='')\nLibGmp:         no (CFLAGS='' LIBS='')\nLibGcrypt:      no (CFLAGS='' LIBS='')\nLibXML2:        no (CFLAGS='' LIBS='')\nLibExpat:       yes (CFLAGS=' ' LIBS='-lexpat  ')\nLibCares:       yes (CFLAGS=' ' LIBS='-lcares  ')\nZlib:           yes (CFLAGS=' ' LIBS='-lz  ')\nLibssh2:        yes (CFLAGS=' ' LIBS='-Wl,-Bsymbolic-functions -Wl,-z,relro -lssh2 -lgcrypt  ')\nTcmalloc:       no (CFLAGS='' LIBS='')\nJemalloc:       no (CFLAGS='' LIBS='')\nEpoll:          yes\nBittorrent:     yes\nMetalink:       yes\nXML-RPC:        yes\nMessage Digest: openssl\nWebSocket:      yes (CFLAGS='-I$(top_builddir)/deps/wslay/lib/includes -I$(top_srcdir)/deps/wslay/lib/includes' LIBS='$(top_builddir)/deps/wslay/lib/libwslay.la')\nLibaria2:       no (shared=yes static=no)\nbash_completion dir: ${datarootdir}/doc/${PACKAGE_TARNAME}/bash_completion\nStatic build:   yes\n```\nBut this time it throw errors agian:\nCXXLD    aria2c\n/usr/lib/x86_64-linux-gnu/libsqlite3.a(sqlite3.o): In function `unixDlOpen':\n(.text+0x8839): warning: Using 'dlopen' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n./.libs/libaria2.a(util.o): In function `aria2::util::getHomeDir()':\n/root/aria2/src/util.cc:1406: warning: Using 'getpwuid' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n./.libs/libaria2.a(SocketCore.o): In function `aria2::callGetaddrinfo(addrinfo**, char const*, char const*, int, int, int, int)':\n/root/aria2/src/SocketCore.cc:1446: warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-misc.o): In function `_gcry_fatal_error':\n(.text+0x22a): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-misc.o): In function `_gcry_divide_by_zero':\n(.text+0x8da): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-misc.o): In function `_gcry_divide_by_zero':\n(.text+0x8e6): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `do_malloc.constprop.4':\n(.text+0x1f2): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_err_make_from_errno':\n(.text+0xd46): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_error_from_errno':\n(.text+0xd75): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_realloc':\n(.text+0xfb9): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_calloc':\n(.text+0x1068): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_calloc_secure':\n(.text+0x10d8): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xmalloc':\n(.text+0x11b7): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xrealloc':\n(.text+0x1232): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xmalloc_secure':\n(.text+0x12ba): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xcalloc':\n(.text+0x1317): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xcalloc':\n(.text+0x1323): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xcalloc_secure':\n(.text+0x1377): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xcalloc_secure':\n(.text+0x1383): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_xstrdup':\n(.text+0x1403): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `do_malloc.constprop.4':\n(.text+0x1fe): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_strerror':\n(.text+0xd01): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_strsource':\n(.text+0xd11): undefined reference to `gpg_strsource'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_err_code_from_errno':\n(.text+0xd21): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_err_code_to_errno':\n(.text+0xd31): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-global.o): In function `_gcry_free':\n(.text+0xf61): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-sexp.o): In function `vsexp_sscan':\n(.text+0x691): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-sexp.o): In function `vsexp_sscan':\n(.text+0x1814): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-sexp.o): In function `make_space':\n(.text+0x2db): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-stdmem.o): In function `_gcry_private_malloc':\n(.text+0xd6): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-stdmem.o): In function `_gcry_private_malloc_secure':\n(.text+0x156): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-secmem.o): In function `_gcry_secmem_malloc_internal':\n(.text+0x43c): undefined reference to `gpg_err_set_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function `_gcry_fips_run_selftests':\n(.text+0x569): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function `_gcry_fips_run_selftests':\n(.text+0x5db): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function `_gcry_fips_run_selftests':\n(.text+0x647): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function `_gcry_fips_run_selftests':\n(.text+0x6db): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-fips.o): In function `_gcry_fips_run_selftests':\n(.text+0x6fe): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(cipher.o): In function `_gcry_cipher_open':\n(.text+0x2196): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(dsa.o): In function `dsa_generate_ext':\n(.text+0x14f3): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(dsa.o): In function `dsa_generate_ext':\n(.text+0x1645): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(kdf.o): In function `pkdf2':\n(.text+0x603): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `md_enable.isra.3':\n(.text+0x6a6): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `md_open':\n(.text+0x8c5): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `md_open':\n(.text+0x8e8): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `_gcry_md_copy':\n(.text+0x10ab): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `_gcry_md_copy':\n(.text+0x1131): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o):(.text+0x1148): more undefined references to `gpg_err_code_from_errno' follow\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `_gcry_md_hash_buffer':\n(.text+0x13c5): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(md.o): In function `_gcry_md_setkey':\n(.text+0x1534): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function `prime_generate_internal':\n(.text+0x169b): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function `prime_generate_internal':\n(.text+0x16b3): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function `prime_generate_internal':\n(.text+0x1701): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function `prime_generate_internal':\n(.text+0x1cd8): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function `_gcry_generate_fips186_2_prime':\n(.text+0x2a11): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(primegen.o): In function `_gcry_generate_fips186_3_prime':\n(.text+0x327e): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o): In function `sexp_to_key':\n(.text+0xb39): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o): In function `octet_string_from_mpi.part.2':\n(.text+0xf59): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o): In function `pss_verify_cmp':\n(.text+0x1109): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(pubkey.o):(.text+0x1ed3): more undefined references to `gpg_err_code_from_syserror' follow\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(libgcrypt_la-module.o): In function `_gcry_module_add':\n(.text+0xf4): undefined reference to `gpg_err_code_from_errno'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function `scanval':\n(.text+0xa9c): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function `ec2os':\n(.text+0x1064): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function `ec2os':\n(.text+0x107c): undefined reference to `gpg_strerror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function `compute_keygrip':\n(.text+0x17c1): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(ecc.o): In function `ecc_generate_ext':\n(.text+0x2274): undefined reference to `gpg_err_code_from_syserror'\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libgcrypt.a(random-fips.o): In function `_gcry_rngfips_init_external_test':\n(.text+0x1180): undefined reference to `gpg_err_code_from_syserror'\ncollect2: error: ld returned 1 exit status\nmake[3]: *** [aria2c] Error 1\nmake[3]: Leaving directory `/root/aria2/src'\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory `/root/aria2/src'\nmake[1]: *** [all-recursive] Error 1\nmake[1]: Leaving directory `/root/aria2'\nmake: *** [all] Error 2\nAny advice for me? Thank you very much.. @tatsuhiro-t \nI found it's libgpg-error make errors above occured.\nSo I use libssl-dev instead of libgnutls-dev, nettle-dev, libgmp-dev, libgpg-error-dev and libgcrypt-dev as suggested.\nAfter that I compile passed!\nThank you, have a good day! . ",
    "hugetiny": "+1. me too. I build aria2-1.34.0 myself ,the aria2c file is too big:\nbuild:78m\nstatically build:82m. Thank you for your help\nOn Jan 14, 2019, at 11:09 PM, Timoth\u00e9e Mazzucotelli notifications@github.com<mailto:notifications@github.com> wrote:\nI guess you need to set this option to \"true\":\n--force-save[=true|false]\n              Save download with --save-session option even if the download is completed or removed.\n              This option also saves control file in that situations. This may be useful to save BitTorrent\n              seeding which is  recognized  as  completed state.  Default: false\nAnd when restarting, pass the saved session file as the --input-file.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/aria2/aria2/issues/1330#issuecomment-454037240, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ASv5wlyQMaBJhMWIirTrDnOIlzLW-fYaks5vDJ2agaJpZM4Zm3nK.\n. \u8fd9\u4e2a\u4eba\u6709\u6bdb\u75c5\n\u53d1\u81ea\u6211\u7684\u5c0f\u7c73\u624b\u673a\n\u5728 Siyuan Xu notifications@github.com\uff0c2019\u5e741\u670821\u65e5 15:05\u5199\u9053\uff1a\nCaution: Not satisfying GPLv2 while providing aria2 bundled in the installer. Not satisfying MIT while including AriaNghttps://github.com/mayswind/AriaNg in it as electron app.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/aria2/aria2/issues/1340#issuecomment-455968361, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ASv5wtCcC6F4swfTFp-RXgtB9ljaCf3Qks5vFWbUgaJpZM4Z8d9V.\n. \u65e0\u8bed\uff0c\u4e2d\u56fd\u5f0f\u5f00\u6e90\u53eb\u5077\uff0c\u518d\u89c1. ",
    "Wh0ba": "iOS builds are available here https://mcapollo.github.io/Public/. ",
    "shellus": "The real reason I found out is that the server returned http 403. ",
    "Cloudiver": "Thank you!\n\nOn Sep 4, 2017, at 20:37, Tatsuhiro Tsujikawa notifications@github.com wrote:\nAre you talking about HTTP BASIC authentication? If so, aria2 supports it.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "Metamba": "Thanks.. ",
    "Eacolt": "\u8bf7\u95ee\u600e\u4e48\u5b89\u88c5aria2\uff0c\u6211\u4e0b\u8f7d\u4e86\u4e00\u4e2aexe\uff0c\u6253\u5f00\u5c31\u95ea\u4e86\u4e00\u4e0b\uff0c\u547d\u4ee4\u884c\u4e1a\u4e5f\u6ca1\u6709\u51fa\u73b0aria2c\uff0c\u8fd9\u662f\u4ec0\u4e48\u539f\u56e0\uff1f. ",
    "tian-le": "The version I used yesterday is:\naria2 version 1.32.0\n Configuration \nEnabled Features: Async DNS, BitTorrent, Firefox3 Cookie, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.11 expat/2.2.0 sqlite3/3.18.0 GMP/6.1.2 c-ares/1.12.0 libssh2/1.8.0\nCompiler: mingw-w64 5.0 (alpha) / gcc 6.3.0 20170321\n  built by   x86_64-pc-linux-gnu\n  targeting x86_64-w64-mingw32\n  on         May 17 2017 22:30:38\nSystem: Windows 7 (Service Pack 1) (x86_64) (6.1)\nHowever, I knew this issue from the first day I use aria2c, which was about 3.5 years ago and version at that time was about 1.17. This issue never got fixed.. some clues:\n1. The website doesn't support keep-alive connection. Please refer the response header as below.\n[('Content-Type', 'application/x-sar'),\n ('Accept-Ranges', 'bytes'),\n ('Server', 'Microsoft-IIS/7.28'),\n ('Last-Modified', 'Thu, 28 Sep 2017 07:38:19 GMT'),\n ('Content-Length', '775031488'),\n ('Date', 'Fri, 29 Sep 2017 03:03:48 GMT'),\n ('Connection', 'close')]\n2. Seems like the connection might be disconnected by the server. Please refer the messages in wget as below.\nwget.exe -c --retry-connrefused --no-check-certificate --http-user=... --htt\np-password=... -i url.lst\n--2017-09-29 12:22:58--  https://XXXXXXX:password@smpdl.sap-ag.de/~swdc/002007\n974700001503242017D/SWPM10SP21_3-20009701.SAR\nResolving smpdl.sap-ag.de (smpdl.sap-ag.de)... 23.0.103.58\nConnecting to smpdl.sap-ag.de (smpdl.sap-ag.de)|23.0.103.58|:443... connected.\nHTTP request sent, awaiting response... 401 Unauthorized\nAuthentication selected: Basic realm=\"SAP Service Marketplace\"\nConnecting to smpdl.sap-ag.de (smpdl.sap-ag.de)|23.0.103.58|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 634398713 (605M) [application/x-sar]\nSaving to: 'SWPM10SP21_3-20009701.SAR'\nSWPM10SP21_3-200097  84%[===============>    ] 511.94M   512KB/s    in 74m 33s\n2017-09-29 13:37:36 (117 KB/s) - Connection closed at byte 536805064. Retrying.\n--2017-09-29 13:37:37--  (try: 2)  https://XXXXXXX:password@smpdl.sap-ag.de/~s\nwdc/002007974700001503242017D/SWPM10SP21_3-20009701.SAR\nConnecting to smpdl.sap-ag.de (smpdl.sap-ag.de)|23.0.103.58|:443... connected.\nHTTP request sent, awaiting response... 401 Unauthorized\nAuthentication selected: Basic realm=\"SAP Service Marketplace\"\nConnecting to smpdl.sap-ag.de (smpdl.sap-ag.de)|23.0.103.58|:443... connected.\nHTTP request sent, awaiting response... 206 Partial Content\nLength: 634398713 (605M), 97593649 (93M) remaining [application/x-sar]\nSaving to: 'SWPM10SP21_3-20009701.SAR'\n10SP21_3-20009701.S  87%[++++++++++++++++>   ] 532.29M  43.6KB/s    eta 35m 20s. @antbryan I downloaded a large file with https protocol yesterday and got no error. It seems like the error gets fixed. However, not too sure if the problem gets 100% resolved, as this issue doesn't always reproduce in the past.. ",
    "mebbert": "@tatsuhiro-t \nI'm seeing what I think is the same issue on the linux version. I ran aria2c -x 10 <link> for three different files. The md5 did not match the md5 provided by the company. I'm using 1.32.0, but it looks like you only made a change for the windows version, right?\nAlso, I just tried gunziping the files and got the following error:\ngzip: stdin: invalid compressed data--format violated\ntar: Unexpected EOF in archive\ntar: Unexpected EOF in archive\ntar: Error is not recoverable: exiting now. ",
    "Rotonen": "Based on what the Python fallocate egg is doing, one would have to implement it the Apple way. At least they do have a mechanism.\nhttps://github.com/trbs/fallocate/blob/6d251fd2354148028a231228beb54265449d7640/fallocate/_fallocatemodule.c#L56-L69. ",
    "q158073378252010": "@antbryan \nPart of the connection test passed! But there is connection test failed! !\nMy file link from Baidu cloud.\naria2c -c -s10 -k1M -x16 --enable-rpc=false -o \"Qt/Qt_For_Android/QtOnAndorid/\u597d\u7a0b\u5e8f\u54582015\u6700\u65b0Android\u5e94\u7528\u89c6\u9891\u6559\u7a0b/Loader\u7684\u81ea\u5b9a\u4e49(1).mov\" --header \"User-Agent: netdisk;5.3.4.5;PC;PC-Windows;5.1.2600;WindowsBaiduYunGuanJia\" --header \"Referer: http://pan.baidu.com/disk/home\" --header \"Cookie: BDUSS=9XcUlnaFZxUXFJSUV1WkNvSzBBSW5rY3FmU0FzYlFad2s1S3d1MXdKbmdieXBhSUFBQUFBJCQAAAAAAAAAAAEAAABPuXgXyq7I~aG2tv6htwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAODiAlrg4gJaam; pcsett=1510226439-f5916ada3785397ae466d713ce1304c7\" \"https://d.pcs.baidu.com/file/1662cacd8d73c0fb1c5fd5823186e9c1?fid=3105030567-250528-338730737644176&time=1510140110&rt=pr&sign=FDTAERVCY-DCb740ccc5511e5e8fedcff06b081203-krj%2B5yzpDmoH8fcklSiLrFZxsmE%3D&expires=8h&chkv=1&chkbd=1&chkpc=et&dp-logid=7231680902494061695&dp-callid=0&r=668477203\" --checksum=md5=1662cacd8d73c0fb1c5fd5823186e9c1. ",
    "apaperumbrella": "I have meet the same problem after installing airia2 successfully and adjusting connecting setting , I don't know how to resolve it, Have you resolve this question \uff1f. ",
    "PRosenb": "Many thanks @tatsuhiro-t for your reply, that's a good idea.\nI'm using Aria2 WebUI and this can be done there too with adding all files at once. It is not possible though to add more files after download has started.\nIs there also a global option to achieve this so that I could add files anytime?. ",
    "guangfnian": "Oh, I solved this by installing pkg-config. ",
    "SlyzertVoltrond": "You need to pass along your web browser's cookies file: https://aria2.github.io/manual/en/html/aria2c.html#cmdoption--load-cookies\nMine, for example, is located at .mozilla/firefox/s36sbfl7.default/cookies.sqlite (Firefox on Linux). Yes, I'm able to download that file by supplying --load-cookies. What web browser are you using? If it's Mozilla Firefox, see this thread to find the cookies file: https://support.mozilla.org/en-US/questions/1096646. Hmm, not sure what's keeping aria2 from fully getting the file. Maybe try downloading it partially through Firefox first, cancel it, and then download the link again using aria2 with --load-cookies option.\nWhat's the error message when aria2 quits with only 20KB downloaded?. ",
    "rfv1122": "Thank you very much, but I gave the cookie you said in my folder to aria2c, but it still doesn't download file success. Maybe there is another parameter need in that link. Can you download that link? How? My OS is Win 10 64bit. aria2c 1.32.. I already loaded the correct cookies.sqlite just after your previous post said. I am very sure it location is right. I am also able to download file, but the file after downloaded is only 20KB, not 48.31 MB, I also tried install fresh Firefox, download file is not correct, too. I think I miss some parameters.. Thanks for you always replying me, there is no error message shows. I fonund why can't I use load-cookies here. But I still encounter problem to use header, it always invalid. My RPC script is: http://jsoneditoronline.org/?id=4ee8fb1e0314e124bd3ab7d4b2ed19f1\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": \"123\",\n  \"method\": \"aria2.addUri\",\n  \"params\": [\n    [\n      \"http://dl51.qiannao.com/downfile/j00seng/e14c16ff?md5=2311bcd74e220d9c35bb81e80e098259# \"\n    ],\n    {\n      \"header\": {\n        \"language\": \"en_us\",\n        \"validCodeUrl\": \"http://qiannao.com:9090/view?module=service&action=queryValidCode\",\n        \"vid\": \"5337fb82\",\n        \"vid1\": \"71737c92a78d326a\"\n      }\n    }\n  ]\n}. I use this command, download is also failed: aria2c http://dl51.qiannao.com/downfile/j00seng/e14c16ff?md5=2311bcd74e220d9c35bb81e80e098259 --header=\"language: en_us\" --header=\"validCodeUrl: http://qiannao.com:9090/view?module=service&action=queryValidCode\" --header=\"vid: 5337fb82\" --header=\"vid1: 71737c92a63170ee\" --log-level=debug --log=aria2.log\nThis is aria2.log. vid1 is changing per times after I open this download page, I get it after normal browser download (download by browser is no problem).\nThe goal I want to do is use rpc to download such links.\nOS: Win 10 64bit, aria2 1.32.0 64bit.\n. Would somebody tell me this problem cause by me or it's something like a bug?. ",
    "adam1x": "Can you download it directly with the browser?\nWhat's the error message? If it's Failed to resolve the hostname y201.dygod.org, cause: nodename nor servname provided, or not known (like on my end), then either you need to switch to another DNS server or that particular link is down.. From the looks of your error message, aria2 can\u2019t resolve the domain name of your download link. Run a dig or nslookup on y201.dygod.org and see if your DNS server can resolve this domain name.\nWhich tool can you successfully download it with? And, are you sure it is downloading through the link directly and not P2P?. You see, you are downloading from a \"mirror\" and P2P, while the original source contributes nothing (0.00B) at all. This means the source is down, hence why aria2 or the browser, for that matter, can't download it.. It's easier to download YouTube videos with youtube-dl. Pass this argument along: --external-downloader aria2c if you need to use aria2.. Well what do you think? Without massively breaching its users' privacy (proactively scanning every user's hard drive for any \"valuable\" file), how do you expect a downloader to be able to do P2P with a non-BT/ed2k/.. link?\nAs for the \"mirror,\" if you don't supply an alternative link, aria2 won't know it. aria2, as well as a host of other tools, is designed to do exactly what its user tells it to do, which is to download that file from a given link. Nothing more than that.\n\nit means aria2 can only download from source?\n\nThat's also the definition of \"downloading.\". See: https://github.com/aria2/aria2/issues/986#issuecomment-325183535. Security issues aside, if you just want to access the web UI outside, you will need to set up port forwarding on your router (assuming the web UI is running on another machine), and you probably need a DDNS service for easy access to your home IP address (unless you get a static IP from your ISP, which is unlikely).. Well, there're always security risks involved when you are opening up your LAN to the entire internet. If you're not careful with configurations, or if your devices contain vulnerabilities, it's entirely possible for others to breach into your LAN. Not to mention there are bots scanning open networks looking for vulnerabilities 24/7.\nAt the very minimum, you should have set up a \"secret\" on your RPC, so that not everyone can (easily) send download jobs to overwhelm your server.. Most likely you already have one instance of aria2 running on port 6800.. ",
    "kang-mk": "The same is true of me, CPU occupancy rate is high, in exchange for version 1.32 normal. 1.33  WIN64. ",
    "sunrisewestern": "Thanks, I changed it back to --file-allocation=none and it works, but I'm using NTFS.. ",
    "Riajyuu": "This is really unlikely to happen... ",
    "txiaocao": "0.0...need ed2k. ",
    "cooppor": "+1. +1. ",
    "xjqxz2": "+1. ",
    "icedream2linxi": "+1. ",
    "iCsav": "@adam1x  Thanks, I figured that out recently. Forgot to close the issue. Sorry. And yes, I'm now using a DDNS service. Also, what security issues would I be facing by doing this?. ",
    "eromoe": "\n16 is plenty. Too easy to do DOS.\n\nLooks like aria2 are trying to protect the site host ...  If one really want to do DOS , you can not stop him by this.\nBut do you ever consider this situation:\nBecause official do not provide max-connections-per-server > 16 option,  so some bad guys build their one with virus and spread to people. People who doesn't know tech always tend to download the dangerous one when they found it does faster than offical (Hackers always advocate their version is much faster).\n. ",
    "trudnorx": "The maximum connection limit needs to be removed.\nIt clearly goes against the basic principle that the user should be in control.\nPeople clearly have a need for it. If they didn't observe a need for it with real-world usage, this wouldn't be so oft-requested. On the connections I have tested this on, more connections than 16 are needed to get the best speeds. People are experiencing this problem. Asking them to recompile it is inconvenient nonsense.\nIf we're speaking of a network application, of course it makes sense for the application not to be selfish and not hog bandwidth, e.g. by naturally adapting in order not to bother other applications, but hard-coded limits like this, that always apply even when they are not necessary, and that are enforced AGAINST the user, do not make any sense.\nOnce again, it is completely clear that there are many real-world cases where this is clearly needed to achieve benefits. Just think of home networks now reaching 100+Mbps commonly, and 500Mbps+ in many cases, and some protocols/server apps/configs being inefficient enough that they require multiple connections - on servers that can without a hitch handle more load.\nIf people don't need it, they can always choose not to use it. We're speaking of situations in which the user has specifically requested it.. ",
    "gzlock": "Server owners can setup they server connections limit, this is not a software needs to worry about.. ",
    "Youxikong": "v 1.33 win64\nTakes up about 30%.. Set seed-ratio and seed-time.\nbt\u4e0b\u8f7d\u8bbe\u7f6e\u4e00\u4e0b\u505a\u79cd\u7387\u548c\u505a\u79cd\u65f6\u95f4\uff0c\u5426\u5219\u9ed8\u8ba4\u65e0\u9650\u505a\u79cd\u3002. ",
    "whka": "\u78b0\u5230\u4e86\u4e00\u6837\u7684\u60c5\u51b5\uff0c\u8bf7\u95ee\u4f60\u89e3\u51b3\u4e86\u5417\uff1f. \u53ef\u4ee5\u8bd5\u8bd5\u8fd9\u4e2a\u6559\u7a0b\uff1ahttps://fhg90.com/p/289. ",
    "sweepdoff": "\u676f\u5177\uff0c\uff0c\u6211\u4e5f\u662f\uff0c\uff0c\u4e0d\u77e5\u9053\u600e\u4e48\u89e3\u51b3\uff01\nubuntu18  aria2 1.34. ",
    "LineSoftteam": "timeout\u5427. ",
    "bidiu": "Translation:\nThe maximum number of downloading threads is 16. My question is how to change the code letting thread reconnect when disconnected from the server.. ",
    "a48625a": "Thank you very much!. ",
    "shyaminayesh": "aria2 have cli, What kind cli are you looking for @HumanG33k ?\nalso seems like this is not a issue with aria2.. ",
    "HumanG33k": "aria2 have a cli can be use through network ? I don\u2019t remember i find doc about it.\n. ",
    "Retrochet": "Parameters in aria2.conf :\ndir=Aria2Data\ndisk-cache=32M\nfile-allocation=falloc\ncontinue=true\nmax-concurrent-downloads=1\nmax-connection-per-server=5\nmin-split-size=10M\nsplit=5\nmax-overall-download-limit=0\nmax-download-limit=0\nmax-overall-upload-limit=0\nmax-upload-limit=0\ndisable-ipv6=false\ninput-file=aria2.session\nsave-session=aria2.session\nsave-session-interval=60\nenable-rpc=true\nrpc-allow-origin-all=true\nrpc-listen-all=true\nevent-poll=select\nrpc-listen-port=6800. ",
    "37896778": "web vpn has open?. ",
    "LamCiuLoeng": "so how to fix ?. ",
    "HoseinGhanbari": "Thank you very much for your quick response!\nHow can I check that?\nAs i mentioned before, when the downloads started, I can't pause them using curl command; actually no response comes back from the rpc server.. The issue is that, after sending the pauseAll command through curl, the aria2c is going to do the 'Cache flush' and during completing this action, nothing happens in the console; therefore I thought something went wrong !\nI strongly recommend that add a simple log string immediately after calling pauseAll. It would be very helpful to show the user, aria2c is just doing the 'Cache flush'.\nIt's worth noting that, when I checked the log file, Cache flush has generated 984 lines before it's getting over !\nThank you so much for your help !\nThank you so much for this GREAT project ! . ",
    "joeky888": "Well, I can't reproduce on another computer.. If I downgrade to v1.32, everything works as expected.\nFull log:\nPS> choco install youtube-dl ffmpeg aria2 -y\nPS> $env:DOWNLOADARGS=\"--continue=true --check-certificate=false --content-disposition-default-utf8=true --max-tries=0 --max-concurrent-downloads=1000 --max-connection-per-server=16 --split=16 --min-split-size=1M --log log.txt\"\nPS> youtube-dl.exe --external-downloader aria2c --external-downloader-args $env:DOWNLOADARGS https://www.youtube.com/watch?v=XFLOh44P5z0 --verbose\n```sh\n[debug] System config: []\n[debug] User config: []\n[debug] Custom config: []\n[debug] Command-line args: ['--external-downloader', 'aria2c', '--external-downloader-args', '--continue=true --check-certificate=false --content-disposition-default-utf8=true --max-tries=0 --max-concurrent-downloads=1000 --max-connection-per-server=16 --split=16 --min-split-size=1M --log log.txt', 'https://www.youtube.com/watch?v=XFLOh44P5z0', '--verbose']\n[debug] Encodings: locale cp1252, fs mbcs, out cp65001, pref cp1252\n[debug] youtube-dl version 2017.11.15\n[debug] Python version 3.4.4 - Windows-10-10.0.16299\n[debug] exe versions: ffmpeg 3.4, ffprobe 3.4\n[debug] Proxy map: {}\n[youtube] XFLOh44P5z0: Downloading webpage\n[youtube] XFLOh44P5z0: Downloading video info webpage\n[youtube] XFLOh44P5z0: Extracting video information\n[youtube] {43} signature length 40.43, html5 player vflXHVFyU\n[youtube] {18} signature length 40.43, html5 player vflXHVFyU\n[youtube] {36} signature length 40.43, html5 player vflXHVFyU\n[youtube] {17} signature length 40.43, html5 player vflXHVFyU\n[youtube] {133} signature length 40.43, html5 player vflXHVFyU\n[youtube] {160} signature length 40.43, html5 player vflXHVFyU\n[youtube] {140} signature length 40.43, html5 player vflXHVFyU\n[youtube] {171} signature length 40.43, html5 player vflXHVFyU\n[youtube] {249} signature length 40.43, html5 player vflXHVFyU\n[youtube] {250} signature length 40.43, html5 player vflXHVFyU\n[youtube] {251} signature length 40.43, html5 player vflXHVFyU\n[youtube] XFLOh44P5z0: Downloading MPD manifest\n[debug] Default format spec: bestvideo+bestaudio/best\nWARNING: Requested formats are incompatible for merge and will be merged into mkv.\n[debug] Invoking downloader on 'https://r4---sn-3cgv-umbe.googlevideo.com/videoplayback?id=5c52ce878e0fe73d&itag=133&source=youtube&requiressl=yes&ms=au&mv=m&ei=uXAMWuD7KcPAqQGXk6D4Aw&initcwndbps=1033750&mm=31&pl=22&mn=sn-3cgv-umbe&ratebypass=yes&mime=video/mp4&gir=yes&clen=215365&lmt=1507304560044396&dur=188.040&signature=38DAC5DF11C6DB1C210497D15E14E0D72CB435E4.0C4E77776A53906C3A1D691E43B6352FBD7C9C17&key=dg_yt0&mt=1510764598&ip=118.233.202.54&ipbits=0&expire=1510786329&sparams=ip,ipbits,expire,id,itag,source,requiressl,ms,mv,ei,initcwndbps,mm,pl,mn,ratebypass,mime,gir,clen,lmt,dur'\n[download] Destination: Wizards in Winter - Trans-Siberian Orchestra-XFLOh44P5z0.f133.mp4\n[debug] aria2c command line: aria2c -c \"--continue=true\" \"--check-certificate=false\" \"--content-disposition-default-utf8=true\" \"--max-tries=0\" \"--max-concurrent-downloads=1000\" \"--max-connection-per-server=16\" \"--split=16\" \"--min-split-size=1M\" --log log.txt --out \"Wizards in Winter - Trans-Siberian Orchestra-XFLOh44P5z0.f133.mp4.part\" --header \"User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20150101 Firefox/47.0 (Chrome)\" --header \"Accept-Encoding: gzip, deflate\" --header \"Accept-Charset: ISO-8859-1,utf-8;q=0.7,;q=0.7\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,/*;q=0.8\" --header \"Accept-Language: en-us,en;q=0.5\" \"--check-certificate=true\" -- \"https://r4---sn-3cgv-umbe.googlevideo.com/videoplayback?id=5c52ce878e0fe73d&itag=133&source=youtube&requiressl=yes&ms=au&mv=m&ei=uXAMWuD7KcPAqQGXk6D4Aw&initcwndbps=1033750&mm=31&pl=22&mn=sn-3cgv-umbe&ratebypass=yes&mime=video/mp4&gir=yes&clen=215365&lmt=1507304560044396&dur=188.040&signature=38DAC5DF11C6DB1C210497D15E14E0D72CB435E4.0C4E77776A53906C3A1D691E43B6352FBD7C9C17&key=dg_yt0&mt=1510764598&ip=xxx.233.202.54&ipbits=0&expire=1510786329&sparams=ip,ipbits,expire,id,itag,source,requiressl,ms,mv,ei,initcwndbps,mm,pl,mn,ratebypass,mime,gir,clen,lmt,dur\"\n11/16 00:52:07 [NOTICE] Downloading 1 item(s)\n[#e748fb 0B/0B CN:1 DL:0B]\n```. PS> cat log.txt\nsh\n2017-11-16 00:52:07.973030 [INFO] [Context.cc:179] <<--- --- --- ---\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:180]   --- --- --- ---\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:181]   --- --- --- --->>\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:182] aria2 1.33.1\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:183] mingw-w64 5.0 (alpha) / gcc 6.3.0 20170516\n  built by  x86_64-pc-linux-gnu\n  targeting x86_64-w64-mingw32\n  on        Nov  8 2017 21:48:38\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:184] Windows 6.2 (x86_64) (6.2)\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:185] zlib/1.2.11 expat/2.2.4 sqlite3/3.20.1 GMP/6.1.2 c-ares/1.13.0 libssh2/1.8.0\n2017-11-16 00:52:07.973532 [INFO] [Context.cc:186] Logging started.\n2017-11-16 00:52:07.974034 [INFO] [SocketCore.cc:1579] Checking configured addresses\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: fe80::8897:592f:95f0:bad2%13\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: 169.254.186.210\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: fe80::f55c:9e9a:8502:9384%9\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: 169.254.147.132\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: fe80::ac43:1b16:557:93c3%16\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1640] Found configured address: 192.168.0.13\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: ::1\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1643] Not considered: 127.0.0.1\n2017-11-16 00:52:07.976540 [INFO] [SocketCore.cc:1651] IPv4 configured=1, IPv6 configured=0\n2017-11-16 00:52:07.976540 [NOTICE] [Context.cc:311] Downloading 1 item(s)\n2017-11-16 00:52:07.986226 [DEBUG] [RequestGroupMan.cc:591] 1 RequestGroup(s) added.\n2017-11-16 00:52:07.986730 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:07.986730 [DEBUG] [FeedbackURISelector.cc:162] Selected from normCands\n2017-11-16 00:52:07.986730 [DEBUG] [FeedbackURISelector.cc:84] FeedbackURISelector selected https://r4---sn-3cgv-umbe.googlevideo.com/videoplayback?id=5c52ce878e0fe73d&itag=133&source=youtube&requiressl=yes&ms=au&mv=m&ei=uXAMWuD7KcPAqQGXk6D4Aw&initcwndbps=1033750&mm=31&pl=22&mn=sn-3cgv-umbe&ratebypass=yes&mime=video/mp4&gir=yes&clen=215365&lmt=1507304560044396&dur=188.040&signature=38DAC5DF11C6DB1C210497D15E14E0D72CB435E4.0C4E77776A53906C3A1D691E43B6352FBD7C9C17&key=dg_yt0&mt=1510764598&ip=xxx.233.202.54&ipbits=0&expire=1510786329&sparams=ip,ipbits,expire,id,itag,source,requiressl,ms,mv,ei,initcwndbps,mm,pl,mn,ratebypass,mime,gir,clen,lmt,dur\n2017-11-16 00:52:07.986730 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:07.990248 [INFO] [AsyncNameResolverMan.cc:83] CUID#7 - Resolving hostname r4---sn-3cgv-umbe.googlevideo.com\n2017-11-16 00:52:08.044888 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:08.044888 [INFO] [AbstractCommand.cc:817] CUID#7 - Name resolution complete: r4---sn-3cgv-umbe.googlevideo.com -> 208.43.170.231\n2017-11-16 00:52:08.044888 [INFO] [HttpInitiateConnectionCommand.cc:123] CUID#7 - Connecting to 208.43.170.231:443\n2017-11-16 00:52:08.045396 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:09.046908 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:10.049241 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:11.053757 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:12.061455 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:13.062687 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:14.078920 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:15.082758 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:16.085755 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:17.087232 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:18.092603 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:19.097847 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:20.099348 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:21.104027 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:22.105958 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:23.112451 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:24.115885 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:25.119362 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:26.121615 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:27.126711 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:28.128487 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:0\n2017-11-16 00:52:29.049738 [DEBUG] [AbstractCommand.cc:184] CUID#7 - socket: read:0, write:0, hup:0, err:1\n2017-11-16 00:52:29.049738 [DEBUG] [ServerStat.cc:162] ServerStat: set status ERROR for r4---sn-3cgv-umbe.googlevideo.com (https)\n2017-11-16 00:52:29.050740 [INFO] [AbstractCommand.cc:368] CUID#7 - Restarting the download. URI=https://r4---sn-3cgv-umbe.googlevideo.com/videoplayback?id=5c52ce878e0fe73d&itag=133&source=youtube&requiressl=yes&ms=au&mv=m&ei=uXAMWuD7KcPAqQGXk6D4Aw&initcwndbps=1033750&mm=31&pl=22&mn=sn-3cgv-umbe&ratebypass=yes&mime=video/mp4&gir=yes&clen=215365&lmt=1507304560044396&dur=188.040&signature=38DAC5DF11C6DB1C210497D15E14E0D72CB435E4.0C4E77776A53906C3A1D691E43B6352FBD7C9C17&key=dg_yt0&mt=1510764598&ip=xxx.233.202.54&ipbits=0&expire=1510786329&sparams=ip,ipbits,expire,id,itag,source,requiressl,ms,mv,ei,initcwndbps,mm,pl,mn,ratebypass,mime,gir,clen,lmt,dur\nException: [AbstractCommand.cc:368] errorCode=1 URI=https://r4---sn-3cgv-umbe.googlevideo.com/videoplayback?id=5c52ce878e0fe73d&itag=133&source=youtube&requiressl=yes&ms=au&mv=m&ei=uXAMWuD7KcPAqQGXk6D4Aw&initcwndbps=1033750&mm=31&pl=22&mn=sn-3cgv-umbe&ratebypass=yes&mime=video/mp4&gir=yes&clen=215365&lmt=1507304560044396&dur=188.040&signature=38DAC5DF11C6DB1C210497D15E14E0D72CB435E4.0C4E77776A53906C3A1D691E43B6352FBD7C9C17&key=dg_yt0&mt=1510764598&ip=xxx.233.202.54&ipbits=0&expire=1510786329&sparams=ip,ipbits,expire,id,itag,source,requiressl,ms,mv,ei,initcwndbps,mm,pl,mn,ratebypass,mime,gir,clen,lmt,dur\n  -> [AbstractCommand.cc:313] errorCode=1 Network problem has occurred. cause:A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond.. Same error happens on cmd.exe, but Cygwin works fine.\nI will close this since it's probably my fault.. ",
    "adwords2008": "Thank you. I'll use aria2-1.33.1.tar.gz to generate it . ",
    "oh-ren": "Thanks!. Thanks. Eagerly awaiting #1079 :wink:. #1190. ",
    "narutowindy": "sorry i have set show-files=true  ... . ",
    "keremcankabadayi": "so, any plan for scheduling?. i can use macOS 10.13.2 Beta (17C79a) and my version is aria2 version 1.33.1\n\n. ",
    "cellargalaxy": "+1. ",
    "yi-ge": "+1\n. ",
    "zzz6519003": "people with a mac tends to use brew install aria2c to install aria2. ",
    "c2726139513": "Try this command \"autoreconf -i\". Thank you!. ",
    "nAnderYang": "thanks. ",
    "shichaohao": "Thank you. ",
    "madmax76": "That would be here.. ",
    "MRezaNasirloo": "Hi, It has nothing to do with BitTorrent,\nBut yes it a feature request to download a file from its beginning using aria2.\nI've noticed that the uget download manager is using aria2, so maybe you want to add a uget tag if u want, I'm gonna open an issue for this feature request there too.. ",
    "webbin": "@tatsuhiro-t Yes,I try again with another configuration file and it works.Thanks!. ",
    "lapsednun": "Hi tatsuhiro-t .\nNo, *.198.138.94 isn't qbittorrent's address. It's the address of the machine I was running Aria from!. ",
    "sy618": "I did a new test.\nInserting errors tracker in the BT-tracker list, between five rows.\nto verify that aria2 has a query request for all tracker.\nhttp://1.1.1.1:2710/announce\nhttp://2.2.2.2:2710/announce\nhttp://3.3.3.3:443/announce\nhttp://4.4.4.4:6969/announce\nhttp://5.5.5.5:80/announce\nhttp://6.6.6.6:80/announce\nhttp://7.7.7.7:80/announce\nhttp://8.8.8.8:8080/announce\nNew log aria2.log\nAs you can see, there is no error tracker like http://1.1.1.1:2710/announce in the log.\n It seems to be in a dead circle. Aria2 doesn't query all tracker.\n. ",
    "casouri": "No, they are not the last byte, and aria2c sends requests for different bytes, but all the requests have a length of one byte.\nLet me later reproduce it and give you more information.. I'm sorry, it's the problem of the server. I'll close it now :P. ",
    "zjlevin": "thanks a lot for your reply. You're developing a really useful software. Thank you!\n\u4e8e 2018\u5e741\u67084\u65e5 GMT+08:00\u4e0b\u53486:51:51, Tatsuhiro Tsujikawa notifications@github.com \u5199\u5230:\nIt is public IP which the tracker or DHT peer can access. So it is 128.100... in your case.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/aria2/aria2/issues/1104#issuecomment-355253125, or mute the threadhttps://github.com/notifications/unsubscribe-auth/Ahdv6QMZAvg0eQOu1GlAyoY5OafMk97Rks5tHK1HgaJpZM4RSnQL.\n--\nBest Regards\n. ",
    "1349422030": "i'm sure i write this sentense into aria2.conf.\u2026\u2026but it still doesn't work well in these PT site.\nemmmm\u2026\u2026i do not means ipv6 doesn't works, in fact, i can see ipv6 address in the peers sometimes, @tatsuhiro-t . ",
    "alanzhangzm": "@tatsuhiro-t my aria2 works perfectly with --async-dns=false. Thank you very much.. ",
    "v8u1er": "This is the aria2 log filtered by following command:\ntail -n 5000000 aria2.log | grep -i --after-context=5 --before-context=5 \"Scrubs.Season.2.part2\" > aria2-filtered.log\naria2-filtered.log\n. ",
    "heimoshuiyu": "I had found that add -V to restart can solve this problem.. ",
    "progmboy": "brew update\nbrew install aria2 \u662f\u6700\u65b0\u7684\nbrew \u7684\u5b89\u88c5\u5728 https://brew.sh/. ",
    "Jobsecond": "Release \u7684 bz2 \u538b\u7f29\u5305\u662f\u6e90\u7801\u5305\uff0c\u9700\u8981\u7f16\u8bd1\u624d\u80fd\u7528\u3002\n\u9996\u5148\u786e\u4fdd macOS \u5b89\u88c5\u4e86\u7f16\u8bd1\u5957\u4ef6\uff08\u901a\u8fc7 xcode-select --install \u5b89\u88c5\uff09\n\u7136\u540e\u89e3\u538b\u538b\u7f29\u5305\uff0ccd \u5230\u6e90\u7801\u76ee\u5f55\uff0c\u6309\u7167 README \u4e2d\u7684\u65b9\u6cd5\u7f16\u8bd1\u5b89\u88c5\uff08\u9ed8\u8ba4\u53c2\u6570\uff09\uff1a\nbash\n./configure\nmake\nmake install\n\u5f53\u7136\uff0c\u5982\u679c\u89c9\u5f97\u9ebb\u70e6\uff0c\u4e0d\u60f3\u81ea\u5df1\u7f16\u8bd1\u7684\u8bdd\uff0c\u8fd8\u53ef\u4ee5\u7528 Homebrew\uff0c\u81ea\u52a8\u89e3\u51b3\u4f9d\u8d56\u5e76\u5b89\u88c5\u3002\nbash\nbrew install aria2. ",
    "snadn": "@tatsuhiro-t this feat can be support\uff1f. ",
    "vermaarjun7": "@SumatraPeter  The log file is too big. I can post some part of it here if that helps. \nYes, I tried downloading using uGet and its failing as well.. @SumatraPeter I asked the person who hosted the dataset on the website. Anyways it's downloaded. I'll upload a drive link asap.. ",
    "anson2416": "I met the same issue. . ",
    "shuaihanhungry": "@Zoetic-Zephyr \nYou can use rm aria2.session && touch aria2.session and then sudo reboot instead.. ",
    "Kanjima": "I find out the problem is the version of aria2, all version beyond 1.8 will corrupt on windows xp, 1.8 will work OOB\u3002so i suggest you could still fix this bug to make the new version can still work on windows xp. thank you!. ",
    "tpzstamp": "I cleared the browser cache. The buttons come back.\nPlease close this issue. . ",
    "balupton": "Why is that the case when the out path is an absolute path? Seems only sensical if out path is a relative path.. For what it is worth, worked around this in the meantime with:\nhttps://github.com/balupton/dotfiles/blob/3beb245c86739909cb7fc6286fc6a09e0526e27e/.scripts/commands/down#L10-L12. ",
    "vcaputo": "@urhue I'm not familiar with this project but stumbled across this while searching google for that exact assert from GNU binutils.\nIn my case I was building something using mingw which depended on libSDL, and my problem has turned out to be the build host's native libSDL was being used instead of the cross-compiled version with the appropriate binary format.\nI see you have quite a number of libraries being linked in, you must ensure these are for the target host architecture and not the build host.\nMaybe that's of use.... ",
    "urhue": "@vcaputo Solved.\nAfter the upgrade from debian stable to debian testing, the glibc version also update to 2.6.\nThen this issue solved.. ",
    "TEDSON007": "That was the problem.. ",
    "Mosney": "ditto!. ",
    "Tmplt": "I totally missed that flag; that's exactly what I'm looking for. Thank you.. ",
    "http403": "I figured out that the server didn't pass the bittorrent content type in response. Closing the issue.. ",
    "jrdeng": "I have the same issue, any update?\nmy cmd:\naria2c --enable-rpc --rpc-allow-origin-all -c -D --log=/var/log/aria2.log --check-certificate=false --save-session=/var/local/aria2c.sess --save-session-interval=2 --continue=true --input-file=/var/local/aria2c.sess --rpc-save-upload-metadata=true --force-save=true --log-level=warn\nI ran it with user 'www-data', and the owner of session file is set to 'www-data'. \nlog file is OK, but just:  \n[ERROR] [SaveSessionCommand.cc:84] Failed to serialize session to '/var/local/aria2c.sess'.. I moved the session file from /var/local/  to  /var/aria2/  (which owner is www-data).  it just works!\ninteresting .... ",
    "sertraline": "/etc/systemd/system/aria2.service\n```\n[Service]\nExecStart=/usr/bin/aria2c --enable-rpc --rpc-listen-all --rpc-allow-origin\n         --save-session /home/user/.config/aria2/session.lock \n         --input-file /home/user/.config/aria2/session.lock \n         --conf-path=/etc/aria2.daemon\n```\nThis works for me. Running from root, aria2 will write sessions to any file in any path and still work in ocdownloader.. ",
    "tinguan": "recompile 1.33.1 or install 1.32.0 dmg package won't do any help. it just ran and quite with nothing, except i ran 'aria2c --help'.. ",
    "Fuzen-py": "I could not reproduce this\nHomebrew 1.5.7\nHomebrew/homebrew-core (git revision b33d; last commit 2018-03-03)\naria2 version 1.33.1. ",
    "jie2515": "Aria2c cann't download BT and MG. How to solve this problem ? Help me.. ",
    "KINDOU": "\u65e0\u6cd5\u8fde\u63a5rpc\u670d\u52a1\u5668\u554a. ",
    "kadagv": "--deferred-input true have not fixed the issue.  \nThe test script with >30 URLs (random/invalid domains) have started to spill notification after reading all URLs.. ",
    "amosbird": "Thanks. Actually what I need is a command line client on linux which could parse url as well as torrent, magnet , etc, and uses rpc to submit download requests instead of launching a new server.. ",
    "alive4ever": "There is aria2rpc script inside /usr/share/doc/aria2/xmlrpc which can be used as command line xmlrpc frontend (needs ruby xmlrpc).. ",
    "icyblade": "I have the same problem. Did you find the solution now?. ",
    "cactus": "This doesn't seem right to me. It seems like this would just break building with libressl for anything older than 2.7.\nWouldn't you want to check for LIBRESSL_VERSION_NUMBER, and if present (regardless of version), still set LIBRESSL_IN_USE=1.\nOnly /then/ check LIBRESSL_VERSION_NUMBER > 0x20700000fL and then define some other variable that informs openssl v1.1 api support?. ",
    "shlyakpavel": "You are probably looking for  libarea2. ",
    "AheadSnail": "@tatsuhiro-t  Website provides  android an  executable program how so small\uff1f thanks. ",
    "kingname": "same problem.. ",
    "billypon": "The value of 'max-connection-per-server' option must be string, not number!!!\nNow it works: addUri(['URL'], {'max-connection-per-server': '1'}). ",
    "clzls": "Broken English... I couldn't read it. Maybe you should just use your native language (Chinese maybe?). ",
    "Saint-Theana": "emmmm. ",
    "lonee8": "Why hasn't it been to May 14?. ",
    "kzw200015": "It didn't work and output the same error infomation. ",
    "maxmib": "same problem when I try to build aria2  on raspberry pi 3b. I have same problem on my raspberry pi 3,can you share how you solve it,thanks . ",
    "out0fmemory": "same problem. ",
    "OzAven": "Same Problem.. I do have \"ld\" installed appropriately in its default path.\nAny changes I can make in the Makefile to solve this one??\nThanks. ",
    "Achaean": "Or maybe an announcement maillist or a related RSS feed, or something?\nI agree that should be really convenient.\nTIA! :-)\n. ",
    "Polynomial-C": "This build failure also happens on Linux.. ",
    "594552583": "how to build openssl statically linked. \nYou mean I need to compile an openssl separately.\nlike this \ncd openssl-1.0.2m/\nPKG_CONFIG_PATH=$PREFIX/lib/pkgconfig/ LD_LIBRARY_PATH=$PREFIX/lib/ CC=$HOST-gcc CXX=$HOST-g++ ./Configure linux-armv4 $CFLAGS --prefix=$PREFIX shared zlib zlib-dynamic -D_GNU_SOURCE -D_BSD_SOURCE --with-zlib-lib=$LOCAL_DIR/lib --with-zlib-include=$LOCAL_DIR/include --enable-static --disable-shared\n. /home/test/android-ndk-r14b/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: cannot find -lpthread\n/home/test/android-ndk-r14b/toolchain/bin/../lib/gcc/arm-linux-androideabi/4.9.x/../../../../arm-linux-androideabi/bin/ld: error: cannot find -lrt\n. could you tell me how to static link openssl  sir\ndo you have any  linux scrtipt\ni use this way but i think its wrong.\nPKG_CONFIG_PATH=$ANDROID_HOME/usr/local/lib/pkgconfig/ LD_LIBRARY_PATH=$ANDROID_HOME/usr/local/lib/ CC=arm-linux-androideabi-gcc CXX=arm-linux-androideabi-g++ ./Configure linux-armv4 \"-march=armv7-a -mtune=cortex-a9\" --prefix=$ANDROID_HOME/usr/local shared zlib zlib-dynamic -D_GNU_SOURCE -D_BSD_SOURCE --with-zlib-lib=$LOCAL_DIR/lib --with-zlib-include=$LOCAL_DIR/include. ok my dear friend . I've solved the problem.\ni have know how to build openssl static link\nI read this blog.  finally i find the way.\nthanks \nhttp://haojiasoft.com/2017/11/11/NDK-Openssl%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BE%8B/\n. ",
    "mosynaq": "On Linux, you can use apt-metalink to speed up apt and/or apt-get. But I'd REALLY appreciate pip/conda/git speed up!\nHey @tatsuhiro-t, could you do this too? \nThanks!. ",
    "JohnCoconut": "Is it one time behavior?Have you tried other images from ws1.sinaimg.cn? Is it the case that aria2 cannot resolve any links to ws1.sinaimg.cn? What about other domains?. Can you try synchronous dns mode?\nbash\naria2c --async-dns=false  http://ws1.sinaimg.cn/large/6a155794ly1fkx1uhxfz6j2039012wen.jpg. ",
    "sbdx": "Any URL not works , prompting the same error.\nIf used IP to down ,it works.\nI'm very confused. wget resolve the domain is right , means the system dns is ok.\n. root@MyNAS:~# aria2c --async-dns=false  http://ws1.sinaimg.cn/large/6a155794ly1fkx1uhxfz6j2039012wen.jpg\naria2c: unrecognized option '--async-dns=false'\nUsage: aria2c [OPTIONS] [URI | MAGNET | TORRENT_FILE | METALINK_FILE]...\nSee 'aria2c -h'.. ",
    "Star-Track": "I also meet the same problem too.. ",
    "brooklyn097": "I'm facing the same problem. ",
    "psycholyzern": "Any solution?. ",
    "kunaltyagi": "I updated the base image from Ubuntu 16.04 to Ubuntu 18.04 and the ecosystem seems to have changed such that the error has vanished. There's another error (this time from automake) but I'm trying to work around it. \n\nGood news: The docker image (kunaltyagi/aria2c) should work for executable aria2c as before\nUnchanged: There is no static build. The image has the same extra baggage (from cpp-dev). \n",
    "NathanLee302": "Did you mean how to download two or more torrent files at a time?. ",
    "leoleoasd": "@NathanLee302 Yes.\n@piaoyun \u8bf7\u4e0d\u8981\u5728GITHUB \u975e\u4e2d\u6587repo\u4e0b\u4f7f\u7528\u4e2d\u6587\u3002 / Plz don't use Chinese in English repo.. Solved. I can change the hard coded value in src/OptionHandlerFactory.cc and rebuild it.\nHope i can help others.. ",
    "cqjjjzr": "You can try run x86_64-w64-mingw32-g++ -shared -o libaria2.dll *.o -Wl,--export-all-symbols,--output-def,libaria2.def command in /src/.lib directory,\nbut you need to add all the lib used in aria2 to the command, so I used x86_64-w64-mingw32-g++ -shared -mwindows -o libaria2.dll *.o -Wl,--export-all-symbols,--output-def,libaria2.def  -lwsock32 -lgdi32 -lwinmm -liphlpapi -lpsapi -lxml2 -lsqlite3 -lpthread -lsecur32 -lssh2 -L/usr/local/x86_64-w64-mingw32/lib -lz -lbcrypt -lcrypt32 -lcares -lws2_32 -L../../deps/wslay/lib/.libs -lwslay, your version may be different.. Also, idk why but the dll generated is extremely big. about 100+MB.. ",
    "RevolverOcelotA": "@tatsuhiro-t I was using a server on lan,but you can test with openssl(1):\n$mkdir /tmp/test && cd /tmp/test\n$openssl req -x509 -newkey rsa:2048 -keyout sign.key -out sign.crt -nodes #generate CA certificate\n$openssl req -new -newkey rsa:2048 -keyout localhost.key -out localhost.req -nodes\n$openssl x509 -CAcreateserial -CAkey sign.key -CA sign.crt -req -in localhost.req -out localhost.crt #type localhost as Comman Name in interactive interface\n#openssl s_server -key localhost.key -cert localhost.crt -accept 443 -www  #Use a higher port number without root\n$curl https://localhost --cacert /tmp/test/sign.crt  #curl works well in Arch Linux\n$aria2c --no-conf --ca-certificate=/tmp/test/sign.crt  https://localhost #aria2c doesn't work :(\n06/05 17:41:06 [NOTICE] Downloading 1 item(s)\n06/05 17:41:06 [ERROR] CUID#7 - Download aborted. URI=https://localhost\nException: [AbstractCommand.cc:351] errorCode=1 URI=https://localhost\n  -> [SocketCore.cc:1015] errorCode=1 SSL/TLS handshake failure: hostname does not match\n06/05 17:41:06 [NOTICE] Download GID#bc52623affd5a435 not complete: \nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\nbc5262|ERR |       0B/s|https://localhost\nStatus Legend:\n(ERR):error occurred.\nSorry for my poor english.. ",
    "hklcf": "@monkey008 I created a shell script to install aria2, hope can help you.\n```sh\n!/bin/sh\nFor Ubuntu\napt update\napt install -y wget unzip screen gcc libgnutls-dev nettle-dev libgmp-dev libssh2-1-dev libc-ares-dev libxml2-dev zlib1g-dev libsqlite3-dev pkg-config\nwget https://github.com/aria2/aria2/releases/download/release-1.34.0/aria2-1.34.0.tar.gz\ntar -zxvf aria2-1.34.0.tar.gz\ncd aria2-1.34.0\n./configure\nmake && make install\n```. torrent problem :(. ",
    "CNAmira": "Apply patch from commit e8e04d6f22a507e8374651d3d2343cd9fb986993 may help you.. ",
    "Mno-hime": "illumos man page (http://illumos.org/man/3c/posix_fallocate) does not mention that, but Solaris one says: \"The posix_fallocate() function is supported only for regular files residing on UFS filesystems. Attempts to use it with files on any other filesystem type results in an EINVAL error.\" I think it could be true for illumos as well. I ran the test on ZFS. . ",
    "gitchs": "aria2 will pass 3 arguments to the script.\n- arguments[0] is GID\n- arguments[1] is the number of the files\n- arguments[2] is first filename\nReferences\n\nhttps://github.com/aria2/aria2/blob/master/src/util.cc#L2336\nhttps://aria2.github.io/manual/en/html/aria2c.html#event-hook\nFor HTTP, FTP, and SFTP downloads, usually the number of files is 1. BitTorrent download can contain multiple files. If number of files is more than one, file path is first one.\n\nWorkaround\nIf you run aria2 in rpc mode, call aria2.tellStatus with GID to fetch file list first.\n. Why not try -d option.\nhttps://aria2.github.io/manual/en/html/aria2c.html#cmdoption-d. why not pass option \"--out\" to aria2?. ",
    "slackhead": "Thanks. I'd forgotten all about this.. Thanks. I'll check it out.. That works great. Many thanks for the suggestion.\nI guess this can be closed now then.. ",
    "salahoued": "@slackhead try Persepolis download manager\nhttps://persepolisdm.github.io/. ",
    "iG8R": "This issue was solved - just used \"token\" instead of \"user/password\" for the authorization.. ",
    "Aleksej-Kozlov": "Confirm that. I have the same problem.\nIt started a few days ago. Maybe, after windows installed updates.\nMy system is Win7 64bit too. Tried versions of aria2c 1.32 from cygwin64 and 1.34 from github 32bit and 64bit (aria2-1.34.0-win-64bit-build1.zip, aria2-1.34.0-win-32bit-build1.zip).\nMy commandline:\naria2c --input-file=\"list.tmp\" --max-concurrent-downloads=100 --bt-stop-timeout=2700 --bt-metadata-only --bt-save-metadata --enable-dht --dht-entry-point=router.bittorrent.com:6881 --listen-port=6996 --dht-listen-port=6996 --dht-file-path=\"dht.dat\" --summary-interval=0\nAria2c at first works fine, then tries to stop by timeout. Last lines in console:\n07/27 13:52:28 [NOTICE] GID#49870cc05b6e3ed7 Stop downloading torrent due to --bt-stop-timeout option.\n07/27 13:52:28 [NOTICE] Download GID#49870cc05b6e3ed7 not complete: [METADATA]25f3958ab00892481b50414b9d449cf3b6c001dc\nand than aria2c freezed and cannot be stopped anyway.\nI tried to change timeout param, it works ok with small timeout, but when I use 2700 (45 min) it freezed 100%.. Seems the problem is in windows update KB4338818.\nUninstalled it and now aria2c works fine again.. control panel - programs and components - installed updates (at the left column). ",
    "nmr50": "Aleksej-Kozlov: now it's time to spread the knowledge - how to uninstall certain Windows updates like KB4338818 :)) Thanks in advance !. Aleksej: I did not check aria2c behavior yet, but after uninstalling this shitty KB4338818 I resolved another really nasty problem related to whole network, and another program (ydl) - when it was trying to retrieve video+audio from video hoster, it caused to stop after a few seconds with \"Only one usage of each socket address (protocol/network address/port) is normally permitted\" message..\nAfter removing KB4338818 this \"socket\" error has gone away, so - THANK YOU very much !. ",
    "Coolerfall": "Close this issue for my error configure. ",
    "wolfhong": "+1. ",
    "rainyl": "is there any solution??. ",
    "Bob0505": "+1 with install RASPBIAN STRETCH WITH DESKTOP (2018-06-27) raspberry PI2.. ",
    "CodeFarmer1995": "@wolfhong @rainyl @Bob0505 \nWe can locate the file [getrandom_linux.c] (https://github.com/aria2/aria2/blob/master/src/getrandom_linux.c) and find this:\n\nifdef HAVE_GETRANDOM\n/* libc already has support */\nread = getrandom(p, buflen, 0);\n\nelse  // HAVE_GETRANDOM\n/* libc has no support, make the syscall ourselves */\nread = syscall(SYS_getrandom, p, buflen, 0);\n/* Some libc impl. might mess -ERESTART up */\nif (read == -EINTR || read == -ERESTART) {\n  /* ERESTART, like EINTR, should restart the call, later, so handle both\n   * the same way.\n   */\n  errno = EINTR;\n  read = -1;\n}\n/* Some other non-interrupted error happened, put error code into errno and\n * switch read to -1 (return value).\n */\nif (read < -1) {\n  errno = -read;\n  read = -1;\n}\n\nendif // HAVE_GETRANDOM\n\nThe latest libc actually has support for getrandom(random.h).But my OS(CentOS Linux release 7.5.1804 (Core)  3.10.0-862.11.6.el7.x86_64) dosen't include this header file nither.\nBut I think it is OK to just comment it, as the comment\n\nlibc has no support, make the syscall ourselves\n\nsays, we can call the syscall.It works for me.\n. ",
    "ZQQ1024": "+1, same error on my several Ubuntu 16.04s. ",
    "Lightdisappear": "Just comment the error line(getrandom_linux.c:40).\nIt works for me.. ",
    "gzlittle": "I find random.h at /usr/include/linux/random.h, so I edit src/getrandom_linux.c\n#include <sys/random.h>\nto\n#include </usr/include/linux/random.h>. ",
    "ifengchao": "My fault, gcc path error...\nActually gcc 4.8.3 works.\naria2 version 1.34.0\nCopyright (C) 2006, 2017 Tatsuhiro Tsujikawa\nThis program is free software; you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation; either version 2 of the License, or\n(at your option) any later version.\nThis program is distributed in the hope that it will be useful,\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\nGNU General Public License for more details.\n Configuration \nEnabled Features: BitTorrent, GZip, HTTPS, Message Digest, Metalink, XML-RPC, SFTP\nHash Algorithms: sha-1, sha-224, sha-256, sha-384, sha-512, md5, adler32\nLibraries: zlib/1.2.8 libxml2/2.9.2 OpenSSL/1.0.2a libssh2/1.4.3\nCompiler: gcc 4.8.3\n  built by  x86_64-pc-linux-gnu\n  targeting mipsel-openwrt-linux-gnu\n  on        Aug  8 2018 12:12:06\nSystem: Linux 3.0.8 #1 PREEMPT Wed Aug 8 14:35:31 CST 2018 mips\nReport bugs to https://github.com/aria2/aria2/issues\nVisit https://aria2.github.io/. ",
    "NingAnMe": "When you see this, trying one more time will solve it.. ",
    "AntonD-mobilmir": "here is log and segment file.zip ackquired after restarting aria2c with logging. ",
    "mikepurvis": "Okay, cool. That's good to know that that's the intention. It may be that what I say was some other issue, but I'll keep my eyes out.\nThanks again for a great tool!. ",
    "tr4usut": "Add a line before \"exit 0\" in System/Startup Luci web:\n\"aria2c --enable-rpc --daemon\"\nwork for me. Im on pandora too.\n. ",
    "MoorayJenkins": "I also get this surprisingly when I download torrents, seems to produce no bad effect.\nWhen I go the link which threw the error occasionally I get:\n\nd14:failure reason19:announcing too faste. \n",
    "JuvenRui": "CentOS 7, make aria2-1.34.0.tar.gz is same error. And aria2-1.33.1 make install success.. homebrew. rpc-save-upload-metadata=false. > @JuvenRui thx, the .torrent file was automatically deleted, but it doesn't take effect on .aira2 file, anything about that?\nauto-save-interval=SEC     Save a control file(*.aria2) every SEC seconds.\n                              If 0 is given, a control file is not saved during\n                              download. aria2 saves a control file when it stops\n                              regardless of the value.. ",
    "chengmeng2018": "Like you, I don't know how to solve it.. Haha, I solved it,\nPlease open the file \\ aria2-1.34.0 \\ src \\ bignum.h\nThen add std :: in front of make_unique\nA total of 4 revisions\nAt 34 35 39 44 lines\n30~50lines show\n`private:\n  std::unique_ptr buf_;\npublic:\n  inline ulong() : buf_(std::make_unique(dim)) {}\n  inline ulong(size_t t) : buf_(std::make_unique(dim))\n  {\n    memcpy(buf_.get(), (char_t)&t, sizeof(t));\n  }\n  inline ulong(const ulong& rhs) : buf_(std::make_unique(dim))\n  {\n    memcpy(buf_.get(), rhs.buf_.get(), dim);\n  }\n  explicit inline ulong(const char_t data, size_t size)\n      : buf_(std::make_unique(dim))\n  {\n    if (size > dim) {\n      throw std::bad_alloc();\n    }\n    memcpy(buf_.get(), data, size);\n  }\n`. ",
    "Naville": "Taking a look at my saved session file:\nhttps://******.pdf  \n gid=db11c450d2d111e4\n timeout=20\n dir=**********\n out=******.pdf \n allow-overwrite=false\n continue=true\n auto-file-renaming=false\n remote-time=true\n max-connection-per-server=4\nAnd this GID contains only [0-9a-fA-F]. ",
    "uKER": "It's aria2 version 1.32.0\nProbably not the latest one I guess?\nI got it with UUPDump.\n\nDe: Tatsuhiro Tsujikawa notifications@github.com\nEnviado: mi\u00e9rcoles, 31 de octubre de 2018 12:50\nPara: aria2/aria2\nCc: uKER; Author\nAsunto: Re: [aria2/aria2] Typo (#1285)\ngrep \"Verifing\" returned empty result. Which version are you using?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/aria2/aria2/issues/1285#issuecomment-434737391, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AIBRHSPpAassThMZfUroO2VJaZMG7I8hks5uqcbegaJpZM4YBNyS.\n. Here's a screenshot of the results of searching for \"Verifing\" on the Aria2 folder I have.\nCome to think about it, Aria2UI is probably a separate project, not owned by you, isn't it?\n\n. Yep. I just noticed. I'll see to let them know.\nSorry for the misunderstanding.. ",
    "fulldecent": "I thought that this was just a minor inconvenience. But now I see it is an actual problem. After renaming 9999 files then all further downloads will fail.\n. ",
    "zengxs": "You can install Homebrew, and then install aria2 via brew:\n~~~sh\nbrew install aria2\n~~~. Translation:\n\nI have a computer running aria2 in a LAN, how can I manage it on another computer.. You can enable jsonrpc, and use AriaNg to manage it.\n\n\nSome guides:\n* http://www.senra.me/download-artifact-aria2-create-your-own-offline-download-server/. ",
    "JadeVane": "@JuvenRui thx, the .torrent file was automatically deleted, but it doesn't take effect on .aira2 file, anything about that?. ",
    "Duke1": "You need add token.\nws.send(JSON.stringify({\n              jsonrpc: '2.0',\n              id:'qwer',\n              method:'aria2.getVersion',\n              params:['token:your-password']\n            })\n        );. ",
    "lzbgt": "@recolic it reports no progress when downloading magnet resource, even added BT servers.. ",
    "runcspelex": "Ready to use blocklist import from url, at torrent add.\nhttps://cloud.githubusercontent.com/assets/5309456/12969755/22cde538-d03a-11e5-9e1b-17724bec4106.png\nthere are nice collections ..\nhttp://john.bitsurge.net/public/biglist.p2p.gz. ",
    "hartwork": "PS: Is there a way to make aria2 \"follow\" Metalink content in this very case?. PS: Found the docs on --follow-metalink=true|false|mem with Default: true but it seems broken or I misunderstand it. It's also rejected when passed on the comment line:\n```console\n/usr/bin/aria2c -d /usr/portage/distfiles -o meld-3.18.3.tar.xz --allow-overwrite=true --max-tries=5 --max-file-not-found=2 --user-agent=Wget/1.19.5 --split=1 --max-connection-per-server=1 --uri-selector=inorder --follow-metalink=mem https://download.gnome.org/sources/meld/3.18/meld-3.18.3.tar.xz\n/usr/bin/aria2c: unrecognized option '--follow-metalink=mem'\nUsage: aria2c [OPTIONS] [URI | MAGNET | TORRENT_FILE | METALINK_FILE]...\nSee 'aria2c -h'.\n``\nI don't see why, please advise.. > aria2 by default follows metalink. Doesn'taria2c https://download.gnome.org/sources/meld/3.18/meld-3.18.3.tar.xz` work for you?\nIt downloads a .meta4 file for me, see:\n```\naria2c https://download.gnome.org/sources/meld/3.18/meld-3.18.3.tar.xz\n11/17 15:58:31 [NOTICE] Downloading 1 item(s)\n11/17 15:58:32 [NOTICE] Download complete: /tmp/tmp.HShTfBCXCY/meld-3.18.3.tar.xz.meta4\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n10f3d8|OK  |        n/a|/tmp/tmp.HShTfBCXCY/meld-3.18.3.tar.xz.meta4\nStatus Legend:\n(OK):download completed.\n``. I just found that my system aria2 was compiled with--disable-metalink. If I recompile--enable-metalink, things look a lot better, even--follow-metalink=memis recognized and seems to work well, pretty cool.\nCould it be that despite--disable-metalinkconfiguration aria2 sent some Accept header to the server that still asks for Metalink? My guess would be that--disable-metalink` needs to affect one place more in the code. What do you think?. Cool, thanks for the quick fix!. ",
    "KeithScheiwiller": "My bad, it looks like pause is intended to be used when submitting an individual task.. ",
    "mnixry": "Okay,I fixed this First Problem,Using master branch to compile it.\nBut I had the Second Problem(What a bad luck!):\nshell\nmake\n...\n  CC       getrandom_linux.lo\ngetrandom_linux.c:40:24: fatal error: sys/random.h: No such file or directory\n #include <sys/random.h>\n                        ^\ncompilation terminated.\nMakefile:2275: recipe for target 'getrandom_linux.lo' failed\nmake[3]: *** [getrandom_linux.lo] Error 1\nmake[3]: Leaving directory '/root/aria2-master/src'\nMakefile:2340: recipe for target 'all-recursive' failed\nmake[2]: *** [all-recursive] Error 1\nmake[2]: Leaving directory '/root/aria2-master/src'\nMakefile:555: recipe for target 'all-recursive' failed\nmake[1]: *** [all-recursive] Error 1\nmake[1]: Leaving directory '/root/aria2-master'\nMakefile:466: recipe for target 'all' failed\nmake: *** [all] Error 2\nAnd I fixed \nComment the #include<sys/random.h> in src/getrandom_linux.c\nAt last,I fixed all problems occurred in compile Aria2c.\nWhat more bug in this!\nHope it can changed in one day.. Check the permission of that folder,and make sure that folder exist and writeable.\nAnd,Please use ```to spilt the config file.. ",
    "Ramzec": "\nAm I missing a library to build?\n\nYes\n\n/usr/bin/ld: cannot find -llzma. \n",
    "dx-daniel": "this problem occurs after I update the docker image\nthe prev version aria2 1.32.0 is OK. ",
    "yannxia": "i also too, 1.34.0 add --async-dns=false is not work. ",
    "ywjdlq": "try disable-ipv6=true. ",
    "twzping": "\ntry disable-ipv6=true\n\nI have the same problem.\nIt worked.Thank you.. ",
    "Melody713": "\ntry disable-ipv6=true\n\nThank you, It worked!. ",
    "neheb": "That error is...bizzare as it works fine locally.. This is ready for pulling.. ",
    "Mapaler": "https://github.com/Mapaler/PixivUserBatchDownload/wiki/%E8%BF%9C%E7%A8%8B%E4%B8%8B%E8%BD%BD\n\u522b\u8bf4\u5c40\u57df\u7f51\uff0c\u53ea\u8981\u6709\u516c\u7f51IP\uff0c\u5168\u7403\u90fd\u53ef\u4ee5\u63a7\u5236. @baskice Do you allow all origin?\n```ini\n\u5f00\u542fRPC\nenable-rpc=true\nRPC\u76d1\u542c\u6240\u6709\u8bf7\u6c42\nrpc-listen-all=true\nRPC\u5141\u8bb8\u6240\u6709\u6765\u6e90\u8bf7\u6c42\uff0c\u5982\u679c\u975e\u5c40\u57df\u7f51\u8bbf\u95ee\u4e00\u5b9a\u8981True\nrpc-allow-origin-all=true\ntoken\u9a8c\u8bc1\nrpc-secret=xxxx\n``` . Your aria2 ip is 192.168.1.1, on the Router\uff1fYou should open the     port in Firewall.\nOr if your aria2 run on Windows, see this page to open Firewall.\nhttps://github.com/Mapaler/PixivUserBatchDownload/wiki/%E8%A7%A3%E9%99%A4Aria2%E7%9A%84%E9%98%B2%E7%81%AB%E5%A2%99%E9%99%90%E5%88%B6. \u4f60\u53ef\u4ee5\u5148\u6e05\u9664\u6389\u9519\u8bef\u4efb\u52a1\u554a\u3002\u6709\u7684\u53ef\u4ee5\u7528\u6e05\u9664\u547d\u4ee4\u6765\u6e05\u9664\uff08\u4e0b\u8f7d\u4e00\u534a\u5931\u8d25\u7684\u90a3\u79cd\u4e0d\u884c\uff09\uff0c\u6709\u7684\u53ef\u4ee5\u53bbsession\u6587\u4ef6\u91cc\u5220\u9664\u3002. \u524d\u7aef\u53ef\u4ee5\u901a\u8fc7rpc\u53c2\u6570\u4fee\u6539aria2\u7684\u5f53\u524d\u73af\u5883\u8bbe\u7f6e\u7684\uff08\u53ea\u5bf9\u5f53\u524d\u8fd0\u884c\u7684\u6709\u6548\uff09\uff0c\u4f46\u4e0d\u662f\u6240\u6709\u7684\u4fee\u6539\u90fd\u8d77\u4f5c\u7528\uff0c\u6709\u5c11\u91cf\u8bbe\u7f6e\u5fc5\u987b\u5728\u542f\u52a8aria2\u7684\u53c2\u6570\u91cc\u8bbe\u7f6e\u3002. ",
    "baskice": "I just did same thing as you wish. Set the rpc path (in AriaNG/yaaw) to something like: http://token:xxx@192.168.1.1:6800/jsonrpc\nIf that does not work, then check the \"server\" firewall. Make sure that the 6800 port is accessible. You may test connection by http://token:xxx@192.168.1.1:6800/jsonrpc?jsoncallback=1 . info like \"1({\"id\":null,\"jsonrpc\":\"2.0\",\"error\":{\"code\":-32600,\"message\":\"Invalid Request.\"}})\" means port connectable.\nBTW, aria2c.com does not support any private ip as rpc in my test. So avoid aria2c.com.. Yes\nenable-rpc=true\nrpc-allow-origin-all=true\nrpc-listen-all=true\nevent-poll=select\nrpc-listen-port=6800\nrpc-secret=xxx. ",
    "rjp0817": "aria2 \u5de5\u5177\u91cd\u542f\u65f6\uff0c\u4f1a\u5c06\u4e0a\u6b21\u7684\u9519\u8bef\u4efb\u52a1\u5168\u90e8\u91cd\u8bd5\u4e00\u904d\uff0c\u5982\u4f55\u907f\u514d\u8fd9\u4e2a\u95ee\u9898\uff0c\u6211\u53ea\u9700\u8981\u5728aria\u91cd\u542f\u65f6\uff0c\u5c06\u672a\u5b8c\u6210\u7684\u4efb\u52a1\u7ee7\u7eed\u4e0b\u8f7d\u5373\u53ef. ",
    "kdlsw": "\n\u524d\u7aef\u53ef\u4ee5\u901a\u8fc7rpc\u53c2\u6570\u4fee\u6539aria2\u7684\u5f53\u524d\u73af\u5883\u8bbe\u7f6e\u7684\uff08\u53ea\u5bf9\u5f53\u524d\u8fd0\u884c\u7684\u6709\u6548\uff09\uff0c\u4f46\u4e0d\u662f\u6240\u6709\u7684\u4fee\u6539\u90fd\u8d77\u4f5c\u7528\uff0c\u6709\u5c11\u91cf\u8bbe\u7f6e\u5fc5\u987b\u5728\u542f\u52a8aria2\u7684\u53c2\u6570\u91cc\u8bbe\u7f6e\u3002\n\n\u8c22\u8c22. ",
    "abergmann": "CVE-2019-3500 was assigned to this issue.. ",
    "kyoshidajp": "I'm not sure if this is the vulnerability. But if so, I noticed that Authorization and Cookie headers are included in the log file, too.\nFor example, run the following command.\naria2c --header='Cookie: key=value' \\\n    --header='Authorization: Digest username=\"admin\"' \\\n    --log=file \\\n    http://example.com\nthen the following data is in the log file.\n```\nGET / HTTP/1.1\nUser-Agent: aria2/1.34.0\nAccept: /,application/metalink4+xml,application/metalink+xml\nHost: example.com\nWant-Digest: SHA-512;q=1, SHA-256;q=1, SHA;q=0.1\nCookie: key=value\nAuthorization: Digest username=\"admin\"\n```. ",
    "Hippeys": "up!. ",
    "arthurafarias": "Could you supply more information? How can I reproduce this?. ",
    "amilino": "Sorry, my bad. It looked like torrents which I used at that time didn't had seeders so the download never started.. ",
    "mayswind": "Thanks for @no1xsyzy's reminder. I'm the author of AriaNg, which is a aria2 web frontend created in 2016. Negibox has stolen the source code of AriaNg, because it obviously contains full aria2 and AriaNg, and just modifies the gui color but does not include both aria2 and AriaNg's licenses in it.. @hugetiny If you don't want to be a thief, please put the licenses of all projects you use in your project. \uff08\u5982\u679c\u4f60\u4e0d\u60f3\u53d8\u6210\u5c0f\u5077\uff0c\u8bf7\u9644\u52a0\u539f\u9879\u76ee\u7684\u534f\u8bae\u3002\uff09Your behavior is not so-called \"OpenSource with Chinease characteristics\", please don't discredit Chinese characteristics. \uff08\u4f60\u7684\u884c\u4e3a\u4e0d\u662f\u6240\u8c13\u7684\u201c\u4e2d\u56fd\u5f0f\u5f00\u6e90\u201d\uff0c\u8bf7\u4e0d\u8981\u62b9\u9ed1\u4e2d\u56fd\u5f0f\uff09. ",
    "ceres-c": "Managed to get it to work via https://github.com/armills/jsonrpc-websocket Maybe you could change examples to use this library\nIf I finish this script I'll publish it on my account and could serve as an example implementation.\nThanks. ",
    "buttonpushertv": "I forgot to include the version of aria2 on Raspibian Stretch is 'aria2 version 1.30.0'\nNot sure if that matters. Or is there a server I need to add to apt-get to get the latest version.. It took me a while to be able to get back to test this.\nAfter running sudo systemctl start aria2\nIt simply returned to a command prompt. Attempts to load the web-ui returned a failed connection.\nAfter running the journalctl commands, the '-b' command returned these 'aria2' related lines among all the other system stuff :\nFeb 11 11:23:08 bitppi4 systemd[1]: Starting LSB: aria2c RPC init script....\nFeb 11 11:23:08 bitppi4 systemd[1]: Started LSB: aria2c RPC init script..\nAnd the '-u aria2.service' returned the same info.\nIn /etc/rc3.d I see this:\nlrwxrwxrwx  1 root root   15 Feb  7 09:43 S01aria2 -> ../init.d/aria2\nI tried uninstalling and then re-installing aria2 from scratch and it still won't auto launch. The only way I can get it to work is to enter this, manually - after boot:\nsudo aria2c --daemon=true --enable-rpc --rpc-listen-all --conf-path=/home/pi/.aria2/aria2.conf &\nI have set raspi-config to wait for network to become available on boot. I also tried adding 'sudo' before the aria2c command in /etc/init.d/aria2 and it doesn't autostart that way either. Additionally, all the web-ui files in /var/www/html are set to root user & in the root group.\nLike I said before, it was working until the latest dist-upgrade, so something got  (maybe) got borked in that update...my next step is to try setting this up on a totally fresh install of Raspbian Stretch...when I have the time.. on a whim, I just added:\nsudo aria2c --daemon=true --enable-rpc --rpc-listen-all --conf-path=/home/pi/.aria2/aria2.conf &\nto /etc/rc.local and that works! It now autostarts on boot. Is that an acceptable way to get aria2 * web-ui launched at boot?. ",
    "soloturn": "it looks it tries to start it with systemd? could you try to launch it with\nsudo systemctl start aria2\nand check what this gives?\nsudo journalctl -b\nsudo journalctl -u aria2.service\nas the start file seems to be in init.d, i understood correctly that you are able to launch it from there? and the links in /etc/rc3.d are there, isn't it, for your desired runlevel? \nsudo /etc/init.d/aria2 start\n. ",
    "xiashali": "I open a issue(https://github.com/hugetiny/negibox/issues/21) to ask for the source code, But the owner delete it without reply.\nI think it is important to keep the free software as free as we want.. ",
    "avagraha": "What should l do? Is it not compatible with VIsta? Thanks.. ",
    "ballsystemlord": "I forgot to mention. I'm running an up-to-date Devuan (Debian) Linux with a known good kernel that I built for myself.. Thanks.\nMight I add a request for improving the man page. The need to add an additional option when downloading multiple files is an unexpected behavior of aria2c with respect to other downloading tools. Thus it would be prudent to mention this in the DESCRIPTION section of the man page in addition to the output of the --help option.. ",
    "bitraid": "From help:\n\nURI, MAGNET, TORRENT_FILE, METALINK_FILE:                                                                                                       \n You can specify multiple HTTP(S)/FTP URIs. Unless you specify -Z option, all                                                                   \n URIs must point to the same file or downloading will fail.\n-Z, --force-sequential[=true|false] Fetch URIs in the command-line sequentially and download each URI in a separate session, like the usual command-line download utilities.. A download could have multiple URIs (to the same file - seperated by a tab in list file). You can set the name of each download by adding a new line under it, containing: out=downloaded_file_name (must have one or more spaces at the beggining).. \n",
    "nreguera": "OK, I found that I had to add the PATH environment variable where the aria executable is located, and it worked.. ",
    "Pirabarlen-Cheenaramen": "Hi Tatsuhiro, \nFrom the draft, https://tools.ietf.org/html/draft-ietf-tls-tls13-23#page-133\nI quote:\nIn the absence of an application profile standard specifying\n   otherwise, a TLS-compliant application MUST implement the\n   TLS_AES_128_GCM_SHA256 [GCM] cipher suite and SHOULD implement the\n   TLS_AES_256_GCM_SHA384 [GCM] and TLS_CHACHA20_POLY1305_SHA256\n   [RFC7539] cipher suites.  (see Appendix B.4)\nBy not setting the cipher list, we chose to use TLS 1.3's default cipher list, which gives us exactly what the draft proposes and ensures that it will work with all TLS 1.3 servers which is compliant.\nSure enough, if I remove that ifndef TLS1_3_VERSION, the handshake works with all servers I have tested with, but I won't then be able to guarantee that it will work for other implementations.\nSee the handshake part  (under Cipher Suites), we got the proper cipher that is required:\nSecure Sockets Layer\n    TLSv1.3 Record Layer: Handshake Protocol: Client Hello\n        Content Type: Handshake (22)\n        Version: TLS 1.0 (0x0301)\n        Length: 512\n        Handshake Protocol: Client Hello\n            Handshake Type: Client Hello (1)\n            Length: 508\n            Version: TLS 1.2 (0x0303)\n            Random: a39aa06e4815fd0aed82f1d25ae7faf3927028dd25716809...\n            Session ID Length: 32\n            Session ID: 449cb70e2e7a21dfeb529b527853069a5574ce8aad1809e8...\n            Cipher Suites Length: 8\n            Cipher Suites (4 suites)\n                Cipher Suite: TLS_AES_256_GCM_SHA384 (0x1302)\n                Cipher Suite: TLS_CHACHA20_POLY1305_SHA256 (0x1303)\n                Cipher Suite: TLS_AES_128_GCM_SHA256 (0x1301)\n                Cipher Suite: TLS_EMPTY_RENEGOTIATION_INFO_SCSV (0x00ff)\n            Compression Methods Length: 1\n            Compression Methods (1 method)\n            Extensions Length: 427\n            Extension: server_name (len=29)\n                Type: server_name (0)\n                Length: 29\n                Server Name Indication extension\n            Extension: ec_point_formats (len=4)\n                Type: ec_point_formats (11)\n                Length: 4\n                EC point formats Length: 3\n                Elliptic curves point formats (3)\n            Extension: supported_groups (len=4)\n                Type: supported_groups (10)\n                Length: 4\n                Supported Groups List Length: 2\n                Supported Groups (1 group)\n            Extension: SessionTicket TLS (len=0)\n                Type: SessionTicket TLS (35)\n                Length: 0\n                Data (0 bytes)\n            Extension: encrypt_then_mac (len=0)\n                Type: encrypt_then_mac (22)\n                Length: 0\n            Extension: extended_master_secret (len=0)\n                Type: extended_master_secret (23)\n                Length: 0\n            Extension: signature_algorithms (len=28)\n                Type: signature_algorithms (13)\n                Length: 28\n                Signature Hash Algorithms Length: 26\n                Signature Hash Algorithms (13 algorithms)\n                    Signature Algorithm: ecdsa_secp256r1_sha256 (0x0403)\n                    Signature Algorithm: ecdsa_secp384r1_sha384 (0x0503)\n                    Signature Algorithm: ecdsa_secp521r1_sha512 (0x0603)\n                    Signature Algorithm: ed25519 (0x0807)\n                    Signature Algorithm: rsa_pss_pss_sha256 (0x0809)\n                    Signature Algorithm: rsa_pss_pss_sha384 (0x080a)\n                    Signature Algorithm: rsa_pss_pss_sha512 (0x080b)\n                    Signature Algorithm: rsa_pss_rsae_sha256 (0x0804)\n                    Signature Algorithm: rsa_pss_rsae_sha384 (0x0805)\n                    Signature Algorithm: rsa_pss_rsae_sha512 (0x0806)\n                    Signature Algorithm: rsa_pkcs1_sha256 (0x0401)\n                    Signature Algorithm: rsa_pkcs1_sha384 (0x0501)\n                    Signature Algorithm: rsa_pkcs1_sha512 (0x0601)\nand Yes, this block is required with other TLS versions with an older server version. The patch is backwards compatible as well. See the testing results, more specifically the cipher suite section for other TLS versions. I did a rather full testing of it with the handshake detailed.  \nThanks again for going through the patch.\nApologies for any grammatical errors. . Sorry if i seem to be spamming,\nHere's a test against a TLS 1.2 server, notice the cipher suites\nTLSv1.2 against a tls1.2 server\n```\nselven@thiruchendur:~/code/installs/aria/bin$ LD_PRELOAD=/home/selven/code/installs/openssl/lib/libssl.so.1.1:/home/selven/code/installs/openssl/lib/libcrypto.so.1.1 ./aria2c  https://hackers.mu --check-certificate=false --min-tls-version=TLSv1.2\n03/17 19:41:29 [NOTICE] Downloading 1 item(s)\n[#54db8f 0B/0B CN:1 DL:0B]                                                                                                                                                                                       \n03/17 19:41:30 [NOTICE] File already exists. Renamed to /home/selven/code/installs/aria/bin/index.21.html.\n03/17 19:41:30 [NOTICE] Download complete: /home/selven/code/installs/aria/bin/index.21.html\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\n54db8f|OK  |   177KiB/s|/home/selven/code/installs/aria/bin/index.21.html\nStatus Legend:\n(OK):download completed.\n```\nwireshark clienthello tlsv1.2 against tls1.2 server\n```\nSecure Sockets Layer\n    TLSv1.2 Record Layer: Handshake Protocol: Client Hello\n        Content Type: Handshake (22)\n        Version: TLS 1.0 (0x0301)\n        Length: 512\n        Handshake Protocol: Client Hello\n            Handshake Type: Client Hello (1)\n            Length: 508\n            Version: TLS 1.2 (0x0303)\n            Random: c2fd424dbd2951ac2e8a7bfe2353224a146566d50605163e...\n            Session ID Length: 32\n            Session ID: 038f12decf8dcf74f289b4d395f6e67c5073292e00d8a31b...\n            Cipher Suites Length: 62\n            Cipher Suites (31 suites)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (0xc02c)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (0x009f)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 (0xcca9)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 (0xcca8)\n                Cipher Suite: TLS_DHE_RSA_WITH_CHACHA20_POLY1305_SHA256 (0xccaa)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (0x009e)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 (0xc024)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (0xc028)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 (0x006b)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 (0xc023)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (0x0067)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (0xc00a)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (0xc014)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x0039)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (0xc009)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (0xc013)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA (0x0033)\n                Cipher Suite: TLS_RSA_WITH_AES_256_GCM_SHA384 (0x009d)\n                Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256 (0x009c)\n                Cipher Suite: TLS_AES_256_GCM_SHA384 (0x1302)\n                Cipher Suite: TLS_CHACHA20_POLY1305_SHA256 (0x1303)\n                Cipher Suite: TLS_AES_128_GCM_SHA256 (0x1301)\n                Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA256 (0x003d)\n                Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA256 (0x003c)\n                Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA (0x0035)\n                Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA (0x002f)\n                Cipher Suite: TLS_EMPTY_RENEGOTIATION_INFO_SCSV (0x00ff)\n            Compression Methods Length: 1\n            Compression Methods (1 method)\n            Extensions Length: 373\n            Extension: server_name (len=15)\n                Type: server_name (0)\n                Length: 15\n                Server Name Indication extension\n            Extension: ec_point_formats (len=4)\n                Type: ec_point_formats (11)\n                Length: 4\n                EC point formats Length: 3\n                Elliptic curves point formats (3)\n            Extension: supported_groups (len=4)\n                Type: supported_groups (10)\n                Length: 4\n                Supported Groups List Length: 2\n                Supported Groups (1 group)\n            Extension: SessionTicket TLS (len=0)\n                Type: SessionTicket TLS (35)\n                Length: 0\n                Data (0 bytes)\n            Extension: encrypt_then_mac (len=0)\n                Type: encrypt_then_mac (22)\n                Length: 0\n            Extension: extended_master_secret (len=0)\n                Type: extended_master_secret (23)\n                Length: 0\n            Extension: signature_algorithms (len=46)\n                Type: signature_algorithms (13)\n                Length: 46\n                Signature Hash Algorithms Length: 44\n                Signature Hash Algorithms (22 algorithms)\n            Extension: supported_versions (len=5)\n                Type: supported_versions (43)\n                Length: 5\n                Supported Versions length: 4\n                Supported Version: TLS 1.3 (draft 23) (0x7f17)\n                Supported Version: TLS 1.2 (0x0303)\n            Extension: psk_key_exchange_modes (len=2)\n                Type: psk_key_exchange_modes (45)\n                Length: 2\n                PSK Key Exchange Modes Length: 1\n                PSK Key Exchange Mode: PSK with (EC)DHE key establishment (psk_dhe_ke) (1)\n            Extension: key_share (len=71)\n                Type: key_share (51)\n                Length: 71\n                Key Share extension\n            Extension: padding (len=182)\n                Type: padding (21)\n                Length: 182\n                Padding Data: 000000000000000000000000000000000000000000000000...\n```\n. and a TLS 1.2  handshake against TLS1.3 server\nTLSv1.2 on against a tls1.3 server\n```\nselven@thiruchendur:~/code/installs/aria/bin$ LD_PRELOAD=/home/selven/code/installs/openssl/lib/libssl.so.1.1:/home/selven/code/installs/openssl/lib/libcrypto.so.1.1 ./aria2c  https://tls13.crypto.mozilla.org/ --check-certificate=false --min-tls-version=TLSv1.2\n03/17 19:19:00 [NOTICE] Downloading 1 item(s)\n03/17 19:19:00 [NOTICE] File already exists. Renamed to /home/selven/code/installs/aria/bin/index.7.html.\n03/17 19:19:00 [NOTICE] Download complete: /home/selven/code/installs/aria/bin/index.7.html\nDownload Results:\ngid   |stat|avg speed  |path/URI\n======+====+===========+=======================================================\naf225d|OK  |   3.2MiB/s|/home/selven/code/installs/aria/bin/index.7.html\nStatus Legend:\n(OK):download completed.\n```\nwireshark clienthello tlsv1.2\n```\nSecure Sockets Layer\n    TLSv1.3 Record Layer: Handshake Protocol: Client Hello\n        Content Type: Handshake (22)\n        Version: TLS 1.0 (0x0301)\n        Length: 512\n        Handshake Protocol: Client Hello\n            Handshake Type: Client Hello (1)\n            Length: 508\n            Version: TLS 1.2 (0x0303)\n            Random: 9a7b336328f5b78052ab73fabc90fde4d118fe6c785da8e6...\n            Session ID Length: 32\n            Session ID: c1188811625630ce7a3f31dac372ec2eae5ed84b995fa2b1...\n            Cipher Suites Length: 62\n            Cipher Suites (31 suites)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (0xc02c)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (0x009f)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 (0xcca9)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 (0xcca8)\n                Cipher Suite: TLS_DHE_RSA_WITH_CHACHA20_POLY1305_SHA256 (0xccaa)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (0x009e)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 (0xc024)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (0xc028)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 (0x006b)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 (0xc023)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (0x0067)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (0xc00a)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (0xc014)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_256_CBC_SHA (0x0039)\n                Cipher Suite: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (0xc009)\n                Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (0xc013)\n                Cipher Suite: TLS_DHE_RSA_WITH_AES_128_CBC_SHA (0x0033)\n                Cipher Suite: TLS_RSA_WITH_AES_256_GCM_SHA384 (0x009d)\n                Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256 (0x009c)\n                Cipher Suite: TLS_AES_256_GCM_SHA384 (0x1302)\n                Cipher Suite: TLS_CHACHA20_POLY1305_SHA256 (0x1303)\n                Cipher Suite: TLS_AES_128_GCM_SHA256 (0x1301)\n                Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA256 (0x003d)\n                Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA256 (0x003c)\n                Cipher Suite: TLS_RSA_WITH_AES_256_CBC_SHA (0x0035)\n                Cipher Suite: TLS_RSA_WITH_AES_128_CBC_SHA (0x002f)\n                Cipher Suite: TLS_EMPTY_RENEGOTIATION_INFO_SCSV (0x00ff)\n            Compression Methods Length: 1\n            Compression Methods (1 method)\n            Extensions Length: 373\n            Extension: server_name (len=29)\n                Type: server_name (0)\n                Length: 29\n                Server Name Indication extension\n            Extension: ec_point_formats (len=4)\n                Type: ec_point_formats (11)\n                Length: 4\n                EC point formats Length: 3\n                Elliptic curves point formats (3)\n            Extension: supported_groups (len=4)\n                Type: supported_groups (10)\n                Length: 4\n                Supported Groups List Length: 2\n                Supported Groups (1 group)\n            Extension: SessionTicket TLS (len=0)\n                Type: SessionTicket TLS (35)\n                Length: 0\n                Data (0 bytes)\n            Extension: encrypt_then_mac (len=0)\n                Type: encrypt_then_mac (22)\n                Length: 0\n            Extension: extended_master_secret (len=0)\n                Type: extended_master_secret (23)\n                Length: 0\n            Extension: signature_algorithms (len=46)\n                Type: signature_algorithms (13)\n                Length: 46\n                Signature Hash Algorithms Length: 44\n                Signature Hash Algorithms (22 algorithms)\n                    Signature Algorithm: ecdsa_secp256r1_sha256 (0x0403)\n                    Signature Algorithm: ecdsa_secp384r1_sha384 (0x0503)\n                    Signature Algorithm: ecdsa_secp521r1_sha512 (0x0603)\n                    Signature Algorithm: ed25519 (0x0807)\n                    Signature Algorithm: rsa_pss_pss_sha256 (0x0809)\n                    Signature Algorithm: rsa_pss_pss_sha384 (0x080a)\n                    Signature Algorithm: rsa_pss_pss_sha512 (0x080b)\n                    Signature Algorithm: rsa_pss_rsae_sha256 (0x0804)\n                    Signature Algorithm: rsa_pss_rsae_sha384 (0x0805)\n                    Signature Algorithm: rsa_pss_rsae_sha512 (0x0806)\n                    Signature Algorithm: rsa_pkcs1_sha256 (0x0401)\n                    Signature Algorithm: rsa_pkcs1_sha384 (0x0501)\n                    Signature Algorithm: rsa_pkcs1_sha512 (0x0601)\n                    Signature Algorithm: SHA224 ECDSA (0x0303)\n                    Signature Algorithm: ecdsa_sha1 (0x0203)\n                    Signature Algorithm: SHA224 RSA (0x0301)\n                    Signature Algorithm: rsa_pkcs1_sha1 (0x0201)\n                    Signature Algorithm: SHA224 DSA (0x0302)\n                    Signature Algorithm: SHA1 DSA (0x0202)\n                    Signature Algorithm: SHA256 DSA (0x0402)\n                    Signature Algorithm: SHA384 DSA (0x0502)\n                    Signature Algorithm: SHA512 DSA (0x0602)\n```\nAgain apologies for so many test logs in the comment section.. Good to hear from you! I thought you were dropping the pr, don't merge it yet then, I'll try to add some comments and update this PR with the changes from draft 28 in the coming 2 weeks. Myself I Apologize for the late reply. . "
}