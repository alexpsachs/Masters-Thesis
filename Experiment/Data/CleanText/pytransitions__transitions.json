{
    "tyarkoni": "Thanks, glad you like the package! I'm still wedded to 2.7 for almost everything, so I'm ashamed to admit it didn't even occur to me to test for Python 3 compatibility. Much appreciated!\n. Merged, thanks!\nI like the idea of adding something like this to the codebase. Not sure if it should be its own OrderedStateMachine class; an alternative would be to have an initialization argument called ordered or sequential that's False by default but will assume states are implicitly ordered if set to True.\nAnother question would be what to name the triggering method(s). A convention like {s1}to{s2} is fine, but it might also be nice to be able to assign a single method to all cases (e.g., advance()).\nActually, another way to handle this might be to add a separate add_ordered_transitions() method to the Machine class that takes optional arguments for states (a list of states ordered in the desired sequence; defaults to all states in the existing order) and trigger_name (defaults to your convention, but can be set to a single string).\nThoughts?\n. I think it might make sense to put add_ordered_transitions() in a separate module (maybe transitions.utilities or helpers or something like that). While I like the idea of putting it in the Machine class in principle, I think there may end up being a bunch of methods like this eventually, and the Machine class could get cluttered. Absent a better place to put them, we could maybe lump them in a utilities module for now (and break the API once much later if it grows enough to warrant refactoring). Then the signature could be something like:\npython\ndef add_ordered_transitions(machine, states=None, trigger_string='%s_to_%s', loop=True, loop_includes_initial=False)\nThoughts? Do you want to work up a PR?\n. Okay, let's keep it in the Machine class then--I don't want to add new subclasses just yet if an initialization argument can cover it.\nThe advance() thing is unnecessary, actually; I realize now that's exactly what your next_state() already does. The one thing I would say though is that I don't think next_state() should be hardcoded in the Machine as a separate method; instead, the add_ordered_transitions() method should just set up a series of transitions that are all triggered by 'next_state'. This would require moving the loop_includes_initial argument back into the add_ordered_transitions method, but I think that's fair, as I don't see many users wanting to change whether the initial state is included or not included in the loop on a call-by-call basis.\nOne other thought: while I really like the automatic attachment of transitions between states, it seems like it should be entirely independent of the sequential transitions. What about just automatically adding to_{state}() triggers (in addition to {source_state}to{dest_state}())? Right now is_{state}() boolean checks are already created for all states, so adding to_{state}() methods that just wrap set_state({state}) seems sensible. This actually seems useful enough that it should probably be True by default. Then if the user sets auto_transitions=False in the initializer, those transitions would be disabled.\nAlso, I'm not sure it's necessary to include the source state in the automatic transition methods--i.e., is there any reason to add {source}to{dest}() as opposed to just to_{dest}()? The only reason I can see wanting to be explicit about the source state is to make sure that the state machine is in a known state before transitioning to the desired state (i.e., if you call state1_to_state2(), but the machine is currently in state3, nothing would happen, whereas calling to_state2() will always work). I can see that being useful once in a while, but it doesn't seem like a very common use case, and is perhaps better left to the user to implement in their own code they need it.\nAnyway, I guess where this would leave us is with (a) a single method for add_ordered_transitions() that automatically gives you next_state(), as defined by the linear sequence in the list of passed state names (or the existing sequence in the Machine if no list is passed), (b) including to_{state}() triggers for all states by default, and (c) adding convenience arguments in the Machine initializer with defaults auto_transitions=True and ordered_transitions=False. Does that sound good? Let me know if you want me to do any part of this, otherwise I'll be happy to accept a PR.\n. Sounds good. I just took a pass at one chunk, and will get to the rest if I have time before the holiday. If not, feel free to take a pass when you get back. Have a pleasant week!\n. Thanks!\n. This would be a great start, @svdgraaf! I agree that the result could be improved aesthetically, but for now it would be great to have even rudimentary diagramming capabilities. Do you want to open a PR for this? I suggest putting your code in a separate 'diagrams' module and refactoring slightly so that the graphing call takes a Machine instance as the first argument. We can also maybe add a diagram() method to the Machine class for convenience.\n. Thanks! This is great; will add feedback in the PR conversation. I agree with @krisztianfekete that we probably want to avoid making pygraphviz a hard requirement.\n. Closed in #47. Thanks @svdgraaf! We'll probably want to revisit this and add more features in future, but we can open more specific issues for that.\n. Can you paste a code snippet that doesn't work, for your data-passing example? Depending on how you've set it up, you may need to set send_event=True in the initializer (see the README), but it should work.\nRegarding the MathWorks example, you can duplicate most (though not quite all) of that functionality with the existing code in transitions... callbacks can be added to both states and transitions (i.e., states have 'on_enter' and 'on_exit' callbacks, and transitions have 'before' and 'after' callbacks), and transitions can have a list of conditions attached that must evaluate to True in order to execute. As far as I can see, the only difference in the MathWorks implementation is that one can have code that executes on successful condition evaluation even though the transition destination is not known to be valid yet. I need to think some more about whether that's worth implementing here, but I guess my first impression is that it doesn't seem like a very common use case.\n. I added an 'unless' argument in 67dce5d8d5123d6317816227c06b4d9e818198b6. It behaves just like conditions, except inverted (i.e., all conditions in the unless list must return False, or the transition fails). I think adding logic to handle disjunctions is probably not worth the extra code; I don't think that's a very common use case. But if other people request OR handling, we can always revisit this.\n. It wouldn't take much work to add that behavior, but I'm not sure how I feel about it. Mainly I worry about feature creep if we start doing things like scanning the data model for already-defined callbacks, etc. It feels a bit inelegant to me to push some of the FSM logic into the data object. That said, I don't feel strongly about it, so let's leave this issue open for now, and if other people weigh in with strong opinions one way or the other, we can re-evaluate.\n. Okay, then I'm sold. Does someone want to take a stab at a PR? If not, I should be able to get to it in a few days.\n. Great!\n. Thanks!\n. Hmm... I can see the benefit of that in some cases, but I don't think it's worth adding here. One reason to keep it the way it is is that we currently allow Machines to be initialized without an explicit initial state, in which case a placeholder 'initial' state is created. In a sense, I think of that placeholder as a kind of null state that the user has to move out of before anything meaningful happens. So for now I guess I'd prefer to leave it as is. Am closing the issue, but will re-open if there's additional demand for this.\n. Thanks for the PR! While this is a simple enough patch, I'm not sure the State initializer is the best place to handle something like this--I'd like to keep the API minimalistic, and adding this kind of thing could easily snowball into special handlers for all kinds of other potential exceptions. I'm also not crazy in general about the idea of preemptively suppressing valid exceptions, as opposed to handling them reactivity. Would one of these alternative patterns work okay for you:\n- Wrap a try/catch block around trigger calls in your app that could fail depending on the current state (which would require no modification to the transitions codebase);\n- Replace the generic MachineException thrown here with something more specific (e.g., InvalidInitialStateException), which would allow you to catch just this exception at the top level of your application and check against a list of states that should be ignored;\n- Use more specific triggers. I'm assuming the reason this particular issue arises is that you have a trigger that's supposed to work for multiple states, just not all of them. Being more specific about the list of valid initial conditions in each transition may make your code a bit more verbose, but is probably a safer way to go in general than adding broader triggers that then have to be ignored for some states;\n- Make the transition conditional on some other check passing. For example, let's say you have a transition called advance() that moves from any state into state C, and you want to prevent the transition only if the current state is A. Then you could do something like:\n``` python\nmachine.add_transition('advance', '*', 'C', conditions='valid_source')\nclass MyModel(object):\n    ...\n    def valid_source(self, event_data):\n        return False if event_data.state.name == 'A' else True\n```\nOf the above, I would personally probably go with the third, then the fourth, and only resort to exception handling if there was some reason why the other two approaches aren't practical. But let me know if none of these makes sense for your particular use case and maybe we can figure something else out. I'll close this for now, but will re-open if needed.\n. Hmmm... okay, you've almost swayed me. But I'm still wary of feature creep for the reason mentioned earlier. So let me reopen this and let it sit here, and if one or two other people indicate that they'd like to have this functionality as well, we'll add it in. My reservation is mainly driven by the fact that I haven't seen other simple FSM implementations provide this functionality, which leads me to think that it's not a common need. But if I'm wrong about that, I'll happily add it. :)\n. Hi @bvdeenen,\nI received an email from another user who also would like to see this exact feature implemented, so as promised, let's go ahead and merge it. But would you mind making the following two changes first:\n1. Write a test for the new functionality.\n2. Rename the ignore argument to something slightly longer and more descriptive (maybe ignore_invalid_triggers).\nIf you don't have time, just let me know and I'll do it.\nAlso, given that we're adding this, I wonder if it would make sense to also add a global switch (at the Machine level) that changes the default behavior. One concern the emailer raised is that he has a lot of different States, and having to set ignore=True explicitly in each one could get unwieldy. If you feel like it, maybe add a global ignore_invalid_triggers to the Machine that changes the default behavior in the State initializer, provided it doesn't complicate things too much.\n. Sounds good. I'll add the test and change the argument name now, but probably won't have the time to add the global flag for a few days.\n. Support for global suppression of the invalid trigger exception added in bd1022b7bff2141c34f4a2107e12a2133a56dbe.\n. Thanks for the PR! Happy to merge this, but could you also add another test condition that checks to make sure that if no value is explicitly passed for initial in the Machine initializer, the property initial will be set to 'initial' (the default)? Thanks!\n. Thanks!\n. I like the idea in principle, and would be happy to consider a PR that adds this relatively unobtrusively (I don't have time to work on it myself right now).\n. Closed in #17\n. Hah, I missed this PR and independently fixed it. But merged anyway so you get credit for catching it. ;)\n. Thanks!\n. Great idea! I won't have time to take this on for a couple of weeks, but would be very happy to consider PRs.\n. Sure--let me get back to you after Friday. :)\n. Sorry @lulingar, just realized I never followed up on this. I just added very basic logging in a17617e4d5480. This could be improved in various ways (e.g., assigning all logged events to named constants, adding messages for other events, allowing writing to file, or adding metadata like timestamp and Machine instance to the logs). All logged events are at INFO level right now, and I haven't changed the default loglevel, so to output the logs to stdout, one just has to import the logger from the module and set its level appropriately before running. I.e.,\n``` python\nimport logging\nfrom transitions import logger\nlogger.setLevel(logging.INFO)\n```\nThen you should have a record of transitions, state changes, and fired callbacks.\nI'm closing this for now, but feel free to re-open if any issues arise.\n. Looks good; thanks for the PR!\n. Not sure I follow... I think the current code does what you describe. If you initialize a state machine and hold on to it in the scope of your executing code, you should be able to call it as needed, and it will block execution until the state machine finishes doing whatever it needs to. If you want to have a non-blocking state machine that listens for events on a separate thread, you could do that via message passing or some other concurrency pattern with a bit of work. But you'd need to implement that yourself, as there's no concurrency support at the moment (and none is planned).\n. Closing this, but re-open if you have a follow-up.\n. python\nv = VendingMachine()\nfsm = Machine(v, states=['rest', 'dispense', 'give_change'])\nwhile True:\n    if check_money_in_slot():\n        to_dispense()\n        to_give_change()\n        ...\n...but note that in practice, you'll probably need to replace the work done here by the check_money_in_slot call with some kind of message passing scheme (e.g., have a look at the Queue module in the standard library), or by polling a socket. So I think your question isn't really about FSMs per se, but more generally about how to implement a server in Python. There are plenty of tutorials for that; once you have that down, embedding the FSM logic should be straightforward.\n. Hmm... that's an interesting idea, but I'm not sure it's a common enough use case to warrant adding. I think there are two alternative approaches that might work better. One is to just fall back on the standard approach and add all transitions explicitly rather than using the ordered_transitions shorthand. I.e., instead of\npython\nmachine.add_ordered_transitions(['A', 'C', 'B'], trigger='next_state')\n...one can always write:\npython\ntransitions = [['next_state', 'A', 'C', 'this_must_pass'], ['next_state', 'C', 'B']]\n...which will usually not be very verbose. I think for the few cases where an individual condition is needed for an ordered chain, and there aren't very many states, that's probably a reasonable approach.\nWhen there are a lot of states, adding all the transitions explicitly might become a pain. In that case I think a reasonable way to handle this would be to add some kind of update_transition or replace_transition method--or maybe add a boolean 'replace' argument to Machine.add_transition() that overwrites any existing matching transition instead of always appending. Then your problem could be solved by doing one of the following:\n``` python\nCreate the chain\nmachine.add_ordered_transitions(['A', 'C', 'B'], trigger='next_state')\nOption A: get transition and manually update state\nt = machine.get_transition('next_state', 'A', 'C')\nt.add_condition('this_must_pass')\nOption B: replace transition in place\nmachine.add_transition('next_state', 'A', 'C', conditions='this_must_pass', replace=True)\n```\nI'm okay with either approach, but I think the first one might be a better way to go as it would probably be generally useful to let users easily retrieve existing transitions for inspection/modification. Thoughts?\n. Thanks for catching this! I bumped the version and it should work in 0.2.7 from PyPI now.\n. Thanks for the pointer; I removed the basicConfig call.\n. That looks right to me... the inheriting instance is passing itself to the Machine initializer as the first argument in order to set itself as the model. This pattern is currently used in one of the tests and it passes fine, so I'm closing this. But thanks for the close read! :)\n. Sorry @deubs, just realized you were right about this (following #48). My apologies.\n. Thanks for the PR, @acjc! I think this an excellent idea, and I'm looking forward to merging it, but it may be a couple of days before I get to it, as I'm swamped with other stuff.\n. Looks great, thanks!\n. Yep, done!\n. Hi @bit-pirate, thanks for using the package!\nAs currently implemented, all callbacks are assumed to be located in the model class rather than in the global environment. That's still true when you initialize the Machine with itself as the model. In your example above, you're defining test_callback() outside of the Machine, so when it looks for the callback function at self.test_feedback, it can't find it. But you can fix this by attaching your method to the machine instance:\n``` python\nfrom transitions import Machine, State\ndef test_callback():\n    print 'testing callbacks'\nif name == 'main':\nstates = ['StateA', State(name='StateB', on_enter=['test_callback'])]\ntransitions = [{ 'trigger': 'triggerA', 'source': 'StateA', 'dest': 'StateB' }]\nsm = Machine(states=states, transitions=transitions, initial='StateA')\nsm.test_callback = test_callback\n\n```\nIn theory I suppose we could inspect all functions currently in scope for a match to the callback... but that seems dangerous. In general I recommend going with the second approach (i.e., inheriting from Machine) for precisely this reason--it lets you contain all model logic in a separate class rather than monkey-patching the Machine class or adding to it at runtime.\nI'm closing this, but feel free to re-open it if needed.\n. Thanks!\n. Great, thanks!\n. Looks good, except there are two places where you now have a dictionary with duplicate keys. E.g.,\npython\nstates = [\n    State(name='solid'),\n    'liquid', \n    { 'name': 'gas', 'name': 'plasma'}\n    ]\nThis won't work; the plasma state needs to be a separate element in the list. You could do [ ... {'name': 'gas'}, {'name': 'plasma'} ... ], which would work fine. If you can change that, I'm happy to merge this as well. Thanks!\n. Thanks!\n. Thanks, will close. I'll make an effort to bump version in the next couple of days so that the PyPI version includes this fix.\n. It looks like there might be a runaway recursion, where a transition is triggering a callback that then calls the original trigger, and so on. Hard to say without seeing your code; could you post the relevant snippets in wake_up() and no_ride_requests()? Thanks!\n. Closing this given the discussion in the other threads.\n. Callbacks are called sequentially (callback C2 shouldn't run until C1 returns), so in general, there shouldn't be multiple callbacks running at the same time unless you're launching new threads within one or more callbacks--in which case all bets are off. That said, one exception is that if you have a callback that itself triggers a state change, then yes, you could very well end up in a situation where the on_enter callback of a new state is activated before the last state's on_enter has finished.\nI agree that this is not really desirable behavior, but I think it would be very complicated to solve this problem in a general way, and I want to avoid adding a lot of additional logic for what is probably a fairly uncommon use case. But if you have ideas for a relatively simple fix, I'd be happy to consider it.\n. I don't think you're doing anything wrong; ideally the package would support asynchronous and/or appropriately prioritized callbacks. It's just that the original goal was to build something very lightweight that met my own needs, which are mostly centered around web applications where transitions are usually triggered by discrete requests from a user and states and associated data are quickly serialized to the DB after each request. Building something that can handle prioritization and async calls starts to get away from that. (For what it's worth, virtually all of the other Python/Ruby FSM implementations I've seen would have the same issue.)\nIn any case, I'll think some more about potential ways to implement a solution to your problem that wouldn't require a lot of new code. Right now everything I can think of seems pretty convoluted. Would love to hear suggestions if anyone else has any.\n. Closing this and labeling wontfix for now. Still open to ideas though.\n. There's currently no support for compositing or hierarchical/nested states. I think some rudimentary support for hierarchical states could be added fairly easily, but I don't have the time to do it myself at the moment. If you (or anyone else) are interested in working up a PR, I can make some suggestions.\nThat said, I'll also give my standard caveat, which is that I don't like to add major new features unless multiple users express desire for them, because there are a lot of potential extensions to a package like this, and I want to avoid bloat. So if anyone else wants to weigh in, please do.\n. Closing this for the time being; can be re-opened if necessary.\n. Oh, thanks for catching that. Yes, we definitely want pickling to work properly. I think we probably just needs getstate and setstate methods in the Machine class. If you can add those, that would be much appreciated. Thanks!\n. Hmm... the travis build appears to be failing. Looks like it's the test_pickle test. Can you look into it? Happy to merge once it passes. Thanks!\n. Looks great, thanks for the contribution!\n. Soon! :)\n. Thanks for fixing this!\n. This issue has come up several times in various flavors; see for instance #18 and #30. As @wtgee points out (thanks!), if all you need to do is just keep the main thread running, you can embed your code in a while loop and just try to advance state every iteration. As long as you give your transitions the same trigger name, they will be executed serially until one passes (see the README), so you can avoid embedding transition logic inside the callbacks. Generically, you could be looking at something as simple as:\npython\nwhile True:\n    if model.is_finished():\n        break\n    model.next_state()\nYou can then use the on_enter, on_exit, before, and after callbacks (attached to States and Transitions, respectively) to push a lot of your code into the model rather than checking a lot of conditionals inside the while loop.\nHope this (and @wtgee's code sample) helps!\n. I added a transition pointer to EventData objects for convenience, so you can now do event_data.transition.dest.\n. Hmm, interesting. @mayowa, do you remember what your rationale was for not allowing model-defined callbacks when the Machine and model are the same object?\n. Ah, I see. The problem is that when the model is self, arguments aren't passed properly from the callback (https://github.com/tyarkoni/transitions/blob/master/transitions/core.py#L460). Should be able to fix this, but probably not until the weekend. If anyone else wants to take a crack at a PR, please feel free. :)\n. Should work now. Let me know if there are any residual issues.\n. The issue here is that people can reasonably have different expectations about what should happen if a condition fails. One view is that a \"before\" callback should always run, even if the transition never completes successfully (because a condition fails). The counterargument is that you might not want before callbacks to fire at all if you know the transition won't happen, because it could leave you in an internally inconsistent state. For a lightweight package like this, my sense is that the latter case is probably the behavior most users expect. So I implemented it with condition-checking first, to prevent any further logic in the event the transition is invalidated.\nI'd be happy to change the order if there's general agreement that that's preferable, but I worry that that would introduce undesirable behavior in other respects. An unambiguous way to resolve this would be to split the before callback into two separate callbacks (e.g., 'before' and 'around'), but I'm kind of hesitant to keep adding callbacks as my overriding concern is to keep it simple.\nLabeling this as a question so other people can weigh in.\n. That's reasonable. I'll leave this open for further comment, and if there's enough sentiment in favor of always firing \"before\" events, we can do it that way in a future release.\n. Yes, conditions and before/after callbacks all receive EventData just like other callbacks. See the \"Passing Data\" section in the README. If it doesn't work as described, open a new issue.\n. Thanks for the feedback, @aleneum. Will keep this open for further input.\n. Okay, I think I'm sold on adding another callback, since it's come up a couple of times now. I think your implementation looks good, @TheMysteriousX. The only thing I'm not sure about is the name... I find 'action' kind of ambiguous. I think if we replace 'before' with 'before_check' and 'before_transition' (while keeping 'after'), that seems clearer. For backward compatibility, we could also alias 'before' to 'before_transition'--at least for the next few releases (the docs wouldn't mention it, and we could remove it at some point).\nThoughts, @aleneum, @wtgee?\n. Sorry, the fix for #37 broke this. Fixed now.\n. Thanks!\n. You shouldn't need to specify any conditions in the second transition---so if you just remove the 'unless' argument, it should work fine. By default, transitions will be attempted in order until one successfully executes. So if you have a conditional on the first transition that fails, the FSM will proceed to execute the second transition.\nIf that doesn't work, let me know.\n. Glad to hear it.\n. Thanks!\n. I think you're asking a more general programming question that isn't really specific to this package, but maybe take a look at #36, as variants of this issue have come up before. The short of it is that you probably want to run a while loop to poll state periodically and trigger events as needed. But this kind of thing should probably be posted to Stack Overflow in future, as it's about general usage.\n. Please read the whole section. That's expected behavior if your callbacks can't all handle arbitrary args and kwargs, unless you set send_event=True in the Machine initializer. Use the second example.\n. Do you mind adding a test? Doesn't have to be anything fancy; just creating a very simple machine and testing to make sure that the graphing code writes out a file with non-zero size would suffice. I can do it too if you prefer. Otherwise I think this is ready to merge.\n. Awesome, thanks---this is great! I'll update the README.\n. Congrats! Hope there are many more to come. ;)\n. Thanks for catching that! I think states=states is the way to go, as I'm generally in favor of using keyword args when possible to increase clarity.\n. Thanks!\n. Thanks for the question, @aleneum! Support for hierarchical states has been suggested before (#31); to recap: I think it would be nice, as long as the implementation can be made relatively compact. I'm happy to consider PRs or to discuss potential implementations, but probably won't have time to implement this myself any time soon, so it would fall to someone else to do it.\nWith respect to concurrent states, it depends on what you mean. If you mean support for being in multiple states at once, but still in a single-threaded context, I'm willing to consider something along those lines---though I'd need to be convinced that there's a real need for it. I guess my intuition is that most potential use cases could be reduced to either (i) making states hierarchical (so, this amounts to implementing hierarchies, as above), (ii) implementing multiple Machine instances, or (iii) refactoring the states so that you encode all possible combinations of desired states as discrete states.\nOn the other hand, if you're talking about concurrency in the sense of multithreading (see discussion in #30), then that's definitely not on the agenda, as I think it would be a beast to get right.\nSince this has come up before, I'll mark it as help wanted and leave it open.\n. Added in b327706941c63ab81. Thanks again, @aleneum!\n. You're missing a comma after \"chapter_teaser\" in the states. Adding that should fix it.\n. Oh, and you would go to the next state by calling the appropriate trigger; in your case, the trigger is advance() for all transitions, so leaderboard.advance().\n. This looks great, thanks! I'll review this as soon as I can--probably on Monday.\n. Okay, I've looked through the code... This is really great--thanks so much for the contribution! I only have a few minor stylistic comments (and I'll probably make some minor edits to the README after this is merged):\n- I'm not sure about using the underscore character to concatenate nested state names. I think the forward slash is probably just as good for purposes of nesting, and would be less likely to cause confusion, since using the underscore in variable names is quite Pythonic and is likely to be used a lot in states that don't involve nesting. I recognize that it probably won't cause any problems functionally if users mix non-nested states with underscores and nested states, but it seems a bit confusing. So unless you have objections, I'd prefer to see 'foo/bar/baz' rather than 'foo_bar_baz'.\n- In the counter example, the instance name is 'counter' in some cases and 'calculator' in others--this should be made consistent.\n- Siince LockedMachine and LockedHSM seem to have identical code, could we maybe use use a mixin pattern or something to manage this without the redundancy?\n- For consistency, we should probably call the LockedHSM class 'LockedHierarchicalMachine'. It's kind of annoying to type, but I think it's good to keep the nomenclature consistent.\n- To minimize redundancy, I think the 'Stuff' and 'Inherited Stuff' classes in the testing modules should probably be moved into a separate module (probably 'utils') under testing, and then they can be imported in multiple places as needed.\nOtherwise everything looks great! If you don't have time to make some of the above changes, just let me know, and I can always merge first and then patch it myself.\n. Oh, good point re: auto_transitions. I agree that the alternatives are messier, so let's stick with underscore for now and revisit it in future if it becomes an issue. Thanks for making all the other changes!\n. Thanks! Most of these changes look great. I generally prefer 'we' to 'you', as it feels more inclusive. But no biggie, so I'll merge as-is.\n. Sorry, I'll bump version shortly---just waiting on some changes to a big PR before bumping to 0.3. :)\n. Just pushed the new release to PyPI.\n. Ah, I see the issue. In _add_nodes(), we have:\npython\nstate = state[0]\n...which expects a list of key/item tuples, but is getting the state dict. I'll fix this and also expand the graphing tests. Thanks!\n. Click on \"details\" under the build failure:\nhttps://travis-ci.org/tyarkoni/transitions/jobs/100266582\nNot sure why it's failing as a result of your changes, but the test itself could use some improvement (right now it hardcodes the removal of the 'C' state). I'll look at it later this week if you don't get to it first.\n. Is this ready to merge, @wtgee?\n. Done! Thanks!\n. Hi @stvo,\nThe graphing functionality (which @svdgraaf was kind enough to contribute) is pretty basic, so there's minimal support for different plotting options. To answer your questions in order:\n1) Not at the moment.\n2) No, because of (1).\n3) Not sure I follow... you define the initial state as '1', and it looks like that is indeed the initial state in the graph (with the double circle). I don't get the 'new' state in my graph for your code; are you using an up-to-date version? However, I do see a separate problem--and maybe this is what you're getting at--which is that the second transition (from 1 --> 3) appears to be ignored. This would be a bug, and I'm guessing it has something to do with the fact that the transitions have the same named trigger. Can you open a separate issue just for this, if you agree that this shouldn't be happening?\n4) I probably won't be able to do this any time soon myself, but if you open a separate issue for it with a clear example of the use case, I'll mark it as a enhancement and hopefully someone can add it.\nNote that the get_graph() call returns a pygraphviz AGraph object, which has all of the usual properties. So you could potentially modify the node/edge properties directly, in lieu of an option to do it in transitions.\nHope that helps! I'll close this issue, but feel free to open new ones for more specific bugs/requests per the above.\n. Hmm... I think pickling is important, but I'd rather not hold this PR up until we fix it. But I also don't want to leave the tests failing if we're going to treat this as a known issue that only applies to an edge case (pickling an HSM on >= 3.4). I would suggest (a) removing the pickling test in test_threading (or only running it on Python < 3.4), and (b) opening a new issue for this, which I'll try to get to this weekend if nobody fixes it sooner. Sound good?\n. Thanks!\n. Awesome, thanks!\n. Sorry for the delay getting to this, @aleneum. Would you mind resolving the merge conflicts on your side? I think at this point, extensions.py is really more your domain. :)\n. Also, @aleneum, I don't see an email address for you in your user profile. Could you please drop me an email (tyarkoni@gmail.com)? Thanks!\n. Looks good to me, and thanks catching the bug.\n. This change seems sensible to me, but let's give it a day or two for other people to weigh in with any possible objections, since it does break behavior that some users may have come to expect.\nNot sure what the change in coverage is about (might be because it's scanning README for docstrings or something?), but no need to worry about it.\n. On thinking about it some more, I think I agree with @aleneum here. So let's leave logging as-is for now. At some point it would be nice to beef up the logging functionality (e.g., by standardizing the format of the output in some machine-readable format, and adding graphing of transition history). At that point we could conceivably add some basic filtering tools, so that one can imagine calling something like logger.get_transitions() vs. logger.get_events(), where the former would return only successful transitions, and the latter returns all events of potential interest.\nIn the shorter term, I'm certainly willing to consider a revision to the logged codes that can be more easily filtered post-hoc by the user. E.g., instead of a human-readable message like \"Transitioned from state S1 to state S2\", it might make more sense to log something like \"TRANSITION\\tS1\\tS2\\tSUCCESS\\n\", \"CALLBACK\\tS1\\tafter_S1\\n\", and so on. Then it would be trivial to grab only the TRANSITION codes with SUCCESS, etc.\n. Sounds good, thanks @Ch00k. I made that change directly.\n. Glad you like the package. I'm also not sure that threading is needed here, but maybe @aleneum can comment, since they contributed the threading functionality. Also, take a look at #18 and #36 in case they address your issue.\nThat said, please submit questions about package usage on Stack Overflow; GitHub issues are for bugs, feature requests, etc. If you think that the False/True values being returned reflect a bug (off the top of my head, I'm not sure what would be causing this, but I don't think that's been flagged as an issue before), you can open a separate issue for that, but please add a minimal code sample that reproduces the problem. Thanks!\n. Thanks @hstarmans. Yes, @wtgee is correct: the behavior is fine in this case, the docstring should just say that it returns a boolean indicating whether or not a transition was successfully executed. I'll update the docstring.\n. I think 'fail' is ambiguous in this case. When you call a triggering function, it serially executes all individual transitions that start with the current source state, until one successfully executes. A transition may fail to execute because a conditional check returned False. But it's not clear that you want to throw an exception just because all available transitions failed to pass; that would make it impossible to distinguish between a genuine failure in the code and a predictable logical condition that the user may want to handle. So I think the onus is on the user in this case to raise an exception if that's the behavior they want.\n. Thanks @wtgee, added that as well.\n. I agree that this is the current behavior, but to me this feels more like a feature than a bug. It seems dangerous to treat the wildcard as a special directive to always send all states to a particular target, because that can have unpredictable effects if you forget you added the wildcard at some point in the past. The alternative approach is that, after you add new states, you just re-add the wildcard transition, which is a single extra line of code. But in general, I would not expect a state transition matrix to update dynamically in response to later state additions/changes without explicit modification. So unless there's a consensus that we should change this, I incline to leave it as-is (though I'd be happy to tweak the README to mention that this is the behavior).\n. Thanks! I also added a note at the top of the README to the same effect.\n. To be honest, I don't think I considered this issue at all when I wrote the original code, so I'm not going to give an elaborate justification for doing it one way versus the other. That said, it does feel more natural to me to not trigger callbacks at instantiation. And I agree with @aleneum's reasoning: it's trivial to make sure a function gets called at initialization (worse case, you just call it manually), but less trivial to prevent an unwanted callback from firing when it shouldn't. So let's leave the code as-is. I'll add a small note to the docs to this effect.\n. Me too!\n. Not sure I follow... Can you explain what you're trying to do? A code sample might help as well.\n. Oh, I see. It should actually work exactly the way you want it to, I believe. In your example, 'IsConditionMet' is just a pointer to the function. It's fine if all conditions point to the same function. All you're missing is catching the EventData instance. I.e., this should work:\npython\ndef IsConditionMet(self, event_data):\n    # trans is a Transition instance that has .source and .dest properties you can access.\n    trans = event_data.transition\n    ...\n    return False\nClosing this unless there are any other issues.\n. Looks great to me! Feel free to merge.\n. Good catch. I'll fix this right now. Thanks @TheMysteriousX!\n. I assume we don't want to allow on_enter_* to work on the model itself, right? I mean, we definitely don't want to start patching an arbitrary model class's getattr method. So I'm just going to update the README to be clear about this.\n. Looks good to me, thanks!\n. Awesome, thanks! I think we're well overdue for a new release... will try to do it this weekend at the latest.\n. +1 for prepare. I know I was the one who pushed for before_check and before_transition in the first place (sorry!), but on reflection, prepare and before probably work better. prepare nicely captures the intended semantics, and also gets us out of having to deal with any deprecation issues, since we wouldn't be breaking the API at all.\nI'm ambivalent about adding a general system_check callback. It would be nice to have, but is another one of those places where once you start down that road, you can add a lot of other features pretty quickly, and it can get hard to keep track of all the functionality. If we do want to pursue this, another avenue I'd prefer to explore--which would add more code, but probably be cleaner in the long run--is to abstract the callback functionality, so that we can easily insert new callbacks by doing something like check_callbacks('before', event_data) at various places in the code, instead of looping over hardcoded named callbacks. It gets kind of ugly having containers for self.before_check, self.before_transition, etc... would be cleaner to just store a single callbacks dict inside the model, and I think it would work just as well and improve code maintainability. I don't think we should tackle this right away, but it's something to keep in mind. Given that kind of implementation, I'd feel much better about adding additional callbacks, since it would add almost no new complexity each time.\n. Oh, and forgot to mention--the patch looks great to me otherwise; thanks @TheMysteriousX!\n. In theory we could implement something like this, as we don't currently use the __getitem__ accessor on the Machine for anything. But it would be a bit clunky, as we'd probably need to create a new class that wraps Event, or something like that.\nThat said, I don't think we really want to go down this road... Personally, I don't like the idea of having a bunch of different ways to achieve the same goal, and it's not clear to me that we would want machine[] to index into States--one could, e.g., imagine indexing directly into Transitions, or Events, etc. Plus maintaining multiple interfaces would start to defeat the point of keeping the core lib as simple as possible. So unless @wtgee and @aleneum are strongly in favor, I would vote to close this--though I do appreciate you bringing it up, @bennyrowland, as it's an interesting idea.\n. +1 for this. It would definitely be nice to allow users to pass callables, and should be pretty easy to patch in. I'm happy to take a pass at this, though it probably won't happen until next weekend. If you want to work up a PR before then, that would be great.\n. Very elegant! Thanks. :)\n. Looks good to me, except I would suggest maybe adding a space before and after the ampersand (just for readability).\n. I'm okay with breaking the API in this case. I mean, I don't think we should make a habit of it, but I suspect the number of people currently using the HSM extension is not very large yet, so, better to break it now rather than later. :) But we should probably mention this change in a parenthetical comment in the docs though (at least for a few months).\nOtherwise this all sounds good to me. I agree that if we can avoid flattening, that would be better. I also think the on_enter/on_exit('C.alt','callback') approach is a good solution.\n. I don't think we need to support unicode separators in 2--I agree it will probably create more trouble than it solves.\n. Thanks for catching that, @chaoflow!\n. I think I'd be okay adding an optional logger argument to the Machine constructor. It seems like a pretty minimal change, and I can see a use case for it. If you want to submit a PR, that would be great.\nAnd yes, feature requests should go here.\n. I agree that the ability to trigger a state change from within a callback is a point of confusion (see, e.g., #30), but I'm not sure it's something we want to explicitly either support or actively prevent. As a general rule, my feeling is that users shouldn't be putting transition logic inside their model callbacks; I have a hard time thinking of a case where one would need to do that. In your example, you could just call e0() followed by e1() from the main thread, and everything would work fine. So I guess the path of least resistance would be to maybe just add a note in the docs saying that users should be aware that triggering transitions from within callbacks is likely to lead to unpleasantness.\nThat said, I would potentially be okay adding queueing functionality if (a) you can point out a common use case where one would need to do this kind of thing and (b) the proposed implementation was relatively simple. Alternatively, if there are no obvious use cases, I would be equally comfortable raising an Exception when a user tries to trigger from within a callback (again, as long as the implementation is simple). If the complexity of a solution is high either way, my inclination would be to leave it as-is.\nThoughts?\n. Is there anything left to do here that isn't in #96, @khigia? If not, can we close this?\n. The current PyPI release doesn't support 'prepare'; please make sure you install from GitHub for the time being (I'll push a new release soon).\n. Yes, definitely--this is long overdue. I'm on vacation till Saturday, but will push the new release on Sunday. Thanks!\n. +1 to @wtgee. I liked queued; it's fairly easy to infer what it means. For transition_strategy, you almost certainly need to read the docs.\n. I think you're confusing the GraphMachine class in Transitions with a separate package in PyPI. If you want to use the Transitions GraphMachine, just import GraphMachine from transitions.extensions. If you want to use the GraphMachine package available on PyPI,  you'll need to look for support elsewhere, as we have no relation to that package.\n. Not sure I understand the example... why would this present a problem from an injection standpoint? You can always sanitize the params in the request if you need to, no?\nMore generally, the issue I see here is that triggers need to be valid Python method names, since they get bound to the model. So I'm not sure how we could add special characters, since something like model.%my_trigger() isn't valid Python. (In theory we could add a Machine flag to prevent dynamic method binding, and then you could call the trigger directly, but that seems like an edge case, so I incline to not support it unless there's more demand.)\n. Thanks! I agree that we shouldn't just ignore the other transitions. But I'm not sure if we should add edges indefinitely in this scenario, as that could clutter things up quickly. The alternative would be to update the label of the existing edge (so it shows something like \"event_0 | event_1 | event_2 | event_3\". Could you add a figure showing what the updated result looks like when there are many other transitions? If it's still manageable, I'm happy to merge this. Otherwise maybe try the label updating route?\n. Thanks for the PR, @aisbaa. Could you provide a quick summary of the concrete benefits? I'm not familiar with tox, and will look at the docs when I have a chance, but I'm kind of swamped at the moment. It's not immediately obvious to me what we gain over the current setup. (Just to be clear, I'm not expressing any skepticism about the benefits, I just don't have the time to look into it right now. @aleneum or @wtgee may have a more informed opinion.)\n. Okay, but in view of the nesting issue, maybe we should just go with my suggestion in #105 to only update the labels rather than allowing multiple edges between the same vertices. Is there a downside to that approach? I'm not sure we need to allow multigraphs in this context. Any FSM with a reasonable number of states is already going to look very messy as is...\n. You can already have default callbacks by passing before_state_change and after_state_change to the Machine initializer. I agree that it might be desirable to also have a default set of conditionals that get checked on every transition (and I think this has been raised before). That said, I'm not so keen on adding yet another argument to the initializer. As it stands, we already lack a prepare_state_change argument in the initializer that would be equivalent to the way before and after are handled. So at minimum we're looking at adding two more arguments to get a more consistent API.\nI think my preferred way to handle this would be to introduce a new TransitionDefaults object (could be just a dict, or possibly an instance of class Transition) that stores the configuration for all parameters that should be applied by default to all new Transition instances. That would include the callbacks before, after, and prepare, as well as conditions, unless, and anything else we want to have a default for. Then the user would only have to pass an optional object to the transition_defaults argument in the initializer. Seems much cleaner to me that way. Thoughts, @aleneum, @wtgee?\n. Is this an issue with Condition being nested inside Transition? If so, we could simply move Condition out of there. I'd prefer to keep it encapsulated since nothing else uses it, but if that's what's tripping up dill, this would be an easy fix.\n. Fixed in #120. Hopefully it works now, @ajax2leet!\n. Last time this came up (#106), it wasn't clear (at least to me) what tox offers that we aren't already doing. I'm not averse to adding tox support, but I also don't want to add config files for every possible testing package/environment. Practically speaking, what would this do for us?\n. Okay, I'm convinced! Merged.\n. I don't really like the idea of adding functionality for this specific use case to core.py. I think what you want to do can probably be done fairly easily by just copying the old transition to a dummy new one. Something like this should work:\n``` python\nfrom copy import copy\nfrom transitions import machine\nclass Model(object): pass\nlump = Model()\nm = Machine(lump, states=['A', 'B', 'C'], initial='A')\nm.add_transition('move', 'A', 'B')\nm.add_transition('also_move', 'A', 'C')\nCopy the\nold_transition = m.events['move'].transitions['A']\nm.events['also_move'].transitions['A'] = copy(old_transition)\nShould print 'B' rather than 'C'\nlump.also_move()\n```\nI haven't extensively tested the above, but I don't think the replacement should have any side effects.\nIf the above code works without any problems, we could consider creating a new utils module and adding the above code there as alias_transition() or something like that. Given that the aliasing can be done in two lines of code, I'm not sure it's worth it, except perhaps insofar as it alleviates the need to understand the internal Model --> Events --> Transitions structure.\n. That's a better solution. And we could still potentially add a helper method in a utils module, saving users from having to write their own add_alias method. It would be identical to your version but take the model instance as the first argument.\n. Thanks!\n. This is an interesting idea. In theory there's no principled reason why you shouldn't be able to use the same Machine for multiple models, provided you want identical behavior. Right now the only barrier I see to doing that is that we track the current State object within the Machine instance  rather than the model instance. This is actually a design flaw, in my opinion; I think it would be cleaner and more sensible to maintain state only in the model. As it stands we already track the current state name within the model, but not the State instance itself.\nThis should be easy to fix without breaking the API. Assuming we move all state out of the Machine, we could then modify the initializer to take a list of models rather than just a single model. Any changes applied to the machine (e.g., adding new transitions) would thereafter be applied to all available models. So that would work fine in cases where you have all of your models instantiated in advance of Machine creation. But note that you wouldn't be able to easily add extra models after initializing the Machine. Simply pointing to the right Machine in your models wouldn't give you the desired behavior, since you wouldn't automatically have all the dynamically added triggers and callbacks. For that, we'd need to implement some kind of add_model() method in Machine that re-applies all existing transitions and callbacks. That's also potentially doable, but I'm not sure I want to take that step unless this is going to be a fairly common use case (whereas simply managing multiple existing models should be trivial).\nAnyway, thanks for opening this issue. I'll think about it some more, and we should be able to do at least something to accommodate this use case without having to change much.\n. Unfortunately, I don't think it's that simple; the State instance currently stored in machine.current_state is used for a number of things--e.g., to determine whether the requested transition is valid for the current state, or to update the EventData instance passed to callbacks. So if you have just one Machine with a lot of models, you're going to run into serious problems if you want to allow those models to be in different states. To make things work properly given the current code, current_state will need to be a property of the model. And like I said, I think it's a design flaw to maintain individual model states in the Machine class anyway; in my view, the Machine should focus on the transition logic and support as little state as possible. This isn't hard to do, but would require patching most of core.py as well as all of the subclasses in extensions.py, so it may have to wait until I have some time (unless you want to submit a PR for it).\n. Oh, and just to clarify: having only the state name in the model is fine; like you say, the corresponding State instance can be looked up in the Machine. But that still requires rewriting various parts of the code to access the right State via the current model (which would have to be passed in from the trigger; right now it isn't) rather than directly from self.current_state.\n. @aleneum, agreed, that's exactly the implementation I would go with as well. I've played with this a bit already and have a version of core.py that passes all tests in test_core with machine.current_state completely removed and all references occurring via the model. I'll push the branch shortly for comment. If it looks good, we'd just need to amend the extensions accordingly.\n. I just pushed a multiple-models branch that modifies the core Machine instance to handle multiple models. As noted above, right now this only works for models passed in at machine initialization. It will not automatically update new models with existing transitions. We can talk about whether that's worth supporting, but for now I lean towards no.\nRight now all changes are completely compatible with the existing API. The one potential sticking point here is that we might want to rename self.model to self.models. Right now, to prevent API breakage, I internally store models in self.models, but define Machine.model as a property that returns a single model if the list has length 1, and the full list otherwise. I'm not thrilled about this, but it seems like the best way to preserve the API, and given that right now probably nobody in the wild is expecting multiple models, it doesn't seem wise to tamper with this.\nI also had to remove a test that in my view shouldn't be a supported use case anyway (passing optional arguments with send_event=False when the callback function is not explicitly defined to handle such an argument), as it was interfering with passing the model as the first argument to trigger.\n@aleneum, see what you think. If the changes look good, we'll need to similarly update all the extensions etc. A bit tedious, but should be straightforward, I think. @gemerden, assuming you're not using any of the extensions, do you want to test these changes out and see if they work for your use case?\n. +1 on moving the graph to the model.\n. And thanks for fixing all the other modules so quickly!\n. There's no built-in handling for this sort of thing; you would just write your own conditional that checks lump.heat and moves to different states depending on its value:\npython\nlump.heat_up()\nif lump.heat:\n    lump.do_something_A()\nelse:\n    lump.do_something_B()\n. I don't have any principled objection to model mixins, and actually kind of like the idea. I also like the idea of handling accepted and rejected states in the model rather than in Machine. That said, I think if we were to add a model mixin, it should probably be something more generic, and support arbitrary tags on model states--and then final/rejected states can just be a special case. For example, here's a TaggableModel mixin that's basically just a more generic version of the above example:\n``` python\nfrom collections import defaultdict\nclass TaggableModel(object):\ndef __init__(self, tags, callbacks=None):\n    # tags is a dict with the tag as key, and a list of state names as vals\n    self.tags = tags\n    self.tagged_states = defaultdict(list)\n    for tag, state in self.tags.items():\n        self.tagged_states[state].append(tag)\n\ndef has_tag(self, tag):\n    return tag in self.tagged_states[self.state]\n\n```\nWe could easily add dynamic tag checking for all passed tags--e.g., model.final_tag() would be the same as model.has_tag(final). And init could potentially have a callbacks dict as another argument, where keys are tags and values are bound methods to call whenever the model enters a state that matches the key. For example, {'reject': 'throw_hissy_fit' } would be equivalent to (and could be implemented as) a call to model.on_enter_reject('throw_hissy_fit').\n. Alternatively, we could also inherit from State, rather than having a model mixin. We could have a TaggableState class that takes an extra tags argument, which is a dict where keys are tag names, and values are (optional) methods to trigger when entering the state. The main downside of this approach is redundancy--it would be a bit annoying to specify the same behavior for the 'final' tag in multiple states. So I think I prefer to do this just once, via the model.\n. I can see arguments for either order (and the same thing goes for the behavior of on_exit()), but I think it's probably a bit late in the game to change this unless there's a clear consensus that the change would make sense (and there doesn't seem to be). @ahmedabt, would a log line like @aleneum suggests be helpful? If not, I suggest we close the issue, though we can always revisit it again in future if there are additional votes for flipping the order.\n. Can you elaborate? What would the expected behavior be? It's true that accessing Transition instances is a bit cumbersome at the moment, but part of the issue is that transitions aren't uniquely identified by the trigger name--there can be multiple transitions triggered by the same model call, depending on the current state. Is the idea that calling model.get_transition('my_trigger_name') would return the first Transition instance valid for the model's current state and the named trigger method? Or are you thinking of something else? We can probably accommodate this, I just want to make sure I understand what you're looking for.\n. On re-reading, maybe I'm overthinking this. Do you just mean you want to fire a trigger based on a string name? I.e., instead of model.my_trigger(), you want model.fire_event('my_trigger')? If so, I think the Pythonic approach would be:\ngetattr(model, 'my_trigger')()\nI don't think you need to eval() anything.\nNote also that the Machine class has a set_state() method, so you can also call machine.set_state('desired_state') to achieve the same thing. I suppose we could add (or move) this to the model, but it seems to work fine as-is.\n. Well, one limitation (though it's actually a feature and not a bug) of set_state() is that it won't cause any of the callbacks to fire. It'll just immediately move the model to the specified state. So you don't want to use set_state() if you need the callbacks to do stuff for you. I would probably go with the getattr approach above.\nOn further reflection though, I do think it probably makes sense to have an easy way to trigger events from the model by passing a string. While the approach I suggested above works fine, the user shouldn't really have to reach inside the model that way. @aleneum and @wtgee, any objections to my adding a trigger() method to the Model?\n. I was planning to get to this once the multiple-models branch was merged, but thanks for taking care of it! :)\n. +1 for merging. More test coverage would be nice, but since all the single-model tests seem to pass now, and probably 99% of use cases will continue to be with one model, I don't know that we need to invest a lot of energy writing multiple-model versions of all the tests.\n. I don't know that we need the fallback. I doubt this will be functionality that someone expects to exist (and even if they do, they won't necessarily expect it to exist at .trigger()); if someone discovers it, it'll be via the documentation. And it seems very unlikely that someone would (a) already be using .trigger and (b) be unable to change it if they want to take advantage of this feature. So I would lean towards just skipping binding with an info message if .trigger already exists.\n. Alternatively, we could allow the user to name the .trigger method themselves. But that seems like overkill to me given that this is likely to be a pretty uncommon use case.\n. Looks good to me!\n. Yeah, I think this makes sense too. It may break expected behavior for some users, but will be easily fixable by changing log-level for those who need it.\n. I agree that this would be useful to have, and seems within the scope of the package. As to whether it should go in core.py or be an extension, I think it could go either way. But I guess my preliminary inclination is to lean towards implementing a new mixin called something like MachineUtilities that consolidates various helper methods like this in one place.\n. Okay, it sounds like putting this in core is the consensus solution. I think I'd prefer to call it get_triggers, and I like the idea of catching states in *args. \n. While I can see the utility in what you're suggesting, @botzill, I worry that adding support for common ORMs could get messy pretty quickly (see also #142), and maintaining some uniformity in the API might take some effort. Given that @aleneum's suggestions are quite elegant and minimalistic, I think you could probably solve your problem with minimal code by subclassing Base and adding the property getter and setter. Then all of your models could just inherit from the state-supporting subclass.\nI'm willing to reconsider adding support for this kind of thing if we get a lot of requests for it, but I think for that to happen I'd want to know that someone is willing to commit the time to maintaining and updating the various mixins in an ORM integration module, and I'm not sure that I or any of the other current maintainers want to take that on.\n. This looks great, thanks @alexandrenorman ! Per discussion in #141, I'm a bit apprehensive about merging this kind of thing into the core package at the moment. But I could be swayed...\nAt the very least, having this here will make it easy for other people to find. :)\n. There's a Machine-level after_state_change handler you can set:\n``` python\nclass Model(object):\n    def state_change_callback(self):\n        ...\nstates = [...]\ntransitions = [...]\nmachine = Machine(Model(), states, transitions, after_state_change='state_change_callback')\n```\nThat will only fire after a successful transition to any new state.\n. Sorry, I also missed this. +1 on both ideas as well. And also +1 on @wtgee's suggestion to not display auto_transitions by default, and call the flag display_auto_transitions (or maybe show_auto_transitions).\n. @wtgee, models can now be in different states, so I think it makes sense to keep the graphs in the model. See discussion in #128.\n. Sorry, 0.4.2 is long overdue. Will try to push to PyPI today.\n. Done!\n. Thanks--closing this here in favor of discussion on SO. But the short answer is that this isn't supported and is unlikely to be added. Sorry!\n. Actually, I take that back--my mistake. In theory this should already work. So will treat it as a bug.\n. Looks like it works fine; the fix is on SO. Closing issue.\n. Okay, looks like there was a bug in the handling of the prepare callback--it wasn't handling callables properly, just strings. Should be fixed as soon as @aleneum or @wtgee merge the PR I just opened. Thanks, @PaleNeutron!\n. Sorry about the delay. This all looks great to me, and I don't think it's worth the extra effort to make it more compact. I agree that a user who wants something pretty and not just functional should expect to have to customize the graph themselves. Okay to merge as far as I'm concerned.. This seems reasonable to me, so I opened a PR for it. I do worry that at some point core.py will start to get really cluttered if we keep adding this kind of functionality, but since this patch was pretty trivial, I think it's fine.\nI haven't add checking to see if states exist yet, but I agree it would make sense to do that, @aleneum . Let's open a separate issue for that though.\n. Oh, I see. Yeah, that makes sense.\n. I don't think it's on the agenda right now, but in principle, it probably wouldn't be very difficult to add probabilistic transitions via a subclass that only triggers its parents execution methods with some (predefined) probability.\n. Actually, on second thought, I'm not sure it's worth tinkering with the package code for this. Depending on your use case, you might be able to do what you want just by setting up a transition probability matrix yourself, and firing (still deterministic) triggers based on that. I.e., suppose you have three states in your machine, and you can transition between any two states i and j with some fixed probability p_ij. Then you could have something like:\n``` python\nclass TransitionMatrix(object):\n    p = np.array([[0.3, 0.1, 0.6], [0.2, 0.5, 0.3], [0.6, 0.4, 0.0]])\ndef move(self, machine):\n    # figure out the index of the current state\n    i = machine.state.get_index()\n    # get the target state probabilistically\n    target = np.random.choice(np.arange(3), p=self.p[i])\n    # move to the target\n    state_name = machine.states.keys()[target]\n    machine.set_state(state_name)\n\n```\nThe above definitely won't work (for one thing, there's no get_index method), but hopefully it gives the general idea. Feel free to elaborate on your use case if this doesn't quite get at what you intend.\n. This is an interesting issue, because in principle the user could want to delete either an entire trigger, or just a particular transition, and we currently don't support the ability to do either. Maybe the way to go about this would be a more general remove_transition method to parallel add_method, where you can specify any combination of trigger, source, and dest, and the most inclusive set is removed (i.e., if you only specify trigger, the trigger is deleted along with all corresponding Transitions; if you specify a trigger and dest, all matching Transitions are removed, but the trigger is retained as long as there's at least one Transition with the same trigger but a different dest, and so on.. Alternatively (and more or less equivalently), you can set send_event to True in the Machine initializer, in which case your callback functions should expect to receive an instance of class EventData as their first argument, which is basically just a container for keywords. Search for \"send_event\" in the docs for an example.. This can't be done right now (well, you could just_ append to machine.models, and that will give you everything except the ability to register triggers properly), but it makes sense to move the model registration code into an encapsulated Machine.add_model() method, and it would be very straightforward.. Closed in #166.. Thanks for the PR! This looks good from my perspective (will take a closer look once tests pass), but we definitely need to make sure the nesting doesn't break. Nesting is @aleneum's baby, so maybe he can weigh in when he has a chance.\nOne quick question: is there any reason to turn Machine.models into a set? I get that this will in principle make in checks more efficient, but the list overhead is likely to be trivial here, and I think it's a good idea to maintain a record of the order of entry of the models.. @paulbovbel I don't have strong feelings about the set thing, but since it's not necessary, and performance is not likely to be an issue, I think we should probably stick with a list. I can't think of a use case for model order info off the top of my head, but it doesn't hurt to have it, seeing as the logic is otherwise identical.. Looks good, thanks again!. Good idea, thanks for the reminder. @aleneum, let me know if you want to pull the trigger on PR #151 in the next few days; if so, I'll include it in the 0.4.3 release. Otherwise I'll bump now and we can  add that next time.. I agree, this is an excellent addition, thanks! Re: the add_self API issue, per discussion in #166, my preference would be to break the API in 0.5 and (a) make it so that model=None initializes with an empty model list, and (b) remove the add_self argument entirely. Then users who want to initialize with self as the model can pass the special string 'self'--i.e., Machine(model='self'). I think that approach has the most sensible semantics, as I agree with @aleneum that it's kind of weird to say \"hey, set yourself as the model by default, unless you explicitly say that you don't want that to happen\". It makes much more sense to me to make the user explicitly acknowledge that they're trying to do something a bit counterintuitive (though very useful), which is to set the newly initialized Machine as its own model. That also means a naive user who hasn't bothered to read the documentation can probably intelligently guess (correctly) that the following will successfully set the Machine as its own model:\npython\nm = Machine(...)\nm.add_model(m). Re: 'self'--funny, it didn't occur to me that we could just make model='self' the default, in which case the current behavior is preserved. I think by far the most common use case is that model will be explicitly passed another object or list anyway, so it's not like making model='self' the default will add work for most people (only the few who really want to initialize with no model at all). So I lean towards 'self' being the default. And actually, if we go with this solution, I would move to change this ASAP in the new release so that we can drop add_self before many people get used to it.\nRe: initial, I guess I have a pretty strong aversion to forcing users to specify the initial argument in the most common use case where the Machine doesn't really start doing anything useful until it's explicitly triggered the first time. I think part of the reason the package has succeeded is that it appears, to the eye, very minimalistic (though there's plenty of power under the hood), and its behavior can be guessed at without having to read very much documentation. While conceptually it's perfectly sensible to expect a state machine to require a user to specify what state it starts in, I like packages that make sane guesses about the defaults. I also suspect that removing the automatic introduction of an 'initial' state when needed will break a lot of people's code. While I'm not averse to that on principle, this one strikes me as a change that we can easily avoid.\nThat said, I definitely agree with @paulbovbel that there should be some ability to initialize without a default initial state. I agree that the suggestion to allow None, False, or str values is a bit clunky, but I think it's probably the best balance between supporting the functionality we want and maintaining users' goodwill. I would probably reverse the meaning of None and False though, so that the new default is False, and it behaves like the current None--i.e., it creates a new 'initial' state if none is provided. Then explicitly setting None would produce the behavior @paulbovbel wants, where an exception is thrown if models are provided. One reason I like that is that it would be consistent with how we're handling the model argument, in that we're cultivating the expectation that some of the key arguments sometimes have to be explicitly set to None.\nWhat do you guys think?\n. +1 to @aleneum's suggestions. And actually, we should probably already be checking if a State with name 'initial' exists in the states argument before calling Machine.add_states('initial'), because it's conceivable that a user will want to define that state themselves and give it some extra behavior. I would suggest maybe deferring the addition of the 'initial' state until after the other states have been added. That will allow us to check against the keys in the .states dict, and only add the initial state if it doesn't exist.\nThis also brings up a more general issue: right now, no uniqueness checking is done in Machine.add_states, which has the potentially undesirable side effect of overwriting older states with newer ones that share the same name. I think it makes sense to enforce a name uniqueness constraint, so maybe we should handle this by raising an exception if the user is trying to add a State whose name already exists. We could add an explicit replace argument that would suppress the exception and give the current behavior (where the last State passed in with a given name is used).. I'm on board with the deprecation warning, but I really don't like the idea of implicitly passing args and kwargs in init, because it makes it impossible to know what the valid arguments are without inspecting the code or reading the docstring. As someone who relies on IDE completions a lot to determine what arguments to pass, I'm loathe to force users to go read the docs every time they want to initialize a Machine and can't remember what the valid arguments are.\nI don't see it as a serious problem that users who might not have explicitly specified model=None will still get a warning, because some of those users will no doubt be intending to use the Machine as model, but simply not explicitly stating that because they know it's the default. So I think we still want to make it clear that the behavior will change even if users haven't tampered with the default arguments.. Thanks for the ping--and yes, I agree with @aleneum's suggestion too. I think as soon as model='self' is the default, this PR is ready to merge. (Or we can merge and then change, either way.). I appreciate the contribution, @janLo, and I can see this being useful on occasion, but I'm not sure it's a sufficiently common use case to warrant adding a special case... the original intent was to keep the core module minimalistic, and I think feature creep is starting to set in. But I could be convinced if others think this is particularly useful. Thoughts?. I like the functionality, my concern is about long-term maintainability and feature creep. Each feature like this is individually lightweight and almost always sensible, but can introduce weird edge considerations (cf. @ankostis' comment) and makes the codebase a little harder to learn and maintain. Again, I'm not fundamentally opposed to adding it, but I'd like to hear the other core maintainers' thoughts on it.. Also, if we merge it, the behavior should probably be described in the docstring and not just the documentation. (I just noticed that we don't describe what source='*' does in the docstring, which was my omission, but that should probably be added as well.). Done, thanks!. Sure, but it's probably better if I add you as a maintainer on PyPI (for some reason I thought only one person could have push privileges on PyPI, but it looks like I was wrong). What's your PyPI username?. Done! Closing.. Can you clarify what the problem behavior is? As detailed in this README section, When send_event=True, args and kwargs are stored inside the EventData object. So the expected pattern here is for callbacks to get what they need from, e.g., event.args and event.kwargs. Is there a reason this approach doesn't work for your use case?. Agree both that this would be great, and that it should probably go in a different project. But, in order to make it as modular as possible, it might be nice to try to design a JSON spec that serves as an intermediate representation between GUI and Python code. Then we could implement some JSONReader functionality in transitions that takes a JSON object as input, and constructs and returns a corresponding Machine instance (the location of the model definition would presumably be specified inside the JSON object, or passed in simultaneously). If we can do that, then the GUI would ideally generate a JSON spec for transitions rather than interfacing directly with the package.\nIf we decide to go the above route, it would also be nice to import export functionality in Machine that outputs the configuration to JSON. Then, people who don't need to maintain state but only want to track the configuration could easily store and send around compact, human-readable representations.\nOf course, I may be overthinking this, as it's not like the typical Machine requires a lot of code, plus there would be little point in implementing an intermediate spec if literally the only thing using it is a GUI package.. > However, extending the convenience function Machine.on_enter/exit_ to also allow Machine.on_timeout_ would require changes in core (which I try to avoid).\nHaven't thought through this in detail, but couldn't we monkey patch State when add_state_features  in the new states extension module is invoked? Admittedly not the most elegant solution, but it could provide the desired functionality without cluttering up core.\nIf we think there might be other decorator-based extensions to State that might need to dynamically add methods, we could probably create a base StateExtension class all the other classes inherit from; then, in __init__, we would look for a _dynamic_methods class property, and, if found, would monkey-patch each of the listed methods into the State class. Would something like that work?. At first glance, this makes sense to me. Do you want to open a PR for those changes, @booware?. Sorry, yes, sounds good to me!. http://www.dictionary.com/browse/dither?s=t. If you click on the little audio icon, it will pronounce it for you. Closing this issue.. This is a usage question rather than a bug report/feature request, and is more appropriate for Stack Overflow. Please post it there with the tags [python] and [transitions]. Thanks.. I think this is a reasonable feature to add, but one thing I'm not clear on is why the trigger argument is mandatory. Wouldn't it make sense to also make it optional, so that the user can, e.g., retrieve all transitions that have a specified source, regardless of trigger?. I don't think consistency matters much here... removing transitions feels to me like a less common operation, and since it's destructive, it's not crazy to make removal harder to do accidentally.\nOh, also: let's return a list rather than a generator. This will almost never be a memory-intensive operation, and for the sake of user-friendliness and consistency with the rest of the API, we should avoid returning a generator when the user isn't going to necessarily being expecting one.. Yeah I agree there's a place for this, but barring demand from other users, I don't think it justifies the increase in code complexity.\nI wonder if the way to handle this is to create a new subfolder of notebooks called \"patterns\" or something like that under examples, and then every time something like this comes up, we can create a new notebook that illustrates the usage. We can then put a README in there with brief summaries of all of these different usage patterns that don't quite rise to the level of core features or extensions.\nProbably worth a sweep through old issues at some point too, as I think there have been a bunch of similar issues before that we've closed without implementing, but might be hard to find by searching.. Actually, the FAQ notebook looks it's already the right place for that--except maybe we should make it a folder and put each question and answer in its own notebook.. Hi @nicain,\nIt's not in requirements.txt because it's not required for transitions to work--but only for optional functionality. I'd be fine with adding it to an optional-dependencies.txt file or something like that, but it shouldn't go in requirements. Alternatively, we could (should?) move all that stuff to setup.py and make it an install option (e.g., [full]).\n  . Oh, hah, I didn't realize we already define a 'diagrams' scheme in setup!\nI don't know that moving to pipenv would buy us anything at this point. But we should perhaps update the installation section of the README to note that users who want to use the graphing tools should pip install transitions[diagram].\nEdit: nevermind, I see that we do already mention that in the diagrams section, which seems fine to me.\n  . This works nicely, but one potential limitation is that if the user passes in callbacks as arguments, any pre-defined method will be ignored even if it exists. Perhaps we should treat the pre-defined method as just another callback, and add it to the on_enter and on_exit lists if it exists? Let me know if you think this makes sense. If not, I'll merge as-is.\n. Let's add this to tests_require in setup.py as well.\n. Maybe add get_graph to Diagram as an @abstractmethod to make sure it's implemented by any future graphing interfaces.\n. Is there a reason to have this as a static method in this class? I don't see it invoked from anywhere other than the tests right now--in which case it should probably be moved into the test class.\n. Oh, right, thanks for catching!\n. Wait, no--that's checking dest, not source. At this point dest hasn't been converted, only source.\n. Done\n. Not sure I like the idea of adding an add_self argument. I agree that we don't want to assume the user wants to add self to the model list automatically, but I think I'd prefer to handle this by making the default value of None leave the model list empty, and requiring a subsequent add_model() call. We could have a special case for the string value self--i.e., Machine(model='self') would produce the current behavior.\nThis isn't ideal, obviously, because it would break the API. But once we allow dynamic addition of models, it starts to seem quite counterintuitive to me to that the way to obtain a truly empty model list is to explicitly pass add_self=False. It seems like the more sensible approach is to default to an empty list, and make the user explicitly indicate if they want to populate the model list with the Machine instance itself.\nMaybe we can keep the proposed approach for now, and save the API-breaking change for a major version release. Thoughts?. Please add a docstring.. Actually, it looks like some of the other public methods also don't have docstrings, so you can ignore this and I'll do a pass later.. @wtgee this PR adds the ability to dynamically add models after Machine initialization. Before, it made no sense to initialize with an empty model list, so None could be interpreted as \"use yourself as model\". Now, the user may want to initialize with no models, and add some later, so if we wanted to avoid using an add_self argument, we'd need to change the behavior of model=None. But I agree that for the time being, we should avoid breaking the API. So I'll merge the current version as-is.. ",
    "nzjrs": "Now you describe it, I like the add_ordered_transitions() option the best.\nThere is a bit of subtlety with looping from state_end back to state0, and\nonly therefore running the initial state only once. I don't know how that\nfits into this api as I pass that as an argument to next_state().\nWhat do you think?\nMerged, thanks!\nI like the idea of adding something like this to the codebase. Not sure if\nit should be its own OrderedStateMachine class; an alternative would be to\nhave an initialization argument called ordered or sequential that's False\nby default but will assume states are implicitly ordered if set to True.\nAnother question would be what to name the triggering method(s). A\nconvention like {s1}to{s2} is fine, but it might also be nice to be able\nto assign a single method to all cases (e.g., advance()).\nActually, another way to handle this might be to add a separate\nadd_ordered_transitions() method to the Machine class that takes optional\narguments for states (a list of states ordered in the desired sequence;\ndefaults to all states in the existing order) and trigger_name (defaults to\nyour convention, but can be set to a single string).\nThoughts?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/2#issuecomment-67511466.\n. If you don't feel it belongs in the machine class then I would rather make an OrderedStateMachine object, more or less like I proposed initially, and put it into utilities.py (and then imported in init.py when stable)\n``` python\ndef add_ordered_transitions(machine, states=None, trigger_string='%s_to_%s', loop=True):\n    pass\ndef next_state(machine, loop_includes_initial=False):\n    pass\n```\nWhat do you propose exactly with advance()? should such a magic method get attached\nto each state, functioning like next_state() above?\n. I'm heading off for a week or so on Christmas holiday, so I won't be able to get back to this before then.\nI like your proposed design, so if you code it first that would also be great.\n. ",
    "ExpandOcean": "Agree! I use plantuml, and I think it's better to me:) By the way, your work is just what I want for a long time, thank you!\n. When I set send_event=True, it works:) Another question, how can I add some logical operation(AND/OR/NOT) to conditions. I have no idea how to excute the transition when condistion is not true. I think define a not_condition function should work, but it seems a little ugly. Thank you!\n. ",
    "bibi21000": "Yep ... it should be a good idea. Don't know if you know blockdiag ant its friends (http://blockdiag.com/en/index.html). Maybe the can help you as they can be embeded in many documents (http://blockdiag.com/en/blockdiag/embed_diagram.html)\nBy the way, thank you very much for transitions ... your statefull machine save hours of dev\nThanks again\n. ",
    "svdgraaf": "I actually have code laying around which does just this, rendering the graph using pygraphviz, I'm not too satistisfied with the pygraphviz output though:\n\nYou can find a quick gist here: https://gist.github.com/svdgraaf/198e2c0cf4cf0a031c84\n. Sure, I'll try to make some time this week to create a PR..!\n\nOn 3 dec. 2015, at 16:33, Tal Yarkoni notifications@github.com wrote:\nThis would be a great start, @svdgraaf! I agree that the result could be improved aesthetically, but for now it would be great to have even rudimentary diagramming capabilities. Do you want to open a PR for this? I suggest putting your code in a separate 'diagrams' module and refactoring slightly so that the graphing call takes a Machine instance as the first argument. We can also maybe add a diagram() method to the Machine class for convenience.\n\u2014\nReply to this email directly or view it on GitHub.\n. I created a PR, let me know of any feedback:\nhttps://github.com/tyarkoni/transitions/pull/47\n. @krisztianfekete it's optional (you can provide your own diagram class), do you have a suggestion for other tools?\n. Perhaps we want to add pygraphviz to the default requirements as well? Not sure.\n. I'll add a test, good call :)\n. Ok, just need to tweak the python 3 compatibility a bit :D on it!\n. boom :)\n. First ever public PR :heart:\n. I like it! :D\n. \n",
    "e3krisztian": "I like this feature, however I think the current implementation requires pygraphviz.\nI'd prefer if it would be optional - when the feature is not needed it need not be installed.\n. @svdgraaf I have no suggestion, pygraphviz is fine, and I like as it is now - good work! :)\n. ",
    "mayowa": "+1 I think it would a great idea for on_enter_ and on_exit_ methods to be detected in the model and executed during transitions, Methinks it would make the code a whole lot more readable \n. I'll do it and send you a PR\n. @tyarkoni I think that was it, I know that bit of code had me scratching my head a bit, till I figured out what was wrong (Which is why I remember it). Sorry I cant be any clearer. its been been a while since I worked on the project\n. Given the way the library is structured (i.e states can have multiple callbacks), that makes sense.\n. ",
    "bvdeenen": "Hi\nFirst of all, I have really cleaned up our code using your transitions library. Thanks!\nI disagree with you though :-)\nIn FSM's used in communications, it's very common, to create an event in the future, like 'timeout', which in case the FSM is still in the state 'waiting_for_answer' should trigger a state transition to the state 'offline'. I don't care about the 'timeout' trigger if I'm already in the state 'auth_connected'. I just want it discarded. When states and triggers are fairly complex, I really don't want to define all triggers for every source, it complicates the FSM, and adds nothing.\nTo me, this kind of behavior is the default of an FSM. Unspecified events should be ignored.\nSince we disagree on this, I've just added the single file to our project (with my changes). \nAgain, thanks for this well thought out piece of code.\n. Hi \nI'm fairly sure http://machina-js.org/ ignores unspecified triggers.\n. Hi Tal\nI'm not working with that piece of code at the moment (It's operational\nin our product, with my changes, but we just copied your code). So yes,\nI don't really have time to dig it up, so if you could do it, that would\nbe awesome.\nI think a global trigger would be great, because that's the way I think\nFSM's should work :-)\nIf you don't have time, I will make time in after two weeks (our sprint\nperiod), because I think it's important that we work together on making\nopensource projects better. This is going to be a key theme of the\nstartup I'm working at.\nThanks for this great project\nBart\nBart van Deenen bart@infoposter.nl\nOn Tue, Apr 14, 2015, at 22:24, Tal Yarkoni wrote:\n\nHi @bvdeenen[1],\nI received an email from another user who also would like to see this\nexact feature implemented, so as promised, let's go ahead and merge\nit. But would you mind making the following two changes first:\n1. Write a test for the new functionality.\n2. Rename the ignore argument to something slightly longer and more\n   descriptive (maybe ignore_invalid_triggers). If you don't have\n   time, just let me know and I'll do it.\nAlso, given that we're adding this, I wonder if it would make sense to\nalso add a global switch (at the Machine level) that changes the\ndefault behavior. One concern the emailer raised is that he has a lot\nof different States, and having to set ignore=True explicitly in each\none could get unwieldy. If you feel like it, maybe add a global\nignore_invalid_triggers to the Machine that changes the default\nbehavior in the State initializer, provided it doesn't complicate\nthings too much.\n\u2014 Reply to this email directly or view it on GitHub[2].\n\nLinks:\n1. https://github.com/bvdeenen\n2. https://github.com/tyarkoni/transitions/pull/10#issuecomment-93049599\n. ",
    "dcere": "Thanks to you!\n. ",
    "xdmiodz": "never mind, I can use a decorator instead\n. @tyarkoni please let me know if want me to update README.md too \n. Oh, I completely missed the possibility to use a 'next_state' trigger. For me it will do the job. Thanks!\n. ",
    "vltr": "Hey, thanks! No credit for me at all, I just bumped into your project and saw this minor typo, nothing special. But your lib is awesome! No dependencies, highly pythonic; I can use it without any effort with other libs, including Twisted. Exactly how a SM should behave ;) Thaks a lot!\n. ",
    "lulingar": "I would love to contribute, but in quick reading core.py I got a little overwhelmed since the code, despite being well written, is rather long. If you have a suggestion where I could add logging hooks safely, I would give it a shot.\n. ",
    "porceberkeley": "Thanks again. I think it will be a very useful example if someone comes up with a simple FSM, such as a vending machine, as a self-contained python script, which never exits. (That will also address my original question.)\n. ",
    "njouanin": "0.2.7 installed successfully.\n. I've corrected it. In fact you just need to prevent getattr in core.py from being called with getstate. I'll create a push request => See issue #33 \n. Tests are passing on my computer with python 3.4.\nI'll check why tests are failing on travis. \n. pickle/unpickle doesn't work on python < 3.4 because the pickle protocol used by this versions doesn't support bound methods in objects. Only protocol 4 supports this (see PEP 3154 and http://bugs.python.org/issue9276)\ntransitions makes a big uses of bounded methods and making pickle works for python < 3.3 would require a lot of changes. What do you think of that ?\n. pickle/unpickle of Machine works on Python 3.4 with built-in pickle module. For Python < 3.4, a workaround is to use dill module as shown in unit test.\nThe fix in transitions/core.py is mandatory for making pickle work with all python versions.\n.  When do you plan the next release ?\n. ",
    "acjc": "No problem, thanks for getting back to me :)\n. Thanks for merging, would you mind doing a new pip release?\n. ",
    "bit-pirate": "I'm fine with leaving it as is following your suggestion. Though it would be good to add this solution as a note to the alternative initialisation section in the readme.\n. Maybe I'm hitting this because of the way I'm using the callbacks (triggering state changes within the callbacks, see #30). Let's discuss the other issue first and come back to this one in case it still persists.\n. That's fine. I haven't ran into this issue again after I moved the transition calls out of the state callbacks.\nI now use worker methods for each state. Works fine enough for me.\nThanks again for this great package.\n. > unless you're launching new threads\nNo threads, but\n\none exception is that if you have a callback that itself triggers a state change\n\nI'm guilty of this one. So, I'm a misusing the callbacks here?\nIn my case I like the states to do some work (if in state A do this, in B do that). Where would I hook this kind of behaviour in? So far I'm putting this in the on_enter callbacks and some of them are triggering the state change.\n. Have been pondering about my implementation a bit. \nSo, if I would move the trigger call out of the callback, then I would need to create separate worker methods. Those would do the actual work and when finished trigger the transition to the next state.\nNow looking at implementing this, I cannot see another straight-forward approach apart from the \"if state A do this, if state B do that\", which you have mentioned in your blog post:\nif state == 'consent' and user_response == 'Agree':\n    state = 'demographics'\nelif state == 'demographics' and validate_demographics(data):\n    save_demographics()\n    state = 'personality'\n...\nBut then again, I started using this package in order to avoid this approach.\nAm I missing something here? Do you have more advanced sample code some where?\nIn my case there are several states with while loops in which another process is polled for information to decide on state transitions depending on the retrieved data.\n. ",
    "bitswype": "I see that a transitions + logging bug was closed 6 days ago.  I installed transitions via pip on 8/1/15.  Do I have an \"out of date\" version?\n. I believe this issue can be closed.  I uninstalled the pip version and cloned the git repo for installation and all appears to be working now.\nSorry for the false alarm!\n. ",
    "alexblack": "Hi, I'm facing this problem too.  I'm changing state within on_entering_state methods, and firing up my state machine with a single .start() trigger.\nIs this not a good way to go about this?\n. ",
    "aleneum": "Hi @alexblack,\nwithout code it's hard to tell what causes this issue for you. I would assume that your enter callbacks end in an infinite loop as tyarkoni suggests for bit-pirate. The logger output should give you some evidence about how the machine behaves.\n. Hi @Sispheor, \nI have answered in your issue tracker since I am quite sure one of your users is on the right track.\nIf we find an issue related to transitions, let's open a new one here.. Hi,\nI do not want to judge who is right or wrong here but for me \"before\" refers to the transition which is about to occur rather than the check if the transition should occur or not. I am pretty sure that there are cases where you prefer to reuse the preparation of the check but the same is true for (certain) transitions. \nI am biased towards tyarkoni's point of view because if \"before\" refers to the check preparation, we loose the ability to do something -- independently of the state -- before the transition occurs since we have to rely on exit and enter functions of (maybe multiple) states then.\nSo I would recommend to call a preparation function from within the condition check if necessary and also a \"tear down\" function if the transition wont happen. This is most likely two extra lines of code and should also be easy to comprehend.\nBest regards,\nAlex\n. Hi @omago,\nI guess I understand your point. And I also see where such a solution comes in handy (e.g. flushing a buffer, synchronizing resources or query things before the actual check...). Let me try to clarify why I personally favour the current concept:\nRight now the execution order is condition -> before -> transition -> after (case A). Conceptual speaking, before refers to a certain transition.\nYou argue for a concept change to before -> condition -> transition -> after (case B) where before references  the condition check(semantically). And you ask \"Why do both functions refer to transition? What must be done in before that cannot be done in after\" (right?).\nThe interesting part of before and after is, that both are independent of the targeted state which means I do not have to couple transition related logic to state related logic. That means I can use them to wrap the transition without touching the target state. Same pattern can be found elsewhere, sometimes called setup/prepare and tearDown/cleanUp (e.g. unit tests).\nSo you ask where setup/tearDown could be useful:\nLet's say I have a resource which must not be accessed during state transition (the current state for instance; it's undefined during transition but not during condition check). This means I have to lock and unlock the resource somehow during transition.\nLet's say we have:\npython\ndef beforeCheck(): #always called\n  ...\ndef afterCheck(): #not specifically mentioned but probably a case for someone somewhere\n  ...\ndef check(): #always called\n  ...\ndef beforeTransition(): #only called if transition happens\n  res.lock();\ndef afterTransition(): #only called if transition happens\n  res.unlock();\nIn case A I can put beforeCheck and afterCheck at the beginning and end of check to achieve your desired behaviour. This will keep everything condition related in one spot.\npython\ndef check():\n  beforeCheck(); # these are the two lines \n  #do stuff\n  afterCheck(); # I was talking about earlier\n  return result;\nThe assignment is condition=check, before=beforeTransition, after=afterTransition.\nIn case B I would assign before=beforeCheck, condition=check, after=afterTransition. \nNow I have to handle a fulfilled condition myself within check or in the enter function of the target state since somewhere I have to lock/assign/handle the resource. And without before=beforeTransition I cannot do that after the condition check is done. In my eyes the cleanest solution for such a case would be:\npython\ndef check():\n  ...\n  if result is True:\n    beforeTransition();\n  return result;\nSo, it is possible but it mixes two things: condition checking and transition preparation. Having before as beforeCheck and after as afterTransitionalso breaks the setup/tearDown pattern which in my eyes is often pretty handy. It might be useful to think about a similar thing for condition checking instead. So instead of before and after one could argue for beforeCondition, afterCondition,beforeTransition and afterTransition. This might clarify what is executed when. I, however can live with the two extra lines of code in the condition check in case A though. But that is just my opinion :).\nSorry for the long post.\n. I think this 'prepare condition' thing is quite complex. I can think of at least two different scenarios:\n- prepare -> check -> tearDown -> prepare -> check -> tearDown\n- prepare -> check -> check -> tearDown\nAnd what if some conditions require preparation and others don't...\nBut that is more complex than what you have in mind. So just for clarification: you argue for an action keyword which always executes code when Event.trigger is called?\nMy first thought was 'well, if it is always called, then call it':\n``` python\naction keyword\ntransitions=[\n    {'trigger': 'maybe_go_B','source':'A', 'dst':'B', 'action':'action', 'conditions':['testA,testB']},\n    {'trigger': 'maybe_go_C_else_D','source':'A', 'dst':'C', 'action':'action', 'conditions':'testC'},\n    {'trigger': 'maybe_go_C_else_D','source':'A', 'dst':'D', 'action':'action'}\n]\nexplicit call\nmodel.action()\nmodel.maybe_go_B()\n...\nmodel.action()\nmodel.maybe_go_C_else_D()\n```\nI don't quite get yet why action is more comprehensible than an explicit call.\nEDIT: Okay, difference is that action only executes code if the transition is valid. An explicit call does not check this.\n. Yeah, I am also convinced that this is a useful addition. Concerning naming: I think before_transition/before_check is a good solution. It might raise questions why there is no after_check and after_transition though. action is a bit more generic which is good (not focused on check) but also bad (semantically not as well embedded in the execution timeline as before_check). From these two I'd go with before_* and let time decide if we have to think about proper after_* handling. \nA third option could be thinking in events and let the keyword reference the transition. In this case I'd name it on_triggered, on_executed (before_execute?) or similar.\n. Thank you for your fast and detailed answer. I missed to check the closed issues. My thoughts went into the same direction as described in #31 and I would be happy to contribute (or at least give it a shot) if you consider this a promising road.\nAbout concurrency: I agree with you that in most cases its preferable to redesign rather than using concurrency. Since it is problematic not just on the programatic level. It's also tough to debug and hard to comprehend and follow, especially if you have not worked with the code before.\nIt just seems to be a required and used feature in our robotic department (which also looks for a new state machine). I better check with the guys again about what they need. I assume they have cases like:\nplanTrip ----> checkEnvironment\n    |                 |\n    V                 V\ncheckSelf ------>  doTrip\nwhere multiple settings and sensors have to be prepared and checked before something can be done. So yeah, the execution context is probably multithreaded, distributed and hell. I guess thats why they also want to rework they current solution :).\nThank you for your input so far. I will tinker around a bit and if we decide to build upon transitions I will probably contact you again.\nBest regards,\nAlex\n. Hi,\nlet me know what you think about this (flattening) approach to HSM and thread-safe function access. I had to do some minor adaptions to the main files to ease subclassing but tried to keep the changes as minimal as possible. The only functional change I have done is to remove the New Node from diagram creation and replaced it with the first state in the machines state list. I did this because New is not connected to the state diagram if 'New' is not part of the machine. If you find the approach to be sufficient but have some remarks concerning code style/best practise/philosophy, let me know and I will do by best to make the code 'blending' into transitions as best as possible. If this approach does not fulfil some requirements, I am open to constructive criticism/feedback as well :).\nBest regards,\nAlex\n. Hi,\nthanks for the feedback. \n\nIn the counter example, the instance name is 'counter' in some cases and 'calculator' in others--this should be made consistent.\n\nfixed\n\nSince LockedMachine and LockedHSM seem to have identical code, could we maybe use use a mixin pattern or something to manage this without the redundancy?\n\nfixed; I had tried multiple inheritance for LockedHierarchicalMachine but could not get it to work. I assumed there were issues with super and __getattribute__ in multi-inheritance scenarios... well, I tried again, now it works \\o/... seems these issues were related to previous locking approaches.\n\nFor consistency, we should probably call the LockedHSM class 'LockedHierarchicalMachine'. It's kind of annoying to type, but I think it's good to keep the nomenclature consistent.\n\nagree and fixed; Co-worker of mine always says 'code is usually read way more often than it is written' and with code completion it does not really matter.\n\nTo minimize redundancy, I think the 'Stuff' and 'Inherited Stuff' classes in the testing modules should probably be moved into a separate module (probably 'utils') under testing, and then they can be imported in multiple places as needed.\n\nfixed; called the module test_utils\n\nI'm not sure about using the underscore character to concatenate nested state names. \n\nThat one is quite tricky. I started with dots actually (like domains) but went for underscore later on because dots mess with auto_transitions. E.g. model.to_A.1 does not work and model.to_A/1 wont work either. The characters allowed in Python 2.x keywords are quite limited. Double underscores (to_A__1) would be an alternative or replacing '/' or '.' in function keywords only. State would be called 'A.1' but auto_transition would be to_A_1. The first approach stretches functions calls and second approach is rather inconsistent. Both are quite nasty. What do you think?\n. Hi,\nI also fiddled around with the diagram and doublecircle but went for self.machine._initial directly. I also prefer the idea of an additional argument in the _add_nodes method because it does not require to access protected attributes. Since _add_nodes is overwritten in AAGraph in extension.py. It should be added there too. This could also be used to mark the initial states of nested states. I would not pass it via get_graph but but let the machine pass it because the initial state was already declared in __init__. \nself.assertEqual(set(m.states.keys()) - set('C'), node_names) does work for me though.\n. This is where I got this information from:\nhttp://stackoverflow.com/a/23046244/1617563\nhttps://github.com/Koed00/django-q/issues/38#issuecomment-126878806\nand this might be a solution:\nhttps://groups.google.com/d/msg/celery-users/E3CurhqxNDI/1dW4Jh0dQMsJ\nIf pickle support is highly appreciated I'd take a look at the reduce approach.\n. Sure, I will do that. Also conflicts are merged and my profile is a bit more informative now.\n. I found a bug in diagram.py:_add_edges where only the first transition triggered for each state is added as edge. Let's assume states A, B, C, D and the following transitions:\n`````` python\n    transitions = [\n        {'trigger': 'walk', 'source': 'A', 'dest': 'B'},\n        {'trigger': 'run', 'source': 'B', 'dest': 'C'},\n        {'trigger': 'sprint', 'source': 'C', 'dest': 'D', 'conditions': 'is_fast'},\n        {'trigger': 'sprint', 'source': 'C', 'dest': 'B'}\n]\nThis should result in four edges but C -> B cannot be found. \n```python\n    for transition in event.transitions.items(): # ('C': [, ])\n        src = transition[0] # C\n        dst = transition[1][0].dest # D\n        container.add_edge(src, dst, label=label)\n``````\nsprintCB is not considered. I changed this to:\npython\nfor transitions in event.transitions.items():\n    src = transitions[0]\n    for t in transitions[1]:\n        dst = t.dest\n        container.add_edge(src, dst, label=label)\ntest_graphing was extended with an edge count test. I also moved self.assertIsNotNull(graph) a bit up in test_graphing.py since graph.get_edges() was called before this test.\n. Hi,\n@Ch00k: thank you for bringing this up. I googled around a bit to find some accepted loglevel guidelines about logging but could not find THE guideline. The essence of what I have read so far is  \"INFO is for operators and DEBUG is for developers\". Concerning this, I'd suggest to keep the transition and execution messages at the INFO level since it tells you as a user of the package what it is doing right now. But that's just my point of view.\nIf that does not work well with your code and your global log level, I'd suggest to set the level for the 'transitions' domain specifically like \npython\nlogging.getLogger(\"transitions\").setLevel(logging.WARNING)\nThat's how I deal with verbose libraries and packages.\nAbout changing the failed condition check level from INFO to WARNING:\npython\nlogger.error(\"Transition condition failed: %s() does not \" + \n     \"return %s. Transition halted.\", c.func, c.target)\nA \"failed\" condition check is part of the standard workflow and should not cause an error message.\nThink about a polled transition {name: 'upshift', 'source': 'Gear1', dst:'Gear2', 'conditions':'fast_enough'} which checks periodically if a car should change gear. Or a \"if X go to StateA else go to StateB\" case where the condition check of A will and should fail from time to time.\n. Hello @hstarmans,\ntriggered Events return whether the transition was successful or not. pause should return True because you try to transit from a substate of run into another state and this transition should be successful. I tested your code and that I could observe:\npython\nLight is run_green and on for 3s\nLight is run_yellow and on for 2s\nLight is run_red and on for 5s\nTraffic light is turned off\nWaiting 5s for all processes to finish\nStop pressed, traffic light stops\nLight is run_green and on for 3s\nLight is run_yellow and on for 2s\nLight is run_red and on for 5s\nLight is run_green and on for 3s\nLight is turned off temporarily\nTrue # <-- I changed the code to 'print trafficlight.pause()'\nPause pressed\nLooks fine to me.\nYour code does not work for python 2.7 because super requires an argument like super(ThreadClass, self).__init__() before python 3.\nThe LockedMachine RLock is not meant for public access. I decided to make in public rather than  protected (_lock) since LockedTransition requires to acquire it too. However, maybe this leads to confusion and a protected _lock would have been the better choice. I will consider changing it as well as extending the documention of the HSM.\nBest regards,\nAlex\n. Neat! looking forward to this feature! how 'fast' can you update graphs with this? close to realtime?\nSmall bug\n``` python\ncore.Machine\ndef get_graph(self, title=None, force_new=False, diagram_class=AGraph):\nextensions.HierarchicalMachine\ndef get_graph(self, title=None, force_new=False, diagram_class=AAGraph):\n    if self._graph is None or force_new:\n        # misses a parameter; diagram_class is mapped to force_new\n        self._graph = super(HierarchicalMachine, self).get_graph(title, diagram_class)\n       # should be  self._graph = super(HierarchicalMachine, self).get_graph(title, force_new, diagram_class)\n```\nAfter that, the tests pass as well.\nBest regards,\nAlex\n. Some thoughts about the usage:\nsend_event=true\nRather than relying on send_event=True, I'd suggest to call _update_graph implicitly if with_graph=True. You could subclass/mixin Transition instead for instance. send_event=true may require complete rewrites of existing models and also may lead to less comprehensible code since you pass event_data which is not necessarily required.\nModel.speed_reached(velocity) is easier to read and debug than Model.speed_reached(event_data) with checks like  if hasatttr(event_data, velocity)\nChoosing the first possible transition\nself._next_state = event_data.event.transitions.get(self.state)[0].dest\nThere is no guarantee that the first transition will be executed.\npython\ntransitions=[\n  {'trigger': 'advance', 'source':'A', 'dest':'B', 'conditions':'returns_false'},\n  {'trigger': 'advance', 'source':'A', 'dest':'C'},\n]\nAnother reason why you might want to connect _update_graph and the transition which will be executed.\nSuggestion:\n- make get_graph a mixin\n``` python\nclass MachineGraphSupport(object):\n    def get_graph(self, title=None, force_new=False, diagram_class=AGraph)\n    def set_edge_state(self, edge_from, edge_to, state='default')\n    def set_node_state(self, node_name=None, state='default', reset=False)\nclass TransitionGraphSupport(object):\n       # in _change_state it is certain that the transition will happen\n       def _change_state(self, event_data):\n           event_data.machine.set_edge_state\n           event_data.machine.set_node_state\n           # this will only work if this class is used as mixin\n           super(TransitionGraphSupport, self)._change_state(event_data)\n```\nThis would work without with_graph. In this case I'd also rework LockedMachine and HierarchicalMachine a bit to be pure mixins themselves.\nUsers can mix their Machines explicitly:\npython\nclass LockedHierarchicalGraphMachine(LockedMachine, HierarchicalMachine, MachineGraphSupport)\nOr there are already available in the library or transitions provides a machine class factory which also creates the appropriate transition... This might be more usable since order plays a vital role in mixins.\nWhat do you think?\n. I am all for it :+1:. It is one feature on my wishlist and pretty handy :). What about if you integrate this feature in a dev-branch in this git and I will refactor the code in extension modules and mixins. After that we review the changes and create a pull request from there if there is no more issue to be clarified.\n. Hi @SteveAmor, \nyes and no. #9 is a about a 'null' initial state but you are talking about a defined state. Question here is: \npython\nm1 = Machine(practise, states=['A','B','C'], initial='A') # on_enter_A not called\nm2 = Machine(practise, states=['A','B','C'])\nm2.to_A() # on_enter called\nShould m1 and m2 be expected to behave the same? My first impression is: yes they should. Let's see what others think.\nBest regards,\nAlex\n. > Basically, I think many people won't view the machine creation and the \"starting\" of the machine as the same thing.\ngood point. I can see where this is a feature rather than a bug :). So initial just defines which transitions are valid from the start and in which state the machine 'wakes up' so to speak. In this case I would suggest:\npython\nm1 = Machine(practise, states=['A','B','C']) # initialised in 'null' state\n... \nm1.to_A() # calls on_enter\nif on_enter executes code which always has to be performed before state A. This workaround just requires one additional line to achieve @SteveAmor's expected result. Nevertheless, this 'special' behaviour for init states is worth mentioning in the documentation, isn't it?\n. I was wondering about 'why' this specific behaviour is intended since the 'why' may be useful for the docs. I came up with the following:\nI guess the crucial point is that the machine is started within the state and not before it. In some scenarios on_enter might be undesired behaviour since the transition into the initial state is undefined in the current implementation (as discussed in #9).\nLet us say we have a system with an idle state which receives information about the last successful task via transitions and therefore via on_enter:\n``` python\nclass Model:\n    def on_enter_idle(self, result):\n        self.process(result)\nstates = ['idle', 'taskA',..., 'taskN']\ntransitions = [\n    ['finished', '*', 'idle'],\n    ['doA', 'idle', 'taskA'],\n    ...\n    ['doN', 'idle', 'taskN']\n]\nm = Machine(Model(), states=states, transitions=transitions, initial='idle')\nm.doA()\n...\nm.finish(result)\n```\nIn this case we do not want on_enter to be called if we set initial=\"idle\" since there is no previously finished task and result to be processed.\nOf course this problem can be solved by design with a dedicated initial state:\n``` python\nstates = ['initial', 'idle', ...]\neither\ntransitions = ['doA', ['initial', 'idle'], 'taskA']\nor\nclass Model:\n    def on_enter_initial(self):\n        self.machine.to_idle()\n```\nor by certain measurements in on_enter like:\npython\ndef on_enter_idle(result=None):\n  if result:\n    self.process(result)\nHowever, the caused overhead to prevent execution of on_enter is significantly larger than to execute it by calling to_A().\nDoes this sound reasonable?\n. :+1:. I will pull it if there is no objection until tomorrow.\n. If there is not objection, I'd like to merge the fix tomorrow (Tuesday).\n. I branched dev-graph into dev-refactor and pushed some code around. Every extension now has its own file in transitions/extensions. Mixing happens in factory.py.\nChanges include:\n- MachineFactory -- A user can call MachineFactory.get_predefined(graph=True/False, locked=True/False, nested=True/False) to get the right class. At first I tried dynamic creation of classes with custom names but pickle does not support this\n- GraphSupport\n  - Some examples in the ReadMe use the model parameter without keyword. That's why I had to push title it to the **kwargs. Otherwise GraphSupport treats the model like a title.\n  - Pickling: I added _get_state_ and _set_state_since AGraph contains a SwigPyObject which cannot be pickled that easy. Pickling for now destroys the 'previous' markup since the state is not explicitly (re)stored.\n  - NestedMachines: I added support for NestedStates in TransitionGraphSupport. It just checks if a dest state has children or not.\n  - Inheritance: I changed GraphSupport to be a subclass of Machine. Otherwise the super function call chains are not resolved properly. This means __init__ of class Foo(HierarchicalMachine, GraphSupport) would otherwise fail with a title keyword since Machine.__init__ is called before GraphSupport.__init__ and Machine does not know the keyword. \n- Notebooks now work without the need of installing transitions and I also added an example for nested graphs.\n. i fixed two bugs. Tests fail at the moment because travis has some ubuntu package fetching issues. Looks like someone delete essential files on http://us-central1.gce.archive.ubuntu.com m).\n. Hi,\nthey are created in core.py in __getattr__:\n``` python\ndef getattr(self, name):\n        if name.startswith(''):\n            if name in self.__dict:\n                return self.dict[name]\n            else:\n                raise AttributeError(\"{} does not exist\".format(name))\n        terms = name.split('')\n        if terms[0] in ['before', 'after']:\n            name = ''.join(terms[1:])\n            if name not in self.events:\n                raise MachineError('Event \"%s\" is not registered.' % name)\n            return partial(self.events[name].add_callback, terms[0])\n    # that's where the magic happens\n    # on_enter / on_exit queries are concatenated with the current state \n    # and predefined with partial\n    elif name.startswith('on_enter') or name.startswith('on_exit'):\n        state = self.get_state('_'.join(terms[2:]))\n        return partial(state.add_callback, terms[1])\n    else:\n        if name in self.__dict__:\n            return self.__dict__[name]\n        else:\n            raise AttributeError(\"{} does not exist\".format(name))\n\n```\non_exit_solid has to be called from the machine, not from the model.\npython\nmachine.on_exit_solid('say_goodbye')\nshould work.\n. Okay,\nafter some more careful reading what you said and what the documentation states, I guess you are right. Afaik, it does not work the way its stated in the documentation.\n. in core.Machine.add_states there is a check if an on_enter_State method exists but it is not created otherwise. \n``` python\nAdd enter/exit callbacks if there are existing bound methods\nenter_callback = 'on_enter_' + state_name\nif hasattr(self.model, enter_callback) and \\\n           inspect.ismethod(getattr(self.model, enter_callback)):\n    state.add_callback('enter', enter_callback)\nexit_callback = 'on_exit_' + state_name\nif hasattr(self.model, exit_callback) and \\\n           inspect.ismethod(getattr(self.model, exit_callback)):\n    state.add_callback('exit', exit_callback)\n\n```\n. :+1: agree\n. looks good so far.\nSome thoughts:\nMachine.add_transition and HierarchicalMachine.add_transition differ concerning keywords or let's say HierarchicalMachine.add_transitiondoes not include before and before_check. Not sure how python handles this. My first guess is that this breaks overriding in cases where before_check is present.\nI'd prefer a raised error instead of 'automatic fixing' since altering callbacks maybe complicate bug tracking. If the method is named after this leads to an error in name.split(separator)[1] I guess. Or if it is called on_exit it becomes before_transition_exit. I know this is heavy abuse of the method but you never know what people come up with :).\nAnd -- I know its a drop in the bucket -- maybe make separator and callbacks class variables since they are more or less static and Machine._identify_callback is probably called frequently. Saves two assignments (weeeee).\n. > In the previous version the constants were indeed optimised out;\nThat's good to know. I haven't spent much thoughts about python optimisation. But it makes sense.\n\nso no exceptions or even log messages (beyond the deprecation warning) needed.\n\nI still have comprehension issues with the 'autofixing':\npython\nif len(name) == len(callback_type) and callback_type in ['before_transition', 'before_check']:\n    logger.info('\"before\" callback is deprecated; use \"before_transition_*\" (callback was: \"%s\")', name)\n    name = separator.join(['before_transition'] + name.split(separator)[1:])\nThis is triggered if name equals 'before_transition' or 'before_check'. Since callback_type has to be a substring of name (otherwise the ValueException would have caused a return), the length comparison is basically a check for equal value (or isn't it?).\nThis results in outputs like before_transition_transition or before_transition_check. Is that the desired behaviour? \n. > But there is a performance hit as in all code paths you're doing a full string comparison.\noh, I get it. I'd suggest just a adding a comment in the code and leave it like it is. Then it should be clear why this is the better solution.\n\nYes - the case we're cleaning up is\n\nunderstood. The case is transparent. It just causes issues of somebody really messes with the system and has a check and transition_check transition for instance. That's very unlikely and I'd take the risk. @wtgee: what do you think? \n. I pulled your changes into feature-#40 branch to resolve the minor conflicts which were added in #82. \nI also wrote a test for the described case:\npython\ndef test_autofixing_before(self):\n    self.stuff.before_check_callback = MagicMock()\n    self.stuff.machine.add_transition('check', 'A', 'B')\n    self.stuff.machine.before_check('before_check_callback')\n    self.stuff.check()\n    self.assertTrue(self.stuff.machine.is_state('B'))\n    self.assertTrue(self.stuff.before_check_callback.called)\nIt throws an AttributeError. Fix in Machine._identify_callback:\npython\nif len(name) == len(callback_type) and callback_type in ['before_transition', 'before_check']:\n    logger.info('\"before\" callback is deprecated; use \"before_transition_*\" (callback was: \"%s\")', name)\n    name = cls.separator.join(['before_transition'] + name.split(cls.separator)[1:])\n    callback_type = 'before_transition' # <--- if case misses this line\nWithout it target becomes [before_trans]ition_check. I guess that is not intended.\nBut I have seen this int test_core.py\npython\ndef test_callback_identification(self):\n    m = Machine(Stuff(), states=['A', 'B', 'C', 'D', 'E', 'F'], initial='A')\n    ...\n    m.add_transition('check', 'C', 'E', before='increase_level')\n    ...\n    with self.assertRaises(AttributeError):\n        m.before_check('increase_level')\nThis implies that before_check is not valid. This contradicts the previously mentioned if statement's purpose, doesn't it?\n. okay, merged the changes into the branch. (Probably) last question:\nyour commit comments read like using class variables in cls.callbacks[[name.find(x) for x in cls.callbacks].index(0)] cannot be optimized like the previous callbacks = ['before_transition', 'after', 'before_check', 'on_enter', 'on_exit', 'before']. Should we change it back then?\n. alright, I have opened a pull request to finally integrate your work into the master under #84.\n. > Maybe even before_condition would make more sense\nI guess before_condition may be more consistent. Let's see what the others say. This change can be done in no time.\n\nTo me that seems like the before_check would then have to be fairly generic rather than state (or transition) specific.\n\nIt is in some sense transition specific since it is guaranteed to be executed if the transition is valid.\n\nis the user expected to do any cleanup for that in the next before_check call?\n\nRight now execution order is before_check --> check -false-> check -false-> ...\nThere is no after_check/condition implemented (yet). This means before_check must not require cleanup. Otherwise the chain of responsibility is broken and every condition check has to execute pretty similar code. \n-- further thoughts\nI guess most of the work was making the underscore processable in __getattr__. So  after_condition is not that hard to add but then we run into the execution order problem:\n- chain execution: before_check/condition -> check -> check -> after_condition\n- single execution: before_check/condition -> check -> after_condition -> before_check -> check -> after_condition\nWe could tackle this with a strategy keyword (e.g.: 'single_execution=False') but imho this sounds like way too much to configure for a user considering the initial goal was just to execute some code every time an event was triggered.\n. Looks good to me,\nminor doc nitpicking: prepare is only called if the transition is evaluated. It is not executed if:\n- the transition is invalid (wrong source)\n- a previous transition is executed (a transition added before the transition in question since at the moment addition order also implies priority)\nNot sure if someone will actually assume that the code is always executed if the trigger fits.\nThe blueprint mechanism will (hopefully) be removed pretty soon. So your changes to nesting.py are sufficient. If @tyarkoni and @wtgee do not object I will merge your changes into master tomorrow if they haven't done it by then :). Thanks for your contribution!\n. yeah, the idea is interesting but I do agree with @tyarkoni. If the code is not comprehensible enough one may fall back to\npython\nmachine.add_transition(trigger='sublimate', source='solid', dest='gas')\n. Hi @tyarkoni,\nsorry for reopening this but I just realised\npython\nmachine.add_transition(trigger='sublimate', source='solid', dest='gas')\nis not possible since arguments 1 to 3 have no keyword. Do you think this is desirable in cases where add_transition('sublimate', 'solid', 'gas') is not verbose enough?\n. gnaaah, nevermind. it does work m(.\n. How about that -> #83 \n. rework of #80 makes this obsolete\n. Hi @khigia,\ninteresting addition. Could you make this an optional feature by adding a keyword (e.g. show_conditions) to MachineGraphSupport and get_graph. show_conditions could be handled like the title keyword.\n. neat, could you attach an image of an example graph with this feature enabled?\n. > Here is code example and result in attached png file\n:+1: \n\nexcept I would suggest maybe adding a space before and after the ampersand\n\n:+1: \n. > Is alt the name of the nested FSM? It seems like you are saying stateD belongs to alt which belongs to stateC, is that correct?\nYes. stateC has children states and one of them is alt. This state also has children and one of them is stateD. stateD might have children, too. I updated my first post to use state1 instead of stateD. It's already confusing enough without me mixing up namespaces of nested states.\n\nI just don't like it. :)\n\nhaha, fair enough. The separator is now a class variable which means theoretically you could use any string you like. I opted for '.' because of chaining reasons but adding a method like a generic go_to like model.go_to('stateC<42>alt<42>state1') is not that hard to implement. Or you could play with fire like model.go_to('stateC\u27b3alt\u27b3state1') ;).\n\nbetter to break it now rather than later. :)\n\nI could add a fallback. If NestedState.separator=='_' then leave out FunctionWrappers. In this case the behaviour would not change. I could even make NestedState.separator='_' the default value for the first time and add a deprecation warning.\n\nBut we should probably mention this change in a parenthetical comment in the docs though (at least for a few months).\n\nYeah, about that... Most changes done in the bigger refactoring during the graph rework have not been documented yet. For instance the factory and mixing model or how graphs work now. I will give it a first shot and would be glad if you guys could review it then.\n. Hi,\njust a small update: I hadn't had time to work on it during the last month. But I will push some changes this week for sure!\nbest regards,\nalex\n. I rearranged and extended the documentation and added the custom separator as a feature which is disabled by default (underscore is used). The documentation changes are limited to the 'Extensions' chapter. Feel free to reword phrases or ask for clarification if something is unclear. \n@wtgee, @tyarkoni: Do you think unicode separators for python 2 is a must have? I tried to 'fix' unicode handling in transitions but I feel like this will break for someone somewhere for sure. If the terminal/command prompt cannot handle unicode right for instance. It does work for python 3 without any hassle though.\npython\n  File \"/[...]/transitions/transitions/core.py\", line 395, in add_states\n    partial(self.is_state, state.name))\nUnicodeEncodeError: 'ascii' codec can't encode character u'\\u21a6' in position 4: ordinal not in range(128)\n. renamed dev-nested to dev-0.4\n. branch has been merged into master and unicode separator support for python2 is a 'wontfix' for now\n. I guess your implementation is pretty close to the minimal changes necessary to make this work.\nSo __setstate__, __getstate__ and _deepcopy_ have to be written and/or altered. This is quite some overhead imho. However, deepcopy should not be necessary any longer if dev-nested gets merged.  Being able to deep copy machines is nice though if you ask me.\nConcerning this I favour the 'machine id/name' solution and -- optionally --  extending the logging string a bit.\n. I have added an identifier string to Machine in dev-0.4.\nmachine(initial='A', name='Test Machine') results in:\nmachine.to_B()\nmachine.to_C()\n-------------------- >> begin captured logging << --------------------\ntransitions.core: INFO: Test Machine: Initiating transition from state A to state B...\ntransitions.core: INFO: Test Machine: Exited state A\ntransitions.core: INFO: Test Machine: Entered state B\ntransitions.core: INFO: Test Machine: Initiating transition from state B to state C...\ntransitions.core: INFO: Test Machine: Exited state B\ntransitions.core: INFO: Test Machine: Entered state C\n--------------------- >> end captured logging << ---------------------\n. Thats more a matter of \"best practises\" imho. A library like transitions should enable people to do things but not dictate how to do it. I agree that this use case looks weird and after some thoughts I guess there are scenarios where you want to have some sort of pass-through states.\nBut that is just not the way how it should be done (again, imho). Transitions offers after callbacks. This is where self.e1() (for this example) belongs. It also eases code comprehension because the transition logic stays on the surface rather than being spread into the state logic.\nA queue might increase code complexity and maybe one guy out there is already bending transition logic the current way because of ... reasons. In the end it's 'just' the log which looks weird. model.state will return the right state.\n\nI am using the regular version (I believe the locked version would block).\n\nGood point. I haven't tried it out myself but my guess is it should not block. RLocks just prevent other threads from executing machine methods. As long as you do not start to spawn threads in on_enter and wait for them to finish inside on_enter, you should be fine.\n@khigia, in your example the state change always happens immediately. As mentioned earlier I'd suggest after in this case. If you were referring to a case as described in #30, the locked machine might be what you are looking for. You can start a worker thread in on_enter and even if it triggers the change immediately, it will be blocked until e0 is done.\nIf you want to prevent threading (which in my experience never is a bad thing :)), you can make the queue idea part of your model with minor overhead:\n``` python\nclass Model():\n    def init(self):\n        self.queue = []\n        self.machine = Machine(self,...)\ndef on_enter_B(self):\n   if condition:\n       self.queue.push(self.e1)\n\ndef flush(self):\n    while len(self.queue) > 0:\n        self.queue.pop(0)()\n\n...\nmodel = Model(model..., after_state_change='flush')\n...\nmodel.e0()\n``\n. Sorry for the long delay. Unfortunately I am still not sold on the queue idea incore`. I still think that this could be either solved by a locked machine or by using an event queue within the model. Can you provide a minimal example why both approaches do not work out for you?\nRemark: I do like the way the queue is implemented but I am just not convinced this has to be done in core.\n. > Again, just trying to explain my thoughts, no bad feeling if we close this pull request :).\ndont worry. I really appreciate your feedback and think you have a valid point. I am sold on the idea to have such a feature. I just try to figure out what the needs are and how to keep the impact on core as minimal as possible. Or let's say to keep it as comprehensible as it is right now. \nI do not like to give up the 'sync' behaviour since having transitions return their success state is quite useful in some cases. Also 'is_state' becomes a bit squishy because you never know if there are more transitions in the queue. We use transitions in an event-based architecture and having instant feedback if a transition worked or not is quite crucial. \nNevertheless, having the option to process transitions asynchronous is a very neat extension and I will create a dev-async branch to include your suggestions into core.\n. @khigia, could you issue a pull request for your changes into dev-async\n. Hi @khigia,\nplease have a look at dev-0.4. I integrated your approach and also added a test_async. Asynchronous processing can now be enabled with Machine(..., async=True). What do you think?\n. yeah, good call. Its better to keep events agnostic and bundle all (a)sync logic in one Machine method. This also allows to switch mode of operations during runtime.\n. I close this since #89 has been implemented in dev-0.4.0 based on the name keyword. If you think that's not sufficient, feel free to reopen again.\n. please issue again for dev-async branch\n. Hi @nskalis,\nthat looks like something you better ask on Stack Overflow.\n\nFor usage questions, post on Stack Overflow, making sure to tag your question with the transitions and python tags.\n\nThere you will find a bigger pool of people who might be able to help you.\nbest regards,\nAlex\n. Oh I see,\nthe 'with' idea looks interesting. However, the after keyword looks quite sufficient for your described case.\n``` python\nclass Model:\n    def init(self):\n        states = ['A', 'B', 'C', 'End']\n        self._machine = Machine(self, states, initial=\"A\")\n        self._machine.add_transition(trigger='aToB', source='A', dest='B', \n                                     conditions=['cond'], unless=['exit_condition'])\n        self._machine.add_transition(trigger='aToB', source='A', dest='End',\n                                     conditions=['exit_condition'], after=['quit_machine'])\n        # for B and C this is just more of the same \ndef cond(self):\n    return True\n\ndef exit_condition(self):\n    return True\n\ndef quit_machine(self):\n    print \"quitting program...\"\n    # del self._machine # if required\n    sys.exit(0)\n\nmodel = Model()\nmodel.aToB()\n```\nYou could also do it your way and create a model function on_enter_End instead of using after.\n\nbut i would like to underline the importance of having an end_ state defined\n\nWell, isn't that done implicitly? Every state which is not a source of any transition is more or less a final state. In contrast to this, initial information cannot be retrieved from the available states and transitions.\n\nI guess the solution would involve the enter and exit methods described ...\n\nIf the machine leaves the scope, the garbage collection should clean it up. I do not see any specific action that has to take place in case of Machine. What do you have in mind?\n. no feedback. I close it for now.\n. Coverage decreased? Details  look good! Thank you @Ch00k!\n. More tinkering revealed that actually one state is set after dill.loads returned. Interestingly that does not happen when using pickling protocol 2 (python >= 2.7.10 it seems) or a locally initialised machine instead of the one build in test.setUp. Maybe dill/pickle tries to serialize threads and this somehow works with protocol 2... \n. If I am not mistaken, @wtgee has chosen this name because the first version did not inherit from Machine (but I am not 100% sure). But since it does now, naming it GraphMachine sounds good to me.\n. Yeah, I agree. 'async' might confuse people. I sticked to it since it was the chosen term to discuss this feature with @khigia. 'queued' sounds good to me but might also be too generic. I was wondering if 'queued_transition' or -- the opposite -- 'immediate_transition' would be more self-explanatory.\n. @wtgee: Do you have any further suggestions? Do you prefer queued or queued_transitions? Or maybe transition_strategy='queued' (default would be 'instant') :P? \n. has_queue is very good change in my opinion \ud83d\udc4d. looking forward to the merge\n. Hi @andrewramsay,\nthe machine's title had not been passed correctly to get_graph. This should be fixed now. If the problem still occurs feel free to reopen the issue. Thanks for the report!\nBest regards,\nAlex\n. Hi @rolandettema,\ndid you use PyPI to install transitions? The notebook examples require version 0.4.0 which is not available through PyPI yet. If you want to test the 0.4.0 features right away you need to clone and build transitions from github.\nBest regards, \nAlex\n. I see,\nhave you tried to install pygraphviz via pip as suggested in the ReadMe?\n\nTransitions can generate basic state diagrams displaying all valid transitions between states. To use the graphing functionality, you'll need to have pygraphviz installed (pip install pygraphviz)\n. I cannot help you with that, sorry. But it seems like you are not the only one having issues installing pygraphviz on Windows. You lack the required build tools. Have a look at Stackoverflow or MSDN. MiniGW is an option. Or just google pygraphviz error: Unable to find vcvarsall.bat. I found many approaches (which I cannot test though).\n. Hi @aisbaa,\n\nwhat you describe is expected behaviour. Transitions binds events to model attributes with setattr. Since all object attribute and method names are more or less keys in the object's __dict__ dictionary, every string which is a valid dictionary key should work with getattr. But as @tyarkoni mentions, you cannot call these functions directly because even though they are bound to the object they do not follow the python function naming scheme. \nIf you do not mind the -- a bit indirect -- getattr approach, it should work just fine for your field of application.  A second approach would be to call the event trigger directly (for instance machine.events['event_%'].trigger()) as Tal suggests. This might be a bit more comprehensible.\nYou could extend your model like this to get your desired behaviour.\npython\nclass TestModel(object):\n    def trigger(self, key):\n        self.machine.events[key].trigger()\nIf using special characters cause problems elsewhere in transitions. Let us know.\n. thank YOU for revealing the issue and helping us to fix it \ud83d\udc4d \n. That does sound interesting and I already have a project in mind where I definitely will try it out :).\nRegarding transitions/github I'd say that most of the functionality tox offers is already covered with travis. I might be wrong though.\n. Unfortunately it is not that easy. The check you want to remove is required for nested graphs where the parent has a valid transition to it's first child and the child itself also has such a transition (for instance because of ''->parent.child1). Removing it will cause duplicated edges for all -transitions in nested graphs. There has not been a test for that yet, sorry.\nHowever, I do think the current 'duplicate fix' is not sufficient at all if it prevents having multiple edges with different names. It also 'hides' the edge from parent to child. This is a limitation in graphviz/dot (or how it deals with edges from cluster to nodes) I could not work around yet.\nLong story short: I think we should merge the pull request to allow multiple edges and I will open  a new issue to find a better to solution to deal with cluster-to-node-edges.\n. Clutter is a good argument. How should it be annotated then? Like\nevent[condition&condition&!unless] || event2[condition&!unless&!unless]  ?\n. Example:\n``` python\nstates = ['standing', 'walking', {'name': 'caffeinated', 'children':['dithering', 'running']}]\ntransitions = [\n  ['walk', 'standing', 'walking'],\n  ['go', 'standing', 'walking'],\n  ['stop', 'walking', 'standing'],\n  {'trigger': 'drink', 'source': '*', 'dest': 'caffeinated_dithering',\n   'conditions':'is_hot', 'unless': 'is_too_hot'},\n  ['walk', 'caffeinated_dithering', 'caffeinated_running'],\n  ['relax', 'caffeinated', 'standing']\n]\nmachine = GraphMachine(model=Matter(), \n                       states=states, \n                       transitions=transitions, \n                       auto_transitions=False, \n                       initial='standing', \n                       title=\"Mood Matrix\",\n                       show_conditions=True)\n```\nleads to\n\n. yeah, I fixed that but wanted to wait for your oppionion about \n\nevent[condition&condition&!unless] || event2[condition&!unless&!unless]\n\nIf you are okay with it I would pull @aisbaa test and commit my changes to make it work with nested graphs\n. The relevant part is just two lines in extenstion/diagram.py\nhttps://gist.github.com/aleneum/602def83e94bf4ee38907d8151cef9b6\nproblem is, that label is falsely reused.\nthis and this should be enough.\n. \ud83d\udc4d \n. Minor spelling error here\nis queed should be queued.\n. You are right. This should be a 'protected/private' method and also it was just a matter of time until somebody stumbles upon this issue when using the trigger name 'process'. Thank you for your contribution!\nBest regards,\nAlex\n. good point. Sounds like a good idea. see #110.\n. Hi @AlexPython,\nsince I cannot test your setup, I had to stick with the django tutorial.\nI set up an app as described there until python manage.py shell and tested the following:\n``` python\nfrom polls.models import Question, Choice\nfrom transitions import Machine\nfrom django.utils import timezone\nCAR_STATES = ['on_factory', 'in_showroom', 'sold']\nCAR_TRANSITIONS = [\n    {'trigger': 'buy', 'source': 'on_factory', 'dest': 'in_showroom'},\n    {'trigger': 'sell', 'source': 'in_showroom', 'dest': 'sold'},\n]\nq = Question(question_text=\"What's new?\", pub_date=timezone.now())\nmachine = Machine(model=q, states=CAR_STATES, transitions=CAR_TRANSITIONS, \n                  initial='on_factory')\nhasattr(q, 'sell') # returns True\nq.sell # returns >\nmachine.current_state.name # returns 'on_factory'\nq.buy() # returns True\nmachine.current_state.name # returns 'in_showroom'\n```\nThis worked like a charm. I did not test how django specific model methods behave like save.\nYou might want to use a debugger  to find out why it does not work for you or give the django tutorial a try as well.\nbest regards,\nalex\n. To stick with the 'NarcolepticSuperhero' example, I adapted the Question to hold its own machine instance class like this:\n``` python\nclass Question(models.Model):\n    question_text = models.CharField(max_length=200)\n    pub_date = models.DateTimeField('date published')\nCAR_STATES = ['on_factory', 'in_showroom', 'sold']\n\nCAR_TRANSITIONS = [\n    {'trigger': 'buy', 'source': 'on_factory', 'dest': 'in_showroom'},\n    {'trigger': 'sell', 'source': 'in_showroom', 'dest': 'sold'},\n]\n\ndef __init__(self, *args, **kwargs):\n    models.Model.__init__(self, *args, **kwargs)\n    self.machine = Machine(self, states=Question.CAR_STATES,\n                           transitions=Question.CAR_TRANSITIONS,\n                           initial=Question.CAR_STATES[0])\n\n```\nUsage in the interactive shell changes slightly:\npython\nfrom polls.models import Question, Choice\nfrom django.utils import timezone\nq = Question(question_text=\"What's new?\", pub_date=timezone.now())\n q.machine.current_state.name # returns u'on_factory'\n. Hi,\n\nWhy initialize machine in class's def init as it resets states?\n\nI assume you cannot name a django field like transition model attribute. So your suggested workaround should be okay. If you want to initialize a model with the last state one could think of Machine(self, states=States, transitions=Transitions, initial=self.current_state). current_state would be a field as mentioned in your workaround.\n\nWhat is the supposed way to actually save states (not in memory, but in DB)?\n\nAs a text field like color or description. current_state will be saved and during initialisation should be set according to the underlying db model. If you use current_state and call save, you should be able to filter like AnotherCar.objects.all().filter(current_state='in_showroom'). Attributes like is_in_showroom are not part of your db model and therefore cannot be queried. You can try to store the machine and/or model instance directly into your db but thats rather inconvenient.\nI will close this issue because in my opinion this does not look like an issue of transition as a library but rather a matter of how to implement a certain solution. Please ask your usage related questions on stackoverflow and tag them with transitions and python so users of transitions can help you to solve your problem.\nFeel free to reopen the issue if you think the previously discussed things do relate to a bug or feature request which I have overlooked so far.\nBest regards,\nAlex\n. looks good \ud83d\udc4d \n. Yeah,\nthis happens when Machine is not the 'last in line'. I see where Machine calling super could be useful. To estimate the changes required it would be nice to know if you also plan to inherit from State, Transition or Event.\n. Additionally,\ncould you provide a minimal example of your inheritance scenario to test against.\n. Very nice examples \ud83d\udc4d \nif I call C(foo=\"bar\") in your first example I will get errors since not all parameters were consumed and end up in object:\nbash\nMaking a C instance:\nC init\nB init\nTraceback (most recent call last):\n  File \"inh2.py\", line 25, in <module>\n    c = C(foo=\"bar\")\n  File \"inh2.py\", line 16, in __init__\n    super(C, self).__init__(*args, **kwargs)\n  File \"inh2.py\", line 5, in __init__\n    super(A, self).__init__(*args, **kwargs)\n  File \"inh2.py\", line 11, in __init__\n    super(B, self).__init__(*args, **kwargs)\nTypeError: object.__init__() takes no parameters\nIt might be possible to inspect the MRO and only call super if next in line is not object but maybe you can think of a better solution.\n. > Informative Stackoverflow on argument passing in multiple inheritance:\nI agree that an extra **kwarg field (like pylab does it for instance) is the least invasive way to achieve the desired behaviour. I already tested it and it seems to work fine until kwargs contain some parameters when passed to object. As you said, that is intended behaviour but I think it would be nice to process this case to prevent weird error messages for library users. I'd rather expect an Error Message like Machine does not know keyword 'foo' instead of object.__init__() takes no parameters\n. > Well... if you're playing around with multiple inheritance, you tend to know enough to be able to work out why that error message occurs.\nagree! However, the error also occurs if you try to create a 'simple' Machine with a wrong argument even if you do mess around with inheritance. Right now Machine(foo=\"bar\") would not complain. With a super call it will raise a TypeError. \nI also think there is no easy way to work around this. So a try/except block is probably enough.\nI integrated your input into pull request #114. Let's see what the others say. Many thanks for your input!\nbest regards,\nAlex\n. HierarchicalMachine already works with *args and **kwargs and just passes arguments to Machine. As far as I can tell, solving the issue for Machine should also solve it for all subclasses.\nFrom nested.py:\npython\nclass HierarchicalMachine(Machine):\n    def __init__(self, *args, **kwargs):\n        self._buffered_transitions = []\n        super(HierarchicalMachine, self).__init__(*args, **kwargs)\n...\nDo I miss something?\n. Hi @jonathanunderwood,\nnice idea. What about this: is_state could accept a strict keyword which allows substates:\npython\nmachine.state # caffeinated_dithering\nmachine.is_caffeinated() # returns True\nmachine.is_caffeinated(strict=True) # returns False\nQuestion is, if strict should be default true or false.\n. see merge \n. Since this pull request will change some things in the core I will wait for some feedback from @wtgee or @tyarkoni. It is supposed to not break anything. This is the most relevant change. If someone passes wrong parameters to a Machine like befor instead of before, this now raises a MachineError. Previously issues like that had been ignored. It also allows more flexible handling of multiple inheritance (as discussed in #112 ). This might also be relevant for all the guys that want to mix transitions into django apps. What do you think? \n. Hi @ajax2leet,\nthank you for the bug report. There has been an issue with how conditions are passed when HSMs are used as a nested state. This one is fixed now and already integrated into the master branch. Nice catch!\nBut there is a second issue with your code which is more a design decision than a bug.\nThe model of a passed machine (in your case ms) is not automatically passed to m.\nThis means m should also use ms_model to be able to use check later on or provide an own model which has a check method.\n``` python\nfrom transitions.extensions import HierarchicalMachine as Machine\nclass Model(object):\n    def check(self):\n        return False\nms_model = Model()\nms = Machine(ms_model, states=[\"C\",\"D\"],\n             transitions {\"trigger\":\"go\",\"source\":\"C\",\"dest\":\"D\",\"conditions\":\"check\"})\nm_model = Model() # you can also reuse ms_model like m_model = ms_model\nm = Machine(m_model, states=[\"A\",\"B\",{\"name\":\"NEST\",\"children\":ms}])\nm_model.to_NEST_C() # call 'to_' of m_model instead of machine m\nm_model.go() # call 'go' of m_model instead of machine m \n```\nAn alternative (but probably less clean) approach would be to manually add a check method to m:\npython\nm = Machine(states=[\"A\",\"B\",{\"name\":\"NEST\",\"children\":ms}])\nm.check = ms_model.check # use machine as a model but add a check method\nm.to_NEST_C() \nm.go()\nBest regards,\nAlex\n. your guess is right. '*' is resolved into all available states. When embedding a machine into another '*' transitions are not longer known. Thanks for pointing this issue out. I will have a look at it asap.\n. Just go give you a small update on this:\nUnfortunately, it would require quite some rework to treat wildcards in a way that allows them do be identified as wildcards later on. There are some 'quick fixes' I can think of which may work for certain scenarios but not all of them. Some things to consider are:\n- adding a transitions: if its a wildcard transition add them to all states\n- adding a state: if there is any wildcard transition, find it and add the state to the valid transition sources\n- execution hierarchy: if transitions are handled separately (wildcard and specific; this would solve the first two questions) should wildcard transitions overwrite other transitions or being handled only if there is no other option? \n- graphs: how to visualize wildcard transitions? Right now GraphMachine treats every transition equally. Having two separate sets of transitions makes this more complicated.\nAdditionally, I can think of situations where the 'isolation' of wildcards to substates may be desired behaviour. restart for instance might be used to reset a machine but maybe should not reset the parent machine when embedded. If 'global' transitions are required, they can be added to the parent machine.\nThat being said, I do not think it is impossible to achieve. I just fear it makes simple use cases more difficult. If you have more thoughts on this let me know.\n. Due to lack of feedback I will close this for now. Feel free to reopen it if you have some ideas or new insights/feedback.\n. That does sound interesting. Do you have a code snippet or link so that I(or @ajax2leet, maybe) can have a look at how you have done it?\n. Another good minimal example, another good catch. Many thanks. \ud83d\udc4d \n. I agree with what @tyarkoni said. Subclassing Transition, State or Machine is the way to go here. I always considered auto_transition to be some kind of 'developer feature' with a guaranteed transition. Imho, this does not involve preparations and checks. I'd rather have a set of custom methods (e.g. conditional_to_*) to distinguish them from auto_transitions. It's basically a two line of code loop over all states which adds a wildcard transitions for every state. But maybe that is just me. \n@afterlastangel: Thank you for pointing out the documentation gap. I added a passage which hopefully will make this feature easier to spot for developers in the future. \n. Do you work with python 2.7 or python 3.3 or older ?\nIf thats so, you can use dill to pickle machine instances. Have a look at the tests in test/test_core.py or test/test_nested.py:\nFor instance here:\n``` python\ndef test_pickle(self):\n        import sys\n        if sys.version_info < (3, 4):\n            import dill as pickle\n        else:\n            import pickle\n    states = ['A', 'B', {'name': 'C', 'children': ['1', '2', {'name': '3', 'children': ['a', 'b', 'c']}]},\n      'D', 'E', 'F']\n    transitions = [\n        {'trigger': 'walk', 'source': 'A', 'dest': 'B'},\n        {'trigger': 'run', 'source': 'B', 'dest': 'C'},\n        {'trigger': 'sprint', 'source': 'C', 'dest': 'D'}\n    ]\n    m = self.stuff.machine_cls(states=states, transitions=transitions, initial='A')\n    m.walk()\n    dump = pickle.dumps(m)\n    self.assertIsNotNone(dump)\n    m2 = pickle.loads(dump)\n    self.assertEqual(m.state, m2.state)\n    m2.run()\n    if State.separator in '_':\n        m2.to_C_3_a()\n        m2.to_C_3_b()\n    else:\n        m2.to_C.s3.a()\n        m2.to_C.s3.b()\n\n```\n. Running the nose tests does not throw any errors but I do have the same issue when executing a test from an external file \ud83d\ude15. I am digging my way through several dill issues ([1][2][3]) and it ~~seems to be related with how dill decides what object requires special treatment and what not.~~ is a namespace issue which is not that easy to solve.\nMaybe there is a way to configure dill so that it 'detects' Condition right because it really should be able to do so.\nSome people also mention cloudpickle which does not have this specific issue. I replaced dill with cloudpickle and things seem to work. Could you give cloudpickle a try if it works for your scenario?\n. That would work, yeah. But the encapsulation makes sense. And dill can handle nesting. I am positive that sooner or later dill we be capable of dealing with this specific issue since it seems to be a known issue. For the moment, I am looking into 'workarounds' other projects have tried so far. If there is no clean solution, I am all for the easy fix.\n. bummer. thanks for the try.\n. After some digging it seems that @tyarkoni's is by far the most efficient solution. \ud83d\udc4d \n. >  As you can see from changes made by @medecau there are few missing dependencies in requirements_test.txt file.\nThe package nose was mentioned in the setup.py which travis/setuptools process before installing transitions into the environment. \n\nPersonally the strongest tox feature to me is its ability to create isolated environment for testing, \n\nIsn't that what travis does for github projects? At least thats what I thought. Travis should complain about the missing package mock though. Maybe some intermediate project already required mock (nose maybe?).\nBut nevertheless, I do see the advantage of offline/local testing and I do agree with your statement that tox does not require much maintenance and afaik it does not interfere with travis. Since it seems to help developers to customize transitions and integrate it into their workflow, I vote \ud83d\udc4d. I also share @tyarkoni's concern that tox support maybe the first of many feature requests for 'this amazing new framework\u2122'. Let's see :).\n. Maybe one could add a method to the model:\npython\nclass Model(object):\n    def add_alias(self, alias, target):\n        if not hasattr(self, target):\n            raise ValueError('Model does not contain target method %s' % target)\n        elif hasattr(self, alias):\n            raise ValueError('Model already contains method with name %s' % alias)\n        else:\n            setattr(self, alias, getattr(self, target))\nCan be used like this:\n``` python\nmodel = Model()\nstates = ['stopped', 'walking']\ntransitions = [\n    ['walk', 'stopped', 'walking'],\n    ['stop', 'walking', 'stopped']\n]\nmachine = Machine(model, states=states, transitions=transitions, initial='stopped')\nprint model.state # >>> stopped\nmodel.walk()\nprint model.state # >>> walking\nmodel.add_alias('stroll', 'walk')\nmodel.add_alias('pause', 'stop')\nmodel.pause()\nprint model.state # >>> stopped\nmodel.stroll()\nprint model.state # >>> walking\nmodel.add_alias('stop', 'walk') # >>> ... ValueError: Model already contains method with name stop\nmodel.add_alias('patrol', 'stroll')\nmodel.add_alias('escort', 'travel') # >>> ValueError: Model does not contain target method travel\n```\n. Good point,\nin this case it gets a bit more messy:\npython\nclass Model(object):\n        ...\n        else:\n            target_func = getattr(self, target)\n            def alias_func(*args, **kwargs):\n                logger.info(\"Calling alias %s for trigger %s\" % (alias, target))\n                target_func(*args,  **kwargs)\n            setattr(self, alias, alias_func)\nOutput would be something like:\nMacBook-Pro-3:transitions alneuman$ python aliastest.py \n...\nwalking\nINFO:__main__:Calling alias pause for trigger stop\nINFO:transitions.core:Initiating transition from state walking to state stopped...\nINFO:transitions.core:Exited state walking\nINFO:transitions.core:Entered state stopped\nstopped\nINFO:__main__:Calling alias stroll for trigger walk\nINFO:transitions.core:Initiating transition from state stopped to state walking...\nINFO:transitions.core:Exited state stopped\nINFO:transitions.core:Entered state walking\nwalking\nAs you see in the logger output above, transitions does not log the name of the triggered event so far.\nI guess, a better solution would be to log the trigger name right before the trigger is called.\npython\nlogger.info('Trigger walk event')\nmodel.walk()\n. I will close this for now since it seems like a reasonable solution have been found. Feel free to reopen this issue if you have more feedback.\n. Hi,\ninteresting thoughts. So the machine would manage the 'ruleset' of valid transitions but the actual state is part of the model. I see how this increases the reuse value. I do have some (initial) questions about the desired behaviour and relationship between model and machine though.\n- Is a one (machine) to many (models) relationship or a many to many relationship desired?\n- Should all models provide all triggers registered in the machine or should the event triggers be spread across all models? \n- If add_transition is executed, should that add the trigger to all models related to the machine instance?\n- Should the State instances/objects be managed by the machine or also be part of the model?\nI would suggest to extend a Event.trigger with a model parameter which is bound with partial during transition creation. This requires that a machine has a list of managed models (if add_transition(s) should be able to register triggers on every model). Some things have to be discussed though (like where to store the state in the model or how to deal with Machine.is_state)\nI give it a try if one of you can provide a test case. Just to be sure I try to achieve the right thing :).\n. The tests should pass now but there is still some work to do for graphing. Right now, only the last transition executed will be shown in the graph. My plan would be to move the graph instance also to the model so that every model has a separate graph. What do you think?\n. Graph issues have been fixed and nesting also seems to work. But we might want to extend testing of this feature a bit before calling it stable enough for the master branch.\n. I guess we can consider this solved with #135. Feel free to reopen this issue if you encounter bugs/limitations or open a new issue.\n. You could use the chaining nature of transitions to achieve a similar behaviour. Transitions are checked in the same order they were added.\nI adapted your example a bit. We have two transitions with the same trigger.  When the first transition is evaluated heat_up is called and if the 'is_really_hot' condition returns False the transition is executed since the condition is negated by unless. If  'is_really_hot' returns True, the second transition will be executed. We could check conditions: 'is_really_hot again but since this transition is only evaluated if the first one was rejected, the condition is already given implicitly.\n``` python\nfrom transitions import Machine\nimport random\nclass Matter(object):\n    heat = False\n    attempts = 0\n    def count_attempts(self): self.attempts += 1\n    def is_really_hot(self): return self.heat\n    def heat_up(self): self.heat = random.random() < 0.5\nstates=['solid', 'liquid', 'gas', 'plasma']\ntransitions = [\n    { 'trigger': 'melt', 'source': 'solid', 'dest': 'liquid', 'prepare': ['heat_up'], 'unless': 'is_really_hot'},\n    { 'trigger': 'melt', 'source': 'solid', 'dest': 'gas'},\n]\nlump = Matter()\nmachine = Machine(lump, states, transitions=transitions, initial='solid')\nlump.melt()\nprint lump.state  # multiple runs return different values: gas, liquid, liquid, liquid, gas...\n```\nSince you mentioned floats: conditions in transitions are supposed to return boolean values.\nIf self.heat = 200  # degree celsius, a condition check could look like this def is_really_hot(self): return self.heat > 300.\n. Hello @thundergolfer,\nI am glad that you bring this up. It is on my (personal) discussion list for transitions since solving #128 will be a big step towards concurrent states where 'final' states may also be required.  I think we could add a _create_state method to Machine similar to Machine._create_transition or Machine._create_event. This would at least allow things like this:\n``` python\nfrom transitions import Machine, State\nstates = ['A', 'B', {'name': 'C', 'final': True}]\nclass FinalState(State):\n    def init(self, name, on_enter=None, on_exit=None,\n                 ignore_invalid_triggers=False, final=False):\n        self.final = final\n        super(FinalState, self).init(name, on_enter, on_exit, ignore_invalid_trigger)\nclass FinalMachine(Machine):\n    def _create_state(*args, kwargs):\n        return FinalState(*args, kwargs)\nm = FinalMachine(states=states, initial='C')\nprint m.get_state(m.state).final\n\n\n\nTrue\n```\n\n\n\nBut let's wait for more feedback. Other approaches or ideas will be appreciated.\n. FYI:\nHierarchicalMachine has a _create_state method. So this should be a working example:\n``` python\nfrom transitions.extensions.nesting import HierarchicalMachine, NestedState\nstates = ['A', 'B', {'name': 'C', 'final': True}]\nclass FinalState(NestedState):\n    def init(self, *args, kwargs):\n        self.final = kwargs.pop('final', False)\n        super(FinalState, self).init(*args, kwargs)\nclass FinalMachine(HierarchicalMachine):\n    @staticmethod\n    def _create_state(*args, kwargs):\n        return FinalState(*args, kwargs)\nm = FinalMachine(states=states, initial='C')\nprint m.get_state(m.state).final\n```\nNevertheless, it might be useful to also have _create_state in Machine\n. Another approach I was thinking about is to check whether a state acts as a transition source. If the state cannot be left it is implicitly a final state whereas a final state with possible transitions cannot be that final.\npython\nClass Machine(object): \n    ...\n    def final(self, model): # method is bound to the model(s)\n        for ev in self.events:\n            if model.state in ev:\n                return False\n        return True\n. Yeah, makes sense. Flickers of memories of computer linguistic seminars come back to my mind :).\nSo we need a set of failed and accepted states. These could be either added to the Machine or to the states themselves\npython\nMachine(..., initial='A', accepted=['D'], failed=['C'])\nOne could also think about how the library should handle a failed state.\nThrowing a MachineError would be one solution.\n. I spent some more time thinking about this and right now I could also see this work within the model. If you consider the machine just being 'responsible' for managing transitions and letting the model add meaning and actions to states, this would make sense in my eyes:\n``` python\nclass FSAModel(object):\n    def init(self, accepted, failed):\n        self.accepted_states = accepted\n        self.failed_states = failed\n# possibility A\ndef check_state(self):\n    if self.state in self.accepted_states:\n        print(\"Weee\")\n    elif self.state in self.failed_states:\n        raise Error('Failstate reached!')\n\n # possibility B\n @property\n def accepted(self):\n     return self.state in self.accepted_states\n\n...\nstates = ['A', 'B', 'C', 'F']\nmodel = FSAModel(accepted=['A'], failed=['F'])\nmachine = Machine(model, states=states, after_state_change='check_state', initial='A')\nmachine.accepted # True\nmodel.to_F() # raises Error\n```\nMaybe in this case one could think of an 'implicit' definition of failed states like if self.state has no transition and self.state not in self.accepted.\n@tyarkoni, @wtgee: What do you think?\n. The transitions package does not include models for now. I am not sure if @tyarkoni plans to add an extension module for model mixins. Since there is potential for reusing things like FSAModel it might be a thing to consider.\n. I close this for now. This might be a part of a model module extension outlined in #146. Feel free to reopen this issue if necessary.\n. transitions support hierarchical state machines which do support nesting of previously defined state machines. It is documented here. This allows scenarios like this:\npython\ncount_states = ['1', '2', '3', 'done']\ncounter = Machine(states=count_states, transitions=count_trans, initial='1') # hsm 1\n...\nstates = ['waiting', 'collecting', {'name': 'counting', 'children': counter}]\ncollector = Machine(states=states, transitions=transitions, initial='waiting') # hsm 2\n...\ncollector.state  # counting_2\nDoes this fit your needs or are you looking for something else?\n. > This is an example of how a bug/misconstruction in the reusable state machine renders the parent crippled.\nThe 'crippling' is a design choice which prefers event handling of children before parents.\nYour ['done', '*', 'done'] is internally converted into ['done', '*', 'reuse.done'].\nThis allows specialisation of generic 'meta' machines. If you want to alter the behaviour of the reused machine, I suggested using inheritance before nesting. \nA bottom-up (parent->children) approach also breaks the isolation of nested machines in a way that requires the user of a pre-defined machines to know quite some internals to not interfere with internal procedures.\nFor instance, we use HSMs in robotics where generic searching procedures reuse control state machines for visual search (which themselves use machines for camera motor controls, computervision approaches and so on). A search pattern procedure triggering a done event meant for the internal machine which is 'catched' by the parent will cause undesired behaviour.\nAt some point you need some delegation for the stacking approach as well. If you are in a substate machine and a trigger is called which cannot be handled by the topmost machine like the event work in your example. Failing or throwing errors is not a good option though because from an external point of view work is a legit event but just unknown to the child. If your solution is delegating the event down the stack than this is practically what HSMs are already doing.\nLong story short: This delegation is desired and required for complex HSM use cases.\nIf you want to prevent that, you can connect the nested state machine with custom mapping. The documentation mentions:\n\nSometimes you want such an embedded state collection to 'return' which means after it is done it should exit...\npython\n...\nstates = ['waiting', 'collecting', {'name': 'counting', 'children': counter, 'remap': {'done': 'waiting'}}]\n\n['done', '*', 'done'] would be internally converted (or actually partly kept) ['done', [all children states], 'done'].\nThats pretty much your stack 'popping', isnt' it?\nWhat we could add (again) is that if a machine defines an initial state it is also reused. This means if reuse is entered it will enter reuse_init automatically. \nThis should be sufficient then:\npython\n    states = ['init', 'working', {'name': 'reuse', 'children': reuse, 'remap': {'done': 'done'}}]\n    transitions = [\n        ['work', 'init', 'working'],\n        ['reuse', 'working', 'reusing'], \n        ['done', 'reusing', 'done']\n    ]\n. > (nb. it could use a message, I had to look up what's going on in the source)\nUh, sorry about that. Will be fixed asap.\n\nWith a stack or at least a prefix derived from the child machine instead of/in addition to the parent I think it'd be fine.\n\nThat should happen already. Can you provide a small example which 'violates' the duplicate_check?\n. That was fast \ud83d\udc4d !\nThank you for discovering this one. I also discovered some other corner cases which I will evaluate asap. If you face more obstacles let me know.\n. This one seems to solved. If you discover further issues, feel free to reopen the issue.\n. Hi @ahmedabt,\nthank you for your feedback. I would actually argue for the current order since the callbacks are part of the entering process which ends when all callbacks have been processed. But that is just my opinion and I also see why the other order may be desirable. Let's see what the others say.\n. What about:\npython\nlogger.info(\"%sEntering state %s\", event_data.machine.id, self.name)\nOr a bit more detailled:\npython\nlogger.info(\"%sEntering state %s. Processing Callbacks.\", event_data.machine.id, self.name)\n. > On further reflection though, I do think it probably makes sense to have an easy way to trigger events from the model by passing a string. \nEasy to implement and maintain. Since this seems to add convenience I am all for it \ud83d\udc4d \n\nMy method does also offer up a default transition if the requested transition can't be found. \n\nThis could be the second candidate for a model extension module: MixInFiniteStates and MixInDefaultTransition. What do you think?\n. It was a welcome way to distract myself from something I (don't) want to do today ;).\nAnd closing tickets is fun (sorry for taking that away).\nBUT... stumbled upon a pygraphviz issue which occurs sometimes -_-\nUpdate: Best way to work around error message generation issues is to prevent errors \ud83d\ude48 \n. I will commit improved test coverage tomorrow.\n. Since we just talk about some lines, I wanted to give it a try. This was also a nice opportunity to find unreachable code which could be removed/simplified. I found two occasions:\npython\ndef model(self):\n        ...\n        elif not self.models:\n            return None\n       ...\nself.models is set during initialisation and only tinkering with internals of Machine could lead to triggering this. In this case it might be better to let the standard AttributeError inform the user of the issue instead silently returning None. This could be removed in my opinion.\nSecond (and the harder one):\npython\n    def __getattr__(self, name):\n        if name.startswith('__'):\n            if name in self.__dict__:\n                return self.__dict__[name]\n            else:\n                raise AttributeError(\"{} does not exist\".format(name))\nI cannot think of an example where dict contains keys starting with double underscore. Machine's dict does not contain any methods like __getattr__ and if you try to add double underscore methods (to the class for instance), they will be mangled as far as I know. I am sure it is possible somehow but does it really \nThis:\npython\nif name.startswith('__'):\n    raise AttributeError(\"{} does not exist\".format(name))\nshould be sufficient until somebody can prove that having double underscore keys is required for some use cases.\n. > I think I would almost prefer a more descriptive word rather than a semi-private one. \nI see your point and agree. A more descriptive name would be favourable.\n\nI doubt this will be functionality that someone expects to exist [...] So I would lean towards just skipping binding with an info message if .trigger already exists.\n\nI think you are right. The approach is kind of a hack. I'd like to have the opportunity to extend Model.trigger somehow to specify the behaviour (like having a default transition if Model.trigger returns False). However, I do not know how to 'inherit' from functions which are added at runtime. But I assume that if someone requires that behaviour, it's better if he or she explicitly tinkers around with the model rather than transitions trying to read minds.\nThank you for your feedback! Both of you :).\n. Hi @limdauto,\nI think this is a good idea. I did a review and added some remarks to the condition check. If you are still interested in this feature let me know.\n. No worries, take your time :). We are not in a rush, are we? I just ping people if there has not been activity for two weeks to see if the issue still is valid.\n. Hello @limdauto,\nif you okay with it, I will take your suggestions and adapt it a bit (see my review) so we can close this issue. What do you think?\n. Thank you for the feedback and I see your point. I guess most output would fit into debug as well.\nSince this will change the (maybe expected) logging behaviour for many users, I do not wan't to make the change without consent of @wtgee or @tyarkoni.\n. I do not really have a strong oppinion towards any solution. I ask myself what the purpose of this dictionary should be and if we can support that purpose directly.\nWe could return the dictionary:\npython\n@property\ndef transitions(self):\n    return {s: [t for (t, ev) in self.events.items() if s in ev.transitions] for s in self.states}\nbut also offer some convenience functions such as:\n``` python\ndef get_triggers_for(self, state):\n    return [t for (t, ev) in self.events.items() if state in ev.transitions]\ncreate functions like get_triggers_for_A() with partial...\ndef is_trigger_valid_for(self, state, trigger)\n    return trigger in self.events and state in self.events[trigger]\n... same for is_trigger_valid_for_A(trigger)\n```\nA new module for the Machine.transitions (condensed) one-liner might be overkill. For the convenience functions this could be more justified...\n. > One benefit of having the dictionary in memory is the ability to look up eligible transitions for multiple states.\nIf getting the sources of transitions is what you need, that is even more straight forward since that is basically how transition triggers are organised:\npython\ndef get_sources_of(self, trigger):\n    return self.events[trigger].transitions.keys()\n. Oh, I see. Now I get it :).\nIn this case get_triggers_for can be altered a bit to accept more than one state.\nStandalone example:\n``` python\nfrom transitions import Machine\nstates = ['A', 'B', 'C', 'D']\ntransitions = [['one', 'A', 'B'],\n               ['two', 'A', 'C'],\n               ['three', 'B', 'C'],\n               ['four', 'D', 'C']]\nm = Machine(states=states, transitions=transitions, initial='A', auto_transitions=False)\ndef get_triggers_for(states):\n    global m\n    states = set(states)\n    return [t for (t, ev) in m.events.items() if any(state in ev.transitions for state in states)]\nprint get_triggers_for(['A', 'D'])\n>>> ['four', 'two', 'one']\nprint get_triggers_for('B')\n>>> ['three']\nprint get_triggers_for('C')\n>>> []\n```\nAs a class method that would be:\npython\ndef get_triggers_for(self, states):\n    states = set(states)\n    return [t for (t, ev) in self.events.items() if any(state in ev.transitions for state in states)]\nOne could even think about using *args directly for state names. In this case get_triggers_for('A') would be as valid as get_triggers_for('A', 'B') and so on.\n. Hi @guilhermecgs and @limdauto,\nI just pushed get_triggers to the master. If you face some issues, fell free to reopen this issue.\n. Hi @botzill,\ncould you give an example of what behaviour you are interested in?\nRight now, a machine will add a state attribute to the model which returns the name of the current state. There are two ways that come into my mind to set another field whenever Model.state changes: a) using after_state_change to set an attribute explicitly or b) using property setters and getters to achieve the same thing but without callbacks: \n``` python\nfrom transitions import Machine\nstates = ['A', 'B']\ntransitions = [['go', 'A', 'B']]\nclass Model(object):\n    def init(self):\n        self.statusA = self.statusB = 'A'\ndef status_changed(self):\n    self.statusA = self.state # version with callback\n\n@property\ndef state(self):\n    return self.statusB\n\n@state.setter\ndef state(self, value):\n    self.statusB = value # version without callback\n\nmodel = Model()\nmachine = Machine(model, states=states, transitions=transitions, initial='A',\n                                  after_state_change='status_changed')\nprint model.state # A\nmodel.go()\nprint model.state # B\nprint model.statusA # B\nprint model.statusB # B\n``\n. I am not sure about how pickysqlalchemy` is when it comes to inheritance. If you want, you can give this a try:\n``` python\nclass User(Base):\n    tablename = 'users'\nid = Column(Integer, primary_key=True)\n# renamed state -> status to allow that getter/setter solution\nstatus = Column(String)\nname = Column(String)\n\ndef __init__(self, session, *args, **kwargs):\n    self._session = session\n    self._session.add(self)\n    super(User, self).__init__(*args, **kwargs)\n\n@property\ndef state(self):\n    return self.status\n\n@state.setter\ndef state(self, value):\n    self.status = value\n    self._session.commit()\n\n```\nI tested it with your example code and it seems to work (as in 'No exceptions are thrown'). I have not checked if the content in test.sqlite is correct though.\n. Nice to hear that you have found a way that suits your needs :).\nThank you for leaving your solution here. In case transitions gets a model mixin extension module, this might be part of it.\nI will close this issue for now. Feel free to reopen it if you have further feedback or face any issues with transitions.\nBest regards!\n. The documentation suggests a @orm.reconstructor decorator. This might also be a solution.\n. We had a discussion with @AlexPython in #111 about how to make Django and transitions work together. Since this seems to be a reoccurring matter, it's really good to have a generic solution. Thanks for that! Just one question. I am not a hundred percent familiar with Django. So what is the purpose of class Meta as it is not used in your example. I am just curious. \n. I close this for now. This might be a part of a model extension module outlined in #146. Feel free to reopen this issue if necessary.\n. default/fallback transitions (see #134)\n. django database integration (see #111/#142)\n. sqlalchemy support (see #141). Coroutine/asyncio Support (see #181). @proofit404: Thanks for the remark. We will definitely add this to the documentation.. I added the example from proofit404 as the first answer to the faq notebook.. @jxskiss: Thanks for the update. I am not completely familiar with how django handles its data.\nIs a django model object equivalent to a data entry? Your remark about records sounds like it.\nI can imagine that If you attach a machine and all its content to each entry in a table/model it blows up the memory footprint.\nBut is it really necessary? To attach a machine to every entry/record I mean. The cool thing about transitions is the separation of model and machine which means you just need to attach the model to your entry and can use one machine instance to handle all models. A global machine instance or singleton might be all you need. The best part is that all model objects will be updated in case the machine changes.\nEdit:\nThe moment you add the model instance to the machine it will be extended with several partial functions which might be in sum also add to the increased memory footprint. This can be reduced by disabling auto_transitions (which means  less functions attached to the machine model) in case they are not needed. But State and Transition objects as well as the Machine object do not need to be copied to work with multiple models. The machine instance itself is actually stateless (except if it acts as a model itself).\nIf you could distill a minimal example (project) of your current approach with transitions (does not have to reach 800M memory usage of course), I could check if I am on the right track here.. Hi @jxskiss and @proofit404,\nI just finished some test runs and wanted to share the results. The full code can be found here and is based on what jxskiss provided. This is the most important stuff:\n```python\nAs a model, I used a simple one field model. Item was extended with a MixIn\nclass Item(, models.Model):\n    state = models.CharField(max_length=16, default='new')\nThis is a Singleton meta class from\nhttps://stackoverflow.com/questions/6760685/creating-a-singleton-in-python\nclass Singleton(type):\n    _instances = {}\n    def call(cls, *args, kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super(Singleton, cls).call(*args, kwargs)\n        return cls._instances[cls]\nclass GlobalMachine(transitions.Machine):\n    metaclass = Singleton\n# # In case you want to use set instead of list to store models\n# def __init__(self, *args, **kwargs):\n#     super(GlobalMachine, self).__init__(*args, **kwargs)\n#     self.models = SetWrapper()\n\nSince transitions expects a list, extend set by a method 'append'\nYou just need that in case you want to use set instead of list for storing models in Machine\nclass SetWrapper(set):\ndef append(self, item):\n    self.add(item)\n\ninstead of adding a machine to each entry, we use a global machine here\nthe constructor is only called ONCE and ignored after the global\ninstance has been created.\nNote that we do not add a model or set an initial state;\nthis will be done for each model entry instead\nclass ItemSingletonMachineMixin(object):\n    def init(self, *args, kwargs):\n        super(ItemSingletonMachineMixin, self).init(*args, kwargs)\n        machine = GlobalMachine(\n            model=None,\n            states=ItemStatus.SM_STATES,\n            transitions=ItemStatus.SM_TRANSITIONS,\n            initial=None,\n            auto_transitions=False,\n            send_event=True\n        )\n        # save item to be hashable\n        self.save()\n        machine.add_model(self, initial=self.state)\n```\nEvaluation\nI tested 5 kinds of models with different MixIns:\n\nItem: add a transitions.Machine instance to each record/item\nItemSingleton: add each model to a global transitions.Machine\nItemSingletonSet: Extend transitions.Machine to use (a subclass of) set instead of list to store models; this increases look up speed in add_model\nItemNoMachine: just a minimal model without a state machine (for referencing purposes)\nItemFysom: add a customized fysom machine to each record/item\nItemFysomClass: use fysom as a class variable, extend the model with an __getattribute__ wrapper which passes the object to the static machine.\n\nnote that I wrote \"add a customized fysom machine\" since imho fysom.StateMachine is not handled as a singleton in the items but gains his waaaay better memory footprint by being more lightweight in general and facilitating static methods where ever possible. But maybe I overlooked something. Edit: I did. It's a class attribute and not bound to an instance as in my current gist. I will update the comparison soon. I added ItemFysomClass which sticks to jxskiss actual idea.\nProcess\nI wrote some helper functions to create instances of Item in memory until the django process exceeded a previously defined memory limit. I also tracked the time how long it took to create the instances (you will see why). This was done on my laptop while I did other things. So its not 100% scientific. Additionally, I added self.save() to each __init__ method of the mixins. Creation times are slightly increased because of this. But it was necessary to make the resulting model hashable (which is required for ItemSingletonSet as you will see later).\nResults\nWith a memory limit of 250MB I could create:\n 3120 instances of Item\n 18680 instances of ItemSingleton\n 18740 instances of ItemSingletonSet\n 14300 instances of ItemFysom\n* 278500 instances of ItemFysomClass\n\nDiscussion\nAs already mentioned by jxskiss, adding a transitions.Machine to each Item will result in a big memory footprint and is therefore not encouraged. Using a lightweight state machine such as the customized version of fysom with static methods produces much better results. However, using transitions.Machine as a Singleton allows to even fit more instances into 250MB (about 30%).\nThe least overhead can be achieved by passing the model to a static state machine as illustrated in jxskiss's ItemFysomClass. With the help of a small convenience wrapper (__getattribute__) and a transition name prefix (e.g. 'sm_'), the memory footprint of the added state machine logic is trivial as the actual memory consumption is more or less determined by the record/entry and it's field. Both test cases, ItemFysomClass and ItemNoMachine resulted in almost the same amount of objects.\nNote that the tested model was close to the smallest possible model. In case your entry includes more fields and complex datatypes, the impact of a model decoration with a state machine will be reduced. These results may vary depending on when and how Python does the garbage collection and/or rearranges stuff in memory.\nUsing Singleton seems to considerably reduce the object overhead when using transitions. However, using just one Machine has its drawbacks:\n\ntransitions.Machine uses list to keep track of added models. This becomes an issue when lots of models are added consecutively since Machine.add_model always checks if the model is already in Machine.models. This takes longer the more models are already in the list.\nAt the end of the test, it takes up to 0.6 seconds to add 10 instances Item to the machine.\nIf this does not satisfy an intended use case I propose 2 solutions:\nSolution 1:  Skip check\nA subclass of Machine could override add_model and basically copy the whole method bust just remove if model not in self.models to skip the test.\nSolution 2: Use set instead of list\nThis approach has been tested with ItemSingletonSet and as you see it improves the execution time of add_model dramatically. Drawbacks of using set instead of list: set is unordered and model instances cannot be retrieved by index. Currently, at some points transitions expects Machine.models to be a list but we can work around this by subclassing set.\nFeedback welcome\nThese tests were focused on memory footprint. I also tested for basic functionality but cannot guarantee everything will work without further adaptions to a specific use case. Feel free to ask questions or provide further feedback to improve the interplay of django and transitions. If you think this comment should be part of the faq, please tell me.. > the deconstruction of django model objects should remove the object from models list in some way.\nYou can use Machine.remove_model for that in __delete__ for instance.\n\nAlso as bonus of attaching StateMachine as a class attribute, one can use different state machine for different Django Models\n\nAh! Thats what I overlooked. Thanks for the clarification. Sounds very reasonable. I will update the previous report accordingly.. @jxskiss, hello once again.\njust for\u00a0the\u00a0sake\u00a0of\u00a0completeness: The approach you have chosen (machine as class attribute; pass model as an argument rather than partial model bindings) does also work with transitions:\n```python\nfrom transitions import Machine\nfrom functools import partial\nfrom mock import MagicMock\nclass Model(object):\nmachine = Machine(model=None, states=['A', 'B', 'C'], initial=None,\n                  transitions=[\n                      {'trigger': 'go', 'source': 'A', 'dest': 'B', 'before': 'before'},\n                      {'trigger': 'check', 'source': 'B', 'dest': 'C', 'conditions': 'is_large'},\n                  ], finalize_event='finalize')\n\ndef __init__(self):\n    self.state = 'A'\n    self.before = MagicMock()\n    self.after = MagicMock()\n    self.finalize = MagicMock()\n\n@staticmethod\ndef is_large(value=0):\n    return value > 9000\n\ndef __getattribute__(self, item):\n    try:\n        return super(Model, self).__getattribute__(item)\n    except AttributeError:\n        if item in self.machine.events:\n            return partial(self.machine.events[item].trigger, self)\n        raise\n\nmodel = Model()\nmodel.go()\nassert model.state == 'B'\nassert model.before.called\nassert model.finalize.called\nmodel.check()\nassert model.state == 'B'\nmodel.check(value=500)\nassert model.state == 'B'\nmodel.check(value=9001)\nassert model.state == 'C'\nassert model.finalize.call_count == 4\n```\nAt a first glance, the only functionality you lose (compared to adding the model to the machine) is the convenience function is_<<state>>.. solutions presented here will be moved to the example section.. * added show_roi to get_graph function which is attached to the model.\n* added show_auto_transitions (default False) to GraphMachine.__init__\nboth has been integrated into dev-0.5. Hi @wtgee,\n\nHowever if all models should always be in the same state this might actually not be that intuitive.\n\nthat is not necessarily the case. Every model can be in a different state. This test in test_core shows how it works (I adapted it to be standalone)\n``` python\nfrom transitions.extensions import GraphMachine as Machine\nclass Model:\n    pass\ndef test_multiple_models():\n    s1, s2 = Model(), Model() \n    states = ['A', 'B', 'C']\nm = Machine(model=[s1, s2], states=states,\n            initial=states[0])\n#self.assertEquals(len(m.models), 2)\n#self.assertEquals(len(m.model), 2)\nm.add_transition('advance', 'A', 'B')\ns1.advance()\n#self.assertEquals(s1.state, 'B')\nprint s1.state # >>> B\n#self.assertEquals(s2.state, 'A')\nprint s2.state # >>> A\n\ntest_multiple_models()\n```\n. Hi @ketanbhatt,\nthe tag 0.4.1 happened about 30 commits ago. We are currently working on release 0.4.2 . If you like to use multiple models as well as the other new features mentioned in the Changelog you have to install transitions manually at the moment. If you are okay with 0.4.1, have a look at the documentation for the tag.\n. Just fyi:\nCoverage decreases because of this line.\nPython optimises some continue statements and therefore coverage cannot evaluate it. More info here.\n. I used the opportunity to rework the generation of nested graphs. But I am not 100 percent satisfied with how that worked out. The main problem is that Graphviz/dot does not support edges to clusters. In the past, this has not been a big issue since states with children always invoked their first child. I could do the same for clusters and adjust the edges with the attributes lhead and ltail to hide certain parts of edges. However, since states now can be entered without the need to enter a child state, this becomes more tricky.\nI used a hidden anchor state at first which represents the cluster and sticked to ltail and lhead. This does look messy in certain cases (lower left):\n\nIn a best case scenario the edges would start and end at the cluster border. But as you see, this does not happen. A transition from the super state to a child state is just floating around and the transition relax to state D is very short and the label looks detached.\nThats why I decided to just show the anchor node and its edges:\n\nI'd prefer a solution where edges start and stop at the cluster's border but I could not find a way to achieve this in a generic manner. If you have some thoughts or feedback about how such a graph could be reorganised, let me know.\n. Okay,\nmy next attempt: First, I have split Agraph into Graph and NestedGraph. This should make both graph generation procedures easier to maintain separately as nested graphs require some specific treatment. I hope this makes Graph less 'scary' in cases where someone is trying to understand what it is doing while bug hunting. I also removed the leading 'A' because it may be confused with pygraphviz.AGraph otherwise.\nSecond, I reworked the nested graph layout. The subgraph structure should take care of having the anchor black dot at the top of each subgraph. You can get the dot 'source' code with model.graph.string(). I copied the output, saved it to a file and tried to work out some decent parameters.\nI would not claim that these Graphviz parameters are perfectly adjusted but imho its less cluttered for complex graphs than the previous attempt.\nTo generate a really awesome looking graph, you probably have to fine tune things anyway.\nHowever, if you find better generic combinations of ranking, spacing and grouping, let me know and I will adapt NestedGraph.\nExample/notebook graph:\n\nTesting graph:\n\n. I could also rework that a bit and only include anchors if there is a transition from parent to child. In this case the result might me a bit more compact. @wtgee, @tyarkoni: What do you think?\n. This feature has been integrated into dev-0.5. Hi @guilhermecgs,\nthat looks like an issue with pygraphviz. Unfortunately, the pygraphviz error output is (ironically) kind of bugged (b\"\".join(error) does not work as expected I guess). I assume something went wrong during the generation of the graph and pygraphviz cannot convert it into a valid output.\nI suggest that you run a debugger and set a breakpoint exactly at that line (1335) or just print out the content of error (which requires an extra line of code in pygraphviz). Alternatively you can print self.graph.string() to get the content of the graph.\nIf you can provide a minimal example to reproduce the bug I can help to track down the bug.\n. @guilhermecgs, that would be nice since it sounds like a really strange side effect (which makes me curious as well :) ). Afaik, there are no reserved key words for states. Maybe some dot/Graphviz naming collision but thats just random guessing.\n. Hi @guilhermecgs,\nwere you able to do some debugging? I experienced IOErrors if I tried to save graphs to directories or file locations with wrong permissions.\n. I close this for now due to lack of information. It sounds like a side effect though. Feel free to reopen if you have further cues to investigate.. Hello @gangefors,\nthank you for your feedback. State objects have a name attribute. Your typo argument is valid and can currently be avoided with:\npython\nmachine.add_transition('melt', solid.name, liquid.name)\nLet's see what the others think. I am okay with using strings for add_transition but also see the advantage of passing objects (and maybe checking if the states are actually in the machine).\n. I also think of transitions' 'lazy evaluation' as a feature. For strings I'd keep that behaviour.\nI was just thinking about the following case: If you use State objects for adding transitions, you might want to make sure this is the actual state object and not just one that has the same name.\npython\nmachine.add_state('A')\nmachine.add_state('B')\nstate_B = State('B', on_enter='fancy_things')\nmachine.add_transition('go', 'A', state_B)\nmachine.to_A()\nmachine.go() # no fancy things happening\n. Hi @d-e-e-p,\nthank you for your feedback. This is a bug which I also discovered recently. It has been tackled in pull request #151 . The subgraphs are wrongly named during the graph generation process. Unfortunately, This is not the only issue with nested state machines and graph generation at the moment.\nSince I cannot tell when we will merge #151, I backported some bugfixes to the current master and added your example as a test case to test_nesting. See the result below.\n\nadd ordered transitions should skip states without children\n\nIn my oppinion states without children should not be ignored. Transitions should be created from a) parents to their first child, from b) siblings to their next sibling and c) from last siblings to their parent's next sibling in this particular order. As you see in the image below, transitions follows this pattern at the moment. What you may also see is that right now transitions from parents to their first child are not visible in the graph.\nSo long story short: The graph may be inaccurate in certain states. Things should be more accurate when #151 is merged. However, if the graph generation in master throws errors, let us know anyway and we will do our best to fix it.\nBest regards,\nAlex\n\n. Hello @luismartingil,\ntransitions relies on collections.OrderedDict for state management which has been introduced in Python 2.7. However, there is a backport of OrderedDicts (ordereddict). You would also need the backport modul mock and also pycodestyle and six.\nThe deal breaker in my oppinion is that we use unittest for testing which has been improved in 2.7. This means the tests written for transitions will not work for python 2.6 (I just tested that).\nUnfortunately, I do not think we will support 2.6 since even the core development team of python discourages the use of 2.6 and earlier and I assume that some third party modules are not maintained for 2.6 as well.\nI branched a version of transitions to an experimental branch called deprecated-2.6. The imports seem to work and I fixed the obvious compatibility errors. But many tests fail due to syntax issues. You can give this a try and file pull requests in case you want to contribute to this branch.\nBest regards,\nAlex\n. Hi @paulbovbel,\nsounds like a good idea and thank you for the pull request. I will review it as soon as I can.\nBest regards,\nAlex\n. The limitation to reentrant locks is no show stopper imho. Thank you for suggesting and implementing this features @paulbovbel. I created an issue for the redesign of the lock mechanism to also support other types of locks (#167).. Hi @vishwa15,\nfor this purpose we have introduced the queued option which will process transitions sequentially.\n```python\nfrom transitions import Machine\nstates = ['asleep', 'hanging_out', 'not_hungry', 'hungry']\ntransitions = [['work_out', 'hanging_out', 'hungry'],\n               ['not_work_out', 'hanging_out', 'not_hungry'],\n               {'trigger': 'wake_up', 'source':'asleep', 'dest': 'hanging_out', 'after':'check'}]\nclass Model():\ndef check(self, energy):\n    if energy > 50:\n        self.work_out()\n    else:\n        self.not_work_out()\n\nmodel = Model()\nmachine = Machine(model, states=states, transitions=transitions, queued=True, initial='asleep')\nmodel.wake_up(energy=80)\nprint(model.state) # >>> hungry\nmodel.to_asleep()\nmodel.wake_up(energy=30) \nprint(model.state) # >>> not_hungry\n```. Hmm...\ngood point. I thought del machine.events[trigger] would do the trick but it does not. The Event object is still bound to (a) model instance(s). It seems like we have to remove the bound method explicitly from the relevant models. I guess in future releases this could be done by transitions (if the others agree). However, for now this might be a quick fix for you:\n```python\nfrom transitions import Machine\nstates = ['A', 'B', 'C']\ntransitions = [['go', 'A', 'B']]\ndef remove_trigger(machine, trigger):\n    for m in machine.models:\n        delattr(m, trigger)\n    del machine.events[trigger]\nclass Model():\n    pass\nmodel = Model()\nmachine = Machine(model, states=states, transitions=transitions, initial='A')\nmodel.go()\nprint(model.state)\nmodel.to_A()\nremove_trigger(machine, 'go')\ntry:\n    model.go()\nexcept AttributeError:\n    pass\nprint(model.state)\n``. Sounds like a plan! I wonder if we should use wildcards '*' as default values forsourceanddest`. Otherwise the parameters change their meaning depending on the other value:\n\nif source is X (and dest is None): remove only t where t.source is X (and ignore dest)\nif dest is X (and source is None): remove only t where t.dest is Y (and ignore source)\nif source is X and  dest is Y: remove only t where t.source is X and t.dest is Y\nif source AND dest are None: remove ALL\n\nOr as a sentence: None for one parameter means 'ignore this unless the other parameter is None as well'. This might lead to some confusion. What do you think?\ndef remove_transition(trigger, source=\"*\", dest=\"*\") may solve this.. My first attempt. It also allows passing lists of sources and destinations. About the attempt: Even though list comprehension is not the most... comprehensible... solution it saves some assignments during the filtering process. I haven't found a neat way without many assignments AND just one dictionary iteration. If you see room for improvement, give me a shout.\n```python\nfrom transitions import Machine\nfrom transitions.core import listify\nstates = ['A', 'B', 'C']\ntransitions = [['go', 'A', 'B'],\n               ['go', 'B', 'C']]\ndef remove_transition(machine, trigger, source=\"\", dest=\"\"):\n    source = listify(source) if source != \"\" else source\n    dest = listify(dest) if dest != \"\" else dest\n    # outer comprehension, keeps events if inner comprehension returns lists with length > 0\n    machine.events[trigger].transitions = {key: value for key, value in\n                                           {k: [t for t in v\n                                                # keep entries if source should not be filtered\n                                                if (source is not \"\" and t.source not in source)\n                                                # same for dest. One condition has to be true for the entry to be kept\n                                                or (dest is not \"\" and t.dest not in dest)]\n                                                # }.items() takes the result of the inner comprehension and uses it\n                                                # for the outer comprehension (see first line of comment)\n                                                for k, v in machine.events[trigger].transitions.items()}.items()\n                                                if len(value) > 0}\n    # if no transition is left remove the trigger from the machine and all models\n    if len(machine.events[trigger].transitions) == 0:\n        for m in machine.models:\n            delattr(m, trigger)\n        del machine.events[trigger]\nclass Model():\n    pass\nmodel = Model()\nmachine = Machine(model, states=states, transitions=transitions, initial='A')\nmodel.go()\nmodel.to_A()\nremove_transition(machine, 'go', ['A'])\nprint(machine.events['go'].transitions)\n``. We might also want to support remove_transition(transition) for cases in which source and dest are equal but 'before', 'after' etc. are different.. implementedremove_transitionas described here indev-0.5`. Hello @valste,\ntransitions passes all given parameters to all functions in prepare, check, before and after.\nThis means your callback methods have to be able to deal with an arbitrary amount of parameters.\nGood news: It's pretty easy to do this in python:\n```python\nfrom transitions import Machine\nstates = ['A', 'B']\ntransitions = [{'trigger': 'connected', 'source': 'A', 'dest': 'B', 'after':['foo','bar','baz']}]\nclass Model():\ndef foo(self, foo, **kwargs):\n    print('foo: ' + foo)\n\ndef bar(self, bar, **kwargs):\n    print('bar: ' + bar)\n\ndef baz(self, baz, **kwargs):\n    print('baz: ' + baz)\n\nmodel = Model()\nmachine = Machine(model, states=states, transitions=transitions, initial='A')\nmodel.connected(foo='1', bar='2', baz='3')\n```\nBest regards,\nAlex. @paulbovbel,\nyou can use this patch to fix the issues with the nested transitions and graph retrieval. If patch -p1 does not work I can also fork your fork and create a pull request.\n. In dev-0.5, we have introduced a custom context manager which will keep track of the thread that currently entered a with block. Entering a second time will be omitted. The default locking mechanism still is a threading.RLock since threading.Lock seems to have issues with pickling.\nAdditionally, LockedMethod wrapping has been reduced to 'public' methods (every method not starting with an underscore) to further reduce the locking overhead.\nConsidering this simple example\npython\nm = M(states=['A', 'B', 'C', 'D'], transitions=[['reset', '*', 'A']], initial='A')\nm.get_triggers('A')\nthe following has been achieved:\n\nreduced execution time from ~600% to ~400% (in contrast to transitions.Machine)\nreduced maximum stack size of with blocks from 3 to 1\nreduced entering with blocks  attempts from 72 (!) to 4. Go ahead. A release is a good idea.  #151 takes some more work and I wont be able to tackle this soon. Let's save it for 0.4.4 or later.. Hello @peendebak,\n\nafter_state_change can handle lists like this:\npython\nmachine = Machine(..., after_state_change=['callback1', 'callback2'])\nAdditionally, this list can be adapted during runtime as machine property:\npython\nmachine.after_state_change = 'callback3'\nHowever, this will not have any effect on already created transitions and this is probably what you need right?\n. Okay,\nto achieve this we could convert Machine.after/before_state_change into a property\n```python\nMachine\n@property\ndef before_state_change(self):\n    return self._before_state_change\nthis should make sure that _before_state_change is always a list\n@before_state_change.setter\ndef before_state_change(self, value):\n  self._before_state_change = listify(value)\n```\nskip the concatenation during add_transition and iterate over two lists (Transition.before and Machine.before_state_change) with itertools.chain\n```python\nTransition.execute\nfrom itertools import chain\nfor func in chain(self.before, machine.before_state_change):\n    ...\n```\nLet's see what others think of this or if there might be other solutions. If we get a go on this solution I will implement it pretty soon.. It took a while but since 6e9334f the following should work:\n```python\nfrom transitions import Machine\nclass Model:\ndef bark(self):\n    print(\"bark\")\n\ndef chirp(self):\n    print(\"chirp\")\n\nmodel = Model()\nm = Machine(model=model, states=['A', 'B'], initial='A', before_state_change='bark')\nmodel.to_B()  # >>> bark\nm.before_state_change = 'chirp'\nmodel.to_A()  # >>> chirp\n```. good call. thanks @cemoody . great addition btw. \ud83d\udc4d . @tyarkoni:\nyeah, I was also thinking about 'self'. What do you (@all) prefer as the default value then? model=None or model='self'? I can't decide. Second would stick to the current behaviour and also prominently show the availability of this option. First would be cleaner I guess.. > Item 20: Use None and Docstrings to Specify Dynamic Default Arguments\nGood reminder. Since we just use static strings, I do not see the imminent issue though.\n\nOpt 2: if 'initial', make 'initial' state under the hood. \n\nhmm... what about default='initial' and 'initial' and 'something' get the same treatment:\nIf 'something' not in self.states, create state 'something'. This adds a possible bug based on spelling mistakes ('initail') though but removes an execution side track. Otherwise we have to check if 'initial' may already exist.\n\nOpt 1: if None, add self. Otherwise, listify and add as model. If [], would add no models.\n\nIf we skip self as a keyword, the user has no change to  add self and other models during initialisation. If we keep self as a keyword but the default is None, it may be not that obvious that you actually have the option to use self.\n. @paulbovbel:\n\nI see a lot of tests and README docs that support... Which breaks if meaning of model=None changes...  leave API-refactoring to another contribution.\n\nI see. What about this: You close this PR and open another one to merge your changes into dev-0.5? I would also use this branch to tackle #167. I (or someone else) will then do a PR from dev-0.5 to master during the next two weeks where we can evaluate if your uses cases will be covered.. > Is this current PR unacceptable as-is?\nNot at all! I (or we) meant it when I/we said thats a really neat contribution!\nI can only speak for myself when I say that the only reason why I hesitate is that I fear that you have to code stuff twice if we change the meaning of keywords later on. The features you request are valid and reasonable. That's why I would like to see them merged into the master asap. But I do not want to change them much when they have been added there because it will require users to alter their code.\nAnyway, if dev-0.5 is no option for you, how about this(@all):\nwe add these features (as is) to 0.4.4 since they only add new configuration scenarios.\nAdditionally, we add deprecation warnings for model=None and initial=None. This may also be good practise since it warns users about the upcoming changes.. Alright, if @tyarkoni agrees, I will merge your PR and later add deprecation warnings for the 0.4.4 release. I was considering a setting like this (sorry for the mess. I am a bit in a hurry.):\n```python\nclass Machine:\ndef __init__(self, *args, **kwargs):\n    # ToDo: mapping of args to kwargs\n    if model in kwargs and model is None:\n        warning.warn(\"Beginning with release 0.5 model=None will not add any model to the machine. Use model='self' instead.\",\n                     DeprecationWarning)\n    if add_self in kwargs:\n       warning.warn(\"Beginning with release 0.5 add_self will be removed in favour for model='self'.\",\n                      DeprecationWarning)\n    if  model is None and add_self:\n        kwargs['model'] = 'self' # remove this for release 0.5\n\n    self._future_init(**kwarg)\n\n def _future_init(model='self', ...)\n     ....\n\n```\nsimilar behaviour for initial. I am not sure if this is how its done in Python but the above mentioned approach (masking the actual calls and checking the passed values) has the advantage that users who have not tinkered with model=None or initial=None, will see no warnings. For all of those people we can switch the default values without any interruption.\nThe rest will have one release to adapt their code before it will function differently. The warnings should still be there until release 0.5.1 at least. Feedback welcome!\n. >  As someone who relies on IDE completions a lot to determine what arguments to pass...\ngood point. totally forgot about that (event though I make use of this feature a LOT as well). No real option, I agree.\n\nI don't see it as a serious problem that users who might not have explicitly specified model=None will still get a warning, because some of those users will no doubt be intending to use the Machine as model, but simply not explicitly stating that because they know it's the default.\n\nAgree, but according to my current understanding this wont change in the future since we switch from model=None/add_self=True to model='self' with exactly the same behaviour. So setting the machine as model will still be the default (or won't it?). Its kind of tough to communicate in a warning that you do not have to change anything. It might startle people without a reason.\nWe could just replace model=None with model='self' as the default value for 0.4.4. In this case warnings are only shown to people which set model=None explicitly. model=None and add_self=True will of course be treated like before. Is that an option?\nFirst warning suggestion. Will be shown if model is None and add_self is True:\n\"Starting from transition version 0.5.0, passing model=None to the constructor will no longer add the machine instance as a model but add NO model at all. Consequently, add_self will be removed. To add the machine as a model (and also hide this warning) use the new default value model='self' instead.\"\n. I am willing to merge it and conduct all the previously mentioned changes, but let's see what @tyarkoni  and/or @wtgee think.. Hello @ankostis,\nthank you for your input. A pull request into dev-0.4 would be much appreciated since I still have minor things to do before merging 0.4 into master.\nbest regards,\nAlex. Both is okay, \nwe can add your changes to dev-0.4 or you rebase it and we merge in into master.\nI see, already done. Thank you for clarifying this part of the documentation.. Will be done.. I assume this is just an effect of how it is implemented right now. Imho, it does make sense to call Machine.before before transition.before. If others agree we can alter the order in no time.. First, thanks for your thoughts. Streamlining this process sounds like a good plan.\n\nHaving separate prepare methods on each transition does not make much sense\n\nprepare is actually considered to prepare the condition check. There are cases where configurations and checks have to be done before the actual condition check can happen (see #40). Preparing the state change should be done in before.\n\nA \"global\" one should suffice.\n\nThere are cases in which specific preparation does make sense. If you want to construct certain temporal data structures which are later on used by the condition checks, they probably are very specific for the case in question. For instance, if a transition depends on the state of some sensors it would be quite an overkill to always prepare all the sensor data.\n\nI would prefer to look at them as global exit/enter\n\nCould you elaborate on cases where this could be useful? Right now, State.add_callback could be used to trigger certain (global) functions when a state is entered or exited. Are there cases you can think of where this is not enough and execution order (M.before, t.before, M.enter, t.enter, ...) is crucial?  \nThis being said, at the moment I feel option A with Machine.prepare --> transition.prepare is sufficient.\n\nit might be possible to support all of the above\n\nI agree, if Machine.enter/exit are useful additions, option C with proper default values can be configured in a flexible way to resemble the other two options as well. The 'code overhead' should be quite small.. Hi @ankostis,\nI need some more input to wrap my head around your bug.\nWhat caused the side effects?\nRight now Machine.before/after and Transition.before/after are just concatenated. If we assume the same pattern for prepare the following two cases are more or less identical:\n```python\nclass Model()\n    def do_prepare(self, event):\n        pass\nstates = ['A', 'B']\nm = Model()\ntransitionsA = [{'trigger': 'do', 'source': 'A', 'dest': 'B'}]\nmachineA = Machine(m, states=states, transitions=transitionsA, prepare='do_prepare')\ntransitionsB = [{'trigger': 'do', 'source': 'A', 'dest': 'B', 'prepare': 'do_prepare'}]\nmachineB = Machine(m, states=states, transitions=transitionsB)\n```\nIf a chain of possible transitions is checked this would result in\nMachine.prepare -> TransitionA.prepare -> TransitionA.check --(fails)--> Machine.prepare -> TransitionB.prepare -> TransitionB.check ... and so on.\nThis is probably not what you have in mind. I assume you require something like this:\nMachine.prepare -> TransitionA.prepare -> TransitionA.check --(fails)--> TransitionB.prepare -> TransitionB.check ... where Machine.prepare is only called once for each trigger, right? . Okay, about the naming: Transition.before relates to Machine.before_state_change and Transition.after relates to Machine.after_state_change. I propose Machine.prepare_conditions_check to keep the more descriptive nature of Machine attributes.\nWhat do you (@all) think?. ~Oookay, this might take a bit longer since model convenience functions such as 'before_stateA', 'after_stateA'  and 'prepare_stateA' seem to collide with the solution discussed in #170 when model and machine are the same object.~\nThis seem to be conflicts with dev-0.5 which I will investigate when #184 is merged. . #175 resolved this. Nice, thanks.\nI think the ExitStack/contextlib.nested issue is a matter of its own. This should probably discussed when we plan to something about it.. I have no strong oppinion about this. @wtgee, @tyarkoni, what about you?. Hi, \nI just want to give you an update why I haven't pulled this request yet. As @wtgee pointed out this might break current implementations catching MachineError. I will wait a bit longer to see if @tyarkoni wants to give feedback. I'd assume that the adaptions for the users are bearable and the change clarifies the cause of errors in a reasonable manner. If no one opposes I would merge the changes in a week.. Hello @Kosyne,\nI am not aware of plans to support asyncio since we like to keep the backwards compatibility to python 2.7. transitions does support threading though. This allows wrapping Machine into async calls.\n```python\nimport asyncio\nfrom transitions.extensions.locking import LockedMachine as Machine\nimport time\nasync def do_this(model):\n    model.running()\n    print(\"I did this\")\n    model.done()\n    return\nasync def do_that(model):\n    model.running()\n    print(\"I did that\")\n    model.done()\n    return\ndef heavy_processing():\n    time.sleep(1.0)\ntransitions = [\n    {'trigger': 'running', 'source': 'Idle', 'dest': 'Running', 'after': heavy_processing},\n    {'trigger': 'done', 'source': 'Running', 'dest': 'Idle'},\n]\nomit model parameter and let the machine act as a model.\nmachine = Machine(states=['Idle', 'Running'], transitions=transitions, initial='Idle')\nloop = asyncio.get_event_loop()\nprint(\"Doing things...\")\nloop.run_until_complete(asyncio.gather(\n    do_this(machine),\n    do_that(machine)\n))\nloop.close()\n```\nIt may be possible to extend LockedMachine to support asyncio directly. If you have any suggestions, let me know.. Hello @oz123,\n\nis possible to use trollius for having asynio with Python 2.7 \n\nI have seen this working for the autobahn project. So yeah, probably.\nI wrote a small test for this and think the question What should be called asynchronously has to be clarified in advance:\n\nCase A: Even.trigger (the methods which will be bound to the models)\n\nThis is the easiest case which can be achieved by adding a method to a model definition, such as:\n```python\nimport asyncio\nfrom transitions.extensions.locking import LockedMachine as Machine\nclass Model(object):\nasync def run_threaded(self, method, *args, **kwargs):\n    await asyncio.coroutine(getattr(self, method))(*args, **kwargs)\n\ndef report(self, task):\n    print('Done with %s' % task)\n    self.done()\n\ntransitions = [\n    {'trigger': 'run', 'source': 'Idle', 'dest': 'Running', 'after': 'report'},\n    {'trigger': 'done', 'source': 'Running', 'dest': 'Idle'},\n]\nmodel = Model()\nmachine = Machine(model=model, states=['Idle', 'Running'], transitions=transitions, initial='Idle', queued=True)\nprint(\"Doing things...\")\nloop = asyncio.get_event_loop()\nloop.run_until_complete(asyncio.gather(\n    model.run_threaded('run', task='task A'),\n    model.run_threaded('run', task='task B')\n))\nloop.close()\n``\nThis is just one way to solve it. You can probably encapsulate async even further but unfortunately it cannot be integrated intoEvent.trigger` that easily because this messes with the order of transitions when a trigger is called within a callback.\n\nCase B: Model.callbacks (like prepare, before, after)\n\nThis is where things start to get complicated because who should await what? Should check/before/after called parallel or sequential? And how do we maintain the order of certain processes if the event loop is already used for executing the event trigger?\nFeedback welcome.. Just a minor remark: case A is enough to process events asynchronously. I use Robotic Service Bus (RSB) to dispatch asynchronous events with a similar method (see rsbhsm).\nRSB uses PubSub Event handler. I added an onMsg function to my custom RSBEvent which is called when a message is received. This way I can still call Event.trigger synchronised. activate and deactivate is just some convenience listener management and not required for using transitions to handle events. Actually, most of the tinkering with RSBState and RSBTransition is just listener management and some dynamic imports (so people do not have to change state machine logic if they want to trigger a certain behaviour).. I guess I found a way to achieve things like this\npython\nclass Model():\n    ...\n    def callback1(): ...\n    def callback2(): ...\n    ...\nloop = asyncio.get_event_loop()\nloop.run_until_complete(asyncio.gather(\n    model.run(task='task A'),\n    model.run(task='task B')\n))\nloop.close()\nwithout the need of extra work in the model. This means events can be handled asynchronously. The drawback is, that all model callbacks have to be synchronous and I guess that's not what you (@Kosyne) require, right?\nI guess what you need is:\n```python\nclass Model():\n    async def callbackA(): ...\n    async def callbackB(): ...\nmodel.run(..)\n```\ncorrect? Could you provide a minimal example of what you trying to achieve?\n. Hi @Kosyne,\nI had a brief look at discord.py and I would agree that it seems like you need async for events (to handle discord events) and callbacks (for sending messages etc.). The danger of asynchronous event handling lies in parallel execution. What happens when you receive an on_message event while another one has not been completely processed yet? core.Machine is not threadsafe which means you are at a risk to face racing conditions and/or weird behaviour when this happens (also debugging will be pure pain).\nI recommend using LockedMachine since this will make sure that events will be handled synchronised. \nHowever, you still have to make sure that Event.trigger does not return before the event and its callbacks have been processed completely. Otherwise the lock may be released too early.. Hi @Kosyne,\n\nHopefully though, sometime in the future, maybe we could see a (very much optional) extension for something like an AsyncMachine :)\n\nsure thing. Personally, I have limited experience with asyncio but if you propose a maintainable extension based on your experience and open a pull request, I would gladly review it.\nFor now I close this issue. Feel free to reopen it, if you want to discuss this matter further.\nGood luck with your bot!. Hello @ivanteresh,\nsounds great. If you open a pull request I will gladly have a look at it.. wrong alert!. Without objection/feedback, I will merge this in a week. This will also be the moment to update the changelog and tag 0.4.4 for a release.. > any thoughts about adding a finalize_after_all_transitions in a finally block that fires once, both for successful/failed transitions?\nright, I will add this\n\nShould I open a new issue to discuss ramifications, such as, where to store collected errors. etc?\n\nPlease do so. Catching and managing errors is (currently) out of transitions scope.. > Since you named it finalize_event, why not prepare_event, to promote the relationship?\nI thought about this (or something like on\\before_event) but this might make some people believe it is always executed. But it is only executed if the transition is technically possible (if state.name in self.transition). Maybe I am overthinking this though. Phew, naming is tough \ud83d\ude13.. > So the prepare/finalize global methods are never executed for \"final\" states, i.e. those without any outgoing transitions on them.\nnope, not right now.\n\nIs it possible to have an event, even for a \"final\" state?\n\nwell, since we are talking about a feature in development, it's up to us how prepare/finalize behave. We could just extend the try/except block and trigger the prepare and finalize callbacks every time Event.trigger is called. In this case I would probably name them before/after_event since I feel this is the most consistent scheme considering before/after_state_change.\nWhat do you think?\n.  > I mean, it is not that he can try many triggers until the correct one fires - no, there is no correct, trigger, that is a dead-end. \nGood point. So I guess we should leave it like it is and only process callbacks if a transition is actually possible.\n\nprepare/finalize has the connotation that the last one gets executed regardless of failures.\n\nagreed. Also prepare_transition does not imply that a transition will actually happen (like before_transition) \n\nAnd I like the _event suffix because it is not related to a single transition, but all those involved.\n\nI refer to the underlying Event object. Thats why prepare_event would not be accurate. But somewhere_in_event is not catchy at all. prepare_transition because we have already determined that a transition is possible but we do not know which one yet.. if nobody objects, I will merge this next week. Also this will be the moment to update the manual and the changelog and also tag version 0.4.4.. Hello @oz123,\nI also assume it would be possible to safeguard Model.state somehow but I am not sure handling this case is sending the right message. First, state should be considered read-only and therefore should only be altered by a machine. However, this is more a suggestion than a strict rule since: second, state is a property of the model which in my oppinion makes fiddling with Model.state a responsibility of the model. Third, binding Model.state to a machine instance (which would be required to check if a state is valid) removes the ability to use one model with multiple machines. Since Machine.set_state already offers the feature to directly set the state of models, safeguarding Model.state sure improves convenience but does not offer new functionality.\nThis is only my 2 cents and I am open for suggestions why this safeguarding is a valuable addition to the library. If others vote for this feature I will change my mind too. \nThis being said, you can achieve your desired behaviour quite easily by defining Model.state yourself:\n```python\nfrom transitions import Machine\nclass Model:\ndef __init__(self, *args, **kwargs):\n    self._state = None\n    # to circumvent bootstrapping issues we intialize the machine without a model.\n    self.machine = Machine(model=None, *args, **kwargs, add_self=False)\n    self.machine.add_model(self)\n\n@property\ndef state(self):\n    return self._state\n\n@state.setter\ndef state(self, value):\n    if value in self.machine.states:\n        self._state = value\n    else:\n        raise ValueError(\"State '%s' not defined\" % value)\n\nmodel = Model(states=['A', 'B'], transitions=[['go', 'A', 'B']], initial='A')\nprint(model.state)\nmodel.go()\nprint(model.state)\nmodel.state = 'A'\nprint(model.state)\ntry:\n    model.state = 'egg'\nexcept ValueError as e:\n    print(e)\n```\nBest regards!. I am glad that this fits your needs.\nI will close this issue for now but feel free to reopen it if you consider this to be still an issue. \nThis matter is not really a feature of transitions but rather a way of application. So having this here (or Stackoverflow) should be sufficient for people to stumble upon. If a similar issue is opened again, we should consider to mention this in the documentation though.. Hi @ankostis,\nI added a global finalize_event attribute and renamed prepare_conditions_check to prepare_transition. For now, return values are handled like before: \nIf a transition is successful, Event.trigger will return True and False if no transition was applicable (if events are processed instantly and not queued).\nIf a callback raises an exception, this exception will be passed.\nThe second part of your suggestion is a bit more tricky: Should the result of the transition be passed to finalize callbacks and how? Personally, I would prefer to let the user handle exceptions. Also I'd prefer to handle finalize callbacks like other callbacks.\nAs mentioned before, checking the success of a transition can already be done with Event.trigger. Silently adding a keyword may lead to errors if callbacks do not expect it.\nEdit:\nThe proposed processing in #184 allows to pass the transition success via the model if required. This could look like this:\npython\nclass Model:\n    def before_transition_callback(self):\n        self._success = False\n    def after_state_change_callback(self):\n        self._success = True\n    def finalize_event_callback(self):\n        if not self._success:\n            print(\"Oh noes!\")\n. > capture exceptions inside ALL callbacks\nMaybe I am missing something but as far as I can tell the effort stays exactly the same. Currently, a user has to try/except every call to Event.trigger if this may raise an exception (MachineError or exceptions caused by the callbacks).\nThis behaviour is not changed because of #184. If you have a variety of callbacks and all of them may raise an exception, you still can do\npython\ntry:\n    model.work()  \nexcept SomeException as e:\n    # handle error\n\nshouldn't the true/false trigger flag be an attribute of the event_data?\n\nAs mentioned before, adding it to event_data.kwargs may lead to errors if callback do not exprect an automatically generated parameter. Adding result to event_data itself could be done without side effects. This requires a Machine with send_event=True though.. Hi @ankostis,\n\nSurrounding model.work() won't help you implement commit/rollback behavior WITH finalize_event callbacks.\n\nI see. Maybe we can find a way to process errors in callbacks without 'swallowing' caught exceptions in Event.trigger. As much as I like to enable your workflow, I also want to keep the current way of doing things for the sake of stability. I do not want to claim that the current way is superior but without further feedback, we cannot distinguish what is more desirable.\n\nThat could be an interesting opportunity: if you set send_event=true, you get exception capturing for free?\n\nUnfortunately, no. Adding the boolean result would just tell you if a transition took place. But this could also be achieved with model callbacks as mentioned above.\nPerhaps, we can solve this issue on the model level. This way we can keep core universal and do not have to introduce another attribute like raise_exceptions and/or implement specific finalize callback behaviour.. If you can catch exceptions raised by Event.trigger but want to process them in finalize callbacks, we could add error to event_data but raise every caught error. This would keep things as they currently are but also add useful information for commit/rollback strategies with finalize. Would that work for you?. > You mean a boolean EventData.error attribute?\nNo, I mean the actual error.\nLike \npython\nevent_data.error = None\ntry:\n...\nexcept Error as e:\n    event_data.error = e\n    raise e\nfinally:\n    for func in self.machine.finalize_after_all_transitions:\n        self.machine._callback(func, event_data)\n        .... resolved by #175 I hope. Hi @blmd-niz,\n\n['count', 'wait', 'counting_1']\n\nyeah, that is just wrong since there is no state wait. This should be collecting I guess.\nThank you for pointing that out!. dask uses  a customized SerializableLock. Maybe we can use something like this as well.. From the README.md:\n\nIf you need to know which transitions are valid from a certain state, you can use get_triggers:\n     m.get_triggers('solid')\n     >>> ['melt', 'sublimate']\n\nis that what you are looking for?. > Automatic transitions for all states\n\nIn addition to any transitions added explicitly, a to_\u00abstate\u00bb() method is created automatically\nwhenever a state is added to a Machine instance. \n...\nIf you desire, you can disable this behavior by setting auto_transitions=False in the Machine initializer.\n\n. no problem. all the best for your project!. I just had a quick look at the blame view of core and this is related to #112. It's a feature, not a bug :). If you consider this an issue which should be discussed/altered, feel free to reopen it.. If you feel like something should be added, removed, reviewed or reworded, leave a comment.\nIn case there are no further remarks, I will tag 0.4.4 next week.. good point.\nmaybe we should postpone the changes related to model and add_self to 0.6 then and integrate the dev-0.5 features right away.. In #172 we discussed how this change should happen.\nA 'soft' transition would be preferable which means that user code does not break instantly and users have at least one version to adapt.\nThose changes are mostly related to some corner cases where you want to mix models and machine instances or initialise empty machines. If you follow the PendingDeprecationWarning the code won't break (because of the change) when updating from 0.5.0 to 0.6.0.\nActually, under the hood these changes have been made already. Most users should not even see the warnings.\n0.5.0 for now sounds reasonable.. If there is nothing more to add, I'd suggest to tag 0.5.0 next week.. tagged version 0.5.0. much appreciated! \nthank you!. It is indeed a good opportunity to add additional information to the ReadMe.\nAbout your recommendations:\n version of current master -- \ud83d\udc4d , a must\n pypi -- also a good call\n meta info in init -- sounds like a good idea\n github -- considering we are talking about the github page... well... not desperately need but okay...\n license -- also a bit redundant but maybe easier to find in the ReadMe.\n update -- hmm.. this sounds like something that may end to be cumbersome to maintain, additionally the information is already on the very same github page; if not steadily maintained \nthe two dates may even contradict each other\nabout the style:\n\nA table is good but I'd actually prefer a clean line of badges. I will give it a shot with shield.io badges for comparison.. > Forgot to mention that I added a new commit where I extended travisCI to Python 3.5 & 3.6:\n\nright, forgot to mention this. This is also a good addition. We should add the appropriate tags in setup.py as well. \nCheckout the dev-readme branch. Imho, this is a bit more polished than a table.\n\nBesides, how many times you bump version per week?\n\nSo this is meant to refer to the last version bump... hmm.. new releases should probably be submitted to PyPi when they are done.  A version bump is not necessarily a new release though. At least that is how I handle it at the moment for transitions. I prefer to bump the version right after a release to show that the current master differs from the release. The 'commits since ' badge also adds to this. I do this because in the past, some people were confused because the 0.4.2 from github differed from the PyPi version.. > I'm using a different workflow for my projects \nUsually I do as well. I used to prefer the master as a release branch. On github most people open pull requests for the master branch though. Seems like people of github prefer bleeding edge masters.\n\nThe important thing is that anyone taking the sources outside git, know roughly which version he is running\n\nMaybe we should increase the frequency of versioning for minor releases/patches then. Not every version has to end on PyPi though.\n\nThe important thing is to have some idea what are you looking at\n\n\ud83d\udc4d \nI copy-pasted your changes to __init__ and .travis to the dev branch and also added tags in setup.py and tox.ini.. I added additional information about the project into the ReadMe based on your recommendations.\nAlso, I will strive to encourage more regular minor tags/releases.\nSince most addressed points in this pull request have been handled, I close it for now.\nFeel free to reopen it, if there is more to discuss.\nThanks again for your input!. Hi @janLo,\nthank you for your contribution. I have seen several occasions where a feature like this may be useful. This being said, I do agree with @tyarkoni that we have to be extra careful when it comes to new features which include either new parameters or symbols.\nAs mentioned, maintenance  is an issue but also clutter.\nWe agree on that only if a functionality cannot be achieved by the model or by proper configuration of the machine, a new parameter should be added.\nWe had this case not long ago when callback processing had to be refined (#175 and related).\n'*' representing a wildcard has been around virtually forever but reserving = for another mode might interfere with some implementations out there.\nI'd suggest None as in 'no destination given'. Of course this would still have to be documented but the change to the code would stay very minimalistic.\nIts basically just this line:\npython\n    # create a transition from s to dest, if dest is None, create a reflexive transition\n     t = self._create_transition(s, dest or s, conditions, unless, before,\n. > In the end its the same as * just syntactic sugar. As that I think it should be easy to read and understand\nagree and as already mentioned earlier, the changes are not that big. However it \n\ncan be easily done in user code\nintroduces a new parameter/placeholder/attribute\nand might interfere with current implementations\n\nHaving \"=\" as a state name is valid at the moment while None is not. You see I do some rule bending here to work around issue 2 and 3. I am not claiming None is the best way to do it, not event that it is a good way. Its a suggestion to reduce new added code but more importantly to not require a reserved character. But yeah, maybe None is not as self-explanatory as it should be.\n.  > I would go for making it configurable as keyword arguments\nAfter some consideration I agree that reflexive transitions fits transitions quite well as entering/exiting states are the main hooks to execute code. Especially for model related updates which require certain conditions to be met, this mechanism is useful, generic and adds flexibility. This justifies the minor increase in code complexity in my oppinion. We still have to agree on how to handle the 'placeholder' characters though.\nDo you think it is required to do that individually for every machine instance?\nIn nested we handle the state separator as a property of the class (ref). Same for state and function separator for Machine convenience functions (ref).\nMaybe we could to the same for e.g. wildcard_all = '*' and wildcard_same = '='. . Alright,\nif you are okay with it, I will merge it as it is and refactor the chars into variables.\nThank you for your contribution and feedback.. Hi @Eric24,\nI also use timeouts in my projects but in my oppinion this should be handled by the model or the specific state. Let's see if others may have another view on this.\nUntil then, a straight forward way to do it in the model could look like this:\n```python\nfrom threading import Thread\nimport time\nfrom transitions import Machine\nclass Timeout(Thread):\ndef __init__(self, func, timeout):\n    super(Timeout, self).__init__()\n    self.func = func\n    self.timeout = timeout\n    self.canceled = False\n    self.start()\n\ndef run(self):\n    time.sleep(self.timeout/1000.0)\n    if not self.canceled:\n        self.func()\n\nclass Model:\ndef __init__(self):\n    self.timer = None\n\ndef on_enter_B(self):\n    self.timer = Timeout(self.timeout, 1000)\n\ndef on_exit_B(self):\n    self.timer.canceled = True\n\nmodel = Model()\ntransitions = [['timeout', 'B', 'C']]\nmachine = Machine(model, states=['A', 'B', 'C'], transitions=transitions, initial='A')\nmodel.to_B()\nprint(model.state)  # >>> B\ntime.sleep(1.1)\nprint(model.state)  # >>> C\n```\nor as part of a subclassed State which allows easier individual timeout handling:\n```python\nclass TimeoutState(State):\ndef __init__(self, timeout):\n    self.timeout = timeout\n\nb = TimeoutState('B', enter='set_timeout')\nm = Machine(model, states=['A', b, 'C']) ...\n```. > For my purposes, having 30 or more states ... it seems like a lot of unnecessary boilerplate.\nIf you subclass Machine, the extra lines of code scale quite well for many states:\n```python\nclass TimeoutState(State):\ndef __init__(self, timeout=None, *args, **kwargs):\n    self.timeout = timeout \n    super(TimeoutState, self).__init__(*args, **kwargs)\n\ndef enter(self, event_data):\n    # initialise timeout here\n\nclass TimeoutMachine(Machine):\ndef _create_state(self, *args, **kwargs):\n    return TimeoutState(*args, **kwargs)\n\nstates = [{'name': 'A', 'timeout': 1000},\n          {'name': 'B', 'timeout': 2000'},...]\nmachine = TimeoutMachine(states=states)\n```\n\nI'm curious as to why you feel that this shouldn't be part of the state machine \"internals\"?\n\nI do not consider timeouts as a core functionality. However, I do think this might be a valuable addition to transitions as part of a model/state extension. We collect ideas in #146 for that module. I will definitely add your suggestion there and in case it receives support/feedback by the community, we will discuss how it can be added to transitions.. We plan to ship timeouts with transitions 0.6.0. See #229 or the whole dev-state-extension branch for further info.. > Presumably it needs threads\nCorrect. It actually uses Timer similar to your code snippet above. \n\nbut I'm curious if the implementation has the same restrictions as I ran into\n\nYeah, it does. I am not aware of any convenient solution which allows timeouts without threads \ud83e\udd14.\nI could think of two threadless solutions but both have major issues:\na) Using async forces the event loop on the user\nb) Using polls/ticks allows synchronised execution but is not really convenient to use. This way the user has more or less to implement his/her own event loop and poll the machine/model regularly or the event won't trigger in time.\n@bedge: What's your lesson learned for timeouts/threading? Should transitions Timeout may support both approaches? Threads and polling? Or do you know about a better third way?. > The only thing I would suggest is that if a user isn't using transitions timers, the timer support should not interfere with using joblib of other threading APIs.\nwell, that should not be the case except joblib already complains when the threading module is imported. Timers are only created when Timeout is explicitly used.. > It's probably good practice to keep the state machine in a separate executable anyway\nagree, from what I heard in my department so far, one should use a single threaded state machine where ever possible. Closing this issue now since 0.6.0 has been merged with master and also pushed to pypi.. closing this since right now there seem to be no demand for something like this. Hi @dgtlmoon,\nthats an error in the ReadMe. The first argument of Machine's constructor should be the model, not the states. \nChanging machine = Machine(states, initial='A') to machine = Machine(states=states, initial='A') does the trick.\nThank you for the report. I will fix it instantly.\n. If an exception occurs before the transition (in prepare, before), it is halted. In case there is a raise after the transition has been conducted (in after, finalize), there is no rollback but the execution of further callbacks is halted. If the error occurs in after callbacks, finalize callbacks will be executed though. This is expected behaviour so far.\n```python\nfrom transitions import Machine\nm = Machine(states=['A', 'B', 'C'], initial='A', before_state_change='do_stuff')\nprint(m.state)  # >>> A\ntry:\n    m.to_B()\nexcept AttributeError:\n    pass\nprint(m.state)  # >>> A\nm = Machine(states=['A', 'B', 'C'], initial='A', after_state_change='do_stuff')\ntry:\n    m.to_B()\nexcept AttributeError:\n    pass\nprint(m.state)  # >>> B\n```\nWhat kind of behaviour would you expect?. Hi @dgtlmoon,\ndo you still have issues with the way the library handles exceptions during state transitions? Feel free to leave some feedback/suggestions.. closing this due to inactivity. Feel free to reopen the issue if it still persist.. > Would it be possible to add this information to the main documentation?\nsure thing! I added the passage right after the execution order.. Machines are picklable. I would say this is the most common approach to store the state of a machine. This feature has not been mentioned in the documentation before. Thank you for pointing that out.. thank you \ud83d\udc4d . Hi @luminize,\non_enter_<state> expects a function pointer or a name of a model function.\nself.machine.machine.on_enter_init(self.cb_reset_node()) calls  cb_reset_node and tries to bind the result which is None as a callback. This is not callable as the raised Error mentions.\nself.machine.machine.on_enter_init(self.cb_reset_node.__func__)\nIn this case you try to pass an unbound function which requires an argument (self). In unbound functions self is not assigned. This is why Pythons complains.\nWhat you need to do is to pass the bound method like that:\nself.machine.machine.on_enter_init(self.cb_reset_node)\n. Hi @luminize,\nthis sounds like a question suitable for Stackoverflow. Posting questions there has the advantage that the community of transitions users (including us) might assist and not just the developers.\nPersonally, I tackle this issue with an event based approach. Event handling is done by the model and can be either happening by reading from a queue (suited for reading from serial devices) or asynchronously.\n```python\nfrom transitions import Machine\nfrom collections import deque\nfrom threading import Thread\nfrom time import sleep\nERROR = -1\nREADY = 0\nBUSY = 1\nline = deque()\nsimulating a remote device which sends status updates every second\ndef writer_mock():\n    line.append(BUSY)\n    sleep(1)\n    line.append(BUSY)\n    sleep(1)\n    line.append(READY)\nread data from line/buffer and trigger events if required\ndef reader_mock():\n    global line, m\n    while True:\n        # if new messages are available in the buffer, trigger a transition attempt\n        if len(line) != 0:\n            m.input_received(state=line.popleft())\n            if m.state == 'process':\n                # end of the showcase has been reached. Exiting program.\n                return\n        sleep(0.1)\ncondition to check wether a transition should happen\ndef is_ready(state):\n    print(\"Current state: \" + str(state))\n    return state == READY\nstates = ['init', 'waiting', 'process']\ntransitions = [\n        ['initialized', 'init', 'waiting'],\n        {'trigger': 'input_received', 'conditions': is_ready, 'source': 'waiting', 'dest': 'process'}\n    ]\nm = Machine(states=states, transitions=transitions, initial='init')\nif setting up your model requires some preparation, 'after' would be a good\nspot to open channels/sockets/streams for reading.\nThis prevents events appearing before the model is set up\nm.initialized()\nwriter = Thread(target=writer_mock)\nwriter.start()\nthe reader could also run in a thread. But this way it blocks and keeps the program from\nexiting too early\nreader_mock()\n```\nI would recommend to process events synchronously to keep the complexity lower. However, if your event processing cannot be streamlined you can use 'LockedMachine' from the extension module which will lock event processing.. I think it really depends on how complex your readout procedure is. It is totally fine to call transitions from within transitions. In that case using queued=True as a Machine parameter (see ReadMe) might be useful to prevent weird logs:\nenter init # enter callback init\nexit init # exit callback init\nexited init # exit callback init done\nenter dest_go_cart # enter callback dest_go_cart\nentered dest_go_cart # enter callback dest_go_cart done\nentered init # enter callback init done\nBasically, queued will finish the enter callback before the next transition is evaluated and/or executed.  For most cases this should be sufficient.\nIf you need switch case statements based on states besides having a state machine, then something is wrong. I'd suggest to either use specific short living WorkerThreads or -- if you have a readout main loop -- to let the machine set the readout strategy  in enter.. Hi @mrdecav,\nthe reason for the last check is to distinguish transitions like to_new_state from actual auto transitions. Auto transition events usually have as many transitions as states since they should be valid from every state. That's also why the tests fail now. It checks if m.add_transition('to_state_A', 'B', 'A') appears in the generated graph.\nIt seems to work for some cases at least.\nCould you provide a minimal example where auto transitions are not filtered correctly? I can join the bug hunting then.. Hi @mrdecav,\nare you still experiencing the error related to graph generation? If thats so, please provide us with a test case to reproduce the error.. Closing this due to inactivity. If the error still occurs, please let us know and/or reopen this pull request.. Hi @Fawenah,\nas you might see, these warnings are generated by pygraphviz. The reason why they haven't been shown before is, that transitions just started to use warnings for (pending) deprecations.\n\nimp issue\nthe second warning is related to how pygraphviz handles searches related PEP\n\nWe could silence/filter the warnings but imho the actual addressee of this issue is the dev-team of pygraphviz, isn't it? Silencing might also just a temporal fix because as written in PEP 479, the warnings will become non-silent in Python 3.6.. Starting from 0.5.2, the PyPi package also contains the LICENSE file.. Hi @booware,\nlooks better that way. Thanks.. Hi @booware,\nvery good bug report! Unfortunately, the test case just tested the basic Machine class. When I changed that, I could also observe the bug. The solution is -- as you already figured out -- to use the Event._trigger procedure for NestedEvent._trigger. I have fixed that issue and will push the changes shortly.Thank you for your contribution.. > Sure, but it's probably better if I add you as a maintainer on PyPI \nIf thats fine with you, sure.\n\nWhat's your PyPI username?\n\naleneum. This is a tricky one since LockedMachine wraps instance methods in partials. To determine if a function should be used as a callback, we check if the returned callable is a method (bound to a model instance). We cannot just check if the returned function is callable since \"Machine.on_enter_\" also returns a partial (a wrapped call to add_callback). \nSmall example:\nCase A (Model != Machine):\nmodel.on_enter_A -> method\nmodel.on_enter_B -> undefined\nCase B (Model == Machine):\nmodel.on_enter_A -> method\nmodel.on_enter_B -> partial\nCase C (Model == LockedMachine):\nmodel.on_enter_A -> partial (from the Model part)\nmodel.on_enter_B -> partial (from the Machine part)\nSolution\nThis special case will now be handled in LockedMachine.  Thank you for the bug report!. Hi @mathiasimmer,\nthe keyword initial currently expects a string. Even though the output of the lump.state is correct, the way the machine has been initialised is not.\nHave a look at this constructed case, even though no one will probably initialise a machine like that:\n```python\nfrom transitions import Machine\nfrom transitions import State\nclass Matter(object):\n    pass\nlump = Matter()\nsolid = State('solid')\nsecond_solid = State('solid')\nliquid = State('liquid')\ngas = State('gas')\nmachine = Machine(lump, [solid, liquid, gas], initial=second_solid)\nprint machine.states['solid'] == second_solid # will return True\n``\nForinitial, transitions expects a string and therefore just checks if a state is already named like the value ofinitial. If you pass aState, this test obviously fails. Consequently,Machine.add_statewill add the passedState` instance as a new state and override our previously added solid state.\nYou see that our first instance of solid has been kicked from the machine's states in favour of the second instance passed to initial.\nLong story short: Passing a State object to initial has not been supported (yet) and the fact that it somehow works for Machine is not intentional.\nThe question is: Should transitions support State as a valid type for initial? I'd say it adds convenience. But let's wait for feedback.. Hi again, \naccording to #153, transitions should be able to process State instances passed to initial correctly. So this qualifies clearly as a bug. I fixed it and extended testing. I checked your provided code sample and it does not raise TypeError anymore.\nThank you for reporting this!. yeah, sounds like #211. It should have been fixed in 0.5.1. If that does not work for you, feel free to reopen the issue.. Hello @KarolOlko,\nthank you for the pull request. This case hasn't been covered before. \n\nI got an error \"KeyError: 'agedge: no key'\"\n\nThis has been mentioned in #133. Back then it seemed to be an issue with Windows and pygraphviz and could not be reproduced. If you can pinpoint this issue to transitions, feel free to reopen #133 again.. Hi @kunalbhagawati, \nthis clearly is a bug. Thank you for pointing it out. I went for initialising EventData.transition in the constructor instead of a default getter argument. This way the transition argument will be present instantly in the EventData object which in my oppinion is a better practise than adding the argument dynamically during transition execution (as it had been before your report). The result is pretty close to your suggestion as EventData.transition is initialised with None.. > My only worry is client code of other library clients.\nThis is the big show stopper.\nWhen implementing _create_state/transition and such they were meant as factory methods which were attached to the class for code clarity and easier inheritance. \nIf static methods do make sense in Python seems to be a discussed topic in the community. If an example is mentioned where it might make sense, it is often this one (connection to class, alternative constructor and inheritance). So much for the reason why they are static.\nThere is a combination of three factors where this might not be sufficient:\n\nMachine and model are the same instance \nstates need to be created during initialization\nstates need to know the machine instance at creation time\n\nIt boils down to the issue that you cannot pass 'future' self in the state dictionary. Could have been avoided if the methods had not been static from the beginning. However, the damage is done.\nWhat to do?\n\n\nWe could prepare _create_state/transition, warn clients and convert them from static methods to instance methods in the next major release. But this is something that requires more feedback from collaborators and the community.\n\n\nWe refine the way how states in particular are created. I wonder if there is a better way than subclassing _create_state which is a) easier and more convenient and b) does not involve yet another parameter in the constructor. I am looking forward for suggestions.\n\n\n(Remark for a): I think its already convenient but we also received feedback that implies we might should think about improving this.). oh, concerning this:\n\nyou may need an ability to pass instance variable to your derived event or transition\n\nEvent is created with Machine instance assigned to it and will get the model via Event._trigger. Transition receives machine and model via EventData. Same is true for State as EventData is passed to State.enter/exit.\nAs mentioned above, the only case where this might not be sufficient -- which I can see so far -- is, when states need to know the machine instance from the start. Let me know if you are facing such a case.\nThis was just an example but I want to show how this can be done quite convenient already:\n```\nclass BookKeeper(object):\n  def init(self):\n    self.events_triggered=0\n    self.transitions_taken_place=0\nclass BookKeepingEvent(Event):\ndef trigger(self, model, *args, kwargs):\n    model.increment_events_triggered()\n    super(BookKeepingEvent, self).trigger(model, *args, kwargs)\nclass BookKeepingMachine(Machine):\n  @staticmethod\n  def _create_event(*args, kwargs):\n    return BookKeepingEvent(*args, kwargs)\nbook_keeper = BookKeeper()\nmachine = BookKeepingMachine(model=book_keeper, ...)\n```\nAlternatively, you can use prepare callbacks to avoid subclassing at all:\n```\nclass BookKeeper(object):\n  def init(self):\n    self.events_triggered=0\n    self.transitions_taken_place=0\ndef on_trigger(self):\n    self.increment_events_triggered()\nmachine = Machine(book_keeper, prepare_event ='on_trigger')\n```. No worries @KarolOlko, thank you for you input. Discussing and reviewing features is also a valuable contribution towards better software.\nLooking forward for further ideas.\nBest regards,\nAlex. Hi @KarolOlko,\nI am experimenting with different ways of passing the class used to create states. It seems like that you can override class/static decorators in inheriting classes without problems:\n```python\nclass Prod(object):\ndef __init__(self, name):\n    self.name = name\n    print(name)\n\nclass Base(object):\n@staticmethod\ndef create(*args, **kwargs):\n    return Prod(*args, **kwargs)\n\ndef trigger(self, *args, **kwargs):\n    self.create(*args, **kwargs)\n\nclass InstanceClass(Base):\ndef create(self, *args, **kwargs):\n    return Prod(*args, **kwargs)\n\nclass StaticClass(Base):\n@staticmethod\ndef create(*args, **kwargs):\n    return Prod(*args, **kwargs)\n\nclass ClassClass(Base):\n@classmethod\ndef create(cls, *args, **kwargs):\n    return Prod(*args, **kwargs)\n\nBase().trigger(\"base\")\nInstanceClass().trigger(\"instance\")\nStaticClass().trigger(\"static\")\nClassClass().trigger(\"class\")\n```\nNo matter what decorator Base is using, the first argument passed to Prod is always correct.\nSo the problem of requiring the Machine instance for state creation can be solved quite easily by just omitting the static decorator and -- of course -- add self to the method specs:\n```python\nclass BookKeepingMachine(Machine):\ndef _create_event(self, *args, **kwargs):\n    return BookKeepingEvent(self.book_keeper)\n\n```\nDoes this solve your initial problem?\nEdit: I let Base call create to simulate the state creating a bit more accurate. Hello @KarolOlko,\nfirst, let me say thank you for your input. We strive for improving transitions wherever suitable.\nThe struggle between convenience, flexibility and code base clarity has been a constant factor so far. \nThis being said I -- personally -- do not feel like the balance of added value compared to added code complexity is held here. I also experienced the need of having *args and **kwargs in callbacks as a mild inconvenience. But I fear that the effort saved here has to be spent elsewhere when mapping goes wrong. Basically your suggestions reimplements one of the core functionalities of Python which is dynamic parameter mapping. Dynamic introspection is an amazing tool but doing it in every callback and check (which comes close to everywhere for everything) is a big point of failure. Especially because Python has many variants of callable objects and inspect itself is a moving target. \nI just peeked at issues with inspect and found that a) inspect.getarcspec is deprecated in Python 3.x and the replacement inspect.signature does not handle partials well. We use partials quite a lot.\ntl;dr: Imho this may requires more effort for maintenance of the library as well as user code in the long run than it saves.. Closing this due to previously discussed maintenance and stability issues. Feel free to open it again in case you like to discuss this further.. Hello @ksandeep,\nthank you for bringing this to our attention. \n\nThe warnings.simplefilter('default') line is modifying the state of warnings module globally and causing logspew.\n\nWhile this is definitely not intended behaviour, removing the filter altogether will also hide our PendingDeprecationWarnings. I just pushed a change to master with a more specific filter which should only show our warnings in case it is necessary. If this still clutters you log, let me know and if possible provide a minimal example of your issue that I can use to adjust the warning output.. Hi @bedge,\nevent.args[0].kwargs sure looks weird but I cannot tell why this is happening from the current input. Can you provide a minimal example of this issue? trigger (frame 10) is usually called before _callback (frame 9), so I cannot wrap my head around what is happening there. Do you trigger an event from a callback?\n. It is considered a feature that you can define on_enter_<state_name> methods in your model which will be called if <state_name> is entered. Or do you refer to the dynamically added trigger -- for instance scale_out -- which will be added to the model?\nUpdate: Ah, well, you probably refer to Machine.on_enter_<state_name> which adds callbacks. I agree this might me a bit confusing. You have Model.on_enter_A which will be called whenever A is entered and you have Machine.on_enter_A which can be called with a function (name) to add it to call it whenever A is entered.\nMachine.on_enter_<state_name> is not actually added to the machine though but dynamically generated whenever called. I assumed an already existing method Machine.on_enter_A will shadow this dynamic add_callback generation.  I will check this out.. I tested this and it behaves like expected:\n```python\nfrom transitions import Machine\nclass MyMachine(Machine):\n# define on_enter_A in Machine; this will shadow the possibility to add\n#  callbacks with on_enter_A \ndef on_enter_A(self, event=None):\n    print \"entered A\"\n\ndef hello(self, event):\n    print \"Hello\"\n\nstates = [\"A\", \"B\"]\ntransitions = [\n    {'trigger': 'go', 'source': 'A', 'dest': 'B'},\n    {'trigger': 'back', 'source': 'B', 'dest': 'A'}\n]\nm = MyMachine(states=states, transitions=transitions, initial='A', send_event=True)\nthe above defined function\nprint(m.on_enter_A)\n>>> >\nthe dynamically generated add_callback function\nprint(m.on_enter_B)\n>>> \nwill call the previously defined method\nm.on_enter_A() \n>>> entered A\nwill call the dynamic add_callback method and pass function name;\n'hello' will now be called whenever B is entered\nm.on_enter_B(\"hello\") \nenter B\nm.go()\n>>> hello\nenter A\nm.back()\n>>> A entered\n```\nAs you see on_enter_A is not overwritten during instantiation. The error must be caused by something else then. If you could provide further information about the issue or provide a minimal example I could investigate further.\n. Hi @timofurrer,\nAs  you mentioned already, MachineError for invalid transitions can be omitted by ignore_invalid_triggers in cases where this kind of transitions is part of the workflow.\nIf set to True, no Error will be raised and the processing of the queue will continue.\nHowever, you cannot set this option for transitions individually.\nImho, clearing the event queue is quite vital for cases in which MachineError actually indicates issues with the ongoing queue processing.\nCould you elaborate why ignore_invalid_triggers is not sufficient for you?. Okay, let me reword, why do you need errors to be raised in every other case except that? And also: Why is it in these other cases vital that the queue is also processed? Currently, I do not see why you cannot use ignore_invalid_triggers here.. Another follow up:\nthe state logic for your presented case becomes much easier if you can timeout the blocking call in after directly. Your code could look something like this then:\n```python\nclass Model(object):\n    def send_request(self):\n        try:\n           # call the blocking function with timeout parameter, if possible\n            module.blocking_call(..., timeout=1)\n            self.ready()\n        # catch the module's timeout error\n        except module.Timeout:\n            self.timeout()\nstates = ['preparing', 'request_abort', 'ready']\ntransitions = [{'trigger': 'query', 'source': 'ready', 'dest': 'preparing', 'after': 'send_request'},\n               ['ready', 'preparing', 'ready'],\n               ['timeout', 'preparing', 'request_abort']]\nmodel = Model()\nm = Machine(model, states= states, transitions=transitions, initial='ready')\nm.query()\n```. Since there has been no activity for 14 days I will close this issue for now. Feel free to reopen it if the issue is still present or you want to provide new insights.. Hi @timofurrer,\n\nThus, all calls to any method is blocked - calls like is_() etc. which don't have to be locked.\n\nThis is intentional since a transition is currently processed and the machine is in an undefined state. Even though the models state has already been changed, after and finalize may alter the state again.\nIf is_stated<> would not be locked, this might trigger actions which are invalid the moment they are triggered. This will be an even bigger problem if you use multiple models and racing conditions become more frequent.\n\nDo you see any possibility that we could add a lock around core.py...\n\nSorry, but no. We strive for a  basic machine which is lightweight and fits general purposes. Locking involves an overhead which may not be in the best interest of most library users. This estimation may be wrong though. If this issue is flooded with opposing feedback, I will gladly change my mind.\n\nBut as I've said I'm not too familiar with the current implementation thus my solution proposals maybe complete non-sense [...]\n\nFeedback is always appreciated and we of course try to improve transitions to support all the use cases around. However, my following conceptional suggestions might be non-sense since I do not know what you are actually planning to achieve:\n\n\nreduce threaded access to the state machine whenever possible: This is what I have been told from our robotics department and I believe them since they work with quite complex state machines on a daily bases. I personally work with some sensor-event-based multithreaded state machines and trying to decouple state transition and state behaviour left me with less complex and easier to debug code.\n\n\ndetach after from the blocking process: If your after callback is blocking and you consider the state transition finished, it might be a good idea to dispatch the blocking process to a new worker thread.\n\n\nqueueing transitions which become invalid during the queue processing could be avoided maybe: Since you are using threads quite a lot you are probably waiting for data from somewhere to trigger certain actions. I have had good experience with applying sensor readings and callbacks to the model. The state machine thread only evaluates the model and triggers transitions whenever suitable. This leads to a very responsive state machine and less interference caused by parallel resource access. This is basically suggestion 1 in disguise.\n\n\nAgain, these are just suggestions and might not fit your use case.\nUpdate: We discussed coroutines a while ago. Maybe this would fit your needs (#181)... ?. Since there has been no follow up for 14 days I will close this issue for now. Feel free to reopen it if the issue is still present or you want to provide new insights.. Hi @bedge,\nare you looking for a way to trigger events by name? If so, Model.trigger might be what you are looking for. From the doc:\n\nAdditionally, there is a method called trigger now attached to your model. This method lets you execute transitions by name in case dynamic triggering is required.\n\n```python\nlump.state\n\n\n\n'gas'\nlump.trigger('ionize')\nlump.state\n'plasma'\n```. Hi @bedge,\n\n\n\ntransitions will be evaluated in the order they were added to the machine. * will actually be replaced by each state in the machine:\n```python\nm = Machine(states=['A', 'B', 'C'])\nm.add_transition('go', '*', 'B')\nthis will execute\nm.add_transition('go', 'A', 'B')\nm.add_transition('go', 'B', 'B')\nm.add_transition('go', 'C', 'B')\n```\nTo use your wildcard transition as fallback/generalized transition, you need to add it last.\npython\nmachine.add_transition('to_liquid', 'gas', 'abort')\nmachine.add_transition('to_liquid', '*', 'liquid')\nThe wildcard transition will then add a transition to the evaluation queue of state gas which cannot be executed though since there is no way your ['to_liquid', 'gas', 'abort'] transition will fail. \nRemark: Maybe you want to change the naming scheme of your transition. to_<state.name> is the naming scheme of auto transitions which will actually end up in the related state. Having a transition which is called to_liquid and does not end in liquid might be a source of confusion later on. Thinking of it: If you did not disable auto transitions with auto_transitions=False in the Machine constructor, your machine will contain the trigger to_liquid already. In this case adding more transitions with the same trigger will have no effect.. Hi @Stig9999,\na state extension is in the pipe. Have a look at the dev-state-extension branch of transitions if you are curious.\nCurrently, the extension is designed as a 'Mix-In-Convenience-Wrapper'.\nThe code below does not work on its own since I copied it from a test case but it shows the currently intended usage:\n```python\nfrom transitions import Machine\nfrom transitions.extensions.states import add_state_features, Tags\n@add_state_features(Tags)\nclass CustomMachine(Machine):\n    pass\nstates = [{\"name\": \"A\", \"tags\": [\"initial\", \"success\", \"error_state\"]}]\nm = CustomMachine(states=states, initial='A')\ns = m.get_state(m.state)\nself.assertTrue(s.is_initial)\nself.assertTrue(s.is_success)\nself.assertTrue(s.is_error_state)\nself.assertFalse(s.is_not_available)\n```\nTags can be used in a flexible manner. For instance to define success/final states. Additionally, there is a specialisation of this MixIn which is called Error. If this feature is added, a state will check for outgoing transitions when entered. If the machine does NOT contain outgoing transitions and the state itself is NOT labelled with accepted a MachineError is raised.\nThe extension also currently features Timeout states and Volatile (reinitialising temporal state objects whenever a state is entered) states.\nSince this module is still in an experimental state it is not well documented yet. But looking at the states or the tests should help to get a basic idea. \nWould this extension make your life easier? What is missing? Feedback is much appreciated.. Hello again @Stig9999,\nI added usage examples and initial implementation details of Tags (#230) and Error (#231). Feel free to discuss how they could be improved for convenience.. Closing this due to inactivity. I am looking forward to feedback for #230/#231 in case this feature is still relevant for you.. Hi @Synss, \nthank you for the feedback. Just a remark why I sticked with kwargs.pop:  The add_state_feature decorator will add mixins to the state class of the chosen Machine. State does not handle *args or **kwargs which means that eventually all custom arguments have to be 'consumed'. The required mixin style becomes a bit stricter but should make bug tracking easier when keywords have been accidentally used twice or a mixin 'misbehaves'.. Good point,\nHierarchicalStateMachine.add_states can already handle that. What do you think about accepting just **kwargs here? This way state parameters have to be passed as keyword arguments. Passing them as ordered arguments feels like a futile endeavor to me. Actually, the state mixins could not handle *args anyway.. > Have you started working on this?\nhas been implemented and tested. Hope this enables your workflow.. 2nd Iteration:\nKeywords\n\nvolatile (class, optional) -- every time the state is entered an object of type class will be assigned to the model. The attribute name is defined by hook. If omitted, an empty VolatileObject will be created instead\nhook (string, default='scope') -- The model's attribute name fore the temporal object.\n\nExample Usage\n```python\nfrom transitions import Machine\nfrom transitions.extensions.states import add_state_features, Volatile\nclass TemporalState(object):\n    def init(self):\n        self.value = 5\ndef increase(self):\n    self.value += 1\n\n@add_state_features(Volatile)\nclass CustomMachine(Machine):\n    pass\nstates = ['A', {'name': 'B', 'volatile': TemporalState}]\nm = CustomMachine(states=states, initial='A')\nm.to_B()\nprint(m.scope.value == 5)  # >>> True \nshould call method of TemporalState\nm.scope.increase()\nprint(m.scope.value == 6)  # >>> True\nre-entering state should reset default volatile object\nm.to_A()\nprint(hasattr(m.scope, 'value'))  # >>> False\nm.scope.foo = 'bar'\nm.to_B()\ncustom attribute of A should be gone\nprint(hasattr(m.scope, 'foo'))  # >>> False\nvalue should be reset\nprint(m.scope.value == 5)  # >>> True \n```. Hi @ankostis,\n\n(sorry to provide feedback so late)\nfeedback is always appreciated.\nHave you considered environmental markers?\n\nnot yet. I guess you suggest to make pygraphviz a dependency for *nix systems only, right?\nMy motivation to make pygraphviz optional is that it is actually optional. You even extended the tests to skip pygraphviz related tests :). I'd love if setuptools/pip had some 'default enabled' optional handling like homebrew (--no-pygraphviz). But I am not aware of any solution like that.\nDo you see issues with making diagrams and optional feature?. Okay, good to know but I would like to avoid platform dependent behaviour.\nExcept if there is a good reason why making diagrams optional for everyone might be a bad idea.\n. > And using environment-markers for platform dependent behaviour is obligatory on \"wheels\", where the setup.py script is never executed.\nI see. Thanks for bringing environment markers to my attention. Knowing about this feature and its purpose will defo save some time in the future.\nDo you have positive experience with certain pygraphviz versions under Windows or know some versions which definitely won't work?.  > If we can do that, then the GUI would ideally generate a JSON spec for transitions rather than interfacing directly with the package.\nJust to clarify what features we consider useful for such a GUI since I have been vague with this ticket: I am personally interested in a way to monitor and control a(n already instantiated) state machine remotely. Having a way to let transitions generate a state machine from JSON sounds like an interactive state machine creator. Do you think of a GUI more as a Controller or Creator (or both)? For both cases a JSON-spec sounds nonetheless useful though.\n. Hi @parthsharma1996,\n\nPardon me for asking again but are there any plans to implement this? \n\nunfortunately, I cannot give you a roadmap for this feature. What are you particularly interested in? A way to visualise graphs or a way to create/control graphs?. >  it would be great to be able to manage all that with a GUI instead of keep adding a dict for each transitions.\nI see. What I can offer is to publish the dev-json branch I am working on  (what I just did) which adds an intermediate layer between the visualisation and Machine itself (MarkupMachine and HierarchicalMarkupMachine). This JSON representation will act as an exchange format.  Additionally, I can outline the tornado (web) server to visualise the graph and trigger events.\nMaking graphs/machines editable may be a long road but this should illustrate the general idea.\n\nI am also using a slightly modified and unsupported version\n\nYou probably have to alter the MarkupMachine._convert_transitions link to deal with this:\n{'trigger': 'do', 'source': 'A', 'dest': {'1': 'B', '2': 'C'} , 'depends_on': 'func'} => \n{'trigger': 'do(func=1)', 'source': 'A', 'dest': 'B'} ...\nThis should at also 'fix' the pygraphviz visualization.\nNote that dev-json is WIP and will be rebased to clean up the history when things settle.. @parthsharma1996:\nI published  the initial version of transitions-gui. Feel free to check it out.. Hi @loicpw,\n\nability to right click and directly add/write python scripts to handle transition events\n\nwriting Python code which is sent to the web server and evaluated/executed is currently not on my list due to security concerns. However, the ability to add callback/condition names to states and transitions (model method strings ('do_something') as well as import handles ('imported.module.do_something')) definitely is.\n\nMaybe a dummy question but would it be easily integrated into a web project like Django or others ?\n\nvery legit question! Since the user interaction and graph editing is handled by the client (javascript), it should not be an issue to use Django instead of Tornado. \nmain.js can be hosted by any web server with Websocket capability.\nThe client library currently expects a Websocket endpoint at ws://${document.location.host}/ws. Messages should be of the format {\"method\": \"<method_name>\", \"arg\": \"<arguments>\"}. The following messages are supported:\nGenerate graph (server -> client)\njson\n{\n  \"method\": \"update_machine\",\n  \"arg\": \"<MarkupMachine.markup>\"\n}\nHighlight transition (server -> client)\njson\n{\n  \"method\": \"state_changed\",\n  \"arg\": {\n    \"model\": \"<model_name>\",\n    \"transition\": {\n      \"source\": \"<source>\",\n      \"dest\": \"<dest>\", \n      \"trigger\": \"<event_name>\"\n    }\n  }\n}\nTrigger event (client -> server)\njson\n{\n  \"method\": \"trigger\",\n  \"arg\": \"<trigger_name>\"\n}\nHaving a look at the WebSocketHandler and the overloaded _change_state in WebMachine here should provide a general idea. Basically a potential handler just needs to forward received Websocket messages to the machine, provide a send_message method for the machine to publish state changes and handle new connections by sending the machine's markup to the client.. Use next-release. The function MarkupMachine._convert_transitions starts here. This line:\nt_def = _convert(trans, self.transition_attributes, self.skip_references) tries to convert every transition attribute into a string representation to create valid JSON. So right BEFORE that, you should check whether trans.dest is a dictionary. If thats the case you should create a set of 'dummy' transitions which are converted to json instead of the customized transition.\n. weird, the build fails for python 2.7 and python 3.3 due to a recursion errors in dill. I cannot reproduce this with tox though \ud83d\ude15 .. Maybe this is a one time phenomena... Could you extend the add_states docstring to cover the new parameter? This will not change the actual code but a) it's a nice thing to do anyway and b) it will trick travis into building again.. Well... this did not help (bummer). Maybe this issue with dill 0.2.7 is related to what we experience. However, I also installed dill 0.2.7 and manually added **kwargs to add_states but everything works fine.... I just rebuilt the 'state-extension' branch and (as expected) it breaks too now \u26c8 . . Okay, I boiled it down to this:\n```python\nimport dill as pickle\nfrom functools import partial\ndef get_trigger(model):\n    pass\nclass Machine(object):\ndef __init__(self):\n    self.child = Model()\n    # raises RuntimeError\n    self.trigger = partial(get_trigger, self)\n    # does not work either\n    self.child.trigger = partial(get_trigger, self.child)\n\nclass Model(object):\n    pass\nm = Machine()\ndump = pickle.dumps(m)\n```\nworks for dill 0.2.6, does not work for dill 0.2.7. (One) problem solved for Python 2.7 but Python 3.3 still breaks.. dill drops Python 3.3 in version 0.2.7 since the issue requires more effort than justifiable concerning the EOL of Python 3.3. The issue with 3.3 is related to how super works and there is a workaround for that (see uqfoundation/dill#236). The big question however is: Should transitions 0.6 also drop Python 3.3 support?. I will go ahead and try to integrate the super workaround if possible.\n. Fixed in cd7bd8939c70a4671ffa591c93e7c65de2ff0b6b. > In most cases, transitions allows to machine.get_state(state).add_callback(function)\nThe purpose of State.add_callback is to add callbacks for entering and exiting states and takes two arguments. See the docstring:\npython\n    def add_callback(self, trigger, func):\n        \"\"\" Add a new enter or exit callback.\n        Args:\n            trigger (string): The type of triggering event. Must be one of\n                'enter' or 'exit'.\nIf I get your suggestion right, you would like to the for Timeout.add_callback to handle not just 'enter' or 'exit' but also allow 'timeout'. We could just listify on_timeout and override add_callback to allow machine.get_state(state).add_callback('timeout', function). However, extending the convenience function Machine.on_enter/exit_<statetname> to also allow Machine.on_timeout_<statetname> would require changes in core (which I try to avoid).\n\nI would therefore propose to add a set_timeout(self, timeout, on_timeout) method for \n\nIf I am not mistaken (which may be the case) getters and setters are not really pythonic as Timeout properties could be altered directly. If we go for the on_timeout listify solution, I'd rather use property decorators to make sure that timeout callbacks are always a list.\n=> I will alter Timeout in a way that allows to handle multiple on_timeout callbacks and extend the add_callback method accordingly. If this does not achieve what you had in mind, feel free to give feedback.. > Generally, timeouts are probably better served ... as custom transitions, that only trigger if one lingers \nThe motivation for timeout states originates from issues as stated in #198 and similar requests on Stackoverflow. I thought of timeout states and timeout transitions in a way that both fulfil different purposes: The first can be used if a state should not be active longer than a certain amount of time and the second if a transition attempt takes too long.\nYou suggest a mixture of both concepts (if I got this right) where when a state is entered, outgoing transitions are evaluated for 'timeout' conditions:\npython\ntransition = [{'trigger': 'slow_timeout', 'timeout': 100, 'src': '*', 'dest': 'Error'},\n              {'trigger': 'fast_timeout', 'timeout': 10, 'src': 'TimeCritical', 'dest': 'Error'}]\nI can see this work too. The decorating process however becomes more complicated since it requires extended functionality for transitions and states. If you have a suggestion how this could be handled by transitions I am all ears.\n\nAs far as I understand, ... machine would not be in any state during the transition\n\nUntil on_exit callbacks are processed, the model will be in the source state. The machine will switch the model's state and start to process destination callbacks. This means (thanks to Tal's design), the processed model should always be in defined state. Bringing threads into the game does make things more complicated of course (dealing with pending/ongoing transitions and such, racing conditions...) I would consider it good practise to do the actions that might timeout in preparation and condition checks . > I use on_timeout to transition to either next_state or some error state\nI would also think that for most use cases a single callback is enough. Does this mean you (plan to) change timeout and on_timeout values during runtime? If so, what is your motivation?\n\nIf this is correct, you should really not listify on_timeout.\n\nwell, it does not hurt \ud83d\ude04 . We do the same handling for before,prepare and such. As a module user you can treat all of these properties as single entities or lists, depending on your needs.\n. Hi @tyarkoni,\ncurrently, callbacks are properties of Machine. This means Machine had to be adapted to alter the behaviour of Machine.on_enter/exit/<dynamic_method>. Since all callbacks are either a) related to states or b) related to transitions it might be a good idea to couple these callback keywords to Transition and State instead.\n```python\nchange this... in Machine._identify_callback\ncallback_type = cls.callbacks[[name.find(x) for x in cls.callbacks].index(0)]\ninto this...\nfor cb in itertools.chain(cls.state_cls._dynamic_methods,\n                          cls.transition_cls._dynamic_methods):\n    if name.find(cb) > -1:\n       callback_type = cb\n       break\nelse:\n    return None, None\n```\nadd_state_features creates a class called CustomState from all passed Mixins and the appropriate State class (depending on if the a Machine, LockedMachine or HierarchicalMachine has to be extended). We could monkey patch _dynamic_methods something like this:\npython\nCustomState._dynamic_methods = set(itertools.chain([c._dynamic_methods for c in inspect.getmro(CustomState)]))\nDoes this comply to what you have in mind?. Hi @Blindfreddy,\nif you could provide a minimal example where this error occurs, I will start investigating (and hopefully fixing it) right away.. Well, I guess I see the issue. You try to add State objects to a HierarchicalMachine which requires NestedState as a state type. The error message should mention that more precisely.. In 0.6, we will introduce a MixIn workflow for extending states which should make customizing states easier. The ReadMe of the dev-branch already contains more details about how this process should look like. I extended it by an example about how 'standard' subclassing could look like.. Partials for condition checks haven't been tested anywhere else yet. If you call fly and make sure that both conditions are checked this would also test if partials are handled correctly. Just in case someone introduces something later on which breaks this compatibility.  Like:\n```python\n[...]\nm = self.machine_cls(states=['A', 'B', 'C'], initial= 'A', show_conditions=True,\n                     title='a test')\nm.add_state({'name': 'E'})\nm.add_transition(trigger='fly', source='A', dest='B',\n                 conditions=Check(False))\nm.add_transition(trigger='fly', source='A', dest='C',\n                 unless=functools.partial(check, False))\nm.fly()\nself.assertTrue(m.is_C())\n[...]\n```. > I could test partial conditions in test_core, make Graph.rep() a staticmethod (it does not use self anyway) and test Graph.rep() directly. Is that OK?\nSounds good. Currently, the 'coverage problem' is, that test_anonymous_callable_conditions does not actually makes use of Check and the partial function check though (see coverage report). So yeah, testing partials for condition checks in core does make sense as well as making rep a module function (does not even have to be part of Graph)  but it does not solve the issue of unused constructs in the test itself.\nI know its not a big issue but I would prefer if this could be solved in a meaningful/contributing way.. Looks good to me, one function name was misspelled, thats why the test hadnt been executed.\nThanks!. Just realised there is a problem. The test test_add_model_no_initial_state actually expects [] to be handled as no model. This was implented by @paulbovbel and is probably intentional. Commit has been reverted for now.. you are right, the docstring isn't accurate. I extended it accordingly.\n\nexample should be added in the documentation ?\n\nIn the alternative initialization pattern section you will find the following passage:\n\nA machine can handle multiple models which can be passed as a list like Machine(model=[model1, model2, ...]). In cases where you want to add models as well as the machine instance itself, you can pass the string placeholder 'self' during initialization like Machine(model=['self', model1, ...])\n\nDo you think this is sufficient or do you have any suggestions how to extend this section?\nIf you have any other idea about making the model parameter a bit more versatile (without extensive type checks ;)), let us know.. API documentation has been added for (at least) every public method. I close this issue for now. Feel free to comment if you consider this issue as not being solved by the documentation attempt or open a new issue if you have further recommendations about how to improve transitions documentation.. Hi @600lyy,\ngreat to hear that transitions supports your development. Please refer to Stackoverflow first when it comes to usage questions. This has several advantages:\n\nYour question gains higher visibility since most developers look for help there\nThe targeted community is larger; Some people will even help you to formulate a good question\nPeople get 'rewarded' with 'reputation' to help you. You also gain reputation in case this questions pops up more frequently. It's a win-win situation. \n\nI will close the issue now. If no one at SO can help you and/or a feature request emerges out of your question, feel free to open another issue here and preferably reference your SO question.\nBest regards!\nUpdate:\nOh, and do not forget to label the question with transitions and python. This way it pops up in the news feeds of transitions developers at least.. Sounds reasonable even though I have to admit that I lack experience when it comes to proper packaging. If @tyarkoni agrees, I will merge this pull request and have a look in how to provide wheels as well.. As the changes do not have any impact on how transition can be used I will treat no further feedback within 7 days as silent agreement and merge the pull request. The first release which will be provided with the extended manifest and as a wheel will probably be 0.6. Hi @Blindfreddy,\n\nNote that the expected callback 'ac1' was not called !!!!\n\nthis has been a bug in the way how NestedStates are recursively initialised. It should not be necessary to explicitly assign the callback. Unfortunately, test had only covered this manual approach so far.\nThanks for taking the time to write a bug report. I reformatted your code example to be directly executable with copy/paste. Give it a try. It should work now.. jupp, its the way the dictionary had been traversed. Initializing instances of NestedState directly has not been influenced.. I went ahead and made callback identification a bit more flexible (see the dev branch). Callbacks are now attached to the class property dynamic_methods of State and Transition. If a state mix in defines a new list for dynamic_methods it will automatically be added to the created class. See State.dynamic_methodshere and Timeout.dynamic_methods here. \nCustom callbacks can now be treated like default callbacks:\n```python\n@add_state_features(Timeout)\nclass CustomMachine(Machine):\n    pass\nclass Model(object):\n    # automatically added\n    def on_timeout_B(self): pass\n    def timeout(self): pass\n    def notification(self): pass\n    def another_notification(self): pass\nadds method timeout\nstates = ['A', {'name': 'B', 'timeout': 0.05, 'on_timeout': 'timeout'}]\nmodel = Model()\nmachine = CustomMachine(model=model, states=states, initial='A')\nadds method notification\nmachine.get_state('B').add_callback('timeout', 'notification')\nadds method another_notification\nmachine.on_timeout_B('another_notification')\n```\n@Synss: Since you use timeouts, this might be helpful.. This sounds like something very suited for Stackoverflow. I quote myself from the past:\n\nThis has several advantages:\n Your question gains higher visibility since most developers look for help there\n The targeted community is larger; Some people will even help you to formulate a good question\n* People get 'rewarded' with 'reputation' to help you. You also gain reputation in case this questions pops up more frequently. It's a win-win situation.\n\nEventually it also helps to grow the transitions community since SO produces some decent incoming traffic.. Hi @Grey-Bit,\n\non_enter callback is attached to the destination nested state, but the library is searching for this callback in the top level machine.\n\nstring callbacks are always looked up in the model which in your case is the Top machine.\nIf you do not pass a specific model instance to Machine it will serve as a model itself.\nFor more complex scenarios I'd suggest do split the machine (transitions and related rules)\nand model (actual state based behaviour).\nWhen you pass a Machine instance to another HSM, the rules and transitions will be copied and not just reused. That's why Nested will use itself as a model but the nested version will use Top instead. Having just copies of Nested's assets has two advantages: first, it does not intervene with the original Nested instance and second, it allows to reuse many functionality provided by core which otherwise had to be rewritten and as a result cause higher code complexity.\n\nIs there any way to achieve the encapsulation by some other means?\n\nThe 'easiest' way would be to pass callbacks by reference rather than by name. Instead of 'on_enter':'print_msg' use 'on_enter':self.print_msg. This way the callback reference is already resolved which prevents transitions to look it up in the model.\n```python\nfrom transitions.extensions import HierarchicalMachine as Machine\nclass Nested(Machine):\ndef print_msg(self):\n    print(\"Nested\")\n\ndef __init__(self):\n    self.states = ['n1', {'name': 'n2', 'on_enter': self.print_msg}]\n    Machine.__init__(self, states=self.states, initial='n1')\n    self.add_transition(trigger='goto_n2',\n                        source='*',\n                        dest='n2')\n\nclass Top(Machine):\ndef print_msg(self):\n    print(\"Top\")\n\ndef __init__(self):\n    self.nested = Nested()\n\n    self.states = ['t1',\n                   {'name': 't2',\n                    'children': self.nested}]\n    Machine.__init__(self, states=self.states, initial='t1')\n    self.add_transition(trigger='goto_t2',\n                        source='*',\n                        dest='t2_n1')\n\ntop_machine = Top()\ntop_machine.goto_t2() \nprint(top_machine.state)  # >>> t2_n1 \ntop_machine.goto_n2()  # >>> Nested\nprint(top_machine.state)  # >>> t2_n1\n``` \nAs mentioned above, I'd also suggest splitting machine and model. This way you can use MixIns to decorate your main model and keep the code less cluttered. This way you can also use every tool OOP has to offer to alter the state machine's behaviour.. > self.top.print_top()\n~Top does not contain a method called print_top. Change this to self.top.print_msg() and the code above works just fine.~\nSorry, my bad. Overlooked the transition which is called print_top. Will have a look shortly. . The problem is this line in extension.nested:\npython\n state = copy.deepcopy(state)\nThis destroys all the previously created cross-references. deepcopy seems to be smart enough to update bound method references as well. During the copying, at least three new instances of Top are created and all of them do not contain the later created methods.\nMaybe we can relax the copying a bit and use copy.copy instead. This would make your code work. Before that, I have to check why I used deepcopy in the first place. ~~Unfortunately, there is no test for that.~~ Actually, there is one: test_blueprint_remap. I will see if I can figure something out to satisfy this as well as your use case.\nRemark: self.state is used in Machine. Your values will probably be overridden.\n. Hello @Grey-Bit,\n\n...  it's better to create a \"parent\" variable in the nested machines that would reference the original containing machine?\n\nThis might work for a scenario with just one level of embedded machines but will not solve the issue for deeper nested configurations. The 'problem' that deepcopy will create new objects for every passed bound function reference still persists.\nI guess I put you on the wrong path by mentioning references to bound functions. They seem to NOT work well with HierarchicalMachine.\nHowever, HierarchicalMachine does work as intended for string callbacks. This is why I'd suggest again to have a look at how to share data via the model. You cannot implicitly override model functions for certain substates but transitions offers some tools to help with extending models and enable context sensitive behaviour:\n```python\nfrom transitions.extensions.nesting import HierarchicalMachine as Machine\nclass Nested(object):\ndef __init__(self):\n    states = ['n1', {'name': 'n2', 'on_enter': 'print_msg'}]\n    transitions = [['goto_n2', '*', 'n2']]\n    self.machine = Machine(self, states=states, transitions=transitions, initial='n1')\n\ndef print_msg(self):\n    print(\"Nested\")\n\nclass Top(Nested):\ndef __init__(self):\n    super(Top, self).__init__()\n    self.nested = Nested()\n    states = ['t1',\n              {'name': 't2', 'children': self.machine}]\n    transitions = [dict(trigger='print', source='*', dest='=', after='print_msg'),\n                   ['goto_t2', '*', 't2_n1']]\n    self.machine = Machine(self, states=states, transitions=transitions, initial='t1')\n\ndef print_msg(self):\n    # call super method in case we are in a substate\n    if self.is_t2(allow_substates=True):\n        super(Top, self).print_msg()\n    else:\n        print(\"Top\")\n\ntop_machine = Top()\ntop_machine.print()  # will call Top.print_msg\ntop_machine.goto_t2()\ntop_machine.print()  # will call Top.print_msg and forward to Nested.print_msg\ntop_machine.goto_n2()  # same as above, but triggered by 'on_enter' instead of 'after'\n```\nI acknowledge this is an issue since it reduces the flexibility of HierarchicalMachine.\nIf you or someone else wants to suggest a fix/redesign of HierarchicalMachine, feel free to open a pull request. Running instances of Machine inside another instance of Machine was one of my first attempts but I ended up more or less with a parallel implementation of this class with way to much glue code.. > Where should I expect it to fail due to the lack of deep copy?\nI am currently aware of the issue that it breaks the imported machine. The above mentioned test_blueprint_remap will fail in case copy is used. The imported machine counter cannot trigger events any longer since the states had been renamed. Additionally, the passed state dictionary might have been changed (for instance added keywords).. @Grey-Bit: If you mind, you can pull the new changes from master. I added your use case as a test and it seems to work now. Deep copying is now limited to NestedState and NestedTransition which \nwill omit creating deep copies of callback arrays. This should keep object references intact and also allow references to parents in the imported machine. If you stumble upon more issues let me know.. awesome, thanks for the feedback!. Hello @nareshsankapellyfkrt,\nLockedMachine uses standard locks for context management but you can pass custom context managers in case this is required. If you already figured out how to share the object between multiple processes and you just need a shareable context, you can pass a managed lock for instance:\npython\nmanager = multiprocessing.Manager()\nmachine = LockedMachine(..., machine_context=manager.Lock())\nJust make sure the passed context is actually a context and can be passed to processes. Keep in mind that some lock mechanisms are not pickable which renders them not usable in multiprocessing queues for instance.\nSharing complex objects is not that trivial as far as I understand, so you might also consider using a remote manager for this. The example below uses a manager to maintain the Model instance which also contains the state machine. As you see, it does not even require a custom lock as all model operations seem to be executed in the manager's context:\n```python\nfrom multiprocessing import Process, Queue, managers\nfrom transitions.extensions.locking import LockedMachine\nimport time\nexecutor function\ndef worker(model, out_queue, op):\n    while True:\n        try:\n            # call the operation; either 'tick' or 'tock'\n            getattr(model, op)()\n            # after that, put message for printing\n            out_queue.put(op)\n        except Exception as e:\n            out_queue.put(e)\n            time.sleep(3)\nclass Model(object):\ndef __init__(self):\n    self.machine = LockedMachine(model=self, states=states, transitions=transitions,\n                                 initial='tocked')\n\n# it takes a bit longer to process ticks...\ndef on_enter_ticked(self):\n    time.sleep(2)\n\n# ... than to process tocks\ndef on_enter_tocked(self):\n    time.sleep(1)\n\nclass StateManager(managers.BaseManager):\n    pass\nregister our class to be maintained by the manager\nStateManager.register(\"Model\", Model)\nstates = ['ticked', 'tocked']\ntransitions = [['tick', 'tocked', 'ticked'],\n               ['tock', 'ticked', 'tocked']]\nmanager = StateManager()\nstart manager\nmanager.start()\nout_queue = Queue()\ncreate shared model\nmodel = manager.Model()\npass\np1 = Process(target=worker, args=(model, out_queue, 'tick'))\np2 = Process(target=worker, args=(model, out_queue, 'tock'))\np1.start()\nwait for 'tick' to be processed\ntime.sleep(0.2)\np2.start()\nwhile True:\n    while not out_queue.empty():\n        print(\"Response: \", out_queue.get())\n>>> Response:  tick\n>>> Response:  tock\n>>> Response:  tick\n>>> Response:  tock\n...\n```\nYou can try to use Machine instead of  LockedMachine to validate that the access is actually threaded/parallel. When using Machine, you will encounter errors sooner or later because of wrong states.\nI will close this for now since this does not look like an issue to me but like a request for recommendations. Feel free to follow up on this in case you think it is an actual bug or missing feature and I will open the issue again. If you need more advices for your project, consider using stackoverflow instead.. > The docs don't mention that this is where it's stashed, had to dig around a bit.\nIs there a specific advantage to retrieve it from the machine directly? Pulling a context manager from the internals of LockedMachine does not look beneficial to me. The intended use case is to share a context manager with the machine in case you need it:\n```python\nclass XxxxCluster(Machine):\ndef __init__(self):\n    self.env = EnvContext()\n    Machine.__init__(self,\n                     states=states, transitions=transitions,\n                     finalize_event='finalize',\n                     send_event=True,\n                     queued=True,\n                     machine_context=self.env,\n                     initial='idle')\n\ndef finalize(self, event):\n    pass\n    # working with self.env\n\n```\nLockedMachine will not create a custom/own context manager (PickableLock) in case machine_context is not None. It will add itself though.\nEdit: Maybe you should extend your EnvContext with an actual lock since when you pass your custom context manager it is assumed to handle threading (afaik context managers themselves do not prevent parallel execution). You can either a) use your favourite r(lock)/semaphore as a base for EnvContext b) use transitions.extension.locking.PickableLock as a base or add your custom context manager later to make LockedMachine create a context manager which will handle locking.\npython\n        # ...\n        self.env = EnvContext()\n        Machine.__init__(self,\n                         states=states, transitions=transitions,\n                         finalize_event='finalize',\n                         send_event=True,\n                         queued=True,\n                         initial='idle')\n        self.machine_context.append(self.env)\nJust assuming you want LockedMachine to actually synchronise access.. > I'm probably contorting the context support for something it's not intended for\nWell it's definitely a new way of using it. This does not have to be bad at all. Not sure its suitable for sharing resources in several processes though. \n\nie: ensure that all threads had access to the same config/env data.\n\nI am not sure if a context manager is shared between several processes. My guess would be it is not. The managers I was talking about earlier are remote managers provided by multiprocessing.\nFor sharing resources, I'd stick to the general best practises for multiprocessing and Python. This usually involves shared queues and/or (remote) managers.\nNote this is only relevant for multiprocessing not threading in general. In case of threading you can use LockedMachine and access model resources in callbacks (and this access will also be synchronised aka locked). This just start to get more complicated if you need multiple processes to make use of multiple CPU cores.\n\nThat said, is this negating the lock in the LockedMachine? IOW, is my \"data only context\" now being relied upon for synchronization, which it is not doing?\n\nyes, the initial use case was that a user already has a lock for synchronising resource access and wants to reduce the locking overhead by sharing the very same lock with the machine. But context managers can do much more of course.\nBut initial use cases can and should be extended wherever necessary. This being said I think this kind of issues should be stated on Stackoverflow to increase visibility (of the issue and also transitions). If a feature request or a bug emerges while trying to solve a task, feel free to open an issue for it. If you tag your question with transitions and python, a Stackoverflow question will also pop up in our newsfeeds.. Hello @boubakerwa,\nits hard to tell without a working example but you might face this issue because your Machine instance is added as a model as well. If you do not explicitly pass a model during initialisation, this is the expected behaviour. In case you actually do not want that to happen either pass the models to the constructor or pass model=None.\npython\nhue_machine = Machine(model=[light_one, light_two], states=hue_states, transitions=hue_transitions, initial = 'offstate')\nIf that does not solve your issue please provide a minimal working example for us to bugfix.. Sorry @boubakerwa,\nbut I cannot reproduce your observation:\n```python\nfrom transitions import Machine\nfrom mock import MagicMock\nclass Matter(object):\ndef __init__(self):\n    self.mock = MagicMock()\n\ndef on_enter_liquid(self):\n    print(\"Called\")\n    self.mock()\n\nstates = ['solid', 'liquid', 'gas', 'plasma']\ntransitions = [\n    {'trigger': 'melt', 'source': 'solid', 'dest': 'liquid'},\n    {'trigger': 'evaporate', 'source': 'liquid', 'dest': 'gas'},\n    {'trigger': 'sublimate', 'source': 'solid', 'dest': 'gas'},\n    {'trigger': 'ionize', 'source': 'gas', 'dest': 'plasma'}\n]\nlump1 = Matter()\nlump2 = Matter()\nmachine = Machine(model=[lump1, lump2], states=states, transitions=transitions, initial='solid')\nlump1.melt()\nassert lump1.mock.call_count == 1\nassert lump2.mock.called is False\nlump1 = Matter()\nlump2 = Matter()\nmachine = Machine(model=None, states=states, transitions=transitions, initial='solid')\nmachine.add_model(lump1)\nmachine.add_model(lump2)\nlump2.melt()\nassert lump2.mock.call_count == 1\nassert lump1.mock.called is False\n```\nThis works just fine for me. Which version of transitions are you using?. I can confirm that this was a bug in 0.5.3 which was fixed as a side effect of #244.. @walterwang,\n\ncan this be a feature?\n\nthe best way to determine if transitions lacks features to accomplish what you want to do is to ask the community by posting a question on stackoverflow, tagging it with transitions and python and see. If no convenient/acceptable solution can be found with the current features of transitions you can come back and open a feature request and reference the SO post.\nThis way we already have a) a good explanation of the problem, b) the 'best shot' of other developers and c) can determine the relevance for such a feature.\nIn most cases answers of SO users are sufficient though. Please give it a shot.. Hi @Synss,\ngood catch! During remove_transitions, the defaultdict of Event.transitions had been falsely converted into a normal dict. Thanks for the test and the report. I integrated it into the existing test_remove_transition. Should be fixed now.. Change looks good to me. Merged.\nAbout that:\n\nAs a side note, I would prefer that add_states and\nadd_transitions take star-args so that the user does not need\nthe [] (easily forgotten)...\n\nCurrently add_states allows to pass keywords such as on_enter/exit, ignore_invalid_trigger and custom keywords for state extensions. With add_states(self, *states) we lose that ability, don't we?\n. Hello @e-d-n-a,\n\nIt seems pygraphviz isn't yet compatible with Python 3.6!?\n\nThe ubuntu-based travis-built works just fine. I personally test transitions with tox on macOS Sierra and it also works with pygraphviz.\n\nWould you consider adding support for 3.6 by using another graphviz-wrapper like graphviz, which already has support up to 3.6!?\n\ngraphviz does not offer all required features as far as I remember. We alter nodes and attributes of the graph quite a lot and also query the graph at some points to retrieve edges. We do not plan to support another graphviz module in the foreseeable future but we will of course review a pull request in case someone is willing to give it a shot.\n\nMaybe I'm wrong here and there is already a way to make the diagrams-feature work, but I got a compilation error with version 1.3.1 of pygraphviz, that gets installed when using pip like this:\npip install transitions[diagrams]\n\nYou could try to install pygraphviz manually with pip install pygraphviz or find another way. Maybe clone the repo and build pygraphviz from source or -- if you use *nix -- install the pygraphviz (homebrew) package instead of the pip version. \n\nI'm not quite sure, but at the moment it seems NetworkX also does NOT support Python 3 for drawing!?\n\nI just have limited experience with NetworkX but yes, the current stable documentation mentions that drawings are not support for Python 3.0 and above.. I will close this issue since it seems to be a pygraphviz issue we cannot help with. If you consider this to be a transitions issue as well, please give some feedback and I will reopen this issue again.. Hello @benselme,\n\nMachine.get_triggers doesn't check conditions, and so returns triggers that can't actually be called.\n\ncorrect. Machine.get_triggers only evaluates events and checks where the passed state is the source state. This means, it returns theoretically possible transitions but not the transitions possible at the current point in time.\n\nGenerally, there is no mechanism to check upon a transition's conditions before actually trying to apply it.\n\nSo you are looking for a way to 'peek' into these transitions and test whether prepare and conditions callbacks will be executed successfully? If so: yes, there is not way to attempt to execute a transition without actually executing it.\nCould you elaborate on your use case or clarify what you would suggest as a desirable feature?. Hi @benselme,\nEventData is a collection of data relevant for the transition which you can create on the fly as you can see in the following example. PeekMachine is based on your initial idea (thanks for that) and adds a can_trigger method to each model for convenience.\n```python\nfrom transitions import Machine, EventData\nfrom functools import partial\nclass Model(object):\ndef fails(self, condition=False):\n    return False\n\ndef success(self, condition=False):\n    return True\n\n# condition is passed by EventData\ndef depends_on(self, condition=False):\n    return condition\n\ndef is_state_B(self, condition=False):\n    return self.state == 'B'\n\nclass PeekMachine(Machine):\ndef _can_trigger(self, model, *args, **kwargs):\n    # We can omit the first two arguments state and event since they are only needed for \n    # actual state transitions. We do have to pass the machine (self) and the model as well as \n    # args and kwargs meant for the callbacks.\n    e = EventData(None, None, self, model, args, kwargs)\n\n    return [trigger_name for trigger_name in self.get_triggers(model.state)\n            if any(all(c.check(e) for c in t.conditions)\n                   for ts in self.events[trigger_name].transitions.values()\n                   for t in ts)]\n\n# override Machine.add_model to assign 'can_trigger' to the model\ndef add_model(self, model, initial=None):\n    super(PeekMachine, self).add_model(model, initial)\n    setattr(model, 'can_trigger', partial(self._can_trigger, model))\n\nstates = ['A', 'B', 'C', 'D']\ntransitions = [\n    dict(trigger='go_A', source='', dest='A', conditions=['depends_on']),  # only available when condition=True is passed\n    dict(trigger='go_B', source='', dest='B', conditions=['success']),  # always available\n    dict(trigger='go_C', source='', dest='C', conditions=['fails']),  # never available\n    dict(trigger='go_D', source='', dest='D', conditions=['is_state_B']),  # only available in state B\n    dict(trigger='reset', source='D', dest='A', conditions=['success', 'depends_on']), # only available in state D when condition=True is passed\n    dict(trigger='forwards', source='A', dest='D', conditions=['success', 'fails']),  # never available\n]\nmodel = Model()\nmachine = PeekMachine(model, states=states, transitions=transitions, initial='A', auto_transitions=False)\nassert model.can_trigger() == ['go_B']\nassert model.can_trigger(condition=True) == ['go_A', 'go_B']\nmodel.go_B(condition=True)\nassert model.can_trigger() == ['go_B', 'go_D']\nmodel.go_D()\nassert model.can_trigger() == ['go_B']\nassert model.can_trigger(condition=True) == ['go_A', 'go_B', 'reset']\n```. Currently this does not seem an urgent feature request but should definitely be documented in case other users may stumble upon the same issue. The presented solution will be documented in the example section.. thanks!. Hello @fedpet,\nthis is a reoccurring  problem of pygraphviz under Windows. It has been reported before (#133), asked before at SO and also reported to pygraphviz (pygraphviz/pygraphviz#88) and networkx (networkx/networkx#2012). Since the issue has been closed in the pygraphviz tracker, I assume that it might be fixed in pygraphviz version 1.4rc1.  In a pull request (#217) a user mentions a workaround for that issue.\nLong story short: afaik we cannot do much about it since it seems to be related to pygraphviz and Windows, not transitions.. > btw if the problem is pygraphviz then what version are you officially using?\nIt shouldn't matter (we have used a couple of versions) as the issue is exclusive to Windows. Our test servers run Ubuntu 14.04  and I work with OSX Sierra (both use pygraphviz 1.3.1 currently). I have also used transitions on Ubuntu 16.04. Never had this issue. This code:\n```python\nfrom transitions.extensions import GraphMachine\nstates = ['first', 'second']\ntransitions = [\n    ['any_trigger', 'first', 'first'],\n    ['anything', '*', 'second'],\n]\nmachine = GraphMachine(states=states, transitions=transitions, initial='first',\n                       auto_transitions=False, show_conditions=True)\nmachine.get_graph().draw('fsm.png', prog='dot')\n```\nproduces this result:\n\nI assume this would not work in your environment.\n\npygraphviz and it should be version 1.5.dev same error.. tried with version 1.4rc1.. same error\n\nBummer, it seems like they closed the issue without actually fixing it then. Thanks for giving it a try.. I am trying to set up a Windows CI test job but installing pygraphviz does not play very nice.\n@fedpet: How did you install pygraphviz? Unfortunately, using pip after installing Graphviz finishes but I end up with DLL import errors (event though PATH is set correctly). The only way I got it to work was by using the unofficial binary builds that are suggested occasionally but this does not look like a way suitable for an automatic build process.. Nevermind, PATH has not been set correctly. Our tests fail on Windows as you can see here. I also added some try/catch phrases in the dev-appveyor branch to get some error messages. As mentioned in the above referenced issues/posts this error occurs only when source and destination of an edge are the same. I tried to omit extra attributes like labels but this does not work as well.\nI do not see what we could do differently given the fact that we have no platform specific code and tests do succeed on Linux and OSX. If you have any suggestions about how to approach this issue I am all ears. . Hi @fedpet,\nI added a minimal test to dev-appveyor:\n```python\nimport pygraphviz as pgv\nfrom unittest import TestCase\nclass TestGraphviz(TestCase):\ndef test_self_reference(self):\n    G = pgv.AGraph()\n    G.add_node('a')\n    G.add_edge('a', 'a')\n    print(G)\n\n```\nStatus *nix: works\nStatus Windows: fails with Graphviz 2.38.0.1, pygraphviz 1.3.1. Hello @lromor,\nunfortunately making transitions run async callbacks requires some major refactoring. Otherwise the async version would more or less copy big chunks of code from the core machine which is a lot harder to maintain.\nHowever, we planned to do this for a while. To check if we are on the right track I got some questions for you:\n\nWhat do you need to call asynchronously? The callbacks in prepare,conditions,before,after or the transitions themselves?\nWho is going to manage the event loop? If most code runs synchronously and only async callbacks have to be synchronised somehow, Machine could handle the event loop.. Hello @lromor,\n\nthank you for the detailed explanation.\n\nI think that the async loop should be managed externally. \n\nI assume this is a requirement for most use cases. In case this is not required one 'quick fix' things by 'synchronising' async calls with the help of run_until_complete for each callback indivually. This could be implemented easily and should work for case in which the only problem is an async API but the actual concept does not require async processing. I still consider that 'cheating' and also probably bad design for the majority of use cases.\n\nBefore/on_enter after/on_exit is in my opinion the way to go.\n\nOkay thanks. Feedback shows that it is okay to do the event processing itself synchronously. It is usually about the callbacks which makes sense.\n\nactions should be mapped as states\n\nWhile it is true that transitions callback structure is designed around transitions it does not prevent designing FSMs around states as actions. Just make sure to use queued=True if you initialise machines and plan to have trigger calls within on_enter callbacks. This way every callback is processed sequentially. You just have to consider that a callback should return when an event has been triggered. \nIt's funny that your example image actually refers to opening and closing procedures since this is what we use transitions for. transitions controls a mechanical prototype (a smart door) by sending and receiving PubSub events. We use RSB and a rsb extension for transition. I can really recommend this message based approach since it makes the resulting architecture very flexible and follows the guide line to not let the state machine do the heavy processing but just maintain system states.. Hello @lromor, \nthere hasn't been any progress on that front so far. The major issue is to find a solution which does not end up to be a re-implementation of major parts of transitions's core classes. @ivanteresh went ahead and implemented an async machine which you can find here. From a brief look I would say this is pretty close to what you can get inheritance-wise with the current core architecture. I have not tested it though but It's definitely worth having a look at.. Hello @idf,\ncould you clarify which part of code you are referring to?\nAbout await syntax: As we strive for Python 2 and 3 compatibility, some newer syntax features cannot be used. However, in case asynchronous callback is integrated it should not make any difference for users of transitions.. Hello @mrtvon,\n\nThe second part of the problem seems to be the decorating of the model in Machine.add_model\n\nI guess this is where most of your garbage collection issues arise. Models keep references to machines through the added convenience functions. This is indeed intended by design. Currently, transitions contains no feature to remove these functions again. One of the reasons is that it would take some introspection to determine if a function has been added by a machine or not (e.g. a model will not be extended with a trigger method if it already contains a method called like this)\n\nOK so it seems one part of the problem is the hard reference to \"machine\" in Event, looks like this can be quite easily solved with weakref.\n\nThis seems to be a symptom of the previously mentioned issue. A machine has a list of events but also assigns the even triggers to model attributes.\nIf this coupling is not desired you can skip adding models to machine and call Event.trigger directly:\n```python\nimport gc\nfrom transitions import Machine\nclass Model(object):\n    def init(self, state):\n        self.state = state\ndef enter_state(self):\n    print(\"State entered!\")\n\ndef create():\n    machine = Machine(model=None, states=['A', 'B'], initial='A', after_state_change='enter_state')\n    model = Model(machine.initial)\n    print(gc.get_referents(model))  # [{'state': 'A'}, ]\n    machine.events['to_B'].trigger(model=model)  # State entered!\n    print(model.state)  # B\ncreate()\n``\nYou just have to make sure that your model contains astate` string attribute and to always call trigger with the appropriate model. You see that even though the machine was initialised without a model, it will call the callback of the passed model since callback strings are resolved during event processing.\nIf you are willing to override __getattribute__ you can achieve the almost the same behaviour/convenience like adding models to machine instances:\n```python\nclass Model(object):\ndef __getattribute__(self, item):\n    try:\n        return super(Model, self).__getattribute__(item)\n    except AttributeError:\n        if item in self.machine.events:\n            return partial(self.machine.events[item].trigger, self)\n        raise\n\nmodel.to_B()\n```. > though for my solution I do need to apply the override.\nThis shouldn't be an issue. If it is, feel free to report back. Closing this for now.. Hello @nakiya,\nif you want to use constants to name states you can use the feature mentioned in the documentation here:\n\nAdditionally, there is a method called trigger now attached to your model. This method lets you execute transitions by name in case dynamic triggering is required.\n\npython\nmodel.trigger(TRANSITIONNAME_CREATE_REPORT, *args, **kwargs)\nThis is more or less equivalent to calling\npython\ngetattr(model, TRANSITIONNAME_CREATE_REPORT)(*args, **kwargs)\nYou might want to reconsider your naming for on_enter/exit callbacks as well since on_enter_initial might become confusing in case you change STATENAME_INITIAL. Of course you could also just use STATENAME_INITIAL there as well:\n```python\nState(STATENAME_INITIAL,\n      on_enter='on_enter_{0}'.format(STATENAME_INITIAL),\n      on_exit='on_exit_{0}'.format(STATENAME_INITIAL)),\n...\n```\nThis does not solve the issue for the definition of those functions though. Refactoring these names to what should be done rather then when might do the trick.. I close this due to inactivity. If you still think there is an issue with transitions which should be resolved. Feel free to comment and I will reopen the issue if necessary.. Hi @tkuester,\nsorry for the late reply. I did some brief investigation about how bad it would be to kill Timer threads just like that. My attempt of garbage collecting running threads did not work out though since the Timer threads actually prevent garbage collection. As the previous mentioned threads to not handle critical resources I assume its save to interrupt them.\nThank you for your contribution!. Structure for output in JSON/YAML\n```yaml\nstates: [{name: A}, {name: B}, {name: C, children: [...]}\ntransitions:\n    - trigger: go\n      source: A\n      dest: B\n      before: ['before_func_name'] # optional\n      after: ['after_func_name'] # optional\n      conditions: ['conditions_func_name'] # optional\n      unless: ['unless_func_name'] # optional\n- more transitions\nname: StateMachine #optional\ninitial: A #optional\nbefore_state_change: [] # optional\nafter_state_change: [] # optional\nprepare_event: [] # optional \nfinalize_event: [] # optional\nsend_event: False # optional\nauto_transitions: True # optional\nignore_invalid_triggers: True # optional\nqueued: False # optional\nmodel: [] # optional;  the tricky part \n```\nEverything except callback references and the list of models should be pretty much straight forward.\nAbout models:\n```yaml\nVariant A; just send model state and the class name and load the class locally\nmodels:\n    - state: B # optional; will use the machines initial state when omitted\n    - class-name: package.module.Model # could be 'self' in case the created machine should be used\nVarian B; send the pickled class definition\nmodels:\n    - state: B # optional; will use the machines initial state when omitted\n    - class-pkl: # serialised class definition here\n # - class-src: # class definition source code\nVariant C; pickle model and send it\nmodels:\n    - model-pkl: # serialised model\n```\nCallback references (of functions; not object methods) could be resolved in before, after and such and replaced by strings.\nThe actual callbacks are added like this:\nyaml\ncallbacks:\n    a_callback_name: #source or pickled code here\n    another_callback: # ...\nVariant B could alternatively include readable source code (with the help of introspect) which is parsed by the receiver like its done in David Kuhlmann's examples.\nI'd suggest starting with variant A and also limit exchangeable machines to use strings (functions defined in the model class) as callbacks. Loading/parsing source code from json/yaml sounds like a security risk. But maybe thats just me.. Merged into next-release branch. Hello @bengartner,\npull requests are always appreciated and we are grateful for every community member who strives for improving transitions. Whether a pull request is accepted depends on several factors. For instance:\n\nrequired change of the current codebase\nimpact on usage complexity\nimpact on maintainability of transitions\nimpact on default behaviour\ncommunity feedback\n\nI cannot really tell you if a PR is accepted before reviewing it and/or getting feedback of other users. Let's keep this issue open and see what others think about this feature.. Hello @bengartner,\nare there any updates for this issue? Did you manage to rework graphs to get closer to UML standards?. closing due to lack of feedback. If this issue becomes valid again, comment and I will reopen it.. > this warning is a bit annoying, what is its purpose for the enduser\ntransitions adds some convenience functions to your model such as is_<state_name> or to_<state_name>. HierarchicalMachine also adds a to function to your model which you can use to transit to (nested) states directly (e.g. model.to('stateA.substateA1.subsubstateA1a')).\nIn case your model already has a function/property called to, this warning is emitted and the current to-attribute is kept.\nSo if you have not added a model function called to, I assume you are using the HierarchicalMachine instance as a model. HierarchicalMachine has a function called to.\n\nwhat the enduser can do to remove it?\n\n\nuse a dedicated model instead of HierarchicalMachine (in case you are using it that way currently)\nRename your model function to (in case you already use a dedicated model)\npython\n    import logging\n    logging.basicConfig(level=logging.DEBUG)\n    logging.getLogger('transitions.extensions.nested').setLevel(level=logging.ERROR)\n3 will also silence warnings about invalid triggers in nested states though.\n\nIt might be a good idea to rename HierarchicalMachine.to to HierarchicalMachine.to_state to get rid of this naming collision.\nAfter all, default values should not cause warnings.. Update: I will rename HierarchicalMachine.to since the current version ~does not work as intended and has also not been tested before~ is probably not widely used since the documentation of this function contains errors. The tests also do not contain a direct usage of HierarchicalMachine.to but only via the assigned model function. I might add some compatibility checks though.\nNevertheless, this means the warning should be gone with the next release/with the next commit to master.. Thank you (again) for your contribution @Synss \ud83d\udc4d . Hello @janekbaraniewski,\nfirst: great bug report!\nAfter reviewing Machine.add_ordered_transitions I agree that this code could be simplified without losing functionality. I am not 100% sure but it feels like the change of the states' order is actually unintentional.  At least there is no test that relies on that change of order. \nI fixed that issue and also added a test that verifies that add_ordered_transitions and initial do not mess with the states order. Thanks a lot for pointing that out!. Will do when #266 is resolved.. Hello @janekbaraniewski,\nI just pushed 0.6.3 to PyPI.. Hello @parthsharma1996,\neven though there is no direct way of declaring a transition based on a function result, it can be achieved with a list of transitions with the same trigger and varying conditions:\npython\ntransitions = [{'trigger': 'call', 'source': 'A', 'dest': 'B', 'prepare':'func', 'conditions': 'result_is_1'},\n               {'trigger': 'call', 'source': 'A', 'dest': 'C', 'conditions': 'result_is_2'},\n               {'trigger': 'call', 'source': 'A', 'dest': 'D'}]\nprepare is called once before the transitions are evaluated. We can omit the last condition check in case func is guaranteed to return 1, 2 or 3.\nIf I understand correctly, you are aware of this.\nI agree that if your design contains a lot of these conditional transitions, defining those transitions manually probably clutters your configuration.\nA way to specify such a transition could look like this:\npython\ntransition =  dict(trigger='shuffle', source='A', dest=({1: 'B', 2: 'C', 3: 'D'}), depends_on='func')\nYou could then override Machine.add_transitions to implement a 'wrapper':\n```python\nfrom transitions import Machine\nfrom transitions.core import listify\nclass ExtendedMachine(Machine):\ndef add_transition(self, trigger, source, dest, conditions=None,\n                   unless=None, before=None, after=None, prepare=None, **kwargs):\n\n    if isinstance(dest, dict):\n        prepare = listify(prepare)\n        conditions = listify(conditions)\n        for idx, k in enumerate(dest):\n            # add depends_on as a preparation call for the first transition\n            prep = [kwargs.pop('depends_on')] + prepare if idx == 0 else prepare\n            # add result check as the first condition for a transition\n            self.add_transition(trigger, source, dest[k], [lambda: self._result == k] + conditions,\n                                unless, before, after, prep, **kwargs)\n    else:\n        super(ExtendedMachine, self).add_transition(trigger, source, dest, conditions,\n                                                     unless, before, after, prepare, **kwargs)\n\n```\nOr you can subclass Transition itself to make its dest property return a different value based on depends_on result:\n```python\nfrom transitions import Machine, Transition\nfrom six import string_types\nclass DependingTransition(Transition):\ndef __init__(self, source, dest, conditions=None, unless=None, before=None,\n             after=None, prepare=None, **kwargs):\n\n    self._result = self._dest = None\n    super(DependingTransition, self).__init__(source, dest, conditions, unless, before, after, prepare)\n    if isinstance(dest, dict):\n        try:\n            self._func = kwargs.pop('depends_on')\n        except KeyError:\n            raise AttributeError(\"A multi-destination transition requires a 'depends_on'\")\n    else:\n        # use base version in case transition does not need special handling\n        self.execute = super(DependingTransition, self).execute\n\ndef execute(self, event_data):\n    func = getattr(event_data.model, self._func) if isinstance(self._func, string_types) \\\n           else self._func\n    self._result = func()\n    super(DependingTransition, self).execute(event_data)\n\n@property\ndef dest(self):\n    return self._dest[self._result] if self._result is not None else self._dest\n\n@dest.setter\ndef dest(self, value):\n    self._dest = value\n\nsubclass Machine to use DependingTransition instead of standard Transition\nclass DependingMachine(Machine):\n    transition_cls = DependingTransition\n```\nBoth approaches should be considered as drafts. The second version might keep your transition count a bit lower but will probably cause incomplete dot representations of the state machine. The first version does not consider the case of a not set depends_on keyword. Additionally, the first version requires some way of how the return value of func is stored into self._result or probably better self.__result to prevent accidental overrides.\n\nCan this be added as a feature?\n\nThis depends on the feedback of the user base. I see a value in this addition. The integration will very likely increase the complexity of the core code though which we like to avoid. \nFeel free to add you ideas/suggestions . > the FAQ notebook looks it's already the right place for that--except maybe we should make it a folder\nsounds good. Notebooks are also indexed and therefore searchable.. This sounds like something very suited for Stackoverflow. I quote myself from the past:\n\nThis has several advantages:\n\nYour question gains higher visibility since most developers look for help there\nThe targeted community is larger; Some people will even help you to formulate a good question\nPeople get 'rewarded' with 'reputation' to help you. You also gain reputation in case this questions pops up more frequently. It's a win-win situation.. I posted a recommendation including a link to a blog post where serialisation and JSON injection is presented. This should be also applicable for YAML. The above mentioned condition based transition feature will not be integrated into transitions (yet). However, the above mentioned approach(es) will be documented in the example section.. Hello @qkmaosjtu,\n\n\nModel is your model object which is enhanced by transitions and changes state whenever an operation is conducted. In the ReadMe the NarcolepticSuperhero is a model or Matter. The most simple possible model is:\npython\nclass Model:\n    pass. closed due to inactivity. Feel free to comment in case you think this issue hasnt been solved. I will reopen the issue if required.. Hello @avneesh91,\nthis might be what you are looking for: https://github.com/pytransitions/transitions#reuse-of-previously-created-hsms. Hello @xuqinghan,\ncould you provide a specific code sample where it does not work as expected?. closing this due to inactivity. Feel free to comment and/or add an affected code sample. I will reopen the issue if necessary.. Hello @xuqinghan,\nthank you for that very precise test case. \nConsidering your issue 1:\nThe machine value for ignore_invalid_triggers is only considered during the creation of new states. This means only states created from strings and/or dict will inherit that value.\nYou could say that creating a State yourself overrides the global value.\nYou need to either define your solid state as State(name='solid', ignore...=True) or just pass 'solid' as a string in the states array to let Machine create a new State from scratch with the default value of ignore_invalid_triggers.\nAllowing custom states to override the machine configuration eases the definition of critical states where an invalid transition should not be ignored:\n```python\nstates = ['A', 'B', 'C', State('Critical')] \nonly in state 'critical' invalid triggers raise exceptions\nMachine(states=states, ignore_invalid_triggers=True)\n```\nThis is indeed not documented. Sorry for that. \nTo make your use cases work we could either a) always consider ignore_invalid_triggers of the current state and the machine (state.ignore or machine.ignore) or b) override the state's value during addition. a) unfortunately removes the ability to override the behaviour in case you do NOT want to ignore triggers for certain states and b) might interfere with other use cases where State objects are used in multiple machines.\nCurrently, I would tend to keep the behaviour as it is since imho it adds more flexibility than inconveniences for users that like to define their states themselves. This is of course open for discussion.\nConsidering your second issue:\ntransitions provides triggers by assigning methods to the model which are names according to the provided transitions. You see the attribute error because your model does not have a method/attribute named evaporate when it hasnt been added by Machine. Dealing with unknown attributes would require that Machine overrides the models getattr(ibute) method which is -- again just imho -- way too intrusive and may have undesirable side effects.\nPython offers ways to work with uncertain object attributes though. You might want to have a look at Stackoverflow 'How can I return a default value for an attribute'.\n. Hi @illes,\nthank you for the report. I guess we have to rework the testing of the related methods if it could not track this bug. . Hi @hrsmanian,\nparent expects a State object. foo.add_states(['4'], parent=foo.get_state('2')) works.\nOr as a working example:\n```python\nfrom transitions.extensions.nesting import HierarchicalMachine as HMachine\nfrom transitions.extensions.nesting import NestedState\nclass Foo(HMachine):\n    def init(self):\n    self.states = [NestedState(name='1'), {'name': '2'},\n                   NestedState('3')]\n\n    HMachine.__init__(self, states=self.states, initial='1')\n\nfoo = Foo()\nfoo.add_transition('process', '*', '2')\nfoo.process()\nfoo.add_states(['4'], parent=foo.get_state(\"2\"))\nfoo.add_transition('into', '2', '2_4')\nfoo.into()\nassert foo.is_2(allow_substates=True)\n``. Thought a bit about it and I thingfoo.add_states('4', parent='2')is a fair guess and should be natively supported as it fits the general style oftransitionsAPI. Your code should work now with the currentmaster.. States are stored in anOrderedDict.del machine.states[]` is all you need to do.. Hello @jlandercy,\nthanks for sharing that. This looks indeed like the better solutions for notebooks. I will adapt our example notebooks accordingly. . added to example notebooks. Hello @carl-lindquist,\nI would say there is more than one way to achieve this. For instance have a look at this. I answered a related question where repeated triggering of a function is achieved by re-entering or via strategies.. Hello @hrsmanian,\nthank you for the bug report and brining this issue to our attention. During a reflexive transition the state should indeed be exited. The only case where this should not happen is when the target state is nested into the source state.. Hello @jacins,\nthis sounds like a question about how to use transitions and does not refer to a bug or a feature request. Have you tried to receive some input from Stackoverflow?\nPosting there has several advantages:\n\nYour question gains higher visibility since most developers look for help there\nThe targeted community is larger; Some people will even help you to formulate a good question\nPeople get 'rewarded' with 'reputation' to help you. You also gain reputation in case this questions pops up more frequently. It's a win-win situation.. Closing due to inactivity. Comment if you think there is something to be done from our side and I will re-open the issue.. Hi @nicain,\n\n\nhave you considered moving over to pipenv?\n\nnot yet but providing a Pipfile could be done if it eases the installation process.\n\nOptional dependencies are defined as in pypa/pipenv#1013\n\nThis just refers to flags of required packages but does not replace the project's own extras_require as far as I can tell.\nFor your personal project an entry like transitions= { extras = ['diagrams'] } in [packages] should do the trick.\nTo install optional dependencies for the project containing the Pipfile you have to do things like pipenv install -e .[diagrams] which just uses the setup.py (probably by calling pip with that option) to retrieve extra information.\nI have not found another way to define optional dependencies in the Pipfile which can be used by pipenv directly. If you stumble upon such feature, let me know.\n. Hello @pwa16000,\nyou can use a list of lists but I would highly discourage you from doing that since you need to keep track of the exact order of arguments passed to add_transition.\n\nIs there anything wrong with the re-write transitions list-of-lists table? \n\nThe order is trigger, source, dest, conditions=None, unless=None, before=None, after=None, prepare=None, **kwargs and list entries will be mapped in that order which means your 4th entry is actually mapped to conditions.  Conditions will be executed (thats why you see the hiss) but when the function does not return a 'truely' value, the transition will be halted.\nFor you code to work you need to pass `['melt', 'solid', 'liquid', None, None, 'make_hissing_noises'] which is not as comprehensible as the dictionary way.\n. Thank you @MSumulong . Hello @xavigisbeg,\ntimeouts are initialised when a state is entered. However, an initial state is actually not entered but just set. Figuratively speaking, the model 'spawns' in this state. This -- the spawning part -- is intended behaviour and required for situations where machines are (re)initiated occasionally.\nThe Readme also mentions that:\n\nNote that on_enter_\u00abstate name\u00bb callback will not fire when a Machine is first initialized. For example if you have an on_enter_A() callback defined, and initialize the Machine with initial='A', on_enter_A() will not be fired until the next time you enter state A.\n\nYour solution of having a preparation or init state before your actual first state is the most common approach for triggering enter callbacks for the intended first state. You could also have a reflexive transition for your first state to minimize the logic overhead:\npython\nm = Machine(states=['A'], transitions=[['init', 'A', 'A']], initial='A')\nm.init()\nSince no state callback is triggered during the 'spawn process' there is no way I can think of which deals with this case elegantly.  If you come up with a generic solution, let me know. For now, I will close this issue.. Hello @dotlambda,\nyou are right. The workaround to cope with dill 2.7 and higher has been introduced in 0.6.0 according to the Changelog. The restriction is not required any longer. Python 3.3 had been problematic but should also work fine with dill 2.7.1 now. Will be removed shortly and thanks for the notice. . Hi @mrjogo,\nsounds good to me. I assume your use case is more likely than halting in the 'meta' state of a passed HSM. Users who do not want to use the initial state of the passed HSM now have to explicitly mention that by passing initial: False now. Let's see if there is some feedback about this change before the next release.. Hello again @mrjogo,\ncurrently callbacks of conditions and unless are handled identically with the exception that conditions are checked for 'true' values and unless are checked for 'false' values. \nSo 'conditions': ['A', 'B'], 'unless': ['C', 'D'] becomes A and B and not C and not D. There is neither an or operator yet nor a way to define relations between conditions.\nSince not C and not D is equal to not (C or D) you could patch Conditions to accept lists in the following way:\n```python\nclass ConditionList(transitions.core.Condition):\ndef __init__(self, func, target=True):\n    super(ConditionList, self).__init__(func, target)\n    self.func = transitions.core.listify(self.func)\n\ndef check(self, event_data):\n    op = any if self.target else all\n    predicates = [getattr(event_data.model, f) if isinstance(f, string_types) else f for f in self.func]\n    if event_data.machine.send_event:\n        return op(p(event_data) for p in predicates) == self.target\n    return op(p(*event_data.args, **event_data.kwargs) for p in predicates) == self.target\n\ntransitions.core.Condition = ConditionList\nclass Model(object):\ndef is_flamable(self, props):\n    return 'flamable' in props\n\ndef is_hot(self, props):\n    return 'hot' in props\n\nmodel = Model()\nm = Machine(model, states=['A', 'B'], initial='A')\nm.add_transition('foo', 'A', 'B', unless=[['is_flamable', 'is_hot']])\nmodel.foo(props=['flamable', 'hot'])\nprint model.state  # >>> A\nmodel.foo(props=['flamable'])\nprint model.state  # >>> B\n```\nThis way 'conditions': ['A', ['B', 'C']] becomes A and (B or C) and 'unless': ['A', ['B', 'C']] becomes not A and not (B and C) = not A and (not B or not C). \nIf this will be integrated into core depends on the community feedback (what's your oppinion @tyarkoni?). Closing this due to inactivity. Feel free to comment anyways. I will reopen the issue if necessary.. Hi @ollamh, \nsorry for the lack of feedback. First of, I think having the ability to address callables by their module path is a valuable addition to transitions. I use a comparable approach myself and agree that this adds flexibility. The reason why I am hesitating is because of the way the different callable cases are processed. The proposed 'standard' case of using the names of model functions will require catching exceptions (ImportError) every time a callback is executed. Before I merge this I want to evaluate the performance impact this has and might also try to do something about it. I can't give you a reliable estimate about when this will happen but its definitely on my list. . Hi @ollamh, no updates so far, sorry. Thanks for the reminder. It should be done mid/end next week.. Hi @ollamh and @paulbovbel,\n\nthought I'd offer an unsolicited outside perspective\n\nthanks for that! I always appreciate having productive feedback such as yours!\nI agree that having the function to resolve callbacks decoupled from the processing context increases the flexibility of the library.\nI refactored this pull request as seen in the branch pr-289.\n@ollamh: Please have a look if this still fulfils your needs.\nI decide to use Machine.resolve_callback(func, event_data) for this since it eases the customisation for library users. This may help to keep state and transition definition as readable as possible.\nI also decided to skip the callable test. In the past we have only checked for string_types and assumed the passed func to be callable otherwise.\nAdditionally, I moved the model attribute check to be conducted before the import approach since I think it is currently way more common.\nA small test with a model using two attributes and one import function shows a significant performance benefit when less exceptions have to be caught.\nThe overall footprint of resolving callbacks is relatively small though.\nLooking forward to your thoughts. Hello @njbuch, \nI am not aware of any issues related to the timeout feature. Could you please provide a) a minimal code example to show your problem and b) tell me which version of transitions you are using.. This code does not work. You define CustomStateMachine to be a subclass of Machine but later you initialise your machine with machine2 = GraphMachine(model=controller, ....\nGraphMachine uses State which does not know about the timeout feature.\nFirst, you should make CustomStateMachine a subclass of GraphMachine to inherit the diagram features and second you should also use this class for object initialisation. \nAdditionally, using the same model (controller) for two state machines is not supported. \nThe second machine will override the methods attached to the model by the first machine or raise an error if this method already exists. From the example code I cannot tell what the benefit of this approach may be but if there is a certain use case for this, I am all ears.\nThe working code looks like this:\n```python\nfrom transitions.extensions import GraphMachine\nfrom transitions.extensions.states import add_state_features, Timeout\n@add_state_features(Timeout)\nclass CustomStateMachine(GraphMachine):\n    pass\nclass RPI_Controller(object):\n    def init(self):\n        self.entourage = 0\n        self.received_data = 0\nstates = [{'name': 'sleep', 'timeout': 2, 'on_timeout': 'timeout2'},\n          {'name': 'state4'}]\ntransitions = [['pin_high', 'sleep', 'state4'],\n               ['timeout2', 'state4', 'sleep']]\ncontroller = RPI_Controller()\nmachine = CustomStateMachine(model=controller,\n                             states=states,\n                             transitions=transitions,\n                             auto_transitions=False,\n                             initial='sleep',\n                             title=\"Mood Matrix\",\n                             show_conditions=True)\ncontroller.get_graph().draw('my_state_diagram2.png', prog='dot')\n```\nand produces this output\n\nwhich is what I would expect. Is there an issue I have overlooked?. Hello @ansumanm,\nwhich Python version and which version of transitions are you using? I tested the code snippet below with Python 3.4 - 3.6 and it works fine.\n```python\nfrom transitions.extensions.diagrams import GraphMachine as Machine\nimport pickle\nm = Machine(states=['A', 'B', 'C'])\npickle.dumps(m)\n```\nNote that the documentation mentions here that Python 2.7 requires dill.\n. Could you provide a minimal example where this error occurs? Right now, I can just guess whats going wrong. Did you override __getstate__ and __setstate__ or implement other pickle specific behaviour? When pickling GraphMachine, it is necessary to omit the graph property because the pygraphviz.AGraph object is not pickable. Usually this is taken care of by GraphMachine.__getstate__.. Hello @ansumanm,\nnow I see the problem: The machine of your Test class will add the AGraph to the model (self) which makes the Test instance unpicklable. Currently, we work around this issue by not pickling the graph when it has been added to the machine itself. This is usually the case when the machine also acts as the model. For other cases (machine != model) there is not much GraphMachine can do about it since it cannot (or should not) override models' pickling behaviour or tinker with attributes.\nSo, with the current state of transitions, you have at least 3 ways to deal with it: \n\nDelete Test.graph before the pickling attempt \nCopy GraphMachine.__getstate__ and GraphMachine.__setstate__ and add it to your Model (Test) to prevent Test.graph from being pickled\nLet Test inherit from GraphMachine instead of membership\n\nThe first approach (1) is probably the most suitable solution for your use case. If you run pickle right before the object is deleted anyway, you can also go ahead and remove graph before pickling. \nImplement your own setstate/getstate (2) is probably the most flexible solution but also adds some code complexity. I mentioned (3) for completeness but I do prefer a clear distinction between model and machine like you do it currently. \nExample for (1):\n```\nimport pickle\nfrom transitions.extensions import GraphMachine as Machine\nclass Test:\ndef __init__(self):\n    self.machine = Machine(model=self)\n\ndef __del__(self):\n    with open('transition.pickle', 'wb') as f:\n        del self.graph  # this has been added by self.machine\n        pickle.dump(self, f)\n\ndef main():\n    t = Test()\nif name == 'main':\n    main()\n```\nThat being said, we might reconsider adding the AGraph to the model objects. This is certainly an inconvenience for library users.. Hmmkay.. unfortunately unpickling seems to have some issues. I will investigate that during the course of tomorrow.. The unpickling issue seems to be related to some properties of Machine.events not being available in __setstate__. Interestingly, the observed errors varies depending on the used Python 3 version (tested 3.4.8, 3.5.5 and 3.6.4). I assume its the level of recursive references and partials that makes serialisation tough for pickle here. Because of the fact it works 'sometimes' with Python 3.4 and 3.5 I filed a bug report. . A workaround is in progress but testing now fails because of unit test related pickling issues see this issue. This could also be worked around but solving this is the preferable solution.. This should be solved now. This test should make sure that it does work in the future. The current solution is to initialize the graph 'lazily' which means it wont be initialized in __setstate__ but the first time it is actually used. The dill issue is not that relevant but I will track the development of the previous mentioned pickle issue just to see whether this something that can be solved.\nIf this does not solve your issue feel free to comment and I will reopen the issue if there is more to do. transitions 0.6.5 will be released when travis builds get on their feet again. I assume PyPi faces issues due to their current warehouse launch.. Hello @Shaun-Griffith-Hive,\nthe method get_graph is attached to the model by Machine. get_machine is a partial of Machine._get_graph(self, model, ...) with an already resolved model parameter. This way you can have multiple models and every model's get_graph will return the diagram and current state of the respective model. In other words, there is no need to reference the Machine instance directly.. Hi @tedmiston,\nI'd like to resolve #289 first. This should be done mid end next week.. Starting from 0.6.7 this should be fixed on PyPI.\nThe process had been taken from here and can be summarised as:\nbash\npyenv shell 3.6.4 \nrm -r */dist\npip install -U setuptools twine wheel\npython setup.py sdist bdist_wheel --universal\ntwine upload dist/*\nI had to use Python 3 explicitly with twine since Python 2.7 did not work (as seen in 0.6.6).. Hi @Shaun-Griffith-Hive,\nthe graph looks correct despite the warning. The warning however is the result of an issue where arrow heads are not configured right when the source is a child of the destination. This should be fixed now. #295 should also work now.. Hi @chace20,\nwhat should be the goal of transition_2. Should your model end up in 2 states at the same time?. I see. Unfortunately transitions does not support concurrency (yet). Models are supposed to have ONE specific state. However, since transitions support multiple models it is possible to have models with different states in the same machine. One way to realize this is to let the model do the spawning of submodels as seen below:\n```python\nfrom transitions import Machine\nclass Model(object):\ndef __init__(self):\n    self.submodels = {}\n\ndef on_enter_B(self, event_data):\n    self.submodels['B'] = Model()\n    event_data.machine.add_model(self.submodels['B'], initial='C')\n\ndef on_exit_B(self, event_data):\n    try:\n        event_data.machine.remove_model(self.submodels['B'])\n    except ValueError:\n        pass\n    finally:\n        del self.submodels['B']\n\ndef on_exit_C(self, event_data):\n    event_data.machine.remove_model(self)\n\n@property\ndef current_state(self):\n    return [model.state for model in self.submodels.values()] + [self.state]\n\nmodel = Model()\nm = Machine(model, states=['A', 'B', 'C', 'done'], transitions=[['jump', 'A', 'B'], ['leave', 'B', 'A'], ['finish', 'C', 'done']],\n            initial='A', send_event=True, ignore_invalid_triggers=True)\nmodel.jump()\nprint model.current_state\nfor mod in m.models:\n    getattr(mod, 'finish')()\nprint model.current_state\nmodel.leave()\nprint model.current_state\n```\nIf you have any suggestions about how this process can be streamlined, let me know.\nEdit: Updated example since dispatch (now replaced with a for-loop) is not a part of Machine yet. But I guess for cases like this it might be handy.\n. Since the above mentioned 'workaround' does not satisfy proper concurrency, I add 'concurrent states' as a feature for 0.7.0. This requires some significant changes in the nested states extension but I assume this tradeoff should be worth it since there is a lack of (Python) state machine libraries that support concurrency.. Hi @jrbrodie77,\nI agree with @asyncee that you should divide the responsibilities if the problem is reasonably complex. The machine should only trigger the necessary actions and react to events. Using a PubSub or RPC middleware for event distribution such as MQTT (like @lostcontrol) to decouple the actual acquisition from the machine itself sounds like the way to go. No polling or while loop required on the machine's side.\nI'll close this issue since it does not contain a feature request or a bug report. Feel free to continue the discussion. I will reopen the issue if necessary.. Hello @maueki,\nthanks for the input. The library already supports reflexive transitions (exit and enter the same state). Could you give an example where this behaviour is not sufficient but actually no transition at all should happen? . Hi @Synss,\nthanks for the fix!. Hello @jodal, thank you for that fix. I will create a new release asap.. The release 0.6.8 has been published. I tested the installation from source with pip and it seems to work now. Thanks again for the report.. Hello @ideabrdg,\nit seems like messages will only be sent after @socket.on returns. If you replace client_state.build() with time.sleep(5) you can also observe a delayed message emission.\nTesting with \npython\n@socketio.on('query_event')\ndef query(json):\n    socketio.emit('results', {'data': 'foo'})\n    time.sleep(5)\nHas the same effect. Currently I don't see anything related to transition causing this. If you see something I can do about that issue, I am happy to help. If this is rather a flask/socketio related problem, please close this ticket.. Hi @brizjin,\nyou override Machine.finalize_event with your own MyMachineWork.finalize_event. This does not play well with the internals of the machine which expects Machine.finalize_event (more precisely Machine._finalize_event) to maintain a list of callbacks for the event.\nThe actual version of Machine._finalize_event will actually make sure that Machine._finalize_event is a list.\nIf you adapt your naming slightly, things work as expected:\n```python\nfrom transitions.extensions.locking import LockedMachine\nimport unittest\nclass StateTest(unittest.TestCase):\ndef test_state_machine(self):\n    class SimpleMachineBroken(LockedMachine):\n        def __init__(self):\n            LockedMachine.__init__(self, model=self, states=[\"init\", \"start\"], initial=\"init\",\n                                   finalize_event=\"my_finalize_event\")\n\n    class MyMachineBroken(SimpleMachineBroken):\n        def __init__(self):\n            super(MyMachineBroken, self).__init__()\n\n        # does not override Machine.finalize_event any longer\n        def my_finalize_event(self):\n            pass\n\n    MyMachineBroken().to_start()\n\n```. Closing this since there hasnt been any follow up. If this is still an issue feel free to comment and I will reopen the issue when necessary.. Hello @WoWuQ,\nsorry for not answering you earlier. Have you tried asking this question on Stackoverflow? This sounds more like a question about how to use transitions rather than a bug report and/or feature request.\nPosting questions at SO has the advantage that you reach a far bigger community which is happy to help with your issues. I can only speak for myself but often just formulating a detailed question usually helps me to figure out problems or sparks ideas. If your attempt at SO does not result in a satisfactory result, feel free to come back again and and/or reference the posted question.. I will close this issue for now since there has not been any feedback for 8 days. Feel free to comment on this issue if you have further feedback. I will reopen the issue if necessary.. Hello @plaes,\napologies for not answering earlier. You are right, timeouts are not mentioned in graphs so far and I do agree that this should be mentioned somehow. Do you have a certain way in mind? I looked up some ways but maybe you know a standardised approach.. I guess it will be something along that line. Probably with a customisable string. Additionally, the time format needs to be adjustable or should adjust dynamically. Neither 'timeout(1200s)' nor 'timeout(0.02h)' is truly informative.. Hello @ncastrohub, could you provide a minimal code example of the reported issue for me to reproduce it?. Could you solve your issues @ncastrohub? I cannot investigate your reported problem without a lead. I can only investigate a reported bug, if the description and a code example allow me to reproduce it.\nI close this issue for now. If your problem still exists, feel free to comment and I will open the issue again when it is confirmed that this is a bug.. Hi @ljaniec,\ndid you solve your issues? Unfortunately, I havent worked with ROS much and cannot be of assistance here.. I will close this issue for now since there is no feature request or bug related to it. Feel free to comment and if necessary we will reopen the issue again.. Hi @pafodie,\nyour assumption is correct. This is a pygraphviz issue which has been reported here. Pygraphviz uses StopIterarion exceptions which have been deprecated in Python 3.5. Starting with 3.7, raising StopIteration does not work any longer. Since this is an upstream issue I will close this ticket for now. If you think there is something transition could do to handle that error, feel free to comment. If necessary, I will open the issue again.. Hello @viper7882,\n\nI couldn't find any way to disable the logging in pytransitions\n\nthe built-in logging module allows to disable logging -- or better set log levels -- for each module individually:\n\nPython Logging - Disable logging from imported modules\nHow do I disable log messages from the Requests library?\n\nimport logging\nlogging.getLogger(\"transitions\").setLevel(logging.WARNING)\nAs far as I know this is the recommended way to configure the logging behaviour of modules.\n. I am closing this issue since there has been no feedback. If you think this problem is still valid feel free to comment. I will reopen the issue if necessary.. Hello @jeasinema,\nI can confirm an increase in memory usage over time.\nHowever, I could not find any leaked Python objects using objgraph:\n```python\nfrom transitions.extensions import GraphMachine\nimport gc\nimport objgraph\nimport resource\nclass Matter(object):\n    pass\nif name == 'main':\n    states = ['solid', 'liquid']\n    transitions = [\n        {'trigger': 'melt', 'source': 'solid', 'dest': 'liquid'},\n        {'trigger': 'freeze', 'source': 'liquid', 'dest': 'solid'}\n    ]\nsize = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\nobjgraph.show_growth()\nfor i in range(1000):\n    lump1 = Matter()\n    machine1 = GraphMachine(lump1, states=states, transitions=transitions, initial='liquid')\n    lump1.trigger('freeze')\n    lump1.trigger('melt')\n    del lump1\n    del machine1\n    gc.collect()\n\nprint(\"====================\")\nprint(objgraph.show_growth())  # >>> None\nprint(\"memory leak (kB): \"\n      \"%.2f\" % ((resource.getrusage(resource.RUSAGE_SELF).ru_maxrss - size) / 1024)) \n# >>> memory leak (kB): 6148.00\n\n```\nAdditionally, using tracemalloc also does not show any significant memory usage:\nCode snippet:\n```python\nif name == 'main':\n    states = ['solid', 'liquid']\n    transitions = [\n        {'trigger': 'melt', 'source': 'solid', 'dest': 'liquid'},\n        {'trigger': 'freeze', 'source': 'liquid', 'dest': 'solid'}\n    ]\nsnapshot1 = tracemalloc.take_snapshot()\nfor i in range(1000):\n    lump1 = Matter()\n    machine1 = GraphMachine(lump1, states=states, transitions=transitions, initial='liquid')\n    lump1.trigger('freeze')\n    lump1.trigger('melt')\n    del lump1\n    del machine1\n    gc.collect()\n\nsnapshot2 = tracemalloc.take_snapshot()\ntop_stats = snapshot2.compare_to(snapshot1, 'lineno')\n\nprint(\"[ Top 10 differences ]\")\nfor stat in top_stats[:10]:\n    print(stat)\n\n```\nOutput:\n[ Top 10 differences ]\n.../transitions/tst2.py:22: size=2208 B (+2208 B), count=1 (+1), average=2208 B\n../transitions/transitions/extensions/diagrams.py:373: size=912 B (+912 B), count=2 (+2), average=456 B\n.../python3.6/site-packages/pygraphviz/agraph.py:734: size=779 B (+779 B), count=3 (+3), average=260 B\n.../transitions/transitions/extensions/diagrams.py:173: size=704 B (+704 B), count=2 (+2), average=352 B\n.../transitions/transitions/extensions/diagrams.py:353: size=680 B (+680 B), count=1 (+1), average=680 B\n.../transitions/transitions/core.py:771: size=675 B (+675 B), count=3 (+3), average=225 B\n.../transitions/transitions/extensions/diagrams.py:137: size=672 B (+672 B), count=1 (+1), average=672 B\n.../transitions/transitions/extensions/diagrams.py:438: size=667 B (+667 B), count=4 (+4), average=167 B\n.../transitions/transitions/core.py:399: size=648 B (+648 B), count=1 (+1), average=648 B\n.../.pyenv/versions/3.6.4/lib/python3.6/_weakrefset.py:37: size=600 B (+600 B), count=5 (+5), average=120 B\nCurrently,  I assume that the problem is in the used C code which is not tracked by tracemalloc.\nI will investigate further and see whether I can track the reason for the leak.\nIf the problem is indeed originating from pygraphviz there is not much I can do about it, afaik.\nIf you have some feedback or ideas how to track the issue, feel free to comment.. Using memory-profiler and loop 10.000 times:\nshell\nmprof run tst.py\nmprof plot\n\n. Maybe relevant: https://github.com/pygraphviz/pygraphviz/issues/119. I have built python3.7 with --with-pydebug --without-pymalloc --with-valgrind and also passed PYTHONMALLOC=malloc (just to be extra certain) to valgrind:\nshell\n$PYTHONMALLOC=malloc valgrind --leak-check=full --show-possibly-lost=no --tool=memcheck --dsymutil=yes --track-origins=yes --trace-children=yes --suppressions=$HOME/valgrind-python.supp --suppressions=minimal.supp /usr/local/bin/python3.7 tst.py\nI can confirm memory leaks in (py)graphviz...\n...without loop:\nshell\n==85778== LEAK SUMMARY:\n==85836==    definitely lost: 565 bytes in 71 blocks\n==85836==    indirectly lost: 0 bytes in 0 blocks\n==85836==      possibly lost: 459,296 bytes in 146 blocks\n==85836==    still reachable: 25,841 bytes in 87 blocks\n==85836==         suppressed: 1,718,564 bytes in 10,511 blocks\n...100 loops:\nshell\n==85907== LEAK SUMMARY:\n==85907==    definitely lost: 70,004 bytes in 7,216 blocks\n==85907==    indirectly lost: 374,279 bytes in 7,408 blocks\n==85907==      possibly lost: 459,296 bytes in 146 blocks\n==85907==    still reachable: 25,841 bytes in 87 blocks\n...1000 loops:\nshell\n==85982== LEAK SUMMARY:\n==85982==    definitely lost: 679,528 bytes in 72,538 blocks\n==85982==    indirectly lost: 3,796,842 bytes in 74,347 blocks\n==85982==      possibly lost: 461,001 bytes in 184 blocks\n==85982==    still reachable: 25,849 bytes in 88 blocks\n==85982==         suppressed: 1,718,564 bytes in 10,511 blocks\nThe 'possibly lost', 'suppressed' and 'still reachable' memory leaks are caused by Python itself. That's why they are more or less stable. The observed memory leaks caused by (py)graphviz are about 4476,37 kB (definitely lost and indirectly lost) which is about 2/3 of the increase in memory usage seen earlier. The other 1/3 might be free memory which has been reserved by Python in advance since max_rss does only report the reserved memory.\nFull heap report from valgrind:\nshell\n==85982== HEAP SUMMARY:\n==85982==     in use at exit: 6,681,784 bytes in 157,668 blocks\n==85982==   total heap usage: 1,999,676 allocs, 1,842,008 frees, 198,320,163 bytes allocated\n==85982== \n==85982== 13,000 bytes in 2,000 blocks are definitely lost in loss record 1,088 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10421F49A: SWIG_AsCharPtrAndSize (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x104219971: _wrap_agnode (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982==    by 0x100040D94: _PyFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211C44: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x10020A510: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982== \n==85982== 64,370 (1,000 direct, 63,370 indirect) bytes in 25 blocks are definitely lost in loss record 1,141 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423BBF9: agalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x1042322E7: dtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcdt.5.dylib)\n==85982==    by 0x10423FCF1: agdtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239BA7: agopen1 (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B4F: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982== \n==85982== 77,353 (2,088 direct, 75,265 indirect) bytes in 29 blocks are definitely lost in loss record 1,150 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x1042321AE: dtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcdt.5.dylib)\n==85982==    by 0x10423FCF1: agdtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239BA7: agopen1 (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B4F: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982== \n==85982== 99,589 (3,472 direct, 96,117 indirect) bytes in 31 blocks are definitely lost in loss record 1,155 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239AF5: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982==    by 0x100040D94: _PyFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211C44: call_function (in /usr/local/bin/python3.7)\n==85982== \n==85982== 324,036 (10,712 direct, 313,324 indirect) bytes in 103 blocks are definitely lost in loss record 1,164 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423BBF9: agalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423BFCC: newnode (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423C198: agnode (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104219A52: _wrap_agnode (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982== \n==85982== 483,158 (19,072 direct, 464,086 indirect) bytes in 149 blocks are definitely lost in loss record 1,169 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423BBF9: agalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423906B: newedge (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x1042392A4: agedge (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10421A92C: _wrap_agedge (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982== \n==85982== 486,691 (7,200 direct, 479,491 indirect) bytes in 180 blocks are definitely lost in loss record 1,170 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423BBF9: agalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x1042322E7: dtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcdt.5.dylib)\n==85982==    by 0x10423FCF1: agdtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B91: agopen1 (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B4F: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982== \n==85982== 547,003 (13,320 direct, 533,683 indirect) bytes in 185 blocks are definitely lost in loss record 1,171 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x1042321AE: dtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcdt.5.dylib)\n==85982==    by 0x10423FCF1: agdtopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B91: agopen1 (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B4F: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982== \n==85982== 551,992 bytes in 68,999 blocks are definitely lost in loss record 1,172 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10421F49A: SWIG_AsCharPtrAndSize (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x10421C00D: _wrap_agattr (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x1000416A8: function_code_fastcall (in /usr/local/bin/python3.7)\n==85982==    by 0x10003F870: _PyFunction_FastCallDict (in /usr/local/bin/python3.7)\n==85982==    by 0x10003F322: _PyObject_FastCallDict (in /usr/local/bin/python3.7)\n==85982==    by 0x1000433FF: _PyObject_Call_Prepend (in /usr/local/bin/python3.7)\n==85982== \n==85982== 892,381 (17,280 direct, 875,101 indirect) bytes in 540 blocks are definitely lost in loss record 1,173 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423BBF9: agalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x10423D2C3: agbindrec (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x1042384CE: agmakeattrs (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239C5B: agopen1 (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239B4F: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982== \n==85982== 936,797 (40,392 direct, 896,405 indirect) bytes in 297 blocks are definitely lost in loss record 1,174 of 1,174\n==85982==    at 0x1005F35C6: malloc (in /usr/local/Cellar/valgrind/HEAD-2b0aa0a/lib/valgrind/vgpreload_memcheck-amd64-darwin.so)\n==85982==    by 0x10423BB83: memalloc (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104239A9A: agopen (in /usr/local/Cellar/graphviz/2.40.1/lib/libcgraph.6.dylib)\n==85982==    by 0x104218D2D: _wrap_agopen (in /usr/local/lib/python3.7/site-packages/pygraphviz/_graphviz.cpython-37d-darwin.so)\n==85982==    by 0x100042983: _PyMethodDef_RawFastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100040EAC: _PyCFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211796: call_function (in /usr/local/bin/python3.7)\n==85982==    by 0x100209F94: _PyEval_EvalFrameDefault (in /usr/local/bin/python3.7)\n==85982==    by 0x1001F5FB6: PyEval_EvalFrameEx (in /usr/local/bin/python3.7)\n==85982==    by 0x100213857: _PyEval_EvalCodeWithName (in /usr/local/bin/python3.7)\n==85982==    by 0x100040D94: _PyFunction_FastCallKeywords (in /usr/local/bin/python3.7)\n==85982==    by 0x100211C44: call_function (in /usr/local/bin/python3.7)\n==85982== \n==85982== LEAK SUMMARY:\n==85982==    definitely lost: 679,528 bytes in 72,538 blocks\n==85982==    indirectly lost: 3,796,842 bytes in 74,347 blocks\n==85982==      possibly lost: 461,001 bytes in 184 blocks\n==85982==    still reachable: 25,849 bytes in 88 blocks\n==85982==         suppressed: 1,718,564 bytes in 10,511 blocks. @jeasinema:\nCurrently, there is no way to use graphs and/or GraphMachine without pygraphviz. I plan to work on a JSON 'intermediate' layer which should make it possible to fallback to the graphviz module or even use a custom visualisation for graphs. But this is still work in progress.\nYou can use any other *Machine without the need of pygraphviz.\nUnfortunately, there is nothing more I can suggest to you rather than not using any machine with GraphSupport.\nAdditionally, apologies if you felt like I was throwing huge amounts of output at you. This is meant to collect all necessary information about the bug in one place.\nIf this bug comes up again in the future, it will be handy to already have investigation results.\nThis hopefully saves a developer in the future some headache :).. Hello @viper7882,\nI guess you referring to the lacking initial = 'A' in the constructor. I will add this to the example. Did you change something else?. If its okay to define transitions after the model has been initialised, you can use partials:\n```python\nfrom transitions import Machine\nfrom functools import partial\nclass Model(object):\ndef resp(self, resp_i):\n    print(\"Got {0}\".format(resp_i))\n\nmodel = Model()\nstates = ['A', 'B', 'C']\ntransitions = [\n    {'trigger': 'go', 'source': 'A', 'dest': 'B', 'after': partial(model.resp, 'resp_1')},\n    {'trigger': 'go', 'source': 'B', 'dest': 'C', 'after': partial(model.resp, 'resp_2')},\n    {'trigger': 'go', 'source': 'C', 'dest': 'A', 'after': partial(model.resp, 'resp_3')}\n]\nmachine = Machine(model=model, states=states, transitions=transitions, initial=states[0])\nmodel.go()  # >>> Got resp_1\nmodel.go()  # >>> Got resp_2\nmodel.go()  # >>> Got resp_3\n```. > Currently I am initializing the Machine inside the model itself i.e.\neven better :). This way it's less likely to mixup initialisation orders.\n```python\nfrom transitions import Machine\nfrom functools import partial\nclass Model(object):\ndef __init__(self):\n    states = ['A', 'B', 'C']\n    transitions = [\n        {'trigger': 'go', 'source': 'A', 'dest': 'B', 'after': partial(self.resp, 'resp_1')},\n        {'trigger': 'go', 'source': 'B', 'dest': 'C', 'after': partial(self.resp, 'resp_2')},\n        {'trigger': 'go', 'source': 'C', 'dest': 'A', 'after': partial(self.resp, 'resp_3')}\n    ]\n\n    self.machine = Machine(model=self, states=states, transitions=transitions, initial=states[0])\n\ndef resp(self, resp_i):\n    print(\"Got {0}\".format(resp_i))\n\nmodel = Model()\nmodel.go()\nmodel.go()\nmodel.go()\n```. Or with inheritance:\n```python\nfrom transitions import Machine\nfrom functools import partial\nclass Model(Machine):\ndef __init__(self):\n    states = ['A', 'B', 'C']\n    transitions = [\n        {'trigger': 'go', 'source': 'A', 'dest': 'B', 'after': partial(self.resp, 'resp_1')},\n        {'trigger': 'go', 'source': 'B', 'dest': 'C', 'after': partial(self.resp, 'resp_2')},\n        {'trigger': 'go', 'source': 'C', 'dest': 'A', 'after': partial(self.resp, 'resp_3')}\n    ]\n\n    Machine.__init__(self, model=self, states=states, transitions=transitions, initial=states[0])\n\ndef resp(self, resp_i):\n    print(\"Got {0}\".format(resp_i))\n\nmodel = Model()\nmodel.go()\nmodel.go()\nmodel.go()\n```. Hi @doanguyen,\nwhat are you looking for? Just a list of state names? Since the stateful object with transitions is the model you can use the state property to track state changes:\n```python\nfrom transitions import Machine\nimport collections\nif you like your machine to act as a model, let Model inherit from Machine\nclass Model(object):\ndef __init__(self, history_length):\n    self.state_history = collections.deque(maxlen=history_length)\n\n@property\ndef state(self):\n    return self.state_history[-1]\n\n@state.setter\ndef state(self, value):\n    self.state_history.append(value)\n\nmodel = Model(3)\nmachine = Machine(model, states=['A', 'B', 'C', 'D'], initial='A')\nprint(model.state)  # >>> A\nmodel.to_B()\nmodel.to_C()\nmodel.to_A()\nmodel.to_D()\nprint(\"->\".join(model.state_history))  # >>> C->A->D\n```\n. > I'm actually looking for a way of storing states and its transitions into database and re-initialize later\nStates are persistent objects maintained by a Machine. States can be pickled (serialized) and deserialized if necessary. However, the State objects themselves do not (or should not) contain actual state related properties. They are rather 'blueprints' to determine what should happen with a 'stateful' object which is a model.\nYou might want to have a look at this issue or this notebook to get an idea how models and database table schemes can be connected.\nThis way you can save and load complete model/object states.. Hello @Arkanayan,\nas mentioned in the documentation about checking states, transitions will add convenience methods to your model according to the pattern is_<<state_name>>. The method Clause.is_first_level matches this pattern and is overridden.\nIf you change the method's name to matches_first_level, your code runs fine.\nEven though the overriding is currently expected behaviour, I consider skipping binding convenience functions if a method is already present. However, for your current situation I would recommend renaming your methods to prevent collisions. . Fixed by e60bc1e. The shown 'fail' is just travis lacking Python 3.7 support.. Hi @prashast,\n\nPerhaps is it possible for me to inherit this Transition class and add additional functionality to it?\n\nthis can be done quite easily by creating your own subclass of Transition and assign it to the transition_cls class attribute of your custom subclass of Machine:\n```python\nfrom transitions.core import Machine, Transition\nclass SubTransition(Transition):\ndef __init__(self,  *args, **kwargs):\n    self.new_arg = kwargs.pop('new_arg', None)\n    super(SubTransition, self).__init__(*args, **kwargs)\n\ndef execute(self, event_data):\n    print(\"I got {0}\".format('nothing' if self.new_arg is None else self.new_arg))\n    return super(SubTransition, self).execute(event_data)\n\nclass SubMachine(Machine):\n    transition_cls = SubTransition\ntransitions = [\n    {'trigger': 'go', 'source': 'A', 'dest': 'B', 'new_arg': 'something'},\n    ['go', 'B', 'A']\n]\nm = SubMachine(states=['A', 'B'], transitions=transitions, initial='A')\nm.go()  # >>> I got something\nm.go()  # >>> I got nothing\n```\nJust make sure you don't accidentally pass unknown attributes to the core classes. This is why custom arguments need to be popped from kwargs.. There is Machine.get_triggers which allows you to get valid events for a certain state.\nBy accessing Machine.events you get all transitions associated with this event. An event organises transitions by source state which should be what you are looking for. If you search the issue tracker and SO you probably find enough information to get this working. If not, consider posting your issue at SO.  This has several advantages:\n\nYour question gains higher visibility since most developers look for help there\nThe targeted community is larger; Some people will even help you to formulate a good question People get 'rewarded' with 'reputation' to help you.\nYou also gain reputation in case this questions pops up more frequently. It's a win-win situation.\n. Hello @potens1,\n\nyou are right. Error.enter is not calling its super class equivalent. I see you have already fixed that in your PR. Thanks for that! You mention issues with Timeout as well? Could you provide an example which is still not working, even after fixing Error?. Yeah, it should call both methods in an order which cannot be altered due to the MRO as you mentioned. Additionally, there might be issues when a MachineError is raised during the processing of a timeout event. The raised exception cannot be caught directly in the main thread as timeouts are processed in a separate thread.\nUnfortunately, there is no nice way to implement timeouts (for Python 2 and 3) without using threads as far as I know.. > I mean, aren't we here in a diamond inheritance ...\nYes. Since every new style Python class is derived from object, practically every multi-inheritance scenario results in a diamond. Afaik, Python uses C3 linearization since Python 2.3 [1] to deal with that.\n\nto just push the timeout events to a queue, and another part of my soft is managing the queue\n\nUsing queues/asyncio is definitely the way to go for sophisticated use cases. This requires some logic which cannot be provided by transitions. As discussed (e.g here) state.Timeout should be considered a tradeoff.. The auto_transitions keyword is just a convenient way to create a bunch of to_<state> transitions. They behave like every other transition apart from that.  Since there is no restriction considering how automatically generated transitions can be used, they should imho be treated as ordinary transitions.\nHowever, I do agree this limits the usefulness of state.Error for cases in which auto transitions are intended to act as 'dev/admin' tools. We have implemented a filter function for diagrams here which might be helpful to filter out transitions that 'look like' auto transitions. What about a keyword ignore_auto_transitions for state.Error? It increases the effort required for Error initialisation but tackles the issue locally. What do you think?. > My point of view on that is it should be enough to put a big fat warning in the doc saying Error is exclusive with auto_transitions\nfair enough. I added a note to state.Timeout and state.Error which hopefully expressed both extensions' limitations. Thanks again for your feedback!. Hello @SuperChomsky,\nthis looks like a question about how to use transitions. Please refer to Stackoverflow for such matters.\nPosting there has several advantages:\n\nYour question gains higher visibility since most developers look for help there\nThe targeted community is larger; Some people will even help you to formulate a good question\nPeople get 'rewarded' with 'reputation' to help you. You also gain reputation in case this questions pops up more frequently. It's a win-win situation.\n\nIf your question results in a feature request or a bug report, feel free to open a ticket here.. Hi @SuperChomsky,\nthanks for following by recommendation and post your question and Stackoverflow (link). Please avoid cross-posting (posting the same question multiple times in different places without references). I will close this issue since it does not contain a feature request or a bug report. Discussion/solutions should be posted in the linked post. Feel free to comment in case a feature request or bug report arises. I will reopen the issue if necessary.. Hello @leonbrag,\na transition requires an event name. This event however can be as generic as you like. You can register ALL transitions with the same event name.\npython\nmachine.add_transition(trigger='process', source=[<sources1>], dest='<dest1>')\n...\nmachine.add_transition(trigger='process', source=[<sourcesN>], dest='<destN>')\nThis way you can call model.process() whenever a state change should happen/should be checked. They will be process in their addition order. Of course, invalid transitions (not being valid in the current state) will not be considered.\nAdditionally, this looks like a question about how to use transitions. Please refer to Stackoverflow for such matters. Posting there has several advantages:\nYour question gains higher visibility since most developers look for help there\nThe targeted community is larger; Some people will even help you to formulate a good question\nPeople get 'rewarded' with 'reputation' to help you. You also gain reputation in case this questions pops up more frequently. It's a win-win situation.\nCurrently, this issue neither contains a feature request nor a bug report. I will close it for now. Feel free to comment nevertheless. If a feature request or a bug report arises, I will reopen the issue again.. Hi @occoder,\nunfortunately, I have currently no Windows at hand.\nCould you give this a try and tell me if it results in the same error:\n```python\nfrom transitions.extensions import MachineFactory\ndiagram_cls = MachineFactory.get_predefined(graph=True)\nclass NarcolepticSuperhero(object):\n    states = ['asleep', 'saving the world']\ndef __init__(self, name):\n    self.name = name\n    self.kittens_rescued = 0\n    self.machine = diagram_cls(model=self, states=NarcolepticSuperhero.states, initial='asleep')\n    self.machine.add_transition('distress_call', '*', 'saving the world')\n\nif name == \"main\":\n    batman = NarcolepticSuperhero(\"Batman\")\n    print(batman.state)\n    batman.get_graph().draw('my_state_diagram.png', prog='dot')\n```\n. This is a problem with (py)graphviz and self-referencing edges under Windows. I will close this issue because it is a duplicate of #258. The issue has been reported to the maintainers of pygraphviz (issue) but hasn't been fixed yet. Unfortunately, there is nothing I can do about it. However, if you want to assist the maintainers of pygraphviz with identifying/fixing the issue, they'll probably appreciate it.. Hello again @occoder,\nI am working on an alternative to pygraphviz for transitions. If you like, check out the dev-graphiz branch and give it a try. You will need the graphviz package and also install Graphviz manually or via Anaconda (conda install graphviz). If you use Anaconda, install graphviz via Anaconda as well with conda install python-graphviz. The dot program provided by Graphviz needs to be executable for Python (it needs to be in %PATH%). You might need to add Graphviz to your %PATH% yourself if you don't use (Ana)conda. Note that the way in which graphs are generated and saved has changed a bit:\n```python\nfrom transitions import Machine\nimport random\nfrom transitions.extensions import GraphMachine as Machine\nfrom transitions.extensions import MachineFactory\ncreate a machine with mixins\ndiagram_cls = MachineFactory.get_predefined(graph=True)\nclass NarcolepticSuperhero(object):\n# Define some states. Most of the time, narcoleptic superheroes are just like\n# everyone else. Except for...\nstates = ['asleep', 'hanging out', 'hungry', 'sweaty', 'saving the world']\n\ndef __init__(self, name):\n\n    # No anonymous superheroes on my watch! Every narcoleptic superhero gets\n    # a name. Any name at all. SleepyMan. SlumberGirl. You get the idea.\n    self.name = name\n\n    # What have we accomplished today?\n    self.kittens_rescued = 0\n\n    # Initialize the state machine\n    self.machine = diagram_cls(model=self, states=NarcolepticSuperhero.states, initial='asleep')\n\n    # Add some transitions. We could also define these using a static list of\n    # dictionaries, as we did with states above, and then pass the list to\n    # the Machine initializer as the transitions= argument.\n\n    # At some point, every superhero must rise and shine.\n    self.machine.add_transition(trigger='wake_up', source='asleep', dest='hanging out')\n\n    # Superheroes need to keep in shape.\n    self.machine.add_transition('work_out', 'hanging out', 'hungry')\n\n    # Those calories won't replenish themselves!\n    self.machine.add_transition('eat', 'hungry', 'hanging out')\n\n    # Superheroes are always on call. ALWAYS. But they're not always\n    # dressed in work-appropriate clothing.\n    self.machine.add_transition('distress_call', '*', 'saving the world',\n                     before='change_into_super_secret_costume')\n\n    # When they get off work, they're all sweaty and disgusting. But before\n    # they do anything else, they have to meticulously log their latest\n    # escapades. Because the legal department says so.\n    self.machine.add_transition('complete_mission', 'saving the world', 'sweaty',\n                     after='update_journal')\n\n    # Sweat is a disorder that can be remedied with water.\n    # Unless you've had a particularly long day, in which case... bed time!\n    self.machine.add_transition('clean_up', 'sweaty', 'asleep', conditions=['is_exhausted'])\n    self.machine.add_transition('clean_up', 'sweaty', 'hanging out')\n\n    # Our NarcolepticSuperhero can fall asleep at pretty much any time.\n    self.machine.add_transition('nap', '*', 'asleep')\n\ndef update_journal(self):\n    \"\"\" Dear Diary, today I saved Mr. Whiskers. Again. \"\"\"\n    self.kittens_rescued += 1\n\ndef is_exhausted(self):\n    \"\"\" Basically a coin toss. \"\"\"\n    return random.random() < 0.5\n\ndef change_into_super_secret_costume(self):\n    print(\"Beauty, eh?\")\n\nif name == \"main\":\n    batman = NarcolepticSuperhero(\"Batman\")\n    print(batman.state)\n    batman.get_graph().generate().render('my_state_diagram', format='png')\n    batman.get_graph(show_roi=True).generate().render('my_roi_diagram', format='png')\n```\nThe output should look like this:\n my_state_diagram.png\n\n my_roi_diagram.png\n\n. Hi @potens1,\nsorry for the long wait. It  has been a deliberately decision to only accept True and False instead of 'truthy' and 'falsy' values such as (non)empty strings, lists and so on for the sake of comprehensibility of condition checks.\nThats why the documentation always states True and False instead of true and false.\nHowever, if community feedback favours changing conditions to also work with 'falsy' and 'truthy' values it can be done. I will leave the ticket open with a request for feedback.. Condition changes to:\n```python\nCondition.check(self, event_data)\nif event_data.machine.send_event:\n    res = predicate(event_data)\nelse:\n    res = predicate(event_data.args, *event_data.kwargs)\nreturn res if self.target else not res\n```. As there has been no feedback considering this, I will close it for now. Please feel free to comment on this feature request if you consider it beneficial. I will reopen the issue when necessary.. Hi @potens1:\n\nSorry, I did not understood you where expecting an answer from my side (was thinking your last message was to signify that this change was acted)\n\nNo action from you required. You made your point clear. I was hoping for someone from the user base to (dis-)agree with you as written in:\n\n'However, if community feedback favours changing conditions to also work with 'falsy' and 'truthy' values it can be done.'\n\nI now see how this can be misinterpreted, sorry. I don't have a strong opinion about that and I think you presented your arguments well. To evaluate whether this would be a desired change, more feedback is required. I reopen the issue again for visibility.. Hello @liuzongquan,\nthis behaviour is the result of this commit. Starting with transitions 0.6.9, already defined model methods will not be overridden any longer (Changelog). This is motivated by experiences documented in this issue.\nYour model DST already defines go. The log mentions that:\nWARNING:transitions.core:Model already contains an attribute 'go'. Skip binding.. The question arises 'how do I call the trigger then?'. Currently this is rather complicated. I have refactored the convenience model method 'Model.trigger' to work independently of the binding status of Events. In case your DST.go needs to stay you can still call the event go the following way:\nif __name__ == '__main__':\n    test_case = DST()\n    print(test_case.state)  # >>> A\n    test_case.go()\n    print(test_case.state)  # >>> A\n    test_case.trigger('go') # <<< call trigger with trigger name.\n    print(test_case.state)  # >>> B\nThis will be published in the release 0.6.10.. Currently, spacing is done in Machine.__init__ (ref) if a name has been passed:\npython\nself.name = name + \": \" if name is not None else \"\"\nAs a result, log messages are either:\nCan't trigger event ... \nor \nMyMachine: Can't trigger event ...\nwhich is expected behaviour.\nWhat you are probably experiencing is the default BASIC_FORMAT logging formatter which does not include spaces:\nBASIC_FORMAT = \"%(levelname)s:%(name)s:%(message)s\"\nIMHO, the message payload itself should not start with a leading space to cope with that. I'd suggest to adapt the formatter to a format you consider appropriate instead.\nA leading space may also interfere with custom formatters:\n```\nformat = \"[%(levelname)s] %(name)s - %(message)s\"\nlogging.basicConfig(level=logging.INFO, format=format)\n>>> transitions.core - MyMachine: Exited state initial\n>>> transitions.core -  MyMachine: Exited state initial with your changes\n```. Hi @kentoshima,\nthe documentation right above here mentions the following:\n\nTo check whether the current state is a substate of a specific state is_state supports the keyword allow_substates:\n\n```python\nmachine.state\n\n\n\n'C.2.a'\nmachine.is_C() # checks for specific states\nFalse\nmachine.is_C(allow_substates=True)\nTrue\n```\n\n\n\nSo this should work:\n```python\nfrom transitions.extensions import HierarchicalMachine as Machine\nstates = ['standing', 'walking', {'name': 'caffeinated', 'children':['dithering', 'running']}]\ntransitions = [\n  ['walk', 'standing', 'walking'],\n  ['stop', 'walking', 'standing'],\n  ['drink', '*', 'caffeinated'],\n  ['walk', ['caffeinated', 'caffeinated_dithering'], 'caffeinated_running'],\n  ['relax', 'caffeinated', 'standing']\n]\nmachine = Machine(states=states, transitions=transitions, initial='standing')\nmachine.drink() # coffee time\nmachine.walk()\nprint(machine.state)  # >>> caffeinated_running\nprint(machine.is_caffeinated())  # >>> False\nprint(machine.is_caffeinated(allow_substates=True))  # >>> True\n```. Hi @peey,\nstarting with 0.7.0 transition will support tags in diagrams. Have a look at the diagram section in the next-release branch. States tagged with accepted should be fairly easy to distinguish.. yeah, this functionality could be extended by updating the node's attributes based on the state's tags. When using pygraphviz, the node can be accessed and updated like this already:\n```python\nfrom transitions.extensions.diagrams import GraphMachine\nm = GraphMachine(states=['S1', 'S2', 'S3', 'S4'], auto_transitions=False,\n                 ordered_transitions=True, initial='S1')\nm.next_state()  # go to S2\nm.get_graph().get_node('S4').attr.update(peripheries=2)  # edit style of S4 \nm.get_graph().draw('diagram.png', prog='dot')  # save diagram\n```\n\n. Hello @amitabhn,\nas mentioned in the Readme:\n\nA machine can handle multiple models which can be passed as a list like Machine(model=[model1, model2, ...]) [...] You can also create a standalone machine, and register models dynamically via machine.add_model\n\nThe Machine instance acts as a 'rulebook' in that case. The models however are isolated, can implement their own state- or transition-related behaviour. However, all models will be decorated with all available triggers. This shouldn't be a problem as invalid triggers will raise a MachineError.\nIssues may occur when wildcards '*' are used for defining transitions as the resulting transitions might be valid on all models and will therefore change the state of all models to the same.\nIt is recommended to not use wildcards in this case.\n```python\nfrom transitions import Machine\ntransitions = [dict(trigger='advance', source='A1', dest='B1', conditions='check'),\n               dict(trigger='progress', source='A2', dest='B2', conditions='check'),\n               dict(trigger='go', source='B1', dest='C1'),\n               dict(trigger='go', source='B2', dest='C2')]\nclass Model1:\ndef check(self):\n    print(\"Everything good!\")\n    return True\n\ndef on_enter_B1(self):\n    print(\"Entered first state\")\n\nclass Model2:\ndef check(self):\n    print(\"Everything better than good!\")\n    return True\n\ndef on_enter_B2(self):\n    print(\"Entered second state.\")\n\nmodel1 = Model1()\nmodel2 = Model2()\nmachine = Machine(model=None, states=['A1', 'A2', 'B1', 'B2', 'C1', 'C2'],\n                  transitions=transitions)\nmachine.add_model(model1, initial='A1')\nmachine.add_model(model2, initial='A2')\ntriggers can be called for models individually\nmodel1.advance()  # >>> Everything good!\\n Entered first state.\nmodel2.progress()  # >>> Everything better than good!\\n Entered second state.\nDispatch will call a trigger on all models\nmachine.dispatch('go')  # >>> equivalent to model1.go(); model2.go();\nprint(model1.state, model2.state)  # >>> C1 C2\n```\n. > In a further extension to my question, I also need to exchange triggers between the two models (triggers generated by one and consumed by the other).\nEasiest solution would be simple membership, wouldn't it?\npython\nclass Model:\n     # ...\n    def trigger_x(self):\n        self.target_model.trigger_x()\nAlternatively, you could use method references (instead of strings) as well:\npython\ntransitions_model1 = [\n    ...\n    {'trigger': 'trigger_x', 'source': 'A', 'dest': 'B', 'after': model2.trigger_x}\n]\n\nOr maybe a mechanism to dispatch a trigger to the machine from within the model?\n\nYou can set send_event=True in Machine. This results in every callback having access to the triggering event which contains the targeted model as well as the machine instance. See the README for more details.\n\nThis is basically the functionality of a deferred event. which I believe is not supported by pytransitions.\n\nExplicitly? No. But it can be modeled without much effort though:\n```python\ntransitions = [\n    {'trigger': 'trigger_x', 'source': 'X', 'dest': None, 'after': 'process_event'},\n    {'trigger': 'trigger_x', 'source': '*', 'dest': None, ('conditions': 'is_deferable'), 'after': 'defer'}, \n... ]\nclass Model:\n    ...\n    def on_enter_X(self):\n        for event in self.deferred:\n            self.process_event(event)\n```\nValidity of transitions for each event will be evaluated in the order they were added. This means for state X the second transition is never evaluated unless there is an additional condition that fails.\n. Since there has been no follow up I will close the issue for now. If you consider this issue not resolved, please comment and I will reopen the issue if necessary.. Hello @keivanzavari,\n\nTo my experience, nesting state machines is very useful as you can reuse the states you have written before. Besides as your state machine grows, it helps to keep things more modular. So no state becomes huge and difficult to read/understand.\n\ntotally agree\n\nI think I have figured out what the problem is (correct me if I am wrong please). Once you create a state with children (sub-state)  [...]  a copy of the sub-state is created.\n\nyes, that's mentioned in the last paragraph of the reuse section:\n\nNote that the HierarchicalMachine will not integrate the machine instance itself but the states and transitions by creating copies of them. This way you are able to continue using your previously created instance without interfering with the embedded version.\nIf the sub-state is copied, how deep does this copy go?\n\nAll states and substates will be integrated into the new Machine\n\nSo what is the right way to be able to fully reuse a machine as a sub-state of another?\n\nI cannot claim this is the 'right' way because using machines in machines is a common practice for realizing HSMs afaik. So your initial thoughts are pretty much in line with how some state machine frameworks work. However, transitions' philosophy differs a bit here: we'd like to consider Machine instances to be the 'rulebooks' which defines transitions and configurations whereas the actual state-dependent behavior is part of the model.\nHere is a rather abstract example about how to organized behavior and transitions in models and machines. More explanation below:\n```\nfrom transitions.extensions.factory import HierarchicalGraphMachine as HSM\ndefine a basic model; useful for generic error handling\nclass BaseBehaviour:\ndef emergency_shutdown(self):\n    print('something is wrong!')\n\ndefine a task-specific behaviour which will act as a model;\nsuch a model will contain all related callbacks\nclass BehaviourA(BaseBehaviour):\ndef do_A(self):\n    print('doing A')\n\ndef prepare_A(self):\n    print('prepare A')\n\ndefine another independent model\nclass BehaviourB(BaseBehaviour):\ndef do_B(self):\n    print('doing B')\n\nextend the previously defined behaviour\nclass ImprovedBehaviourA(BehaviourA):\ndef do_A(self):\n    super(ImprovedBehaviourA, self).do_A()\n    print('post process A')\n\nthe final model will be a combination of the previously defined models\nclass Agent(ImprovedBehaviourA, BehaviourB):\n    pass\nstates_A = ['initial', 'A', 'done']\nstates_B = ['initial', 'B', 'done']\ntransitions_A = [{'trigger': 'do', 'source': 'initial', 'dest': 'A'},\n                 {'trigger': 'do', 'source': 'A', 'dest': 'done', 'before': 'do_A'}]\ntransitions_B = [{'trigger': 'do', 'source': 'initial', 'dest': 'B'},\n                 {'trigger': 'do', 'source': 'B', 'dest': 'done', 'before': 'do_B'}]\ninitialized the individual models and pass them to their related machines\nbehaviourA = BehaviourA()\nmachine_A = HSM(model=behaviourA, states=states_A, transitions=transitions_A, initial='initial', title='Behaviour A',\n                auto_transitions=False)\nbehaviourB = BehaviourB()\nmachine_B = HSM(model=behaviourB, states=states_B, transitions=transitions_B, initial='initial', title='Behaviour B',\n                auto_transitions=False)\nstitch everything together\nstates_agent = ['initial',\n                {'name': 'behaviourA', 'children': machine_A,\n                 'remap': {'done': 'initial'}},\n                {'name': 'behaviourB', 'children': machine_B,\n                 'remap': {'done': 'initial'}}]\ntransitions_agent = [['initA', 'initial', 'behaviourA'],\n                     ['initB', 'initial', 'behaviourB']]\nagent = Agent()\nmachine_agent = HSM(model=agent, states=states_agent, transitions=transitions_agent, initial='initial', title='Agent',\n                    auto_transitions=False)\nGraphviz plots of all rather simple state machines. See below.\nbehaviourA.get_graph().draw('behaviourA.png', prog='dot')\nbehaviourB.get_graph().draw('behaviourB.png', prog='dot')\nagent.get_graph().draw('agent.png', prog='dot')\nassert agent.state == 'initial'\nagent.initA()\nassert agent.state == 'behaviourA_initial'\nagent.do()\nassert agent.state == 'behaviourA_A'\nagent.do()\nassert agent.state == 'initial'\nagent.initB()\nagent.do()\nagent.do()\nassert agent.state == 'initial'\n```\nBehaviour A\n\nBehaviour B\n\nAgent (Combined Behaviour)\n\nAdvantages\nSeparation of rules and behaviour -- models and states/transitions can be used independently of each other\nTrigger events in callbacks -- events in submodules will be processed, can be overridden when necessary and will 'dispatch' to their parent in case they cannot be processed in the current context.\nThis is handy when a specific event might end a subroutine but this event is not specified in the subroutine itself. See for instance the 'relax' event in the example notebook which exits the nested state independently of the current substate.\nDrawbacks\nNamespace collision -- As everything will end up in a (set of) macro models, methods with the same name will be overridden by inheritance. This can be desired for specialization but may also cause conflicts when generic callback names (e.g. 'on_event' ) are frequently used in submodels and transitions.\non_enter_ -- Callbacks such as on_enter_stateX in submodels will not work anylonger when state names changes due to nesting.. > There it's very easy to load another state machine without having to know what's inside of it [...]\nSo I would very much like to use some smaller states as a sort of plug and play modules and do not have to tweak with them.\nI see the appeal of that. I'd assume it can be done with transitions as well. Since callbacks can also be function/method references instead of strings. The degree of isolation depends on how the module is defined:\npython\nclass BehaviorA:\n    def __init__(self):\n        states = [{'name': 'A', 'on_enter': self.do_something}, ...]\n        transitions = [{'trigger':'foo', ..., 'prepare': self.prepare,\n                        'conditions': 'model_callback'}, ...]\n        # initialized machine without model\n        self.machine = Machine(model=None, states=states,\n                               transitions=transitions, initial=...)\nHowever, it might not be as convenient as it should be. Feel free to give feedback about your experience and how to improve the handling of nested states.\n\nIf I understand you correctly, I'll have to load each state as a separate model, right?\n\nThe states and transitions are defined for the machine. However, the model is the actual 'stateful' object and contains the state- and transition-related callbacks.\nI'd suggest to isolate context-specific behaviour into a machine-model unit.. Hi @JustinTTL,\ninteresting idea. Currently, I am working with string constants but enums sound also reasonable.\nLet's see what others might have to add to this.. Hello @Edvard-D,\nwhere is indicate_logged_in coming from. The error informs you that indicate_logged_in cannot be found as part of the model, in your case your Machine instance.. Hi @jodal,\nthanks for the update!. Shouldn't it be len(conditions) != len(states) - 1 since n states mean n-1 transitions.\ne.g: A, B, C, D -> A>B, B>C, C>D\nAdditionally, I'd suggest to also accept string or a function as valid for conditions in cases where one condition check should be applied to all transitions\ne.g: is_ready or similar\n. Couldn't you skip these lines? You have done the State check already in Line 524. At this point every State object has been converted already, hasnt it?\n. Nice one! You could put that in an else statement to prevent double listify\nEDIT: Well, not double listify but IF the source had been a string we do not need to process it again.\n. Argh, my bad. you are right\n. RLock is imported from threading. self.managers.append(RLock()) should be sufficient.\n. Having two keywords which are pretty much handled the same way might be a bit confusing. I do not know which word might encompass both (context maybe?).\n. Since you already use contextlib, we could also make use of suppress or Jeff Paine's\n fallback to shorten this a bit. In the longer run both nested and suppress might go to a utils module (together with listify) to clean up the code. If we end up with just one keyword (instead of lock and managers) this might be a bit over the top though.\n. Yes and no. Yes: Locks have to be reentrant since every function which can be called will require the look and this procedure is most likely nested. No: Afaik there is no monkey patching going on, only inheritance and therefore method overloading/overriding. What could be done is to check wether the lock has been acquired already and if that is the case skip the LockedMethod wrapping and return the base class method directly. This needs to be done for LockedEvent as well. I will have a look into it.. ~just minor remark: 156-157 can be deleted since this has already been tested in test_ordering~\nnah, well. s1 is not the same as stuff. my bad.\n. I'd suggest to remove add_self again. Having accidentally set add_self=False and no model leads to weird effects which may be hard to track down. If no model is passed, use self as model. If someone wants to explicitly add self AND a model, why not do it in two steps m = Machine(model,...); m.add_model(m) (or vice versa) . This keeps the consistency of previous versions and requires one line of code for a special case instead of requiring another parameter to consider for every other case. What do you think?. > Actually, add_self=False and no model is exactly the use case i'm interested in\noh, I see. Well, if that is actually a use case I agree that there should be a way to achieve this.\n\nWhat kind of weird effects do your foresee?\n\nI was thinking about the easier settings where someone tries to use Machine as a model but nothing happens. I am also not a big fan of attributes that depend on other attributes ('adds self but only if...') or change meaning based on the value of other attributes.\nMaybe in transitions 0.5.x a Machine without model parameter should actually be initialized without a model. Or add_self should always add the machine as a model. Or we find a better way to actually pass Machine as a part of the model parameter which would be preferable.\n\nI also like the possibility of not instantiating a magic 'initial' state, which is only possible if no models are specified and no initial arg is provided.\n\nThe state 'initial' is only created if you do not pass initial as an argument. You could just pass initial to have a default initial argument for all the following models. In your scenario, you would have to pass initial to add_model anyway to not raise Exceptions. If you plan to initialize Machine without states this might be a problem though.. > Agreed re 0.5.x, in the meantime, can we keep add_self to maintain current behaviour/API but enable my use case?\nsure, why not. with your additions, 0.5.0 is around the corner anyway :).\n\nI think the MachineError here makes sense as currently implemented (if no default 'initial' and no 'initial' in add_model)\n\nyes, it does make sense if we allow Machine to not have a 'default' initial state. I am not sold on the idea we should let that happen.\nBut maybe we find a way to have None as a valid value for the initial parameter while keeping the current behaviour as default (e.g. initial=False?). If someone tries to intialize a Machine with a model and with initial=Nonean Exception is raised.. The documentation never mentions that an 'initial' state is created if initial=None if I am not mistaken. Maybe we should just remove that behaviour completely. What do you think @tyarkoni and @wtgee?. afaik, no graph functionality is tested here. Instead of skipIf you can just remove graph=True from get_predefined in line 176(184). This way we do not have to pull pygraphviz into test_threading.py.. yeah, I first wondered what 'S' could mean :). The only thing (I assume) you have to do to make the tests in test_threading work without pygraphviz is to change this line \npython\nself.stuff = Stuff(states, machine_cls=MachineFactory.get_predefined(locked=True, graph=True, nested=True))\ninto \npython\nself.stuff = Stuff(states, machine_cls=MachineFactory.get_predefined(locked=True, nested=True))\nin  setUp of TestLockedHierarchicalTransitions.. ",
    "Sispheor": "Hi, same for us.\nThis is the issue our users have openned.\nThis is the code of the state machine.\nWe use callback methods that switch our state after a thread as finished its job.\n. ",
    "wtgee": "I end up rolling my own, which is straightforward. You just basically throw things in a while loop and then check the state status.\nExample here\nI essentially use transitions.Machine as base class and create my own state machine. In addition to an initial state, the state machine itself keeps tracking of the previous and the next state. If the next_state is set to 'exit' I do just that. Note that my machine doesn't have a static route through the machine but does have a static exit point. My state machine class is responsible for setting things up as well as defining enter_state and exit_state methods that are called before and after each state as well an execute method that calls the same method name in per state. \n(edited to update example link)\n. I know you have access to the name of the state via the transition event:\ndest_state = event_data.event.name.replace('to_', '')\nprev_state = event_data.state.name\nBut since you haven't gone to the dest_state yet my feeling is that there\nis no object to have. You have the transition object and the previous state\nobject. The transition object indicates what the dest_state will be.\nHope that helps.\n~Wilfred\nOn Tue, Nov 10, 2015 at 4:18 AM, omago notifications@github.com wrote:\n\nHi,\nI have a question. I have a code like this\n{'trigger': 'new_to_pending', 'source': States.NEW, 'dest': States.PENDING,\n     'before': 'write_insert_statement',\n     'after': ['save_current_state',\n               'set_related_active_instructions_to_pending_state']},\ni write_insert_statement i would like to access source and dest states, if\ni send send_event=True to initializer i get event_data object but his\nobject only contains initial state. Is it possible to retrieve both states\nsource and dest?\nBest,\nDomagoj\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/issues/37.\n\n\n~Wilfred Tyler Gee\n. On Sat, Jan 2, 2016 at 10:51 AM, aleneum notifications@github.com wrote:\n\nHi,\nthanks for the feedback.\nIn the counter example, the instance name is 'counter' in some cases and\n'calculator' in others--this should be made consistent.\nfixed\nSince LockedMachine and LockedHSM seem to have identical code, could we\nmaybe use use a mixin pattern or something to manage this without the\nredundancy?\nfixed; I had tried multiple inheritance for LockedHierarchicalMachine but\ncould not get it to work. I assumed there were issues with super and\ngetattribute in multi-inheritance scenarios... well, I tried again,\nnow it works \\o/... seems these issues were related to previous locking\napproaches.\n\nFYI, I was running into this multiple inheritance issue with v0.2.9 as\nwell. getattribute was doing a locking check to make sure self !=\nself.model but that is gone in favor of the inspect module and I haven't\nhad problems since then.\n\nFor consistency, we should probably call the LockedHSM class\n'LockedHierarchicalMachine'. It's kind of annoying to type, but I think\nit's good to keep the nomenclature consistent.\nagree and fixed; Co-worker of mine always says 'code is usually read way\nmore often than it is written' and with code completion it does not really\nmatter.\nTo minimize redundancy, I think the 'Stuff' and 'Inherited Stuff' classes\nin the testing modules should probably be moved into a separate module\n(probably 'utils') under testing, and then they can be imported in multiple\nplaces as needed.\nfixed; called the module test_utils\nI'm not sure about using the underscore character to concatenate nested\nstate names.\nThat one is quite tricky. I started with dots actually (like domains) but\nwent for underscore later on because dots mess with auto_transitions. E.g.\nmodel.to_A.1 does not work and model.to_A/1 wont work either. The\ncharacters allowed in Python 2.x keywords\nhttps://docs.python.org/2/reference/lexical_analysis.html#grammar-token-identifier\nare quite limited. Double underscores (to_A__1) would be an alternative or\nreplacing '/' or '.' in function keywords only. State would be called 'A.1'\nbut auto_transition would be to_A_1. The first approach stretches functions\ncalls and second approach is rather inconsistent. Both are quite nasty.\nWhat do you think?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/52#issuecomment-168427391.\n\n\n~Wilfred Tyler Gee\n. No problem, thanks.  If I'm ambitious in the next week I'll try out the HSM\ntoo.\nCheers,\n~Wilfred\nOn Wed, Dec 30, 2015 at 8:27 AM, Tal Yarkoni notifications@github.com\nwrote:\n\nSorry, I'll bump version shortly---just waiting on some changes to a big\nPR before bumping to 0.3. :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/issues/54#issuecomment-168049603\n.\n\n\n~Wilfred Tyler Gee\n. Thanks for the note and the update! I was sitting here trying to figure out\nwhy my prod and dev were acting differently, completely forgetting I had\nmanually updated dev. D'oh.\nUpdated from pip and my robot is able to park itself again. :)\nCheers!\n~Wilfred\nOn Sat, Jan 2, 2016 at 11:49 AM, Tal Yarkoni notifications@github.com\nwrote:\n\nJust pushed the new release to PyPI.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/issues/54#issuecomment-168430718\n.\n\n\n~Wilfred Tyler Gee\n. I'm getting some spurious states in my graph and can't figure out where they come from, so something else needs to be fixed as well. The spurious states each have a single letter as their name but I can't seem to figure out where they are coming from.\n\n. Sorry, I'm not sure what happened. I tried to do two separate PR and the first one built fine as it's pretty simple, but I think the second PR merged with it. How do I find out where travis-cl failed?\n. Thanks, I got it figured out (logging in helps).\nThe build is failing on the test for the nested graphs (HSM). I wanted to\nplay with those this week anyway so I'll see what I can do.\nThanks,\nOn Mon, Jan 4, 2016 at 6:16 PM, Tal Yarkoni notifications@github.com\nwrote:\n\nClick on \"details\" under the build failure:\nhttps://travis-ci.org/tyarkoni/transitions/jobs/100266582\nNot sure why it's failing as a result of your changes, but the test itself\ncould use some improvement (right now it hardcodes the removal of the 'C'\nstate). I'll look at it later this week if you don't get to it first.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/56#issuecomment-168891724.\n\n\n~Wilfred Tyler Gee\n. Yes, it should be.  You'll get a merge conflict with @aleneum work on the double-circle but it should be easy to resolve. A fix for the graph title is also included.\n. I'd go ahead and merge the doublecircle from here directly to get it\nworking.\nCheers,\nOn Jan 6, 2016 07:51, \"aleneum\" notifications@github.com wrote:\n\nThis is where I got this information from:\nhttp://stackoverflow.com/a/23046244/1617563\nKoed00/django-q#38 (comment)\nhttps://github.com/Koed00/django-q/issues/38#issuecomment-126878806\nand this might be a solution:\nhttps://groups.google.com/d/msg/celery-users/E3CurhqxNDI/1dW4Jh0dQMsJ\nIf pickle support is highly appreciated I'd take a look at the reduce\napproach.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/58#issuecomment-169402515.\n. Hi @hstarmans,\n\nI don't see the need for the Thread and it is probably giving you problems the way it is set up. Are you just trying to get some kind of loop that actually runs the machine or do you have a need for threads?\n. Hi @hstarmans. I've created a machine that runs as you describe using asyncio (in python3.5). I'm not sure we ever want to pull this into the machine itself as it is pretty light-weight, but I can put together a document describing some of the process. I'll try to get to that this weekend. Thanks\n. The documentation doesn't mention the return value but I assume this is intended behavior. You are getting a bool as to whether or not you successfully transitioned or not.\npython\nif lump.melt():\n    print(\"Matter melted\")\nelse:\n   print(\"Problem\")\n. @tyarkoni Transitions.execute also?\n@hstarmans The method isn't failing, the state machine is just not transitioning. I would say if that is a failure to you then throw your own exception:\npython\nif not lump.melt():\n    raise MyMatterException(\"Lump would not melt\")\nYou would need to write the MyMatterException or just raise a regular Exception\n. Hi @hstarmans,\nI ran your example and the results print as True for me. Make sure you are updated to latest as I can't recreate problem.\nI don't see a compelling reason to not return the success. What would turning off the success allow you to do that you can't do now?\n. Example of active and previous states marked:\n\n. I agree with a lot of your ideas. Mostly I had this for my model but thought it might be nice to be an actual part of the Machine class. If we think it is something nice we can integrate in the manner that you suggest, which I agree is a lot better to do.\nAll I am really doing is storing the graph object and then updating certain nodes. My Machines have all been fairly small (< 15 states) so updating/drawing takes almost no time at all. The alternative approach would be to just generate a SVG and then update that elsewhere but this proved to be easier.\nOne annoying thing is that the graph redraws itself based on the colors, so sometimes state nodes move around. I'm not sure if there is a way to fix that or not.\nSo is this a feature we'd like to add, assuming it gets cleaned up?\n. Agreed. I'm going to close this PR and get a more formal solution going in a separate branch. I'll let you know when it's up. Thanks!\n. Thanks for pointing this out, we'll get it added in.\n. Perhaps we should move the get_state example to the States section and change this example to\nmachine.current_state.name. Or at least also include the current_state, which currently isn't documented anywhere.\n. I made a few small changes in my branch, let me know what you think:\nhttps://github.com/wtgee/transitions/tree/metadata_changes#checking-state\n. I'm going to merge this just because this corrects an obvious mistake. I improved the example a bit with the .current_state attribute (as shown in link above) but will just merge those changes in with some other project metadata changes. Thanks again for catching this @avikam \n. I go back and forth on this. Certainly it was the behavior I was expecting the first time around. It's complicated a bit by running a machine in some sort of event loop:\n``` python\nMachine\nm1 = Machine(my_model, states=['A','B','C'], initial='A') # I don't want on_enter_A called here\nDo some other stuff\nStart machine\nmy_model.run() # I want on_enter_A called here\n```\nSince my machine is in an event loop, I do:\n``` python\nMachine\nm1 = Machine(my_model, states=['A','B','C'], initial='C') # Or could be null initial state \nStart machine\nmy_model.run() # run() calls .to_A()\n```\nBasically, I think many people won't view the machine creation and the \"starting\" of the machine as the same thing.\n. :+1: Makes sense to me.\n. :+1: Looks good to me, thanks.\n. @svdgraaf can you give your input too since you original developed the graphs. Thanks!\n. Closed with #79 \n. :+1: Do you want to merge it into dev-graph or just work on dev-refactor as part of #75?\n. :+1: \nYeah, I think it looks good and I have been using it for a about a week now without problems. I had wanted to get the documentation and a few examples updated a little more but let's go ahead and merge this and then iterate on any improvements.\n. Hi everyone, sorry for the delay but I finally had to a chance to dig around here. It looks like a nice clean implementation (and I'm glad for the __getattr__ rework). \nThe naming to me is a little weird. I'd prefer something like prepare instead of before_check for the pre-condition and then just a simple before and after as it was. I think that makes more sense in my head but I'm not tied to it (and more people will probably have implementation methods called prepare than before_check). Maybe even before_condition would make more sense but that doesn't help with the verbosity.\nAlso, just for my clarification, if a condition fails is the user expected to do any cleanup for that in the next before_check call? To me that seems like the before_check would then have to be fairly generic rather than state (or transition) specific. If that is the case, it seems like a general system_check that happens before any conditions would accomplish the same thing.\n. Hi @khigia, just wanted to follow-up on this issue. If you can, will you post a pic of the graph with this option enabled and then we can get this merged.\nThanks!\n. Hi @aleneum, sorry it was so long getting back to you on this.\nFirst, I don't like the dot notation at all. Second, it probably makes most sense so I'm not really opposed. I just don't like it. :) I do think the features it provides in this implementation far outweigh the disadvantages although I am also a little concerned about breaking the API. I especially think the actual embedding (vs flattening) moves them toward a true hierarchical SM, which is a lot better.\nI am a little confused by your examples to_stateC.alt.stateD() and on_enter('stateC.alt.stateD','callback'). Is alt the name of the nested FSM? It seems like you are saying stateD belongs to alt which belongs to stateC, is that correct?\n. On Tue, Mar 8, 2016 at 11:58 PM, Alexander Neumann <notifications@github.com\n\nwrote:\nIs alt the name of the nested FSM? It seems like you are saying stateD\nbelongs to alt which belongs to stateC, is that correct?\nYes. stateC has children states and one of them is alt. This state also\nhas children and one of them is stateD. stateD might have children, too.\nI updated my first post to use state1 instead of stateD. It's already\nconfusing enough without me mixing up namespaces of nested states.\nI just don't like it. :)\nhaha, fair enough. The separator is now a class variable which means\ntheoretically you could use any string you like. I opted for '.' because of\nchaining reasons but adding a method like a generic go_to like\nmodel.go_to('stateC<42>alt<42>state1') is not that hard to implement. Or\nyou could play with fire like model.go_to('stateC\u27b3alt\u27b3state1') ;).\n\nFun. I keep telling myself I'm going to map out some cool utf8 symbols for\neasy typing, maybe now's the time! :)\n\nbetter to break it now rather than later. :)\nI could add a fallback. If NestedState.separator=='' then leave out\nFunctionWrappers. In this case the behaviour would not change. I could even\nmake NestedState.separator='' the default value for the first time and\nadd a deprecation warning.\nI like this idea. Certainly we need to give at least one release cycle of\nwarning if not more. Speaking of which...\nBut we should probably mention this change in a parenthetical comment in\nthe docs though (at least for a few months).\nYeah, about that... Most changes done in the bigger refactoring during the\ngraph rework have not been documented yet. For instance the factory and\nmixing model or how graphs work now. I will give it a first shot and would\nbe glad if you could review it then.\nYes, I can help try to make a push to get things updated and get a new\nrelease out.\n\nI think this enhancement should try to make it in that release.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tyarkoni/transitions/issues/86#issuecomment-194216895\n.\n\n\n~Wilfred Tyler Gee\n. Seems like you could just pass some kind of name or id attribute of the FSM to the logger rather than passing multiple loggers around. \nI'm not entirely sure this is something that most users would need and that we would want to incorporate but will wait for other opinions. \n. Do you have some example code that demonstrates the problem and/or solution? Are you using the threaded version of the FSM or just a regular?\n. @khigia the other common idiom would be to have your state logic return the name of the next transition (or state) so that you are making decisions within the state logic but you are just calling the actual transition after the state, as @aleneum suggests.\nMy feeling is we don't need to do anything with this at the moment. @khigia, let us know if that doesn't help otherwise let's close.\n. If your async call is supposed to trigger an event then you should also be able to wait or join from the point where called, which means you could return the name of the transition event rather than just calling it from inside the async call.\nTo a large extent, this overlaps with the questions about a built-in event loop for this library. So far we have avoided that but pointed people in the right direction of how to implement it. Perhaps if we had some example docs with different ways of implementing an event loop. @khigia, are you just looking for a way to run things asynchronously in an event loop of some sort or do you have more specific requirements?\n. :+1: \n. I would say that since the module itself is 'transitions' we can make the\nlinguistic assumption and just go with queued :) However, if we think\nthere will be more than the two options then maybe the\ntransition_strategy is best.  I vote for just queued though, with\nqueued=False as the default.\nNo strong feelings though.\n. I'll fix this up after this weekend when I will have a bunch more time.\n. I made this change. It made more sense to me to have has_queue than to say queued to test the machine. We could add both but it's stored as _queued right now.\n. I'm with @tyarkoni as I think the labels idea is a little better although that still gets a little crowded on any reasonably sized FSM.\n. I just tested on my main machine which is modest (I think?) at 11 states. Each state has one check_safety condition and some of the states have an additional condition. The generated graph is pretty much too large to use. But I guess if you printed it and put it in a wall for reference it would be handy. :)\nI expect not too many people will use this on large machines but it's definitely a feature we should support. \n. After looking at my large graph closer, either there is a bug in the code or this will be really helpful in finding conditions that are applied multiple times.\nIf you look at the park transition on the top it has the check_safety condition listed multiple times and I'm pretty sure my code isn't doing that. I'll look into it more and update shortly.\n\n. @aleneum Got it, sorry. I'm with it now. Is your fix small that you can post a gist here so I can see run it on my actual machine?\n. Great, thanks. Looks a lot better for sure. :+1:\nOn Wed, Jun 1, 2016 at 6:48 AM, Alexander Neumann notifications@github.com\nwrote:\n\nThe relevant part is just two lines in extenstion/diagram.py\nhttps://gist.github.com/aleneum/602def83e94bf4ee38907d8151cef9b6\nproblem is, that label is falsely reused.\nthis\nhttps://gist.github.com/aleneum/602def83e94bf4ee38907d8151cef9b6#file-fix105-diff-L10\nand this\nhttps://gist.github.com/aleneum/602def83e94bf4ee38907d8151cef9b6#file-fix105-diff-L29\nshould be enough.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/107#issuecomment-223054548,\nor mute the thread\nhttps://github.com/notifications/unsubscribe/AAEUUI5DZATKO9RKEVUvKiTfJfSPI7Moks5qHbfygaJpZM4IqgYc\n.\n\n\n~Wilfred Tyler Gee\n. Thanks for catching that @dcere. Similarly, one could hit the same error with a trigger named callback:\n``` python\ndef foo(self): print(\"FOO!\")\ntransitions = [\n    { 'trigger': 'callback', 'source': 'before', 'dest': 'after', 'before': 'foo'},\n]\nmachine = Machine(states=['before', 'after'], transitions=transitions, initial='before')\nmachine.callback()\n```\nAny reason to keep the callback method public? Probably a little less likely, but still might happen.\n. :+1:\n. Hi @AlexPython , glad you are giving it a try.\nI'm not somewhere I can test this, but you'll want to create an instance of your Car object and pass that to the model param.  Something like:\n``` python\nmy_car = Car(...)\n...\nmachine = Machine(model=my_car, ...)\n```\nIf that is still giving you problems we can work through but give that a try.\n. Sorry, took me a while to look a but looks good. :+1: \n. Hi @Cabalist It looks like you are just running an older version of the code. Here's what I'm getting:\n\n. :+1: Looks good to me, thanks @medecau! @tyarkoni @aleneum any concerns?\n. I thought this looked familiar. Sorry about that, I had forgotten about\n106.\nOn Sat, Jul 23, 2016 at 6:14 AM, Tal Yarkoni notifications@github.com\nwrote:\n\nLast time this came up (#106\nhttps://github.com/tyarkoni/transitions/pull/106), it wasn't clear (at\nleast to me) what tox offers that we aren't already doing. I'm not averse\nto adding tox support, but I also don't want to add config files for every\npossible testing package/environment. Practically speaking, what would this\ndo for us?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/123#issuecomment-234644793,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAEUUONtUrwM4X3DkpFhC3SBlZVlE0oGks5qYSS3gaJpZM4JPSno\n.\n\n\n~Wilfred Tyler Gee\n. :+1: \n. Hi @julianhille. That's an interesting idea but not one we've heard that is in high demand. We are trying to keep the library fairly simple and I don't think a lot of people would necessarily have that need, although I can definitely see some uses. Can you provide an example of what you are looking for and how you want to use it.\n. My feeling is that it's not something we would want to support in the main code. If you write it up and do a pull-request we could look into it further but doesn't seem like it would be used frequently. @tyarkoni @aleneum ?\n. @julianhille Would the above solution work in your case?\n. Originally I expected it to be the way that @ahmedabt suggests but have adjusted. We could simply add another logging line that makes it clear it is about to do the callbacks and then keep the line that it has actually entered the state.\n. Works in python 3+ with same versions of graphviz and pygraphviz. I'll check out python 2.7 a little later.\n\n. Also works on pyhon2.7.12 with same library version numbers. I'm not able to test on a windows machine at this time. \nSearching for that error message yields a bunch of people with the same problem and it seems to be traceable to something within pygraphviz so I'm afraid you'll have to go looking there for a solution. Closing for now.\n. I actually have a private method called _lookup_trigger that I use to accomplish this same thing, so I certainly wouldn't be opposed. All of my states are loaded from an external file so my method does the lookup against a _state_table, which is just a yaml document that has been loaded and stored.\nMy method does also offer up a default transition if the requested transition can't be found. Not sure if we would want to build that functionality into it as it would be easy enough to write if someone needed it, but worth considering.\n. :+1: for the simple method. Let's leave the default until later. I don't think it would need a full extension module and I would be a little sceptical to start making too many extensions without a clear need although am not actually opposed.\n. I think I would almost prefer a more descriptive word rather than a semi-private one. Maybe something like do_trigger or call_trigger instead of _trigger, which I think would be more inline with some of our other <verb>_<noun> methods.\n. :+1: \n. Since we implemented a way to call via trigger name in #134 I think that this makes some sense.\nI create my machines from a yaml file and keep the loaded yaml object around to perform this exact same thing. It wouldn't be too much into the core. @tyarkoni, do you have other ideas of things that would go into a MachineUtilities?\n. Eek, sorry, the new github review thing is messing with me. Still need to get lines 158 and 168 changed. Thanks!\n. :+1: I think it sounds like a good idea and I could see both of them being useful.\nDoes it make sense to automatically filter the auto transitions and then make the keyword display_auto_transitions? It might lead to some confusion if people don't read the docs carefully enough.\n(Also, sorry for ignoring this for 17 days...)\n. HI @ketanbhatt. Since we moved to support multiple models (#128) the graph actually became a property of an individual model rather than the machine. So the example is actually correct, however I can easily understand where the confusion comes from. A GraphMachine does have a get_graph method which is meant to be used to get that graph so maybe the example would read better as:\npython\nfrom transitions.extensions import GraphMachine as Machine\nm = Model()\nmachine = Machine(model=m, ...)\nmachine.get_graph().draw('my_state_diagram.png', prog='dot')\nIn the example notebook you can also see how we define a convenience method on the model called show_graph with the point being that it is actually a property of an individual model.\nHowever if all models should always be in the same state this might actually not be that intuitive. @aleneum @tyarkoni it almost seems to me that it makes sense to move the graph back into the machine rather than the model. The graph, after all, reflects the current status of the machine, not of any individual model. Or is there something I'm missing with how the multiple models should be used?\n. @tyarkoni @aleneum right, sorry, now my brain is refreshed on that. I haven't yet worked with it in multiple models and August was the month I was much too busy with other things.\n@ketanbhatt You are most likely on a slightly outdated version from what the documentation reflects.\n. Yeah, it's a little clunky with the anchor but looks a lot better than the free floating version of this. I'll have a chance to test this out on my machines in the next few days but looks good from the overview.\n. :+1: Looks good.\n@aleneum there is a built-in PendingDeprectationWarning that is typically used: https://docs.python.org/3/library/exceptions.html#PendingDeprecationWarning. :+1: . @phpepe I'm closing the issue. Feel free to re-open if you didn't get the answer you need. Thanks!. I do think it makes sense to wrap the calls. However I think that might open up the question of what kind of callbacks people will want to write in MACHINE.before/after such that the question then becomes where do you run the transitions.prepare/conditions/unless. \nPlacing the transition callbacks inside the MACHINEcallbacks makes me think that maybe we want the entire transition logic wrapped. I'm thinking mostly of something like a custom logger or something else at the MACHINE level that would want to help prepare a transition or otherwise know about its failure.. :+1: I just ran this locally against some of my machines and all looks good. I think the issues concerning the warnings are fine in the testing as long as we know they get displayed to the users properly.. Could break some current implementation code but other than that it sees like a sensible change.\n:+1: . :+1: . Did you mean to leave this line in here to show the available options? Would be clearer with a comment.\n. of a graph...\n. Since a model=None currently adds self to the list I don't understand why you wouldn't also just want that functionality here.. @tyarkoni Makes sense. For the future I still think we should assume most uses will have a single model and opt not to break the API, but we can figure that out at that point and don't need to go too much into it here.\nThanks @paulbovbel! Nice clean implementation.. While we definitely want this possible I don't think it is the most typical use case. What about just reversing the logic of add_self so that there is a dont_add_self (with a much better name than that) that would prevent the Machine being added as a model but the default is to add self so the API doesn't break and people can use a Machine in a straight-forward way.. ",
    "kmcnayr": "This is perfect and is along the lines of what I was thinking the answer might be. Thanks a bunch!!\n. ",
    "omago": "Thanks Wilfred,\nIn the meantime i also noticed event.name so i think i will use it.\n. Thanks!\n. Sorry, never mind i will put this to_error part to my condition, so if this condition fails it will trigger some kind of error handler.\n. Thanks for the reply. My view is that \"before\" callback is some kind of preparation stage for the transition, as such my view is that it need to be triggered always. After \"before\" \"condition\" is triggered and \"condition \"is the one that decides about successful transition. After that \"after\" callback is triggered. Also it would be cool to have two after callbacks, \"success\", \"fail\".\n. I think @aleneum did not understand my point. \nMy point was that \"condition\" is triggered before \"before\" and i would expect that \"before\" is triggered before \"condition\". In this situation where \"condition\" is triggered before \"before\" and \"after\" i am not sure what is the difference between \"before\" and \"after\" - if \"condition\" is satisfied both are always triggered.\n. Hi tyarkoni, what about this? Also it would be cool to have two after callbacks, \"success\", \"fail\".\n. ",
    "zrgravity": "I ended up just moving the model to a separate class, as it only required a few lines to be changed (make sure the model isn't inheriting from Machine anymore; that got me for a bit). For me, at least, just updating the documentation to list that condition would be enough.\n. ",
    "centralniak": "Would be great to have this working on the Machine instance too.\n. ",
    "harshi3t": "Is there any way to pass data along with defining conditions using the same data, in a single transition?\nsomething like : \nmachine.add_transition('trigger', 'stateA', 'stateB', before=['set_environment', 'fn1'], conditions=['cond1'])\nHere fn1 and cond1 use the data passed through trigger\n. Adding transitions in the way defined above in the second example gives the following error:\nTraceback (most recent call last):\n  File \"/Users/harshit/PycharmProjects/DialogFlow/Transitions/test.py\", line 24, in <module>\n    lump.melt(temp=45, pressure=1853.68)  # keyword args\n  File \"/usr/local/lib/python2.7/site-packages/transitions/core.py\", line 227, in trigger\n    if t.execute(event):\n  File \"/usr/local/lib/python2.7/site-packages/transitions/core.py\", line 145, in execute\n    machine.callback(getattr(event_data.model, func), event_data)\n  File \"/usr/local/lib/python2.7/site-packages/transitions/core.py\", line 458, in callback\n    func(event_data)\nTypeError: print_pressure() takes exactly 1 argument (2 given)\n. ",
    "TheMysteriousX": "I had a similar requirement for running code on transitions before conditions were checked - I initially did it like this:\npython\ndef condition():\n  action();\n  return real_condition();\nBut if only some transitions have conditions, you either:\n- swap between the above and the before callback\n- write a dummy condition that is always true\nNeither is great for consistency/clarity/maintainability or making code written by users of the library easy to follow.\nI've tidied it up and pushed it to my fork here: https://github.com/TheMysteriousX/transitions/commit/15a683b79610cfdde68a1bcf6770fb646e46f061\nI can send it as a pull request, if desired. Happy to make changes too.\n. Sorry, I omitted that from my post; that action only executes if the transition is valid is a critical point.\nFor a concrete example, I have a command parser, where each commend is a transition. A command comes in, and it is mapped to a transition. If the transition is valid in the current state, then action fires updates the model according to what the command does.\nThere then may or may not be a condition to verify the models state (did the user send us enough information, did they send junk...) before the before/after callbacks fire to cleanup the previous state, and enter the new state.\nThis can all be done without adding an additional callback with workarounds as detailed, but the clarity is much higher and there's no possibility that someone will try and \"fix that condition that's always true\".\n~~~Giving it some additional thought overnight, I have an idea of how this might be implemented without a callback, though it may be too complex to be useful. I'll try and make it work later today.~~~\nI created a working example without a callback by monkey patching methods found to match the transition trigger. This is too fragile though - a similar approach to on_enter/exit_state might work, but I think an additional transition callback is the simplest option.\n. I've no particular attachment to action; from the other suggestions I think either before/after or on_* is fine as long as it's consistent with the rest of the callbacks, so I think changing the names of the existing ones and aliasing them might be sensible.\n. > HierarchicalMachine.add_transition does not include before and before_check\nI'll address this; I thought that the nested stuff hadn't been hadn't been included a release so didn't add before; the missing before_check is an oversight.\n\nI'd prefer a raised error instead of 'automatic fixing' \n\nCan do, that makes things much neater too.\n\nIf the method is named after this leads to an error in name.split(separator)[1]\n\nI'll add a regression test and fix accordingly.\n\nmake separator and callbacks class variables\n\nAs they're constants, the interpreter should optimise them out by in-lining the values where needed. I'll double check what bytecode is actually produced. \n. - The signature inconsistency has been fixed.\n- After thinking about it for a while I realised that the naming of callbacks is completely deterministic; even if someone names a transition something like \"on_exit_A\", it will be correctly handled with the changes in this version, so no exceptions or even log messages (beyond the deprecation warning) needed.\n- In the previous version the constants were indeed optimised out; they're now operated on directly though (cls.seperator.join etc.), so I've moved them to class scope to avoid them being assigned multiple times.\n. That section fixes an edge case where a user has created a transition called transition or check.\nIn this case, you have the callback_type being extracted as either before_transition or before_check with no remainder - name and callback_type will be equal.\nThis could be rewritten like this:\nif name in ['before_transition', 'before_check']\nBut there is a performance hit as in all code paths you're doing a full string comparison.\n\nThis results in outputs like before_transition_transition or before_transition_check. Is that the desired behaviour?\n\nYes - the case we're cleaning up is:\nMachine.add_transition('check')\nMachine.before_check('do_this_callback)  # __getattr__ maps this to before_transition_check\nIs that clearer?\n. You're correct about both of those - looks like I didn't push my branch with my last set of changes (I've done it now).\nI had removed that no longer valid case and replaced it with these two: https://github.com/tyarkoni/transitions/pull/80/files#diff-cc4345db19ff44863e9122c74e9f383fR401\nYour fix there is what I have.\n. No, in this form using cls is more efficient (by about half a second over 20 million iterations). I didn't dig into the reason too deeply but I suspect it's because:\ncls.separator.join(['before_transition'] + name.split(cls.separator)[1:])\nMakes a call against separator directly, so it has to be assigned rather than embedded as a constant.\n. I've renamed before_check to prepare, reverted the before rename and stripped the compatibility code.\nEverything has been rebased onto the current master, so the changeset is nice and clean. It could probably do with someone else giving it a thorough check before merging, in case I went too crazy stripping bits out.\nFrom @aleneum's additional changes in #84:\n- c4fd30b, 2bcf17c, 1fd7ec6\n  Merge commit, git fast forwarded over.\n- a3cfc2c\n  No longer needed as that mechanism has been removed.\n- 7813c5d\n  Manually merged, I'm not sure if the behaviour is right in the original though. Should before_state_change be added to prepare (line 214)? I've assumed not.\nEDIT: I've also noticed that __ methods are checked for twice, so I've added a commit to remove the second, less precise check.\n. > minor doc nitpicking\nFair comment, I'll push a quick fix.\n. ",
    "firefoxbug": "I tested it as you had told, I does works! So appreciated for your help! Awesome project!!!\n. ",
    "stuaxo": "Cheers :)\n. ",
    "Ch00k": "A change in README.md decreased coverage by 0.3%?\n. @aleneum @tyarkoni I agree with your remarks. What I was trying to achieve with this change is indeed quite specific to my use case.\nCommit cf894732f1dabd5bd11c2eab1441d9341a75a38c though is still important as it fixes an issue introduced by my other MR earlier (sorry for that). Perhaps the easiest is to just commit it directly, without the MR.\n. Typo - instantiating.\n. ",
    "hstarmans": "Hi @wtgee,\nMy idea is indeed to use a separate loop to run the actual machine, do computations and listen to responses.\n. Dear @aleneum, thank you for your reply. The fault is in my system, not transitions, see #64.  If i run the code with ipython from the shell, it works. If I run the code using the interactive in Eclipse; Eclipse IDE Version: Mars.1 Release (4.5.1) Build id: 20150924-1200, PyDev for Eclipse 4.5.1.201601132212, Ubuntu 14.04 LTS, Python 3.4 Oct 14 2015, ipython 4.0.1, latest git clone from Transitions. I , still, get False if I transitions between states. I have not been able to resolve it.\nI look forward to the extended documentation. I am especially interested in something similar to the above, that is a machine which is handled by a background process and user can still control in the foreground.\n. Hey @wtgee , I am definitely interested in other solutions. So please share!\nMy objective is to use a flask webserver to control a statemachine. \n. Hey @wtgee, @aleneum and @tyarkoni, thank you for your suggestions. I updated the trafficlight example and moved from threads to coroutines as @wtgee  suggested.\nControl is done via Flask and Tornado with a very basic web frontend. It is based on Python 3.4, so the syntax is a bit dated (no async and await). It might need some further polishing but should run.\n``` python\nfrom flask import Flask, render_template, jsonify \nfrom tornado.wsgi import WSGIContainer\nfrom tornado.web import FallbackHandler, Application\nfrom tornado.ioloop import IOLoop\nfrom tornado import gen\nfrom tornado.locks import Event\nfrom transitions import LockedHierarchicalMachine as Machine\nfrom time import time\nclass Trafficlight(Machine):\n    def init(self):\n        self.timeoutdic = {'run_green': 3, 'run_red': 5, 'run_yellow': 2}\n        states=['paused',{'name':'run', 'children':['green','yellow','red']}]\n        transitions = [\n                       { 'trigger': 'next', 'source': 'run_green', 'dest': 'run_yellow'},\n                       { 'trigger': 'next', 'source': 'run_yellow', 'dest': 'run_red'},\n                       { 'trigger': 'next', 'source': 'run_red', 'dest': 'run_green'},\n                       {'trigger':'pause','source': 'run', 'dest':'paused', 'before':'storestate', 'conditions':'is_running'},\n                       {'trigger':'pause','source':'paused','dest':'run', 'after':'restorestate','unless':'is_running'},\n                       {'trigger':'stop', 'source':'run','dest':'run_green','after':'stopafter','conditions':'is_running'},\n                       {'trigger':'stop', 'source':'paused','dest':'run_green','after':['restorestate','stopafter'],'conditions':'is_paused'}\n                       ]\n        Machine.init(self, states=states,transitions=transitions, initial='run_green')\n        self.running=False\n        self.stopped=Event()\n        self.reinstall()\n    def reinstall(self):\n        self.paused=Event()\n        self.oldtime=None\n        self.elapsedtime=None\n        self.oldstate=None\n    def is_running(self):\n        try:\n            running=self.running.running()\n        except:\n            running=self.running\n        return running\n    def is_paused(self):\n        return self.running.is_set() and self.paused.is_set()\n    def printstatetimeout(self):\n        self.oldtime=time()\n        self.oldstate=self.state\n        if self.elapsedtime:\n            naptime=self.timeoutdic[self.state]-self.elapsedtime\n            self.elapsedtime=None\n        else:\n            naptime=self.timeoutdic[self.state]\n        print('Light is '+self.state+' and on for '+str(naptime)+'s')\n        return naptime\n    @gen.coroutine\n    def loop(self):\n        while(True):\n                nxt = gen.sleep(self.printstatetimeout())\n                yield nxt  \n                if self.stopped.is_set():\n                    print(\"Stop pressed, traffic light stops\")\n                    self.running=False\n                    self.stopped=Event()\n                    break\n                elif self.paused.is_set():\n                    print(\"Pause pressed\")\n                    break\n                else:\n                    self.next()\n    def start(self):\n        if self.is_running():\n            print(\"Traffic light already running\") \n        else:\n            self.running=self.loop()\n    def stopafter(self):\n        print('Traffic light is turned off')\n        print('Waiting '+str(self.timeoutdic[self.state])+'s for all processes to finish')\n        self.stopped.set()\n        self.reinstall()\n    def storestate(self):\n        print('Light is turned off temporarily')\n        self.elapsedtime=time()-self.oldtime\n        self.paused.set()\n    def restorestate(self):\n        self.paused.clear()\n        self.set_state(self.oldstate)\n        self.running=self.loop() \ntrafficlight=Trafficlight()\nFlask\n\nFlask application\napp = Flask(name)\n@app.route(\"/\")\ndef index():\n    return render_template('main.html')\n@app.route('/_pause') \ndef pause():\n    print(\"Command pause received\")\n    trafficlight.pause()\n    return jsonify()\n@app.route('/_stop') \ndef stop():\n    print(\"Command stop recevied\")\n    trafficlight.stop()\n    return jsonify()\n@app.route('/_start') \ndef start():\n    print(\"Command start received\")\n    trafficlight.start()\n    return jsonify()\ntr = WSGIContainer(app)\napplication = Application([\n(r\".*\", FallbackHandler, dict(fallback=tr)),\n])\nif name == \"main\":\n    print(\"Server started\")\n    application.listen(5000)\n    IOLoop.instance().start()\n```\nThe main.html file is as follows:\n``` javascript\n<!doctype html>\n\n\n User access to intenet is required \n\n",
    "GertBurger": "Thanks for the quick response!\nA notice in the README would be a good addition.\n. ",
    "fkromer": "Thanks.\n. ",
    "SteveAmor": "I think this is the same as #9 ?\n. I understand and think it is best to \"create\" the machine and then \"start\" the machine.\nThat is if your final command calls .to_C()  ;-)\n. I just realised, the machine is already running as it alllows you to transition to other states.  So it's not like you're setting it up and then \"starting\" it.\nI agree that the solution is documentation.\n. ",
    "jupiterkenji": "I have this:\ntransitions = [\n    { 'trigger': 'pulse', 'source': 'input', 'dest': 'input', 'conditions': 'IsConditionMet'},\n    { 'trigger': 'pulse', 'source': 'input', 'dest': 'log', 'conditions': 'IsConditionMet'},\n    { 'trigger': 'pulse', 'source': 'input', 'dest': 'display', 'conditions': 'IsConditionMet'},\n    { 'trigger': 'reset', 'source': '*', 'dest': 'input'}\n]\nAs you can see all the conditions are the same i.e. IsConditionMet\nThen I have:\ndef IsConditionMet(self):\n    if self.State == 'input' and dest == 'input':\n        return False\n    .....\n    return False\nThe idea is I don't want to populate my class with each condition in transition.\nI just want to have 1 method.\nPlease let me know if that make sense. I may be having paralysis analysis =)\n. Wow! You are absolutely correct! Thank you for your prompt reply and solution! Awesome module!!!!!\n. ",
    "adam-bishop": "I'm happy to change it to prepare - I've got some time this evening so I'll rebase my changes with the different names, then apply @aleneum 's changes on top where they're still required.\n. ",
    "khigia": "Added a parameter show_conditions to make this behaviour optional (and default is disable).\n. Hum ... sorry, will change again, to follow UML-like notation: transition [condition] / action\n. Sure! Sorry, missed the comment asking for pic :(.\nHere is code example and result in attached png file:\n``` python\nfrom transitions.extensions.diagrams import MachineGraphSupport\nfsm = MachineGraphSupport(\n    states=['A', 'B', 'C'],\n    initial='A', \n    auto_transitions=False,\n    transitions=[\n        {'trigger': 'e0', 'source': 'A', 'dest': 'B', 'conditions': ['ready']},\n        {'trigger': 'e1', 'source': 'B', 'dest': 'C', 'conditions': ['bored'], 'unless': ['bad-c']},\n    ],\n    show_conditions=True,\n)   \ng = fsm.get_graph(title='Condition example', force_new=True)\ng.draw('cond-ex.png', prog='dot')\n```\n\n. Space added around ampersand.\n. IMHO using name or id is not easier; passing a logger allow user to embed any context (using LoggerAdapter) without having FSM code to have more data (name or id); and logger has advantage of having its own logging conf (level etc). It's completely transparent and optional.\nBtw, if this feature is seen as useful (or at least not creating issue I haven't foreseen), I can maybe propose a pull request (to be honest I haven't looked at all extensions code though).\nAnd one last question: is creating issue a good way to propose feature? let me know and I will use the project standard workflow!\nThanks you very much.\n. Pull request created: https://github.com/tyarkoni/transitions/pull/91\n. Hum, in core, having a logger as attribute is nice. But in extensions (because of deepcopy and pickle use) the code is a bit convoluted. Maybe better to close the pull request and add a name attribute to Machine as @wtgee proposed. Let me know.\n. I am using the regular version (I believe the locked version would block).\nHere is an example of code triggering this behaviour:\n``` python\nimport logging\nimport transitions\ntransitions.logger.setLevel(logging.INFO)\nlogging.basicConfig()\nclass Model(object):\ndef on_enter_B(self):\n    print('begin enter B', self.state)\n    self.e1()\n    print('end enter B', self.state)\n\nm = Model()\nfsm = transitions.Machine(\n    model=m,\n    states=['A', 'B', 'C'],\n    initial='A',\n    transitions=[\n        {'trigger': 'e0', 'source': 'A', 'dest': 'B'},\n        {'trigger': 'e1', 'source': 'B', 'dest': 'C'},\n    ],\n)\nm.e0()\n```\nAnd here is the output:\nINFO:transitions.core:Initiating transition from state A to state B...\nINFO:transitions.core:Exited state A\n('begin enter B', 'B')\nINFO:transitions.core:Initiating transition from state B to state C...\nINFO:transitions.core:Exited state B\nINFO:transitions.core:Entered state C\n('end enter B', 'C')\nINFO:transitions.core:Entered state B\nAs we can see, state change during execution of on_enter_B. And logging become rather confusing as we log 'Exited B' before 'Entered B', and after this log line, state is C. Having more callback (before/after) transition would probably be difficult to handle.\nI have not implemented a solution but I believe that queueing call to transitions/core.py trigger method would solve the issue (by queuing I mean delaying the processing, this can be done on same thread).\n. Thanks everyone for your comments.\nI think my example is a bit contrived, as I wanted to highlight the behaviour only. A more realisitc use case is when the on_enter_B trigger an asynchronous call which once executed can trigger an FSM event. As far as my model is concerned, it cannot assume when the async call will be done (it might well be executed right away if the async call is not really async because it is cached etc). This use case exists even in single threaded context.\nWith this async call in mind, I believe state logic defining next as proposed by @wtgee doesn't apply. Using after callback as @aleneum suggested also doesn't solve the situation.\nSupporting the use case, or preventing it, seems both better idea to me than doing nothing (less surprise for user). Preventing seems simple, as it could roughly be done by having a flag executing in the machine, raising exception in trigger if flag is already set and else set/reset this flag around trigger execution. I believe queuing to support the use case is not much more involved: instead of a flag, keep a list of trigger calls, and instead of raising we enqueue current call, instead of resetting the flag we execute next queued call.\nBut first, does the async call use case make sense?\n. I like the fact that transitions lib does not have it's own event loop. This allow user to embed it in many different contexts.\nIn my particular use case, I use it inside a code base which is all async (with future). There is no way I can wait or join inside any function (so not inside a state function). I could attach a continuation function but this defeat the purpose or FSM. This event could happen anytime, and I am using the FSM to track when it happen. As example, let's say I trigger 2 async calls with timeout, I want to use the FSM to keep track (state) of what is happening (both succeed, one first, one fail etc) and use FSM callback to trigger different behaviours on all combination of possible events. If I knew event ordering and waited I would not really need an FSM.\nI think best is for me to try to create a branch for this so discussion will be more concrete. I really appreciate all your comments!\n. Note that the proposed pull request change behaviour: sending event to the FSM cannot have a return value (since it can be queued). I believe this is ok, as FSM is meant to handle behaviour with callbacks and should refrain to give direct control to external interaction. However I see lots of configurations (through ignore_invalid_triggers raising exception) where my assumption is not correct.\n. May I ask if there is any update on this?\n. I understand your concern, it does make code more complicated.\nBut allow me to try to explain why I still think it is a good thing to have in core. Then you can decide one way or the other.\nFirst, why the proposed solutions are not ideal:\n- the Lock machine, in an event based system, is not solving the issue: if the lock block the call, the event system die; if the caller need to use a thread, the event system is not single thread anymore and this propagate back the use of lock everywhere; if the lock is reentrant, then it doesn't delay the event.\n- queue in the model is nice, but force the caller to know when to send event and when to queue event; this break the abstraction of FSM since the caller need to understand the state. Imagine the function on_enter_A trigger an async call; when this call is completed it triggered an event in the state machine; since it is async, I dont know when the result will be available, so I need to have a way to decide if event need to be queued or processed. This function need to understand the state processing of the FSM, and thus this is what I did in the core implementation, making it default for all events.\nSecond, why it seems to me it should be in the core.\nA FSM is supposed to abstract state management. So I find it very surprising to run 'after_state_A' after running 'enter_state_B', I consider this as \"breaking FSM contract\". Imagine a case where the FSM would process multiple events: on_enter_A, trigger an event, which move FSM to B, which trigger event which move FSM to C ... etc up to FSM final state .... and then after_state_A get triggered: isn't it very difficult for the developer to have to know that FSM could be in any state when his function 'after_state_A' is triggered? From concept point of view, I consider the FSM failed to help developer to manage the state.\nAgain, just trying to explain my thoughts, no bad feeling if we close this pull request :).\n. Looks great, thanks! In fact I was almost going to write similar machine config to handle both cases :).\nOnly one small detail: instead of deciding early to call trigger_async or trigger_sync depending on machine.async config, the transition could always call machine _process_async; in that function, depending on async the machine could either process the transition (queue is empty), enqueue (queue not empty and async is true) or raise (something running and not async). This add detection of suspect transition for the non async case.\nAnyway, this fulfil my use case very well!\n. Yes, can be closed, complete functionality is in #96.\n. Not directly related but I had a similar issue when I wanted to graph the * transition.\nWhat I did is an abstraction to describe the state machine, and only when want to use it I create an instance of the state machine using transition lib. That way the abstraction can do the graphing, showing * etc and even having more properties for node and edge.\nI think it would be too much of design change for this lib though.\n. I can't provide code (sadly it's not not open source). But the idea is quite simple. I created a AbstractMachine class, passing the full description at once (I believe it is important to see the transition matrix in one place, not building it iteratively). So it looks like:\n```\nmachine_factory = AbstractMachine([\n  S('state1': [\n    Tr('event0', 'state2'),\n    Tr('event1', 'state3', condition='cond0'),\n  ],\n  S('state2': [\n    Tr('event0', 'state1'),\n  ],\n])\nmachine_representation = machine_factory.graph() # create a graph\nmachine = machine_factory.make(...) # create and return a transition lib Machine type\n```\nThis purposely remove dynamic creation of state, event, transition etc and force user to define the full machine at once (because that is what we use state machine for, for making explicit transition and states).\nHope it help.\n. Moved it.\nReasoning to leave it in AGraph was to get it close to reverse code _transition_label as both are making same assumption on formatting. But it doesn't matter really.\n. ",
    "nskalis": "thanks @tyarkoni for the prompt reply. noted :)\n. hi @aleneum , indeed your suggestion may help.\nbut i would like to underline the importance of having an end__ state defined,\nfor the same reasons that you have an _init state.\nin theory, a workflow defines a starting and an ending point (unless it runs forever).\n. ",
    "coveralls": "\nCoverage decreased (-0.3%) to 97.372% when pulling 818a9ce7ef1fc1740683ea6bed2d3195409c0680 on Ch00k:master into fee785e87373f86923869fe6d1d26bb677d5a8a6 on tyarkoni:master.\n. \nCoverage decreased (-0.2%) to 97.437% when pulling 8441c5030b7fd000962d9697adc8e0ad47bed4d2 on dev-0.4 into 2c1a21bd50ffcb9efa74aa9660e0413d9a3f1408 on master.\n. \nCoverage increased (+0.4%) to 98.057% when pulling 898f97392e6ed482142925432f49a9382203a1af on dev-0.4 into 2c1a21bd50ffcb9efa74aa9660e0413d9a3f1408 on master.\n. \nCoverage increased (+0.7%) to 98.286% when pulling eeff0467996af41b7cbe3b352c7dc0f6b8650880 on dev-0.4 into 2c1a21bd50ffcb9efa74aa9660e0413d9a3f1408 on master.\n. \nCoverage remained the same at 98.286% when pulling 0ec08099480496072cbd4018c1a1ac0b2d01e97e on cleanup into f4437a9022ace2553def4d40b8ba5538151daf98 on master.\n. \nCoverage remained the same at 98.286% when pulling b6c2d52857bd40e6bb56a103c552920804a60237 on rename-graph-machine into 2c946bcefc26f78671d77558e340118ba9dafd08 on master.\n. \nCoverage increased (+0.01%) to 98.24% when pulling de878bcc7fe76838bffa73849778772a9271d6d8 on aisbaa:issues-105 into b68bb05cab0309688fc00b1c71ed9a73fa5d127d on tyarkoni:master.\n. \nCoverage increased (+0.008%) to 98.253% when pulling 3b101fc3c7d95bbe990ec844630d144b4afbb4f5 on async_rename-issues-101 into 9deb2942160394ae365ef652507a3aa45635d47f on master.\n. \nCoverage increased (+0.005%) to 98.257% when pulling 47833e796f0b0e52a0dd7ab696d3290298cdb235 on dcere:master into c0c0341637df20f01492c7d5680661d23473dc32 on tyarkoni:master.\n. \nCoverage remained the same at 98.257% when pulling 5b1428bb2430546d4dfd2dc313cd28d9b9707acf on pr_109 into 7d5f620fc5cfaeedf0808247bc890e9159593666 on master.\n. \nCoverage decreased (-0.8%) to 97.503% when pulling ba0d955248ad7fff803a13dfde2c3fee214c2bc5 on dev_112_113 into 7e3f2dcfe87d9a3df25c982f0e691de444c86b5d on master.\n. \nCoverage increased (+0.02%) to 98.279% when pulling a625690cfe1378c109eb127f759912b527b7eaac on dev_112_113 into 7e3f2dcfe87d9a3df25c982f0e691de444c86b5d on master.\n. \nCoverage decreased (-1.2%) to 97.091% when pulling 892a59c11161ceeff42c3021fb23eb83291dcce8 on pr_119 into aed571c49de4f7e4bf320a381ba612965ff16965 on master.\n. \nCoverage remained the same at 98.299% when pulling e5d80446fbfc559d9435f2b5db7548840d2323e8 on medecau:add-tox into d97a05f2b1227182bc6bffbccb5112ff5513de24 on tyarkoni:master.\n. \nCoverage remained the same at 98.299% when pulling c054ce8528eb8f7bc3e048e22396b9501b7de082 on medecau:add-tox into d97a05f2b1227182bc6bffbccb5112ff5513de24 on tyarkoni:master.\n. \nCoverage remained the same at 98.299% when pulling c054ce8528eb8f7bc3e048e22396b9501b7de082 on medecau:add-tox into d97a05f2b1227182bc6bffbccb5112ff5513de24 on tyarkoni:master.\n. \nCoverage remained the same at 98.299% when pulling 70818d9294d7e75854030b986095737206712394 on medecau:add-tox into d97a05f2b1227182bc6bffbccb5112ff5513de24 on tyarkoni:master.\n. \nCoverage increased (+0.007%) to 98.306% when pulling 67ffc997d2462c3dd57a0fcfee0d50e170a14977 on medecau:test-codestyle into d97a05f2b1227182bc6bffbccb5112ff5513de24 on tyarkoni:master.\n. \nCoverage remained the same at 98.306% when pulling b83f46af82c7e08b507aabe7f4113a4f4671259c on otommod:patch-1 into 5f8bc15e26917fbb30f9aaea43a79f5a4e3b6f54 on tyarkoni:master.\n. \nCoverage decreased (-0.2%) to 98.109% when pulling 158313137e0cde246233b8cd43dd264a0f3f307b on multiple-models into b7ea10b1105bb583fe4616668293037d86ddd5d5 on master.\n. \nCoverage increased (+0.3%) to 98.653% when pulling 22148279097332961e83fcdc9d835e4cf5e8af67 on multiple-models into b7ea10b1105bb583fe4616668293037d86ddd5d5 on master.\n. \nCoverage decreased (-0.05%) to 99.645% when pulling dc8cecc9758a4e532779f292d5355ccb62fb7fdd on dev-string-trigger into d592550cb97a17a9f6989302833d9dd00e9fd260 on master.\n. \nCoverage increased (+0.002%) to 99.696% when pulling 0f54317574565cdf0db45e25d9e9bc455d98fe36 on dev-string-trigger into d592550cb97a17a9f6989302833d9dd00e9fd260 on master.\n. \nCoverage increased (+0.001%) to 99.695% when pulling 5adec03dd83bb5a7aaa0526c1f4ba35835666f5b on dev-string-trigger into d592550cb97a17a9f6989302833d9dd00e9fd260 on master.\n. \nCoverage decreased (-0.05%) to 99.644% when pulling 4d3ddae49895f3f3f028da08985bc67bf93b7f1a on limdauto:feature-conditions-ordered-transitions into d9d9e808efeed3137e086fbece02e7eccc2191ca on tyarkoni:master.\n. \nCoverage remained the same at 99.695% when pulling c58c0b09088fda72b77c332ce0861dbdf968bf18 on ankostis:log_levels into d9d9e808efeed3137e086fbece02e7eccc2191ca on tyarkoni:master.\n. \nCoverage increased (+0.004%) to 99.699% when pulling 74d03e291c28b9bd37ae4611b8acca00e63aab12 on dev_#140 into df2a87563b06a5b4922993e38d332fa27d0fef5f on master.\n. \nCoverage increased (+0.004%) to 99.699% when pulling 74d03e291c28b9bd37ae4611b8acca00e63aab12 on dev_#140 into df2a87563b06a5b4922993e38d332fa27d0fef5f on master.\n. \nCoverage increased (+0.004%) to 99.699% when pulling 74d03e291c28b9bd37ae4611b8acca00e63aab12 on dev_#140 into df2a87563b06a5b4922993e38d332fa27d0fef5f on master.\n. \nCoverage increased (+0.004%) to 99.699% when pulling bb6ad0b94848f7070ad8b082ed78d3fe5b980807 on dev_#140 into df2a87563b06a5b4922993e38d332fa27d0fef5f on master.\n. \nCoverage remained the same at 99.699% when pulling 32c6c7a082534522a43a0af1e290c62bb0fb2c8f on ketanbhatt:patch-1 into 745cf2e0c218b29e06773c4dbee92d5fce1a71ea on tyarkoni:master.\n. \nCoverage remained the same at 99.699% when pulling 60d009f3fb30fb4db48f2961f8c0a2c65a9bbf47 on fix-prepare into 7e7f6c29854dbe66a2a4b67eb8067235e71bc89d on master.\n. \nCoverage increased (+0.02%) to 99.716% when pulling 235ab8de0d9e58458b7b7bb8e930c5014bd2f906 on feature-#147 into bbd1a79b33a5b843004f9b135492e6561681bb7e on master.\n. \nCoverage increased (+0.002%) to 99.701% when pulling 2c3195e1fcf2c5ceacb9f0b96ccab408aa2ba978 on state-refs into bbd1a79b33a5b843004f9b135492e6561681bb7e on master.\n. \nCoverage increased (+0.002%) to 99.701% when pulling f54b8cdabf5d64324547c7c32e2276ad2daec554 on state-refs into bbd1a79b33a5b843004f9b135492e6561681bb7e on master.\n. \nCoverage increased (+0.002%) to 99.701% when pulling f54b8cdabf5d64324547c7c32e2276ad2daec554 on state-refs into bbd1a79b33a5b843004f9b135492e6561681bb7e on master.\n. \n\nCoverage increased (+0.002%) to 99.709% when pulling e91dc26cc983f98de1efb09cbf687c70ca0f557d on paulbovbel:inject-lock into ea939d400ffc215519ea7cc7661b439c8aebae68 on tyarkoni:master.\n. \n\nCoverage increased (+0.005%) to 99.713% when pulling 954b5d68f25554179b82915b395d77d5753a0e7c on paulbovbel:inject-lock into ea939d400ffc215519ea7cc7661b439c8aebae68 on tyarkoni:master.\n. \n\nCoverage increased (+0.005%) to 99.713% when pulling c2bf27a916e666eefbf4bb518181c0e65cf0809b on paulbovbel:inject-lock into ea939d400ffc215519ea7cc7661b439c8aebae68 on tyarkoni:master.\n. \n\nCoverage remained the same at 99.705% when pulling 1a1fb22dd29678e971c1915ccb0bd2f71526269c on sobolevn:patch-1 into 572d6a792ae6b4976059ad800195ae14293f3bd4 on tyarkoni:master.\n. \n\nCoverage decreased (-0.2%) to 99.527% when pulling 681b843e9e9f84511de19c2ee941bc88742a01f5 on paulbovbel:multiple-models into ea939d400ffc215519ea7cc7661b439c8aebae68 on tyarkoni:master.\n. \n\nCoverage decreased (-0.2%) to 99.529% when pulling ebe8cd9ec3010ea185e0d02c11225dc61e7ae5a3 on paulbovbel:multiple-models into ea939d400ffc215519ea7cc7661b439c8aebae68 on tyarkoni:master.\n. \n\nCoverage decreased (-0.2%) to 99.528% when pulling ab00a52e8e10a3f873873c0734851c8b5ec72c8c on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.676% when pulling 54be9e9d24b8b6efbc8e8bd3787a1bf7f96ece6a on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.675% when pulling 54be9e9d24b8b6efbc8e8bd3787a1bf7f96ece6a on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.675% when pulling 774189ac554da63796024180694e356510f5d88a on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.675% when pulling 966fa58d1d3ae51c34efd1996c57095c6981f74f on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.675% when pulling 966fa58d1d3ae51c34efd1996c57095c6981f74f on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.675% when pulling 38fe6169eb29b3973b05669893c87e24f0a0768f on paulbovbel:multiple-models into 15a02d3b5932ad15f72379ae18cb8cc57bd3bd0a on tyarkoni:master.\n. \n\nCoverage increased (+0.0003%) to 99.675% when pulling fcb88090ca4fc5204763f81c33381284d217c71f on cemoody:fix_print_conditions_when_func into 0eccd55bce68f37765fea87b076fc50cebcb02f0 on tyarkoni:master.\n. \n\nCoverage decreased (-0.2%) to 99.505% when pulling a6cbc71c4346c4778aeb92dfd866db07ee2a275f on paulbovbel:add-model-handling into 6221ddbfa4399e96a372db6af0bf93c945236f61 on tyarkoni:master.\n. \n\nCoverage decreased (-1.2%) to 98.435% when pulling c037cf1f5787cc78ec5bbc655e761c1d6349e05e on paulbovbel:add-model-handling into 6221ddbfa4399e96a372db6af0bf93c945236f61 on tyarkoni:master.\n. \n\nCoverage increased (+0.06%) to 99.731% when pulling a00c086cfbf17b712c71519b5cf891396f077f0d on paulbovbel:add-model-handling into 6221ddbfa4399e96a372db6af0bf93c945236f61 on tyarkoni:master.\n. \n\nCoverage increased (+0.06%) to 99.731% when pulling bf9887dea5a70a92ba12b3b35b0747969e6769ce on paulbovbel:add-model-handling into 6221ddbfa4399e96a372db6af0bf93c945236f61 on tyarkoni:master.\n. \n\nCoverage increased (+0.06%) to 99.731% when pulling b23c842b875df63a2dfd3a00a0c00cceb8621a92 on paulbovbel:add-model-handling into 6221ddbfa4399e96a372db6af0bf93c945236f61 on tyarkoni:master.\n. \n\nCoverage increased (+0.003%) to 99.734% when pulling c92604859a9e4050642ef7ef8fa5e1f6ea523a55 on dev-0.4.4 into 8f542727995d744fa7045621b3584495d90a87bb on master.\n. \n\nCoverage increased (+0.003%) to 99.734% when pulling eff8c06071ce4a4ed73a0c4961755cb838ef8277 on dev-0.4.4 into 8f542727995d744fa7045621b3584495d90a87bb on master.\n. \n\nCoverage increased (+0.0001%) to 99.735% when pulling 6173cfcb3c18c85bee1ad5f17e3b2b23aa320b7a on wtgee:parse-version into c643506e11889a88d73c2c0ab5adc0eee2319e0d on tyarkoni:master.\n. \n\nCoverage increased (+0.001%) to 99.736% when pulling db018903e2e3fc819d8684afcee3bac6b7919c32 on ankostis:skipgraphtcs into 9dc9f0fbed0ee50bff3d1e94f69feec3b6c77b4e on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.694% when pulling 3bb0af35427bd8872fcd894d5867a478a5501c08 on ankostis:skipgraphtcs into 1843e512e105104f5708bfa9735009a82ae034e5 on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.694% when pulling 3bb0af35427bd8872fcd894d5867a478a5501c08 on ankostis:skipgraphtcs into 1843e512e105104f5708bfa9735009a82ae034e5 on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.694% when pulling 318f3df52e4a306fedff820ab07b30b7debda0fe on ankostis:skipgraphtcs into 1843e512e105104f5708bfa9735009a82ae034e5 on tyarkoni:master.\n. \n\nCoverage decreased (-0.2%) to 99.559% when pulling 5dc007ebf5765762fa297134a33ec25f39443ea2 on ankostis:repr into 9dc9f0fbed0ee50bff3d1e94f69feec3b6c77b4e on tyarkoni:master.\n. \n\nCoverage decreased (-1.1%) to 98.597% when pulling b9df28134de336d3280d5ffcffc686fac7ad47f0 on ankostis:repr into 9dc9f0fbed0ee50bff3d1e94f69feec3b6c77b4e on tyarkoni:master.\n. \n\nCoverage increased (+0.003%) to 99.737% when pulling d78a09b5f9a1185a4a6b364a49e0fc08918aed89 on ankostis:repr into 9dc9f0fbed0ee50bff3d1e94f69feec3b6c77b4e on tyarkoni:master.\n. \n\nCoverage increased (+0.003%) to 99.737% when pulling 0939e509fcfedff354cf5a1bcc78e0a14d5b6397 on ankostis:repr into 9dc9f0fbed0ee50bff3d1e94f69feec3b6c77b4e on tyarkoni:master.\n. \n\nCoverage remained the same at 99.735% when pulling 595161fb9ded9661e3a64b652ef9ed55906ef8d5 on ankostis:raisevalerr into 9dc9f0fbed0ee50bff3d1e94f69feec3b6c77b4e on tyarkoni:master.\n. \n\nCoverage decreased (-0.04%) to 99.694% when pulling 7cc578aa49676607556256e6a7bbdc69539e3522 on ankostis:raisevalerr into 1843e512e105104f5708bfa9735009a82ae034e5 on tyarkoni:master.\n. \n\nCoverage remained the same at 99.694% when pulling 51cbcd97d08032cf5b938a2c644e438d81a44ce9 on ankostis:raisevalerr into 607b6dd477011006637cea3f77e106464be8dca8 on tyarkoni:master.\n. \n\nCoverage remained the same at 99.694% when pulling 91a269eacb24c6173478a049e9ee3fc03500ddbd on paulbovbel:patch-1 into 607b6dd477011006637cea3f77e106464be8dca8 on tyarkoni:master.\n. \n\nCoverage increased (+0.004%) to 99.698% when pulling c37f5a6c69f8dd8e04e2fe2c5bcbd775c211b479 on feature-#175 into c7c701a257abb84e0ffa3145b01f18493632e07c on master.\n. \n\nCoverage increased (+0.009%) to 99.705% when pulling d410e0433c8f5cd51832801e479e775219a51963 on feature-#175 into 9a5a3f559bb01d5fcd880aff32a28e3e74f7bf7f on master.\n. \n\nCoverage increased (+0.009%) to 99.705% when pulling 2f7c41696a29a2926bd4dc6a7d9c0b5b31dad9be on feature-#175 into 9a5a3f559bb01d5fcd880aff32a28e3e74f7bf7f on master.\n. \n\nCoverage decreased (-0.04%) to 99.67% when pulling cb39638d95e9cdd47f0e88fc45f0a5b55bc1c947 on aforren1:enhance_ordered into 67be2411c0244f3ec661c9d58099cc4303aeaccf on tyarkoni:master.\n. \n\nCoverage increased (+0.1%) to 99.768% when pulling 1d9e10a5d2cce9179ccb8eb9e06b506071bbac62 on dev-0.5 into d7a9b825686cebba5fd282222caf3263e0323d24 on master.\n. \n\nCoverage remained the same at 99.768% when pulling 93e95779dba054b01883ec2d8a08d1e27db25708 on ankostis:projcoords into 3ad59c10f8415827fb6e20fa7c2ad8de7734ac3c on tyarkoni:master.\n. \n\nCoverage decreased (-1.1%) to 98.662% when pulling 1c0c8c98016634cc34cbddb0c5651d89d412db03 on ankostis:projcoords into 3ad59c10f8415827fb6e20fa7c2ad8de7734ac3c on tyarkoni:master.\n. \n\nCoverage decreased (-0.07%) to 99.694% when pulling b8f5e607dbbe7137749081b7663dcca07de0c9f0 on ankostis:projcoords into 3ad59c10f8415827fb6e20fa7c2ad8de7734ac3c on tyarkoni:master.\n. \n\nCoverage decreased (-0.07%) to 99.694% when pulling f63bbf5a9e21d6db47a5bf4ae6b2432e4e29136b on ankostis:projcoords into 3ad59c10f8415827fb6e20fa7c2ad8de7734ac3c on tyarkoni:master.\n. \n\nCoverage increased (+0.002%) to 99.77% when pulling 012b7a01e193582fa0e150550bb0e00945d76e1c on janLo:reflexive-state-notation into 833614e287c8861de45ccb4f584a833c9e70940e on tyarkoni:master.\n. \n\nCoverage increased (+0.002%) to 99.77% when pulling 012b7a01e193582fa0e150550bb0e00945d76e1c on janLo:reflexive-state-notation into 833614e287c8861de45ccb4f584a833c9e70940e on tyarkoni:master.\n. \n\nCoverage increased (+0.002%) to 99.77% when pulling 9faf8e739b6f702e3ebecd09ba28669025db4fd6 on janLo:reflexive-state-notation into 833614e287c8861de45ccb4f584a833c9e70940e on tyarkoni:master.\n. \n\nCoverage increased (+1.6%) to 99.924% when pulling 3761ff141d593894191cd6a1feb930d0397ee331 on adippel:patch-1 into 1c9ea6345d82d9fd099b3d6ae5d84e9604706a15 on tyarkoni:master.\n. \n\nCoverage increased (+1.6%) to 99.924% when pulling 3761ff141d593894191cd6a1feb930d0397ee331 on adippel:patch-1 into 1c9ea6345d82d9fd099b3d6ae5d84e9604706a15 on tyarkoni:master.\n. \n\nCoverage remained the same at 99.962% when pulling 218fa538f1ec10e4b46c5cdc76f51646ccfa6c95 on booware:master into d3d875ca79ee72137a8a24754a79b10873725780 on tyarkoni:master.\n. \n\nCoverage increased (+0.04%) to 99.888% when pulling 33baf47955ba00c382f1f1cda4144a7d29529fb7 on KarolOlko:master into bb3f31c64dfcffbde168caabb31ddab886a55f32 on tyarkoni:master.\n. \n\nCoverage remained the same at 99.888% when pulling 78f0d59f664768f0e5e3095e2cc256d7bf08e2a0 on kunalbhagawati:master into a71107b4b60597b3a5c516cd909ecb26e94372b7 on tyarkoni:master.\n. \n\nCoverage decreased (-0.03%) to 99.854% when pulling 2d099fb09db2ce6a0487c377f6fa5ed3e54d4602 on KarolOlko:master into 23e2b29b7afb41ab9346002c6e1c6c54a195ff7c on tyarkoni:master.\n. \n\nCoverage increased (+0.003%) to 99.89% when pulling 3710fe7fccf36ec2fb9800b3fbd84a5a8edf3b86 on KarolOlko:allow_callbacks_with_less_args into 23e2b29b7afb41ab9346002c6e1c6c54a195ff7c on tyarkoni:master.\n. \n\nCoverage increased (+0.003%) to 99.89% when pulling 3710fe7fccf36ec2fb9800b3fbd84a5a8edf3b86 on KarolOlko:allow_callbacks_with_less_args into 23e2b29b7afb41ab9346002c6e1c6c54a195ff7c on tyarkoni:master.\n. \n\nCoverage increased (+0.003%) to 99.89% when pulling 49bb4d9c7ebe99013d82d26749897cad810e96e3 on KarolOlko:allow_callbacks_with_less_args into 23e2b29b7afb41ab9346002c6e1c6c54a195ff7c on tyarkoni:master.\n. \n\nCoverage decreased (-6.0e-05%) to 99.851% when pulling 11c52cc58195e3a58f669eaa4c5129a494a28e48 on ksandeep:master into ce7e82f63f75a28e826d1c9ecf2c618522942203 on tyarkoni:master.\n. \n\nCoverage decreased (-1.3%) to 98.546% when pulling 4ada1d2b76414b810228dc903c07bd2a1ed482c5 on Synss:dev-state-extensions into 9152f9f5cfcf37ff670a57b3d309ba5c964491ad on pytransitions:dev-state-extensions.\n. \n\nCoverage decreased (-0.07%) to 99.752% when pulling dbafe90c1ee85cfc22cb2d9722bec0010045e3a8 on Synss:dev-state-extensions into 94eae93fbb20b8144a2948897c42ff00e4e1e1e5 on pytransitions:dev-state-extensions.\n. \n\nCoverage decreased (-0.07%) to 99.778% when pulling 1ca302ea8e9aadfbeac61d489304862eccaf089f on Synss:graphing-nameless-callable into 9f7cbe3fa6d371277e35af09f458a4bad9a6fe67 on pytransitions:master.\n. \n\nCoverage decreased (-1.5%) to 98.32% when pulling ef9f4dfb365f0f4aef847255c15ce22f2a23ddb4 on Synss:graphing-nameless-callable into 9f7cbe3fa6d371277e35af09f458a4bad9a6fe67 on pytransitions:master.\n. \n\nCoverage decreased (-0.2%) to 99.673% when pulling 235bfa0da6192088f9e0a39ea0a2349fc1ddcacc on Synss:graphing-nameless-callable into 9f7cbe3fa6d371277e35af09f458a4bad9a6fe67 on pytransitions:master.\n. \n\nCoverage remained the same at 99.854% when pulling 8b5b7f919fa1e641c8c3fc598e10b99225d762fd on jodal:manifest into 12f9b96344b16a67853d0e11f016a12ca29ad3db on pytransitions:master.\n. \n\nCoverage increased (+0.0006%) to 99.855% when pulling 3e59f7ba24019b8d6e6b7e26187b109c0aeb7790 on termim:double_callbacks into db3026aa68c120c0753ecfad6828552e8e7321fc on pytransitions:master.\n. \n\nCoverage increased (+0.0001%) to 99.703% when pulling 09197f9673e885d8e2777f16217cba142d64c26c on Synss:add_transitionS into 1416fa12e8cca7ec450ea24c9a2a38f2d32dfe8f on pytransitions:master.\n. \n\nCoverage remained the same at 99.703% when pulling 06a46b1341db219f920508e3ab746f76b5efd17b on fsismondi:master into 615a63ae0c1ecc26e870c16a04d918558d55a4d4 on pytransitions:master.\n. \n\nCoverage increased (+0.0001%) to 99.703% when pulling dc66f5c8eab4f82e597f69b6597fbe636a5e8700 on tkuester:master into 0e697e2977d5b62ae4ec1ffca16587346f87a96f on pytransitions:master.\n. \n\nCoverage increased (+0.002%) to 99.533% when pulling c6723c009d29b3888005de0fdacff1e6ed82e281 on Synss:get_transitions into 31a586b42617754ba56a8306b1a0ea606d8e9280 on pytransitions:master.\n. \n\nCoverage increased (+0.003%) to 99.534% when pulling 853d829894c7472695fed903072e9ce0d0820efd on Synss:get_transitions into 31a586b42617754ba56a8306b1a0ea606d8e9280 on pytransitions:master.\n. \n\nCoverage remained the same at 99.531% when pulling 94b0255970209682591d0d24275494010c31328a on elipavlov:master into 31a586b42617754ba56a8306b1a0ea606d8e9280 on pytransitions:master.\n. \n\nCoverage remained the same at 99.534% when pulling 91a545c12eeab43444cf082bd68f5eb0461cef96 on illes:patch-1 into 006b177dc8b53434b63b57c321c5e8fb6e7b125f on pytransitions:master.\n. \n\nCoverage remained the same at 89.047% when pulling eb8c4ec01d65df8284677fbb72df4a1dd8d1daf6 on MSumulong:patch-1 into a3a47721dbf1d23623177f305ee20cf29edd161b on pytransitions:master.\n. \n\nCoverage increased (+10.5%) to 99.552% when pulling cb1704887990ed48f6d816d4465080308877d5b6 on quokky:master into 6c89ac27222b62565b976eabf085f4e3cf24e3d8 on pytransitions:master.\n. \n\nCoverage increased (+0.004%) to 99.391% when pulling 3fb5ec82c72f7d23a82627fe0986cecd0a4c427b on maueki:support-internal-transition into 3fa473554d80f9c514ced5ff668199746e835867 on pytransitions:master.\n. \n\nCoverage remained the same at 99.387% when pulling 9981320165187af0f489b2fc06ac2e0570927a37 on Synss:is_alive_fix_call into 3fa473554d80f9c514ced5ff668199746e835867 on pytransitions:master.\n. \n\nCoverage decreased (-1.07%) to 98.328% when pulling 6055ecde8b3e36495e6ea11b389c9d2626f79502 on jodal:fix-py3-install-with-non-utf8-locale into 11a4a3832bddebf3040bc3e8310fcda4fa0ca0f7 on pytransitions:master.\n. \n\nCoverage increased (+1.07%) to 99.403% when pulling 2998a61cc7e877fdda20bcc757b76a8cc6e4ef24 on potens1:master into 9dedc70517a7f30e51e2f5b86c5a26835a03d759 on pytransitions:master.\n. \n\nCoverage increased (+1.005%) to 99.403% when pulling 9699510bd40ad294327b15123c656bed1329503d on cglewis:master into fb6842f5666e3367999d7456e783313ff05742f8 on pytransitions:master.\n. ",
    "rolandettema": "Thanks,\nI want to run the examples in transitions, it gives an error.\nException                                 Traceback (most recent call last)\n in ()\n     13                          auto_transitions=False,\n     14                          initial='standing',\n---> 15                          title=\"Mood Matrix\")\n     16 machine.show_graph()\nCheers Roland Ettema\nVan: Tal Yarkoni [mailto:notifications@github.com]\nVerzonden: donderdag 19 mei 2016 14:33\nAan: tyarkoni/transitions\nCC: Ettema, Roland; Author\nOnderwerp: Re: [tyarkoni/transitions] Error 0777 (#103)\nI think you're confusing the GraphMachine class in Transitions with a separate package in PyPI. If you want to use the Transitions GraphMachine, just import GraphMachine from transitions.extensions. If you want to use the GraphMachine package available on PyPI, you'll need to look for support elsewhere, as we have no relation to that package.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHubhttps://github.com/tyarkoni/transitions/issues/103#issuecomment-220310609\n\nDeze e-mail is uitsluitend bestemd voor de geadresseerde(n). Verstrekking aan en gebruik door anderen is niet toegestaan. Open Universiteit sluit iedere aansprakelijkheid uit die voortvloeit uit elektronische verzending. Aan de inhoud van deze e-mail en/of eventueel toegevoegde bijlagen kunnen geen rechten worden ontleend.\nThis e-mail is intended exclusively for the addressee(s), and may not be passed on to, or made available for use by any person other than the addressee(s). Open Universiteit rules out any and every liability resulting from any electronic transmission. No rights may be derived from the contents of this message.\n. Hi Alex,\nok I will try to follow your suggestions but what I see until know is that I battle dependency with\nbuild\\lib.win-amd64-3.5\\pygraphviz\nMet vriendelijke groet / With kind regards,\nRoland Ettema\nBestuursdienst Open Universiteit\nValkenburgerweg 177\n6419 AT Heerlen\nThe Netherlands\nT: +31 (0) 45-576 2502\nM: +31 (0) 6 15866614\nE: roland.ettema@ou.nl\nwww.ou.nl\n\nFrom: Alexander Neumann [notifications@github.com]\nSent: Thursday, May 19, 2016 18:48\nTo: tyarkoni/transitions\nCc: Ettema, Roland; Mention\nSubject: Re: [tyarkoni/transitions] Error 0777 (#103)\nHi @rolandettemahttps://github.com/rolandettema,\ndid you use PyPI to install transitions? The notebook examples require version 0.4.0 which is not available through PyPI yet. If you want to test the 0.4.0 features right away you need to clone and build transitions from github.\nBest regards,\nAlex\n\ufffd\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHubhttps://github.com/tyarkoni/transitions/issues/103#issuecomment-220384319\nDeze e-mail is uitsluitend bestemd voor de geadresseerde(n). Verstrekking aan en gebruik door anderen is niet toegestaan. Open Universiteit sluit iedere aansprakelijkheid uit die voortvloeit uit elektronische verzending. Aan de inhoud van deze e-mail en/of eventueel toegevoegde bijlagen kunnen geen rechten worden ontleend.\nThis e-mail is intended exclusively for the addressee(s), and may not be passed on to, or made available for use by any person other than the addressee(s). Open Universiteit rules out any and every liability resulting from any electronic transmission. No rights may be derived from the contents of this message.\n. Yes I did, but pygraphviz wants to use a C++ compiler of Microsoft Visual Studio. He cannot find vcvarsall.bat\nlogging:\n[Anaconda3] C:\\Users\\RET>pip install pygraphviz\nCollecting pygraphviz\n  Using cached pygraphviz-1.3.1.zip\nBuilding wheels for collected packages: pygraphviz\n  Running setup.py bdist_wheel for pygraphviz ... error\n  Complete output from command d:\\anaconda3\\python.exe -u -c \"import setuptools, tokenize;file='C:\\Users\\RET\\AppData\\Local\\Temp\\pip-build-vjdb2mku\\py\ngraphviz\\setup.py';exec(compile(getattr(tokenize, 'open', open)(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" bdist_wheel -d C:\\Users\\RET\\AppData\n\\Local\\Temp\\tmpsyh341p7pip-wheel- --python-tag cp35:\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\\lib.win-amd64-3.5\n  creating build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\release.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\version.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz__init__.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  creating build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_attributes.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests__init__.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  running egg_info\n  writing top-level names to pygraphviz.egg-info\\top_level.txt\n  writing pygraphviz.egg-info\\PKG-INFO\n  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n  warning: manifest_maker: standard file '-c' not found\nreading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n  reading manifest template 'MANIFEST.in'\n  warning: no previously-included files matching '~' found anywhere in distribution\n  warning: no previously-included files matching '.pyc' found anywhere in distribution\n  warning: no previously-included files matching '.svn' found anywhere in distribution\n  no previously-included directories found matching 'doc\\build'\n  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-3.5\\pygraphviz\n  running build_ext\n  building 'pygraphviz._graphviz' extension\n  error: Unable to find vcvarsall.bat\nMet vriendelijke groet / With kind regards,\nRoland Ettema\nBestuursdienst Open Universiteit\nValkenburgerweg 177\n6419 AT Heerlen\nThe Netherlands\nT: +31 (0) 45-576 2502\nM: +31 (0) 6 15866614\nE: roland.ettema@ou.nl\nwww.ou.nl\n\nFrom: Alexander Neumann [notifications@github.com]\nSent: Thursday, May 19, 2016 20:31\nTo: tyarkoni/transitions\nCc: Ettema, Roland; Mention\nSubject: Re: [tyarkoni/transitions] Error 0777 (#103)\nI see,\nhave you tried to install pygraphviz via pip as suggested in the ReadMe?\nTransitions can generate basic state diagrams displaying all valid transitions between states. To use the graphing functionality, you'll need to have pygraphviz installed (pip install pygraphviz)\n\ufffd\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHubhttps://github.com/tyarkoni/transitions/issues/103#issuecomment-220411919\nDeze e-mail is uitsluitend bestemd voor de geadresseerde(n). Verstrekking aan en gebruik door anderen is niet toegestaan. Open Universiteit sluit iedere aansprakelijkheid uit die voortvloeit uit elektronische verzending. Aan de inhoud van deze e-mail en/of eventueel toegevoegde bijlagen kunnen geen rechten worden ontleend.\nThis e-mail is intended exclusively for the addressee(s), and may not be passed on to, or made available for use by any person other than the addressee(s). Open Universiteit rules out any and every liability resulting from any electronic transmission. No rights may be derived from the contents of this message.\n. It is undoable to get pygraphviz installed, very pitty that i cannot graphically support transitions in a working example\nThis site helped me a lot https://blogs.msdn.microsoft.com/pythonengineering/2016/04/11/unable-to-find-vcvarsall-bat/\nHowever, I got stuk on not finding graphviz/cgraph.h\n'\ngraphviz.org was unreachable\nMet vriendelijke groet / With kind regards,\nRoland Ettema\nBestuursdienst Open Universiteit\nValkenburgerweg 177\n6419 AT Heerlen\nThe Netherlands\nT: +31 (0) 45-576 2502\nM: +31 (0) 6 15866614\nE: roland.ettema@ou.nl\nwww.ou.nl\n\nFrom: Alexander Neumann [notifications@github.com]\nSent: Thursday, May 19, 2016 21:07\nTo: tyarkoni/transitions\nCc: Ettema, Roland; Mention\nSubject: Re: [tyarkoni/transitions] Error 0777 (#103)\nI cannot help you with that, sorry. But it seems like you are not the only one having issues installing pygraphviz on Windows. You lack the required build tools. Have a look at Stackoverflowhttp://stackoverflow.com/a/28832992/1617563 or MSDNhttps://blogs.msdn.microsoft.com/pythonengineering/2016/04/11/unable-to-find-vcvarsall-bat/. MiniGW is an option. Or just google pygraphviz error: Unable to find vcvarsall.bat. I found many approaches (which I cannot test though).\n\ufffd\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHubhttps://github.com/tyarkoni/transitions/issues/103#issuecomment-220420937\nDeze e-mail is uitsluitend bestemd voor de geadresseerde(n). Verstrekking aan en gebruik door anderen is niet toegestaan. Open Universiteit sluit iedere aansprakelijkheid uit die voortvloeit uit elektronische verzending. Aan de inhoud van deze e-mail en/of eventueel toegevoegde bijlagen kunnen geen rechten worden ontleend.\nThis e-mail is intended exclusively for the addressee(s), and may not be passed on to, or made available for use by any person other than the addressee(s). Open Universiteit rules out any and every liability resulting from any electronic transmission. No rights may be derived from the contents of this message.\n. Alexander,\nI cannot work with the graphmachine it is a library thing. This is a pitty.\nHowever I like the statemachine software a lot!\nI use it in a simulation of a business transaction. What I like to achieve is stochastic behavior between the state changes. For example a state change from A to B occurs\nrandomly and normally distributed.\nIs this a randomly normally distributed state change in your interest?\nRegards\nRoland\n-----Oorspronkelijk bericht-----\nVan: Ettema, Roland\nVerzonden: donderdag 19 mei 2016 20:38\nAan: tyarkoni/transitions; tyarkoni/transitions\nCC: Mention\nOnderwerp: RE: [tyarkoni/transitions] Error 0777 (#103)\nYes I did, but pygraphviz wants to use a C++ compiler of Microsoft Visual Studio. He cannot find vcvarsall.bat\nlogging:\n[Anaconda3] C:\\Users\\RET>pip install pygraphviz Collecting pygraphviz\n  Using cached pygraphviz-1.3.1.zip\nBuilding wheels for collected packages: pygraphviz\n  Running setup.py bdist_wheel for pygraphviz ... error\n  Complete output from command d:\\anaconda3\\python.exe -u -c \"import setuptools, tokenize;file='C:\\Users\\RET\\AppData\\Local\\Temp\\pip-build-vjdb2mku\\py\ngraphviz\\setup.py';exec(compile(getattr(tokenize, 'open', open)(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" bdist_wheel -d C:\\Users\\RET\\AppData\n\\Local\\Temp\\tmpsyh341p7pip-wheel- --python-tag cp35:\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build\\lib.win-amd64-3.5\n  creating build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\release.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\version.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz__init__.py -> build\\lib.win-amd64-3.5\\pygraphviz\n  creating build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_attributes.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  copying pygraphviz\\tests__init__.py -> build\\lib.win-amd64-3.5\\pygraphviz\\tests\n  running egg_info\n  writing top-level names to pygraphviz.egg-info\\top_level.txt\n  writing pygraphviz.egg-info\\PKG-INFO\n  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n  warning: manifest_maker: standard file '-c' not found\nreading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n  reading manifest template 'MANIFEST.in'\n  warning: no previously-included files matching '~' found anywhere in distribution\n  warning: no previously-included files matching '.pyc' found anywhere in distribution\n  warning: no previously-included files matching '.svn' found anywhere in distribution\n  no previously-included directories found matching 'doc\\build'\n  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-3.5\\pygraphviz\n  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-3.5\\pygraphviz\n  running build_ext\n  building 'pygraphviz._graphviz' extension\n  error: Unable to find vcvarsall.bat\nMet vriendelijke groet / With kind regards,\nRoland Ettema\nBestuursdienst Open Universiteit\nValkenburgerweg 177\n6419 AT Heerlen\nThe Netherlands\nT: +31 (0) 45-576 2502\nM: +31 (0) 6 15866614\nE: roland.ettema@ou.nl\nwww.ou.nl\n\nFrom: Alexander Neumann [notifications@github.com]\nSent: Thursday, May 19, 2016 20:31\nTo: tyarkoni/transitions\nCc: Ettema, Roland; Mention\nSubject: Re: [tyarkoni/transitions] Error 0777 (#103)\nI see,\nhave you tried to install pygraphviz via pip as suggested in the ReadMe?\nTransitions can generate basic state diagrams displaying all valid transitions between states. To use the graphing functionality, you'll need to have pygraphviz installed (pip install pygraphviz)\n\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHubhttps://github.com/tyarkoni/transitions/issues/103#issuecomment-220411919\nDeze e-mail is uitsluitend bestemd voor de geadresseerde(n). Verstrekking aan en gebruik door anderen is niet toegestaan. Open Universiteit sluit iedere aansprakelijkheid uit die voortvloeit uit elektronische verzending. Aan de inhoud van deze e-mail en/of eventueel toegevoegde bijlagen kunnen geen rechten worden ontleend.\nThis e-mail is intended exclusively for the addressee(s), and may not be passed on to, or made available for use by any person other than the addressee(s). Open Universiteit rules out any and every liability resulting from any electronic transmission. No rights may be derived from the contents of this message.\n. ",
    "aisbaa": "Yes your right, it is possible to sanitize arguments before interpolating those into string. But sometimes developer (including me) forget to do that. And I want to have static code analysis to detect that during automate testing stage.\nI do agree on your argument concerning method name. Though it seems that transitions does not complain if trigger method name has reserved symbols.\n``` python\nfrom transitions import Machine\ntransitions = [                                         \n    ['event_+', 'a', 'b'],\n    ['event_-', 'a', 'b'],\n    ['event_*', 'a', 'b'],\n    ['event_%', 'a', 'b'],\n]\nmachine = Machine(\n    states=['a', 'b'],\n    transitions=transitions,\n    initial='a',\n    auto_transitions=False,\n)\nprint([method_name  for method_name in dir(machine.model) if 'event_' in method_name])\n\n\n\n['event_%', 'event_*', 'event_+', 'event_-']\n\n\n\ngetattr(machine.model, 'event_+')()\n\n\n\nTrue\n```\n\n\n\nI've tried that on Python 3.4.3, maybe it should be solved by interpreter or maybe it is expected behaviour. But it seems that it is possible to bind methods with unusual names.\nI do agree that it seems odd and maybe even hacky.\nBack to the main question - it would be nice to be able to trigger state change with those symbols, but its not critical feature. And I'm open for discussion how it could be approached.\nThank you and apologies for really long response.\n. I don't mind, both approaches sound sensible.\nwith auto_transitions=False:\n\nwith auto_transitions=True:\n\nAdded a test and naive fix for this issue https://github.com/aisbaa/transitions/commit/de878bcc7fe76838bffa73849778772a9271d6d8 , will try to work on label approach in near future.\n. Hey, thank you guys! :smiley: \n. Will try to do my best. Basically tox tries to minimize differences between all testing environments by providing really strict isolation from system.\n1. It creates separate virtualenv for each interpreter (missing interpreter can be skipped). By running tox you would be running tests on all available python interpreters.\n2. Virtualenv does not include system libraries (unless configured to include) - therefore there is less of a chance that tests run on someones computer and don't run on other because of dependency misconfiguration.\n3. Before running tests it installs latest version of your library into virtualenv, so setup.py gets tested.\nHope this helps!\n. @aleneum yes indeed most is already covered by travis, will close this pull request ;)\n. Just to put my two cents in, have a feeling that tox is becoming de-facto way to test python packages. Tox is like travis on localhost for python libraries. And its really simple to integrate tox into travis, here's example https://github.com/aisbaa/reparse/blob/master/.travis.yml , so you don't have to maintain same configuration in two places.\nPersonally the strongest tox feature to me is its ability to create isolated environment for testing, which in turn reveals missing dependencies. As you can see from changes made by @medecau there are few missing dependencies in  requirements_test.txt file.\n. ",
    "AlexPython": "I tried this, it does not work.\nI also, moved the code to another file (so as to import the model) like this:\n```\n    from .models import Car\n    car_model = Car()\n    another_machine = Machine(model=car_model, states=CAR_STATES, transitions=CAR_TRANSITIONS, initial='on_factory')\n```\nDev server starts, but in shell no object has states: default Car instances know nothing about states, and as for car_model instance referenced in the Machine, it does not exist in shell and can't be imported.\nI copypasted the \"batman\" example and it works fine with a simple class Anything (object).\nAs for Django models, they inherit from Django classes like class Django (models.Model) and some internal mechanics seem to prevent Django models from attaching states.\n. Thanks for the update, it did work!\nI have both good news and bad news from my experiments.\nHere's what works fine\nTo make it simple I created a new model \"AnotherCar\" so as not to mess with existing models, and initialized it in def __init__:\n```\n\n\n\nfrom tools.models import AnotherCar\ncars = AnotherCar.objects.all()\ncars\n[, ]\ncar = cars[0]\ncar\n\ncar.machine.current_state.name\n'on_factory'\ncar.buy()\nTrue\ncar.machine.current_state.name\n'in_showroom'\n\n\n\n```\nBesides  [model].machine.current_state.name syntax, the plain syntax described in the readme works too fine: \n```\n\n\n\nfiesta = AnotherCar(title=\"Fiesta 2015\", color=\"red\")\nfiesta.save()\ncars\n[, , ]\nfiesta.state\n'on_factory'\nfiesta.buy()\nTrue\nfiesta.sell()\nTrue\nfiesta.state\n'sold'\nfiesta.is_sold()\nTrue\n```\n\n\n\nWhat did not work\nHowever, I can't see states as fields in the database.\nAnd Django's filtering does not work, because state is rather a function, not a field:\n```\n\n\n\nfiesta.state\n'sold'\nfiesta.is_sold()\nTrue\nsold_cars = AnotherCar.objects.all().filter(is_sold=True)\n```\n\n\n\nends in error: \n\"Choices are: %s\" % (name, \", \".join(available)))\ndjango.core.exceptions.FieldError: Cannot resolve keyword 'is_sold' into field.\nChoices are: color, id, title\nSame applies to filtering like state='sold', is_sold()=True, etc, which is not valid syntax, I understand.\nDjango does not filter on functions.\nSo, I can't think of a way to filter cars with \"sold\" state, for example, and show them in the template.\nI thought about a workaround with redundant fields\nI could add a redundant physical field like current_state = models.Charfield(max_length=50) and save any current state in plain text with an after transition function.\nThis would be redundant, but all out-of-box Django filtering would work besides the transitions/states functionality.\nAnd the workaround failed\nSince states are not stored in the database, but initialized in def __init__ they're reset to defaults when any query made.\nAbove, I created an entry (fiesta car), updated the state to \"sold\" and saved it.\nAny new query forgets about states:\n```\n\n\n\nimport django\nfrom tools.models import AnotherCar\ncars = AnotherCar.objects.all()\nfor car in cars: print (car.title, car.state)\n...\nFord Focus 2016 on_factory\nFord Explorer 2015 on_factory\nFiesta 2015 on_factory\n```\n\n\n\nQuestions\nI am confused.\nIf purpose of states is to remember the state of each item and process it in code and output, so:\n1. Why initialize machine in class's def __init__ as it resets states?\n2. What is the supposed way to actually save states (not in memory, but in DB)?\n. Thanks everyone for help!\nIn case anyone later will need a quick \"how to\", below is the final working solution:\nTransitions in a Django model.\n```\nclass AnotherCar(models.Model):\n    title = models.CharField(('title'), max_length=100)\n    color = models.CharField(('color'), max_length=50)\n    state_field = models.CharField(_('state field'), max_length=50, default='on_factory', editable=False)\nCAR_STATES = ['on_factory', 'in_showroom', 'sold']\n\nCAR_TRANSITIONS = [\n    {'trigger': 'buy', 'source': 'on_factory', 'dest': 'in_showroom', 'after': 'update_state_field'},\n    {'trigger': 'sell', 'source': 'in_showroom', 'dest': 'sold', 'after': 'update_state_field'},\n]\n\ndef __init__(self, *args, **kwargs):\n    models.Model.__init__(self, *args, **kwargs)\n    self.machine = Machine(self, states=AnotherCar.CAR_STATES,\n                           transitions=AnotherCar.CAR_TRANSITIONS,\n                           initial=self.state_field)\n\ndef update_state_field(self):\n    self.state_field = self.machine.current_state.name\n    self.save()\n\ndef __str__(self):\n    return \"%s %s\" % (self.color, self.title)\n\n```\n. ",
    "jonathanunderwood": "In my work to date, I haven't needed to inherit from State, Transition, or Event - I've only inherited from Machine and HirearchicalStateMachine - I can imagine inheriting from the other extended Machines too.\nThe issue is actually two things: calling super, and also handling args and keyword args in a way that init functions through the MRO can extract their parameters as needed. \nHere's a simple example for the Machine class. Notice that when creating the D instance, neither A or B's init functions are called:\n``` python\nfrom transitions import Machine\nclass A(object):\n    def init(self, *args, kwargs):\n        print('A init')\n        super(A, self).init(*args, kwargs)\nclass B(object):\n    def init(self, *args, kwargs):\n        print('B init')\n        super(B, self).init(*args, kwargs)\nclass C(A, B):\n    def init(self, *args, kwargs):\n        print('C init')\n        super(C, self).init(*args, kwargs)\nclass D(Machine, A, B):\n    def init(self, *args, kwargs):\n        print('D init')\n        super(D, self).init(*args, kwargs)\nprint('Making a C instance:')\nc = C()\nprint('Making a D instance:')\nd = D()\n```\n. Here's a slightly more complicated example showing how arg and keyword arg handling should work...\n``` python\nfrom transitions import Machine\nclass A(object):\n    def init(self, aarg, *args, kwargs):\n        print('A init, aarg:{0}'.format(aarg))\n        super(A, self).init(*args, kwargs)\nclass B(object):\n    def init(self, barg, *args, kwargs):\n        print('B init, barg:{0}'.format(barg))\n        super(B, self).init(*args, kwargs)\nclass C(A, B):\n    def init(self, carg, *args, kwargs):\n        print('C init, carg:{0}'.format(carg))\n        super(C, self).init(*args, kwargs)\nclass D(Machine, A, B):\n    def init(self, darg, *args, kwargs):\n        print('D init, darg:{0}'.format(darg))\n        super(D, self).init(*args, kwargs)\nprint('Making a C instance:')\nc = C(aarg='John', barg='Paul', carg='George')\nprint('Making a D instance:')\nd = D(aarg='John', barg='Paul', carg='George', darg='Ringo',\n      states=['a', 'b', 'c'], transitions=[['A', '', 'a'], ['B', '', 'b'], ['C', '*', 'c']])\n```\n. Informative Stackoverflow on argument passing in multiple inheritance:\nhttp://stackoverflow.com/questions/34884567/python-multiple-inheritance-passing-arguments-to-constructors-using-super\n. Yes - I think that's the right outcome though - none of the init functions were expecting a keyword argument 'foo' so you get an error...\n. Here's another variant based on the Stackoverflow article...\n``` python\nfrom transitions import Machine\nclass A(object):\n    def init(self, aarg, kwargs):\n        print('A init, aarg:{0}'.format(aarg))\n        super(A, self).init(kwargs)\nclass B(object):\n    def init(self, barg, kwargs):\n        print('B init, barg:{0}'.format(barg))\n        super(B, self).init(kwargs)\nclass C(A, B):\n    def init(self, carg,  kwargs):\n        print('C init, carg:{0}'.format(carg))\n        super(C, self).init(kwargs)\nclass D(Machine, A, B):\n    def init(self, darg, kwargs):\n        print('D init, darg:{0}'.format(darg))\n        super(D, self).init(kwargs)\nprint('Making a C instance:')\nc = C(aarg='John', barg='Paul', carg='George')\nprint('Making a D instance:')\nd = D(aarg='John', barg='Paul', carg='George', darg='Ringo',\n      states=['a', 'b', 'c'], transitions=[['A', '', 'a'], ['B', '', 'b'], ['C', '*', 'c']])\n```\n. > As you said, that is intended behaviour but I think it would be nice to process this case to prevent weird error messages for library users. I'd rather expect an Error Message like Machine does not know keyword 'foo' instead of object.init() takes no parameters\nWell... if you're playing around with multiple inheritance, you tend to know enough to be able to work out why that error message occurs. I'm not sure the complexity of calculating the next object in the MRO inside each init function is really worth the benefit to the user. But hey, it's your project and code :)\n. Great, thanks Alex.\n. Do you plan to add the same capability to the extended machines - although I was using Machine for illustration, I actually think it needs adding to the others too for consistency - I was actually using HirearchicalStateMachine in my use case.\n. Hah, no you didn't miss anything - in fact I now remember that was why I used Machine in the examples! I must be getting tired :)\n. Yes, that is a nice interface design, I agree. \"specific\" might be a better keyword than \"strict\", but that's just bike shedding on my part.\nIf you don't want to break people's existing code, I think you'd want strict to default to True.\n. Wow, that was quick work, many thanks!\n. ",
    "ajax2leet": "Hi Alex, thanks for the quick fix!\n. Ah, thats good to know. I'm in fact using python 2.7.3. But dill works fine, thanks!\n. Whops, actually it doesn't work. There seems to be a problem with conditions:\nEdit: Using python 2.7.3\n``` python\nfrom transitions import Machine\nimport dill \nclass Model:\n    def condition(self):\n        return False\nstates = ['A', 'B', 'C', 'D']\ntransitions = [\n    {'trigger': 'walk', 'source': 'A', 'dest': 'B','conditions':'condition'},\n    {'trigger': 'run', 'source': 'B', 'dest': 'C'},\n    {'trigger': 'sprint', 'source': 'C', 'dest': 'D'}\n]\nm = Model()\nms = Machine(m,states=states, transitions=transitions, initial='A')\nm.walk()\ndump = dill.dumps(ms)     \nms2 = dill.loads(dump)\nms2.run()\n```\nThe example raises a PicklingError:\nPicklingError: Can't pickle <class 'transitions.core.Condition'>: it's not found as transitions.core.Condition\n. Unfortunately Cloudpickle doesn't work. I haven't tracked down why, but for my usecase it fails with an AssertionError:\n../lib/python2.7/pickle.pyc in memoize(self, obj)\n....\n242         if self.fast:\n    243             return\n--> 244         assert id(obj) not in self.memo\n    245         memo_len = len(self.memo)\n    246         self.write(self.put(memo_len))\nAssertionError:\n. ",
    "afterlastangel": "Thanks tyarkoni, \nI found the after_state_change that is not mentioned in the homepage. It's useful for me to set the object model state by the machine state. TransitionDefaults is a good idea but it's not our priority right now. \nYour library is very clean and extensible. I built some helpers to get the possible states and triggers from current state (I got idea from your HSM) for my project. \nI hope to contribute to this project in near future ) \n. ",
    "Cabalist": "Excellent!  I just did a pip install. I'll pull from the repo. Thanks!\n. ",
    "medecau": "I was not aware of #106.\n@aisbaa already mentioned the essential points on #106.\nI'll only add that tox or detox make it trivially easy to guarantee all tests are passing before pushing to remote. While travis provides public visibility to other developers that indeed tests are passing.\n. ",
    "julianhille": "I've got some fairly complex logic behind some of my transitions. But this specific state has a specific name called \"new_data_received\" all this logic now is also needed at a another transition which has nothing in common with the old one in case of naming or the cause of the transition only the result/logic is the same.\nAt first i thought about doing just a copy of that transition and give it another name and call internally another function, but then i would have had to copy also a huge amount of unit tests. These are testing the set up of these transition, so this wasn't an option (don't add tests wasn't one either). I also would have had to  edit all other transitions which are involved in the old and the new one.\nAliases didn't exist and so i just added a function to my state machine which calls the other transition but that will lead to \"wrong\" log entries.\nso i thought this would be best implemented as a list of aliases possible to configure at the level of a transition.\n. That would depend on what is logged if this happens:\nmodel.pause()\nprint model.state # >>> stopped\nbut that looks fairly simple and usable to me.\n. ",
    "immae": "Ok, it is already documented, I just misread it...\n. ",
    "gemerden": "Thank you for your quick reply. I think having just the state name in the model is not a problem; it is always possible to access the actual state from the model and from a database persistence point of view having just strings for the state is much easier to handle. \nAfter reading some more of the transitions code i think it would be possible to maintain (just extend) the API, and optionally move all methods (callback, triggers) to the state machine itself, by introducing an optional base class for the models. E.g. for triggers something like this:\n```\nclass BaseModel(object):\nmachine = None # e.g. have one state machine instance for all instances\n\ndef __getattr__(self, trigger_name):  # only called if  trigger_name was not found on the model\n    if trigger_name in self.machine.triggers:  # or some such, maybe not even required\n        return partial(getattr(self.machine, trigger_name), model=self)\n    raise AttributeError\n\nif name == \"main\":\n    class SomeMachine(object):\n        triggers = [\"some_trigger\"]\n    def some_trigger(self, model):  # access to machine and model\n        print \"triggered from \"+ type(model).__name__\n\nclass SomeModel(BaseModel):\n    machine = SomeMachine()\n\nmodel = SomeModel()\nmodel.some_trigger()\n\n``\n. @aleneum: I don't know the code enough to understand theEvent.triggerpart, but in answer to your questions:\n- _Is a one (machine) to many (models) relationship or a many to many relationship desired?:_\n  I could see a use-case for many to many, but our use-case is one-to-many.\n- _Should all models provide all triggers registered in the machine or should the event triggers be spread across all models?_\n  Preferably all state related data and methods be in the machine, and the triggers possibly be made accessible though a call as in the code in my seconds post, so the model would only contain a string for the current_state and a reference to it's state machine (either on class level, as a property or in itsdict`), the state machine would not need the model beforehand, because the model is passed when a trigger on it is called.\n- If add_transition is executed, should that add the trigger to all models related to the machine instance?\n  preferably to the model (reducing overhead)\n- Should the State instances/objects be managed by the machine or also be part of the model?\n  They would be constant and part of the machine instance, the current_state string of the model would be they way to access it's State instance.\n. ",
    "kampta": "Thanks for the quick reply\n. Thanks @aleneum,  I ended up doing the similar thing.\nI think my problem was more in terms of, like we have this * wildcard to go from any state to plasma,\n{ 'trigger': 'ionize', 'source': '*', 'dest': 'plasma' }\ncan we write something like\n{ 'trigger': 'melt', 'source': 'solid', 'dest': '*',  prepare': ['heat_up']}\nwhere dest state  depends on the output of heatup\ndef heat_up(self):\n    if random.random() < 0.5:\n        return 'liquid'\n    else:\n       return 'solid'\n(Not an issue per se, more of a feature request if you think it will be useful)\n. ",
    "thundergolfer": "@aleneum : This wouldn't work there are non-final states with no outgoing transitions, and final states with outgoing transitions. At least there are in the Finite State Machines I am playing with in my Computing Theory textbook. \nA non-final state with no outgoing transitions is sometimes used as a 'fail' state, for example.\n. @aleneum: I think an implicit definition of failed states works fine. \nWould the FSAModel be an extension module of the package?\n. ",
    "imbaczek": "After some playing around I think I could make it work, but it's not perfect. I've tried a different example:\n``` python\ndef make_reusable():\n    states = ['init', 'using', 'done']\n    transitions = [\n        ['use', 'init', 'using'],\n        ['done', '*', 'done']\n    ]\n    return Machine(states=states, transitions=transitions, initial='init')\ndef make_user():\n    # you have to have a concrete machine instance to create a definition a dependent machine which looks wrong\n    states = ['init', 'working', {'name': 'reusing', 'children': make_reusable()}, 'done']\n    transitions = [\n        ['work', 'init', 'working'],\n        ['reuse', 'working', 'reusing_init'], \n        ['done', 'reusing_done', 'done']\n    ]\n    return Machine(states=states, transitions=transitions, initial='init')\nuser = make_user()\nprint(user.state)\nuser.work()\nprint(user.state)\nuser.reuse()\nprint(user.state)\nuser.use()\nprint(user.state)\nuser.done()\nprint(user.state) # reusing_done - expected\nuser.done()\nprint(user.state)  # somewhat unexpectedly: still reusing_done\n```\nThis is an example of how a bug/misconstruction in the reusable state machine renders the parent crippled. This is a proposal I came up with that looks nearly like what I'd want:\n``` python\ndef make_reusable():\n    states = ['init', 'using', PopState('done')]\n    transitions = [\n        ['use', 'init', 'using'],\n        ['done', '*', 'done']\n    ]\n    return Machine(states=states, transitions=transitions, initial='init')\ndef make_user():\n    reusable = make_reusable()\n    states = ['init', 'working', PushState(name='reusing', target=reusable, initial='init'), 'done']\n    transitions = [\n        ['work', 'init', 'working'],\n        ['reuse', 'working', 'reusing'], \n        ['done', 'reusing', 'done']\n    ]\n    return Machine(states=states, transitions=transitions, initial='init')\nuser = make_user()\nprint(user.state)\nuser.work()\nprint(user.state)  # working\nprint(len(user.stack))  # 1\nuser.reuse()\nprint(user.state)  # reusing\nprint(len(user.stack))  # 2\nprint(user.stack[-1].state)  # init\nuser.use()\nprint(user.state)  # reusing\nprint(len(user.stack))  # 2\nprint(user.stack[-1].state)  # using\nuser.done()\nprint(user.state)  # reusing\nprint(len(user.stack))  # 1\nprint(user.stack[-1].state)  # reusing - back to parent state because stack was popped\nuser.done()\nprint(user.state)  # done\n```\nI don't like how the machine reusable instance would have to use the parent's stack but maybe that's fine. Additionally you could have a 'target=\"self\"' for a recursive state machine.\nI think the single biggest reason I've got for push and pop is that I can just do\npython\nfrom common import make_reusable\nand not worry about state names changing in there as long as event names stay the same.\n. I think it would be mostly there, but I'm hitting this sanity check in nesting.py:227:\npython\n            if s.name in duplicate_check:\n                raise ValueError\n(nb. it could use a message, I had to look up what's going on in the source)\nWith a stack or at least a prefix derived from the child machine instead of/in addition to the parent I think it'd be fine.\n. Just added what you recommended to the previous example:\n``` python\nfrom transitions.extensions import HierarchicalMachine as Machine\ndef make_reusable():\n    states = ['init', 'using', 'done']\n    transitions = [\n        ['use', 'init', 'using'],\n        ['done', '*', 'done']\n    ]\n    return Machine(states=states, transitions=transitions, initial='init')\ndef make_user():\n    # you have to have a concrete machine instance to create a definition a dependent machine which looks wrong\n    states = ['init', 'working', {'name': 'reusing', 'children': make_reusable(), 'remap': {'done': 'done'}}, 'done']\n    transitions = [\n        ['work', 'init', 'working'],\n        ['reuse', 'working', 'reusing_init'],\n        ['done', 'reusing_done', 'done']\n    ]\n    return Machine(states=states, transitions=transitions, initial='init')\nuser = make_user()\nprint(user.state)\nuser.work()\nprint(user.state)\nuser.reuse()\nprint(user.state)\nuser.use()\nprint(user.state)\nuser.done()\nprint(user.state)\n```\nIf I run this, I get a ValueError. Python 3.5.1, transitions 0.4.1. Renaming the parent's 'done' to 'done2' makes it run.\n. ",
    "IwanLD": "Yes, I just want to fire a trigger based on a string name.\nThank you, getattr(model, 'my_trigger')()  is sure more pythonic!\nJest ran some tests and set_state really does work on both states and transitions. Was not clear to me from the otherwise great documentation. To me that's rather confusing, since states and transitions are two rather different entities. In my opinion to have set_state() work only on states and add a set_transitions() that works on transitions only would be much cleaner, since else you can come into namespace conflicts - and obviously it is not very intuitive this way.\nSure not critical though, since there is an easy existing workaround. \n. ",
    "limdauto": "Hey @aleneum sorry I've been busy so I forgot about this. I will push an update soon.\n. @aleneum hey sorry I forgot again. I don't think I need this feature anymore and it feels very niche to me so I will close the issue and the PR.\n. @wtgee I'm creating machines through YAML too. Bloody convenient.\n@aleneum One benefit of having the dictionary in memory is the ability to look up eligible transitions for multiple states.\nThanks for your input. I can make a proof of concept for MachineUtilities :+1: \n. @aleneum No, sorry, for example if I have the following transitions\nA -(1)-> B\nA -(2)-> C\nB -(3)-> C\nD -(4)-> E\nI want to get all eligible transitions starting from A and D, which is 1,2,4. I suppose that'd be something like. What is the quickest way to do that? \n. Thanks!\n. ",
    "ankostis": "Also a minor typo at core.py#L163 instead of \"Executing callback...\" --> \"Executed callback...\"\n. I realized i did not pushed over master but on top of dev-0.4.4.\nIf it is a problem, I can rebase.. You mean I should rebase on master, correct?. Please check if my ordering is correct.. (I didn't want to open this can of worms my self... :-)\n...but since it's open, I can make a couple more observations:\n\nHaving separate prepare methods on each transition does not make much sense:\n  Why would you \"prepare\" for a transition that might halt immediately after, in the coming condition?\n  A \"global\" one should suffice.\nI would then couple this new global  prepare with a global finalize at the end, \n  but only if there is not already some MACHINE at the very end (see case B, below).\nRegarding what you discuss @wtgee , I can see at least 3 possibilities:\n\nCase A: this is my original proposal, where a global before/after intermixes with `transition methods:\n\nMACHINE.prepare\ntransition.condition\ntransition.unless\nMACHINE.before\ntransition.before\nstate.exit\n<STATE CHANGE>\nstate.enter\ntransition.after\n\n\nMACHINE.after\n\nCase B: global before/after surrounded by transition methods:\nIn that case (A) I would prefer to look at them as global exit/enter methods (not before/after):\nNotice that there is a need for a global finalize method:\n\nMACHINE.prepare\ntransition.condition\ntransition.unless\ntransition.before\nMACHINE.exit\nstate.exit\n<STATE CHANGE>\nstate.enter\n\n\nMACHINE.enter\ntransition.after\nMACHINE.finalize\n\nCase C: combination of A & B:\n\nMACHINE.prepare\ntransition.condition\ntransition.unless\nMACHINE.before\ntransition.before\nMACHINE.exit\nstate.exit\n<STATE CHANGE>\nstate.enter\nMACHINE.enter\ntransition.after\n\n\nMACHINE.after\n\nIn order not to proliferate the alternatives, and you have to have a case-study model to judge them (e.g. 2-phase commit processors).\nFor instance,   the prepare is way too early to be used for as the 1st phase because no IDs have been generated yet, and generally, data become available after the conditions.\nSo it is the before/after and exit/enter methods that have to curry the burden of that task.\nA final comment is that the code of the project is so well written that it might be possible to support all of the above, and even more (e.g. customizable ordering) without the sources becoming convoluted.. Today I had a nasty bug because there is no global \"prepare\":  I use the same prepare function on each transition, and most of the cases were running, except for those when the side-effect of the 1st call of prepare fiddled with subesquent calls.  And since the ordering of testing transitions is not deterministic, I was bitten badly.\nThe bottom line: this excellent lib needs global prepare/finalize - those on transitions are no substitute.. @aleneum thank you for pointing me #40.\nFrom this fruitful discussion I have the following observations to make:\nFiring patter for a new MACHINE.prepare callback\nI think that the following question of yours has been neglected:\n\nthink this 'prepare condition' thing is quite complex. I can think of at least two different scenarios:\n- prepare -> check -> tearDown -> prepare -> check -> tearDown\n- prepare -> check -> check -> tearDown\n\nI vote the 2nd pattern for all cases A, B, C above, for a newly added MACHINE.prepare; it should fire only once; it is the per-transition declared prepare callbacks that would fire every tried transition.\nMental rule for introducing new callbacks\nAnother insight from #40 is that if we are to satisfy all requirements, the callbacks must proliferate.\nSo I'm proposing as a mental rule to \"ban\" splitting callbacks between machine & transition/state, unless they have a different firing patter (as is the case for the MACHINE.prepare in my paragraph above).\nAnother way of saying this is that if a \"global\" callback can be worked-around by adding the same function to all transitions/states, then this global callback is not needed.\nNote that MACHINE.before/after fall in this category, and they have to be removed, if we were to strictly apply this rule.\nInvoking callback with try...finally\nFinally, I get the feeling that another major functionality, that regards the proposed \"shutdown/cleanup\" callbacks:  the capability to invoke callbacks even if exceptions have been raised earlier.\nWhat are you thought about that?\nRelease plan\nI believe that the last 2 points belong to 0.5.0 release, or even better, to 1.0.0.\nTill then, an intermediate 0.4.4 release may add MACHINE.prepare and reorder the MACHINE.before.. > ...TransitionB.check ... where Machine.prepare is only called once for each trigger, right?\nYes, that's right.\nOtherwise, you have to be very careful not to introduce side-effects in machine.prepare among its multiple calls.  \nSo the machine.prepare must not assume the same concatenate pattern.\n. For the naming I would go for prepare_all_transitions - not all transitions have conditions. [Edit:] Or prepare_before_all_transitions.. What about finalize_after_all_transitions?\nThat may contain an error kwarg holding any catched exceptions?\n(although it is n not accurate because a transition might no have eventually happened). Rebased on top of master + #178, to avoid merging.. Rebased on latest master.. Not an objection, but a wish: \nany thoughts about adding a finalize_after_all_transitions in a finally block that fires once, both for successful/failed transitions?\nShould I open a new issue to discuss ramifications, such as, where to store collected errors. etc?. Created #186 for finalize_after_all_transitions.. Since you named it finalize_event, why not prepare_event, to promote the relationship?. So the prepare/finalize global methods are never executed for \"final\" states, i.e. those without any outgoing transitions on them.\nOk, that's the expected behavior, I guess.\nOr am I missing something here?\nIs it possible to have an event, even for a \"final\" state?\nPS: Naming is the hardest part in programming.\nBut it is fun :-). I would expect that for a \"final\" state, no code should run at all, because there is nothing the user can do to change that.  I mean, it is not that he can try many triggers until the correct one fires - no, there is no correct, trigger, that is a dead-end.  So running code in prepare/finalize would be an undesirable side affect, like opening a db-connection to write empty.\nIf you care to add such functionality, it might be better to have separate global callback, like on_dead_trigger or something like that. \nBut that's my 2cnt on this.\nRegarding the beauty contest, before/after is smooth, but prepare/finalize  has the connotation that the last one gets executed regardless of failures.\nAnd I like the _event suffix because it is not related to a single transition, but all those involved (but I guess that's slightly different meaning of the term \"event\" than yours, I used \"trigger\" for yours).\n(I hope I'm not intervening too much to your mental space). By the way, I hadn't  thought of the dead-trigger subtlety.\nNow I'm thinking that the proper way to deal with it is to invoke a single method on machine(or model), called like triggered_on_final_state() that, by default, throws MachineError.\nActually I was bitten by this problem while developing my model.\nYou see, I'm using YAML-text to setup my transitions, and I had some comma in the wrong place, so an outgoing transitions wasn't declared to the state I wanted (that state was in effect \"final\"), and I couldn't understand why I was getting false, although all conditions were supposed to be true.\nA MachineError would have waked me up.. Setting ignore_invalid_triggers=False does the job also for final-states. \nPlease ignore my last comment!  It It was late at night and never examine carefully what was my issue back then.. So with #184, you have implemented a \"finalizer\" capable of releasing \"resources.\"  \n\nPersonally, I would prefer to let the user handle exceptions. \n\nI understand that handling exceptions becomes a burden. so you prefer to shift that to the user.\nBut handling exceptions is a requirement when emulating commit/rollback  behavior.\nWith #184 as is, a lost of user effort would be needed: capture exceptions inside ALL callbacks, store an appropriate flag somewhere, and then re-raise them.  At least that is my understanding.\nAre we sure this is desired?\n[brainstorming now] should'nt the true/false trigger flag be an attribute of the event_data?\n. > [...] the effort stays exactly the same. [...] This behaviour is not changed because of #184.\nI believe there is a subtle misunderstanding.\nSurrounding model.work() won't help you implement commit/rollback behavior WITH finalize_event callbacks.\nSo if (one of) the point of #184 is to support commit/rollback capabilities, then there is no comparison of the effort; previously you just couldn't implement it centrally, unless you surrounded every trigger point, as you said.\nIs it now more clear what I'm thinking?\n\nAdding result to event_data itself could be done without side effects. This requires a Machine with send_event=True though.\n\nThat could be an interesting opportunity: if you set send_event=true, you get exception capturing for free?. (I'll give it another shot)\nBefore #184, in order to have a resource-cleanup-finalizer, you had to surround every trigger-point in try/except.\nNow with finalize_event you don't have to do that. And that's great.\nBut you still need this try/except for implementing commit/rollback.\nIsn't that a pitty?. You mean a boolean EventData.error attribute?\nYes, that's fine.\nActually much better than the OK flag in kwargs.\n. Then it should be called errored,  no?. Yes, that would be the a perfect solution.  Thanks.. Maybe it should be 0.5.0 because of non-backward compatible changes, such as (at least for what I'm involved) #180, no?. From a user perspective, probably it's better to have a single non-compatible bump, with all changes included, instead 2 conjecutive ones (0.5.x & 0.6.x), no?\nHistory of changes is also simpler (\"0.5.x: incompatible features: blah, blah\").. Please check README as rendered in my branch.. > date -- hmm.. this sounds like something that may end to be cumbersome to maintain\nI know.  I have create a TC just for checking this.\nPractically, the home and ver/rel-dates infos are needed when downloading archives with the sources locally.  So it really pays the effort of keeping it in syncing with version.py.  Besides, how many times you bump version per week?. Forgot to mention that I added a new commit where I extended travisCI to Python 3.5 & 3.6:\n  https://travis-ci.org/ankostis/traitlets/builds/209304857\nAll pass OK!. I'm using a different workflow for my projects, where I bump immediately prior to release,\nand then bump again immediately afterwards, to .dev0 or something like that.\nThe important thing is that anyone taking the sources outside git, know roughly which version he is running.\nOur testers need that info, I agree it might not make much sense in this project.\nThe important thing is to have some idea what are you looking at, from the landing page.\nGreat!. I agree it is small and useful.  The only drawback is that it prevents from using = as a state name (e.g writing a polish machine anyone?).\nBut in such a fringe case, she would have to overwrite ` add_transition(() method, and still survive. \nI would also give a little thought on the symbol, assuming there are more clever shortcuts in the future, and = might be better suited to one of them.\nBesides that, it looks neat.. None is really not helpful, \ni.e. it could mean both SAME('=') and ALL('*').  \nAn alternative would be to use a specific object instances:\npython\nALL = object()\nSAME = object()\ninstead of strings, but that would eliminate the possibility to configure FSM with text (e.g. I'm using yaml in my project).\nSo I'm in favor of using strings because they are both clear and flexible.\n\nHaving \"=\" as a state name is valid at the moment while None is not. \n\nCurrently * is not a valid name for a source-state, unless it is included in a list, correct?\nIn any case, a user can override Machine.add_transition() to cancel the special meaning of '='.\n\ncan be easily done in user code\n\nAgree.  But it is not concise.\n. (sorry to provide feedback so late)\nHave you considered environmental markers?\nhttp://setuptools.readthedocs.io/en/latest/setuptools.html#id15. You can also add environment-markers for extras:\npython\nextras_require={\n    'diagrams:sys_platform != \"win32\"': 'pygraphviz >= x.y.z',\n}\n[edit:] have not tested that it works!. I agree that diagrams should be an optional extras - I consider diagrams an \"interactive\" feature that is a waste of space for headless or unsupervised applications that depend on your library, increasing needlessly the probabilities for a version-conflicts.\nAnd using environment-markers for platform dependent behaviour is obligatory on \"wheels\", where the setup.py script is never executed.. No I have not.\n6 months ago I hadn't managed to install this library - we use graphviz lib instead.. I' not sure how can I locate that line?\nA nice point about unittest.skipIf is that you get the report of skipped TCs at the end.. Can we store the result on the event_data.result so finalize_event knows that?\nDo we have time before 4.4 release?. Why add new var real_dist and not update dest variable in-place, when it is '='?\nIt renders also the else: path unnecessary.. humbled :-). ",
    "guilhermecgs": "Hi Folks,\nI have almost the same need ..  This issue is a must have.. \nAny clues of when this feature will be available?\nPlease don't forget that a state machine can have nested states..\nex:\n\nSo, if you are in \"caffeinated_dithering\" state, the get_triggers_for() would return:\n- Drink\n- Walk\n- ## Relax\n. very thanks!\n. @aleneum , I will do the additional debugging and inform you\nbtw, I can change the state name and make it work. So, it is not something critical...  It is just a curiosity...\n. ",
    "parthsharma1996": "@wtgee  and @limdauto You said that you're using YAML files to store the FSM configuration. Can you give me an example of how you're doing that? Or just pointers in the right direction?. Are there any updates on this? This feature would be super useful!. Pardon me for asking again but are there any plans to implement this? I might be able to help with some PRs. I am using the FSMs for Dialog Management in a chatbot.\nI am more interested in \n\na way to create/control graphs\n\nas I am currently dealing with FSMs with 10-20 states and  40-50 transitions and it would be great to be able to manage all that with a GUI instead of keep adding a dict for each transitions. \nIt gets very hard to get a high level overview of the relationships between states just by looking at the code.\nI am also using a slightly modified and unsupported version (The DepedningMachine you illustrated in #269) so currently visualization isn't working very well either (I'll have to modify the GraphMachine to make that work I assume) . @aleneum Thanks a lot for creating the GUI for transitions! I will check it out! Sorry for the delayed response, I was off from the project for a while.\nRegarding this,\n\nYou probably have to alter the MarkupMachine._convert_transitions link to deal with this:\n{'trigger': 'do', 'source': 'A', 'dest': {'1': 'B', '2': 'C'} , 'depends_on': 'func'} => \n{'trigger': 'do(func=1)', 'source': 'A', 'dest': 'B'} ...\nThis should at also 'fix' the pygraphviz visualization.\nNote that dev-json is WIP and will be rebased to clean up the history when things settle.\n\nI can't find the relevant code in any of the current branches. I assume that this has been changed ? I see markup_transitions instead of the json_transtions in them. \nWhich branch should I currently use? dev-json? \nAlso I don't see anything related to source and dest in the _convert_transitions function in the dev-json branch, so how do I got about converting the required representation :\npython\n{'trigger': 'do', 'source': 'A', 'dest': {'1': 'B', '2': 'C'} , 'depends_on': 'func'} => \n{'trigger': 'do(func=1)', 'source': 'A', 'dest': 'B'} .... Thanks for the example codes @aleneum . I will try and use one of the two approaches. This certainly would be a useful feature for my use-case i.e. Building a chatbot. @aleneum  Also some users mentioned storing FSM configs as YAML files. I'm not entirely sure how to store the python functions in YAML. Could you provide an example of that, if you're aware of this?. @alaneum I posted this on StackOverflow here with relevant tags, however I didn't receive any replies. What would you suggest I do?. Currently I am initializing the Machine inside the model itself i.e.\n```python\nclass Model(Machine):\ndef __init__(self, user, name):\n    ...\n    ...\n    ...\n    Machine.__init__(self, states=self.states_declaration, transitions=self.transitions, initial='bot_greet', prepare_event='extractor', finalize_event='set_response')\n\n``\nI guess thepartial` solution would not work in this case?\nIf not is there anything else that could work? Or I can switch how things are being initialized then.. Thanks a lot! Really makes things easier for me. Learned about the partial in python that I didn't know about earlier :) . ",
    "botzill": "Hi @aleneum,\nHere is a small example of what I mean:\n``` python\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, scoped_session\nfrom transitions import Machine\nfrom sqlalchemy import Column, Integer, String\nengine = create_engine('sqlite:///test.sqlite')\nsession = scoped_session(sessionmaker(bind=engine))\nBase = declarative_base()\nclass User(Base):\n    tablename = 'users'\nid = Column(Integer, primary_key=True)\nstate = Column(String)\nname = Column(String)\n\nif name == 'main':\n    states = ['created', 'validated', 'active', 'inactive']\ntransitions = [\n    ['validate', 'created', 'validated'],\n    ['enable', 'validated', 'active'],\n    ['disable', 'active', 'inactive'],\n]\n\nBase.metadata.create_all(engine)\n\nuser = User(name=\"User1\")\nmachine = Machine(model=user, states=states, transitions=transitions, initial='created')\n\nprint(user.state)\n# output: created\n# but not saved into DB\n\nuser.validate()\nprint(user.state)\n# output: validated\n# but not saved into DB\n\nuser.enable()\nprint(user.state)\n# output: active\n# but not saved into DB\n\n# only at this point we actually save the state into DB\nsession.add(user)\nsession.commit()\n\n```\nWhat would be great to have is for the Machine object to accept a session object and when the state is changed we save it into DB transparently(of course via a different Machine class).\nOf course we can achieve this by methods you mentioned above, but having a standard support for this would be really nice. \nHere we can also encounter scenarios like \npython\nstatus = Column(String, name=\"state\")\nso, the fields which holds the state can have different name in the DB. By having a sort of mapping would help to integrate the  transitions into a bigger project easier. \np.s: I just discovered this awesome library today and maybe it already has some of the features implemented that I'm asking. \nThx.\n. Thx @tyarkoni,\nOf course adding support for this feature is pretty straight forward currently without any additional helpers. But it's always surprisingly good when you get such functionality out of the box :).\nI will play with it and see what I can come up with.\nThx again for the great library which is not yet added in awesome python?\n. Thx @aleneum,\nYou solution is good. I made a small change so that we don't need to pass in the session every time we create a new User object:\n``` python\nBase._session = scoped_session(sessionmaker(bind=engine))\nclass User(Base):\n    tablename = 'users'\nid = Column(Integer, primary_key=True)\nstatus = Column(String)\nname = Column(String)\n\ndef __init__(self, *args, **kwargs):\n    super(User, self).__init__(*args, **kwargs)\n    self._session.add(self)\n\n@property\ndef state(self):\n    return self.status\n\n@state.setter\ndef state(self, value):\n    self.status = value\n    self._session.commit()\n\n```\nAnother solution is to use a mixin, here is a working example:\n``` python\nBase = declarative_base()\nBase._session = scoped_session(sessionmaker(bind=engine))\nclass StatusMixin(object):\n    @declared_attr\n    def tablename(cls):\n        return cls.name.lower()\n@declared_attr\ndef status(cls):\n    return Column(String())\n\n@property\ndef state(self):\n    return self.status\n\n@state.setter\ndef state(self, value):\n    if self.status != value:\n        self.status = value\n        self._session.add(self)\n        self._session.commit()\n\nclass User(Base, StatusMixin):\n    tablename = 'users'\nid = Column(Integer, primary_key=True)\nname = Column(String)\n\n```\nThis way we can add state to an existing model easily. \nTo be honest I'm not sure if the way I did is the right way(taking into account sqlalchemy philosophy, optimization and other), but it's working :).\nThx. \n. OK, just a small update here. The examples above works OK when we initialize the model object ourself(and __init__ is called). But when we make a query then sqlachemy will initialize the model object itself and __init__ is not called(which mean that machine is not initialized). The solution I found so far is to use the sqlachemy events, here is a complete example:\n``` python\nfrom sqlalchemy import Column, Integer, String\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker, scoped_session\nfrom transitions import Machine\nfrom sqlalchemy.ext.declarative import declared_attr\nfrom sqlalchemy import event\nengine = create_engine('sqlite:///test.sqlite')\nBase = declarative_base()\nsession = scoped_session(sessionmaker(bind=engine))\nBase._session = session\nclass StateMixin(object):\n    @declared_attr\n    def tablename(cls):\n        return cls.name.lower()\n@declared_attr\ndef status(cls):\n    return Column(String())\n\n@property\ndef state(self):\n    return self.status\n\n@state.setter\ndef state(self, value):\n    if self.status != value:\n        self.status = value\n\ndef after_state_change(self):\n    self._session.add(self)\n    self._session.commit()\n\n@classmethod\ndef init_state_machine(cls, obj, *args, **kwargs):\n    # when we load data from the DB(via query) we need to set the proper initial state\n    initial = obj.status or 'created'\n\n    machine = Machine(model=obj, states=states, transitions=transitions, initial=initial,\n                      after_state_change='after_state_change')\n\n    # in case that we need to have machine obj in model obj\n    setattr(obj, 'machine', machine)\n\nclass User(Base, StateMixin):\n    tablename = 'users'\nid = Column(Integer, primary_key=True)\nname = Column(String)\n\nevent.listen(User, 'init', User.init_state_machine)\nevent.listen(User, 'load', User.init_state_machine)\nif name == 'main':\n    states = ['created', 'validated', 'active', 'inactive']\ntransitions = [\n    ['validated', 'created', 'validated'],\n    ['enable', ['validated', 'created'], 'active'],\n    ['disable', 'active', 'inactive'],\n]\n\n# Base.metadata.drop_all(engine)\nBase.metadata.create_all(engine)\n\nuser = User(name=\"User1\")\n\nuser.validated()\n\nprint(user.state)\n# output: validated\n\n# extract object from DB and init state machine\nuser_db = session.query(User).first()\n\nprint(user_db.state)\n# output: validated\n\nuser_db.enable()\nprint(user.state)\n# output: active\n\n```\n. ",
    "alexandrenorman": "class Meta is used to specify some options to the model class (https://docs.djangoproject.com/en/1.10/topics/db/models/#meta-options). I used it here to make this class an abstract class.\n. ",
    "shravan-shandilya": "Great! Checked it.Its working.\nThanks\n. ",
    "theY4Kman": "Great job there, coveralls. Really staying on top of things.\n. ",
    "proofit404": "I don't think django integration is necessary as separate extension. There is a convenient way for attaching state machines to django models without any boilerplate. Maybe explicit example in the readme will be sophisticated.\n```python\nfrom django.db import models\nfrom django.db.models.signals import post_init\nfrom django.dispatch import receiver\nfrom django.utils.translation import ugettext_lazy as _\nfrom transitions import Machine\nclass ModelWithState(models.Model):\n    ASLEEP = 'asleep'\n    HANGING_OUT = 'hanging out'\n    HUNGRY = 'hungry'\n    SWEATY = 'sweaty'\n    SAVING_THE_WORLD = 'saving the world'\n    STATE_TYPES = [\n        (ASLEEP, ('asleep')),\n        (HANGING_OUT, ('hanging out')),\n        (HUNGRY, ('hungry')),\n        (SWEATY, ('sweaty')),\n        (SAVING_THE_WORLD, ('saving the world')),\n    ]\n    state = models.CharField(\n        ('state'),\n        max_length=100,\n        choices=STATE_TYPES,\n        default=ASLEEP,\n        help_text=_('actual state'),\n    )\n@receiver(post_init, sender=ModelWithState)\ndef init_state_machine(instance, **kwargs):\nstates = [state for state, _ in instance.STATE_TYPES]\nmachine = instance.machine = Machine(model=instance, states=states, initial=instance.state)\nmachine.add_transition('work_out', instance.HANGING_OUT, instance.HUNGRY)\nmachine.add_transition('eat', instance.HUNGRY, instance.HANGING_OUT)\n\n```. Does this memory usage start immediately at 800m or does it takes some time?. @jxskiss Thanks for your work! If you can provide your solution as example filled with comments, it would be really helpful! I think this topic worth its own page in the documentation.. ",
    "jxskiss": "Has anyone used this in project, I am fixing a memory leak problem after attaching a state Machine to the django object.\nThe problem:\nBefore using state Machine, a django process takes about 100M memory, and with state Machine, it takes about 800M memory (may be more or not, the multiple django processes have exthausted the server's memory and being killed).\nCode:\npython\nclass ItemMachineMixin(object):\n    def __init__(self, *args, **kwargs):\n        super(ItemMachineMixin, self).__init__(*args, **kwargs)\n        self.machine = transitions.Machine(\n            model=self,\n            states=SM_STATES,\n            initial=self.status,\n            transitions=SM_TRANSITIONS,\n            auto_transitions=False,\n            send_event=True,\n        )\nI'm not sure if the problem is related to the state Machine, or am I missing something? Any advise is welcome, thank you.. @proofit404 I'm debugging this issue, by disabling the state machine, in a clean started django (with nginx/gunicorn), processing a django admin request increase the process memory from ~100M to ~250M and stop there, but with state machine enabled, also clean started django with same request, the memory grow up from ~100M to about 4GB (8GB * 48%).\n. Looks strange, but I have no idea how to inspect where the memory goes, is there any instruction to profile django or python's memory problems?. @aleneum The \"memory leak\" issue I mentioned above, as I dive into it, I found it may be not a leak, but an expected behavior.\nIn my situation, there are 7 states, 10 transitions and 4 conditions, according to the way pytransitions working, when a django model object is initialized, there will be more than (7 + 10 + 4 = 21) Machine/State/Transition/Condition objects being initialized, django has cache mechanism for model object for performance, so the huge amount objects will stay in memory, and then the memory blows.\nI suggest don't use this SM for models which have many records, especially for admin usage. Maybe we should mention this someway in the FAQ.\nAlso, as a workaround, a used a custom version of \"fysom\" library to handle the model states, I changed the state machine to be a singleton class, by passing model object as parameter to transitions and conditions.\nThe memory stays about like without state machine and it works well, my project has been published to production about two weeks ago and it works like a charm.\nFinally, I'm very appreciate this awesome project and like to use it in some other situations, thanks.. @aleneum Yes, a model object is a data entry. A global machine is the solution I used finally, but I didn't find an easy setup with transitions, also each model object has its own state, independent with others.\nAs proofit404 mentioned above, I initialized a machine instance (with states, transitions and conditions objects) for each model object. The problem is right here.\nMaybe I used transitions not the right way, glad to know how to use this as global machine or singleton to handler independent state for model objects. Thanks!\nSample code with memory issue:\n```python\nclass ItemStatus(object):\n    NEW = 'new'\n    NEED_INFO = 'need_info'\n    REVIEWING = 'reviewing'\n    REDOING = 'redoing'\n    CONFLICT = 'conflict'\n    VERIFIED = 'verified'\n    DELETED = 'deleted'\nSM_STATES = [\n    NEW, NEED_INFO, REVIEWING, REDOING, CONFLICT, VERIFIED, DELETED\n]\n\nSM_TRANSITIONS = [\n    # trigger, source, destination\n    ['sm_prepare_new', NEW, NEED_INFO],\n    {\n        'trigger': 'sm_commit_review',\n        'source': NEED_INFO,\n        'dest': REVIEWING,\n        'conditions': ['check_review_ready'],\n    },\n    {\n        'trigger': 'sm_done_verified',\n        'source': [REVIEWING, REDOING],\n        'dest': VERIFIED,\n        'conditions': ['check_required_fields', 'check_barcodes_valid', 'check_no_conflict'],\n    },\n    ['sm_mark_conflict', [REVIEWING, REDOING], CONFLICT],\n    ['sm_revert_verified', [VERIFIED, CONFLICT], REDOING],\n    ['sm_require_info', [REVIEWING, REDOING], NEED_INFO],\n    {\n        'trigger': 'sm_mark_deleted',\n        'source': [\n            NEW, NEED_INFO, REVIEWING, REDOING, CONFLICT, VERIFIED\n        ],\n        'dest': DELETED\n    },\n    ['sm_revert_deleted', DELETED, REDOING],\n    {\n        'trigger': 'sm_update',\n        'source': [NEW, NEED_INFO, REVIEWING, REDOING, VERIFIED],\n        'dest': '=',\n    }\n]\n\nclass ItemMachineMixin(object):\n    def init(self, *args, kwargs):\n        super(ItemMachineMixin, self).init(*args, kwargs)\n        self.machine = transitions.Machine(\n            model=self,\n            states=ItemStatus.SM_STATES,\n            initial=self.status,\n            transitions=ItemStatus.SM_TRANSITIONS,\n            auto_transitions=False,\n            send_event=True,\n        )\nclass Item(ItemMachineMixin, models.Model):\n    status = models.CharField(max_length=16, default='new')\n    # many other fields\n```. @proofit404 Thanks, for someone interested with my solution, I have posted it here:\nhttps://gist.github.com/jxskiss/01816eec9a2b64bae341f4d07f58646e. @aleneum Very impressive comparison! There are two points I want to mention:\nFirst, when using Machine.add_model to add an object to the models list, the deconstruction of django model objects should remove the object from models list in some way.\nAnd, as I posted in the gist, I used the Machine as a class attribute, so there will be only one simple Machine object globally without registry, the machine is totally stateless, any object related thing is passed to machine methods as the obj parameter. Though the calling style looks ugly.\n```\nclass ItemMachineMixin(object):\nsm = StateMachine(\n    state_field='status',\n    states=ItemStatus.SM_STATES,\n    transitions=ItemStatus.SM_TRANSITIONS,\n)\n\nUsage:\nobj = Item()\nobj.sm.sm_prepare_new(obj)\ncan use obj.sm_prepare_new() by overriding the __getattribute__ method\n```\nThanks for your instruction about how to use transitions as global machine, quite helpful!. Also as bonus of attaching StateMachine as a class attribute, one can use different state machine for different Django Models within one application, since it's not a really singleton.. @aleneum Thanks for your serious work! Nice way to make \"self\" behave as model by passing to the event as parameter.\nGlad to have another choice \ud83d\udc4d . ",
    "cleder": "I started writing a django_transitions package which will cut the above boiler plate down.\nhttps://github.com/PrimarySite/django-transitions/\n\nExample workflow implementation.\nBase classes and mixins to keep your transitions consistent and avoid boiler plate.\nAdmin mixin to add workflow actions to the django admin.\n. I pushed the package to pypi https://pypi.org/project/django-transitions/. \n",
    "ketanbhatt": "@wtgee so I tested it out, and if I do:\npython\nfrom transitions.extensions import GraphMachine as Machine\nm = Model()\nmachine = Machine(model=m, ...)\nm.graph.draw('my_state_diagram.png', prog='dot')\nI get: AttributeError: 'Model' object has no attribute 'graph'\nIt works if I do machine.graph.draw('my_state_diagram.png', prog='dot'). Can you check if that is the case with you too?\n. Yes that does seem to be the case. I am on 0.4.1, and I installed using pip.\nBut transitions/version.py also says that is the version, and that seems to be the highest number according to tags too. Am I missing something?\n. Okay, thank you. I will close this then.\nAlso, the library is written very beautifully, we are going to use it in our codebase, and it fits in perfectly. \nThank you again.\n. Will update in that case \ud83d\ude04 \n. ",
    "gangefors": "Wow, that was really fast. :+1: \nThanks a lot for handling this issue so fast. Feels like I made the right decision when I chose transitions for my state machine implementation, both feature-wise and issue response time.\n. ",
    "paulbovbel": "Interface fixed, tests pending, thanks for review. test added. Thanks for your patch @aleneum, that did the trick.\n@tyarkoni I'm torn on the set():\nCons:\n- models must be hashable\n- no order of entry (is this a use case?)\nPros:\n- can't register a model twice with a Machine - should this throw an exception, or is it currently considered valid?\n- when removing (TBD) a model from a Machine, there's a clean way to unregister callbacks because the model is guaranteed unique\n- efficiency in add/remove. Looks like the set() implementation wasn't necessary, so happy to unwind.. set reverted to list. In my use case, I'm using re-entrant context managers (an instrumented RLock and django.transaction.atomic), but because of the event frequencies involved, the overhead of triggering the re-entrant behaviour (django generating a save point) ~10+ times for a single trigger is unpleasant.. Thanks! Looking forward to 0.5. defaults that aren't None can have some caveats (http://www.informit.com/articles/article.aspx?p=2314818 Item 20), so I would propose two options:\nOption 1.\ninitial (default None):\nif None, make 'initial' state under the hood. if False, set no initial state. if 'something', make 'something' initial state, must be added in states.\nmodel (default None):\nif None, add self. Otherwise, listify and add as model. If [], would add no models.\n\nOption 2.\ninitial (default 'initial'):\nif 'initial', make 'initial' state under the hood. if falsey (None or False), set no initial state. if 'something', make 'something' initial state, must be added in states.\nmodel (default 'self'):\nif 'self', add self. Otherwise, listify and add as model. If falsey (None or `[]), would add no models.\n\nLet me know which option is preferable, and I will implement as part of this PR.. I guess I see an arg that takes a 'placeholder' like a string and then does something else as dynamic, but that can be argued either way.\nAnyways, will update PR with Option 2-ish.. Not updating this PR.\nI see a lot of tests and README docs that support:\nstates = ['beginning', 'middle', 'end']\nm = Machine(None, states...)\nWhich breaks if meaning of model=None changes.\nSo please evaluate this PR on the merits of not changing the API (where add_self has already gone in), and leave API-refactoring to another contribution.\n\nOption 1 as I outlined above would not break anything, but should still be a separate PR, otherwise this will get out of hand.. Is this current PR unacceptable as-is? It doesn't modify the API ('add_self' already exists, initial=None behaviour is maintained).\nI know an API shakedown tends to drag on, and I'm really keen on getting an 'initial state' arg added to 'add_model' so I can roll transitions into my project. After that I'm happy to participate in a long philosophical discussion on default arguments :). +1, if that's acceptable. I have no problem updating my internal glue code later if there's an API shift for 0.5.. > We could just replace model=None with model='self' as the default value for 0.4.4. In this case warnings are only shown to people which set model=None explicitly. model=None and add_self=True will of course be treated like before. Is that an option?\n+1. Ping for comment and/or merge and/or release. Thanks for reverting that, it was indeed my intent that an empty list would serve as a no-model initialization.\nThe listify behaviour is super handy, but a bit magical and not always obvious. This is exacerbated by Python's false-y evaluation of empty lists, and the expectation that you could hypothetically use a list/dict/etc. as a model (because why not?).\nA split in the API such as add_model and add_models may help to clarify the distinction, and eliminate listify's magic.\nWithout breaking API, it might be helpful to have API docs generated of the package, where the contract of the API, and the input parameters, is more clearly laid out for consumption.. Just noticed this, thought I'd offer an unsolicited outside perspective - I've done a similar thing in the past using a free function helper like so:\nState(name='B', on_enter=import_callable('on_enter_B'), on_exit=on_exit_B),\nIt's nice to keep things like this as standalone helpers rather than core code since it limits the scope/complexity of the internal workings of a library like transitions.. I've used this library with ROS quite a bit. There's nothing special about how to use it with rospy in a 'node-based approach', just import it as you would any other python library, and go to town.. agreed. There are a LOT of internal enter/exits. I suppose this is because core.Machine.getattr and core.Machine.getattribute are monkey patched as well.\nIt would be nice if calling one trigger only required one lock cycle, but I'm not sure how that could be accomplished.\nFor now, any contexts must be (low cost) re-entrant.. You're right, no monkey patching, just wrapping.. I had initially intended to implement a state.remove_callback, until I realized that this is adding a string and not an actual function callback (which would have created a reference) to the string.\nIs there any harm in leaving stale callback registrations on the state object?. I'm not sure I understand the purpose of this function, as every time a model is added, if it has the method model.on_enter_<state>, state.add_callback will add an instance of the string \"on_enter_<state>\" to the list State.on_enter. +1 to change on major version, API compatibility is king. added. Actually, add_self=False and no model is exactly the use case i'm interested in: definining a singleton, long-lived machine object, configuring all it's states/transitions up front, and then add/remove models (in-memory cache from db data) on the fly.\nI also like the possibility of not instantiating a magic 'initial' state, which is only possible if no models are specified and no initial arg is provided.\nWhat kind of weird effects do your foresee?. Agreed re 0.5.x, in the meantime, can we keep add_self to maintain current behaviour/API but enable my use case?\nSometimes it doesn't make sense to provide an 'initial' state. In my case, I'm loading/unloading models all the time as they get cached from the db, meaning their 'initial' state is actually whatever the DB says.\nI think the MachineError here makes sense as currently implemented (if no default 'initial' and no 'initial' in add_model) but i'm totally open to alternatives.. That might be getting too clever:\n```\ninitial=False - no initial state, Error if models provided or add_self=True in init\ninitial=None - default, create 'initial' state for machine\ninitial=something - must be a valid state in machine\n```\nTorn whether implementing that is worthwhile rather than just enforcing that SOME initial state is provided. However, that would allow initialising a machine with nothing, and then dynamically adding states, transitions and models piecemeal.. ",
    "merinom": "Okey!, thank you for responding so quickly, I'll see what I can do.\n. I thought about something similar to that, but your solution is clearer. \nThank you again. I'm sure that this topic will be useful to more people.\n. ",
    "renatosamperio": "This looks useful!\n. ",
    "vishwa15": "Yes. Got it. Thank you!!\nOn Mon, Nov 28, 2016 at 11:00 PM, Alexander Neumann \nnotifications@github.com wrote:\n\nHi @vishwa15 https://github.com/vishwa15,\nfor this purpose we have introduced the queued option which will process\ntransitions sequentially.\nfrom transitions import Machine\nstates = ['asleep', 'hanging_out', 'not_hungry', 'hungry']\ntransitions = [['work_out', 'hanging_out', 'hungry'],\n               ['not_work_out', 'hanging_out', 'not_hungry'],\n               {'trigger': 'wake_up', 'source':'asleep', 'dest': 'hanging_out', 'after':'check'}]\nclass Model():\ndef check(self, energy):\n    if energy > 50:\n        self.work_out()\n    else:\n        self.not_work_out()\n\nmodel = Model()\nmachine = Machine(model, states=states, transitions=transitions, queued=True, initial='asleep')\nmodel.wake_up(energy=80)print(model.state) # >>> hungry\nmodel.to_asleep()\nmodel.wake_up(energy=30) >>> not_hungryprint(model.state)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/tyarkoni/transitions/issues/160#issuecomment-263336484,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AI5k35Jc-k5mfMu1zwZfZBuP_apkCAIIks5rCw-mgaJpZM4K5QnH\n.\n. \n",
    "valste": "Many thanks!\nval. Very good idea! -> upvote. Me again guys :)\nCan't get run the above code.\nPlease take a look at http://stackoverflow.com/questions/43275092\nWhat the ... ;)  \nThanks!\n. My next try to implement default timouts using def _create_state(self, *args, **kwargs) fails permanently on exiting the states.\nPlease see the issue on stack http://stackoverflow.com/questions/43937365/setting-and-canceling-of-predefined-timeouts-for-hierarchical-state-machine-fail \nThnx!. ",
    "peendebak": "@aleneum Thanks for the reply. Your example already helps, but I want the callback to apply to already existing states.\nAfter creating a machine with a state and transitions I want to automatically create a GUI that shows the current state and has options to change the state. If the machine changes state through some other way. I want this to be reflected in the GUI. E.g. after changing the state I want to call gui.update. \nI create the gui after creating the machine, so the gui can use machine.states to build the interface.. ",
    "phpepe": "Ok I will answer myself, I just found a reference on the EventData object, so can be done in this way:\ndef condition(self, event, **kwargs):\n        print 'event', event.transition.dest. ",
    "oz123": "@aleneum it is possible to use trollius  for having asynio with Python 2.7.\nhttps://pypi.python.org/pypi/trollius. The is indeed very smart way of doing that! Maybe we should just this to the documentation, and avoid messing around with the Machine class.. ",
    "Kosyne": "@aleneum Yeah, that bits a no-go. I could actually probably get by with the reverse, lol (events sync, callbacks async) . I'm writing a discord bot using discord.py for python 3.4+, and I need practically every callback to be called asynchronously, as discord.py's API is full of coroutines.\nThe exact case is making a state-based jukebox for the bot (playing/paused/idle/etc), and I want each of the callbacks to be able to be awaited/yielded from.\nI hacked together the jankiest (but somehow still functional) version of this by 'async def'/'await'-ing anything relating to the callbacks and triggers in 'transitions/core.py', hah. That resulted in both events and callbacks being async, and thus needing to be 'await'ed, which my desired behavior. I haven't encountered anything screwy yet, but I'll definitely look into some of the above methods though, because I really don't like the idea of having to maintain my own hacked-up version of this alongside my other projects.\n(And sorry for late reply, github alerts me for all sorts of things... but not this thread. Go figure) . The triggers are setup to be async as well, and I have each command (from the on_message event) put into a queue where each trigger is awaited, so it does not continue until the trigger in question is fully resolved. Thus far, I haven't ran into such issues, but I'll definitely be keeping an eye out for them in case, and will also be giving LockedMachine a try. Hopefully though, sometime in the future, maybe we could see a (very much optional) extension for something like an AsyncMachine :). ",
    "ivanteresh": "Hello, @aleneum.\nI'm currently working on a project based on the principle of chat-bot. In it, I use pytransitions to handle the current state of the bot dialog with the user. To support the asynchronous processing mode, I wrote my own extension for a state machine. In it, I was able to create an event trigger, all callbacks and even conditions checks are asynchronous. The order of the callbacks is saved and works as expected. What do you think about if I send you a pull-request for review?. @idf Thx for testing. I also test my solution in my project, and it works good for me. But finally, i think it is not enough good to be the part of main library. It contains a lot of copy-past and rewritten core classes and methods, which will be hard to maintain in the future, in case if any code in core will be changed. Also, AsyncMachine can't take part in inheritance with other extension classes, as NestedMachine, GraphMachine, LockedMachine, etc. \nI think, for now i keep this code in my fork brunch, until I find a better solution, which is really good for inclusion in the main branch. Unfortunately, now I do not have free time to do this.. I think we should wait and take a look wait for @lromor solution. As he said, his solution looks more interesting.. ",
    "lromor": "+1 for this feature, @ivanteresh could you provide a link to your patch? \n. Hello @aleneum , \nfirst of all, I forgot to thank you for your work, it's a very well done project.\nI will be a bit verbose on this post, sorry for that.\nSo, we are working on a real machine and we wanted to have a more consistent way to define its behavior.\nOur problem\n(it's just to share our view, it may be important for you in order to understand if we match or not transitions goals):\nOne of the biggest problems introduced by the async (or also with safe multithread) paradigm is that for big projects (without an FSM) a lot of states variables are spread around the program pinning down the machine behavior becomes a difficult task. Similar problems are encountered for example while building async/event driven web interfaces. It can really become a mess when you start triggering a lot of changes at the same time and you don't really know what is the flow of your program anymore (see flux paradigm).\nSo we decided to introduce an FSM that centralizes all of this logic making the program hopefully more consistent and ease the testing process.\nRegarding your questions:\n\n\nShort answer: Before/on_enter after/on_exit is in my opinion the way to go.\nLong answer: I think that for our use case, actions should be mapped as states. \nWe require the possibility to change an action if, for example, during \"running\" a stop event occurs. \nTransitions should always be immediate. \nI think that modeling actions with transitions may introduce some flaws that would lead us to merge the states logic to the transitions one (e.g. we will need to define if allow or do not allow to transition from a transition to another state).\nIn general, in order to avoid to keep track of all the asynchronous tasks spawned by a state on_enter/on_exit a better approach would be to allow an optional state's task. \nI can send you a complete example of what I mean. \n\n\nI think that the async loop should be managed externally. Mostly because there's no real reason to force this requirement.\n\n\nWhat do you think?\n-l\n. Hello @aleneum ,\nI wanted to ask you if you are already working on this, if you need someone to test or if you need patches.\n-l. @aleneum  \nI think that is a very nice start. I was going to do something similar but didn't know which methods were to be overloaded.\nTo fully use it I'm gonna use some StateHandlers that automatically register a state task\non enter while on_exit I can cancel that task and await for it to finish.\nIn this way I can avoid rogue tasks spawning around.\nThank you @aleneum and @ivanteresh .\n-l\n. Hello @aleneum I wanted to update you about what we did, just in case someone wanted the to achieve the same result.\nIn this sense, I wanted a nested asynchronous machine, as you pointed out, is not so easy to do that via mixins. So I had to override a bunch of functions similarly to what @ivanteresh did. \nWe are happy about the result, we also added an async lock for the transitions in order to avoid callbacks race conditions, etc.. so we keep the promise that transitions must be immediate but we introduced the concept of a state handler which is spawned and killed on_enter and on_exit.\nWe also started adding some tests. \n-l\n. thank you @aleneum ! . ",
    "lucalenardi": "+1 for asyncio support.. ",
    "pfertyk": "+>>> mm = MyMachine()\n+>>> mm.machine.get_triggers('victorious')\n['to_victorious', 'to_in_danger', 'to_defeated', 'back', 'to_escaped']\nIs there a way to leave just the method names? In this case, to skip everything that starts with 'to_' and leave just ['back']? I know I can filter the list manually, but what if I create a trigger that actually starts with 'to_'?. That is exactly what I was looking for ;) Thanks for a quick response and forgive me for not reading the README file closely enough.\nThe issue can be closed.. ",
    "aforren1": "Sure! I messed up the merge and fixed a few things, so now it's 7ab6ee5eef7377a12d03aa3518abe81a2240da37 for reference (and PR is #193). . ",
    "janLo": "Well, the code is minimal, it's fully tested and documented. The idea came from fysom. I needed in a project and I thought it's small enough to be done in the library instead of explicitly writing all the states ore having them generated outside.. I added both cases to the docstring.\n. As said, I choosed = because its used in other projects. that provide state machines for this purpose. I've no preference about the symbol, but I think None might cause more confusion than = as it has no semantic meaning like \"same\" or \"equal\".\nIn the end its the same as * just syntactic sugar. As that I think it should be easy to read and understand.. I fully agree with @ankostis on the preference of strings over objects or None. If conflict with = as a possible state name I would go for making it configurable as keyword arguments on initialization of the machine. Like \npython\ndef __init__(self, model= ..., wildcard_char='*', same_char='='). What is the status now? Can this be merged or shall I make the chars configurable?. I'm fine with the current state, but I will change it to a class or instance property if preferred. Just tell me what to do to get it merged.. This is because if you have more than one source (more than one iteration of the loop there), then after the first loop the value of dest is not = anymore and the destination for all created transitions is the first source state.. ",
    "Eric24": "Yes, that's essentially my current approach. I'm curious as to why you feel that this shouldn't be part of the state machine \"internals\"? To me, it seems like \"core functionality\", and as such, why trouble the developer to handle their own timeouts explicitly? For my purposes, having 30 or more states, most with timeouts, it seems like a lot of unnecessary boilerplate.. ",
    "bedge": "I got here looking for the same thing. Built-in support for timeouts would make for less overall LOC in the client apps. \nGreat idea. Just to add my $.02, I ended up just using threading.Timers:\n```\n    def timer_poll_start(self, event):\n        self.timer_poll = Timer(poll_interval, self.timer_poll)\n        self.timer_poll.start()\ndef timer_poll_cancel(self, event):\n    self.timer_poll.cancel()\n\n```. What restrictions does this place on code that uses timeouts? Presumably it needs threads, which precludes the ability to use joblib in the same process (with python 2.x only anyway)\nI've already solved this problem by separating my concurrent code in a different process, but I'm curious if the implementation has the same restrictions as I ran into.. I believe that the threading restrictions are mainly python <3 only and that >3 has fixed many of the threading problems and inconsistencies.\nThat said, I've been stuck in a 2.7 world so my experience with 3.x is limited to lusting while window shopping.  However, I will be attempting a 3.x migration in the near future so I'll keep this in mind during that process.\nIn short, I found the addition of timers to the model to be of sufficient benefit to outweigh the threading impact drawback.\nThe only thing I would suggest is that if a user isn't using transitions timers, the timer support should not interfere with using joblib of other threading APIs. \n. While it's unfortunate, it's not really transitions' fault that the python 2.x threading has issues.\nIt's probably good practice to keep the state machine in a separate executable anyway. Anything that needs massive concurrency should be popened as a new process. (IMO). ok, found that the args are not present in event.kwargs, rather \n(Pdb++) event.args[0].kwargs\n{'api_wait': 10, 'region': 'us-west-2', 'asg': 'dc-12-ur-api-AppServerGroup-1DFQF3NVKPZ1G'}\nNot sure if this in intentional. \nJust feels odd to have to pull them out of event.args[0].kwargs where elsewhere they exist in event.kwargs\n. That was it - I had a python namespace overload, where an imported method has the same name as a generated transitions on_enter method.\nRenaming the on_enter method fixed the namespace collision.\nI suppose one could detect this on initialization and flag the error. I'll leave it to you to decide whether to close this or keep as a wishlist todo item.\n. Coming back to this and I can't replicate now. Much has changed, including my switch to using the LockedMachine as I was using timers. So I expect I was violating a lot of the rules of engagement. \nClosing as I doubt I'll get time to dig further.\nThanks again for the excellent assistance.. Ahh, perfect. Must have missed that. thanks!. Perfect, exactly what I needed to know. I didn't see this order of precedence in the docs, might be worth adding.\nUnderstood on the naming issue, thanks for pointing that out. This it not my naming scheme, I copied it from the docs for simplicity, but the point you make and the note are appreciated.. xposted to S.O. https://stackoverflow.com/questions/45515392/python-transitions-lib-wait-for-multiple-events-before-transition-from-single\n. Resolving, details on S.O. at above link. Better options probably exist, but it works and doesn't completely suck.. I'm also looking into a better way to share a set of env data between handlers which may or may not be in the same thread.\nIn my current attempt I'm creating a context that wraps my shared env data class that I pass into the LockedMachine with machine_context arg. \nThen I added a self.env() to extract it from self.machine_context[0] (this bit seems a bit clunky, maybe there's a better way) The docs don't mention that this is where it's stashed, had to dig around a bit.\n```\ndef get_event_cfg():\n    global cfg_data\n    if cfg_data is None:\n        logger.debug('read cfg....')\n        cfg = get_config('blargh')\nwrap above in context:\nclass EnvContext():\n    def init(self):\n        self.env = get_event_cfg()\ndef __enter__(self):\n    return self.env\n\ndef __exit__(self, *args):\n    pass\n\nShortcut to env extraction:\nfrom transitions.extensions import LockedMachine as Machine\nclass XxxxCluster(Machine):\ndef env(self):\n    return self.machine_context[0].env       # found it here, maybe better option?\n\ndef __init__(self):\n    env = EnvContext()\n    Machine.__init__(self,\n                     states=states, transitions=transitions,\n                     finalize_event='finalize',\n                     send_event=True,\n                     queued=True,\n                     machine_context=[env],\n                     initial='idle')\n\nUsing it, which works in same and other threads, timeout handlers etc:\ndef finalize(self, event):\n    env = self.env()\n\n``. The reason I'm \"pulling it from the internals of the Machine is not to use the context's \"with\", but for the additional data payload it contains.\nThe context's 'env` element is a dict of config data.\nI'm probably contorting the context support for something it's not intended for. I picked up on the prior comment:\n   \"Sharing complex objects is not that trivial as far as I understand\"\nand felt that this mechanism was usable specifically to do that. ie: ensure that all threads had access to the same config/env data.\nHowever, I am getting the feeling that I'm making it much more complicated than it needs to be.\nI don't actually need the lock aspect of the context manager, I'm using it solely to expose shared data to all handlers/callbacks. It doesn't need exclusive access. It's just a way to make a class of config data available to all of the handlers and callbacks used by the Machine, locked or otherwise, to share config data.\nThat said, is this negating the lock in the LockedMachine? IOW, is my \"data only context\" now being relied upon for synchronization, which it is not doing?\nReading over the docs again, I realize that this is what the \"model\" that the machine is bound to is for, but IIRC I had problems with model data being uninitialized in threaded contexts.. OK, not sure what I was smoking at the time, but I'm not having the un-init model data in threads as I did earlier. \nMaybe consider nuking from my comment on down as it does nothing but confuse and overcomplicate the issue.. ",
    "dgtlmoon": "Glad to help! This is a great project, thanks! resolved the issue for me.. ",
    "pkonyves": "Hi there, I was just looking for information on which cases does a 'rollback' occur on state transition when any of the callback raises an exception. Would it be possible to add this information to the main documentation?\nThank you!\n. cool, thank you!. ",
    "luminize": "@aleneum thanks for the help. This was the answer I was looking for. I had not realized the differences between bound and unbound methods (learned somethin I wasn't aware of today). I'm using transitions for an application running Machinekit and canopen package. Python is the glue for all machine logic here :)\nThanks!. @aleneum thanks, I need to look at the extensions 'LockedMachine' and I saw 'Hierarchical State Machine' too. I guess my question was not formulated correctly. It's more about where best to put the transition decision logic. (that's not totally clear for me yet)\nIn the synchronous way one would periodically process this logic in a separate thread (if one is in state_x, then check inputs, and then call a transition)\npython\nif (machine.state == 'init'):\n    # directly read a hardware signal\n    while hal.Signal('emcmot.00.enable').get() == 0:\n        pass\n    machine.go_cart()\nhere go_cart is a transition\nAnother way would be to put this logic in a function and pass this to the on_enter_init callback\n```python\ndef example_function():\n    # directly read a hardware signal\n    while hal.Signal('emcmot.00.enable').get() == 0:\n        pass\n    machine.go_cart()\nmachine.on_enter_init(example_function)\n```\nOne way to find out, and experiment what works best.. > If you need switch case statements based on states besides having a state machine, then something is wrong. I'd suggest to either use specific short living WorkerThreads or -- if you have a readout main loop -- to let the machine set the readout strategy in enter.\nyes, that was my feeling too. Seems like this would be a duplicate.\nI'll go and experiment a bit with calling (if need be all) transitions (of which some could be conditional transitions) like machine.go_cart() either periodically, from other states (queued) or from other events.\nThanks for your help.. ",
    "Fawenah": "I see.\nThanks for the input. I just assumed it was related to transitions as I've never had the issue using pygraphviz earlier. And it was not an issue when running transitions with Python 2.7.\nI will either supress them, ignore them or apply a fix for my current repo then.\nKind regards, Fawenah. ",
    "kunalbhagawati": "It seems NestedEvent._trigger is not calling self.machine.finalize_event. Can this be the issue? \nLikewise prepare_event is also not getting called, and the code does not have a super() call. Is this intentional for a HierarchicalMachine?. Sorry just saw the latest pull. Closing this.. ",
    "KarolOlko": "Hello @aleneum \nI digged deeper this afternoon. I cloned pygraphviz repository on Windows VM and found out that one  examples fails for the same reason as #133  :) This seems to be a graphviz bug. There is precisely the same issue hanging on their bug tracker for more than a year. I won't spend whole weekend trying to compile their sources so I just scraped ~15 lines of code to generate text file input for dot program from Machine class. If I then feed it to dot program from command line, it generates proper output. Good enough for me. If you think this might be a valuable addition for poor Windows souls, I can prepare another PR for that.. Alexander, thank you for both answers! You really took your time to explain\nyour line of thinking. Hope my future ideas will be more useful for you :)\n2017-05-17 10:37 GMT+02:00 Alexander Neumann notifications@github.com:\n\noh, concerning this:\nyou may need an ability to pass instance variable to your derived event or\ntransition\nEvent is created with Machine instance assigned to it and will get the\nmodel via Event._trigger. Transition receives machine and model via\nEventData. Same is true for State as EventData is passed to\nState.enter/exit.\nAs mentioned above, the only case where this might not be sufficient --\nwhich I can see so far -- is, when states need to know the machine instance\nfrom the start.\nI know this was just an example but I want to show how this can be done\nquite convenient already:\nclass BookKeeper(object):\n  def init(self):\n    self.events_triggered=0\n    self.transitions_taken_place=0\nclass BookKeepingEvent(Event):\ndef trigger(self, model, args, *kwargs):\n    self.model.increment_events_triggered()\n    super(BookKeepingEvent, self).trigger()\nclass BookKeepingMachine(Machine):\n  @staticmethod\n  def _create_event(*args, kwargs):\n    return BookKeepingEvent(*args, kwargs)\nbook_keeper = BookKeeper()\nmachine = BookKeepingMachine(model=book_keeper, ...)\nAlternatively, you can use prepare callbacks to avoid subclassing at all:\nclass BookKeeper(object):\n  def init(self):\n    self.events_triggered=0\n    self.transitions_taken_place=0\ndef on_trigger(self):\n    self.increment_events_triggered()\nmachine = Machine(book_keeper, prepare_event ='on_trigger')\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/219#issuecomment-302024233,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AadCn8jF9qnhMkZyAs481HSu5tYw-2A1ks5r6rGugaJpZM4Nbf1e\n.\n\n\n-- \nBest regards / Pozdrawiam,\nKarol Olko\n. Wow, thanks a lot! Python does not stop to surprise me :)\nBest regards,\nKarol\n03.06.2017 9:52 AM \"Alexander Neumann\" notifications@github.com\nnapisa\u0142(a):\n\nHi @KarolOlko https://github.com/karololko,\nI am experimenting with different ways of passing the class used to create\nstates. It seems like that you can override class/static decorators in\ninheriting classes without problems:\nclass Prod(object):\ndef __init__(self, name):\n    self.name = name\n    print(name)\n\nclass Base(object):\n@staticmethod\ndef create(*args, **kwargs):\n    return Prod(*args, **kwargs)\n\nclass InstanceClass(Base):\ndef create(self, *args, **kwargs):\n    return Prod(*args, **kwargs)\n\nclass StaticClass(Base):\n@staticmethod\ndef create(*args, **kwargs):\n    return Prod(*args, **kwargs)\n\nclass ClassClass(Base):\n@classmethod\ndef create(cls, *args, **kwargs):\n    return Prod(*args, **kwargs)\n\nBase().create(\"base\")\nInstanceClass().create(\"instance\")\nStaticClass().create(\"static\")\nClassClass().create(\"class\")\nNo matter what decorator Base is using, the first argument passed to Prod\nis always correct.\nSo the problem of requiring the Machine instance for state creation can\nbe solved quite easily by just omitting the static decorator and -- of\ncourse -- add self to the method specs:\nclass BookKeepingMachine(Machine):\ndef _create_event(self, *args, **kwargs):\n    return BookKeepingEvent(self.book_keeper)\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/tyarkoni/transitions/pull/219#issuecomment-305959082,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AadCnzsPrmtqyGDhzS08JOmaB9DsGPCIks5sARC2gaJpZM4Nbf1e\n.\n. Oops.. Now I realized conditions are not covered. This method needs to be moved to EventData. Let me do it in another pull request.. Moved function arguments trimming to EventData and checked conditions in unit test added.. Hi, thanks for your reply. Well, it would work, but now some callbacks need an unused event (or *args or whatever) function parameter in their signature. I think client code is cleaner if you don't impose this limitation. If I don't need event data and base my callback only on internals (see example) - library should respect that.. \n",
    "timofurrer": "What I did to prevent this MachineErroras a workaround was to set unless-guards for a transition. However, because this guards are checked after the MachineError is raised (due to no valid transition with this source state) I had to allow those missing source states - but they can never be trigger because the unless guards prevent it.\nSomething like this, which is quite ugly..\npython\nself.state_machine.add_transition('prepared', ['preparing', 'request_abort'], \n    'ready', unless=[self.is_request_abort]). > Imho, clearing the event queue is quite vital for cases in which MachineError actually indicates issues with the ongoing queue processing.\nIn most cases that's probably true.\n\nCould you elaborate why ignore_invalid_triggers is not sufficient for you?\n\nIt's not sufficient in my case because I only want to ignore invalid triggers if the event was triggered from a certain to a certain state. And not always to a certain state.\nWhat I did as a work around was (what I've already mentioned in the second post) to include the source state I want to ignore in a transition but specify the unless-guard so that this transition from this source state basically is never triggered - which is pretty ugly. With that the transition is simply prevented by the guard and no MachineError is raised - so the queue remains as is.. ",
    "Synss": "Hi, great to see this coming. Just two small things: could you put a comment to #198: I was following #198 and overlooked this thread until yesterday. I would also check the presence of on_timeout with EAFP\ndiff --git a/transitions/extensions/states.py b/transitions/extensions/states.py\nindex 40e9ce7..1d8a01f 100644\n--- a/transitions/extensions/states.py\n+++ b/transitions/extensions/states.py\n@@ -36,8 +36,9 @@ class Timeout(object):\n     def __init__(self, *args, **kwargs):\n         self.timeout = kwargs.pop('timeout', 0)\n         if self.timeout > 0:\n-            self.on_timeout = kwargs.pop('on_timeout', None)\n-            if self.on_timeout is None:\n+            try:\n+                self.on_timeout = kwargs[\"on_timeout\"]\n+            except KeyError as exc:\n                 raise AttributeError(\"Timeout state requires 'on_timeout' when timeout is set.\")\n         self.runner = {}\n         super(Timeout, self).__init__(*args, **kwargs)\nThis way, you avoid the if in the normal case.. Servus! Thank you for your quick answer and for taking my patch. That is really appreciated.\nIf ever you want a pedantic code review either now or when you go 3+-only, do not hesitate to ask: I can do that in my paid-for time ;-). Machine.add_states() could accept *args, **kwargs so that Machine.add_state(\"A\", timeout=999, on_timeout=lambda: None) work.\nI can make a pull request if you agree with the idea.. I have changed my mind since #237, I now believe that listifying on_timeout and allowing to add_callback(\"timeout\", ...) would be useful.\nThat would allow me to remove the timeout_error state in the following case:\nstate -[timeout]-> timeout_error [do/ write error message] --> error\nand instead to have two on_timeout callbacks, one writing the error message and the second one transitioning to error.\nstate -[timeout, write error message]-> error\nHave you started working on this?. I have not actually checked it but just the idea: it is awesome!. interesting... that triggered an infinite recursion... I'll see if I can reproduce that.. Yes, I have seen that. I will see if I can reproduce this tomorrow.... As far as I understand, transitions must be instantaneous, otherwise the machine would not be in any state during the transition. If you exit a state and wait for a timeout before entering the next state, this waiting-for-a-timeout period must be another state that can be represented with this extension.\nOr am I completely missing the point?. > I will alter Timeout in a way that allows to handle multiple on_timeout callbacks and extend the add_callback method accordingly.\nI am not sure this is a good idea, in my case at least, I use on_timeout to transition to either next_state or some error state. I cannot really think of any other meaningful thing to do in on_timeout actually. If this is correct, you should really not listify on_timeout.\nAccessors are not pythonic. But in the present case, the user may want to set two attributes at once.\nIt is true that you can machine.get_state(name).timeout = 10.0 and then machine.get_state(name).on_timeout = \"next_state\". Maybe this is good enough.. If you like, I can explicitly handle functools.partial and return \"check(True)\" for\n```\ndef check(result):\n    return result\n... conditions=partial(check, True)...\n. I could test partial conditions in `test_core`, make `Graph.rep()` a `staticmethod` (it does not use `self` anyway) and test `Graph.rep()` directly. Is that OK?. Tests passed on my machine with 2.7.13, I'll try again.... You are really fast, thank you! I'll try it tomorrow.. You fix works perfectly!. @tyarkoni I guess so. However,triggeris also mandatory toremove_transition``` and I just reuse the signature. What do you think?. OK, I'll work on that.. I am done. You can see if that is ok now.. ",
    "johnarnold": "A tangent, but being able to dump machine state to json (instead of just pickle) would be cool for some other uses. There's probably a ton of stuff that won't serialize to json though.. ",
    "loicpw": "gave it a try, really nice, looks clear and simple to me, as a user I would love to have the ability to right click and directly add/write python scripts to handle transition events. Maybe a dummy question but would it be easily integrated into a web project like Django or others ?. this absolutely makes sense since the add_model method can take a sequence as 'model' argument, but I think this should be documented about Machine initialization. Sorry just realized it actually is, am I just not careful enough or maybe this should be a bit more explicit or an example should be added in the documentation ? \nthe Machine.init doc says : \n\nmodel (object): The object(s) whose states we want to manage. If 'self',\n                the current Machine instance will be used the model (i.e., all\n                triggering events will be attached to the Machine itself).\n. thank you, I didn't see this part in the documentation, seems pretty clear to me, the thing is you don't necessarily go through it if you don't intend to initialize with several models so basically you don't know 'model' can be interpreted as 'models', but my thought is it's ok if it's clear in the init doc...\n\nMaybe this is a personal feeling but I would find more intuitive to use 'models' keyword in arguments instead of 'model' given the fact you can have one or more, and used 'add_models' instead of 'add_model' in the same way. ",
    "Blindfreddy": "Yes, a more precise error message would be useful.  Perhaps also mention it in the HSM section of the documentation, including different imports (if any).. apologies for not properly marking the code - it's beyond me to format it in this editor..... Ok thanks, appreciate the reformatting.\nAlso, I found a workaround:  instantiate NestedState objects using on_enter= and/or on_exit= keywords, in the case of children with the parent= keyword argument. Subsequently instantiate the machine using the list of NestedState objects, all callbacks are then called.\n. I think I figured it out myself. NestedState now seems to work differently in v0.6, substates must not be passed to the Machine. Instead, substates are created with the parent attribute and thus 'attached' to the parent. Only the list of top-level states is then passed to the Machine. That works using the add_states method, I'll have to try it out with direct Machine instantiation but I think that will work, too.. ",
    "jodal": "Great! :-)\nThe following is the gist of building wheels in addition to sdist tarballs and securely uploading them to PyPI with twine.\npip install twine\npython setup.py sdist bdist_wheel\ntwine upload dist/*. ",
    "Grey-Bit": "Thanks @aleneum - changing to direct references instead of strings worked well.\nHowever, now it introduced another problem - inside the callback, if I try to issue any trigger in the Nested or Top, then it fails with an AttributeError - can't find the trigger functions.\n```\nfrom transitions.extensions import HierarchicalMachine as Machine\nfrom transitions.extensions.nesting import NestedState as State\nfrom transitions.extensions.nesting import NestedTransition as Transition\nclass Nested(Machine):\n    def print_msg(self):\n        print(\"Nested\")\n        self.top.print_top()\n    def init(self, top):\n        self.top = top\n        self.states = ['n1', {'name':'n2', 'on_enter': self.print_msg}]\n        Machine.init(self, states=self.states, initial='n1')\n        self.add_transition(trigger='goto_n2',\n                            source='*',\n                            dest='n2')\nclass Top(Machine):\n    def print_msg(self):\n        print(\"Top\")\n    def init(self):\n        self.nested = Nested(self)\n    self.states = [  't1',\n                    {'name': 't2',\n                    'children': self.nested}]\n    Machine.__init__(self, states=self.states, initial='t1')\n    self.add_transition(trigger='print_top',\n                        source='*',\n                        dest='=',\n                        after= self.print_msg)\n    self.add_transition(trigger='goto_t2',\n                        source='*',\n                        dest='t2_n1')\n\ntop_machine = Top()\ntop_machine.goto_t2()\ntop_machine.goto_n2()\n```\nI suspect it's the artifact of the copying process and order of transition initializations, but can't figure out the exact cause and how to make it work.. Thanks @aleneum, \nThe copy process introduces another substantial issue:\nIt's not possible to access any information in the original Top. \nIn the following example, I am calling print_msg directly, trying to access variable \"var\",\nwhich exists on the original Top.\n```\nclass Nested(Machine):\n    def print_msg(self):\n        print(\"Nested\")\n#raises AttributeError exception\nself.top.print_msg()\n    def init(self, top):\n        self.top = top\n        self.states = ['n1', {'name':'n2', 'on_enter': self.print_msg}]\n        Machine.init(self, states=self.states, initial='n1')\n        self.add_transition(trigger='goto_n2',\n                            source='*',\n                            dest='n2')\nclass Top(Machine):\n    def set_var(self, var):\n        self.var = var\n    def print_msg(self):\n        print(\"Top: \" + self.var)\n    def init(self):\n        self.nested = Nested(self)\n    self.states = [  't1',\n                    {'name': 't2',\n                    'children': self.nested}]\n    Machine.__init__(self, states=self.states, initial='t1')\n    self.add_transition(trigger='print_top',\n                        source='*',\n                        dest='=',\n                        after= self.print_msg)\n    self.add_transition(trigger='goto_t2',\n                        source='*',\n                        dest='t2_n1')\n\ntop_machine = Top()\ntop_machine.set_var(\"var value\")\ntop_machine.goto_t2()\ntop_machine.goto_n2()\n```\nMay be instead of playing with the copy methods, it's better to create a \"parent\" variable in the nested machines that would reference the original containing machine? This would allow anybody to issue triggers or access any information stored in the containing machines?\nFor symmetry, we could add an ability to access nested machines through the state that references them.. Thanks @aleneum \nI will try to come up with an alternative and issue a pull request.\nIn the meantime, I changed deepcopy to copy and at least in my case of two level nesting of machines everything works as expected.\nWhere should I expect it to fail due to the lack of deep copy?. Thanks @aleneum, I will test over the weekend and will report back here if there are any issues.. Sorry for the late response: I validated this change on a more complex scenario that included three level hierarchy and it works well. Thanks @aleneum for taking care of this.. ",
    "nareshsankapelly": "Thanks.. ",
    "boubakerwa": "Thanks for your answer :)\nI tried to reproduce it using the example given in the tutorial and tried your solution but I think it's still not working. Here's the code:\n```python\nfrom transitions import Machine\nclass Matter():\n    def on_enter_liquid(self):\n    print(\"on_enter_liquid has been called\")\nstates= ['solid', 'liquid', 'gas', 'plasma']\ntransitions = [\n    { 'trigger': 'melt', 'source': 'solid', 'dest': 'liquid' },\n    { 'trigger': 'evaporate', 'source': 'liquid', 'dest': 'gas' },\n    { 'trigger': 'sublimate', 'source': 'solid', 'dest': 'gas' },\n    { 'trigger': 'ionize', 'source': 'gas', 'dest': 'plasma' }\n]\nlump1 = Matter()\nlump2 = Matter()\nmachine = Machine(model=[lump1, lump2], states=states, transitions=transitions, initial='solid', add_self=False)\n```\ncalling lump1.melt() prints the output twice.\nI also tried this:\n```python\nfrom transitions import Machine\nclass Matter():\n    def on_enter_liquid(self):\n    print(\"on_enter_liquid has been called\")\nstates= ['solid', 'liquid', 'gas', 'plasma']\ntransitions = [\n    { 'trigger': 'melt', 'source': 'solid', 'dest': 'liquid' },\n    { 'trigger': 'evaporate', 'source': 'liquid', 'dest': 'gas' },\n    { 'trigger': 'sublimate', 'source': 'solid', 'dest': 'gas' },\n    { 'trigger': 'ionize', 'source': 'gas', 'dest': 'plasma' }\n]\nlump1 = Matter()\nlump2 = Matter()\nmachine = Machine(model=None, states=states, transitions=transitions, initial='solid')\nmachine.add_model(lump1)\nmachine.add_model(lump2, initial='liquid')\n```\nsame problem.\nThanks for your time. Hum okay. I'm using transitions (0.5.3). Worked just fine after updating to 0.6.0! Thanks a lot! :) Next time I'll upgrade before asking a question :) . ",
    "walterwang": "can this be a feature? . ok thanks for the response. I posted on SO. \nedit : Someone suggested  setting queued = True. Haven't checked for memory leaks yet, but so far working nicely. ",
    "e-d-n-a": "I'm looking for a solution for Windows and there are people talking about this issue in various PyGraphviz-Issues on Github (eg here and here).\nAnd there is a Patch you have to use to make it compile.\nFrom that you might be able to get PyGraphviz to work under Windows and Python 3.6, but I couldn't figure out a solution yet. For Python 3.4 it seems to be easy, as there is a compiled package from C. Gohlke's archive, which includes statically linked libraries, which circumvents the main problems you can have with compiling and linking. But normally you get an installation, that fails tests or crashes when being used.\nI can compile v1.3.1 or v.1.4RC1, but former crashes on import and latter on usage of Graphviz-tools.\nMaybe this describes how you can use this wheel in a Python 3.6 environment, but I'm not sure.\nI'm working with WinPython-32bit-3.6.1.0Qt5 at the moment and do not know how to adapt this.\nSo I'll probably go with a seperate Python 3.4 environment to at least get something running or even switch to a linux install, if nescessary.\n. ",
    "benselme": "I'm trying to answer the question, \"Where can I go from here ?\". For example I might want to disable certain UI controls that would trigger an impossible transition. Something similar to django-fsm's can_proceed.\nSomething like this should do the trick I guess:\n    def can_trigger(self, trigger_name):\n        return trigger_name in self.get_triggers(self.state) and any(\n            all(c.check() for c in t.conditions)\n            for t in self.events[trigger_name].transitions.items())\n\nBut it's rather hard to write a function like this, since Condition.check needs some EventData that's generated in Event._trigger.\n. Yes, that's exactly what I was looking for. Thanks.. ",
    "daino3": "FWIW - I also expected the library to have this functionality. It's immensely useful for having FSM logic server-side and serializing possible transitions for a client (e.g. UI). That way, you don't need to reinvent an FSM in two places.\nIn any event, thank you for documenting this!. ",
    "fedpet": "the error only happens when I try to draw reflexive transitions or ones which have '*' as the source.\nbtw if the problem is pygraphviz then what version are you officially using?\nI see the repo examples are working..\nedit.\nI cloned and installed pygraphviz and it should be version 1.5.dev\nsame error\nedit.\ntried with version 1.4rc1.. same error. hi aleneum, thank you for your support.\n\ntransitions = [\n    ['any_trigger', 'first', 'first'],\n    ['anything', '*', 'second'],\n]\nI assume this would not work in your environment.\n this error occurs only when source and destination of an edge are the same\n\nExactly\n\n@fedpet: How did you install pygraphviz? [...]\nNevermind, PATH has not been set correctly\n\nThis. I'm not using unofficial binaries. Glad to see you found the problem :)\nYour answer suggests me the problem may be on pygraphviz or graphviz side.\n\nIf you have any suggestions about how to approach this issue I am all ears.\n\nA minimal code example demonstrating this bug would be needed to be able to open a proper bug report on pygraphviz/pygraphviz  or graphviz-issue-tracker. ",
    "idf": "@aleneum I saw your code and it works reasonably good. Can you upgrade it use async/await syntax newly introduced in python?. @aleneum I am referring to code in https://github.com/ivanteresh/transitions/blob/async_machine/transitions/extensions/asynchronous.py . \nI see you are striving for 2 3 compatibility. Let's not use the new syntax.\nI actually try out the async code, it works after some debugging. What's the plan of incorporating it into master branch?. ",
    "mrtvon": "OK so it seems one part of the problem is the hard reference to \"machine\" in Event, looks like this can be quite easily solved with weakref.\nThe second part of the problem seems to be the decorating of the model in Machine.add_model\nIs this a know issue, or does it indicate design intent?. Thank you, the above approach achieves exactly what I need, though for my solution I do need to apply the override.. ",
    "bengartner": "Okay - I think I can put it in without changing default behavior or adding too much code. Just wanted to check if there was already discussion I'd missed. I'll fork for now and put up a PR after waiting for some feedback.\nHere's an example of the slash notation from wikipedia's UML state machine.\nThere's already code for optionally displaying transition conditions in []s so it should be easy enough to add to the transitions. Nodes use a default for the label so I'll have to add an analogous function there.\nOr I could do something that's a little more flexible in terms of how labels are generated, IE an internal function that can generically map graphing attributes, but it seems premature for that. Not sure how much flexibility is actually needed - or what people want other than standard UML stuff.\nUML seems to treat all transition actions the same, so I can incorporate any advice on how transitions treats them - I tend to avoid using more than one action on the same transition.. ",
    "janekbaraniewski": "@aleneum thanks for getting back to me so quickly! I'm glad I could help \ud83d\ude04 \nCan you also push this fix to pypi?. @aleneum awesome, thanks for letting me know! \ud83d\ude04 . ",
    "xuqinghan": "python3.6.4 x64  transitions-0.6.4-py2.py3-none-any.whl\nissue 1:\nignore_invalid_triggers=Trure  only work  in State() but not work in Machine()\n2 failed tests:\n  test_in_machine_with_machine_sperated\n  test_in_machine_with_machine_inside\nissue 2:\nif without { 'trigger': 'evaporate', 'source': 'liquid', 'dest': 'gas' } in transitions:\nall test failed:\n\nAttributeError: 'Matter' object has no attribute 'evaporate'\n\nCan \"invalid_triggers\" condition involve this stituation and silently ignore it?\nJust use demo code:\n```\nimport unittest\nfrom transitions import Machine, State\ntransitions = [\n    { 'trigger': 'melt', 'source': 'solid', 'dest': 'liquid' },\n    { 'trigger': 'evaporate', 'source': 'liquid', 'dest': 'gas' },\n]\nclass TestIgnoreInvalidTriggers(unittest.TestCase):\ndef test_in_state_with_machine_sperated(self):\n    states = [State(name='solid',\n                    ignore_invalid_triggers=True),\n            'liquid']\n\n    class Matter(object):\n        pass\n\n    lump = Matter()\n\n    machine = Machine(lump, \n        states=states, \n        transitions=transitions,\n        initial='solid',\n        )\n    # invalid trigger!\n    lump.evaporate()\n\ndef test_in_machine_with_machine_sperated(self):\n    states = [State(name='solid'),\n            'liquid',\n            { 'name': 'gas'}]\n\n    class Matter(object):\n        pass\n\n    lump = Matter()\n\n    machine = Machine(lump, \n        states=states, \n        transitions=transitions,\n        initial='solid',\n        ignore_invalid_triggers=True,\n        )\n    # invalid trigger!\n    lump.evaporate()\n\n\ndef test_in_state_with_machine_inside(self):\n\n    states = [State(name='solid', \n                    ignore_invalid_triggers=True),\n            'liquid']\n\n    class Matter(object):\n\n        def __init__(self):\n            self.machine = Machine(model=self, \n                                states=states, \n                                transitions=transitions,\n                                initial='solid',\n                                )\n\n    lump = Matter()\n    # invalid trigger!\n    lump.evaporate()\n\ndef test_in_machine_with_machine_inside(self):\n    states = [State(name='solid'),\n            'liquid',\n            { 'name': 'gas'}]\n\n    class Matter(object):\n        def __init__(self):\n            self.machine = Machine(model=self, \n                                states=states, \n                                transitions=transitions,\n                                initial='solid',\n                                ignore_invalid_triggers=True,\n                                )\n\n    lump = Matter()\n    # invalid trigger!\n    lump.evaporate()\n\nif name == 'main':\n    unittest.main()\n```. Thanks for your reply! Very useful! . ",
    "hrsmanian": "Thanks a lot for the reply. I did realize that the parent has to be a State object. I will sync to the latest to get the updated code. Really appreciate the help. Hi, how do we remove states from the machine dynamically? I know the state name but cannot see an API to remove the state from the machine. . ",
    "jlandercy": "You are welcome, glad you updated your example. Best regards. ",
    "nicain": "+1 on the above\n@tyarkoni have you considered moving over to pipenv?  I am not the authority, because I am learning it myself right now, but it looks great so far.  Optional dependencies are defined as in https://github.com/pypa/pipenv/issues/1013, but I am struggling to find the documentation.\n  . ",
    "pwa16000": "Hello Aleneum,\nThanks very much for your information, it works well.\nBest Regards\nPhilip\n. ",
    "jaumearagay": "I've seen this -> usage question to Stack Overflow\nI've asked on Stack Overflow! ;)\n. ",
    "xavigisbeg": "Thanks for the clarification @aleneum!. ",
    "Errogant": "I'm extremely interested in this feature!. Just saw that this is essentially a replication of https://github.com/pytransitions/transitions/issues/288, my apologies\nI would be quite interested in this feature, however!. ",
    "ollamh": "@aleneum Sorry to disturb you, but is there any update on this one?. @aleneum Looks good! Actually it is more clean solution.. ",
    "apiraino": "thanks everyone for improving and merging our patch!. ",
    "njbuch": "Of course, I tried to minimize the example:\n```\nfrom transitions import Machine\nfrom transitions.extensions import GraphMachine\nfrom transitions.extensions.states import add_state_features, Timeout\n\"\"\" Use the decorator to add extensions \"\"\"\n@add_state_features(Timeout)\nclass CustomStateMachine(Machine):\n    pass\nclass RPI_Controller(object):\n    def init(self):\n        self.entourage = 0\n        self.received_data = 0\nstates = [{'name': 'sleep', 'timeout': 2, 'on_timeout': 'timeout2'},\n          {'name': 'state4'}]\ntransitions = [['pin_high', 'sleep', 'state4'],\n               ['timeout2', 'state4', 'sleep']]\ncontroller = RPI_Controller()\nmachine = CustomStateMachine(model=controller, states=states, transitions=transitions, initial='sleep')\nmachine2 = GraphMachine(model=controller,\n                       states=states,\n                       transitions=transitions,\n                       auto_transitions=False,\n                       initial='sleep',\n                       title=\"Mood Matrix\",\n                       show_conditions=True)\ncontroller.get_graph().draw('my_state_diagram2.png', prog='dot')\n```. Thank you so much, I did not realize the inheritance hierarchy between the GraphMachine and Machine, which was the reason for two machines. The intention was to create a machine just for exporting the graph.\nYou have been really helpful, I appreciate it a lot. Will continue my state-machine adventure.\nThanks again :) \ud83d\udc4d . ",
    "ahsenqamar": "Answered here. ",
    "ansumanm": "Thanks for your response.\nThere are other elements in the class, it works fine for Machine, only if I turn on GraphMachine, it breaks.\n$python -V   \nPython 3.6.3\n\npip show transitions\nName: transitions\nVersion: 0.6.4\nSummary: A lightweight, object-oriented Python state machine implementation.\nHome-page: http://github.com/pytransitions/transitions\nAuthor: Tal Yarkoni\nAuthor-email: tyarkoni@gmail.com\nLicense: MIT\nLocation: /home/ansuman/env3/lib/python3.6/site-packages\nRequires: six   . The following code gives error:-                                                                                                \nException ignored in: >                          \nTraceback (most recent call last):                        \n  File \"repro.py\", line 41, in del \n    pickle.dump(self,f)     \nTypeError: can't pickle SwigPyObject objects  \n\nCode:\n```\nimport pickle\nfrom transitions.extensions import GraphMachine as Machine\nclass Test:\n    states = ['A', 'B', 'C']\nt = 'trigger'\nd = 'dest'\ns = 'source'\nc = 'conditions'\n\ntransitions = [\n        {t: 'to_B', s: 'A', d: 'B', c: 'true_func'},\n        {t: 'to_C', s: 'A', d: 'C', c: 'true_func'},\n        {t: 'to_C', s: 'B', d: 'C', c: 'true_func'},\n        ]\n\ndef __init__(self):\n    self.machine = Machine(model=self, states=self.states,\n            transitions=self.transitions, title = 'Example', send_event=True,\n            after_state_change='asc',\n            initial='A',\n            auto_transitions=False, ignore_invalid_triggers=True)\n\ndef asc(self, event_data):\n    pass\n\ndef on_enter_B(self, event_data):\n    print('Entering B')\n\ndef on_enter_C(self, event_data):\n    print('Entering C')\n\ndef true_func(self, event_data):\n    return True\n\ndef __del__(self):\n    with open('transition.pickle', 'wb') as f:\n        pickle.dump(self,f)\n\ndef main():\n    t = Test()\nif name == 'main':\n    main()\n```. Thanks a ton for maintaining this wonderful library.. . ",
    "Shaun-Griffith-Hive": "Ah, thanks.. Sorry, my version of pygraphviz was out of date. After pulling down the pygraphviz source, there was no problem.. Thanks. I've pulled down the latest master from github, no warnings. . ",
    "tedmiston": "I came here for this as well (and have seen / experienced similar issues on other projects with markdown on PyPI).  It looks like the 0.6.6 release fixes the issue.  Do you have an idea when it will be published?. Sounds great.  That looks like a cool feature.  Looking forward to it.. ",
    "chace20": "Yeah, I think so. There are some parallel states.. ",
    "amitabhn": "Concurrent states would be super useful feature to add! Any updates on this?. Hi @aleneum, thanks for your reply.\nI understood what you're saying. I can think of creating the Models separately with their own lists of States and Transitions, and then while creating the Machine, pass both Models and the concatenation of their States and Transitions.\nIn a further extension to my question, I also need to exchange triggers between the two models (triggers generated by one and consumed by the other).\nIs there any mechanism to do so? \nOr maybe a mechanism to dispatch a trigger to the machine from within the model?\n\nIssues may occur when wildcards '*' are used for defining transitions as the resulting transitions might be valid on all models and will therefore change the state of all models to the same.\nIt is recommended to not use wildcards in this case.\n\nAs for the wildcard issue, I am only using wildcards to register events that may arrive in any state, but are only required in a specific state.\n```\ntransitions = [\n    {\n        'trigger': 'trig_x',             # takes precedence\n        'source' : 'wait_for_x',\n        'dest'   : 'next_state',\n    },\n    {\n        'trigger': 'trig_x',\n        'source' : '*',\n        'dest'   : None,\n        'prepare': 'prepare_trig_x'\n    }\n]\nclass Model1:\ndef prepare_trig_x():\n    self.flag_x = True\n\non_enter_wait_for_x():\n    if self.flag_x is True:\n        self.flag_x = False\n        self.trig_x()\n\n```\nThis is basically the functionality of a deferred event, which I believe is not supported by pytransitions.\nAny ideas about a better way to achieve this?. ",
    "asyncee": "If your code is simple enough and it is okay to block execution, then you can do your loop inside the machine itself (on on_enter) callback.\nBut better way is to have three entities in the system: a model holding data and state, a machine that controls state and some external event system that notifies machine about events happened.\nIt is not a responsibility of a model to monitor sensors or read some data. It is responsibility of another system, which can be swapped out later if you design appropriately.\nWith suggested approach, it is much easier to test such a model, also.. ",
    "lostcontrol": "I don't know if that could help you but I'm currently developing a pool control system based on transitions and Pykka. I have several FSM implemented with transitions that communicate via actors (Pykka). I'm using MQTT as external API and database to store the settings. You can have a look at the code maybe it can help you: https://github.com/lostcontrol/poupool. Actually, I have several FSM (implemented with transitions) running in different actors (Pykka, an actor model framework). E.g. the data acquisition is done in an actor and either polled from another actor or pushed. Since actors run in their own threads and communicate by messages, it is easy to decouple the blocking readings from e.g. the main FSM.\nToo bad Pykka does not seem to be develop anymore. Still I find it's working very nicely together with transitions.\nThe topic of blocking operations is not related to transitions and must be address at a different level.. ",
    "maueki": "Hi @aleneum ,\ne.g. https://en.wikipedia.org/wiki/UML_state_machine#Internal_transitions\n. ",
    "ideabrdg": "Thank you @aleneum for the help. I will continue tracing. Closing the ticket. \nP.S., thank you for transitions. It's an elegant piece of software. . ",
    "WoWuQ": "OK, I solve the problem , and  transitions can support the config file.. ",
    "plaes": "Unfortunately, neither do I. Maybe annotate like this: timeout(n, state) ?. ",
    "ljaniec": "Do you have somewhere your projects, where I could \"catch the feel\" for it? I am pretty new to this library, but it seems really useful.. ",
    "pafodie": "Tried again with a different Conda environment on Python 3.5 and it worked - no Exception. Maybe it is a Python version related bug.. ",
    "jeasinema": "I also try to change the loop into a finite one, then put these code below the loop, to see if the memory can be free:\npython\nimport gc\ndel lump1\ndel machine1\ngc.collect()\nHowever, the memory still cannot be free.. Thanks for your response! I just used htop to monitor the memory consumption, thus the result may not be accurate. But it seems that the result of  memory-profiler also shows a significant memory increase. \nAs for this comment, I think I cannot track this down since it is totally out of my ability. But I wonder if it exists some methods to disable graphviz when use transitions.extensions.GraphMachine?. Thanks for your work on this issue! Now I believe that this memory leak may cause by (py)graphviz instead of transitions. However, my question seems to still remain unsettled, can you help me with that?\nFor convinience, I rewrite it below:\nplain\nIs there any mechanisms existing in transitions to disable graphviz when using transitions.extensions.GraphMachine? Or I should just use transitions.Machine instead? \nThank you!. @aleneum \nThanks for all your work on this issue! I did learn a lot from the experiments you did on this memory problem.. ",
    "doanguyen": "Hi,\nI'm actually looking for a way of storing states and its transitions into database and re-initialize later.\nAfter a while, I think storing events with triggered time could work as well.. Thanks a bunch! I've got it.. ",
    "prashast": "Hi @aleneum,\nThanks again for such a detailed reply. This is definitely what I was looking for. One additional thing, is there an exposed API to query the attributes attached with the subclass directly without executing the trigger callback function? \nThe reason why I ask for this is because I want to based on the current state I am in, I want to query the attributes for the different legal transitions available and then trigger the appropriate transition. Conditional transitions won't help because they would only work based on the local context whereas I want to take into account multiple contexts based on the available transitions.\nI could create a mapping of the created subclasses to the transitions when they are created but I was wondering if Transitions itself exposes a way for me query the attributes. \nThanks  again for  being so responsive and creating such a clean FSM library! :)\nEDIT: Hmm, now that I gave it some more thought, perhaps I can do a pass special keywords to the callback function as event data and then have appropriate return values based on the keyword passed i.e if the event data passed had QUERY as keyword, the transition won't be exercised but would only return the transition attributes.\n. Sounds good, thanks again!. ",
    "potens1": "Hello @aleneum,\nMy bad, I was talking with Timeout AND Error at the same time, I was thinking the enter method of the state will either from Timeout or from Error (depends on MRO and order you put), but not both.... About the threads thing, my point of view is pytransitions should not bother with IO at all, it should be a lib \u00e0 la sans-io (io and blocking code outside of the lib), this way, it is compatible with asyncio, threading, multiprocess et al., only events should be passed to and from the blocking part (i.e., in my case, I'm rewriting the Timeout extension to just push the timeout events to a queue, and another part of my soft is managing the queue, the nice thing is either on python2 with queue or python3 with asyncio.queue, both have a method put_nowait and get_nowait, then my soft could use threading.Timer, or sched.scheduler or loop.call_later/call_at, whatever). Still two years to wait before stopping bothering with this kind of things (py2/py3) (but some like django have already announced 2020 is now...)\nAbout the MRO, I'm sorry, but I don't understand how it working, I mean, aren't we here in a diamond inheritance with\ndot dep.svg\ndigraph D {\n  State -> {Timeout, Error} -> {CustomState}\n}\nSo, I don't get how the Timeout.enter and Error.enter are called both (sorry for my ignorance). I'm not very fond of the filtering idea, the problem I see is if you create to_ method by your self, it can bites (i.e, you are not very imaginative, and every trigger you create in the transition, you call it to_). My point of view on that is it should be enough to put a big fat warning in the doc saying Error is exclusive with auto_transitions. I'm fan of the Principle of least astonishment. I don't know if it's the way to go, but, if you replace\nsuper().__init__(name='B',on_enter='enterCallBack',on_exit='exitCallBack')\nwith\nsuper().__init__(name='B',on_enter=self.enterCallBack,on_exit=self.exitCallBack)\nIt should work. Sorry, I did not understood you where expecting an answer from my side (was thinking your last message was to signify that this change was acted)\nMy point of view is this is strange the current implementation can lead to cases where you have conditions and unless (for two transitions), with the same \"condition\" statement, to no transition at all.\nThe thing is I don't see correct way (meaning logical and without magic or surprise) to do it without doing what you wrote in your comment.\nThe other way could be to say that \"unless\" is equal to \"not conditions\", but this way, conditions are evaluated against True or False, and unless is \"is not True\" (and that's different from \"is False\")\nSo, if you choose to keep it the way it is, I'm fine with that, the think is to know this situation can happend (my_condition is not True and my_condition is not False -> no transition). Hi,\nMaybe I'm wrong (fast read), but, if you add model=self in the super().__init__(), it should correct it.\nThe error I see means the model is not your instance (but I can be wrong).\nHope it helps. ",
    "occoder": "Just ran it and got the same kind of exception\n```\nTraceback (most recent call last):\n  File \"C:/PycharmProjects/test/test.py\", line 88, in \n    batman = NarcolepticSuperhero(\"Batman\")\n  File \"C:/PycharmProjects/test/test.py\", line 85, in init\n    self.machine.add_transition('distress_call', '', 'saving the world')\n  File \"C:\\Python34\\lib\\site-packages\\transitions\\extensions\\diagrams.py\", line 425, in add_transition\n    model.get_graph(force_new=True)\n  File \"C:\\Python34\\lib\\site-packages\\transitions\\extensions\\diagrams.py\", line 373, in _get_graph\n    self.model_graphs[model] = self.graph_cls(self).get_graph(title if title is not None else self.title)\n  File \"C:\\Python34\\lib\\site-packages\\transitions\\extensions\\diagrams.py\", line 179, in get_graph\n    self._add_edges(self.machine.events.copy(), fsm_graph)\n  File \"C:\\Python34\\lib\\site-packages\\transitions\\extensions\\diagrams.py\", line 137, in _add_edges\n    container.add_edge(src, dst, *edge_attr)\n  File \"C:\\Python34\\lib\\site-packages\\pygraphviz\\agraph.py\", line 481, in add_edge\n    eh = gv.agedge(self.handle, uh, vh, key, _Action.find)\nKeyError: 'agedge: no key'\nProcess finished with exit code 1\n```\n. Hello @aleneum \nJust tried out the new approach. It worked perfectly.\nThanks for the excellent work.. ",
    "liuzongquan": "@aleneum . @aleneum Got it!\nthanks so much for your perfect explanation!. ",
    "cglewis": "ah, ok. that makes sense. I was using the BASIC_FORMAT. ",
    "kentoshima": "\nHi @kentoshima,\nthe documentation right above here mentions the following:\n\nTo check whether the current state is a substate of a specific state is_state supports the keyword allow_substates:\n\n```python\nmachine.state\n\n\n\n'C.2.a'\nmachine.is_C() # checks for specific states\nFalse\nmachine.is_C(allow_substates=True)\nTrue\n```\n\n\n\nSo this should work:\n```python\nfrom transitions.extensions import HierarchicalMachine as Machine\nstates = ['standing', 'walking', {'name': 'caffeinated', 'children':['dithering', 'running']}]\ntransitions = [\n  ['walk', 'standing', 'walking'],\n  ['stop', 'walking', 'standing'],\n  ['drink', '*', 'caffeinated'],\n  ['walk', ['caffeinated', 'caffeinated_dithering'], 'caffeinated_running'],\n  ['relax', 'caffeinated', 'standing']\n]\nmachine = Machine(states=states, transitions=transitions, initial='standing')\nmachine.drink() # coffee time\nmachine.walk()\nprint(machine.state)  # >>> caffeinated_running\nprint(machine.is_caffeinated())  # >>> False\nprint(machine.is_caffeinated(allow_substates=True))  # >>> True\n```\n\nthank you!\ni should read the doc carefully next time. ",
    "peey": "Oh, this is wonderful! From what I understand, \"accepted\" will be listed as a tag, correct?\nI think that should be good enough. One possible enhancement could be to give special notation to accept states. e.g. this (source):\n\nHere, S4 is a final state. This double circle is one notation I've seen commonly in books for automata.. Oh. Thanks for telling me about this. I'll use this to customize the graph to look like how I want it. \nYou can choose to keep this issue open if you want to invite further discussion on this / incorporate it into the lib or close if you think it's too niche.. ",
    "keivanzavari": "I think I have figured out what the problem is (correct me if I am wrong please). Once you create a state with children (sub-state) as\npython\nself._running = RunningStateMachine()\n{\"name\": \"running\", \"children\": self._running},\na copy of the sub-state is created. That's why machine._running and machine are in different states. Copying is fine by me, but the drawback is the following:\ndrawback\nIf there are callbacks inside the sub-state who are supposed to do stuff and then trigger events, they cannot do their job anymore.\nI can create a transition in the parent state as\npython\nself.add_transition(\"e_start_chain\", \"running_init\", \"running_configuration\")\nand trigger this event immediately after the call of e_run(). So I would do\npython\nmachine.e_run() # machine state = running_init\nmachine.e_start_chain() # machine state = running_configuration\nHowever, since configuration method in RunningStateMachine class has self.e_success_config(), triggering this event raises an error because the sub-state defined by machine._running is obviously in init state and I get the error of Can't trigger event e_success_config from state init!. But triggering machine.e_success_config() does the job.\nstill vague\nSo what is the right way to be able to fully reuse a machine as a sub-state of another?\nDoes my parent machine need to inherit from the sub-state?\nP.S. If the sub-state is copied, how deep does this copy go? Until it reaches the leaves? Or does it stop somewhere? . Thanks for the answer, much appreciated. \nIn the meantime, I changed the implementation to just one machine that has all the states. So in the example above RunningStateMachine is incorporated into the parent state machine.\nIf my state machine grows, I'll have to find ways to fix this. I have previously used rFSM and made quite complicated state machines. There it's very easy to load another state machine without having to know what's inside of it like here.\nSo I would very much like to use some smaller states as a sort of plug and play modules and do not have to tweak with them. If I understand you correctly, I'll have to load each state as a separate model, right?\nSo for my example above it would be separate add_model calls. What if one state machine needs to use another?\n. ",
    "JustinTTL": "Sounds good! Would love to hear other user's thought on this. \nI personally like hard typing everything instead of loose references. Having intellisense + mypy type checks whenever possible really helps with faster development. ",
    "artofhuman": "+1 for this feature. ",
    "Edvard-D": "@aleneum You're right, thanks. Realized that it's being registered in a different class but the callback function needs to be assigned to the model.. "
}