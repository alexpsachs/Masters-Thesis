{
    "alexandercampbell-wf": "+1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1 any idea how this affects performance yet?\n. +1\n. Minor, +1\n. +1\n. +1\n. +1\n. +1 on the code so far\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1 nice!\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. Accidentally checked in .prof file, and it looks like there are some debug logs still present.\nOtherwise, +1\n. +1\n. +1\n. +1 LGTM\n. +1\n. +1\n. I got Go code to call Rust code a few days ago. It's actually not too difficult-- just compile Rust to a C library (easier than you think) and write headers so Go can recognize it.\n. The biggest problem is that you're constantly casting your variables back and forth between Rust -> C -> Go and Go -> C -> Rust. Very awkward.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1, looks good\n. Theoretically you could recover from a panic and continue using the datastructure, but whatever caused the panic probably left it in a bad state. I wouldn't trust the data at that point.\nDefer is very convenient and aids safety in larger functions with multiple return sites, but I agree that in simple functions like these, the performance improvement is worth explicitly unlocking before the return.\n. Thanks for fixing that issue! +1\n. @funny-falcon sorry it's taken us so long to look at your suggestion. What is the advantage to making this change? The only difference in the public-facing API appears to be the introduction of a Wait() method, which can already be achieved by calling future.GetResult() and ignoring the output.\n. @funny-falcon ah, I didn't see that Wait() was returning a channel.\nWe've hit many issues with channels in the past, so I'd prefer to preserve our existing struct. But I'd be ok with adding a SelectableFuture type to the future package. Does that sound good to you?\n. @funny-falcon sure.\n. @dustinhiatt-wf are you okay with https://github.com/alexandercampbell-wf/go-datastructures/commit/6034e869e4d7795878f17314214fa1199ab17733 ?\n. Closing as stale; the discussion seems to have moved elsewhere.\n. Closed by #93 \n. +1\n. +1\n. +1\nIsn't this kind of optimization highly specific to each system configuration?\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. LGTM\n. Minor comments, +1\n. +1\n. +1\n. Confirmed tests pass for me (some testify glitches, but values are correct)\n. +1, but I can't say I like introducing another channel.\n. @beaulyddon-wf did a quick rebase, would you mind taking another look? Thanks! (changes are identical)\n. +1\nUnrelated, but maybe we should add go test -bench . -benchtime 1ms to CI and integration tests, just to confirm the benchmarks have no panics.\n. Minor comment, +1\n. +1\n. +1\nNice! Thank you @tylertreat-wf!\n. Closes https://github.com/Workiva/go-datastructures/issues/66\n. +1\n. +1\n. +1\n. Looks great besides one question.\n@dustinhiatt-wf @tylertreat-wf do you guys have any comments?\n. I opened an issue for the failing ctrie Travis tests.\nIn my opinion this PR is safe to merge.\n. +1\n. @ichinaski we can merge this PR now (unless you want to add the duplication flag before this goes in). Your call.\n. @ichinaski yep, thank you!\n. +1, thank you\n. @dustinhiatt-wf \n. It looks like Travis is failing because of a race condition somewhere in trie/ctrie. Interesting stack trace, but it can't be related to this PR.\nIMO this is safe to merge.\n. @andygrunwald sorry about the delay. gods does look promising, but merging the projects would be a lot of work due to conflicting designs. I'll bring this up for discussion with my team. I do like the interfaces defined in gods and it may be worth satisfying those interfaces with go-datastructures implementations.\nFor what it's worth, Workiva/go-datastructures is currently ~5 times larger than emirpasic/gods:\nsh\nwc -l $(git ls-files | grep \"go$\")\ngods has 5,908 lines, while go-datastructures has 26,046.\n. +1\n. @tehbilly thanks for the suggestion! I've opened #136 to address this issue.\n. Minor comment, LGTM.\n@dustinhiatt-wf @beaulyddon-wf @tylertreat-wf \n. +1\n. +1\n@dustinhiatt-wf @beaulyddon-wf @tylertreat-wf \n. Thanks @jlhonora!\n. @pkieltyka thanks for the information. xtgo/set and our Set implementation appear to have completely different approaches. We implement a Set struct with only basic methods: Add, Has, Len, and so on. The xtgo/set approach works on sort.Interface, but includes much richer functionality.\nSince our approaches are so different and have different use cases, I'd prefer to keep them separate. However, I've opened a PR here to update the documentation and point to the repositories you mentioned: https://github.com/Workiva/go-datastructures/pull/135.\nThanks!\n. +1, LGTM. This is technically a breaking change to the API, but it's unlikely to affect much code :)\n. +1\n. +1\n. +1\n. LGTM but I don't know much about this code.\n. +1\n. Minor comments. +1 otherwise.\n. +1\n. +1, I agree that inclusive ranges make a lot more sense. I couldn't find any public users of this package, so hopefully this won't break anyone elses' code (and like you said, it's a simple fix if it does).\n. @seanstrickland-wf there was no documentation on whether the rangetree was exclusive or inclusive before (or at least none that I could find).\n. +1, thanks!\n@dustinhiatt-wf @tannermiller-wf @tylertreat-wf @seanstrickland-wf \n. +1\n@dustinhiatt-wf \n. +1, I really like this change\n. @dustinhiatt-wf ready to merge\n. +1\n. +1\n. +1\n. +1\n. Thank you @brentp!\n. Closing as stale. @newhook please re-open if you think this requires further discussion :)\n. Closing, since we don't have the resources to customize the augmentedtree for the other Golang types. Feel free to open a PR.\n. @Theodus looks like there's an issue in one of the tests:\n```\n=== RUN TestIterate-2\n--- FAIL: TestIterate-2 (0.36s)\n    Error Trace:    dtrie_test.go:158\n    Error:      Should be true\n```\n. One minor stylistic comment. Otherwise, this looks good to me. Thanks for your PR!\n. +1\n. > I will change the Dtrie implementation to use this package but I was not sure if you would want that done in a separate PR.\nI'd prefer it was done as part of the same PR; the code usually ends up cleaner if there's at least one consumer from the outset.\nI'd almost prefer this was part of the bitarray package. Not necessarily as an implementation of the bitarray.BitArray interface, but maybe as a separate, exported struct labelled BitArray32. Alternatively, this bitmap package could become a subdirectory underneath bitarray. Thoughts?\nFYI @dustinhiatt-wf @tylertreat-wf \n. +1\n@dustinhiatt-wf @tylertreat-wf \n. +1\n. Thanks for your contribution @nvanbenschoten!\n. +1\n. +1\n. +1\n. :) +1\n. +1. Thank you!\n. +1 awesome, thank you!\n. +1\n. +1\n. Thank you!\n. Would you mind adding a unit test covering Traverse()?\n. @azr sorry about the delay. Thanks for the contribution! Looks good to me.\n. +1\n. Looks like CI is failing :(\nYou'll have to change the package name in the other files in the sort directory.\n. What's the point of this conditional? We want to allow both row and column inserts, correct?\n. probably want a wg.Done() above this break?\n. This can be\ngo\nfor i := range cp {\n. Ok, doesn't really matter.\n. lol\n. I did a search-replace for \"or -> and\"\n. Addressed\n. No idea what these constants mean. Would they be clear to someone who understood the Nelder-Mead algorithm?\n. Creating this extra slice here has got to be expensive, right? Unless the compiler automatically transforms to\ngo\nfor i := 1; i < len(vertices); i++ {\n    v := vertices[i]\n. go\nfor i := range nm.vars {\n. Similar comment.\n. And here\n. Is it possible to do a 1-dimension nelderMead convergence?\n. Yeah. I feel kinda silly pointing out simplifications but I'm pretty sure I've seen golint complain about this in the past. I don't mind your way because it's closer to C.\n. Pretty sure this would traditionally be called epsilon.\n. Why not call this Map? Then it will show up in external code as\ngo\nmap := new(fastinteger.Map)\nand so on.\n. Unrelated:\n@dustinhiatt-wf there are several PRs ready to be merged against this repo whenever you're ready.\n. This, what, the eighth implementation of an Iterator? Generics please @robpike\n. Unrelated to this PR, but have you thought about making a generic datastructures.Comparable interface? Users of the library might want to put the same item in different datastructures.\n. If Key was a top-level datastructures interface, then users could have one []datastructure.Keys variable that could be added to many different datastructures.\n. Sounds good.\n. From what I can see, this clears the cache on every call. Will inserting 100 items cause 100 cache clears and rebuilds? If so, would it be worth it to make a variadic Insertion call?\n. I don't understand why this works. Can you explain?\nEither way, it would be nice to wrap our NumCPU() calls in some utility function that would do this for us.\n. Compile error on this line:\n```\ngithub.com/Workiva/go-datastructures/set\n../../workspace/src/github.com/Workiva/go-datastructures/set/dict_test.go:205: undefined: set\nFAIL    github.com/Workiva/go-datastructures/set [build failed]\n``\n. Accidentally commented-out?\n. Shouldn't the tree be reset at the beginning of every iteration of this benchmark?\n. You can use_` in struct definitions to be explicit about padding (I've seen it used in some C bindings)\n. These padding variables can be\ngo\ntype RingBuffer struct {\n    _              [8]uint64\n    queue          uint64\n    _              [8]uint64\n    dequeue        uint64\n    _              [8]uint64\n    mask, disposed uint64\n    _              [8]uint64\n    nodes          nodes\n}\n. Shouldn't this be a constant?\n. Maybe name these return parameters?\n. Syntactic sugar, but\ngo\nswitch t := br.(type) {\n    case *iNode:\n        array[i] = t.copyToGen(gen, ctrie)\n    default:\n        array[i] = br\n}\nMight be cleaner.\n. This can just be for range c.Iterator()\n. Good point-- the new syntax was not adopted until 1.4\n. What happens if you only iterate over the first, say, 5 elements of the trie? Would dead channel remain open in the background?\n. I think this should be \"queue: poll timed out\"\nhttps://golang.org/doc/effective_go.html#errors\nhttps://github.com/golang/go/wiki/CodeReviewComments#error-strings\n. Don't need the i variable.\ngo\nfor q := range qs {\n. Please rename this struct to just Batcher. Then calling code can use:\ngo\nbatcher := new(mock.Batcher)\n. Pointer receiver methods shouldn't be used in the case of slices. A slice is already a pointer. Instead, use the \"by value\" syntax:\ngo\nfunc (items priorityItems) pop() Item {\n. Oh, you're right, slice header mutation requires a pointer receiver. Sorry, my mistake!\n. If I'm reading this correctly, itemMap is used to check presence only. If that's the case, you can make it\ngo\nitemMap map[Item]struct{}\nand then use this pattern:\n``` go\n// add item to map\nitemMap[i] = struct{}{}\n// remove item\ndelete(itemMap, i)\n// check presence\n_, ok := itemMap[i]\n```\nThis pattern reduces the memory consumption slightly, but more important, I think it clarifies the purpose of itemMap. Thoughts?\n. @dustinhiatt-wf thoughts on the duplication flag?\n. Does it make more sense for this to be\ngo\nfor range expected {\n        <-iter\n}\n. go\nfor _ := range expected {\n}\nthen?\n. We should lock here, just in case.\n. In our experience, defer has a performance overhead. Have you re-run the benchmarks on Put to see how they are affected?\n. I ran the benchmarks locally and got a similar result to what your benchmarks show. The defer version is actually faster for Put and Get. Interesting.\n4-core i7 2.8 GHz, 16GB memory\n```\n[master][~/workspace/src/github.com/Workiva/go-datastructures/queue]$ go test -bench .\nPASS\nBenchmarkPriorityQueue-8         1000000              1618 ns/op\nBenchmarkQueue-8         3000000               524 ns/op\nBenchmarkChannel-8        500000              3726 ns/op\nBenchmarkQueuePut-8        20000             84385 ns/op\nBenchmarkQueueGet-8        20000             84042 ns/op\nBenchmarkQueuePoll-8       20000             76694 ns/op\nBenchmarkExecuteInParallel-8       30000             52584 ns/op\nBenchmarkRBLifeCycle-8  20000000               111 ns/op\nBenchmarkRBPut-8        20000000               112 ns/op\nBenchmarkRBGet-8        30000000               247 ns/op\nok      github.com/Workiva/go-datastructures/queue      62.393s\n[master][~/workspace/src/github.com/Workiva/go-datastructures/queue]$ gco jlhorona/master\nNote: checking out 'jlhorona/master'.\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\ngit checkout -b \nHEAD is now at a942133... Priority queue cleanup\n[a942133][~/workspace/src/github.com/Workiva/go-datastructures/queue]$ go test -bench .\nPASS\nBenchmarkPriorityQueue-8         1000000              1621 ns/op\nBenchmarkQueue-8         3000000               503 ns/op\nBenchmarkChannel-8        500000              3532 ns/op\nBenchmarkQueuePut-8        20000             79595 ns/op\nBenchmarkQueueGet-8        20000             81775 ns/op\nBenchmarkQueuePoll-8       20000             78193 ns/op\nBenchmarkExecuteInParallel-8       30000             60249 ns/op\nBenchmarkRBLifeCycle-8  20000000               101 ns/op\nBenchmarkRBPut-8        20000000                83.9 ns/op\nBenchmarkRBGet-8        30000000               207 ns/op\nok      github.com/Workiva/go-datastructures/queue      59.569s\n[a942133][~/workspace/src/github.com/Workiva/go-datastructures/queue]$\n``\n. This exported function has an unexported type in the argument list. This unusable from an external library. I'm unsure of how to solve this. I don't think it's ideal to exportsparseBitArray`.\n@dustinhiatt-wf @tylertreat-wf thoughts?\n. I do not like this duplication. Far too fragile.\nMight I suggest a style such as:\n``` go\ntype blockOperation func(Block, Block) Block\nfunc and(Block, Block) Block { ... }\nfunc nand(Block, Block) Block { ... }\nfunc compareSparseWithSparseBitArray(operation blockOperation, sba, other *sparseBitArray) BitArray {\n    // ...\n    resultBlock = operation(sba.blocks[selfIndex], other.blocks[otherIndex])\n    // ...\n}\n``\n. lol\n. Might suggest naming thistryableMutexor something else that describes the purpose.mutexmakes me thinksync.Mutex`.\n. Some typos in this comment.\n\"trying to read something\" -> \"try to read something\"\n\"going back to trying\"     -> \"go back to trying\"\n\"if unsuccessful works\"    -> \"if unsuccessful\"\n. Looks like accidental inclusion. I think if you remove this function, CI will pass.\n. Unintentional addition?\n. Thanks for including this link!\n. You should be able to simplify this switch with\ngo\nswitch v := value.(type) {\ncase uint8:\n        return uint32(v)\ncase uint16:\n        return uint32(v)\n...\n}\n. We use the name GetBit elsewhere in the code to be consistent with our convention of SetBit. Mind changing it here as well?\n. This should probably wrap at 80 chars to fit with the other entries in the README.\n. cacher is not quite an interface... Maybe you could say in this docstring that it's added threadsafety and caching around a Persister?\n. Personally, I'd rename the cache variable to useCache to more clearly express that it's a boolean and not an object.\n. Could this be made into a method on cacher? That way you could just write\ngo\ngo c.asyncLoadNode(t, key, completer)\n. Why would this be msg:\"-\"?\n. Would you mind upgrading to the latest msgp? This generated code looks like it was generated by an older version.\n. Not seeing the commit; can you push the regeneration?\n. ",
    "tannermiller-wf": "+1 Never quite saw the point of that bool.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. Yeah, definitely remove references to non-OSS Workiva software, otherwise +1\n. +1\n. +1\n. +1\n. +1\n. I'm really starting to hate the unsafety of Go.\n+1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1 very cool\n. +1\n. +1\n. +1\n. +1 I'm so jealous that you get to pump out these cool data structures.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1 Time to rewrite in a different language :wink: \n. @alexandercampbell-wf yeah I was playing with that in december. It's pretty smooth actually.\n. Yeah, that sucks, but it's a small price to pay.\n. +1\n. +1\n. +1\n. +1\n. +1 lockless datastructures are very cool\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1 I remember all about Hilbert. Great mathematician.\n. +1\n. +1\n. +1\n. Shouldn't this be wg.add(runtime.NumCPU()) since you're starting that many goroutines?\n. Ah, gotcha.\n. @dustinhiatt-wf I've been working on calling a rust func from within Go :smile: And as far as style. I'd just do whatever is idiomatic Go since Rust can support a much more functional style, it might end up looking completely different.\n. I wish I had time to read those papers, but given that I haven't, are these values specifically called out in the papers? Or are they chosen by you and going to be further tweaked? If they're going to be tweaked, then it might make sense to expose them to a user of the package so that it can be tweaked at runtime.\n. I'm fine with the style as is.\nAs far as rewriting in Rust, I'd love to do it. But it would definitely take a lot of work and learning to rewrite it all. Of course I think it'd probably be worth it considering Rust is faster and, I find, much more pleasant to work in.\n. Cool, that's what I figured.\n. I'm with Alex, fwiw, but it probably doesn't matter.\n. Yeah, and AMD at least went through a phase where they sold triple-core processors. I actually have one at home in my desktop; fourth core unlocked and overclocked of course :smile:\n. ",
    "beaulyddon-wf": "+1\n. +1\n. +1\n. +1\n. +1\n. :+1: \n. Cool. +1\n. +1\n. +1\n. +1\n. +1\n. +1. And yeah might need to blow history away in the repo if we have mentions of products, etc.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1 meh ;p\n. +1\n. +1\n. Cool. +1\n. Cool +1\n. Cool. +1\n. Nice +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. But why would you ever need generics? ;p\n+1\n. +1\n. Awesome. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. fun.\n+1\n. +1\n. +1\n. +1\n. lol. The rule of Go.... when all else fails just add another channel.\n+1\n. +1\n. +1\n. +1\n. +1. I'd maybe go HashMap. When I see just Map I think a map function.\n. Good lord Go can really remind you of old Java/C# code.\n. So if an attempt to modify a read-only snapshot happens it's an unrecoverable state?\n. K. Fair enough. The more I've been writing Go the more I've hit these kind of errors. Not really ideal to bubble up (or at times stuck in go routines so not easily done without specific channels) but also maybe not \"panic\" level.\n. ",
    "dustinhiatt-wf": "@tannermiller-wf @beaulyddon-wf @alexandercampbell-wf \nExpanded on this PR a bit.  Added some functions I may need when evaluating nodes instead of formulas and also fixed a potential bug when adding nodes.\n. @alexandercampbell-wf, it's slower than the immutable version obviously, but I'm really just waiting to see how it does compared to calc.  If it's a trivial hit next to calc it may be acceptable.\n. Removed product references and erased their history.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. @alexandercampbell-wf, yeah, going to get back and make the corrections not noted in the paper as soon as possible :).\n. Anlhord, I use interface{} when no methods are required of the object (queues, sets, etc) and an interface when I'm trying to make an ordered generic data structure, and usually that interface has a single method like Compare.  \nI've noticed a 5x performance hit (skiplist and B-trees are good cases) by using an interface as opposed to a more primitive type.  You'll notice in the skiplist case that fetching an item by a position is quite a bit faster than by value even though the algorithm is nearly identical, and that difference is the fact that by position gets to compare uint64s while the interface has Compare called on it for every search.  The difference is not minor.  This is sad in the fact that there are a lot of cases where I may want a B-tree or skiplist to store ints or uints with optimal performance, but have to wrap them in an interface first.\nIn nearly all my profiling now I see the interface methods pop up near the top of the list.  I haven't traced the overhead completely, but I assume it involves two factors:\n1) Calling an interface method involves I2T calls in the runtime.  Haven't looked to see what is involved with this method, but the overhead is certainly there.\n2) It really hurts when I'm trying to achieve better memory locality to reduce cache misses.  By accepting interfaces, I've nearly guaranteed two cache misses for every comparison I believe, one to grab the object that's holding the concrete implementation's type and a pointer to the implementation and then another visit to actually grab the implementation.  I may be wrong on this, but I believe cache thrashing is causing some of the overhead with interfaces.\nFor anyone using these data structures, if you need absolute performance I would recommend copying/pasting the implementations and using your specific type.  \nIf I could get generics in Go I would be forever grateful to you.  I really think performance here could be greatly improved and a lot of code could be simplified.\nAs for myself, I use a lot of these datastructures in my own (and my company's) projects but I'm really tired of knowing that performance is not all it could be.  I'm finishing up the concurrent B-tree (PALM) and then I think I'm going to start porting some of these over to Rust to see what the differential is.  If it is significant, I'll probably end up porting the whole repo and dedicate myself to that language.\n. Most line sizes are 64 bytes, so it works most of the time.  We most definitely have 64-byte alignment and I think the servers we are using also have Haswells.\n. @tylertreat Yeah, pulled the branch this morning and tried a multithreaded workload using the the benchmark found here: https://gist.github.com/dustinhiatt-wf/960c5ed7834169431d77\nIn the pure insert case, \nLock: BenchmarkMultithreadedInsert-8         300       4345771 ns/op\nBuffer: BenchmarkMultithreadedInsert-8       300       3726488 ns/op\nThen I tried different combinations of workloads (pure inserts has additional overhead with allocation and GC)\n50/50 mix inserts/lookup\nLock: BenchmarkMultithreadedInsert-8         300       3960659 ns/op\nBuffer: BenchmarkMultithreadedInsert-8       500       2922099 ns/op\n25/75 mix inserts/lookup\nLock: BenchmarkMultithreadedInsert-8         500       3688026 ns/op\nBuffer: BenchmarkMultithreadedInsert-8       500       2547969 ns/op\nI think the biggest advantage will be in a read-heavy environment.\n. BAM!\n. +1\n. I can merge this, but I have to agree with @alexandercampbell-wf, I'd much prefer to use a stateful iterator instead of leaving it up to the consumer to ensure memory isn't leaked.  Especially for people coming from other languages, the duty of having to create a channel and then cancel is a burden people probably aren't used to for a simple iteration.\n@tylertreat, I'll merge as is if you want, but I'm just worried people will just forget to cancel or pass in nil and this thing will leak memory.  Up to you.\n. +1\n. +1\n. +1\n. @tylertreat-wf The stretchr guys modified testify awhile back :/.  assert.Equal(0, int32(0)) is now false.\n. +1\n. +1\n. +1\n. +1 should be safe to merge.\n. In regards to the flag, I could see a legitimate use care for either:\n1) Actually allowing duplicates\n2) Knowing that duplicates will never exist and not wanting the PQ to do the extra work.\n. @ichinaski, we'll go ahead and merge then.  Thanks for this :+1: \n. The race conditions I've seen can be highly sensitive to the environment.  I've also seen the -race flag illuminate threadsafe race conditions.  I'm guessing it's a real issue.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. @seanstrickland-wf @matthinrichsen-wf added additional info the interface docstrings.\n. +1\n. The failing test here is coming from the batcher package, I've alerted @brianshannan-wf \n. CI is fixed with: https://github.com/Workiva/go-datastructures/pull/119\n. @mmalone Awesome, thanks for the fix!  https://github.com/Workiva/go-datastructures/pull/121\nI'm also swamped right now, but if you come up with the optimal fix we can certainly get it merged.\n. Any further work I'll consider to be an improvement so I'm closing this as a bug ticket.\n. @newhook Thanks for finding this!  I'll investigate either today or tomorrow most likely.\n. @newhook Addressed in https://github.com/Workiva/go-datastructures/pull/127.  Thanks for the fix!\n. Closed as fixed.  Thanks again!\n. Yeah, you'd overflow the int64 in a lot of cases.  Unfortunately, only way to support []byte is to copy/paste the tree or use interface{}.  I'm not opposed to having those things, just don't have time to do that myself.\n. +1\n. +!\n. +1\n. Yeah, I feel as if this should be a part of that package.  Technically, you can create a new bit array of size 32 or 64 and you'll get the same functionality but at a higher cost (still O(1) but more overhead).\n. +1\n. +1\n. +1\n. +1\n. @mikeatlas That is unexpected.  I would expect get to return [c].  Sorry for the slow response, been very busy lately.  I'll take a look when I get a chance.\n. +1\n. +1\n. Addressed with: https://github.com/Workiva/go-datastructures/pull/145\n. @Theodus Is this a race condition in the test or code?  Seems like an odd solution if there's a race condition in iterate.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1. +1\n. +1\n. +1\n. +1. +1. @matthinrichsen-wf You able to make these changes?. +1. +1. Thank you!  +1. +1. +1. @jagandecapri I'll take a look this afternoon/tonight.. @jagandecapri tossed this code into the augmentedtree package and ran the test.  It seemed to pass:\n~/projects/src/github.com/Workiva/go-datastructures/augmentedtree (check-interval-tree) $ go test -run TestIntervalQueryInt$ -v\n=== RUN   TestIntervalQueryInt\n--- PASS: TestIntervalQueryInt (0.00s)\nPASS\nok      github.com/Workiva/go-datastructures/augmentedtree  0.016s\ngo version go1.8.3 darwin/amd64. \ud83d\udc4d . @Spriithy Would you mind addressing @brianshannan-wf 's question?. Once the docstrings are added, lgtm. @JulianGriggs You mind adding some docstrings?. +1. +1. +1. +1. +1. @stephane-martin can you reproduce this in a test to confirm the fix?. +1. +1. This tree struct only exists in a single dimension. There's a different struct for multi dimensional inserts.\n. Only one of the routines will call wg.Done().  The rest will get the err result from get and just die.\n. They don't need to.  Line 254 will evaluate to true once and call Done.  The other goroutines will get an error from q.Get() as we dispose it at the end of the function and they'll just quit.\n. I always feel a little uneasy setting values in cp while I iterate it.  I know in this case it would be ok but it just feels wrong.\n. Probably not, but someone who didn't understand Nelder-Mead probably wouldn't be in this code changing constants :).  Later on, I'm going to make these configurable via the configuration object and better documentation will be required then, but anyone consuming this package directly should probably have some idea how it works.\n. Subslices don't create another slice, it just creates a pointer to some positions in the original slice, which is why subslices can be dangerous for concurrency and garbage collection.\n. Yes, but len(nm.vertices) is number of dimensions + 1, returns index 0 in that case.\n. Seems like a stylistic choice, no?\n. And at some point this might be converted to Rust.  This is probably closer to what Rust supports.\n. Used delta here because it better describes the purpose of this constant, if some delta between target convergence and calculated convergence is below the targeted delta, we can cease iteration.\n. I saw some benchmarks where Rust ended up being quite a bit faster than Go, especially for their binary tree test.  Memory usage on the intensive algorithms was also improved.  I'm in favor of just rewriting the whole thing in Rust when it reaches 1.0 :).  The reduction in memory consumption and elimination of the garbage collector would be worth it I think.\n. They were actually the values recommended by the paper.  The paper further describes an adaptive algorithm where these values are not constant, which will be a further improvement to this code. \n. @tannermiller-wf, just ran golint in this package and everything passes.  Not sure if one way or the other is idiomatic Go.\n. The above will result in a hashmap that won't work :(.  Ideally, consumers would call fastinteger.New() from the hashmap folder.\n. There is commonality amongst most implementations but I'll likely pull out a common interface to a specific package.  Right now, a user could use most datastructures with the same object, (using Key, Entry, Interval interfaces).\n. True, but then we could never change what that interface looked without forcing everyone to rewrite their code even if that change was for a datastructure they don't care about.  I see that as a Golang issue and not necessarily one with this package.\n. It has to be cleared on every call because the cache is specific to an individual insertion operation (the cache is being used to track path information basically).  A faster option would probably be to just allocate on every insertion but I was concerned about memory consumption especially when skiplists already can be somewhat memory intensive (every node has two lists attached to it now).  The best optimization is probably a pool-based cache, target for further performance enhancements.\n. We're just checking to see if there are an odd number of CPUs.  In most cases a user will have 1, 2 and then some multiple of 2 thereafter.  If someone intentionally disabled a CPU to get an odd number (someone who has more than one core) this will also even that out.\n. Which would probably also keep the goroutine live.  This might be leaky in the case where the iterator wasn't exhausted during iteration.\n. Switch to C# or Rust :).\nYou can also just return an object that supports Next and Value and do for iter := c.Iter(); iter.Next(); { val := iter.Value() }\n. Damn, beat me, and yes this is another case where's Go's demos about channels look better than they are.\n. You may have to iterate through the list first and set each item to nil to prevent a leak.\n. May need to set (*items)[size-1] to nil to prevent a memory leak.\n. I know it's a bigger refactor for consumers, but this probably makes sense as a constructor argument.  I doubt anyone is going to change this after instantiation.\n. Yeah, you could just put (un)marhsal methods on the interface that take the io interfaces, or you could make (un)marshal functions on the package that take the BitArray interface and return byte arrays.  The latter is probably closer to how the standard library marshaling functionality works.\n. Not sure if you'll ever hit it, or if it matters, but two threads could have len(b.batchChan) evaluate to greater than 0 at the same time and if there was only one the other will be blocked on the next line.\n. So what happens here if 1000 goroutines are waiting to send on this channel?  Does only one get cleared before the rest panic on this close?\n. It's a function.  It doesn't technically need to be made explicit like this, but I felt it made it clear that this isn't persisted.\n. Done.\n. Out of curiosity, any reason not to use something like stretchr/testify?  . If someone just wants to use the default options this might be the only docstring they read.  Might want to mention the 10MB default here.. If the consumer requires a list of items, this means you only have to lock the mutex once for a large range.  This is usually a lot more performant than many locks back to back.  Also ensures atomicity.  \nI've found at least one large advantage to the ordering.  Let's say I expect something to be cached and I've passed in a list of keys.  When I do nil detection on the other side and find the nth item is nil, it's trivial for me to log the associated key.  . Could you do this a couple of times and verify the tree's integrity with the checkredblack function?. We typically follow golang's documentation recommendation found here: https://blog.golang.org/godoc-documenting-go-code.  Specifically, the docstring should start with the name of the function.. Is this here purely as a reference example?  If so, you might just put a link to this source code in the documentation and not include the file.. This comment doesn't really add any value.. Why the short lines here?. You might consider returning typed errors here.  It gives the caller an easy way to differentiate between errors.. This is the same error message that's returned from DecreaseKey.  Another reason to extract this into a single error type.. This is an example where a typed error would be handy.  Checking the string means that this code can never change the error message and is quite clumsy.. Should these errors be checked?. If you add b.ResetTimer you can narrow down the timing to the one operation you care about.. One thing you might consider using here is require.NoError(b, err).  Require is also in the testify lib.. Would it be possible to eliminate this loop and thus the toVisit allocation?  Seems like there may be some combination of checks in the outer loop immediately proceeding this one that could avoid it (although I could be wrong).. The public methods should have docstrings.. ",
    "stevenosborne-wf": "+1\n. +1\n. +1\n. Super minor. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. @brianshannan-wf @tylertreat-wf Comments addressed. @alexandercampbell-wf Can you review the most recent commits?\n. Investigating regression.\n. @dustinhiatt-wf @brianshannan-wf @alexandercampbell-wf Fix deadlock in dispose. Ready for review.\n. +1\n. +1\n. +1\n. @fasaxc Looks good other than the change to the copyright. Please remove that change and we can get this merged.. lgtm. lgtm. lgtm. Alignment is a little off here.\n. We're safe in here because of the lock.\n. Each routine bumps b.waiting to ensure the drain runs enough times. See here.\n. Probably want to add a comment saying that a non-positive timeout equates to no timeout.. ",
    "tylertreat-wf": "+1\n. +1\n. +1\n. +1\n. +1\n. +1\n. lgtm\nMight want to remove references to gotable in documentation.md since it won't have any meaning to anyone reading this outside of workiva.\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. @dustinhiatt-wf So is this ready to be merged? :)\n. @alexandercampbell-wf Comments addressed.\n. The stateful iterator will be surprisingly nasty with this type of trie, at least if you want to do it in a \"generator\" style.\n. There appears to be a race condition somewhere causing a deadlock:\n```\ngo test -bench=BenchmarkQueue -run=XXX ./queue\nPASS\nBenchmarkQueue-8        fatal error: all goroutines are asleep - deadlock!\ngoroutine 1 [chan receive]:\ntesting.(B).run(0xc208094600, 0x0, 0x0, 0x0, 0x0, 0x0)\n        /usr/local/go/src/testing/benchmark.go:180 +0x67\ntesting.RunBenchmarks(0x3b03f8, 0x49e5a0, 0xa, 0xa)\n        /usr/local/go/src/testing/benchmark.go:312 +0x649\ntesting.(M).Run(0xc2080683c0, 0x4a9140)\n        /usr/local/go/src/testing/testing.go:494 +0x1a5\nmain.main()\n        github.com/Workiva/go-datastructures/queue/_test/_testmain.go:138 +0x1d5\ngoroutine 5 [semacquire]:\nsync.(WaitGroup).Wait(0xc208022000)\n        /usr/local/go/src/sync/waitgroup.go:132 +0x169\ngithub.com/Workiva/go-datastructures/queue.BenchmarkQueue(0xc208094600)\n        /Users/tylertreat/Go/src/github.com/Workiva/go-datastructures/queue/queue_test.go:267 +0x37d\ntesting.(B).runN(0xc208094600, 0x2710)\n        /usr/local/go/src/testing/benchmark.go:124 +0x95\ntesting.(B).launch(0xc208094600)\n        /usr/local/go/src/testing/benchmark.go:216 +0x159\ncreated by testing.(B).run\n        /usr/local/go/src/testing/benchmark.go:179 +0x3e\ngoroutine 8 [select]:\ngithub.com/Workiva/go-datastructures/queue.(Queue).Poll(0xc2080aa040, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)\n        /Users/tylertreat/Go/src/github.com/Workiva/go-datastructures/queue/queue.go:215 +0x5b9\ngithub.com/Workiva/go-datastructures/queue.(Queue).Get(0xc2080aa040, 0x1, 0x0, 0x0, 0x0, 0x0, 0x0)\n        /Users/tylertreat/Go/src/github.com/Workiva/go-datastructures/queue/queue.go:183 +0x68\ngithub.com/Workiva/go-datastructures/queue.func\u00b7012()\n        /Users/tylertreat/Go/src/github.com/Workiva/go-datastructures/queue/queue_test.go:254 +0x58\ncreated by github.com/Workiva/go-datastructures/queue.BenchmarkQueue\n        /Users/tylertreat/Go/src/github.com/Workiva/go-datastructures/queue/queue_test.go:261 +0x251\nexit status 2\nFAIL    github.com/Workiva/go-datastructures/queue      0.012s\n```\n. Fixed the deadlock and addressed comments.\n@dustinhiatt-wf @alexandercampbell-wf \n. +1\n. +1\n. Welp, https://travis-ci.org/Workiva/go-datastructures/jobs/68482154\n. @alexandercampbell-wf @dustinhiatt-wf Weeee, build fixed.\n. Failed build fixed with https://github.com/Workiva/go-datastructures/pull/93\n. +1\n. +1\n. Looking into it.\n. Should be fixed with https://github.com/Workiva/go-datastructures/pull/100.\n. Looks like an unrelated test failed.\n. Looks like CI is passing now.\n. +1\n. Is this good to merge? @dustinhiatt-wf \n. +1\n. lgtm\n. +1\n. +1\n. +1\n@alexandercampbell-wf @dustinhiatt-wf @stevenosborne-wf \n. Thanks!\n. +1\n. +1\n. +1\n. +1\n. Interesting. The hasher pool was added as a perf optimization to avoid locking. Thought I benchmarked it. Will have to take another look at it. Maybe its size just needs to be increased if we're waiting on it a lot in high concurrency situations.\n. Fixed in #128.\n. Yeah, I'm not super thrilled with the current iterator implementation. Happy to accept PRs for it.\n. Looks more or less how I'd implement a stateful iterator. Glancing over it, I don't see any immediately obvious issues. Surprised the performance isn't much better than the goroutine/channel.\n. Individual operations not under contention appear to be about the same, though snapshotting is substantially faster after the fix:\nBefore GCAS fix:\nBenchmarkInsert-8                3000000               488 ns/op\nBenchmarkLookup-8               10000000               208 ns/op\nBenchmarkRemove-8               10000000               196 ns/op\nBenchmarkSnapshot-8              1000000              2061 ns/op\nBenchmarkReadOnlySnapshot-8      1000000              2007 ns/op\nAfter GCAS fix:\nBenchmarkInsert-8                3000000               443 ns/op\nBenchmarkLookup-8               10000000               173 ns/op\nBenchmarkRemove-8               10000000               156 ns/op\nBenchmarkSnapshot-8              5000000               350 ns/op\nBenchmarkReadOnlySnapshot-8      5000000               263 ns/op\nI imagine under high contention on certain parts of the ctrie, performance will degrade due to retries now that GCAS actually works. Would be nice to get benchmarking around contention.\nWhat do the access patterns look like in your profiling? High contention on same keys?\n. Can you quantify \"substantially slower\"? Following from the benchmarks above, I'm not sure how it would be slower in a single-threaded case.\n. Do you have a lot of snapshotting going on? It looks like the performance degradation is due to renewed/copyToGen which is caused by a snapshot. Snapshots are essentially lazily applied by copying nodes to the new generation as they are accessed, so if there are a lot of snapshots, nodes will potentially get copied a lot of times.\n. That's likely the cause of the performance slowdown since snapshotting was pretty much broken before the fix. Though indeed I am surprised renewed is that expensive.\n. lgtm\n. +1\n. lgtm\n. lgtm. lgtm. The benchmarking does this for some reason. Pretty annoying.\n. Would love to hear some ideas on how to do this better. Main issue is unsafe.Pointer does not retain any type information.\n. We could have this return an error. However, you'd have to bubble that up to Insert, Remove, and Snapshot, but there's only 1 situation where an error occurs and its due to programmer error. This panic basically indicates your code is incorrect, which should get caught at development time.\n. Is that compatible with go 1.3? Are we still trying to ensure compatibility with 1.3?\n. Damn, you're right, this is problematic because if the user doesn't read from the channel the goroutine will block. Any ideas on making a nicer iterator which doesn't have this problem?\n. Will probably just go with a stateful iterator with HasNext() and Next(), which means you can't range. Go is bullshit.\n. This is just copy-pastad from the other benchmarks :p \n. Should be able to just clear the slice instead of reallocating with b.items = b.items[:0].\n. Does this need to be inside of the mutex?\n. Nevermind, this wouldn't work since you're passing it into the channel.\n. Probably. Does that for syntax work with go1.3?\n. +1 on constructor\n. Seems to me like the BitArray interface should just have Write and Read methods exposed.\n. Seems like there could be a more intelligent/safer way to know if anyone is waiting to put stuff on the channel.\n. I don't think we care about the ordering, but might want to document it.\n. ",
    "davetucker-wf": "+1 pending removal of product references\n. ",
    "wesleybalvanz-wf": "+1\n. +1\n. +1\n. Is there a reason this is Wandkiva rather then Workiva?\n. ",
    "rosshendrickson-wf": "+1\n. +1 very very cool :smile: \n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. +1\n. Nice!\n. +1\n. +1\n. Just a general comment, it would be really nice if there was a specific benchmark you could run that would give some hint what the optimal for this was for your system and that it was noted in the readme how to figure it out.\n. Also an interesting performance tweak spot that could be a const or something.\n. ",
    "cep21": "The defer optimization is somewhat surprising for me.  My only guess on why it's not so easy to optimize the same way is that defer() will also do the unlock if something inside panics, so if the code ever panics because of some bug users of the data structure would be unable to recover.  Any other thoughts?\n. ",
    "noxiouz": "I can show you a lot of places in stdlib where defer is not used to unlock. On the other side I replaced defer only in functions without possibilities to panic and one point to return. It's hard to expect a situation where _, ok := m[\"a\"] would panic. It's a really simple cases. Also there's some kind of research here: http://lk4d4.darth.io/posts/defer/\n. ",
    "tmm1": "Futures can also be implemented elegantly using a self-pumping channel:http://thegozette.com/articles/2011/05/11/futures-revisited/\n. Basically everytime you receive a value from the channel, you send the value back to the channel for the next receiver.\n``` go\nfuture := make(chan bool, 1)\ngo func() {\n  time.Sleep(2 * time.Second)\n  future <- true\n}()\nvar w sync.WaitGroup\nfor n := 0; n < 10; n++ {\n  w.Add(1)\n  go func() {\n    val := <-future\n    future <- val\n    w.Done()\n  }()\n}\nw.Wait()\n```\n. ",
    "funny-falcon": "@tmm1 unfortunately, thegozette is not available :-( (at least, from my network)\ncan you describe that approach?\n. No, it is not elegant. It is error prone and inefficient.\nError prone, cause there is no way to determine if value already set (cause channel may be empty between fetching from and sending back), so that value could be set twice or more times.\nInefficient, cause it wakes waiters serially. Closing channel wakes all waiters at once, so does WaitGroup.\n. @alexandercampbell-wf , no, difference in an API is huge.\nWith my proposal, there is ability to wait future with external select.\nThat means, one can:\n- wait several futures at once\n- wait future and timeout (now I think, timeout should not be part of a future itself, but rather add Cancel public method)\n- wait future and not future (for example, waiting on net.Context.Done() channel https://godoc.org/golang.org/x/net/context#Context.Done ).\nThis make api much more flexible.\nI understand, that avoiding channels it a performance issue. Maybe, two Futures should co-exists in a library - one with WaitGroup for waiting, and other with channel.\n. Yes, it is good.\nShall I make a pull request?\n. added https://github.com/Workiva/go-datastructures/pull/137\n. Can't log in to your jira :-(. ",
    "anlhord": "Given the positive reply, let me show you what I currently have:\nhttp://our-gol-842.appspot.com/p/ePsSIabncM\nThis is a linked list demo:\nhttp://our-gol-842.appspot.com/p/5MMZpov8UH\nI don't yet have a working generic slice , e.g. a [] type object.\n. Use copy and paste?\n. ",
    "bruth": "Use go generate?\n. @anlhord A go generate tool could be used to output each algorithm in this repository optimized for the specified type being targeted which would alleviate the performance issues described by @dustinhiatt-wf. Of course you could copy and paste the code and change it to your needs, but then any time the algorithm is further changed (bug fixes, optimizations), you could have to manually make the changes.\nThat being said I do not know how much work it would require to write this tool to accommodate various types for each algorithm. Nonetheless I wanted to pass along the idea.\n. ",
    "cryptix": "@bruth you might want to checkout gen. It is a tool for this job.\n. ",
    "rmconsole-wf": "SOC 1 Checklist\n\n[x] All commits reviewed\n[ ] QA Review (ab3acb6e4f7ff13e00a8d8761610b0357d07cc05)\n[x] Security Review Completed if Applicable:  (N/A)\n\nTo remain in SOC1 Compliance the following users cannot merge this PR:\n- ttreat31-wf\n- tylertreat-wf\n- dzyp\n\nLast updated on Tuesday, May 05 06:05 PM CST\n. QA review can be found here: https://jira.atl.workiva.net/browse/RM-15648\n. QA review can be found here: https://jira.atl.workiva.net/browse/RM-15648\n. QA review can be found here: https://jira.atl.workiva.net/browse/RM-16142\n. QA review can be found here: https://jira.atl.workiva.net/browse/RM-16341. QA review can be found here: https://jira.atl.workiva.net/browse/RM-16341. ",
    "dzyp": "Couple of comments, otherwise awesome!  +1  F off Rosie.\n. @nikox94 Only one final comment about the errors but otherwise looks good!. +1. You are correct sir, they've really improved.  +1. @stephane-martin \nI added unit tests here: https://github.com/Workiva/go-datastructures/pull/198 that basically just use your example code. If you'd rather, feel free to pull those commits over to this PR and I'll close the other one.. Copy might be faster here.\n. Also here :).\n. So looking at the rest of the code, I'm guessing this will be the primary bottleneck as almost everything calls hash and will be linearized right here.  A suggestion might be to ask the consumer to pass in a hash factory (in the constructor, that is) or use a default if none passed in and then fill a ringbuffer with some number of hashers.  Puts to the buffer will never block and gets will be as fast as any hasher can hash.  Found that sort of model worked well in the PALM btree.\n. Looks like this can be reduced to for i, sub in arr\n. This is just a nit, but you could also just do var ErrEmptyHeap = errors.New(\"message\"). If you made this a var instead, you can eliminate copying these strings.. Hah, I was working on something similar earlier to check the pool performance.  Was wondering if it would be beneficial here to add a 0 duration so consumers could basically do a non-blocking get with a simple cursory check.. Yeah, I wrote a little app that allocated half a gig of byte arrays and then used some goroutines to grab items out of the pool and then dump them back in.  I went and looked at the pool source code and it's going to be tough to beat:\nhttps://github.com/golang/go/blob/master/src/sync/pool.go\nThey have something that looks akin to threadlocal storage that caches an item so the thread can quickly grab another.  Going to be really difficult to match that performance with any sort of FIFO queue.  Cheaters.. ",
    "tylertreat": "@dzyp I added the changes you suggested. Not really sure what an optimal number of hashers to use for the ringbuffer is, but there seems to be a slight performance regression compared to the mutex.\nWith serialized hashing:\nBenchmarkInsert  2000000               710 ns/op\nBenchmarkLookup  5000000               283 ns/op\nBenchmarkRemove  5000000               253 ns/op\nWith hasher ringbuffer:\nBenchmarkInsert  2000000               783 ns/op\nBenchmarkLookup  5000000               345 ns/op\nBenchmarkRemove  5000000               320 ns/op\nOn second thought, this probably makes sense since the benefit can really only be seen with concurrent operations.\n. Think I found a decent compromise on the iterator nonsense @dustinhiatt-wf @alexandercampbell-wf. See last commit.\n. Thanks, will need to take a closer look, but that probably needs to be an\natomic.\nOn Thu, Dec 24, 2015, 11:59 AM Matthew Newhook notifications@github.com\nwrote:\n\nI just got a report of data race in the ctrie impl on committed.\nfunc (c Ctrie) rdcssRoot(old iNode, expected mainNode, nv iNode) bool {\n    desc := &iNode{\n        rdcss: &rdcssDescriptor{\n            old:      old,\n            expected: expected,\n            nv:       nv,\n        },\n    }\n    if c.casRoot(old, desc) {\n        c.rdcssComplete(false)\n        return desc.rdcss.committed\n    }\n    return false\n}\nfunc (c Ctrie) rdcssComplete(abort bool) iNode {\n...\n            if oldeMain == exp {\n            // Commit the RDCSS.\n            if c.casRoot(r, nv) {\n                desc.committed = true\n                return nv\nRead by goroutine 9:\n  customerio/chgbuf/ctrie.(_Ctrie).rdcssRoot()\n      /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:881 +0x1e7\n  customerio/chgbuf/ctrie.(_Ctrie).Snapshot()\n      /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:318 +0xb7\n...\nPrevious write by goroutine 6:\n  customerio/chgbuf/ctrie.(_Ctrie).rdcssComplete()\n      /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:912 +0x1a1\n  customerio/chgbuf/ctrie.(_Ctrie).rdcssReadRoot()\n      /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:863 +0x78\n  customerio/chgbuf/ctrie.(_Ctrie).readRoot()\n      /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:855 +0x33\n  customerio/chgbuf/ctrie.(_Ctrie).ReadOnlySnapshot()\n...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Workiva/go-datastructures/issues/122.\n. If you have a test which can reproduce semi reliably that would be great.\n\nOn Thu, Dec 24, 2015, 3:15 PM Matthew Newhook notifications@github.com\nwrote:\n\n\nreturn desc.rdcss.committed\nreturn atomic.LoadInt32(&desc.rdcss.committed) == 1\n      }\n      return false\n  }\n  @@ -909,7 +909,7 @@ func (c Ctrie) rdcssComplete(abort bool) iNode {\n              if oldeMain == exp {\n                      // Commit the RDCSS.\n                      if c.casRoot(r, nv) {\ndesc.committed = true\natomic.StoreInt32(&desc.committed, 1)\n                              return nv\n\nI made that fix locally, but I'm still getting very occasional crashes in\na highly concurrent test case.\ncustomerio/chgbuf/ctrie.(_Ctrie).ilookup(0xc82039cd00, 0xc8203b3ee0, 0xc8203994d0, 0x0, 0x0, 0x3f9990, 0x0, 0x0, 0x8)\n    /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:540 +0x7b\ncustomerio/chgbuf/ctrie.(_Ctrie).lookup(0xc82039cd00, 0xc8203994d0, 0x0, 0x0, 0x340ca71c)\n    /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:430 +0x9d\ncustomerio/chgbuf/ctrie.(_Ctrie).Lookup(0xc82039cd00, 0xc8203b6090, 0x1, 0x8, 0x0, 0x0, 0x1)\n    /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:303 +0x111\ncustomerio/chgbuf.(_data).child(0xc82039cd40, 0xc8203b6090, 0x1, 0x8, 0x256a00, 0x2fdde8)\n    /Users/matthew/src/services/src/customerio/chgbuf/data.go:17 +0x68\ncustomerio/chgbuf.(*bucketData).child(0xc82039cd20, 0xc8203b6090, 0x1, 0x8, 0x2fe980, 0x39a00)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Workiva/go-datastructures/issues/122#issuecomment-167160254\n.\n. I haven't hit the nil pointer issue, but there definitely appears to be an issue with snapshotting (don't know if it's related to your issue or not). I ran the following program which gives the correct output unless the two goroutines are commented out and the wg is adjusted accordingly.\n\n``` go\npackage main\nimport (\n    \"fmt\"\n    \"strconv\"\n    \"sync\"\n\"github.com/Workiva/go-datastructures/trie/ctrie\"\n\n)\nfunc main() {\n    trie := ctrie.New(nil)\n    var wg sync.WaitGroup\n    wg.Add(2)\n    go func() {\n        for i := 0; i < 1000000; i++ {\n            trie.Insert([]byte(strconv.Itoa(i)), i)\n        }\n        wg.Done()\n    }()\n    go func() {\n        for i := 0; i < 1000000; i++ {\n            trie.Lookup([]byte(strconv.Itoa(i)))\n        }\n        wg.Done()\n    }()\n    //go func() {\n    //  for i := 0; i < 1000000; i++ {\n    //      trie.Snapshot()\n    //  }\n    //  wg.Done()\n    //}()\n    //go func() {\n    //  for i := 0; i < 1000000; i++ {\n    //      trie.ReadOnlySnapshot()\n    //  }\n    //  wg.Done()\n    //}()\n    wg.Wait()\ni := 1\nfor _ = range trie.Iterator(nil) {\n    fmt.Println(i)\n    i++\n}\nfmt.Println(\"size\", trie.Size())\n\n}\n```\n. I have a branch with a few fixes, but snapshotting is still broken: https://github.com/tylertreat/go-datastructures/tree/fixes\nSimpler test:\n``` go\npackage main\nimport (\n    \"fmt\"\n    \"strconv\"\n    \"sync\"\n\"github.com/Workiva/go-datastructures/trie/ctrie\"\n\n)\nfunc main() {\n    trie := ctrie.New(nil)\n    var wg sync.WaitGroup\n    wg.Add(2)\n    go func() {\n        for i := 0; i < 7; i++ {\n            trie.Insert([]byte(strconv.Itoa(i)), i)\n        }\n        wg.Done()\n    }()\n    go func() {\n        for i := 0; i < 7; i++ {\n            trie.Snapshot()\n        }\n        wg.Done()\n    }()\n    wg.Wait()\n    fmt.Println(\"size\", trie.Size())\n}\n```\nExpected size is 7, but if you run it enough times you should see values less than 7 occasionally.\n. Issue appears to be with GCAS. I made an incorrect assumption from Java (where new Object() != new Object()). In Go, this is not quite the case: https://play.golang.org/p/BBde4cX1GC. As a result, GCAS always succeeds, despite the root generation changing during a snapshot.\n. I believe I have it fixed with this: https://github.com/Workiva/go-datastructures/compare/master...tylertreat:fixes?expand=1. I haven't been able to reproduce after applying those fixes.\n@newhook can you confirm this branch fixes your problem?\n. What did you replace the hasher pool with?\n. lgtm. @fasaxc Try it with the PR I made: https://github.com/Workiva/go-datastructures/pull/181. Your fix looks better. Will close this PR.. lgtm. done. I thought so too, but what I ended up doing was:\ngo\n// Get a byte array from the pool.\nfunc (p *RBPool) Get() []byte {\n        if p.ring.Len() == 0 {\n                return make([]byte, alloc)\n        }\n        b, _ := p.ring.Poll(1)\n        if b == nil {\n                b = make([]byte, alloc)\n        }\n        return b.([]byte)\n}\nWorks OK. sync.Pool is much better now though:\nBenchmarkSlab-8                         20000000                83.5 ns/op             0 B/op          0 allocs/op                                                                    \u2502\nBenchmarkSlabParallel-8                 10000000               179 ns/op               0 B/op          0 allocs/op                                                                    \u2502\nBenchmarkMake-8                          3000000               547 ns/op            4096 B/op          1 allocs/op                                                                    \u2502\nBenchmarkMakeParallel-8                  3000000               520 ns/op            4096 B/op          1 allocs/op                                                                    \u2502\nBenchmarkSyncPool-8                     20000000                75.1 ns/op            32 B/op          1 allocs/op                                                                    \u2502\nBenchmarkSyncPoolParallel-8             50000000                24.0 ns/op            32 B/op          1 allocs/op                                                                    \u2502\nBenchmarkChannelPool-8                  20000000                71.6 ns/op             0 B/op          0 allocs/op                                                                    \u2502\nBenchmarkChannelPoolParallel-8           5000000               287 ns/op               0 B/op          0 allocs/op                                                                    \u2502\nBenchmarkRBPool-8                       20000000               111 ns/op              32 B/op          1 allocs/op                                                                    \u2502\nBenchmarkRBPoolParallel-8               10000000               158 ns/op             890 B/op          1 allocs/op                                                                    \u2502\nBenchmarkArena-8                          200000                99.0 ns/op             0 B/op          0 allocs/op                                                                    \u2502\nBenchmarkArenaParallel-8                  200000                28.0 ns/op             0 B/op          0 allocs/op. Would be nice if they implemented this: https://github.com/golang/go/issues/18802. Also, you can kind of hack it: https://github.com/jonhoo/drwmutex. ",
    "seanstrickland-wf": "+1\n. +1\n. Is there any documentation that could be updated to specify that rangetree ranges are now inclusive?\n. +1 Other than my documentation comment.  This will also fix the issue where you can't technically query for all entries.  No range query can currently reach an entry like (5, MaxInt64) even though it is a valid 2-dimensional entry.\n. @alexandercampbell-wf Yeah, don't you think it's an important detail to document?  It's knowledge that is required in order to use this data structure.  Instead of making people write a small test or dig through code to figure it out, wouldn't it be easier to specify it in the documentation?\n. +1\n. +1\n. +1\n. +1\n. ",
    "matthinrichsen-wf": "+1\n. +1\n. I would be in favor of documenting this functionality.\n. +1\n. +1. +1. Darn. I had grown partial to Wandkiva. \"Capable of wand\". \n. ",
    "brianshannan-wf": "+1\n. +1 if we don't care about ordering per above comment\n. +1\n. +1\n. +1\n. +1\n. +1. You'll need to pull in master to get the build to pass @nikepan. +1. +1. +1. +1. +1. +1. +1. +1. +1. +1 You'll need to pull in master to get the build to pass. +1. @iancmcc It looks like our travis build is still pulling in an old version of uuid, could you update that version so the tests pass?. +1. @dustinhiatt-wf @stevenosborne-wf \nWe should probably update this to use something smaller like alpine in the future. Good to know, I was just going for feature parity as I have a few of these to do and figured we could optimize later. +1. +1. +1. +1. @tylertreat-wf moved outside mutex\n. This wouldn't necessarily preserve the order of items coming in versus going out, as go routines could add the batches in any order once they get backed up, or really before too.\n. added. This isn't persistent/immutable is it? I'm not saying it should be, but you modify the internal state in all the operations. ",
    "deden88": "Good\n. Request\n. ",
    "ichinaski": "I'm happy with either choice. Strictly speaking, I would consider adding such a flag a separate, self-contained issue, and having an isolated feature branch and PR will keep things simple. But if that sounds overkill, I can include it here.\n. No problem! I'll try to add the duplicates flag in a separate branch then.\n. Good point. I used the pointer receiver in new functions merely for consistency (all existing methods in priorityItems use this approach). Also, in the case of push() and pop() the length of the slice gets changed, thus the receiver must still be a pointer as far as I understand (http://blog.golang.org/slices#TOC_5.).\n. Thanks for the tip, after catching up with the empty struct and its underlying width (0 bytes), it definitely makes sense to use it in this context.\nThe purpose of the set is indeed to keep track of existing elements, since duplicates are not allowed. I can picture some cases where supporting duplicates can be handy though, but this is out of the scope of this change. Off the top of my head, would it make sense to have a flag on PriorityQueue to determine whether or not this is permitted?\n. Well spotted :+1: \n. The constructor approach, although introducing a compromise for existing users, looks like a simpler solution overall. The flag should not be changed after instantiation IMO.\n. Cool, I'll update the PR with this change, unless there is any objection.\n. ",
    "andygrunwald": "No response since ~6 month. So i think this is not wanted\n. With merging i mean \"merge both projects together\". In what direction, doesn`t matter.\nBut maybe a link to gods might be cool to know what projects in this area exists as well.\n. ",
    "tehbilly": "Happy to help!\n. ",
    "ANDERW1263": "ja jullle poese\nOn Sat, Jul 11, 2015 at 11:59 AM, Alexander Campbell \nnotifications@github.com wrote:\n\nMinor comment, LGTM.\n@dustinhiatt-wf https://github.com/dustinhiatt-wf @beaulyddon-wf\nhttps://github.com/beaulyddon-wf @tylertreat-wf\nhttps://github.com/tylertreat-wf\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Workiva/go-datastructures/pull/102#issuecomment-120652579\n.\n. poes\n. \n",
    "jlhonora": "Great! Awesome repo, looking forward to make some time to do more meaningful contribs.\n. Good catch. I changed that part of the code just to be consistent with the rest of the functions.\nAnyways, how can you test it consistently? I just ran two benchmarks, one was faster and one was slower than the current version:\nworkiva/go-datastructures > go test -bench .\nPASS\nBenchmarkPriorityQueue   1000000          2272 ns/op\nBenchmarkQueue   5000000           388 ns/op\nBenchmarkChannel     1000000          1129 ns/op\nBenchmarkQueuePut       5000        243654 ns/op\nBenchmarkQueueGet      10000        211298 ns/op\nBenchmarkQueuePoll     10000        178354 ns/op\nBenchmarkExecuteInParallel     10000        105245 ns/op\nBenchmarkRBLifeCycle      300000          5260 ns/op\nBenchmarkRBPut  10000000           749 ns/op\nBenchmarkRBGet  10000000           193 ns/op\nok      github.com/workiva/go-datastructures/queue  76.658s\njlhonora/go-datastructures > go test -bench .\nPASS\nBenchmarkPriorityQueue   1000000          2527 ns/op\nBenchmarkQueue   5000000           386 ns/op\nBenchmarkChannel     1000000          1147 ns/op\nBenchmarkQueuePut       5000        247075 ns/op\nBenchmarkQueueGet      10000        329593 ns/op\nBenchmarkQueuePoll     10000        231860 ns/op\nBenchmarkExecuteInParallel     10000        108442 ns/op\nBenchmarkRBLifeCycle      300000          5350 ns/op\nBenchmarkRBPut   5000000           230 ns/op\nBenchmarkRBGet  10000000           644 ns/op\nok      github.com/jlhonora/go-datastructures/queue 59.819s\njlhonora/go-datastructures > go test -bench .\nPASS\nBenchmarkPriorityQueue   1000000          2350 ns/op\nBenchmarkQueue   5000000           373 ns/op\nBenchmarkChannel     1000000          1136 ns/op\nBenchmarkQueuePut       5000        239267 ns/op\nBenchmarkQueueGet      10000        191165 ns/op\nBenchmarkQueuePoll     10000        181181 ns/op\nBenchmarkExecuteInParallel     10000        152712 ns/op\nBenchmarkRBLifeCycle      300000          7282 ns/op\nBenchmarkRBPut   5000000           219 ns/op\nBenchmarkRBGet  10000000           511 ns/op\nok      github.com/jlhonora/go-datastructures/queue 54.827s\nDo you have a more standard way to run the benchmark suite?\n. ",
    "pkieltyka": "btw, I wrapped it with a few methods here: https://github.com/goware/set .. perhaps you guys can do something like this, and even better?\n. ",
    "evanh": "So I changed it up to use a Marshal and Unmarshal functionality instead of the Read/Write functions I had before. Let me know what you think.\n. So I started going down that road at first, but I found that the functions differed beyond just the block comparison. So I tried a way where I passed flags in to do decisioning but then the code got even messier.\nAs well, I realized that I actually needed to add a new function specifically for nand, to handle the extra case of dense nand sparse. With and, you can handle the dense and sparse case with a single function, since it's commutative, but nand isn't.\n. ",
    "tylerrinnan-wf": "+1\n. ",
    "blakewilson-wf": "+1\n. +1\n. +1\n. ",
    "teresarevious-wf": "@rosie run_merge_script\n. @rosie run_merge_script\n. @rosie run_merge_script\n. @rosie run_merge_script\n. RM +1\nVerified dependencies manually. RM +1\nverified dependencies. RM +1 verified dependencies.. ",
    "travisreed-wf": "rosie\n. rosie\n. @rosie run_merge_script\n. rosie\n. As long as this looks like an accurate reflection of your dependencies, I am happy\nhttps://w-rmconsole.appspot.com/pulls/Workiva/go-datastructures/175/dependencies/\n. can you add a glide.lock artifact?. ",
    "jacobmoss-wf": "@rosshendrickson-wf @ericolson-wf @alexandercampbell-wf @seanstrickland-wf @blakewilson-wf @matthinrichsen-wf @wesleybalvanz-wf \n. ",
    "johnryan-wf": "+1\n. ",
    "mmalone": "I just checked TAOCP and Knuth suggests another algorithm. I don't have an implementation (yet), but if you're interested check out Volume 3, Section 6.4 (it's page 533-534 in the newest edition). He claims it results in no performance degradation (on an average complexity basis). Cursory Googling shows some debate and a couple different techniques that are used. The implementation above seems the most intuitive (to me), but possibly sub-optimal.\nSeems like something worth nerding out on at some point. Will report back if I come up with any code worth sharing.\n. ",
    "newhook": "-               return desc.rdcss.committed\n+        return atomic.LoadInt32(&desc.rdcss.committed) == 1\n        }\n        return false\n }\n@@ -909,7 +909,7 @@ func (c *Ctrie) rdcssComplete(abort bool) *iNode {\n                if oldeMain == exp {\n                        // Commit the RDCSS.\n                        if c.casRoot(r, nv) {\n-                               desc.committed = true\n+                atomic.StoreInt32(&desc.committed, 1)\n                                return nv\nI made that fix locally, but I'm still getting very occasional crashes in a highly concurrent test case.\n```\npanic: runtime error: invalid memory address or nil pointer dereference [recovered]\n    panic: runtime error: invalid memory address or nil pointer dereference\n[signal 0xb code=0x1 addr=0x0 pc=0x19146b]\ngoroutine 5 [running]:\ntesting.tRunner.func1(0xc8200a8000)\n    /private/var/folders/q8/bf_4b1ts2zj0l7b0p1dv36lr0000gp/T/workdir/go/src/testing/testing.go:450 +0x1f5\ncustomerio/chgbuf/ctrie.(Ctrie).ilookup(0xc82039cd00, 0xc8203b3ee0, 0xc8203994d0, 0x0, 0x0, 0x3f9990, 0x0, 0x0, 0x8)\n    /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:540 +0x7b\ncustomerio/chgbuf/ctrie.(Ctrie).lookup(0xc82039cd00, 0xc8203994d0, 0x0, 0x0, 0x340ca71c)\n    /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:430 +0x9d\ncustomerio/chgbuf/ctrie.(Ctrie).Lookup(0xc82039cd00, 0xc8203b6090, 0x1, 0x8, 0x0, 0x0, 0x1)\n    /Users/matthew/src/services/src/customerio/chgbuf/ctrie/ctrie.go:303 +0x111\ncustomerio/chgbuf.(data).child(0xc82039cd40, 0xc8203b6090, 0x1, 0x8, 0x256a00, 0x2fdde8)\n    /Users/matthew/src/services/src/customerio/chgbuf/data.go:17 +0x68\ncustomerio/chgbuf.(*bucketData).child(0xc82039cd20, 0xc8203b6090, 0x1, 0x8, 0x2fe980, 0x39a00)\n```\n. The test is part of something much larger. I'll try and reproduce in something small.\n. Awesome! I'll check on Tuesday :)\n. I tested and this change is A+++.\n. I just had a look for the perf graph I generated before & after and unfortunately its gone. However, if I recall correctly the pool queue was pretty porky in the graph.\n. I didn't pool at all, just allocate a new hasher each time.\n. I think this is the fix:\ndiff --git a/tree/avl/avl.go b/tree/avl/avl.go\nindex 2174454..79ac4b3 100644\n--- a/tree/avl/avl.go\n+++ b/tree/avl/avl.go\n@@ -250,6 +250,9 @@ func (immutable *Immutable) delete(entry Entry) Entry {\n                }\n        }\n        it = it.copy() // the node we found needs to be copied\n+       if top == 0 {\n+               immutable.root = it\n+       }\nThe problem is if the node you are deleting is the root AND there are no rotations then the immutable.root is not fixed up.\n. Actually this isnt the correct fix. The following is still broken (this graph is ordered lexicographically not numerically) :(\n\nDelete 6 here leads to this bogus graph\n\n. I think this is the correct fix.\n```\ndiff --git a/tree/avl/avl.go b/tree/avl/avl.go\nindex 2174454..b3b349a 100644\n--- a/tree/avl/avl.go\n+++ b/tree/avl/avl.go\n@@ -251,6 +251,7 @@ func (immutable *Immutable) delete(entry Entry) Entry {\n        }\n        it = it.copy() // the node we found needs to be copied\n\noldTop := top\n        if it.children[0] == nil || it.children[1] == nil { // need to set children on parent, splicing out\n                dir = intFromBool(it.children[0] == nil)\n                if top != 0 {\n@@ -272,6 +273,11 @@ func (immutable *Immutable) delete(entry Entry) Entry {\n                }        it.entry = heir.entry\n\n\nif oldTop != 0 {\ncache[oldTop-1].children[dirs[oldTop-1]] = it\n} else {\nimmutable.root = it\n}\n            cache[top-1].children[intFromBool(cache[top-1] == it)] = heir.children[1]\n    }\n```\n. +1 thanks!\n. +1 Thanks for that!\n. I'm experimenting with this impl I just whipped up. Its still very very slow. Still digging... not sure if you have insight?\n\n\n\n```\ntype istate struct {\n    array []branch\n    l     PersistentList\n    index int\n}\nfunc newIState(i iNode, c Ctrie) *istate {\n    main := gcasRead(i, c)\n    switch {\n    case main.cNode != nil:\n        return &istate{\n            array: main.cNode.array,\n        }\ncase main.lNode != nil:\n    return &istate{\n        l: main.lNode,\n    }\n}\nreturn nil\n\n}\ntype Iterator struct {\n    c     Ctrie\n    stack []istate\n}\n// Next ...\nfunc (i Iterator) Next() Entry {\n    for {\n        if len(i.stack) == 0 {\n            return nil\n        }\n    state := i.stack[len(i.stack)-1]\n    if state.array != nil {\n        if state.index >= len(state.array) {\n            i.stack = i.stack[:len(i.stack)-1]\n            continue\n        }\n\n        br := state.array[state.index]\n        state.index++\n\n        switch b := br.(type) {\n        case *iNode:\n            // start := time.Now()\n            ns := newIState(b, i.c)\n            // fmt.Println(\"newIstate: \", time.Now().Sub(start))\n            i.stack = append(i.stack, ns)\n\n        case *sNode:\n            return b.Entry\n        }\n    } else {\n        if state.l == nil {\n            i.stack = i.stack[:len(i.stack)-1]\n            continue\n        }\n        head, ok := state.l.Head()\n        if !ok {\n            i.stack = i.stack[:len(i.stack)-1]\n            continue\n        }\n        state.l, _ = state.l.Remove(0)\n\n        return head.(*sNode).Entry\n    }\n}\n\n}\n// Iterator returns a channel which yields the Entries of the Ctrie. If a\n// cancel channel is provided, closing it will terminate and close the iterator\n// channel. Note that if a cancel channel is not used and not every entry is\n// read from the iterator, a goroutine will leak.\nfunc (c Ctrie) Iterator2() Iterator {\n    snapshot := c.ReadOnlySnapshot()\n    return &Iterator{\n        c:     snapshot,\n        stack: []*istate{newIState(snapshot.readRoot(), snapshot)},\n    }\n}\n```\n. Actually, I think its faster. I was confused in my benchmark but other databasey factors :) That said on a performance note, after your ctrie fix for the generations the ctrie is substantially slower. My profiling of lots of inserts shows 16% of the time in gcasRead/atomic.LoadPointer.\n. No, my test basically wrote 1000000 unique items into the ctree serially.\n. My test case shows ctrie.Insert at 16.75s with the new ctrie and 1.76s with the old. The test isn't standalone (it has lots of other stuff in there), but that part of the profile stood out to me.\n\n\n. Yes, I essentially have a transactional data model, So each write transaction creates a snapshot of the data and then alters the snapshotted version. On commit the snapshot is swapped with the formerly committed data.\n. Yeah, makes sense. I think I can rearrange the implementation to snapshot differently to avoid the additional overhead.\n. ",
    "Theodus": "Sorry about that. I hadn't tested the original for Go 1.3 compatibility.\n. That's fine with me.\n. The next commit is the last one. It will fail because the import path of bitarray is changed to the Workiva version and it has to be merged before it will compile.\n. Disregard the last comment, I underestimated Travis CI.\n. No problem.\n. The race condition is that the loop wasn't broken after the channel received the 100'th element. Any values in transit would still be received, causing the loop to iterate and increment the counter.\n. That's probably a better solution then removing the test entirely now that I think of it.\n. ",
    "brycewilson-wf": "+1\n. +1\n. +1\n. ",
    "mikeatlas": "Anyways, the point was that I was hoping TakeUntil could serve as a Peek (a common operation on many queue data structure implementations) but the behavior I'm seeing doesn't indicate that it's usable nor that TakeUntil behaves as I expected from the documentation.\n. Closing since for now since the maintainers didn't comment on this behavior being correctly defined as expected or not. Will reopen if others see a reason.\n. I implemented this since it was what I was chasing regarding #138 \n. great! \n. Thanks @dustinhiatt-wf \n. ",
    "DavyC": "PR#147\n. ",
    "aviary2-wf": "Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on Slack: #support-infosec.. ",
    "aviary-wf": "Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 1\n- Watched file aviary.yaml added\nAs a result of the finding(s) listed above, a security review is required for this pull request.\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Raven\nNumber of Findings: 0\n. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Raven\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Module Findings\nNo security relevant content detected. Please review for security relevance and request security review as needed.\n. ## Raven\n\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Raven\n\nNumber of Findings: 0\n. ## Module Findings\nNo security relevant content detected. Please review for security relevance and request security review as needed.\n. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ## Security Insights\nNo security relevant content was detected by automated scans.\nAction Items\n\nReview PR for security impact; comment \"security review required\" if needed or unsure\nVerify aviary.yaml coverage of security relevant code\n\n\nQuestions or Comments? Reach out on HipChat: InfoSec Forum.. ",
    "jim-slattery-rs": "fixes https://github.com/Workiva/go-datastructures/issues/141\n. without the Poll() code change in place, the next Put() would hang indefinitely\n. ",
    "sheldonlyr": "$go env\nGOARCH=\"amd64\"\nGOBIN=\"\"\nGOEXE=\"\"\nGOHOSTARCH=\"amd64\"\nGOHOSTOS=\"linux\"\nGOOS=\"linux\"\nGOPATH=\"/home/sheldon/Gopath\"\nGORACE=\"\"\nGOROOT=\"/usr/local/go\"\nGOTOOLDIR=\"/usr/local/go/pkg/tool/linux_amd64\"\nGO15VENDOREXPERIMENT=\"1\"\nCC=\"gcc\"\nGOGCCFLAGS=\"-fPIC -m64 -pthread -fmessage-length=0\"\nCXX=\"g++\"\nCGO_ENABLED=\"1\"\n. $go version\ngo version go1.6.2 linux/amd64\n. ",
    "riaan53": "Im seeing the same. (Go 1.8)\n```go\npackage main\nimport (\n  \"github.com/Workiva/go-datastructures/queue\"\n)\nfunc main() {\n  rb := queue.NewRingBuffer(5)\n  rb.Get()\n}\n```\n100% cpu usage for above. ",
    "kitech": "100% CPU\nany news for this? . I need do this:\n```\nfor rb.Len() == 0 { time.Sleep(50 * time.MillSecond) }\nitem, err := rb.Get()\n```. another patch use chan notification, run better now\n```\ndiff --git a/queue/ring.go b/queue/ring.go\nindex dfd0b53..8b40dc9 100644\n--- a/queue/ring.go\n+++ b/queue/ring.go\n@@ -57,6 +57,7 @@ type RingBuffer struct {\n    _padding2      [8]uint64\n    mask, disposed uint64\n    _padding3      [8]uint64\n+   condC          chan bool\n    nodes          nodes\n }\n@@ -67,6 +68,7 @@ func (rb *RingBuffer) init(size uint64) {\n        rb.nodes[i] = &node{position: i}\n    }\n    rb.mask = size - 1 // so we don't have to do this with every put/get operation\n+   rb.condC = make(chan bool, 0)\n }\n// Put adds the provided item to the queue.  If the queue is full, this\n@@ -115,6 +117,12 @@ L:\nn.data = item\natomic.StoreUint64(&n.position, pos+1)\n\n\nif rb.Len() < 3 {\nselect {\ncase rb.condC <- true:\ndefault:\n}\n}\n    return true, nil\n }\n\n@@ -146,6 +154,12 @@ L:\n            return nil, ErrDisposed\n        }\n\nif rb.Len() == 0 {\nselect {\ncase <-rb.condC:\n}\n}\n+\n        n = rb.nodes[pos&rb.mask]\n        seq := atomic.LoadUint64(&n.position)\n        switch dif := seq - (pos + 1); {\n@@ -186,6 +200,10 @@ func (rb RingBuffer) Cap() uint64 {\n // queue will return an error.\n func (rb RingBuffer) Dispose() {\n    atomic.CompareAndSwapUint64(&rb.disposed, 0, 1)\nselect {\ncase rb.condC <- true:\ndefault:\n}\n }\n\n// IsDisposed will return a bool indicating if this queue has been\n```\n. ",
    "azr": "Not at all :)\n. is it okay like this ? LGTM :)\n. ?\n. Hey no problem :D\n. ",
    "nikox94": "I'm working in a fork where I'll try and finish the implementation, and complement it with an interface.. I have not yet had time to remove the interface and return the struct. I will do this ASAP and will ping you guys.\nThanks,\nNick. I seem to have addressed the Interface -> struct change. Could we merge soon?. Great comments, @dustinhiatt-wf. I will sit down to address them ASAP.\nRegards,\nNick. @dustinhiatt-wf , for both of your comments - I have basically defined custom types, so that a sophisticated client can do Type-checking of the error. The message is only for additional information and is different across methods in order to provide more context of the errors. I feel it's better to have things like that? I could externalise the constants but again, they are different across different methods in order to provide more context.. Hmm... I am not sure. Perhaps I don't really need that layer of abstraction, but.. I don't think it hurts either. I am also thinking of making the Priority variable of Entry exported... I had forgotten that people might want to use it.. Btw. what do Aviary and Rosie do?. Done :). :+1: about the blog article. Am going through it now and will change the code soon.. @joshhayes-sheen-wf: I've written a small attribution file. I'm still not sure it's acceptable to have them here like this though. I will ask the professor.. fixed. :100: . Hmm.. yes... you're right.. :100: . I will need to rethink the benchmarks as a whole. they are designed a bit iffy at the moment.. It's not that clumsy and people do do that, but.. I suppose what you propose is more sophisticated and elegant.. ",
    "matthewlorimor-wf": "Security +1\n. +1. ",
    "colefeisthamel-wf": "RM +1 manually scanned dependencies. RM +1 manually reviewed dependencies.. RM +1 manually reviewed dependencies. ",
    "ericklaus-wf": "+1. I don't usually love APIs like this, where the order of things in the returned list has an important correspondence to the input. Is there a big performance or usability benefit to accepting a list of strings?. Okay, that's reasonable.. ",
    "tomdeering-wf": "@dustinhiatt-wf, I assume you have write access to this repo? Would you be able to merge this when ready please?. That's true. Or I could just make that a required param rather than an option.. Nope, no reason. I was just avoiding adding dependencies to this repo.. Ha. Now that I say that, I see that other tests in the repo do already use testify. I'll go ahead and use it then.. Done.. ",
    "travissmith-wf": "+1. ",
    "joshhayes-sheen-wf": "@nikox94 Are the PDF files you're contributing under a license that's compatible with the repository? They don't have any license or attribution visible and look like they're maybe your teachers?. ",
    "nikepan": "Updated. ",
    "szyhf": "I'm not sure if other data struct has the same problem, may be you can check them \u263a\ufe0f @dustinhiatt-wf @matthinrichsen-wf @aviary2-wf . ",
    "fasaxc": "@trevorgray I've pushed the requested markups.. D'oh, I also made a fix: https://github.com/Workiva/go-datastructures/pull/182/files. Sorry, should have flagged that I was about to put up the PR!. ",
    "jagandecapri": "Hei @alexandercampbell-wf @dustinhiatt-wf, any help on the above question? :). @dustinbraun-wf I identified where was the mistake in my code. I was importing github.com/golang-collections/go-datastructures/augmentedtree. Noticed that it should be github.com/Workiva/go-datastructures/augmentedtree. My mistake. Thanks for checking on this.. ",
    "JulianGriggs": "Sorry I forgot about this PR. I just added the requested docstrings.. ",
    "andreis": "I've noticed this as well, .Get only returns half of min(number, pq.Len()). It's really annoying, and I have no idea what causes it.. Nvm\nhttps://github.com/Workiva/go-datastructures/blob/master/queue/priority_queue.go#L79\nThis should be \nif len(*items) == 0\ncc @dustinhiatt-wf @ichinaski . ",
    "nightrune": "I just hit this as well. I don't need btree yet so its not urgent, but this has been opened for 22 days.. ",
    "rsc": "I sent a PR removing go.uuid entirely. It was not contributing much.\n. I sent replacement PR #192, which removes go.uuid entirely. Then it doesn't matter what Travis is supplying.\n. Thanks!. ",
    "Rooster17678": "I'll make one.. It is at https://github.com/Rooster17678/go-datastructures\nThis is the first go program I have ever written so I recommend validating it yourself.. ",
    "evandesantola": "I'm going to work on this and make a pull request.\n. I looked at the fib-heap benchmarks and realized why no one has implemented a PQ as a fib-heap yet.. ",
    "stephane-martin": "I don't really understand why the PR takes so long to be integrated. Is there a problem ?\nPlaying with hashes, it looks like that the words 'costarring' and 'liquid' have the same fnv32a hash.\nSo the previous POC can be simplified, without any \"fakehash\": \nfunc main() {\n    trie := ctrie.New(factory)\n    trie.Insert([]byte(\"costarring\"), 1)\n    fmt.Println(trie.Lookup([]byte(\"costarring\")))\n    trie.Insert([]byte(\"liquid\"), 2)\n    fmt.Println(trie.Lookup([]byte(\"liquid\")))\n    trie.Insert([]byte(\"costarring\"), 3)\n    fmt.Println(trie.Lookup([]byte(\"costarring\")))\n    trie.Remove([]byte(\"costarring\"))\n    // foobar is supposed to be removed, but the next lookup returns 1\n    fmt.Println(trie.Lookup([]byte(\"costarring\")))\n}\nThank you in advance for your feedback.\n. @dustincataldo-wf see https://github.com/Workiva/go-datastructures/issues/194. Thanks :-)\nLe 1 juillet 2018 23:18:42 Dustin Hiatt notifications@github.com a \u00e9crit :\n\n@stephane-martin\nI added unit tests here: #198\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n\n. ",
    "stefankraus-wf": "LGTM \ud83d\udc40. There is also a section in our docs about reducing build duration that may help. . ",
    "charliestrawn-wf": "+1. ",
    "kevinfrommelt-wf": "+1. ",
    "HaraldNordgren": "@dustinhiatt-wf Ping. ",
    "detailyang": "It looks like some tests broken, because the diff is actually below 0. ",
    "benechols-wf": "Why an interface instead of just directly exposing the a fib heap struct with the same public methods? . as far as the interfaces go, check out this blog talking about design in go: https://medium.com/@cep21/what-accept-interfaces-return-structs-means-in-go-2fe879e25ee8#.geu8ysx4g\nAviary and Rosie are part of our continuous integration systems. \nRosie runs the checks to validate a PR is ready and aviary is part of a watcher that makes system to watch for changes to sensitive files (and thus needing special reviews) . ",
    "trevorgray": "To support cancellation this should be:\nselect {\ncase ch <- main.tNode.Entry:\ncase <-cancel:\n    return errCanceled\n}. ",
    "patkujawa-wf": "A code comment saying what's in the PR description would be really helpful, I think.. ",
    "travissanderson-wf": "to me it seems unintuitive that this would return objects that do not pass checker, I'd expect the opposite behavior. "
}