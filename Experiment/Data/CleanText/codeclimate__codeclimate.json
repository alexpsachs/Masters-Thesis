{
    "kevinSuttle": "It's a Docker issue. If you're on Mac, check that boot2docker is installed and running (boot2docker up). \nhttps://github.com/codeclimate/codeclimate/issues/2\n. I set it in my config.fish file:\nset -x DOCKER_HOST tcp://192.168.59.103:2376\nset -x DOCKER_CERT_PATH /Users/kevinsuttle/.boot2docker/certs/boot2docker-vm\nset -x DOCKER_TLS_VERIFY 1\nSo, substitute bashrc or zshrc\n. Fixed by it. \n. It's mentioned in the README, but agree it should be surfaced or mitigated as in https://github.com/codeclimate/codeclimate/issues/2. \n. :+1: thanks!\n. Sure. \n. ",
    "pbrisbin": "We've seen this error happen if you've not set the environment variables needed by boot2docker.\nI believe the fix is to put something like eval $(boot2docker shellinit) in your shell startup file, but I'm not 100% sure (I'm a Linux user).\n. Or write the output of boot2docker shellinit into your startup file directly (to avoid the eval on every new terminal)\n. @kevinSuttle sorry, was your issue (#2) fixed by boot2docker up, or still failing with the same error?\n. OK good. Then setting those env vars may fix @stefanpenner 's issue.\n. With #7 we attempt to catch this on install. Sorry it that wasn't present for you. Glad it's working now.\n. I like to suggest closing this issue:\n- boot2docker is now deprecated in favor of docker-machine\n- Helpful suggestions to correct environment issues sounds like a nice feature, but to implement it generically and correctly is not something I feel is worthwhile at this time.\n@kevinSuttle WDYT?\n. Hi! Can you tell me where this incorrect link is appearing?\n. I found it and fixed. Thanks reporting!\n. Thanks for reporting this. Can you try running docker info and see if you get the same error?\n. > FATA[0000] Error response from daemon: client and server don't have same version (client : 1.18, server: 1.17) \nIs the error I was referring to, sorry if that wasn't clear. I'm trying to pin down if the mismatch is between your local client and your local server, or your local client and the docker hub server.\nAre you able to pull any images from docker hub?\n. What does docker version say? Here's mine for comparison:\n...\nClient API version: 1.18\n...\nServer API version: 1.18\n...\nI'm pretty sure this is a problem in your local setup. Perhaps you've updated docker but not restarted the server, so a new client is talking to an old server.\nMy output above shows that 1.18 is not a problem for connecting to docker hub.\n. OK, I just realized the problem. The codeclimate image itself contains a docker client (to pull and run the engine images). It is at API Version 1.18. That's why it fails when it talks to your server which is at API Version 1.17.\nWe're currently thinking through how we're going to address this. Sorry for the trouble!\nIf it's a possibility, updating your local docker so that it's using API Version 1.18 should work around the issue for now.\n. Hey @benjamin-thomas thanks for the suggestion. That or something similar sounds like a really good way around this issue. I'll discuss with the team and see if we can implement something like that. In the meantime, can I suggest the following workaround?\n- Clone this repo\n- Update this line to the version you need\n- docker build -t codeclimate/codeclimate .\nThe wrapper script runs whatever image is present so you can still make install and invoke codeclimate analyze and it will run this image with the correct client.\n. Ah, that's too bad. I think for now the suggested fix will have to be to update your Docker. Sorry about that.\n. LGTM\n. LGTM\n. @laszlof have you tried outputting to a file? I ask, because I thought the colorizing library we were using was smart enough to not colorize unless connected to a tty. If that's not the case, then yes, we should implement that behavior.\nEDIT: tested myself, looks like that's not the case. I'll look into implementing that.\n. >  I would expect it to produce an array of json objects that could be easily parsed. The entire thing should be a valid JSON object in my opinion.\nYes that makes total sense, and was probably an oversight on our part.\n. Hi @kevinburkeshyp , sorry about this. I'm not exactly sure why that's happening, but you can ignore the warning for now. I'll create a card in our internal Trello to figure this out.\n. I think it sounds like we're good here? Thanks for confirming @ntwb \n. Yes, I agree it's inconvenient and we're definitely working on ways to make this better -- unfortunately, it's a tricky problem.\nFor now the idea is that you use codeclimate init to create the file, and codeclimate engines:x to modify it. If those are true, you should not receive permissions errors because both operations run as the same user.\nUntil we implement a proper fix for the permissions of the codeclimate.yml file, I suggest the following:\n- Set the file back to root:root and 644 permissions (or delete it and re-init)\n- engines:enable should work now\n- If you have to modify it by hand, please use sudo\nLet me know if this works.\n. OK, I'm glad you're found a workaround. I'll close this since we are tracking (aspects of) this problem in other Issues and our Trello board.\n. Sorry about that! I didn't realize we hadn't pushed our base image. It's up now, so please try again\n. Thanks for the info, and sorry for the trouble. I think there's a number of subtle user and permissions issues that we'll need to work through to address this.\nThe generated codeclimate.yml being root-owned is not desirable but is expected for the time being. We're stilling working through potential solutions for this, but shouldn't itself cause errors.\nThe solution for (files like) dev keys is probably to make the engines more tolerant of unreadable files and skip them, rather than erroring. Unfortunately this'll have to be implemented in each engine so it might crop up from time to time.\nI've created cards in our internal Trello to track both of these and will report back any progress.\n. @alexpjohnson (and possibly @mhlavac), I would also recommend putting these files into exclude_paths if they're not intended to be analyzed. That should prevent the engine from attempting to read them and solve these errors.\n. @alexpjohnson can you confirm that adding - dd/**/* to exclude_paths solves your particular permissions issue?\nIf so, I'd like to close this and track the general user/permissions problems separately.\n\nOf course this is not best solution, in my case it's a dev ssh key that is used to connect to our Docker container and it should really be 600.\n\n@mhlavac  I agree, and would recommend you also try adding - server/dev/id_rsa do your exclude_paths and see if that solves the problem, without opening up those permissions.\nEDIT: I had at-mentioned the wrong users in my original comment.\n. Hi @alexpjohnson , I'm sorry, my replies were to the opposite users I intended! My first comment was meant for you, and my second for @mhlavac. I've edited the comment to (hopefully) clarify.\nThe /code prefix in the error message can be a bit confusing. Basically your local files are placed in /code within the container. The exclude_paths, shouldn't include it and should be relative to your local directory.\nPlease try - dd/**/* (not - /code/dd/**/*) and see if that fixes it.\n. Hmm. OK, I'll have to dig a bit further into this I guess. Is dd some kind of special file, a socket or something? Errno::EOPNOTSUPP is a strange error.\n. Also, are you able to run rubocop on this project normally (not via the Code Climate CLI)?\n. There have been a number of problems being reported and worked through in this Issue. I'm going to try and summarize:\nResolved:\n- @mhlavac permission denied on id_rsa\nExcluding or modifying permissions solved the problem\n- @Jared-Prime can't access tmp stuff\nExcluding (once the known \"excludes too big\" problem was fixed) solved the problem\nOpen:\n- @alexpjohnson permission denied on dd\nWe're definitely working on making excludes more intuitive, but I think the issue here is still that our attempts to exclude this directory aren't working. I would try the following:\nexclude_paths\n  - dd\n  - dd/**\n- @acarpe can't work in the /code directory itself\nThis is new, and I believe a different kind of error than @alexpjohnson 's or the other follow-on issues. Would you please open a new GitHub issue where we can trouble shoot it specifically?\n. Hmm, that's strange. I would have expected the - \"tmp/**\" entry to work and prevent rubocop from trying to read that file. I'm sorry to not have an answer yet, but I'll keeping digging into this and report back any findings.\n. Hmm, that does seem possible. But I can't picture a way files would be generated after the list of files to exclude is built but before the analysis is run. Are you running tests, or the app in another terminal at the same time as the codeclimate analyze command?\n. @sergey-alekseev (and @pnomolos), we identified (and spent a lot of time fixing) #82 which may be what's happening here. So far we've only made the fix in the eslint engine but are in the process of updating other engines. I'll report back once we've made the same fix to rubocop and see if that addresses things.\n. LGTM\n. Minor comments, LGTM besides.\n. Minor style thing (I feel crowded when block elements aren't separated by whitespace :)), LGTM\n. Hi @d-Pixie, sorry for the trouble here. I don't have a fix or workaround just yet, but I did want to offer some context:\n- We parse each issue's JSON as it's emitted, so the fact that the error occurs in JSON parsing code doesn't mean a complete linting step was done and a separate parsing step was failing\n- We intentionally run each engine in a restricted environment, which includes an artificial memory limit, so increasing available RAM on the VM or your local machine wouldn't help\nOne solution could be to allow users to lift the timeout and memory restrictions themselves via a command line flag. We've seen a few failures like this (for CLI users and on the server) due to large repos hitting our limits, so we're definitely looking into solutions.\nDoes your repo happen to be open source? It would be great for us to test with it if possible.\n. No worries, we'll probably be able to find or create test projects for this, if for some reason we need to look at this specific one I can let you know.\n. Actually, looking again, it is the codeclimate image running out of memory, not the engine itself, so increasing available memory to your boot2docker VM could help. I believe you can tune this in the Virtual Box or VMWare GUI (whichever backend you're using).\n. Besides the test failure, this LGTM\n. Sorry, I thought the Error in the PR status was Circle. LGTM\n. What happens if you do run this with an engine that doesn't have an app user? When we were debugging the codeclimate.yml permissions issue, we were able to run as a user id that didn't exist in the engine and (as long as we didn't do something that required actual permissions) it didn't seems to blow up.\n. And what about --user 9000?\n. I think that using --user 9000 is nicer to engine authors:\n- You're not running as root, our only goal here\n- If the engine follows the spec, 9000 == app, and the engine could use that in whatever way it wants\n- If the user doesn't exist, you're basically running as no one; you can't create files and you can't access resources not available to the \"everyone\" bit -- aka exactly what we'd want\nI'm not sure I see a downside.\n/cc @brynary \n. LGTM, but can someone remind me why we're not using Timeout.timeout?\n. @fhwang did we happen to fix this with some recent changes?\n. Thanks for letting us know @bassrock \n. LGTM - I'm fine with the error given that it's temporary and I can't think of anything better. @brynary may have an opinion since it's user facing.\n. Eventually we should automate this so updating the VERSION file is all that's needed. But until, then LGTM too.\n. LGTM - is this a hanging yellow?\n. LGTM\n. Worth a shot!\n. Closing this but will leave the branch. I think it's a good refactor, but using Thread.abort_on_exception seems to have solved the hung builders for now.\n. Hi, thanks for the report and PR!\n\nFirst, codeclimate-fixme isn't in config/engines.yml nor could I find it in the docker registry. Are there plans to add it?\n\nIf a particular engine is not yet in engines.yml that means it's not ready for use . We do plan to incorporate this engine (and many others) when it's done, at which time we'll also add it to engines.yml.\n\nSecond, I guess we should not try to run engines if they're not in config/engines.yml\n\nIn general, that's correct. An engines developer does need to be able to run engines not yet in engines.yml to test their work. For this we have the undocumented (I think?) --dev flag which allows you to give any engine name and (if a docker image for it can be found on your system) codeclimate analyze will run it regardless of engines.yml.\nYou can see the implementation of that here.\n\n... we'll ignore unregistered engines and output a warning.\n\nThanks for this PR, we should have time to review it and potentially merge it this week.\n. Hi @fproulx-pbox -- no, we have not implemented a Brakeman engine yet. That does mean that the new engines-based analysis does not have this feature.\nHowever, our original, non-engines analysis is still fully supported. If you rely on Brakeman, you can keep it by not turning on engines until we've reached feature parity in this way.\nWe're working hard to port all existing analyses (Brakeman, duplication, python, etc) to the new engines-based platform -- unfortunately, I don't have any concrete timelines to provide just yet.\n. I agree that would be better, but I'm not sure yet how much effort it would require and would consider it a \"nice to have\" against the other work we're doing. If you'd like to try and implement it, we'd be happy to review a PR though!\n. Nice! This LGTM, I'll look to merge it and release on Monday.\n. This change LGTM, but it seems you didn't have to update any tests -- is the formatter not tested? Should it be?\n. What a great diff! LGTM\n. I wouldn't call it a \"refactor\", but LGTM ;)\n. What are the permissions on the current directory where you run codeclimate analyze? You should be able to see that with stat . or ls -l ../.\n. So that is the issue. You've only given read access to the user bit. The group and (most importantly) all cannot read this directory.\n7 - user (503/silk) can read (+4) / write (+2) / execute (+1)\n0 - group (20/staff) can do nothing\n0 - all can do nothing\nNote: for directories \"execute\" means \"able to change into the directory and/or list directory contents\".\nThese are unusual permissions for a project directory and prevents anyone other than the user (503/silk) from entering the directory or seeing anything within it. This is also preventing our CLI from reading the code for the purposes of analysis (it does not run as you, it runs as a dedicated, unprivileged user).\nI'd recommend opening up the permissions on this directory with chmod 755 .\n7 - user can read/write/execute\n5 - group can read/execute\n5 - all can read/execute\nIf this gets you passed your current error but you find more permissions errors on files or directories within the project, it's possible they also have unexpectedly restrictive permissions on them as well. In that case you can either exclude them using exclude_paths or modify their permissions similarly.\n. Does\nyaml\nexclude_paths\n- public/**\n- vendor/**\nNot work?\n. > why not adding a check on permission before starting?\nUnfortunately we have to prioritize improvements like this against all the other things we want to do and we just haven't gotten to it yet. Please know that it's on our roadmap though.\n. @acarpe i believe your issue is the same as #82, which we've hopefully just released a fix for. I'm going to close this and centralize discussion there.\nSorry for the troubles and the long time to fix, it was a much more complicated issue than it appeared.\n. This LGTM with two notes:\n- We double-quote all strings (also, %w[ ] might be good for the spec arguments)\n- Adding a public #dev_mode? only for the spec is a smell to me, but we have plans to upgrade to a real options parser soon, so I'm OK not worrying about it for now.\n/cc @GordonDiggs WDYT?\n. Pulled some more, similar changes over, this time for the PlaintextFormatter\n. Going to ignore the CC check, it's Engine being too long, something this PR doesn't contribute to in a meaningful way IMO.\n. Always.\n. It's probably mergeable (after dealing with the conflicts), the major blocking TODO has been resolved. We've just been too strapped for time to pick it back up. I'll close and re-open later.\n. We have a lot of desperate places across our systems that need content that lives in the codeclimate.yml. I've said, and I know I've heard you say, basically, \"anywhere that needs to read codeclimate.yml should go through this gem\". It doesn't make sense (to me) to do anything else. The only reason that's not the case here already is that the gem didn't exist when it was written.\nWhen places (like this one) do their own Yaml.parse instead of using the gem you can have all sorts of problems and unexpected behavior.\n- Using data from an unvalidated config for unexpected results\n- Forgetting to use SafeYaml in your custom reader\n- Getting no-method for nil instead of meaningful errors the gem provides on mis-use\n- In one place \"no engines\" might mean [] but in another it means nil\n- New developers don't realize the gem exists and start building custom validation and warning logic that duplicates what the gem already provides\n- We find a bug in cc-yaml logic and fix the gem, but that logic is duplicated here and goes unfixed\n- etc, etc\nSome of these have happened and some of these are just general reasons for DRYing code.\n. LGTM\n. @brynary I agree with you and made that comment myself\n. @brynary scratch that, sorry -- I forgot I said both may make some sense earlier... The sense I see in this way would be:\n- It still is part of validate-config experience, engines:validate is a bonus\n- I wouldn't normally say it was worth it except this implementation is quite small and actually easier this way than the other (because of our current inheritance-based architecture)\nUp to me: I'd refactor the inheritance in the Engines commands to use composition for the interaction with the config that needs to now be shared. Then I'd use that shared object to implement this only in the validate-config command.\n. LGTM, understood that this is really hard to test so we're deferring, but we should try to come back to that.\n. You can check the permissions directly with\nstat tmp/asset_rewrite-cache_path-RFcmONBd.tmp\n. @elwayman02 we're still working on a fix for these issues, but we had a few questions and I'm wondering if you'd be willing to help us better understand what's going on:\n1. You mentioned a script that cleans the tmp/ directory of these files that codeclimate can't analyze. If you run this script immediately before analysis, does it still error?\nNote: you may need to do a quick sudo rm -r tmp && mkdir tmp to correct the permissions from our earlier attempted fixes before trying this.\n2. The main source of trouble is that these files are generated into the source directory itself and therefore show up as potentially analyzable. Do you know if there's a way to tell eslint (perhaps via .eslintrc) to put these files in /tmp (note the leading slash), not tmp?\nAlso, would you be willing to let us look at the source of the project? If so, you can email me a zip file since you mentioned it's a private repo (pat at codeclimate dot com). That would be the best way to help us sort this out, but I understand if it's not feasible.\n. Thanks so much for your help. The root issue is yes, the engine is attempting to read files and/or directories that it can't and shouldn't because they're listed as excluded. We have a good idea of why this is happening and are working on a fix. In the meantime, I think if you make it a habit to clean before running an analysis you should be able to avoid the issue.\nCould you confirm one more thing for us? Try doing a clean, then analyze, then analyze again. If the second analyze still succeeds, that'd prove that the analysis itself is not creating these files, it's something else. That wouldn't really change things; we'll still make the same fix and you'll still need the same workaround for now, but it would increase our understanding of the issue and could even point us at a different, easier workaround (for example: maybe your development web server is doing this, and it can be easily configured to put these files in /tmp instead).\n. Gotcha. Well, thanks for the additional understanding.\n. Sorry, there is no update. We're still actively working on a fix for this.\n. All,\nWe believe we have a fix in the latest version (v0.4.0). Please update to this version and give it a try.\nNOTE we've made this fix specifically for the eslint engine. If you run into a similar error with another engine, please hang tight. We're working to get all affected engines updated as quickly as we can.\n. Thanks @elwayman02 that seems very unrelated to this initial issue and I've created #111 to track it.\nGiven the actual issue here appears to be fixed, I'm going to go ahead and close this.\n. > boot2docker has been deprecated in favour of Docker Machine\nCan you link to a source on this? We weren't aware of that.\nI'm not familiar with Docker Machine, or know what it would take to get the wrapper script working in such a setup, but we can certainly look into it.\nDoes using docker run directly as the error message suggests work for your setup?\nYou can check here for example options. You'll probably need to adjust them since you don't have a /var/run/docker.sock.\n. > Docker run works fine but is a bit cumbersome.\nAs a workaround, you could edit the installed wrapper script to execute the docker run command you need. If you'd like some help with that, please post a docker run invocation that works and I can suggest the edits you'd have to make to get that working. Seeing that example command might actually help us in adding real Docker Machine support too.\n\nhttps://github.com/boot2docker/boot2docker-cli readme indicates the deprecation.\n\nFWIW: there is a bit of a contradiction here as the Docker Machine page linked from that one states:\n\nNote: Machine is currently in beta, so things are likely to change. We don\u2019t recommend you use it in production yet.\n\nIn any event, thank you for the report. We do want to support as many use cases as possible and will absolutely support Docker Machine if that is the recommended way to run Docker containers on OS X (which it looks like it is, or is very close to being). I'll report back when we're able to prioritize this work and have a better idea on timeline.\n. Yes CC, Engine is a craaazy class, but it's not my fault and I don't plan on fixing it here :)\n. @GordonDiggs suggestion implemented. @noahd1 let me know if my reasoning is satisfactory on your comment.\nReady for re-review.\n. FYI: because of the rebase on the base branch, this is now showing some differences that aren't really intended. Sorry.\n. Spoke with Gordon IRL -- we think this is promising enough to move forward. I'll open a new PR with tests and things shortly.\n. > Do any of the new issues on CC need to be addressed?\nThe issues on CC are because the #run method which I moved from Engine to Container, while reduced and simplified greatly (IMO), is still flagged -- (hence 5 fixed in Engine and 5 new in Container). IMO the class/method is improved and there's not much obvious work I can do to go further such that CC is also happy so I'm good shipping it as is. WDYT?\n\nDoes this work locally?\n\nWill definitely test locally before shipping.\n. I'm not sure what that'd do. I do want to catch anyone writing { } for a Hash or [ ] for an Array, but a I don't want to write {} for a lambda...\n. FYI: codeclimate analyze works locally\n. Thanks so much for addressing this. I had a minor comment, but once addressed, we should be able to get this out today.\n. @GordonDiggs moved. @noahd1 thoughts?\n. Thanks!\n. Sorry about that! I've corrected the sha, please try again.\n. @kulte the following should work to try out this branch yourself:\ngit clone https://github.com/dbergey/codeclimate\ncd codeclimate && sudo make install\nThis PR LGTM, but I still think we need an answer to Gordon's question before merging:\n\nDoes this also work for people who start from scratch and install Docker Toolbox (rather than migrating from boot2docker)\n. Awesome, thanks @sveinn . I'll check with the team and hopefully merge/release this today.\n. Unfortunately, docker run codeclimate/codeclimate validate-config isn't enough to properly run the CLI.\n\nYou can see the required options in the README or wrapper script we provide. Specifically, you need to mount the current directory as /code within the container being run.\nLet me know if if you have additional questions.\n. No worries at all! I'm glad it was an easy fix. I'm going to close this, but feel free to reopen if you find it's not working for you with the corrected invocation.\n. I'd assume we don't want to merge something like this until the very end, once we've done some testing of the new engine(s)?\n. I'm going to hold off on additional review, in case there's any large changes to come out my inline comment.\n. OK. I'm going to call this LGTM without nitpicking further for the following reasons:\n- The specs are comprehensive\n- The code is, for the most part, confined to the new class\nThis is probably worth some manual QAing as well, which we should do before releasing.\n. @squaresurf I notice you're not using \"default\" as the docker machine name, which is what the CLI is expecting in its assertions (source).\nAre you able to make it so that there is a docker machine available with the name \"default\"? If that gets things working, we'll know that's the reason and can start to think about how to handle such a scenario.\n. @squaresurf glad that got it working. Do you think it's safe to say using $DOCKER_MACHINE_NAME (with a default of, well, \"default\") would be the way to go?\n. Cool, thanks. I'm going to re-title the issue. Hopefully we can action the fix soon. Sorry for the trouble.\n. Thanks, will definitely let you know. To centralize some debugging info:\n.codeclimate.yml:\n``` yaml\nengines:\n  eslint:\n    enabled: true\n  csslint:\n    enabled: false\n  fixme:\n    enabled: true\n  watson:\n    enabled: true\nratings:\n  paths:\n  - \"app/\"\nexclude_paths:\n- bower_components//\n- dist//*\n- node_modules//\n- tests//*\n- tmp//\n- vendor//\n```\nEmber 1.12 app w/ over 32,000 lines of code across 200+ files.\nPlease let me know if any of this is out of date.\n. Hey, just a headsup: I found the source of this bug and am getting started on a fix.\nIt's actually a bug in the -f option handling. Running without it (which is functionally the same as -f text, since text is the default) should work for you.\n. LGTM\n. Pending tests, LGTM.\n. Hi @albertpak, it's possible you have restrictive permissions on the current directory which can lead to issues as the CLI tries to read/write/chdir there.\nCan you paste the output of the following commands right before you run init?\npwd\nstat .\nstat ..\nThanks.\n. It looks like you're only allowing the execute bit to the all group which is unusual and I think explains why the CLI is unable to change to the directory (note: /code within the cli/engines is mapped to the current working directory on the host system).\nIs it intentional? If not, you could perform chmod 755 . (this may need sudo) to set the current directory to more conventional permissions.\n. And how about with chmod 755 ..?\n. Hmm, actually I misread your stat output earlier. Both directories were already 755, I apologize. It looks like now you've loosened the restrictions on . to 777 -- which I would probably try to correct if I were you -- but that wouldn't cause our problem with init.\nIs there any more to the error message than just that line? A backtrace after, or \"Running engine...\" before?\n. Ah, that makes sense. A vanilla docker run is not expected to work. Sorry for the trouble, glad you got it sorted out.\n. docker version is happy when run as your user. make install is being executed with sudo. I'd imagine the issue is the docker commands ran by bin/check don't work for your root user.\nDoes\ncd /tmp && make install PREFIX=$PWD && ./bin/codeclimate version\nwork?\n. Relevant: https://wiki.archlinux.org/index.php/Sudo#Environment_variables\n. > what do you think about updating the bin/check error output \nI think we could update it to be more helpful, but just saying \"sudo docker version\" is too naive as we can't know if it was run with sudo when it failed or not. Something like \"ensure docker version works for the XYZ user\" we could do though, and hopefully seeing \"for the root user\" would be enough to get people going?\n. > I don't think the edge case of root-without-sudo is particularly worth worrying about\nI guess I (slightly) disagree here, but if that's how you feel, then I'm OK with it.\n. https://github.com/codeclimate/codeclimate/pull/120 -- could you do me a favor and try out that branch to ensure it shows you the right message?\n. > That can/should be a separate issue/PR, but what do you think about updating the bin/check error output to help avoid this tripping someone else up?\nClosing this -- when we get some time, let's open that separate issue to discuss. For a standard boot2docker/docker-machine setup, we expect everything to work, so I'm curious what's different about yours that it doesn't.\n. LGTM. Excite!\n. I'm having a really tough time coming up with a valuable test here. If anyone has any ideas, please let know. Otherwise, I'm going to merge without it shortly.\n. Thank's @mxie , it's actually not the resolve method that needs testing (IMO). The original bug was in how we were instantiating the formatter (and only presented when it ultimately gets used a number of objects away), so what I'm having trouble with is finding a spec that would expose that bug...\n. @fhwang i had originally discounted that as brittle and not meeting the \"valuable\" bar; it's probably better than nothing though, so I'll explore that route a bit further.\n. Cool, spec added. Note: I also fixed some invalid block nesting in that spec as part of adding my new example at the end.\n. Hey @andyw8 there are some issues in that code block (smart and missing quotes), is that just paste-fail or is it really what you're trying to run?\nAssuming it's just paste-fail, what error are you seeing? I would expect replacing $PWD with whatever directory you want to analyze in to work as you're expecting.\nEDIT: oh, I see you said \"Just hangs\". In that case, I'm guessing it really is the missing closing quote on the CODE_PATH option.\n. > Is there any way to see that?\nI was going to say unfortunately no, but it looks like someone improved the situation: https://github.com/codeclimate/codeclimate/blob/89d9069c6dc8d8be65b060c0bda8be8403f06559/lib/cc/cli/runner.rb#L14\nI think if you pass an additional -e CODECLIMATE_DEBUG=1, you'll get a backtrace.\n. Hi @stephenprater does that file happen to be unreadable for the \"all\" group (permissions 644)?\nThe best way to think about it is that codeclimate is an unknown user (for security reasons) so if you want it to analyze a file, it has to be readable by all (not just you).\n. Discussed IRL that IOProcessor (builder's formatter, the object raising because it lacks a #close) should've probably  subclassed Formatter. That would've given it an empty #close that would've also prevented this bug -- we came to the conclusion that over-paranoia is warranted though, and even if we did go ahead and do that, having the #responds_to? check here is valuable over-protection.\nSo... LGTM\n. Can we spend some time pairing together on this and the builder PR? Coupling the formatter and the listeners together would be really bad, so I want to be absolutely sure we have to do it before signing off. I think I just need to spend time actually digging in with you to get the needed context to feel comfortable one way or another. Sorry to be a blocker on this work...\n. I think this happens if someone skips the bundle step when releasing a new version. The version in the lockfile should always match the version in the gemspec, AFAIK.\n. LGTM, is there a good way to confirm this works? I assume there's no good way to get it into the test suite.\n. Fine with me, although I don't see a merge conflict on the horizon -- oh you meant the tests. 10-4.\n. Awesome. LGTM\n. Can you describe a little bit (preferably ammending it into the commit too) in what cases we can/should run an #analyze without the cc-yaml present? That is what this change is allowing for right?\n. LGTM\n. \"Blank\" feels a little implementation-ey -- what is the source of this error?\n. Cool. I was wondering if it was because of a bad lookup into engine metadata.\nGiven that it's more generic, how about NoImageGiven or ImageNameRequired?\nI think tying the exception name directly to the fact that you're testing it with #blank? is exactly what I'm against doing (though I'm doing a poor job of articulating why).\n. Cool, LGTM after that.\n. LGTM too\n. I'm in favor of being more explicit and telling the user a command to run to update engines images. However, others may want to err on the side of convenience, which I'm fine with, and agree we should be showing some output (if possible) so it doesn't appear frozen.\n. Seems reasonable to me /cc @dblandin though\n. Commit message updated. Ready for re-review\n. /cc @codeclimate/review @jpignata @brynary \n. Nice catch. LGTM\n. LGTM\n. Here's some context, if you're curious: https://github.com/codeclimate/codeclimate/pull/125\n. LGTM\n. Hmm. I can't see how what you're doing would impact that. The spec is a little shaky by the nature of what it's doing, but it's been robust enough so far...\n. I think those lines are a red herring. I can reproduce the abort locally and the messages that show differ each run (depending on spec order).\nIt looks like you're calling InvalidFormatterError.new(name), \"...\" which is probably a problem, maybe the problem?\n. Nice. I'd request a merge around the long-method for now.\n. LGTM\n. LGTM \n. Those specs could be flakey as they do docker-run and thread stuff. They're important specs, but anything that you can do to make them more stable would be worthwhile.\n. LGTM\n. @ABaldwinHunter short answer: I didn't think about it.\nLooking at it now though, I think the only difference is that that one runs docker build in the test step instead of dependencies -- that's actually a bug since not overriding the dependency step will cause an inferred bundle install step to run, which (as we've seen) can cause problems by creating config files in the source tree that end up in the docker image.\nSo I'd argue that rubocop's should actually be made to look like this.\n. LGTM -- pending the flag change and CI green\n. This LGTM.\nThe CC issue is annoying. I want trailing commas in arrays and hashes, and hash arguments to method calls, but I dislike the trailing comma in all method calls. I don't think rubocop can be tuned that finely. Maybe I/we should just get used to the trailing comma everywhere?\n. Seems OK to me -- I just happend to know about .slim, there may be others. I dunno who would be the authority on this sort of thing...\n. CC issues look legit\n. Love the various extracted classes. LGTM.\n. Would moving the calls to #join up from the ensure block have solved this\ntoo?\nOn Thu, Nov 19, 2015, 17:31 Will Fleming notifications@github.com wrote:\n\nMerged #216 https://github.com/codeclimate/codeclimate/pull/216.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/216#event-469767484.\n. LGTM\n. This appears to now just remove the Thread#join calls -- what waits on the threads without them?\n. @mrb were you able to sync up out of band? Can we close this issue?\n. I @mgracer48 sorry for the trouble, we've seen this happen if something fails outside of the \"steps\" we capture on the Build page UI.\n\nWould you mind submitting a description of the problem at https://codeclimate.com/help? That way, we'll be able to get more information about what repo this is happening on and try to get to the root issue.\n. LGTM\n. > Is there any major difference between the codeclimate-cli and the cloud service?\nThe performance bottleneck we're suspicious of here is the building of the paths we send to the engine for analysis. They're built by looking at the source directory's contents in conjunction with your configured exclude_paths. It can be slow on a project with many files and/or complicated excludes.\nOne reason it could be fast on codeclimate.com but slow locally is if you have many files not checked into git (e.g. node_modules). codeclimate.com would not see these files at all since it does a fresh clone and only has tracked files in the local source directory. CLI on the other hand has all files present, tracked or untracked, when building these paths.\nConceptually, adding such untracked and problematic files to exclude_paths should be the same as if they didn't exist and therefore make the CLI perform like on codeclimate.com, but it's not that easy: since the performance issue lies exactly with the process of working with exclusions, having files present but excluded has very different performance characteristics than not present at all.\n. Will gh / hub read the message on stdin (potentially -F -)? If so, you could ditch the tempfile.\n. LGTM\n. FYI: worked locally, builder stopped with this at the 15 minute mark:\n[565e25e4d309520001000227] emitting to kafka type=document collection=container_events document={:snapshot_id=>BSON::ObjectId('565e25e4d309520001000227'), :name=>\"finished\", :container_name=>\"cc-engines-csslint-75c10835-8dd5-4a6f-93da-687cec0fecf4\", :errored=>true, :exit_code=>nil, :step_name=>\"engine:csslint\", :host=>\"\", :image_name=>\"codeclimate/codeclimate-csslint:b27\", :occurred_at=>2015-12-02 16:56:34 +0000, :stderr=>\"\", :stdout=>\"\", :_schema_version=>\"2\"} immediate_flush=true enqueued_at=2015-12-02 16:56:34 +0000 container_id=837bb9ea5d8f\n[565e25e4d309520001000227] emitting to kafka type=state value=error snapshot_id=BSON::ObjectId('565e25e4d309520001000227') details={:error=>{:code=>\"E11\", :details=>{:output=>\"\", :backtrace=>nil}}} expectation_set={\"0\"=>true, \"1\"=>false} enqueued_at=2015-12-02 16:56:34 +0000 container_id=837bb9ea5d8f\n[565e25e4d309520001000227] emitting to kafka type=state value=error snapshot_id=BSON::ObjectId('565e25e4d309520001000227') details={:error=>{:code=>\"E11\", :details=>{:output=>\"\", :backtrace=>nil}}} expectation_set={\"0\"=>false, \"1\"=>true} enqueued_at=2015-12-02 16:56:34 +0000 container_id=837bb9ea5d8f\nW, [2015-12-02T16:56:34.181397 #1]  WARN -- : ** [Bugsnag] Your API key () is not valid, couldn't notify\n[565e25e4d309520001000227] backtrace=nil code=E11 exception_class=CC::Builder::Engine::EngineTimeout message=\nSame build without this patch was still running after an hour.\n. Thanks all. Will pick up with a release and builder-side changes after lunch.\n. Hi @lucianosousa the codeclimate image requires a number of options passed to docker run to work correctly. It's one of the reasons we ship a wrapper script: https://github.com/codeclimate/codeclimate/blob/master/codeclimate-wrapper#L52\nCan you try it again passing similar options?\n. Ignore -- fixing up the prep-release script.\n. Hi @envygeeks , sorry about this. I agree it's a problem that we hope to address soon. I'll report back when I have a workaround or actual solution.\n. Hi @envygeeks sorry for the late response here. You're right, claiming /tmp/cc was a poor decision we made early on and we'd like to correct it. Unfortunately, we haven't been able to prioritize a solution just yet. Hopefully I'll be able to report back soon when we do.\n. Looks like it misfired... trying again\n. I like it. Makefile All the Things.\n. It's not, see #258 \n. I'm a little baffled here. Shouldn't running the specs in a container make them more reliable? Not less? Everything passes locally, consistently...\n. I looks like on Circle the container's not stopping as quickly as locally, so it's still running when we kill the output reading threads causing a SIGPIPE instead of an exit with an exit code like locally. Adding a call to docker ps after the kill (which I did to debug) slows things down enough to pass. Feels like an actual race we could be suffering from in production -- but I'm not sure how to best fix it.\n. This is ready for re-review. @codeclimate/review \n. Ugh. I cannot get this thing to pass reliably. Back to some CI debugging.\n. I have to abandon this. I can't get it to pass on Circle.\nI'll re-open if I get some time to continue digging.\n. This looks really good. I think my only concern is using the name Issue for something that's really just generic, arbitrary engine output that we interpret as issues based on a type key. I think renaming it to something like Output would make things a lot better. You could then have Output#issue? and maybe even Output#as_issue to get an Issue, if it makes sense still to also have that object when you have confirmed it was an issue output by the engine.\n. Two minor thoughts. LGTM.\n. I think @brynary has strong opinions against fixing it this way. In cases like this he wants the responsibility to lie with the engine, leaving the runner as dumb as possible. I'm parroting though, so I'd let him chime in before moving forward or abandoning on this.\n. Hi, sorry about the trouble here.\nDoes your project happen to be open source? It'd be great if we could play with a copy ourselves to try and figure out what's going on.\n. Thanks @frobichaud, going via support is definitely the way to go. Do you mind if I close this issue so we're not tracking it in two places?\n. Hello folks, sorry for the delay here.\nIt seems this has become a classic \"me-too\" catch-all for general engine timeouts. These can occur for a variety of reasons and in any engine. At this point, we're relatively confident there's not a bug to be fixed in the CLI itself and so are going to close this issue.\nThere may be bugs (now or in the future) in specific engines making them more prone to timeouts. If that's the case, an issue opened on the specific engine would be preferable. We're always on the lookout for such cases (for example, I recently fixed such an issue in phpmd).\nWe have a trouble-shooting guide around engine timeouts available on our docs site which may be useful.\n@grahamlyons since you've mentioned that your analysis completes on codeclimate.com but errors locally, that's likely because the engine is spending (potentially a lot of) time operating on files not checked into git (node_modules is a common source of this trouble). I'd suggest trying to identify these files and excluding them from analysis via .codeclimate.yml.\n. Hi @chfast,\nI agree that error output can be a bit confusing, but it shouldn't prevent the installation from continuing (the || true basically means ignore this failure). It happens when you have no images on your system that need updating and xargs invokes docker pull without passing the NAME argument.\nCan you check if, even with this output, the installation worked?\nThere's actually a convenient way to prevent this with an option to xargs, but unfortunately it doesn't work on the BSD version (used by OS X).\n. These seem way too lenient to me, I think an 80 line method is\nunacceptable, and 250 for a class is pretty bad.\nI'm fine with it if these have already been discussed and decided in a\nlarger group, but if it's still up for discussion, I'd vote for limits of\n150 and 15.\nOn Dec 28, 2015 10:09, \"Ashley Baldwin-Hunter\" notifications@github.com\nwrote:\n\nIncrease Class and Module length Max from 100 to 250\nTurn on method length check\nIncrease method length Max from 10 to 80\n- In light of grade point tuning\n- leaves ABCSize enabled, Cyclomatic Complexity and Perceived\n  Complexity disabled\n@codeclimate/review https://github.com/orgs/codeclimate/teams/review\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/codeclimate/codeclimate/pull/287\nCommit Summary\n- Increase rubocop defaults for complexity checks\nFile Changes\n- M config/rubocop/.rubocop.yml\n  https://github.com/codeclimate/codeclimate/pull/287/files#diff-0\n  (13)\nPatch Links:\n- https://github.com/codeclimate/codeclimate/pull/287.patch\n- https://github.com/codeclimate/codeclimate/pull/287.diff\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/287.\n. > Is now really the appropriate time to do this?\n\nThe RFC and the PoC aren't meant to trigger immediate action on this. Just to get the discussion started and set a general direction for if/when anything does get actioned. There was a reason I opened these PRs over vacation :)\n\nI think there's such a thing as having the code be too separate. ... I'm not convinced that sub commands should share 0 code (as the RFC currently talks about).\n\nI think it's important to start with that rule. If we come across a case where the 0-share rule is causing pain, we can discuss that in concrete terms and only then come up with the right solution.\nI think Ruby in general, and our codebases in specific, have sufferred from over-DRYing. Whenever I've tried to pre-DRY (CC::Analyzer::*, CC::Kafka::*) it's turned out very poorly. Whenever I've taken the \"duplicate, then extract\" approach (StructuredLogger, KafkaOffset), I've been generally much happier.\n\nI think inevitably there will be utility functions or small classes that should be shared (I currently have a branch to work on verbose logging for debugging that would fall under this category).\n\nI'd be curious to see how that shakes out. Do you really need complex logging in every, or even most sub-commands? I think you could get a long way with only that feature existing in codeclimate-engines.\n\nThat code could be extracted into a separate gem, or it could live at a top-level here. Maybe it's more a packaging concern than anything else.\n\nI do think we could look to extract general gems (i.e. not in any way codeclimate specific), StructuredLogger might be a good candidate. Having something live top-level and be loaded into the sub-commands that need it seems like a reasonable middle ground. We might end up with something shared to help testing too, for example.\nIn short, there's a lot of wiggle room from the \"rule\" I'm outlining to begin with. My take would be to start with the rule and consider if/when/how to break it, rather than start with no rule because we suspect it'll be too constrictive.\n(Meta note: ^ this discussion probably should've been in the RFC PR)\n. Going to close this for now. There's good discussion here and it's linked back to from the RFC PR, so it's done its job. I think further discussion should take place in the RFC anyway.\nIf/when we're ready to move forward on this, I will re-open.\n. > I'm not convinced that using paths instead of patterns is significantly more performant\nI guess no one can be convinced until I benchmark :)\nConsidering the old logic takes x/**/* and recursively, fully expands it before doing anything else, and the new logic just looks at x as-is I have to assume the new logic is vastly more performant. Consider that difference in behavior for something like .node_modules!\n\nAs soon as you realize spec is a directory, add spec to include paths, and stop drilling down.\n\nI'm happy to look at some code if you could implement that optimization without removing what's present, but my suspicion is that it would mean complicating already complicated bug-risky code to accomplish.\n\nHave you done any bench marking on different sized repos to see where the most time is spent?\n\nI know that @wfleming has an example repo, so next week when we're both back in the office I'm going to use that for benchmarking. I may also ask the folks in the motivating Issue to try this branch.\n\nI'm 50% concerned with this code because it's slow and 50% concerned with this code because it's has had numerous bugs, and the same bugs repeatedly. I want to ensure whatever solution we chose, we fix both aspects. Simplifying things greatly is the solution chosen here.\nMy opinion is that we don't need patterns: the complexity involved in supporting them is not worth it for how (not) useful they are. To back that up, I'm going to take a sampling of codeclimate.yml's on the site and try to bucket out how many would be negatively impacted by this change. Hopefully, it's very few, but we'll see!\n. @ABaldwinHunter FYI, I'm going to run a longer query later, but looking at repos that have analyzed the past hour, I get about ~7% using exclude paths that would be ignored by this new logic. Some examples are:\ninvalid exclude: **/vendor/*\ninvalid exclude: **/vendor/**/*\ninvalid exclude: client/tests/**/*.js\ninvalid exclude: *.md\ninvalid exclude: app/**/*.liquid\ninvalid exclude: module/**/config/*\ninvalid exclude: app/assets/javascripts/**/*bundle.js\ninvalid exclude: server/**/*.spec.js\ninvalid exclude: **.jpg\ninvalid exclude: **/*.scss\ninvalid exclude: config/*.rb\ninvalid exclude: components/ui/react/app/assets/javascripts/react/*_bundle.js\ninvalid exclude: components/ui/react/app/assets/javascripts/react/*_bundle.js\ninvalid exclude: */vendor/assets/**\ninvalid exclude: ci/*.js\ninvalid exclude: *.swp\ninvalid exclude: app/*/i18n/**/*.js\ninvalid exclude: engines/**/vendor/**/*\ninvalid exclude: public/js/*.bundle.js\ninvalid exclude: */__tests__/*\ninvalid exclude: **/*.test.js\ninvalid exclude: server/**/migrations/*.py\ninvalid exclude: public/javascripts/*.min.js\ninvalid exclude: app/*.php\ninvalid exclude: src/app/**/*.spec.js\ninvalid exclude: app/assets/javascripts/**/*.haml\ninvalid exclude: src/js/*jquery.js\ninvalid exclude: */tests.py\ninvalid exclude: lib/seed_models/**/*.rb\ninvalid exclude: **/spec/**/*\ninvalid exclude: **/*.css\ninvalid exclude: app/assets/javascripts/**/routes/*\ninvalid exclude: lib/**/*.rb\ninvalid exclude: app/assets/javascripts/**/*.jsx\ninvalid exclude: **/tools/*\ninvalid exclude: **.jpg\ninvalid exclude: app/modules/*/test/*\ninvalid exclude: migrations/versions/*.py\ninvalid exclude: .*.yml\ninvalid exclude: apps/*/migrations/*\ninvalid exclude: */vendor/**/*\nFood for thought.\n. > I think we'll still need to handle the case where a file we need to touch for interpreting an exclude can't be read, though\nCan you expand on this?\n\n@pbrisbin removed the type check stuff for YAML's globs That may need to come back in some way?\n\nProbably. I think we need to do two things:\n- Build the exclude_paths argument in the specs from actual CC::Yaml.parse(x).exclude_paths, as it would be in production\n- Add/verify spec examples for our transparent handling of /**-style globs, which we intend to continue to support\n\nUnclear if this would need to change anything in PathsValidator\n\nProbably not. That class annoys me and I'd like to continue thinking about ways to remove it, but if it stays it can probably stay as-is across this work.\n. > I think current spec coverage does cover this in that those style globs are shown being used?\nYes, we (probably) do have adequate spec coverage here; thus I hedged with Add/verify, and didn't just say Add or verify in my suggestion.\nThis important point is that we shouldn't be passing in a raw Array in the specs, because that's not what the object would receive in the wild, and the difference is important to this behavior. We should pass CC::Yaml.parse(\"--content--\").exclude_paths. As long as we do that, and the spec cases use both styles, we'll have our answer as to what we need to do implementation-wise (maybe nothing?)\n. I didn't review super closely, I think we should merge the branches, close #300 and this, and open a new PR with updated description, centralized TODO list, and start a fresh discussion.\n. > There could conceptually be a directory that is not readable by us, but is within the project & gets hit by an exclude path. Since this class works by descending through directories referenced by exclude/include paths, that would result in an exception\nSince the CLI runs as uid 0 (i.e. root), I doubt we'll see permissions exceptions here. The main source of these in the past was engines (which run as uid 9000) hitting such a scenario because they were doing their own version of workspace building.\nMy gut is that moving to include_paths pretty much solved all permissions issues and any such logic is just vestigial or was implemented because of misunderstanding. Do you believe otherwise?\n. > If I create a directory that my user cannot read locally\nThat sounds highly unrealistic to me, and is not an example of the sort of permissions issues i remember plaguing us in the past.\n. > files existed underneath the project directory that were not readable by the running user\nIf you could find an example of that, I'd love to see it. My recollection is that root-owned or 0700-moded files were the issue. The rfc is a little thin on details, but does mention the root-owned issue and does not mention anything about a user having a file they themselves can't read, which --even if we see a case in the wild-- I'd argue we shouldn't support.\n. Wait. I'm dumb -- clearly root-owned is a file they themselves can't read. Sorry. I was focusing on file mode since those were the issues I'd seen. Totally forgot about ownership.\n. Still though:\n- Are you sure unreadable directory is a common case, not just file(s)?\n- Can't, and shouldn't, such a case be solved by the user excluding the directory, which under your new algorithm should actually work?\n. Woot!\nSince your code here seems to be the bulk of it. Do you mind handling the merge-close-reopen dance?\n. Want to exclude config/engines.yml (or all of config)?\n. > what the workspace paths provided to the engines look like? \nIf there are no exclusions in lib, the workspace will be [\"lib/\"]. If there are other exclusions in lib (but not lib/unreadable.rb) the workspace will be [\"lib/unreadable.rb\", \"...\", \"...\"] with whatever was excluded, well, excluded.\n(There's one caveat to  this: I think that docker-machine will prevent lib/unreadable.rb from even existing on the VM. I'm going to ignore this fact for now because I don't understand it well, not being an OSX user -- if you want more details, I defer to @wfleming) Disregard.\n\nare we still expecting the engine to potentially raise an exception if/when it tries to read it? \n\nYes, if the engine attempts to read a file it can't read, I'd expect/want an exception. I don't think we have any engines that silently rescue this case, but I'm not 100% sure.\n. Ok. Then I'm not sure how the docker machine fact impacts things, but you\nindicated previously (I think) that it may. Does it?\nOn Fri, Jan 22, 2016, 10:25 Will Fleming notifications@github.com wrote:\n\nPat's description is correct, except for the following: in the\ndocker-machine case the unreadable file will still exist, and will still be\nunreadable.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/308#issuecomment-173949392\n.\n. @wfleming great, I modified my comment to remove that confusing information, which, in retrospect, was just me making stuff up :)\n\nCan the benchmark you have here be added to master (and maybe not made an assertion, but just output timings)? Then we could compare the numbers between the two branches.\n. @wfleming I went ahead with that refactor, bringing back Workspace as a proper class and its spec -- which I think exposed a bug. Can you take a look at the Workspace specs marked skip and let me know what you think?\n. I don't think there are any behavioral changes here. Users will just see better performance. @wfleming would you agree?\nThere may be subtle changes to how analyze FILE invocations work (so called \"explicit includes\"), but we're still nailing that down, so I'm not sure what they'll be yet.\n. LG(reat)TM. I think there's still a product decision needed around customer comms, but we could consider that blocking release, not merge if we wanted.\n. Nice. LGTM.\n. Code looks like an improvement on things. If tests pass and things are fast, LGTM.\n. LGTM. I'd support any of:\n- Pull the rename out to its own PR, which I will immediately :+1:\n- Fix the two commits so the right changes are in the right place, but keep as one PR\n- Squash the commits to 1, if redoing them is too much of a hassle\n. LGTM\n. FYI: this is a re-opening of #265 \n. @wfleming good for a squash-merge?\n. LGTM\n. > whether CodeClimate people think there's a need for it\nFWIW, I'd enable a markdown linter on my own projects.\nOne of the big drivers behind the Platform and its openness is to allow easy creation and use of any niche engines folks are willing to build. Whether we choose to write and maintain an engine ourselves is one thing, but I don't see any reason we wouldn't want any and all engines the OSS community is willing to build.\n\nwhether they would add it to approved engines once it meets the standards \n\nI can't think of any reason we wouldn't approve an engine if it met the standards. Otherwise, we should probably change the standards, right?\n. Hi @mikz, thanks for this. Once the -n fix is in place, I'd be in favor of merging it, but I'd like for someone on our team who uses OS X and docker-machine to sign-off first.\n. I'm not sure I agree with this UX. At least, I'm not ready to change this UX if we don't have known cases we're dealing with where we've decided this exception is the solution. I think arguments could be made either way about what should happen, and so I hesitate to add a new errored-build scenario where we don't have one currently.\nTo me this is similar to the NoEnginesEnabled error we removed recently, and I agreed with the justification there. As long as it's clear in the build output (I might consider adding a warning here) that we've done a \"no-op\" analysis, I think it's fine and better than an errored snapshot, which can be very problematic for first-run analyses (where this scenario is most likely to be seen IMO) and merge base analyses.\n. One thought about using the nicer Child interface. LGTM besides.\n. How has this not caused massive problems?\n. Gotcha. I figured if it was a 1.9 thing we'd be seeing 100% errored builds since the upgrade. Interesting that it's only sometimes an issue.\nAnyway, LGTM.\n. LGTM\n. LGTM\n. Oof, sorry about this. The Nokogiri warning is entirely unrelated. I made a\nchange recently to use shelljoin, and there must be a transitive require\nthat made it work in my tests but not your case. Probably just need to add\nan explicit require in the file that uses it.\nUnfortunately, I'm out of town, but hopefully a colleague of mine will see\nthis and make the easy fix soon.\nOn Mon, Feb 15, 2016, 16:34 Ryan notifications@github.com wrote:\n\nRunning latest image gives me this error. Docker promised me I would never\nhave to see ruby dependency errors again, but they lied.\n$ docker run   --interactive --tty --rm   --env CODE_PATH=\"$PWD\"   --volume \"$PWD\":/code   --volume /var/run/docker.sock:/var/run/docker.sock   --volume /tmp/cc:/tmp/cc   codeclimate/codeclimate analyze\nStarting analysis\nRunning brakeman: Done!\nRunning csslint: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine csslint failed with status 1 and stderr\nUnable to find image 'codeclimate/codeclimate-csslint:latest' locally\nlatest: Pulling from codeclimate/codeclimate-csslint\nf5f17db9ef7c: Pulling fs layer\nb323df73e6c4: Pulling fs layer\n0fabb5fa5487: Pulling fs layer\na3ed95caeb02: Pulling fs layer\nd9ccb0036cfb: Pulling fs layer\nec0a54bd51aa: Pulling fs layer\nd60b871a6c06: Pulling fs layer\n45e9f8b6dbef: Pulling fs layer\n9bd4352dc82b: Pulling fs layer\nbc45d97772cd: Pulling fs layer\na3ed95caeb02: Waiting\nd9ccb0036cfb: Waiting\nec0a54bd51aa: Waiting\nd60b871a6c06: Waiting\n45e9f8b6dbef: Waiting\n9bd4352dc82b: Waiting\nbc45d97772cd: Waiting\n0fabb5fa5487: Verifying Checksum\n0fabb5fa5487: Download complete\na3ed95caeb02: Verifying Checksum\na3ed95caeb02: Download complete\nf5f17db9ef7c: Verifying Checksum\nf5f17db9ef7c: Download complete\nf5f17db9ef7c: Pull complete\nf5f17db9ef7c: Pull complete\nd9ccb0036cfb: Verifying Checksum\nd9ccb0036cfb: Download complete\nec0a54bd51aa: Verifying Checksum\nec0a54bd51aa: Download complete\nb323df73e6c4: Verifying Checksum\nb323df73e6c4: Download complete\nb323df73e6c4: Pull complete\nb323df73e6c4: Pull complete\n0fabb5fa5487: Pull complete\n0fabb5fa5487: Pull complete\na3ed95caeb02: Pull complete\na3ed95caeb02: Pull complete\nd9ccb0036cfb: Pull complete\nd9ccb0036cfb: Pull complete\nec0a54bd51aa: Pull complete\nec0a54bd51aa: Pull complete\n9bd4352dc82b: Verifying Checksum\n9bd4352dc82b: Download complete\n45e9f8b6dbef: Verifying Checksum\n45e9f8b6dbef: Download complete\nd60b871a6c06: Verifying Checksum\nd60b871a6c06: Download complete\nd60b871a6c06: Pull complete\nd60b871a6c06: Pull complete\n45e9f8b6dbef: Pull complete\n45e9f8b6dbef: Pull complete\n9bd4352dc82b: Pull complete\n9bd4352dc82b: Pull complete\nbc45d97772cd: Verifying Checksum\nbc45d97772cd: Download complete\nbc45d97772cd: Pull complete\nbc45d97772cd: Pull complete\nDigest: sha256:71415c6acdd307c4775adedaacbbf0bd0aa5d66ada41eb87db52891dd62b17bf\nStatus: Downloaded newer image for codeclimate/codeclimate-csslint:latest\nWARNING: Nokogiri was built against LibXML version 2.9.2, but has dynamically loaded 2.9.3\n/usr/src/app/lib/cc/engine/csslint.rb:65:in csslint_xml': undefined methodshelljoin' for #Array:0x00561ca2d51dc0 (NoMethodError)\n    from /usr/src/app/lib/cc/engine/csslint.rb:61:in results'\n    from /usr/src/app/lib/cc/engine/csslint.rb:19:inblock in run'\n    from /usr/src/app/lib/cc/engine/csslint.rb:18:in chdir'\n    from /usr/src/app/lib/cc/engine/csslint.rb:18:inrun'\n    from /usr/src/app/bin/csslint:14:in `'\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/349.\n. LGTM\n. Hi @afestein this issue is very interesting, I haven't heard of anything like it happening before.\n\nDo you mind running a few commands in your project directory and pasting the complete output here?\npwd\nls -la\ncodeclimate init\ncodeclimate validate-config\nls -la\ncat .codeclimate.yml\nAlso, are you using docker-machine or anything like it? If so, it's possible something funny is going on with the local filesystem vs the VM filesystem, in which case I might have to hand you off to one of my OS X-using colleagues.\nThanks\n. What this error always appearing?\nGenerating default configuration for engines... error: (NoMethodError) private method `select' called for nil:NilClass\nDo you see the .codeclimate.yml if you run sudo ls -la?\n. Very interesting...\nCould you show me the raw output of\ndocker images | awk '/codeclimate\\/codeclimate-/ { print $1 }'\nplease? And then the same without the hyphen?\nEDIT: I removed the second dollar since it should be $1 when outside the context of the Makefile.\n. Thank you!\nSo the bug here is not the hyphen, it's just poor handling of the case where the listing finds no images.\nYou can see we already append || true so our intention is to ignore this error and proceed; this shouldn't break the install in any way -- did that not happen in your case?\nWe could also be a little more clever with handling this case and its stderr, as it does seem confusing.\n. The following:\n```\ndocker: \"pull\" requires 1 argument.\nSee 'docker pull --help'.\nUsage:  docker pull [OPTIONS] NAME[:TAG|@DIGEST]\nPull an image or a repository from a registry\n```\nIs error output that you can safely ignore. The || true allows the install to continue anyway. The reason you see this error output is because you currently have no existing engine images that need updating.\nmkdir -p /usr/local/bin\ninstall -m 0755 codeclimate-wrapper /usr/local/bin/codeclimate\nThese last two steps still happen, creating /usr/local/bin/codeclimate. Seeing those complete without errors indicates to me that the install succeeded.\n. No problem! Thanks very much for attempting to make your own fix. I'll keep this confusing scenario in mind and try to action a fix to prevent it from tripping up other users.\n. bin/rube-goldberg\nLGTM\n. Seems reasonable. I wish find had something like the -- argument separator, but it doesn't and from what I can find online, working around this can get pretty hacky.\n. Hey @rafamanzo, thanks very much for bringing this to our attention. I'd be in favor of using YAML#safe_load everywhere (regardless of if we consider the source trusted or not) and then, once that's done, removing safe_yaml.\nIf you'd like to open that PR, that'd be great. Otherwise, we'll look to make this change when we're able to.\n. Since this changes the environment variable API (but does maintain backwards compatibility), I'm calling it v0.22.0\n. @wfleming brings up a good point. I'm going to close this and leave the weird require in Builder for now, to be cleaned up by the sub-command rewrite of CLI.\n. Hi @krainboltgreene thanks for pointing this out, seems like an oversight on our part. I'll let you know when we're able to fix.\n. What is the exit code after your manual docker run invocation? Is it in fact 1?\n. No worries! Glad it was an easy fix.\n. Hi @justinschier I'm going to close this Issue since we haven't heard back from you in a while. Please feel free to re-open with more information if you have time and still want the help.\n. LGTM\n. > Since you've gotten the CLI working, though...\nHi @XaBerr it sounds like you've gotten the CLI itself working but are having some trouble with the atom plugin. Would you consider that resolved enough to close this Issue?\n. I'm not sure if I have an opinion on the string escaping. I'd have to see some screenshots, I think. If that's too annoying though, I'm fine merging and discussing later (or just living with it) if I find I don't like it.\nSo... pretty much LGTM.\n. LGTM\n. Some minor comments. Looks good enough to RC and move onto a builder branch IMO.\n. Thanks for reporting this, it's great that OS X and Windows will soon have native docker.\n\nWill support be added to the wrapper script for Docker versions >= 1.11.0?\n\nAbsolutely. As for when, that's a trickier question :)\nOur OS X-using developers are very much itching to get off of docker-machine and onto native docker, so as soon as they're able to (it's still invite-only beta right? edit: sorry, I might've been thinking of Docker for Mac), I'm sure you'll see patches here that make codeclimate work under that setup. I'd suspect this will happen before 1.11 is released, but we've not done any formal planning for that work yet.\n. I'm genuinely surprised by this, but have confirmed that's what's happening. This was either an oversight or a regression; either way, we'll look to fix soon. Thanks!\n. Hi @joncursi, sorry I was a little over-eager with my use of \"soon\" previously. We agree this is an issue, but we have no concrete plans to work on it quite yet.. Hey @devth thanks for offering to take a swing at this!\n\nThis doesn't contradict the SPEC. The SPEC is referring to engines themselves, which should not exit non-zero when they find issues; the behavior of the CLI is not part of the SPEC\nThat PR just got stale. It looks like there were some open discussion threads but, as is usually the case with stale PRs, I don't really remember the specifics. That seems like a worthwhile extension, but I would suggest doing it separately. Personally, I think exiting non-zero when issues are found is a saner default which could be implemented separate from, and before having the option to turn it off engine-by-engine.\n\nI could be convinced that a global flag to go back to the old behavior would be useful so we don't just start erroring folks' builds, but engine-by-engine seems like clear feature-creep that can be tackled after.. I think you've made this PR against a very old version of master. We've actually moved from minitest to rspec since then. In any event, I don't think we're interested in using this aspect of Circle for this project.\n. I spoke with the team and while there wasn't too much excitement either way, this doesn't really hurt anything so why not try it out? If you go ahead and rebase one more time (sorry), I'll merge it in.\n. Hi @amercier sorry about this. I'm going to move this issue over to codeclimate/codeclimate-eslint. Let's pick up discussion there.\n. Hi @nadeemja sorry for the trouble here. There's a few things worth looking into:\n- The engine is running for a long time\nThis can happen to any engine for a variety of reasons. Most often, the engine is analyzing files or directories it shouldn't. Configuring exclusions (overall or per engine) would be the answer here. Sometimes there is a bug or performance regression in the engine itself. If that turns out to be the case, we can open it as an issue on codeclimate/codeclimate-duplication and go from there.\n- The engine isn't timing out after 15 minutes\nThis is a bit more concerning. Engines run under a strict timeout and a docker kill should be invoked after it's expired. If that's not happening in this case, I'd definitely like to understand why.\nAs for verbosity, you may find useful information by running with DEBUG enabled:\nCODECLIMATE_DEBUG=1 codeclimate analyze -e duplication\nThe best way for us to help investigate would be if we had a copy of the project to experiment in. If it's not OSS, would you be willing to email me an archive (pat at codeclimate.com)?\n. Oof. Unfortunately the CLI doesn't have autofix (yet), and in this case neither does the underlying tool (eslint).\nFWIW, such a high number of issues is often due to a small number of checks that you don't particularly care about or have your own opinions for (indentation level, for example), so a small .eslintrc adjustment may have a large impact on getting that number down to something manageable.\nI'm going to go ahead and close this issue, since it looks like your \"stuck\" duplication engine has been addressed. If that's not the case, feel free to re-open.\n. Hi @sysadmiral, we don't have any specific plans for a puppet engine at the moment but that doesn't mean it won't happen. Certainly if you (or anyone) would like to work on wrapping puppet-lint up as an Engine, we'd love to have it.\nWe actually have a codeclimate-community slack organization where folks hang out to discuss engine ideas and development. If you're interested (you don't have to be authoring an engine to participate in the discussion), you can join our Developer Program to get an invite.\n. @ABaldwinHunter it's a good point. IMO this is just trading an unclear error and a U10 for a clear one and a not-U10 for the time being. Agreed with Gordon that there will be much larger, sweeping changes to actually support issues on non-existent files and reverting this bit would make up a very small percentage of such a change.\n. I snuck in a small commit to exit 1 on errors, which I noticed we weren't doing while testing the ImageRequired error handling.\n. Forgot to make engines:install work. Stand by.\n. Made the updates for engines:install and test. Could use another quick look (/cc @GordonDiggs). I noticed that engines:list might benefit from including channel info, but the formatting was non-obvious so I'm punting for now.\n. Ping @codeclimate/review for a last look please.\n. @abritinthebay yes, that's correct. Note that we're still testing this image out so I can't say for sure that it'll work, but you're welcome to try it:\nOnce you've updated to the latest CLI, you can add:\nyaml\neslint:\n  enabled: true\n  channel: eslint-2\n. Oh yes sorry. Same caveat about it not being thoroughly tested yet, but you can commit that yaml change and it will run eslint 2 on our hosted analysis too.\n. Sorry, you were just a few minutes too soon as I was in the process of pushing that feature out for hosted analysis. It should work if you try again now.\n. Damn. Unfortunately, I'm not immediately sure what the issue is there. I'll open up an issue on the engine repo to track it, but it probably won't get addressed today. Thank you very much for trying it out, and apologies that it's not working on your project yet.\n. Thanks! I've rebuilt a new image from #92 with that fix and pushed it to Docker Hub, this means you could test the fix via the CLI right now. If you can only use hosted, you'll have wait just a bit longer as I go through the process of getting the image out there as well.\n. OK, that fix is now out. Feel free to try again.\n. That's great to hear!\nTomorrow we'll be writing up documentation and dropping comments on all the OSS Issues where this support has been requested. Then we'll start collecting and addressing things like that. Thanks again for being an early tester (and finding that babel-eslint fix).\n. LGTM\n. Hi, are you a fellow Arch Linux user?\nI ran into this because Arch's docker binary is built with go-1.6 (latest) but the client installed in the CLI is built with go-1.5 (as upstream intends). This makes them incompatible. I opened a bug about this here with more details.\nTo confirm this issue, take a look at docker version, it'll tell you which version of go was used to build the binary -- if it's 1.6, that's it.\nAs a workaround, I built and installed my own docker package against go-1.5. If you are in fact on Arch, I can give you more specific instructions, it's very easy to do on that distro.\n. Hi @matchdav,\nThe sample config section includes the following snippet for your codeclimate.yml:\nengines:\n  phpmd:\n    enabled: true\n    config:\n      file_extensions: \"php\"\n      rulesets: \"unusedcode,codesize,naming,optional_relative_path_to_custom_ruleset.xml\"\nNotice optional_relative_path_to_custom_ruleset.xml. As long as your ruleset.xml file is present in the repository, you can add its path (relative to the repository root) as a value in the rulesets key. Unfortunately, we only have access to the repository sources during analysis, so if you keep your ruleset file elsewhere, that won't work at this time.\nHope this helps.\nNote: if you have further trouble with this or other engines, please open those issues on the engines' repo directly (e.g. codeclimate/codeclimate-phpmd)\n. Hi, sorry for the trouble here. Can you try running with --env CODECLIMATE_DEBUG=1? That should show the exact invocation we're using to run the apex engine and may shed some light.\n. Thanks for the log @MaurizioBella, It looks a bit mangled so here's an attempt at cleaning it up a little:\n```\n$ docker run \\\n  --interactive --tty --rm \\\n  --env CODECLIMATE_CODE=\"$PWD\" \\\n  --env CODECLIMATE_DEBUG=1 \\\n  --volume \"$PWD\":/code \\\n  --volume /tmp/cc:/tmp/cc \\\n  --volume /var/run/docker.sock:/var/run/docker.sock \\\n  codeclimate/codeclimate analyze\nStarting analysis\n[DEBUG] apexmetrics:stable engine config: {\"enabled\":true,\"include_paths\":[\".bas h_history\",\".codeclimate.yml\",\".csslintrc\",\".docker/\",\".eslintignore\",\".eslintrc \",\".gitconfig\",\".oracle_jre_usage/\",\".ssh/\",\".VirtualBox/\",\".zenmap/\",\"apex-rule set.xml\",\"AppData/\",\"codeclimate/\",\"Cookies\",\"Dati applicazioni\",\"Documenti\",\"Im postazioni locali\",\"Menu Avvio\",\"Modelli\",\"NTUSER.DAT\",\"ntuser.dat.LOG1\",\"ntuser .dat.LOG2\",\"NTUSER.DAT{016888bd-6c6f-11de-8d1d-001e0bcde3ec}.TM.blf\",\"NTUSER.DAT {016888bd-6c6f-11de-8d1d-001e0bcde3ec}.TMContainer00000000000000000001.regtrans- ms\",\"NTUSER.DAT{016888bd-6c6f-11de-8d1d-001e0bcde3ec}.TMContainer000000000000000 00002.regtrans-ms\",\"ntuser.ini\",\"Recenti\",\"Risorse di rete\",\"Risorse di stampa\", \"ruleset.xml\",\"salesforce/\",\"SendTo\",\"Tracing/\"]}\n[DEBUG] docker run: [\"docker\", \"run\", \"--name\", \"cc-engines-apexmetrics-stable-4 127e567-b16e-4746-9923-1a60654c0bcb\", \"--cap-drop\", \"all\", \"--label\", \"com.codeclimate.label=5a5c0456-a26c-40af-9ec9-002b2897644d\", \"--memory\", \"512000000\", \"--memory-swap\", \"-1\", \"--net\", \"none\", \"--rm\", \"--volume\", \"/c/Users/Maurizio:/cod e:ro\", \"--volume\", \"/tmp/cc/e56f5523-1e30-4ad3-92e2-88a47d321458:/config.json:ro \", \"--user\", \"9000:9000\", \"codeclimate/codeclimate-apexmetrics\"]\n1) A java source code filename or directoryandatory arguments:\n2) A report format\n3) A ruleset filename or a comma-delimited string of ruleset filenames\nFor example:\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -d c:\\my\\source\\code -f html -R java-unus\nedcode\nLanguages and version suported:\napex\nAvailable report formats and their configuration properties are:\n   codeclimate: Code Climate integration.\n   csv: Comma-separated values tabular format.\n        problem - Include Problem column   default: true\n        package - Include Package column   default: true\n        file - Include File column   default: true\n        priority - Include Priority column   default: true\n        line - Include Line column   default: true\n        desc - Include Description column   default: true\n        ruleSet - Include Rule set column   default: true\n        rule - Include Rule column   default: true\n   emacs: GNU Emacs integration.\n   html: HTML format\n        linePrefix - Prefix for line number anchor in the source file.\n        linkPrefix - Path to HTML source.\n   ideaj: IntelliJ IDEA integration.\n        classAndMethodName - Class and Method name, pass '.method' when processing a directory.   default:\n        sourcePath - Source path.   default:\n        fileName - File name.   default:\n   summaryhtml: Summary HTML format.\n        linePrefix - Prefix for line number anchor in the source file.\n        linkPrefix - Path to HTML source.\n   text: Text format.\n   textcolor: Text format, with color support (requires ANSI console support, e.g. xterm, rxvt, etc.).\n        color - Enables colors with anything other than 'false' or '0'.   default: yes\n   textpad: TextPad integration.\n   vbhtml: Vladimir Bossicard HTML format.\n   xml: XML format.\n        encoding - XML encoding format, defaults to UTF-8.   default: UTF-8\n   xslt: XML with a XSL Transformation applied.\n        encoding - XML encoding format, defaults to UTF-8.   default: UTF-8\n        xsltFilename - The XSLT file name.\n   yahtml: Yet Another HTML format.\n        outputDir - Output directory.\nFor example on windows:\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -dir c:\\my\\source\\code -format text -R java-unusedcode,java-imports -version 1.5 -language java -debug\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -dir c:\\my\\source\\code -f xml -rulesets java-basic,java-design -encoding UTF-8\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -d c:\\my\\source\\code -rulesets java-typeresolution -auxclasspath commons-collections.jar;derby.jar\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -d c:\\my\\source\\code -f html -R java-typeresolution -auxclasspath file:///C:/my/classpathfile\nFor example on *nix:\n$ pmd-bin-5.5.0-SNAPSHOT/bin/run.sh pmd -dir /home/workspace/src/main/java/code -f html -rulesets java-basic,java-design\n$ pmd-bin-5.5.0-SNAPSHOT/bin/run.sh pmd -d ./src/main/java/code -f xslt -R java-basic,java-design -property xsltFilename=my-own.xsl\n$ pmd-bin-5.5.0-SNAPSHOT/bin/run.sh pmd -d ./src/main/java/code -f html -R java-typeresolution -auxclasspath commons-collections.jar:derby.jar\nerror: (JSON::ParserError) 757: unexpected token at 'Mandatory arguments:\n1) A java source code filename or directory\n2) A report format\n3) A ruleset filename or a comma-delimited string of ruleset filenames\nFor example:\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -d c:\\my\\source\\code -f html -R java-unusedcode\nLanguages and version suported:\napex\nAvailable report formats and their configuration properties are:\n   codeclimate: Code Climate integration.\n   csv: Comma-separated values tabular format.\n        problem - Include Problem column   default: true\n        package - Include Package column   default: true\n        file - Include File column   default: true\n        priority - Include Priority column   default: true\n        line - Include Line column   default: true\n        desc - Include Description column   default: true\n        ruleSet - Include Rule set column   default: true\n        rule - Include Rule column   default: true\n   emacs: GNU Emacs integration.\n   html: HTML format\n        linePrefix - Prefix for line number anchor in the source file.\n        linkPrefix - Path to HTML source.\n   ideaj: IntelliJ IDEA integration.\n        classAndMethodName - Class and Method name, pass '.method' when processing a directory.   default:\n        sourcePath - Source path.   default:\n        fileName - File name.   default:\n   summaryhtml: Summary HTML format.\n        linePrefix - Prefix for line number anchor in the source file.\n        linkPrefix - Path to HTML source.\n   text: Text format.\n   textcolor: Text format, with color support (requires ANSI console support, e.g. xterm, rxvt, etc.).\n        color - Enables colors with anything other than 'false' or '0'.   default: yes\n   textpad: TextPad integration.\n   vbhtml: Vladimir Bossicard HTML format.\n   xml: XML format.\n        encoding - XML encoding format, defaults to UTF-8.   default: UTF-8\n   xslt: XML with a XSL Transformation applied.\n        encoding - XML encoding format, defaults to UTF-8.   default: UTF-8\n        xsltFilename - The XSLT file name.\n   yahtml: Yet Another HTML format.\n        outputDir - Output directory.\nFor example on windows:\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -dir c:\\my\\source\\code -format text -R java-unusedcode,java-imports -version 1.5 -language java -debug\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -dir c:\\my\\source\\code -f xml -rulesets java-basic,java-design -encoding UTF-8\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -d c:\\my\\source\\code -rulesets java-typeresolution -auxclasspath commons-collections.jar;derby.jar\nC:>pmd-bin-5.5.0-SNAPSHOT\\bin\\pmd.bat -d c:\\my\\source\\code -f html -R java-typeresolution -auxclasspath file:///C:/my/classpathfile\nFor example on *nix:\n$ pmd-bin-5.5.0-SNAPSHOT/bin/run.sh pmd -dir /home/workspace/src/main/java/code -f html -rulesets java-basic,java-design\n$ pmd-bin-5.5.0-SNAPSHOT/bin/run.sh pmd -d ./src/main/java/code -f xslt -R java-basic,java-design -property xsltFilename=my-own.xsl\n$ pmd-bin-5.5.0-SNAPSHOT/bin/run.sh pmd -d ./src/main/java/code -f html -R java-typeresolution -auxclasspath commons-collections.jar:derby.jar\n    /usr/lib/ruby/gems/2.2.0/gems/json-1.8.3/lib/json/common.rb:155:in `parse'\n\n'       /usr/src/app/lib/cc/analyzer/issue.rb:50:in parsed_output'\n[DEBUG] /usr/src/app/lib/cc/analyzer/issue.rb:21:inas_json'ib/json/common.rb:155:in p/usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.6/lib/active_support/json/encodi/usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.6/lib/active_support/json/encodi/usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.6/lib/active_support/core_ext/ob/usr/src/app/lib/cc/analyzer/engine_output.rb:5:into_json'\n        /usr/src/app/lib/cc/analyzer/container.rb:115:in call'run'\n        /usr/src/app/lib/cc/analyzer/container.rb:112:ineach_line'evels) in read_stdou/usr/src/app/lib/cc/analyzer/container.rb:112:in `block in read_stdout'\nMaurizio@Maurizio-VAIO MINGW64 ~\n$\n```\nNothing immediately jumped out at me, except that there are files in the include-paths with spaces in them. One possibility is the apex engine doesn't handle that well and is incorrectly interpretting them being passed on a commandline invocation somewhere.\nI'll have to dig in a bit more tomorrow.\n/cc @mrb \n. @MaurizioBella I've tried to repruce this, but am unable. Can you please send or link me a tar archive of an example project that produces this issue for you? So I can be sure I'm testing the same code.\n```\n% ls -l\ntotal 4\n-rw-r--r-- 1 patrick patrick   0 Jul  8 09:52 Foo.cls\n-rw-r--r-- 1 patrick patrick 373 Jul  8 09:53 ruleset.xml\n% cat .codeclimate.yml \nengines:\n  apexmetrics:\n    enabled: true\n% cat ruleset.xml \n\n3\n\n\n\n\n\n\n\n% codeclimate analyze\nStarting analysis\nRunning apexmetrics: Done!\nAnalysis complete! Found 0 issues.\n``\n. Hi @remik, sorry for the trouble here. The exclude paths look correct to me,- node_modules/` is also another option but either the pattern or directory name should work.\nI just verified that things are working here:\nI have a project with one fixme issue:\n```\n% CODECLIMATE_DEBUG=1 codeclimate analyze -e fixme\nStarting analysis\n[DEBUG] fixme:stable engine config: {\"enabled\":true,\"include_paths\":[\"tmp/\",\"lib/\",\"app/\",\".env.development.example\",\"log/\",\"docker/\",\".ruby-version\",\".env.test\",\"Gemfile.lock\",\"Dockerfile\",\".codeclimate.yml\",\".dockerignore\",\"config.ru\",\"Makefile\",\".env\",\".gitignore\",\"circle.yml\",\"Gemfile\",\".rubocop.yml\",\"LICENSE\",\"tags\",\"Rakefile\"]}\n[DEBUG] docker run: [\"docker\", \"run\", \"--name\", \"cc-engines-fixme-stable-29d5dd95-5ba4-4d94-9342-09ed332c2d0c\", \"--cap-drop\", \"all\", \"--label\", \"com.codeclimate.label=35c23b51-e25f-4166-ac96-bc090ed04f5a\", \"--memory\", \"512000000\", \"--memory-swap\", \"-1\", \"--net\", \"none\", \"--rm\", \"--volume\", \"/home/patrick/code/codeclimate/api:/code:ro\", \"--volume\", \"/tmp/cc/63c21ac8-f29a-4ee2-b0f3-4ede6d443b00:/config.json:ro\", \"--user\", \"9000:9000\", \"codeclimate/codeclimate-fixme\"]\n[DEBUG] fixme:stable engine output: {\"categories\":[\"Bug Risk\"],\"check_name\":\"TODO\",\"description\":\"TODO found\",\"location\":{\"lines\":{\"begin\":7,\"end\":7},\"path\":\"app/controllers/v1/user/repo_permissions_controller.rb\"},\"type\":\"issue\"}\n[DEBUG] fixme:stable engine stderr: \n== app/controllers/v1/user/repo_permissions_controller.rb (1 issue) ==\n7: TODO found [fixme]\nAnalysis complete! Found 1 issue.\n```\nAnd if I exclude by a similar pattern, it goes away:\n```\n% echo '- app/controllers//' >> .codeclimate.yml\n% tail -6 .codeclimate.yml\nexclude_paths:\n- \".md\"\n- bin/\n- config/\n- spec/\n- app/controllers//*\n% CODECLIMATE_DEBUG=1 codeclimate analyze -e fixme\nStarting analysis\n[DEBUG] fixme:stable engine config: {\"enabled\":true,\"include_paths\":[\"tmp/\",\"lib/\",\"app/models/\",\"app/services/\",\"app/serializers/\",\".env.development.example\",\"log/\",\"docker/\",\".ruby-version\",\".env.test\",\"Gemfile.lock\",\"Dockerfile\",\".codeclimate.yml\",\".dockerignore\",\"config.ru\",\"Makefile\",\".env\",\".gitignore\",\"circle.yml\",\"Gemfile\",\".rubocop.yml\",\"LICENSE\",\"tags\",\"Rakefile\"]}\n[DEBUG] docker run: [\"docker\", \"run\", \"--name\", \"cc-engines-fixme-stable-a0db3a45-f17f-4125-8716-e20f55e0ea91\", \"--cap-drop\", \"all\", \"--label\", \"com.codeclimate.label=b5a79a75-45af-4f57-993d-b6c78b02f63c\", \"--memory\", \"512000000\", \"--memory-swap\", \"-1\", \"--net\", \"none\", \"--rm\", \"--volume\", \"/home/patrick/code/codeclimate/api:/code:ro\", \"--volume\", \"/tmp/cc/719125a6-8005-4e02-989e-3e4eb0a7ee2e:/config.json:ro\", \"--user\", \"9000:9000\", \"codeclimate/codeclimate-fixme\"]\n[DEBUG] fixme:stable engine stderr: \nAnalysis complete! Found 0 issues.                       \n```\nI notice that in my case the issues are reported as path: foo/bar, but yours are path: ./foo/bar -- this could be why the exclude path isn't matching for you, and may be because you're using an out of date image that has an old bug. Can you confirm you're on the latest of everything and see if the issue persists?\ndocker pull codeclimate/codeclimate\ncodeclimate engines:install\ncodeclimate analyze -e fixme\nLet me know.\n. Oh interesting, I didn't realize you were doing a docker run-based invocation. I did re-test locally using your exact invocation and it worked as expected. Can you show the output of echo $PWD?\nPing @wfleming I know you worked on the code in the area that emits this message:\n[DEBUG] Couldn't include because part of path doesn't exist. path=\"./.\"\nMaybe you have some ideas?\n. Hi @remik are you still running into issues here? If so, can you restate what's going on -- the thread's a little hard to follow. If not, I'll go ahead and close. Thanks.\n. Hi @anoobbava unfortunately the CLI does require Docker.\nSince Engines often have to be written in the language they analyze, a version of our CLI that didn't rely on the them being containerized would require the user have a working environment for a prohibitively large set of programming languages and frameworks. You'd need to have various versions of interpreters installed, any dependencies they use, and if the engine were a compiled language, we would need to do a lot of cross-compiling and your architecture would have to be one we supported.\nI'm really sorry about the limitation, but the CLI would likely be impossible for us to build and maintain otherwise. Maybe you'd find value in using our hosted analysis instead/only?\n. I'm going to go ahead and close this issue now. I hope my explanation was valuable.\n. I meant that, even though you can't use the CLI for local analysis, you could still add your project(s) on codeclimate.com and see the results of analysis there.\n. Hi @danielkza use of this project as a gem isn't really intended. We do it in our own infrastructure but that's an accident of history, and I'd consider it deprecated. This repository is only meant to be used as the Code Climate CLI which runs within a docker container with the appropriate Ruby version -- therefore, we don't worry about wide compatability like that.\nI'm curious, what is your use case for loading this as a gem?\n. I'm sorry you felt mislead and are encountering breakage in your system. If you were to open a PR that added a minimum ruby version to the gemspec, I'd happily merge. Unfortunately, I don't think we're going to worry about if/how this is used as a gem at this time.\n. Hey sorry for the trouble here. Are you able to run the apex tool directly (not as an engine or via codeclimate) to see if it indeed takes longer than 15 minutes on your source code?\nAlso, please provide output when run with CODECLIMATE_DEBUG=1 as well as some general system information like docker version or uname -a. Thanks.\n. Sorry for the delayed response here. Are you able to run the apex tool directly (not as an engine or via codeclimate) to see if it indeed takes longer than 15 minutes on your source code?\nI'd like to figure out if the time is being taken by our code in the engine, or the underlying tool itself.\n. Hmm. OK, that indicates to me that the bug is in the engine. I believe the Issue you originally opened there is the appropriate place, since this is unlikely to be the fault of the CLI itself. I would encourage you to ask that it be re-opened, but I appreciate how annoying it is to be bounced back and forth.\nEither way, would you be willing to share a tar archive of a minimal project that exhibits this issue? It's probably the only way we'll be able to reproduce and debug the issue further. Thanks.\n. Thanks very much for your understanding.\n. Hi @slifin we've seen this come up when the docker server has an incompatibility with the client we use in the codeclimate image (the service is Go 1.6 and the client is Go 1.5). Can you run docker version to confirm? We've seen this first with Arch Linux users, but Ubuntu may have caught up enough to hit the bug as well now.\n. Sorry, I think that's docker --version. Can you post docker version (argument, not flag)? That'll include more information.\n. OK, that definitely explains it.\nHere's some more details if you're interested:\n- Original Issue: https://github.com/docker/docker/issues/20865\n- Fixes tagged with 1.12 milestone: https://github.com/docker/docker/pull/22000 https://github.com/docker/docker/pull/22888\nAnd here are the options I see to get you working again:\n- Rebuild your docker package with go-1.5\nThis is what the Arch users have done so far. A little annoying, but at least immediate and in your own hands. There might even be a package available for Ubuntu, I'm not sure.\n- We update our client\nI'm not against this, but it'll take us time to fully evaluate and test that impact. There may be users on older dockers that rely on the version we're using (an older client can talk to a newer server, but not the other way around).\n- Wait for / upgrade to docker 1.12\nI'm not sure how viable that is for you.\nSorry I don't have better news.\n. I believe so. I based that on the current milestone for the fixes I linked to above.\n. Hi @dread-uo, the primary use-case for this project is as a CLI tool via the codeclimate/codeclimate docker image. The fact that it's available as a gem is more an accident of history than anything, and is something we plan to move away from soon.\nI'm very curious to know your use case for loading this project as a gem, especially in a Rails application.\n. Thanks for that information. Unfortunately, I'm going to go ahead and close this issue.\nWe're not against folks like yourself doing this, but we want to be upfront about the fact that we will likely stop releasing this project as a gem soon, and we won't be addressing any Issues like this in the meantime. However, if you were to open a PR correcting these kinds of version bounds problems, we would likely merge it.\nI've added some copy to the ISSUE_TEMPLATE to hopefully clarify for future users who encounter this.\n. Thanks!\n. Yessssss\n. > should we remove the intro about using items in this section for debugging?\nIMO, yes.\nLGTM pending that change.\n. Nice\n. > Reproducing locally, I found that the second results overwrite the first. That's the story there.\nThat's what I suspected -- now I'm more curious why the old-style usage wasn't impacted by this. My theory: old-style usage posted both payloads, the first was accepted, the second rejected as a duplicate. New-style usage runs after everything and so only submits the last payload.\nIf true, one workaround would be to change the command:\nbundle exec rake spec:all  && bundle exec codeclimate-test-reporter && bundle exec rake spec:benchmark\nThis seems reasonable to me, we want the coverage of the actual test suite, not the benchmarks.\n. For the UX, I imagined it'd just be codeclimate dependencies. Just because today it only has a files sub-key and only takes that action, I still see the command as broader and open to future extension. WDYT?\n. codeclimate dependencies --files might be another option, if you really want to make the \"I'm only doing files things\" explicit.\n. Yes, I think codeclimate dependencies would do everything (which is today just the files stuff). Then if/when we extend further we can decide if:\n- A sub-sub command makes sense (your suggestion)\n- A flag makes sense (my second suggestin)\n- It actually doesn't ever make sense to do \"part\" of the dependencies step (what I think is likely)\nI don't see it backing us into anything, personally.\n. Cool, LGTM.\n. I'm not sure the most robust way to do this, but just wanted to note that that regex is too restrictive IMO. Lots of terminals which are neither xterm nor 256color-capable should still be able to show our spinner and limited coloring. The most notable would be screen.\nIt might be more valuable to avoid certain \"known-dumb\" TERMs (like linux). @zenspider can you tell me what your TERM was when you uncovered this?\nI think @wfleming mentioned matching tools like ls and grep which have an auto|always|off argument to their --color options. I'm :+1: on that, in addition to matching their implementation of \"auto\".. Hi @pointlessone there are some Docker complexities about storing config data which I'll have to work through with you to get this over the line. Could you do me a huge favor? Please split this PR into two: one that implements the actual version checking code and another that deals with caching, XDG, etc.\nThe first PR (the one that actually does the version checking) should be guarded by a --[no-]version-check flag and default to don't. That should be a pretty quick review and we can ship that and get it out. \nThen we can follow up with the feature of caching last-checked etc, and making it on-by-default. Grab me in Slack before starting on that second PR and I can describe the Docker complexities we'll need to account for.\nIs that OK?. @pointlessone I think this is superseded by the other two PRs, so I'm going to close this one.. @maxjacobson is there anything blocking this from merge?. Sounds good. This is further evidence that a better default-config system would allow the engines to themselves control what default configs are written for them.. The order dependency and code duplication/alteration with the pull step makes total sense, and is a clear reason why this is probably the least-bad option at this time. Thanks for clarifying that.. @zenspider \n\nbecause you have to use self. or rename the arg where it is used.\n\nI don't think so. You'd be calling #[] and #[]= on (basically) a reader, so none of the self. or scoping issues of a writer would come into play.\n. @zenspider I agree with this statement:\n\nIf an engine produces one other_location for a given path correctly, we can presume it will for all other values with the same path.\n\nBut I also agree with the spec's docstring as written:\n\nCC::Analyzer::IssueValidations::OtherLocationsFormatValidation#valid? returns false if the other locations are not valid\n\nCan the test be changed to produce no valid other_locations, and such still be a good test?. @zenspider \"change the test to have non-zero but entirely invalid other_locations\". @GordonDiggs should we merge this now, or wait for #587 to merge into it?. @pointlessone headsup I've rebased this branch and will merge on Green.. So, here's the deal :)\nSince the CLI runs as a Docker container, anything you put in ~/ will only exist in that container. Nothing would persist run to run. There are some hacks we could do in the wrapper script to mount the user's local ~/ into the container on each run, but that can get complicated (especially with Docker For Mac, which is always finicky).\nI would suggest two things:\n\nReduce the things you need persisted as much as possible\n\nI wouldn't worry about persisting the \"don't check version\", if users want to opt out they should pass --no-check-version on each invocation (and make their own shell aliases to \"persist\" it). That means you really just need to store a timestamp in cc-version-last-checked-at.txt.\n\nPut that in /tmp, which we do mount through and make [available in code][code]\n\n[code]: https://github.com/codeclimate/codeclimate/blob/becc31c1c8292fd214d0b04b79cfd82117296269/lib/cc/analyzer/mounted_path.rb#L19. In my first suggestion, I forgot about storing the UUID so we can identify repeated checks from the same user. I'll have to think about this some more, since /tmp doesn't really work. Not really sure yet how to meet the product requirements there, given the Docker constraints. /cc @GordonDiggs . > Since CC CLI can be ran both in container and out of it, we have to make sure both cases work identically.\nThis is not true. We do not endorse or support users running the CLI outside of docker.\n\nIt's build of machine's MAC address\n\nCan we access a stable machine MAC address, without the added uniqueness of a UUID? That sounds like what we want.\nBarring the answer to this question, I see the following options:\n\nDon't do anything (my favorite option, cutting scope is always an option)\nIdentify by IP server-side (may be close enough for requirements, who knows?)\nUse a generated, persisted UUID handled in the wrapper script\nPro: no docker complexities\nCon: doesn't work for folks running docker run directly\nUse docker info\nPro: readily available, works with or without wrapper script\nCon: changes ~~at unknown times~~ every time docker is restarted\n\nWe need to take these tradeoffs to the feature-owner and come back with a direction. @GordonDiggs can you facilitate that?\nThat said, if you move to my suggestion (don't send a uuid, store last-checked-at in the mounted tmp), we could ship this as a meaningful user-facing increment and defer the user-identification until we have that direction.. @GordonDiggs isn't that the best case I described?. @GordonDiggs none. I was guessing it could be as good as the best or as bad as the worst but had no evidence either way. Since you've got docs, I'll update the comment.. > Is that a supported way of running CC?\nIt's \"supported\" yes, we document how to do it in the README. But this issue isn't about a user-facing feature, so it's up to us if \"wrapper-only\" is OK or not.\n\nChange when hardware changes (sometimes even when default network interface changes, e.g. from Wifi to Ethernet/LTE/etc).\n\nThis sounds like deal breaker.\n\nInaccessible from container, still needs to be passed by a wrapper\n\nThis suprises me. If we can build a UUID from MAC in the container, it's obviously accessing the MAC somehow right? Anyway, doesn't really matter if MAC is out because it changes with network interface changes, IMO.. Sorry @pointlessone I believe that is actually a sub-optimal solution. It means the files written by the CLI will be root-owned. I think it's surprising (and slightly alarming) from an end-user perspective to have a tool writing root-owned files into my user dotfiles.\n@GordonDiggs WDYT? Does that matter / is it important? Given that MAC address is out, your next preference was for UUID, but you didn't clarify if it was OK to be a \"wrapper-only\" thing.. @pointlessone that's pretty good hack actually! I think I'm good with that.. @pointlessone I've merged the PR on which this was based. Please let me know if you're finished here, then I can take over to clean up history and merge.. Re-opened as #591. Will merge and release tomorrow. Confirmed locally this doesn't break anything, but there is a JSON parse error visible in DEBUG, so it's just skipping the check at the moment.\n/cc @pointlessone . Must've been temporary, it's working now.\nOnly thing left here now is the test failures, I guess.. I don't see a persistent UUID written anywhere though,\n```\n% cat ~/.{config,cache}/codeclimate/*.yml\n\nlatest-version: 0.52.0\noutdated: false\nlast-version-check: 2017-03-15 14:03:52.801191019 +00:00\n```\nIs that expected?. @pointlessone it appears to me nothing ever calls GlobalCache#save. The other file is saved as part of all the write methods.. Thanks! Will try to do a release today.. There's definitely more work on this track, but I'd like to pause at points where things are at least functional and I can get a deployment out, and avoid monster PRs.. Just opening for visibility, will generally merge these on green. We actually have really good tests in this area!. Hi @vovimayhem this is a really interesting use-case. Let me test some things out and report back with suggestions for how we might accomodate.. I'm glad you were able to work around this @vovimayhem. Most likely we wouldn't have been able to make changes on our end in a timely matter.\nWe have broader plans for supporting projects where the code to analyze exists in a sub-directory of the checkout. This is mostly intended to support folks using a monorepo approach to organizing their projects, which is becoming more common these days, but such a feature would've also solved your use case.\nI'm not sure what the feature will eventually look like, or when it might land, but the fact that it was on the horizon is motivation to avoid making orthogonal, more acute changes in this area at this time.\nI'm going to go ahead and close this, but if you feel there's more here to discuss, and it's worth keeping open during that discussion, feel free to re-open.. TODO: fix and add specs.. Uncovering a thicket, removed the review-request for now.. OK, green and ready for review.. @wfleming nice catch. Added a spec and fixed another bug.. For parsing and reporting test coverage information, you should check out our universal test reporter. This CLI is for facilitating and running analysis.. #uid and #guid should be cheap, with File.stat being the only (and not really) expensive call. What do you think about FileSystem#stat delegating to and memoizing File.stat, then just calling these methods when needed?\n. I don't think there's a lot of value in the default here. It duplicates a constant and may run into issues because we're never calling FileSystem#path_for. I would drop it and either always call this method with filesystem.path_for(CODECLIMATE_YML) or implement FileSystem#stat and have it call #path_for internally, maybe?\n. Can you put a blank line above this?\n. Sorry, I think this method should still take an argument, I meant to get rid of the defaulting.\n. Is there a better name here? The purpose of the method isn't really to \"set local owner\" (it sets owner and group, and there's only a loose concept of \"local\"). What about #correct_permissions?\n. Not something to change now, but worth noting. I think there's an abstraction issue here. We go through filesystem for things like path_for or stat, but then we break the abstraction and call things like File.open or File.write directly? If FileSystem had a #write method that would be better, and #path_for could probably be made private as it'd only be used internally within (methods like) FileSystem#write.\nAgain, something to consider in a separate PR -- but it provides a little context for my FileSystem#stat suggestion.\n. What do you think about this method living on FileSystem?\nIf we eventually fix the abstraction issue I mentioned, the calling code would look like (for example):\nrb\nfilesystem.write(CODECLIMATE_YAML, parsed_yaml)\nfilesystem.correct_permissions(CODECLIMATE_YAML)\nAnd that feels nice to me.\n. Is it likely that we'll want to correct every file we write? I think probably. If so, we could move the chown into FileSystem#write itself, and remove #correct_permissions altogether.\n. Do these existing files/directories matter to the spec at all?\n. Doh. I didn't realize #read_path existed. Please remove the #read method I added and use #read_path instead.\n. If this variable is unused (which is likely b/c you renamed it and nothing broke), please call it _ to convey that.\n. Done.\n. docker pull and docker run are only needed if you don't use our wrapper package. If you run the curl; make install instructions you have pulled the image and codeclimate the command is available, no need to docker pull or docker run.\nThe basic categories would be this:\nOS X suggested: run brew ... and use codeclimate [cmd]\nLinux suggested: run curl; make install and use codeclimate [cmd]\nAnywhere: run docker pull and use docker run.\n. Did you find this to be much faster? @noahd1 and I found that it's the actual file access that's slow, not the ruby. In other words when we ran this find command in boot2docker on the large test repo, it was just as slow as the Dir.glob approach. We weren't rigorous though so I can't cite numbers. It could be faster, it just didn't feel it.\nI'm fine making this change, just FYI it might not be the silver bullet.\n. You've also now opened yourself up to funny filenaming issues. I'd suggest -print0 and split(\"\\0\").\n. :+1:\n. If you use find * instead of find . you won't need to strip it in ruby.\n. There may be caveats, see http://stackoverflow.com/questions/2596462/how-to-strip-leading-in-unix-find/2596474#2596474 for details.\n. :lipstick: no ternaries.\nWhat do you think about extracting a #registry_entry to hold the conditional?\n. Can we get rid of timed_out and do whatever happens on timed_out = true in the rescue? I think the only change in behavior is that \"cli.engines.finished\" wouldn't be ticked in the case of a timeout. If that's important, I'd just duplicate the increment call: once in the happy path and again in the timeout rescue.\nAlso, the begin/rescue is telling me to extract a #wait_for_container method.\n. Calling waitpid again after sending the kill should reap the process.\nOn Sun, Jun 28, 2015, 19:15 Bryan Helmkamp notifications@github.com wrote:\n\nIn lib/cc/analyzer/engine.rb\nhttps://github.com/codeclimate/codeclimate/pull/35#discussion_r33428252:\n\nend\n-        rescue Timeout::Error\n-          run_command(\"docker kill #{container_name} || true\")\n-          timed_out = true\n\nIn the timeout case, the process does not get cleaned up.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/35/files#r33428252.\n. The limit is line length, I think it's \"ENGINE_CONFIG=#{@config_json}\".size, right?\n. Do you think there's anything more valuable we can say here? Unfortunately, I'm having trouble thinking of a concrete improvement, but I find this message as-is a little lacking from the end-user's perspective.\n. I'm pretty sure this approach won't work, but I have other ideas. I can flesh them out if we green-light this PR in general.\n. How about\n\n... | xargs docker pull\n. Generally grep <re> | awk { <cmds> } can be replaced with awk /<re>/ { <cmds> }\n... | 'awk /codeclimate\\/codeclimate-/ { print $1 }' ...\n. Can you shift these two spaces so the continuations are still indented beyond what they continue?\n. I think I suggested this before, but you can change the syntax here:\nrb\ndef engine_running(engine, &block)\n  # ...\n  with_spinner(\"...\", &block)\nend\nIn this case I think it'd help because you're pushing another level of indentation.\n. I'm wondering if it's worth DRYing this so the two don't drift out of sync. One way to do that would be to extract a function:\n``` sh\ndocker_run() {\n  exec docker run --all --the --shared --options \"$@\"\n}\nif ...; then\n  docker_run --interactive --tty codeclimate/codeclimate \"$@\"\nelse\n  docker_run codeclimate/codeclimate \"$@\"\nfi\n```\nWDYT?\n. Does something try to kill this thread later? Is it a problem that @thread will be nil in the non-tty case?\n. I support rubocop in its return unless $stdout.tty? suggestion, FWIW.\n. Yeah, I think I will in the feature branch. Leaving it seems more in the spirit of behavior-neutral for this PR.\n. Ruby's method security is weird and that's not what protected means. But it could be private, sure.\n. Nope, that's the traditional definition of these keywords. In Ruby, private just means you can't call it with a receiver (foo works, anything.foo, self.foo errors). This means, even within a subclass, you can call current_engine which is private and it works because there's no method receiver.\nprotected means you can only call it with a receiver that is your class or one of your subclasses (or maybe something even more subtle, I can't remember). It's really just meant for this scenario:\n``` rb\nclass Foo\n  def ==(other)\n    name == other.name\n  end\nprotected\n# this should be private, but because we need to invoke other.name \n  # within #==, we use protected\n  attr_reader :name\nend\n```\n\nMy main goal here is that this is accessible to subclasses but not outside.\n\nYup, done.\n. Went ahead with this anyway now that I refactored the spec such that it doesn't matter\n. If the output is a JSON array (which is valid for JSON). See here for a test that fails without this condition in place.\n. Good call, done.\n. Yeah, I guess that's true. If the filter doesn't blow up on that, the formatter would anyway. Will remove.\n. It was a drive-by fix: args is unused, if this were written today, it would be a rubocop issue.\n. No reason, didn't think about it.\n. I think this should be config.enabled?, it's a true CC::Yaml object now.\n. Could remove flatten by using flat_map above.\n. I have no idea! Agreed merge is probably better either way\n. Nope. Just putting the p in WIP\n. Had the same thought and no strong opinion so left it as is. Fatal makes sense to me.\n. I thought we wanted this to be incorporated into the existing validate-config command. Might be a question for the team, both ways make some sense.\n. accidental?\n. We would want this command to exit non-zero to signify failure in this case right? I'm not sure the mechanism commands have for controlling that, but if it's returning true here, that seems backwards.\n. The object that would initialize this log instance wouldn't know the image name. Since we've got the EnginesRunner class in the middle, the original invoking object doesn't know anything engine-specific unless it's passed into the life-cycle methods themselves (like this).\n. I like it.\n. I forgot to implement docker_run_command but it'll be docker run + default options + options\n. Should be ->(*) { }, basically a no-op default.\n. FYI: I'll move this to its own file in the real PR.\n. Heh, would clearly catch stuff like this when I do the real PR with tests.\n. I don't have a strong preference between making (private) attr_readers or using instance variables directly. I think I advocated the former at one point but because I see the latter more prevalent in our code bases, I've been starting to do that -- which is what I've done here.\n. Sorry, got my formers and latters mixed up. Editing my original comment to hopefully clarify...\n. Yup, makes it a required keyword argument.\n. > I haven't seen much of using instance variables directly\nI'd have to do some kind of audit to be sure, but at least in this PR Engine also accesses its instance variables directly.\nI was going to switch these over, but it's actually kind of annoying and error prone so I'm going to leave them as is (if that's OK with you). If you want to push for the attr_reader approach can you open a PR on the style guide?\n. Since this check was never meant to be super strict anyway, what do you think about grep -Fq \"Server\"?\nIf you'd like to keep the or-pattern, I would just escape the pipe since it's only the one character (and the parens are redundant): grep -q \"Server version\\|Server:\".\nIf you'd like to keep the extended option, please switch the deprecated egrep out for grep -E.\n. Didn't think too hard about it. Container seems like a good home too. Container::ContainerData is a little redundant, but that's probably OK.\nI'd prefer not to do Struct.new(...).new(...) or use an OpenStruct at the call site.\n. Originally the requirements of this solution were such that, if there were files/directories that were not readable and weren't intended to be excluded, those were still supposed to bubble up as permissions errors.\nIt was only when the engines encountered unreadable files that the user had intended to exclude that is \"the permissions  bug\" we're trying to fix.\nIt might be a fine 95% solution, or the best we can do given all the subtle hurdles we've encountered, but if the requirement were boiled down to: \"just skip unreadable stuff\", there may have been something simpler that didn't involve all the git tom-foolery:\n- Recursively expand the source dir\n- Rescue permissions errors and ignore\n- Filter excluded\n- Present the result as include_paths\nRight?\nAlso, we have to keep in mind that the CLI (this code) runs as root (technically whatever user is UID:0), while the engines run as an underprivileged user (app:9000), so anything you do permissions-related in this code isn't guaranteed to translate to what the engine is ultimately able to access.\n. :lipstick: we don't use this pattern of underscored \"private\" (I assume?) instance variables\n. :lipstick: no ternary please\n. :lipstick: we use the UnreadableFileError = Class.new(StandardError) form\n. I'm 99% sure Enurable#each returns the collection.\n. https://github.com/codeclimate/styleguide#general\nThe reasoning is that ternaries (regardless of complexity) \"hide\" conditionals, so expanding them is a way to make the conditional logic of your program more visible and painful so you're motivated to remove it rather than work around it by compressing to a ternary.\n. Why did you go for a monkey-patch over just putting a #readable_by_all? on the object that needs this logic?\n. I'm noticing the \"exception handling for control flow\" smell here. Did you consider any non-exception-based alternatives?\n. Oh nevermind, this is actually raising out to the end-user? Sorry, ignore my comment.\n. :lipstick: no parens on raise\n. > I also tried making this a method on IncludePathsBuilder\nThis is what I was suggesting. Thanks for the explanation.\n. How about @file_entries ||= relevant_full_entries.reject do |e|?\n. We don't use this @_ convention anywhere else. Could you avoid it to keep things consistent?\n. At what point are you actually looking to see if directories themselves are \"unreadable\"?\n. Gotcha\n. This is the only actual change in this file.\n. Is this supposed to be ---\\nlanguages...?\n. Nice, can you use _data so we don't lose the information about what it would be? Same with _output.\n. :lipstick: extra whitespace\n. :lipstick: if ! => unless, then unless / else => flip the conditional\nrb\nif @engines_options.any?\n  # ...\nelse\n  # ...\nend\n. Should these be filled in with something?\n. I'd expect that one file in the enable_regexps then, but OK.\n. Why is this necessary?\n. Probably warn? I'm also OK completely ignoring, maybe with a statsd increment.\n. > I don't usually advocate using or but given that it's for control flow and not logic, I think it's a good use case.\nFWIW, I love and / or for control flow. That's what they're there for; it's why the lower precedence.\n``` rb\nfoo_bar or raise \"x\"\nx = get_it and go(x)\n```\nWe seem to avoid them here, so I've been abiding but I'd be happy to have a discussion about bringing them back into our toolbox.\n. 232.04x slower ha!\n. I think we need to actually avoid always storing stdout for all containers. The Engines' stdout is completely useless and can be crazy big, already causing memory issues across our infrastructure.\nMy original thought is that we could default @on_output to write to a StringIO, like you have here (instead of the current just-ignore-it lamba).\nThen engines would continue to override it to read their results (but not additionally bloat up a big @stdout_io object) but non-engines would have access to that output in the container data passed to the lifecycle methods.\n. I can see how engines-specific listeners may be valuable (or required) soon, but is it needed to do the stdout stuff you have in this PR? Feels orthogonal.\n. Unfortunately not true for me. Can you test, maybe it was a version\ndifference?\nOn Tue, Oct 20, 2015, 18:33 Bryan Helmkamp notifications@github.com wrote:\n\nIn lib/cc/analyzer/container.rb\nhttps://github.com/codeclimate/codeclimate/pull/154#discussion_r42563788\n:\n\n@@ -124,6 +124,15 @@ def container_data(duration: nil, status: nil)\n           @stderr_io.string\n         )\n       end\n+\n-      def reap_running_container\n-        container_id = docker ps --quiet --filter name=#{@name}.chomp\n\ndocker kill (and all docker commands0 accept a container name as a\nsubstitute for the container ID. Therefore, I think the name lookup is\nunnessary.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/154/files#r42563788.\n. You're right! That's much better.\n\nI had been getting errors in the specs which I had to fix by letting the container start before trying to reap it (hence the sleep 1, etc) and mistook that as meaning I had to use the ID -- it's been a confusing evening on this track....\n. Nice catch, but what do you think about pulling this to its own PR? The timeout logic is so critical and so futzy, I want to be super careful with any changes to it.\n. Nothing :)\nI'm not sure what would be worthwhile to do in such a case, any suggestions?\n. I would actually be against it raising if it fails because we're already in an error-handler of sorts and you'd end up masking what really happened with that failure -- maybe that'd be OK, I don't know.\n. It might be good enough to extract out a &defaults reference, so the engine keys can specify less if they care about less.\n``` yaml\ndefaults: &defaults\n  beta: false\n  community: false\n  enable_regexps:\n  default_ratings_paths:\n  default_config:\ngofmt:\n  <<: *defaults\n  image: ...\n``\n. Probably don't need this now that you aren't subclassingArray. Should be--env` -- it's causing the CI failure.\n. Relatively recent policy on this:\n- Everyone should be using latest bundler on all projects\n- That is currently 1.10.6, so doing so will prevent this diff from cropping up\n- If/when bundler does update, we'll see some noise here once per project\nSo... please git reset this against master, then gem install bundler, then you shouldn't see it vanish again on your next bundle invocation.\n. I think we support slim too.\n. I'd probably ditch this local\n. Is this equivalent to paths - ignore_paths?\n. I just want to highlight that we've had a number of subtle bugs around some confusing behavior in Ruby.\nImagine the following structure:\nfoo.rb\nfoo/\n  bar.rb\nDir.glob(\"**/*.rb\") will find foo.rb (as expected). However, File.fnmatch?(\"**/*.rb\", \"foo.rb\") is false.\nThis is why we (for a time) had to tell users they needed **/*.rb in excludes to \"exclude all ruby files\", but **.rb in ratings-paths to \"rate all ruby files\" -- confusing, and dumb.\nSo, BE CAREFUL. Where do globs come from? User input? Do you expect to see **.rb or **/*.rb? Is there a way to use the PathPatterns class, which we created in an effort to standardize on one kind of behavior in all our glob handling?\n. Now that these stanzas are simpler, can we ditch the locals?\nrb\nin_diff?(path) || IncludePathsBuilder::IGNORE_PATHS.include?(path)\n. Thoughts on co-locating the let and before into the (only) example using them?\n. Oh, this is worse than I thought ;) -- cc_includes is somehow magic and used by something not visible within this describe or it?\nOh well, backing away...\n. Sorry, I'm not sure if that answers my concerns.\nThis implementation will require pattern to be (.e.g) **.rb (not **/*.rb) to match a top-level file like foo.rb -- is that the behavior you want / need? It's usually not, but it may be; just want to be sure.\n. > Doesn't the glob_value method do the proper conversion?\nI don't know what that means.\n\nIt's being given to me as */.rb currently.\n\nThen this method will return false for path = \"foo.rb\" -- is that desired?\n\nI don't think I completely understand when that would get passed in (\"**.rb\")\n\nThat's precisely the question on the table: where does @patterns come from (specifically is it us or the user)? I think you'll need to track it down to be sure this bit works the way you need.\n\nand how I would make sure both work.\n\nIn other places across the codebases we ensure it all works by:\n1. Make sure we only see **/*.rb, never **.rb (i.e. the cc/yaml gem translates the latter into the former)\n2. Always use PathPatterns for any glob matching or expanding as it does the Right Thing\n. OK, I think I'm tracking better now...\nAssuming @patterns are coming in as cc/yaml Glob instances, then you're right in that my point number 1 above is being followed (thanks to #glob_value). You should only ever be seeing **/*.rb here.\nHowever, point number 2 is not. By using File.fnmatch? you're going to return false here for path = \"foo.rb\". I suggest you use PathPatterns.\n. :lipstick: order macros like this first after the private pragma\n. Hi :) I assume you'll be ditching this in favor of #expand or PathPatterns?\n. map.flatten -> flat_map?\n. map.flatten => flat_map again please.\n. flat_map again\n. This was my typo, but \"directory\" -> \"directly\"\n. The reason it worked this way, is that this script doesn't assume you've pulled master since the PR was merged -- that's done here.\nNot saying what you're picturing won't or can't work, but it might need a few more changes to ensure running this script doesn't release the existing version by mistake.\n. I guess the simplest thing is to just move the version= line to after the checkout/pull\n. I think it'd be safest / simplest to just join both\n. What's this little guy?\n. I see, should've read the commit\n. WDYT about bringing this out from under the timed-out conditional? Presumably, if we're exiting this method (successfully or otherwise) we're done with these threads. If we were successful, we'll have joined them already and the kill should be a no-op -- if not, better-kill-than-sorry?\n. I wondered this last time it came though: doesn't this basically just re-implement Thread#join?\n. Comment lost to the diff:\nI wondered this last time it came though: doesn't this basically just re-implement Thread#join?\n. What is io, do you mean out?\n. Never use backtick, always $( ). http://mywiki.wooledge.org/BashFAQ/082\n. :lipstick: quote all the things, these commands and the rm below.\n. Oh and the usage above at L38\n. Because it doesn't need to be, it's not referenced outside this method.\n. That makes sense to me, but I'm leaning towards reducing variables and not making that unrelated change as part of this fix.\n. I'm actually curious why we do this. Do we ever use the CLI images on GCR?\n. Yup, you're right -- there's no reason to have it in the circle dependencies.\n. Oh I'm sorry. I started down a debugging track on Circle with WIP commits. I should've marked the PR itself WIP too.\n. @dblandin I agree with that, and that's why I put it in there originally. Unfortunately, I don't want to take it out of the Makefile because then I'm sure there will be a day, or many days, I run make test and can't figure out why my changes aren't having the desired effect.\nI'd probably go back to what I had. Even though it's technically duplicated work, it is a 100% cached and fast build when Circle runs the test. I don't feel strongly though. @wfleming ?\n. I think even then, it was using the gem executable not a docker image.\n. Interested in folks' thoughts here. If we feel this is too hacky to commit, I think I'll have to abandon this approach. Without some sort of delay after the kill, it fails reliably on Circle.\n. Mentioned IRL, but for visibility:\nI think we should go with an actual Issue class we can pass around and filter on that responds to methods. Then we #to_json that for the stdout_io.write call.\n. I considered that, but then we run the risk of a run-away poll meaning a run-away builder in production. Not something I wanted to add because of flakiness on Circle.\nIn the end though, this sleep seems to introduce additional flakiness that I was able to see locally as well, so it's not a good enough solution. I've abandoned this branch for now.\n. Doh, I guess this should be issue_filter now. I'm fine punting on the rename for now, it'd muddy the diff quite a bit I think.\n. I'm having some naming trouble here: hey instance of Issue are you an issue? feels wrong. I think we either\n- Don't construct an Issue unless it's the right type, or\n- Rename Issue to something more generic (maybe Output?) then it makes sense to ask that thing if it's an \"issue\" (vs, I guess, a warning?)\nWDYT?\n. You're right. I think it's issue that's actually the wrong name here, as mentioned in other comments.\n. Add a #to_json delegate to prevent angering Demeter?\n. Would it make sense to guard this with #issue??\n. If so, I might raise on false instead of (e.g.) returning nil.\n. Is the intention of codeclimate engines:list to list all available engines? If so, we could use that here to perform this validation. That would be well in line with the spirit of this architecture. The codeclimate-engines subcommand could encapsulate access to the registry.\n. This sub-Gemfile was more of a convenience thing: I could cd codeclimate-validate-config and suddenly find myself working in a much simpler, but still complete project tree.\nThe Ruby environment (in the container) is a shared global thing, created by the single top-level bundle in the Dockerfile. We could definitely figure things out one way or another, but for now I'd chalk this up to a non-interesting packaging concern.\n. One of the biggest appeals of the isolated sub-commands is that they are free to make their own choices about dealing with whatever level of complexity they happen to be at. While codeclimate itself has long passed the bar for bringing in a real options parser (IMO), I don't think this command and its single flag meets it yet.\nAlso, this --strict idea might not even land (we might decide to preserve the \"warnings are always fatal\" behavior), so I didn't want to spend additional effort supporting it here.\n. Just an oversight; I didn't notice that behavior when porting the code. I'll bring it back and add a spec if/when we move forward on this.\n. Agreed on all counts, most of all: This take is probably fine for now :)\n. I thought this was much more readable than that, myself. Maybe a third opinion?\n. Yes, in some cases.\npath can enter this method as foo or foo/, depending on circumstances. Therefore, without the remove-and-readd, you'd get foo/ and foo// as possible outputs. With the remove-and-readd, you get foo/ and foo/ as desired.\nIf you like, I could make the branches explicit, something like:\nrb\nif path.end_with?(File::SEPARATOR)\n  path\nelse\n  \"#{path}#{File::SEPARATOR}\"\nend\n. Can you unpack \"this situation\"?\n. My intent would be that the pattern is ignored and the warning is visible. That's not dot-com specific though, and assumes this stderr shows up on the build screen, which it may not.\nBut you might mean something else?\n. Now that the complicated part has shifted from the list itself to the individual patterns, I don't think Exclusions is what we want. We probably want [Exclusion] here:\n``` rb\ndef filter(patterns)\n  patterns.each do |pattern|\n    exclusion = Exclusion.new(pattern)\nif exclusion.glob?\n  path_tree.exclude_paths(exclusion.expand)\nelse\n  path_tree.exclude_paths([exclusion.raw]) # or something\nend\n\nend\nend\n```\nThen my next suggestion would be to resolve the TDA violation by pushing glob? into expand\n``` rb\nclass Exclusion\n  def expand\n    return [pattern] unless glob?\n# expansion logic...\n\nend\nend\n```\nThen my next suggesion is... do we really need both Workspace and PathTree? At that point, Workspace isn't doing too much, and the indirection may not be worth it.\n. I think it's a little leaky to let/expect callers to reach in for PathTree and Exclusion directly. WDYT about having Workspace.create (or something) to encapsulate the PathTree instantiation, then have PathTree#exclude_paths accept patterns and wrap them as Exclusions internally?\n. Should we use Benchmark.realtime for these measurements?\n. I vote we put this and other benchmarks under ./benchmarks, with a separate rake task. I'd also vote they output timing information (e.g. Benchmark.bm), rather than assert on timings being under some threshold.\nI wouldn't characterize what happened as developers just not realizing, because nothing was watching their backs. Rather, I think we would've actively used benchmarks during the development of this logic, had we had them -- and we probably should've written them then. Therefore, I think benchmarks being available to run and view as needed is just as valuable as putting performance-based assertions in the normal spec suite.\nMaybe some day we could incorporate it into the release process, to run the benchmarks between master and the last released tag.\n. I believe, because of this, we no longer need that is_a?(Glob) => .value hack. Since this will simplify x/**/* and x/** both to x. After adding the workspace spec using vendor/**, it still passes without that logic.\n. PathTree.new here and self.class.new at line 81. Probably should be consistent, I think I prefer self.class.new since it's robust against renames.\n. FWIW: If you made this method signature delete(head, *tail), you'd get path_pieces[0] and path_pieces.drop(1) for free. This is a common way to operate on lists in Haskell.\n. Under what circumstances do you expect this? Is it possible to remove those circumstances so we don't have to have this branch here?\n. Same question for #insert\n. I can be convinced that we should keep the logging in #insert (and maybe make it a WARN even). But for excludes, I think we should silently ignore.\nTwo reasons:\n- When I create a git project, I start with a .gitignore full of things that don't exist (yet or never will), this is super common and I see analysis exclusions the same way\n- Something not existing clearly won't be analyzed, i.e. it's been excluded -- technically speaking, we've done the Right Thing\n. CC::Analyzer::Config is a dying class. Can you try using CC::Yaml directly?\n. Is there a strong reason for these renames (inserting _engine_)? I'm finding it distracting when trying to make out the actual behavior change here.\nGiven your PR description, I expected a smaller change; something along the lines of:\n- extract something like #engine_names that uses cc.yml if present or ConfigGenerator if not\n- Replace config_generator.eligible_engines with #engine_names\nThe other renames and refactors might be good, but I think it'd be easier to discern if the behavior-changing and non-behavior-changing stuff were in separate PRs.\n. The commits don't seem sliced that way. https://github.com/codeclimate/codeclimate/commit/668956f7ce32d996f27836d7d1aaf82649f876fb has a rename in it, for example. And, in that commit, I still can't see where you fallback to config-generator when existing_cc_config doesn't exist, but maybe I'm misunderstanding the intent (because of the diff confusion?).\n. >  If it does not exist when you run init, #create_codeclimate_yaml will write it, and again it will exist before #create_default_engine_configs is called.\nSorry, yeah, I didn't get that originally. Makes sense.\n. Feel free to argue for its existence though, if you find in the course of doing so that it makes sense to keep it. The decision to deprecate was made a long time ago and possibly in haste.\n. The editor version of \"I did a mv when I meant cp\". Fixed.\n. You're right. I was originally going to argue against adding the complexity of a timeout here for a number of reasons, then I realized I can just pass the :timeout option to Child.new which is super easy. I'll do that.\n. I have no idea why this would be here. I'm running the suite locally now without it and will commit its removal if it's green, or (hopefully) explain why it's here.\n. I think you meant [ -n \"...\" ] (the test you have is a bashism only supported by [[). Also, do we think it's reasonable to go by this check alone and remove the command check?\n. typo: analyzable\nI think we should decide if this exception is primarily for us or end-users. If it's for us, I'd argue for a more generic construct, something like CC::Spawn that takes a command (as Array) and returns out or raises a more implementation-specific error:  raise ProcessError, \"command <x, y, z> exited with status <a> and stderr <b>\". If it's more for the end-users, then I think we shouldn't leak the abstraction so much: raise ConfigGeneratorError, \"Failed to find analyzable files.\\n(additional details for us like command run, exit status, etc)\"\nWDYT?\n. I think POSIX::Spawn::Child (a pattern we use more frequently) wraps this up\n``` rb\nchild = POSIX::Spawn::Child.new(*find_cmd)\nif child.success?\n  # use child.out\nelse\n  # use child.err and child.status\nend\n``\n. Will this auto-enable both new and old if.rbfiles are found?\n. With this auto-enable both new and old if a classic config specifiedRuby?\n. I like it. Will update throughout.\n. If not being run via docker, we can't use the container-side paths of/codeand/tmp/cc`, we have to set them as whatever the host side is. I couldn't find any way to do that without:\n- Having two new environment variables for the container side (with defaults) making 4 total\n- Having a single environment variable to represent the single conditional (as I've done)\nI may be missing something; if you have something in mind, please describe it a little more concretely.\n. My bad, I thought I saw space between nearby ones. I was seeing things.\n. I can add the period, are you also saying I need to make this a grammatically correct sentence? \"ShellCheck is a...\"\n. I matched builder's assuming that one was sorted; guess not. Will fix here at least.\n. There are other calls to Analyzer.logger.{warn,info} reachable by the CLI, so this shim is necessary. The interface mismatch is worth thinking about though.\n. I approve of this fixture scheme\n. :clap: I've always wanted this.\n. I think this is telling you these objects should live under the Analyzer namespace. Is there a reason you went with CLI?\n. Does this need to be public?\n. You may or may not enjoy this kind of conciseness, but I thought it was a neat trick nonetheless (to get rid of the contents temp):\nrb\nirb(main):001:0> file = \"foo\\nbar\\nbaz\\n\"\nirb(main):011:0> file.each_line.with_object(\"memo\").with_index do |(l, m), ln|\nirb(main):012:1* p l, m, ln\nirb(main):013:1> end\n\"foo\\n\"\n\"memo\"\n0\n\"bar\\n\"\n\"memo\"\n1\n\"baz\\n\"\n\"memo\"\n2\n=> \"memo\"\n. Should this be ensured? Maybe behind a block-based with_env helper?\n. Yeah but if, for example issue.fingerprint raises, it won't be called. RSpec will hold the exception as a failure and run other specs with a sullied ENV.\n. I know I've written this somewhere:\nrb\nwith_env(k, v)\n  old_v = ENV[k]\n  ENV[k] = v\n  yield\nensure\n  ENV[k] = old_v\nend\nYou could also just stub ENV#[] I suppose.\n. I'm still not clear on the concern here, can you give an example of two issues' source that would collide because of containing |?\n. I consider it an anti-pattern to make methods public only for testing. Not a big deal though.\n. FWIW: I've started to come around to:\nrb\noffset +=\n  if line == index\n    column\n  else\n    source_line.length\n  end\nWhich appeases rubocop without misaligning the if/else/end depending on the size of the LHS of the assignment.\n. The nested hash access seems ripe for nil-errors. Are you confident these keys will be here? Would Hash#fetch be too syntactically noisy?\n. I thought I converted this test suite to RSpec? I think we typically inject our helper modules into all specs via RSpec.configure immediately after the module definition, and only do this sort of thing when we're forced to by minitest.\n. Is this still relevant?\n. Does this mean you're going to replace the errors we saw in production with engine validation errors?\nIf so, would it be better to cast?\n. If you're stubbing read, why did you have to create the fixture file?\n. Did you actually see cases of { fingerprint: nil } or { fingerprint: false }?\n. Ah sorry. How about parsed_output.fetch(\"fingerprint\") { default_fingerprint } then? The block is only evaluated on missing keys with this form.\n. I see. If you're confident that this change won't cause a bunch of unexpected validation errors, then I'm totally good with the strict approach. My concern was that we had a lot of engines reporting string locations and the system has just been OK with it to this point.\n. | grep -q \"Docker version 1.11\" is functionally equivalent to this awk script right?\n. I think there are some subtle bugs in the docker-machine case since this invocation of socket_path will run on the local system, not the docker-machine VM, so it won't find either socket.\nWhat do you think about restructuring your change like this:\n``` sh\nFix our bug, stop hardcoding a literal ;)\nsocket_path=/var/run/docker.sock\nModify it for your case\n\nNote: the predicate has to be smarter than just \"modern_docker_version\". For example,\nI run 1.11 on Linux and the socket is in the default location\nif docker_for_mac\n  socket_path=/var/tmp/docker.sock\nfi\nNow, the rest of the script is exactly as it was on master, except that anywhere\nwe've hardcoded the socket path, use $socket_path.\n``\n. This approach still won't work for docker-machine (or boot2docker). The invocation at L47 will evaluate on the local machine andexit 1(which should bereturn 1anyway) since the socket is in the VM. This'll trip over intosocket_missing` when it shouldn't.\nThe invocations of socket_exists at L53 and L60 would also fail for similar reasons, but I don't think it'd get that far.\nSomething like this should work:\n``` sh\nsocket_path=/var/run/docker.sock\nif [ -S /var/tmp/docker.sock ]; then\n  socket_path=/var/tmp/docker.sock\nfi\n```\nLeaving the rest of the script completely as-is, except for replacing the hardcoded socket with $socket_path.\nThis is very intentional in not moving things out into named functions like socket_path or socket_exists because that'd change the semantics: currently, we're giving arguments to the ssh commands, your changes make them actual local invocations to produce arguments for the ssh commands -- which won't work.\nEDIT: technically your changes are just passing a string literal of \"socket_exists\" to the ssh commands, which won't work at all.\n. \ud83d\udc84 quotes: \"$socket_path\":/var/run/docker.sock\n. Also, sorry for the back and forth; we really appreciate you taking the time to work on this. Please let me know if you'd rather I commit what I'm thinking to this branch (or another) for your review instead.\n. Ah good note.\nWhat about this:\n1. If the current version is symlinking to /var/run/docker.sock we should just use that and not bother with an alternate $socket_path\n2. If the documententation directs users to unset $DOCKER_, we should rely on that and not worry about short-circuiting before checking for docker-machine\n3. This only leaves the potential for a user having boot2docker on $PATH, but actually intending to use Docker Machine -- I think it's OK not to handle this edge-case since boot2docker is deprecated\nIf those three things are true / appropriate -- do we need any changes at all?\n. > At least one of them is false in my opinion. My view is that the socket path should be changed.\nMakes sense. It also wouldn't work because we'd have to mount in both the symlink and the source for it to resolve.\nSeparately, I've gotten the green-light to remove the boot2docker code entirely -- which I'll now do.\nAre we in agreement then that the few lines I've been pasting is the answer? Just adjust $socket_path up top and leave the rest of the script alone?\n. That makes it sound more mandatory, which I didn't feel was necessary -- but would be fine with me, if you do.\n. Should I put this in the parenthetical list with version and ps? Otherwise, I think i'd have to re-word more of the paragraph to include that and have it still flow nicely.\n. @brynary had a good suggestion to use Pathname for this, just to avoid messing up any of the fiddly bits in dealing with path names. I thought there was a relative_to?-like method on it already, but it doesn't look like it. There might be a way to use #relative_path_from though?\n. This seems a little out of scope for this object.\n. Where did we land on dependent validations? Assuming this validation runs after the existence-validation, and we're OK with relying on order-dependence, I'd say we do nothing here.\n. I'm interested in having an in-chat conversation about how we have decided / are deciding to \"address symlinks\". I think there's some nuance there and I know we've fought this battle before.\n. No one reads my commit messages ;)\n. This logic could've been done as just a private method here, but I thought the adapter class was nice because it hints that, design-wise, this is the interface Registry should have, but I've elected not to go down that route because the current CLI/Builder split of responsibilities makes that difficult and investing the time into addressing the difficulty doesn't make sense when we hope to move to something entirely different (the sub-command approach) eventually.\n. I don't see any wins either way. If you prefer dropping the temp, that's fine with me. The name comes in handy in the comment that describes the assumptions so I'd have to reword that too.\n. I commented when I added this: it was motivated by the work here, but is its own thing, so I figured same PR separate commit was appropriate. It seems to be (somehow) triggering these JUnit reporter errors though so I'm going to pull it out. Baffling.\n. Thoughts on File.file? which is \"exists and is not a directory\". The exceptions that prompted some other directory-related work were from such a case (but didn't fix it because of this unknown order situation).\n. I do try and avoid it because I think it looks a bit off. In this case, I'd be open to constants.sort.map(&method(:const_get)).select do |klass|. Just an idea, I'd also be find disabling the rule if that's how everyone feels.\n. I think it'd be worth doing a quick query (on the secondary of course) for issues with content: nil. I know the extension always checks for presence before displaying it, so I thought it was valid to omit. I'm fairly sure not everything has ReadUp content and I'd hate to start throwing validation errors.\n. Ohhh. OK, you can ignore me then, or go ahead with investigation. Up to you.\n. Protip: Add an _id: { $gt: BSON::ObjectId.from_time(something_reasonable) }. We don't need to check if there's ever been such issues, but knowing if any have been emitted recently is valuable.\n. :+1:\n. I think --dev is under-explained here. I would either explain it more (i.e. \"lets you run engines not known to the CLI, for example if you're an engine author developing your own, unreleased image\"), or not mention it at all.\n. I would call this section something else (maybe Environment Variables?). Only CODECLIMATE_DEBUG has to do with debugging, the other two don't.\n. It makes me sad these aren't CODECLIMATE_ prefixed. Nothing to address now obviously, but just flagging it as a bit of debt.\n. WDYT about disabling this check. All three cases where you listened to it feel worse to me.\n. \ud83d\udc84 the continuation lines should be indented two spaces below the docker run, like they were.\n. \ud83d\udc84 I missed this because it was tucked up here. Can you put it on the next line?\n. I agree. Looking forward to when Builder just invokes codeclimate as a (containerized) process, the exit status will be part of the interface, and a specific status for issues found makes sense.\n. Are you saying an error is 2 and reserving issues found as 1?\nLooking at http://tldp.org/LDP/abs/html/exitcodes.html#EXITCODESREF\n\n1 Catchall for general errors\n2 Misuse of shell builtins (according to Bash documentation)\nAccording to the above table, exit codes 1 - 2, 126 - 165, and 255 [1] have special meanings, and should therefore be avoided for user-specified exit parameters\n\nI think it's fine to use 1 for general errors. For issues-found, it looks like 3-125 or 166-255 is available; I'd prefer going above 165, myself.\n. I'm :+1: on this cleanup. Are there builder-side changes to conform to the new Formatter interface?\n. I like it, but I'm not sure how much mileage we'd get out of that idea since most of the individual error codes can be determined externally. A non-zero exit from analyze and validate-config are probably the only two cases that could use differentiation.\n. I guess what I'm saying is, aside from analyze and validate config, there really is no other cases where the CLI would be involved:\n- G* these are a clone in a totally different container\n- E* these are just error vs timeout which builder knows (error is non-zero exit, timeout is no exit at at all, same for output exceeded, etc)\nNot super important now; 170 for issues-found is fine with me regardless of future planning.\n. Instead of doing this, WDYT of defining:\nrb\ndef other_locations\n  @other_locations ||= {}\nend\nAnd using the reader at L34?. :lipstick: I realize this was existing, but can you drop the outer parens so all invocations of #say are consistent here?. I think it's mixing responsibilities to have this class in charge of argument parsing. I would prefer this class just check the version and have the caller (Runner) invoke it or not based on the arguments (it's already got that responsibility).\n```rb\nclass Runner\n  def run\n    VersionChecker.run if check_version?\n``. WDYT about putting (only) a barerescue => exin#check. IMO any failure in this class at all should be logged at DEBUG and ignored.. Instead of doing this, setting#open_timeoutand#read_timeouton the HTTP client should be functionally equivalent and more robust, right?. This can also be removed if we put go with a \"rescue everything in#check\" approach.. Might not be worth it, but WDYT of DRYing this with https://github.com/codeclimate/codeclimate/blob/master/lib/cc/cli/version.rb somehow? I'm slightly concerned if we re-org this repo, we'll have to be careful to update multiple path references.. :lipstick: we don't useRSpec.in this codebase..Ctrl-Cand similar wouldn't be handled byrescue => exbecause they don't descend fromStandardError`, specifically for that reason.\nBecause there is a UX constraint that this object should be best-effort and can never cause the CLI itself to error, I believe you will need a rescue => ex in #check. If it makes you feel better to still rescue the parse error or http error internally, that's fine with me; I would just find it to be unnecessary clutter at that point.\n(Sorry I didn't clarify the UX constraint in my original comment, I only just now realized that our hands are a bit tied in that way.). Just curious, is there a reason for the array inclusion instead of if ARGV.first == \"--check-version\"?. :lipstick: use implicit begin. Since you're memoizing this as the parsed api_response already, I don't think you need to memoize here. I'd prefer you didn't, to cut down on some syntactic noise.. Is uuid a required param (or will it be soon)? If not, I'd suggest you remove that from this PR. We're probably going to have to do something different (which we can discuss in #587) so I think it'd be a cleaner eventual diff if this wasn't already present.. Oh I see. Sorry I misread that, maybe that's an indication that the methods could be broken up a bit differently and be easier to follow? I'm not sure, but FWIW I might've written this this way:\n```rb\nNot in love with the names, just trying to show division of responsibility...\ndef remote_version_info\n  # only memoize one thing, the final result\n  @remote_version_info ||= get_remote_version_info\nend\ndef get_remote_version_info\n  # response parsing, not memoized\n  response = http_response\nif response.is_a?(...)\n    JSON.parse(response.body)\n  else\n    raise ...\n  end\nrescue JSON::ParserError\n  { ... }\nend\ndef http_response\n  # Net::HTTP stuff, not memoized\nend\n```\nThis is really similar to what you have now, it just avoids memoizing multiple intermediate results which can be confusing and hide bugs (in my opinion and experience). This also would address two explicit begins, which I do consider smells.. Sorry I missed that, my comment here applies here too. If you decide not to go that way then this comment can be ignored.. We shouldn't make up CC_ versions of the XDG variables. We should use them directly and default them if missing.\nsh\n: \"${XDG_CONFIG_HOME:=$HOME/.config}\"\n: \"${XDG_CACHE_HOME:=$HOME/.cache}\". These variables aren't themselves related to XDG: it's our config file, it could live anywhere, we're just nice enough to follow XDG in our default paths. Also, why not let the users set alternate values if they want?\nsh\n: \"${CC_CONFIG:=$XDG_CONFIG_HOME/codeclimate/config.yml}\"\n: \"${CC_CACHE:=$XDG_CACHE_HOME/codeclimate/cache.yml}\". These actions are idempotent (if you replace echo with touch), so I would just always do it. You can also DRY it up with below via a loop:\nsh\nfor file in \"$CC_CONFIG\" \"$CC_CACHE\"; do\n  mkdir -p \"$(dirname \"$file\")\"\n  touch \"$file\"\ndone. Was this intentional? It drastically changes the process tree semantics, signal handling, etc.. :lipstick: we don't use ${ } unless it's needed (it's not needed here).. My personal preference would be not to worry about XDG within the container. We're respecting it in the wrapper for the user (and huge :+1: to that!), but inside the container I'd be inclined to just look for something like a hard-coded /config.yml and /cache.yml for simplicity. WDYT?. We still want this, to support --no-check-version. We're just going to flip the default to --check-version now that the cache is in place.. This class (and some of the others) seem to be mixing two very distinct concerns:\n\nWhere is the file (XDG, etc)?\nHow do I read/write a YAML file (which I'm surprised we have to deal with so directly)\n\nI had recommended in another comment not worrying about XDG or namespaces inside the container. We can just look for /config.yml and /cache.yml, defined as hard-coded constants (similar to how we handle /code). If you did that, I think a ton of this code goes away.. Allowing the override does introduce an error case if users set a relative path. Something to consider.. > Is there any particular reason why we want docker to become the main process?\nWe don't necessarily rely on it now, but it's less surprising and error-prone IMO if the docker process sees any signals directly.\nClearly that was preventing intentional intercept logic you had at one time, so the change would've been OK if we needed that, but given no other trade-offs I'd keep the direct signal handling via exec as the default behavior still.. We shouldn't do this. If the files don't exist we should not attempt any version checking; and I wouldn't even have the code to do it, since it's a risk to write root-owned data.. What's the portability of realpath? We claim the wrapper should work on any POSIX system.. Should this be ||=?. :lipstick: Please drop the RSpec. part. > Docker mounts relative paths just fine.\nAh, that's news to me, but cool.. I see; that's pretty confusing, but we don't have to hold up the PR further about it.. Can you rename @location to @other_locations? This would differentiate it from the local location variable, and indicate it's a Hash of many location values, not just one.. Sorry, on second thought maybe other_location_validities would be better? I didn't realize this was caching the resulting boolean, not the locations themselves.. Anything is possible!\nCan you explain why you'd prefer that?. Yeah, in this case I only need to know that it's valid as YAML to work with it in the way I need to, all the cc-yaml validation machinery will still happen downstream (as desired).\nAs this feature grows, we may start to move some functionality around between here and cc-yaml, but I'm deferring on that for now.. Yup, that's intentional for now, but we can revisit later.. This'll only execute if codeclimate prepare:quality is run. We'll run it (guarded by rollout) on hosted.. Seems reasonable.. Actually, going to not do that for now. From the outside, the method is meant to take and return something. The fact this it uses mutation is kind of a quirk of the current set of changes we need to make right now. We can swing one way or the other in the future, but I'll keep the name more aligned with how it's used (non-mutating).. There are a number of answers about what to do in this languages list. I'm just deferring entirely for now because it's a 2 second change to do something different later.. Is this meant to be \"Upgrade instructions...\" ?. A different exception is thrown by the Registry itself, and it has the context there so there's no need to catch and re-raise.. I can't decide if each object should own how to get itself from YAML, or if these should be reduced to value objects with the YAML \"parsing\" left to Config::YAML.. My current approach is to write all of this consuming code with the assumption that the config has been validated. We'll maintain codeclimate validate-config (and run that on as a step on hosted still); it will go through cc-yaml for now, but be encapsulated in a class that we can rewrite later (see #638). This may be best reviewed by just viewing it in the To state.. Nice catch. I'd like to do a few things to solve this (only one of which will be in this PR):\n\nMerge https://github.com/codeclimate/codeclimate/pull/638 first\n\nThis'll ensure validate-config would catch this with a nice user-facing error.\n\nDon't bring prepare back into Builder without validate-config\n\nThis'll ensure we don't get to this step without having validated already.\n\n\nDuplicate that check here, for layered security, just with a less user-friendly outcome because we don't need to be super graceful in an unexpected case where validate-config was not run.. Updated. I could see us ending up there. Another option is to make it so you can only get a config through a validator (even though what you get is just a nested Hash). In any event, I'm not boxing us into any corners and am open to ideas as this matures.. This doesn't make sense to me. Config::X is basically a source of configuration:\n\n\nDefault is our standard no-config default values\n\nYAML::* come from .codeclimate.yml\nJSON::* would come from the new .codeclimate.json\n\nIn no case would one source reference the either, they'd all be loaded individually and possibly merged by the caller.\nIn the case of the default configuration, there would be no checks key, since the default configuration would run the engine with, well, it's own default configuration.. Any Config::* source object must have the same interface -- otherwise they can't be merged and used uniformly. So this will have to have all the same public methods as Config::Default and Config::YAML, but loaded from the JSON file.. I like that idea, Prepare#merge. I also wonder if Engine#merge would be better than the Engines class you have here. Merging the engines would be a concatenation and calling left.merge(right) for any collisions.. This is an interesting situation, subclassing your namespace parent. It feels wrong, though I have no concrete reason against it.\nAs an alternative, what do you think of something like this:\n```rb\nmodule CC\n  module Config\n    class Data\n      # your struct-like object\n    end\nclass Default < SimpleDelegator # or YAML, or JSON\n  def initialize\n    super(Data.new(...))\n  end\nend\n\nend\nend\n```. Discussed a change to this IRL :). Is this used?. I think this would be more readable like:\nrb\nif File.exists?(JSON::DEFAULT_PATH)\n  config.merge(JSON.new)\nelsif File.exists?(YAML::DEFAULT_PATH)\n  config.merge(YAML.new)\nend. Whoops. FWIW my own style is to use simple echo for simple strings (as all these are), and only go to the clunkier printf when needed (for escapes, variables, etc).. Quotes are not needed for the left-hand side of an assignment, and we typically omit them.\nsh\nbranch_head=$(git rev-parse --short \"$branch\"). These quotes aren't needed. The extra whitespace here was intentional. I found I missed this message if it wasn't set off from all the other logging. To address the shellcheck issue but keep the formatting, you could move to this:\n```sh\ncat <<EOM\nBe sure to...\nhttps://...\nEOM\n```. ",
    "stefanpenner": "\nOK good. Then setting those env vars may fix @stefanpenner 's issue.\n\nCan confirm this works.\nIt seems like maybe providing a small wrapper that provides good errors might aid users? Otherwise, maybe the readme just need to contain this TL;DR for us OSX users.\n. ",
    "michaelmior": "I get no errors from running docker info.\n. $ sudo docker version\nClient version: 1.5.0\nClient API version: 1.17\nGo version (client): go1.4.1\nGit commit (client): a8a31ef\nOS/Arch (client): linux/amd64\nServer version: 1.5.0\nServer API version: 1.17\nGo version (server): go1.4.1\nGit commit (server): a8a31ef\n. Isn't the codeclimate/codeclimate image itself pulled from Docker Hub? That worked fine. I can also manually pull in the codeclimate/codeclimate-rubocop image. But I get the same error.\n. Updating Docker did indeed fix this. Thanks! I'll leave you to close the issue in case you want to keep open to track the problem.\n. ",
    "mshappe": "For what it's worth, Ubuntu 15.04's current docker.io package is 1.17. I had to uninstall it and install from Docker's official script.\n. ",
    "benjamin-thomas": "Ran into the same issue.\nRunning Ubuntu LTS myself and the docker server API version is 1.13 after updating.\nCould you distribute the codeclimate image versioned against the docker client?\nFor instance one would do\ndocker pull codeclimate/codeclimate:1.13\nor something similar?\n. Thanks for the feedback\nThe container starts but seems to depend on docker 1.2 features (https://blog.docker.com/tag/docker-1-2/ introduces cap-drop)\nHere is the console's output:\nStarting analysis\nRunning rubocop: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 2 and stderr \"flag provided but not defined: --cap-drop\\n\\nUsage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]\\n\\nRun a command in a new container\\n\\n  -a, --attach=[]            Attach to stdin, stdout or stderr.\\n  -c, --cpu-shares=0         CPU shares (relative weight)\\n  --cidfile=\\\"\\\"               Write the container ID to the file\\n  --cpuset=\\\"\\\"                CPUs in which to allow execution (0-3, 0,1)\\n  -d, --detach=false         Detached mode: Run container in the background, print new container id\\n  --dns=[]                   Set custom dns servers\\n  --dns-search=[]            Set custom dns search domains\\n  -e, --env=[]               Set environment variables\\n  --entrypoint=\\\"\\\"            Overwrite the default entrypoint of the image\\n  --env-file=[]              Read in a line delimited file of ENV variables\\n  --expose=[]                Expose a port from the container without publishing it to your host\\n  -h, --hostname=\\\"\\\"          Container host name\\n  -i, --interactive=false    Keep stdin open even if not attached\\n  --link=[]                  Add link to another container (name:alias)\\n  --lxc-conf=[]              (lxc exec-driver only) Add custom lxc options --lxc-conf=\\\"lxc.cgroup.cpuset.cpus = 0,1\\\"\\n  -m, --memory=\\\"\\\"            Memory limit (format: <number><optional unit>, where unit = b, k, m or g)\\n  --name=\\\"\\\"                  Assign a name to the container\\n  --net=\\\"bridge\\\"             Set the Network mode for the container\\n                               'bridge': creates a new network stack for the container on the docker bridge\\n                               'none': no networking for this container\\n                               'container:<name|id>': reuses another container network stack\\n                               'host': use the host network stack inside the container.  Note: the host mode gives the container full access to local system services such as D-bus and is therefore considered insecure.\\n  -P, --publish-all=false    Publish all exposed ports to the host interfaces\\n  -p, --publish=[]           Publish a container's port to the host\\n                               format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort\\n                               (use 'docker port' to see the actual mapping)\\n  --privileged=false         Give extended privileges to this container\\n  --rm=false                 Automatically remove the container when it exits (incompatible with -d)\\n  --sig-proxy=true           Proxify received signals to the process (even in non-tty mode). SIGCHLD is not proxied.\\n  -t, --tty=false            Allocate a pseudo-tty\\n  -u, --user=\\\"\\\"              Username or UID\\n  -v, --volume=[]            Bind mount a volume (e.g., from the host: -v /host:/container, from docker: -v /container)\\n  --volumes-from=[]          Mount volumes from the specified container(s)\\n  -w, --workdir=\\\"\\\"           Working directory inside the container\\n\"\n. I thought so! Thanks :)\nLe mer. 8 juil. 2015 \u00e0 22:49, pat brisbin notifications@github.com a\n\u00e9crit :\n\nAh, that's too bad. I think for now the suggested fix will have to be to\nupdate your Docker. Sorry!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/4#issuecomment-119727234\n.\n. \n",
    "wfleming": "We no longer require a .codeclimate.yml to be present at all to run codeclimate analyze, so this doesn't seem needed anymore. https://github.com/codeclimate/codeclimate/releases/tag/v0.70.0. @cilindrox while we are not yet able to support custom-installed ESLint plugins, we do have several plugins baked into our eslint engine, and babel-eslint is one of them, so it is supported. You can add \"parser\": \"babel-eslint\" to your .eslintrc.* Our docs page has more info on which plugins are currently supported.\n. @cilindrox Ah, sorry: this issue was filed for the babel-eslint plugin so I mistakenly presumed that's what you wanted to use, sorry. Supporting arbitrary plugins is something we'd love to do, but we're not there yet. Stay tuned, though. Sorry it's not possible today.\n. Improving the CLI help and doing per-command detailed help is definitely something we need to do as we start to build out more features like this (though it means we'll need a new interview pairing problem :wink:).\nI do think that functionality should be in the CLI, but since it's a wider-reaching thing that will impact all commands, I also think we can do it separately.\n. :+1: \n. I vote we ship this and work on updating builder via https://trello.com/c/IVH8HtKh/993-builder-codeclimate-rubygem-conflicts-with-docker-binary\n. LGTM. I agree with @mxie that some of it feels like it could be a bit cleaner, so if you agree I'd ask you to take a couple minutes to think about if it could be improved, but I don't consider it blocking.\n. @pbrisbin I'll alter the tests for it, but since I can't foresee that merging at all cleanly with #137, I'm going to wait until that's done & then I'll rebase this & update it. Make sense?\n. @pbrisbin spec added.\n. @fhwang Yep, I'm in progress on that now.\n. Ok, this is feeling better. Another look @fhwang @codeclimate/review ?\n. This looks good. I think you can remove the lines in the formatters made redundant by this change.\nThere may be some higher-level specs here that might be good to add to as well, if convenient.\n. Looks ok to me. Might want to build as a docker image locally and use the CLI to run analysis a couple times if you haven't already.\n. :ship: \n. It's nice to see the existing tests pass with this, but Engines should probably get a unit spec for itself?\n. :+1: \n. Can we please do the rubocop config separately? Changing/enforcing our style guide should be separated from functional changes. And the PRs are a heck of a lot easier to review when they're separate. The functional one is naturally smaller, and the rubocop-style one almost doesn't need human review by definition if everything's green.\n. LGTM\n. Quick suggestion for refactoring that long method:\n```\ndef line_begins\n  @line_begins ||= [ [ 0, 0 ] ].tap |line_begins|\n    index = 1\n    @source.each_char do |char|\n      line_begins.unshift [ line_begins.length, index ] if char == \"\\n\"\n  index += 1\nend\n\nend\nend\n```\nI think that will get you under the limit.\nI'd also be up for boosting that limit a bit. 10 is quite restrictive.\n. :+1: \n. :+1: \n. LGTM.\nUnrelated nit: I notice we're inconsistent about whether descriptions get periods at the end or not. I'm making a note to do that in a separate PR.\n. :+1: \n. > If that's the case, it seems to me that the additional languages check doesn't add much value here, and might cause harm in exceptional cases (e.g. rails repos that get added with javascript as default language bc of settings in Github).\nThese exceptional cases are actually why I think we should add upgrade_languages. The logic in UpgradeConfigGenerator is what it is because if you did have a classic configuration, and it has (for example), *.rb files in it, and you explicitly did not have Ruby in your yaml, then we should not auto-enable any Ruby engines. So without upgrade languages here, we would end up enabling brakeman on a repo that had a script/rails file but had been explicitly configured to not have Ruby analysis on classic, which would not be correct.\nLanguages used during upgrade aren't directly connected to GitHub repo language recognition, by the way: they come directly from the user's checked-in .codeclimate.yml when it's configured for classic.\n. :+1: \n. :+1: \n. Seems like a great quick win. Good find!\n. Having --force behavior apply specifically to one file this command touches but not other is surprising behavior, I think, from an end user perspective. I'm also wondering what use case drives this, but if it's needed I think it should behave the way --force does on pretty much every other UNIX utility and force everything. As Francis said, deleting the .codeclimate.yml is easy if that's the only file you want overwritten. \n\nOn Nov 17, 2015, at 08:30, Francis Hwang notifications@github.com wrote:\nThere's probably some context I'm missing: What's the use-case here? Why not just tell users to edit .codeclimate.yml directly or delete it?\n\u2014\nReply to this email directly or view it on GitHub.\n. That card is really old. My guess is that the use-case @brynary had in mind for this was what we ended up addressing with --upgrade, and that this card should be dropped. Bryan, can you chime in if you had other cases in mind?\n. @codeclimate/review can i get another quick review on this?\n. I can't find any solid references in Brakeman docs about what they process, and the source doesn't lend itself to an easy check either (the closest I got was reading through https://github.com/presidentbeef/brakeman/tree/master/lib/brakeman/processors). The list now added is the best reflection of brakeman's support I can determine, so I'm comfortable shipping it for now.\n\n@ABaldwinHunter I removed config.ru since I can't actually find any mention of the file or the extension in the brakeman source. Can you point me at something indicating it is processed if you want it added back?\n. @pbrisbin Gordon just reverted to the sleep usage since it appeared to be more reliable, if slower. The join was causing problems for us. At this point the only changes here are really cleanup & a spec, which I'm fine with. I do think we need to look more closely at the threading behavior still, but the current state of the PR should be behavior neutral as far as that goes.\n. Hi @andyw8,\nThanks for noticing this. You're correct that the internal implementation changed in a couple ways: the new console invocation would be something like:\nAnalyze.new(['-e', 'my-engine', '--dev']).run\nNote that you no longer need to provide the entire image name: your docker image should still be codeclimate/codeclimate-my-engine, but the CLI invocation just uses my-engine. Let me know if you continue to run into trouble with that.\nI'll look into updating that blog post as well.\n. @pbrisbin updated with the thread joining we discussed.\n. Hi @robtarr, sorry for the issue. Is the repo you're seeing on this open source that you can share or something private? If it's something private, can you tell us a bit about how big this repository is in terms of total directories & files?\nWe've seen some cases with repos with large numbers of directories & files where the analyze command can take an excessive amount of time to get started (up to several minutes) and appear hung. It's a performance issue we're looking into. So I'd like to figure out if that's what you're running into or if this is something else.\n. Sorry for the delayed response, guys. This does seem related to a known issue with how we process exclude paths, though the degree to which the performance is unacceptable is far more extreme for you than we'd previously seen.\nWe're looking into a fix soon, but in the meantime you might want to comment out those exclude_paths, as a workaround. The trade-off is that the CLI will then report issues for those files of course, which may be annoying until we get this fixed.\n. Hi all,\nSorry for the delay on this. We have a PR open now (#308) that we believe will fix these problems. We're hoping to release that fix soon, but until we do we'd encourage anybody having this problem to take a look at that PR & try using a local build of that branch to see if it solves this for you.\nIf you'd like to try out that branch, these would be the steps:\nshell\n$ git clone https://github.com/codeclimate/codeclimate.git\n$ cd codeclimate\n$ git checkout will-pb/serenity-now\n$ make\nThe make task will build a docker image of the CLI, which will then get used whenever you run codeclimate locally.\nIf you're still finding that this version hangs for a very long time before it starts running any engines when you run codeclimate analyze, please let us know.\n. @prrrnd Thanks for the report. I don't suppose that app is public by any chance?\nIf not, other details that could help us:\n1. Can you share the stack trace/any output you see if you you kill the command while it's hanging?\n2. Are there are any large vendor-oriented directories under your local project directory (e.g. .bundle, node_modules, etc.)?\n3. Do you have any symlinked directories under your repo directory that might lead to loops, that you know about?\n4. Can you share the contents of your .codeclimate.yml?\nThanks.\n. @prrrnd That stack trace indicates that you're still running the latest release build: several of the methods on the stack there don't exist in the branch that we think fixes this issue.\nIf you pull that branch again, I added a small change to the recorded version to make it a bit easier to confirm you're running the branch for the bugfix. Can you pull that branch & run make again please? Check the output of the make to see if it looks like anything went wrong. (If it's failing to install dependencies via apt or bundle, you may need to stop and start your docker-machine: there's a bug we've seen with docker-machine where sometimes the VM seems to lose net connectivity to its host machine.)\nWhen the branch is built successfully, running codeclimate --version should echo 0.18.0-alpha.workspace.\n. v0.18.0 has been shipped, so our fix for this is now fully released. I'm going to close this issue, but if anybody here continues to experience this on the new release, please feel free to re-open with details.\n. @pbrisbin I played with that, but it doesn't seem to support any of the ways you would think would work for that behavior.\n. Thanks @pbrisbin @GordonDiggs, ready for re-review.\n. Awesome. Nice spelunking. :+1: \n. Hi @envygeeks & @nielsm \nSorry for the delay on this. We have a PR open now (#308) that substantially refactored how we construct the workspace (the paths that analysis operates on). For the reproducible cases we had where exclude paths where not working correctly, the work on that branch has fixed the behavior.\nWe're hoping to release that fix soon, but until we do we'd encourage anybody having this problem to take a look at that PR & try using a local build of that branch to see if it solves this problem for you.\nIf you'd like to try out that branch, these would be the steps:\nshell\n$ git clone https://github.com/codeclimate/codeclimate.git\n$ cd codeclimate\n$ git checkout will-pb/serenity-now\n$ make\nThe make task will build a docker image of the CLI, which will then get used whenever you run codeclimate locally.\nIf you're still seeing results for paths that should have been excluded with that build, please let us know.\n. v0.18.0 has been shipped, so our fix for this is now fully released. I'm going to close this issue, but if anybody here continues to experience this on the new release, please feel free to re-open with details.\n. :+1: \n. Thanks @gordondiggs. I'm happy to have this go out as-is if it's urgent, but I wasn't really considering this quite ready to ship: my plan was to shift things so that the adapted output was emitted from the the engine class here in the CLI, and and then remove all of this code from builder so that it was only happening in one place.\nThe biggest piece of this that is still kind of in flux is actually error handling: right now adapter will raise for issue validation problems. If we need to ship this ASAP, the output filter should probably catch those & return false to avoid changing error handling behavior elsewhere. \n\nOn Dec 11, 2015, at 11:08, Gordon Diggs notifications@github.com wrote:\nAll @wfleming's work here, but I tested it and it is working. The issue previously was that the the fingerprint defaulting happened after the output filtering. This ports a bunch of stuff over from builder to do the issue validation here. A future PR will remove this all from builder.\n@codeclimate/review\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/codeclimate/codeclimate/pull/266\nCommit Summary\nadd make image task\nport issue validations\nsource buffer: add method used by ported builder code\nvalidator: autoloads & such\nupdate validation stuff\nissue adapter/builder\nIssue: delegate directly to hash\nfix & spec the issue builder\nengine output filter: validate engine output\nMerge branch 'master' of github.com:codeclimate/codeclimate into will/issue-validation\nFile Changes\nM Makefile (1)\nM lib/cc/analyzer.rb (1)\nM lib/cc/analyzer/engine.rb (4)\nA lib/cc/analyzer/engine/errors.rb (18)\nM lib/cc/analyzer/engine_output_filter.rb (31)\nA lib/cc/analyzer/issue.rb (50)\nA lib/cc/analyzer/issue/adapter.rb (105)\nA lib/cc/analyzer/issue/builder.rb (80)\nA lib/cc/analyzer/issue/validations.rb (13)\nA lib/cc/analyzer/issue/validations/check_name_presence_validation.rb (17)\nA lib/cc/analyzer/issue/validations/path_presence_validation.rb (23)\nA lib/cc/analyzer/issue/validations/relative_path_validation.rb (23)\nA lib/cc/analyzer/issue/validations/type_validation.rb (23)\nA lib/cc/analyzer/issue/validations/validation.rb (25)\nA lib/cc/analyzer/issue/validator.rb (54)\nM lib/cc/analyzer/source_buffer.rb (4)\nM spec/cc/analyzer/engine_output_filter_spec.rb (63)\nM spec/cc/analyzer/engine_spec.rb (24)\nM spec/cc/analyzer/formatters/json_formatter_spec.rb (4)\nA spec/cc/analyzer/issue/adapter_spec.rb (186)\nA spec/cc/analyzer/issue/builder_spec.rb (49)\nA spec/cc/analyzer/issue/validations/check_name_presence_validation_spec.rb (16)\nA spec/cc/analyzer/issue/validations/path_presence_validation_spec.rb (16)\nA spec/cc/analyzer/issue/validations/relative_path_validation_spec.rb (17)\nA spec/cc/analyzer/issue/validations/type_validation_spec.rb (15)\nA spec/cc/analyzer/issue/validator_spec.rb (35)\nM spec/support/factory.rb (10)\nPatch Links:\nhttps://github.com/codeclimate/codeclimate/pull/266.patch\nhttps://github.com/codeclimate/codeclimate/pull/266.diff\n\u2014\nReply to this email directly or view it on GitHub.\n. Let's touch base later today if you don't finish it today. I was going to work on it this weekend.\nOn Dec 11, 2015, at 11:47, Gordon Diggs notifications@github.com wrote:\nClosed #266.\n\u2014\nReply to this email directly or view it on GitHub.\n. I'm still weirded it that we're still not validating output at any point here: unless I've missed something, it seems wrong to me that Issue validation behavior is essentially part of IOProcessor in builder. In other words, it's an implementation detail of a particular output formatter, not core behavior of how engines are run.\n\nI know I probably missed in-office discussion, so ignore me if that's not germane. If the goal was to get just this bug fixed fast, this approach seems ok. But the responsibilities of where input \"adaptation\" & validation continue to feel wrongly separated to me: fingerprint generation happens here, but validation (including location validation, which fingerprint partial depends on!) happen later.\n. That makes sense to me.\nMaybe validation should be a next, separate PR since it will impact builder with error reporting. As long as we're tracking it, I guess.\n\nOn Dec 11, 2015, at 16:44, Gordon Diggs notifications@github.com wrote:\n@wfleming the only in-office discussion was that it felt weird to pull all of SmellAdapter over because our internal database schema doesn't seem like a concern of the CLI. In that regard, I think the adaptation should still happen in builder.\nHowever, I agree on the validation - I'll move that stuff into here now.\n\u2014\nReply to this email directly or view it on GitHub.\n. Makes sense to me. Even though I know the card will languish in icebox & that makes me sad.\nOn Dec 11, 2015, at 16:50, Gordon Diggs notifications@github.com wrote:\n@wfleming that might be a good idea. As it stands now, integrating this with builder means bumping the gem and removing some code, without much other messing around. I will add a card for the validation stuff and punt on it for now, unless it gets hairy once I get over to builder land\n\u2014\nReply to this email directly or view it on GitHub.\n. Support for an app_path config directive was added to the Brakeman engine some time ago: details available on our docs page.\n\nMultiple apps within a single repo is not supported yet, but that seems a bit beyond scope for the initial request here.\nI'm going to close this. If there are related feature requests, please consider filing those on https://github.com/presidentbeef/brakeman, since Brakeman's Code Climate integration is implemented within the primary Brakeman repo.. > Remove any rules that were set to 0 as that's the default\nI recall there being discussion around this & other defaults that we were intentionally including rules set to defaults for discoverability. I.e. It's easier for a customer to realize they can turn some knobs if it's already in the file we provide than if they have to go research docs for that tool.\n. this is time sensitive, so i'm going to mercy merge to avoid rebasing again.\n. I agree with @pbrisbin that these new numbers seem too large. What's the motivating issue here? I feel like the farther we stray from the underlying tool's defaults, the more potential confusion we cause for customers.\n. 30 seems much more reasonable than 80. :)\n. I'm a :+1: on the philosophy behind the RFC and this POC. I'm being nitpicky since if we're going to rearchitect (autocorrect suggests: \"rear hotels\") the early stages are the time to discuss.\nTwo somewhat broader concerns:\n1. Is now really the appropriate time to do this? We already have other big pieces of work kind of stranded in-progress (I'm thinking of errored snapshots in particular), so I'm not sure we should open a new surgery patient before we finished sewing up a few of the current ones. This is a cool direction, but personally I don't feel like the current code is really blocking urgent work.\n2. I think there's such a thing as having the code be too separate. My comment on the Gemfile relates to this feeling. To go into that that in a bit more detail, I'm not convinced that sub commands should share 0 code (as the RFC currently talks about). I think inevitably there will be utility functions or small classes that should be shared (I currently have a branch to work on verbose logging for debugging that would fall under this category). That code could be extracted into a separate gem, or it could live at a top-level here. Maybe it's more a packaging concern than anything else. \n. Hi @envygeeks,\nThere's a difference between files that are rated and files that are analyzed: you can have files that are analyzed (they may have issues in them you care about), but that you don't want to contribute to your repo's overall grade.\nThe ratings key controls which of the analyzed files are included in the calculation of your repo's grade, but not which files are actually analyzed.\nBy default, all files in a repo are analyzed. (Or to be a bit more precise, all files that your enabled engines care about are analyzed.) Controlling the set of analyzed files is what exclude_paths is for. At the moment there's no support for anything like include_paths, sorry: we think analysis is most useful when run against most of a repo.\nThe naming of these config keys can be a bit confusing, and we should improve our docs around that. Does that clarify the purposes serve?\n. We've looked into this more, and this doesn't really make sense for our roadmap. Changing the behavior of ratings would have negative disruptive effects on existing configurations, and we do feel strongly the the tool is most valuable when more paths are included than excluded.\nI'm sorry that means your own configurations need to be more complicated, @envygeeks. There may be other changes to how we support config in the future that will improve this, but changing ratings behavior isn't something we plan to do, so I'm going to close this.\n. HI @KevinBongart,\nSorry for the lack of feedback here recently. As @ABaldwinHunter said, we've reorganized how we build the workspace for analysis in #308. We had an internal implementation of per-engine exclude_paths that we'd been holding off on because of the performance issues with the previous workspace-management, and we ended up including that work in #308, so I think we're going to move forward with that: sorry about that. If you have feedback on that PR, we'd be happy to discuss details of the implementation there.\n. I'm excited by the re-architecture & the overall improvements! All kinds of awesome.\nSimilar to @ABaldwinHunter, I am concerned about completely eliminating support for globs. I think there are enough examples you found in your own research where a path equivalent would not really work, and I can think of at least one use-case that I don't see represented, which is Go projects: if you want exclude tests (a fairly common use-case, I think), it would be something like **/*_test.go: the alternative is effectively tracking every single file in your project in your excludes. I see similar cases in some of your examples, so I think completely dropping support for globs would be too drastic, and would be dropping support for something that is seen as a pretty basic feature for scanning tools in general by a wide swath of devs.\nI think we can support globs while continuing to keep the architectural & performance gains you've made here. I've drafted a working implementation in #302 based off of this work, which adds back glob support but does not add back any of the things I considered troublesome in the old implementation.\n. Closing to re-open with the glob work & updated things.\n. :shipit: \n. Open Questions:\n- @pbrisbin removed the type check stuff for YAML's globs That may need to come back in some way?\n- Unclear if this would need to change anything in PathsValidator, but I don't think it would: any glob given for include paths on the command line should be expanded by the shell before the CLI gets them.\n. > > I think we'll still need to handle the case where a file we need to touch for interpreting an exclude can't be read, though\n\nCan you expand on this?\n\nThere could conceptually be a directory that is not readable by us, but is within the project & gets hit by an exclude path. Since this class works by descending through directories referenced by exclude/include paths, that would result in an exception. I'm suggesting we'll want a catch and a  CLI.debug() for that case.\n\nAdd/verify spec examples for our transparent handling of /**-style globs, which we intend to continue to support\n\nCan you expand on this? I think current spec coverage does cover this in that those style globs are shown being used?\nThis PR also means we would support all globs that Ruby supports, not just trailing-* globs. I tried to explain why I think that's worthwhile on #300. FWIW, in my own testing, it was not simply globbing that was performance intensive, but  the fact that we were doing far too much extraneous work on top of globbing & that our algorithms were poor. With this PR & #300, globs that can be simplified (trailing-*) are simplified & are not expanded, but globs that can't be simplified are fully expanded. The performance of this approach has been perfectly fine in my local tests, but I do want to add more strenuous benchmarks here as tests as well.\n. > This important point is that we shouldn't be passing in a raw Array in the specs, because that's not what the object would receive in the wild, and the difference is important to this behavior. We should pass CC::Yaml.parse(\"--content--\").exclude_paths. As long as we do that, and the spec cases use both styles, we'll have our answer as to what we need to do implementation-wise (maybe nothing?)\nGotcha. Agreed. I'll add it to the TODO list above.\n. > My gut is that moving to include_paths pretty much solved all permissions issues and any such logic is just vestigial or was implemented because of misunderstanding. Do you believe otherwise?\nI do, though this scenario may be limited to docker-machine/OS X users. If I create a directory that my user cannot read locally, and then mount that directory as a volume in a docker container where I am root, I get a permission error trying to ls the directory.\n. > I didn't review super closely, I think we should merge the branches, close #300 and this, and open a new PR with updated description, centralized TODO list, and start a fresh discussion.\nI'm cool with that.\n. > That sounds highly unrealistic to me, and is not an example of the sort of permissions issues i remember plaguing us in the past.\nI thought those were exactly the sort of permissions issues we'd seen in the past: files existed underneath the project directory that were not readable by the running user for some weird workflow reason.\n. @pbrisbin are you running root as your login account on your laptop or something? ;)\n. > Are you sure unreadable directory is a common case, not just file(s)?\nNo, I'm not. I don't know how common either case is, I'm just going off the memory that root-owned files/directories were a problem.\n\nCan't, and shouldn't, such a case be solved by the user excluding the directory, which under your new algorithm should actually work?\n\nYes, it should work, you're right.\nI was thinking of a case where a glob needing expanding ended up matching an unreadable directory/file, but I've now realized that can't happen, since Dir.glob handles unreadable dirs itself.So I think it would have to be a situation where a user tried to exclude something underneath an unreadable dir, which I agree probably qualifies as user error.\nSo I'm ok with not handling the unreadable thing.\n. Sure, I can take that.\n\nOn 20 Jan 2016, at 14:42 , pat brisbin notifications@github.com wrote:\nWoot!\nSince you're code here seems to be the bulk of it. Do you mind handling the merge-close-reopen dance?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/codeclimate/codeclimate/pull/302#issuecomment-173336980.\n. :+1: \n. I was going to exclude it just for fixme (since that'll work pretty soon) and hold this until that work is merged.\n\n~will out.\nOn Jan 21, 2016, 20:23 -0500, pat brisbinnotifications@github.com, wrote:\n\nWant to excludeconfig/engines.yml(or all ofconfig)?\n\u2014\nReply to this email directly orview it on GitHub(https://github.com/codeclimate/codeclimate/pull/307#issuecomment-173769781).\n. Going to merge around the CC failure: the 1 new issue is a TODO in a source file that we expect for now, but should fix.\n. Pat's description is correct, except for the following: in the docker-machine case the unreadable file will still exist, and will still be unreadable.\n. It should be noted that prior to this we explicitly excluded unreadable files in the CLI -- so if we do have any engines that silently rescue unreadable files, their observed behavior will not be changed by this work. I agree that's behavior we should change if it exists.\n. @pbrisbin the docker-machine case was part of my previous argument for why we needed to potentially handle unreadable files touched as part of the exclude/include path behavior. You were arguing (I think) that because the CLI is root in the container there shouldn't be any unreadable files, and I was providing a counter-example. Then I realized I was wrong about the needed behavior because of other details. You can safely forget everything I ever told you about docker-machine.\n. > OK, great. Both of those answers were what I was hoping/expecting. Do we have benchmark numbers on this implementation compared to current?\n\nWe do! For a known case I have on a local repo where workspace building used to take 20-30 minutes, it now takes less than 1 second. Not the most precise benchmark, I know, but I think the orders of magnitude are the important thing :wink:.\nThere's also a spec here that tries to stress-test the algorithm & keep it honest & performant in the future.\n. The big behavioral change that probably needs broad explanation is that we don't exclude the same things git does using .gitignore anymore -- that should have 0 impact on .com, but it could change local CLI results in many cases, and customers may want to add many of their .gitignore paths to their .codeclimate.yml as well.\nThe non-handling of unreadable files is the other behavioral change, and should also only impact local CLI usage. It's more of an edge case, though, so probably doesn't need to be broadcast as widely.\n. @codeclimate/review I think this is in a good place now. Git history still needs cleaning up, but the code is feeling cleaner than it was this morning, and we've corrected the behavior around applying exclude paths when explicit include paths have been given (we no longer apply the excludes in this case). Other thoughts?\n. @brynary You have a chance to think about how you'd like to handle shipping this & educating users of the behavior change?\nMy thought was, aside from putting it in the GitHub release description, posting a changelog. I could write that up today so we could release the update tomorrow along with the changelog.\n. Thanks for the feedback, @KevinBongart: if you have more details about that, could you please add them to https://github.com/codeclimate/codeclimate-rubocop/issues/39? I'd be interested to know if that's only on this branch or also the case on master (I'd be surprised if the behavior changed).\nKeep in mind we don't currently support the inherit_from directive in RuboCop config files: that's been the cause of unexpected RuboCop results in many cases.\n. cc @codeclimate/review \n@noahd1 This might be worth trying on the local case you had where init took an unreasonably long time.\n. @noahd1 Decent test case, though master wasn't that slow for me on worker.\n- master: 10.5s\n- this branch: 1.8s\n. cc @codeclimate/review \n. cc @codeclimate/review \n. Thanks @GordonDiggs & @pbrisbin: ready for another look.\n. Hi @prrrnd,\nRight now grades are only calculated on https://codeclimate.com: the CLI doesn't support them yet. Sorry about that. Our docs could definitely be clearer about that, so I'll make a note to update that.\n. GPA as an overall concept has been deprecated in our system, and we're moving towards a a clearer rating system that focuses on Maintainability & Test Coverage as overall concepts.\nWhile the new ratings are still similar to \"grades\" in that they use a conventional A-F letter grade, the calculations that affect them are significantly different. Additionally, these rating calculations on codeclimate.com respond to real-time changes made by user actions like changing the status of an issue, which isn't yet something the CLI can do.\nThis has been open a long time, and since these concepts are changing dramatically in Code Climate, I'm going to go ahead and close this for now. We can re-open or consider a different issue in the future when appropriate.. Hi @TheNotary, are you still having this problem? I see you've made quite a few changes to your .codeclimate.yml config recently. When I ran fixme against your repo locally, it was very fast, so I'm not sure if this was the result of some configuration changes or if something else might be up.\nFirst thing I would suggest is making sure you have the newest versions of the CLI and fixme: if you're on OS X a brew update && brew upgrade codeclimate should do that.\nIf after updating you're still seeing this, please let me know.\n. :eggplant: :ship: \n. > Did you mean to type **/* is what we'd append or am I missing something?\nSigh. That is what I typed, but markdown decided that meant I wanted \"*/\". Fixed above.\n. The JSON formatter is mostly a pass-through of the raw issue data generated by individual engines, intended to be used for debugging or consumption by other software. Our spec allows engines to emit either line/column information or character offsets relative to the beginning of the file, whichever is more convenient.\nIf you're seeing JSON without line numbers it's probably because the engine chose to emit offsets instead. If you're seeing JSON without any position information at all, that would be a bug I'd want to look at, and would appreciate more info about what engine was running, what JSON was emitted, and the contents of the file being analyzed if possible.\n. Ah, sorry, I misunderstood.\nWhen it comes to the actual content of the source file the issue relates to, we think that's more of a display concern than a data concern, and don't want engines to emit that source code directly into an issue for a variety of reasons. As one example, some engines report issues for things like \"module too long\", which would mean storing potentially hundreds of lines of source code in the JSON, which is excessive when the source file containing those lines will also be nearby & readable if that code needs to be shown for any reason.\nThis is pretty much what our own code does when it needs to, and if you're writing something making use of the JSON emitted by our CLI, I'd suggest the same thing: if you want to show the affected source, read it back out from the source file based on the information in the JSON.\nIf you don't mind, I'm going to go ahead & close this issue: we don't see this as a desirable part of the data schema for issues, and the JSON format is intended to be closely tied to schema, so this isn't something we're likely to change. But if you're building scripts or anything else on top of our CLI, I think you can implement what you need yourself.\n. Hi @devth,\nI wasn't aware of this tool, so thanks for bringing it to our attention. I'm not sure when we might be able to get to doing this ourselves, but we're always happy to get OSS contributions for new engines if it's something you'd be interested in doing! Our spec for engine behavior goes into more details about how engines are built & some reference implementations.\n. You can run a custom engine locally: first, you would build your local engine image with a name like codeclimate/codeclimate-markdownlint, and add it to your project's .codeclimate.yml with config something like:\nyaml\nengines:\n  markdownlint:\n    enabled: true\nWhen you run the CLI, you have to supply the --dev flag (run codeclimate analyze --dev), so that the CLI will run engines aside from our approved engines.\nRight now releasing an engine for our platform as a whole does require approval from us (those approved engines are what engines:list shows), but that's not at all necessary to get started building it & getting it working!\n. One of our team members, @jpignata, ended up making this engine recently as part of a hack week. So this engine now exists & is available for use on the CLI & http://codeclimate.com. We'll post a more detailed post on our changelog later this week, but for now, @devth, you should be able to start using this engine today. It's early days, so if you'd like to see opportunities for improvement & want to contribute, please take a look at the engine's repo. Thanks for the suggestion!\n. :+1: \n. I've tested this locally, and this is a welcome fix, so I'm in favor of merging if we can add the -n. @mikz would you mind rebasing against our current master as well when you make that change? We try to avoid merge commits when we can. Thanks!\n. Thanks, @mikz !\n. LGTM\n. @pbrisbin Good points. I don't care enough to do the necessary refactoring right now to make this a warning, so I'll just close for now.\n. @pbrisbin updated\n. @pbrisbin Good point, updated if you want to check that.\n. Worth a shot :+1: \n. @codeclimate/review there's talk of change-logging this, so I'm adding it here & to builder.\n. Can we tag it as something more descriptive than old? like rubocop-v36? Or even rubocop:v36?\n. > I'm not sure we can support a :v35 tag of the engine, but if you have a clear idea of how to go this route I'd be down for it.\nI may not be thinking of something, but I think if you just put the image as codeclimate/codeclimate-rubocop:v35 in the yml here & in builder, it'll work. That value is used directly for running & pulling engines in CLI, and running in builder. So as long as we push that tag out to GCR & Docker Hub, I think it'll be fine.\n. @jpignata Yep, that's pretty much exactly what I'm proposing.\nShould probably remove the enable_regexps, though: otherwise we'll auto-enable both the old & new engines, which won't go well. Ignore me: that's exactly what you did, I read too quickly and confused the ratings patterns for the enable regexps.\n. @jpignata Sorry, yeah, I edited my comment: I just read too hastily!\n. :sheep:  it.\n. Code looks good :+1:. That test needs updating.\n. :+1: \n. The fix for this has been released @ryancastle. Sorry about the issue. If you docker pull codeclimate/codeclimate-csslint to get the latest build, it should work.\n. Hi @marocchino,\nThe engine should be using the same config file ESLint would. If you have a .eslintrc.json checked in to the root of your project, it should get used, as long as there's no higher-precedence file present, like .eslintrc.yml, etc.\nHave you tried using the config file this way and aren't seeing it be used? If so, please provide as many details as you can: what version of the Code Climate CLI you're using, what the contents of your .eslintrc.json are, and anything else you can think of.\n. Those issues look like no-undef reports, @marocchino. I believe if you add \"jquery\": true to the env key of your config, it will stop reporting those.\nI also notice you have both no-undef and no-unused-vars set to 1 in your config. Code Climate doesn't distinguish between \"warning\" & \"error\" levels of issues in the same way that ESLint does: so with this configuration, Code Climate will report both no-undef & no-unused-vars issues.\nIf you don't want those kinds of issues reported at all, you should set them to 0. If you want to see them when running eslint directly, but not when using Code Climate, you can also exclude them from Code Climate with changes to your .codeclimate.yml\n. Thanks for this, @rafamanzo. After looking, we actually weren't even using faraday or faraday_middleware anymore: they got removed, but we neglected to remove them from the gemspec at the time.\nI've removed them now, and cut a new version, so if you update to 0.21.1 of codeclimate, you shouldn't have this dependency conflict.\n. :shipit: \n. :+1: \n. This is great! The MountedPath is a nice abstraction I can't believe we didn't see earlier.\nThe test functionality isn't very used now, and needs real work to be legitimately useful at any rate, so I wouldn't worry about it excessively. That said, we shouldn't break existing functionality even if it's not widely used, so we should do whatever needs doing to figure out if this is breaking it. @dblandin tried using it for something, so he might have a simple testcase.\n. > bin/rube-goldberg\nGive me some marbles & springs, and I will write a deploy script.\n. LGTM\n. LGTM\n. :+1: \n. cc @codeclimate/review \n. Hi @justinschier,\nCan you please check the output of docker-machine ssh $DOCKER_MACHINE_NAME sudo df -h? The duplication failure, though strange looking, still looks like a low disk space issue to me: I've seen similar problems when a docker VM disk is close to full, but not actually completely full.\nIf you have old container data hanging out in docker ps -a, that might be another opportunity for you to free up more disk space. I run docker ps -a | grep 'weeks ago' | awk '{print $1}' | xargs docker rm fairly regularly, in addition to the \u2026 docker rmi invocation you've already run.\n. Hi @DavidEBest,\nThanks for the report. This is indeed a bug in our CLI: I've opened a PR to patch the issue, and should be able to release a build with the fix some time tomorrow.\n. @DavidEBest FYI v0.24.1 of the CLI has been released with the fix for this issue.\n. Hi @XaBerr,\nWe think you might be our first Windows user for the CLI, so we don't have all the kinks worked out for setting it up and using it on Windows yet. That said, I just ran through a quick setup on a Windows machine, and I think it is doable, so I think we can figure it out together.\n1. You'll need to setup docker to run from the Windows Command Prompt, including creating a new Docker Machine VM, etc. if you haven't already done that.\nNote: I don't think docker-machine on Windows will automatically start the VM when you reboot your computer. You might want to see if you can configure your machine to do that: otherwise you'll need to manually start the VM using docker-machine start anytime you reboot your computer.\n2. The following is a rough batch file I wrote that will run the Code Climate CLI from cmd.exe. Note that you have to replace MACHINE_NAME with whatever you actually named your docker machine VM in step 1. Please copy this into a file named codeclimate.cmd wherever you want to keep that file on your hard drive.\n``` bat\n   @ECHO OFF\n   SETLOCAL\nFOR /f \"tokens=*\" %%i IN ('docker-machine env MACHINE_NAME') DO %%i\nSET CODECLIMATE_CODE=%CD:\\=/%\n   SET CODECLIMATE_CODE=%CODECLIMATE_CODE:C:=/c%\n   SET CODECLIMATE_TMP=%TEMP:\\=/%/codeclimate\n   SET CODECLIMATE_TMP=%CODECLIMATE_TMP:C:=/c%\ndocker run ^\n   --interactive --rm ^\n   --env CODECLIMATE_CODE ^\n   --env CODECLIMATE_TMP ^\n   --env CODECLIMATE_DEBUG ^\n   --volume \"%CODECLIMATE_CODE%\":/code ^\n   --volume \"%CODECLIMATE_TMP%\":/tmp/cc ^\n   --volume /var/run/docker.sock:/var/run/docker.sock ^\n   codeclimate/codeclimate %*\n   ```\nThis script is a bit limited right now: it doesn't have any real error handling, and is limited to running against directories on the \"C:\\\" drive. It should be enough to get started with, though.\n3. You can test that everything's ok so far by opening a cmd.exe prompt, cd-ing to the directory where you saved codeclimate.cmd, and running it. It should print the CLI's help screen. (Note that it will probably pull the docker image again first: since this is using a docker machine VM, the image you already pulled is living on a different VM.)\nYou can further confirm that the CLI script above is working by cd-ing to the source directory of your project in the shell, and running C:\\path\\to\\codeclimate.cmd engines:install and C:\\path\\to\\codeclimate.cmd analyze to see analysis results directly before configuring the Atom integration.\n4. At this point, you should be ready to configure Atom to use your codeclimate.cmd script: just set the executablePath for the plugin to the path to where your codeclimate.cmd script is saved.\nLet me know if you run into trouble following the above steps or anything doesn't work. We'd love to get this hammered out so we can make this easier for other Windows users in the future!\n. Silly question, but did you try C:\\codeclimate.cmd (backslash instead of forward slash) in Atom?\nI didn't actually go all the way through installing Atom & setting up the plugin on my Windows box when I put together those instructions. If it's not just the path needing the other kind of slash, let me know & I'll try to reproduce on my machine.\n. I dug into this more @XaBerr. Unfortunately, the linter-codeclimate Atom plugin currently assumes it's running in a Unix environment in several key ways, and we don't have an immediate fix for that. I'm sorry I wasn't aware of that limitation when we started this.\nI've filed https://github.com/AtomLinter/linter-codeclimate/issues/25 with details of what I think needs to get addressed in that plugin for Windows support. I'm sorry I don't know  exactly when we'll be able to schedule that work.\nSince you've gotten the CLI working, though, you can continue to use that directly until this is addressed. Hopefully that's still useful to you!\n. Hi @XaBerr,\nThe CLI always analyzes the project in the current directory. File arguments can be given to specify which files in that directory to analyze, but in your case they'd have to be given as the relative Unix paths they are inside the Docker VM, not Windows paths. So just running C:\\codeclimate analyze would try to analyze all of the files in C:\\wamp64\\www\\JUICE\\projects\\JATE, but if you wanted to just analyze one file or directory you'd want to run C:\\codeclimate analyze dist C:\\codeclimate analyze dist/some/file.js.\nCan you please set CODECLIMATE_DEBUG in your environment by running Set CODECLIMATE_DEBUG=1 in the command window, and then run C:\\codeclimate analyze and provide that output here if it's still failing? If you're still getting that same error message, please also check that your docker VM is mounting your Windows drive in the expected way: you can ssh into the Docker VM by running docker-machine ssh default, and then you should check that ls /c/wamp64/www/JUICE/projects/JATE shows the expected directory contents.\n. I don't think any of our team are familiar enough with the specifics of Docker on Windows to be much help on the file visibility issue there, sorry, @XaBerr. Since that looks like a docker-machine issue of, you might want to consider asking something on the Docker Forum or Stack Overflow, or seeing if there are any relevant questions there under the docker and windows tags.\n. Hi @XaBerr,\nIf you're going to run the CLI via docker run, then there are a number of other options needed: please refer to the details in the README.\nAvoiding needing to remember and type all those options is why we provide a wrapper script for Unix platforms, and is also what the batch script was doing. It looks like you're now trying to run Code Climate from a terminal inside of your Docker Machine instead of from a Windows command line. You may want to copy that wrapper script into your Docker Machine if that's how you intend to run the CLI in the future.\n. @pbrisbin \nBefore (escaping everything):\n\nAfter (not escaping everything):\n\n. Tweaked it a bit, and decided to just strip engine output before echoing without doing any other manipulation: newlines in issue readups are already escaped (because it has to be valid JSON). We handle leading/trailing whitespace before we parse the issues, so it doesn't seem very useful for debugging anyway.\n@pbrisbin @GordonDiggs any problems with that thinking?\n. Thanks for catching this, @rolandhawk!\n. This has been discussed before: we intentionally stuck with .eslintrc in the past because it has the lowest precedence, ensuring we would never overwrite a user's explicit settings.\n. The problem is that we run init on .com even if a .codeclimate.yml is present, because we want to provide our default engine configs when explicit configs are not present.\nThe copy-configs code currently pretty much just says \"copy each file in a directory if it doesn't already exist\". In the ESLint case, that's problematic because there are 5 standard files they could have configuration in, and older configs are likely to be the older .eslintrc name (since I think that used to be the only name used). That's why we've continued to name our config .eslintrc: it's a less optimal first-run setup since we're giving the user a deprecated filename, but it won't stomp over explicit user config.\nI don't think we can reasonably change this without first adding features to to the copy-configs code  to allow more sophisticated conditions for copying a file.\n. The original card prompting this work was about path validations, and I could be wrong, but I think one of the things around that was not just that the file path could be invalid, but also that the location (line numbers/offsets) could be invalid. Are you planning to investigate/address that separately, or did you conclude it wasn't necessary?\n. My only remaining nit is that I think intentionally calling IssueValidator.new(nil) is a smell. I'd love to see that not be the case eventually, but I'm fine with it not being done now. Aside from that, this is awesome!\n. This looks good to me. One thing I'd be interested in doing some testing of before shipping is performance impact on some repos: you're reading in the file afresh for each issue, which could fairly seriously slow down analysis on largish repos/repos with many issues. It'd be nice to have some assurance that impact is acceptable. \n. LGTM pending green.\n. Nit: we're not validating the path of other_locations entries, are we? Should we?\n. One note about another validation you probably want in the other_locations stack. Otherwise, LGTM.\n. Hi @jkugler thanks for your interest in helping out. I'm going to ask @chrishulton to give his thoughts here since he works a bit more closely with the CLI codebase than I do these days, but I'll try and sketch out my own thoughts on what I think an appropriate way to implement this support would be.\n\nAny direct calls to exit should probably be limited to the command class under CC::CLI, or something in that area. Code under CC::Analyzer (where you'll find formatter-related code) is treated like a functional library reused in non-CLI contexts where hard-exits would be problematic.\nThe exit code for these states should probably not be 1. Since 1 is generally the \"who knows what just happened\" error code for unix CLI tools, and is already the exit code the CLI uses when it errors for any reason, I think it's important for scripting purposes that the exit code for \"we found issues with your code\" be different from \"an error of some kind occurred\". So for the sake of expediency let's say the exit code for this should probably be 2.\nI suspect the text (default) formatter might be the only specific formatter that it's appropriate to have this exit code apply to? My thinking is that the text formatter seems likely to be the one that people will use in CI/scripting environments where you would in fact want to be likely to error/exit immediately if issues were found. Exiting with this error code on, for example, the JSON formatter doesn't make much sense to me since most shell scripts are going to have set -e (I hope), and the main reason for using the JSON formatter is to collect the JSON issue details in order to do something with those JSON issues later in the same script, so set -e combined with a non-zero exit code would be likely to break existing scripts.\n\nTo sum up, I suspect the best first pass is:\n\nFormatter base class's interface should expand to return some details about 1) did it output any issues and 2) is it a kind of formatter that should exit with a nonzero exit code if it did.\nThe PlainTextFormatter should implement that new interface appropriately.\nThe Analyze command should learn to use that new interface, and exit with an appropriate code if necessary.\n\nLet me know if that makes sense to you, and @chrishulton please let chime in here with your thoughts on the subject.. Hi @nadeemja,\nWe unfortunately do not currently support arbitrary ESLint plugins: since plugins are effectively arbitrary remote code executing on our system, we need to be very careful about our architecture choices before we can support them. Right now we bundle & whitelist several plugins into the engine (eslint-config-airbnb, eslint-plugin-react, and eslint-plugin-babel), but other plugins won't work.\nThis is something we'd certainly like to support, but I'm sorry we're not there yet. We have several issues discussing this restriction on the codclimate-eslint repo right now, and that engine repo is a more appropriate place to discuss these changes, so I'm going to go ahead and close this issue. Please keep an eye out there for updates.\n. :shipit: \n. Should we update the message as well?  \"Path must be relative\" is...not a very helpful message if the path is ../foo.rb.\n. LGTM\n. Definitely really helpful for community authors!\n. \ud83d\udc4d \n. \ud83d\udc4d \n. LGTM modulo CC issues.\n. Still  LGTM for an RC\n. Credit for the implementation here goes to @maxjacobson. I just cleaned it up a bit & added a couple other tests for sanity.\n. \ud83d\udc4d \n. Docker 1.12 was released on Aug 18, and has resolved this issue in all the cases we've seen, so I'm going to close this issue for now. If anybody is still affected by this after upgrading to Docker 1.12, please let us know.\n. Hi @Aeolun,\nThe first issue you're running into looks like a YAML parsing oddity we've seen before: when a node begins with *, Ruby's YAML parser tries to parse that as a pointer to another node, instead of parsing it as a string, which is what you want it to be. The result is a mangled YAML document that unfortunately the CLI doesn't handle as well as it could right now. If you quote the **/bin/ entry (so that line would be - \"**/bin/\"), that should fix that issue.\nThe vendor issue does look like a bug. Could you please include the entire output of CODECLIMATE_DEBUG_ANALYZE=1 codeclimate analyze after fixing the **/bin/ path? There's output there relating to exclude paths that could be useful here. Is there any chance that those files are symlinked somewhere else in your project? We've seen some confusing cases where engines would analyze symlinks in non-excluded locations but report the file's original name.\n. Hi @Aeolun,\nSorry this got dropped: I went on vacation for a while, and this issue unfortunately didn't get picked up in the meantime.\n\nI've tried running with CODECLIMATE_DEBUG_ANALYZE=1, but that didn't work, and running with CODECLIMATE_DEBUG=1 the final output keeps overwriting the debug output. Anything I can do against that?\n\nThat's confusing, and I don't think we've observed that before. Can you run CODECLIMATE_DEBUG=1 codeclimate analyze > cc-out.txt and post the contents of cc-out.txt?  Can you also run just CODECLIMATE_DEBUG=1 codeclimate analyze and post that output to demonstrate the overwriting you're talking about? The CLI is just spitting stuff out on stderr & stdout: it's possible that something it echoed included some kind of shell escape code. Are you using bash in your VM or a different shell? \nAside from this output issue, it seems like your original issues have been addressed now, is that correct?\n. Code Climate engines run without network access for security reasons, and in general our spec schema is organized around analyzing & reporting issues on source code, not things derived from source code like web pages. So unfortunately, AccessLint is a poor fit for Code Climate. Never say never, I'm just leaving this as a small note on some current hurdles in the way of supporting this tool.. It looks okay to me, and we got coverage for the PR, that all seems great. I'm confused & surprised by the PR coverage status saying coverage dropped 18.2% though?\n. LGTM\n(C++ style comments next to shell commands seems like a mistake in any case.)\n. Actually, wait, this isn't valid shell anyway, is it? Underscores in numbers won't work setting this in ENV AFAIK. If these are intended to be runnable commands, should that be changed?\n. LGTM (for realz).\n. Hi @ovr,\nIt looks like you're running into the same issue as #475. We have a docker client embedded in the CLI, and versions of Docker prior to 1.12.0 have this unfortunate behavior when the client & daemon are compiled with different versions of Go.\nThis bug in Docker was fixed in 1.12.0, so the recommended remediation is to upgrade your system to Docker 1.12.0.\nHope that helps, please let us know if upgrading Docker doesn't help.\n. Good catch, thanks @mmornati \n. Hi @ehannes,\nSorry for the trouble here. I see a couple things to try:\n1. I suggest not putting the . path in your invocation when you run analysis: specifying a path to analyze on the command line currently overrides/ignores all exclude paths, so I would not expect any exclude paths to get applied with that argument there. Without a path provided, the CLI will analyze the whole project (except the exclude paths), so you don't need to provide it. For future reference, there's currently a quirk in our path-processing code that doesn't like leading .s, so if you did want to analyze a subdirectory or a specific file, you'd want to run codeclimate analyze foo/bar, not codeclimate analyze ./foo/bar.\n2. If you're still seeing different behavior after removing that argument, could you please add --env CODECLIMATE_DEBUG=1 to your explicit docker run invocation? That would show more of the same debug output around what paths were generated & how engines were run, which would help identify how these invocations are behaving differently.\nLet me know how that goes.\n. Cool. LGTM. We should probably find a way to dogfood inferred configs better for this kind of issue.\n. > For the UX, I imagined it'd just be codeclimate dependencies. Just because today it only has a files sub-key and only takes that action, I still see the command as broader and open to future extension. WDYT?\n@pbrisbin I think we'd still want to be able to execute individual sub-parts of dependencies independently. Were you thinking a git-style codeclimate dependencies files for that case, and a plain codeclimate dependencies do (potentially) everything?\n. @pbrisbin updated\n. @codeclimate/review this is ready for review\n. Hi @daften,\nSorry for the trouble here: our docs were not correct. \nPath is not a required argument for analyze, and in normal cases where you want to analyze your entire project probably actually doesn't do what you want. The reason being that providing an explicit path for analysis does not apply any exclude_paths you have configured. I've updated the README & the help output to reflect this.\nThat's why analyze . was taking a long time & using large amounts of CPU but analyze did what you expected: it was probably analyzing a large number of files you normally exclude.\nYour docker run ... command not finding any issues is a more confusing thing. A couple questions there:\n\n\nI notice a different set of engines in the output of the first docker run ... you ran vs the output you got from codecimate analyze. Did you change your .codeclimate.yml in between these commands, or would you have expected the two commands to run the same engines when you were running them?\n\n\nCan you please share the content of your .codeclimate.yml and also try running the docker run with DEBUG turned on & the . arg removed? e.g.\ndocker run \\\n  --interactive --tty --rm \\\n  --env CODECLIMATE_DEBUG=1 \\\n  --env CODECLIMATE_CODE=\"/code\" \\\n  --volume \"$PWD\":/code \\\n  --volume /var/run/docker.sock:/var/run/docker.sock \\\n  --volume /tmp/cc:/tmp/cc \\\n  codeclimate/codeclimate analyze\n\n\nThanks.. Thanks for the links. I had clicked through to your project before, but didn't think to look for a branch with the Code Climate config.\nI cloned locally & was able to reproduce, and after comparing that docker run command more closely to what our codeclimate wrapper script does, I saw the issue (which I should have noticed earlier). the CODECLIMATE_CODE env var is expected to be the original host path that the repository lives at (i.e. $PWD), not the internal path mounted into the docker container (i.e. /code).\nThe reason that ENV var exists is because the CLI runs each engine in a separate docker container, and when it does it needs to give it a volume mount for the repo code into /code for analysis. But, since the CLI is running using your machines's docker daemon, the source path for that mount needs to be the real path the code exists at, not the path it exists at inside the CLI container.  With CODECLIMATE_CODE=/code, the CLI was trying to run something like docker run -v /code:/code codeclimate/codeclimate-phpcodesniffer, when what it should have been running was docker run -v /your/home/projects/repo:/code codeclimate/codeclimate-phpcodesniffer.\nSo the correct manual docker invocation would be\ndocker run \\\n  --interactive --tty --rm \\\n  --env CODECLIMATE_CODE=\"$PWD\" \\\n  --volume \"$PWD\":/code \\\n  --volume /var/run/docker.sock:/var/run/docker.sock \\\n  --volume /tmp/cc:/tmp/cc \\\n  codeclimate/codeclimate analyze\nThis is another instance where the README is incorrect, so I'll fix that shortly. Thanks for catching all of these issues! . README fixed in #536. Thanks for addressing those issues, @pointlessone. I turned up something else doing some local QA, that I didn't encounter yesterday so this might have been introduced as part of the recent changes?\nIt looks like each code block gets the source code of the entire file, which has a  severe impact on file size & browser render performance. Generating the HTML report for this repository turned up 71 issues, and the HTML file was 236 MB, which Chrome choked on (entirely independent of the Javascript: just parsing/rendering the HTML itself was problematic).\nOn the site we have a restriction in place for how many lines we'll render for a given issue for similar performance reasons: can we introduce something similar here? Specifically, can we include a maximum of 10 lines of code in the markup for any code block? It's fine if users need to go the actual source to see related lines or all of the content for issues that cover more than 10 lines. For issues less than 10 lines, it's also fine to just render the relevant line(s).. Ah, I see what happened.\nI had test coverage results locally in coverage/index.html (which isn't excluded from analysis because it's not normally there), and that test coverage file has several TODO comments in it (most of which seem to actually be from Simplecov). That coverage file is > 8 MB, and there were 21 issues found in it, so that's ~168 MB right there.\nWhile this isn't an especially common case, and in this particular instance I should have excluded that dir from analysis, it's also not really unusual for customers to have quite large files that might have several issues in  them, and when that happens the \"include all the source\" strategy can get problematic quickly.\nYou make good points about context, so including context around smaller instances is entirely reasonable, but I still think we need to enforce a limit on the total number of lines put into the HTML for any given code block.. I realize this is WIP, so maybe this is planned, but IMHO we should also make this not fail out if the user isn't connected to the internet, or if the endpoint is down/unreachable. E.g timeouts, non-expected response bodies, non-200 codes.. Closing due to staleness. Hi @devth, we have a related issue filed for this already: #422. We don't know when we'll be able to schedule implementing a fix, but we're interested in help getting it done if you're interested!\nI'm going to go ahead and close this as a duplicate, but feel free to discuss further on #422.\nThanks.. I don't think option 1 is preferred, partially for the reasons Max gave. I would go further and say that I don't think we should even try and be smart enough to only prepare non-existing files, since this could lead to confusion about whether the CLI would automatically check for whether those remote files have changed (it won't).\nPersonally, I think the error message approach is plenty, probably by just emitting a warning if any files expected to exist from prepare don't exist.. > FWIW, running the prepare step seems pretty quick to me, so I don't see a huge downside. \nOne of the very nice advantages of the CLI is that you can use it without network access. And not everybody always has fast internet access, even if they are connected.\n\nFurther, one argument in favor of always running the prepare step when configured is that it's consistent with analysis on codeclimate.com.\n\nI would argue doing it automatically makes it less like .com. There's a reason prepare is it's own step in the build process, same as init, etc. analyze is intended to be just the engines analysis.\n\nAlternatively we could pass a --prepare flag to analyze.\n\nIn terms of user-facing effort, I don't see a significant difference between typing that and typing codeclimate prepare && codeclimate analyze, so I don't see that as an improvement (for one thing it begs the question of do we then also add an --init flag? What about an --engines-install flag? \"Simple\" solutions are rarely actually that simple :).).\nAdding a flag also doesn't solve the the motivating issue here, which is that if you forget/don't know to run prepare, the error message you get doesn't tell you you should. So you'd still need to make the improvement to emit a warning. . > FWIW we do install engines by default when you run codeclimate analyze\nI wondered if you would call me out on that :). Only as a side effect of docker run though, and importantly that doesn't update engines that exist locally, it only pulls image not available locally, which makes the current \"unintentional side effect\" behavior different from what I presume a --prepare or --engines-install flag would do (which I would expect to run the relevant commands regardless).. So far, the primary intent I've seen behind changing this seem to be the profiling, is that accurate? If that's the case, would it be better to change the perms based on the PROFILE setting instead of debug?. > That's my current reason, yes... But I see this as useful in all sorts of debugging tasks. That's why I toggled it on debug.\nThis is kinda YAGNI IMHO. If the current reason is for profiling, we should turn it on when doing profiling. If you're debugging normally, you don't necessarily want this on (and, in fact, having it on may be counterproductive since now you're \"debugging\" in an environment different from \"production\"). And, from the other side, doing profiling work does not mean you want to see a ton of debug output (and in fact may be counterproductive since the CLI may spend a bunch of time in I/O for debug output it wouldn't normally.)\nAll of that having been said, Devon's suggestion also sounds attractive to me. If it were reasonable to configure the profiling code you have in mind to write to /tmp, writing to a different mounted directory seems a little bit preferable long term since it doesn't mean special-casing how we treat the code-under-analysis.. Hi @iainbryson,\nThank you for providing so much detail & the debug output. I think the root cause here is indicated by the line at the top of the debug output:\n[DEBUG] Couldn't include because part of path doesn't exist. path=\"./code\"\nSpecifying /code as a path to analyze when you run codeclimate analyze is causing unexpected behavior. The /code path is an implementation detail of how the CLI makes code available to engines for analysis internally, but you don't need to specify it when running the command: you can just run codeclimate analyze (either with our wrapper script or as the full docker invocation like you shared here).\nWhen you do specify a path argument to analyze, the path should be relative to your project root, and exclude_paths are not applied when an explicit path is specified. So when you pass /code, the CLI can't find that subdirectory and falls back to analyzing the entire repository, and doesn't apply exclude paths because an explicit path was provided. (This failure case should probably error more explicitly than just logging a debug message, sorry.) There's more detail on this behavior in the analyze entry under the \"Commands\" section of the README\nSo if you just run codeclimate analyze without a path, I hope you'll see your exclude paths there being respected.\nOne other small note about the config you shared: I realize you were probably just starting to add exclude_paths everywhere to make it work, but an exclude_paths entry under the language name for duplication isn't a valid configuration. If you did want to exclude only specific files for the duplication engine that key would need to be at the same indentation level as enabled and config under duplication, e.g. the same as the exclude_paths entry you have for eslint. Similarly, if you want to exclude assets/javascripts/mathjax.js entirely you only need it in the top-level exclude_paths entry, not the engine-specific ones. Again, I realize you were probably just adding it everywhere while debugging, just mentioning it.\nIf you're still not seeing these files excluded when running codeclimate analyze without any path specified, please let us know here. Output of CODECLIMATE_DEBUG=1 codeclimate analyze in that case would also be very helpful.. > but I think it's likely to happen again via our bin/prep-release\nI don't understand what prep-release's flaw is here. If that script can ever change dependency versions accidentally/without programmer action, that's a real problem.. Oh, I think I know what's up. The way bundler works, because the version of codeclimate changed, any of its dependencies are also up for grabs if there are new versions in range. If we wanted to be more careful I think we'd want to prep-release to pass flags to bundler to limit what it will do. Either bundle update codeclimate or bundle update --source=codeclimate would probably do what we want.. Would you consider making this script run rake from inside a docker container instead? That would be in keeping with our approach elsewhere and avoid the need to bundle install locally as well as in the image. . When I run spec:benchmark on master, I got:\n\nPathTree over 49890 files, with 50 excludes took: 0.27004753300025186s\n\nRunning on this branch, I got:\n\nPathTree over 49897 files, with 50 excludes took: 7.1820523669994145s\n\nWhile still within that benchmarks's max time of 10s, that's a very significant slowdown, and I find it concerning, so I don't agree that this is nearly as fast as the the previous implementation. Keep in mind that this is the amount of time a CLI user on a large repo might have to wait before any analysis starts running. IMHO, 7s is longer than we should consider acceptable. (The 10s limit was picked out of a hat to catch catastrophic performance regression, but since we've had sub-second performance for so long I'd really like to keep it there.)\nIf the goal here is to allow \"partial scan mode\", the changes here seem far larger than required to achieve that. I would actually support making exclude paths apply even with provided paths the default behavior, and allowing a flag to change it for cases where the user really does want to analyze excluded files. This is a very quick draft of a patch that would do that (with some important details not addressed):\n```\ndiff --git a/lib/cc/analyzer/engines_config_builder.rb b/lib/cc/analyzer/engines_config_builder.rb\nindex 7e688e0..53a4b5d 100644\n--- a/lib/cc/analyzer/engines_config_builder.rb\n+++ b/lib/cc/analyzer/engines_config_builder.rb\n@@ -24,12 +24,15 @@ module CC\n         :container_label,\n       )\n\ndef initialize(registry:, config:, container_label:, source_dir:, requested_paths:)\ndef initialize(registry:, config:, container_label:, source_dir:, requested_paths:, apply_excludes: true)\n         @registry = RegistryAdapter.new(registry)\n         @config = config\n         @container_label = container_label\n         @requested_paths = requested_paths\n         @source_dir = source_dir\n@apply_excludes = apply_excludes\n+\n\nCC::CLI.debug(\"in EngineConfigBuilder apply_excludes=#{@apply_excludes}\")\n       end\ndef run\n@@ -55,7 +58,7 @@ module CC\n   end\ndef engine_workspace(raw_engine_config)\n-        if raw_engine_config.key?(\"exclude_paths\") && !@requested_paths.present?\n+        if raw_engine_config.key?(\"exclude_paths\") && @apply_excludes\n       base_workspace.clone.tap do |workspace|\n         workspace.remove(raw_engine_config[\"exclude_paths\"])\n       end\n@@ -76,8 +79,11 @@ module CC\ndef base_workspace\n     @base_workspace ||= Workspace.new.tap do |workspace|\n+          CC::CLI.debug(\"WORKSPACE requested_paths=#{@requested_paths}\")\n       workspace.add(@requested_paths)\n-          unless @requested_paths.present?\n+          CC::CLI.debug(\"WORKSPACE workspace=#{workspace.inspect}\")\n+          exit 1\n+          if @apply_excludes\n         workspace.remove([\".git\"])\n         workspace.remove(@config.exclude_paths)\n       end\ndiff --git a/lib/cc/analyzer/engines_runner.rb b/lib/cc/analyzer/engines_runner.rb\nindex 803cf5c..88a6b7c 100644\n--- a/lib/cc/analyzer/engines_runner.rb\n+++ b/lib/cc/analyzer/engines_runner.rb\n@@ -5,12 +5,13 @@ module CC\n class EnginesRunner\n   NoEnabledEngines = Class.new(StandardError)\n\n\ndef initialize(registry, formatter, source_dir, config, requested_paths = [], container_label = nil)\n\ndef initialize(registry, formatter, source_dir, config, requested_paths = [], apply_excludes = false, container_label = nil)\n         @registry = registry\n         @formatter = formatter\n         @source_dir = source_dir\n         @config = config\n         @requested_paths = requested_paths\n@apply_excludes = apply_excludes\n         @container_label = container_label\n       end\n\n@@ -47,6 +48,7 @@ module CC\n           container_label: @container_label,\n           source_dir: @source_dir,\n           requested_paths: requested_paths,\n+          apply_excludes: @apply_excludes,\n         ).run\n       end\ndiff --git a/lib/cc/cli/analyze.rb b/lib/cc/cli/analyze.rb\nindex 8e435a0..e0e506f 100644\n--- a/lib/cc/cli/analyze.rb\n+++ b/lib/cc/cli/analyze.rb\n@@ -18,6 +18,7 @@ module CC\n         super\n         @engine_options = []\n         @path_options = []\n+        @apply_excludes = true\n     process_args\n     apply_config_options\n\n@@ -27,7 +28,7 @@ module CC\n         require_codeclimate_yml\n     Dir.chdir(MountedPath.code.container_path) do\n\n\nrunner = EnginesRunner.new(registry, formatter, source_dir, config, path_options)\nrunner = EnginesRunner.new(registry, formatter, source_dir, config, path_options, @apply_excludes)\n           runner.run\n         end\n       rescue EnginesRunner::NoEnabledEngines\n@@ -48,6 +49,8 @@ module CC\n             @engine_options << @args.shift\n           when \"--dev\"\n             @dev_mode = true\nwhen \"--no-excludes\"\n\n@apply_excludes = false\n           else\n             @path_options << arg\n           end\ndiff --git a/lib/cc/workspace/path_tree/dir_node.rb b/lib/cc/workspace/path_tree/dir_node.rb\nindex 36bef6d..3d33d60 100644\n--- a/lib/cc/workspace/path_tree/dir_node.rb\n+++ b/lib/cc/workspace/path_tree/dir_node.rb\n@@ -14,7 +14,7 @@ module CC\n         end\n def all_paths\n\n\nif populated?\n\nif populated? || @was_expanded\n         children.values.flat_map(&:all_paths)\n       else\n         [File.join(root_path, File::SEPARATOR)]\n@@ -39,6 +39,7 @@ module CC\n       return if head.nil? && tail.empty?\nif (entry = find_direct_child(head))\n+            @was_expanded = true\n     children[entry.basename.to_s.dup.freeze] ||= PathTree.node_for_pathname(entry)\n     children[entry.basename.to_s.dup.freeze].add(*tail)\n   else\n@@ -52,6 +53,7 @@ module CC\ndef populate_direct_children\n   return if populated?\n+          @was_expanded = true\nPathname.new(root_path).each_child do |child_path|\n     children[child_path.basename.to_s] = PathTree.node_for_pathname(child_path)\ndiff --git a/spec/cc/workspace/path_tree_spec.rb b/spec/cc/workspace/path_tree_spec.rb\nindex 8935233..dba4648 100644\n--- a/spec/cc/workspace/path_tree_spec.rb\n+++ b/spec/cc/workspace/path_tree_spec.rb\n@@ -44,6 +44,17 @@ class CC::Workspace\n       end\n     end\n\n\n\n\nit \"excludes everything after explicit include\" do\n\nwithin_temp_dir do\nmake_fixture_tree\n+\ntree = PathTree.for_path(\".\")\ntree.include_paths([\"code/a/bar.rb\"])\ntree.exclude_paths([\"code/\"])\nexpect(tree.all_paths.sort).to eq []\nend\nend\n+\n     it \"excludes directory after excluding only part of it\" do\n       within_temp_dir do\n         make_fixture_tree\n```\n\n\n\nIt prevents project root escape\n\n\nCan you provide more details here? The current implementation does guard against root escape. A demonstration of a configuration that would allow root escape would be helpful if this is a problem. I just tried to do the naive thing of writing a spec that added an existing file, and it was not able to escape the project:\n```\n    it \"handles dir escape\" do\n      within_temp_dir do\n        make_fixture_tree\n    $stderr.puts \"DEBUG pwd=#{Dir.pwd} exist=#{File.exist?(\"../../linuxrc\")}\"\n    tree = PathTree.for_path(\".\")\n    tree.include_paths([\"../../linuxrc\"])\n    expect(tree.all_paths.sort).to eq [\"./\"]\n  end\nend\n\n```. @dblandin I should still get around to reviewing it, and I feel very guilty I haven't, but please leave it open for now.. > This gets us to * and ? but still leaves out [a-z], {a,b}, and \\ (escapes).\nIf we're adding stuff, we may as well also add [] and {}, yeah?\n\nMaybe it'd be easier and more robust to always glob even when there are no special characters?\n\nI don't remember exactly why we did this. It was probably a performance optimization (don't read the FS if you don't have to), and it may have been premature. I'd be personally ok with always doing the match as a glob if it doesn't change any behavior we can identify and doesn't move the needle of spec:benchmark.. >  in a docker container\nThis might be part of what's up.\nI'm guessing that the docker.sock available within your container may be mounted into that container from the host running the docker daemon. Launching docker containers from within docker containers can make the file paths for mounting volumes rather confusing, since the source path needs to be the path on the host machine, not the path within the docker container at that point.\nSo $PWD within your current docker container may possibly not point to the same directory you expect it to within the codeclimate/codeclimate container.\nThis is just a quick guess based on the symptoms described here. To test out whether this might be affecting you, you can run docker run --rm -v \"$PWD:/code\" --entrypoint \"/bin/sh\" codeclimate/codeclimate -c \"cat /code/.codeclimate.yml\" within your pipeline from the same terminal you were running the other commands in your screenshot, and see if that cats out the contents you expect for your config.. @halfpastfouram I think that confirms my suspicion that $PWD is a different directory within the docker container you're in & on the host running the docker daemon, since that doesn't at all match the contents of your config you've shown elsewhere. How & why there's a .codeclimate.yml in that other directory I really don't know.\nWould you be able to share more of your .gitlablab-ci.yml? I'm assuming you set this up based on GitLab's docs, since your command looks similar to their docs.\nYou also could try and get more details by running other commands similar to what I suggested to do the cat: e.g. you could use the same basic formulation to do an ls -al /code and see if the rest of that directory does look like your project's root or something else.\nYou also might want to consider contacting GitLab support about this if you haven't already: what you've shown me makes me think the problem is arrising from confusion about paths within docker containers on GitLab's CI system, so they might be able to point you in the right direction better than we will.\n. grauwoelfchen's comment at https://github.com/codeclimate/codeclimate/issues/691#issuecomment-337679618 seems like a good thorough explanation of the underlying root cause here & workarounds. Since this is an environmental setup issue primarily affecting GitLab's CI environment & not a bug in the codeclimate CLI, I'm going to go ahead and close this issue, but folks should feel free to keep discussing here if it's helpful!\nIf people continue to encounter difficulties with these kinds of path/privilege issues in GitLab's CI environment, I would encourage you to file issues https://gitlab.com/gitlab-org/gitlab-ce/issues since it seems like that's where other related issues have been tracked, several of which are linked throughout the conversation above.. Good points both, @pbrisbin @nporteschaikin: updated.\n\nbut I still wonder whether we need any override logic, \n\nPat & I discussed this in Slack, but my feeling is that we at least need to be able to override channel for QM engines so we can test changes to them. Pat suggested a different strategy there, which the latest commit here takes into account.. > I think a canary to a repo that tests duplication would result in slightly cleaner code and an always-semantic configuration. But this has a very small footprint/isn't the hill I'd die on, so LGTM \ud83d\ude04\nI don't think that really works long term: the beta for structure has already been really valuable while rolling through checks, and I suspect we'll do something similar for duplication when switching it to use the parser server. Channels are super valuable for dogfooding large changes before rolling them out to all customers, and I don't think spot-check canaries allows for the kind of persistent QA that channels do.. You're both right, again. Updated.. > Did you run this on things?\nI did not. I will do some local testing before merging since you mention RuboCop and that surprises me.. Urgh, previous code was correct, RuboCop does not like the new style yet.\nOTOH, csslint (& maybe others?) crash on the old style. So everything is wonderful.. > Thanks! Sorry i didn't know EngineFailure was present here\nIt's kinda dumb it wasn't covered by a test: I think it used to be for the spec of the analyze command, but that got \"temporarily\" erased during QM spike. We'll want to restore it, I'm sure, but honestly it's not something I have time to do right now.. Pretty sure this isn't actually used in QM and won't work. In fact I think this whole file might be defunct.\nYou want to modify CC::Config::Default.. > However, this file appears to still be used - even in QM - for the codeclimate engines:enable duplication command.\nInteresting. Well, having this in so many places is gonna be terrible long term, but that's a problem to consider another day.. @dblandin might be easier to go through this one commit-by-commiit. Re-purposing this for #733 -- closing. Thanks @pointlessone, I'll address the spec after this. Since the limit has been higher in web analysis for over a year, the spec was already pretty inaccurate.. Actually I think the spec is fine right now: the two relevant lines I see are:\n* The Docker image for an Engine must not exceed 512MB, including all layers.\n* The combined total RSS memory usage by all processes within the Docker container must not exceed 1GB at any time.\nI think Alex was noticing that the first line, but that's a restriction on image size, not container memory usage. The second line already said 1GB, so CLI was being more restrictive than the spec suggested it should have been!. Oh, my bad, I totally misunderstood you, and the image memory limit being coincidentally the same as the old container memory limit increased my confusion.. I don't know why the spec in https://circleci.com/gh/codeclimate/codeclimate/2168 is failing: it passes for me locally, and it passed previously on the quality-model branch. No obvious reason it should be flickery. Looking into it.. I identified the spec breakage and have that open as #741, since it's not strictly related to this change: I think this change just shifted GC of the suite reliably enough to trigger the issue. I'll rebase here once that's merged and it should be green (it was when I had the fix on this branch: https://circleci.com/gh/codeclimate/codeclimate/2177)\n@dblandin Can you take another look here, or was your comment at https://github.com/codeclimate/codeclimate/pull/740#discussion_r141445325 an implied approval?. @maxjacobson Good catch, I have written more specs, all lines are now super green.. Hi @daften,\nWe released version 0.70.0 of the CLI today with support for the new configuration schema, as well as some significant new analysis checks. You can see some release notes at https://github.com/codeclimate/codeclimate/releases/tag/v0.70.0.\nIf you upgrade your CLI to get the latest version, the config file you posted above should work.\nI'm going to go ahead and close this issue, but please re-open and @ me here if your config file still isn't working after upgrading.. Closing in preference to #777. @GordonDiggs pinging you for review in case you were party to a discussion on dropping this with Pat that I missed.. @toddmazierski commented, also added a new commit to catch a thing I realized I need on the builder side.. @larkinscott text changes look good, but I think you want to make this change against quality-model instead of master: we're not really rebasing quality-model these days, and we're going to try and merge QM back to master real soon, so it'll be easier to just make these changes on QM right now.. I rebased quality-model on master to make the merge easier & resolved conflicts. To verify correctness, I:\n\ngit diff origin/maser -- config/engines.yml to verify only expected changes were made to the engines registry.\nSanity checked git diff origin/quality-model against this branch to make sure the differences of this rebased branch are what we expect.\nRan make install locally to confirm that still works as expected.. > are there breaking changes here? Should this be 1.0.0?\n\nThere are breaking changes (the removal of several commands certainly qualifies), but since we're currently sub-1.0, that doesn't matter: anything goes in semver land as long as you're less than 1.0.\nI don't think we're planning to call this 1.0, for product/marketing reasons.. My apologies @Miouge1, I listed this in the pull request introducing the changes, but accidentally omitted that copy from the release notes. I've copied that information over to the release notes now. Thanks for filing this.\n\nmy assumption is init generates linter configuration files which are used during the analyze command. Maybe this might cause discrepancies.\n\n@aequitas that is correct, and is what init used to do. We've removed that functionality as part of wider changes to our analysis to provide better out-of-the-box feedback on code quality. Please note we're not removing support for linters like RuboCop, ESLint, etc., but we're no longer enabling them by default or providing our own opinionated default configurations for those tools. An up-to-date list of the plugins we support and how  to configure them is available in our documentation.\nWe have adjusted what init enabled by default in the past, so relying on init could also have resulted in discrepancies before now. For users with their own preferences about what plugins to use, we always recommend committing the relevant linter configuration files and a .codeclimate.yml controlling what plugins you want to run.\nFor all gitlab CI users, yes, we recommend removing usage of codeclimate init. Please note a bug affecting the JSON formatter of the CLI was also caught this morning, which will also affect GitLab usage. We're sorry that bug slipped into the release & should have a bugfix release out shortly.\nI'm going to go ahead and close this issue since it was filed for our failure to sufficiently document the init removal, which I think I've addressed.. Hey @billmei sorry for the delayed response here. Thanks for the clarification to the docs. I know it's a minor change, but if can please sign the contributor license agreement (link in the automated comment above) then we can get this merged. Thanks!. Hi @benmccann,\nI'm afraid there's been some confusion stemming from #298: include_paths is not a configuration key that's recognized or used in configurations. There are internal parts of the system that invert exclude_patterns (the configured list of files/patterns to not analyze) into an internal include_paths collection (the list of files/directories that may be analyzed), but configurations should always use exclude_patterns (or exclude_paths, as you have, which is an older key name: new configs should use the name exclude_patterns instead, but the old name works the same way).\nFor your particular use case, you may notice that the docs page you were looking at (https://docs.codeclimate.com/v1.0/docs/excluding-files-and-folders) mentions \"negated patterns\":\n\nPatterns can be negated by prefixing them with a !. A negated pattern will include the matched files for analysis, even if they have been excluded by a previous pattern.\n\nSo if you want test/ & samples/ to be excluded for most plugins & but analyzed by ESLint, you can configure ESLint like:\neslint:\n    enabled: true\n    channel: \"eslint-4\"\n    exclude_patterns:\n    - '!test/'\n    - '!samples/'\nLet me know if that helps!. Hi @daften,\nThanks for the feedback. One reason we don't want to fetch to be done automatically every time analysis runs is that one useful use-case for the CLI is working offline, so relying on a network connection seems like an anti-pattern, and would make analysis slower to run as well. We also generally try to design the CLI as sets of small, narrowly focused, independent commands that can be composed as necessary and don't cross-run each other too much.\nThat being said, I realize the workflow can be a bit confusing as-is since nothing clearly says prepare needs to be run first. I think our docs could improve in this area, but as a functionality change I also think it would be reasonable to have analyze also run prepare when it detects the config file prepare will write are missing locally, which I think would address the biggest pain point.\n\nand default delete afterwards\n\nCan you comment a bit on why that's a desirable workflow for you? In most team's usage of this feature that we've seen, they change fairly rarely, so always fetching and deleting seems wasteful. If they're annoying because they show up in diffs or something, we do recommend adding files fetched via prepare to your .gitignore.. Dave deleted the out-of-date page, and the link on docs.codeclimate.com has been updated to point to an up-to-date document: https://docs.codeclimate.com/docs/configuring-your-analysis.\nI'm going to close this as I believe we've addressed the issue. @rhwood I'm sorry we dropped the ball with the docs, and that led to confusion. Thank you for pointing out the issue! If you're still having trouble let us know.. This PR has been inactive for a while, I'm going to go ahead and close it. I earlier tried to detail both why this approach doesn't work for us and also how I think a successful approach to implementing this would work in this comment.\nI'm afraid that this functionality is still not a priority for our team, so we're not planning to change this behavior ourselves anytime soon. I recognize that deferring to external contributors on a code base that we depend on for some internal usage can lead to frustrations in cases like this where a seemingly innocuous change in the open source code won't work because of non-obvious internal requirements. I hope the comment I linked to above can alleviate that in the future by more clearly laying out the boundaries of how the modules in this project are used, and am happy to discuss further questions about this feature on the original issue #422 if anybody is interested in implementing this.\n. I'm going to close this. We've evaluated squashing this image in the past and decided against it: the image is already fairly small (a bit over 100MB), and the Dockerfile isn't doing any large deletes in later layers, so squashing wouldn't make it much smaller. Squashing also removes the usefulness of cached older layers: right now when we release CLI updates, most users who upgrade will only need to pull one or two slightly different layers, not the entire image all over again, but if we released squashed images the entire image would need to be pulled every time.\nGiven David's comment, it sounds like the performance is more of an issue with GitLab's CI environment, and there may be configuration changes that will help there.. Really sorry this slipped out of my inbox and I forgot about it.\nI'm fairly sure this would have been identified as similar code, not identical. See our docs for a description of this: https://docs.codeclimate.com/docs/duplication-concept. But, in brief: similar code is code that is structurally the same but may have different identifiers/arguments, etc.\nSimilar code is of course a slightly more heuristic kind of check, and is more likely to identify things you don't consider a problem. You can configure the similar code check to have a higher threshold (how much code needs to match before it shows an issue), or turn it off entirely: https://docs.codeclimate.com/docs/advanced-configuration#section-default-checks.. Closing this, as I think I've explained the reasons behind this and how to change the behavior if desired. I will still see further comments here if needed.. Customer OS & Docker version would be helpful details to get if possible.\nThis might be a docker bug. There have been some recent Docker bugs with similar symptoms (e.g. https://github.com/moby/moby/issues/23930). And our CLI wrapper doesn't rely on any persistent docker volumes normally, so this is very strange behavior.. Closing due to lack of activity and clarity here. This sounded like a docker issue based on the details available, we can re-open if new information surfaces.. Hi @PurpleBabar, thanks for the getting in touch.\nCan you expand a bit on your use-case? From our perspective, under any kind of error condition such as a timeout, the CLI is going to exit with a non-zero exit status & any results generated up to that point should be considered, at best, partial results & not to be used. In other words, if an error occurred any output should be presumed invalid & not used.\nUnder what circumstances do you expect to use partial results returned by an errored process? And can you explain a bit how you arrived at your timeout cutoff and why an engine timing out isn't troubling to you? If your timeout seconds is in fact only 60 and not 1800, that's fairly aggressive depending on the size of the repository you're analyzing. If you're seeing phpcodesniffer run for 30 minutes and timeout, I think it would be useful to discuss that on that engine's repo.. Hi, thanks for the answer, and apologies for how long it took us to think this over.\nAfter discussion, we believe this is undesirable and are not going to implement this behavior. Timeouts are intended to catch runaway processes that could fail to ever terminate or could harm the system and other processes by consuming too many resources. A process that has reached a timeout is, in our opinion, in an unknown state and to any results we may have from should not be trusted. It also would make comparison between reports on different commits effectively impossible to do reliably, and that's a critical stability requirement for the product for us.\nI do sympathize with your use case. codeclimate.com has features to help teams with these situations by setting issue statuses and making it easy to filter issues by severity & type, etc. to help teams chip away at technical debt without it needing to block current work. If you're focused on using the CLI, though, my suggestion would be to pick particular files or directories you want to improve & analyze only them (e.g. codeclimate analyze app/models/user.rb), then fix those files immediately.. This is a good suggestion, thanks, and sorry for the delay in reply here.\nI think we'd be happy to see this a PR add this. My only concern is being sure this option has no negative effects on other platforms, e.g. Linux.. Hi @2ur1st,\nRight now maintainability ratings are only provided on codeclimate.com, not as part of the CLI. Code Climate is free for Open Source projects, and if the project you're interested is closed source, you can sign up for your free trial. To get started you can go to https://codeclimate.com/quality/ and sign up with your github account.. To clarify here, the CLI does still colorize output. It only removes colors if it detects that the output is not going to a tty that supports colors, which is generally what happens when you're piping or redirecting output (e.g. codeclimate analyze | grep or codeclimate analyze > results.txt). The change is described here.\nWhat situation are you in where you're piping or redirecting but still want the escape sequences? That usually just leads to seeing escape characters in output like \\033[0;31mhello world\\033[0m.\nIf there's an interest in making this possible, I'd suggest opening a PR to change the codeclimate-wrapper shell script to support an environment variable to force running with --tty.. I think the question has been addressed, and it doesn't seem like any action is needed or planned right now, so I'm going to close this.. I'm going to close this, as I think supporting absolute paths is an anti-feature that will only make things more confusing. The fact that the CLI and all the analysis it performs is fundamentally connected to how docker works would make supporting this quite tricky. If an absolute file path could be specified, there are some awkward cases that would arise.\nAnalysis always occurs within the context of a repo, since the repo is what provides configuration, both for the Code Climate CLI and for any plugins being used (e.g. RuboCop). If an absolute path were used for analysis, then either:\n\nThat absolute path needs to point to a path underneath the current working directory (which we consider to be the root of the repo used to determine configuration context), in which case supporting an absolute path is not very helpful and would lead to other confusing usages since the absolute path would be required to be relative to the current working directory. Or:\nIf the absolute path really could be arbitrarily anywhere, then the CLI either needs to determine where the repo root is within that path hierarchy, or it would still use the current working directory (which would greatly complicate code since there would need to be separate volume mounts for config and analysis), or it would have to be settable via a flag (which comes with the same code complications). That's a degree of complication we'd find undesirable.. This would be more appropriate to track and try to address over at https://github.com/zenspider/codeclimate-flog, where this plugin is maintained.. Thank you for the docs corrections, @AndrewRayCode. If you can sign the CLA I'll be happy to merge this.. codeclimate prepare, indeed.. Glad you resolved this, FWIW if you have other test-reporter issues in the future, the https://github.com/codeclimate/test-reporter repo would be a better place to file issues than this repo, which is for our CLI.. @Rafi993 are there particular tools for linting Flow.js that you would like to see supported? I'm not familiar with Flow.js, but it seems like it's a pretty standard JS library, so normal JS code written using Flow should be analyzable by Code Climate's usual JavaScript analysis.. We'd be happy to consider PRs to add plugins to our ESLint plugin.\n\nBuilding new Code Climate engines wrapping Flow's linter is not a priority for us right now, sorry. I've added the \"help wanted\" tag to this issue: if you or somebody else wanted to write & maintain an engine wrapping that tool, we would be able to support that engine on our platform. There's a spec covering how engines work and are packaged, and some of our smaller engines make for good examples to look at for basic engine structure & packaging.. Hi @sombreroEnPuntas,\nCan you please try running codeclimate engines:install and then run your analyze command? engines:install pulls necessary docker images based on your config. \nanalyze will also pull docker images if they're not locally available, and it's unusual for it to be very slow, but if your internet connection isn't that fast it could cause a timeout since the analyze timeout code isn't optimized for this case and doesn't count the pull separately from everything else. engines:install does not have any timeouts aside from whatever docker pull does natively.. The structure & duplication engines are unfortunately fairly large right now because they package up the parsers for every language we support. Splitting them by language is something we'd like to do, but it's not on our immediate roadmap. We realize this is sub-optimal but we do not consider it a bug.\nIf you'd like to open a PR changing the timeout to not apply to the pull when it's necessary, I'd be happy to review it.\nDoes running engines:install allow you to run analyze successfully? We do recommend that users run engines:install directly as a general principle since analyze will never install updates to engines, while running engines:install occasionally will ensure you're running the most recent versions of analysis.. We made this conversion in https://github.com/codeclimate/codeclimate/pull/865 several weeks ago, and this was opened by a now-deleted user. Closing.. Sorry for the extremely late reply here, several things fell through the cracks for me last year and I'm trying to address my backlog.\nWe track analysis & test coverage results on a commit-by-commit basis, and our system does not assume that results didn't change from previous commits if we don't get results for the later commits. And at the moment we don't have an option to skip analysis on commits tagged with a specific commit message, sorry. So sending the test coverage results is actually what I'd recommend doing in this situation.\nI'm going to go ahead and close those issue. This repo is for our CLI, and isn't really the best place to discuss general product questions. \n. Hi,\nThanks for the feedback. The cognitive complexity algorithm is intended to follow the original specification published in this PDF: there are several explanations and examples there that address exactly some of the patterns you're discussing. In particular, see the discussion on if and else if/elif starting on page 5, the discussion of switch/match statements on page 6, and  Java examples on pages 18 & 19 that show the rules around if expressions and nesting in action in detail.\nWe adopted cognitive complexity for our complexity analysis because it was designed with how complex code is to read for most people, and since maintaining existing code is a big part of software development we felt that was a better default choice for most teams than other algorithms, such as cyclomatic complexity. Of course, one trouble with an algorithm trying to measure the cost of human perception is that is fairly subjective, and different people will have different thoughts on the relative complexity of different structures, which seems to be the case here. We agree with the authors of the cognitive complexity paper that else if is more readable than else {\\n  if: the former can be read as effectively a single statement, while the second generally isn't at an initial glance and so is harder to read due to the additional nesting. And although I agree that your theoretical myFun3 is an unappealing option I wouldn't write myself, I agree with the algorithm that myFun1 is even less appealing.\nIf cognitive complexity does not suit your tastes, you may want to disable it and consider using our Scalastyle plugin, which has a cyclomatic complexity check you might prefer. I'm not sure if you're using codeclimate.com or the CLI, but you can turn off checks & turn on plugins in your repo settings on codeclimate.com, or add configuration to a .codeclimate.yml file  to achieve this.. > Is there a way to configure maintainability check thresholds on a per-language basis? It'd be great if we could relax the complexity threshold just for Scala, but leave it as-is for other languages.\nI'm afraid we don't support that yet, sorry. It's something we've discussed internally and would like to do, but haven't scheduled the work yet.. I suspect @koic may be using the gem as a library within some other tool, hence wanting compatibility with Ruby 2.6? Is that accurate Koichi?\nWe discourage usage of the gem as a library because it's not a stable interface, and we do sometimes change it for internal reasons & only distribute as a gem at all to support some internal usage. We really should have distributed it as a private gem instead of a public one to avoid this confusion, and I'm sorry we didn't. I realize this can be confusing, so I apologize for that.\nThat being said, this is a small patch that seems entirely reasonable to me. I'll reiterate that usage of the gem as a library is not something we encourage people to do & I can't promise we'll always be able to accommodate changes to support those use cases, but if I'm right in my guess about why @koic submitted this change, it LGTM if it looks good to you, @filipesperandio.\n. There are instructions at https://github.com/codeclimate/codeclimate/blob/master/DEVELOPERS.md#releasing-a-new-version, but you're not a gem owner, so one of the engineers that is should probably do the release. I can do it this morning.. Released: https://github.com/codeclimate/codeclimate/releases/tag/v0.81.0. I'm afraid there is no replacement for exclude_fingerprints in the CLI. We deprecated the functionality because we created a more fully featured system of issue statuses that can be used on the website. But that system is only on the web UI and has no CLI integration right now.\nDespite exclude_fingerprints being deprecated, we have no plans to actually remove it right now, so you ca continue to use it.. That's a totally fair point. We did intend to actually change this more when we introduced the warning of course, but... that obviously hasn't happened. I'm happy to review a PR removing the warning.. .git is always removed from the include paths sent to plugins, FYI: https://github.com/codeclimate/codeclimate/blob/master/lib/cc/analyzer/bridge.rb#L99-L100. It's basically a \"default exclude pattern\".\n\nSo to me this means that both \"/*\" and \"/.*\" are interpreted very strangely when passed as common exclude to the editorconfig plugin\n\nThe plugin itself doesn't use those globs: globs are interpreted by the CLI itself, not plugins, in order to ensure consistent behavior, so I think something else is going on here. The plugins pay attention to the include_paths (which the CLI computes based on the exclude patterns).\n\nWhen reading this, i noticed that exclude_patterns are actually inside the include_paths array\n\nThe exclude patterns specific to a plugins' config are included in the config.json right now, but this is accidental and AFAIK no plugin actually uses them (they certainly shouldn't). You'll notice none of your global exclude patterns are part of the list sent to the plugin.\n\nI use the exclude pattern **/* to get rid of all files in the project root.\n\nIf you want to exclude all files in your project root, * and .* will accomplish the same thing as **/* and **/.* and probably perform better. **/* matches every single non-hidden file in your repo recursively, not just files in the root, and so the code has to iterate over a much larger set of files. Excluding * and .* in the root excludes every regular and hidden file or directory in the root, which also excludes everything inside those directories. \nThose two patterns effectively exclude your entire repository from analysis, which leads to an unfortunate edge-case in the code right now where if everything from the entire repository is excluded, the CLI falls back to analyzing everything (i.e. include paths becomes .). It looks like you are un-excluding things for every individual plugin you've configured, which avoids this problem, but you probably want to un-exclude things at the global level as well: our quality metrics (the ones you configure under checks:) aren't part of a plugin, so those are only using the global exclude patterns right now, which probably isn't what you want.\nFWIW We do not recommend excluding everything from a repository in general, because it gets into these edge cases and is generally difficult to maintain such a config. Can I ask what led you to want to exclude everything and then un-exclude for specific plugins?. I did not know there was a standard UNIX exit code for usage errors. Neat.\n. I don't think release should be part of the built gem.\n. I think maybe what makes it feel unclean is naming: we're passing around an engine_config which is really the \"default\" or \"prototype\" engine config, and referring to the actual current engine config as just config. (I think: that's my reading of the code.) Agree it's not a blocker, but it does seem it could be made clearer.\n. \u2026Yes. I thought I had caught all the instances. Thanks.\n. Yep, good point.\n. Kind of. Because of how CC::YAML works, if the engines value is invalid, it won't actually be present in the fully parsed node. An empty engines node is considered invalid now.\nI was going to suggest that CLI commands that use config values should probably run validate-config before they do anything else. But I think that should be a separate PR. In this particular case this is just a change to maintain existing behavior due to changing dependency behavior.\n\nOn Nov 4, 2015, at 08:01, Francis Hwang notifications@github.com wrote:\nIn lib/cc/analyzer/engines_builder.rb:\n\n@@ -44,7 +44,7 @@ def engine_config(raw_engine_config)\ndef names_and_raw_engine_configs\n     {}.tap do |ret|\n-          @config.engines.each do |name, raw_engine_config|\n-          (@config.engines || []).each do |name, raw_engine_config|\n  Out of curiosity, is this for the case where the engines array is entirely missing from the YAML?\n\n\u2014\nReply to this email directly or view it on GitHub.\n. For the UpgradeConfigGenerator: the stub is here for API consistency between the two.\n. That...was debugging code :disappointed: . Removed.\n. Sure. Done.\n. I guess we could. Is it worth it, though? It's longer to write, and wrap has some surprising semantics, and the returned object is a YAML node that already responds to each, so why wrap it if it's already present?\n. Just tried this locally, and it broke\u2026 a lot of things. Array.wrap & YAML Nodes both have some surprising behavior, and they do not play well together.\n\n@GordonDiggs do you have other concerns around this PR?\n. Good point. I'll change that.\n. \"here\" seems a bit unnecessary.\n. As does \"from the source code.\"\n. Related to earlier discussion around upgrade_languages, it feels weird to me that we include enable_regexps for community engines that we'll never auto-enable. Is the thinking that eventually we'll remove the community restriction for auto-enable?\n. I agree, but I think then it also makes sense to include upgrade_languages, doesn't it?\n. It's not urgent, and I saw your earlier change for brakeman too late to discuss it there. I just think we should figure out what the correct way to be consistent with these engines is moving forward: if we plan to auto-enable community engines at some point, we should probably include both enable_regexps & upgrade_languages. If we don't plan to auto-enable community engines, we should probably include neither.\nAnd brakeman is an interesting specific case because you're earlier PR made a comment about Brakeman not being appropriate for all Ruby projects. In which case maybe we should adjust the enable_regexps for it.\n. This comes pretty much directly from the project page, and we try to copy/imitate official descriptions where possible.\n. I think you probably want this quoted in case of spaces. (Possibly ditto for the codeclimate_path)\n. I don't see any error handling for if this is missing right now: seems worth adding since not all engines are going to have this file immediately.\n. You're only using taking advantage of this default value in one place, and I personally find the idea of calling say without params a bit surprising when reading the calling code. Is this really better than being explicit at the call site?\n. Aborting the entire program as soon as you hit one missed issue seems harsh. I think it would be more useful to act a bit more like a test suite & emit all issues (hits or misses) before exiting.\n. That snippet results in \"\" in irb.\nI'm pretty sure the only way you can get a nil in ENV is if the Ruby process explicitly sets it.\n. We probably want to add back upgrade_languages here: the upgrade languages are an and condition with the enable_regexps: classic repos need to trigger both to get the engine.\n. Yeah, if this default configs is the desired behavior, I think it should be a successful output exit code & message. I would suggest outputting the informational message about not changing .codeclimate.yml first, and then generate the default configs.\nThis can & probably should actually be refactored to be part of #create_codeclimate_yaml behavior. Putting it here makes behavior kind of strange in that codeclimate init will not touch .codeclimate.yml, but will touch default engine configs, whereas codeclimate init --upgrade will refuse to generate default engine configs if .codeclimate.yml already has engines.\n. > What was our original reason in favor of going with the exitcode 1 when there's no .codeclimate.yml\nThe logic predated me, but it was failing with exit code 1 if .codeclimate.yml already existed because init's primary purpose was to create that file.\n\nWhat would you think about something more neutral like .codeclimate.yml already present, skipping generation\n\nI think that sounds fine (#warn seems appropriate for the output). The verb \"generation\" would not be appropriate for the --upgrade case, though: it seems like you'll need another *_verb method on the generator class to distinguish between the generaion/upgrade cases.\n. Ah, neat, added.\n. Oh, good point. So co master; pull; version=...\n. Good call. That is much more effective.\n. Yep, you're right. That was my intent but I messed up my boolean logic.\n. Seems reasonable to me.\n. :lipstick:, but looking at this now I think it would be nicer to read as [t_timeout, t_out, t_err].each { |t| t.kill if t }\n. Ah, good point, but, that being the case, I'm not sure the existing code is correct either: t_out.kill if t_out will also raise an exception if t_out never got defined. We'd want to either use defined?(t_tout), or switch to instance vars that have the nil-if-undefined behavior.\n. I do. The fact that tests passed with that dumb typo is worrying. Hmmm.\n. Oh, I think it was because those thread's aren't set to raise on exceptions.\n. I borrowed this from an example online, but my understanding was that $(\u2026) could hide a bad exit code? I can never remember how $(\u2026) and \u2026 differ.\n. Small consideration: I believe this will run make image again. Which should be fast since the image will already exist, but is doing needless work. Maybe we should just remove the build from dependencies and let it happen here?\n. There was a time when builder just ran codeclimate init using the cc binary. That may have used the docker image, so maybe this is vestigial to that?\n. This looks like debugging code?\n. Eh. Whatever. None of the solutions seem good.\n. Thought of something else about why this kind of bugs me: I agree with Devon that having the desperate step in circle is nice. And I also agree having the task be dependent in the Makefile is important. I think doing both is a false advantage because, yes, you have the build in a separate step, but you are also polluting the test step output with the same build output all over again (except that every later will be cached), which is bad.\nSo on balance I still think we should either have separate circle steps or Makefile dependencies, but not both. Personally I lean towards keeping the Makefile dependencies since that seems like a more important use case for local development.\n. If we're going that direction that much, I would propose calling the task test_only, and then declaring test as just test: image test_only with no other content.\n~will out.\nOn Dec 11, 2015, 10:15 -0500, Devon Blandinnotifications@github.com, wrote:\n\nIncircle.yml(https://github.com/codeclimate/codeclimate/pull/265#discussion_r47364882):\n\n\ntest:>override:>- - bundle exec rake>+ - make test\n\n\nAll good points. What do you think of a separate Makefile command calledcitestthat does not have theimagedependency?\n\u2014\nReply to this email directly orview it on GitHub(https://github.com/codeclimate/codeclimate/pull/265/files#r47364882).\n. I'm ok with this. You've explained it thoroughly enough. I wonder if it would be more reliable to poll for whether the container pid is still alive? Probably not worth it.\nOn Dec 11, 2015, at 11:49, pat brisbin notifications@github.com wrote:\nIn lib/cc/analyzer/container.rb:\n\n\n\nKnown:\n\n\n\n\n\n- The docker kill succeeds\n\n\n- The container process exits with SIGPIPE and no exit code\n\n\n- Therefore, the assertion on the exit code fails\n\n\n\n\n\nTheory: docker kill succeeds, but the container hasn't actually\n\n\nstopped when we go ahead and kill the output reading threads. The loss\n\n\nof the output readers causes the still-running container to SIGPIPE\n\n\nwhich causes the result to not have an exit code.\n\n\n\n\n\nThis sleep is a bit of a hack, but passes the specs. It shouldn't\n\n\nnegatively impact production as we're already in a kill scenario, so\n\n\nsmall delay between killing the engine and killing the output reading\n\n\nthreads doesn't strike me as a huge deal\n\nsleep 2\n  Interested in folks' thoughts here. If we feel this is too hacky to commit, I think I'll have to abandon this approach. Without some sort of delay after the kill, it fails reliably on Circle.\n\n\n\u2014\nReply to this email directly or view it on GitHub.\n. I'm :+1: on @pbrisbin's approach. That was the direction I was trying to move in.\nOn Dec 11, 2015, at 14:28, pat brisbin notifications@github.com wrote:\nIn lib/cc/analyzer/engine.rb:\n\n@@ -34,8 +34,12 @@ def run(stdout_io, container_listener)\n         )\ncontainer.on_output(\"\\0\") do |output|\n-          unless output_filter.filter?(output)\n-            stdout_io.write(output) || container.stop\n-          next if output.blank?\n  +\n-          issue_hash = IssueHash.new(output)\n  Mentioned IRL, but for visibility:\n\nI think we should go with an actual Issue class we can pass around and filter on that responds to methods. Then we #to_json that for the stdout_io.write call.\n\u2014\nReply to this email directly or view it on GitHub.\n. I prefer this over method missing.\n. I don't think it'd muddy the diff that much. Might as well do it now if it's better.\n. Agreeing with @GordonDiggs on this: I think it's better to be explicit and only push the release we care about.\n. Very good point: we actually had a debug tag of mine on docker hub already because of this! Fixed.\n. There's a bit of an edge case with this idea for when users are locally developing new engines. Maybe not worth thinking about that edge case. Even ignoring that I feel this is kind of a non-feature and not very worth the coupling & implementation effort.\n. I'm not sure it's best for us to split commands to the point where they have entirely different dependency trees. That seems like a good way to some day introduce bugs & inconsistent behavior from updating some commands and not others.\n\nFWIW, git doesn't structure itself this way: shared dependencies are \"global\".\n. I realize this command does not currently recognize other flags, but depending on it being the first arg doesn't seem awesome.\n. I don't think I'm a fan of losing the VALID_CONFIG_MESSAGE (at least I think it's gone?): without it, the happy path has no output at all, which could be confusing to end users.\n. Our option parsing is kind of an ad-hoc mess in general. Maybe we should actually use something like OptionParser?\n. This take is probably fine for now, but right now I think one of the important missing features in the CLI is support for subcommand --help or help subcommand. I think supporting both of those is important.\nActually I guess this script could implement the latter one by just...running subcommand --help, so I guess it's really just the former case we should be addressing.\n. Glad to see this extracted :+1:.\n. Is this a related change or related to https://github.com/codeclimate/codeclimate-rubocop/issues/39? Feels like it should be extracted unless there's a closer connection to the workspace work I'm missing.\n. Actually, thinking on it, it feels like this fix belongs in cc-yaml: if we intend to allow config: file-name, then cc-yaml should not presume the type of the config key.\n. This spec may be better suited to a different rake task outside of test -- it's not a traditional spec in many ways. But since we got into our previous bad situation via a number of well-intentioned steps that led us to an unfortunate position, I wanted some kind of automated check to prevent this performance getting out of hand again.\n. Yes, probably -- I also turned up some unexpected things about the size of the generated workspace while porting this to master (master did blow well past the 10 second mark at about 2 minutes, FWIW), so I think this spec needs some attention overall.\n. Good point, thanks. I had added it back, but I just reverted it.\n. This falls into the same category as our long slack convo. You could have an old exclude pattern that no longer applies because you deleted a directory, or maybe it only applies to local files and you're running in .com, or maybe you made a typo. I don't think any of those cases are worth being overly noisy about, but I think they are worth having a message about in debug/verbose mode.\n. Also for the cases where you might give the style of paths that PathValidator used to cover -- if you run something like analyze /root/path or analyze ../../not/in/the/project/repo, this will provide feedback about why that didn't work (albeit only with debug visibility).\n. They're in separate commits to make review easier, if that helps. I can extract the rename commit as a separate PR if you'd like.\n. Bummer: I was doing a fair amount of rebase editing & must have fouled something. Sorry, I'll redo.\n\nI still can't see where you fallback to config-generator when existing_cc_config doesn't exist, but maybe I'm misunderstanding the intent (because of the diff confusion?).\n\nI don't think that case exists, and I did not intend to implement that behavior. If the YAML already exists, it already exists, yay. If it does not exist when you run init, #create_codeclimate_yaml will write it, and again it will exist before #create_default_engine_configs is called.\n. You're right the || bit is pointless: I'll remove that. We do an existence check up above, though, specifically so that we do memoize the false case.\n. Will do.\n. Looks like we're missing the rest of the command here?\n. In the past we've seen zombie engines that continued to run even after being killed. If that were to happen, this would result in builder effectively zombieing as well as it would wait for something that isn't actually going to die. That might make a zombie engine more visibile, which would be good, but it might also just make the problem worse. Thoughts on that?\n. That makes sense to me!\n. Good point. Updated.\n. I favor the second, at least for the time being. I think wrapping up our spawn logic somewhere might be useful, but I think getting better user-facing errors out is important, so I'll focus on that for now.\n. If you're suggesting that attempting to exclude a non-existent path should blow up, we can't really do that. The use case is that you may have files locally you want excluded, but those files may be in your .gitignore, so they won't exist on .com.\n. We've tended to do it on other engines just because it makes it an easier change if we decide we do want to enable them by default, I think. The same question would apply to the enable_regexps field, and we add that for every engine.\n. Am I correct that this is only false for local dev/local tests? If that's the case, I'd suggest dropping it completely & making sure tests provide appropriate ENV. Since docker is the CLI's natural environ, special-casing for the other case (esp. if it affects tests) seems like it makes tests less honest.\n. Bleh, you're right, I didn't think it through all the way. Yeah, this seems like the less troubling option.\n. Nit, but right now we don't have spaces between engine definitions. Seems like a nice addition to me, but if we're going to do it I think we should do all of them at once.\n. :lipstick: description fields should be full sentences with periods at the end. Or interrobangs if you're feeling whimsical\u203d\n. I think this should be sorted after scss-lint, shouldn't it?\n. Good point. Other descriptions in the file are currently fragments, so for now I think just adding the period is fine, and we can wait for @scriberty to decide it's bad & needs changing.\n. Oops. Builder might have been my bad, sorry.\n. Is this actually used right now?  Since #debug doesn't follow the same contract as ruby's Logger, I don't see a reason for a shim like this unless we already have usage relying on it (which I don't believe we do).\n. This was discussed a bit on #312 when this was implemented. existing_cc_config is guaranteed to exist when this is called: either it will have been generated by this class just now, or it already exists (and was upgraded from classic, if it needed to be).\nThe crash that did occur was that engines is nil instead of {} in CC::Yaml when it's empty. Maybe that should be fixed instead.\n. > WDYT of gsub(/[\\n\\t]/, \" \")?\nCould do, but I'm hesitant to eliminate information about the kind of whitespace present in something calling itself a debug mode. That whitespace could also be present within the issue, where it's kind may be more important to interpreting the results.\n\nThere's also JSON.pretty_generate but I think you want it to all be one line?\n\nWe definitely want this on one line. Also, this debug output is before anything else has tried to parse the output has JSON, I believe. I wouldn't want invalid-engine-output to start raising from here instead of from where we want it to.\n. We could simply not escape it: I'm not escaping it in stderr below right now.\nThe only downside of that, for me, is it can be less obvious where engine output begins or ends when it has leading or trailing whitespace.\n. > You could wrap it in quotes to make that more evident if that would help\nI was considering that, but I think we need a delimiter other than quotes, since pretty much all engine output will contain quotes.\n. I think we're supposed to freeze these individual values.\n. There's an interesting ordering issue here that might prompt us to not sort all of these alphabetically: checking for path presence after checking for path existence seems wrong to me.\nI think either we should re-order these to presence -> relative -> existence (and add a comment explaining why), or collapse all of these into a single IssuePathValidation.\n. API nit: most ActiveModel-esque interfaces allow you to call #valid? without explicitly calling validate. Should we do the same? It's our own little world, so we don't have to, but OTOH it seems like something likely to trip somebody up down the road, and IMHO it is a nice little feature.\n. Is this worth keeping after shipping this? Won't the CLI very quickly be echoing the above messages telling you that it's invalid?\n. I think there's a not-great edge case here for issues that are unparseable: the IssueValidator get's initialized with nil, which then hits this branch because issue && invalid_messages.any? also evaluates to nil. Is the unparseable case still covered somewhere that I'm just not seeing in the diff?\n. From an API design perspective, I guess I also question whether considering a nil issue \"valid\" is semantically a good idea. Personally, I don't think it is.\n. Fair enough. I see the other two validations are well guarded against nil paths, so that makes sense to me.\n. Sounds good. I agree about not having an extra validation be better. I had seen a rescue in the diff, and forgot that we do that parse elsewhere without the rescue.\n. Still a bit squirrely about considering nil to be a valid issue, though :)\n. Should there be an else after this to add an error in the event that the location is completely invalid and doesn't have either? Is that covered anywhere else?\n. There's a NoMethodError risk if an engine does something really dumb like emit positions: \"foo\". Maybe not worth addressing.\n. Oh, wait, you're implicitly returning nil if neither of these checks is true, which counts as not valid. Right? Nevermind, then.\n. Should we also do the IssueRelativePathValidation here?\n. Any particular reason we're only supporting lines, and not positions?\n. You might find the SourceBuffer class helpful.\n. Nit: there is a lot of hash access going on in these two fingerprint classes. Would it be nicer in the long run to add more accessors to Issue?\n. I think our spec is pretty clear that these values should be numbers: I would not consider an engine sending us anything else as compliant, personally, and there's always bad edge cases with casting. I'd like to know which engines would be impacted by this change & action fixing them before shipping this, but IMHO this is a positive change.\n. relative_path_from doesn't behave very well in terms of trying to resolve a relative path in terms of an absolute path: it errors out. I don't think that's really what it's intended for anyway, since it doesn't actually touch the file system, it's just manipulating the path independent of the real FS.\n#cleanpath may be useful: you could check that path == Pathname.new(path).cleanpath.to_s.\n. Q: how does it handle dangling symlinks? (a symlink that points at a non-existent file.)\n. > I'm interested in having an in-chat conversation about how we have decided / are deciding to \"address symlinks\". I think there's some nuance there and I know we've fought this battle before.\nDefinitely worth having a discussion (maybe in-person tomorrow at this point). I think our hand is being forced a bit now: we've fought parts of this battle before, but also continually deferred the war (so to speak). With these stricter validations, and the behavior of content-based-fingerprinting, we now must \"handle\" symlinks in one way or another.\n. Any reason not to use Pathname#expand_path? I think it pretty much would basically replace this whole method from what i've tested of its behavior.\n. Should probably validate this after presence & relative path validations?\n. ~~This is false for symlinks. That's a kind of significant product change that should probably be discussed.~~\nI was wrong above. It's false for dangling symlinks, but true for valid ones, so I think this is fine.\n. > Like latin, order does not matter here.\n\ud83d\udc4f \n. \"Trust but verify\".\n. \ud83d\udc84 this list should probably be sorted, as should the autoload list above.\n. FWIW the return value of lets are memoized by rspec, so I don't think the || is doing anything for you here?\n. I disagree with Rubocop on this because I prefer functional transform chaining to temporary vars. Other people's opinion?\n. I totally forgot about the &method trick in this case. That'll probably work here for now.\n. Honestly not sure. It doesn't comply with the spec, though, so may as well catch it?\n. I guess there's a valid question of \"if this doesn't cause issues, how common is it currently in the wild?\"\n. It is valid to omit. It is not valid to include with a null value. Minor semantic difference. I'll check secondary tomorrow.\n. So db.smells.count({ content: { $exists: true, $in: [null] } }) is not going to run in a reasonable amount of time (my connection got broken by fab after an hour or so). Can't do mapReduce on slave (apparently), so I don't know of a good way to \"background\" the job. Any other ideas about how to query for this?\n. Got back to this today. For future reference, it seemed like I had to provide an index hint to count to get a response in reasonable time.\ndb.runCommand({ \n   count: 'smells',\n   query: { _id: { $gt: ObjectId('577144910000000000000000') }, content: { $exists: true, $in: [null] } },\n   hint: { _id: 1 }\n})\nAnyway: no issues in the last day that matched this query, which seems like a large enough data set to me. (That's ~88.7M issues.)\n. This is human readable, so I think we can use some commas here.\n. Oops, thanks.\n. We also exit 1 when analysis errored (which we unfortunately chose to call \"failed\" in Formatter). To distinguish those cases maybe we should exit with a different code for this case?\n. We could use 170 for for \"analysis failed/issues found\", and do increments of 10 for each category when we do error-class specific status codes. (e.g. 180 for a G10, 181 for a G11, 190 for a C10, etc.)\n. We could, probably: I think keeping them unique at the CLI level is desirable, though, if we're going to differentiate them at all. The grouping-by-10 suggestion is primarily so that each category would still be contiguous if we decided to add a new code to a category.\n. Oh, got it. You're quite right about G. I think E timeouts vs errors would still be CLI territory: CLI already knows about timeouts & in the \"thin-builder\" world I think that might continue to be the case?\nYeah, not relevant for this PR anyway: just starting with 170 here is plenty.\n. @pbrisbin You were on the right track with thinking there was a method name collision, but the collision was (surprisingly) with #prepare, not fetch. Node#prepare in cc-yaml is basically a method nodes can use to set themselves up with initial state. So when the code here called config.prepare (what I had originally), it wasn't fetching my Prepare node, but calling the default empty #prepare method which returns nil, resulting in thinking there were no fetch entries configured. Using #[] is a workaround here to actually access the node we want :hurtrealbad:.\nAs for why the presenting symptom was silent RSpec failure, I've addressed & explained that in 7e302d3.\n. I got the following error locally running this against https://github.com/codeclimate/codeclimate-rubocop:\nerror: (NoMethodError) undefined method `uniq' for \"30\":String\n[DEBUG] backtrace: /usr/src/app/lib/cc/analyzer/formatters/html_formatter.rb:202:in `location'\n        (erb):660:in `block in render'\n        (erb):653:in `each'\n        (erb):653:in `render'\n        /usr/lib/ruby/2.2.0/erb.rb:863:in `eval'\n        /usr/lib/ruby/2.2.0/erb.rb:863:in `result'\n        /usr/src/app/lib/cc/analyzer/formatters/html_formatter.rb:176:in `render'\n        /usr/src/app/lib/cc/analyzer/formatters/html_formatter.rb:277:in `finished'\n        /usr/src/app/lib/cc/analyzer/engines_runner.rb:25:in `run'\n        /usr/src/app/lib/cc/cli/analyze.rb:20:in `block in run'\n        /usr/src/app/lib/cc/cli/analyze.rb:18:in `chdir'\n        /usr/src/app/lib/cc/cli/analyze.rb:18:in `run'\n        /usr/src/app/lib/cc/cli/command.rb:24:in `execute'\n        /usr/src/app/lib/cc/cli/runner.rb:22:in `run'\n        /usr/src/app/lib/cc/cli/runner.rb:8:in `run'\n        /usr/src/app/bin/codeclimate:6:in `<main>'\nLooks to me like lines returns the array you want to uniq.sort.join, but positions returns a string already.. There are several items commented out in this list that we do support some engines on, so I'm curious what the thinking was behind leaving some of those here commented out: do we not have the necessary plugins or whatever to actually do syntax highlighting on some of them?\nI can take a scan & give a more specific list of which ones we should probably have enabled if that's appropriate/we can actually highlight them.. other_locations can also be either the lines or positions format. It doesn't look like this supports positions?. What's -bug here for? It doesn't seem to match the classes elsewhere in the markup, and the engine filter dropdown doesn't seem to be working for me locally, but removing -bug fixed it.. Would it be possible to get an empty state for when there are no issues to show?\nThere is, of course, the overall case of no issues having been found at all, but it's also possible to reach an \"empty issues\" state by selecting a combination of engine/category filters (e.g. style/duplication will yield no results for any repo that happens to include both style issues & duplication issues): it would be great if we could also show some copy for that instead of just a blank page.. Ahh, right, I saw that default-val code but didn't make the connection. Thanks for the explanation.. > Is this documented anywhere?\nYes, the spec covers this. Sorry if that wasn't explained earlier in the process or if I saddled you with fixing a pre-existing bug in this instance.\n\nI wonder how this is reflected in the UI\n\nPlain list (which I think is what you went with?) is totally fine.. Are these data-line-offset attrs actually used? It looked like 9ba3a28d4ccc2baec8fbd8b3c06439691c005254 removed the JS referring to them. Does prism use this internally or something?. \ud83d\udc84 you have two spaces before the = here.. Based on the mess we got ourselves into with cc-yaml, I'm inclined to say the \"parse\" stage should effectively produce a plain YAML object (maybe with some very light type-checking/coercing), and extracting semantic meaning from that YAML is a separate stage. Which it looks to me like what you have here, so I think this is a good direction.. Although having said that I'm wondering how we'll end up structuring \"validation\" of config to give user's reasonable errors.. We did more strenuous validation of the path being safe for security reasons in the old impl. I think we want to keep that.\nhttps://github.com/codeclimate/codeclimate-yaml/blob/master/lib/cc/yaml/nodes/fetch.rb#L51\nLess critical, but the new impl here also doesn't prevent path ending up as \"\" in several ways. I assume that will blow up at File.write, but it may be worth validating earlier.. Yeah, that's where I figured we'd end up. I was more thinking that we don't want to totally divorce that validate logic from the data munging in these `CC::Config::* classes. So maybe they'll raise exceptions or set error flags & the top-level config building runner will catch/use those and validate-config just builds the config & echos errors?. Oh, man, another case where we've just been always exiting 0 no matter what? Good catch to fix.. I like the change to only coloring the \"type\".. Pretty sure you want %w: %[ is just a string of everything inside, not a space-separated array.. \n. @ABaldwinHunter that lives elsewhere, as part of Config.. \ud83d\udc84 these descriptions should get punctuation at the end. That's coming! I'm trying to make smaller changes so the diffs don't get too crazy with just name changes. I'm happy to keep pushing on this branch in commits if you'd prefer to review that way.. Because the JSON hasn't been turned into an Adapter of the same style yet. It will be. . Both of those are defaulted as expected within Engine.. We're pruning entries that do exist. The validator constructs all engines, deletes ones that are valid, and reports on the remaining ones.\nI am planning to rebuild the validator in depth after stabilizing the rest of this: the current changes here were to keep specs passing/behavior consistent in the short term.. Changed, good catch.. Mentioned in a commit message, but we don't need these anymore: duplication provides a default itself if one is not configured.. Fair enough: I had favored erroring hard since it's a state that really isn't supposed to exist & warnings aren't the most user-obvious feedback if there aren't errors. But you're right, so I've pushed a new commit addressing that.. Test added, will merge on green.. Ack, this wasn't meant to be in here at all, thanks for catching. Fixed.. These fingerprints were all based on reading the source of lib/cc/analyzer/config.rb, which I've deleted, so they changed here because I moved the relevant source to a new fixture file.\nI am so mad that anybody ever thought it was a good idea to write tests that relied on an unrelated source file not changing :hurtrealbad:. Unfortunately, that initial bad idea bled out into several specs.. This data was already basically identical to the contents of Factory#sample_issue, may as well use it instead.. This factory has had the wrong key for a long, long time. Nice.. d'oh, I meant to type exclude_patterns. Fixing.. Version should change really rarely. I'm inclined to leave it messy since any version bump would probably radically change the organization of this parsing/validation, so leaning on DRY now would probably just make that potential future action harder.. If you pass -e foo -e bar, you only want to disable all the engines one time, otherwise you'll only end up with bar enabled.\nThis logic was inline in process_args: I extracted it to a method, and kept the once-only guard here since otherwise it didn't seem worth extracting.. Done. Well, if they're primarily CLI users, they can't yet, so I don't want to say that yet.. I like that this allows us to add future validations with less boilerplate code around which validations to run: we have the same bit of code in IssueValidations, so I'm also in favor of treating the two things the same.\n\nI wonder if there's a potential bug here if we added a helper module\n\nWe have specs asserting the validations that are run, so that seems unlikely.. I also feel like the current pattern is ugly, and definitely would want to do that extraction if we add a third type. I don't see it as absolutely necessary to do for this current change, and didn't do it since I didn't come into this with a very strong idea of what that new type would be called/look like. If you have a good idea there, I'm happy to do it now.. What do you mean by \"authenticate with gem push\"?. Got it.  It's fine as-is, I did not realize that was how RubyGems actually suggested logging in.. Done.. I think we'd like to keep the --dev flag documented here, please.. This is not really a supported command, despite the code still existing for it. We don't recommend engine authors use it, so I think we'd like to keep it out of the README.. Yes. test is not encouraged to be used, and we'd prefer to leave it undocumented.. ",
    "noahd1": "Test and it worked for me.\n. :shipit: \n. We pushed the image to Docker Hub.\n. Alternatively, don't run the docker pull during install, but print post-install instructions to do so.\n. Good idea. Unfortunately it looks like \"OR\":\nhttps://github.com/codeclimate/codeclimate/blob/master/lib/cc/cli/config_generator.rb#L63\nBut we could extend the pattern to look for ruby files in app ... \napp\\/**/*.rb\nThoughts?\n. Makes sense. Good catch.\n. @GordonDiggs ready for re-review\n. That's a good point -- but there are still cases where they aren't figments of autogeneration, right?\n. I'm working my way up to objectionable. Just you wait.\n. I have only seen 1 case of it to date so we could wait. My initial thought was \"what's the harm if there's little chance of a false positive.\" However, I guess that doesn't preclude us adding \"*-my-mega-optimized-tiny-file.js\" and whatever weird other conventions people have.\n. Removing minified pattern for now.\n. /c @codeclimate/review \n. It was worker IIRC (after removing the existing .codeclimate.yml)\n. 10 seconds is prettttty slow! Nice work.\n. \ud83d\udc4f . I would make this a constant\n. I think this would read better on multiple lines\n. I think it might read a little cleaner if you call the method exclude_paths  and have it take in an argument AUTO_EXCLUDE_PATHS\n. All good suggestions. Just waiting for someone (@brynary) to tell us why this is a bad idea first.\n. Thoughts on creating an initializer which takes an image name? It just seems strange that only one of the log methods takes an image but they all relate to the same image.\n. Do you want to suffix it with _BYTES so the unit is understood?\nAlso, maybe a constant for the default?\n. ",
    "ABaldwinHunter": "@codeclimate/review @noahd1 thanks for feedback. I added your suggestions:\n1) made a constant AUTO_EXCLUDE_PATHS\n2) refactored exclude_paths method to span multiple lines\n3) and take AUTO_EXCLUDE_PATHS as an argument\n. Hi @laszlof. Thanks for your feedback! We updated codeclimate to output analysis results as a single JSON object in version 0.0.19. If you're using homebrew, you can upgrade by running:\nbrew update\nbrew upgrade codeclimate\n. @laszlof We updated codeclimate to output colorless text when analysis results are piped to a file. Try upgrading with the same commands above. I'm going to close this issue now. :)\n. Hi @kevinburkeshyp. I am looking into this issue and having some trouble replicating it. The codeclimate.yml you have above looks good to me.\nI think you might need to upgrade your version of codeclimate. I'm running 0.0.6.\nTry brew upgrade codeclimate to update if you're using brew. Otherwise, you can also try docker pull codeclimate/codeclimate to pull the most recent image.\nLet me know how that goes! \n. Heads up that this PR also updates the .codeclimate.yml version in Gemfile.lock.\n. @brynary sure. The .codeclimate.yml had been empty. I just merged PR updating that so we should get feedback now. \n. @pbrisbin: thanks for feedback. I made the set_local_owner method refer only to the path_for(CODECLIMATE_YAML), and created a stat method that's memoized in Filesystem class, instead of memoizing the gid and uid calls. \n. @pbrisbin: sounds good. blank line added. \n. @GordonDiggs sure. link to compare:  https://github.com/codeclimate/codeclimate-yaml/compare/old...master\nAnd most important changes:\n\n. LGTM -- but maybe wait for other feedback. :)\n. @pbrisbin looks like we only have a test for plain_text_formatter. Might be useful to have one for json as well. \nEdit: what would we be testing there? Mostly that it produces a valid json at the end?\n. @codeclimate/review ready for re-review. I added tests and made refactor suggestion.\nLargest worry is around tests: I think the goal of testing the JSONFormatter - esp post new changes, is to make sure valid json comes back.\nHence, one of the tests just checks that output is precisely the string expected. Not sure if that is too brittle or okay.\n. @codeclimate/review @GordonDiggs Added a test that checks that specifically the stdout result can be parsed as json. Alack, my investigations suggest that Minitest may no longer support #must_not_raise or #assert_nothing_raised assertions.\n. @GordonDiggs yes, was just realizing I didn't post anything.\n```\nAshleys-MacBook-Pro:codeclimate ashleybaldwin-hunter$ bundle exec rake\nRunning tests with run options --seed 54645:\n.............................................................\nFinished tests in 0.169189s, 360.5435 tests/s, 957.5091 assertions/s.\n61 tests, 162 assertions, 0 failures, 0 errors, 0 skips\nAshleys-MacBook-Pro:codeclimate ashleybaldwin-hunter$ \n```\n. @pbrisbin @GordonDiggs Thanks for the feedback! And @brynary thanks for the feedback earlier. \nI believe I responded to all comments: \n1) updated wrapper script to abstract out adocker_run method\n2) move conditional spinner use out of formatter into spinner#start method\n3) refactor unless statement\n. see https://github.com/codeclimate/codeclimate/pull/57 for updates to gem file\nedit: updated cc-yaml in Gemfile.lock in this branch without changing other gems and specs pass. Deleted pull 57 ^^\n. The error parsing doesn't work appropriately. Fixing bug. \n. @brynary @benjaminwood @ktowle Progress is indeed underway! \ntl;dr By the end of this week, we should be able to release a new version of the CLI supporting this feature.\nWe have a drafted solution that's close to being ready for release.\nSome details about implementation: \nIn the past, the CLI passed each engine present in .codeclimate.yml: a code directory, engine config, and list of exclude_paths. We've recently switched to an implementation (in part because of permissions issues on some files), that involves passing each engine include_paths to analyze (derived from the excludes) instead.\nThis change has made it much simpler to implement runtime analysis of particular files passed as args to codeclimate analyze. While some engines have already been updated to accept include_paths (codeclimate-eslint and codeclimate-rubocop for instance), a few others still need updating.\n. Update: this feature is now available with release 0.5.0.\nCaveat: only engines that have been updated to support handling of include_paths will support this feature.\nEngines that do support analysis of single files include codeclimate-rubocop and codeclimate-eslint. \n. Going to close this issue but please feel free to comment or reach out!\n. LGTM \n. @brynary @pbrisbin that sounds pretty good.\nAs an FYI or reminder for consideration- I think the reasons we went with inheritance originally was that at least half of the current collection of engines subcommands (remove, enable, disable) reference  only one engine. (engines:enable , engines:remove ). These subcommands are initialized with an @engine_name variable that reduces argument passing. \nThat structure might not make sense as our need for EngineRegistry and engines stuff in other places expands, but wanted to raise that thought. \n. @brynary @pbrisbin okay that implementation sounds good to me. Thanks for the discussion. \n. See https://github.com/codeclimate/codeclimate/pull/78/files for composition implementation. \n. P.S. First approach using engines:validate subcommand and discussion found here.\n. @codeclimate/review Ready for re-review. \nRefactored approach to use EngineRegistry class to check whether an engine exists.\nAdds engine_registry to Command class.\n. @GordonDiggs good points. Fixed.\n. @elwayman02 Thanks for the feedback and apologies for delay! We're looking into this issue.\nI'm surprised the error showed up there, because I see that you've excluded node_modules. I'd like to reproduce the issue. Are you able to share repo / is it public? \n. @elwayman02 Hm I notice that you've chosen to rate app/**, but exclude node_modules, which is under app.\nHave you tried adding /app/node_modules/**/* to exclude_paths?\n. (The paths in exclude_paths should be relative to root)\n. @elwayman02 Ah you're right. That seems fine.\nTaking another look at the original error, it looks like this is a permissions issue. Are there any special permissions on that directory?\nRelated issue: https://github.com/codeclimate/codeclimate-eslint/issues/3\nI'm investigating to reproduce locally. \n. @elwayman02 Thanks for bringing this issue to our attention. We realize that it's non-trivial and are investing engineering energy in a solution that creates a better architecture to how engines handle permissions issues.\nAs a short term fix, you can change permissions to 644 by running:\nchmod 644 dir/foo.bar \n. Yep. And chmod 755 foo to make a directory drwxr-xr-x\n. @elwayman02 Thanks for the helpful feedback. This issue seems specific to certain checks in Eslint. Could there be a plugin that you're using that creates those files?\nThere may be some workarounds with manually setting the permissions on files created in the directory, but we realize it's an issue with our exclude architecture.\nWe're working on a solution for this issue now. \n. @elwayman02 Thanks for the feedback! I'm sorry my suggestion created a new issue for you. We'll keep that information in mind.\n. @jacobi007 Thanks for your work! Someone from our team will review this PR soon.\n. @jacobi007 @codeclimate/review is this change related to the duplication work that @BlakeWilliams is working on or waiting on something else?\n. like arbitrary configs permitted in codeclimate-yaml, which we now have :)\n. @BlakeWilliams @jacobi007 Hm, yeah those look pretty similar to me.\n. @codeclimate/review @brynary Ready for re-review.\nUpdates: \n1) let a user pass an engine not in .codeclimate.yml config (fixed cc-yaml node bug)\n2) accept multiple file and dir paths as arguments\n3) leverage permissions-checking of IncludePathsBuilder and honor exclude_paths from .codeclimate.yml when analyzing requested file paths.\nPart three is the trickiest IMO, and any feedback appreciated!\nRe codeclimate issues: I think a refactoring might be in order, but outside the scope of this PR. (These changes seem like jenga pieces.)\nExample:\n```\nAshleys-MacBook-Pro-2:boggle ashleybaldwin-hunter$ codeclimate analyze -e rubocop app/models\nStarting analysis\nRunning rubocop: Done!\n== app/models/boggle_board.rb (17 issues) ==\n1: Missing top-level class documentation comment. [rubocop]\n18: Pass &:shuffle! as an argument to each instead of a block. [rubocop]\n6: Prefer single-quoted strings when you don't need string interpolation or special symbols. [rubocop]\n24-25: Extra empty line detected at class body end. [rubocop]\n6: Prefer single-quoted strings when you don't need string interpolation or special symbols. [rubocop]\n31-36: 5 trailing blank lines detected. [rubocop]\n18: Space between { and | missing. [rubocop]\n22: Space between { and | missing. [rubocop]\n18: Space missing inside }. [rubocop]\n22: Surrounding space missing for operator +. [rubocop]\n22: Surrounding space missing for operator %. [rubocop]\n22: Surrounding space missing for operator +. [rubocop]\n22: Prefer single-quoted strings when you don't need string interpolation or special symbols. [rubocop]\n22: Space missing inside }. [rubocop]\n22: Line is too long. [102/80] [rubocop]\n22: Prefer single-quoted strings when you don't need string interpolation or special symbols. [rubocop]\n22: Prefer single-quoted strings when you don't need string interpolation or special symbols. [rubocop]\n== app/models/score.rb (1 issue) ==\n2: Final newline missing. [rubocop]\n== app/models/word.rb (1 issue) ==\n2: Final newline missing. [rubocop]\nAnalysis complete! Found 19 issues.\n```\n. edit: removed v long comment. Realized that bug was a symptom of my local rubocop image not being up to date.\n. Closing for now.\n. @codeclimate/review @mrb @brynary \nUpdated to use severity instead of confidence in plaintextformatter.\nJSON formatter already works as is.\nPlaintext formatter sample output:\n\n. @brynary :+1:  \nFor a clarification: \n1) I think we decided that order of severity atm is\ninfo < normal < critical, translated from weak < medium < high in confidence terms.\nI'm assuming we want to print the two most severe, so did you want a name swap so that medium => info and weak => normal, or am I reading too much into your comment :) ?\n2) When the issue severity is weakest, should we omit that issue from CLI output entirely, or only the severity description?\n. :+1:\n. @codeclimate/review cc/ @brynary @mrb Ready for re-review. Formatting updated.\nI've currently stuck with this style:\n\nMore concise alternative:\n\n. @brynary @mrb updated post design feedback:\n\n. Going to close this branch for now to reduce noise. \n. Hm, I may not be circumventing the output filter. Going to take another look tomorrow.\n. Closing this PR for now because there's more urgent work. \n. Interesting. The order in engines.yml affects the order in which engines are written to .codeclimate.yml during init. Is that intentional behavior? And/or do we want to decouple those things.\n. @dblandin Ah got it.\n@GordonDiggs Hm I don't see a ton of benefit in maintaining an order in the generated config as the list of engines grows.\nBut I do see some value.\nIf we want that behavior, I like keeping the hierarchy knowledge somewhere else (or perhaps giving an ID or pecking order property to the engine).\nBenefit: engines.yml is easier to navigate and only acts as a simple source of information\n. Wdyt? (I can also side step for now)\n. @GordonDiggs @dblandin Fixed tests. Ready for re-review!\n. Pushed onto docker hub\n. Weird. tests pass locally \n``` CONSOLE\nAshleys-MacBook-Pro-2:codeclimate ashleybaldwin-hunter$ be rake\nRunning tests with run options --seed 20076:\n.......................................................................fatal: Not a git repository (or any of the parent directories): .git\nfatal: Not a git repository (or any of the parent directories): .git\n.............................................................................\nFinished tests in 6.460906s, 22.9070 tests/s, 61.2917 assertions/s.\n148 tests, 396 assertions, 0 failures, 0 errors, 0 skips\n```\n. @pbrisbin cool, I'm making a card for that. Refreshed build and tests pass.\n. @jpignata Thanks!\n. Late: but why don't we make this look more like https://github.com/codeclimate/codeclimate-rubocop/blob/master/circle.yml\n. Also, thanks for addressing this issue!\n. Okay cool. Thanks for the explanation.\n. LGTM\n. Thanks @GordonDiggs @wfleming for feedback.\nReady for re-review! \n. @wfleming thanks! haha I noticed that too. Figured it would be better fixed in a separate pr\n. LGTM\n. @wfleming thanks for the detailed explanation and feedback!\nOkay, I see what you're saying about the config. (Yeah, I was thinking those languages were coming from repo.languages not a traditional .codeclimate.yml).\nI still think it's an unusual edge case (and hope we move away from the upgrade logic once the crossover happens), but adding upgrade_languages sounds good to me.\nAdded.\n. LGTM\n. I'm late but second that. Nice catch!\n. @codeclimate/review @wfleming Ready for re-review.\nI updated the PR to return a warning that .codeclimate.yml is not found, instead of error.\nI left the behavior of init --upgrade the same because it seems separate enough, and perhaps desirable as is: at the moment, codeclimate init doesn't get called on .com unless the .codeclimate.yml file is missing or contains engines, so this change shouldn't have an impact there.\nLet me know what you think!\n. @GordonDiggs @wfleming fixed!\n. @BlakeWilliams can you fix the failing CI tests and also run codeclimate analyze under a few scenarios with the new docker image locally if you haven't already?\n. @BlakeWilliams as chatted about in slack, my concern is performance issues and I think it would be smart to cache some results of  one walk:\n```\nsafe_dirs = IncludePathsBuilder.new([codeclimate.yml_excludes + all_engine_excludes]).build\nIncludePathsBuilder::SAFE_DIRS = _\n```\nthen for each engine\nIncludePathsBuilder.build(includes, excludes)\nwill have an extra step\n```\nif SAFE_DIRS.include?(path)\n  engine_include_paths << path\nelse\n   drill down\nend\n```\n. Also as discussed, not sure if we'll abandon drilling down into each directory, in which case this performance difference would be negligible.\nBut see what other peeps think. \n. @fhwang @wfleming thanks for the feedback! I'm halting this branch in favor of engines QA at the moment, but can make the suggested changes later.\n\nwhat's driving this change?\n\nI actually just found a card for it in trello backlog of Engines board and - since I just worked on the init command, figured I would take a crack at it.\n. Okay sounds fine\n. @wfleming fine by me to remove it. \n:+1:  \nI don't feel particularly confident that it's checked. \n. @BlakeWilliams  looking now. Do exclude_paths still get respected when a path is passed to codeclimate analyze <path1> <path2>?\n. @BlakeWilliams wait\n. what manual testing have you done? I tried it out just now and am afraid that I see duplicate paths behavior\n. ```\nAshleys-MacBook-Pro-2:railsgoat ashleybaldwin-hunter$ codeclimate analyze -e rubocop lib/\nStarting analysis\nRunning rubocop: Done!\n== lib/tasks/server.rake (6 issues) ==\n6: File.exists? is deprecated in favor of File.exist?. [rubocop]\n6: File.exists? is deprecated in favor of File.exist?. [rubocop]\n6: File.exists? is deprecated in favor of File.exist?. [rubocop]\n16: File.exists? is deprecated in favor of File.exist?. [rubocop]\n16: File.exists? is deprecated in favor of File.exist?. [rubocop]\n16: File.exists? is deprecated in favor of File.exist?. [rubocop]\n``\n. @BlakeWilliams If we can't fix that problem, we should revert to before the minimization change\n. @BlakeWilliams I think they're related - it's how do you passpathstocodeclimate analyze` - whether they're files or directories\n. @BlakeWilliams nice work.\nIn general, I feel like the original minimize paths builder feature rebuilt some functionality that already existed, and I question that decision but it feels like a separate issue. \nI really like the added tests here and I'm happy that this update fixes the broken behavior on master!\nCan you compact the commits? Besides that LGTM\n. :shipit: \n. wow. so subtle. nice\n. Sounds good. I like it better than the original coffeelint change https://github.com/codeclimate/codeclimate-coffeelint/pull/12/files\n. @wfleming Nice.\nSo the idea is to let engines raise or warn when they encounter unreadable files, instead of CLI, to get clearer error reporting?\nThat sounds good to me.\nPerhaps we can drop the directory walk in the future, but I'm happy with little change first. LGTM.\n. Minor comment but LGTM. Nice sleuthing and explanatory commit message. So happy to have this bug unearthed. \n. LGTM\n. :+1:\n. @pbrisbin is the compare link correct?\nhttps://github.com/codeclimate/codeclimate/compare/0.15.0...ca4ef34\n. :+1:\n. example bugsnag https://bugsnag.com/code-climate/app/errors/562a8f5622e62149658053ac?filters%5Bevent.since%5D%5B%5D=30d\n. @pbrisbin Okay, I'll wait for @brynary's thoughts. I like engines being discriminate about what files they analyze as well, but in this case we're also passing them config files that don't actually belong to the repo. Figment of our autogeneration. \n. @noahd1 yes. But v few have seemed valuable. I don't think we have any engines that analyze config files ATM except fixme - and its finding of its own name has been deemed irksome. E.g. and here. (Agree that's more of a FIXME bug than CLI bug).\nWe may however have a yml linter in the future. \nFor me, biggest selling point is that the autoexclude paths only get generated if a user runs codeclimate init in the CLI.\nOtherwise, it gets run on prod when there's no codeclimate.yml.\n. @brynary at the moment there are no others outstanding.\nAgree it feels like this fix might fit better in the fixme engine. \nAlthough not a problem at the moment, it seems potentially hazardous to analyze generated files long term.\nI'll go ahead and close this PR for now in favor of a change to fixme.\n. amazing\n. @jpignata Interested in hearing @mrb's thoughts, but I like your idea a lot.\nAn intelligent render method sounds much smarter than my original suggestion. \n. Note: Other complexity checks are present but disabled (ABCsize, cyclomatic complexity, perceived complexity)\n. @jpignata Of course. Will do.\nSorry it's not in commit message, I commented above:\nNote: Other complexity checks are present but disabled (ABCsize, cyclomatic complexity, perceived complexity)\nFrom my discussion with @brynary, I think the reasoning is that the variety of complexity checks present several evaluation options which could be used in conjunction with one another, but would create some redundancy. (Imagine an inspector measuring building height and penalizing for being too high in meters, feet, and stories).\nFor a first run experience, class and method length were considered intuitive and thus good introductory units of measure. \n. Closing this PR in favor smaller increments, starting with a reordering https://github.com/codeclimate/codeclimate/pull/284\n. @jpignata Thanks!\nI agree on points, except I found the included cops or headings comment a nice overview (otherwise you'd have to scroll to see what sections were present). \nBut I removed it for now. \n. Fixes in place. Leaving commits while in review but can fixup at end.\n. @jpignata Thanks, that makes sense. I hadn't realized the config was exhaustive.\nFixedup. \n. @wfleming @pbrisbin thanks. These were discussed and decided on. \nI'm fine with any changes though - nothing's set until set. cc @brynary \nRelated point changes in codeclimate-rubocop: https://github.com/codeclimate/codeclimate-rubocop/pull/42\n. For some context / summary of discussion:\n- Main motivation is to make scoring more similar to Classic\n- These changes only impact the default .rubocop.yml generated during init\n- The remediation points for complexity violations are steeper in the PR linked to above. Effectively, default is that users don't trigger the complexity violation until a higher threshold, but when they do, it's an automatic C.\n- All complexity checks provided by Rubocop are included in our default config for informational purposes, but some are disabled. They're not necessarily meant to be used in conjunction with one another. Might create some redundant remediation scoring.\nThe Class and Method length checks seemed a more intuitive measure than ABCSize for beginners.\n@brynary correct me on any of the above. :) \ncc @jpignata \n. @codeclimate/review Note: I had the method length incorrect. Should have been 30. Updated.  \ncc @brynary \n. @KevinBongart Thanks again for your suggestion and moving the issue to this repo! \nThis feature has been on our radar. \nI look forward to reporting updates as soon as there's progress. \n. @KevinBongart Thanks for your work!\nCouple of things:\n1. passing engines the exclude_paths config key is deprecated in favor of include_paths, which get derived from the exclude_paths in a user's .codeclimate.yml. Passing your updates through the include_paths key instead should have the desired effect. \n2.  Performance: Building the include_paths has proven slow at times, and we have been thinking about a way to make that process more performant. Building them fresh for each engine - to accommodate per-engine excludes - with the current implementation could be inhibitive in terms of speed.\nWe're open to any suggestions! If you'd like to see the per-engine excludes locally, getting your change through the include_paths key should do the trick.\n. @KevinBongart Thanks for following up!\nThere's actually a related Pull under review now that revamps the way we organize file paths for analysis:\nhttps://github.com/codeclimate/codeclimate/pull/308/files\n. @pbrisbin applause for this work! I'm incredibly excited to have a revamped and simplified system for path handling.\nImmediate thoughts:\nThe good\n1) I like not worrying about permissions handling +1\n2) Having excludes in .codelcimate.yml filter through directories passed to codeclimate analyze is okay and expected behavior at present\nThe bad\n3) I'm not convinced that using paths instead of patterns is significantly more performant? and if the downside is that users can't exclude individual files, or use patterns in some cases, I don't love that.\nMy understanding was that the slowness came from drilling down into directories recursively. If we forget about permissions issues and forego the file-by-file tree walk, isn't that the major performance win? \ne.g. as you walk tree for exclude paths:\nexclude_paths:\n- spec/**/*\n- test/**/*\nAs soon as you realize spec is a directory, add spec to include paths, and stop drilling down.\nOnly users who care enough to exclude particular files or extensions get the slower behavior.\nHave you done any bench marking on different sized repos to see where the most time is spent? If the paths vs. patterns is only a minimal performance win, might not be worth it imo.\nBut overall, really love this simplification and happier to have the code in this state than previous one.\n. @pbrisbin Thanks. Great food for thought!\n\nI'm happy to look at some code if you could implement that optimization without removing what's present, but my suspicion is that it would mean complicating already complicated bug-risky code to accomplish.\n\nThat could be so. Going to think about an implementation. I had in mind originally our first tree walking algorithm, which had a good seam for checking if a path was a directory.\n\nI'm 50% concerned with this code because it's slow and 50% concerned with this code because it's has had numerous bugs, and the same bugs repeatedly. I want to ensure whatever solution we chose, we fix both aspects. Simplifying things greatly is the solution chosen here.\n\n:+1:  I'm on board with this sentiment.  Simple code with some loss  > bedbugs.\n. Nice\n. :+1:\n. I'd include a link to the RuboCop diff in commit message.\nOtherwise LGTM.\n. I think having v-35 in engine name instead of as a tag for now makes sense and would be fine.\nThat way there's no conflict with the way we use tags to identify versions of an engine.\nThis old rubocop engine we can think of as a separate engine under hood, instead of different version of the same imo.\n. @jpignata that sounds good to me!\n. Nice\n. @GordonDiggs @jpignata ready for another look!\n. @jpignata thanks! that was a good distinction to catch - I misunderstood the function before.\nUpdated.\n. @GordonDiggs Updated. Ready for another look!\n. One question that might be outside of scope: have we considered how we might handle permitting valid issues without location in the future - like a security vulnerability that says you're missing x file. ?\nOther than that LGTM\n. I hesitate over this change, because I believe it's moving in the opposite direction of what we want: a way to handle fileless issues gracefully - but I'm okay with it for the time being since I agree that:\n\nEmitting issues for directories is not something we currently support. \n. Makes sense. \ud83d\udc4d \n. nice\n. @pbrisbin Ready for another look!\n- added additional information about --dev\n- renamed the new section to Environment Variables (should we remove the intro about using\n  items in this section for debugging?)\n- enabled markdownlint and fixed related issues. (sorry - makes diff a little hard to read)\n. Hi @chollier! Cool. You can run the engine with docker run and pass it all of the env vars as you started doing originally.\n\nOr, if you have codeclimate CLI installed, you can build your engine and run it by including it in a .codeclimate.yml file or passing the name as an arg to \ncodeclimate analyze -e my-cool-engine --dev\nNote the --dev flag which allows you to run unofficial engines as you develop them.\nYou can build the engine from its directory:\ndocker build -t codeclimate/codeclimate-my-cool-engine .\n```\n$ docker images | grep my-cool-engine\n-> codeclimate/codeclimate-my-cool-engine              latest        0d7535e245ec        10 days ago         285.9 MB\n```\n. @chollier ah great. sorry I missed some of your original output!\nTo use a custom engine outside of codeclimate.com, you could build a modified image and run with --dev as you described.\nFor general eslint-3 support: we currently have an issue open on the codeclimate-eslint repo for supporting an eslint-3 channel. \nI'm going to direct you over there and close the issue here. Please feel free to reopen if something else comes up.\nApologies for the delay on the eslint-3 channel -we're eager to add support and plan to add a new branch supporting eslint-3 as soon as possible. If you have time and would like to, please feel free to open a pull against codeclimate-eslint master.\nFor your eslint-config-quri plugin, we vendor in particular eslint plugins but for security reasons don't automatically load all of your npm modules. I'd have to take a closer look to confirm but at the moment we probably wouldn't support that. \n. Nice fix. Hi @NullVoxPopuli! Thanks for writing in. It looks like your code isn't getting mounted into the codeclimate container correctly:\n\n[DEBUG] Couldn't include because part of path doesn't exist. path=\"./web\"\n\nTypically the codeclimate analyze command is passed a path relative to the root of the project you'd like to analyze. Then, that code gets mounted into a container at /code. \nHere's an example of invoking the docker run command directly passing the correct volumes. \nSome things to try:\n\nWhat happens when you run codeclimate analyze directly from the command line, within the root directory of your project?\nWhat happens when you update the volumes passed into the container to match the path set up in https://github.com/codeclimate/codeclimate#usage? For instance:\n\n```\ntest-server:\n  build: .\n  dockerfile: ./Dockerfile\n  command: npm run ci\n  volumes:\n    - .:/web\ncodeclimate:\n  image: codeclimate/codeclimate\n  command: analyze -f html\n  volumes:\n    - ./:/code\n    - /var/run/docker.sock:/var/run/docker.sock\n    - /tmp/cc:/tmp/cc\nenvironment:\n    - CODECLIMATE_DEBUG=1\n```\nHope some of that information helps. Let me know what those commands output.. > Personally, I think the error message approach is plenty, probably by just emitting a warning if any files expected to exist from prepare don't exist.\nThat seems like a sufficient solution.\nFWIW, running the prepare step seems pretty quick to me, so I don't see a huge downside. Further, one argument in favor of always running the prepare step when configured is that it's consistent with analysis on codeclimate.com. \nAlternatively we could pass a --prepare flag to analyze.\nAll that said, I think an updated error message will work. \n. Emitting a warning WFM. \n\nWhat about an --engines-install flag? \"Simple\" solutions are rarely actually that simple :).\n\nFWIW we do install engines by default when you run codeclimate analyze. This issue seems like a behavior suggestion that we don't want at the moment. I'm going to close for now. \nThe one valuable action item mentioned seems like better error messaging, but I'm not sure that it's valuable enough to action work at the moment - and maybe deserves its own issue if so. . this commit actually got merged in a separate PR. closing. @maxjacobson fair question! the only engines of which I'm aware that emit severity are Brakeman and Bundler Audit: normal, info, critical.\nA database query for distinct severity values on the relevant collection is unindexed and prohibitively expensive. Looking at https://github.com/codeclimate-community/submissions/blob/master/manifest.yml I don't believe there are any other engines about which to be concerned. If that's inaccurate we're most likely better off finding out and addressing - since those severities will not be supported. . @vesper8 you can use any regular operators on the output that's sent to stdout. So here you could try:\ncodeclimate analyze -f html > output.html\nand save it to a file.\nI'm going to close this issue for not but please feel free to reopen if anything else comes up!. Hi @konstantin24121!\nThanks for writing in. Today, a Code Climate engine won't make network calls to install arbitrary third party plugins during analysis. See https://github.com/codeclimate/codeclimate/issues/480 for an explanation of why.\nHowever, there's a workaround. Many engines come packaged with relevant plugins already installed. You can go ahead and open an issue or PR on the stylelint project  to add the dependency you'd like to use. \nFor an example, our ESLint engine supports a variety of plugins that has grown in number over time. Here's an example of a PR updating the list.\nI'm going to go ahead and close the issue here, since we have the general network access issue above, and the Stylelint engine repo is probably a better place to address adding this specific dependency.\n. Thanks for the feedback. Going to go ahead and close this as it appears resolved, along with https://github.com/codeclimate/codeclimate/issues/660.\nPlease feel free to reopen if you're still encountering the same issue.. @alxndr Thanks for opening this issue! It looks we actually fixed this bug recently here but it hasn't been released yet. I'm going to go ahead and release a new version!\nIn the meantime, please feel free to build the image locally to use the corrected version using make.. @alxndr just released 0.63.7!\nCould you go ahead try out the updated version?\nCheers. Meh I like to get another set of eyes on the sem ver decision. Thanks @maxjacobson . Basically we don't want to produce issue data that has normal severity any more. \nNote: this should not change the fingerprint because of the way the merge works. . Primarily impacts brakeman and bundler-audit. . > You want to modify CC::Config::Default.\n@wfleming thanks! I think you're right - that's what's used for analysis.\nHowever, this file appears to still be used - even in QM - for the codeclimate engines:enable duplication command.\nSo I think we want this change as well, right? Adding the other. @wfleming ready for another look!. > Specifically: what's happening is that Config::YAML gets parsed and sees a duplication engine, and defaults it to the stable channel when initializing an Engine object. Config later merges Config::Default, which specifies cronopio, but at the point the earlier YAML object wins.\nYeah. In my own testing, I ran into a confusing experience when I updated my .codeclimate.yml to use \nengines:\n  duplication:\n    config:\n      languages:\n      - java\nand inadvertently turned off java duplication analysis. Suddenly, 0 duplication issues found.\n@wfleming @nporteschaikin the points about the best place in the code for this change, and that many QM users probably won't configure the duplication engine in their .codeclimate.yml config are well made.\nI'll close this PR. Thanks for review. Nice fix. Fast turn around!. Hi @daften! Thanks for writing in.\nI believe to get those files locally, you'll need to run the codeclimate prepare step separately:\n$ codeclimate prepare\n$ codeclimate analyze\nIt's a bit hidden, but in codeclimate help output there's a description:\nprepare [--allow-internal-ips]                      Run the commands in your prepare step.\nCan you try that out and let me know how it goes?\nThanks!\nAshley. sounds good to me\n. although is it undesirable that in that case we're repeatedly setting @has_begun to true?\n. cool\n. @GordonDiggs do you also like that better than:\n``` ruby\nif @has_begun\n  print \", \\n\"\nelse\n  @has_begun = true\nend\nprint document.json\nend\n```\n. sorry for quibbles! Just wasn't sure the best way :P maybe there's none. \nthe perfect is the enemy of the good \nI'll stick with your suggestion. Currently working on tests.\n. @GordonDiggs that sounds good.\n. that makes sense. Added that refactor\n. sure.\n. I tested locally by running ./codeclimate-wrapper analyze > test.txt and ./codeclimate-wrapper analyze, and both worked correctly. That said, I'm pretty new to bash scripting - mostly started with Pat's suggestion above - so welcome other suggestions! \n. @brynary I think you're correct. I could make that change and bump version?\n. It looks like right now our codeclimate-yaml gem throws an error when this is called. It's:\nNameError: uninitialized constant CC::Yaml::Parser::Ruby\nshows up in two spots\nI think it's a mistake in cc/yaml. Looking into fixing.\n. I like the suggestion of using CC::Analyzer::EngineRegistry.exists?(engine_name).\n. Ah nice catch. CC::Analyzer is already included in the EngineCommand class so Install has access. Not sure why I added Analyzer here. \n. Okay, yeah I thought about that too. \nSounds good.\n. @pbrisbin this is probably a ruby syntax I'm not familiar with, but just wanted to make sure the absence of a value here was intentional.\n. Cool. thanks for explanation!\n. Put include_paths at higher level than exclude_paths method because the former uses the latter, but maybe noisy change here. \n. Yes that sounds good! thanks!\n. okay that sounds good\n. :+1: good call\n. :+1:\n. :+1:\n. This setup defaults to inclusively reporting the severity if it does not fit one of our expected levels [info normal critical].\nAlternative: exclude severity unless critical or info\n. I think {} is slightly better than [] for the default engines, because it's usually a hash not array\n. Okay sounds good. Making change.\n(I mostly cargo-culted from radon's self description)\n. @wfleming Good question. I included the enable_regexps because that seemed to be the pattern present for the other community engines, like gofmt.\nHowever, I personally think we'll auto-enable certain community engines eventually and I'd advocate that.\nThat seems like the way we'd offer the same easy first-time-analysis-without-config experience to users with projects in languages like python, and go\n. @wfleming Ah sorry saw this too late!\nI'm happy with either way.\nI could open a new PR making that change for all of them if we wanted. WDYT?\n. Cool. I agree\n. Thanks @wfleming! Good catch\n. @wfleming Actually, taking a look at the code, it seems like upgrade_languages, if present, serve as an additional filtering check on top of regex and files _present, but that the default will be whatever the latter comes up as.\nIf that's the case, it seems to me that the additional languages check doesn't add much value here, and might cause harm in exceptional cases (e.g. rails repos that get added with javascript as default language bc of settings in Github). \n. Yeah, I had qualms about the final exitcode as well.\n. @wfleming cool. Thanks for the explanation. I'd like consistently generating a successful exit code.\nWhat was our original reason in favor of going with the exitcode 1 when there's no .codeclimate.yml? What would you think about something more neutral like .codeclimate.yml already present, skipping generation, like we do for each engine config that's already present?\n. k. I like that\n. yeah, agreed.\nAt first I was curious about whether we have --upgrade in the help commands, and noticed this absence as well.\n. Alphabetize these to pave the way for additional options\n. What's our stance on keeping these in diffs? \n. Nice! I like this test. Can we also have a test that checks what happens when passed dir with no slash (e.g. lib), and multiple paths lib test.rb app/models?\n. I might be missing the complete flow of things, but aren't we going to honor excludes from .codeclimate.yml unless --ignore-excludes gets set? and if so, would we pass those here?\n. Hm. Not sure if it's relevant, but I think the difference between **/*.rb and **.rb is that the latter is more inclusive. The former misses top level .rb files.\nirb(main):002:0> File.fnmatch(\"**.rb\", \"test.rb\")\n=> true\nirb(main):003:0> File.fnmatch(\"**/*.rb\", \"test.rb\")\n=> false\nirb(main):004:0> File.fnmatch(\"**.rb\", \"app/test.rb\")\n=> true\nirb(main):005:0>\n. Curious why this call was absent before but present now?\n. :+1:  thanks\n. curious about why this variable isn't also instance?\n. nice job adding specs!\n. what do you think about keeping the JSON parse error rescue here?\nas in\nhttps://github.com/codeclimate/codeclimate/pull/267/files#diff-f70998052f6e066aec2b9393461c245cL24\n. I think output filter is fine still. It's still filtering the output, no?\n. what do you think about calling this the rubocop version instead of old?\n. ah just saw top level comment addressing\n. Sure either of those are fine by me.\nI can go with Checks formatting of annotation comments..\nPersonally, I prefer examples but I'm a newbie. ;)\n. This might be outside scope of this PR, but maybe we could consider in the future blowing up here instead? Not sure which is better.\n. What do you think about autoloading all of the other validators in validation.rb?\n. I slightly like using presence throughout here, instead of mixing with existence, but looks like we've already mixed a bit so, perhaps that's fine. WDYT?\n. Maybe this could be a constant?\n. Got it. Thanks\n. \ud83d\udc4d  makes sense\n. Nice! I like the work here and that you broke out the fingerprint computations into two separate functions, so that the old mechanism's still available. \nOne question: Does this mean that anytime content changes the fingerprint will change? Could that create negative behavior changes in reporting new issues instead of worse issues - in fact perhaps not allowing issues to get worse in some cases? \nI suppose engines can implement their own fingerprints to account for some of those cases - like method length.\n. Ah okay. I didn't know that we'd considered and discussed the impact of that change.\nOne downside might be that more PRs will fail. And editing an existing issue - even improving it - will show up as a new issue.\nBut it's hard to have a perfect system so maybe this tradeoff is okay \n. \ud83d\udc4d \n. @GordonDiggs good call.\nThought I saw a case where ENV wasn't working but I think it was just that the engine ran for less than 1 second. \nThanks!\n. okay\n. nice catch! thanks. I considered checking for .present? here, but I don't think we need or want that. The overwrite to default 'minor only checks for nil here. Open to other ideas though.. could this be extracted into a constant?. any reason we're using safe_yaml over cc::yaml? simpler?. \ud83d\udc4f  enjoying the red. nice rspec and_yield. TIL :). Since cronopio was intentionally random, branch name will probably change in the future. Using a constant ref avoids us having to change the channel name here, and provides an opportunity to use a clearer name - like QUALITY_CHANNEL or DUPLICATION_QUALITY_CHANNEL?\nDon't feel strongly though. up to you!. I think this is fine. One thing to note that we'd be losing through this step for the Duplication engine is some additional configuration, like engine-specific exclude paths and a reduced language set. . Is this class mostly just a refactor? I don't see a lot of value in it and might avoid muddying the diff if not directly related to the change. . will we still want this class for filtering plugins that are configured via the UI or a user's .codeclimate.yml, or will that live elsewhere?. this check is a bit hacky but I think it's an improvement. once QM is on stable we can remove. ",
    "gdiggs": ":+1: LGTM\n. @ivantsepp Yep - good call!\n. @ivantsepp this is fixed in master and will be in our next release!\n. @kevinburkeshyp This is definitely something we want to improve. For now, codeclimate help will display all the commands and what arguments they can take. analyze can take an optional -f flag that will change the format of the output. Currently the options are \n- -f text The default plaintext formatter\n- -f json A JSON formatter that will output the raw issue data as it comes from the engines.\nIf you would like to analyze only a subset of files, I would recommend adding to your exclude_paths\n. @kevinburkeshyp Can you confirm whether or not this is fixed for you? I can't repro it anymore either.\n. @lenart Sorry about that! Try again.\nAs for the docker pull command, make sure boot2docker is running\n. Duplicate of #16.\nThis should be fixed. Try brew update and then install again\n. @Jared-Prime I can take a look into this specifically in the morning.In the meantime, do you mean to be analyzing the code in your tmp directory? Does it work if you exclude that path?\n. @Jared-Prime This is a known issue that we are in the process of fixing. I will update this issue when we have a fix!\n. @Jared-Prime can you update to 0.0.17, re-run codeclimate engines:install and let me know if it is working for you now? We shipped a change to the way we handle the engine configuration that should resolve that\n. Awesome! Glad it's working. Going to close this issue out and we will be working on bringing this fix to other engines in the next few weeks.\n. :+1:\n. LGTM Will merge and release\n. @stickel your server/* glob is malformed. Each of those should be **/* (like the one for node_modules). Does it work if you update the config to be:\n``` yaml\nengines:\n  coffeelint:\n    enabled: false\n  eslint:\n    enabled: true\nratings:\n  paths:\n  - \".js\"\n  - \".scss\"\nexclude_paths:\n- \"node_modules//*\"\n- \"app/assets/build//\"\n- \"app/assets/fonts//*\"\n- \"app/assets/images//\"\n- \"server/*/\"\n```\n. @pbrisbin the analysis errors out:\n~/git_repos/ellis (master) \ud83d\udc16  codeclimate analyze\nStarting analysis\nRunning eslint: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine eslint failed with status 1 and stderr \"Unable to find user app\\ntime=\\\"2015-06-26T14:23:50Z\\\" level=fatal msg=\\\"Error response from daemon: Cannot start container 6241cbf968dc5e1041cd4a48bd967d5171cbd6008ab0e0509d48af28df0aedcd: [8] System error: Unable to find user app\\\" \\n\"\n. @pbrisbin hmmm that does run - how do we handle that? Seems like using app here gets around that problem\n. @pbrisbin read up a bit and addressed the issue - using UID and GID now\n. LGTM save for that extra line\n. I forget the specific reasons, but IIRC it didn't play nice with that waitpid call. This Thread implementation is nearly identical to how Timeout does it. @noahd1 is working on a proof-of-concept branch now that uses Timeout so we can see if that works.\n. LGTM\n. Can you post the codeclimate-yaml diff?\n. :+1: looks good\n. LGTM\n. LGTM\n. @codeclimate/review this is ready for another look! I added a line to the Makefile to update all engines that are installed on the user's machine\n. @ivantsepp there is not an engine in the works for that yet! Take a look at the spec and let me know if you have questions!\n. @ivantsepp looks good save for the one comment I added and the failing tests. Ping me when you have a chance to address them and I can merge this! Thanks!\n. Ah good call - I need to address that separately.\n. @ivantsepp this will go out in the next release!\n. +1 for adding tests\n. LGTM - can you verify that the tests pass on your local? I don't trust the circle CI result\n. LGTM!\n. This is a nice solution - much better than turning Rainbow on and off\n. LGTM!\n. LGTM\n. :+1: \n. LGTM\n. @pbrisbin Agreed!\n. I agree this would be a good feature! The -f argument is already taken for the formatter, but I see two options:\n- Use -a /  --analyze and you pass the filename there\n- Accept it as the last argument to the command codeclimate analyze -f json path/to/file\nI lean towards the second personally\n. LGTM\n. LGTM\n. LGTM!\n. LGTM\n. LGTM\n. One minor thing - LGTM otherwise\n. @stickel Unfortunately we don\u2019t support ESLint modules just yet \u2014 sorry about that. We do have plans to better support these down the road, there's just more dev work to do on our end before that will be possible. Sorry for the limitation in the meantime though.\n. Interesting rubocop failures - I support them\n. LGTM\n. @amochumber The console command gives access to the classes within the CLI and is useful mostly for engine developers and maintainers. For example, to run analysis you would access the Analyze class directly: CC::CLI::Analyze.new.run\n. Thank you!\n. @amochumber ah I see it - will fix in master\n. This should be working now that we have merged #100!\n. LGTM\n. LGTM\n. LGTM. 2 questions:\n1. Do any of the new issues on CC need to be addressed?\n2. Does this work locally?\n. I'm cool with that. Should we disable the Space inside empty braces detected. rule?\n. LGTM\n. @elwayman02 We do have plans to add it! It's not quite ready yet but I will update this issue when we release it\n. @elwayman02 @dylangrafmyre \nSCSS Lint is now available as of version 0.6.0! To enable it, you can run codeclimate engines:enable scss-lint\n. Thank you @ablyler!\n. LGTM\n. LGTM\n. @dbergey Thanks! Does this also work for people who start from scratch and install Docker Toolbox (rather than migrating from boot2docker)\n. Thank you! I will release this now\n. @squaresurf what version are you running? You can find this out using docker run codeclimate/codeclimate version\nNOTE: using docker run here without the environment variables and bind-mounts is sufficient for getting the version, but won't work for analyzing files or most other commands.\n. @squaresurf I just released it!\n. Thank you!\n. LGTM\n. LGTM\n. @albertpak It should support standard UNIX redirection. For example:\n~ \ud83d\udc16  codeclimate version > version\n~ \ud83d\udc16  cat version \n0.3.2\n. LGTM\n. @rojotek The CLI is already updated to support Docker Machine. Assuming you have that set up, the rest of the instructions should work! Agreed we should update the docs - will add that to our backlog!\n. The README is now updated!\n. LGTM\n. LGTM\n. :+1:\n. LGTM\n. LGTM\n. I vote we disable the long class check - we never fix it and now we require CC to be green to merge this\n. LGTM\n. :+1:\n. LGTM\n. LGTM\n. :+1:\n. @jpignata \n. Probably consequential behavior but IMO not undesirable\n. LGTM\n. LGTM\n. :+1:\n. LGTM\n. LGTM2\n. :+1:\n. LGTM\n. LGTM\n. LGTM\n. +1\n. Si ves algo di :+1: \n. :+1:\n. Very nice. Would be interested to see some benchmarks on this\n. :+1:\n. :+1: \n. LGTM\n. LGTM\n. Nice find. LGTM\n. LGTM\n. LGTM\n. @stphung Can you describe more of what you're seeing? Do you have some terminal output you could share?\n. @stphung Ah I see what you're doing now. Engines don't have access to the network, for security reasons. Any network calls you want to make need to be done during the image build process\n. Would like support to mercy merge this as it could help fix the waiting status\n. @mgracer48 Using or here is actually preferred, as we are using it for control flow and not logic operations (the post that @andyw8 shared explains that concept well).\n. @mgracer48 This is supported! You can either exclude checks inside the .codeclimate.yml file, or if the library supports a configuration file, you can tweak the settings there.\nExample yaml snippet:\nyaml\nengines:\n  pep8:\n    enabled: true\n    checks:\n      W293:\n        enabled: false\npep8 configuration: http://pep8.readthedocs.org/en/latest/intro.html#configuration\n. LGTM. Love the comments\n. LGTM\n. Seems good to me\n. LGTM\n. Are the enable regexps OR or AND? If they're AND, could we also check for ruby files?\n. I think that would be good - I know some JS projects use app by convention\n. LGTM\n. :+1: \n. @wfleming thanks! I will work on that\n. @pbrisbin @codeclimate/review ready for another look!\n. @wfleming the only in-office discussion was that it felt weird to pull all of SmellAdapter over because our internal database schema doesn't seem like a concern of the CLI. In that regard, I think the adaptation should still happen in builder. \nHowever, I agree on the validation - I'll move that stuff into here now.\n. @wfleming that might be a good idea. As it stands now, integrating this with builder means bumping the gem and removing some code, without much other messing around. I will add a card for the validation stuff and punt on it for now, unless it gets hairy once I get over to builder land\n. LGTM\n. LGTM\n. :raised_hands: \n. Hey @DavidEBest the /code location is a requirement in our spec and is unlikely to change, as it provides a lot of convenience as well as security. It's important to note that /code is the directory inside the container - it can be any directory outside the container.\n. @lucasmazza here's the tricky bit about this (and why we initially went with a hardcoded path): The path within this docker run invocation must exist on the host machine as well (see where we mount it as a volume here). So, I don't believe your current implementation will work, as /tmp/foo will exist within the codeclimate container, but not be accessible to the docker daemon, which is dropping back down to the host to mount the file.\n. @lucasmazza that would work too!\n. LGTM. Thanks! Will merge on green\n. Hey @sgerrand! I should have some time later today to get this set up!\n. @sgerrand this should be all set! Thanks! I'm also going to email you with some information\n. LGTM\n. One style thing but otherwise LGTM\n. LGTM\n. LGTM\n. @sysadmiral @devth We have an in-progress engine for shellcheck! https://github.com/filib/codeclimate-shellcheck\nIf you are interested in getting involved, there are a few open issues on that repo\n. @pbrisbin >100 builds have errored in the past few days because of it. I think we might be seeing it more because of the docker upgrade and new nodes\n. Looks like there's a typo here - should say around\n. LGTM\n. @wfleming updated!\n. @antiagainst thank you! We will take a look and let you know about next steps soon!\n. LGTM\n. I think presenting it as seconds would be better (your alternative)\n. :+1: \n. :+1: \n. I merged ahead of you, sorry :/\n. LGTM\n. @sheenobu thanks for reporting! I just merged a fix for this and will release it to rubygems shortly.\nOut of curiosity, what kinds of tools are you using?\n. LGTM\n. Thank you! Looks great\n. :+1: \n. LGTM\n. LGTM\n. LGTM pending green builds\n. Works for me! :shipit: \n. Can we use the .js one? It has the highest precedence (and is what we suggest in our styleguide)\n. @dblandin Something to think about: how will this change the inferred config experience for people?\n. @codeclimate/review ready for another look!\n. @wfleming ah that wasn't clear from the card. I can do that validation in a follow-up PR!\n. @codeclimate/review this is ready for a look! I'm going to leave the length issues for now.\n. > have we considered how we might handle permitting valid issues without location in the future - like a security vulnerability that says you're missing x file. ?\nThis will likely have to change to accomodate that, but we also would have to do a fair amount of work elsewhere to support it\n. @wfleming when you have a moment, I'm curious about your thoughts on https://codeclimate.slack.com/archives/dev/p1461000692000097\nDiscovered that behavior while trying to test the performance impact of this\n. Going to close this and re-work. We decided that asserting that the format is correct is good enough\n. Hey @dezmathio sorry about that! Can you run it in debug mode and paste the output?\nCODECLIMATE_DEBUG=1 codeclimate analyze app/controllers/vendor/\n. @dezmathio thank you! I'm going to look into this now and get back to you\n. @dezmathio awesome! I'm releasing it to docker hub as I type this. Also, if you're using the rubocop engine, you'll want to run codeclimate engines:install\n. @wfleming ah yeah we should. I'll update\n. @wfleming updated!\n. Hey @joncursi! Right now, diffing issues is only available on codeclimate.com, not through the CLI. \nWe do, however, support analysis of specific files or directories, which I use often in my workflow. Say you're working on file lib/foo.js, you can make sure that you aren't introducing issues in that file by running codeclimate analyze lib/foo.js. It should cut down on the number of issues (and execution time) you have to look at.\n. LGTM\n. A few thoughts but LGTM\n. \ud83d\udc4d \n. LGTM\n. @ABaldwinHunter definitely a valid concern. I think that there's going to be a large amount of change to be made whenever we decide to support that, though, and a lot of it will be in this area. I agree it does move in that direction, but not a huge amount\n. One minor thing and I agree with Will's comment but otherwise LGTM! This will be awesome to have\n. Some tiny nits. This looks awesome\n. \ud83d\udc4d \n. \ud83d\udc4d \n. Implementation LGTM if we decide we want this\n. LGTM\n. \ud83d\udc4d \n. LGTM. FWIW we've seen this behavior on an enterprise instance as well\n. LGTM\n. LGTM\n. @mrb yep!\n. Closing due to staleness. Feel free to reopen if this picks up again. LGTM\n. LGTM\n. @reedstonefood Sorry for the confusion! There are a few implementations of patch that you can use.\n\nOne from GnuWin32\nI've also read that Git on windows ships with one, but am not super familiar with that.. @reedstonefood looks like you had a combination of array format and hash format in the duplication languages. I've opened a PR to fix that for you!. No problem! Going to close this issue now. @andyw8 Our default configuration aims to be fairly objective and not opinionated. For example, it doesn't enable any style rules by default. I think enabling this gem by default would go against that. WDYT?. @backus Sorry for the delay here - I was on vacation. While I personally agree those cops are good (we use some of them internally), they don't meet our criteria of \"objective\" for a default config for one simple reason: not everyone uses rspec, so we shouldn't by default suggest rules that only apply to it.. @mckinnsb The PR status is red from Code Climate. Here's a link to the results https://codeclimate.com/github/codeclimate/codeclimate/pull/571. @zenspider Yep! I want to make sure we can monitor it after we ship it but I will merge it soon!. Yeah I have these in my global gitignore (I think that's how I missed them and they ended up in the docker image). A global dockerignore would be awesome. Until then, we probably need to do this :/. @pbrisbin can't hurt to merge this first!. Is there some kind of machine identifier we could hash up and use? Looks like docker info has an ID that may be unique per docker engine, which may be good enough. > changes at unknown times, best case: docker reinstall, medium case: docker upgrade, worst case: docker restarts\n\n@pbrisbin are you sure it changes in these scenarios? The documentation I read yesterday suggested it is unique per docker engine installation. @pbrisbin yes - my question is whether or not you have any evidence it happens in the other cases too. @pbrisbin Just tried restarting docker and the ID changed, so that's a no-go.\nHere's my prioritized list of options:\n\nMAC Address\nUUID if that is somehow possible but MAC address isn't\nIP Address. This isn't great but may work for now and we can always revisit in the future. I'd be ok with having a wrapper-only solution for now and then being able to see in the analytics events if there's a high percentage of uid's missing (which would correlate to people not using the wrapper). @maxjacobson good catch! We should do the first idea (don't print the warning). I think we're set!. @maxjacobson ah it's totally because we didn't make a tag - can you make one?. Talked IRL - we want the server to do the outdated check by design. Closing. Closing this for now. Hi @jhabdas! We currently have documentation at https://docs.codeclimate.com, including a large page about configuration. Additionally, you can use codeclimate help to understand what the CLI commands do.\n\nWe are constantly improving our docs and hope to make contributing them easier in the future.\nI'm going to close this now as there aren't changes to be made to the CLI to improve this. If you have suggestions on how to improve our README, I would be happy to discuss them on a pull request!. Version bumps should happen in their own PRs, but that raises an interesting question - are there breaking changes here? Should this be 1.0.0?. :lipstick: use %w[] for word arrays\n. This should also include --rm\n. Does this change work without any change to the JSON formatter?\n. :lipstick: These conditionals should be swapped so that the positive case is first\n. Will it always be codeclimate/? I thought the codeclimate- prefix was so that someone could have a repo like user/codeclimate-foo\n. extra line here\n. Oh yeah good call\n. Updated!\n. Agreed. We could suggest excluding fewer files, since that is the main contributor to this size, but that doesn't seem like a good UX either.\nIf it helps, this will only be around until next week when we move to a different solution.\n. We have a fatal method that I think would be a better fit here\n. Yep that would work much better!\n. @pbrisbin updated!\n. What do you think of\n``` ruby\nif @has_begun\n  print \",\\n\"\nend\nprint document.json\n@has_begun = true\n```\n. No harm in doing that\n. @ABaldwinHunter sorry - was heads down in bugsnag hell. Whichever you think is best is cool with me!\n. I think this check is good. What do you think of also doing a thing like\nruby\nlambda { JSON.parse(stdout) }.must_not_raise\nThis will simply assert that the output is valid JSON and parses successfully\n. What do you think of putting this logic inside of Spinner? The start method could become:\ndef start\n      if $stdout.tty?\n        @thread = Thread.new do\n          loop do\n            @spinning = true\n            spinner.spin\n            sleep 0.075\n          end\n        end\n      end\n    end\n. @pbrisbin it happens in stop below but is guarded\n. Have you tested that this works correctly? My understanding was that wrapping this in quotes makes it one argument\n. Ok cool - if it works then I'm good!\n. We use the must_ syntax - can you reformat these lines? Should be instance.dev_mode?.must_equal true\n. Should this be protected so that subclasses can get it, but outsiders can't?\n. hah should we remove this conditional re: conversation yesterday?\n. I thought private stuff wasn't accessible to subclasses but I could have been wrong.\nMy main goal here is that this is accessible to subclasses but not outside.\n. Ah I get that now  - thanks for the explanation!\n. When would the first condition be false?\n. Could be good to memoize this since this object is somewhat long running.\n. That's valid for JSON, but not our spec, right? Is there a situation where an engine will output an array?\n. What's the value of this change?\n. Any reason not to declare these on the same line?\ncattr_accessor :logger, :statsd\n. Does this actually mutate the CC::Yaml object we pass around? Would it be better to use merge here?\n. registry.list[name].present? should be a little more performant here. I realize you didn't make the change but since you're already changing this line.\n. Should these p statements be here?\n. hmm should this and the one on line 13 be fatal?\n. Do you know if ls-files has an argument to delimit these with \\0? Other git calls have that\n. Also, does this work with symlinks?\n. Running code when defining a constant can cause some weird things (related to the way that classes are loaded). Can you move this to a method? Alternatively, what do you think of being able to call CC::Analyzer::EngineRegistry.exists?(engine_name)?\n. This include should probably be nested under Install so that this doesn't override the defaults\n. What do you think of naming this display_invalid_engines to match the convention elsewhere?\n. Update: this works with symlinks\n. What do you think of making these named params?\nruby\ndef run(stdout_io:, stderr_io: StringIO.new, container_log: NullContainerlog.new\nThen you could call it below with just\nruby\nrun(stdout_io: @formatter, container_log: container_log)\nand not have to worry about the stderr value\n. ContainerLogLog?\n. Is there a reason not to use attr_reader for these?\n. same attr_reader question here\n. >  I see the former more prevalent our code bases I've been starting to do that -- which is what I've done here.\nI don't see attr_reader in this class\n. Cool. I haven't seen much of using instance variables directly (probably because I prefer the attr_reader approach).\nFunctionally, they're the same so I don't see a big win either way.\n. Will do!\n. :clap:\n. What's the benefit of nesting this under ContainerListener instead of Container? Nothing in this class actually uses the struct directly. You could even do this Struct.new call right within container_data above\n. I think naming this exclude_paths might be clearer. WDYT?\n. Is it possible for things to show up in both? Would a union be better here?\n. What in the above calls could make obj be of different types?\n. This method could be \nruby\n@_file_entries ||= relevant_full_entries.reject do |e|\n  File.directory?(e)\nend\n. We use describe everywhere else. What does context give us?\n. Cool - makes sense\n. I like cc_exclude_paths\n. We definitely use ||= generously for memoization. I'm not sure about the begin...end pattern. I don't think it makes sense in this method but maybe elswhere\n. :lipstick: combine these 2 lines\n. The one issue with this memoization is that if @engines_enabled is false, it won't use the memoized value. I think you can get around that by returning unless @engines_enabled.nil?\n. What happens if @pid is nil here?\n. I think this should be resilient to being called prematurely. Would a simple if @pid achieve that?\n. this trailing conditional seems odd to me because sdtout_io.write is the primary action here. What do you think of\nruby\nstdout_io.write(output) or container.stop\nI don't usually advocate using or but given that it's for control flow and not logic, I think it's a good use case.\n. Using << instead of += here will be a tiny bit faster, as it will not make a new String object every time.\n```\n[1] pry(main)> require 'benchmark/ips'\n=> true\n[2] pry(main)> \n[3] pry(main)> str1 = \"\"\n=> \"\"\n[4] pry(main)> str2 = \"\"\n=> \"\"\n[5] pry(main)> \n[6] pry(main)> Benchmark.ips do |x|\n[6] pry(main)   x.report(\"+=\") { str1 += \"a\" }\n[6] pry(main)   x.report(\"<<\") { str2 << \"a\" }\n[6] pry(main)   x.compare!\n[6] pry(main) end\nCalculating -------------------------------------\n                  +=     5.054k i/100ms\n                  <<   104.102k i/100ms\n\n              +=     16.325k (\u00b152.8%) i/s -     70.756k in   5.550502s\n              <<      3.788M (\u00b1 5.4%) i/s -     18.947M\n\nComparison:\n                  <<:  3788143.5 i/s\n                  +=:    16325.3 i/s - 232.04x slower\n``\n. Does our spec allow arbitrary values for severity or do we need to validate these values?\n. Should there be a change to the constructor forContainerData?\n. What happens if this command fails?\n. I guess the line above would get logged and we could see if orphaned containers were attempted to be killed. It's probably fine. The only suggestion I would make is to execute this command in some way that raises if it fails (ie. backticks)\n. Makes sense. I'm fine with trying this and seeing what happens. Might be a non-issue\n. Agreed on both - will make that change\n. Fixed\n. We have activesupport here, right? Could this useArray.wrap(@config.engines)?\n. When would this be false?\n. Should this usesay?\n. Should this call theerrors` method on this object?\n. EDIT: nvm - figured out what is happening here\n. I would word this more simply as\n\nPython tool used to compute Cyclomatic Complexity.\n. What do you think of doing the || SecureRandom.uuid in the constructor?\n. Ah got it\n. nice thanks for putting this in the ENV\n. One important behavioral difference here is that if ENV[\"CONTAINER_TIMEOUT_SECONDS\"] exists but is nil, this will be 0\n. I'm not sure on the behavior of this snippet:\n\nCONTAINER_TIMEOUT_SECONDS=\nBut the behavior would be the same either way. What does a 0 timeout or max bytes mean behavior-wise?\n. Ah yeah good point\n. Is this dependency true? The gemspec still specifies 0.5\n. Should this be named check_disabled??\n. Oops sorry - I thought this was builder.\n. Why disable this? Our styleguide does not\n. We're ok with it. IIRC the rule specifies that they have to be surrounded by parentheses, so the line below would be \nruby\nif (fingerprint = json[\"fingerprint\"])\nThat should not set off the cop.\n. It seems odd to have a fatal output if we successfully created default configs. Maybe the message should mention that we generated them?\n. EDIT: nvm - I see the output of that now\n. I don't think it needs to be removed, but want to mention that this seems like a drive-by fix\n. WDYT of success?\n. Is it possible for one of these to finish before the other? Imagining if stderr closes but stdout is still flushing? Is that possible?\n. I think doing that would be an issue if something raised an error before one of them was initialized (which is the purpose of the if t_out right?)\n. This is from @wfleming's original change - it's explained in the PR description\n. Interesting idea - I would like to ship this and revisit that if the problem isn't solved, but keeping this as small as possible seems like a good idea\n. @wfleming had a reason to back that change out - will, what was that?\n. Hmm that might be right. I'll use the array and see what happens\n. should this use $(...)?\n. docker stop will signal SIGTERM and then kill after a time. Would there be any benefit in using that here? \n. Maybe with a very low timeout (1)?\n. WFM\n. PHP has a few extensions\n. Is this array format still valid? I've been doing them as mappings recently\n. They are definitely common. I would support adding them in both\n. good to know! thanks\n. Open to other ideas on this. I'm torn between doing this and using method_missing. What do others think?\n. I think I do too \n. The other mechanisms of this class require that JSON.parse to succeed, and that one was only rescued in order to pass on invalid JSON for this very error to be raised later, so I think this is better as-is\n. That starts to get into the validation territory IMO (if we're raising then we need to make sure it matches the errors builder expects, etc) - curious to see how this plays out as-is\n. looks like an erroneous character here\n. I don't think this is necessary, bin/release builds the image\n. Ah nvm this is outside of the release directions\n. I'm -1 on that. Way too easy to have other tagged images locally that will be pushed up\n. This series of short-circuited returns is hard to read to me. WDYT of using if...else?\n. Does this just take the separator off the end and add it back?\n. Is there a solution for this situation on .com?\n. Nope - this makes sense to me as-is now!\n. A .codeclimate.yml with pattern-based exclusions\n. I'm not sure how valuable this memoization is. Most of the work is probably done in existing_cc_config and nothing will be memoized if present? or any? return false.\n. :lipstick: use %w here\n. Could be a good use case for |= here\n. Is this line needed? I don't remember it being present before\n. Weird! \n. I think this format is more confusing. Can we just delete the line? There's a url to explain this more if people are confused. Maybe we could also change the description to Checks for presence of maintenance comments? WDYT?\n. Is it worth it to set the upgrade and enable patterns if it's not going to be enabled by default?\n. Cool - makes sense\n. Is this version bump intentional?\n. existing_cc_config returns nil when the file doesn't exist, right? So calling engines on that would raise an error?\n. WDYT of gsub(/[\\n\\t]/, \" \")? \n. There's also JSON.pretty_generate but I think you want it to all be one line?\n. Ah cool. Makes sense! I think returning nil is fine. Coercing it into {} might harm us more down the road.\n. Cool - all good points. What you have seems like a good way to go for now\n. You could wrap it in quotes to make that more evident if that would help\n. If we move them under that namespace that would work, but these need to be autoloaded under the module to which they belong (in this case, Analyzer)\n. When we first introduced these, we made the choice that they should \n1. Not be order dependent\n2. Be able to run independently of each other\n3. All be run all the time\nThis keeps the classes small (responding to just a valid? and message method). See that discussion here.\nI don't like the idea of doing multiple checks in one validation class - I think it will cause the classes to become bloated and do too many things (additionally, having a single coherent message to be returned from them will be harder)\n. Yeah the unparseable case is handled elsewhere (we let JSON.parse raise in this repo). In builder we handle it separately. Because it's a different error code (E12 vs E13), I think not having a Parseable JSON validation is better\n. Presence means \"is it present in the output?\", whereas existence means \"does it actually exist where the output says it is?\"\n. Eh, I don't see a big win in that - do you? It has to be a method in order to conform to the Validator format\n. Right - adding the explicit false though just because I like it.\n. Good call - updated!\n. Yep!\n. Why use | separators instead of adding each item to the digest with << separately?\n. This is where I'm concerned about using the | separators - it could lead to collisions here (maybe thats ok)\n. Hmm I thought it would do some work the help with collisions, but it doesn't. I think | is a little naive of a separator (especially since it's so common in source listings). WDYT of using \\0 instead?\n. See my above comment - I was wrong about collisions, but still have ideas about separators\n. Hmm the more I think about it, I can't really come up with a good example. So, might be fine!\n. Would it be enough to check position[\"offset\"].is_a?(Integer), since it would imply the presence check?\n. WDYT of also suggesting docker run hello-world?\n. Include the output of the following commands?\n. Yeah I think putting it in that list is a good idea\n. Like latin, order does not matter here. All the validations get run every time\n. I believe this will also return false for symlinks. I think that's fine but wanted to be sure that's ok with you\n. All these puts make me sad. How hard would it be to pull something like ERB into this to handle these?\n. Maybe use an h4 here?\n. I don't see a big win in this assignment over doing self[name].merge(...). WDYT?\n. This is awesome - we should highlight this when documenting upgrading to the new eslint\n. Drive by change?\n. EDIT: looks like it's in its own commit, so I'm fine with it (unless it causes enough issues to be worth pulling for now)\n. I don't feel that strongly - fine to leave it as is\n. Good idea - done!\n. Does this case cause issues?\n. Yeah I'm cool with leaving it, but we should keep an eye on the error codes\n. Why is this preferable to using the env variable directly?\n. Hey @jrafanie AFAIK this is not true. I can see where in the CLI this is used. Have you seen otherwise?\n. @jrafanie I was able to get it to work like this:\nconsole\n~/git_repos/manageiq (master) \ud83d\udc16  CONTAINER_TIMEOUT_SECONDS=30 codeclimate analyze\nStarting analysis\nRunning csslint: Done!\nRunning duplication: Done!\nerror: (CC::Analyzer::Engine::EngineTimeout) engine duplication:stable ran for 30 seconds and was killed\nCan you run cat $(which codeclimate) and share the output? You might be using an outdated wrapper\n. Ah! I see the issue - your wrapper is out of date. Did you install via homebrew? If so can you run  brew update && brew upgrade codeclimate\n. Great @jrafanie! Looking forward to it!\n. this $PROGRAM_NAME seems to be expanded into a full path:\nUsage: /usr/src/app/bin/codeclimate analyze [-f format] [-e engine[:channel]] [path]\nIt will always be codeclimate so I would be ok with hardcoding that here. Might be good to expand on this. WDYT of \"Run in development mode. Engines installed locally that are not in the manifest will be run\". \ud83d\udc84 probably enough to see if this is truthy and just return @abstract. Would it work to do\n@@subclasses.reject(&:abstract?). \ud83d\udcd6  For the last sentence: \"Useful for developing against the CLI\". \ud83d\udcd6  \"commad\" should be \"command\". \ud83d\udcd6  \"Display help information\". \ud83d\udcd6  \"scpecified\" should be \"specified\". \ud83d\udcd6  \"Generate a configuration based on the contents of your repo.\"\nWe can leave out the image pulling for this. \ud83d\udcd6  \"Upgrade a Code Climate Classic configuration\". \ud83d\udcd6  \"Test an engine\". Could we add a line here that is something like \"Validate that an engine is behaving correctly\". \ud83d\udcd6  \"Validate your .codeclimate.yml. We generally useNet::HTTPfor requests like this. Can you use that here?. I thinkwarn` already colorizes the message? Additionally:\n\nDrop the tildes\nWDYT of \"A new version (#{latest}) is available\". Does this need to be mounted into the container?. The engines in this file are sorted alphabetically. Can you move this into place? . Should we have this in beta for now?. This ENV key shouldn't have the BUILDER_ prefix. \ud83d\udc84 The product name should be written as \"Code Climate\". \ud83d\udc84 are the parentheses here required?. \ud83d\udc84 we prefer fetch here:\n\nruby\nengine.fetch(\"config_files\", {}). I would reformat this a bit:\nSkipping generating #{file_name}, existing file(s) found: #{existing_files.join(\", \")}).. Ah got it - makes sense. I believe these can have any final character. Would *.sw* work here?. That's a limitation I'm willing to accept hahaha\nIf you're concerned, we could match .*.sw*. ",
    "kkirsche": "Closed due to X-Ref: codeclimate/homebrew-formulae#3\n. ",
    "laszlof": "Further on this. Is there a way to tell it to NOT try to output color? I want to dump the results to a plain text file thats actually readable.\n. Yup. I just redirected stdout to a file and it dropped all the color codes in there. I didnt notice if there was a -f (file) option. That would probably be the easiest way to implement it. Either that, or a \"plaintext\" output type.\nAnother thing I notice that I might as well mention. The json format option produces some odd results. It appears to create individual JSON objects on each line. This isnt what I would expect. I would expect it to produce an array of json objects that could be easily parsed. The entire thing should be a valid JSON object in my opinion.\n. Thanks! I'll check it out when I get the office tomorrow.\n. ",
    "ntwb": "Just taking codeclimate for a spin and needed to validate my config and happened upon this issue.\nUsing codeclimate 0.1.3 on a heavily focused PHP/JS project:\n\u2022 codeclimate init\n\u2022 codeclimate validate-config\nResult: No errors or warnings found in .codeclimate.yml file.\n. ",
    "mhlavac": "@mssola make sure to check to who the file belongs to. For me it was created with root:root, I changed it and also check permissions, make sure everyone can read it\n. Running into same problem, I've found out that .codeclimate.yml was belonging to root:root when I created it with init. When I changed it to my user I get\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 1 and stderr \"/usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `initialize': Permission denied @ rb_sysopen - /code/server/dev/id_rsa (Errno::EACCES)\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `open'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `ruby_executable?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:78:in `to_inspect?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:65:in `block in target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in `select'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in `target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:31:in `find'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/runner.rb:41:in `find_target_files'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:18:in `block in run'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `chdir'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `run'\\n\\tfrom /usr/src/app/bin/codeclimate-rubocop:6:in `<main>'\\n\"\nShould we force user somehow?\n. @alexpjohnson I've found out the issue for me was this: /code/server/dev/id_rsa (Errno::EACCES) you have same problem with /code/dd, the file belonged to me, but didn't have read permission for everyone. I've changed permissions from 600 to 644 and it's fine.\nOf course this is not best solution, in my case it's a dev ssh key that is used to connect to our Docker container and it should really be 600.\n. ",
    "mssola": "Ah, now I see. I just had to give write permissions to everyone for this file. This happened because I created the .codeclimate.yml myself, and I did this before by executing codeclimate init I get exactly the same error:\nerror: (Errno::EACCES) Permission denied @ rb_sysopen - /code/.codeclimate.yml\nAnd moreover, something is telling me that this issue is related to #18 . Probably I should give more access to the directory where my project lies (even if I created it with the defaults of mkdir) ? But that is inconvenient, I'd expect everything working out of the box :P\n. @pbrisbin I fixed it by given more permissions to everyone. Also note that by doing codeclimate init I get the same error as I mentioned before. So for me the fix is to create it manually and then set the proper permissions. If you are already working on this you can close this issue, since it seems that it's a duplicate of #18 ;)\n. ",
    "hellvinz": "works great, thanks!\n. ",
    "alexpjohnson": "Hey @pbrisbin,\nI updated my yml to:\n---\nengines:\n  rubocop:\n    enabled: true\nratings:\n  paths:\n  - \"**.rb\"\nexclude_paths:\n- config/**/*\n- db/**/*\n- test/**/*\n- vendor/**/*\n- .rubocop*\n- server/dev/is_rsa\n- /code/dd\nand am still receiving this error on codeclimate analyze:\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 1 and stderr \"/usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:ininitialize': Not supported @ rb_sysopen - /code/dd (Errno::EOPNOTSUPP)\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in open'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:inruby_executable?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:78:in to_inspect?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:65:inblock in target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in select'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:intarget_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:31:in find'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/runner.rb:41:infind_target_files'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:18:in block in run'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:inchdir'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in run'\\n\\tfrom /usr/src/app/bin/codeclimate-rubocop:6:in'\\n\"``\n. @pbrisbin Modifying the .codeclimate.yml as you suggestion did not result in a change on my end.\n. Yes running rubocop locally results in output.\n. Works for me as well. Thanks guys\n. Any update on this issue?\n. ESLint worked for me. Just waiting on Rubocop :) Thanks for all the effort guys.\n. ",
    "Jared-Prime": "I am having a similar issue\nStarting analysis\nRunning rubocop: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 1 and stderr \"/usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `initialize': Permission denied @ rb_sysopen - /code/tmp/cache/2C5/130/User_cc (Errno::EACCES)\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `open'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `ruby_executable?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:78:in `to_inspect?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:65:in `block in target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in `select'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in `target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:31:in `find'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/runner.rb:41:in `find_target_files'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:18:in `block in run'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `chdir'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `run'\\n\\tfrom /usr/src/app/bin/codeclimate-rubocop:6:in `<main>'\\n\"\n. bump. any news on this issue?\n. thank you @GordonDiggs, that helps\nhowever, I have a new failure:\n$ codeclimate analyze\nStarting analysis\nRunning rubocop: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) Config for engine rubocop exceeds 64k character limit\n. @GordonDiggs I no longer have this issue with the latest container. Thank you!\nAs some users apparently still have trouble, do you have any insight into the cause?\n. Wonderful, thank you once again for educating us!\nOn Sun, Jul 12, 2015, 09:35 pat brisbin notifications@github.com wrote:\n\nThere have been a number of problems being reported and worked through in\nthis Issue. I'm going to try and summarize:\nResolved:\n-\n@mhlavac https://github.com/mhlavac permission denied on id_rsa\nExcluding or modifying permissions solved the problem\n    -\n@Jared-Prime https://github.com/Jared-Prime can't access tmp stuff\nExcluding (once to \"excludes too big\" problem was fixed) solved the\n   problem\nOpen:\n-\n@alexpjohnson https://github.com/alexpjohnson permission denied on dd\nWe're definitely working on making excludes more intuitive, but I\n   think the issue here is still that our attempts to exclude this directory\n   aren't working. I would try the following:\nexclude_paths\n- dd\n- dd/**\n## \n@acarpe https://github.com/acarpe can't work in the /code directory\n  itself\nThis is new, and I believe a different kind of error than @alexpjohnson\n  https://github.com/alexpjohnson 's or the other follow-on issues.\n  Would you please open a new GitHub issue where we can trouble shoot it\n  specifically?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/18#issuecomment-120725666\n.\n. \n",
    "acarpe": "version 0.0.22, re-ran codeclimate engines:install and still continue to get:\nStarting analysis\nRunning rubocop: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 1 and stderr\n\"/usr/src/app/lib/cc/engine/rubocop.rb:16:in `chdir': Permission denied @ dir_chdir - /code (Errno::EACCES)\\n\\t\nfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `run'\\n\\t\nfrom /usr/src/app/bin/codeclimate-rubocop:12:in `<main>'\\n\"\n. @pbrisbin done! see #54 \n. Access: (0700/drwx------)  Uid: (  503/    silk)   Gid: (   20/   staff)\nsilk is my user id\n. changed permission (why not adding a check on permission before starting? ) and it has gone forward.\nNow the issue seems to be about the exclude_paths not being considered:\nError: EACCES, permission denied '/code/vendor/assets/javascripts/fastclick.js\nit started from the stuff in the public folder and in fact all files had wrong permission but adding:\nexclude_paths:\n- public\n- public/**/*\n- public/*\ndidn't work, at the end I updated all permissions inside public folder but it started the same behaviour in the vendor folder :(\n. ",
    "pnomolos": "I am also running into this issue - fresh install today:\nPermission denied @ rb_sysopen - /code/tmp/cache/A97/930/settings%3Adata_guard_links (Errno::EACCES)\nFull Error\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 1 and stderr \"/usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `initialize': Permission denied @ rb_sysopen - /code/tmp/cache/A97/930/settings%3Adata_guard_links (Errno::EACCES)\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `open'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `ruby_executable?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:78:in `to_inspect?'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:65:in `block in target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in `select'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:64:in `target_files_in_dir'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:31:in `find'\\n\\tfrom /usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/runner.rb:41:in `find_target_files'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:18:in `block in run'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `chdir'\\n\\tfrom /usr/src/app/lib/cc/engine/rubocop.rb:16:in `run'\\n\\tfrom /usr/src/app/bin/codeclimate-rubocop:12:in `<main>'\\n\"\nMy .codeclimate.yml is as follows:\n``` yaml\nSave as .codeclimate.yml (note leading .) in project root directory\nengines:\n  rubocop:\n    enabled: true\n  eslint:\n    enabled: true\n  csslint:\n    enabled: true\n  bundler-audit:\n    enabled: true\nratings: #Specifies which files/paths will be graded.\n  paths:\n  - \"app/\"\n  - \"lib/\"\n  - Gemfile.lock\nexclude_paths:\n  - \"spec//\"\n  - \"db/\"\n  - \"app/assets/javascripts/vendor/\"\n  - \"app/assets/javascripts/static/\"\n  - \"tmp/\"\n  - \"tmp//*\"\n  - \"tmp/cache/\"\n  - \"tmp/cache//*\"\n``\n. @pbrisbin Thanks!\n. @pbrisbin I have an idea on this one - in our project./tmp/cache` is used as a cache directory - I'm guessing that if files are generated in that directory after** the initial calculation of directories then they'll still be parsed?\n. @pbrisbin I did realize after I wrote the comment that this explanation seems implausible :)  The app would be running in another terminal at the time but it's unlikely that it'd happen to be generating files at that time.\n. Looks good, thanks!\n. Just updated to the latest release and it seems this was fixed, thanks!\n. ",
    "sergey-alekseev": "I installed CodeClimate locally and I get:\n\u276f codeclimate analyze                \u272d \u2731\nStarting analysis\nRunning rubocop: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine rubocop failed with status 1 and stderr \n/usr/lib/ruby/gems/2.2.0/gems/rubocop-0.31.0/lib/rubocop/target_finder.rb:121:in `initialize': Permission denied @ rb_sysopen - /code/tmp/archive/extract/RackMultipart20150911-11827-872ref.zip/dbcf4df20d4a29738cf8c4d705f516e0 (Errno::EACCES)\nSeems there is still no fix for that.\n. I've run codeclimate engines:enable rubocop and now codeclimate analyze works! Good job, guys :clap: \nHowever it basically works similar to rubocop. I hoped to see the same result as on CodeClimate - issues for changes only, not for the entire codebase.\n. ",
    "fhwang": "We've now pushed changes to codeclimate-rubocop. Can you try updating your image and then giving it a try?\n. While we didn't test that situation exactly, there has been a lot of change regarding both exclusions and symlinks since June 29. I would expect those changes would fix this problem.\n@bassrock can you try updating and running it again?\n. OK, this is now ready for review again. The logic regarding unreadable files and directories is:\n- If a directory can't be read by everybody, we exclude it from the whitelist we pass to the engines. This mimics the way that Git silently ignores unreadable directories.\n- If a file can't be read by everybody, we check for its presence in .gitignore or .codeclimate.yml\n  - If it matches a pattern in one of those, we exclude it from the whitelist we pass to the engines\n  - If it doesn't match any pattern in those files, we raise an error. The user needs to fix it locally before continuing.\ncc @codeclimate/review \n. Code-wise this LGTM. However:\nWhen we start adding all these subtle types of includes and excludes some of the edge case start to get tricky. What happens if my .codeclimate.yml excludes a path but I explicitly include it in the command line? If I include engines A and B in .codeclimate.yml, but I specify engine C in the command line, am I running one engine or three?\nThe answers to these aren't obvious and should be documented somewhere. I tried running codeclimate help analyze but I got no love. Is there an easy way to put this in the CLI help? Or failing that can we make sure to update docs.codeclimate.com when this is released?\n. Makes sense. Personally I'd be fine with this PR as-is if a related card about CLI documentation made its way into the backlog.\n. Did you consider putting an expectation on JSONFormatter#new to ensure it gets the filesystem argument it's expecting when a -f flag is passed?\n. Yeah I'd imagine a more full-scale spec would be something on the integration level, as this bug seems to be in part due to a misunderstanding as to how the classes are supposed to interact.\nStill, on its own I think this LGTM\n. Context on this Trello card: https://trello.com/c/IVH8HtKh/993-builder-codeclimate-rubygem-conflicts-with-docker-binary\n. init.rb has a lot of calls to upgrade? At the risk of inciting OO wankery, I wonder if it would clean things up to use a little delegation or even inheritance.\n. I was trying to run a builder image on the command line. I forgot to set BUILDER_CLONE_IMAGE in my call to bin/codeclimate-builder, which ended up eventually calling CC::Analyzer::Container with an image that was an empty string (because it's trying to get them from the env). Figuring out the issue took me maybe fifteen minutes of writing layers of debugging code.\nThere are probably lots of other places this issue could've been prevented and/or made visible, but at the very least trying to run docker run with no image name seems incorrect. I'm calling it \"blank\" in this case to go along with the definition of blankness in ActiveSupport.\n. Yeah, ImageNameRequired is a good one, I'll change to that and fix the CC issues.\n. @BlakeWilliams Want to give us a compare URL, like the one used in #73?\n. Thanks! :+1: \n. Thanks, this is a better place to fix this issue. For example, now other formatters get the benefit of this filtering.\n. I ended up supporting this differently and with minimal changes to this repo, so I'm closing this.\n. Good point @wfleming . I've moved over the relevant specs to a new engines_spec.rb.\n. @dblandin checks are passing, can you take a look?\n. LGTM\n. Closing this PR in favor of one that changes less on the codeclimate side.\n. Hold off on review for now, there's a little more work necessary on this branch.\n. K, this is now ready for review. In the interest of cleaning up work in platform, I ended up changing two classes here:\nAnalyzer::Container#run\nNow returns a result object\nAnalyzer::Engines\n\nRenamed to Analyzer::EnginesBuilder\nis-a Array behavior has been removed in favor of a more vanilla run method.\nrun accepts an optional engine class. This way collaborators can take advantage of its config parsing functionality but still use a different engine class.\n\nAll of these changes are forward compatible.\n@codeclimate/review \n. LGTM\n. @codeclimate/review this is ready for a look, thanks!\n. This PR is probably not necessary as I just merged in 0.14.0: #194 \n. A few things:\nContainerData and Result\nIt's not an easy change, conceptually, to merge these two. We've been sending ContainerData to listeners at container-specific events (start / finish / timeout) and returning Result to whoever owns the Container instance when the Docker instance terminates. The listener and the owner of the Container instance are usually not the same object.\nContainer responsibilities\nIt's my opinion that we got ourselves into a lot of trouble by trying to make Container smart. This class is used for many different things, from running a simple git clone to invoking a very complex 3rd-party engine that could take many minutes and push out a lot of output. All those different use-cases have different ranges of what's appropriate when it comes to expected stdout, stdout delimiters, expected stderr, quantity of streamed output, exit status, etc. I think we'd be better served by making Container focused and simple, and giving Container owners lots of flexibility in how to determine behavior.\nFor example, in builder we currently listen to engine output, and if we detect unparseable output, we stop the container immediately. Although I'm not clear on specifically what problem you're trying to solve, I think that we could so something similar here as well.\n. That's helpful, thanks. I agree that stopping itself if it emits a massive amount of data is properly the responsibility of Container. And on thinking about it more I think that a 150MB limit is so high that it makes a pretty safe cutoff.\nI do wonder about forcing all listener classes to add a maximum_output_exceeded method. (I'd actually like to move away from our use of listeners objects overall, precisely because of this sort of inflexibility.) We have quite a few of them now.\nAnother option might to have Container check if its listener implements maximum_output_exceeded, and if not, to simply call finished with a slightly different Result object. That would minimize code churn at some cost in conceptual muddiness. But it is a kind of finish, so ...\n. I guess, since I've spent literally a week refactoring this code, I don't know how much more we want to do in this area for now. But in terms of priorities, it's really not my call :)\nI personally would support reducing listeners to only having started and finished methods. I think that change wouldn't be too difficult.\nI'd also support conceptually merging finished and the returned Result object. But I think that change could be more difficult, because it'll be tricky to make sure everything is rewired correctly. The tests are good in that area, though, so we might do okay.\nBut it would be the right direction, I think. For engines, having too many objects receiving signals from Container has introduced a lot of unnecessary complexity. This definitely added to the time it took to fix E12 and E13 reporting.\n(Eventually I'd love to change Container so that it doesn't even take a listener object, and Container#run doesn't return an end result value. It just has three callbacks: on_stdout, on_stderr, and on_event. I don't think anything here goes against that, though.)\n. LGTM, other than my question about ||= and the Code Climate issue.\n. Nothing quick comes to mind, and personally I wouldn't mind a mercy merge here.\nOne possibility for extraction: Since the max output logic is primarily listening to stderr and stdout, you could extract a separate class for enforcing that limit if Container were to take multiple on_stdout and on_stderr callbacks. I don't think that would have to be done now, though.\n. LGTM\n. Other than one style nit, LGTM!\n. Can you also support the requested_paths key that Builder uses?\n. There's probably some context I'm missing: What's the use-case here? Why not just tell users to edit .codeclimate.yml directly or delete it?\n. Code-wise I think this looks good. Curious if others can think of a reason not to do this but if not let's do it\n. Maybe cc_exclude_paths? I wanted to differentiate it from patterns in .gitignore, which aren't ever technically called exclude_paths, but are usually a list of paths to exclude.\n. My understanding is that the two sets are always mutually exclusive. git ls-files only shows tracked files and git ls-files -o only shows untracked files.\n. Basically, there's a necessary step of turning an Array into a Hash as an optimization. In practice it's only run once, at the top directory, and then the hash is passed down recursively.\nI opted to do this inside Directory, because it felt like the responsibility of Directory to know how it's going to use that list and thus optimize it.\n. Yeah, I just didn't feel like finding out if our CodeClimate setup would complain about that too ;) So we consider these sorts of or-equals assignments okay?\nI also sometimes do ||= begin ... end, which some people hate but I think make sense if you're into the functionalish side of Ruby. Also, it makes a lot of editors (including my Vim setup) lose their mind w.r.t. indenting.\n@_memoized_var ||= begin\n   some_code\n   var\nend\n. Is it house style at CC not to use ternaries? Personally I'm fine with them as long as they're not too complex.\n. 1. The object under consideration is a String, which seems like a class we don't want to be adding methods to. Unless you're suggesting assigning readable_by_all? as a singleton method on any given String that could end up being used as a path inside IncludePathsBuilder::Directory, but that seems brittle in practice.\n2. I could use Pathname instead of String, which was in Bryan's initial code sample. Generally I found that the switching back and forth between the two caused a lot of bookkeeping overhead. For example, you're dealing with git ls-files output, should you convert them all into Pathname before moving on?\n3. I also tried making this a method on IncludePathsBuilder, but hit problems due to testing. In a lot of the tests in this repo, we use Dir.mktmpdir, which creates a temporary directory. Only problem is, it sets permissions of that temp directory to be 0700, which caused erroneous bugs when testing code that's so dependent on file and directory permissions. I wanted to centralize this logic in a method that was stubbable, and I didn't want that method to live on IncludePathsBuilder since I disliked the idea of stubbing a method on the class under test.\n. When Directory#include_paths calls Directory#readable_by_all?.\n. Not a blocker, but this argument is getting long enough that keyword arguments are starting to look like a good option.\nhttps://robots.thoughtbot.com/ruby-2-keyword-arguments\n. Yeah, it's on line 11 above :)\n. Yeah, that's fair, I'll back it out.\n. Not a blocker for this, but this file's getting kind of hairy. At some point somebody should probably break this up into individual YAML files in a config/engines directory or something.\n. Out of curiosity, is this for the case where the engines array is entirely missing from the YAML?\n. The desired behavior, based at least on the previous code, was to call SecureRandom.uuid once for each engine, so I'm just preserving that here.\n. I can't find a solid reference for this, but ||= is actually two operations and thus not thread-safe, right? It's hard to imagine what sort of bug this could cause, but it might just be best to initialize this before spawning secondary threads.\n. Trailing slashes for directories is part of the spec. It's meant to make it a little easier for engine implementors to find directories:\nhttps://github.com/codeclimate/spec/blob/master/SPEC.md (under \"Which files to analyze\")\nSo they should probably be kept in unless there's a strong enough reason to force all the engines to update.\n. I think having both a build and build_with_excludes sort of muddies the intention of this class. And, in fact, you could argue that build here is just build_with_excludes with an empty excludes array. What do you think about merging the two?\n. Looks like you forgot to delete this line.\n. I think our house style is not to put leading underscores on ivars like this. i.e. just @build_without_extra_excludes\n. I missed this change in the last PR, where EnginesConfigBuilder requires somebody else instantiated an IncludePathsBuilder. What's the rationale for that?\nAs it is this will require changes to builder. More conceptually, it seems appropriate for me that EnginesConfigBuilder owns the reference to IncludePathsBuilder, returning the Result that a caller might use to instantiate whichever engine class it's using.\n. Yeah, my vote would be that we keep this responsibility inside EnginesConfigBuilder. If we're genuinely seeing performance issues from this, there are ways to have IncludePathsBuilder cache its own results -- class variables, singletons, etc.\nFor context: builder doesn't even use EnginesRunner any more, it uses a builder-specific class. So pushing this responsibility our of EnginesConfigBuilder is going to lead to some cross-repo duplication.\n. Right, I meant something on the class-level instead of the instance-level.\n. It wouldn't be hard to do as a one-off. It just increases coupling between codeclimate and builder if builder has to be aware of one more class, and how to instantiate it. We've already had a lot of slowness forced on us by how entangled these repos are, so we should be looking to narrow touchpoints as much as possible.\n. This is some fairly confusing branching behavior. And I notice that create_default_configs is called in two places, here in run and lower at the end of generate_config. You might be able to make this clearer if:\n- create_default_config were pulled out of generate_config and put somewhere inside of run, to more clearly communicate the fact that it's going to get called whether or not .codeclimate.yml already exists\n- create_default_config were renamed to indicate we're talking about engine-specific configs\n. ",
    "jonathancadepowers": "@nWidart Hey. Sorry again for the trouble. Can you try running the following three commands:\n$ boot2docker init\n$ boot2docker up\n$ eval \"$(boot2docker shellinit)\"\nIf that doesn't get things working, can you post the output that you get?\n. @nWidart I'm pretty sure you can run boot2docker init from any location. That's what I'm seeing in my testing.\n. @nWidart Glad to hear that did the trick! And great questions:\nTo see where the boot2docker.iso file is stored, run: boot2docker info. Then check the value of \"Iso\":.\nUsing this same command, you can also see if the VM is running or not. Check the \"State\": value.\nTo stop the VM, pass boot2docker stop. Just be sure to start it again the next time you want to run an analysis (by running boot2docker up)\nFinally, in terms of where the actual Docker images are stored, that's a bit more involved, as boot2docker handles all of this for you. If you do want to see which docker images you have on your machine though, you can run docker images.\nThanks for bringing all of these up. I'm going to work on documenting it on our end.\n. @klippx Hey. Sorry for the confusion. I just reworked our documentation to better explain how this works.\nEssentially, when using the Code Climate CLI -- or when using our new engines platform on codeclimate.com -- your .codeclimate.yml file should not contain a languages: node. This node should only be used with our legacy, hosted analysis.\nHere is the (now updated) help doc that explains how this works in more detail: http://docs.codeclimate.com/article/289-configuring-your-repository-via-codeclimate-yml\n. I'm going to go ahead and close out this issue. If there's anything else that we can help with, please let us know.\n. @jhmilan Hey! Thanks for the report, and sorry for the trouble.\nWe just released a new version of the CLI today (version 0.0.9). Go ahead and try updating and then running a new analysis.\nHere are the steps:\n- To update our CLI: brew update && brew upgrade codeclimate.\n- After you update the CLI, next run codeclimate engines:install. That will update the Docker images for the engines.\n- Finally, run codeclimate analyze.\nLet us know if that doesn't do the trick.\n. @stickel, @MattWalker: Hey guys. Sorry for the trouble. It turns out that we had a bug in Version 0.2.4 of the CLI, which was preventing exclusions from working correctly. Sorry about that.\nCould you try upgrading to Version 0.2.5? To do so, run brew update && brew upgrade codeclimate. \nLet us know if that doesn't do the trick!\n. Hey @bruno-\nYou're right -- the types of Ruby checks that we run on our hosted, legacy analysis platform are currently different than what you'll see in our CLI.\nOur plan though is to release more Code Climate engines to perform the types of Ruby analysis that you mentioned (complexity, duplication, etc.). When those are released, you'll be able to run them within our CLI!\nOur team will be working on new engines, plus now that the platform is open/extensible, anyone can build their own Code Climate engines as well. So, the scope of engine-based analysis for all languages should grow over time.\nAs far as grades go, those will just be on codeclimate.com.\nGreat questions! Let us know if we can help with anything else. Thanks!\n. ",
    "nWidart": "No problem at all, I'm new to docker so I'm sure it's just me not using it properly. :)\nDo I have to run the init command in a dedicated folder or something ? Or anywhere is ok ?\nThanks,\n. The steps provided did the trick.\nThough it's not clear to me where docker downloaded the iso image, if it's continuously running on background (what I don't want) or where it downloaded the codeclimate docker image.\n. Thank you for the explanation, very helpful. :smile: \n. ",
    "brynary": "@ABaldwinHunter hmm... any idea why we aren't getting Code Climate results on this PR? Can we check to make sure it's setup properly and also add the badge to the README?\nIf someone added this repo on their local dev env, it could've broken the integration.\n. @pbrisbin actually, the tests fail. However, Circle CI is not reporting on these PRs for some reason. Adding a card.\n. Replaced by #99\n. Did a quick review. One naming comment and one blocker: flags that are more than one character should be prefixed with --.\n. @GordonDiggs I have some ideas, but interested in your take. Can you field @pbrisbin's Q?\n. Quick update: There's been movement on this.\n@ABaldwinHunter  -- Can you provide an update here?\n. @pbrisbin can we fixup the codeclimate issues detected (with the possible exception of the \"long method\" one... that's more subjective)?\n. @pbrisbin where did this shake out?\n. Can you describe briefly in layman's terms the value of this?\n. Makes perfect sense. Thanks.\n. Seems like this should be part of the codeclimate validate-config experience. Pat -- What's your thinking on why a separate subcommand may make sense?\n. Ok. Yeah I thinkI agree with Pat's proposal\n. @jacobi007 I think I fixed the build issue in master. Can you pleasemerge master in here and see if it builds green?\n. Have another idea. Working on it.\n. OK, can you please try one more time?\n. OK, tried another thing. Another merge please? :)\n. Build fixed. There's a couple (pre-existing) bugs that need to be resolved, however.\n. (Added line comments about said bugs)\n. @jacobi007 looks good to me.\nWe'd eventually need the filesystem object if we wanted to make the JSON data more closely match the plain text output, but I think it's ok like this for now.\n. @dbergey can you please merge master into your branch? It should resolve the build failure\n. @grstk some feedback:\n- I think this infers a bit too much. The default config for an engine will not always be \".#{engine_name}.yml\"\n- I'd prefer not to embed the default configs intoengines.yml`\n- Some engines may have more than one config file we want to generate\nGiven all this, I propose that we create a directory structure which is like: config/#{engine_name}/... and any files we put in there are the default configs. For example config/rubocop/.rubocop.yml and config/eshint/.eshint.json (or whatever their config file is called, I forgot).\nThat resolves all of the issues, and I think would be cleaner. WDYT?\n. Also if you merge master, the build should pass\n. LGTM\n. Would it work for us to use a JSON-formatted .eslintrc?\n. OK, sounds good\n. @jacobi007 I think in addition to enabling the engine in this case, we should also configure the languages to be \"Ruby\". Thoughts on how we could do that?\n. I'm good with this.\n. You are correct that sudo docker version errors out. Good catch.\n(And, as expected, sudo DOCKER_HOST=$DOCKER_HOST DOCKER_TLS_VERIFY=$DOCKER_TLS_VERIFY docker version works. It's the missing ENV vars that break it.)\nAt the very least, does this mean we should update our instructions to ask the user if sudo docker version works?\nAnyways, continuing on make install PREFIX=/tmp seems to work. However, /tmp/bin/codeclimate version then fails with:\n```\n$ /tmp/bin/codeclimate version\nYour Docker setup does not support the codeclimate wrapper script:\n\n/var/run/docker.sock\n\nWe require a local Docker daemon that supports communication via the default\nsocket path.\nPlease use docker run' to run thecodeclimate/codeclimate' image directly.\nSee https://github.com/codeclimate/codeclimate for more details.\n```\nThis doesn't surprise me, as I remember we accepted this limitation. However, I think we could workaround this limitation in the wrapper fairly easily for people using a boot2docker/Docker machine setup (like I am). My understanding of the issue with the wrapper is around volume mounting... however, in the case of Docker machine, there is a shared filesystem between the Mac and the VM running Docker. So, I think we'd need something like a CODECLIMATE_VOLUME_PATH environment variable, and then we could tweak the --volume options we send to Docker appropriately, and things would just work.\nThat can/should be a separate issue/PR, but what do you think about updating the bin/check error output to help avoid this tripping someone else up?\n. @pbrisbin if ran as root can we insert sudo into the help text, but not if it is not run as root?\nThat should be easy/simple/quick and I don't think the edge case of root-without-sudo is particularly worth worrying about\n. Lgtm\n. I would omit normal and only print info and severity. We an put it in brackets next to the engine name. Critic in red, info in another color.\n\u2014Bryan Helmkamp, Founder, Code Climate\nbryan@brynary.com / 646-379-1810 / @brynary\nTyped with thumbs.\nOn Wed, Oct 7, 2015 at 4:00 PM, Ashley Baldwin-Hunter\nnotifications@github.com wrote:\n\n@codeclimate/review @mrb @brynary \nUpdated to use severity instead of confidence in plaintextformatter.\nJSON formatter already works as is.\nPlaintext formatter sample output:\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/codeclimate/codeclimate/pull/132#issuecomment-146311519\n. Actually, I'd maybe display the issue when it is [info] or [critical] and leave it off for normal\n. Going in a different direction.\n. This looks like it's getting stale. Should we close it?\n. Let's punt on this for the moment.\n. Also see https://github.com/codeclimate/codeclimate-fixme/pull/12\n. Fine to close this\u00a0\n\n\u2014Bryan Helmkamp, Founder, Code Climate\nbryan@brynary.com / 646-379-1810 / @brynary\nTyped with thumbs.\nOn Tue, Nov 17, 2015 at 11:16 AM, Will Fleming notifications@github.com\nwrote:\n\nThat card is really old. My guess is that the use-case @brynary had in mind for this was what we ended up addressing with --upgrade, and that this card should be dropped. Bryan, can you chime in if you had other cases in mind?\nReply to this email directly or view it on GitHub:\nhttps://github.com/codeclimate/codeclimate/pull/212#issuecomment-157417955\n. @ABaldwinHunter are there other specific issues we've identified with not having these excludes in places besides the fixme issue?\n. LGTM\n. LGTM\n. :clap:\n\nWith this model, if there is an unreadable file let's say lib/urneadable.rb that is not explicitly excluded... a) what the workspace paths provided to the engines look like? and b) are we still expecting the engine to potentially raise an exception if/when it tries to read it? (I think this is actually desirable, for the record)\n. OK, great. Both of those answers were what I was hoping/expecting. Do we have benchmark numbers on this implementation compared to current?\n. > We do! For a known case I have on a local repo where workspace building used to take 20-30 minutes, it now takes less than 1 second. \nSomething something computer science something big-Oh notation blah blah :)\n. OK, so with this behavioral change what's the customer impact we need to communicate? How would we instruct someone who has exclude paths to know if they need to do anything, and if so what do they need to do?\n. @wfleming I think we can probably roll this out with just a Changelog. Can discuss tomorrow.\n. @pbrisbin @toddmohney Pat is accurate that #2 is not desirable from a product standpoint. Normally it'd be an \"implementation detail\" but we expose generated configurations in the app and encourage people to download, commit and modify them, so anything we introduce into the configuration file is content that we can get \"stuck\" with (it's hard to get everyone to change their configurations).\nAs discussed, we do have the ability to ensure configuration files are as-needed because we will be hand-holding people through the setup of Pro. I wasn't envisioning the need to go back and have them modify the configuration files again, but it's not a deal breaker, just more work for the customer success team.\nMy question is:\nHow far did we get, and what difficulties did we encounter implementing this on the read-side? (In essence, could we make the list of engines returned by the CLI include an extra element if the special ENV var is set?, for now)\n. Thanks for the additional explanation, Todd. Very helpful . > \ud83d\udc4b Doing some New Year's cleaning and (with @GordonDiggs's OK) am closing out inactive PRs (more than 30 days w/ no activity), using the handy Pull Requests report in Velocity.\n\nThis is not an editorial judgement on the value of the PR, I'm just acting as a human \ud83e\udd16 . Please feel free to re-open in the future if you'd like to advance this further.. > \ud83d\udc4b Doing some New Year's cleaning and (with @GordonDiggs's OK) am closing out inactive PRs (more than 30 days w/ no activity), using the handy Pull Requests report in Velocity.\nThis is not an editorial judgement on the value of the PR, I'm just acting as a human \ud83e\udd16 . Please feel free to re-open in the future if you'd like to advance this further.. @pbrisbin find is not intended to be a speed improvement, it's an improvement because Dir.glob blocks signal handling, and so you can't stop it with CTRL+C.\n\nI will use -print0\n. This should be --dev instead of -dev\n. Doesn't seem like the make_ prefix here conveys much.\n. I actually put this here intentionally because I wanted to separate this from the other threads (which are handled differently, and are grouped together)\n. In the timeout case, the process does not get cleaned up.\n. Hmm, --interactive is about STDIN, not STDOUT. I wonder if it should not be affected.\n. Sounds good\n. Someone should add a rubocop check for flat_map :)\n\u2014Bryan Helmkamp, Founder, Code Climate\nbryan@brynary.com / 646-379-1810 / @brynary\nTyped with thumbs.\nOn Thu, Jul 23, 2015 at 6:31 PM, pat brisbin notifications@github.com\nwrote:\n\n\n\nend\n  +\ndef expanded\n@expanded ||= expand\nend\n  +\nprivate\n  +\ndef expand\nresults = Dir.chdir(@root) do\n@patterns.map do |pattern|\nDir.glob(pattern)\nend\nend\n  +\nresults.flatten.sort.uniq\n  Could remove flatten by using flat_map above.\n\n\nReply to this email directly or view it on GitHub:\n  https://github.com/codeclimate/codeclimate/pull/67/files#r35389255\n. I don't think we have that exit code behavior currently, so if so we should do that separately. Probably want a CommandResult object so we don't litter exit calls in the classes\n. We need to adjust the usage of Formatters.resolve so it also passes a filesystem param\n. The initialize method in the JSONFormatter will need adjustment to accept filesystem (currently takes no args)\n. Is this the same as Dir['**/*'] or something similar? Why do we need git at all?\n. I don't love hardcoding specific engine names here. Rather than doing that, what if we add:\n\n\nyaml\nduplication:\n  # ...\n  default_config:\n    languages:\n      - ruby\nTo engines.yml and use that?\nThat would work for now, and we can revisit when we run into the issue of: \"How do we make the languages variable, based on what we find when we init?\"\n. BTW, should this be \"ruby\" or \"Ruby\"? Do both work?\n. docker kill (and all docker commands0 accept a container name as a substitute for the container ID. Therefore, I think the name lookup is unnessary.\n. Doubtful. The behavior I'm referring to has been in Docker for a long time now. Example:\n```\n$ docker run -d --name=foo alpine sleep 120\n219b77e8f943b41c4ca61461c123af62f2e7533a5ac23fa23734c75c739e67e1\n\u263a ~ \n [osx 18:41:36] $ docker kill foo\nfoo\n```\n(That's off 1.8.2)\n. This was a change I had to make to get things working in my local dev environment (where I run everything within a Docker container. Since it's an ||= it seemed safe enough to commit)\n. This was a change I had to make to get things working in my local dev environment (where I run everything within a Docker container). This directory seems to need to exist to write the config, and I don't see where we are creating it. This seemed safe enough, and should no-op if it is already there.\n. The error that comes back is basically \"File not found /engine.json\" so it seems OK for now.\n. Can we also get a spec for: foo/../../../../bar?\n. ",
    "d-Pixie": "Tried running the csslint engine as well and it errors out with:\nRunning csslint: -[FATAL] failed to allocate memory\nI think this is after the linting is done and it's attempting to parse the JSON. I ran it several times and got this when force quitting after it hung:\n$ codeclimate analyze\nStarting analysis\nRunning csslint: Done!\n/usr/lib/ruby/gems/2.2.0/gems/json-1.8.3/lib/json/common.rb:155:in `parse': failed to allocate memory (NoMemoryError)\nfrom /usr/lib/ruby/gems/2.2.0/gems/json-1.8.3/lib/json/common.rb:155:in `parse'\nfrom /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:16:in `write'\nfrom /usr/src/app/lib/cc/analyzer/engine.rb:25:in `block (2 levels) in run'\nfrom /usr/src/app/lib/cc/analyzer/engine.rb:24:in `each_line'\nfrom /usr/src/app/lib/cc/analyzer/engine.rb:24:in `block in run'\nMy computer has about 2GB of free memory while running this so I'm assuming it's the VM that's the problem here. Any configuration options for increasing the VM memory size and see if these goes away?\n. No, it's an internal project. Not on Github but using Git (in Stash at the moment). I might get permission to put it in a private repo and link that into CodeClimate if that would help?\n. Ok, just let me know if I can help :)\n. Ok, I'll try that tomorrow and report back :)\nOn 25 Jun 2015 4:54 pm, \"pat brisbin\" notifications@github.com wrote:\n\nActually, looking again, it is the codeclimate image running out of\nmemory, not the engine itself, so increasing available memory to your\nboot2docker VM could help. I believe you can tune this in the Virtual Box\nor VMWare GUI (whichever backend you're using).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/23#issuecomment-115283675\n.\n. A little later than tomorrow but here is an update: I changed the settings on the Virtualbox VM to allow for 4GB of memory, instead of 2Gb that is the default, and rerun the tests.\n\ncsslint passes and produced output as expected. phpcodesniffer finished but did not produce any results (and trust me, there are lots of results to produce here :)). eslint is still running, several hours later ...\nSo it's a mixed bag, but the initial problems seems to have been due to the VM running out of memory.\n. ",
    "mrb": "Issues addressed @pbrisbin \n. @GordonDiggs Cool, I think this should go to 0.0.10\n. /c @brynary \n. /c @GordonDiggs \n. Yay! :tada: \n. /c @codeclimate/review \n. @ABaldwinHunter - Use info < normal < critical but only display the level when it is normal or critical. Display the issue in all cases.\n. @stphung Hey Steven! Gordon pinged me on this issue because it's my responsibility to make sure that developers building engines have an excellent experience. Let's take this to email - mind shooting me a message at mrb@codeclimate.com ?\n. @mikebryant Hey Mike! Wow, nice! Can you shoot me an email at mrb@codeclimate.com? Thanks!\n. @wfleming Thanks! I'll handle the blog update. /c @andyw8 \n. @pbrisbin FWIW I think the interaction you described with single file analysis is totally fine.\n. This discussion has been taken offline - the engine is being tested locally!\n. @GordonDiggs Ready for re-review\n. @dblandin Yep!\n. @pbrisbin @wfleming Yes almost certainly because of two things:\n- Different SimpleCov version\n- Implicit SimpleCov configuration that was happening under the auspices of the old test-reporter, which invoked SimpleCov\nBut I'll look into it more in the morning.\nAlso seems relevant: https://circleci.com/gh/codeclimate/codeclimate/1469?utm_campaign=vcs-integration-link&utm_medium=referral&utm_source=github-build-link\n. @pbrisbin @wfleming As per the citest target here: https://github.com/codeclimate/codeclimate/blob/update_test_reporter/Makefile#L26 we run:\nbundle exec rake spec:all spec:benchmark && bundle exec codeclimate-test-reporter\nWhich produces:\nCoverage report generated for RSpec to /usr/src/app/coverage. 3178 / 3241 LOC (98.06%) covered.\nAnd also produces:\nCoverage report generated for RSpec to /usr/src/app/coverage. 160 / 205 LOC (78.05%) covered.\nin the build. Reproducing locally, I found that the second results overwrite the first. That's the story there.\n. @pbrisbin Works for me!\n. @wfleming @pbrisbin Ok after filtering specs and excluding the benchmark results, we're back to the same coverage %.\n. :+1: @GordonDiggs Assuming I'll have to do something similar for other OSS repos?\n. Can do.\n. @pbrisbin This tool only looks at one file, and doesn't impact grades yet, so I think we're fine for now.\n. @gordondiggs probably not too hard! I'll give it a shot. \n. :+1:\n. :+1:\n. ",
    "jhmilan": "Paths excluded. Nice!\n. ",
    "stickel": "I've updated to the latest version of codeclimate and the engines. codeclimate is still analyzing directories that are supposed to be excluded.\n``` shell\nengines:\n  coffeelint:\n    enabled: false\n  eslint:\n    enabled: true\nratings:\n  paths:\n  - \".js\"\n  - \".scss\"\nexclude_paths:\n- \"node_modules//\"\n- \"app/assets/build/\"\n- \"app/assets/fonts/\"\n- \"app/assets/images/\"\n- \"server/*\"\n```\nAnd the output still has errors like this:\n``` shell\n== node_modules/webpack/node_modules/webpack-core/node_modules/source-map/node_modules/amdefine/intercept.js (1 issue) ==\n0:0-0:0: Cannot find module 'babel-eslint' [eslint]\n== server/config/config.js (1 issue) ==\n0:0-0:0: Cannot find module 'babel-eslint' [eslint]\n```\nIt's my understanding that even if those errors are legit, they shouldn't be appearing because codeclimate should be excluding the server/**/* and node_modules directories.\n. @GordonDiggs Sorry, poor copy/paste job. My server glob is server/**/* in the file. There are no subdirectories in each of app/assets/[build/fonts/images].\n. @jonathancadepowers Looks like v0.2.5 is properly ignoring files now. brew upgrade codeclimate failed the first time I tried because I didn't realize boot2docker/docker needed to be running. :wink:\n. Alright, thanks for the info/update @GordonDiggs \n. ",
    "MattWalker": "Having the same issue.\n- OS X 10.10.3\n- boot2docker 1.7.1\n- codeclimate CLI 0.1.5\nI stripped down .codeclimate.yml to:\n``` yaml\nengines:\n  coffeelint:\n    enabled: true\nratings:\n  paths:\n  - \".coffee\"\nexclude_paths:\n- \"node_modules//*\"\n```\nHere's a sample of codeclimate analyze output:\n``` bash\n== node_modules/protractor/node_modules/selenium-webdriver/node_modules/xml2js/83.coffee (1 issue) ==\n4-4: Line exceeds maximum allowed length [coffeelint]\n== node_modules/protractor/node_modules/selenium-webdriver/node_modules/xml2js/incompat.coffee (2 issues) ==\n2-2: Line exceeds maximum allowed length [coffeelint]\n4-4: Line contains inconsistent indentation [coffeelint]\n```\nEverything in node_modules was processed.\n. ",
    "bruno-": "Hey,\nit's good to hear you guys will be open sourcing more engines eventually. That will increase the value of the open sourced CLI tools dramatically.\nBe sure to let us know when new engines are out!\nThanks for the fast and friendly response!\n. ",
    "bassrock": "@fhwang One of the latest must have fixed this. To my knowledge it looks like it is working now.\n. ",
    "ivantsepp": "Thanks for taking a look and clarifying the --dev flag!\n\nWe do plan to incorporate this engine (and many others) when it's done, at which time we'll also add it to\u00a0engines.yml.\n\nIs there an engine underway for scss-lint? If not I'd love to help with that!\n. @GordonDiggs Made the changes! Not sure what that build failure is about though. Looks like it's something to do with gcloud not authenticating?\n. Before:\nStarting analysis\nRunning rubocop: Done!\nRunning scss-lint: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine scss-lint failed with status 1 and stderr \"/usr/src/app/lib/cc/engine/scss-lint.rb:48:in `read': Is a directory @ io_fread - /config.json (Errno::EISDIR)\\n\\tfrom /usr/src/app/lib/cc/engine/scss-lint.rb:48:in `parse_config'\\n\\tfrom /usr/src/app/lib/cc/engine/scss-lint.rb:11:in `initialize'\\n\\tfrom /usr/src/app/bin/codeclimate-scss-lint:6:in `new'\\n\\tfrom /usr/src/app/bin/codeclimate-scss-lint:6:in `<main>'\\n\"\nAfter:\nStarting analysis\nRunning rubocop: Done!\nRunning scss-lint: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine scss-lint failed with status 1 and stderr\n/usr/src/app/lib/cc/engine/scss-lint.rb:48:in `read': Is a directory @ io_fread - /config.json (Errno::EISDIR)\n    from /usr/src/app/lib/cc/engine/scss-lint.rb:48:in `parse_config'\n    from /usr/src/app/lib/cc/engine/scss-lint.rb:11:in `initialize'\n    from /usr/src/app/bin/codeclimate-scss-lint:6:in `new'\n    from /usr/src/app/bin/codeclimate-scss-lint:6:in `<main>'\n. Sweet! thanks for looking!\n. ",
    "lucasmartins": "I've had the same problem, disabling SElinux \"solves\" it.. ",
    "bobbytables": "@pbrisbin @GordonDiggs - Style comments applied. I agree dev_mode? is an odd method but it allowed me quickly try this out.\nA real option parser would help these problems.\n. ",
    "ktowle": "+1 on the ability to analyze a single file, or perhaps also a single directory\n. ",
    "benjaminwood": "Sweet, that's awesome news! Thanks @ABaldwinHunter for the updates and do the rest of the team that worked on the feature.\n. ",
    "ablyler": "I uninstalled docker and friends, and re-installed and it is working now.\n. @pbrisbin good call, updated\n. @brynary looks like @dbergey did the merge. :+1: \n. ",
    "joshpfosi": "I actually realized that docker version had been failing and this is probably related. I was also under the impression that more engines for Ruby (beyond rubocop, which I am already using) were available on the CLI. #36 makes me think otherwise! Looking forward to this project's development though! Very cool!\n. ",
    "geshan": "needed to do init again.\n. ",
    "emosbaugh": "+1\n. ",
    "knownasilya": "Is there a date that we could expect this to be supported? Basically makes codeclimate useless for any modern apps, or apps using custom eslint modules, like with standard.\n. ",
    "tomchentw": "I really like the interface provided by codeclimate and hope this could be fixed soon. Thanks a lot :100: \n. ",
    "cilindrox": "+1\n. @wfleming using standard JS style which we enforce via the eslint-config-standard plugin, so I'm on the same boat as some of the other folks here :/\n. ",
    "abey-alex": "+1\n. ",
    "dmiskiew": "I restarted the boot2docker and everything works correctly.\nThe cause of this problem may be related to the fact, that I switched to another internet connection while using the VM.\n. ",
    "elwayman02": "Anyone there? :(\n. The repo is not public, unfortunately.\n. There are only 3 directories not excluded by my config: \napp/\nconfig/\npublic/\n. In Ember projects, app/ is not the root directory.  It is a neighbor to node_modules.  The project structure looks like this:\napp/\n  adapters/\n  components/\n  controllers/\n  etc...\nbower_components/\nconfig/\ndist/\nnode_modules/\npublic/\ntests/\ntmp/\nvendor/\n.codeclimate.yml\nAs you can see, app/ only contains project files, ie code that we've written.  All third-party library code lives outside the app/ directory.\n. The default permissions on my project directory are drwxr-xr-x  29 jordan  staff   986.  How can I make sure docker has write access?\n. Ran it again (so the filename will be different):\n16777220 35719825 drwx------ 15 jordan staff 0 510 \"Aug 11 11:23:28 2015\" \"Aug  6 19:16:45 2015\" \"Aug  6 19:16:45 2015\" \"Aug  6 19:16:33 2015\" 4096 0 0 tmp/asset_rewrite-cache_path-YSmsAl3D.tmp/\n. Any ideas on how I can fix this?\n. Ok, thanks!\n. Running those commands didn't help, because the file itself is created as part of the analysis and I can't fix the permissions until after the analysis has failed.  I can fix the directory permissions, but it doesn't stop the analysis from failing.\n. We don't have any special configs/plugins for ESlint in our project (not even .eslintrc).  I was trying to use the defaults from codeclimate just to get it working first.\n. @ABaldwinHunter I ran across another related issue, which I can log separately if you prefer.  Once I ran the chmod 644 on the files in tmp/, it broke my cleanup scripts for the project.  I couldn't clean tmp/, because rimraf didn't have permission to remove the files created by codeclimate.  I can't run the clean script with sudo, because the script runs some other commands like npm cache clean and bower cache clean which don't necessarily work with sudo.  Something to keep in mind as you address the permissions issues for engines :)\n. @pbrisbin running my clean script:\n\"clean\": \"npm cache clean && bower cache clean && rm -rf node_modules bower_components dist tmp\"\nThis does seem to allow the analysis to run successfully!  The problem here is seemingly that codeclimate's \"exclude_paths\" directive isn't being respected by the engines.  tmp should never have been analyzed in the first place, so there shouldn't have been a problem with eslint generating files into that directory.\nUnfortunately, I can't share the repo, but this seems to be a breakthrough perhaps?\n. codeclimate is not creating these files.  The files are created as part of the ember-cli build process.  That said, I don't think it's a reasonable workaround to configure it to write to a different directory.  This is the default setup for all ember-cli apps; unless you convince the ember-cli devs to change how their project is configured, every Ember app that attempts to use codeclimate will run into this issue, unfortunately.\n. No problem! I'm happy to help provide any info needed to get this resolved, so we can switch to using Engines :)\n. Thanks @pbrisbin pulling the latest docker image now! :)\n. Doesn't seem to be working still...I updated codeclimate from docker and pulled the latest eslint engine...the error is different but it's still not actually running the config. The analysis runs for about 5-10 minutes (eslint cli itself takes <30s when run outside of codeclimate), and then I get this:\n```\njordan$ codeclimate analyze -f text\nStarting analysis\nRunning eslint: Done!\n== Brocfile.js (7 issues) ==\nerror: (NoMethodError) undefined method `source_buffer_for' for \"/code\":String\n```\nThis is especially confusing because there is no method (or even text string) source_buffer_for anywhere in my project, which leads me to believe this error is coming from codeclimate.\n. Thanks @pbrisbin, though I'm not confident that eslint was actually run correctly, but it does seem like a new/different issue this time.\n. Thanks @GordonDiggs!\n. Awesome, glad to hear it!\n. Please let me know what information you need, though most of it is in #82 already.\n. I've since updated my codeclimate config to only enable the eslint engine, in order to test that specifically to be working.\n. :+1:\nOn Fri, Sep 25, 2015 at 11:12 AM pat brisbin notifications@github.com\nwrote:\n\nHey, just a headsup: I found the source of this bug and am getting started\non a fix.\nIt's actually a bug in the -f option handling. Running without it (which\nis functionally the same as -f text, since text is the default) should\nwork for you.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/111#issuecomment-143311649\n.\n. \n",
    "sysadmiral": "No probs. Although I committed a typo...\n\n. They tweeted out about this a while ago: https://twitter.com/codeclimate/status/624265704846585856\nI was going to start looking at wrapping shellcheck in an engine soon.\n. :+1: \n. ",
    "Soliah": "Docker run works fine but is a bit cumbersome.\nBy deprecated I mean the CLI is deprecated and Docker Machine will be taking over that responsibility. Docker Machine is still using the same boot2docker ISO though at this stage. \nhttps://github.com/boot2docker/boot2docker-cli readme indicates the deprecation. \n\nOn 14 Aug 2015, at 12:18 am, pat brisbin notifications@github.com wrote:\nboot2docker has been deprecated in favour of Docker Machine\nCan you link to a source on this? We weren't aware of that.\nI'm not familiar with Docker Machine, or know what it would take to get the wrapper script working in such a setup, but we can certainly look into it.\nDoes using docker run directly as the error message suggests work for your setup?\nYou can check here for example options. You'll probably need to adjust them since you don't have a /var/run/docker.sock.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "dylangrafmyre": ":+1: \nThe maintainer of scss-lint also has slim-lint and haml-lint. Maybe you can add 3 for the price of one :)\n. Great! Thank You!\n. ",
    "aliceinwire": ":+1\n. ",
    "edbo": "Thanks that got it.\n. ",
    "jacooobi": "@brynary it didn't help :/\n. Noted, thanks!\n. I've modified the JSONFormatter and it takes a filesystem argument now. On the other hand I'm wondering if that's the best solution because the variable remains unused.\n. @brynary Check out my solution. Btw I can't access the codeclimate issues, so not sure what's wrong with the code.\n. Should be ok now, @brynary \n. Hmmm some tests failed, let me get back to you once I fix it\nEdit: oh I just realized that the reload method comes from a gem version that has not been released yet...\n. Thanks for the info @ABaldwinHunter . I've reverted the last commit as it was referencing code from my old PR to yaml-repo which is no longer relevent in the light of mxie's pull request . I think there is nothing else stopping us here.\n. ",
    "dbergey": "I'm not sure. I haven't had a chance to test on a fresh machine yet. I can do that soon, or someone else can try it out. \n. ",
    "kulte": "@dbergey I'm very new to Docker, can I pull the image from this PR before it gets merged/pushed to Docker registry server so I can roll with the new Docker Toolbox on my machine?\n. ",
    "sveinn": "\n\"This PR LGTM, but I still think we need an answer to Gordon's question before merging:\n\nDoes this also work for people who start from scratch and install Docker Toolbox (rather than migrating from boot2docker)\"\n\n\n@pbrisbin I did not migrate from boot2docker and the following worked for me:\ngit clone https://github.com/dbergey/codeclimate\ngit checkout support-docker-machine\nmake install\ncodeclimate help\n. ",
    "scottspeidel": "@pbrisbin, thanks for the information. I apologize for my oversight. \n. ",
    "grstk": "@brynary sounds reasonable. I'll be back with the improvements soon.\n. Yes, eslint accepts both formats. I used YAML only because I find it cleaner and easier to read than JSON.\n. ",
    "BlakeWilliams": "I forgot to mention it, but is this the same thing? https://github.com/codeclimate/codeclimate/pull/130\n. Yeah, we should close this PR unless there's any objections.\n. @mxie @wfleming I cleaned it up a bit. One more look?\n. LGTM\n. cc @codeclimate/review \nThis will also require a new release to be cut.\n. https://github.com/codeclimate/codeclimate/compare/v0.8.0...bmw-cc-yaml-upgrade\n. or do you mean for YAML?\n. https://github.com/codeclimate/codeclimate-yaml/compare/v0.2.3...v0.3.0\n. Thanks! Thanks for taking a look!\n. Thanks for the review!\n. @fhwang Changed the public API to be just build\n. Thanks for the reviews!\n. @fhwang Made include_paths_builder optional now.\n. Yep, turns out some other requirement need it too. So adding that in. :smiley: \n. Oddly enough it's passing locally. I'll look into that.\nI tried it out locally giving it several files, single file, and directories and it seemed to work as intended.\n. cc @codeclimate/review \n. Yeah, they should since it's only created with  IncludePathsBuilder.new(exclude_paths, Array(@requested_paths)).build\n. This doesn't fix duplicate paths. I'm not sure how to reproduce that one.\n. I was thinking we could either merge this fix and start a new PR or figure out how to repro the duplication issue.\n. I haven't looked into it yet since they're two different issues and this is the fix individual paths.\n. It definitely rebuilds some functionality unintentionally, but we can revisit that later like you said.\nI'll squash and merge. Thanks for the review!\n. It also needs to set \"enabled\" => true on the engine so I don't think this will work unless we extract that as well.\n. I agree. I just used what it was called in the calling method. I think it would be nice to refactor the entire file.\n. Hah, just put two and two together on this one. Union equals.\n. I accidentally deleted private above it. :stuck_out_tongue: \n. Good catch!\n. Wanna bump this back up to 0.10.2?\n. Yes, it's updated in this branch.\n. I can remove it if we prefer that. I only disabled it because CC reported it and was failing the build.\nDo we prefer not to have assignment in condition? If there's no consensus I wouldn't mind making a PR to the style guide.\n. No worries! :+1: \n. Weird! I'll try that, thanks.\n. Gotcha, wasn't sure if there was a reason for that or not. I'll change it back.\nThe engine should probably check for itself too though.\n. I started looking into it but I don't think we'd want to call glob_or_include_path if @cc_include_paths is empty because Dir.glob(\"**/*\") already includes all files / folders.\nThe case where we need glob_or_include_path is when the class is given @cc_include_paths that have directories since we need to work on the files in the directory at this stage.\n. Fair enough. One reason I avoided it was so that it wouldn't have to loop over the paths another time.\nI'll change it to just build with an optional extra_excludes param. :+1: \n. Yep!\n. :+1: \n. Even if they're not meant to be used directly?\n. Talked about this in Slack, keeping for now.\n. It's so we don't have to rebuild the paths from scratch each time we run a new engine. We could probably hoist that logic higher so it builds using the correct config one level higher, but this seemed like this class already handled it so I added it here.\n. Gotcha, I wasn't aware that it wasn't using EnginesRunner. I'll work on moving this out.\n. Also, IncludePathsBuilder does cache its own results, which is why we pass down the instance to EnginesConfigBuilder due to having the global excludes and then engine specific excludes.\n. Ah, gotcha, missed the singleton part.\nWould it be hard to do this in builder? I think all you need to do is pass in:\nruby\nIncludePathsBuilder.new(\n  @config.exclude_paths || [], @requested_paths\n)\nIf not this might be worth moving to a singleton if that works for builder.\n. Right, I'm 100% unaware of builder and how it works so I want to make sure whatever change I make here is going to be compatible / what we want to do while also keeping the startup time of each engine down in the CLI.\n. No idea, I didn't remove this manually.\n. Good catch, was left over from debugging.\n. :+1:\n. I can extract the before block, but I think the let has to stay since it's used waaaaay above.\n. I think these are the exclude_paths that users give us.\nI'll look into PathPatterns and see if that works here.\n. Yeah.... Just gonna say that it wasn't me. :stuck_out_tongue: \n. @pbrisbin I replaced my method for matching globs with this.\n. Oops! This was left over from when we were discussing it and then I got sidetracked. Adding it back in.\n. Doesn't the glob_value method do the proper conversion? It's being given to me as **/*.rb currently.\nI don't think I completely understand when that would get passed in (\"**.rb\") and how I would make sure both work.\n. Right, but I think glob_value turns **.rb into **/*.rb, or am I wrong?\n. Oh I see. That's strange.\n. The class doesn't accept multiple paths, it just generates entries for a given path. I'll add a test for no slash though.\n. Gotcha! That's kind of a tricky one. I'll use expand instead.\n. Welcome back! I do!\n. ",
    "squaresurf": "@GordonDiggs I'm running version 0.3.1.\n. @pbrisbin that worked. I was able to get the codeclimate wrapper script by creating a default docker machine.\nThis is definitely going to become an issue as more people migrate. As you can see in the official docker docs, their instructions name the machine dev which would also break the codeclimate wrapper script.\n. I'm not sure you need a default if the code is only for docker-machine since it appears that docker-machine env sets $DOCKER_MACHINE_NAME\n```\n$ docker-machine env default                                                                                                                                                         \nexport DOCKER_TLS_VERIFY=\"1\"\nexport DOCKER_HOST=\"tcp://192.168.99.101:2376\"\nexport DOCKER_CERT_PATH=\"/Users/daniel/.docker/machine/machines/default\"\nexport DOCKER_MACHINE_NAME=\"default\"\nRun this command to configure your shell:\neval \"$(docker-machine env default)\"\n```\n```\n$ docker-machine env docker-dev                                                                                                                                                      \nexport DOCKER_TLS_VERIFY=\"1\"\nexport DOCKER_HOST=\"tcp://192.168.99.100:2376\"\nexport DOCKER_CERT_PATH=\"/Users/daniel/.docker/machine/machines/docker-dev\"\nexport DOCKER_MACHINE_NAME=\"docker-dev\"\nRun this command to configure your shell:\neval \"$(docker-machine env docker-dev)\"\n```\n. @pbrisbin I went ahead and opened a PR to fix this :smile:\n. How long before I can expect a release with this fix?\n. Thank you @GordonDiggs!\n. ",
    "albertpak": "Ran: pwd\nOutput: /Users/albertpak/Sites/site1\n\nRan: stat .\nOutput: 16777220 4627266 drwxr-xr-x 30 albertpak staff 0 1020 \"Sep 17 18:27:27 2015\" \"Sep 17 17:44:16 2015\" \"Sep 17 17:44:16 2015\" \"May  2 00:59:10 2015\" 4096 0 0 .\n\nRan: stat ..\nOutput: 16777220 932628 drwxr-xr-x 20 albertpak staff 0 680 \"Sep 18 09:38:35 2015\" \"Aug 14 15:52:57 2015\" \"Aug 14 15:52:57 2015\" \"Oct 31 14:06:13 2014\" 4096 0 0 ..\n. I tried chmod 755 . and then ran codeclimate init and still got the same error\n. ran it and then ran it with sudo permissions\noutputs of stat . and stat ..\n\n```\n16777220 141713816 drwxrwxrwx 25 albertpak staff 0 850 \"Sep 18 11:19:20 2015\" \"Sep 18 10:39:54 2015\" \"Sep 18 11:18:58 2015\" \"Jul 20 23:12:04 2015\" 4096 0 0 .\n16777220 6156819 drwxr-xr-x 8 albertpak staff 0 272 \"Sep 18 11:19:27 2015\" \"Sep 15 14:58:33 2015\" \"Sep 15 14:58:33 2015\" \"May  5 00:25:18 2015\" 4096 0 0 ..\n``\n. nope, it no other messages or anything before or after. justerror: (Errno::ENOENT) No such file or directory @ dir_chdir - /code. so i finally got it to work, i was running jsutdocker run codeclimate/codeclimate, but then i changed it todocker run --interactive --tty --rm --env CODE_PATH=\"$PWD\" --volume \"$PWD\":/code --volume /var/run/docker.sock:/var/run/docker.sock --volume /tmp/cc:/tmp/cc codeclimate/codeclimate` and it worked like it should\nsorry for the trouble\n. :) thank you for quick responses\n. sweet :)\n. ",
    "ambles": "docker run --interactive --tty --rm --env CODE_PATH=\"$PWD\" --volume \"$PWD\":/code --volume /var/run/docker.sock:/var/run/docker.sock --volume /tmp/cc:/tmp/cc codeclimate/codeclimate init works perfectly fine with me. \nAfter the .codeclimate.yml is generated, docker run --interactive --tty --rm --env CODE_PATH=\"$PWD\" --volume \"$PWD\":/code --volume /var/run/docker.sock:/var/run/docker.sock --volume /tmp/cc:/tmp/cc codeclimate/codeclimate analyze starts the analysis. \nGood Luck!\n. ",
    "mxie": "@pbrisbin You could potentially do a stub_const on FORMATTERS to make sure that we're only ever passing in something that's in that array (and raise otherwise).\n. Ah, I see...so it's on the Analyze class instead then? Could you spy on the resolve method?\n. Tagging @codeclimate/review for a review. (Can someone also just add Blake on this team?)\n. LGTM, but maybe get a set of eyes from a CC dev just in case.\n. Just a few nitpicks, but this refactor looks awesome. Great job!\n. A few nits. LGTM otherwise.\n. LGTM\n. Use the same spacing for both lines.\n. Is this style preferred over += or even just included_file_entries + included_subdirectory_results?\n. You could replace the above 5 lines with something like this:\nruby\nobj.each_with_object({}) do |included, result|\n  result[included]\nend\nand it'll return the resulting hash at the end.\n. How about using none? over !<whatever>.any??\n. Similar trick here as https://github.com/codeclimate/codeclimate/pull/107/files#r39193403 using each_with_object but with a [].\n. If paths is any array, can we get away with just doing if paths.present? instead?\n. Can we combine these cases? i.e. when '-e', '--engine'\n. What do you think about doing something like...:\nruby\ndef create_codeclimate_yaml\n  # ...\n  config[\"engines\"][engine_name][\"config\"] = build_engine_config(engine_config)\n  # ...\nend\n...and then just have build_engine_config return the appropriate config hash?\n. Oh wait...nevermind.\n. It feels like there should be a cleaner way to do this...but I can't think of anything. Shouldn't be a blocker though.\n. Maybe name this with ? since it's returning a boolean.\n. I think attr_readers generally belong near the top of the class definition.\n. Alternatively: delegate :to_yaml, to: :config, but shrug.\n. Can we make this into a constant instead? This seems unlikely to change per instance.\n. Could be combine these 2 lines to make it into a single print statement?\n. Finds\n. Could we just say CSS?\n. Ah ok. Sure!\n. ",
    "andyw8": "Hah, thanks, I've no idea how that smart quote got in there.\nNow when I run I'm seeing just error: (NoMethodError) undefined methodeach' for nil:NilClassbut there is no backtrace at all. Is there any way to see that?\n. You'll need to wrap the arguments toraise` in parentheses for this to be valid syntax.\n(However, RuboCop's rule for this is somewhat controversial \u2013 see this post by Avdi Grimm for arguments in favour of using and and or).\n. Hi @GordonDiggs \nLook at the defaults, there's some that should be non-controversial:\nRSpec/EmptyExampleGroup:\n  Description: Checks if an example group does not include any tests.\nRSpec/Focus:\n  Description: Checks if examples are focused.\nRSpec/LetSetup:\n  Description: Checks unreferenced `let!` calls being used for test setup.\nBut that's probably not enough to justify enabling the gem. Thanks anyway!\ncc @bquorning @backus. I'm also running lots of parsing problems due to the old version of ruby-parser.. I think the exclude_paths method defined on line 87 will override this?\n. ",
    "stephenprater": "That was it!  Thanks for your help. \n. ",
    "dblandin": "@pbrisbin No worries! That sounds good to me. After we talked yesterday, I dug into the issue a bit more and realized that we did in fact have a race condition between the exception raise and the ContainerListener#finished event firing. I was able to remove the event that I added in the IOProcessor, replace it with a sleep 5, and see the same \"second\" finished event come through on its own. So it seems that by adding that finished event in Builder, I've given codeclimate/codeclimate just enough time for it to send off its non-errored finished event.\nLet me know how you would like to move forward :+1:\n. Ended up taking a different approach. Closing this PR.\n. Updated the remove the redundant empty output checks within formatters.\n. Seems to be running fine locally :+1:\n. Looks good to me! :+1: \n. @pbrisbin Do you have any insight into these CircleCI failures?\nError response from daemon: no such id: codeclimate-container-test\nFATA[0000] Error: failed to kill one or more containers \nError response from daemon: no such id: codeclimate-container-test\nFATA[0000] Error: failed to remove one or more containers \n.Error response from daemon: no such id: codeclimate-container-test\nFATA[0000] Error: failed to remove one or more containers \nError response from daemon: no such id: codeclimate-container-test\nFATA[0000] Error: failed to kill one or more containers\nSeems to be coming from the \"stopping containers\" spec?\n. This has to be one of the most unhelpful error messages:\n```\n\u276f rake test TEST=spec/cc/cli/analyze_spec.rb                                                                                                                                                                                                      codeclimate/git/devon/fix-unknown-formatter-error !\nRunning tests with run options --seed 27771:\n.rake aborted!\nCommand failed with status (1): [ruby -I\"lib:spec\" -I\"/usr/local/opt/rbenv/versions/2.2.2/lib/ruby/2.2.0\" \"/usr/local/opt/rbenv/versions/2.2.2/lib/ruby/2.2.0/rake/rake_test_loader.rb\" \"spec/cc/cli/analyze_spec.rb\" ]\n```\n. Unfortunately, this is still an issue on master.\nbash\n$ codeclimate analyze -f badformatter\nerror: (NameError) uninitialized constant CC::Analyzer::Formatters::InvalidFormatterError\nI can revive this work and see if I can get the specs to pass\n. Sometimes the docker-machine networking stack gets in a weird state and a restart helps.\n$ docker-machine restart default\nCan you give that a try? You may need to change default to another name if you've set docker-machine up differently.\n. Ahh, it looks like your shell still has an old IP address for the docker-machine instance. It's trying to connect at 192.168.59.103 and I can see in your docker-machine listing that the IP is actually 192.168.99.100.\nWith boot2docker, that IP address was more likely to be static, but with docker-machine, an instance's IP address can change between restarts so you sometimes have to run eval \"$(docker-machine env default)\" after restarting for your shell to pick up the new address.\nThat line simply sets a few environment variables so your shell can connect successfully. It's a good idea to add it to your .bash_profile or .zshrc as well.\nHere's the command's output without the eval:\n```\n$ docker-machine env default\nexport DOCKER_TLS_VERIFY=\"1\"\nexport DOCKER_HOST=\"tcp://192.168.99.100:2376\"\nexport DOCKER_CERT_PATH=\"/Users/[user]/.docker/machine/machines/default\"\nexport DOCKER_MACHINE_NAME=\"default\"\nRun this command to configure your shell:\neval \"$(docker-machine env default)\"\n```\nCan you try running eval \"$(docker-machine env default)\" and trying the install again? You shouldn't have to restart the dev instance if you're using default.\nSorry for the trouble. Docker can be a little tricky to setup.\n. Awesome! I'm glad we were able to get you setup! Feel free to reach out if you have any feedback. :+1: \n. @wfleming Yep, just pruned it out. Will introduce the updated rubocop configuration in a separate PR.\n. Closing in favor of #178\n. @ABaldwinHunter Yep. Ran into that in #174.\n. :+1:\n. :+1: \n. Thanks for the suggestion! We'll keep pylint on our radar moving forward.\nIn the meantime, if you're interested in building an engine for pylint, you can find our engine spec here.\nThanks for your interest!\n. Hey @mgracer48, are you still experiencing this issue?\n. I'm going to close this issue for now. Feel free to reopen if this is still occurring. Thanks!\n. Worth a shot :+1: \n. Hey @envygeeks,\nWe recently released v0.22.1 of the Code Climate CLI which includes @pbrisbin's updates in #369 regarding mounted code and tmp paths. You can now use a CODECLIMATE_TMP environment variable to specify a custom host directory for temporary files during Code Climate analyses.\nNow that this enhancement is in place, I'm going to go ahead and close this issue. Thanks!\n. Hey @envygeeks, did #303 (now merged) address your concerns?\n. @envygeeks We're still using the host's /tmp/cc directory so that we can write out a config file used by the next engine container. The change made in #303 will ensure that the config file we create is removed.\nNo existing files within the host's /tmp/cc directory are accessed and we remove our own temporary file, but we do mount the /tmp/cc directory, create it it necessary, and leave it on the system.\nYou can see the volume mount within our codeclimate-wrapper script.\nI'm guessing that we're using the specific /tmp/cc path to avoid volume mounting the entire /tmp directory. Bumping the volume mount up a level to /tmp would allow us to create a unique temp directory and completely remove it before exiting but would also expose more of the user's files/directories to the codeclimate container, which we'd like to avoid.\n. Hey @envygeeks,\n\nHowever, as long as the /tmp/cc folder is gone then all complaints are address from this end so it's safe to close this!\n\nAs of v0.22.1, we now support a CODECLIMATE_TMP environment variable to specify a custom host directory for temporary files during Code Climate analyses.\nNow that this enhancement is in place, I'm going to go ahead and close this issue. Thanks!\n. LGTM :+1: \n. Closing and continuing with #263 \n. Updated to include on .inc and .module files.\n. LGTM\n. I'm going to go ahead and close this issue as it has been inactive for a while.\n@chfast Let us know if you're still experiencing installation issues.\n. Hi @wpolicarpo,\nSupport for an alternate brakeman app_path is on our roadmap and will likely be implemented as a brakeman engine configuration option, as you suggested.\nDoes your custom directory structure support multiple apps within the same repository or is your Rails application at a non-root path for another reason?\nThanks for your feedback!\n. I can't give any guarantees but I'd expect support to roll out either late this month or early January.\nCan you give us any more detail regarding the decision to have your Rails app at a non-root path? It may influence the priority of this issue moving forward.\nThanks!\n. Gotcha. That makes sense. Thank you for sharing that info!\nWe'll post here when we have an update.\n. @wpolicarpo You're absolutely right. Applying this configuration option platform-wide for any engine seems like the best move.\nThanks for your feedback!\n. Hey @wpolicarpo,\nThis is going to take a bit more time unfortunately. We plan to support sub-directory analysis for all engines across the platform, it's just a matter of getting through some higher priority tasks currently further ahead on our roadmap.\nAs a workaround, you might try setting up symlinks at the root of your repository. This seemed to work for me:\n``` bash\nfor bundler-audit\n$ ln -s subapp/Gemfile.lock ./Gemfile.lock\n$ ln -s subapp/Gemfile ./Gemfile\nfor brakeman\n$ ln -s subapp ./app\n```\nThanks for your patience.\n. Hey @KevinBongart,\n308 was merged and released a couple weeks ago. As we mentioned in #298, engine-level exclude_paths are now supported by the CLI.\nGoing to go ahead and close this issue. Thanks for your feedback and nudge towards implementing this feature!\n. Hey @DavidEBest,\nWe recently made some enhancements to mounted code and tmp paths in #369 which may be of interest to you.\nYou can use the CODECLIMATE_CODE environment variable (renamed from CODE_PATH) to specify a host directory containing application code to be analyzed. This will default to the host machine's current working directory.\nYou can also use the CODECLIMATE_TMP environment variable to specify a host directory that the CLI can use for temporary files during analysis. This will default to /tmp/cc on the host machine.\nSupport for these new environment variables are available as of the recently released version v0.22.1 of the Code Climate CLI. Let me know if you have any questions!\n. @wfleming I made a short note on our ratings docs page. Let me know if we need to update any READMEs as well.\n. On second thought, I'm going to leave this issue open with its current \"enhancement\" label as a feature request.\n. Hi @devth,\nNot sure when we'll be able to get to this ourselves but if you're interested in creating a JSONLint engine for the Code Climate Platform, you can find our open source spec here.\n. @kalmbach Awesome! Let me know if I can be of any help! You can reach me via email at devon@codeclimate.com.\n. Hey @devth @kalmbach,\nJust wanted to let you two know that we've created a new codeclimate-community slack organization. The discussion so far has been focused around engine ideas and development. If you're already part of the Developer Program you should have received an invite already. If not, you can sign up here and join the discussion!\n. > The test functionality isn't very used now, and needs real work to be legitimately useful at any rate, so I wouldn't worry about it excessively.\nI wouldn't worry about it. It's not used at the moment.\nThis LGTM and addresses a few open issues including #245, #246, and #299.\n. This fix works for me :+1: \n. :+1:\n. One minor comment. LGTM to me either way.\n. This should be fixed as of https://github.com/codeclimate/codeclimate/pull/576. \ud83c\udf89 . > Can we use the .js one? It has the highest precedence (and is what we suggest in our styleguide)\nSounds good to me. I'll convert the config to JS.\n. > we intentionally stuck with .eslintrc in the past because it has the lowest precedence\n\n...\nI don't think we can reasonably change this without first adding features to to the copy-configs code to allow more sophisticated conditions for copying a file.\n\nMakes sense to me. Thanks for the context! I'll go ahead and close this PR.\n. Hey @monfresh! Agreed! That looks like a useful tool and would certainly make a great engine addition to the Code Climate Platform.\nIf you're interested in creating the engine or want to gauge interest from other developers, I encourage you to join our Developer Program and pitch it in our new codeclimate-community slack organization.\nWhile this repo has been a common landing pad for engine ideas, the new slack organization should serve as a more productive channel for engine-related discussion.\nThanks!\n. > Did anything result from the chat?\n@parndt Not that I'm aware of but there are a couple in-progress haml-lint engines that should be similar to a slim-lint implementation since haml-lint also sits on top of rubocop:\nhttps://github.com/michaelherold/codeclimate-haml_lint by @michaelherold (under active development)\nhttps://github.com/rafdizzle86/codeclimate-haml-lint by @rafdizzle86 (inactive). @wfleming I pushed up a commit with support for location positions either in the line/column or offset form. Let me know what you think.\n. @codeclimate/review This is ready for another look! I addressed all of the comments brought up in the last round.\n. > Should we update the message as well? \"Path must be relative\" is...not a very helpful message if the path is ../foo.rb.\nGood idea. I've updated the message to \"Path must be relative to the project directory\".\n. @mrb Is this ready to merge?\n. LGTM\n. @GordonDiggs Do you know when a fingerprint would be generated for an issue before the issue validations (including IssuePathIsFileValidation) run?\nBased on this snippet it seems like we may instead be outputting the issue json, and creating a source fingerprint, even if the output is invalid:\n``` ruby\nunless output.valid?\n  stdout_io.failed(\"#{qualified_name} produced invalid output: #{output.error[:message]}\")\n  container.stop\nend\nunless output_filter.filter?(output)\n  stdout_io.write(output.to_json) || container.stop\nend\n```\nWould it make sense to fix that instead of duplicating the File.file? check?\n. Instead of adding these detailed instructions for Windows which dive into docker-specific commands, what do you think of creating a Windows-compatible version of the codeclimate-wrapper script? The existing script is automatically installed via homebrew (OSX) and an AUR (Arch Linux) package: https://github.com/codeclimate/codeclimate/blob/master/codeclimate-wrapper. Going to go ahead and close this PR for now. Can bring it up later if we feel like it's an worthwhile enhancement.. While you're in here, I'm getting a separate nil error when running codeclimate with no args:\n$ CODECLIMATE_DEBUG=1 codeclimate\nerror: (NoMethodError) undefined method `any?' for nil:NilClass\n[DEBUG] backtrace: /usr/src/app/lib/cc/cli/help.rb:14:in `run'\n        /usr/src/app/lib/cc/cli/command.rb:70:in `execute'\n        /usr/src/app/lib/cc/cli/runner.rb:22:in `run'\n        /usr/src/app/lib/cc/cli/runner.rb:8:in `run'\n        /usr/src/app/bin/codeclimate:6:in `<main>'\nAlso tests?. Yep! LGTM. Love that green! :ok_hand:\n\n. @maxjacobson What do you think of resetting the resolver stubs after each spec?\nruby\nRSpec.configure do |config|\n  config.after do\n    ::Resolv::DefaultResolver.replace_resolvers([])\n  end\nend. I think this is great! I wonder though if the working directory is the best place to allow written artifacts. Keeping the working directory read-only is one way that we ensure engines behave properly. Would volume-mounting the configured tmp directory work for this case?\n```ruby\nif CLI.debug?\n\"--volume\", \"#{MountedPath.tmp.host_path}:#{MountedPath.tmp.join(SecureRandom.uuid)container_path}\",\n```\nThen, within an engine, you can write file artifacts to /tmp/cc.. Going to go ahead and close this PR for now.. Sounds like we should additionally always print this warning to stderr. Any reason it's currently emitted on stdout?. Should this be closed now that #611 has merged or do we still want further action?. > I've realized that for this to work, every engine should understand ENV[\"CODECLIMATE_CODE_PATH\"]\nProbably not. All our spec requires is that the engine expect code to be at /code as a volume mounted path.. @pointlessone Is this PR still active?. @pointlessone Is this PR still active?. > I'd be personally ok with always doing the match as a glob if it doesn't change any behavior we can identify and doesn't move the needle of spec:benchmark.\nDitto. Sounds like a good path forward \ud83d\udc4d . > Can you do me a favor and do the same on the quality-model branch?\nSure thing \ud83d\udc4d . > I think you also need to add this on the quality-model branch, yeah?\nThis PR is meant for the quality-model branch. Master PR was https://github.com/codeclimate/codeclimate/pull/700. Hey @nocnokneo,\nWe don't have any plans for a clang-tidy engine right now but if you (or anyone) would like to work on wrapping clang-tidy up as an engine, we'd love to have it. You can find our open source spec here.\nWe have a Slack organization setup to facilitate communication on the Platform and engine development. You can receive an invite by joining our developer program: https://codeclimate.com/dev_form. @pointlessone Sorry to delay this a bit but would you restructure your changes to the codeclimate/codeclimate-eslint repo so that it includes a PR?\n\nPush master to channel/eslint-4 branch\nPush updates to a separate branch: ex: eslint-4\nOpen PR against channel/eslint-4 base branch proposing channel updates. > Oh, wow. I didn't expect a review on a weekend.\nWill push the changes tomorrow. AFK at the moment.\n\n\n\nNo rush! I was at a computer already and saw the notification so thought I'd take a moment to respond :). @matthewwiesen Thanks for the heads up! Looks like the description on DockerHub and the README here have drifted considerably.\nI just updated the description with the current content in the README. We might also want to look into linking the DockerHub repo so that it tracks README changes automatically in the future.\nThanks!. @kickerAADS It looks like you submitted the issue template?\nGoing to go ahead and close this.. Nice! That's very exciting. I'll queue up an engine update.. Hey @amitrai99,\nI'm waiting for the updates in the 3.0.0 branch of nodesecurity/nsp to hit master before releasing an engine update.\nI also have [a PR][pr] open against that branch with some Dockerfile fixes.\n[pr]: https://github.com/nodesecurity/nsp/pull/200. Hey @amitrai99,\nI asked and it looks like they're pretty close! https://github.com/nodesecurity/nsp/pull/200#issuecomment-335926978. @amitrai99 We hope to get that out soon! Very exciting!. Unfortunately, the state of affairs regarding engine/plugin management is not so great. While we have plenty of automation to ease the process it still relies on registry documents instead of an API-backed system. In general, I think the CLI should be more forgiving than production registries which target systems which known constraints rather than any system running the CLI.\nI think proposing a spec addition for plugin system requirements (like memory) is a good one, but should probably be taken out of this first iteration, which is a good step forward.\nAlso unfortunately, the /engine.json file in the spec is not widely followed. In the future, I'd love a better plugin management interface that allows plugin authors to submit their own updates and I imagine the /engine.json file will be useful to infer information regarding the submission (the docker image).. > Several commands have been deprecated & removed: init, engines:enable, engines:disable, & engines:remove are no longer supported commands.\nMany of our documentation pages refer to the engines:enable sub-command. We should make sure to clean up those references after this goes out.. Hi @suan,\nLooks like we released version 0.7.0 of the CLI on November 20th which includes the new maintainability checks: https://codeclimate.com/changelog/5a0e488824cfa902a300091c\nYou can update locally using your package manager (homebrew, pacman, etc) or by pulling the most recent docker image: docker pull codeclimate/codeclimate.. @vovimayhem The beta channel for these engines were promoted to a stable channel. You may explicitly target the stable channel within your configuration or omit the channel and your builds with use the stable channel by default.. Looks like if @pid were nil we would get a TypeError: no implicit conversion from nil to integer but I don't think that's possible. Container#stop is only called in response to output emitted from the running engine which would have been assigned a PID. If the process terminates before we send a TERM command, we'll get an Errno::ESRCH exception, which we're already handling with a no-op rescue.\n. It seems like the process (and output) still runs for a bit even after sending TERM or KILL so this prevents a bunch of extra errored events from reaching Kafka and triggering unprocessable state changes on the snapshot.\n. I was getting a Code Climate issue for leaving this empty. I think a statsd increment sounds good.\n. Sure, that works for me :+1: \n. Yep, I think that gives more weight to the primary action. :+1: \n. @pbrisbin Is this fine as a metric key or would you prefer something else?\n. That sounds like a good approach! I'll extract out some defaults in a separate PR.\n. Should we keep the behavior between a timeout and too much memory by both calling #stop which stops the on_output behavior? I'm wondering if the timeout + on_output still handing output might be causing something to hang.\n. Looks like the array format is still valid. The hash format is necessary when you're overriding mass threshold for a language.\n. @GordonDiggs Are those extensions common enough to include by default or should we leave it as an opt in? If we add those two other extensions here, we should probably add them for ratings as well.\n. Sounds good :+1: \n. I'm not sure either. We push to docker hub as part of the bin/release script, which is pulled during installation.\nAs far as I know, we just install codeclimate as a gem in builder.\n. Or we could remove the image pre command and keep make image in dependencies. I personally like seeing the two actions in separate sections on CircleCI:\n\n. @pbrisbin Makes sense. Having the second 100% cached build sounds like a good move then. Generally I don't think that docker image build time should contribute to  test suite time.\n. All good points. What do you think of a separate Makefile command called citest that does not have the image dependency?\n. Nice :+1: \nI think that  docker push will push all tagged images so you can move the docker tag line up and drop the second docker push.\nbash\n docker build --rm -t codeclimate/codeclimate .\n docker tag codeclimate/codeclimate codeclimate/codeclimate:$version\n docker push codeclimate/codeclimate\n. Sounds good to me. I don't think that's the script's current behavior so we should probably qualify the first docker push as well:\nbash\ndocker push codeclimate/codeclimate:latest\n. Seems so. With only the bundler/gem_helper require I get the same message:\nrake aborted!\nDon't know how to build task 'release'\n. What do you think of renaming local_path to host_path? When scanning other lines, reading \"local\" prompted the question \"local to what?\".\n. Same question here for local_prefix -> host_prefix.\n. Is it worth moving this to its own file? cc/cli/logger?\n. Ahh, that was an oversight. I'll move it into Analyzer.\n. It was nice to write assertions against the key in the spec. That's the only reason it's public.\n. Nice, I like it.\n. Nope, I can bake in position support as well.\n. ENV.delete isn't an exception raising method, so I think it's fine as it. Doesn't seem worth it to extract as a helper method just yet.\n``` ruby\n\n\nENV.delete(\"CODECLIMATE_SOURCE_FINGERPRINT\")\n=> nil\n``\n. Ahh, I see what you mean. Yes, that makes sense. I'll make that change.\n. Could you explain the benefit of adding the separators separately? I don't think they're even necessary, but it makes for a more readable key.\n. Not sure I get what you mean about the collisions. Could you elaborate?\n. I think I'm leaning towards removing the separator entirely. I don't think it's very helpful. codeclimate-markdownlint doesn't [use one either](https://github.com/jpignata/codeclimate-markdownlint/blob/master/lib/cc/engine/markdownlint.rb#L93-L97). \n. Using accessors on theIssue` sounds fine to me. The just pass the issue to the fingerprinting class?\n\n\nruby\ndef fingerprint\n  SourceFingerprint.new(self).compute\nend\n. That's fair. Totally willing to move this to private scope.\n. That's a good question and I think that we're okay with the new behavior. If source code relevant to an existing issue is changed, we shouldn't consider the existing issue up-to-date. If a new analysis determines that the same kind of issue (identical check_name) is present for the updated source, code, we should emit a fresh issue with a new fingerprint. So in that case, you'd get a fixed issue and a new issue.\n. That's true. The new behavior will produce more issues, and potentially cause more failing status checks, but I think that's a favorable outcome. We want to reveal issues, not sweep them under the rug.\nIf an engine author wishes to override the default fingerprinting behavior, they can easily do so by providing that key in the issue, but I think it's a more useful default that what we have now.\n. I think the #convert_to_offsets method should ensure that these keys will be present but I'll take a look through this again.\n. Looks like I missed this line in the spec_helper which loads all of the helpers:\nruby\nDir.glob(\"spec/support/**/*.rb\").each(&method(:load))\n. Looks a little strange, but seems better to me! \ud83d\udc4d \n. Nope! Will remove.\n. I went into more detail in the commit message. This is more about not going through the trouble of reading a file / computing the default fingerprint if we already have one in the issue output.\n. Ahh, that's right. The fixture file wasn't working so I switched tactics. I'll take out the fixture file.\n. I don't think it's better to cast in this case because any string could be cast to a 0. You could have \"offset\": \"ohmygod\" and still get a 0 with to_i. \nThe bugsnag error I saw actually pointed to a bug in the radon engine. I don't think we should have generated this issue at all and it's the only issue I saw with a string location value.\njson\n{\n    \"categories\": [\n        \"Bug Risk\"\n    ],\n    \"check_name\": \"Complexity\",\n    \"content\": {\n        \"body\": \"We encountered an error attempting to analyze this line.\"\n    },\n    \"description\": \"Error: invalid syntax (<unknown>, line 102)\",\n    \"fingerprint\": \"d2fec2141485c30d047b12f9f06283ee\",\n    \"location\": {\n        \"lines\": {\n            \"begin\": \"102\",\n            \"end\": \"102\"\n        },\n        \"path\": \"some/path/features.py\"\n    },\n    \"remediation_points\": 1000000,\n    \"type\": \"issue\"\n}\n. I like it \ud83d\udc4d \n. I think it's worth introducing and seeing what shakes out. We might want to fix the known Radon bug first as it's an engine we auto-enable.\n. I just opened up a PR for Radon: https://github.com/rubik/radon/pull/89\n. Good call. I'm doing that elsewhere too. Will update.\n. I looked at Pathname and didn't find a useful method for this check. Pathname#relative_path_from looked promising but didn't end up offering a way to enforce that a path is a child of a base directory.\nFor example:\n``` ruby\n\n\nbase = Pathname.new(Dir.pwd)\nPathname.new(\"/tmp/example.txt\").relative_path_from(base)\n=> #\n``\n. Updated the expand logic to usePathname#realpathwhich has the same cleaning behavior ascleanpathbut also follows symlinks.\n. Yep! Added.\n.Pathname#realpath` touches the filesystem and will error if the file doesn't exist.\n\n\nErrno::ENOENT:\n       No such file or directory @ realpath_rec - /private/tmp/source.rb\nI could rescue that exception in #relative_to? instead. What do you think?\n. Ah that's right. I forgot about that validation. I'll remove this exist? check.\n. I backed out of the symlink changes for this particular PR. It seems complex enough to deal with separately.\n. I think that we'll have to update the IssuePathExistenceValidation to address symlinks and then we should be safe to use Pathname#realpath here.\n. Works for me! Updated.\n. Tiny nit. Feel free to ignore. #double also takes a symbol argument.. It's a little confusing that we're using JSON as the class name. Would it make sense to rename this to JSONAdapter?. Is there an interface difference here between JSON.load and YAMLAdapter.load? Wondering why we need the extra #config for the YAML adapater but not for the JSON adapter.. Do channel and config account for nil values correctly within Engine? Or do we need stable and {} fallbacks here?. Should we error in the case of an unknown engine instead of silently pruning the entry?. Might be able to use config.keys.one? here.. \ud83c\udf89 . Do we want to exit hard here or emit a warning and continue validating with the config file with higher precedence?\nFrom what I remember, we're going to document a config file precedence giving priority to .codeclimate.json.. I think we also have an app UI change in the pipeline to show which config file (or in-app config) is used, so this should be more visible.. heh :joy:. Isn't exclude_paths a common key in version 1 configs?. What do you think of flipping this so that if existing_engine.present? is the first block?. Do you expect this to be called more than once? Wondering why we need the engines_disabled check.. Ahh, that makes sense \ud83d\udc4d  I didn't realize -e was accepted multiple times.. What do you think about changing this key to memory_limit?. I don't think you have to explicitly pass in nil here. Any missing arguments will default to a nil value:\nruby\nEngineDetails.new(\"codeclimate/codeclimate-#{engine.name}\", nil, \"\"). What do you think of moving def default_memory_limit here and having that be the fallback value for this fetch?. I wonder if this logic is something we want to introduce right now. What do you think of adding an item in the chain of precedence but keeping out the max logic?\nSo the precedence would be:\n- ENV\n- yaml registry (new)\n- DEFAULT_MEMORY_LIMIT constant. Ahh, right. That makes sense. The max behavior sounds good to me then.. I think memory_limit is probably fine for the registry. The fact that we can give it more memory either via the CLI or in production can be a behind the scenes detail.. The option this affects it the upper limit of memory a container can use, not necessarily guaranteeing that amount of memory will be available. That's more of a clustering/scheduling issue.\nWhat do you think of minimum_memory_limit or simply memory_limit as an override key to the default, but knowing that the allowed memory limit might be increased through other means, like a repo-override or CLI option.. You might be able to simplify this a bit using activesupport. Not sure you'd need to to_s with #present?.\nruby\nif (memory = metadata[\"memory\"]).present?\n  options.concat([\"--memory\", memory])\nend. Yep, I'm pretty sure it's available.. ",
    "taiidani": "This issue seems stale, but I want to add my support for it. My make install took over 7 minutes. I ended up executing watch 'sh -c \"docker image ls | grep code\"' just so I had some proof that it wasn't frozen.\n$ brew reinstall codeclimate\n==> Reinstalling codeclimate/formulae/codeclimate\n==> Downloading https://github.com/codeclimate/codeclimate/archive/v0.72.0.tar.gz\n==> make install\n\ud83c\udf7a  /usr/local/Cellar/codeclimate/0.72.0: 5 files, 43.6KB, built in 7 minutes 14 seconds. That definitely shows the output! Now if only that were the default :)\nAt the least that gives me an easy response for developers wanting to know what's going on under the hood during their installs.. ",
    "maxjacobson": "I think that's great feedback. The make install process currently does print output, but I suppose the brew install step may suppress it. I'm curious if brew install --verbose codeclimate would avoid suppressing the output, and if so, if we should recommend folks use it. What do you think?. That's true. I don't have all the context, but it looks like we removed it back in March 2016. Not 100% sure why. But, happy news: there's currently an effort to bring it back: https://github.com/meuspedidos/codeclimate-pylint\nFeel free to join us in the #pylint channel of our community slack to track the progress. @larkinscott might have more context than that ^. Hi Kurt. The usual explanation for this is that, on codeclimate.com, we do a fresh clone of the repository before analysis. On your computer, it's possible that there are extra files there which are ignored by git because of your .gitignore. To confirm if that is impacting analysis time, would you please do a fresh clone of your repository and run codeclimate analyze on that?. Hm I'm skeptical that the directory and all its contents is actually 288 bytes. I think that's probably just the size of the directory, but not its contents.  You can run du -sh lucy and du -sh lucy3 to confirm the full size. Further, you can use a tool like ncdu (brew install ncdu and then ncdu lucy to determine which files are making up that size. The best thing to do in the short term is to add node_modules to your exclude_patterns (more context here: https://docs.codeclimate.com/docs/excluding-files-and-folders). We have considered respecting the gitignore in the past (and I think we might have tried to do that at one point) but I think it was too complex to support correctly. I'll make a note of it as a feature request internally and we'll definitely talk about it internally soon. Thanks for the nudge.. Neat. If you (or someone else reading this) are interested in spearheading the effort to add a Puppet engine, I'd recommend:\n\nreading the overview of the engine spec\njoining the community slack where you can ask for help as you work on it, and ping us when you're ready to add the engine to the CLI and codecliimate.com. \ud83d\udc4b oh hey. Thanks for cleaning it up \ud83d\ude0a \n. LGTM\n. \ud83d\udc4d I like the logging strategy\n. Update:\n\nSince November 10, 2016, we've supported downloading external configuration files as part of a build. You can read more details about that in the changelog post announcing it: https://codeclimate.com/changelog/582495c32c33066f1b00191d\nWe hope this will address some of the use-cases that require network access, such as sharing one configuration file across multiple repos.\nThere are still other use-cases that aren't covered by this, so we'll keep this issue open and provide updates when we have them.. This dog food tastes good to me\n. LGTM\nAgreed that this is slightly tedious\n. @wfleming heh, good point! Updated\n. @Jacob87 Good catch. Do you want to make a PR with that change?\n. That sounds like a good idea @Jacob87. The place to make those changes is in the individual engines. We expect them to emit markdown-formatted messages, and if they use backticks around their variable references, we'll render those as code samples. It seems like, for example, that codeclimate-rubocop already does this:\n\nI'll close this issue, but feel free to open new ones on the repos for the engines you're using which could emit their messages in a more useful way.\n. LGTM\n. LGTM\n. @pbrisbin yes. The codeclimate-rubocop engine is currently running rubocop 0.46.0. I'm planning to spend some time this week upgrading the codeclimate-rubocop engine from 0.46 to 0.47.1, after which we can ship this. I'd like to find a way to do it that tolerates outdated configuration more gracefully. Update: we've added a channel to support RuboCop 0.48.1. We haven't switched to making it the default yet, but users can opt in by following the steps here: https://docs.codeclimate.com/docs/rubocop#section-using-rubocop-s-newer-versions\nThanks for the ping. Going to close this PR for now. We'll open a similar one when we change the default.. @kjg We've just shipped the fixes in #182, which I believe will resolve your issue. When you get a chance, will you confirm?. @kjg \ud83d\ude05 yep!. Will you try running codeclimate engines:install to make sure you've pulled the latest version of the docker image?. @kjg Is this still an issue?. Good point. Thanks for your help getting to the bottom of this. How did you generate those diagrams btw?. Re: your update - yep, exactly. Generally I agree with that philosophy though \ud83d\ude04 . I haven't shipped the CLI before, but after reviewing the release script it looks pretty straight-forward. Going for it . Are we able to move some of that logic into https://github.com/codeclimate/codeclimate/blob/master/codeclimate-wrapper which runs on the host and has access to the full filesystem? It could read the file and pass it into the container. We can't assume that everyone uses the wrapper, but I think most people do. Just a thought \ud83d\ude04 . For option 1, I could see an argument for only fetching files that otherwise don't exist - that way we don't slow down every analyze. I know it was an intentional decision to require users to explicitly invoke this command, but maybe that would be an acceptable compromise.\nFor option 2, maybe the CLI can check for the absence of the fetch-files after analysis fails and encourage running codeclimate prepare only if they're missing? I don't think it can tell that the engine failed specifically because the files were missing and it would be annoying to suggest fetching files that have already been fetched.. Ah good catch. I'll add a spec for this one first and then take a look at that one in a second PR. @dblandin  updated, and opened https://github.com/codeclimate/codeclimate/pull/596. @dblandin LGTY?. @pbrisbin updated - does that fix look OK? (context in commit message). Oo, I like that better. Updated. Will merge on green. I'm curious if you've checked in the database whether any engines are already emitting issues that wouldn't pass this validation, and if so, if those engines would start errorring when this change is shipped.. I think the idea is that we want the average user to see the warning, so they'll know to upgrade their CLI. In engines, stderr isn't visible by default, but I'm realizing now that may not be the case for CLI code.. I can create a release for 0.59.1, which should resolve this issue for now, but I think there's some design changes that would help prevent it in the future (outlined in the issue). Curious if you have any thoughts on those.\nDo you want me to create a new tagged release for the latest change on master (adding the grep engine) which isn't part of 0.59.1 as well?. @GordonDiggs @filipesperandio  yesterday, after seeing the warning, upgrading, and then still seeing the warning I made this PR. WDYT of the approach of moving the checking of outdated? from the server to the client? I think the responsibility makes more sense here personally.. Cool, added. Good point. I'll look into that. @wfleming here's the minimal reproduction case:\ngit checkout b3b89f18520e1165052bb94dfbae154c2a88ecdc\nmake image\necho \"0.63.4\" > VERSION\nmake Gemfile.lock\nYou wouldn't expect that to update activesupport, but it does.\nWe can dig into that more, but wdyt so far?. I tried those, and a few other things, but it seems to always update activesupport \ud83d\ude1e . (@ABaldwinHunter @chrishulton, this is the exception we were talking about). @chrishulton updated this - removed the weird argument, and added details about why the location is invalid. The latter is ... a lot of conditionals. WDYT about the approach / the copy?. @chrishulton I like that. updated. Mind taking one more look?. Hm interesting. If we mount ~/.gem/credentials into the container, it might work. I can try that.. @wfleming there are a few hurdles here:\n\nthe release process tries to tag the version, which requires access to the current user's git credentials. This is do-able if we expose some environment variables\nit of course also requires access to the .git directory, which is currently docker-ignored\n\nwere you thinking we'd use a different image than codeclimate/codeclimate? I played briefly with using the codeclimate/alpine-ruby one but that doesn't have git installed...\nI'm leaning toward leaving this PR as-is but curious if you have any additional thoughts. :) no worries. I hope it wasn't too passive-aggressive to reach for hermes instead of pinging you again. I like that it picked you again though haha. Thanks! Good \ud83d\udc40 . \ud83c\udf4f \ud83d\udcd7 \ud83d\udc9a \ud83e\udd57 \ud83c\uddec\ud83c\uddf1 . This looks good. Will you also add it to the quality-model branch?. Hey @snowblink, looks like we're overdue for a release. Good catch. I'll cut a v0.68.0 now. @snowblink All ready, thanks for the nudge: https://github.com/codeclimate/codeclimate/releases/tag/v0.68.0. Requested in https://github.com/codeclimate/codeclimate/issues/752. Going to close this, but feel free to let us know if there are any more questions. Hi @2ur1st . I see you're invoking the docker image directly. The PR you pointed to, #645, implements most of the pipe logic in codeclimate-wrapper, a file that is outside of the docker image, and which is itself responsible for invoking the docker image correctly. If you follow the installation instructions in the readme, you should have a codeclimate binary installed, which runs the codeclimate-wrapper script.  Would you mind trying installing the binary and trying again?. Hi @2ur1st. Right now we don't have that on our roadmap. The official way to use the CLI is via the wrapper script. For what it's worth, the script does use docker containers for the majority of the work, it just does a little setup first.. I think I stumbled on a tiny bug while QA-ing this\nshell\ncodeclimate analyze --dev -e reek\nThis works before the upgrade to docker, but not after. I think what's happening is that if the CLI is in development mode, it passes --memory \"\" down to the docker CLI, and maybe that used to be allowed, but now it's not.\nhttps://github.com/codeclimate/codeclimate/blob/d63c59db1ba202cb6148645dfbe7a0df825125ae/lib/cc/engine_registry.rb#L30-L31\nWorth fixing before releasing?. Sounds OK to me - I don't have context on the urgency of the other work.\nDo you have the sizes offhand? I'm curious how large it is. It's not ideal, but OK if the CLI grows a little IMO. Drive-by question: how did you determine we needed to change from /bin/sh to /bin/bash? I know in our styleguide we say:\n\n/bin/sh should be preferred to /bin/bash for compatability unless Bash-only features are really needed. No worries, and nice job figuring it out :smile: . Hi @koic \n\nThanks for the detailed issue. To see the list of rubocop release channels, you can look at the branches available on that repository: https://github.com/codeclimate/codeclimate-rubocop/branches/all?utf8=%E2%9C%93&query=channel%2Frubocop\nIt appears that as of right now, the channel/rubocop-058 branch is locked to 0.58.0. We can update that branch, do a little QA, and push that to users of that channel. I'll aim to do that today.. My pleasure! Going to close this out now. Please let us know if anything else comes up. . Thanks!. Good find. Looks like, after migrating to Circle CI 2.0, the \"context\" for the commit status changed. Looks like tests are running, but they're sending their status as build_test. I believe we should update our branch protection settings to expect/require that setting, instead of ci/circleci: build_test. cc @wfleming. Gemfilee?\n. \u2328\ufe0f typo, chanenel\n. SGTM - I know .swf is used for flash animations, so as long as we don't intend to include those in the future, we should be good. oo sure. happy to update. This change was helpful for confirming that this was the double that was leaking, btw (just mentioning in case it wasn't clear why this change was included). I think mirroring the condition, like you've done, makes sense. \ud83e\udd13 uses does nothing -> does nothing. \ud83e\udd13 uses does nothing -> does nothing. @pbrisbin Yuuup. Updated. I think I must have heard someone say the word \"installation\" while I was typing that.. The reason for extracting the class is so we can use the validator in a context where we have access to the location, but not the issue (like in SourceExtractor). It would've been cool to just use the existing validator as-is, but it requires having access to the issue... agreed this feels a little weird. currently it doesn't have any level of detail. could add it, I suppose \ud83e\udd14 . that sounds reasonable. The reason it felt a little weird was that the exception is pretty far away from this call site. For this call site to know that that exception might be raised requires it to know that Issue#fingerprint eventually, sometimes uses SourceExtractor. I guess that's OK, though.. and does make a smaller diff... I think I'm convinced, will update :). Ah, this happened again: https://github.com/codeclimate/codeclimate/pull/658#issuecomment-301601663\njust make sure to do a bit of QA locally before shipping to make sure this doesn't break anything in a way the tests aren't catching. I think it could be worth covering just the changed behavior: that for duplication it uses cronopio, and for something else, it uses \"stable\". That second part seems not to be explicitly covered (not that I think it won't work). And the merging behavior probably doesn't need to be covered in this spec, in the interest of keeping specs focused. seems fine to me for now \ud83d\udc4d . nice use of ||= to express that it shouldn't override the exclude_patterns when present. Worth covering that precedence behavior with a test?. ~~Feel free to punt on this, but I'm wondering if we've considered any kind of strategy where we log a warning that they're using a legacy key, and that they should use the new thing?~~ I see you have this! That's what I get for reviewing commit-by-commit \ud83d\ude1c . Worth mentioning that they can use issue statuses, instead?. Good calling including this \ud83d\udc4d \nI think we should consider using the more generic if ENV[\"CI\"] which I believe will be set in all CI environments, just in case we migrate to some other service (something we've been talking about a bit recently). It seems like this will be a little more challenging to maintain, since we'll need to update this line whenever the apk registry switches over to 2.5 as the ruby that gets installed when someone runs apk add ruby :thinking:.\nUsers who use the CLI will pull the image, not build it themselves, so it's not likely that this occurrence will break things for users, but it could be a bit of a headache in the future for us. Do you agree? Your POV is that it's worth it for the sake of slimming the image, or are there other reasons as well?. ",
    "deltamualpha": "Wait-a-second, that is valid YAML, although it looks odd. Nevermind.\n. ",
    "rjrobinson": "Thanks. After I restarted I got this error... \n```\nbrew install codeclimate                                                                                                  [8:27:24]\n==> Installing codeclimate from codeclimate/homebrew-formulae\n==> Downloading https://github.com/codeclimate/codeclimate/archive/v0.9.6.tar.gz\nAlready downloaded: /Library/Caches/Homebrew/codeclimate-0.9.6.tar.gz\n==> env PATH=/usr/local/bin:/usr/local/Library/ENV/4.3:/usr/bin:/bin:/usr/sbin:/sbin PREFIX=/usr/local/Cellar/codeclimate/0.9.6 make install\nLast 15 lines from /Users/rrobin008c/Library/Logs/Homebrew/codeclimate/01.env:\n2015-10-28 08:27:33 -0400\nenv\nPATH=/usr/local/bin:/usr/local/Library/ENV/4.3:/usr/bin:/bin:/usr/sbin:/sbin\nPREFIX=/usr/local/Cellar/codeclimate/0.9.6\nmake\ninstall\nbin/check\nAn error occurred trying to connect: Get https://192.168.59.103:2376/v1.20/version: dial tcp 192.168.59.103:2376: i/o timeout\nUnable to run docker version', the docker daemon may not be running\nPlease ensureboot2docker upsucceeds and you've runeval $(boot2docker shellinit)` in this shell\nmake: *** [install] Error 1\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\nREAD THIS: https://git.io/brew-troubleshooting\nIf reporting this issue please do so at (not Homebrew/homebrew):\n  https://github.com/codeclimate/homebrew-formulae/issues\n```\nand \ndocker-machine ls                                                                                                         [8:28:06]\nNAME      ACTIVE   DRIVER       STATE     URL                         SWARM\ndefault            virtualbox   Running   tcp://192.168.99.100:2376\ndev                virtualbox   Stopped\ndo I have to start the dev docker container?\n. No worries about the trouble.  I know the issues. I'll try that. Thanks for the help. I'll update you. \n. Thanks for the help. The issue was when I originally installed boot2docker way back, it had me setting env vars.  It was deep... I deleted them, reinstalled all of docker. CC works now. BTW. Love the tool!!!\n. Thanks again so much\n. ",
    "jpignata": ":+1:\n. :ship:\n. :ship: :ship: :ship: \n. Opening early for thoughts since this area of the code seems to be under some churn recently. Also it passes locally on OS X but seems to fail in CI.\n. Let's focus on Container responsibilities as the struct merge was just a target of opportunity since they had mostly overlapping attributes and might be moot depending on how this shakes out.\nThe problem I'm trying to solve is that containers can generate an unbounded amount of output. This is bad for a variety of reasons, but the symptom I'm most interested in solving is that Docker has a memory leak around dealing with large STDOUT streams especially when there are \"slow\" readers attached. Just as we enforce a maximum runtime for containers, I'd like to enforce a maximum output byte number. I picked this spot to add it because I'm concerned enforcing it upstream will still force Docker to flush bytes generated and buffered within it and I'd prefer not to generate those bytes to begin with if possible. Also, conceptually, I see something like output parsing to be a higher level concern than a gate on output. This concept feels in the same family as the timeout of the running process.\nSo:\n1) Can I generalize this in such a way where it is applicable to all payload processes of container and not seemingly too targeted at engines? i.e., can this concept exist in Container?\n2) If there's no way this concept should exist in Container, where can it exist and achieve the goal of eliminating our irritation of the Docker daemon under high output scenarios?\nThanks, @fhwang!\n. @fhwang I wonder if we could go further and collapse the listener interface to started and finished and put the onus on the listener itself to figure out the result by inspecting the passed ContainerData object. Kind of \ud83d\udca9s on tell don't ask, but it might be worth it as you indicated. Being killed for running time, too much output, memory consumption (which we need to capture and pass along state and turn it into an error code), does qualify as finished as you say.\nSo on the struct merge: it does seem as though these have mostly overlapping attributes. The path I was going down was trying to figure out if they were both going into the direction of the same concept \u2013 some kind of snapshot of the status of the Container whether running or complete. Despite the recipient of each struct being different, it seems like if they are interested in the same information then perhaps they can use the same delivery mechanism. WDYT? Too fraught to pursue?\n. @fhwang Got it. Your desired end state seems right to me. Thanks for thinking this through with me. \nI should take the shortest path of work that accomplishes the goal of terminating containers that generate more than a defined limit of output while ensuring that we drive that error through to all collaborates of Container so that users will get correct error feedback. I think I can still accomplish that if I unwind my consolidation, not tinker with the callback methods right now and just extend Result. \n. @fhwang Updated the pull with in accordance with the above thought.\n. Thoughts on the CC issue? I added some lines for clarity, and I'd rather not prune them out. I don't see any good places for a quick extraction or compaction.\n. @codeclimate/review This a month old and our priorities shifted away from it. My preference is to close this and reference it later when we move back to it. Any objections?\n. Closing for now.\n. +1.\n. @codeclimate/review Any thoughts or objections?\n. Merging on green.\n. That makes some good sense. I'll re-add them and re-add a comment I had\npulled before pushing that points to the documentation site.\nOn Wed, Dec 16, 2015 at 10:23 PM, Will Fleming notifications@github.com\nwrote:\n\nRemove any rules that were set to 0 as that's the default\nI recall there being discussion around this & other defaults that we were\nintentionally including rules set to defaults for discoverability. I.e.\nIt's easier for a customer to realize they can turn some knobs if it's\nalready in the file we provide than if they have to go research docs for\nthat tool.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/276#issuecomment-165326624\n.\n. Rather than assigning a value to end_line that wasn't intended for it, what do you think about just changing the render_lines methods to do what you want explicitly?\n\nruby\ndef render_lines(begin_line, end_line)\n  [begin_line, end_line].uniq.compact.join(\"-\")\nend\nOn a higher level, the spec and validations should probably mandate what we input we actually expect here. Is just a begin_line even valid syntax today? If not, is it desirable? cc @mrb\n. @ABaldwinHunter This is a rather large commit. Attempting to diff the two, I'm noticing differences not noted in your commit message. For example, why did we decide to disable Metrics/AbcSize by default? \nCan you please unwind your reordering changes from this pull and make smaller commits that we can compare to the original and discuss?\n. I don't understand the point of the \"included cops\" comment. \n. Seems like there are some cops listed out of order in at least the metrics category.\n. Since we're rearranging deck chairs here, I'd say the pre-existing comment that opens the file, specifically line 2, is also bunk. I'd nuke it.\nAlso lines 328 - 330. Seems self-explanatory.\nI don't know what line 10 is trying to communicate.\n. Thanks. Since we're including all categories and all checks within all categories, this seemed redundant and I thought it was communicating something I was missing.\nThis looks good to me. I'd squash down into one commit but seems good to merge.\n. Unobjectionable.\n. **/*{.,-}min.js seems reasonable to me.\nOn **/*{.,-}minified.js, have we seen this often? Seems like perhaps we should have some minimum threshold of usage in the wild before we add patterns here. I imagine the 95% case is the jQuery convention of .min.js.\n. Up to you. LGTM either way.\nOn Thu, Dec 24, 2015, 2:47 PM Noah Davis notifications@github.com wrote:\n\nI have only seen 1 case of it to date so we could wait. My initial thought\nwas \"what's the harm if there's little chance of a false positive.\"\nHowever, I guess that doesn't preclude us adding\n\"*-my-mega-optimized-tiny-file.js\" and whatever weird other conventions\npeople have.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/pull/286#issuecomment-167153437\n.\n. LGTM.\n. Did you mean to type **/* is what we'd append or am I missing something?\n. @GordonDiggs Thanks for the catch! Can you take another peek.\n. @wfleming I'd be fine with -v35. I'm not sure we can support a :v35 tag of the engine, but if you have a clear idea of how to go this route I'd be down for it.\n. @wfleming So you're proposing:\n\nrubocop-v35:\n  image: codeclimate/codeclimate-rubocop:v35\n  description: A Ruby static code analyzer, based on the community Ruby style guide. Version 0.35.1 of RuboCop.\n  community: false\n  enable_regexps:\n  default_ratings_paths:\n    - \"**.rb\"\n. @wfleming That works for me.\nenable_regexps is empty. It shouldn't auto-enable.\n. @wfleming Updated.\n. :+1:\n. @afestein I just tested locally and was able to reproduce the issue you're seeing on OS X. I believe this is due to docker-machine / VirtualBox only mounting /Users within the virtual machine by default. Our image can't see your directory, and we fail inelegantly. Can you copy this directory into your home directory and see if you see the same issue?\n. @afestein Great. I think your best bet is to mount the /var/www directory from the VirtualBox UI to make sure it is available within your virtual machine. This post outlines the steps that are necessary: http://serverfault.com/questions/674974/how-to-mount-a-virtualbox-shared-folder/674978#674978. Let us know if that doesn't work.\n. LGTM\n. :+1:\n. lgtm\n. :+1:\n. Yep, that's right. It could lead to a slightly inaccurate byte count if both streams fire at once. Moving into the initializer.\n. Hmm, could that happen? I'd think it could either be empty string (which would be 0) or a value, but I'm not sure how a nil value could be present in ENV.\n. @GordonDiggs a 0 timeout would result in immediate failure as would 0 max bytes. I think these inputs would result in the same behavior with the fetch or the ||.\n. Hmm, would git rev-parse --short [tree-ish] achieve the same thing?\n(Edit: short sha)\n. Tested and the answer is yep. Yanking.\n. What do you think about replacing the description with:\n\nChecks formatting of annotation comments.\n\nThis is the language the Ruby style guide users and sufficiently explains what the check is. I think a hyphen in the word would be confusing to a reader.\nSee: https://github.com/bbatsov/ruby-style-guide#comment-annotations\n. Nit: It's not checking for presence. It's checking for formatting of those comments when present.\n. ",
    "codeclimate-shipbot": "Mercy merged on behalf of jp.\n. Mercy merged on behalf of will.\n. Mercy merged on behalf of will.\n. ",
    "stphung": "Definitely, I have a fork here which has the changes made in the following test.\n1. Build the docker image using docker build -t codeclimate/codeclimate-fixme2 .\n2. Try running the fixme2 engine on a codeclimate enabled project using codeclimate analyze --dev -e fixme2\nThe output produced is the following:\nStarting analysis\nRunning fixme2: Done!\nerror: (CC::Analyzer::Engine::EngineFailure) engine fixme2 failed with status 4 and stderr\nconverted 'https://google.com' (ANSI_X3.4-1968) -> 'https://google.com' (UTF-8)\n--2015-11-20 19:32:04--  https://google.com/\nResolving google.com (google.com)... failed: Name or service not known.\nwget: unable to resolve host address 'google.com'\n. Is this something that can be changed? This disallows doing analysis which\nrequires building code that in turn may require network access. The\nspecific use case I am looking at is analysis of Java bytecode.\nOn Nov 20, 2015 11:45 AM, \"Gordon Diggs\" notifications@github.com wrote:\n\n@stphung https://github.com/stphung Ah I see what you're doing now.\nEngines don't have access to the network\nhttps://github.com/codeclimate/spec/blob/master/SPEC.md#resource-restrictions,\nfor security reasons. Any network calls you want to make need to be done\nduring the image build process\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/224#issuecomment-158505895\n.\n. Sure!\nOn Nov 20, 2015 11:57 AM, \"Michael Bernstein\" notifications@github.com\nwrote:\n@stphung https://github.com/stphung Hey Steven! Gordon pinged me on\nthis issue because it's my responsibility to make sure that developers\nbuilding engines have an excellent experience. Let's take this to email -\nmind shooting me a message at mrb@codeclimate.com ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/224#issuecomment-158509043\n.\n. \n",
    "AnonymousDeveloper13": "I don't know  this coding I'm just trying to fix issues that are like u don't need to know the code can u fix it up for me pls\n. Make sure u add a config like pep8 has :)\n. Can someone reopen this I want to do via site\n. :D \n. ",
    "mikebryant": "See #232 - I hadn't actually seen this issue before I started writing the engine. Interesting coincidence!\n. Is this the repo? - https://github.com/codeclimate-community/brakeman\n. ",
    "bittner": "What happened to this PR? This engine doesn't seem to be included in codeclimate by default today.. There is a pdk validate command now for linting file formats present in Puppet modules. See Validating and testing modules using the Puppet Development Kit.. ",
    "larkinscott": "Hey @bittner! We have another version of this plugin (https://github.com/meuspedidos/codeclimate-pylint) that's in testing right now. It should be released to beta shortly.. ",
    "floriank": "Bam.\nSorry for being blind :confused: \n. Running the codeclimate-brakeman image on the code going through codeclimate itself seems to work. Strange.\n. Digging deeper, both images (codeclimate and codeclimate-brakeman) work fine on their own. However, when using codeclimate it'll create a command to run the codeclimate-brakeman container from it's own container, using a command like this:\nbash\ndocker run --rm --name cc-engines-brakeman-2a684b9b-3743-43d5-948c-47a4dd9edfd7\n                  --cap-drop all --label com.codeclimate.label=eb7a1645-406d-47aa-af32-4dedcc5b2e5d \n                  --memory 512000000 \n                  --memory-swap -1 \n                  --net none \n                  --volume /home/florian/code/project:/code:ro \n                  --volume /tmp/cc/a9659ba3-56ec-43fa-987f-b0aad32013c3:/config.json:ro \n                  --user 9000:9000 codeclimate/codeclimate-brakeman\nThis crashes for me with the Syntax error above. Not sure why, I would suspect a docker issue here, as changing the entrypoint for the target container produces the very same error.\nIt does not seem to be a problem with codeclimate itself, so I'll close this issue.\nNote: Tested with Docker 1.8.3 on Ubuntu (15.10)\n. ",
    "robtarr": "It is a private repo, and has about 180 files. I let it run for at least 30 minutes with no output. Considerably longer than it takes on the hosted instance of CodeClimate.\n. I just ran docker run \\ --interactive --tty --rm \\ --env CODE_PATH=\"$PWD\" \\ --volume \"$PWD\":/code \\ --volume /var/run/docker.sock:/var/run/docker.sock \\ --volume /tmp/cc:/tmp/cc \\ codeclimate/codeclimate analyze on a MUCH smaller project (30 files), and I get the exact same result.\n. If I cancel it, it seems to always dump this to the console: \n/usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.4/lib/active_support/core_ext/kernel/agnostics.rb:7:in ``': Interrupt\n    from /usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.4/lib/active_support/core_ext/kernel/agnostics.rb:7:in ``'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:70:ingitignore_paths'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:65:in exclude_paths'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:36:inengine_config'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:25:in block in run'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:23:ineach'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:23:in map'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:23:inrun'\n    from /usr/src/app/lib/cc/analyzer/engines_runner.rb:51:in configs'\n    from /usr/src/app/lib/cc/analyzer/engines_runner.rb:55:inengines'\n    from /usr/src/app/lib/cc/analyzer/engines_runner.rb:19:in run'\n    from /usr/src/app/lib/cc/cli/analyze.rb:20:inblock in run'\n    from /usr/src/app/lib/cc/cli/analyze.rb:18:in chdir'\n    from /usr/src/app/lib/cc/cli/analyze.rb:18:inrun'\n    from /usr/src/app/lib/cc/cli/command.rb:24:in execute'\n    from /usr/src/app/lib/cc/cli/runner.rb:27:inrun'\n    from /usr/src/app/lib/cc/cli/runner.rb:9:in run'\n    from /usr/src/app/bin/codeclimate:9:in'`\n. I just let analyze run for about 20 minutes on my small project, and it came back with results!\nWhy does it take so long???? Most of that time was with no output, and then it seemed to run the analysis quickly and then stop.\n. Is this not the right way to exclude folders?\nengines:\n  eslint:\n    enabled: true\nexclude_paths:\n- node_modules\nI removed the node_modules folder, and it worked fine.\n. I tried that. The problem is, that unless I remove the node_modules folder, it examines the whole folder, and that takes a LONG time, as there are a lot of modules being included. And removing the node_modules folder is not a good long term solution.\n. I built this version today and ran my code through it - working great!\n. ",
    "devinus": "Experiencing the same issue on a pretty standard Ember project. I get NO feedback whatsoever and my laptop sounds like it's about to take off.\n. ",
    "nervetattoo": "I can confirm this behaviour.\nI tried running from the console as well, with the same (no) results.\nThis is on a big project so I don't even have the patience to let it run without the exclude paths and get a result back.\n. ",
    "frobichaud": "Same issue here, attempting to run a simple bundler-audit takes over a minute, while it takes 2 seconds on online codeclimate.com.\nExecution time:\n\nOnline bundler-audit:\n\nProcesses:\n\nI'm just getting started with docker, but what I see here is lots of CPU overhead being consumed by the VBoxHeadless process.\n. Is there any major difference between the codeclimate-cli and the cloud service? I've tried virtualbox, vmware fusion and attempted some changes with file sharing. I still can't pinpoint the root cause of my issue. \n. @pbrisbin, I raised the issue with codeclimate's support, they should be able to access our repo. I'm on the same team as @eproulx-petalmd and yes our repo is unfortunately private.\nerror: (CC::Analyzer::Engine::EngineTimeout) engine brakeman ran for 900000 seconds and was killed\n. @pbrisbin It could be nice to keep it open to expose our problem to the community. But it's up to you if you feel this is a duplicate.\n. ",
    "winkler1": "Having the same experience... this is really bad. No feedback at all, crazy slow even after turning off all engines. I've setup feedback loops with Karma, Guard, eslint, rubocop. Things run in seconds. The whole point of doing this is fast feedback on the dev's machine.\nInstead of fighting with the exclude_paths stuff, I'd suggest being able to specify include_paths. If given, just look in those whitelisted dirs. That way people could hone in one one folder and get things working quickly.\nIMO, this should be done be default in codeclimate initialize for something like a Rails app. You know where the code's going to be by convention.\nSomething that takes more than a minute without feedback is impenetrable and will not be used.\n. ",
    "sb8244": "I am also experiencing this issue.\n. ",
    "ccoffey": "I am experiencing the same problem. I let codeclimate analyze run for 20 minutes with no output, then I did rm -rf node_modules and ran codeclimate analyze again and saw output after 1 minute.\n. ",
    "Domon": "Same issue here. Is there any option like --verbose that we can turn on to see what causes analyze hangs?\n. ",
    "prrrnd": "@wfleming \nI'm also having the issue where analyze is just hanging. \nThe project I'm trying it on is a small ruby on rails application. \nThe steps in your previous comment didn't fix the problem. \n. @wfleming \n1. After ctrl + c\n/usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.5/lib/active_support/core_ext/kernel/agnostics.rb:7:in ``': Interrupt\n    from /usr/lib/ruby/gems/2.2.0/gems/activesupport-4.2.5/lib/active_support/core_ext/kernel/agnostics.rb:7:in ``'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:70:in `gitignore_paths'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:65:in `exclude_paths'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:60:in `include_paths'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:37:in `engine_config'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:25:in `block in run'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:23:in `each'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:23:in `map'\n    from /usr/src/app/lib/cc/analyzer/engines_config_builder.rb:23:in `run'\n    from /usr/src/app/lib/cc/analyzer/engines_runner.rb:51:in `configs'\n    from /usr/src/app/lib/cc/analyzer/engines_runner.rb:55:in `engines'\n    from /usr/src/app/lib/cc/analyzer/engines_runner.rb:19:in `run'\n    from /usr/src/app/lib/cc/cli/analyze.rb:20:in `block in run'\n    from /usr/src/app/lib/cc/cli/analyze.rb:18:in `chdir'\n    from /usr/src/app/lib/cc/cli/analyze.rb:18:in `run'\n    from /usr/src/app/lib/cc/cli/command.rb:24:in `execute'\n    from /usr/src/app/lib/cc/cli/runner.rb:27:in `run'\n    from /usr/src/app/lib/cc/cli/runner.rb:9:in `run'\n    from /usr/src/app/bin/codeclimate:9:in `<main>'\n1. No\n2. No symlinked directories\n3. Here is the .codeclimate.yml\n``` yml\nengines:\n  brakeman:\n    enabled: true\n  bundler-audit:\n    enabled: true\n  csslint:\n    enabled: true\n  coffeelint:\n    enabled: true\n  duplication:\n    enabled: true\n    config:\n      languages:\n      - ruby\n      - javascript\n  eslint:\n    enabled: true\n  fixme:\n    enabled: true\n  rubocop:\n    enabled: true\nratings:\n  paths:\n  - Gemfile.lock\n  - \".erb\"\n  - \".rb\"\n  - \".css\"\n  - \".coffee\"\n  - \".js\"\nexclude_paths:\n- config//\n- db//*\n- spec//\n- vendor/*/\n```\ncodeclimate validate-config outputs No errors or warnings found in .codeclimate.yml file.\n. @wfleming Seems to be working now! Thanks :+1: \n. Thanks @wfleming - sounds like it's planned though, would be great!\n. ",
    "eduardojmatos": "@wfleming here worked well, thank you! :smile: \n. ",
    "khpeek": "I'm running version 0.71.1 of CodeClimate, but I'm still running into an issue of a codeclimate analyze command hanging. It has been running for >10 minutes:\nKurts-MacBook-Pro:lucy kurtpeek$ codeclimate analyze\nStarting analysis\nRunning structure: -\nUsing the website, I estimate it takes about a minute. According to my git status there are no large untracked files. Why the discrepancy?\n. Hi Max,\nThanks for your quick reply. I ran codeclimate analyze on a fresh clone\nof my repository and it was indeed much faster.\nJust from comparing the sizes of the 'worked-on' repository, lucy, and\nthe 'fresh' one, lucy3, I still don't see why it would take so much\nlonger because their sizes are not that different:\nKurts-MacBook-Pro:dev kurtpeek$ ls -lh\ntotal 0\ndrwxr-xr-x  11 kurtpeek  staff   352B Feb 16 10:07 lucy\ndrwxr-xr-x   9 kurtpeek  staff   288B Jan 24 13:26 lucy2\ndrwxr-xr-x  10 kurtpeek  staff   320B Feb 20 11:40 lucy3\nIs there a way to get it to work fast on the original lucy repository?\nBest,\nKurt\nOn Tue, Feb 20, 2018 at 11:38 AM, Max Jacobson notifications@github.com\nwrote:\n\nHi Kurt. The usual explanation for this is that, on codeclimate.com, we\ndo a fresh clone of the repository before analysis. On your computer, it's\npossible that there are extra files there which are ignored by git because\nof your .gitignore. To confirm if that is impacting analysis time, would\nyou please do a fresh clone of your repository and run codeclimate analyze\non that?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/238#issuecomment-367093653,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGT5-vCB73l2ccEkc4-BgcTyLbIEvF7Pks5tWx8QgaJpZM4Gsf-4\n.\n. Hi Max,\n\nThanks for your reply, you're totally right: the lucy3 directory is 177M\nwhereas lucy is 1.3G. A large part of the difference are the\nnode_modules in one of the subdirectories.\nThat said, I don't suppose it is possible to run codeclimate analyze in\nsuch a way that it ignores files in .gitignores, so that its performance\nwould be similar to running it on a fresh clone?\nBest,\nKurt\nOn Tue, Feb 20, 2018 at 12:25 PM, Max Jacobson notifications@github.com\nwrote:\n\nHm I'm skeptical that the directory and all its contents is actually\n288 bytes. I think that's probably just the size of the directory, but not\nits contents. You can run du -sh lucy and du -sh lucy3 to confirm the\nfull size\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/238#issuecomment-367103635,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGT5-np2jTx66BX8W0cdIk3foFHIDd8uks5tWybAgaJpZM4Gsf-4\n.\n. \n",
    "lucianosousa": "@pbrisbin It's working with all these parameters.\nThanks.\n. ",
    "envygeeks": "@dblandin I haven't check yet but I will be sure to check it out today.  However, as long as the /tmp/cc folder is gone then all complaints are address from this end so it's safe to close this!\n. It does clarify the purpose but it also muddies the development environment where this is most useful and makes it even harder to use codeclimate on a private CI where vendor is always the preferred route.\n. ",
    "nielsm": "Getting similar issues locally for other directories\n. @wfleming That seems to have corrected the exclude issues for me.\n. ",
    "Kaijiro": "I'm having the same issue when executing codeclimate with phpmd at root of a Wordpress Installation.\nerror: (CC::Analyzer::Engine::EngineTimeout) engine phpmd ran for 900000 seconds and was killed\nI would like to know how to fix the problem.\n. ",
    "grahamlyons": "I'm getting the same issue in a Ruby project. It runs fine using Code Climate as a Service.\n. ",
    "guy-mograbi-at-gigaspaces": "me too. \n. ",
    "richartl": "me too\n. ",
    "boboldehampsink": "I'm experiencing the same issue. Excluding .git, node_modules, vendor etc. doesn't resolve the issue.\n. ",
    "JelF": "lol, wrong repo\n. ",
    "wpolicarpo": "The configuration could be made in brakeman config section:\nyaml\nengines:\n  brakeman:\n    enabled: true\n    config:\n      path: path/to/rails/application\n. @dblandin it is a single Rails app at a non-root path.\nIs there any prevision on when this configuration would be possible? Wouldn't like to switch back to old analysis :)\nThanks in advance.\n. We use a homemade deploy tool (shared with other projects and different languages) that enforce us to have an specific directory structure.\nThere are other reasons (Vagrant, ansible, etc), but that is the main reason we have to use a custom path.\n. @dblandin I fear codeclimate-bundler-audit suffers from the same problem we have here. When I run codeclimate analyze --engine bundler-audit -f json, I get:\njson\n[{\n  \"type\": \"warning\",\n  \"description\": \"No Gemfile.lock file found\",\n  \"fingerprint\": \"b99834bc19bbad24580b3adfa04fb947\",\n  \"engine_name\":\"bundler-audit\"\n}]\nI think this configuration should be implemented in a system-wide way, so all engines gain access to that path. What do you think?\n. Hi @dblandin, any news here?\n. ",
    "eclubb": "I have a slightly different use-case. I have my Rails app and Angular app in two subdirectories under a common project root with my .codeclimate.yml file, like this:\n|\n|--- backend\n|    |--- app\n|    |--- ...\n|--- frontend\n|    |--- ...\n|--- .codeclimate.yml\nI want some of the engines (brakeman, rubocop, etc.) to look at the Rails API app in backend, but others (requiresafe, eslint, scss-lint, etc.) to look at the Angular app in frontend. Given these requirements, the ability to set custom sub-directories on a per-engine basis seems preferable. Perhaps a global config option with overrides for individual engines would be best.\n. A more general solution might be to allow arbitrary arguments to be passed from the config file, through  the engine, to the underlying tool. This would be a flexible way to allow full usage of the tool's capabilities until they are fully supported in the config file.\n. We decided to go with a custom solution, so we're not using the \ncodeclimate engines at all.\nOn 06/30/2016 09:04 AM, Ryan Clements wrote:\n\n@eclubb https://github.com/eclubb - did you find a workaround for \nthis? I have a very similar use-case, and haven't yet been able to \ncome up with a solution.\n@dblandin https://github.com/dblandin - is support for this still on \nthe roadmap?\nThanks.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub \nhttps://github.com/codeclimate/codeclimate/issues/275#issuecomment-229651626, \nor mute the thread \nhttps://github.com/notifications/unsubscribe/AAChhs58cCcwzgYBLwgEJuzxyJu-3ynAks5qQ77ggaJpZM4G24QL.\n\n\nSoftware Engineer\nValcom, Inc.\n(540) 563-2000 x253\neclubb@valcom.com\n. ",
    "Roar1827": "@eclubb - did you find a workaround for this? I have a very similar use-case, and haven't yet been able to come up with a solution.\n@dblandin - is support for this still on the roadmap?\nThanks.\n. ",
    "JDutil": "@dblandin I'm hoping to do this as well, but for multiple applications within the same project.\n. ",
    "KevinBongart": "I didn't read the instructions, but after running make image, I finally got the engines to run! However, while I can confirm the engine_config lists my engine-specific exclude_paths, the paths don't seem to be excluded from the analysis.\nAny pointers would be helpful!\n. @ABaldwinHunter Thanks for the feedback, I understand why this wasn't working now!\nI tweaked it to also update include_paths and it worked. Not the most elegant code or variable names, so if you have suggestions that would be quick to fix. If the direction is right, I can also write some specs.\nAt that point, would the feature make its way to master?\n. @ABaldwinHunter @GordonDiggs Any interest in getting this merged?\n. @ABaldwinHunter @wfleming No problem, my implementation was mostly a workaround, I can definitely see the performance implications. Glad to see this feature making its way into the CLI!\nClosing this one then :+1: \n. Just some feedback: my .rubocop.yml config file doesn't seem to be taken into account (https://github.com/codeclimate/codeclimate-rubocop/issues/39) when running CC from this branch. Not sure if this fits here, but it seems like this PR is also trying to fix the issue?\n. ",
    "DavidEBest": "Thanks for the update! I'll give it a shot.\n. @wfleming :+1: Thanks for the quick fix!\n. ",
    "lucasmazza": "@GordonDiggs I have the image a proper spin locally and it failed - makes sense to delete the file after running the container instead?\n. @GordonDiggs rebased and updated the PR title with the delete approach.\n. ",
    "sgerrand": ":wave: @GordonDiggs: Would you please review this change?\n. :gift_heart: \n. > sorry, I might've been thinking of Docker for Mac\nYour assumption was correct. That's the use case here.\nApart from testing for docker-machine etc a lot, the codeclimate-wrapper script references /var/run/docker.sock. This has moved to /var/tmp/docker.sock in Docker v1.11.0. By adding a few changes to the conditionals, I've been able to get this script working with Docker for Mac. I'll submit a pull request soon.\n. > Just to be a bit pedantic (mostly so people don't get their hype trains running): Docker for {Mac,Windows} is not native docker, it's a tiny VM and an native app that tries to keep it running correctly at all times.\n\ud83d\ude47  You are correct.\n\n. \ud83d\udcdd  Updated the title and description of this issue based on @Mange's feedback.\n. \ud83c\udf89  Docker for Mac now works with codeclimate-wrapper as of v0.25.2.\n. @pbrisbin: Thanks for all of your feedback through this process. Since the recent changes in Docker for Mac (as of beta10) and the removal of boot2docker (in c28015e7447f420dab0c0cbc0dcb38a7c068881b) I've found that codeclimate-wrapper now works fine as of v0.27.2 with Docker for Mac. No changes required!\n. > I think you've made this PR against a very old version of master. We've actually moved from minitest to rspec since then.\nI did. :blush:\nSubsequently updated to tie into the Docker, make and RSpec changes. \u2728 \n. \ud83c\udf89\n\n. > In any event, I don't think we're interested in using this aspect of Circle for this project.\nReally? Oh well, feel free to close this if you confirm that decision. \ud83d\ude1e \n. \ud83d\ude05  Rebased in c8a1539. \u267b\ufe0f \n. Pretty much.\n. That makes sense, I'll add something similar in.\n. Done in 7b4ad87 and 4ad8a6b. \u267b\ufe0f \n. > # Note: the predicate has to be smarter than just \"modern_docker_version\". For example,\n\nI run 1.11 on Linux and the socket is in the default location\nif docker_for_mac\n\nDone in 2ca5f7f. \u267b\ufe0f \n. \ud83d\ude47  Updated in 0e69153.\n. @pbrisbin: Thanks for the tips, no worries about the back and forth.\n\nLeaving the rest of the script completely as-is, except for replacing the hardcoded socket with $socket_path.\n\nTo be clear: approaching this problem by changing the socket file location does not work due to the differences between how docker-machine and Docker for Mac behave. There are no Docker related environment variables set by Docker for Mac and the Docker Machine executables (boot2docker and docker-machine) may still exist on the user path, so the conditionals which testing for command -v docker-machine and command -v boot2docker need to be short circuited early.\n. \ud83d\udcdd  The current version of Docker for Mac (v1.11.1-beta10) symlinks /var/run/docker.sock to /var/tmp/docker.sock, so the changes which are really needed in this script is:\n- setting $socket_path to the right path; and\n- shortcircuiting for Docker for Mac users before testing for boot2docker.\nThe test for docker-machine are guarded by if [ -n \"$DOCKER_MACHINE_NAME\" ] and the Docker for Mac documentation directs the user to unset every environment variable prefixed with DOCKER_.\n. > technically your changes are just passing a string literal of \"socket_exists\" to the ssh commands, which won't work at all.\nYou're completely correct, apologies for letting these two lines through.\n. > If the current version is symlinking to /var/run/docker.sock we should just use that and not bother with an alternate $socket_path\nThe current script tests whether this file is a socket file, which fails as it's a symlink.\n\nIf the documententation directs users to unset $DOCKER_, we should rely on that and not worry about short-circuiting before checking for docker-machine\n\nAgreed. \ud83d\udc4d \n\nThis only leaves the potential for a user having boot2docker on $PATH, but actually intending to use Docker Machine -- I think it's OK not to handle this edge-case since boot2docker is deprecated\n\nThat sounds like an argument for removing that test altogether, but I'm not really fussed either way. \n\nIf those three things are true / appropriate -- do we need any changes at all?\n\nAt least one of them is false in my opinion. My view is that the socket path should be changed.\n. \ud83d\udcdd  Docker Toolbox for Mac does still install boot2docker. I'll check where it gets installed to.\nedit: Sorry, it's just the boot2docker ISO image. Ignore me. \ud83d\ude0a \n. > Are we in agreement then that the few lines I've been pasting is the\n\nanswer? Just adjust $socket_path up top and leave the rest of the script \nalone?\n\nYes, that's fine with me.\n. ",
    "mikeLspohn": "Any word on the Overall GPA feature? The CLI is great, btw! \n. ",
    "TheNotary": "Thanks for checking on this @wfleming!  Hmmm... you know I'm not sure what happened, but running codeclimate analyze offline seems to be working as one would expect.  I disabled all the ignore statements to try and reproduce some kind of error message but couldn't... many files were deleted locally though which may explain this.  Or gremlins.  \n\u00af(\u30c4)/\u00af \n. ",
    "devth": "Thanks, but I meant the actual line of code, e.g.puts :foo in addition to the position data.\n. Cool, thanks for the explanation. Makes total sense. I've already done the work to read in the LoC from disk anyway :)\n. @wfleming cool. I checked out the spec on building them but wasn't sure how to actually use a custom engine. It looks like codeclimate engines:list only includes engines that are approved by you all?\n. Ok, awesome. Thanks for the info @wfleming. \nI'd definitely want to get it approved eventually as my goal would be to use it with a new plugin I released today for my chatbot, which would require being able to dynamically locate/download the docker image via the codeclimate cli.\nIt'd be nice to know ahead of time whether 1) CodeClimate people think there's a need for it and 2) whether they would add it to approved engines once it meets the standards before embarking on dev of a custom engine. Markdown isn't the only thing I'm curious about contributing.\n. Yesssssssssssss :space_invader: :100: :ocean:  Nice work @jpignata!\nI'll start running it against all my repos.\n. Thanks @dblandin. Not sure when I'll be able to get to it either :)\n. I'm interested in this issue and potentially helping out.\n\nisn't this contradictory to the spec? Or is that only for engines, but the CC CLI can exit 1?\nwhy was https://github.com/codeclimate/codeclimate/pull/508 closed?. I think individual engines should be allowed to fail based on config. For example:\n\nyaml\nengines:\n  markdownlint:\n    enabled: true\n  fixme:\n    enabled: true\n    allow_failure: true\n  shellcheck:\n    enabled: true\nIn this case allow_failure: true is set on the fixme engine. Reasoning is that it can be useful to see those issues in the build log, but I don't want to fail the build because of them.\nThe default would be allow_failure: false meaning if any issues were found for an engine then analyze would exit 1.\nThoughts?. ",
    "mikz": "@wfleming @pbrisbin fixed, rebased!\n. Good to know. I found it there: http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html\nwhich is the bash man. Will change it to -n.\nI think the docker-machine check is required. If I have this flag by accident, but have no docker-machine, I don't want codeclimate to try to use it.\n. ",
    "kalmbach": "@devth @dblandin I want to work on this, will give it a try.\n. ",
    "marocchino": "OK,\nThis is my settings:\n- .codeclimate.yml\n``` yml\n\nengines:\n    brakeman:\n      enabled: true\n    bundler-audit:\n      enabled: true\n    csslint:\n      enabled: true\n    coffeelint:\n      enabled: true\n    duplication:\n      enabled: true\n      config:\n        languages:\n        - ruby\n        - javascript\n        - python\n        - php\n    eslint:\n      enabled: true\n    fixme:\n      enabled: true\n    rubocop:\n      enabled: true\n  ratings:\n    paths:\n    - Gemfile.lock\n    - \".erb\"\n    - \".haml\"\n    - \".rb\"\n    - \".rhtml\"\n    - \".slim\"\n    - \".css\"\n    - \".coffee\"\n    - \".inc\"\n    - \".js\"\n    - \".jsx\"\n    - \".module\"\n    - \".php\"\n    - \".py\"\n  exclude_paths:\n  - config//\n  - db//*\n  - spec//\n  - vendor/*/\n  ```\n- .eslint.json\njson\n  {\n      \"parser\": \"babel-eslint\",\n      \"rules\": {\n          \"indent\": [\n              2,\n              2\n          ],\n          \"quotes\": [\n              2,\n              \"double\"\n          ],\n          \"linebreak-style\": [\n              2,\n              \"unix\"\n          ],\n          \"semi\": [\n              2,\n              \"never\"\n          ],\n          \"no-var\" : 2,\n          \"no-unused-vars\": 1,\n          \"no-undef\" : 1,\n          \"prefer-arrow-callback\": 2,\n          \"prefer-const\": 1\n      },\n      \"env\": {\n          \"es6\": true,\n          \"browser\": true\n      },\n      \"extends\": \"eslint:recommended\"\n  }\nand there's no higher-precedence file present.\n-rw-r--r--@  1 marocchino  staff   8196 Jan 14 15:08 .DS_Store\ndrwxr-xr-x   3 marocchino  staff    102 Jan 13 16:28 .bundle\n-rw-r--r--   1 marocchino  staff    530 Dec 24 10:07 .codeclimate.yml\n-rw-r--r--   1 marocchino  staff     87 Nov 27 14:05 .editorconfig\n-rw-r--r--@  1 marocchino  staff    140 Feb  5 15:52 .env\n-rw-r--r--   1 marocchino  staff    621 Feb 17 10:06 .eslintrc.json\ndrwxr-xr-x  15 marocchino  staff    510 Feb 16 15:57 .git\n-rw-r--r--   1 marocchino  staff    645 Dec 10 10:16 .gitignore\n-rw-r--r--   1 marocchino  staff    153 Feb 16 15:48 .hound.yml\n-rw-r--r--   1 marocchino  staff   7954 Jan 19 14:12 .rubocop.yml\n-rw-r--r--   1 marocchino  staff      6 Jan 13 16:24 .ruby-version\n-rw-r--r--   1 marocchino  staff   4615 Jan 21 18:33 .scss-lint.yml\n-rw-r--r--   1 marocchino  staff   3112 Feb  5 16:18 Gemfile\n-rw-r--r--   1 marocchino  staff  15638 Feb 16 15:03 Gemfile.lock\n.. so on ..\nand 'no-unused-vars' are still reported.\n\n. Ah, It's clear now. I thought warning should not be reported one.\nThanks @wfleming \n. ",
    "GenaBitu": "Any progress? It has been several months...\n. Thank you, no need to apologise :)\n. Hi, wanted to nag again for some time too... Would you consider reopening this issue until it is truly resolved?\nAlso, did you check off any point on that list? Do you have a specific copy for this engine? I should be able to help with some of them, if that's ok with you, although my experience with Code Climate is limited to say the least...\nFeel free to contact me if there is anything I can help with (GitHub or email - genabitu@gmail.com)\nHope this can be solved asap :) Thanks!. ",
    "antiagainst": "@GenaBitu: Sorry, I've been busy with some other stuff. Seems dropped the ball. I'll revisit this this weekend.\n. Turned out I didn't really have time last weekend; but still on my TODO list. I hope to find a time for it soon.\n. Hi @ramirezd42, after @GenaBitu pinged me last time, I updated the source code for the engine (Oct 10, 2016) and got up to the point of the \"Copy the Engine QA spreadsheet\" step. It's a non-trivial list of tasks to tackle down for moving to Beta, especially the \"Remediation Points\" and \"10 Repo tests\". For the remediation points, I don't actually have clear ideas of how to assign a number to represent the effort needed for fixing a issue reported by cppcheck. So the effort was paused and I got distracted by other tasks. (Yep, need paycheck for living. :) ) I'm not sure when I'll come back to this issue, but I'll definitely try; you are very welcome to contribute and make it publicly available. Thanks!. @GenaBitu: Oh, cool! That would be awesome!\nHere is the repo: https://github.com/antiagainst/codeclimate-cppcheck\nI fixed several other problems today and created issues for the things yet to be done. Your help is certainly very welcome! Please just pick the one that you are interested.\nAs for familiaring yourself with Code Climate tools, here are things helpful:\n Engine lifecycle\n Engine Spec\n Engine QA spreedsheet\n CLI tool. ",
    "ramirezd42": "Anything happening with this? Perhaps the issue could be re-opened?. ",
    "afestein": "Hey, thanks so much for the quick reply. Yes, I am on OSX using docker-machine as recommended in the readme.\nHere are the results:\npwd\n/var/www/sites/myproject-motion-ios\nls -la\ntotal 232\ndrwxr-xr-x  28 afestein  wheel    952 27 Feb 09:20 .\ndrwxrwxrwx   7 root      wheel    238 27 Jan 12:44 ..\n-rw-r--r--   1 afestein  wheel   1280 26 Feb 16:40 .env\n-rw-r--r--   1 afestein  wheel    710 27 Feb 09:20 .env.development\n-rw-r--r--   1 afestein  wheel     51 28 Oct 09:30 .env.test\ndrwxr-xr-x  16 afestein  wheel    544 27 Feb 09:27 .git\n-rw-r--r--   1 afestein  wheel    174 17 Feb 18:08 .gitignore\ndrwxr-xr-x   9 afestein  wheel    306 25 Feb 18:34 .idea\n-rw-r--r--@  1 afestein  wheel     99 26 Feb 17:01 .repl_history\n-rw-r--r--   1 afestein  wheel    686 26 Feb 13:00 .rubocop.yml\n-rw-r--r--   1 afestein  wheel   1048 26 Feb 13:00 .travis.yml\n-rw-r--r--   1 afestein  wheel  11154  4 Nov 13:45 AdHoc_com.myproject.yhi.mobileprovision\n-rw-r--r--   1 afestein  wheel  11586  1 Dec 10:20 Adhoc_com.myproject.yhi.staging.mobileprovision\n-rw-r--r--   1 afestein  wheel   7490  4 Nov 13:47 AppStore_com.myproject.yhi.mobileprovision\n-rw-r--r--   1 afestein  wheel  14094 13 Nov 15:59 Development_com.myproject.yhi.mobileprovision\n-rw-r--r--   1 afestein  wheel    605 26 Feb 16:40 Gemfile\n-rw-r--r--   1 afestein  wheel   9046 26 Feb 16:40 Gemfile.lock\n-rw-r--r--   1 afestein  wheel   2038 10 Dec 17:02 README.md\n-rw-r--r--   1 afestein  wheel   2772 26 Feb 16:40 Rakefile\ndrwxr-xr-x  12 afestein  wheel    408 27 Feb 09:20 app\ndrwxr-xr-x   8 afestein  wheel    272 27 Feb 09:20 bin\ndrwxr-xr-x   4 afestein  wheel    136 26 Feb 08:51 build\ndrwxr-xr-x   3 afestein  wheel    102  3 Dec 15:03 config\ndrwxr-xr-x  17 afestein  wheel    578 26 Feb 08:59 fastlane\ndrwxr-xr-x  18 afestein  wheel    612 26 Feb 16:40 resources\ndrwxr-xr-x   5 afestein  wheel    170  9 Feb 15:57 spec\ndrwxr-xr-x   5 afestein  wheel    170 26 Feb 16:40 vendor\n-rw-r--r--   1 afestein  wheel  14456 25 Feb 18:37 myproject-motion-ios.iml\ncodeclimate init\nGenerating .codeclimate.yml...\nConfig file .codeclimate.yml successfully generated.\nEdit and then try running 'validate-config' to check configuration.\nGenerating default configuration for engines...\nerror: (NoMethodError) private methodselect' called for nil:NilClass`\ncodeclimate validate-config\nERROR: invalid \"engines\" section: The engines key cannot be empty.\nls -la\nSame as above (i.e. no .codeclimate.yml file)\ncat .codeclimate.yml\ncat: .codeclimate.yml: No such file or directory\n. @pbrisbin Thanks, yes I have seen that error message before, and no I still can't see it using sudo. \n@jpignata Yes! That worked:\nGenerating .codeclimate.yml...\nConfig file .codeclimate.yml successfully generated.\nEdit and then try running 'validate-config' to check configuration.\nGenerating default configuration for engines...\nConfig file .eslintrc successfully generated.\nConfig file .eslintignore successfully generated.\nCopying the project into my /Users/afestein directory did the trick. It all works as expected. \nThat's great but I don't want my project folders in with my other junk. How can we improve the project to work around this issue?\n. OK thanks. I looked into mounting other directories in VirtualBox, but I couldn't get it to work for me easily. Installing guest additions and mucking around with docker config started getting too complicated. \nFor my purposes I've decided to just move my project into ~/Code which is much easier. Here are the full setup scripts I ended up with: \n```\nSet up Code Climate\nbrew install docker\nbrew install docker-machine\ndocker-machine create --driver virtualbox code-climate\nbrew tap codeclimate/formulae\nbrew install codeclimate\neval $(docker-machine env code-climate)\n```\nFrom there, codeclimate init works and here's how I run my tests: \ndocker-machine start code-climate\neval $(docker-machine env code-climate)\ncodeclimate analyze\n. Hi @dblandin - I figured out how to configure the upstream and rebase this. Would you be able take a look at this one as well please?. What's the best way to get this code reviewed @GordonDiggs?. Thanks @dblandin . ",
    "jonatas": "Yes!\nwith hyphen:\njonatas@davi:~/codeclimate-master$ sudo docker images | awk '/codeclimate\\/codeclimate-/ { print $$1 }'\nWithout hyphen:\njonatas@davi:~/codeclimate-master$ sudo docker images | awk '/codeclimate\\/codeclimate/ { print $$1 }'\ncodeclimate/codeclimate   latest              fe1d43774970        5 days ago          95.37 MB\n. It does not work for me with || true. Or I did not understand the trace:\nSee the full trace:\n```\njonatas@davi:~/codeclimate-master$ sudo make install\nbin/check\ndocker pull codeclimate/codeclimate:latest\nlatest: Pulling from codeclimate/codeclimate\n2f3f3e5e133b: Already exists \n2654c654a6e7: Already exists \n412e64056adf: Already exists \na3ed95caeb02: Already exists \nc0cff5d1be19: Already exists \n15eaaa0bdfe1: Already exists \n142129337929: Already exists \n92a216aa1e9d: Already exists \n4b9f51590cc5: Already exists \n5455568f57b3: Already exists \ndc4d4d71fda9: Already exists \nc822c61d18e8: Already exists \nDigest: sha256:a3afb30c41575bfb97d52bba1ba636542079f63ef3b2aa971ecb7398f204bdff\nStatus: Image is up to date for codeclimate/codeclimate:latest\ndocker images | awk '/codeclimate\\/codeclimate:/ { print $1 }' | xargs -n1 docker pull || true\ndocker: \"pull\" requires 1 argument.\nSee 'docker pull --help'.\nUsage:  docker pull [OPTIONS] NAME[:TAG|@DIGEST]\nPull an image or a repository from a registry\nmkdir -p /usr/local/bin\ninstall -m 0755 codeclimate-wrapper /usr/local/bin/codeclimate\n```\nIs it continuing without run docker pull without errors. Is it right?\n. AH, ok!\nI think it was wrong and did not complete the installation.\nThank you for explain!\nI think my code will not be merged, so let's close it! Thank you @pbrisbin!\n. Nice @pbrisbin! :+1: \n. ",
    "rafamanzo": "Nice :) Thank you @wfleming \n. ",
    "sheenobu": "@GordonDiggs NixOS / Nix Package Manager. At package creation time, the tooling takes a Gemfile (literally gem \"codecomplete\") and converts it to something nix compatible. \nAt package build and installation time, the tooling iterates over spec.executables and wraps them in ruby scripts that sets up the proper environment [code]. Additionally, only things in spec.executables get added to PATH (so the codecomplete script doesn't get wrapped or added to PATH, only script and codecomplete-init). I'm packaging this but haven't used it so I don't have context for what gem users need in the PATH.\nGuide for packaging ruby packages I am following: https://nixos.org/nixpkgs/manual/#sec-language-ruby\n. @GordonDiggs that said, the interested person wanting this package is currently running it via docker so it isn't a blocker on the Nix packaging side. Thought I'd give it a try as packaging is pretty simple when the gemspec matches expectations.\n. ",
    "diegoamc": "I've squashed the commits and removed the additional version bump for code-ray.\n. ",
    "tkqubo": "I'm so sorry MY CODE was actually calling exit 1 since I misunderstood codeclimate's specification :sob:  Thanks, I will close this issue.\n. ",
    "afeld": "That was fast! :clap: \n. ",
    "XaBerr": "Hi @wfleming,\nThank you for answering so fast.\nI'm stuck on the third point in your amazing guide.\nI added the file in this path: C:\\codeclimate.cmd\nif I'll try cd-ing stuff like codeclimate  help everything work,\nbut when I try to enter this path in atom: \nC:/codeclimate\nI get this error:\n\ncodeclimate binary not found! Installation instructions at http://github.com/codeclimate/codeclimate\n\nif I try this path instead:\nC:/codeclimate.cmd\nI get this error:\n\nError: Impossibile trovare il percorso specificato.\nError: Impossibile trovare il percorso specificato.\n    at exit (file:///C:/Users/user_12/.atom/packages/linter-codeclimate/node_modules/atom-linter/lib/helpers.coffee:32:24)\n    at triggerExitCallback (C:\\Users\\user_12\\AppData\\Local\\atom\\app-1.6.2\\resources\\app.asar\\src\\buffered-process.js:213:47)\n    at C:\\Users\\user_12\\AppData\\Local\\atom\\app-1.6.2\\resources\\app.asar\\src\\buffered-process.js:227:18\n    at Socket. (C:\\Users\\user_12\\AppData\\Local\\atom\\app-1.6.2\\resources\\app.asar\\src\\buffered-process.js:98:18)\n    at emitOne (events.js:82:20)\n    at Socket.emit (events.js:169:7)\n    at Pipe._onclose (net.js:469:12)\n\nWhat have I forgotten?\n. Same errors for C:/codeclimate.cmd C:\\codeclimate.cmd!\n. @pbrisbin  I'm sorry I have not tried in the hope of having the complete package.\nI try between three days when I get back to work.\n. I've tried:\nanalyze [-f format] [-e engine] <path>\nwith this file in C:\\\n```\n@ECHO OFF\nSETLOCAL\nSET MACHINE_NAME=%default%\nFOR /f \"tokens=*\" %%i IN ('docker-machine env %MACHINE_NAME%') DO %%i\nSET CODECLIMATE_CODE=%CD:\\=/%\nSET CODECLIMATE_CODE=%CODECLIMATE_CODE:C:=/c%\nSET CODECLIMATE_TMP=%TEMP:\\=/%/codeclimate\nSET CODECLIMATE_TMP=%CODECLIMATE_TMP:C:=/c%\ndocker run ^\n--interactive --rm ^\n--env CODECLIMATE_CODE ^\n--env CODECLIMATE_TMP ^\n--env CODECLIMATE_DEBUG ^\n--volume \"%CODECLIMATE_CODE%\":/code ^\n--volume \"%CODECLIMATE_TMP%\":/tmp/cc ^\n--volume /var/run/docker.sock:/var/run/docker.sock ^\ncodeclimate/codeclimate %*\n```\nand seems doesn't work\n\n. still getting that same error message\n\nand seems docker VM isn't mounting my Windows drive in the expected way.\n\n. I opened new topic.\nI'm waiting for news.\n. I have done some progress. Now I see the folder and try to send the command but I get the same error.\n\n. > If you're going to run the CLI via docker run, then there are a number of other options needed\nCrap...\nNow it works correctly!\nI'm the first user in windows 10 :)\n. @gerard2p excellent!\n. ",
    "gerard2p": "Hello I'm trying run codeclimete on windows, It seem to be working, but when I run \"codeclimate analyze\" i get this:\nzsh\nC:\\development\\koaton [v1 +26 ~41 -11 | +36 ~11 -51 !]> codeclimate analyze\n[DEBUG] duplication:stable engine config: {\"enabled\":true,\"config\":{\"languages\":[\"javascript\"]},\"include_paths\":[\"src/\"]}\n[DEBUG] docker run: [\"docker\", \"run\", \"--name\", \"cc-engines-duplication-stable-b472b3a4-0ca1-465b-a9c4-163d61ee3ff4\", \"--cap-drop\", \"all\", \"--label\", \"com.codeclimate.label=825aa059-d90b-44be-ba10-576a945833b7\", \"--memory\", \"512000000\", \"--memory-swap\", \"-1\", \"--net\", \"n\none\", \"--rm\", \"--volume\", \"c:/development/koaton:/code:ro\", \"--volume\", \"c:/Users/gerar/AppData/Local/Temp/codeclimate/fe85c283-7c63-4639-a531-d8d5c9ebd622:/config.json:ro\", \"--user\", \"9000:9000\", \"codeclimate/codeclimate-duplication\"]\nerror: (CC::Analyzer::Engine::EngineFailure) engine duplication:stable failed with status 2 and stderr\ninvalid value \"c:/development/koaton:/code:ro\" for flag --volume: bad format for volumes: c:/development/koaton:/code:ro\nSee 'docker run --help'.\n[DEBUG] backtrace: /usr/src/app/lib/cc/analyzer/raising_container_listener.rb:23:in `finished'\n        /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:17:in `block in finished'\n        /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:17:in `each'\n        /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:17:in `finished'\n        /usr/src/app/lib/cc/analyzer/container.rb:78:in `run'\n        /usr/src/app/lib/cc/analyzer/engine.rb:52:in `run'\n        /usr/src/app/lib/cc/analyzer/engines_runner.rb:60:in `block in run_engine'\n        /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:60:in `with_spinner'\n        /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:41:in `block in engine_running'\n        /usr/src/app/lib/cc/analyzer/formatters/formatter.rb:29:in `engine_running'\n        /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:40:in `engine_running'\n        /usr/src/app/lib/cc/analyzer/engines_runner.rb:59:in `run_engine'\n        /usr/src/app/lib/cc/analyzer/engines_runner.rb:23:in `block in run'\n        /usr/src/app/lib/cc/analyzer/engines_runner.rb:23:in `each'\n        /usr/src/app/lib/cc/analyzer/engines_runner.rb:23:in `run'\n        /usr/src/app/lib/cc/cli/analyze.rb:20:in `block in run'\n        /usr/src/app/lib/cc/cli/analyze.rb:18:in `chdir'\n        /usr/src/app/lib/cc/cli/analyze.rb:18:in `run'\n        /usr/src/app/lib/cc/cli/command.rb:24:in `execute'\n        /usr/src/app/lib/cc/cli/runner.rb:22:in `run'\n        /usr/src/app/lib/cc/cli/runner.rb:8:in `run'\n        /usr/src/app/bin/codeclimate:6:in `<main>'\nStarting analysis\nC:\\development\\koaton [v1 +26 ~41 -11 | +36 ~11 -51 !]>\nand my .codeclimate.yml is:\nyml\nengines:\n  duplication:\n    enabled: true\n    config:\n      languages:\n      - javascript\n  eslint:\n    enabled: true\n  fixme:\n    enabled: true\nratings:\n    paths:\n    - \"src/**\"\nexclude_paths:\n- .nyc_output/\n- docs/\n- core/\n- node_modules/\n- lib/\n- test/\n- testcoverage/\n- testingapp/\n- templates/\n- koaton\n- .*\n- ./**.json\n- ./**.md\n- ./*.js\nthe command spends a lot to give an output longest time was 240+ seconds\nHope you can help me.\n. I've actually find a way to do it, I've make a pull request and now I can even run it with the linter-codeclimate for atom puglin.\n. Sorry this is actually my first pull request and i edit it directly from  gihub, I've also a way to use codeclimate with the linter-codeclime, I'll make a pull request to that repo.\n. ",
    "dezmathio": "``Starting analysis\n\\nand run slightly slower.\\n\\n### Example:\\n    # bad\\n    case foo\\n    when *condition\\n      bar\\n    when baz\\n      foobar\\n    end\\n\\n    case foo\\n    when *[1, 2, 3, 4]\\n      bar\\n    when 5\\n      baz\\n    end\\n\\n    # good\\n    case foo\\n    when baz\\n      foobar\\n    when *condition\\n      bar\\n    end\\n\\n    case foo\\n    when 1, 2, 3, 4\\n      bar\\n    when 5\\n      baz\\n    end\"}}\nerror: (NoMethodError) undefined method[]' for nil:NilClass\n[DEBUG] backtrace: /usr/src/app/lib/cc/analyzer/engine.rb:41:in block in run'\n    /usr/src/app/lib/cc/analyzer/container.rb:115:incall'\n    /usr/src/app/lib/cc/analyzer/container.rb:115:in block (2 levels) in read_stdout'\n    /usr/src/app/lib/cc/analyzer/container.rb:112:ineach_line'\n    /usr/src/app/lib/cc/analyzer/container.rb:112:in `block in read_stdout'\n\n. @GordonDiggs appreciate it.\n. @GordonDiggs as a sidenote; Is there a straight forward way to downgrade to 0.24.3 in the meantime?\n. @GordonDiggs appreciate the super fast turnaround. It's working now :)\n. ",
    "monfresh": "Great! Will do!\n. ",
    "parndt": "Did anything result from the chat? \ud83d\ude04 . ",
    "michaelherold": "I don't use Slim myself, but I'd be up for making an engine for slim_lint through sponsorship if it's important to you.. ",
    "leonelgalan": "Expanding on @GordonDiggs answer, you may also list all the files that change in the feature branch and ran them through codeclimate analyze as such:\nsh\ngit checkout feature-branch-A\ncodeclimate analyze $(git diff --name-only master)\nAssuing the feature branch's name is feature-branch-A and the base branch is master. This will ran the entire file, and not just the changes, through the engines. This won't help much if you already have 300+ issues, but it's a small step forward. . ",
    "Mange": "Just to be a bit pedantic (mostly so people don't get their hype trains running): Docker for {Mac,Windows} is not native docker, it's a tiny VM and an native app that tries to keep it running correctly at all times.\nIt works almost exactly like native, except for a few problems I hope they'll be ironing out later.\nI'm subscribing to this issue as I cannot run codeclimate locally right now.\n. ",
    "joncursi": "@pbrisbin is this still on the roadmap?. ",
    "dahlb": "in the mean time the work around I am using is to pipe the results into a file then grep the file as grep will return 0 or 1 for matches\nie:\nanalyze -f json > codeclimate.json\ncat codeclimate.json\ngrep \"^[]$\" codeclimate.json. ",
    "ahmadnassri": "~any progress (or decision) on this issue?~\nmade a quick pull request to address this for text formatter\n(I don't think this belongs to HTML / JSON formatters, since we want to indicate the success / failure of creating the JSON / HTML report itself). bump. thanks @chrishulton I've seen both the PR and issue #422 which is what prompted me to make the change and open up this PR ...\nhappy to hear internal discussion is ongoing, would there be a venue for us on the outside to track and contribute to the discussion? (for example, I'm representing corp organization with 700+ repos and 300+ members, might be able to give some context from an Enterprise technology perspective). ",
    "jkugler": "Just pinging on this feature. We'd really like to fail our builds when Code Climate finds an issue. Anything I could do to help? Is their a docker build with this code in it we could test?. ",
    "amercier": "For reference: codeclimate/codeclimate-eslint#90\n. ",
    "nadeemja": "PS. Seems like it might not really be stuck, just taking a long time, based on the fact that it completed on a folder with only one file with a single. Any way to run it more verbosely? \n. Hi pbrisbin,\nThank you for a such a thoughtful answer. \nSuch things are rare, and I'm really, really grateful to you.\nI've run codeclimate analyze a few more this, and this last time it actually timed out with:\nerror: (CC::Analyzer::Engine::EngineTimeout) engine duplication ran for 900 seconds and was killed\nI think my Macbook might've suspended the process after inactivity from my part (screen goes black even though i'm AC).\nI'll try configuring exclusions and come back to you :) \n. Update:\nI'm running MeteorJS and added the following exclusion paths:\n- \".meteor/\"\n- \".git/\"\n- \"public/\"\nThe duplication stage now passes. Yay! - and again many thanks.\nThe eslint stage just passed also. 19'360 issues. \nAny chance codeclimate does autofix? \n. ",
    "abritinthebay": "Does this mean I can opt-in on a project right now if I edit my yml file? Because holy-crap I will commit that so fast....\n. The latest CLI? Will it not also work on the web dashboard..?\n. hmmm I'm getting \"We had trouble running the unknown engine.\"\nHere's the engines section of my yml:\nengines:\n  csslint:\n    enabled: false\n  duplication:\n    enabled: false\n  eslint:\n    enabled: true\n    channel: eslint-2\n    config: .eslintrc.js\n  fixme:\n    enabled: true\n  scss-lint:\n    enabled: true\n. haha, what's more new than bleeding edge ;) \nSo right now it fails with Error: Cannot find module 'estraverse-fb'\nWhich appears to be a babel-eslint dependency issue...? \n. Worked it out but only you can fix it. For ESlint 2.x you need babel-eslint@6.x.x not the 5.x branch that works with regular ESlint.\n. see here: https://github.com/babel/babel-eslint/issues/267\n. I'm very willing to alpha test this and find bugs - it's very important for my team here at Bleacher Report to get this in our toolchain on CC :) \n. I could use CLI locally but I'm totally willing to wait - don't have it fully set up to use the CLI atm.\n. It works! \nI'm getting a lot of Definition for rule 'babel/some-rule-name' was not found which I guess means it's not loading the babel eslint plugin, but everything else seems to work.\nThis is great :) if that odd babel plugin issue starts working it'll be perfect ! \n. Specifically it seems to complain about babel/no-await-in-loop... but not the other babel rules we have in there... hmmm.\n. for now I've just set that to not be checked in the checks section of the config.\n. ",
    "milgner": "Hi Pat,\nthank you for the hint! I am indeed on Arch! In that case I'll just recompile my own package, too, I guess :)\nThanks a lot for the quick feedback, I'll close this issue then.\nAll the best\nMarcus\n. ",
    "MaurizioBella": "@pbrisbin If you don't mind please don't close the issue since I'm not able to run the test until the end of this week. Apologize for that and appreciate your feedback.\n. @pbrisbin attached the output. Any thought? thanks\nlogoutput.txt\n. @pbrisbin thanks for dropping me your note. I've tried to run from an empty path without all those directories.\nhere you are\nlogoutput.txt\n. @mrb @pbrisbin any though please?\n. @pbrisbin  I don't know why but I suppose I've some problem with the docker codeclimate at all\nattached the file.\ndocker.txt\nI'm trying with Debian or other SO. appreciate your help\n. yes the problem was on windows, with debian works perfectly. thanks @pbrisbin \n. @pbrisbin thanks for all your thought on that. here you are:\n``\nmauri@debianvb:~/Documents/codeclimate/apexmetrics$ sudo CODECLIMATE_DEBUG=1 codeclimate analyze\nStarting analysis\n[DEBUG] apexmetrics:stable engine config: {\"enabled\":true,\"include_paths\":[\".codeclimate.yml\",\"analyze/\"]}\n[DEBUG] docker run: [\"docker\", \"run\", \"--name\", \"cc-engines-apexmetrics-stable-62b8dbdc-6112-4fc7-a41d-0539c0269ae0\", \"--cap-drop\", \"all\", \"--label\", \"com.codeclimate.label=ee959036-a2e4-43cc-932b-6e67f7cba326\", \"--memory\", \"512000000\", \"--memory-swap\", \"-1\", \"--net\", \"none\", \"--rm\", \"--volume\", \"/home/mauri/Documents/codeclimate/apexmetrics:/code:ro\", \"--volume\", \"/tmp/cc/56da097f-c3bb-458f-97a3-592bcdde883d:/config.json:ro\", \"--user\", \"9000:9000\", \"codeclimate/codeclimate-apexmetrics\"]\nerror: (CC::Analyzer::Engine::EngineTimeout) engine apexmetrics:stable ran for 900 seconds and was killed\n[DEBUG] backtrace: /usr/src/app/lib/cc/analyzer/raising_container_listener.rb:14:intimed_out'\n    /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:13:in block in timed_out'\n    /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:13:ineach'\n    /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:13:in timed_out'\n    /usr/src/app/lib/cc/analyzer/container.rb:71:inrun'\n    /usr/src/app/lib/cc/analyzer/engine.rb:52:in run'\n    /usr/src/app/lib/cc/analyzer/engines_runner.rb:60:inblock in run_engine'\n    /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:74:in with_spinner'\n    /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:55:inblock in engine_running'\n    /usr/src/app/lib/cc/analyzer/formatters/formatter.rb:18:in engine_running'\n    /usr/src/app/lib/cc/analyzer/formatters/plain_text_formatter.rb:54:inengine_running'\n    /usr/src/app/lib/cc/analyzer/engines_runner.rb:59:in run_engine'\n    /usr/src/app/lib/cc/analyzer/engines_runner.rb:23:inblock in run'\n    /usr/src/app/lib/cc/analyzer/engines_runner.rb:23:in each'\n    /usr/src/app/lib/cc/analyzer/engines_runner.rb:23:inrun'\n    /usr/src/app/lib/cc/cli/analyze.rb:20:in block in run'\n    /usr/src/app/lib/cc/cli/analyze.rb:18:inchdir'\n    /usr/src/app/lib/cc/cli/analyze.rb:18:in run'\n    /usr/src/app/lib/cc/cli/command.rb:24:inexecute'\n    /usr/src/app/lib/cc/cli/runner.rb:22:in run'\n    /usr/src/app/lib/cc/cli/runner.rb:8:inrun'\n    /usr/src/app/bin/codeclimate:6:in `'\nmauri@debianvb:~/Documents/codeclimate/apexmetrics$ docker version\nClient:\n Version:      1.11.2\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   b9f10c9\n Built:        Wed Jun  1 21:23:39 2016\n OS/Arch:      linux/amd64\nServer:\n Version:      1.11.2\n API version:  1.23\n Go version:   go1.5.4\n Git commit:   b9f10c9\n Built:        Wed Jun  1 21:23:39 2016\n OS/Arch:      linux/amd64\nmauri@debianvb:~/Documents/codeclimate/apexmetrics$ uname -a\nLinux debianvb 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt25-2+deb8u3 (2016-07-02) x86_64 GNU/Linux\nmauri@debianvb:~/Documents/codeclimate/apexmetrics$ \n```\n. thanks @pbrisbin for coming back to me. \nThe PMD on Eclipse works fine, taking a short time (less than 15m) to send me back the result.\n. @pbrisbin I understand and not a problem at all. \nAs soon as I can I'll share the tar. Please feel free to close this issue\nappreciate for your help on that.\n. ",
    "remik": "I installed it yesterday so I assume it is latest.\nI run your commnads:\n$ docker pull codeclimate/codeclimate\nUsing default tag: latest\nlatest: Pulling from codeclimate/codeclimate\n2f3f3e5e133b: Already exists\n2654c654a6e7: Already exists\n412e64056adf: Already exists\na3ed95caeb02: Already exists\n358c606c9e8c: Already exists\n046233a2b112: Already exists\n7afcb31331eb: Already exists\nc3b0011af4e4: Already exists\nb21ee26695b6: Already exists\n06e3f9018a4d: Already exists\n8bc7aaf2800a: Already exists\na668d0cdafcd: Already exists\nDigest: sha256:9b387b747ac406d66e86cacac7336696e57635e4b41cc3d51b99d94a48d308c0\nStatus: Image is up to date for codeclimate/codeclimate:latest\n$ docker run   --interactive --tty --rm   --env CODECLIMATE_CODE=\"$PWD\"   --volume \"$PWD\":/code   --volume /var/run/docker.sock:/var/run/docker.sock   --volume /tmp/cc:/tmp/cc   codeclimate/codeclimate engines:install\nPulling docker images.\nlatest: Pulling from codeclimate/codeclimate-fixme\nDigest: sha256:7a97f603f9ae200dc3604fe5531a11c33d3d5220fae03fb2ca79f532cc497aed\nStatus: Image is up to date for codeclimate/codeclimate-fixme:latest\nlatest: Pulling from codeclimate/codeclimate-radon\nefd26ecc9548: Already exists\na3ed95caeb02: Already exists\n364b21a1aba7: Already exists\n14de0ac9af46: Already exists\nf06abae204f7: Already exists\n0146945d3ce0: Already exists\n01284cc4d3b7: Already exists\n3ca254603383: Already exists\n086952cfbea1: Already exists\n523aa3ae2b5a: Already exists\n77feb445794f: Already exists\nc99992aa6c39: Already exists\ne88bb41a2fd8: Already exists\nDigest: sha256:7e4334b768dcae8bedd53573793773e08b79868423731e748df4ea5c9d589617\nStatus: Image is up to date for codeclimate/codeclimate-radon:latest\n$ docker run   --interactive --tty --rm   --env CODECLIMATE_CODE=\"$PWD\" --env CODECLIMATE_DEBUG=1   --volume \"$PWD\":/code   --volume /var/run/docker.sock:/var/run/docker.sock   --volume /tmp/cc:/tmp/cc   codeclimate/codeclimate analyze -f html -e fixme . > report.html\n....\n[DEBUG] fixme:stable engine output: {\"categories\":[\"Bug Risk\"],\"check_name\":\"TODO\",\"description\":\"TODO found\",\"location\":{\"lines\":{\"begin\":116,\"end\":116},\"path\":\"./node_modules/karma-coverage/node_modules/ibrik/node_modules/fileset/node_modules/glob/common.js\"},\"type\":\"issue\"}\nI also found:\n[DEBUG] Couldn't include because part of path doesn't exist. path=\"./.\"\n[DEBUG] fixme:stable engine config: {\"enabled\":true,\"include_paths\":[\"./\"]}\nMaybe something is wrong with --volumes params? I copied it from README.\n. Here you go:\n$ echo $PWD\n/home/remik/workspace/web-codeclimate\nI forgot to install wrapper. I will install it check again.\n. Found issue!\nYou are wrong handling relative paths. \nI put . in <path> param so it is current dir but it breaks exclude_paths.\nShould I keep this ticket to fix it or you have internal process?\n. I think my above command is wrong - I will edit it.\n. I changed to absolute path and it is fine.\n. ",
    "anoobbava": "\"Maybe you'd find value in using our hosted analysis instead/only?\" is it means?\n. ",
    "danielkza": "We want to integrate the CC collectors into our own code analysis platform called Mezuro (about, repo, public instance). We've been using the gem successfully for some months, and we intended to deploy it to a CentOS 7 setup that only has Ruby 2.0.\nIf use as a gem isn't intended, it would have been courteous to mention it somewhere, or not make it public on Rubygems.org. :disappointed: \n. ",
    "slifin": "hi @pbrisbin here is the output: \nDocker version 1.10.3, build 20f81dd\n. ```\nClient:\n Version:      1.10.3\n API version:  1.22\n Go version:   go1.6.1\n Git commit:   20f81dd\n Built:        Wed, 20 Apr 2016 14:19:16 -0700\n OS/Arch:      linux/amd64\nServer:\n Version:      1.10.3\n API version:  1.22\n Go version:   go1.6.1\n Git commit:   20f81dd\n Built:        Wed, 20 Apr 2016 14:19:16 -0700\n OS/Arch:      linux/amd64\n. like socodeclimate analyze /private/var/www/xxx/lint.php?\nwhere I'm looking to lintlint.php```\nIt's been stuck on this:\n\nfor several minutes, since I'm hoping to hook this up to run inside my editor it appears way too slow,\nI know using phpcs itself this lint is near instant\nConfiguration looks like this: .codeclimate.yml\nversion: \"2\"\nplugins:\n  phpcodesniffer:\n    enabled: true\n    config:\n      standard: \"Drupal\"\n      file_extensions: \"php,inc,module\"\nSomething that I am aware of that might be relevant here is the Drupal's standard runs on a old version of phpcs, the new version breaks \nthe Drupal coder project use this requirement in their composer.json:\n\"squizlabs/php_codesniffer\": \">=2.8.1 <3.0\" (https://www.drupal.org/project/coder). Looks like the process did complete:\ncodeclimate analyze /private/var/www/xxx/lint.php\nStarting analysis\nRunning structure: Done!\nRunning duplication: Done!\nerror: (CC::CLI::Analyze::EngineFailure) engine duplication failed with status 1 and stderr \n10\nParser process id: 10\ncodeclimate-parser socket not present\nwaiting 1s...\nW, [2018-03-15T13:55:00.023156 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.button.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.023290 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.044678 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.datepicker.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.045084 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.128892 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.tabs.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.129002 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.138401 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.accordion.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.138811 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.139274 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.droppable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.139331 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.143631 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.position.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.143891 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.149701 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.dialog.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.150066 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.162336 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.sortable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.162987 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.164120 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.mouse.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.164448 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.171654 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.slider.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.172221 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.190089 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.selectable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.190297 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.289297 #1]  WARN -- : Skipping ./misc/ui/jquery.effects.scale.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.289427 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.314270 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.autocomplete.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.314391 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.322166 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.core.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.322295 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.323250 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.resizable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.323309 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.331207 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.widget.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.331468 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.360518 #1]  WARN -- : Skipping ./misc/ui/jquery.ui.draggable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.360757 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.372105 #1]  WARN -- : Skipping ./misc/ui/jquery.effects.core.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.372192 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.387300 #1]  WARN -- : Skipping ./misc/jquery.ba-bbq.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.387380 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:00.625757 #1]  WARN -- : Skipping ./misc/farbtastic/farbtastic.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:00.625841 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:01.692517 #1]  WARN -- : Skipping ./misc/jquery.form.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:01.692659 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:01.698990 #1]  WARN -- : Skipping ./misc/jquery.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:01.700802 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:02.179371 #1]  WARN -- : Skipping ./sites/anon/files/js/js_r4u2Vh1EVUNn485K_Z-67QAx88TCzV37CZMh5G0Owg8.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:02.179512 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:03.099121 #1]  WARN -- : Skipping ./sites/anon/files/js/js_euuZ8MTP6bz-yPqqQj7_j9wsEUFMNxIoi9YHZOO8fyU.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:03.099309 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:03.112543 #1]  WARN -- : Skipping ./sites/anon/files/js/js_x1XmG9yT9-YGwJh3lNWvo_FHkvFuLPMkzIH4T23an9w.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:03.112839 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:26.365590 #1]  WARN -- : Skipping ./sites/anon/files/js/js_2hoh0v0y6B2TInaEIHI3XwA7E31uiNqpq69BJ97pODY.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:26.465867 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:55:26.769040 #1]  WARN -- : Skipping ./sites/anon/files/js/js_DkqGp44yg4JPQgvQw3hE_zEiBFGq1PB16gSZhVoZHUI.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:55:26.769115 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:15.319400 #1]  WARN -- : Skipping ./sites/anon/files/js/js_RY2bQm03Bh4EavXnrk7mlDNDS6bohm4LFJhuAjTQcbI.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:15.319510 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:16.024029 #1]  WARN -- : Skipping ./sites/anon/files/js/js_Z9LjYzW4GTsuo8kaI-OQO1f_HHsys6jF1EGt1qXTm9E.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:16.024134 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:37.662822 #1]  WARN -- : Skipping ./sites/all/libraries/respondjs/respond.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:37.666752 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:37.671109 #1]  WARN -- : Skipping ./sites/all/libraries/tablesorter/jquery.tablesorter.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:37.671180 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:37.752162 #1]  WARN -- : Skipping ./sites/all/libraries/tablesorter/jquery-latest.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:37.752378 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.785524 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/colordialog/dialogs/colordialog.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.786519 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.794182 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/wsc/dialogs/wsc.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.796385 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.819752 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/iframe/dialogs/iframe.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.820364 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.822865 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/wsc/dialogs/wsc_ie.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.823915 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.834112 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/div/dialogs/div.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.834426 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.840065 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/textfield.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.840329 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.841078 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/textarea.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.841991 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.869285 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/select.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.871988 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.878320 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/checkbox.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.882509 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.891570 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/hiddenfield.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.892032 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.901105 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/button.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.901268 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.906254 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/form.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.906616 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.912186 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/forms/dialogs/radio.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.912279 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.917437 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/liststyle/dialogs/liststyle.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.918465 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.924630 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/tabletools/dialogs/tableCell.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.924707 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.929090 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/pastefromword/filter/default.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.932327 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.933570 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/about/dialogs/about.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.933656 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.942590 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/smiley/dialogs/smiley.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.942811 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.943210 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/image/dialogs/image.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.943262 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.951468 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/flash/dialogs/flash.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.951929 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.958164 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/link/dialogs/anchor.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.958232 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.959900 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/link/dialogs/link.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.960158 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.965978 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/table/dialogs/table.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.966076 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.977285 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/templates/dialogs/templates.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.977446 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.981288 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/templates/templates/default.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.983021 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:38.988930 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/find/dialogs/find.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:38.989293 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.001409 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/sr-latn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.001482 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.008380 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/a11yhelp.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.013561 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.015447 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/pt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.015616 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.026994 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/vi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.028382 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.028274 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/lv.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.030498 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.040972 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/gl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.041730 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.043462 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/pl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.043622 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.049453 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/mn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.049811 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.050236 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/el.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.050345 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.058708 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/et.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.059066 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.060394 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/sl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.060962 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.067869 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ko.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.068294 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.068789 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/hr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.068891 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.076403 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/fi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.076860 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.077145 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/th.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.077357 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.083277 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ru.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.083603 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.084041 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/mk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.084105 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.089958 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/no.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.090390 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.091158 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/sq.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.091487 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.098907 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/si.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.098972 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.099557 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/gu.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.099732 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.104847 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/tt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.104914 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.108590 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ja.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.108762 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.109985 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/he.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.110178 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.117661 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ug.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.118114 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.119020 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/bg.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.119140 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.127481 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/af.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.127877 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.128458 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/id.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.128815 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.136893 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/cy.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.136963 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.139678 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.139996 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.146312 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/nb.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.146406 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.149140 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/zh-cn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.149446 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.155080 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/pt-br.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.155168 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.161009 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/da.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.161388 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.161907 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/fa.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.162155 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.169360 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/de.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.169794 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.170243 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/en.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.170477 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.180860 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ku.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.181537 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.182315 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/sv.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.182494 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.189433 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/hi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.189506 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.194037 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/zh.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.194389 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.201339 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/uk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.201409 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.203770 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/cs.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.204017 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.208583 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/km.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.208657 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.216203 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/fr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.216427 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.218622 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/nl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.218694 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.224715 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/en-gb.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.224794 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.226513 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/fr-ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.227196 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.232388 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/sr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.232453 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.235422 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/hu.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.236123 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.241473 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/lt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.241539 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.245842 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/fo.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.246226 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.246877 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ar.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.246931 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.254055 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/sk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.254264 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.254769 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/it.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.254840 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.262697 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/eo.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.262788 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.268687 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/es.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.269190 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.269836 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/ro.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.269940 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.277312 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/specialchar.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.277380 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.278505 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/a11yhelp/dialogs/lang/tr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.279282 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.285011 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/pt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.285079 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.287432 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/vi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.287625 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.293006 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/lv.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.293075 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.294766 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/gl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.294970 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.300264 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/pl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.300332 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.302337 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/el.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.302643 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.307341 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/et.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.307413 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.312772 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/sl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.313208 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.313482 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ko.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.313696 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.322183 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/hr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.322407 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.322895 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/fi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.322970 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.329275 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/th.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.329626 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ru.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.329823 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.329742 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.343728 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/sq.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.344318 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.344955 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/no.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.345071 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.352534 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/si.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.352716 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.353123 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/tt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.353215 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.361950 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ja.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.362143 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.362766 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/he.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.362877 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.368773 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ug.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.369205 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.369479 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/bg.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.369677 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.377780 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/af.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.378188 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.378967 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/id.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.379048 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.386058 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/cy.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.386153 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.388381 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.390297 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.391585 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/nb.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.391696 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.398586 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/pt-br.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.398652 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.399461 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/zh-cn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.399692 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.404471 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/da.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.404531 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.406626 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/fa.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.408409 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.409715 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/de.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.409955 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.418915 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ku.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.418999 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.419807 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/en.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.420024 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.425394 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/sv.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.425462 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.435718 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/zh.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.436095 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/uk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.436492 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.436318 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.448171 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/cs.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.448251 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.449540 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/km.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.450263 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.454429 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/fr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.454491 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.459403 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/nl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.459781 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.460410 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/fr-ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.460487 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.467688 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/en-gb.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.467949 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/hu.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.468151 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.468076 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.475185 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/lt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.475323 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.480025 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/ar.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.480441 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.481726 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/sk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.481825 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.489822 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/es.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.489896 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.490538 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/it.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.490704 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.496257 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/eo.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.496324 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.497402 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/specialchar/dialogs/lang/tr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.497693 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.502334 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/scayt/dialogs/options.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.502397 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.503901 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/plugins/clipboard/dialogs/paste.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.504119 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.519013 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/ckeditor.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.521065 #1]  WARN -- : Response status: 413\nW, [2018-03-15T13:56:39.522345 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/sr-latn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.522549 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.528817 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/vi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.528884 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.529586 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/pt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.529901 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.538391 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/lv.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.538473 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.539281 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/gl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.539524 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.547188 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/pl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.547261 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.548044 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/mn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.548259 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.555564 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/en-ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.555633 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.560417 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/el.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.560857 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.561598 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/et.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.561704 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.569227 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/is.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.569867 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.570220 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/sl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.570407 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.577336 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/hr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.577424 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.579587 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ko.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.581779 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.583218 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ms.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.583372 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.590875 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/fi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.591245 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.591790 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/th.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.591894 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.600962 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ru.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.601442 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.601730 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/eu.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.601963 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.611541 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/no.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.611632 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.612509 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/mk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.612738 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.618604 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/sq.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.618671 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.621387 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/gu.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.621834 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.629125 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/si.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.629267 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.633574 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/tt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.633917 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.634738 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ja.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.634833 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.642358 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/he.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.642456 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.643084 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ka.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.643351 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.650679 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ug.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.650745 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.653261 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/bg.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.653505 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.658452 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/af.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.658520 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.661105 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/id.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.662981 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.664687 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/en-au.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.664745 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.671142 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.671548 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.671843 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/cy.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.672073 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.679755 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/nb.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.679980 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.680785 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/zh-cn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.680842 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.689011 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/da.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.689084 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.689580 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/pt-br.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.689749 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.695664 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/fa.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.695727 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.700014 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/de.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.700404 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.701758 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/en.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.701851 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.709637 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/bs.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.710065 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.710964 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ku.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.711263 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.718913 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/sv.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.719490 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.719374 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/zh.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.720238 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.730812 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/hi.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.731418 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.731301 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/uk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.731850 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.740416 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/km.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.740485 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.741001 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/cs.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.741303 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.748792 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/fr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.748860 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.751344 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/nl.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.751610 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.755104 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/fr-ca.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.755170 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.764241 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/en-gb.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.764731 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/sr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.764911 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.764839 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.772607 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/hu.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.772673 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.775210 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/lt.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.775459 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.780284 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/fo.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.780348 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.783353 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ar.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.785867 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.786800 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/sk.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.787061 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.794076 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/es.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.794150 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.794883 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/it.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.795161 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.801676 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/bn.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.801754 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.804217 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/eo.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.804470 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.808489 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/ro.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.808565 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.814542 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/lang/tr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.814738 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.815224 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/js/sf.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.815556 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.824144 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/old/htmlwriter/assets/outputforflash/swfobject.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.824253 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.857350 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/old/assets/uilanguages/languages.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.857767 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.892309 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/js/fulltoolbareditor.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.892502 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.899232 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/js/abstracttoolbarmodifier.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.899441 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.905340 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/js/toolbartextmodifier.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.906984 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.908479 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/js/toolbarmodifier.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.908820 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.918169 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/lib/codemirror/codemirror.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.918387 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.927084 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/lib/codemirror/javascript.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.927489 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.928565 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/samples/toolbarconfigurator/lib/codemirror/show-hint.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.928688 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:39.932724 #1]  WARN -- : Skipping ./sites/all/libraries/ckeditor/adapters/jquery.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:39.932897 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:40.017932 #1]  WARN -- : Skipping ./sites/all/libraries/modernizr/Xmodernizr.custom.52053.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:40.018329 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:40.025055 #1]  WARN -- : Skipping ./sites/all/libraries/modernizr/modernizr.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:40.032759 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:41.788717 #1]  WARN -- : Skipping ./sites/all/libraries/chosen/chosen/docsupport/prism.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:41.789153 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:43.711252 #1]  WARN -- : Skipping ./sites/all/libraries/chosen/chosen/chosen.jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:43.711397 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:44.057362 #1]  WARN -- : Skipping ./sites/all/libraries/chosen/chosen/chosen.proto.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:44.140541 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:44.859102 #1]  WARN -- : Skipping ./sites/all/libraries/jQuery-UI-Date-Range-Picker/js/daterangepicker.jQuery.compressed.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:44.859250 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.562419 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.gears.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.562927 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.589977 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.html4.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.590501 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.591381 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.html5.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.591575 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.617898 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/jquery.ui.plupload/jquery.ui.plupload.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.618276 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.618979 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/jquery.plupload.queue/jquery.plupload.queue.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.619121 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.637326 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.637417 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.638296 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.browserplus.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.638707 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.656096 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.silverlight.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.656206 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.659537 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.flash.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.662536 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:49.665717 #1]  WARN -- : Skipping ./sites/all/libraries/plupload/js/plupload.full.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:49.665854 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:50.184499 #1]  WARN -- : Skipping ./sites/all/modules/core_cp/bootstrap/js/bootstrap.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:50.184625 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:51.123907 #1]  WARN -- : Skipping ./sites/all/modules/core_cp/js/cp.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:51.124006 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:51.124980 #1]  WARN -- : Skipping ./sites/all/modules/core_cp/js/polyfill.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:51.125169 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:51.188973 #1]  WARN -- : Skipping ./sites/all/modules/core_cp/js/moment.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:51.189067 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:51.998894 #1]  WARN -- : Skipping ./sites/all/modules/tooltip/js/cp_tooltip.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:51.999143 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:52.158425 #1]  WARN -- : Skipping ./sites/all/modules/ultimate_cron/js/jquery.tablesorter.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:52.158687 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:52.437689 #1]  WARN -- : Skipping ./sites/all/modules/respondjs/lib/respond.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:52.438187 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:53.558852 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:53.561064 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:53.610809 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_dialog.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:53.610888 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:53.926683 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_rows.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:53.927073 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:54.338985 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_items.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:54.339163 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:54.602191 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_items_resize.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:54.602326 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:54.923921 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_items_overlap.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:54.925101 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:55.021669 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_items_select.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:55.021837 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:55.571926 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_items_nudge.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:55.572020 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:55.573798 #1]  WARN -- : Skipping ./sites/all/modules/roster/js/cp_roster_items_drag.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:55.574130 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:57.668795 #1]  WARN -- : Skipping ./sites/all/modules/datepicker/js/cp_datepicker.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:57.668975 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:56:59.261613 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery-migrate/1.2.1/jquery-migrate.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:56:59.263289 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.418853 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-scale.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.419274 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.436046 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.progressbar.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.436577 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.438096 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.tooltip.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.439945 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.457299 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-fold.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.457510 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.459019 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-slide.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.459140 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.471645 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.button.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.471875 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.479827 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-pulsate.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.479955 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.497039 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery-ui.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.497139 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.498545 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.datepicker.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.498637 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.508723 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-highlight.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.508821 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.509446 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-drop.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.509534 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.520440 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.tabs.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.520528 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.522042 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.spinner.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.522150 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.537781 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.droppable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.537875 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.546102 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.accordion.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.546177 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.546836 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.menu.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.546933 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.556303 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-transfer.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.556396 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.557424 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.position.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.557498 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.563655 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.563752 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.564810 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.dialog.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.564943 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.573148 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-bounce.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.573219 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.574404 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-blind.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.574458 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.584723 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.sortable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.584794 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.585990 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.mouse.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.586045 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.592122 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.slider.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.592205 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.593641 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-shake.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.593747 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.601546 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.selectable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.601618 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.602576 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-clip.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.602701 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.613150 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.autocomplete.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.613332 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.616089 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.effect-explode.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.616170 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.635197 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.core.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.635284 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.635811 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.resizable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.635887 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.642284 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-hu.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.642410 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.642872 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-kk.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.642930 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.650365 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-hy.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.650466 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.650913 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ar-DZ.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.650976 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.659160 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-nl-BE.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.659230 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.659862 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-nb.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.659979 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.669938 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-bg.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.670996 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.671664 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-nn.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.671729 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.682167 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-vi.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.682276 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.687927 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery-ui-i18n.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.689436 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.691077 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-bs.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.691145 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.699059 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-sl.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.699187 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.700226 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ta.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.700284 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.709214 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-be.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.709300 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.710498 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-sv.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.710622 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.717961 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-cs.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.718108 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.719363 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-gl.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.719463 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.730872 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-cy-GB.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.730948 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.734813 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-nl.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.734900 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.738548 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-zh-CN.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.738639 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.743970 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-pt.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.744083 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.749333 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-et.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.749452 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.750393 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-fr-CA.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.750471 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.757355 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-el.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.757439 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.758395 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-fr.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.758462 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.762196 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-sr.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.762267 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.770844 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ky.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.770916 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.771753 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-pl.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.771876 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.779690 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-lt.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.779767 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.781496 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-km.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.781748 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.787281 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ka.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.787349 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.789735 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-hi.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.789818 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.793245 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-lv.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.793354 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.803672 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-is.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.804118 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.804625 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-he.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.804697 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.819237 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-lb.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.819596 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.822221 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-en-NZ.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.822380 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.843171 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ml.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.843269 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.844079 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ko.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.844198 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.862183 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-en-GB.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.862319 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.863099 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ja.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.863179 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.876469 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ca.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.876637 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.877578 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-uk.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.877673 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.890825 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-en-AU.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.891034 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.891946 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-fa.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.892149 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.901801 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-es.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.901872 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.902700 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ro.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.902857 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.910945 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-de.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.911014 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.911442 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-no.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.911536 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.916092 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ms.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.916158 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.917025 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-it.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.917075 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.921247 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-mk.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.921313 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.922097 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-sr-SR.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.922209 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.931362 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-rm.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.931436 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.931902 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-fo.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.931965 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.937256 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-fr-CH.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.937322 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.937858 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-pt-BR.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.937935 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.943996 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-zh-HK.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.944066 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.946759 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ru.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.946826 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.949936 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-az.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.950018 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.952655 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-hr.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.952717 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.955710 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-zh-TW.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.955775 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.958575 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-id.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.958638 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.961911 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-tr.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.961999 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.966941 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-ar.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.967004 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.968086 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-sk.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.968152 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.973589 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-tj.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.973669 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.974609 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-eu.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.974706 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.978383 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-af.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.978460 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.981673 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-sq.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.981738 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.987042 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-eo.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.987122 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.988136 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-da.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.988199 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.992303 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-fi.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.992376 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:06.996400 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/i18n/jquery.ui.datepicker-th.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:06.996515 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:07.000239 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.widget.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:07.000314 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:07.004839 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/ui/ui/minified/jquery.ui.draggable.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:07.005080 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:23.844106 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery.form/3/jquery.form.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:23.845056 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:27.217664 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery.form/2/jquery.form.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:27.217918 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:29.060294 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/1.9/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:29.060905 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:34.067441 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/1.7/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:34.068497 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:47.342449 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/1.8/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:47.345414 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:57:48.996307 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/2.1/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:57:48.996489 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:58:06.991085 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/1.5/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:58:06.991626 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:58:08.298087 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/1.11/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:58:08.298275 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:58:36.228418 #1]  WARN -- : Skipping ./sites/all/modules/jquery_update/replace/jquery/1.10/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:58:36.231105 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:12.898774 #1]  WARN -- : Skipping ./sites/all/modules/ajax_cp/js/cp_ajax.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:12.900436 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:23.796039 #1]  WARN -- : Skipping ./sites/all/modules/google_api/js/cp_map.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:23.797321 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:25.309775 #1]  WARN -- : Skipping ./sites/all/modules/runs/js/cp_roster_items_runs.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:25.310184 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:26.416488 #1]  WARN -- : Skipping ./sites/all/themes/xxx2/js/jquery.expander.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:26.416638 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:26.419210 #1]  WARN -- : Skipping ./sites/all/themes/xxx2/js/jquery.plugin.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:26.419298 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:31.711890 #1]  WARN -- : Skipping ./sites/all/themes/xxx_bootstrap/bootstrap/dist/js/bootstrap.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:31.711997 #1]  WARN -- : Response status: 422\nW, [2018-03-15T13:59:52.768290 #1]  WARN -- : Skipping ./sites/all/themes/xxx_bootstrap/bootstrap/js/tests/vendor/jquery.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T13:59:52.771643 #1]  WARN -- : Response status: 422\nW, [2018-03-15T14:00:01.589331 #1]  WARN -- : Skipping ./sites/all/themes/xxx_bootstrap/bootstrap/docs/dist/js/bootstrap.min.js due to CC::Parser::Client::HTTPError\nW, [2018-03-15T14:00:01.590616 #1]  WARN -- : Response status: 422\nE, [2018-03-15T14:00:09.215793 #1] ERROR -- : Error processing file: ./sites/all/themes/xxx_bootstrap/bootstrap/docs/assets/js/customize.min.js\nE, [2018-03-15T14:00:09.216995 #1] ERROR -- : Excon::Error::Socket: Broken pipe (Errno::EPIPE)\nI, [2018-03-15T14:00:09.236554 #1]  INFO -- : CC::Parser::Client::Error error occurred processing file ./sites/all/themes/xxx_bootstrap/bootstrap/docs/assets/js/customize.min.js: aborting.\nW, [2018-03-15T14:00:09.236715 #1]  WARN -- : Error processing file: ./sites/all/themes/xxx_bootstrap/bootstrap/docs/assets/js/customize.min.js\n/home/app/codeclimate-parser-client/lib/cc/parser/client.rb:93:in `rescue in run': Excon::Error::Socket: Broken pipe (Errno::EPIPE) (CC::Parser::Client::Error)\n  from /home/app/codeclimate-parser-client/lib/cc/parser/client.rb:73:in `run'\n  from /home/app/codeclimate-parser-client/lib/cc/parser.rb:22:in `parse'\n  from /usr/src/app/lib/cc/engine/processed_source.rb:18:in `ast'\n  from /usr/src/app/lib/cc/engine/analyzers/analyzer_base.rb:136:in `parse'\n  from /usr/src/app/lib/cc/engine/analyzers/javascript/main.rb:30:in `process_file'\n  from /usr/src/app/lib/cc/engine/analyzers/analyzer_base.rb:41:in `run'\n  from /usr/src/app/lib/cc/engine/analyzers/reporter.rb:76:in `block in process_files'\n  from /usr/src/app/lib/cc/engine/analyzers/file_thread_pool.rb:24:in `block (2 levels) in run'. codeclimate analyze lint.php works whilst in cwd, thank you. ",
    "paulodiovani": "\nWait for / upgrade to docker 1.12\n\nWill this be fixed on 1.12?\n. ",
    "Aeolun": "Hi @wfleming,\nThanks for the reply. The YAML issue was indeed solved by escaping the text. Stupid that I didn't notice, as I'm almost positive I tried doing that, but happy to have that resolved.\nAs it turns out, the files are indeed symlinked from the bin directory.\n$ ls -la bin\ntotal 44\ndrwxrwxr-x 11 1987272988 1829757191  374 Jun 29 14:56 .\ndrwxr-xr-x 43 1987272988 1829757191 1462 Aug  3 12:36 ..\nlrwxrwxrwx  1 1987272988 1829757191   31 Jan 21  2016 behat -> ../vendor/behat/behat/bin/behat\nlrwxrwxrwx  1 1987272988 1829757191   64 Mar  1 16:59 classmap_generator.php -> ../vendor/zendframework/zendframework/bin/classmap_generator.php\nlrwxr-xr-x  1 1987272988 1829757191   42 Mar 15 16:25 commonmark -> ../vendor/league/commonmark/bin/commonmark\nlrwxrwxrwx  1 1987272988 1829757191   54 Mar  1 16:57 doctrine-module -> ../vendor/doctrine/doctrine-module/bin/doctrine-module\nlrwxrwxrwx  1 1987272988 1829757191   37 Mar  1 16:59 phpspec -> ../vendor/phpspec/phpspec/bin/phpspec\nlrwxr-xr-x  1 1987272988 1829757191   33 Mar 15 16:27 phpunit -> ../vendor/phpunit/phpunit/phpunit\nlrwxrwxrwx  1 1987272988 1829757191   65 Mar  1 16:59 pluginmap_generator.php -> ../vendor/zendframework/zendframework/bin/pluginmap_generator.php\nlrwxrwxrwx  1 1987272988 1829757191   29 Jan 21  2016 psysh -> ../vendor/psy/psysh/bin/psysh\nlrwxrwxrwx  1 1987272988 1829757191   67 Mar  1 16:59 templatemap_generator.php -> ../vendor/zendframework/zendframework/bin/templatemap_generator.php\nOn the plus side, that means that correctly excluding the bin directory also excluded these files from being included.\nI've tried running with CODECLIMATE_DEBUG_ANALYZE=1, but that didn't work, and running with CODECLIMATE_DEBUG=1 the final output keeps overwriting the debug output. Anything I can do against that?\nThanks!\n. Hi @wfleming,\nNo worries, my original issues had indeed been addressed, and I'm now happily analyzing the climate. I'll try and test to see what happens with the output and send you the results tomorrow.\nThanks for the help!\n. ",
    "dread-uo": "We are currently using it at mezuro.org to collect metrics for PHP projects. To be more accurate, we use it on kolekti_cc_phpmd, a metric collector we use on kalibro_processor, which is the application I am updating to use Rails 5.\n. ",
    "chollier": "I was actually able to run it by doing \ndocker build . -t codeclimate/codeclimate-eslint\nwhich overrode the \"stable\" channel\n. I did build my own engine, if you look at my first output you'll see \ncodeclimate/codeclimate-eslint                                                 quri\nI ran docker build . -t codeclimate/codeclimate-eslint:quri.\nNote that I was also already using --dev.\nHmm, so I guess I can't be using eslint because it's available channels are built in the codeship image ?\nWe've been customers of codeclimate for a while and use it with ruby but I've never been able to use it with our front-end javascript projects, mainly because we are using cutting edge tech / versions (eg: first because eslint wasn't supported: corrected, but now we use eslint 3 with our own custom config)\nI decided to give it another shot and realized I could be using a custom engine, we use our own eslint-config-quri which is a fork of eslint-config-airbnb.\nWhat would be the best path to be able to use eslint3 and our own eslint-config-quri + other packages in codeship.com ? Would you guys accept a PR to codeclimate/codeclimate-eslint:pb-eslint2 to : \n- add our eslint-config-quri ?\n- support eslint3 ?\n. ",
    "ovr": "Thanks @wfleming, I updated docker from original PPA for ubuntu from Docker team\nI am having 1.12.1, build 23cf638 now, and it's works\nThanks\n. ",
    "Jacob87": "It seems the pull request #509 has fixed the apparent issue. But other markdown formatting might be a problem for certain names and descriptions. I was wondering if perhaps the method variables found in the code could be wrapped like file_get_contents() in the html template, because they are already kind of \"pre-formatted\". What do you think?\n. ",
    "ehannes": "Perfect! Removing the . made it work! Thanks for the quick reply!\n. ",
    "toddmohney": "LGTM\n. LGTM. LGTM. @pbrisbin yep. you are correct on all counts.. https://github.com/codeclimate/app/issues/3612. @pbrisbin @brynary I agree that this is not ideal. IMO, it is acceptable for now because it won't affect CLI customers in practice until we remove the feature flag. We have until then to come up with an alternative.\nThe motivation behind this implementation was to use the pipeline as designed with minimal hacks. This change is small and easy to move when we feel it would be necessary. Understanding the implication of pretty much any change to the CLI and the resulting impacts on Builder is very difficult. We set the timebox for this work to 1 day, so this was the path of least resistance for me.\nHappy to talk more about it, but what we have here will get us to a point where we can validate our work and unblock some stories. If small modifications need to be made before public release, I think that's acceptable.. @brynary to answer your question:\n\nwhat difficulties did we encounter ... ?\n\nHacking something into the resulting engine list for analysis is doable (but gross, IMO). A problem arises, however, because the analysis step occurs after required engines have been pulled. Now, a second hack is needed to get the engines which do not appear in the .codeclimate.yml file to be pulled. This step is implemented differently for the CLI and Builder. Not sure why.\nIt was my preference to make a small change that would functionally get us somewhere. With the alternative exhibiting signs of cascading hackery, I felt it best to work with the system as-is rather than try to fight it.\nAgain, I think I've made this easy to change as we explore our options.. ",
    "daften": "No problem, it happens and this is an extremely quick fix. I'm impressed TBH :)\nThe different engines are because I changed the codeclimate file, there is nothing wrong in that regard. I can rerun with the \"big\" set of engines if you want, but that's not the problem (I temporarily disabled some engines to see if that would speed things up, it didn't).\nCodeclimate file: https://raw.githubusercontent.com/digipolisgent/robo-drupal-console/feature/codeclimate/.codeclimate.yml\nRun with DEBUG on: https://gist.github.com/daften/f5351066fde2bf13dd9a9dfe1c47994e\nThe output about RoboFile.php not existing is what made me try the . at the end of the command.\nIf you need anything else for debugging, please let me know, and thanks for the help so far!. Hi,\nConfirmation: that command works indeed for me locally. I'll leave this issue open for the README fixes, feel free to close it when you deem it OK :)\nAnd thanks for the quick and excellent support!. Thanks @wfleming for the quick fix and notification! :). Hi,\nI completely looked over that, my apologies. That does work, thank you for that!\nHowever when I discussed this with some of our developers, we all felt it would be more natural if the analyze step would also fetch (and default delete afterwards) the config files in the prefetch step. A flag could indicate not to do this, e.g. when you want to try to change those files and are testing locally in the repository.\nI don't know if this could be accepted as a feature request?\nthanks!. Hi Will,\nThe use case of working purely offline is something we hadn't thought\nabout, and it would slow it down a bit, although that last part shouldn't\nbe a big issue nowadays. Then again, we're privileged in our work\ncircumstances.\nThe fix you suggest, to download if the local files are missing, seem like\na very good way to work with it. Documentation improvements are also\npossible. Something simple like outputting on analyze that the config files\nare only fetched with prepare would also be a good solution for us.\nThe default delete afterwards is because I was thinking about getting local\nsetup as close to codeclimate cloud as possible. In the cloud, if I'm not\nmistaken, there's always the start from a \"clean\" start. So a fresh clone\nor a git clean -fd or something. So the files are fetched every time.\nDeleting the files afterwards seemed like a good solution at the time, but\ngiven your input regarding offline work mostly, scratch that thought.\nIn conclusion, there's two things that you suggest that seem very feasible\nto me and would help us (and most devs I think) tremendously:\n\nFetching the files if they are not present.\nImproving documentation, with the added item I suggest to output a\n   warning or info message on analyze about the prepare step.\n\nThanks for getting back to us so quickly each time and evaluating this\nfeature request :)\nDieter\nhttps://mailtrack.io/ Sent with Mailtrack\nhttps://chrome.google.com/webstore/detail/mailtrack-for-gmail-inbox/ndnaehgpjlnokgebbaldlmgkapkpjkkb?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality\n--\nDieter Blomme\nOn 13 January 2018 at 00:49, Will Fleming notifications@github.com wrote:\n\nHi @daften https://github.com/daften,\nThanks for the feedback. One reason we don't want to fetch to be done\nautomatically every time analysis runs is that one useful use-case for the\nCLI is working offline, so relying on a network connection seems like an\nanti-pattern, and would make analysis slower to run as well. We also\ngenerally try to design the CLI as sets of small, narrowly focused,\nindepenent commands that can be composed as necessary and don't cross-run\neach other too much.\nThat being said, I realize the workflow can be a bit confusing as-is since\nnothing clearly says prepare needs to be run first. I think our docs\ncould improve in this area, but as a functionality change I also think it\nwould be reasonable to have analyze also run prepare when it detects the\nconfig file prepare will write are missing locally, which I think would\naddress the biggest pain point.\nand default delete afterwards\nCan you comment a bit on why that's a desirable workflow for you? In most\nteam's usage of this feature that we've seen, they change fairly rarely, so\nalways fetching and deleting seems wasteful. If they're annoying because\nthey show up in diffs or something, we do recommend adding files fetched\nvia prepare to your .gitignore.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/805#issuecomment-357385890,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABKhoHjKPBx0r9S0PF_rwCMFU52VaXGlks5tJ-9_gaJpZM4RYEbU\n.\n. \n",
    "reedstonefood": "Thanks for the response. I installed that, but it didn't work for me.\nCould you offer some manual help... as setting up the config file(s) would appear to be a one-time thing. I tried copy & pasting what I thought was the right bit from the config file, minus the first column, but to no avail. Perhaps you could have a look at what I have done & why it is wrong?\nhttps://github.com/reedstonefood/machi_koro/blob/master/.codeclimate.yml. Ha, nice to know I wasn't missing something obvious. Thanks very much for your help!. ",
    "backus": "@GordonDiggs I'd recommend looking at https://github.com/backus/rubocop-rspec/issues/228 for cops which are viewed as \"good\" by an rspec core member (not endorsed by the team as a whole but still telling I think). I think some of the cops are objectively good like the ones that @andyw8 mentioned in the comment above. Oh heh that makes a lot of sense. Thanks for the reply. ",
    "zenspider": "In emacs' shell, TERM=dumb.\nI have yet to have anyone complain about my choice for minitest's pride being too restrictive. In general, I much prefer whitelisting to blacklisting so I know what I am getting, but I'm fine with whatever as long as I don't have to remember a flag every time.. Oh, and the \"right\" way of doing this would be to test capability via termcap. In the case of screen:\nscreen|VT 100/ANSI X3.64 virtual terminal:\\\n[...lots of crap]...:tc=ecma+color:\nETA:\n1085 % infocmp -l1 dumb | grep \"^\\tcolor\"\n1086 % infocmp -l1 screen | grep \"^\\tcolor\"\n    colors#8,\n1087 % infocmp -l1 xterm-256color | grep \"^\\tcolor\"\n    colors#256,. Goes from:\n\nto:\n\n. @maxjacobson integrated stackprof into bin/codeclimate. That'll be a separate PR.\n@wfleming it won't go green as-is. There's a test that thwarts my change (and is right). I'm assuming that if one thing built an other_location for path properly, that they all will. The test shows that is false. Either the caching needs to be pushed down for JUST the path value, or some other assumptions need to be made about how the sub-validators are run. If I push down to the real path existance validator, the output is wrong because it bypasses the other 999 issues somewhere. (It lists 1 issue with 1 other location instead of 999 other locations)\n@pbrisbin no benefit in using a lazy accessor and it makes the code less clear because you have to use self. or rename the arg where it is used.. @maxjacobson https://github.com/codeclimate/codeclimate/pull/584\n. @pbrisbin done. @max any thoughts on that failing test? It's a valid test given the requirements... but maybe not a valid requirement. If an engine produces one other_location for a given path correctly, we can presume it will for all other values with the same path.. @pbrisbin I don't understand the question as worded. Do you mean \"change the test to have zero other_locations\" or \"change the test to have non-zero but entirely invalid other_locations\"? \nEither way should be fine. The former wouldn't hit this code at all and the latter would cache the failure. If neither of those interpretations, can you please reword?. kk. fixed. This should be good to go and changes some of my runs from 9+ minutes to 3-4.. @GordonDiggs or @pbrisbin can you merge please?. @pbrisbin done. I wrote that under contract with you... So you already have full rights to it.. @wfleming That's my current reason, yes... But I see this as useful in all sorts of debugging tasks. That's why I toggled it on debug.\n@dblandin \"Keeping the working directory read-only is one way that we ensure engines behave properly\"\nNot sure why that's a concern when it is only in debug mode. It is still obviously enforced when it isn't enabled.. This isn't ruby idiomatic and is an antipattern. Leave the assignment above. Depending on settings rubocop will probably bitch about it.. ooh. that seems useful. May I pull that into minitest (probably separate from capture_io)?. ",
    "pointlessone": "\nif you have advice on how to avoid reflows beyond the obvious stuff like don't-modify-the-dom-in-a-tight-loop, that could be very helpful for us in looking into issues there.\n\nFor this particular PR it was two things:\n\nCut layout calculation early. My report had over 400 code blocks. Each contains a few quite big elements including long text. Browser needs to apply all styles and run trough a long text to calculate its height. I forced code blocks to a specific height. That made browser to stop layout calculation not walking the whole DOM tree.\nCode styling includes repeating gradient background to give alternating line different background. I've hidden those elements (visibility: hidden) to reduce rendering load. It also further reduced layout load since now these elements are completely removed from reflow consideration.\n\nI also used CSS for filtering. Going through 400+ elements and hiding/showing them one by one is extremely slow. CSS on the other had is relatively fast. First, you don't loop over a large collection, you just set/unset a class on container. Then the whole showing/hiding is done in one reflow by the browsers.. Whoa! 236MB! This is unexpected.\nInitially I only included the relevant lines (plus 2 lines of context on each side). Even though there was no heredocs, delimited comments or multiline strings in the issues the syntax highlighting still didn't look right all the time.\nI decided to include full source for two main reasons:\n1. I wonted to include \"Expand\" functionality as 2 lines of context is not always enough.\n2. It's hard to always properly highlight syntax of a code cut at arbitrary points.\nI tested it on this repo and with 61 issues it's only 1.2 MB (it was over 400 issues and just over 1.6 MB when I worked on it \u2014 wrong quotes on strings). The full source (lib and spec) is about 224 KB. It would need to be fully included over 1000 times to reach that size. I wonder how many issues are there on your repo and how big is the source.. Updated to include only  relevant piece of code up to 10 lines (plus up to 2 lines of context on each side). Removed \"View more\" links as that would've defeated the effort.\nReport file size dropped significantly (from 1.2MB to 185KB in my test case).. I'd recommend squashing it before merging. I kept commits to (hopefully) make reviews a bit easier but there's no need to keep them as they're not very meaningful on their own.. This is an updated version checker feature. It's more or less the same code just a bit refactored.\nNotable changes:\n\nIt uses UUID for identification; doesn't send out local username and other private information\nIt implements XDG spec for configuration and caching\nConfig lives in ~/.config/codeclimate/config.yml (by default)\nCache lives in ~/.cache/codeclimate/cache.yml (by default)\n\n\u26a0\ufe0f DO NOT MERGE \u26a0\ufe0f \nIt requires a small change to Versions API before it can be merged. It also probably should be squashed before merging for a bit cleaner history.. Hi @kjg,\nCould you please post debug output and your .eslintrc.json?. This sort of things should be in everyone's personal global gitignore. People use all sorts of editors and tools. It's their responsibility to keep temp files created by their setup out of repo.\nFor instance, I use vim and ctags. It's my setup. It's not specific to any particular project I'm working on. It's my responsibility to keep files generated by vim and ctags out of git. Those files are not generated by anything in the repo. Someone who works on the same projects I do but uses Atom will never encounter swap files created by vim so they don't need to ever deal with them and there's no need for this piece of setup to ever be shared.\nJust my 2 cents\u2026\nUpdate: Apparently, Docker doesn't have a global ignore file. My point if moot. docker/docker#12843. Since CC CLI can be ran both in container and out of it, we have to make sure both cases work identically.\n\nIs there some kind of machine identifier we could hash up and use? Looks like docker info has an ID that may be unique per docker engine, which may be good enough\n\nUUID is a candidate. It's build of machine's MAC address (which is supposed to be unique, but might be spoofed), time and some other data for extra uniqueness.\nID from docker info is likely to be unique but I don't know if docker updates (or anything else) reset it.\nA persisted UUID in user's home directory is likely to even survive OS reinstallation as homedir is the first thing people back up (if at all).\n\nAre we able to move some of that logic into codeclimate-wrapper\n\nProbably not since I believe containerized and bare CLI should behave the same but it definitely will need to do some setup to get local config/cache into container and back.. I wonder why MAC address is higher priority than UUID.\nPersisted UUID:\n Pros\n  * Semantic and de-facto standard way of getting an unique identifier\n  * Includes MAC address\n Cons\n  * Somewhat more complex in generation\n  * Requires wrapper to pass in\nMAC address:\n Pros\n  * Supposed to be unique\n  * Less code than UUID\n Cons\n  * Somewhat arbitrary piece of information\n  * Can be spoofed\n  * Change when hardware changes (sometimes even when default network interface changes, e.g. from Wifi to Ethernet/LTE/etc).\n  * Inaccessible from container, still needs to be passed by a wrapper\n\nWe do not endorse or support users running the CLI outside of docker.\n\nOK. Noted.\n\nCon: doesn't work for folks running docker run directly\n\nIs that a supported way of running CC?\n. > If we can build a UUID from MAC in the container, it's obviously accessing the MAC somehow right?\nIt does. Container's MAC. Which might be a real mac (if network is bridged) or some fake MAC (which might me the same for all containers on the planet using this particular VM). With UUID it doesn't really matter because there are other sources of entropy providing global uniqueness.\nSo as long as we persist generated UUID all is good.\n\nIt's \"supported\" yes, we document how to do it in the README.\n\nDocumented Docker command is 7 lines long and not something I would instantly recall before my first coffee. Would adding 2-4 lines to it be a deal breaker?\n\nBut this issue isn't about a user-facing feature, so it's up to us if \"wrapper-only\" is OK or not.\n\nIs it OK or not? Wrapper definitely improves ergonomics but Docker-only doesn't appear to be impossible either.. I've updated the wrapper to properly mount XDG dirs.\nHere's how a Docker version would look like:\ndocker run \\\n    --interactive --rm \\\n    --env CODECLIMATE_CODE \\\n    --env CODECLIMATE_TMP \\\n    --env CODECLIMATE_DEBUG \\\n    --env CODECLIMATE_VERSIONS_URL \\\n    --env CONTAINER_MAXIMUM_OUTPUT_BYTES \\\n    --env CONTAINER_TIMEOUT_SECONDS \\\n    --env ENGINE_MEMORY_LIMIT_BYTES \\\n    --env XDG_CONFIG_HOME=\"/xdg/config\" \\\n    --env XDG_CACHE_HOME=\"/xdg/cache\" \\\n    --volume \"$CODECLIMATE_CODE\":/code \\\n    --volume \"$CODECLIMATE_TMP\":/tmp/cc \\\n    --volume ~/.config/codeclimate:/xdg/config \\\n    --volume ~/.cache/codeclimate:/xdg/cache \\\n    --volume /var/run/docker.sock:/var/run/docker.sock \\\n    analyze. @pbrisbin Indeed. Do you think creating empty files before mounting would be acceptable? CLI never deletes those files. Only creates/writes to them. Once those files are there their permissions and ownership shouldn't change.. I think it's all good. Just squash corresponding fixup commits and it'll be fine.. JSON? Is Verssions API broken?. No, the config doesn't appear to be saved.. @pbrisbin Fixed specs and added config persistence. Separate commit for ease of review. Safe to squash before merging.. This has been resolved in #645. Please refer to that PR for the details.. @ale7714 Thanks. I'll push a commit for that in this PR.. Try negated excludes:\nyaml\nexclude_paths:\n  - \"src/assets/*\"\n  - \"!src/**{*.php,sample.inc}\"\n  - \"!tests/**.php\"\nThat is globs with ! prefix.. I wander why you need to explicitly include files. Aren't they all included by default?. @wfleming I redone this from scratch. This time without rewriting DirNode/FileNode. This time it is as fast as it used to be.\nI rewritten FS tree code because I couldn't find the issue with reexpansion. Also default include all and narrow down after include is confusing as well. I wanted to make it easier to understand: give it consistent behaviour (default is include none, include only adds paths).  Your code gave me idea how to implement what I wanted (inclusion state tracking) within existing code. While doing that I found the initial bug that motivated the rewrite: empty dir node get repopulated after second time its child gets removed. See example.\n\nThe current implementation does guard against root escape.\n\nYou're right. Partially. Current implementation does indeed guard against root escape. But it's done not by the linked code but in the child node detection code. Pathname#children doesn't include .. so it never can be added to paths. It's all right even if somewhat explicit.. @dblandin Yes, this is a desired feature. May need a rebase/minor tweaks but otherwise I'd like to merge it.. @dblandin If there's any interest in this functionality I'd like to add other glob capabilities as well. Otherwise feel free to close it.. @pbrisbin Since CC CLI uses cc-yaml for config parsing it would warn and completely ignore the relevant config piece. Effectively disabling the feature.. Oh, wow. I didn't expect a review on a weekend.\nWill push the changes tomorrow. AFK at the moment.. This limit is mentioned in the Spec. And it's there for at least 7 months.. Sorry if I wasn't clear. I was pointing out that CLI was behind the spec for at least 7 month with regards to memory limit.. I wonder why memory requirement doesn't go into engine specification file but rather into a registry. This sort of defeats the tell part.\nWe also have more registries. Do we need to update those as well? What if CLI registry runs a different version of engine than the one in the registry? Say, someone uses older CLI but fetches a new engine build that requires more memory than specified in the registry?\nI'd suggest adding memory requirement to the engine spec file. Use some sensible default if it's not specified. Cap it in runner to prevent OOMs.. > I think the versioning problem will always be present\nWe can try and lit the effects.\n\nand I think we are having decent defaults to cover that.\n\nI'm not absolutely sure about this. Imagine the following scenario:\nA dev uses CC CLI 0.69. It's default mem limit is 1GB. An engine in its registry has no memory requirement specified. A new build of said engine is pushed. It wants more than 1 GB of memory. It starts crashing randomly (because that's how most OOM problems start). To fix it we need to update at least two registries and cut a new CLI release.\nAlternatively, we can have a reasonably big mem cap (say, 4GB), default to 1GB and pull the actual value from inside the container. In this case we don't need to update any registries or cut CLI releases. Users can just pull new build of an engine and the configuration will be applied.\nThe downside might be that we need to update the spec and bump its version. And maybe start more thoroughly validate spec compliance. Maybe.. I'm not very familiar with this particular part. I thought we use the spec for something (that is, it's available for the runner). Otherwise why do we need it?\nEven if it requires starting a container we don't need lots of resources. We need maybe 2MB of RAM and maybe a second of CPU time to run cat /engine.json. That is unless ther's another way to get it.. Indeed. Well spotted.. Is this documented anywhere?\nI wonder how this is reflected in the UI. Should I just display them one after another in a plain list or is there any hierarchy to it?. This is a\u2026 bug. It shouldn't be there.. The commented out are the ones that map to themselves.\nThe default is to use file extension as the syntax used to highlight that file. So entry like 'abap' => 'abap' is redundant. But I left comments for the ones that are actually supported by Prism.\nThis list is completely based on what's supported by Prism, not what CC can actually  analyze.. I'm not a designer so comments on visual part are welcome.\nHere's how the report looks when no issues match selected filters:\n\nAnd here's how it looks when no issues have been found:\n\n. data-line-offset is used by Prism's line highlight plugin. The one that gives different background to affected lines.\nThe removed code was based on that plugin and used it for the same calculations the plugin does. Removed code was used to properly position the whole source within a small window showing relevant piece of code. And it was removed since we don't do that any more (we don't position the code, we display the whole piece available for Prism now).. $PROGRAM_NAME is just the first element of $ARGV. It depends on invocation. If the executable is in the $PATH and command is codeclimate help it fill be just codeclimate. If you're in the project dir and the command is bin/codeclimate help it will be bin/codeclimate. If invoked with full path it will be full path. I find it a bit more friendlier to mimic user's invocation style but I have no objections.. Lately I'm more inclined to use proper types. Query methods like this are supposed to return a boolean value. In Ruby that is either true or false. This variable is specifically set to true and there's no API to set it to anything else so all other values (including default nil) are false.\nGetting nil from query method feels more like \ud83e\udd37\u200d\u2640\ufe0f for an answer to a yes/no question.\nI personally might've written !!@abstract but Rubocop doesn't like that.. Not strictly in the latest Rubies. I personally prefer it that way as in this case it's destructuring. available_engine_configs is an array of arrays so block is technically passed a single argument, an array of two values.. Generally I try hard to avoid Pokemon exception handling (catch all exceptions). This is an expected one and this class knows how to handle it. There are other exceptions though. For example, Ctrl-C is an exception and this class has no business handling it but it may be handled somewhere else.. Updated.\nI left this one here because we can gracefully fallback here. And with upcoming cache we can even use real (albeit slightly outdated) values.. At first I wanted to include a short version as well but failed to come up with a good one. Can change but This seem to be a short-lived code so\u2026. http_response is called twice in api_response_body. Momoization saves us one extra request here. I can save the resposnse in local var there if you wish.. I'm not sure what you mean. Here rescue block returns a value we want to memoize so it doesn't work with method-lever rescue.. It's a leftover of an intentional change. I started with a directory having only XDG files in it that was mounted into a container and used trap EXIT to clean up that dir. With exec script process got replaced by exec and there was no one to actually clean up.\nI can change it back.\nIs there any particular reason why we want docker to become the main process?. realpath is defined as a function in POSIX. Also present as a CLI tool in GNU coreutils. It's main use case is expansion of symlinks but it also gives a full path for a relative paths.\nBut on a second though we don't need it here. Docker mounts relative paths just fine.. No, it shouldn't. We still want the check-version in even if it's missing from the config file. super sets this ivar so we need to unconditionally reassign it.. We need to add global_config.save after this line.. Sorry, after the next one.. CC suggests using a short version (all?(&:complete?)) but this is not equivalent in this case as the method is protected.. container_label is not used. I can remove it but chosen to keep it as the change is not related to this PR.. This branch bumps complexity for this method over the threshold. While it's true I don't see how to make it simpler and keep readability.. Nope. Copy-paste leftovers.. ",
    "tedmiston": "I'd really like to have this updated to the latest as well.  Is there anything we can do to help from the dev side?. Hi guys - I ran the same command as OP, then also codeclimate engines:install and am seeing a similar error.\n``\n$ CODECLIMATE_DEBUG=1 codeclimate test pep8\nerror: (NameError) undefined local variable or methodengine_registry' for #\nD, [2018-03-01T04:27:04.259700 #1] DEBUG -- : backtrace: /usr/src/app/lib/cc/cli/test.rb:243:in engine_image'\n    /usr/src/app/lib/cc/cli/test.rb:227:innull_container_id'\n    /usr/src/app/lib/cc/cli/test.rb:231:in remove_null_container'\n    /usr/src/app/lib/cc/cli/test.rb:94:inensure in test_engine'\n    /usr/src/app/lib/cc/cli/test.rb:94:in test_engine'\n    /usr/src/app/lib/cc/cli/test.rb:84:inrun'\n    /usr/src/app/lib/cc/cli/command.rb:73:in execute'\n    /usr/src/app/lib/cc/cli/runner.rb:25:inrun'\n    /usr/src/app/lib/cc/cli/runner.rb:9:in run'\n    /usr/src/app/bin/codeclimate:12:in'\n$ CODECLIMATE_DEBUG=1 codeclimate test markdownlint\nerror: (NameError) undefined local variable or method engine_registry' for #<CC::CLI::Test:0x0055db51a44b88>\nD, [2018-03-01T04:30:18.319967 #1] DEBUG -- : backtrace: /usr/src/app/lib/cc/cli/test.rb:243:inengine_image'\n    /usr/src/app/lib/cc/cli/test.rb:227:in null_container_id'\n    /usr/src/app/lib/cc/cli/test.rb:231:inremove_null_container'\n    /usr/src/app/lib/cc/cli/test.rb:94:in ensure in test_engine'\n    /usr/src/app/lib/cc/cli/test.rb:94:intest_engine'\n    /usr/src/app/lib/cc/cli/test.rb:84:in run'\n    /usr/src/app/lib/cc/cli/command.rb:73:inexecute'\n    /usr/src/app/lib/cc/cli/runner.rb:25:in run'\n    /usr/src/app/lib/cc/cli/runner.rb:9:inrun'\n    /usr/src/app/bin/codeclimate:12:in `'\n```\nOther commands like $ codeclimate engines:list seem to be working as expected.  I installed via homebrew today.\nOn the Docker side, I'm running the latest Docker for Mac edge channel.\n$ docker --version\nDocker version 18.03.0-ce-rc1, build c160c73\n$ codeclimate version\n0.71.1. @ale7714 Thanks for updating!\nI ran codeclimate --help which had the test command in the output.\nI was trying to figure out exactly what the test command did.  I poked around https://github.com/codeclimate/pep8 but didn't see any particular tests that it would run, so was just curious what test was supposed to do.\n```\nt-mbp:~ taylor$ codeclimate --help\nUsage: codeclimate COMMAND ...\nAvailable commands:\n    analyze [-f format] [-e engine[:channel]] [path]    Run analysis with the given arguments\n    console                                             Open a ruby console for the CLI. Useful for developing against the CLI.\n    engines:install                                     Pull the latest images for enabled engines in your configuration\n    engines:list                                        List all available engines\n    help [command]                                      Display help information.\n    prepare [--allow-internal-ips]                      Run the commands in your prepare step.\n    test                                   Test an engine.\n    validate-config                                     Validate your .codeclimate.yml or .codeclimate.json.\n    version                                             Display the CLI version.\n``. Is the idea that this command will be superseded by something or dropped?  I wasn't sure if it turned around to run unit tests on the particular tool being integrated or if CC was writing some custom tests around the engine working, etc.  Or maybe it's just completely unnecessary and we should assume if we can runanalyze` that the engine is working as expected?. ",
    "ghost": "Update?. Potential root cause #660. For improved DX, please consider creating a separate dev docs site under your TLD and providing more in-depth and detailed information, and consider open sourcing the docs for the benefit of public discussion.. This is a terrible idea and I'm disappointed in myself for even bringing it up. But still.... > Aren't they all included by default?\nYes, they are, including things like config, dotfiles and images. As opposed to trying to blacklist everything I was looking for a way to simply whitelist the things I want scanned. The negation should do the trick. Hopefully rules can conflict with each other and later rules will take precedence (e.g. negate everything, then include the right things).\nI find it's also a little funky to have ratings and exclude_paths in separate places, but I'm just getting into this and am not aware of previous design decisions and why they were made.\nThanks for you help @pointlessone!. This appeared to do what I wanted. Not really intuitive but it seems to be working:\nyml\nratings:\n  paths:\n    - \"src/**.php\"\n    - \"tests/**.spec.php\"\nexclude_paths:\n  - \"src/**/*\"\n  - \"!src/**.php\"\n  - node_modules/\n  - \"**/vendor/**/*\". ",
    "mckinnsb": "Sorry, I am a little confused by \"can you also address the issues that Code Climate found? Thank you!\"\n. It's passing Code Climate now - how's this look?. @GordonDiggs Hey, how's this look?. woo!. ",
    "kjg": "The file at path/to/.eslintrc.json is the following\n```json\n{\n  \"parserOptions\": {\n    \"ecmaVersion\": 5,\n    \"sourceType\": \"module\",\n    \"ecmaFeatures\": {\n      \"impliedStrict\": true\n    }\n  },\n\"plugins\": [\n    \"standard\"\n  ],\n\"extends\": \"eslint:recommended\",\n  \"rules\": {\n    \"standard/object-curly-even-spacing\": [2, \"either\"],\n    \"standard/array-bracket-even-spacing\": [2, \"either\"],\n    \"standard/computed-property-even-spacing\": [2, \"even\"],\n    \"no-unused-vars\": [\"error\", { \"argsIgnorePattern\": \"^_\" }]\n  },\n\"env\": {\n    \"node\": true,\n    \"mocha\": true\n  }\n}\n```. It looks like you probably mean https://github.com/codeclimate/codeclimate-eslint/pull/182. I'll give it a shot, thanks!. codeclimate/codeclimate-eslint#182 does not seem to have fixed this particular issue for me. It looks like the eslint code is reading engine config from a json file. Where does the yaml get translated to a json file?. This appears to be working fine on codeclimate.com, but not on the docker images for some reason. I still get the noConfigError unless I symlink my config to the top level (when running locally). Yeah. I did that multiple times and it did updates and I can log into the\nimage and see the new code. I think somehow the code climate yaml file\nisn't sending the path to the config over to the eslint image\neslint-3: Pulling from codeclimate/codeclimate-eslint\nDigest: sha256:4d7955a030f339ebeb5b3b059b216086adb253fecc9457c9e06a5b1d3f94f391\nStatus: Image is up to date for codeclimate/codeclimate-eslint:eslint-3. @maxjacobson Is there any way I can debug this further and see exactly what path the es-lint image is getting for the path to the config?. Ah, I have a little more info now. The analysis seems to work when running codeclimate analyze, but fails with the Error: No ESLint configuration found when passing the engine as a flag codeclimate analyze -e eslint:eslint-3. codeclimate analyze -e eslint also seems to work. So the issue is only seen when running codeclimate analyze -e eslint:eslint-3 for some reason. Since eslint-3 is no longer a valid channel, I won't run into this issue personally anymore. but maybe it's worth looking into if codeclimate analyze -e eslint:eslint-2 with a non top-level eslintrc is going to cause issues.. ",
    "NullVoxPopuli": ".codeclimate.yml:\n```yml\n\nengines:\n  scss-lint:\n    enabled: false\n  watson:\n    enabled: true\nduplication:\n    enabled: true\n    config:\n      languages:\n        - javascript\n  eslint:\n    enabled: true\n  fixme:\n    enabled: true\nratings:\n  paths:\n    - \".scss\"\n    - \".js\"\n    - \"**.jsx\"\nexclude_paths:\n  - config/\n  - dist/\n  - node_modules/\n  - tests/\n  - vendor/\n  - public/\n  - coverage/\n  - bower_components/\n```. ",
    "wevtimoteo": "Hi @NullVoxPopuli, I know this is closed, but just to register for other people with same problem:\nWhat is happening is that your container run by docker-compose is mapping host directories under it, so when your CI runs, it executes CodeClimate analyze for a new docker under it (docker in docker). So mapped volumes used in docker run does not exist in your host machine.\nWhat you have to do is to create a volume in your docker-compose.yml file (under exclusive volumes setting), then mount it using volumes under your test-server. Also remember to create this directory in your host machine \"/code\" so volumes won't be able to store files under it:\nsudo mkdir -p /code && sudo chown -R 1000 /code && sudo chmod -R a+rwx /code\nThis will make this path writable for docker as docker in docker containers will be able to run containers \"inside\" of it mounting volumes properly, then your test files will be found.. ",
    "CLAassistant": " Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.1 out of 2 committers have signed the CLA.:white_check_mark: dblandin:x: zenspiderYou have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you all sign our Contributor License Agreement before we can accept your contribution.4 out of 5 committers have signed the CLA.:white_check_mark: pointlessone:white_check_mark: filipesperandio:white_check_mark: maxjacobson:white_check_mark: larkinscott:x: zenspiderYou have signed the CLA already but the status is still pending? Let us recheck it..  Thank you for your submission, we really appreciate it. Like many open source projects, we ask that you sign our Contributor License Agreement before we can accept your contribution.You have signed the CLA already but the status is still pending? Let us recheck it..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA..  All committers have signed the CLA.. ",
    "halfpastfouram": "How would this work with editors? Would the docker image be running as a container and then the code inserted from outside the container?. I've been trying to find out what caused this but still have no clue thus far. When I use the same configuration locally everything works as expected.\nDetails of my local machine:\n\nuname -a returns:\nDarwin Bobs-MacBook-Pro.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\n\n\ndocker version returns:\n    > Client:\n    > Version:      17.03.1-ce\n    > API version:  1.27\n    > Go version:   go1.7.5\n    > Git commit:   c6d412e\n    > Built:        Tue Mar 28 00:40:02 2017\n    > OS/Arch:      darwin/amd64\n    >\n    >Server:\n    > Version:      17.03.1-ce\n    > API version:  1.27 (minimum version 1.12)\n    > Go version:   go1.7.5\n    > Git commit:   c6d412e\n    > Built:        Fri Mar 24 00:00:50 2017\n    > OS/Arch:      linux/amd64\n    > Experimental: true\n. @aalimovs Yes this occurs in a docker container created by gitlab-ci.\n\n@nporteschaikin I have not found a solution for this and gave up on it. Is there anything I can do to help locate the source of the problem? I still really want it to work.. @wfleming Thank you for your input. I've ran the command in the pipeline as you suggested:\n```\ndocker run --rm -v \"$PWD:/code\" --entrypoint \"/bin/sh\" codeclimate/codeclimate \\\n    -c \"cat /code/.codeclimate.yml\"\n\nengines: {}\nratings:\n  paths: []\nexclude_paths: []\n```. ",
    "vovimayhem": "I'm also noticing that CC::Analyzer::MountedPath#initialize accepts a third parameter path, however it is not being used by the CC::Analyzer::MountedPath.code factory method.... I've renamed the var to CODECLIMATE_CODE_PATH\nI've realized that for this to work, every engine should understand -e CODECLIMATE_CODE_PATH=bar/baz --volume my_volume:/code\nIs that feasible?. I was avoiding having to do something to checkout a worktree from a git repo into the root of a volume, because I knew I had to spend a couple of days on that... and basically rewrite the whole process...\n...which I did: Go Fetch! - Why?\nHowever, I'm still interested on whatever can be done on codeclimate's side :). This is still far from addressing #631 :(. I've realized that for this to work, every engine should understand ENV[\"CODECLIMATE_CODE_PATH\"] \nIs that feasible?. @2ur1st IMHO I don't think that is gonna make it to the CLI, since it's the project rating and the maintainability score the value proposition of codeclimate.com.. Why did the beta channels got removed?\nHow can we re-enable them?. Got it! Thanks!. ",
    "iainbryson": "Great, thanks Will!  I\u2019m not sure why I added /code; I think I was trying to debug something and then it just stayed along.\n\nOn Apr 26, 2017, at 9:52 PM, Will Fleming notifications@github.com wrote:\nHi @iainbryson https://github.com/iainbryson,\nThank you for providing so much detail & the debug output. I think the root cause here is indicated by the line at the top of the debug output:\n[DEBUG] Couldn't include because part of path doesn't exist. path=\"./code\"\nSpecifying /code as a path to analyze when you run codeclimate analyze is causing unexpected behavior. The /code path is an implementation detail of how the CLI makes code available to engines for analysis internally, but you don't need to specify it when running the command: you can just run codeclimate analyze (either with our wrapper script https://github.com/codeclimate/codeclimate/blob/master/codeclimate-wrapper or as the full docker invocation like you shared here).\nWhen you do specify a path argument to analyze, the path should be relative to your project root, and exclude_paths are not applied when an explicit path is specified. So when you pass /code, the CLI can't find that subdirectory and falls back to analyzing the entire repository, and doesn't apply exclude paths because an explicit path was provided. (This failure case should probably error more explicitly than just logging a debug message, sorry.) There's more detail on this behavior in the analyze entry under the \"Commands\" section of the README https://github.com/codeclimate/codeclimate/blob/master/README.md#commands\nSo if you just run codeclimate analyze without a path, I hope you'll see your exclude paths there being respected.\nOne other small note about the config you shared: I realize you were probably just starting to add exclude_paths everywhere to make it work, but an exclude_paths entry under the language name for duplication isn't a valid configuration. If you did want to exclude only specific files for the duplication engine that key would need to be at the same indentation level as enabled and config under duplication, e.g. the same as the exclude_paths entry you have for eslint. Similarly, if you want to exclude assets/javascripts/mathjax.js entirely you only need it in the top-level exclude_paths entry, not the engine-specific ones. Again, I realize you were probably just adding it everywhere while debugging, just mentioning it.\nIf you're still not seeing these files excluded when running codeclimate analyze without any path specified, please let us know here. Output of CODECLIMATE_DEBUG=1 codeclimate analyze in that case would also be very helpful.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub https://github.com/codeclimate/codeclimate/issues/644#issuecomment-297596997, or mute the thread https://github.com/notifications/unsubscribe-auth/ABdc31LD1GXNyufadqzlQeNHG1iP7GqRks5r0ALygaJpZM4NIMo6.\n\n\n. ",
    "nporteschaikin": "One note: I make the deliberate decision not to decide which check configurations to send to the structure engine. I think leaving this determination to the engine saves us from writing this logic in two places.. Re-thinking this in a new PR.. Sending this to you while it's WIP, @pbrisbin, to get your early review.. @halfpastfouram @aalimovs \ud83d\udc4b  Thanks for reaching out! Apologies for how long it took to reply. Were you able to remedy this?. I think it makes sense as-is; the data is the configuration. I do agree that using the class as a namespace is a bit awkward, but it makes the most semantic sense (and is better than, say, nesting another namespace).. You could ~simplify this~ make this a little cleaner, I think:\nruby\nif File.exist?(JSON::DEFAULT_PATH)\n  # merge JSON\nelsif File.exist?(YAML::DEFAULT_PATH)\n  # merge YAML\nend. \n. You can remove the assignment here.. ... and here \ud83d\ude04 . ",
    "alxndr": "--format works in 0.63.7, thanks @ABaldwinHunter !. ",
    "aalimovs": "Is this on GitLab by any chance? Having exactly the same issue. @grauwoelfchen you're a legend, it works.\nHave you see having issues between stages complaining about below?\nUsing docker image sha256:5fbffac31f69cf01e333b34f494d19c649d9daef790903499b5bff669bfb1a6f for predefined container...\nERROR: Preparation failed: Error response from daemon: Conflict. The container name \"/runner-f25555af-project-3835346-concurrent-0-predefined\" is already in use by container \"ae17e87094a364cd2a4cf95d7f0c33a66a8c874332ae5b9429f56e779fda5039\". You have to remove (or rename) that container to be able to reuse that name.. got it set as concurrency = 1 and it's the same.\nPulling in codeclimate on each run taking 6-7 minutes is quite a lot. Are you still doing this yourself or did you find a workaround?. ",
    "grauwoelfchen": "Hi there,\nI also got exactly same issue. but it's solved. I would like to report my situation and (mis-) understanding here. It seems that this problem comes from usage of  dind (docker in docker) service.\n1. --privileged option\nIf you run gitlab-ci-multi-runner on your machine, it might be also needed to add --docker-privileged option to gitlab-ci-multi-runner.\nThis is option is mentioned in here (Use Docker in Docker Executor Section):\nhttps://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker-executor\nI've found also these reports which are caused by the lack of this option use:\nhttps://gitlab.com/gitlab-org/gitlab-runner/issues/1544\nhttps://gitlab.com/gitlab-org/gitlab-runner/issues/2255\n2. overlay\nIf you use DOCKER_DRIVER as overlay or overlay2 (like sample in this gitlab document), docker must have overlay fs support, otherwise volume (/code) will be empty with this environment variable at runtime. (In my case, the lack of this driver was problem, I fogot to run modprobe overlay...)\nIt needs kernel option CONFIG_OVERLAY_FS. I use Gentoo Linux, and ebuild of docker has overlay use flag.\nzsh\n% equery u app-emulation/docker\n...\n + + overlay        : Enables dependencies for the \"overlay\" graph driver, including necessary kernel flags. \n...\nAbout overlay fs driver, see this section:\nhttps://docs.gitlab.com/ee/ci/docker/using_docker_build.html#using-the-overlayfs-driver\nAlso its caching is keep being discussed at here:\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/17861\nThis is my runner script and a stage configuration of .gitlab-ci.yml.\nzsh\n% path/to/bin/gitlab-ci-multi-runner exec docker \\\n--cache-dir /cache \\\n--docker-privileged \\\n--docker-volumes /path/to/tmp/cache:/cache \\\n--docker-volumes /var/run/docker.sock:/var/run/docker.sock\nyaml\ncodequality:\n  stage: codequality\n  image: docker:latest\n  variables:\n    DOCKER_DRIVER: overlay\n  services:\n    - docker:dind\n  before_script:\n    - docker pull codeclimate/codeclimate\n    - docker run --env CODECLIMATE_CODE=\"$PWD\"\n      --volume \"$PWD\":/code\n      --volume /var/run/docker.sock:/var/run/docker.sock\n      --volume /tmp/cc:/tmp/cc\n      codeclimate/codeclimate validate-config\n    - docker run --env CODECLIMATE_CODE=\"$PWD\"\n      --volume \"$PWD\":/code\n      --volume /var/run/docker.sock:/var/run/docker.sock\n      --volume /tmp/cc:/tmp/cc\n      codeclimate/codeclimate engines:install\n  script:\n    - docker run --env CODECLIMATE_CODE=\"$PWD\"\n      --volume \"$PWD\":/code\n      --volume /var/run/docker.sock:/var/run/docker.sock\n      --volume /tmp/cc:/tmp/cc\n      codeclimate/codeclimate analyze -f json > codequality.json\n  artifacts:\n    paths:\n      - codequality.json\nIt will pull images every time, but it works on both gitlab.com and my desktop.\nI don't know why the setup above gitlab document uses codeclimate init in CI.\nIf you have only an empty .codeclimate.yml in /code directory, it might be caused by it.\n# @wfleming 's suggestion ls -al /code was very usefull to me to the understanding.\nAnyway, apparently, I think, it seems that it's not issue at codeclimate side.\nThank you for great tool :-). @aalimovs \ud83d\ude03 \nI have never seen it before. I'm afraid It may be another problem for the issue.\nBut it seems that you have concurrency in config.toml. If your runner has always above its error, I'm not sure, but how about to set concurrency = 1 for now?\n. @aalimovs oh, that's sorry...\nYeah, that will execute pulling all layers every time. Overlay is not enough solution for this... I use codeclimate directly for development on local machine, and I don't care about duration on remote ci for now.\nAs my understand, also for docker in docker, it seems that the layer caching using --cache-from and container registry could be some help, but i don't try yet by myself:\nhttps://semaphoreci.com/docs/docker/docker-layer-caching.html#how_caching_works\nAbout --cache-from option is mentioned also here:\nhttps://gitlab.com/gitlab-org/gitlab-ce/issues/17861\nI hope this would be something help for your situation ;). ",
    "ale7714": "Hi @kelvinst! we don't have any specific plans for an dialyzer engine right now but if you (or anyone) would like to work on wrapping it up as an engine, we'd love to have it.  You can find our open source spec here.\nWe have a codeclimate-community slack organization where folks hang out to discuss engine ideas and development. If you're interested, you can join our Developer Program to get an invite.. Hi @Fire-Dragon-DoL! We changed the executable name (PR) to avoid collisions with the binstub distributed on our Docker image. \nCurrently we recommend using the CLI following our docker based instructions. You can read about it here. Let me know if you have any other questions. . @Fire-Dragon-DoL sorry for the confusion, feel free to contact us through the support form if you need help setting up Code Climate . . Hi @narutozak,\nThank you for reaching out. We take security concerns seriously.\nOur CLI needs to pull images and run containers to perform analysis; that's why \nit needs access to the Docker daemon.  The containers created by the CLI to run \nengines have restricted permissions, with no access to the Docker daemon \nsocket. You can read more about engines specification here.\nWhen running CC on a CI provider, similar to running other tools (e.g. rspec), \nit is important to configure your CI build in a secure way. Most CI providers \nwill have mechanisms in-place to prevent certain malicious actions and to \nprevent a user from gaining control of shared resources. Most often, this means \nrunning your CI builds inside their own VM or container. I don't know the \nspecifics for GitLab but it would also be a good idea to check in with them.\nLet us know if you have any other questions or concerns, and thank you for your \ninterest in Code Climate.. Hi @alexhernandez, thank you for reporting this. It seems like an oversight on our part. I'll let you know when we release a fix for this. . Closing this issue because we're tracking the bug internally. I will post an update when is fixed. . \ud83d\udc4b  @daften, thank you for trying out the new checks. The new maintainability checks are in beta but work is in progress to release them to the CLI. Unfortunately for now, the CLI doesn't support the new codeclimate.yml configuration. Sorry for the trouble and I'll update back as soon as I have new info. . @berfarah @tedmiston  \ud83d\udc4b \nThank you for your detailed issue report. And also, sorry for the delay response. The command test is currently a deprecated/undocumented command, that we're not actively supporting anymore. I suspect you may have found an out of date docs page, is that case? If so, can you please share the link with me so we can update it properly. Also, I wanted to ask what are you using this command for? \nAgain, thanks! \n. Thanks for reporting this! Good catch. On a recent PR, we removed this command and on the next release it won't be available anymore. Sorry for the confusion! . @tedmiston it's being dropped. Actually. this was an experimental command that we didn't got around to implement correctly. It's not necessary. Sorry if it caused some confusion.\n\nwe should assume if we can run analyze that the engine is working as expected?\n\nThat's correct. We have in-depth details on how to build an engine over here https://docs.codeclimate.com/docs/building-a-code-climate-engine. You can also join our community Slack over here.\n. @2ur1st \ud83d\udc4b Ale from Code Climate. Thank you for writing. We don't have any immediate plans to add support back for colorized output. But we welcome contributions from the community. You (or someone else) could open a PR that adds a flag so the CLI outputs colorized output optionally. Thanks again!. @Kristinita thank you for writing this very detailed issue. Windows is not an OS we actively support or QA for. Although, we have a couple of recommendations that you may want to explore. \nYou're running the CLI from a Cygwin while Docker is running in a different VM. $PWD in the Cygwin shell is not the same path for the Docker daemon. This means that CODECLIMATE_CODE isn't pointing to a real directory. \nHave you considered using the Linux bash shell for Windows?\nEven if want to continue using to Cygwin, you will need to determine what is the correct path for your code in the docker machine and fix your script to calculate the right CODECLIMATE_CODE and set that env & use the same correct path to mount /code.\nHope this information is helpful.. typo legact. ohh :(. should we have tests for our tests? jk \ud83d\ude05 . ",
    "Fire-Dragon-DoL": "Oh ok thanks @ale7714 I got really sidetracked because on the website v1.0 and v2.0 the documentation says very different things on how to setup various things. Thanks, I'll make sure to use the docker version!. ",
    "scottbartell": "This appears to be more complicated than I thought it would be. Apparently Circle 2.0 doesn't support mounting volumes this way \nhttps://discuss.circleci.com/t/why-circleci-2-0-does-not-support-mounting-folders/11605/2\nhttps://circleci.com/docs/2.0/building-docker-images/#mounting-folders. ",
    "narutozak": "Hi @ale7714,\nThanks for response.\nI agree - this problem should indeed be secure by the CI - and opened a security issue in GitLab for this matter.   For now it looks like they concur there's a problem, but no solution for the time being.\nThank you - you may close the issue if there's nothing further to be done on CC side.. ",
    "kickerAADS": "I not understand  , make to working my phone.\nJumat, 22 September 2017, Devon Blandin notifications@github.com menulis:\n\n@kickerAADS https://github.com/kickeraads It looks like you submitted\nthe issue template?\nGoing to go ahead and close this.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/738#issuecomment-331351249,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AeGbS_7ZmAsEdLAeZ40h4rsxn92iDS6Bks5sk0CHgaJpZM4PgI3o\n.\n. \n",
    "filipesperandio": "My bad!. @maxjacobson Yes, thanks for the reminder.. I believe this was fixed with the latest release https://github.com/codeclimate/codeclimate/releases/tag/v0.68.0. @pointlessone That's an interesting thought. Let me look into it.\nThe way it is now we definitely need to update other registries, like the one in builder.\nI think the versioning problem will always be present and I think we are having decent defaults to cover that.. @pointlessone Yeah, not something too simple. Also not sure we want to spin up a container to get that info before starting the analysis, but I might be overthinking this right now.\nI agree that updating multiple registries is not ideal, but my understanding is that it is like this for other things as well like channels.. @zaventh There is no actual reason for it to be private, so we just made it public! \ud83c\udf89 . Hey @koic the issue you mentioned wasn't properly linked, could you fix that so we get the full context?. @koic Do you usually do testing/dev outside of the Docker context? I am looking at this and feeling this is an unnecessary change once we do all testing within docker. \n@wfleming WDYT?. @wfleming Do we manually release new versions of the CLI? How we do it?\n. Hey @jasonkarns !\nDo you happen to have a XDG_CACHE_HOME or CODECLIMATE_CACHE env var set? Those would override the default cache directory under $HOME/.cache.\nDocker-for-mac has a limitation of where volumes can be placed, being it within $HOME should be enough, but not outside.. Our CLI runs on docker and docker-for-mac has this limitation where it can't access directories outside  of users' home dir.\nWhile it is not a problem on Linux, where it would simply use that path, on MacOS docker will error out with the message you saw.\nYou can export CODECLIMATE_CACHE=$HOME/.cache on your .bash_profile (or equivalent), that will override the cache dir only for the CLI.\nAs a simple test, you can invoke the CLI with that var set:\n```shell\n$ CODECLIMATE_CACHE=$HOME/.cache codeclimate --help\nUsage: codeclimate COMMAND ...\nAvailable commands:\n    analyze [-f format] [-e engine[:channel]] [path]    Run analysis with the given arguments\n    console                                             Open a ruby console for the CLI. Useful for developing against the CLI.\n    engines:install                                     Pull the latest images for enabled engines in your configuration\n    engines:list                                        List all available engines\n    help [command]                                      Display help information.\n    prepare [--allow-internal-ips]                      Run the commands in your prepare step.\n    validate-config                                     Validate your .codeclimate.yml or .codeclimate.json.\n    version                                             Display the CLI version.\n``. Its a known limitation ofdocker-for-mac`.\nReading this https://docs.docker.com/docker-for-mac/#file-sharing made me believe you could also add /usr/local to the shared directories and make it accessible.. Hey,\nI've tried the below and it successfully excluded dotfiles.\nyml\nexclude_paths:\n  - \"**/.*\"\nYou may try CODECLIMATE_DEBUG=1 codeclimatea analyze to get extra output about what is going on if the above isn't enough.\nAn alternative way is exclude everything and unexclude the files you want.\nyml\nexclude_paths:\n  - \"**/.*\"\n  - \"**/*\"\n  - \"!**/*.php\". Have you tried unexcluding the specific files in the plugin and excluding everything else?\nWorking with the exclude patterns can be challenging sometimes.\nyml\n editorconfig:\n    enabled: true\n    exclude_patterns:\n      - \"**/*\"\n      - \"**/.*\"\n      - \"!www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/js/**\"\n      - \"!www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/scss/**\"\n      - \"!.editorconfig\". It shouldn't ignore, not really clear to me why it is hanging.. Thanks for clarifying this @wfleming, a few of these things weren't clear to me.. @dblandin The problem with this approach is that we always have ENGINE_MEMORY_LIMITS_BYTES set when invoked from the builder. The ENV is set in scheduler and cascades from there, so we will never get to use the yaml entry in this scenario, and that's the reason I was treating it like a minimum_required_memory instead.. From the explanation below, this is not the limit... maybe minimum_required_memory?. @dblandin Made it required_memory. Would give it another shot?. minimum_memory_limit makes sense to me! Adjusted.. @dblandin Do you mind giving another shot?. @chrishulton The engine is based in the https://github.com/codeclimate/sonar-wrapper lib which we use for sonar-java and sonar-php already, meaning the infra was well tested already. The repo is also a fork from sonar-php, which also give me some confidence.\nAdding it to the stable channel is to actually skip the beta step.\nWe don't have to go straight to stable though. WDYT?. ",
    "abbyarmada": "@dblandin can we make sure we update the doc for NSP to mention this once it's updated? https://docs.codeclimate.com/docs/nodesecurity\nThanks! . ",
    "amitrai99": "@dblandin thanks for the quick response. Hope to see the update soon.. @dblandin Any update on this issue?. I wonder if you have information about the nsp 3.0.0 release schedule.. @dblandin Since nsp has been upgraded to v3 and is available in npm, hope to see the engine upgrade very soon.. @zanona for yarn.lock support you will need to use a pre-processor.\nSee https://github.com/nodesecurity/nsp/pull/187#issuecomment-334624079. @dblandin Is there a way to set the build status to warning instead of errors. I want to get all the security warnings but not necessarily force the build to fail due to security errors.. ",
    "zanona": "Hey guys, one question: It seems the latest nsp version also supports yarn.lock correct?\n. @amitrai99 That's great, thanks!\n@dblandin by any chance are pre-processors already implemented on .codeclimate.yaml? \u2014 I couldn't find any references to it, I'm afraid. Thanks.. ",
    "msteward": "@dblandin Looks like the NSP version used by CodeClimate now supports the pre-processors (so that yarn.lock can be used but it doesn't look like this can be configured using .codeclimate.yaml as mentioned by @zanona above. Is there any timeline for adding a configuration option to enable a pre-processor?. ",
    "eutopian": "Closing because I think this has been updated with the pep8 engine. If the rule is still not ignored, please comment and will look into it again. . ",
    "aequitas": "Not codeclimate's fault, but using init is still suggested in Gitlab CI docs: https://docs.gitlab.com/ee/ci/examples/code_climate.html. @patvdleer I dunno, I cargoculted it and try currently running without it but so far no luck[0]. I also tried switching to the previous release but it resulted in the same error[1].\nedit: apparently I was only pulling the old release not actually using it in the run :), actual test running now: https://gitlab.com/failmap/admin/-/jobs/40782684\nThe issue next to this one https://github.com/codeclimate/codeclimate/issues/782 seems to point towards a solution i'm going to try now.\n[0] https://gitlab.com/failmap/admin/-/jobs/40773069\n[1] https://gitlab.com/failmap/admin/-/jobs/40777317. Job completed without failure: https://gitlab.com/failmap/admin/-/jobs/40782684\nDid not compare results yet, my assumption is init generates linter configuration files which are used during the analyze command. Maybe this might cause discrepancies. . @wfleming thanks for the swift response and resolution.. Running into the same issue: https://gitlab.com/failmap/admin/-/jobs/40773069\nedit: wrong build link. ",
    "patvdleer": "Does this mean init should simply be removed from the run/gitlab-ci.yml ?. Can confirm\n```\n$ codeclimate version\n0.70.0\n$ codeclimate analyze  -f json > codeclimate.json\nerror: (CC::CLI::Analyze::EngineFailure) engine structure failed with status 99 and stderr \nCC::Analyzer::Formatters::JSONFormatter#write returned false, indicating an error\n$ CODECLIMATE_DEBUG=1 codeclimate analyze  -f json > codeclimate.json\n...\nD, [2017-11-17T09:42:35.256399 #1] DEBUG -- : engine stdout: \n{\"name\":\"python.parse.succeeded\",\"type\":\"measurement\",\"value\":54}\nW, [2017-11-17T09:42:35.258176 #1]  WARN -- : killing container name=cc-engines-structure-stable-688f5df0-834c-41ff-b650-86237173db57 message=\"output error\"\nI, [2017-11-17T09:42:35.480505 #1]  INFO -- : finished engine structure\nerror: (CC::CLI::Analyze::EngineFailure) engine structure failed with status 99 and stderr \nCC::Analyzer::Formatters::JSONFormatter#write returned false, indicating an error\nD, [2017-11-17T09:42:35.480856 #1] DEBUG -- : backtrace: /usr/src/app/lib/cc/analyzer/raising_container_listener.rb:23:in finished'\n    /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:13:inblock in finished'\n    /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:13:in each'\n    /usr/src/app/lib/cc/analyzer/composite_container_listener.rb:13:infinished'\n    /usr/src/app/lib/cc/analyzer/bridge.rb:52:in block (2 levels) in run'\n    /usr/src/app/lib/cc/analyzer/formatters/formatter.rb:31:inengine_running'\n    /usr/src/app/lib/cc/analyzer/bridge.rb:37:in block in run'\n    /usr/src/app/lib/cc/analyzer/bridge.rb:34:ineach'\n    /usr/src/app/lib/cc/analyzer/bridge.rb:34:in run'\n    /usr/src/app/lib/cc/cli/analyze.rb:36:inrun'\n    /usr/src/app/lib/cc/cli/command.rb:73:in execute'\n    /usr/src/app/lib/cc/cli/runner.rb:25:inrun'\n    /usr/src/app/lib/cc/cli/runner.rb:9:in run'\n    /usr/src/app/bin/codeclimate:12:in'\n```. ",
    "gitlab-winnie": "@wfleming Thank you for the detailed explanation! \ud83d\udc4d \nWe are tracking the GitLab documentation update in https://gitlab.com/gitlab-org/gitlab-ce/issues/40276.. We think (https://gitlab.com/gitlab-org/gitlab-ce/issues/40255#note_47571857) that this is caused by a config change from 0.69 to 0.70. However running codeclimate init --upgrade (as described in Updating existing Code Climate configuration on https://hub.docker.com/r/codeclimate/codeclimate/) resulted in unknown command init. I also could not find upgrade instructions or a changelog entry for the configuration change.. Using CODECLIMATE_DEBUG=1 the command succeeded: https://gitlab.com/gitlab-org/gitlab-ce/-/jobs/40775443 but contained multiple CC::Engine::Analyzers::ParserErrors. So the root cause may be in our code or in the babylon parser. @toddmazierski Thank you very much for the fast reaction! \ud83d\ude80 \nI can confirm that this is fixed with 0.70.1: https://gitlab.com/gitlab-org/gitlab-ce/-/jobs/40869216. ",
    "frenck": "Having the same issue in our GitLab CI.\nEnforced the use of CodeClimate 0.69.0 for now, until this is fixed.. \ud83d\udc4d  Thanks for the quick fix!. ",
    "brammittendorff": "Same issues here in our GitLab CI. Confirmed.. ",
    "mjrider": "Same here, broken Gitlab-CI builds. ",
    "toddmazierski": "Thanks for the report! We're looking into the issue now.. My apologies for the trouble, all. A fix is included in release v0.70.1 if you wouldn't mind upgrading. Thanks!\n. One note about the fix: there is a new type of document included in the JSON output named measurement, described here: codeclimate/spec#59.. Given that this release will include a new channel, I think it merits a minor version bump instead.. Hello @zaventh,\nThanks for reporting this! My colleague @filipesperandio and I think we've located and fixed the bug (codeclimate/codeclimate-sonar-java#53). Sorry for the trouble. Mind trying again?. Is the all-caps formatting intentional?. &method \ud83c\udd92 . TIL that the closing parenthesis can go here! I've always placed it after the closing heredoc.. Is 2 the current version? Would it make sense to make a constant out of it so this warning is correct when it's bumped, or do we not expect it to change that often?. Do you think the literal array [NameValidation, TypeValidation, ValueValidation] might be preferable to iterating through constants? Besides being more straightforward, I wonder if there's a potential bug here if we added a helper module, for example.. Perhaps we can try this if/when there's a third type, but both #to_json and #validator have knowledge of all possible document types. It might be nice to have an intermediate class to call #to_json and #validator on instead.. > If you have a good idea there, I'm happy to do it now.\nI don't! So let's hold off on that.. This was recommended by the gem CLI when my first release failed. If you run gem push without specifying a .gem, you're prompted for your credentials and then they're saved for later.\nI could flesh that out a little bit: \"authenticate with rubygems.org by running gem push\".\n. ",
    "billmei": "@wfleming I see there is a clause in the CLA\n\nYou are legally entitled to grant the above license, and if Your employer(s) has rights to intellectual property that You create that includes Your Contributions, then You represent and warrant that You have received permission to make Contributions on behalf of that employer, that Your employer has waived such rights for Your Contributions to Code Climate, or that Your employer has executed a separate CLA with Code Climate;\n\nBecause I made this contribution on a device owned by my employer, I'll have to get back to you on this (it may take a few weeks).. I'm unable to sign the CLA, so I'm closing this PR.. ",
    "benmccann": "Yes, thank you very much for the clarification!. ",
    "mteodori": "it would be nice if there was a command line option for analyze to fetch. ",
    "davehenton": "Hey @rhwood , Dave here with Code Climate Support. \nIt looks like you've found an outdated doc! I believe that language came from a doc which we had hidden, which I've now deleted. Could you let me know where you found the link to that?\nMoving forward, there is no longer a way to generate a .codeclimate.yml via the CLI. However, you can head over here for instructions on creating one. \nSorry about the confusion here. Let me know if you have any further questions. Thanks!. Hey @Shantanu-Kotambkar, thanks for the heads up. I've added a step to our section here to make that a little clearer. I appreciate you looking out!. Hey @2ur1st , happy to help with this. We have a few editor integrations which you might find helpful: \n\nAtom\nVim\nSublime\n\nLet me know if you have any questions about those, or if there's anything else I can do for you on my end. Cheers.. ",
    "rhwood": "I found the link on https://docs.codeclimate.com , step 2 \"Configuration\". ",
    "dgw": "This documentation issue still exists, I believe. Either that, or I found another path to it.\nFollowed a link to this repo from https://docs.codeclimate.com/docs/configuring-your-code-climate-analysis (which says to generate a config with this CLI tool) from https://docs.codeclimate.com/docs/default-analysis-configuration just this afternoon, and then installed Docker on my system to pull the CLI only to find that it can't generate a configuration for me. :disappointed:. Hi @efueger! I looked back in my browser history and revisited a number of the documentation pages, but couldn't find the one that actually linked me to the incorrect docs.\nThe repo I was thinking about configuring is sopel-irc/sopel. I might not want to know how much technical debt it's hiding, though\u2026 It's an old project, and I took it over only recently. :laughing:. ",
    "efueger": "Sorry about that @dgw! I think you found a different path.\n- What repo are you working with? I can create a config file for you.\n- If you happen to remember how you got to the link, let me know and I'll make a note to fix it. \ud83d\udc4d \nThanks for your help.. Ha! No worries @dgw. \n- I've opened a pull request with that here.. Hi @slifin - I'd recommend:\n\ncodeclimate analyze [path]\n\n\nYou can find more details here: https://github.com/codeclimate/codeclimate#commands\nLet me know if you have any other questions \ud83d\udc4d \n. Hi again - thanks for the output. To help troubleshoot:\n- are you trying to analyze a file that's outside of your current working directory?\n- if so, it's possible that we're not finding the file and then falling back to analyzing everything. \n(and then choking on that min file.). ",
    "wilson": "Thank you for the report, and for investigating the source of the problem. I'll take a look asap.. I think we'd be open to accepting a patch for this, but it does need to have the attributes described by @wfleming over on issue #422 \nI'll take a swing at this next week if I can fit it in.. Sorry, too much Slack; I mean a different Will. Sorry for the ping!. Definitely worth fixing, I'd say.\nAlso, this image is noticeably larger than the previous release. I think I should close this one, and take another swing at it. Sound OK?. I'm going to double-check in the morning to make sure I'm comparing apples to apples.. but it looks like 0.73.0 is 92MB, and this build is 180MB.\nThat being said, our 'structure' image is like 3.2GB, so it's still pretty small in the grand scheme.. Fixed the dev-mode thing over here: https://github.com/codeclimate/codeclimate/pull/843. The CLI only volume-mounts (in the docker -v sense) the current working directory, unless you explicitly set the CODECLIMATE_CODE environment variable.\nIn this case, the file exists under the working directory, but is not accessible via the full path, which is different inside the container.\nWhat we should probably do here instead is normalize the input files based on their shared prefixes.\nSo if you did: codeclimate analyze /foo/baz/qux /foo/bar/baz.rb\n..we would docker -v /foo:/code and pass the relative paths baz/qux and bar/baz.rb to the analysis plugin.\nI'll try to fit that into our future planning, though a patch that implemented such behavior would be very welcome.. 1) shellcheck pointed out its use of features that /bin/sh lacks\n2) The use of local is a giveaway, as that's a bash keyword; it's a no-op in POSIX shell.\nI totally agree with that comment in the handbook; in this case I figured it made sense to call bash-using things bash, and then ideally turn them into /bin/sh scripts as a subsequent step.\nThe bin/prep-release and bin/release scripts use $(< FILE) which is a bash-only feature.. Closing this in favor of separate branches for each of these unrelated changes.. This is ready for another look, at your convenience.. Actually, that part may not be necessary in the first place.\nI added it because it's what the codeclimate/docker-alpine-ruby Dockerfile we previously inherited from was doing. (Though there the path was set to 2.2.0)\nLet me remove that and run the checks again; it shouldn't actually be necessary, because we're happy with the default paths built into the binary package.. Aah, I wasn't sure if it was safe to rely on ActiveSupport in that part of the code.. Changed it, though a to_s is still necessary, because the specs check that it's a String.. ",
    "berfarah": "@ale7714 Same here - also found it through the --help flag. ",
    "chrishulton": "Hi, thanks for the PR.  I've been discussing this internally, and we think that we need a larger discussion for how this should work.\nWe are considering whether to distinguish the CLI exiting with an error (status 1) versus exiting with issues (which should perhaps use a separate error code) as we rely on the status code throughout our infrastructure as well.  There's also the issue of what formatters to apply this behavior to (plaintext, json, html).\nThere is some similar discussion in a previous PR.\nI'd encourage continuing to use the workaround in https://github.com/codeclimate/codeclimate/issues/422 for now.  There's no ETA for when we will get to addressing this change but it's something on our radar.. so will this only execute if the cc yaml looks something like\nprepare:\n  quality: true\n?  is that something to cover in a spec?. super minor, is modify!(content) more appropriate?. should this be a constant?. this could also just be defined as a no-op for the formatters that don't need to close, if it'd be better to have a uniform \"formatter\" interface.. expect_valid_locations seems like kind of a weird argument to me.  since this is the only place where it is false, could you just add a rescue block here for the SourceExtractor::InvalidLocation instead?  i guess it could just return false in the rescue and error further downstream?. will this exception have information about why its invalid?  is it just Location is not formatted correctly?  i think the more detail the better.. curious, why is this going into the stable channel?  This engine is under development, right?  Is it because this is the quality-model branch of CLI?. Thanks for the context.  Since the infra is well QA'd and we haven't announced this engine yet, I think it's OK to go to stable, especially if you followed that process for php.. hm, should this go back to 0.66 since we ended up getting up to 0.69 on master?  there is also the VERSION file on this branch which looks like it got updated to 0.69.. should we use the terminology non-negative here rather than positive since it can be zero?. ",
    "will": "I described no such thing!. ",
    "WTFKr0": "Hey, is there any updates on this ?\nWhen using codeclimate globally in a CI/CD system, it should be apreciate that it exit other thant 0 if issues are found\nMaybe with an option like the curl -f cmd\nWDYT ?. ",
    "dhekimian": "Do you have the overlay2 driver enabled?\nhttps://docs.gitlab.com/ce/ci/docker/using_docker_build.html#using-the-overlayfs-driver\nor in your .gitlab-ci.yml:\ncodequality:\n  variables:\n    DOCKER_DRIVER: overlay2. ",
    "Mode7James": "Any update on this issue @wfleming ?. ",
    "Shantanu-Kotambkar": "I was able to resolve the issue, I had previously turned the checkboxes off\nfor test coverage, and diff coverage in the settings. Please add it in the\ndocumentation, as It is not mentioned anywhere in the documentation.\nOn Tue, Mar 20, 2018 at 6:22 PM, Dave Henton notifications@github.com\nwrote:\n\nHey @Shantanu-Kotambkar https://github.com/shantanu-kotambkar, thanks\nfor the heads up. I've added a step to our section here\nhttps://docs.codeclimate.com/docs/github#section-show-me-how to make\nthat a little clearer. I appreciate you looking out!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/codeclimate/codeclimate/issues/822#issuecomment-374777335,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/Adon9G-qAh6g2pYH9HMyfPO3dPS2xkYcks5tgYEcgaJpZM4Synai\n.\n. \n",
    "PurpleBabar": "Hi :) \nThanks for the answer :)\nWell, the use case is, i'd like to have a partial result :p. The eroor that occurred is not an error generated by software issue, i'm willingly producing it by setting low timeouts.\nThe code that i'm analyzing is really big and contains a lot of legacy code. The thing is,having an enormous report would not be practical, and i imagined a way to progress where, i'd have a timeout of 60 seconds, a small report, that i can correct in one week, and week by week i would be able to correct errors, step by step...\nAnd finally, if the timeout is a setting (needed for performance use case for example) shouldn't the output of a timeout set by human hand be a valid json ?\nSorry for the long answer :/\nCheerz\nPurpleBabar. ",
    "zaventh": "@toddmazierski Preliminary results look good. Thanks.\nIs there a reason that https://github.com/codeclimate/codeclimate-sonar-java is actually private right now? I was looking for that repository initially.\n . ",
    "2ur1st": "Hello @wfleming \nI  cant use codeclimate.com for my project, this project is close for any external service.\nDo you plane to add maintainability ratings to CLI ? I think it`s very useful feature for most projects. sorry, already exist isssue #422. #645 This pull request add this feature. Hello @maxjacobson , thanks for response. I prefer use docker containers. \nDo you have a plan to implements this feature for docker image without wrappers ?. Hello @davehenton. Thank you. I want use the codeclimate in Jetbrains product ( PhpStorm )\nI don not found plugin for this IDE, but may be are you know who did plugin for this tool ?. ",
    "Edvinas-Matulaitis": "Solved issue removing codeclimate docker image and structure image with those:\ndocker rmi codeclimate/codeclimate\ndocker rmi codeclimate/codeclimate-structure\nand then installing them back:\ncodeclimate engines:install\n. ",
    "schnubor": "I found it, exclude_patterns was indented 2 spaces so it became a \"child\" of checks. Removed the spaces, now it works. Sorry.  . ",
    "koic": "@maxjacobson Thank you for your quick answer.\nI could get to know where I could find out about the version of RuboCop and Parser supported by codeclimate.com. I also thank you for the early solution.. I confirmed that it was upgraded to RuboCop 0.58.2. I appreciate your kindness.. @filipesperandio Oops, I'm sorry about it. There is no related issue. That is my mistake and I removed it. Thanks for your review.. > I suspect @koic may be using the gem as a library within some other tool, hence wanting compatibility with Ruby 2.6? Is that accurate Koichi?\nYes. That's right. I appreciate your explanation. Actually this Psych's API has been changed later.\n\nhttps://github.com/ruby/psych/pull/378\nhttps://github.com/ruby/ruby/commit/6268098208e72af53e94b09c4f1d8b010816c328\n\nI will close this PR. \nCode Climate is extremely grateful to help many OSS communities and others. Thank you very much for your team activities.. ",
    "bigquant": "seems hangs on image pull. ",
    "cgriego": "Ruby 2.3 was released Dec 2015 and will hit end of life in April of 2019.. Did that a year ago prior to this issue being opened, but there\u2019s no code change needed to the engine, the container just needs to be rebuilt.\nhttps://github.com/zenspider/codeclimate-flog/issues/8. ",
    "AndrewRayCode": "@wfleming codeclimate prepare. codeclimate prepare \ud83d\ude04 . codeclimate prepare. what isn't? test ?. codeclimate prepare. codeclimate prepare. ",
    "developer239": "There was a problem in jest config. Probably because I updated it to the latest version: https://github.com/developer239/localized-graphql-koa-typescript/commit/96d65bd6be560bb174f8bf957a578db6fda602cd#diff-2d0cd5d10b9604941c38c6aac608178aR28. ",
    "Rafi993": "Yes support  for flowjs is a selling point for me. Flow comes with cli tool for linting. There are also some eslint plugins to run flow ( adding that support will also do ) https://github.com/amilajack/eslint-plugin-flowtype-errors. ",
    "sombreroEnPuntas": "Hola @wfleming :)\nThanks for the fast answer!\nI understand this, but I would still consider it a bug.\nOptions to fix it would be:\n- exclude install step from the timeout count, or even give it a separate count \u231b\ufe0f \n- optimize the install step, since it downloads a HUGE amount of files (even for a decent internet speed this is not good, and it will consume a lot of disk space anyway) and probably not all of them are needed or could be replaced by lighter \"task targeted\" versions.\nFor reference, this is the output of running codeclimate engines:install.\nIt seems to be too much.\nPulling docker images.\nUsing default tag: latest\nlatest: Pulling from codeclimate/codeclimate-structure\nbe8881be8156: Pulling fs layer\na3ed95caeb02: Pulling fs layer\nb48068135ee8: Pulling fs layer\nae1b55f024b1: Pulling fs layer\nae1b55f024b1: Waiting\nb41b6f1b5443: Pulling fs layer\n73ad1c73069a: Pulling fs layer\nbd3c952a7b55: Waiting\n517f8d87afc0: Waiting\n3b15e5686eca: Waiting\n56c8a1afb315: Waiting\nbedabba02a0e: Pull complete\ncd72d8af5337: Pull complete\nd30dbe85d092: Pull complete\n85c3a26ee90a: Pull complete\n011f46571a10: Pull complete\n104c61d9bed9: Pull complete\n0d7eb82823b0: Pull complete\n47dec36717ad: Pull complete\n938170e51a64: Pull complete\n13323a75a80f: Pull complete\n211e9bbfbe79: Pull complete\n1d7a2a2b862a: Pull complete\n169151d4490c: Pull complete\nc2df740cb5e8: Pull complete\ne5e7289c0972: Pull complete\n51171b5718a3: Pull complete\ne7f362e29f5b: Pull complete\n76a0a48d0e5e: Pull complete\nec8af605c2b3: Pull complete\n19c5c6a478e9: Pull complete\n8c492be2e9f1: Pull complete\n23cd489384fd: Pull complete\n0775f16515c8: Pull complete\n9f8ffdaad99c: Pull complete\nd1bf773c1252: Pull complete\n35ff3cd56458: Pull complete\n437c75bc42f3: Pull complete\n0417bfa73343: Pull complete\nfcad30c8bfc5: Pull complete\nd11a8cd3f0b9: Pull complete\n8249bc0574ed: Pull complete\nfddd70d15521: Pull complete\n9a11cfd100c5: Pull complete\ncc6cc5881bea: Pull complete\n2323c8e1d206: Pull complete\nb09678e77c1c: Pull complete\n06a1845f5639: Pull complete\nDigest: sha256:0ba4718a89c002ea7310e12b553e50a103d3c87c18d7e77a995d52e604725dbd\nStatus: Downloaded newer image for codeclimate/codeclimate-structure:latest\nUsing default tag: latest\nlatest: Pulling from codeclimate/codeclimate-duplication\nbe8881be8156: Already exists\na3ed95caeb02: Pulling fs layer\nb48068135ee8: Pulling fs layer\nae1b55f024b1: Pulling fs layer\n6f740d0522ac: Pulling fs layer\nb41b6f1b5443: Pulling fs layer\n73ad1c73069a: Pulling fs layer\nbd3c952a7b55: Pulling fs layer\n517f8d87afc0: Pulling fs layer\n3b15e5686eca: Pulling fs layer\n56c8a1afb315: Pulling fs layer\nbedabba02a0e: Pulling fs layer\ncd72d8af5337: Pulling fs layer\nae1b55f024b1: Downloading [==================================>                ]  840.9MB/1.234GB\n85c3a26ee90a: Download complete\n011f46571a10: Download complete\n104c61d9bed9: Download complete\n0d7eb82823b0: Download complete\n47dec36717ad: Download complete\n938170e51a64: Download complete\n13323a75a80f: Download complete\n211e9bbfbe79: Download complete\n1d7a2a2b862a: Download complete\n169151d4490c: Download complete\nc2df740cb5e8: Download complete\ne5e7289c0972: Download complete\n51171b5718a3: Download complete\ne7f362e29f5b: Download complete\n76a0a48d0e5e: Download complete\nec8af605c2b3: Download complete\n19c5c6a478e9: Download complete\n8c492be2e9f1: Download complete\n23cd489384fd: Download complete\n0775f16515c8: Download complete\n9f8ffdaad99c: Download complete\nd1bf773c1252: Download complete\n35ff3cd56458: Download complete\n437c75bc42f3: Download complete\n0417bfa73343: Download complete\nfcad30c8bfc5: Download complete\nd11a8cd3f0b9: Download complete\n8249bc0574ed: Download complete\nfddd70d15521: Download complete\n9a11cfd100c5: Download complete\nb0d6738c29d9: Download complete\n18bb9101aad7: Download complete\n568bf39d97ae: Download complete\nc060345f2354: Download complete\n4bb3fc9a399d: Download complete\n3e614cf707f5: Download complete. Hmmm... that is two bugs (feature requests if bug is not cool) then:\n- current timeout too short for a HUGE amount of files to download; consider excluding the download step from timeout, or completely remove the step and require installation as a separate task\n- not checking for updates on start-up; consider adding this check either to install step or as part of a separate install task\nIf I get some free time I'll try to send a PR.\nThanks anyway! :D. ",
    "mprussak": "Thanks for the link to that whitepaper, with that extra context I have a better understanding of what the cognitive complexity metric is trying to accomplish. Within this context, the complexity calculation is working as intended, so I'll close this issue.\nIs there a way to configure maintainability check thresholds on a per-language basis? It'd be great if we could relax the complexity threshold just for Scala, but leave it as-is for other languages.. ",
    "jasonkarns": "I do:\necho $XDG_CACHE_HOME \n/usr/local/cache\nI'm confused, though. If the variable is set, why would that break this? Shouldn't it just use that directory as specified? And even if it doesn't, it's a cache directory. Presence shouldn't be relied upon for operation, right? Regardless... what's the recommended workaround?. I can't find any existing issue about this under the docker org. Is it known? How should I be able to reproduce this in a way that pin points docker instead of codeclimate, such that I can open an issue to docker?. (confirmed that using the env var as you mentioned works). Thanks!. FWIW, if anyone else runs into this, you have to add /usr/local/cache to the file sharing list. Attempting to add /usr/local gives another error that usr/local is reserved by Docker. \ud83e\udd26\u200d\u2642\ufe0f . ",
    "tillig": "Should the warning be removed until such time as there's a replacement? Or can the warning message be updated to include a note explaining that it's deprecated yet but there's also no replacement so keep doing what you're doing? It's just confusing to see the warning say \"stop doing this\" when the current plan is... to keep doing it.. Submitted PR to remove the warning.. It appears the ci/circleci: build_test check is not working or otherwise never completes. #893 was submitted 20 days ago and is still waiting for completion.. ",
    "MDSLKTR": "Hey @filipesperandio,\nthanks for the quick reply. The above seems like the right call but unfortunately adding **/.* causes the editorconfig plugin to hangup in our current check chain. This also happens when i run it locally CODECLIMATE_DEBUG=1 codeclimate analyze -e editorconfig\n```\nexclude_patterns:\n  - \"/*\"\n  - \"/.*\"\n  - \".circleci/\"\n  - \".vagrant/\"\n  - \"ansible/\"\n  - \"deployment/\"\n  - \"node_modules/\"\n  - \"www/\"\n  - \"Vagrantfile\"\n```\nThis is the output locally: https://gist.github.com/MDSLKTR/3fd6dad1f3ea8eb4d72bd39c14968b2d\nWhen reading this, i noticed that exclude_patterns are actually inside the include_paths array. This might lead to **/.* checking the .git folder, which is large obviously. You can that log inside the comments.\nRemote it will just hangup. When i remove the line again, it finishes normally and much faster. \nFull .codeclimate.yml:\nhttps://gist.github.com/MDSLKTR/4783907c9436c70df5f60a1b09b2540d. This works for me, thank you! However is this working as intended that the editorconfig plugin seems to ignore the common exclude_patterns?. It is hanging because in fact .git/ is included. This happens when i don't exclude inside plugin but in the common exclude_patterns field.\nThis is the config if i exclude only on the top level:\nD, [2019-01-30T14:54:48.128315 #1] DEBUG -- : /config.json content: {\"enabled\"=>true, \"exclude_patterns\"=>[\"!www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/js/**\", \"!www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/scss/**\"], \"channel\"=>\"stable\", \"include_paths\"=>[\".DS_Store\", \"generate-static-files.js\", \"setup-dev-server.js\", \".eslintrc\", \"webpack.config.js\", \".editorconfig\", \"readme.md\", \".stylelintrc\", \".gitignore\", \"package-lock.json\", \"package.json\", \".prettierrc\", \".gitattributes\", \"optimize-svgs.js\", \".eslintignore\", \".git/\", \".postcssrc.js\", \".codeclimate.yml\", \"composer.json\", \".php_cs.dist\", \"www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/js/\", \"www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/scss/\"], \"debug\"=>\"1\"}\nThis is the config if I exclude as well on the plugin level:\nD, [2019-01-30T14:58:36.890962 #1] DEBUG -- : /config.json content: {\"enabled\"=>true, \"exclude_patterns\"=>[\"**/*\", \"**/.*\", \"!www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/js/**\", \"!www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/scss/**\"], \"channel\"=>\"stable\", \"include_paths\"=>[\"www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/js/\", \"www/custom/plugins/PxswTheme/Resources/Themes/Frontend/PxswTheme/frontend/_public/src/scss/\"], \"debug\"=>\"1\"}\nWhen comparing i see that \"**/*\", \"**/.*\" are missing in the first log when having set the exclude on the top level. Moreover the include_paths array is much larger, even having the .git folder which will cause the hangup.\nSo to me this means that both \"**/*\" and \"**/.*\" are interpreted very strangely when passed as common exclude to the editorconfig plugin. It looks like exclude here will be converted to include by negation which shouldn't be applied if i don't set the ! in front.. First of all thanks @wfleming and @filipesperandio for the detailed explanation and taking the time to make this more clear to me. I tried to test with different patterns so the 'all exclude' is certainly not my first choice. The use case here is a big legacy project with loads of files you don't want to be checking (believe me). I  have improved it now with your help, so the hangup is gone and the checks outside of plugins also work. Again thanks for taking the time :). ",
    "madrian-es": "Any update on this?. ",
    "joshuaclayton": "Does this coincide with the logic in glob_or_include_path? It'd be neat if we could do something like:\n``` ruby\ndef include_paths\n  cc_include_paths.map do |path|\n    glob_or_include_path(path)\n  end.flatten\nend\ndef cc_include_paths\n  if @cc_include_paths.empty?\n    @cc_include_paths += Dir.glob(\"*/\", File::FNM_DOTMATCH)\n  end\n  @cc_include_paths\nend\n``\n.@_filtered_paths`?\n. should this be removed?\n. ",
    "jrafanie": "@GordonDiggs Hi!  Thanks, I hope I'm doing something wrong but support emailed me that the CLI doesn't allow increasing the engine timeout... I would love if it did work in some way...\nI'm seeing this:\nerror: (CC::Analyzer::Engine::EngineTimeout) engine duplication:stable ran for 900 seconds and was killed\nafter export CONTAINER_TIMEOUT_SECONDS=3600; codeclimate analyze\nMy repo is open source so I'd love it if someone can show me how to get that to work.\nhttps://codeclimate.com/github/jrafanie/manageiq\n. If you run my repo locally, make sure you're against current master as I have some changes to hopefully get the codeclimate run to complete.  Hopefully.  \ud83d\ude4f \n. ``` sh\n!/bin/sh\ninvalid_setup() {\n  local reason=$1\ncat >&2 <<EOF\nYour Docker setup does not support the codeclimate wrapper script:\n\n$reason\n\nWe require a local Docker daemon that supports communication via the default\nsocket path.\nPlease use `docker run' to run the `codeclimate/codeclimate' image directly.\nSee https://github.com/codeclimate/codeclimate for more details.\nEOF\n  exit 1\n}\nsocket_missing() {\n  invalid_setup \"/var/run/docker.sock must exist as a Unix domain socket\"\n}\ninvalid_docker_host() {\n  local host=$1\ninvalid_setup \"invalid DOCKER_HOST=$host, must be unset or unix:///var/run/docker.sock\"\n}\nif [ -n \"$DOCKER_MACHINE_NAME\" ] && command -v docker-machine > /dev/null 2>&1; then\n  docker-machine ssh $DOCKER_MACHINE_NAME -- \\\n    test -S /var/run/docker.sock > /dev/null 2>&1 || socket_missing\ndocker-machine ssh $DOCKER_MACHINE_NAME -- \\\n    'test -n \"$DOCKER_HOST\" -a \"$DOCKER_HOST\" != \"unix:///var/run/docker.sock\"' > /dev/null 2>&1 \\\n    && invalid_docker_host $(docker-machine ssh $DOCKER_MACHINE_NAME -- 'echo \"$DOCKER_HOST\"')\nelif command -v boot2docker > /dev/null 2>&1; then\n  boot2docker ssh -- \\\n    test -S /var/run/docker.sock > /dev/null 2>&1 || socket_missing\nboot2docker ssh -- \\\n    'test -n \"$DOCKER_HOST\" -a \"$DOCKER_HOST\" != \"unix:///var/run/docker.sock\"' > /dev/null 2>&1 \\\n    && invalid_docker_host $(boot2docker ssh -- 'echo \"$DOCKER_HOST\"')\nelse\n  test -S /var/run/docker.sock || socket_missing\n  test -n \"$DOCKER_HOST\" -a \"$DOCKER_HOST\" != \"unix:///var/run/docker.sock\" \\\n    && invalid_docker_host \"$DOCKER_HOST\"\nfi\ndocker_run() {\n  exec docker run \\\n    --interactive --rm \\\n    --env CODECLIMATE_CODE \\\n    --env CODECLIMATE_TMP \\\n    --env CODECLIMATE_DEBUG \\\n    --volume \"$CODECLIMATE_CODE\":/code \\\n    --volume \"$CODECLIMATE_TMP\":/tmp/cc \\\n    --volume /var/run/docker.sock:/var/run/docker.sock \\\n    \"$@\"\n}\nif [ -z \"$CODECLIMATE_CODE\" ]; then\n  export CODECLIMATE_CODE=$PWD\nfi\nif [ -z \"$CODECLIMATE_TMP\" ]; then\n  export CODECLIMATE_TMP=/tmp/cc\nfi\nif [ -t 0 ] && [ -t 1 ]; then\n  docker_run --tty codeclimate/codeclimate \"$@\"\nelse\n  docker_run codeclimate/codeclimate \"$@\"\nfi\n```\n. @GordonDiggs See above.  Let me know if there's a way to update to a newer wrapper.  Thanks!\n. Great, thanks @GordonDiggs.  That seems to have worked.  Closing PR, I'll do other cleanups I find after I get a good build going.\n. ",
    "elcuervo": "I used net/http before a refactor \ud83e\udd15 I'll go back to that version. Perfect, it was just a placeholder.. "
}