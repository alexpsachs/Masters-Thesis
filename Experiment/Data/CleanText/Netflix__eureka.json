{
    "karthik-vn": "The documentation may not discuss too much about non-AWS environments, but it is pretty similar to AWS environment, except the EIP part. I will revisit this again\ntomorrow to see if I can provide some more details.\n\nFrom: David Trott [notifications@github.com]\nSent: Monday, October 15, 2012 6:09 PM\nTo: Netflix/eureka\nSubject: [eureka] Provide better documentation for (Non-AWS) datacenter configuration (#1)\nI am trying to configure two Eureka servers on a pair of machines on a LAN to verify inter-server communication is configured correctly.\nIt would be extremely helpful to have a sample configuration for this configuration so that I can verify everything is setup/working correctly.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/issues/1.\n. Thanks, David. I think I found the problem. There was a bug related to bootstrapping non-AWS data centers the first time due to a recent priming feature we introduced which was preventing the application from deploying correctly. I fixed it and release a new revision. Please retain the property configurations you have already and get the new archive(1.1.16) and then give it a try. Your problem should be fixed. I also updated the documentation to make the server configurations little more clear - https://github.com/Netflix/eureka/wiki/Getting-started-with-Eureka\nUnfortunately, I cannot change the default port number now since I may break a few.\nThe following error was the key :\n2012-10-16 13:06:26,683 ERROR com.netflix.eureka.PeerAwareInstanceRegistry:399 [localhost-startStop-1] [openForTraffic] Could not contact null\njava.lang.NullPointerException\n    at com.netflix.eureka.PeerAwareInstanceRegistry.openForTraffic(PeerAwareInstanceRegistry.java:373)\n    at com.netflix.eureka.EurekaBootStrap.contextInitialized(EurekaBootStrap.java:105)\n    at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4791)\n    at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5285)\n    at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:150)\n    at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:901)\n    at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:877)\n    at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:633)\n    at org.apache.catalina.startup.HostConfig.deployDirectory(HostConfig.java:1105)\n    at org.apache.catalina.startup.HostConfig$DeployDirectory.run(HostConfig.java:1664)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)\n    at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:138)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)\n    at java.lang.Thread.run(Thread.java:662)\n. Hi,\nI'm wondering if something is different about how you are storing these records in Route53. We also store the information in Route53 but store the value as for e.g.. \"a\" \"b\" \"c\".\nWhen we retrieve it, the DnsContextFactory retrieves the values without quotes and a split with a space works perfectly.\n. Closing this as this works for you.\n. It does seem like including the \"eurekaServer\" will make it clear that it is not the client's information but the server's information. So, I will try to merge this information in.\n. Yes, it is in my to-do list. We had an internal conflict with aws-jdk version earlier. Will try again this week.\nSent from my iPhone\nOn Mar 10, 2013, at 5:49 PM, \"Trotter Cashion\" notifications@github.com<mailto:notifications@github.com> wrote:\nWhat's the state of this pull request? I'd really like to have Eureka lookup its credentials via its iam-role.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/pull/5#issuecomment-14693288.\n. I merged in this pull request after upgrading aws-java-sdk. I hope this worked for you.\n\nFrom: Karthik Ranganathan\nSent: Monday, March 11, 2013 12:13 AM\nTo: Netflix/eureka\nCc: Netflix/eureka\nSubject: Re: [eureka] Use IAM role as fallback when AWS credentials are not provided (#5)\nYes, it is in my to-do list. We had an internal conflict with aws-jdk version earlier. Will try again this week.\nSent from my iPhone\nOn Mar 10, 2013, at 5:49 PM, \"Trotter Cashion\" notifications@github.com<mailto:notifications@github.com> wrote:\nWhat's the state of this pull request? I'd really like to have Eureka lookup its credentials via its iam-role.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/pull/5#issuecomment-14693288.\n. Cool. Thanks for getting back to me.\nOn Wed, Apr 17, 2013 at 3:31 PM, Aaron Feng notifications@github.comwrote:\n\n@karthik-vn https://github.com/karthik-vn I was able to get it working.\nThx!\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/pull/5#issuecomment-16539884\n.\n. New and improved replication pipeline\n\n1) One per peer per action\n2) Taking down peers do not affect replication to other peers.\n3) Indefinite retries during network timeouts because of the above isolation.\n4) Replication Events hanging around for more than 30 s automatically removed.\n5) On AWS, it immediately represents a 5X increase in replication scalability.\n6) The new model lends itself pretty easily to future batching of events which further increases scalability depending on the batch size \nhttps://github.com/Netflix/eureka/commit/7af3a79a7f4e5969096b030b628f9ead1bd06c66\n. I'm looking into the problem...\n. I'm still not able to reproduce the problem.. But it does look like there is a problem. I will update you by EOD tomorrow.\n. Thanks. I'm able to reproduce the issue and will check in a fix soon. We had some custom netflix configurations hiding the bug for us.\nI'm waiting for the latest blitz4j library to show up in the maven library and once that shows up I will check in the fix.\n. BTW, I will have to rollback this change https://github.com/Netflix/eureka/commit/68acc47b82191ff0be2f2c418b209e8fe21e5c87 before the release as I realized the name has been used quite a bit and this might break a few things. May be we will have make this backward compatible too with the old property.\n. Is this service you are registering running on the same host as the eureka server? \nAs far as eureka server is concerned, the register port and listen port would always be the same and it is identified by the property eureka.port in eureka-client.properties.\nI can't think of a scenario where you would listen in a different port than the one advertised (registered).\n. BTW, I have already fixed this issue. With the latest change your problem should go away. The binary will take sometime to show up. Please let me know if this fixes your issue.\n. You can do that by specifying eureka.port in eureka-client.properties both the server and the service. There will be 2 eureka-client.properties one for the eureka server and one for the service. For example,\nthe server configuration might be something like. This will register the client part of the server (and advertises it to other peers)\neureka.name=eureka-server\neureka.port=8080\nThe service configuration will be something like\neureka.name=myservice\neureka.port=8001\nHence, there will be 2 different sets of eureka-client.properties in this situation. Please let me know if this clarifies the confusion.\n. BTW, You can see the example set up here https://github.com/Netflix/eureka/wiki/Running-the-Demo-Application. And in the run configurations, I have specified an example where in I change the name of the eureka-client.properties by specifying\n-Deureka.client.props\nhttps://github.com/Netflix/eureka/blob/master/eureka-server/runservice.sh\nhttps://github.com/Netflix/eureka/blob/master/eureka-server/runclient.sh\nThe above system property -Deureka.client.props is not needed, if you have your configurations in eureka-client.properties.\n. OK, I see the confusion now. For the \"service\", you need different sets of ports eureka.port represents both the advertising port and the port where eureka server runs. Internally, here in netflix we map the namespaces to be different and hence there is no problem.\nThis can be overcome by specifying the namespace of your choice to https://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/appinfo/CloudInstanceConfig.java\nand \nhttps://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/appinfo/EurekaInstanceConfig.java\nMeanwhile, I will try to incorporate your earlier change so as to reduce the confusion.\n. BTW, if you have not already noticed - I merged your change https://github.com/Netflix/eureka/commit/68acc47b82191ff0be2f2c418b209e8fe21e5c87 by providing backward compatibility now.\n. This is now supported with https://github.com/Netflix/eureka/commit/26816f32873bb2f6cd4c75b464d2ad831c9b74d4\n. HI,\nDo you have any more stack trace? Or is that all?\n. We will try to reproduce this and get back to you.\n. Was able to reproduce it. And it has been fixed by this change list https://github.com/Netflix/eureka/commit/3e8cfd3bde5879a5a70442f844838d408db25903\nPlease let me know if it works for you and then we can close the issue.\n. Makes sense. I will try to get to it today.\nOn Jan 17, 2013, at 9:04 AM, \"Tyson Stewart\" notifications@github.com<mailto:notifications@github.com> wrote:\nAs far as I can tell, the only way to update metadata for a service is to re-register the service. It would be super handy for me if there existed a PUT endpoint similar to the {...}/status?value= endpoint that could be used to update the metadata, in part or in whole.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/issues/12.\n. I fixed this with this change list :https://github.com/Netflix/eureka/commit/6feaa10f315e456170905fc6bbc1f01c2ffb4e42\nGive it a try: Example below\ncurl -X PUT http://localhost/discovery/v2/apps/APIPROXY/i-8a59f494/metadata?key1=value1&key2=value2\n. Chris,\nThere are no known issues with the servo 0.4.13. If you can tell me how exactly I can reproduce the issue (i.e.) the exact steps for doing the maven build, I will try to see why the problem happens.\nI just verified that the gradle build for eureka works fine.\nThanks.\n. Chris,\nI update eureka to use servo 0.4.15. Can you do a build and see if that solves the problem. I will release the latest version to maven central soon.\n. Cool- I also release the latest version of eureka.\nhttp://search.maven.org/remotecontent?filepath=com/netflix/eureka/eureka-core/1.1.73/eureka-core-1.1.73.pom\nI'm going to close the issue. Please reopen as needed.\n. Chris,\nMay be I'm not understanding clearly when you say, configuring the port is pretty involved.\nAre you saying specifying the following URL is complicated?\neureka.serviceUrl.defaultZone=http://localhost:8080/eureka/v2/\n. Chris,\nYou have it all correct. \nEureka has not been built to support embedded servers. But these would be used only for dev purposes - correct. In production you may have to change server.xml etc based on your traffic needs. Isn't it?\nAnd the option you are looking for - to change a port setting and everything should just work - will be available only with an embedded tomcat/jetty kind of setup.\n. I think it is reasonable to fall back on archaius configs in case the specified eureka properties do not exist. I will make that change.\n. Not needed anymore - since the deletions are now honored properly.\n. Fixed by the commit : https://github.com/Netflix/eureka/commit/3478052ddef01a6de5fca9a601959c90e4bb3d6a\n. Hi,\nYes - the wiki has to be fixed. I think you are probably getting the format of the TXT record wrong. I think the TXT records should be similar to this\n\"eu-west-1a\" \"eu-west-1b\".\nCan you try this and let me know?\n. Not sure what is going wrong in your case. Our route53 configuration works perfectly.\nFor eg. here is the TXT record for our test environment.\nhttp://www.dnswatch.info/dns/dnslookup?la=en&host=txt.us-east-1.discoverytest.netflix.net&type=TXT&submit=Resolve\n. @Nils.\nWhat is the motivation behind your design? Is it to autoscale the eureka nodes or load balance the requests to multiple eureka servers for a particular AZ?\nAutoscaling has to be dealt with carefully because of  the horizontal replication in eureka.If it is to load balance across multiple servers in an AZ, we have thought of a way do this by retaining all the optimizations that Sudhir was talking about earlier.\n. Your motivation does make sense with regards to distributing one eureka server per AZ with a max size of 1. Autoscaling may not be necessary. I will have to refresh my knowledge of how VPC and EIP works. Can you now bind an EIP in a VPC environment?\n. When eureka first starts up without peers it takes about 5 mins for it to start serving requests because it waits for all clients to register completely before it can give out the list. You can disable this by setting this\nSet this only for this sample service without which starting the instance will by default wait for the default of 5 mins\neureka.waitTimeInMsWhenSyncEmpty=0\nIn a production environment, it is recommended that you don't set this property. You might want to revert the other property changes above as they are unrelated.\n. ",
    "ericdowd": "Ah. That explains quite a bit. I put it in as \"a b c\". Fortunately easy\nchange on my end to fix the DNS records. I guess it shows if there are two\nways of doing something and one way is wrong, someone will inevitably do it\nthe wrong way :)\nOn Thursday, December 20, 2012, karthik-vn wrote:\n\nHi,\nI'm wondering if something is different about how you are storing these\nrecords in Route53. We also store the information in Route53 but store the\nvalue as for e.g.. \"a\" \"b\" \"c\".\nWhen we retrieve it, the DnsContextFactory retrieves the values without\nquotes and a split with a space works perfectly.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/pull/3#issuecomment-11577122.\n. If it will help, created an AMI that reproduces the problem, ami-eb8a0482 in us-east-1. Based off Amazon Linux 2012.09, so log in with ec2-user. AWS credentials need to be set in eureka-server.properties.\n\nhttps://gist.github.com/4423040 has the description of how I set it up.\n. It is a bit of a relief, I was afraid I misconfigured something again. As for the change rollback, makes sense. Though I am curious, if the eureka server is listening on port 8080 and I want to register a service on port 80, how would I do that? Looking at the documentation and what I've gotten from looking at the code, it seems like in eureka-client.properties they both would have eureka.port = 8080 (for the server) and eureka.port = 80 (for registering the service)\n. It would be a client service on a different server. For example with the demo service, in eureka-server/conf/sampleservice/sample-eureka-service.properties, if I wanted to have it listen on port 8001 for the service and have the eureka server listen on port 8080 on a separate server\n. Okay, I'm following you, I think. I will give it a shot. Thanks\n. Ah yes! I get it now. Thanks :)\n. Can bootstrap now. So closing the issue\n. For DescribeAddressesResult it is not mutually exclusive. It will always have the public ip, and will also have the allocation id when it is a VPC elastic IP. \nHowever for ec2Service.associateAddress(associateAddressRequest); it is mutually exclusive; public ip for ec2-classic and allocation id for vpc\n. Also if you would prefer, in DescribeAddressesResult there is a method getDomain() which returns the string standard for ec2-classic and vpc for VPCs\n. ",
    "trotter": "What's the state of this pull request? I'd really like to have Eureka lookup its credentials via its iam-role.\n. Thank you, @karthik-vn. I'll test it out later this week.\n. ",
    "aaronfeng": "@karthik-vn I was able to get it working.  Thx!\n. ",
    "tysonstewart": "That's the trace from the response message. Here's the stack trace from the Tomcat logs. Doesn't look much more useful.\nJan 16, 2013 4:55:33 AM com.sun.jersey.spi.container.ContainerResponse mapMappableContainerException\nSEVERE: The RuntimeException could not be mapped to a response, re-throwing to the HTTP container\njava.lang.NullPointerException\n    at com.netflix.eureka.PeerAwareInstanceRegistry.register(PeerAwareInstanceRegistry.java:444)\n    at com.netflix.eureka.resources.ApplicationResource.addInstance(ApplicationResource.java:124)\n    at sun.reflect.GeneratedMethodAccessor39.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\n    at java.lang.reflect.Method.invoke(Unknown Source)\n    at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n    at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$VoidOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:167)\n    at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n    at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n    at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:134)\n    at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n    at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n    at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n    at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n    at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:416)\n    at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:537)\n    at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:895)\n    at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:843)\n    at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:804)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n    at com.netflix.eureka.StatusFilter.doFilter(StatusFilter.java:68)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)\n    at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:936)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)\n    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)\n    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)\n    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\n    at java.lang.Thread.run(Unknown Source)\n. Confirmed. Fixed! Thanks!\n. Awesome! Thanks!\n. Works perfectly. Thanks!\n. ",
    "cfregly": "i've added build instructions to Refapp's README.md:  https://github.com/cfregly/refapp#how-to-build\nyou'll want to uncomment out eureka-core from the refapp-core/pom.xml before building to reproduce the error.\nbut i just realized that i only need the eureka-client dependency in my eureka clients (refapp-middletier, in this case).  in other words, i don't need the eureka-server, eureka-core, eureka-resources dependencies in my eureka clients - just the eureka-client dependency which works fine.\nso unless you want to investigate this non-standard dependency configuration further, we can close this out.\nthanks, karthik!\n-chris\n. reopening based on https://github.com/Netflix/ribbon/issues/3\n. looks good, karthik.  i pulled the latest from source, installed eureka-core-1.1.74-SNAPSHOT.jar to my local maven repo, and re-ran my build and it's successful.\nnote:  in my pom configuration, i'm explicitly declaring servo-core-0.4.32.jar because i need StatsTimer (not available in 0.4.15, apparently).  \nmaven is doing the proper thing and pulling in this later 0.4.32 version versus the older, transitive 0.4.15 version declared in your latest eureka-core-1.1.74-SNAPSHOT.jar.\nhere's my pom snippet:\n<dependency>      \n        <groupId>com.netflix.servo</groupId>\n        <artifactId>servo-core</artifactId>\n        <version>0.4.32</version>\n    </dependency>\n    <dependency>      \n        <groupId>com.netflix.eureka</groupId>\n        <artifactId>eureka-core</artifactId>\n        <version>1.1.74-SNAPSHOT</version>\n    </dependency>\njust an fyi.  things look good and i'm unblocked.\n. right, so the use case is changing the default port that eureka runs on.\nunless i'm missing something, i need to modify tomcat's server.xml as well as one of the following:\n1) modify the tomcat startup scripts to pass -D's to override the defaultZone property that you highlighted (not that bad)\nor\n2) manually change the property files in the source, rebuild the war, and redeploy the war (bad).\nthe ideal state is to pass --port 8080 or equivalent and everything would just work - without having to modify tomcat or eureka configs.\ni'm likely missing something, however.\n-chris\n. understood.  yeah, this is primarily a development versus production request.\nfrom a dev perspective, it may be useful to have an EmbeddedEureka server used for end-to-end integration testing.\ni did something similar when building end-to-end tests for an implementation of Curator's Service Discovery feature.  Jordan exposes an embedded ZooKeeper TestingServer that proved very helpful in this situation.  it actually helped us identify a regression bug in Curator that was introduced when we picked up a newer version (https://github.com/Netflix/curator/issues/227)\nhere's the TestingServer code:  https://github.com/Netflix/curator/blob/master/curator-test/src/main/java/com/netflix/curator/test/TestingServer.java\nagain, not something that would be used in production, but definitely helpful for development/testing.\nthanks, karthik!\n-chris\n. Panos-\nmy https://github.com/cfregly/fluxcapacitor project has Eureka-Client/CloudWatch integration.\nI'm currently passing in the accessKey and secretKey as -D system properties at tomcat startup.\nthese get used by the DefaultAwsCredentialsChain class.\nhere is the code you'll want to review: https://github.com/cfregly/fluxcapacitor/blob/master/flux-core/src/main/java/com/fluxcapacitor/core/metrics/FluxMetrics.java\nthis code also demonstrates how to configure Graphite integration.\nalso, it's worth noting that if you use something like Karyon that contains an Admin tool to inspect your System properties at runtime, your AWS credentials will now be exposed.\nI'm about to issue a karyon pull request that will allow masking - and immutability - of certain properties such as these.\nlemme know if you have other issues.\nthanks!\n-Chris\nOn Jul 5, 2013, at 3:32 AM, Panos Partheniadis notifications@github.com wrote:\n\nHello,\nI can see the metrics exposed through Servo and JMX successfully. How do i integrate CloudWatch though? Where should i provide AWS credentials? Are these a standard accessKey and secretKey combination? For the server configuration, i can see the accessKey and secretKey configuration parameters. Are these used for CloudWatch integration? If this is the case, i do not see these parameters for the client configuration. Is CloudWatch available only to server?\n\u2014\nReply to this email directly or view it on GitHub.\n. @jfenner -  this might sound silly, but are you rebuilding the eureka-server webapp with the new properties being set?  \n\nalso, you might want to try setting those -D's in the actually eureka-server.properties file itself.\nhere's a link to my FluxCapacitor Netflix OSS FAQ that describes this issue:  https://github.com/cfregly/fluxcapacitor/wiki/NetflixOSS-FAQ#eureka-service-discovery-load-balancer\nThe eureka.registration.enabled=false should have taken care of the problem (it has for others), so i wonder if those -D's aren't being picked up for some reason.\ni just added karthik's recent suggestion of setting eureka.waitTimeInMsWhenSyncEmpty=0 to the FAQ as i hadn't heard of that before.\nlemme know if that helps.\n-chris\n. ",
    "cloudbees-pull-request-builder": "eureka-pull-requests #1 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #2 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #3 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #4 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #5 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #6 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #7 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #8 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #10 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #12 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #9 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #11 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #13 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #14 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #15 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #16 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #17 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #18 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #19 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #20 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #21 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #22 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #23 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #24 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #25 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #26 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #27 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #28 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #29 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #30 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #31 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #32 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #33 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #34 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #35 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #36 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #37 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #38 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #39 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #40 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #41 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #42 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #43 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #44 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #45 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #46 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #47 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #50 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #51 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #48 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #49 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #52 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #53 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #54 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #55 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #56 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #57 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #58 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #59 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #61 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #65 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #66 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #67 ABORTED\n. eureka-pull-requests #68 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #73 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #74 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #60 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #62 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #63 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #64 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #69 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #70 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #71 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #72 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #75 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #76 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #77 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #78 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #79 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #80 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #81 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #82 ABORTED\n. eureka-pull-requests #84 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #85 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #86 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #87 ABORTED\n. eureka-pull-requests #88 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #89 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #90 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #91 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #94 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #95 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #92 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #93 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #96 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #97 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #98 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #99 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #100 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #105 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #101 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #102 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #103 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #106 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #107 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #108 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #109 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #110 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #111 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #113 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #114 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #115 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #116 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #117 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #118 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #119 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #120 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #121 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #122 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #123 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #124 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #125 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #126 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #127 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #128 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #129 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #130 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #131 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #132 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #133 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #134 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #135 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #136 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #138 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #137 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #139 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #140 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #141 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #142 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #143 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #154 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #155 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #156 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #144 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #145 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #146 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #147 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #148 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #149 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #150 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #151 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #152 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #153 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #157 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #158 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #159 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #160 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #161 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #164 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #162 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #163 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #165 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #166 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #167 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #168 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #169 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #170 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #172 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #173 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #174 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #175 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #176 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #177 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #178 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #179 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #180 ABORTED\n. eureka-pull-requests #181 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #182 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #183 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #184 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #185 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #186 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #188 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #187 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #189 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #190 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #191 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #192 ABORTED\n. eureka-pull-requests #193 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #196 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #199 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #194 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #195 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #200 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #197 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #198 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #201 ABORTED\n. eureka-pull-requests #202 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #203 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #204 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #205 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #206 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #207 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #210 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #208 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #209 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #211 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #212 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #214 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #215 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #216 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #220 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #221 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #222 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #223 ABORTED\n. eureka-pull-requests #224 ABORTED\n. eureka-pull-requests #225 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #226 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #227 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #228 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #229 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #235 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #230 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #231 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #232 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #233 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #234 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #236 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #238 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #239 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #237 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #242 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #240 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #243 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #244 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #245 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #247 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #248 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #249 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #241 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #250 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #251 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #252 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #253 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #254 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #255 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #256 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #257 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #258 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #259 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #260 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #261 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #262 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #263 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #265 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #264 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #266 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #267 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #268 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #269 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #270 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #271 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #272 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #273 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #274 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #275 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #359 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #360 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #276 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #277 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #279 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #278 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #280 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #281 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #282 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #283 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #284 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #285 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #286 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #287 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #288 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #289 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #290 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #291 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #292 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #293 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #294 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #295 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #296 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #297 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #298 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #299 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #300 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #301 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #302 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #303 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #304 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #305 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #306 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #307 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #308 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #309 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #310 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #311 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #312 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #313 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #314 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #315 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #316 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #317 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #318 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #319 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #320 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #321 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #322 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #323 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #324 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #325 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #326 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #327 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #328 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #329 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #330 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #331 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #332 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #333 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #334 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #335 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #336 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #337 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #338 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #339 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #340 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #341 ABORTED\n. eureka-pull-requests #345 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #351 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #342 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #343 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #344 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #346 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #347 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #348 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #349 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #350 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #352 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #353 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #354 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #355 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #356 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #357 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #358 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #361 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #362 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #363 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #364 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #365 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #366 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #367 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #368 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #369 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #370 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #371 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #372 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #373 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #374 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #375 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #376 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #377 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #378 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #379 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #380 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #381 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #382 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #383 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #385 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #388 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #389 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #390 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #384 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #386 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #387 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #391 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #392 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #393 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #394 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #396 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #397 ABORTED\n. eureka-pull-requests #398 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #395 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #399 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #400 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #401 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #402 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #403 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #404 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #406 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #407 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #405 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #408 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #410 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #409 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #411 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #412 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #413 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #416 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #417 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #414 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #415 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #418 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #1 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #419 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #420 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #2 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #421 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #3 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #422 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #4 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #423 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #5 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #6 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #424 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #7 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #425 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #426 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #8 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #9 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #427 SUCCESS\nThis pull request looks good\n. eureka-pull-requests #428 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #10 FAILURE\nLooks like there's a problem with this pull request\n. eureka-pull-requests #429 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #11 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #12 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #18 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #13 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #14 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #15 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #19 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #22 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #23 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #24 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #16 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #17 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #25 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #26 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #27 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #28 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #29 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #30 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #31 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #32 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #33 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #34 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #35 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #36 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #37 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #38 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #39 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #40 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #41 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #42 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #44 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #45 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #46 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #43 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #47 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #48 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #49 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #50 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #51 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #53 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #52 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #54 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #55 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #57 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #58 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #59 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #60 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #61 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #62 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #63 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #64 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #65 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #66 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #67 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #68 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #69 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #70 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #71 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #72 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #73 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #74 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #75 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #76 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #77 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #78 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #90 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #92 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #98 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #100 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #79 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #85 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #80 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #81 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #82 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #83 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #84 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #86 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #91 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #87 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #88 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #89 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #93 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #94 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #103 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #95 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #96 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #97 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #99 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #101 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #104 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #102 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #105 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #106 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #107 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #108 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #109 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #110 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #111 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #112 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #113 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #114 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #122 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #115 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #116 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #119 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #118 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #120 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #121 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #123 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #124 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #125 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #126 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #127 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #128 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #129 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #131 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #141 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #142 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #146 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #147 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #130 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #132 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #133 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #134 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #137 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #138 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #139 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #140 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #143 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #144 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #145 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #148 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #149 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #150 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #151 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #152 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #153 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #154 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #155 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #156 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #157 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #158 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #159 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #161 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #162 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #220 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #221 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #163 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #164 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #165 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #169 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #170 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #174 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #177 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #166 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #167 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #168 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #171 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #172 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #173 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #175 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #176 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #178 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #186 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #191 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #192 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #179 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #180 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #184 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #181 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #182 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #185 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #187 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #188 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #189 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #190 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #193 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #194 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #195 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #196 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #197 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #198 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #199 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #200 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #201 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #202 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #203 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #204 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #205 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #206 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #207 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #208 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #209 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #210 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #211 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #212 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #214 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #213 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #215 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #216 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #218 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #217 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #219 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #222 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #224 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #223 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #227 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #225 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #226 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #228 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #229 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #230 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #231 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #232 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #233 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #234 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #235 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #236 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #237 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #238 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #239 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #241 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #260 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #240 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #242 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #246 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #248 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #249 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #258 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #259 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #268 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #243 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #244 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #247 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #250 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #251 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #252 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #253 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #254 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #255 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #256 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #257 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #261 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #262 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #263 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #264 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #265 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #266 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #288 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #267 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #269 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #271 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #274 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #296 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #310 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #325 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #327 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #333 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #270 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #272 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #273 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #275 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #276 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #277 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #278 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #279 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #284 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #285 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #286 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #280 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #281 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #287 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #283 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #289 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #290 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #291 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #292 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #293 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #294 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #298 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #299 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #300 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #301 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #303 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #307 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #295 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #297 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #304 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #364 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #365 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #302 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #305 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #306 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #324 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #326 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #308 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #309 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #311 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #312 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #313 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #314 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #315 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #316 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #317 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #318 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #319 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #322 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #320 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #321 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #323 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #328 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #329 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #330 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #331 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #335 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #336 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #337 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #338 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #332 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #334 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #339 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #348 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #356 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #410 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #411 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #418 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #419 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #340 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #341 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #342 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #343 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #344 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #345 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #346 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #347 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #349 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #350 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #351 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #352 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #353 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #354 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #355 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #357 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #358 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #359 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #360 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #361 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #362 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #363 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #366 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #367 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #369 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #368 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #370 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #371 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #372 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #373 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #374 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #375 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #376 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #377 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #378 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #379 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #380 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #381 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #382 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #383 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #384 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #385 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #386 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #387 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #388 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #389 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #390 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #391 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #392 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #393 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #394 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #396 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #397 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #395 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #398 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #399 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #400 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #401 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #402 ABORTED\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #405 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #406 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #407 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #408 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #409 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #412 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #413 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #414 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #416 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #420 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #422 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #415 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #417 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #421 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #429 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #423 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #424 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #425 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #426 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #427 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #428 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #430 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #431 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #432 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #433 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #434 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #435 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #436 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #439 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #437 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #438 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #440 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #441 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #442 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #443 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #444 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #445 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #446 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #447 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #448 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #449 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #451 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #452 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #450 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #460 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #454 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #455 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #456 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #457 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #458 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #459 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #461 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #462 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #466 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #467 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #476 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #477 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #464 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #465 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #472 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #475 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #468 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #469 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #470 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #471 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #473 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #474 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #478 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #479 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #480 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #481 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #482 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #483 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #485 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #484 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #486 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #487 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #488 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #489 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #490 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #491 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #492 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #493 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #494 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #495 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #496 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #497 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #498 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #499 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #500 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #501 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #502 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #503 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #504 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #505 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #506 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #507 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #508 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #509 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #510 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #511 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #512 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #513 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #514 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #515 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #516 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #517 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #518 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #519 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #520 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #521 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #522 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #523 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #524 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #525 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #526 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #527 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #528 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #529 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #530 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #532 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #533 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #534 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #535 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #536 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #537 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #538 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #539 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #540 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #542 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #541 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #543 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #544 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #545 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #546 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #547 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #548 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #550 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #549 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #551 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #552 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #553 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #554 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #555 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #556 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #557 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #558 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #559 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #561 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #563 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #564 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #565 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #566 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #562 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #567 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #568 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #569 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #570 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #571 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #572 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #573 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #574 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #575 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #576 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #577 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #582 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #583 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #578 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #579 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #580 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #581 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #584 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #585 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #586 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #590 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #587 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #588 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #589 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #592 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #591 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #593 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #594 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #595 SUCCESS\nThis pull request looks good\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #596 FAILURE\nLooks like there's a problem with this pull request\n. NetflixOSS \u00bb eureka \u00bb eureka-pull-requests #597 SUCCESS\nThis pull request looks good\n. ",
    "NiteshKant": "Canceling this pull request, will include few more changes and submit a new pull request.\n. The client surely does not assume that you are running inside a web\napplication. It just requires you to call discoverManager.initcomponents()\nwhich initializes the client. The client provided in the eureka project\ndemonstrates this behavior.\nEureka server requires an HTTP endpoint, the easiest way of doing that is\nto package it in a war & have your embedded servlet container.\nOn Thursday, February 6, 2014, viveklon notifications@github.com wrote:\n\nCan Eureka be used for a distributed (non web) JAVA application(s) to\nachieve same results? I am assuming yes, any example client/server known to\nanyone?\n\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/issues/16#issuecomment-34373742\n.\n. There were a few times there was a mismatch between what is available internally & what is available in maven.\nSince, then we have fixed the problem (manual release process) and now the artifacts should be available in both repos.\n. Curious whether you tried with the actual TXT record having a comma between\nentries as suggested by the wiki? If yes, does that work?\n\nOn Fri, Jun 14, 2013 at 4:34 AM, OskarKjellin notifications@github.comwrote:\n\nI ran into some issues when I tried to setup multiple zones with eureka.\nAccording to the wiki, the txt records should be separated with ','.\nHowever, it seems like the code is using the whitespace character?\nWiki page I am referring to:\nhttps://github.com/Netflix/eureka/wiki/Configuring-Eureka-in-AWS-Cloud\nBut on this line it splits using whitespace:\nhttps://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/discovery/DiscoveryClient.java#L1366\nThis would be fine if it was as simple as a code->wiki mismatch. But when\nthere is a whitespace within a txt record it returns it as \"eu-west1a\neu-west1b\", instead of with comma as eu-west1a,eu-west1b (hard to\nillustrate but in the first case it returns a string containing actual\nquotation marks). So when it splits it winds up with:\n- \"eu-west1a\n- eu-west1b\"\nWhich of course causes problems.\nAm I the only one who ran into this issue? Like the way that the\nTXT-records and automatic assigning of EIPs but it's very fragile to have\nonly one eureka server.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/issues/22\n.\n. I merged this pull request: https://github.com/Netflix/eureka/pull/85 recently. Does that suffice? @danielkwinsor unfortunately we have not been able to merge this request before. In the light of the other code change (https://github.com/Netflix/eureka/pull/85), if you think this is required, can you sync this pull request to the master?\n. @CH3CHO if your DatacenterInfo Object implements UniqueIdentifier interface, the id for the instance will be assigned the id returned via getId()\n. Closing this pull request as it is not required anymore. @CH3CHO let me know if you think otherwise.\n. Made changes based on your comments.\n. @bpollack I personally like the option 2. so that there is less configuration to set.\nIn fact we should be able to support starting the servers with no eureka peers configured. This would automatically remove all these issues. Thoughts?\n. Sounds like a good feature request, do you wish to contribute?\n. Awesome, thanks!\n\nnitesh\nOn Aug 22, 2013, at 3:19 PM, Melvin Cardozo notifications@github.com wrote:\n\nSure. I'll work on getting the changes done.\n\u2014\nReply to this email directly or view it on GitHub.\n. Thanks @mampcs \n. @grze Apologies that we have not been able to merge this change till now. If this is required can you sync the code with the master for this request?\n. Closing this PR as it can not be merged and there doesn't seem to be any activity.\n. Looks good to me\n. Does this also solves the race condition when two instances try to take the same EIP concurrently? I guess not.\n. I haven't yet seen the entire code, but have a question: How do we assert whether a peer node supports batched requests? \n. LGTM\n. Ribbon provides a MonitoredConnectionManager that can be used instead of the currently used ThreadSafeClientConnManager. It provides similar metrics to what we are looking for here.\n. Eureka supports a comma separated VIP list for an instance but the port/secure port can just be one. Which makes the usage of multiple VIPs limited.\nSo, one should be able to register a list of \"endpoints\" which translates to a set of properties like VIP address, port, SSL config (client auth, etc.). This would result in a substantial change in the way we register (via properties as making them hierarchical is non-intutive) with eureka & the REST payload.\n. Since, there isn't much handle that eureka code has in the internals of jersey & connection management for such errors, the only suitable place seems to be the DiscoveryJerseyProvider where in we can close the underlying response stream when such an error occurs.\n. Thanks!\n. @bpollack agreed, closed.\n. Partial fix is available in release 1.1.128 as part of fix for issue #97 \n. Thanks Ryan for the contribution!\n\nSince, you are only using UniqueIdentifier for DataCenterInfo & there isn't any general purpose use of the interface, do you think it is simple to just add the method getInstanceId() in DataCenterInfo interface itself?\n. That makes sense, I will merge the pull request.\nOn Monday, February 17, 2014, Ryan Thomas notifications@github.com wrote:\n\nThe reason I chose to have a new interface was to not introduce a breaking\nchange for existing implementations of DataCenterInfo.\nIf that is acceptable however, I am happy to move it across.\nCheers,\nryan\n\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/pull/85#issuecomment-35321350\n.\n. Yes the failure is not related to your code, it is a flaky test.\n. Thanks @CH3CHO for the contribution\n. @bpollack its just a read-only status page. Sure, I can assign this issue to to you then?\n. Fixed in eureka-1.1.128\n. > > > Looks like there's a problem with this pull request\n\nSince, the same test failed twice, which does not happen in other pull requests. I suspect that there is a change in this PR that is causing the failure. @elandau can you verify?\n. Thanks @bpollack !\n. @bpollack I agree that the other option would be cleaner. Although, you will have to make that change in all the tests using the mock server.\nInstead, how about creating a factory method in mock eureka server like: MockRemoteEurekaServer.createWithRandomPortIfAlreadyBound(int port ... ) which retries on random ports (derived from the passed port) for X times before giving up. The chosen port can then be retrieved from the returned instance.\nWe can then replace all new MockRemoteEurekaServer() with this factory calls in all tests.\nThanks again for the contribution!\n. @bpollack Sounds awesome!\n. Thanks @elandau for the ephemeral port tip. I had to fix a critical bug in the client and did not have time to completely review your request. So, I just plucked the ephemeral port changes from your commit. Can you resubmit your PR after I merge #100 \nApologies for the inconvenience & thanks again for the tip!\n@bpollack Can I close this PR as the ephemeral port fix is better?\n. @aspyker it indeed is a bug. There should be a break after line 136. I will fix this.\n. Available in release 1.1.128\n. Available in release 1.1.128\n. Available in release 1.1.128\n. Thanks @jhohertz !\n. Thanks @bpollack !\n. @bpollack time sensitive tests sometime fail in cloudbees builds and we are working towards fixing flaky tests like these. There isn't any issue with this PR, I will merge it soon.\n. Thanks @bpollack!\n. @pgkelley4 \n\n\n\nNote that this will still break with config files that specify either eurekaServer.readTimeout or eurekaServer.connectTimeout as milliseconds, not seconds.\n\n\n\nYes that is reasonable as we are atleast being truthful to what the property name is :)\n. If we produce compiled code that can run on java 6 its fine.\nInside Netflix we have not yet moved completely to java 7 & hence if we require java 7 for eureka (specifically the client), it will not be possible to use it inside netflix.\n. @bpollack I have reviewed these changes and they seem fine to me. If you can sync this with the master, i will merge it.\n. Yeah thats just the way things have been. Eureka Client defaults the namespace to \"eureka.\" and hence properties are more legible. \nFeel free to submit a patch if the changes are backward compatible.\n. Thanks @bpollack !\n. #116 achieves the same goal but with an upper bound on the current major version.\n. Thanks @bpollack !\n. Available in 1.1.131\n. @bpollack I am not merging this PR assuming you are working on the comment I provided. Let me know if you think otherwise.\n. > > >  having a mode that starts without peers would be beneficial outside of this use case, if you are still thinking this makes sense I can fix up this PR.\nYes, certainly. I think it makes sense. \n. Thanks @pgkelley4 for working on this.\n\n\n\n1) The proposal was to check if peerEurekaNodes was empty before syncUp. However, on my box when run locally, peerEurekaNodes is not empty becuase my local computer makes it into the list. This is because the PeerAwareInstanceRegistry.isThisMe method doesn't work in this circumstance.\nMy computers hostname is username.local, and the default files shipped with Eureka specify localhost as the default serviceUrl for testing locally. So the hostname comparison is never equal. (It works in AWS because the hostname is actually retrieved from ec2 metadata)\n\n\n\nIs it possible to fix PeerAwareInstanceRegistry.isThisMe() then? One possible solution could be to change the default service URL in the eureka properties to have 127.0.0.1 instead of localhost and then use InetAddress.getLocalHost().getHostAddress() and see if the URL host is same as the localhost. This of course will be on top of the existing pure host string based matching.\n. Available in 1.1.131\n. Thanks @pgkelley4 !\n. The failure is a flaky test, merging this now.\n. Thanks @elandau!\n. Thanks @tommack!\n. @pgkelley4 apologies for the late reply.\n\n\n\nThere could be other code paths I have missed where AppsHashCode isn't getting set correctly. It is currently inconsistent where it is set. In InstanceRegistry it is set in getApplicationsFromMultipleRegions but there isn't an analogous place in DiscoveryClient. This should probably be rethought, I think it made it easy to miss this bug.\n\n\n\nIn the DiscoveryClient, the app hash code used to always come from the server (in the response) but looks like after the remote region change, this hash code was not getting updated to reflect the  remote instances.\nThe app hashcode is used only when applying delta, where it seems to be checking correctly. Which bug are you referring to?\n\n\n\nWhy is AbstractDiscoveryClientTester.CLIENT_REFRESH_RATE = 10? Can we lower it to speed up the tests?\n\n\n\nSure it can be.\n\n\n\nThis code reconcileHashCode.equals(delta.getAppsHashCode()) In fetchRegistry will not return false and log differences if one app goes from UP to DOWN and another from DOWN to UP. Is this not a concern?\n\n\n\nYes thats a valid point and we have thought about it before. You are correct that this scenario can occur and will incorrectly indicate that the registry contents are identical.\nHowever, the point to note is that the hashcode comes into picture only when it does not match (after applying the delta on the client). So, if the delta calculation at the server is correct, then the client would get the same registry information after applying the delta even though the hashcode did not change between the two calls (before and after this delta).\nIn other words, since the delta application is not conditional (based on the hashcode) the fact that the hashcode is not completely indicative of the registry content is not really an issue.\n. The changes look good to me. Should I merge it or you have some more changes to make?\n. @pgkelley4 sure if you have thoughts on how to fix it, feel free to issue a PR or open an issue to discuss.\n. Thanks @jhohertz for reporting this. I am also deploying this build inside Netflix and will look into this.\nIn the meanwhile, can you provide the logs from your server which is showing this behavior?\n. No problems at all @jhohertz. Sure reopen this if you see this again.\n. Property .registryRefreshSingleVipAddress can be used to specify a single VIP address that will be fetched by the client instead of the complete registry.\n. Pull request #150 achieves this without a property knob, which seems unnecessary, as discussed in previous comments.\nI am closing this PR, the other PR will be released as part of milestone 1.1.137\n. Thanks @jboulon! I have provided my comments on #134 \n. The fix is done in #150 instead.\n. Thanks @aspyker \n. @elandau LGTM, merge?\n. Fixed with pull request #153 \n. Thanks @ericdowd !\n. @qiangdavidliu please rebase + submit, will merge.\n. PR #158 fixes this issue. \n\n\n\nShould we only disallow fetch registry calls that requires remote region data in this scenario?\n\n\n\nThis change disallows remote registry fetch calls when remote region registry is not available. The local region registry fetch is allowed.\n. Thanks @jeffw-wherethebitsroam \n. @christorpelund can you explain the usecase you are solving with this change?\n. @christorpelund that makes sense.\n. \\cc @tbak @qiangdavidliu \n. @tbak This change is included in the other PR #188, so I can close this one?\n. @pgkelley4 we certainly are open to accepting any enhancement to eureka which adds value :)\nThe changes look good and will be useful for us internally too. Thanks!\n. > > > Using this new method the health check is only consulted if ApplicationInfoManager.getInstanceStatus() is UP.\nThis means a HealthCheckHandler can not transition health status from STARTING -> UP?\n. The change looks good to me.\n. What was the motivation of removing this interface?\n. I think it will be useful to provide code samples on how a client will consume this API. There are a lot of complex constructs as conditional batching and non-batching modes. I would like to see how this manifests on the consumer end. \nA few implementation related questions:\n- How are these batching hints stored? It looks to me from your description of the various scenarios of multiple subscribers to the same interest, that the hints are generated at subscription time. I would have thought that the hints will be stored along with the data & hence will be delivered to multiple subscribers as is.\n- Is there an attempt to be precise about the hints? I get a feeling of this when you talk about hint merging i.e. an intent not to send multiple hints and de-dup them. If it is so, then what value will it add being precise?\n- What is the behavior in case of server failure between sending a \"Batch\" hint and \"Finished batching\" hint? What if there is no server available and we have already sent a \"Batch\" hint.\nI am not really convinced about the need of \"Batch\" hint, however, I can see what you are trying to achieve i.e. the ability for the same client to switch between batching & non-batching mode. This is something will be cleared to see in a code example whether the complexity is worth. \n@qiangdavidliu \n\nthe consumer should be able to apply a collection operator to the stream that emits a new List each time it sees a finishBuffer hint, and possibly timeout otherwise.\n\nI think there is value in having an API where batch or non-batch is not a choice that the client is to make. In this model, the client will always batch & non-batch interaction will be timeout based. \n. I would prefer the support for DELETE overridden status for the following reason:\nThe merge algorithm addresses the \"most common\" usecase for today (for Netflix). I can think of corner cases when someone wants to override DOWN status from the instance with UP, may be in the case the healthcheck has an issue or it is flapping. \nThere is value in being consistent with the definition of \"overridden status\" that it always overrides the status with no special cases. If the override does not apply anymore, then it should be deleted.\n. @qiangdavidliu the changes look good to me. I do have a few questions:\n\nThe SelfRegistrationService and SelfInfoResolver currently used by the servers should be generalised for client use, so that we can componentize the creation of different parts of an InstanceInfo\n\nDoes this mean that a client will have a to use a helper class for registration?\nI am not convinced that we should go that route. If InstanceInfo is complex to create, we should provide ways in InstanceInfo to make it easier to use, as opposed to having a separate class that does so. The reason being intuitiveness of the API if a user has to look at a bunch of classes to do registration.\nSince, we are on the topic of Client API changes, do you intend to create another issue for creating complex Interest sets. eg: How does one create a cumulative interest for a VIP + an app + secure VIP (of course this is hypothetical)?\nI remember us briefly discussing the need of a DSL for that, somewhat like:\njava\nclient.forInterest(Interests.forVip(\"vip1\"))\n        .andApplication(\"app1\").orInstance(\"I1\")\nThe above DSL is capturing a modifiable interest set which can be subscribed at any branching point.\n. > > For example channel might be in { Idle, Connected, Closed } states. These states must be mapped to Eureka InstanceInfo.State.\nIs there a value in having these as two different Status? IOW, why not have the components return InstanceInfo.State?\n\n\nSubsystemDescriptor JavaBean provides static, supplementary information primary for UIs\n\n\nI think we are conflating the health status with this granular information. \nBigger question: \"Can the subsystem status better be exposed via metrics and have the system health as a status, potentially aggregated over multiple sources?\"\n\n\nClients wishing to receive live updates about Eureka health status can connect to WebSocket endpoint\n\n\nIn absence of subsystem statuses, Is this just the forInterest endpoint otherwise available for any interest in eureka?\n. > It is possible to override any InstanceInfo attribute, however this feature is provided primarily for status override.\nSince, we know that it is useful only for status overrides, is there any value in making it generic for any override? Do we see this applying to any other attribute in the future?\n\nThe override data will be kept in separate registry\n\nDoes this mean, we will always be merging multiple notifications from multiple Observable sources? Is the override an optional feature or it is always available with the server? \nIf it is always available, why would we want to put it in a different registry and incur the merge overhead?\n\nIf no version is provided by client, we would fallback to previously described behavior.\n\nIt looks like we know that the operation with no version is bound to have inconsistent data. So, should we disallow operations without versions?\nIt seems we are missing a case of disaster recovery, where all eureka nodes go down and all override statuses are wiped out. Contrary to the usual case, where the data is regenerated, this data will never be regenerated. Eureka 1.x handles this case by querying the AWS API to see if the owning ASG (or may be instance) is enabled or not. I think we should do that too, WDYT?\nHaving said the above, do you think the source of truth (AWS status) can be used for conflict resolution?\n. What will be the downside of only considering option 3:\n\nWhen full cluster is restarted, or there is other reason why a new server cannot bootstrap itself from a peer, it should load last known registry content from an external source/backup storage. Multiple backup storages may be implemented here.\n\nas a \"bootstrap\" scenario and any other scenario as a usual replication scenario? In other words, what is the usecase of getting the entire registry contents from a source (peer or backup) when other peers are available in the cluster?\nAFAIU, the entire registry would be required to assert if it is safe to serve registry contents to clients or not. That assertion will be based on the number of instances in a peer's registry. If this is the only reason for the bootstrap, I propose the following:\n- Modify replication protocol to also send; \n  - total instances in the peer registry\n  - Number of peers\n- Modify replication change notification stream to include a marker when the local registry (owned by that node) is streamed completely.\nFor a node starting up, it should do the following:\n1. Attempt to connect to all peers.\n2. Get the number of peers and registry information from all peers.\n3. If all other peers are reachable then connect to all of them and wait till all of them have streamed all their local registry content.\n4. If any of the peer is unreachable or not ready to serve traffic, connect to the backup store to fetch the last known registry information.\nA node would start serving registry information to clients, if it has received the registry contents. We may also choose to have some heuristics around how much of the registry information we should wait for in case nodes are not able to stream all their data before disconnect.\nThe positive of this approach is that you would not get into the hierarchy of bootstrap sources and would also eliminate the need of full registry fetch from a peer in spite of all peers being available.\n\n\nInstead this information has to be provided somehow when connecting to the server. A few options may be envisaged here\n\n\nI did not quiet understand the difference between the options here. All the options look like sending a message \"Not available for registry fetch\" and closing the connection. Since, the protocol is framed, so you would have to send the message as a different frame, isn't?\n. > > The current replication channel connections are very similar to the interest channels, with the exception that interest channels are client initiated and replication channels are server initiated.\nAre you referring to the similarity as the data that flows on the channel or how the Channel is implemented on client and server? \nSemantics of storage, heartbeats and expiries are very different for a replication channel, isn't?\n. May be it will be better to see the implementation to better understand your thoughts. So, let me hold on till then :)\n. Could an alternate be to initialize multiple interest client instances and merge the interest stream if/when required? I do not quiet understand the need of adding this to the client & interest DSL when it can easily be solved by having a client per server group.\n. @tbak I am just questioning the change in the client via introduction of data sources. \nMultiple server groups inside the same client does not sound the correct abstraction to me. I see the following usecases:\n- Read server configured to read from multiple regions: This is a server level configuration and the decision to use which client should be split at the time of query for an interest, choosing an appropriate client for the query. This does not require introducing the data source concept at the client level.\n- Users querying for cross-region data. This should be an attribute of the interest and should not need any configuration on the client. I do not think \"datasource\" is the correct terminology for this. We should be explicit that it is a cross-region query, something like Interests.forVip(\"vip\").inRegion(\"us-east-1\"). In this case it will be an out-of-band understanding for the user that whether the application is running in an environment which supports cross-region queries. If not, the interest should error out.\nI can see from where the proposal is coming i.e. to generalize the implementation in the server to be available for all clients but I think the usage is pretty different for an end user vis-a-vis a eureka server.\n. This is interesting! \nWould there be a reason why someone will need to register and not send heartbeats or not update instance info periodically?\nIOW, should the change more be for controlling registrations (and possibly registry fetch) explicitly instead of getting registered in the constructor but deferring heartbeats & instance info refresh?\n. > >  A change to externalize the scheduling of any of the events (registry refresh, heartbeat, and instance info dirty check/update) isn't the intent of this patch.\nMy point here is, if we do externalize registration out of the constructor, we do not need these additional knobs and that also provides a intuitive API. This is the model eureka 2.x follows i.e. registration is not baked into the constructor and is driven by the users. \n\n\nOne point of interest is whether we should separate registration/update and heartbeat scheduler initializations from each other\n\n\nIMO, we shouldn't separate them (what I was saying in my earlier comment) as heartbeat & instance info updates are required for registration and without them, registrations do not work as expected. \n. > > > I would like this to be interpreted as the service is DOWN.\nLeaving aside Eureka internals, how would you use this DOWN status differently than the instance not being available in Eureka registry?\n. > > > I have already implemented my own poller mechanism which is setting the status to down when there are no heartbeats.\nSo, all servers that do not send an explicit remove, will stay in eureka registry forever?\n. You can possibly use Math.abs() for this.\n. Not sure if I understand this. Shouldn't it be != null &&!isempty()\n. Did you mean if(!isSuccess(...)) ?\n. Any reason why we need the list to be homogeneous w.r.t action? Can we have mixed actions in the list?\n. May be we should put this inside the if block to avoid creating garbage\n. I think modeling failure due to batching not supported on server, as an exception will be more cleaner for people reading code.\n. Move inside the if statement to avoid garbage creation.\n. I would add a check here for empty string & also check if the namespace ends with a \".\" to avoid exception if someone changes the namespace.\n. Here is the reasoning for adding this check:\nThe code which creates this constant namespace + \"metadata.\" and the code that assumes that this constant ends with a \".\" are in different places & anyone changing the constant will have no idea about this assumption. There can possibly be two solutions to this: have a test case to make sure this assumption is not broken OR don't make this assumption. I went for the latter, if you think the former is better than I don't have any issues but certainly making the assumption of the constant value did not seem correct to me.\n. Why does this need to pass an instance of the client? The callback registers with an instance of the client via client.register...(), so if at all it requires the client later (when we move to injected client), it can store the client instance as an instance variable.\n. Can we use nflx-commons eventbus here rather than providing another way to register callbacks?\n. :)\n. Should we be doing this only on success?\n. If we move the call to this method away from finally, may be we can catch Exception instead of Throwable. I think we should atleast log it.\n. Possibly a syntactic sugar. Since, this is a public interface, I was keen on keeping the interface precise and clean. Passing DiscoveryClient itself sounded a little awkward as it is a singleton accessed via DiscoveryManager. \n. Can you explain partial failure? Do you mean registry fetch passed but something else failed OR part of the registry was fetched?\nSince the refresh callback is invoked when a registry is fetched, I guess invoking the callback on success makes more sense. \n. sorry for being abstract.\nWhat I meant was that we should catch \"Exception\" instead of \"Throwable\"\nSince, this method is invoked from within a finally block, throwing an Error (when not catching Throwable) would swallow the earlier caught Throwable (if any) and hence if we move the callbacks out of the finally block (in the caller method), catching \"Exception\" will suffice\n. Genuine concerns and good points.\nI would not be concerned with publishing too many events to the eventbus, since, the purpose of the eventbus is to be the backbone of all the events exchanged in the system. Having multiple eventbus instances complicates the usage pattern as the user has to make a decision of which instance to publish/subscribe to.\nI guess we should be enriching Pundit to ignore events based on pkg name, frequency, etc. but that probably should not govern what we publish to the eventbus.\n. Although I agree with your comment in isolation, that what you suggested is a better way, but if you look at the code, this function is inside the Builder and the \"result\" instance it is updating is essentially \"hidden\" till build is called. So, unless the builder is concurrently updated, this should not be an issue. makes sense?\n. I agree with all you are saying, I have updated the PR.\n. eureka-lifecycle need to be removed.\n. Is this required? I guess it creates race-conditions for any code using the config during shutdown.\n. Is this required? I guess it creates race-conditions for any code using the config during shutdown.\n. Shouldn't we do this at the end of the constructor? Avoiding escaping of \"this\" or exposing unfinished object.\n. I think we should not do this. Instead if we are paranoid about people not using this after shutdown(), we can add checks of isShutdown() but I think its not required.\n. @PostConstruct would not be called concurrently, rite? Do we need the current status as AtomicRef?\n. I think its better to keep this property name same and convert it into seconds.\n. An illegal name would throw an IllegalArgumentException here which would break the de-serialization.\nCan we catch IllegalArgumentException (illegal name) and default to Name.MyOwn just to be more tolerable to name issues? \n. Sure I understand your point of view.\n. Isn't this the same as registeredInstances > 0?\n. Never mind. This is different if register() failed.\n. I think instead of deducing this from \"no instance found\", we should deduce it from whether there are peers or not.\nWhether there are peers or not, can be asserted using \"peerEurekaNodes\" instance variable.\nSo, if there are no peers, just bail out, don't even get to the sync up loop.\nNow, in order to do this, we have to allow starting up with no discovery servers configured In discovery client).\nWhat do you think?\n. > > > What's the best thing to do if we go to this mode by having no discovery servers? Just accept that Eureka won't self-register?\nIts a good question. In order to understand the implications, let us understand it both from the client and server perspective.\nClient\nIf there are no servers available then this means two things:\n- It is a misconfiguration and hence this situation should result in a fast failure (abort app startup)\n- It is a valid scenario (primarily when this client is inside a eureka server) and the client is not required to be initialized. Ideally we should be able to turn off client initialization OR have a NoOpClient which does not do any registry lookups.\nConsidering the current design, it is non-trivial to not initialize the client. So, I would go with accepting that its just valid to have no eureka servers configured. We should add a property which forces fast fail in such scenarios. For the sample application we can set this property to false but the client defaults it to true.\nServer\nIn this case, the server list serves two purposes:\n- Identify peers: In this case, no peer list, means no replication.\n- Identify itself to register itself: Ideally I would like eureka server to register with itself by making an in memory call rather than over HTTP. However, it requires more work with little benefits. So, I think its ok to just ignore it. The property based fast-fail in client described above will act as a safety net here.\n. Instead of providing this blanket property for all DataCenters, I would rather have this be specific to a DataCenterInfo and AmazonInfo specific logic in PeerAwareInstanceRegistry move to AmazonInfo. \nNow, since DataCenterInfo is public we would have to either provide a new interface for this specific behavior (not ideal) or have a new DataCenterInfo interface, extending the existing interface and add this functionality. In PeerAwareInstanceRegistry we check if the DataCenterInfo implements this new interface, if yes, delegate else return false.\n. Apologies for the delayed response. \nI understand your point & I think returning true by default (if not AmazonInfo) is the correct behavior & we should not guard it with this configuration. However, for AmazonInfo, we should keep the current behavior i.e. default to false if other conditions are not met.\nIf you are not in a hurry to have this patch, I would recommend going with the other interface design and have a single PR for both.\n. Making it a final will be good.\n. I understand that this will work but it will be intuitive to follow the model of incrementAndGet() instead of get()\n. Can you explain the need of this synchronized block?\n. Am I correct in saying that with these arguments the passed SynchronousQueue will never accept an offer()?\nThreadPoolExecutor will only offer the task to the queue if there are no \"idle threads\" and the SynchronousQueue will never accept an offer if there are no \"idle threads\".\nIs this the intent of using a SynchronousQueue? If yes, I guess using a zero size queue will also work?\n. Sure I can merge it, but i would not want to guard this with a property i.e. just return true instead of EUREKA_SERVER_CONFIG.shouldAcceptAllDataCenterRegistrations()\n. > > > it gives you the ability to have the same behavior as we used to have.\nWasn't this behavior a bug which we have fixed?\n. I think EurekaClientIdentity may be a better name. We aren't doing any auth correct?\n. Is there a reason why we would want to disable sending these headers? In other words, does this need to be configurable?\n. Does this have to be configurable?\n. Can we use the same class for both client & server?\n. May be good to default to \"unknown\" in case IP could not be resolved.\n. Sounds good to me.\n. I don't think we should be so pessimistic about this change. If there are problems we find it in our testing and fix it. I certainly don't like the idea of guarding such changes with properties.\n. I thought about it but that will break people who have a HealthCheckHandler implementation, rite?\n. Good point. Although we can't return UP always as it will break people who depend on STARTING -> UP transition after app initialization.\nI will remove this check and add an appropriate handler.\n. do you want to include the isDebugEnabled() check as before?\n. Since you are creating a string array anyways, the benefits of guarding it with the isDebugEnabled check are minimal. You can either just do logger.debug() or have the if check inline.\n. In DescribeAddressesResult are public IP & allocation ID mutually exclusive i.e. only one will be set at any time?\nI am trying to see if this, in any case breaks ec2-classic since we are only setting publicIp if allocation Id is null.\n. > > > Also if you would prefer, in DescribeAddressesResult there is a method getDomain() which returns the string standard for ec2-classic and vpc for VPCs\nThis actually will be much explicit and I think we should use it.\n. Having a String key - Object value pair is too loose an abstraction and forces to do the isSupported() kind of validations you are doing.\nCan we follow netty's ChannelOption abstraction?\nWhich means we have Keys that forces the value to be of a certain type. To elaborate:\n``` java\npublic class InstanceInfoField {\nprotected InstanceInfoField() {\n}\n\npublic static final InstanceInfoField<String> ID = new InstanceInfoField<String>();\npublic static final InstanceInfoField<String> APPLICATION = new InstanceInfoField<String>();\npublic static final InstanceInfoField<String> APPLICATION_GROUP = new InstanceInfoField<String>();\n\n}\npublic class Delta {\n// Immutable object.\n\nstatic class Builder {\n\n    <T> Builder withField(InstanceInfoField<T> field, T value) {\n        // add field\n        return this;\n    }\n\n    Delta build() {\n        return new Delta();\n    }\n}\n\n}\n```\nThis has two benefits:\n- Forces types.\n- Limits what fields can be added/updated.\n. This is a diff() method, correct?\nIf yes, then an Iterable may be much easier/optimal to use than an Observable. \n. This isn't pretty. If we follow the above suggested model, we will be able to avoid reflection\n. Don't we want InstanceInfo to be immutable?\n. Do we need to use reflection here? This means that:\n- Instance Info is mutable.\n- It is not intuitive for people to know how Instance Info is mutable.\nAn alternative way could be to have pass the InstanceInfo.Builder in this method which has methods like withXXX() that can be used. eg: for ApplicationGroup this method will call builder.withApplicationGroup(value)\nSo, the final abstraction would be:\n``` java\npublic class InstanceInfoField {\npublic static final InstanceInfoField<String> APPLICATION = new InstanceInfoField<String>(new Updater<String>() {\n    @Override\n    public void update(InstanceInfo.Builder builder, String value) {\n        builder.withApp(value);\n    }\n});\n\npublic static final InstanceInfoField<String> APPLICATION_GROUP = new InstanceInfoField<String>(new Updater<String>() {\n    @Override\n    public void update(InstanceInfo.Builder builder, String value) {\n        builder.withAppGroup(value);\n    }\n});\n\nprivate final Updater<T> updater;\n\npublic InstanceInfoField(Updater<T> updater) {\n    this.updater = updater;\n}\n\npublic InstanceInfo.Builder update(InstanceInfo.Builder builder, T value) {\n    updater.update(builder, value);\n    return builder;\n}\n\nprivate interface Updater<T> {\n\n    void update(InstanceInfo.Builder builder, T value);\n}\n\n}\n``\n. Since we are not really applying this delta on the passedInstanceInfo, should we be clearer of the intent in the name? Lets say callcopyFrom(InstanceInfo instanceInfo)? In which case, the better place for this method may be inInstanceInfogiving theDelta. Item sounds too abstract. Do you want to look at the existingModifyNotification` ?\nThe positive is that we do not have to get into the generic type to understand what is the type of the data.\n. +1 I did not remove it as I wasn't sure whether thats what you intend it to be.\n. This makes it possible to concat the returned Observable since write is eager.\nThis is used in ClientConnectionImpl to sequence delta sends but in general this enables to sequence writes on the channel based on the completion of a previous Observable.\nIf we write eagerly and concat, then the above can not be achieved.\n. I was thinking over it and if we do transparent reconnects on the transport level, the callers will loose insight into this reconnection. For a loosely consistent system like eureka, we would need callers to know about reconnect to a different server. eg: the client when moving from one server to another would need some insights into handling conflicts when moving to a different server.\nSo, it will possibly be better to let the users of the ServiceChannel re-create a new channel on error and handle the semantics by themselves. A new channel creation will take into consideration the current state of the system (servers available/loaded) and create an appropriate connection. We should be using ribbon for this.\nIf we follow this model, the client ServiceChannel chooses a server at start (before doing any operations) and when the callers subscribe to it and there is a disconnect the error is propagated to the input of the ServiceChannel. This will make the caller create a new ServiceChannel and start over.\n. Please see my comment below about failover handling on the client.\n. I haven't thought completely over the request-response style communication but from the client end we do not need it as we will always use full duplex communication, rite?\n. I agree with @tbak about making sure these two clients are always privileged irrespective of what the config says. \n. Since this is an IndexRegistry, shouldn't it return an Index?\n. Can we eliminate the registry dependency here?\nInstead can we just say compose(Index<T> current, Index<T>... newIndices); or better still if we provide a method in Index itself to compose/upgrade which underneath may be uses this method.\n. Will the EurekaRegistry ever store anything else apart from InstanceInfo?\n. Isn't this a tight CPU loop polling the queue?\n. Yeah typo ... I meant \"register arrives after update\"\n. > > > Our protocol semantic does not require waiting for ack\nBut we do overwrite interest set on every upgrade, so it is required that we do not interleave two upgrades. Consider this scenario:\ntime t1 -> Register Interest Vip1\ntime t2 -> Upgrade Interest Vip1 + Vip2\ntime t3 -> Upgrade Interest Vip1\ntime t4 -> Upgrade Interest Vip1 + Vip3\nIf we do not sequence send on these upgrades (which is what this code is trying to do), InterestChannel.upgrade() can be interleaved and hence time t3 operation may happen after time t4 operation thus overriding the interest set. \nIn essence we need to make sure that write on the connection is sequenced as opposed to an async send which the InterestChannel does. Once we enqueue write in the correct order, netty + tcp makes sure that the order is maintained.\n. Yes the constructor should flatten the interest a priori rather than doing it in flatten(), will make the change.\n. We should flatten the interests in the constructor (as commented by @tbak). I will make the change.\n. Yes this change does not add remove calls, which should be done when all subscribers are unsubscribed from the index.\n. There is a new module eureka-server which is added and read/write server modules depend on it. Any abstraction common to all servers go in this module and common to client & server goes into eureka-core.\nWith the current module structure, the eureka-server was dependent on eureka-client which sounds awkward.\n. > > > The channel returns the actual stream from the transport, whereas we want to return here the stream from the underlying actual registry. \nGood catch. Thanks, will change.\n\n\n\nWe should ignoreAllElements for this stream \n\n\n\nswitchMap is a more appropriate operation as concat waits for the previous stream to finish.\n\n\n\nwe should change the InterestChannel interface of register to return Observable to denote just the success/failure of creating the initial channel.\n\n\n\nYes, I agree. We should merge register and upgrade into just upgrade which makes the contract much simpler.\n. Why not just pass the client config to the EurekaJerseyClient?\n. Isn't this register call coming from the eventloop & this blocking call is blocking the eventloop?\n. You can instead just use Observable.retry() and doOnError() to reset state on error.\n. This means on reconnect you will write the same messages again on the same websocket connection.\nYou must send a reset message to the client if you want transparent retries. OTOH, you can propogate the error to the dashboard which then can retry. In this setup, it will be very convoluted for you to manage state on the connection once there is an error in the stream from eureka client.\n. Every subscription (triggered by retry in this case) re-runs the source. So when you retry, eureka client should give you the latest stream, which may be from a different read server or not, this code should not be concerned about that, it should only be concerned about the stream of the specified interest. \n. Isn't this just a map function? Why does it have to be implemented as a different operator?\n. Why would this never happen?\n. You mean for the implementations of this class that exist today?\n. Any reason why you are not using String.intern() simply?\n. What is the reasoning for this length limitation?\n. Is concating the two streams what we need here instead of merge?\nI understand that this pauses the emission of the realtime stream but the use of merge is counter-intuitive. \nAlso, is the notification subject Backpressure aware?\n. I see. Since, NotificationSubject was written before backpressure in RxJava, it may be a good time now to have a second look at it.\nI can see this being implemented as an operator that does not request upstream till the init state finish, which naturally buffers in the subject.\n. Are there redirects from the server that we need to ignore?\n. Isn't the below code checking for redirects? Shouldn't this check be checking for code b/w 300-400 ?\n. Handle errors on listener invocation?\n. Are you trying to achieve scheduling with fixed delay with this schedule-at-the-end-of-a-run construct?\n. May be having the last onDemand run time stored and shared between onDemand & scheduled tasks, can remove this schedule-cancel-schedule song & dance :)\nIn that case, the scheduled task can just complete, if the onDemand update has run within X amount of time.\n. ",
    "qiangdavidliu": "Closing old issue. Please re-open if the issue is still not resolved.\n. This is possible by implementing a DataCenterInfo that also implement UniqueIdentifier.\n. Closing due to inactivity. \n. Closing due to inactivity.\n. Closing due to inactivity.\n. Closing due to inactivity.\n. Issue #554 have been addressed, so it is now possible to create multiple instances of DiscoveryClient (with their own configs) and achieve multiple registration from the same process. Note that to do this the server would have to not use Guice to create the clients.\n. Closing due to inactivity.\n. @pgkelley4 the associated issue for this pull (#42) has been closed and it seems the settled upon way to remove the initial start up wait is just to set property eureka.numberRegistrySyncRetries=0. If you still want to continue working on this PR that would be more than welcome. Otherwise, we can just close this one out.\n. Thanks. Have added a paragraph for this in https://github.com/Netflix/eureka/wiki/Configuring-Eureka#configuration-1, under Configuring for local development.\n. #142 \n. merged\n. #138 \n. Not merged\n. Thanks for the suggestion @futurely . That's an interesting idea and we will look into it.\n. archiving as eureka2 work is going through some larger internal changes.\n. archiving as eureka2 work is going through some larger internal changes.\n. Moving to a different design.\n. Hi, the environment initialization is handled by contextInitialized and contextDestroyed methods inside EurekaBootStrap. Are you able to explicitly force these calls at bootstrap initialization time to see if that works for you?\n. Hi, I did a bit of reading on WebSphere class loaders and it looks like by default, it loads the web modules with a child loader of the application class loader.\nCan you try to set your WAR class-loader policy control to \"Application\" instead of \"Module\" and see if that helps?\n. Hi @davidcurrie, thanks for the clarifications. I only did a quick reading about WebSphere so it's good to know the differences between the two profiles.\nBack to the problem at hand, are you only seeing this issue with EurekaServerConfigurationManager? If so, the second fix you proposed (instance fields instead of statics) seems the best way forward for this.\n. Hi @davidcurrie , sorry I somehow missed your message. Your changes looks good.\n. hi @davidcurrie , I have merged in your changes to master. We have a couple of minor fixes that should be checked in this week after which a release should be ready.\n. Released in version 1.1.142\n. Thanks for the contribution @pgkelley4 , we will take a look at the pull request.\n. closing this for now.\n. Thanks for the contribution @tkowalcz. The change looks good, though would you be able to move the change from convention.gradle to build.gradle? Thanks.\n. Sure, there looks good\n. Hi @george-smith , I just tried a build with a fresh clone and the test passes fine. Can you please try again and or post the complete stack trace? Thanks.\n. Hi, it looks like from the logs you are running the tests in a worker thread? Can you share your test setup (IDE, cmdline etc)? Additionally, can you try to \"./gradlew clean test\" to see if a cmdline test of eureka works for your environment? You can also use \"./gradlew -Dtest.single=InstanceRegistryTest :eureka-core:test\" to execute only the unit test in question on your cmdline. Thanks.\n. Thanks for the contribution @krutsko \n. If the EurekaClient is not obeying correct rx contact w.r.t. retry() we should look into that also.\n. Thanks @bethesque. Have updated the relevant line in the documentation to reflect this is for EC2 classic.\n. I actually have the opposite opinion here, and would say that reuse of existing classes simplifies out code and design instead of adding more complexity, if the usecase is valid and we are not trying to shoehorn an implementation into a different purpose. Let's take a step back and look at the channel-registry problem for both replication and interest.\nFor replication, we have a channel writing data into a registry. The registry is persistent regardless of the channel lifecycle, and during channel changeover, we evict the data authored by the old channel until a new, replacement channel is recreated and reconnected up to some level of the old state (our 80% rule). While this rule is not met, self preservation is in effect.\nFor interest, we also have a channel writing data into a registry. The registry is persistent regardless of the channel lifecycle, and during channel changeover, we evict the data authored by the old channel until a new, replacement channel is recreated and reconnected up to some level of the old state. While this rule is not met, self preservation is in effect.\nThe two cases are identical, and the reuse of our current SourcedRegistry + PreservableRegistry implementations, if it fits one, it would also fit the other perfectly.\n. The healthCheck is now a component resolver\n. More changes TBD. Close for now.\n. Looks good!\n. Much kudos on all the metrics tests!\n. Ship it. \nOn an unrelated note, we use the terms interest and discovery for the same meaning interchangeably in our code. We should do a sweep through at the end and stick to one or the other.\n. Latest release (1.2.0) has bumped jersey version to 1.19. Apologies for how long this took!\n. Is this the fix for the intermittent interestChannel test failures?\n. Thanks for the catch.\n. fixed\n. Thanks for the catch.\n. fixed\n. For the proposed hint markers, it seems the Buffer hint is always sent for all cases described. From a behaviour point, what does the Buffer hint offer? It seems that consuming clients and/or operators only need to listen for the finishBuffer hint for an optimised buffering experience regardless of whether there are prior Buffer hints. E.g. the consumer should be able to apply a collection operator to the stream that emits a new List each time it sees a finishBuffer hint, and possibly timeout otherwise.\nOn the client side, it seem to make more sense that the source of the hints is only the registry, as it should be the source of truth for all data. On the server side, this is naturally the case, and on the client side the hints should be a merge of local registry hints plus server side hints if any are available. If we make sure the hints are only generated by the registry, we should then be able to merge the multiple hints emitted by atomic interests for composite forInterests so that clients only receive a single finishBatching marker (the logic would then be that a finishBuffer is emitted once all atomic FinishBuffers are received at the merge point).\n. Thanks for the fix.\n. Make sense, thanks for the pull.\n. thanks for the fix.\n. Thanks for the fix.\n. This issue is still pending a part 2 clean up of the client builder.\n. Issue resolve per pull requests #426 and #444 \n. archiving as eureka2 work is going through some larger internal changes.\n. The code looks good, but a more consistent behaviour could be to fix the update code so that the (non-) overridden status is not updated when an override is specified, and hence at deletion time we'll only need to remove the overridden status. Then on the InstanceInfo getter side, we can return either the base status or the override status based on whether the override is present.\n. @ddatsh are you running this in an IDE or on the command line?\n. ship it!\n. Hi @C0rWin , thanks for the pull and the fix. We took another look at the logic around the fix, and it looks like the fixes will actually enable some code paths that have been dormant all this time (and eureka has been working in production for a long time). A better fix would be to remove both checks and any associated code paths that were never exercised instead, i.e. remove both conditional statements and their inner executions. Feel free to resubmit your pull with the change if you'd like, otherwise we can make the fix also. Thanks.\n. Thanks for the contrib @C0rWin \n. Hi @teeratpitakrat unfortunately our new build process requires git pull if you are building from source. Is this a blocking issue for you w.r.t. using eureka?\n. @teeratpitakrat do you need to edit source code? If not, why not just depend on the published eureka artifacts?\n. @teeratpitakrat unfortunately it looks our new build process does not allow eureka to be used as a git submodule inside another project. If your changes to eureka are not domain specific for your case, feel free to send us pull requests. If you would like to make changes to the build files to enable submoduling, that would be appreciated also.\n. Note new Client organisation:\n| Interface | DefaultImpl |\n| --- | --- |\n| EurekaInterestClient | EurekaInterestClientImpl |\n| EurekaRegistrationClient | EurekaRegistrationClientImpl |\n| EurekaClient | EurekaClientImpl (this just wraps around an interestClientImpl and a  registrationClientImpl) |\n. How to better structure construction of clients (and the proper separation of the registration and interest clients) will be in a subsequent pull.\n. Rather than implementing a StringCache independent of xstream, can't we just register a StringConverter with high priority when we register the specific converters for the JsonXStream and XmlXStream?\nWe may also want to look at implementing an alternative to the default StringConverter similar to http://javadoc.jenkins-ci.org/hudson/util/HeapSpaceStringConverter.html.\n. This proposal, taken from a more generic perspective, seems like something that would be an interface in Karyon and services built on top should provide specific implementations. It should then be Karyon's responsibility to feed the aggregated status back to eureka for eureka status.\n. Done in #454 #473 \n. archiving as eureka2 work is going through some larger internal changes.\n. fixed\n. fixed\n. @futurely we will take a look into this. Thanks for the links.\n. archiving as eureka2 work is going through some larger internal changes.\n. Rethinking this a little bit from a broader perspective, if we want to provide backwards compatibility with Eureka1, it might be easier to dependent on eureka 1.x server modules and reuse the same server side core components. The the work necessary will only be:\n- add the necessary rxNetty REST resources to talk to the 1.x server components\n- bridge interest from 2.x registry to 1.x registry\n- bridge registrations to 1.x registry to the 2.x registry\n. Thanks @brharrington . We'll look at a release for this.\n. We are pretty close to doing an RC1 release. We were hoping to do this this week but wanted to double check some server-side metrics so right now RC1 is looking to be next week. Would that be soon enough for you?\n. @benjchristensen rc.1 is now released and we have updated wiki documentation as well for configuration and use. Please take a look at: \n- https://github.com/Netflix/eureka/wiki/Eureka-2.0-Client-Configuration-And-Use\n- https://github.com/Netflix/eureka/wiki/Eureka-2.0-Server-Configuration-And-Use\n. archiving as eureka2 work is going through some larger internal changes.\n. Actually rethinking about this a similar issue can also occur on the removal side as well, which will lead to stale instances. This will need a deeper think.\n. Looks good!\n. fixed in #487\n. archiving as eureka2 work is going through some larger internal changes.\n. archiving as eureka2 work is going through some larger internal changes.\n. archiving as eureka2 work is going through some larger internal changes.\n. Correct, however the semantic differences can be either merge in the future (e.g. in the case of expiry with a better eviction mechanism) or are better applied at a higher level (such as in the case of storage).\n. archiving as eureka2 work is going through some larger internal changes.\n. This should also fix issue #455\n. Pull #497 provides some of the functionality for this. With http2 support in rxNetty 0.5 coming soon there may be bigger changes to the transport layer (e.g. multiplexed registration/interest over the same http2 connection) so will reevaluate when that comes.\n. archiving as eureka2 work is going through some larger internal changes.\n. Per discussions, some confusion were around whether the configurations specified are for read servers only, or also for EurekaClient used by users. The configurations are only for the former and will not be for  clients exposed to end users.\nThere are also some discussions tbd on whether a more specific DSL should be used to specify the \"dataSource\" vs using strings.\n. archiving as eureka2 work is going through some larger internal changes.\n. @qu1j0t3 we are working on some cleanup of eureka1 to ease migration for eureka2, and part of that will include some fixing of these examples. The changes should be done pretty soon, and hopefully with that the examples should be much more clear and runnable.\n. @qu1j0t3 please take a look at #515 which also cleans up the examples. Specifically the new examples module readme with updated instructions https://github.com/qiangdavidliu/eureka/blob/master/eureka-examples/README.md and the updated config files.\n. @qu1j0t3 pull #515 has been merged. Let us know if you are still having trouble with the new examples.\n. LGTM\n. @jeremydyoung thanks for the fix.\n. @spencergibb apologies for the lag, there's been a flurry of activity on eureka recently. We are a bit reluctant to make this constructor public available as that can lead to potential multiple instantiations. Which DI system in particular did you have in mind for this?\n. @spencergibb merged. Thanks. There a few other small things and we should make a patch release soonish.\n. @aspyker thanks for the pull, this would definitely help with some of the slow eureka startup issues we have. One point of interest is whether we should separate registration/update and heartbeat scheduler initializations from each other, as there are some inherent assumptions in eureka of a client's behaviour on the registration path concerning registrations/updates/heartbeats. From the changes it looks like the use cases would be either to initialize both tasks with the existing delays, or to initialize both tasks with 0 initial delay. If this is the case, we should be able to combine the inits for both heartbeat and update, so at least that will guarantee a super use won't init one and forget to init the other.\n. @amanya thank you for the pull request, this would be a very useful feature for Eureka to have. I added a couple of minor comments that I hope you can take a quick look at. \nAdditionally, have you been able to verify this code change? We have mockito as a dependency and it should be able to write a quick unit test for this mocking out the AWS SDK with mockito.\n. Thanks @amanya . We can merge this in and I'll take a look at what kind of testing we can do for this.\n. @aspyker changed the close() on the replicator to call executors.shutdownNow() instead of shutdown().\n. @brenuart thanks for point this out, this indeed looks to be the case. We'll take a look at the impact of this and get back to you on whether we fix or update the comments (as this code is very old and been working in our production for a while, this unintended behaviour may be something that clients now expect, and is therefore potentially harmful to change). Thanks again.\n. Comments updated in #537\n. fixed in #537\n. @brenuart this is a feature that we needed internally to help eureka scale to our production usage. It would be useful to have this controllable via a server configuration however. Would you like to make a pull request for this?\n. Hi @brenuart thanks for the pull request. The readonly cache exist as it's a non-expiry based cache compared to the readWriteCache. What we had observed previously was that the increased numbers of 503s (caused due to cache misses on gets as items are expiring) was causing more issues for us due to the scale of usage.\n. Feature in #544 \n. @brenuart this is already fixed.\n. Sorry should have been more clear. The fix was released in release 1.1.156\n. Thanks for this @brenuart . Rather than conflating the same property for two different use cases (setting the refresh rate as well as enabling/disabling the readonly cache), what about defining a new configuration for disabling/enabling the cache? There is a top level get method (get(final Key key)) that then calls the internal get methods with ignoreReadonly as a param, but right now it always calls with false. This seems a nice hook point for bypassing the readonly cache.\n. Thanks again for the pull @brenuart . The readonly cache and the readWrite caches are actually serving two different use cases that are not quite symmetric. The readonly cache is not a guava cache and does not actually have any expiry or clean up policy, so once it caches data the data stays in the cache without expiry (the update task helps with purging removed apps and leaves tombstones). The issue with using the readWrite cache directly, is that the auto expiry for that causes 503s for gets when a cache miss occur.\nFor convenience I created pull #544 for this, does this pull satisfy your needs?\n. Thanks @brenuart . Closing. \n. @brenuart this would be a useful feature. A simple hook point for this would be to publish this event after every successful execution of the CacheRefreshThread, however this may return some false positives as not every refresh will actually have updates to the local cache. To publish this event only for real changes  may involved some careful hooks to a few different methods (starting point would be the CacheRefreshThread).\nWould you be interested in making a pull for this feature?\n. @brenuart sorry was busy with other work.\nI believe you and I essentially have the same agreement in both of our comments, that is there is two ways to go about this.\nThe simpler way is to emit events on the cacheRefresh, which gives false positives as not all cache refreshes actually updates data. This is pretty straight forward to add.\nThe more complex and better way to generate events for real refresh that actually did work is to hook into the various update methods themselves. As the update actions involves deltas and retries the instrumentation point may not be as straight forward.\nW.r.t. to the message publishing, using the existing eventBus is nice as a different event (StatusChangeEvent) is already published there. However I have no strong dislikes of a listener, provided that it can be added nicely to the current interface and does not add too much clutter.\nSince we don't have a requirement for this feature internally, I leave it to you to decide which route is best for your use case.\n. Thanks @brenuart . I restarted the test and it looks like it was a transient failure.\nOn your comments:\n1/ Agree.\n2/ Messages published on the event bus can be consumed with the following recipe:\njava\n// Here I am using an anonymous inner class to reduce verbosity of the example, in reality, although this works, you may want to have a named class.\neventBus.registerSubscriber(new Object() {\n    // Any method annotated with @Subscribe will be a consumer of the event class (or any subclass thereof), which is the first (and only) argument in the method.\n    @Subscribe\n    /* Any access modifier & any method name works. You do not have to implement any interface */\n    public void consume(MyEvent event) {\n        // Consumption of the event code.\n    }\n});\nSo the consumers can listen for specific event types without interfering with the consumers of different event types.\nAnother example to look at for event bus consumption is EurekaUpStatusResolver\n3/ You are correct on this. I guess right now since EventBus publish and consumption is async it doesn't make a big difference.\n4/ Agree.\n. Thanks @brenuart \n. Since most of the static methods are deprecated (and the remaining ones are fixable), one way out of this bind is to keep two copies of clientConfig, one static and one instance level. The static clientConfig will be used by the deprecated static methods, and the setting of this will be by each client construction (so slightly undefined as to which version you will get when referenced statically).\n. If the aim of this is to support multiple instances of DiscoveryClient to be created (for some specific use cases), and the only blocking item is the static client config, then adding exceptions would not be a good user experience, especially since it looks like it's not difficult to make the client config an instance variable of the client itself without compromising the singleton usage of client in the more main stream use case.\n. @KishorGrandhe this is on our list of items to fix. If you are interested, a pull request would be very welcome as well. Thanks.\n. This is fixed and now DiscoveryClient instances now have their own config instances. (A static reference still exist for backwards compatibility of some of the existing deprecated static methods, but the static config will be pointing a non-deterministic version of one of the client's instance level config).\n. Thanks @spencergibb . Changes looks clean.\n. @spencergibb we are looking at doing an rc release today. Since many of the dependencies has been updated, we will make the full release once the rc from today is confirmed to be stable.\n. looks like the build system is having hiccups\n. thanks @kukgini \n. Still todo: adding integ tests\n. Much cleaner:)\n. archiving as eureka2 work is going through some larger internal changes.\n. Hi @willtran- can you please do a rebase? Thanks.\n. @willtran- looks good, thanks for the contribution.\n. Fixed, thanks @jeffreymyers \n. @xbaran thanks for the fix.\n. @cforce thanks for the suggestion. Are you interested in making a pull request for this feature?\n. @cforce just re-read your initial post, are you raising this issue for eureka 1.x or eureka 2.x? Using the vip field for versioning is not a misuse, a vipAddress can be a composite of multiple variables that define the application, one of which can be the version itself.\n. Closing due to inactivity.\n. @cforce thanks for the suggestion. Are you interested in making a pull request for this feature?\n. @cforce it's up to you:). We'd love a discussion/design beforehand but feel free to make a pull request and we can discuss over that also.\n. Closing due to inactivity.\n. @cforce eureka-client depends on jersey 1.x only and we have not tested (or guarantee) compatibility with jersey 2.x. We also do not have any plans on upgrading to jersey 2.x in the short term.\n. @singerdmx we are doing some work that will help with this this quarter, but we can't commit to any timelines right now unfortunately. I will update once we have anything more concrete.\n. @jasollien @saneItchyHog we are taking a more drastic direction w.r.t. the client side of eureka (thinner clients with no jersey dependencies at all), and is working more towards this goal at the moment. We believe that this is a more flexible solution at the end of the day as it addresses other dependency problems as well as the jersey issue.\nUs providing a jersey 2.x implementation of the current client is technically feasible, however part of the value of eureka (client and server) is that is it battle tested in very large and varied deployment scenarios at Netflix, and even if we provide a jersey 2.x variant, it will not be used internally and will lack similar levels of production readiness.\nHaving said the above, the aforementioned (earlier in this thread) new transport is now active, and there is a jersey 2.x skeleton in the eureka-client-jersey2 submodule, so we are definitely more than willing to look at any pull requests to build on top of these.\n. @mattnelson as part of the new work we are doing a bit more than just a different client, but are also taking advantage of this to rework the data model to update it to the 2016 requirements we have as a company, compared to when eureka was first published (better VPC support for example). Part of the work will include introducing a proxy tier to handle the compatibility with the existing eureka server so I suspect it would not fit with your immediate use case. \nIf you are keen to follow up on the existing -jersey2 work that would be greatly appreciated, as I don't think the newer work will completely deprecate all use of the existing client(s). I think it will bring a lot of value to this project.\nThanks.\n. archiving as eureka2 work is going through some larger internal changes.\n. @spencergibb we are working on a more native jackson codec on the features/jackson_codec_ng branch. The code is pretty close to being merged back in to master. Do you want to take a look at the changes there w.r.t. your pull request?\n. @spencergibb most of the code for the new codec are in this package https://github.com/Netflix/eureka/tree/features/jackson_codec_ng/eureka-client/src/main/java/com/netflix/discovery/converters/jackson, see EurekaJacksonCodecNG.java as the main entry point.\nMultiple codec types (such as the older EurekaJacksonCodec and the newer NG version) will be supported for a while and configuration is available to switch between them, but at some point the non-NG codecs will be deprecated and removed. If you would like to add hooks to provide custom behaviour, I would try to add them to both EurekaJacksonCodec and EurekaJacksonCodecNG. Hopefully it'll be pretty straight forward.\n. If you can wait a few days, it should make it back to master. Also feel free to make pulls to that branch directly. The code in that branch is pretty much complete and sync-ed with master, so we are just waiting for some performance experiments to be done before we call it good and merge it back.\n. @spencergibb is this pull still needed now that (hopefully) you no longer need to customize the serializer?\n. Thanks. Closing.\n. Thanks @bondj. This is indirectly fixed in the refactorings/transport branch. Closing.\n. Closing due to inactivity.\n. @spencergibb we've actually removed some of the warn level logging recently, especially the reconcile hash code mismatch warn log msg that had no value, and is the most \"annoying\" of the warn logs.\n. My mistake for the wrong comment when I closed this issue.\n. Closing due to inactivity.\n. @brenuart thanks for the issue. Will fix.\n. I am doing some clean up work on the server side right now, so can just add the fix as part of that. Feel free to provide a PR as well.\n. Resolved per #639\n. thanks @brenuart \n. Hi @aivans there are some known bugs with rc.2 that we are fixing for a rc.3 release. As for 1.0, we don't have any timelines for this at the moment.\n. Closed in favour of #652 which merges into a branch first.\n. Closing w.r.t. #649\n. @jkschneider thanks for the pull. Regarding your question on compatibility of adding a new Name enum, it would break older clients who while fail at Name.valueOf(\"ANewCustomName\") unfortunately. \n. @jkschneider @spencergibb #649 should provide a way to specify custom ids for InstanceInfo without having to go through DataCenterInfo.\n. Thanks @hakanson. The internal document no longer exist and was likely for linkage with other internal tooling and not relevant for this xsd. Updated the wiki.\n. Turns out there are some lingering internal compatibility issues with reusing sid. Going to rework this pull and add a new field (client usage should be similar).\n. ship it.\n. @Crystark you are right, thanks for raising the issue. The problem appears to be in the withInstanceInfo() method inside the builder, where instead of copying the metadata map, it assigns to the older instance's metadata map. \n. Fixed in #658\n. @aroger-r7 thanks for the pull, this looks quite useful indeed. I apologies for this but we are close to checking in some large server side refactoring (see the feature/di-friendly-server branch) that affects this pull. Would you mind considering rebasing this change w.r.t. to that branch instead? \nThe overall pull request should not need to change much, and in particular in the refactoring branch some similar was work done (EIP binding was moved out of the bootstrap class for example). The main class you may want to look at is EIPManager.java. You may want to just provide a route53 parallel to this and at bootstrap/setup time, we can pick between the right ones to use.\n. Looks good.\n. @aroger-r7 thanks for the contribution.\n. Closing due to inactivity.\n. @aroger-r7 fyi some minor edits.\n. Thanks @spencergibb \n. Not a bug, this is also handled by the full fetch code path in \nprivate Applications filterAndShuffle(Applications apps);\n. Ship it.\n. New transport is now the default, closing.\n. archiving as eureka2 work is going through some larger internal changes.\n. @octonary thanks for raising the issue. The current implementation of OUT_OF_SERVICE does not work well with multi-tenant environments and uses the id as the key for OOS (which defaults to the hostname/aws instanceId). We will take a look at fixing this in a future release.\n. ship it!\n. ship it!\n. Eureka has been updated to servo 0.10.x\n. @alexandre-gauge that is a java8 method. Can you try to update to java8 and try again? Thanks.\n. Thanks @brharrington. That's a good suggestion.\n. Updated as @brharrington suggested\n. Closing this for now, will reopen when needed\n. :+1:\n. There is actually some work in progress that will address this exact issue\n(for a different use case). The changes should make it into the next\nrelease.\nOn Dec 4, 2015 9:13 AM, \"tbak\" notifications@github.com wrote:\n\nCloudInstanceConfig depends on Amazon metadata. If access to metadata\nfails, and flag 'eureka.validateInstanceId' is set to false, as a fallback\na local host address is read. Possibly this is happening in your case.\nYou can always override the default CloudInstanceConfig implementation, and\nprovide your custom version that better handles docker environment.\n/Tomasz\nOn Fri, Dec 4, 2015 at 7:16 AM, Stefan Fussenegger <\nnotifications@github.com\n\nwrote:\nI'm trying to get Eureka running in AWS EC2 Container Service (ECS).\nUnfortunately, CloudInstanceConfig relies on\nInetAddress.getLocalHost().getHostAddress() to get the IP address. In\ncase of Docker, this is the IP inside the Docker network (typically\nsomething like 172.17.0.2) which isn't very helpful.\nUsing MetaDataKey.localIpv4 should fix this problem without changing\ncurrent behavior:\n@Overridepublic String getIpAddress() {\nreturn ((AmazonInfo) info).get(MetaDataKey.localIpv4);\n}\nhere's the current implementation of getHostName(..):\n@Overridepublic String getHostName(boolean refresh) {\nif (refresh) {\nrefreshAmazonInfo();\n}\nreturn ((AmazonInfo) info).get(MetaDataKey.publicHostname);\n}\nAlternatively, there could be a new property to enable this behavior.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/715.\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/715#issuecomment-162024552.\n. Sorry for not updating. This is actually already fixed and released in release 1.3.7. Will update the release notes also.\n. Looks good\n. @FabianHoltkoetter what you propose makes sense. I have a suspicion that had Optional been available prior to java8, this API would likely have been done that way. Unfortunately the getNextServerFromEureka() method is now a public API and for compatibility, it would be a breaking change to change it from returning an InstanceInfo to return an Optional.\n. @FabianHoltkoetter Thanks for raising this issue. Although it is valid, I'm going to close this for now as there are work around methods (e.g. get the full list of the vip and do a simple round robin on the list), and updating the method in question would leave to requiring an incompatible version bump.\n. @jylin putIfAbsent is part of the map API since java8.\n. In that case, sure. However please do note that we are developing on java8 and may introduce other java8 only functionality in the future.\n. @sfussenegger thanks, we will update the wiki. To address your 3 specific questions:\n\n1) client/server protocol compatibility should be ensured for minor version updates. Minor version bumps may indicate client side java API changes or dependency changes but should not impact client/server protocol.\n2) server should be compatible with earlier clients at minor version differences.\n3) servers are designed to be upgraded one at a time (but preferably not between versions that are too far apart) so there is server-side compatibility between minor version differences.\n. @sfussenegger yes, we use semantic versioning for eureka. Id like to say we've been trying out best to keep complete protocol compatibility for the 1.x series of releases, though to be honest I haven't really validated some of the truly early versions (say from 3+ years ago). I can however confirm that 1.1.147 is compatible with server version 1.3.7 (we have instances of 1.1.147 running with our current server deployments of 1.3.7).\nOne caveat is that we don't package internally using spring-cloud-netflix, so I can't verify any compatibility requirements w.r.t. the spring wrappings.\n. Thanks for the update @spencergibb .\n@sfussenegger I'm going to close this issue for now. Please feel free to re-open if you have further questions.\n. @kristofferpeterhansel it's possible you are running into an eureka incompatibility also. We keep a much closer eye on (earlier) client, (later) server compatibility than the reverse (looks like you are trying to run a later client client 1.4.4 with an earlier server 1.1.x?), and typically upgrade the server much more aggressively than the client versions.\nWhat exact server version are you running with?\n. @kristofferpeterhansel how big of a cluster do you run? You should be able to upgrade the nodes one by one ... but given that the version 1.1.147 is now over a year old, it's \"possible\" an incompatibility exist. What happens if you just upgrade one of the nodes to the latest server build? Does it work for you?\n. Closing this issue as the discussion seem to have to come to some conclusion.\n. Thanks @mrumpf . We'll take a look at this.\n. ship it\n. Hi @maliksalman thanks for the issue. For different deployment environments, we are aiming for a more custom strategy based on the AwsBinder (https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/aws/AwsBinder.java) interface and better DI support for the server (there are some work-in-progress code in the eureka-server-karyon3 package). The idea would be to be able to custom bind different components of eureka servers as needs arise. So in your case, you can bind your own (NoOp or specialised) AwsBinder to suit your use cases, whereas the default that works for us is the EIPBinder.\nWe are hoping to have this complete in the short term.\n. Latest spring-cloud-netflix is on eureka 1.4.x, closing.\n. @spencergibb looks good, I'll merge this in. Will spring cloud netflix be moving to java8 servo soon?\n. Great, thanks for letting me know. There is no great need to enforce java8 for now, so we can try to make sure we can build against java7 unless anything comes up.\n. Hi @drax68 eureka 1.1.51 is over 3 years old, and significant changes have gone into eureka since. I'm not sure if it will be easy to figure out what issue you might be running into given the age of the version. Are you able to upgrade to a more recent release?\n. Minor versions of servers should still be compatible. We are running with 1.3.8 servers as of this moment.\n. @pparth from looking at your error log and comparing against source code, it looks like the status result you are seeing is due to an NPE in your StatusResource itself, not necessarily due to any actual system issues. Given that you are seeing replication logs, it's likely your servers are still connected. One way to check is to try to make a /v2/apps/ call to see what the registry data looks like.\nAs an aside regarding the NPE, are you using the provided war to deploy your server or customizing it? Using the provided artifacts there shouldn't be any NPEs.\n. @drax68 that is a known issue. status overrides for eureka at an instance level are scoped for the lifetime of a registration. So for example when you remove a server, a previously registering client to that server (which was overridden) will switch registration to a different server, and reset the override. We have explored a few different ways of dealing with internally but it has not come up as a priority. Typically internally we set overrides at an (EC2) ASG level, and that is guarded by AwsAsgUtil.java.\n. Hi @pparth \nCan I clarify that your (client) applications register with STARTING only, and only transition to UP status via an external trigger (the REST call from the deployment workflow process mentioned)?\nWe use discovery's statuses slightly differently internally. Internally, we tie discovery statuses (STARTING, UP, DOWN) with our application healthchecks, and the state transitions between these statuses are automatically governed by the applications. For example, an application will register with STARTING, and at some point in time (e.g. Guice container initialized, or some known async warm-up process has completed), the application will automatically transition it's own status to UP. The healthcheck is also tied in to this (eurekaClient.registerHealthCheckHandler()) and is used to move between UP and DOWN programmatically. All this can be achieved via usage of EurekaClient and ApplicationInfoManager.\nThe OUT_OF_SERVICE status is used as a special case override. Our deployment workflow has the ability to make PUT and DELETE rest calls to the eureka servers to set and remove OUT_OF_SERVICE override statuses (see https://github.com/Netflix/eureka/wiki/Eureka-REST-operations, I have updated the doc to reflect the DELETE option of removing overrides).\nA slight clarification to my point earlier regarding instance-level overrides are scoped only for a registration lifecycle, if a client re-registration happens to a different eureka server (as is the case when the original target eureka server disappears, such as for re-deployment), this is not considered as a new registration lifecycle (as an explicit unregistration never happens), and as such overrides are preserved.\nRegarding my comment on AwsAsgUtil, internally our most common form of overrides are applied at the (EC2) AutoScalingGroup level. We synchronized our ASG disables with eureka's OUT_OF_SERVICE status, and the logic for that is contained within AwsAsgUtil.\n. @pparth looking at your description, this could potentially be an issue due to the order of operation between bringing up the new servers, and adding their records to the txt record. When a new server comes up, it will do a one time sync with a recognized peer (in this case an existing server). However this is one time only, so by the time this peer becomes a live server (due to the addition of it to the master txt records), the data it contain may now exceed the expiration deadline, especially when clients switch to registering with it.\nCan you try the following to see if it helps with your case:\n1. Add one elb to the txt record first before bringing up the new server\n2. Wait a little to make sure dns propagates\n3. Bring up the new eureka server\nEureka clients and servers are able to handle \"missing\" servers in the cluster.\n. @drax68 glad to hear that this resolves your issue.\n. @neo-tian thanks for that. This was fixed in release 1.1.158.\n. :+1: \n. @lenadroid are you running the client and server from the same git repo? Wondering if there may be a version mismatch somewhere as the server has a dependency on the client also.\n. @lenadroid this is a pretty weird one. The class that's failing with ClassNotFound is there, and your successful executions also prove that. Are you able to see the same sort of problems with a more complicated set up than the simple examples provided?\n. @SphereUser I'm curious to the instability that you are seeing. We internally run eureka at very large scale and it has been stable for many years. One thing we are trying to update is documentation on configuration and operation of the servers, which currently on github is lacking some advanced info.\n. Closing this issue as the problem is specific (after more investigation) for the example when ran with gradle using the gradle applications plugin. Using the dist option and also in real operation the ClassNotFoundExceptions are not seen.\n. @searover we no longer host javadoc, but the interfaces themselves are documented. Have updated the links on the wikipage. Thanks.\n. @andreldm there are no limits (either on total number of instances, or number of instances per application) currently. Is this some new functionality you are looking at?\n. @andreldm one of the tenants of eureka is that instances are abstracted away and application talk to each other over some fungible set of physical instances. If your use case require limiting it to just 1 instance, then yes eureka doesn't make too much sense.\n. @hieurl thanks for the pull. Looking at the change, unbindEIP() is currently really used at shutdown time, so a more optimized behaviour when unbindEIP() is called when no EIP is bound, is to perhaps log.info() and then just return from the function, instead of throwing an RuntimeException. What do you think?\n. @hieurl thanks for the contribution.\n. :+1: \n. Hi @stevewallecs we are working on some updated documentation. Hold on.\n. Fixed the broken link, closing this issue for now. Will be adding some higher level docs for configuration both the client and server later.\n. Hi @bspline looking at the records, it looks like your configuration is expecting \"eureka/v2/...\", whereas the txt records are expecting it of the form \"discovery/v2/...\". There is a mistake in https://github.com/Netflix/eureka/wiki/Deploying-Eureka-Servers-in-EC2 between the words eureka vs discovery that would have caused this. The page has been updated. Thanks.\n. @fangzhining sorry about that, looks like when I fixed the documentation mistake on that page, I did not do it fully (update yet again). For the dns option, you only need the hostname in the records, and should not include \"http://\", the port, nor the \"eureka/v2\".\n. Hi @ervansetiawan , the eureka servers are themselves clients as well, and use eureka-client to register with the server cluster (non-deterministic which server to register with, though governed by the zonal preferences). Its possible to see no peers if these clients on the servers fail with their registration. Can you see if there are client registration failure logs on your servers? \n. @jelez eureka servers are not really designed to operate with floating IPs, the servers themselves need to have fixed IPs (e.g. EIPs in aws) to work well.\n. @fangzhining sorry about that, looks like when I fixed the documentation mistake on that page, I did not do it fully (update yet again). For the dns option, you only need the hostname in the records, and should not include \"http://\", the port, nor the \"eureka/v2\".\n. @fangzhining can you tell me which AwsBinder you are using? Are you using Route53 or EIP? Thanks.\n. @LennyZtyle eureka 2.x is not work that can be merged into 1.x (on master branch).\n. Hi @cschneider eureka2 is not a tomcat base application, so there is no war file generated. Having said this, the current stable eureka is the build on the master branch, which is the 1.x system. The 2.x system is currently not complete. Thanks.\n. @mattnelson we are open to either resolution step, though I can foresee potential confusion w.r.t. option 2 as the (archaius based) configuration file for eureka is also called eureka-client.properties.\n. @mattnelson sorry about missing this PR, not sure how I missed this.\nThe changes in general looks fine, though taking a look at the information exposed by StatusInfo (which is code that has been moved around a bunch of times now and is pretty old), the contract for isHealthy seems poorly defined. The isHealthy field should really only be applied to the local server itself, as at a cluster level, eureka is can still be considered \"healthy\" even with some down replicas.\n. If you are accessing eureka (server) through the provided eureka-client, then the theoretical threshold for DOWN replicas is pretty much n-1. There is a some load balancing built into the provided client such that they can handle parts of the server cluster being unavailable.\nThe replication protocol within eureka is a broadcast model, and hence as long as you have a single server standing, the cluster is \"ok\" (provided that this single server can handle the incoming requests of the world of course).\n. Hi @mattnelson , eureka is designed to be able to operate fully even when replicas are missing (as long as not all replicas are missing, and of course there are enough replicas to satisfy the data output bandwidth requirements). Replication is not tied to the number of replicas available so having downed replicas does not affect replication at a local level between the healthy replicas.\nI do agree fully with you that it would be very useful to have, from the status endpoint, a view of the cluster's health. However the current PR results in an \"unhealthy\" status for a given server, if peers of this server are unhealthy. This would be incorrect information per our discussions in this thread.\nHow would you like to proceed? You are more than welcome to update this PR to expand on the health status to expose cluster level health if you would like to define a cluster level down threshold. Alternatively we can close this PR for now, and start a new PR for that.\nThanks.\n. @mattnelson sorry didn't see this PR getting updated, some minor quibbles but LGTM.\n. @mattnelson thanks, the failures are not your fault. Ever since we migrated to travisCI we've had these intermittent failures. Current theory is that the limited CPU that the travis containers are configured for are not enough for some of the multi-treading tests. I'll trigger some reruns for you.\n. @mattnelson the failures are actually due to one of the tests added:\ncom.netflix.eureka.util.StatusUtilTest > testGetStatusInfoHealthy FAILED\n    java.lang.AssertionError at StatusUtilTest.java:28\n. Looks good, merged. Thanks.\n. @agomezcafeto eureka does not use a yml based configuration. Currently, the configs are self documented in javadoc in EurekaServerConfig.java, and you can get some highlevel set up information from https://github.com/Netflix/eureka/wiki/Deploying-Eureka-Servers-in-EC2\n. @jc89 thanks for the PR. Could you please also add some comments to specify what the expected DNS records would look like, and what tags the ENIs will need to be tagged with? Thanks.\n. Thanks again @jc89. Would you mind adding what you just described as javadoc comments to the Top of the ENIBinder class? That way the documentation will live with the code.\nOtherwise everything looks fine, and I'll merge this in as soon as you add the documentation.\n. @jc89 thanks for the contrib.\n. @bebepeng @zgagnon  sorry for not taking a look at this issue earlier. Can you describe the issue you are seeing in a bit more detail? From what you describe, can I assume the \"http://\" of the id is what's preventing the DELETE request due to url parsing?\nIf that is the case, eureka have an internal eviction mechanism where if a heartbeat from a client source is missed for 3 consecutive times (using default config, this would be ~90s), then that entry will be evicted from the registry on the client side. Are you able to shutdown the client with bad instancesIds for that amount of time? If so, that will allow you to evict these client with bad ids.\nAs for defining instanceIds, as of release 1.2.5 there is a configuration option available to define a custom instanceid for the client instead of sourcing it automatically (see #553), and if you are using the default configuration options, the config setting is eureka.instanceId=some-id\n. Glad to hear that issue is resolve on your end. Closing this issue.\nW.r.t. an API for application level deletion, agree that it would be useful in some cases. If there is some urgency to the desire of this feature, please feel free to make a PR to add it. Thanks.\n. Thanks, fix in #801\n. @tsjsdbd thanks for noting this. What you say is correct. From the server side logic, gzip or not is an option governed by accept encoding. However the default server build contains, as a default filter, the Gzip encoding filter that gzips all responses regardless of accept encoding.\nInternally, our usage levels are so high that is not realistic to produce unzip responses for any request, hence the default this way as a server side guard against all incoming requests.\nIf you do need the ability to return zipped or unzipped data depending on accept encoding, please edit your server build to remove the default usage of the gzip filter.\n. @mattnelson thanks for the fix!\n. @alessnet are you using eureka via direct REST requests, and not through the provided eureka-client? There are a few subtleties in the way registrations are handled by eureka, that is usually abstracted away by using the client. Primarily, these are:\n- the client contains a eureka specific loadbalancer for talking to the server cluster, such that it minimises target switches for a given client:server pair.\n- the client abstract away the usage of the InstanceInfo.lastDirtyTimestamp field in the registration protocol, which is used to provide linearization for registration events even if they end up going to different eureka servers.\n. @alessnet the lastDirtyTimestamp is intended to be supplied at the client side (and is what the java client does, see InstanceInfoReplicator.java for code and also comments on client registration logic).\nSince this intended to be client generated (and guaranteed at the client side to be serialized), it is possible to use this value as the mechanism to serialize write operations (register, update and cancel). The server side replication logic also utilize the dirtyTimestamp to deal with conflict as you described.\n. @alessnet sorry about only getting back to you now, I was away for a bit.\nI did some more digging into the code, and I think you are correct in saying that (if using the REST api directly), there is a potential registration race condition where if two successive registration requests landed on different machines and happen fast enough such that replication has not yet occurred between the two machines, it may lead to the inconsistency you observed. I believe the provided java client's error handling (inadvertently) guards against this which is why we have not seen it in our production systems.\nI'm going to see if I can repro this and work on a fix if it is confirmed. Thanks again for point this out!\n. Hi @alessnet we have not had time to work on this unfortunately. Will see if we can try to repro this this week.\n. @alessnet I've semi-verified it via the above PR, and will be doing some tests in our test and prod environments before confirming.\n. Fixed in release 1.4.9\n. Actually 1.4.9 provided a mechanism to \"fix\" this, but has not defaulted it yet. Will keep this open until we switch the defaults over.\n. Released in 1.4.11\n. Thanks @spencergibb. Looking at the the issue on the spring cloud netflix issue and the code, I see that the NPE is due to an out of order creation of a metrics counter. This is a harmless NPE that should only happen at init time. We will take a look at a simple PR to address this regardless.\nThe details: this is caused due to the second server not completing initialization (specifically, the openForTraffic() method on the local registry that creates the metrics counter in question) before having the first server heartbeat to the second server, and trying to log the renew metrics on an as yet non-existent metrics counter.\n. Fix will be available in the next release.\n. Hi, if you are using the provided java eureka-client, then the registry cache on the client side will be forever and does not expire. The data will update if (at least one) eureka server exist and is reachable, and if no eureka servers exist, then the cache will essentially be frozen in time. Note that the default DiscoveryClient.java implementation offers the method getLastSuccessfulRegistryFetchTimePeriod() for users to monitor for staleness of the local registry cache.\nIf by closing the server, you mean the shutdown of the server for Application(A), then the entries for Application(A) will be purged from the local cache of the client on Application(B). The time delays are:\nA shutdown gracefully -> eureka server removes entries for A (0s delay)\nA has a dirty shutdown -> eureka server evicts entries for A (90s delay)\n        +\nB cache update -> B see cache update for removal of A (0-30s cache refresh cycle)\nAlso please note that if you run with a small number if instances, you may be subject to self-preservation as described here (https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication), and may want to tune the self-preservation thresholds as necessary.\n. @vseguin thank you for the fix!\n. Thanks @mattnelson \n. @kennedyoliveira unfortunately we have not tried out any deployments on Wildfly, and I am not sure if any one in the community have tried this either. It might be worth while asking this question in the Eureka Google Group to see if anyone from the community respond.\n. @Writtscher we have decided to take a different direction and will be making the client side of eureka independent of jaxrs completely. Work is being done internally, however we don't have any timelines that can be shared as of yet.\n. @bitsofinfo thanks. PR #813 should be a fix.\n. @bitsofinfo give 1.4.10-rc.1 a try and see if it fixes your issue?\n. Closing this issue as the specific issue to address is resolved. Custom hostname verifier is tracked in #816.\n. @moizkhan2712 our internal set-up do SSL via fronting the eureka tomcat servers with an apache layer.\n. https://github.com/Netflix/Raigad is one possible solution.\n. Hi @bitsofinfo that sounds like a useful addition for eureka. We are a bit swamped with other work at this moment, would you like to try a PR for this feature? Thanks.\n. Minor quibbles, but LGTM. Thanks for the PR.\n. Hi @robertnosburn thank you for the PR. Looking at your usecase, it seems like what you would prefer is that the EIPBinder not run at all?\nEureka servers need to have fixed IPs, and EIP is one mechanism that we use to guarantee that in a cloud environment. However if you are able to guarantee that via some other mechanism, then possibly a better way to disable the errors from the EIPBinder is to not initialize the EIPBinder at all.\nEureka server currently support a configuration AwsBinder strategy (see https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/aws/AwsBinderDelegate.java) where configuration (eureka. awsBindingStrategy=) can be used to define the binder type. What about a proposal that we add a fourth option (NOOP for a no-op binder) to that set of binders, which you can then configure via properties in your setup?\n. @robertnosburn I buy your point, thanks. Have merged your PR in. As for the route53binder, let me take a look at that. We don't actually use that binder optional at Netflix and it was contributed to us by an external user, so it may have quirks that's specific for their use case. \n. @ibaiul can you double check to see that all of your aws-java-sdk-* dependencies are at the exact same patch version? Misalignment between the aws java sdk jar can cause these kind of errors.. @robertnosburn thanks for the PR.\n. Hi @fengbaicanhe the current eureka server implementation have some level of caching, and does not support real time notifications.\n. @fengbaicanhe there's nothing on that that we can commit to at the moment unfortunately.\n. @mattnelson thank you for the PR! Much appreciated. I'll take a look at this as soon as I can.\n. @mattnelson are you running both jersey2 client and server in your set up, or just the client?\n. @spencergibb you'll be interested in this PR too.\n. @mattnelson much appreciated. It would be good to have some confirmation that replication is also unaffected once you have >1 server running.\n. @mattnelson great to hear, thanks!\n. @mattnelson nothing major, I just thought (per your last message) that you were making some additional changes to the PR for replication?\n. Ah. In that case then all good. A separate PR would be better if they are unrelated. Let me make a release of eureka without this going in first to have an artifact for the current head before merging this in.\n. @mattnelson I'm looking at merging this in and doing a release. There is one last issue where due to the move of \"DiscoveryClientOptionalArgs\" it creates a minor api incompatibility. I am assessing the blast radius of this at the moment.\n. @mattnelson there are a few small changes that I would like to make to this PR, but in the interest of not blocking you further, what do you say to moving this PR to against the (newly created) \"contrib/jersey2\" branch, where we can merge it in, and then I will make some PRs for the minor changes before we moving it back into master?\nedit: I'm actually able to change the base branch, so have done the above.\n. Hi @ShadySQL eureka support other forms of fixed addresses. such as ENI and Route53 DNS (which in EC2 vpc can be private). In all cases (EIP or otherwise) you can secure your service with Security Groups.\nSee https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/DefaultEurekaServerConfig.java#L664 where you can supply the binding strategy via eureka.awsBindingStrategy=...\n. Thanks for the contribution @Benky \n. Hi @miggy8234 do you mean the configuration based eureka-server.properties? The one that is sourced by the configuration system (archaius) should be under the path WEB-INF/classes/eureka-server.properties .\n. Hi @miggy8234 your link is for the client (eureka-client), do you mean the client or the server? For the eureka server themselves, you'll need to build them as a war which packages in the eureka-server.properties prop file.\n. Hi @rs017991 the correct property file is in the war at /WEB-INF/classes/eureka-server.properties. The file in META-INF may have the same name, but that is purely an artifact of the war name and is auto generated by the build. It does not affect actual property loading of the property file.\nThanks.\n. Hi @lijunyong what environment (tomcat version etc) are you trying to run the server under? Thanks.\n. Hi @lijunyong we do have tomcat8 servers running as well, but I have not been able to repro this issue. Are you still seeing the problem? It might also be worthwhile asking this in the google group to see if the community has any idea. Thanks.\n. Hi @killjason there is some very basic \"client side LB\" available via the default java client, see EurekaClient.getNextServerFromEureka(). However there are currently no LB rest endpoints exposed from the server.\n. Thanks for the fix!\n. @mattnelson this is an update to your PR #821\n. Cool, thanks. Merging it in then. Once you've verified that it is fine in your env, I'll move it into master and cut a release.\n. Great, thanks @mattnelson. I'll merge the jersey2 branch into master and have it released in the 1.6.0 release.\n. Hi @adoura we had some internal needs that triggered the flurry of 1.5.x releases recently. It looking like that should be stabalizing, so we are tentatively looking at merging in the jersey2 support and cutting 1.6.x sometime this week.\n. Hi @iamzhout we don't have any exact numbers on the edge limits for eureka, and of course this also is highly dependent on the instance type that the servers are deployed on. To give you a rough idea:\n1. eureka servers do not shard their registry, so from a memory footprint p.o.v. all servers will share the same restrictions. Having said that, we have typically found that network I/O being the bounding factor (by far) rather than cpu or memory, especially considering that the network out for queries will increase with the number of instances registered with eureka. \nWe run a pretty limited number of servers internally (~10), which serves many 10s of thousands of clients. Having said that, these servers are running on the larger EC2 instance types. If the number of clients reduce, the number of servers can also be reduced.\n1. See above regarding network I/O being the bigger bounding factor for eureka servers. Eureka servers does need some baseline amounts of CPU and memory to operate, probably something similar to an EC2 .2xl would be fine.\n2. The original (if not overridden) refresh rate is 30seconds.\n. Thanks for the update. I have some questions regarding your set up:\n- are you testing with just a single eureka server, or with a cluster set up (and if so, how many instances?)\n- with your 200 concurrent calls, are they (relating to the above) hitting the same server or distributed? what is the rate of these calls?\nAddress your questions without understanding of the two questions above, \n1. We typically run with a cluster set up (~10) as mentioned, so the requests would be shared between these servers. Additionally, we have independent deployments in different regions so the environment itself is effectively sharded.\n2. We did encounter this issue as well, and resolve it by adding an autoscalable readonly proxy fleet internally. There is logic (disabled via configuration) inside eureka-client that handles logic regarding a redirect to only do reads from servers in the readonly fleet. The readonly fleet code has not been open sourced yet, but it is quite straight forward:\neureka-server's REST resource -> cache -> eureka-client connecting to write servers\nsee EurekaTransportConfig.java for the configs as well as javadoc.\nLastly, there are some server side optimizations that we have not enabled by default in OSS configs yet (mainly due to complexity of upgrading an existing deployment with these). \n- See this setting which enables batching for the server to server replication.\n- Are you using the gzipEncodingEnforcingFilter? This is enabled by default in the provided example web.xml but your set up may be different.\n. Closing old issue. Please re-open if necessary.. Thanks @spencergibb \n. Hi @killjason the hostname should be automatically discovered by eureka-client.\n. @killjason same for ip address as well. The client auto detects your hostname and IP via standard system calls, and then (optionally, if in EC2) overlays these with data retrieved from calling the ec2 instance metadata url.\n. @killjason we don't yet support multiple interfaces.\n. @killjason if the server is running on Amazon, it defaults to eth0. Otherwise, the default interface is whatever will be picked up by InetAddress.getLocalHost().\n. @d-sauer thanks for the contribution!\n. @killjason you can just create them using the constructor. See some examples here:\nhttps://github.com/Netflix/eureka/blob/master/eureka-examples/src/main/java/com/netflix/eureka/ExampleEurekaClient.java\n. @nick-pww this seems spring cloud specific, you might be able to get better help at https://github.com/spring-cloud/spring-cloud-netflix. \nInternally, our deployment of eureka does depend on this, and we have not observed the EIP issue you described. We do not run with spring cloud however.\n. @nick-pww the default DiscoveryClient should start up a thread to run the InstanceInfoReplicator, which when it runs will refresh the datacenter info.\nNote that the Amazon based datacenter info refreshes in ApplicationInfoManager only occurs if the config is of CloudInstanceInstanceConfig.\n. yeah that's stuck forever unfortunately.\n. The issue is to do with config interpolation when using prefixedView, where if prefixedView is used, then the interpolator automatically expect the same prefix to be attached to the interpolated config.\ne.g. if my.prefix.config=${ENV_VAR}, then using prefixed view with prefix=my.prefix, ENV_VAR will not be loaded as the interpolator will expect my.prefix.ENV_VAR instead.\nWe will fix archaius2, however as the fix is less clear right now we are doing this to be unblocked.\n. @deekshasharma the default id for eureka registration is the instanceId of the EC2 instance, however there is configuration available to customize the id so they are unique across your services. Are you registering by direct http POST? If you, you'll want to supply a custom instance_id field at the InstanceInfo level.\nSimilarly, the port field in the InstanceInfo is available to be customized with the port of your services.\n. \ud83d\udc4d . @mattnelson going into master\n. Hi @todoubaba we've never really tested eureka with non-ascii values in the metadata map. If you want to make a contribution to enable this, that would be much appreciated.\n. HI @vitosamson thanks for the issue, we'll take a look at the documentation.\n. Hi @yihukurama you may want to ask this question at https://github.com/spring-cloud/spring-cloud-netflix\n. Hi @william-tran some of the usage of the metadata such as these are driven by convention, so it depends somewhat on how you want to interpret this. In one scenario it might be used as a way to have a permissive server (I support both) and restrictive clients.\n. Thanks @hieurl \n. thanks @mattnelson \n. @elnur we do not use the Route53Binder at Netflix, and it was a component that contributed to us externally. The implementation as it is today may be specific to the contributor's internal needs. You can try to contact @aroger-r7 to discuss.\n. @elnur glad to hear that you have resolved your issue.\n. \ud83d\udc4d \n. @wanghongfei eureka server set up actually requires that you configure as peers all other available servers. So in your example, you would configure both B and C to be peers of A. I have updated the wiki page https://github.com/Netflix/eureka/wiki/Deploying-Eureka-Servers-in-EC2. Thanks.\n. @kalyanvgopal we've had some internal changes w.r.t. to eureka2, and do not have any time lines for open sourcing.\n. Hi @garakelian thank you for the issue. At Netflix, we try to guard against cases where a local eureka-client starts up without any registry information, as that can adversely affect the server performance. As such, we deliberately did not put in a lazy loading option within eureka-client.\n. @garakelian we welcome any PR that improves eureka from the community.. thanks @spencergibb \n. Thanks @klues fixed in #876. @spencergibb that is correct. We've done some major change to our approach, and the code that is currently in the 2.x branch can be considered archived.. @klues thanks for the contrib.. Thanks @qiukeren . @tianxiaoliang agree that the registration code path for eureka can probably be improved for higher TPS, however we have not had the need at Netflix to work on this.. @aserg it looks like your question is more pertinent to the spring-cloud-netflix usage of eureka. I would recommend that you ask your question at https://github.com/spring-cloud/spring-cloud-netflix . @eacdy your picture is correct. At Netflix our set up is to deploy several servers per zone, and all the servers in the region (across the zones) are peered together for redundancy.. Eureka uses a client side field within InstanceInfo lastDirtyTimestamp for conflict resolution. If you are using the java eureka-client, this should be taken care of already. However if you are using direct http calls, then for any client side updates that changes some InstanceInfo value (e.g. a POST or a PUT), it is recommended that an extra queryParam lastDirtyTimestamp=System.currentTimeMillis() be added.. @MarcP04 you can register multiple vipAddresses for a service, as long as they are comma delimited (e.g. vipAddress=vip1,vip2). In this way, you can use a strategy where your ServiceV1 register with vip vip1, and a newer deployment that also support the v2 api register with a vip of vip1,vip2.\nFrom a client side, clients that ask for vip1 will get servers for both older and newer deployments, whereas clients that want vip2 will only get the newer servers.. @xiaoerlyl you can, if you create your own implementation of EurekaClientConfig. You can then either use it directly, or create an override Guice binding to your own impl.. @VikramBPurohit I would advice not looking too deeply into eureka2. Per our wiki:\nThe 2.x branch is currently frozen as we have had some internal changes w.r.t. to eureka2, and do not have any time lines for open sourcing of the new changes.. Hi @brunobottazzini a Nebula update may also be required to get gradle 3.x to work for this project. Thanks.. @asarkar thanks for the question. I looked at the related issues on spring-cloud and it looks like you have found the answers you need.\nOut of curiosity, what versions of eureka are you running with? I read your blog (nice summary) and a few things with eureka/ribbon latencies have been improved recently.. @BenjenStark these branches are not meant to be merged. Thanks.. @erikgollot it is possible to create multiple eureka-clients within the same JVM (if you avoid using DI), and potentially you may then be able to configure these separate clients to connect to the two separate server groups.. @Milesy thank you for the issue. We can take a look at this, but definitely if you are able to get the appropriate approval for a contribution, that'll likely lead to a quicker turn around.. @klues thanks for raising this issue. What you describe make sense, however the reason it is this way today is primarily due to legacy reasons and unfortunately making large scale changes here would be difficult without breaking some level of backwards compatibility.. Thanks @RichiMueller . Thanks @spencergibb . Thanks @mattnelson . @sankarbalu eureka uniquely identifies a registering client via two keys, the instanceId and the appName. For your clients to be unique, you need to have at least one of these two be different between your clients.\nIt is possible to custom configure the instanceId of a client via config eureka.instanceId=<some id> (see https://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/appinfo/PropertyBasedInstanceConfigConstants.java#L11).. Closing old issue. Please re-open if necessary.. Hi @amit2103 by default, this is the behaviour. This can be changed via configuration eureka. shouldFilterOnlyUpInstances=false. (See https://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/discovery/DefaultEurekaClientConfig.java#L392). @Jaredjin your logs looks a bit strange, there are both registration and also unregistration logs mixed together. Are you in a shutdown sequence?\nAdditionally, looks like you are using spring cloud netflix, so you might also be able to get help here:\nhttps://github.com/spring-cloud/spring-cloud-netflix .. Closing old issue. Please re-open if necessary.. @magg how are you using loadbalancing? Most native uses of eureka uses the getInstances() -> List api which is not opinionated on loadbalancing.. Closing old issue. Please re-open if necessary.. Hi @rqw I believe some fixes for this has gone into the later eureka releases. I see that spring cloud netflix currently has an 1.3.* RC release out that has upgraded to the latest eureka client.. Hi @ericis @rqw this PR (#838) was released around eureka version 1.5.x and changes the log levels from error to warn in the cases of an executor shutdown. Are you still seeing the messages logged at an error level?. @mherlund eureka server replication protocol by default does replicate status overrides to all peers. Is this something you saw regularly, or a one off? Thanks.. @derTobsch do you mean for registration or data fetch?\nFor registration, rather than grace time, we prefer to control the registration state via eureka status.\nFor data fetch, we actually want to ensure that data is loaded in to the client at constructor time.\nThanks.. Closing old issue. Please reopen is necessary.. @imsandy are you calling the shutdown method in the client when you shutdown your service? The eureka servers have two ways of removing registered clients:\n1. eagerly if a shutdown is received.\n2. if a client does not heartbeat for 3 consecutive heartbeats, it is evicted. This case can happen if your service shutdown without calling shutdown on EurekaClient, and leave to a 90s delay.. @LXChild the java client contains a shutdown method that unregisters. This internally translates to an unregister REST call (https://github.com/Netflix/eureka/wiki/Eureka-REST-operations).. Closing old issue. Please reopen is necessary.. @applelight eureka server's resource requirements do ramp up as the number of connected clients in your environment increases, so it is hard to give you a good low limit. In practice, we've used EC2 m3.xlarge in smaller testing environments. These are 4cpu instances. For memory, I would recommend try to have a couple of GB.. Hi @kosurusekhar an you please verify the version numbers of your eureka-client and your deployed eureka servers? Thanks.. Hmm, let me take a look.... Hi. Apologies for not updating, this issue somehow dropped off our radar. We did take a look at this originally, but was not able to find anything unfortunately. We have not seem these kind of cases internally (though we are not using eureka via spring). \nIn general, the eureka-client logic is such that once a heartbeat request receives an 404, the client will attempt to re-register with the remote server, and this should happen every time a heartbeat fails. The heartbeat themselves will continue to happen at a 30s interval regardless of this success or fail. \nLooking at the eureka dependencies between Dalston.SR5 (eureka-client:1.6.2) and Edgeware.SR3 (eureka-client:1.7.2), these are clients that we still have internally and we have not seen issues with them so it seems unlikely this is a compatibility.\nTo verify, I can try to run a similar test as done by @cptstffn with our internal set up with the above two eureka-client versions and a custom server version at 1.7.2 to match Edgeware. I'll post back with results once I get some time to try that.\n@ryanjbaxter can you verify for me that the versions I have quoted are the correct versions as used by Edgeware.SR5 and Dalston.SR3? Thanks.\n. @cptstffn thank you for reporting back your findings, I'm glad to hear that your issue is resolved. To summarize:\n1. Per the original issue reported by @kosurusekhar, the answer posted by @goatherder provided an answer. It is possible that eureka server builds from many years ago may have incompatibilities with more modern clients, but we don't believe there are any incompatibilities between servers and clients released in the last 2 years at the least. \n2. Per the issue posted by @cptstffn that indicated a potential issue with eureka version between two differing spring cloud releases, this issue is now root caused as due to dependency exclusions on lower level artifacts.\nGiven the above, I am going to resolve this issue unless there are any additional questions remaining? Thanks.\n. Hi @kirillsablin , the next heartbeat will put the instance into either UP or DOWN, depending on what the registered healthcheck to the eureka-client is (if none, it should be UP).. HI @erdog looks like a code level fix is necessary here to enable https. We welcome any PRs for updates.. @pktippa for spring cloud packaging of eureka, please ask questions at https://github.com/spring-cloud/spring-cloud-netflix. thanks @ekesken . Thanks for the report @ekesken . We'll take a look into this .... Should be fixed in #946. Thanks for the PR @bistros . Hi @listaction for AWS features, please refer to AWS documentation. Thanks.. Hi @sameekb do you have other dependencies in you application that bumped jackson version 2.8.3? Jackson have a family of jars that need to be in sync with versions. . Hi @Dreampie at this point, we are going some other directions and is unlikely to support thrift unfortunately.. Hi @sameekb this question is better answered by the maintainers of https://github.com/apache/camel. @maximkir looks like the size of 3 for the top level schedule is a legacy of old client needs, and there really only need to be 2 threads (1 for cache refresh, 1 for heartbeat). The InstanceInfoReplicator function used to share the same pool (hence the size of 3) but that now has its own scheduler.\nAs the actual execution tasks are protected, there should be no need to make the pool size configurable and it should instead be set to 2. Was there some reason you found in your environment that prompted the need to make this pool size configurable? Thanks.. Thanks, done.. Hi @maximkir thanks for the PR, please see the comments/questions in the corresponding issue.. @maximkir thanks for the PR. Have fixed the client and added comments.. Hi @jebeaudet we internally deploy in a way that is a combination of your last two methods. We terminate the older instance without editing the TXT records (running sub-par) and bring up a new instance that assumes the vacated EIP once it is up.\nThis does generate some connection logs on the other eureka servers (clients have additional logic to mitigate even this) but eureka is designed to be resilient to running sub-par.\nPlease do note that we run a lot more than 2 servers internally. I would recommend at least 3 so when you are deploying, you are never down to just a single live server.. Hi @jebeaudet there are a few potential minor races that can occur when an eureka server has synced but has not assumed an EIP, and what you describe is plausible. There might also be stale registry data in the synced server as while it has not assumed the EIP, it is not receiving up to date replications.\nRe the other issue opened, we do our deployments by going sub-par first to avoid any races. We also run with more servers so when sub-par, we still have plenty of redundancy. The system is designed so that going sub-par temporarily is not an issue (as running in AWS, you can lose an instance at any time).. Thank you @macsj200 . Hi @jbaurchn thank you for the analysis. The usage here is not for security purposes. . Thanks @jebeaudet, taking a look .... Hi @jebeaudet apologies for the delayed response. This PR looks sound and makes logical sense, but I want to set up a quick test in our test env to test this out just to verify any potential unintended side effects. I'll let you know soon.. @jebeaudet prelim trial seems ok, though there were some weirdness. Will merge this and I'll also set up a config guard for a quick 'undo'. Thanks for the contrib!. Thanks for the PR @lqjack . I am going to close this and update to the latest nebula version. Appreciate the PR though.. @erudisch would you mind clarifying your question? When you say 'hostname', are you referring to the hostname of your registering application (including the eureka client), or the remote eureka server(s)?. Hi @multiplyzero a client can/should only connect to a single eureka server cluster. Can you clarify your question? Thanks.. @niuhp self preservation mode is only activated when a large percentage of services are potentially expiring at the same time (i.e. in a network partitioned scenario). By default, the configured percentage is 15%. It should not activate for single server expirations. The config to set the percentage is dynamically configurable at run time, so if you do run in to self preservation mode and need to end it for a legitimate reason, you can alway temporarily lower the percentage threshold as required. See https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/DefaultEurekaServerConfig.java#L221. Hi @wimnat this looks related to spring cloud Netflix. I would advise to ask questions at https://github.com/spring-cloud/spring-cloud-netflix. Thanks for the contrib @weswalker125 . Hi @divyanagrath this looks related to Spring Cloud Netflix. I would try to ask about it at https://github.com/spring-cloud/spring-cloud-netflix. Hi @lorgine I'm sure if I understand your issue? The documentation for the REST APIs are still accurate.. Thanks @wanggang1987 , this would be a bug.. @uttamanand I'm not sure I understand your question. What do you expect as an output from ./gradlew clean build?. @fahimfarookme that looks to be the case, thanks. This is likely a legacy of some optimisations elsewhere.. Hi @goatherder this is a bug that was fixed in #984  and released in 1.8.1. It will also be back-ported shortly to the 1.6.x branch.. In the meantime, using a suggested status value when deleting an override is one way to alleviate the issue.. Thanks, fixed.. @Lovett1991 thanks for the issue, will look to add documentation on batched replication.. Thanks @borlafu for the PR.. @dtrebbien thanks for the PR, we will take a look at this.. Looks good, thanks @dtrebbien .. @jingege thanks for the PR, that makes sense. I believe you still need to call scheduler.shutdown() before blocking on an awaitTermination however. See the last example at the ExecutorService javadoc. The phased shutdown example in the javadoc seems to be the right way to execute the shutdown, would you mind updating your PR to reflect that?\nAppreciate the PR, thanks.\nCopy pasting the javadoc here for relevance:\n```\nThe following method shuts down an ExecutorService in two phases, first by calling shutdown to reject incoming tasks, and then calling shutdownNow, if necessary, to cancel any lingering tasks:\nvoid shutdownAndAwaitTermination(ExecutorService pool) {\n   pool.shutdown(); // Disable new tasks from being submitted\n   try {\n     // Wait a while for existing tasks to terminate\n     if (!pool.awaitTermination(60, TimeUnit.SECONDS)) {\n       pool.shutdownNow(); // Cancel currently executing tasks\n       // Wait a while for tasks to respond to being cancelled\n       if (!pool.awaitTermination(60, TimeUnit.SECONDS))\n           System.err.println(\"Pool did not terminate\");\n     }\n   } catch (InterruptedException ie) {\n     // (Re-)Cancel if current thread also interrupted\n     pool.shutdownNow();\n     // Preserve interrupt status\n     Thread.currentThread().interrupt();\n   }\n }\n```. @jingege apologies for the late review, I have been away. Some minor comments.. Hi @mulderbaba thanks for the PR, and apologies for the late review. Some minor comments.. going to merge this and address the comments in a separate PR.. Closing as this is a spring cloud related issue. As an aside, the scenario described shouldn't occur, unless there is some async replication happening. One possibility for this to occur is mismatched server peer configuration where one server is configured to know about the peer, but the other server is not.. Looks like the question has been address on stackoverflow. Closing this issue. Please reopen if this continues to be an issue.. @WillieMatthewLiu This seem specific to nebula, you may be best served to ask the question at https://nebula-plugins.github.io/. Linked PR have been merged and should be released soon.. Closing as this is specific to spring cloud.. Unfortunately it was a while ago at release 1.4.11 (triggered due to PR #822, but not because of this PR). This issue mainly affects server side status override removals that does not specify a suggested status. The behaviour then will be:\n1. server side status is updated to UNKNOWN (with an updated dirty timestamp) and will force a re-registration from the client\n2. the client re-registers with an InstanceInfo that potentially has an older dirty timestamp.\n3. the server will disregard the re-registration and keep on using its local copy (the effect of PR #822), leading to an unchanged status of UNKNOWN (until the client refreshes at some point with an even later timestamp). Sure thing. Once we've validated this fix, I'll cut a patch based on release 1.7.0 (last pre java8 release). @spencergibb here's the diff (https://github.com/Netflix/eureka/compare/v1.7.0...v1.7.x). I'll cut 1.7.1 release this afternoon.. v1.7.1 is released with this fix on the 1.7.x branch.. Eureka client allows for customization of several parameters that may be able to help address this issue. I believe the solution outlined by @wangpenghit2155 executes an override of the (auto-discovered) system ip and port that is used for registration. Another potential way to address this is to set the override for the absolute url of the homepage: https://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/appinfo/EurekaInstanceConfig.java#L293\nClosing this issue for now. Please reopen if neither of the above solutions work.. @jasollien looks like you have resolved your issue. Closing this issue. Please re open if you need.. Hi @javanan this look specific to the spring cloud integration with eureka (this original project does not make use of spring). I would advice that you redirect your queries there (https://github.com/spring-cloud/spring-cloud-netflix). Thanks.. Hi @javanan your stack trace look related to the spring cloud integration with eureka. I would suggest that you redirect this question there. Thanks.. @angheladrianclaudiu the configuration eureka.eurekaserver.connectionIdleTimeoutInSeconds should allow you to configure a longer timeout if desired. This configuration is the native eureka config key and may be mapped to a slightly different name in spring cloud. It should be easily findable in the spring cloud documentation. Thanks.. Hi @lvc Thank you for the information, this look quite interesting. Appreciate the report.. Hi @YunaiV yes, this is handled by the underlying apache http client. Thanks for the issue.. Hi @igorbljahhin it looks like you have resolved your own issue? Please reopen if you have any more questions. Thanks.. @mattnelson we'll take a look. Thanks for the PR.. Hi @mekhaba unfortunately your issue look very specific to spring cloud, and I am not able to provide you much help here. I believe the spring cloud public documentation is quite detailed, and they are also active and helpful at https://github.com/spring-cloud/spring-cloud-netflix.\nThanks.. Merging this and addressing the PR comment in a separate PR.. Hi @odin-delrio thank you for raising the issue. I believe these exists for backward compatibility reasons only. If you think a more clear message should be present, we'd love a PR. Thanks again.. @jpedro the documentation is correct, however the wording is misleading. I have updated the documentation to \"Move instance back into service\". Thanks for the issue.. @LucasHCruz eureka should be able to handle that change dynamically, however since the configuration is proxied via springboot, I would double check with springboot that these are dynamically updatable. Thanks.. Hi @jwarder this is specific to springboot. Can you see if this documentation offers more clarity: http://cloud.spring.io/spring-cloud-static/spring-cloud.html#_peer_awareness.\nThanks.. Hi @karlwanghn you might need to update to a version of jackson that is greater than 2.3.2. Eureka currently comes with a jackson dependency of 2.8.7.. Thanks @holy12345 .. Hi @holy12345 we are probably going to look at some of the other outstanding PRs before a new release. This PR only adds a guard against misconfiguration (i.e. when the config value is specified incorrectly as > 1), and can be addressed for now by appropriately setting the config. Is there an urgent need for a release? Thanks.. @Harmoney-RogerParkinson apologies for taking so long to take a look at this, I have submitted a PR for the fix: #1033 .\nFrom the stack trace I suspect is is some race condition to do with checking the isShutdown flag that results in a null holder which then NPEs when metrics are computed from it.. Merged and will be released in the next release (should be soon). Hi I am not able to see any relation to jersey-apache-client4 from reading the CVE documentation:\nhttps://nvd.nist.gov/vuln/detail/CVE-2006-0550. Can you please elaborate? Thanks.. Hi, can you please add some additional details to describe your issue? Thanks. Thanks @holy12345 . Closing the issue as it is spring cloud Netflix specific.. @holy12345 thanks for the PR, you logic seems sound and there does seem to be an error in the code. Before I merge in your fix however, I'd appreciate it if you added a unit test that assert and validate the expected behaviour? Thanks.. Hi @holy12345 I do think your logic sounds correct. I would however appreciate if you added some unit tests in your PR to explicitly check for and verify the appropriate behaviour with the change. Thanks.. @holy12345 no worries, thanks.. Hi, we'd like to move away from using author tags as these can get confusing w.r.t. maintenance down the track. Otherwise, the PR looks good. Thanks.. No problem, thanks for the PR.. @abracadv8 thanks. Looks good.. Hi @basiths please check to see if this document help to address your questions:\nhttp://cloud.spring.io/spring-cloud-static/spring-cloud.html#_peer_awareness\nThanks.. Thanks for the contribution @Panmax . Hi @ex00 the java eureka client provides an event interface eurekaClient.registerEventListener that allows you to listen to eureka update events. Under the hood, the client/server communication is still poll based however.. Hi, you might want to take a look at CacheRefreshedEvent, which is generated each time the client receives an update. If you want to look into specifics however, you'll have to implement that logic when the event is triggered.. @dulimitta by default eureka client queries the EC2 metadata endpoint for system information. I have not used Fargate yet, but I suspect perhaps this endpoint is not available within Fargate. \nIf that is the case, instead of autoBuild(), you'll want to manually create the AmazonInfo object with system information provided in other ways.. Looks good, thanks for the contribution @tjuchniewicz . @mattnelson good catch, let me do that.. @mattnelson this work was for some internal refactoring that we needed. However after doing some testing the PR as it stands does not quite work for us and I will probably close this. Is this something you are interested in, or something you need?. @skyesx thanks for the PR, this looks quite reasonable. Out of curiosity is this something that you have ran into in a deployed setup?. Thanks @skyesx . Hi @Victoremepunto we don't maintain the javadoc html for eureka at that url any more unfortunately. The javadocs are still present on the interface and I have updated the link from the wiki page to point to that.. @SyCode7 I'm not sure I 100% understand your request, but I don't think we have anything in mind to support your exact request. What we do with our server framework internally, is that all applications start up in the STARTING state, and once ready, their UP/DOWN status is tied to the application's healthcheck state. This should offer similar functionality to what you request I think?. Hi @lovelivestyle1102 are you still running into this error? Thanks.. Hi is this the same problem as the (more general) issue described at #1039?. @fahimfarookme thanks for the data, we will take a look at this.. @YangGuang001 this seem more related to spring boot integration with eureka. Please try at https://github.com/spring-cloud/spring-cloud-netflix. Thanks.. @mgtriffid there were some changes a long time ago, if I remember, at least some of the changes involve moving to Jackson for json ser/deser and was probably around version 1.1.159. \nIn general, for server updates, we try not to introduce breaking changes between immediate minor versions. One thing you can try to upgrade your server, is to upgrade one minor version at a time (e.g. 1.1.x -> 1.2.x -> 1.3.x etc).. @wangzhenhua-bijie what version of the server are you running with?. @chendurex thank you for the report, this does look to be the case. We will take a look at this. . Hi @narenchoudhary before I answer the questions specifically, here's some high level information regarding heartbeats and evictions (based on default configs):\n1. instances are only evicted if they miss 3 consecutive heartbeats\n2. (most) heartbeats do not retry, they are best effort every 30s. The only time a heartbeat will retry is that if there is a threadlevel error on the heartbeating thread (i.e. Timeout or RejectedExecution), but this should be very rare.\nlet me try to answer your questions:\n- Are the sequences correct? If not, what did I miss?\nA: The sequences are correct, with the above clarifications\n- Is the assumption about eviction and registration scheduler correct?\n A: The eviction is handled by an internal scheduler. \n    The registration is processed by the handler thread for the registration request.\n- An instance of service#2 requests fresh registry copy from server right after ServerStep2.\n  - Will srv#1inst#1 be in the fresh registry copy, because it has not been evicted yet?\n    - If yes, will srv#1inst#1 be marked UP or DOWN?\nA: There are a few things here:\n  1. until the instance is actually evicted, it will be part of the result\n  2. eviction does not involve changing the instance's status, it merely removes the instance\n     from the registry\n  3. the server holds 30s caches of the state of the world, and it is this cache that's returned. \n     So the exact result as seem by the client, in an eviction scenario, still depends on when it\n     falls within the cache's update cycle.\n- The retry request from InstanceStep2 of srv#1inst#1 reaches server right after ServerStep2.\n  - Will there be an immediate change in registry?\n  - How that will affect the response to instance of service#2's request for fresh registry? How will it affect the eviction scheduler?\nA: again a few things:\n  1. When the actual eviction happen, we check each evictee's time to see if it is eligible to be evicted. \n     If an instance is able to renew its heartbeats before this event, then it is no longer a target for eviction.\n  2. The 3 events in question (evaluation of eviction eligibility at eviction time, updating the\n     heartbeat status of an instance, generation of the result to be returned to the read operations)\n     all happen asynchronously and their result will depend on the evaluation of the above\n     described criteria at execution time.\nPlease let me know if you still have more questions.. @ryanjbaxter. Hi @thinksky-sourcecode thank you for raising the issue. As you correctly state, the errors are transient at start up when multiple servers are being bootstrapped. Since the servers know a priori the hostnames of all of its peers (via config), and there is no guarantee on the order of server start up, it is somewhat difficult to know whether a server should avoid the exceptions at start up. If you have any good suggests, we welcome any PRs. Thanks.. @ravikancherla thanks for raising this issue. I followed your links and it looks like you have made a PR against servo that resolves this issue. Are you able to pin forward your servo version and achieve your goals?\nWe will look at updating the eureka dependency versions on servo to the latest soon.\n(On the matter of moving to spectator, that is something we wanted to look at but unfortunately is not at the top of our priorities at the moment).. @mengjiann the eureka client implementation have an internal resolver concept where it reads data about the eureka servers (via the standard eureka api) which is then used for failovers. You can take a look at this class for the actual implementation:\nhttps://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/discovery/shared/transport/decorator/RetryableEurekaHttpClient.java. To comment on this specifically for eureka, we are not moving away or deprecating eureka any time soon. Internally, we do have some extensions (e.g. a readonly replica tier) that we use, but these are extensions and not replacements for the existing system.\nThe open source future for our internal extensions are as yet uncertain, however if there are any active movement on that front, we will involve Spring Cloud in the discussion.. @wangwenyao I think your issue is similar to #1053. This has been resolved in merged PR #1054.. @ryanjbaxter that you for reporting this, this indeed looks to be an issue. I will take a look at making a fix for this.. @ryanjbaxter version 1.8.8 released with the fix.. Thanks @moxnet have merged in your PR.. Thanks @moxnet . @zjh-coder do you mean to add support for advertising rabbitmq brokers via eureka? . Thanks @LuanLouis . Your PR is merged.. @LuanLouis thanks for the fix.. Hi @jsntghf please see if this updated wiki document answers your question. Thanks.\nhttps://github.com/Netflix/eureka/wiki/Server-Self-Preservation-Mode. Thanks @narenchoudhary and @Sanisy for answering the question.. @mayras the reason this is done is documented at https://github.com/Netflix/eureka/issues/72 . That may no longer be a valid case, but would you mind commenting on what the issues you have seen with catching the Error here? Thanks.. Thanks @neoremind . I'm a little busy right now, but I'll try to take a look at this when I can.. @neoremind @holy12345 apologies on not being able to take a look at this, we have been swamped and have not had the bandwidth to work on this.\nTo answer your question about how we are using this, we are using the existing core logic as is, and have not had any issues with it as far as we can remember.. @neoremind have looked over your changes over the weekend, these look good, and I very much appreciate the test cases attached.\nI'll merge this and cut a new release.. Hi. Thanks for the questions, let me try to address these.\n1. How does eureka clients 'end' their registration lifecycle?\n - the eureka protocol requires clients to execute an explicit unregister action when they are permanently going away. For example, in the provided java client, this is done in the shutdown() method.\n - any clients that fails 3 consecutive heartbeats is considered to have an unclean termination, and will be evicted by the background eviction process.\n2. What happens when too many unclean terminations happen and trigger self preservations?\n - this is typically a rare case and we expect that this happen because of some failure mode. The expectation here is that once recovery has happened, the number of heartbeating clients will go back to be above the expected threshold and the servers will automatically recover from self preservation state. \n - if however this is expected (or after recovery the number of heartbeating clients does not go back to be above the threshold), you can force the servers to be out of self preservation mode by temporarily disabling self preservation. We would expect that in these cases, a human operation is available to evaluate the situation and take the appropriate action.. Hi @holy12345 this is not a feature we would need internally at Netflix (we use spinnaker for our needs), but we would be more than happy to support any PRs that add these features to the existing eureka dashboard.. I was wondering about that :(. Let me give it one last shot.. Thanks @spencergibb . Closing this issue.. It would be nice to have :).. Thanks @mgtriffid for the proposed solution, that would work. In effect what's required is for eureka servers to have an identity that it can match on. When using hostnames directly, this works, but not when servers are fronted by an ELB. The custom changes by @mgtriffid may be something that can be generalised into something that can work with both hostnames and custom UUIDs, and we would welcome such a PR for this project.. @tdanylchuk looks good, thanks for the contribution.. Hi. The 1.x branch of eureka still form the core of the service discovery ecosystem at Netflix and will continue to be maintained.. the 2.x work (on the 2.x branch) have been abandoned, but the 1.x branch of eureka still form the core of the service discovery ecosystem at Netflix and will continue to be maintained.. Hi, please note that The open source work on eureka 2.0 has been discontinued. The code base and artifacts that were released as part of the existing repository of work on the 2.x branch is considered use at your own risk.. @mgtriffid no worries, that was a minor issue. Thank you for the PR.. Looks good, thanks @holy12345 .. Looks good, thanks @holy12345 .. @holy12345 thanks for the PR. This looks good in theory, though I would like to get some additional verification on whether this is safe to do as removal of apps is not something that expected in current client behaviour. Can you please add some testing to verify? DiscoveryClientRegistryTest would be a good starting point for this. Thanks.. Looks good, thanks @holy12345 .. @mgtriffid thanks for the PR. We will take a look at this.. @mgtriffid I think @mattnelson raise some good points here about additional complexity that would be involved with this change. Does your deployment model support node specific configs? If so, the below strategy may be an easier way of achieving the same goal:\n1. introduce a config variable that can be set to override the isThisMe url that is checked at https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/cluster/PeerEurekaNodes.java#L246. Doing this eureka nodes can be configured to match on custom names that does not have to be the local hostname.\n2. in your deployment, set this config to be the ELB hostname that correspond to each node.. Thanks @mgtriffid , I retriggered the travis build.. build passes. Thanks @mgtriffid . @mgtriffid we should have a release out some time this week.. Hi @AlbertoImpl @holy12345 from an architectural pov, eureka is designed so that eureka servers being down is considered a disaster scenario. Having clients that can potentially stop trying to re-register is not an expected part of eureka client/server interaction.\n@AlbertoImpl is your use case here purely driven by the logs generated? If so, they can be turned of via the necessary log4j log level configuration.. Thanks for the PR @mgtriffid ! @brharrington do you have any thoughts to this?. Thanks for that @mgtriffid . Closing the PR per the comment updates.. @michael-pratt you are correct that the current implementation does not offer what you ask out of the box. We welcome community contributions if you would like to provide a PR for your functionality.. @ileler thank you for the PR. This looks fine, but would you mind adding some unit tests to verify both the existing and the future behaviour? Thanks.. @ileler thanks for the contrib!. Hi @mgtriffid thanks for the issue and the experiment! The algorithm to compute the full/delta hash code is pretty ancient and I would not be surprised if it has some false signals. In out internal set up (i.e. in the Java EurekaClient) the client just falls back to a full fetch (refresh global state) when it sees a hash mismatch, and this is acceptable to us as we don't look at each individual fetch request, but rather whether the data is consistent over (a relatively short period of) time.\nRelated, we also run a side app internally that continuously calculates the eventual data consistency between the servers.. PRs are definitely welcome. Internally, we have partitioned our eureka usage to a read/write set that allows the read cluster to autoscale.\nAs for the side server that does data diffing, it is just a simple app that periodically gets data from each eureka write server and publish some metrics after comparing the data. We use it to alert on data inconsistencies. Nothing fancy.. Hi @pparth we run eureka at much larger scales than 1500 instances (order of magnitude). There are a few things we do differently than the defaults in open source:\n1. we use G1GC which has given us much better GC characteristics compared to CMS\n2. we actually run an autoscalable readonly tier in front of our fixed host write cluster that take all the read traffic.. Hi @mattnelson the readonly server is not related to the Eureka2 work on the 2.x branch. That effort is abandon for various reasons, one being dependencies on projects that were never fully realised.\nWe do something pretty simple internally by basically taking the same eureka REST resources, put it in front of a guava cache, which in turn fronts a regular eureka client. This app then just registers with eureka as a regular app. (this app source code is not open source, but it is pretty straight forward).\nThe eureka transport client config contains some configuration to support such a model.\nFor example, set the following configs:\n```\nfalse == talk to readonly for query\neureka.transport.useBootstrapResolverForQuery=false\nthe vipAddress for the readonly cluster\neureka.transport.readClusterVip={some vip you've defined for the read only servers}\nthe vipAddress for the write cluster\neureka.transport.writeClusterVip={the vip address the write cluster register with}\n```. Thanks @mgtriffid . We will take a look.. Closing this issue as the fix has been merged in. @mgtriffid will cut a release as soon as the current round of PRs are resolved.. @rickywu @mgtriffid is correct. Information propagation through eureka is eventual consistent (up to 30s max latency by default).. Thanks @krutsko for the PR.. @mgtriffid thanks for the PR. I checked some statistics and the data serialization (in extreme p99.9+ cases) can be pretty heavy, beyond even a second. With a write lock around this, this means instance registration and updates will be unable to proceed for that duration, which can be problematic.\nSeems like the root issue here is the mutable InstanceInfo objects to be serialized. It might be worth doing a quick experiment to see which is cheaper: locking around the serialization or ensuring copies of the data is returned by the getApplicationDelta* methods.. Looks good, thanks @mgtriffid . Just want to verify with you that doing this is also able to solve your original issue?. @pparth we run with a readonly tier internally (same REST API -> cache -> EurekaClient ---> write servers), which due to its nature mitigated the original issue referenced in this PR.\n. The PR looks good, thank you @mgtriffid for the fix.. Sorry for the delayed response, and thanks for the detailed write up. I am also unsure to the reason why the calculation was done on the client rather than the registry, and found this PR from 2013 (!) that showed registry based calculations was possible at one point (https://github.com/Netflix/eureka/commit/4cd9c6e49c0151785bc0133c5e4b995d14191e96). I suspect that the registry is eventually not used due to the concurrent nature of accessing the server internal registry at scale.\nAs for your suggestion that we apply eureka.shouldFilterOnlyUpInstances=false as a default on the server side (and internally, we do run with that set to false too), that makes a lot of sense.. Thanks @mgtriffid . @rajgoothy Spring Cloud Netflix would be the best place to ask Spring Cloud integration specific questions. As a general comment, issues to do with the TimedSupervisorTask tasks are typically caused by initialization issues (e.g. bad start up config etc) and not typically related to the actual TimedSupervisorTask itself (which are just periodic background tasks that the eureka-client executes).. Hi @ksurent. The open source work on eureka 2.0 (as embodied by the 2.x branch) is discontinued. The rationale for this is variously due to dependencies on some parallel open source projects that never came to full fruition, and also the big bang nature of the project.\nThe majority of the motivations for eureka 2.0 is something that we (Netflix) still believe in, and have since realized internally. This is done in a much more evolutionary and incremental way, via variously:\n- a simple, auto-scalable REST readonly cluster with the same APIs to help with scale.\n- a simple, auto-scalable gRPC readonly cluster leveraging gRPC to provide streaming capabilities and better multi-language client support.. @mattnelson the changes you referenced were indeed client side updates to help with client auto-discovery of the REST readonly cluster. The server side code for the read only servers (both REST and gRPC) are both internal at the moment unfortunately. . Closing in favour or PR.. Thanks @krutsko . Thanks @holy12345. @jishamenon2207 we are happy to look at any PRs that can improve on the usability of eureka.. @jishamenon2207 The eureka dashboard code is super old, you can find them here:\nhttps://github.com/Netflix/eureka/tree/master/eureka-resources/src/main/resources/jsp. @jawitthuhn thanks for the PR, this does look like a bug. Given what the logic is trying express, it would make this code block much easier to read if we apply the below changes (and also add a test case):\nfor (String cname : ec2Urls) {\n            int beginIndex = cname.indexOf(\"ec2-\");\n            if (-1 < beginIndex) {  // contains \"ec2-\"\n                int endIndex = cname.indexOf(regionPhrase + \".compute\");\n                String eipStr = cname.substring(beginIndex + 4, endIndex);\n                String eip = eipStr.replaceAll(\"\\\\-\", \".\");\n                returnedUrls.add(eip);\n            } else {  // do nothing\n              // Handle case where there are no cnames containing \"ec2-\"\n              // Reasons include:\n              //  Systems without public addresses - purely attached to corp lan via AWS Direct Connect             \n              //  Use of EC2 network adapters that are attached to an instance after startup\n            }\n}\nWould you mind updating the PR? Thanks!. LGTM, thanks @mgtriffid .. Thanks @mgtriffid for providing the answer, that is exactly right.. @holy12345 releasing one now.. Eureka does not do paxos style consensus, so there is no need to deploy at odd numbers. Having said that, I would recommend 3 or more servers as a general rule of thumb. The reason being eureka server deployments will often bring you under par (i.e. to 2 available when running 3).. ship it!. cc-ing the current primary maintainers @elandau @troshko111 . That's a fair point. I actually had \"client\" in the name but later removed it because the auth also applies to server <-> server calls as well as client -> server.\nHow about just AbstractEurekaIdentify?\n. The configuration is actually on enabling/disabling the filter itself in case there are problems with too many filters on the request. Will rename to be more explicit.\n. Similar to the client one this is enabling/disabling the filter. Will rename.\n. We can. Having them separately is more explicit.\n. The logging filter will log it as unknown. The sending filter here should send null or empty data and shouldn't make the decision on whether a null is an unknown or anything else.\n. typo, AbstractEurekaIdentity\n. I wouldn't call a pessimistic:). In the eureka code base we already have a precedence of having on/off configuration for filters (StatusFilter).\n. Not a race if a given instance's lifecycle change in the registry is single threaded (which we can assume).\n. Agreed. Let me look into refactoring DeltaInstanceInfo with this abstraction.\n. We do. This is useful for comparisions between two instanceInfo objects that are logically the same, and is not for use to version the same instanceInfo objects.\n. Agree. The forDeltas methods here are stub implementations of ways to generate Changenotifications, which are probably not necessary as both Delta and DeltaInstanceInfo can be merged into an InstanceInfo directly by calling applyTo ()\n. Either name is fine with me. A complementary operation already exist in InstanceInfo called applyDelta(DeltaInstanceInfo). It is straight forward to add one that takes as a parameter Delta as well. \n. The problem we have here is that the data we want to push out via notifications (and receive on the client side) have different types (InstanceInfo, Delta, id String for delete). We can either abstract the data into Item as done here, or alternatively interface ChangeNotification and provide specific implementations for Add, Delete and Modify that understand their respective data types.\n. Using String here is an optimisation we should consider when we are sending a lot of deltas down the wire. Having to serialize an entire InstanceInfoField could be more expensive.\n. We would want to defer calculations away from the registry. Since update changes are now driven from the input channel, we should remove this helper method and move this logic to the channel level.\n. Can we default the PrivilegedClients to EurekaServerIdentity.DEFAULT_SERVER_NAME and EurekaClientIdentity.DEFAULT_CLIENT_NAME? Otherwise, the rateLimiter won't work \"out of the box\" without the appropriate configurations set.\n. Oh I see that you had the default clients defined separately in the actual filter. Having them as defaults in the configuration instead of separate hard coded keys would allow us to be more flexible with the configuration.\n. Java's ConcurrentLinkedDeque (and Queue) does not provide constant time and strongly consistent size() and each call will cause a traversal of the deque.\nSince we are locking anyway, and the normal operation of the RateLimiter will involve the locked portion of the code, we can extend the lock to include the if. We can then switch to using a straight LinkedList.\n. I don't have too strong an opinion about this so either way works for me:).\n. That looks like a merge artifact, will add it back.\n. It is. Most of the time the work should be a queue.poll() and a task != null check. How optimized is the computation scheduler in rx? If a tight loop is expensive we can add a delay for each iteration.\n. The changes here breaks the expected behaviour of flatten, as the internal interests of a MultipleInterest can also be MultipleInterests\n. The channel returns the actual stream from the transport, whereas we want to return here the stream from the underlying actual registry. We should ignoreAllElements for this stream and concat the return with currentState.registry.forInterest(interest).\nIn fact the register operation on the InterestChannel on both the client and the server does not need to return the change notification stream, we should change the InterestChannel interface of register to return Observable to denote just the success/failure of creating the initial channel.\n. The write() contract returns an Observable. Is this ever subscribed to? If not, we could just return void.\nWe should also ensure that the audit service is never blocking.\n. Can we use the static finals from EurekaTransports.java here instead of magic numbers?\n. ApplicationsResource also allows calls of the format /apps/{appId} for specific applications, we would want to cover this Target type here too. If we don't want to introduce more Target types it could roll up into FullFetch.\n. That makes sense too. We did add a feature to the client recently that allows clients to be configured to change it's periodic fetch from a full_all/delta_all pattern to be always full_single_app, so I just don't want this feature to become a backdoor to get around the rateLimiter.\n. Originally we made a design decision to block at the registry level. We may want to plumb this Observable all way to the channels, but for that we should at least think a bit more about whether that will affect other parts of our design. (See TODO item just above this line).\n. +1 on that.\n. Perhaps rename these as the specific modes are Registration, Interest and RegistrationAndInterest\n. Can we add a default constructor that uses a sensible default Scheduler as well?\n. also set InstanceInfo to null here?\n. typo\n. While we are streaming in the change notifications to the new registry, and before we execute the swap, we can also stream the same notifications to the old registry so that clients see fresher data. This can help in cases where the swap condition does not get met for a long enough time.\n. Can we add a test case where we ensure no reconnects are attempted after a close() is called?\n. Can you please remove the static here? The ClientConfig instance is a singleton so should function fine as an instance variable. The *XStream classes are also used on the server side and we have seen cases where statics can cause bootstrapping issues (#214).\n. Same as the comment in JSONXStream.java, please make this an instance variable.\n. Good point, I'll remove this.\n. It seems with all the recent refactoring the change() method is now only really used on the server side (where we get serialization for free), whereas on the client side it is only used by appendInterest and removeInterest methods in InterestChannelImpl internally. Rather than implementing it directly for RetryableInterestChannel, we should just throw an UnsupportedException.\n. the onComplete() for appendInterest and removeInterest where these actions is not guarded by the serializedTaskInvoker, so createAppendInterestAction and createRemoteInterestAction can potentially execute in parallel. We should revert back to the AtomicInteger version for the refCount inc/dec.\n. We should use doOnUnsubscribe here. When a stream from a forInterest() call is unsubscribed by the calling entity, we should decrement the removed interest's refCount until it is at zero, at which time we unsubscribe to it from the channel level (do the actual removeInterest at InterestChannelImpl).\n. We need to figure out the exact replication protocol for cases such as these. For example, if the sender reconnects and sends a Hello but the receiver is in state Opened already (due to a bug say), then we have a leaked receiver channel that is stuck with opened resources. We should close and remove the receiver channel after returning errors on the channel to the sender, as we are guaranteed that the sender will retry (and hence a new receiver channel will be created).\n. We don't make use of versioning on the write server/replication side. Let's remove it for now and we can add it back if needed later.\n. fixed\n. This naming makes more sense. Can you also change the corresponding method name for InterestChannel from \"change()\" to \"forInterest()\" as well?\n. What is the state diagram for the snapshot request? The previous line sets the state to Closed but the metric transition only moves from Idle to Open.\n. You can merged the doOnNext() here into the map()\n. What happens if the ack here onErrors?\n. Shouldn't this onErrorResumeNext() be before the flatMap()?\n. Will fix this\n. It's preferable that we do retries for client side unregister failures instead of just walking away from the connection. Otherwise, the instance will be unregistered via the eviction mechanism which can be slow.\n. Not easily, there's a few layers of plumbing that we might need to do. The latch here executes very quickly as the underlying channels are mocked and just returns Observable.empty().\n. the refCount() calls connect().\n. No\n. Currently, sendErrorOnTransport() closes the channel implicitly so this is the current behaviour. We should discuss whether we want this to be the standard behaviour on all the channels however.\n. This code assumes single threaded calls of addNotification(). Are we guaranteed that?\n. This comment is outdated now that this is in a separate method. Are we only ever allowed to drainBuffer() as part of resume or if we are not currently paused? Can we add a comment here to details these restrictions?\n. With the latest changes the subscribe operator should not reorder them if they are declared in order.\n. I deliberately tried to avoid test code in the client so we can re-use it as a standalone elsewhere.\n. We can do Observable.from(list).interval()\n. Yeah not needed. I think this might have been autocomplete.\n. The Ocelli version is nicer, but we don't want to have dependency on ocelli for all the packages that needs retry. It feels like this is something useful to put in a more basic layer (rxjava/rxnetty)\n. What is the contract for the return of this method? If we are already at the state that we are trying to move to, it could be said that the moveToState is successful (i.e. true).\n. Why not just use the enum available in Source.Origin directly here?\n. Why commented out?\n. Should use the server string instead of \"server\" here.\n. How does this work with the (now) overridden moveToState in the specific channelImpls?\n. It's in a separate class for clearer organisation. If we added it to the write test class chances are someone in the future might see the \"missing\" complementary test in the read class and add a read version back, which will then get us back to the same problem as now.\n. Back to Idle or to Closed?\n. Is it possible for the handshake processing to fail? If so, this channel will be stuck in state handshake and have no transition out. We should either let handshake -> handshake to be valid or better yet, close this channel if the handshake fails so we can retry.\n. With this line replacing all the metrics.incrementStateCount(Idle) lines in the concrete classes' constructors and the metric less moveToState(STATE to) option, can we possibly lose metrics when channels are created and are then immediately closed via a call to moveToState(Closed)?\n. Do we have verification tests to ensure that onComplete and onError terminates will trigger the proper shutdown and send the correct onComplete or onError on the lifecycle observable?\n. I see. But shouldn't we let unregisters be best effort? Server side we are ok with best effort unregisters, and we would not want a bad unregister to block server shutdown.\n. the typical pattern for shutdown overrides are \nvoid shutdown() {\n   // do child shutdown\n   super.shutdown().\n}\nIn this case we want the cleanUp action to happen after the super.shutdown(), so this is a safer pattern.\n. fixed\n. changed\n. Yep. Going forward the RegistrationResult object should be what will be exposed to users.\n. The combineLatest does not compose without this.\n. For the interest side, since all interest subscriptions share the same underlying channel, it makes more sense to have final channel failures propagate the error to the registry, and then have the registry onError the clients.\n. Ahh yes. This TestChannelFactory was created before that one. Indeed they can be merged. Will do that in a separate pull.\n. nullary and unary are pretty standard mathematical names for operand sizes: http://en.wikipedia.org/wiki/Arity.\n. This is intended as a realtime task as it need to sync with some other steps in the test. It'll be difficult to do as a testScheduler unfortunately.\n. the abstract executeOnChannel() functionality is now provide as a func1/func2 that are passed in, so RetryableConnectionFactory is no longer abstract.\n. For consistency can we reference them as EurekaV2 and EurekaV1?\n. Will fix.\n. Good suggestion\n. There are only two variables right now. We can add a builder if this config grows in the future.\n. We should still be able to do so, the config just provides a way to specify the codec and defaults to avro, it does not force it to avro.\n. The ReceiverReplicationChannel handles the receiver channel eviction without calling registry level eviction methods.\n. Can we change the name here? This is pretty confusing from an rx perspective as in rx we subscribe to observables but the API here inverts that.\n. A bit pedantic, can we shorten the name here to something like Buffer and EndBuffer?\n. Can we shorten this a bit, maybe just BufferSentinel?\n. maybe NonDataNotificationFilter or DataOnlyFilter as we may introduce other types of metadata markers in the future?\n. again just BufferState and EndBuffer?\n. Minor convention, can we have the params be indexRegistry, metricsFactory, Scheduler in that order?\n. errant semicolon\n. Why change this to 1, 1? Part of this cluster wide integration test was to have replication also in play, and this loses that.\n. Instead of map.filterNull can we not just use the special filter already created for this purposes?\n. It's hard to diff here, is this just a renamed NotificationsSubject (nice name change btw) or are there code changes as well?\n. println\n. Since there is ever only one channelInterestStream, we should be able to attach it to the remoteBatchingRegistry when the channelInterestStream is created in the constructor and not need to reattach it each time we do a change().\n. shutdown for batchingRegistryAlso?\n. shutdown for batchingRegistryAlso?\n. can we use the standard DataOnlyFilter here?\n. we can achieve this here with\njava\n                .filter(new Func1<Boolean, Boolean>() {\n                    @Override\n                    public Boolean call(Boolean batching) {\n                        return batching;\n                    }\n                })\n                .map(new Func1<Boolean, ChangeNotification<T>>() {\n                    @Override\n                    public InstanceInfo.Status call(Boolean batchingTrue) {\n                        return FINISH_BATCHING_NOTIFICATION;\n                    }\n                });\nwhich is cheaper than using flatmap.\n. You'll need to do finishBatchingObservable.mergeWith(dataNotifications).subscribe(resultSubject) here.\n. we can map here rather than flatmap\n. need to handle and propagate Kind.onCompleted.\n. Would it be more clean here to instead do\njava\nnotifications.filter( return notification instanceof StreamStateNotification))\n                   .map(interestsBufferingState.put(stateNotification.getInterest(), stateNotification.getBufferingState());\n                             return true;\n                           )\n. This error handling here and the onCompleted .clear() are a bit confusing. What are the clean up actions for onError and onCompleted and are they different?\n. We don't seem to care about the true/false emits of the updatesSubject, just that each emit is a \"tick\". Why bother emit a boolean then in the updatesSubject? Can we just make it simpler and ignore the boolean logic?\n. need to handle catch (Exception e) { subscriber.onError(e); } Maybe we can restructure the Ob.create() here to\njava\nObservable.just(updatesSubject)\n    .switchMap(new Func1<PausableSubject, Observable<BufferingState>>() {\n        public Observable<BufferingState> call(PausableSubject subject) {\n            // do logic\n        }\n    }\n. Description is same as test above. What is the actual intended behaviour?\n. All the test cases send and verifies with waits between sending remote/local states. None of these seem to test cases when merging of local and remote states and what the final batching hint should be. Should that be tested also?\n. I think we are missing tests for the following cases:\n- onError and onCompleted cases for the attached data stream\n- behaviours for reconnecting data streams (this will be a common occurrence)\n- case tests for the many different cases of shouldBatch\n- shutdown cleanup test\n. We should also add tests for:\n- shutdown and cleanup\n- handling of onError and onCompleted cases for the batchHintStream\n- handling of onError and onCompleted cases for the dataStream\n. I think that is the case only for using operators. If we do an Observable.create, we'll need to be explicit on calling subscriber.onCompleted() and subscriber.onError(). Per the doc for .create:\nWrite this function so that it behaves as an Observable \u2014 by calling the observer\u2019s onNext, onError, and onCompleted methods appropriately.\nA well-formed finite Observable must attempt to call either the observer\u2019s onCompleted method exactly once or its onError method exactly once, and must not thereafter attempt to call any of the observer\u2019s other methods.\n. Why do we need to try catch here? It's all rx so the doOnTerminate (we can be even safer with a finallyDo) should handle the client closure.\n. the withMetricFactory overload seems confusing, we can be more specific with the type of metric factories?\n. At part of the client reorganisation, the final EurekaClient should be provided as a wrapper of both a RegistrationClient and an InterestClient. When that is available, we can just use a raw InterestClient here.\n. What is the contract for this operations if we received two successive BufferSentinels from the stream? Should we emit empty lists or emit nothing (what the code seem to do right now)? We should document the expected behaviour in this case.\n. Can we add an extra test here to validate that a third batch that does not change the snapshot == no emits?\n. Good point, moved to com.netflix.eureka2\n. Make sense.\n. Sure. Also, these should be package private.\n. I think at one time we may have queried the WriteSelfRegService for it's source, but looks like that dependency is gone now, so this can be removed.\n. added doc\n. added doc\n. The caller need to subscribe() to the request to initiate the registration, so it makes more sense for this to be top layer observable.\n. Are these the best fields for caching? IP for example would be pretty unique for all instances.\n. The original intent for having these in the constructor was to ensure that they are not multi-subscribed to, and also that they are always eagerly subscribed to. Moving these to methods in the abstract client allows breakage of the above assumptions for future implementors. From what I can see the two implementing clients always call\njava\nregistryEvictionSubscribe(retryableConnection);\nlifecycleSubscribe(retryableConnection);\nanyway in the constructor, so can we just move this block to the constructor for the new Abstract class instead of making them methods?\n. can just do an addAll(buffer) here\n. So the change in behaviour here is that the read registry will always buffer inbetween each BufferSentinel? Would be good to document the expected behaviour here.\n. Seems like the standard InterestClient should be able to be used for the same purpose as this special client, as long as we do an eager forInterest(FullRegistryInterest) from the ReadRegistry?\n. sure\n. This is a somewhat misleading match specific to the holder, which is why it is here as a private method. The Source class already have matcher methods that does similar with a more sensible API.\n. Unfortunately this is not trivial unless we override Source's equals and hashcode to ignore the id, which come with its own set of issues. The whole ordering of the copies is just an optimisation anyway, so I see no strong need for it to be enforced.\n. updated comment\n. We can use a treeMap, but we'd still have to override Source's equals and hashcode to ignore id.\n. Is concurrency control important here? There is still no concurrency guard against two threads that execute in the following order:\nThread1__Thread2\nS1 -> S2_\n__S2 -> S3\n__onNext S3\nonNext S2          \n. typo\n. Per our discussion, we should not mark servers as DOWN even when they are in selfPreservation. Otherwise we may redirect all traffic to a (possibly) much smaller set of UP servers and take them down.\n. Do you want distinct or distinctUntilChanged?\n. Would we subscribe each time we call handle here?\n. can this assert be equals to prev client read size?\n. Can we prefix this with Test* to ensure it's use is for testing purposes?\n. Can we express the state machine for this function in the comments above? This will help clarify the exact combine algorithm.\n. maybe use a switch(state) here? That way we can better express the state machine.\n. why secureVip?\n. Are these functions just moved over from ChangeNotificationFunctions.java or are they changed as well?\n. Again secureVip? Do you mean instanceId?\n. Can we standardise our naming here? we refer to 2.0 as eureka2 (no \"x\"), but then refer to eureka1 as eureka1x. May be more clear to change eureka1x to eureka1.\n. More a question on implementation, do they all a \"default\" type handle so that if we do add new serverTypes in the future we won't need to change code for all current server types?\n. Can we make this ROOT_PATH configurable? E.g. for backwards compatibility it does not align with current eureka1 root path.\n. Do we have the choice here to redirect to either public or private ips? (For running in AWS Classic).\n. remove public?\n. Does this mean that all the sub classes all have their individual subscriptions to the eureka2 registry? Would that introduce synchronisation differences between the different views? What about just having a single converter that converts from eureka2 registry interest to a eureka1 registry (store in app groups) at a regular interval, then feel all queries from there?\n. remove first from map then call unregister for better synchronisation\n. for this case we may want to do an unregister (from old) and re-register (with new).\n. \"Server\" in our terminology implies hostname + port and I wanted to avoid that implication, hence \"HostResolver\".\n. good catch\n. done\n. I had that originally but add these optimisations later. It does make sense to keep the API cleaner, removed.\n. It's just a mathematical formula so is provable that the result will be in the range of [lifecycleDuration/2, lifecycleDuration + lifecycleDuration/2]. As well, the random nature of the method make it hard to write an fixed unit test.\n. we need to merge here instead of concat (which would be Ob.from(init).concatWith(realTimeSubject) ) as we need to ensure that the realTimeSubject is subscribed to before resume() is called on it. Otherwise, we would lose buffered messages that are stored while paused.\n. Agree on that. Since this is a pretty central component the rewrite need to take a bit more care. As it stands right now, it works well enough for the RC1 release.\n. Why not just make the static comparator public?\n. Why toBlocking here? Also, if the timeout occurs and there is no element returned, this would result in an NPE?\n. Why not inititalize this hot or just use synchronized? This seems more complex than needed.\n. Are all the layers of aggregateChanges and collapse necessary? It seems emitAndAggregateChanges() is the only function actually used externally.\n. If these are to be public API functions, then please make sure that they have more descriptive names and better java doc (especially the differences between the many flavours of functions that currently have the same name).\n. Can we add a guard to ensure only data notifications are processed?\n. For item A the modify here is not really tested as there is no real data modification, so collapse for meaningful modifies are not actually tested. Can we explicitly test for that?\n. Are there any NPE potential here? Also, instead of doing a materialize().toList(), can't we just do a\njava\nfindInstance()\n                .filter(new Func1<InstanceInfo, Boolean>() {\n                    @Override\n                    public Boolean call(InstanceInfo instanceInfo) {\n                        // find and return true for the instance.\n                    }\n                })\n                .materialize()\n                .map(new Func1<Notification<InstanceInfo>, Void>() {\n                    @Override\n                    public Void call(Notification<InstanceInfo> instanceInfoNotification) {\n                        // check for the different cases and do appropriate returns\n                        return null;\n                    }\n                })\n                .take(1);\n. I think .replay(1).share() can work here too without having to use a subject.\n. We should be able to get all the non-fullFetch variants (app, vip etc) just by going to the fullFetchView, and not need to cache.\n. Is there a modify equivalent of this test (or is that tested together with one of the current testcases?)\n. see change to toEureka1xInstanceInfo() which catches exceptions during conversion and returns null.\n. karyon-admin brings in jettison 1.1, which does not work with serializing v1.Applications. (http://jettison.codehaus.org/)\n. Remove the reference to Netflix and use a more generic header name?\n. Minor race here, as lastRedirect.get() may change in between the two calls. Can cache it locally first by String serviceUrl = lastRedirect.get() before the if statement.\n. Can eurekaServiceUrls be null here?\n. is eurekaServiceUrls.get() nullable?\n. Can we add some comments on why the jerseyClient's redirects are explicitly turned off? Otherwise it may be confusing for future maintainers.\n. What happens if the latch does not count down after the timeout (i..e. the first batch is still empty)? Since legacy code does not do well with an empty list, is a null return or an exception better here?\n. Can we have this as a second constructor option?\n. With this gone, should this class still be abstract?\n. be nice to have javadoc here to specify the expected string format for hostnameAndPorts\n. These statics seems redundant as we have a factory class EurekaEndpointResolvers that provides the same functionality.\n. Seems like we should have some more logic here that ties in the realtime server health status to whether we should server interest data. Whenever the server status changes to not be UP (which may happen outside of bootstrap time) we should also stop serving interest data.\n. Can we change our code pattern to always explicitly check for all cases and defaults to some sort of breaking error? Treating default as a specific valid case can potentially lead to missed updates when an enum is added for example, and thus lead to non-deterministic behaviour.\n. This whole block doesn't seem to do any heavy lifting, why not just move this to the constructor?\n. Nitpick, peer in the name here assumes bootstrapping from peer write nodes, whereas we can bootstrap from any arbitrary eureka source based on configuration.\n. This here seems to be doing almost exactly what the FullFetchInterestClient does for the read servers. Can we not reuse the FullFetchInterestClient and pass it the write server's registry?\n. Let's do this and add it to write server config:)\n. The comment mentioned retrying on another server but I can't find any .retry() in the code?\n. Would be nice to have additional tests to cover:\n- bootstrap fail on first source but succeeds on subsequent source\n. Doing the modulo on the atomicInt value and then setting it means the op will no longer be atomic, in this case I guess it doesn't matter that much as concurrent usage is unlikely, but I'd like to avoid it still. How about changing it to AtomicLong instead.\n. We still need the warmup time as a cap on the time to wait for the initial case when there are no data from the serverSource.\n. Actually even if the atomicInt overflows we are still good, so no need to change this here.\n. Done\n. Is this threadsafe? Seems like this can be called by multiple observable chains concurrently here.\n. Let's guard this with an atomic state boolean to observe the rx contract and not call onCompleted more than once.\n. If this is purely for testing purposes, it might be useful to define a counting id in the client, and append the counting id to the end of this to differentiate between channel generations.\n. Good catch!\n. Can we change this to not use reflection and avoid the performance penalty?\n. By id I meant as an append to the clientName, since we can have multiple generations of MessageConnection per client.\n. Again change from using reflection?\n. How about change all the default client names to something like client(InterestClient, FullFetchClient).class.getSimpleName()? That way they can be nice and programmatic.\n. Good catch\n. Actually most of Eureka (1.0) is at Java6, and since it has some pretty old users it would be nice to keep it that way.\n. We'd have to mock a few different configs. This also allows us to test the actual config bindings. The test runs pretty fast even with the archaius singleton.\n. Agreed. But let's do this in a separate pull and not conflate the current changes.\n. That's true, it could be. It was mostly because this was just a transport of the method from the client.\n. The accountId metadata field was added to eureka-client relatively recently, so for backwards compatibility, it is possible in existing deployments to have older clients that do not register this field. This will return null here and cause an NPE upstream. Can you please add a null check here and let it fall through instead?\n. Can you make the role name (ListAutoScalingGroups) a configurable parameter? You can add it as a config param to EurekaServerConfig/DefaultEurekaServerConfig with this as the default.\n. Good point. It should not be fatal in this case, as we still have the (guarded) heartbeat thread that will enforce re-registration for dirty instanceInfo (server side we check the lastDirtyTimestamp) if this thread is hanging on the network. This just means updates will be periodic as opposed to on-demand during the hangs until the hangs end.\n. How much change is this from the original InstanceRegistry?\n. Was there any logic changes other than the interface refactoring?\n. The 1s sleeps here are explicit to allow the operations to go through without getting rateLimited (contrast with the @ Test below). May be able to shorten the longer sleeps though by making the replication interval even tighter than 10s.\n. This is just for the example project so that we can actually see logs (cient dependency is on slf4j-api);\n. Yes it is:). But cleaning up the statics (there are many others) should be a separate task so as not to conflate the pull requests.\n. the InstanceInfo should contain the appName and id, so no need to pass these as params.\nSame for statusUpdate() and deleteStatusOverride()\n. Can we move these peer specific code to a server implementation of this class? If we can break these out, it would be nice to refactor DiscoveryClient with this class.\n. see issue #533. This is to align servo reporting logic with actual selfPreservation logic.\n. @brenuart there are subtle differences in the two, so it would not be a trivial replacement.\n. In actual implementation yes, but this is not enforced by the current InterestChannel contract. Going forward I propose we have all the channel interfaces extend the Sourced interface.\n. Trigger happy autocomplete. Fixed.\n. Legacy code not removed. Gone.\n. In a previous iteration this was different. Removed.\n. As part of this pull InterestChannel have a new API getChangeNotificationStream(). On the server side this is bridged to the Multiplexer's changeNotifications so even though we don't subscribe to this stream more than once, this share() is to guard against that per the new contract.\n. Can we avoid using this if possible? This is still @ Experimental in rxJava.\n. close(exception)?\n. This new test doesn't seem to cover all the cases that the old test covers?\n. Can we use the fields in the com.netflix.eureka2.Names class here instead of strings? (Also the same in the Module binding).\n. Can we use a different name than Provider here? It conflates with Guice Provider<>.\n. on line 78 distinctUntilChanged instead of distinct?\n. @ Experimental method, can we avoid?\n. The returned result here is the chained result of registrationProcessor.register, whereas for update and unregister we have separate observables. What instead of setting up the initial registration processor in the first register, we do the set up independently and then can just use the same code as in registrationUpdate() for both the initial register and subsequent updates?\n. thanks, fixed.\n. Agree. Did some of the that but there are still more we can consolidate here.\n. It's not. In the interest channel version (from which this was copied) it was needed.\n. Good point. This is a bug. Fixing.\n. There seemed to be some issues with these test when run together (one of them fails, but both passes fine when run independently). This points to resource clean up issues and this try finally fixes this.\n. There is an upstream change where we install(EurekaModule) instead of just binding DiscoveryClient, which necessitates this here.\n. We have a circular injection issues between the resolver, the TcpHanders and the TcpServers which necessitates the providers.\n. With governator 1.7 we can @ Inject LifecycleManager and then add a listener for onStarted(). Changing this to avoid needing @ PostInject all together.\n. habit:)\n. See earlier comment on circular injections\n. Agree. This is currently in an awkward place here but it's also slightly different in that it's not strictly for the eureka transport layer. Some small reorg of the transport and the codecs may be necessary.\n. It's not strictly the instanceId (in that EC2 instance sense). The id is the id of the InstanceInfo, which is uniquely identifiable in ec2 or in containers etc. Will rename to instanceInfoId.\n. If the PutObjectResult is returned, then the file is created. Failed putObject() will exception (which is caught at an upper layer).\n. Yes. I'm going to take a look at the other pull but there'll need to be a way to merge the ASG strategy and this one.\n. Good catch. Should eagerly update the local map here if the underlying put to the external store is successful.\n. This is legacy from the earlier pull when we still had the Overrides datastructure. Should be removed.\n. In this case for the S3 specific use case we need to have some S3 specific properties (bucketName and prefix). It extends AwsConfiguration.\n. We had specific bindings for override stuff that breaks the write server when removed. What we need is some no-op bindings.\n. Add a sensible prefix to this config?\n. woop. Yeah I was testing locally. Thanks for spotting!\n. Agree. The public REST API current does not care about codecs, but takes a X-Eureka-Accept header. DiscoveryClient (for now, during the transition) translates between the specified decoder and the appropriate X-Eureka-Accept (translation in EurekaAccept.java)\n. Either way works. Once we move beyond the transitions phase and deprecate the older codecs, the wrappers can be removed and the actual codec classes be moved to implement the Encoder and Decoder interface.\n. eureka (1.x) has a weird structure where eureka-client is the base module. eureka-core is really for server side only.\n. move this to the super class and then both can reference it instead of having a magic \"eureka\" in EurekaArchaius2InstanceConfig?\n. use namespace instead of \"eureka\".\n. use namespace instead of DEFAULT\n. why remove the singleton check?\n. The PeerEurekaNodes on the server side also uses this method, so it should really not be dependent on EurekaClient for this functionality. Moving it to EndpointUtils was just a convenient way of moving this out of the client side interface. Feel free to enhance this to as part of the transport work.\n. Good point. I think we do need an abstraction over our codecs, as even when we standardize on a single codec in the future, there needs to be a way to add additional codecs for extension purposes.\nThe APIs as they exist today are pretty bare and generic. We can always add additional ones in the future as needed.\n. This code has always been here ... But a good point on what the correct action should be here. As this is code that has worked well for a long time now, let's not change it immediately without doing some more testing.\n. Agree with the logic placement. The comment was more of a \"comment\" on the structure of the interfaces (e.g. the non-peer aware registry should not understand replication). Unfortunately we are stuck with some of this without doing major surgery.\n. I buy that.\n. Yes, because the cache needs a reference to the registry unfortunately.\n. I agree. But we can fix this in the next round of refactoring.\n. indeed. Thanks.\n. Thanks. Forgot to move it.\n. Urg must have forgotten to do this last time I added the test class.\n. If it at the class level then it'll need to be propagated all the way up to the PeerAwareRegistry, which gets messy. I'm not happy with the way either. Maybe this is over wrapping it and we should just let class Key be part of the interface.\n. The initial purpose of adding this was to aid in the migration of legacy codecs to new codecs, with the ability to switch between codecs quickly (without having rebuild and redeploy) for compatibility purposes. In the case of the Jackson json codecs for example, the two codecs does not actually have any dependency differences (both use jackson), but they handle the encode and decode differently. \n. add a comment about why this is necessary?\n. nvm saw it was commented on later.\n. I can imaging potential future cases where we may have multiple different compact types. As this is exposed as public API, can we change this from a boolean to a more flexible type?\n. It's in a public constructor and there are already cases of extensions of the Codec classes.\n. The else here assumes xml. This code will do funny stuff if other mediaTypes are supported in the future. How about if(json)elseif(xml)else(rawString) instead?\n. Can probably move the myZone initialization into createStandardClient, since it already takes clientConfig and appInfoManager as params.\n. This Endpoint class seems pretty aws specific (references to zones etc). Can we interface this and then move the aws specific implementations of endpoint + resolver into a .aws package?\n. Wouldn't this potentially resolve to and cache private hostnames in an aws environment?\n. Can this block?\n. the transportUtils method already keeps track of the client in an AtomicRef. There is no need to check again here.\n. Typos?\n. why use the static and not the configurable value?\n. Somewhat paranoid. Are we sure the regex does all the right things w.r.t. the rfcs? Creating a new URI is not so expensive, and we know that it does the right thing underneath.\n. The ids here should be a concat of appName + instanceId as their combination uniquely identifies.\n. Can just do this math once and check the result instead of compare first.\n. Add a max bound to this as well so delays are not too long?\n. what about the reverse (encoded with JacksonJson and decoded with Legacy)?\n. Ahh yes, thanks. I misread.\n. Good catch\n. There is a difference that matter for some resolvers (e.g. zoneAffinity)\n. The contract (as per the interface of ApplicationsSource) is to return no data if too stale.\n. I wanted to keep the logic of which \"name\" the read cluster has inside the Resolver. If we were to return a list of InstanceInfos, it'll either be inefficient (scan) or bleed the logic out to the implementation of ApplicationsSource to understand and filter on the name.\n. Sure\n. Good catch.\n. Yeah let me play around with that.\n. I was actually going to move EndpointUtils to the transport package:)\n. True. I was lazy. Let me do the right thing.\n. We still could. This change was made as the two (reg and query) clients need different resolvers that may internally be backed by threadpools, and given that we give the option of disabling reg and query, it makes sense to separate them so init can be skipped.\n. All the new transport stuff are created lazily so will not use any resources unless triggered. We do need them to be pre-created though, as currently the option to use/no-use them are dynamic and not tied to a restart.\nHaving said that, the latest change to the AsyncResolver may have broken the lazy guarantee. Will fix that.\n. Correct. There should be no external dependencies (e.g. network calls) needed for the new transport init, they should all be lazy.\n. Cruft code I forgot to delete. Will remove\n. These were due to a bad diff.\n. Good point. However we should also also not have it so that if there is only a single good server left, then we send a thundering herd there.\n. If this is the majority use case and inside EurekaJerseyClientImpl we use the idle timeout as an int, why use long in the first place?\n. the gzip encoding could be specified as a later param, which would fail the getFirst here.\n. Ideally, it would be nice to get rid of the toplevel hostname/ipAddr fields and just have users access them from DataCenterInfo. At the toplevel, what's nice to have is a default \"address\" that can be either hostname or ip, as defined by the registering service itself. Unfortunately, for backwards compatibility, the hostname field is today the realistic data that's used for this. Introducing this new accessor for a cleaner client API.\n. This is not entirely correct. Since with the new changes registering entities are now able to specify their own (potentially custom and not related to EC2 instanceId) instanceId, we cannot make this assumption here and assume this put into the metadata map is correct.\n. Check for  and handle null name if it exist?\n. do we need to do null check for value here?\n. sounds good.\n. it might be safer to try/catch here (and also in json version) to filter out any bad instance level data and not just exception out the entire application.\n. Use class instead of raw strings here\n. added\n. Agree here. It is preferable to run with the two different event mechanisms side-by-side for now, until future client refactors.\n. If the aim of this is to move from discovery* to eureka* in terms of naming, then I would propose that it's fine to keep the old event model as there are functionally no difference. We already have .discovery. in our package names and it would introduce more api complexity with the renaming, than keeping with the current.\n. Make these final.\n. Rename to something like AlwaysMatchStatusRule to better describe what this rule does?\n. These can all be final\n. This comment is misleading. From the rule interface design, each individual rule should not have understanding of where it applies in relation to other rules, and it is up to the definer at the top level to define them in the appropriate hierarchy. Perhaps move this comment to the *registry.java's?\n. Rules themselves should not understand their hierarchy.\n. Why not use myInstance.getASGName() here? That way there won't be magic strings.\n. Why not use myInstance.getASGName() here? That way there won't be magic strings.\n. I think it is reasonable to add getEurekaClientConfig() to the EurekaClient interface, which will then allow the reference here to be to the EurekaClient interface instead of the DiscoveryClient implementation.\n. Rather than providing overrideable ways to set the client, maybe we can add the necessary constructors to EurekaBootstrap:\n```\npublic EurekaBootstrap(ApplicationInfoManager infoManager, EurekaClient client) {\n    this... = ...\n}\npublic EurekaBootstrap() {\n    this(null, null);\n}\n```\n. It might be worthwhile creating a jersey2 version of the EurekaClientIdentity here such that they identify as jersey2 variants of the eureka-client.\n. In the existing code the connCleaner is called one last time before it is shutdown. Do you want to replicate that here too?\n. Can we try another way to do this here instead of having a default static instance reference of a child class in the TransportClientFactories interface? One suggestion could be:\n- define the interface for TransportClientFactories as is, but with no default static instance\n- have a TransportClientFactoriesProvider, e.g. \n``` java\npublic class TransportClientFactoriesProvider implements Provider> {\nprivate volatile TransportClientFactories<?> transportClientFactories;\n\npublic TransportClientFactoriesProvider(TransportClientFactories<?> transportClientFactories) {\n    this.transportClientFactories = transportClientFactories;\n}\n\n@Override\npublic synchronized TransportClientFactories get() {\n    if (transportClientFactories == null) {\n        transportClientFactories = new Jersey1TransportClientFactories();\n    }\n\n    return transportClientFactories;\n}\n\n}\n- in DiscoveryClient, initialize this provider with args.getTransportClientFactories(), then just get the actual impl out here in the same way.\n. fixed\n. It is actually the same. Changed to Entity.json for better clarity.\n. sure\n. yeah, changed.\n. fixed\n. Yeah, but maybe in a separate PR for that.\n. Replacement is to not use the Manager and just create things either via DI or directly.\n. Yeah good idea, I'll take a stab at that.\n. sure\n. Normally this would be the right thing to do, but there are some (unfortunate, due to legacy code) quirks of this Builder that means the values can't be cached. Will do something else for the resolver however to make this cleaner.\n. I don't think these two classes are really used now, only keeping them around for legacy support (and also making this change as they have config references).\n. open to other suggestions for this :).\n. minor quibble, change the method name to withInstanceInfo()?\n. Looks like this config is designed for the statusPage only. Perhaps rename the method to reflect that? As it stands, it (name + comment) feels more like something that is system critical.\n. What about a not configured default of -1? Technically you can run with a single eureka server (obv not recommended), in which case you would legitimately have 0 peers.\n. Moving all of these to be providers so that they are still lazy even if DiscoveryManager is eagerly instantiated due to requestStaticInjection. For example, with this, DiscoveryClient will be created eagerly due to DiscoveryManager instantiation.\n. These methods were not here to support DI, they are legacy setters that just need to be supported.\n. Sigh. I'll down rev to 2.0.6.\n. Yeah thought about that too, I'll stick with Provider for now.\n. lol got too lazy on this one:)\n. :) woops indeed. Thanks for the check!\n. nit: there are some weird spacing in this file.. Are these two tests intended to be `@Ignore`'d?. How stable is this library?. As part of going to 1.8, let's also update the servo version to 0.12.17 and governator to 1.17.4. Before the Java7 compatibility issue was the blocker for these libraries from moving forward.. Nit: general coding style, even for one liners please use newline and {}.. Since this is a private constructor, why not make an assumption that the passed in `intern` function is never null, and just do the right thing later where instead of passing in `null`, pass in `StringCache::intern`? Can avoid the conditional check that way.. \ud83d\udc4d . You can merge this and the insecure version into both calling an internal function with the two different maps.. This has lost the `.toUpperCase()`?. why 75?. Use a ThreadLocal random?. undo the commented out code?. Sorry I should have been more clear. I was thinking of something along the lines of\nprivate static List internalGetInstancesByVirtualHostName(Map<> vipAppMapping, String vipName) {\n    return Optional.ofNullable(vipAppMapping.get(vipName.toUpperCase(Locale.ROOT)))\n     .map(VipIndexSupport::getVipList)\n     .map(AtomicReference::get)\n     .orElseGet(Collections::emptyList); \n}\n. \ud83d\udc4d Be nice to have that in a comment. All three use cases are still internal to this class, so it seems reasonable to explicitly specify at each place. The benefit we'd get is that the if check would no longer need to be performed at each builder creation.. Hi, this should be `e1` here. should be `e1` here. should be `e1` here. You shouldn't need to cancel the future here, shutting down the scheduler should handle that as the future is scheduled on that.. You missed an `instanceInfo.getId()` here.. I know this is very unlikely to be used outside of internal classes, but give that the method has a public signature, do you mind creating a new method with the optionals and delegate over (rather than changing) from the original? Thanks.. I know this is very unlikely to be used outside of internal classes, but give that the method has a public signature, do you mind creating a new method with the optionals and delegate over (rather than changing) from the original? Thanks.. Hi. To replicate the existing behaviour, when the context is not null, this should append an additional `/`.. The full stacktrace is explicitly not logged here (see comment).. Let's keep the existing background-color please. Can just delete this line.. All the `PREFIX +` in this class can also be moved to `PREFIX + appPathIdentifier`. there should still be a final check here that\nif (!clientConfig.getEurekaServerURLContext().endsWith(\"/\") {\n   sb.append(\"/\");\n}\n``. This is a typo, the actual intent here isdebugLogEnabled =logger.isDebugEnabled(); . Good catch, thanks. We'll fix it in a future release.. This computation is repeated three times and might be better moved to a central method.. You'll also need to handle the async refresh on line 70.. very minor nit: mind calling thisspotTerminationTime? That aligns more with how the rest of the enums are named.. I would appreciate this be kept final to better ensure it is always correctly instantiated. An alternative for your test can be to add a new constructor that can be used to setRefreshableAmazonInfoProvider, with test visibility?. It is unfortunate that the API forAmazonInfois a bit leaky, but the preferred API to extract data is\nhttps://github.com/Netflix/eureka/blob/f8439886921e3655a301adb149a13eaa34268074/eureka-client/src/main/java/com/netflix/appinfo/AmazonInfo.java#L299, where the enum can be used directly.. There is duplication of code here with code on line 218/219/220, mind consolidating them? Thanks.. (mostly due to our bad naming) I think this is the wrong metadata map to get here, you want the metadata from the instanceInfo.getDataCenterInfo(), if it is an instance of AmazonInfo.. This is more you use case, is this change worth a WARN level log? Assuming spot termination actions can change often, this'll get noisy.. instead of an attempt counter, what about a completion counter after thefuture.get()`? That way all state (success|timeout|reject|throwable) is measured is a similar way.. please either log the error and do not rethrow, or don't log the error here as it is rethrown.. \ud83d\udc4d \nI poked through the code to check what actually happens to the exception (before it was implicitly rethrown, and now it is explicitly rethrown). I see that the full exception is eventually logged at:\nhttps://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/discovery/DiscoveryClient.java#L817\nhttps://github.com/Netflix/eureka/blob/master/eureka-client/src/main/java/com/netflix/discovery/DiscoveryClient.java#L972\nso if you want to log the full exception here, may be remove the duplicate logging in these other places?\n. ",
    "OskarKjellin": "@NiteshKant Well yeah, that was the first thing I tried. That ended up just like trying to connect to \n\"ec2-54-216-23-251.eu-west-1.compute.amazonaws.com,ec2-54-216-23-251.eu-west-1.compute.amazonaws.com:8080\"\nwhich of course didn't work which was when I started stepping through the code and found that it was actually splitting on a whitespace:\nString[] cnames = txtRecord.split(\" \");\n. @karthik-vn It ends up the same. Tries to query like \ntxt.\"eu-west1.mydomain.com\nWhich doesn't work. According to the route53 documentation, multiple values should be one per line. But that doesn't work either. I had a fix before that just did value.replace(\"\\\"\", \"\") which worked. But I should be able to use your jars and not need to modify my code.\n. @karthik-vn thanks. The issue was the setup in route53 that I had made. The test link helped me narrow down the issue with my configuration. It's working now.\nThe wiki should be updated to match our discussion here\n. ",
    "stonse": "Hi, (Answering on behalf of Karthik)\n   The eureka clients (for instances deployed in AWS) have a default logic\nof registering and subsequently obtaining the list of registered instances\nby communicating specifically to the eureka instance in its own zone (and\nwill failover to another eureka instance in its own zone etc.)\nAlthough using Route53 might work technically, the clients will then route\nto different instances resolved by Route53 (i.e they will not be pinned)\nthus bypassing some of the optimizations built around this pinning.\nWill get back to you once we pour some more thought on it.\nThanks\n/Sudhir\nOn Fri, Jun 14, 2013 at 2:33 PM, pommerien notifications@github.com wrote:\n\nHi there,\nWe are trying to run Eureka in a solely VPC environment and don't have the\nneed for EIP registration. Instead we are considering adding functionality\nto have Eureka register itself directly in Route53 as\ndiscovery.us-west-2c.xyz.com, or similar. That way we can make Eureka\npart of an ASG, avoid middle-tier ELBs, and use round-robin DNS once we\nneed more than one Eureka node per AZ.\nBefore we go through the effort, what is your guys' thinking around VPC\ndeployments of Eureka and would you be interested in us committing this\nback?\nCheers\nNils\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/issues/23\n.\n\n\n/Sudhir\n. ",
    "pommerien": "Hi Karthik,\nThe main motivation is self-healing, and secondly autoscale, even though I understand we won't have to scale out Eureka until we hit thousands of nodes.  That said, I was envisioning putting Eureka into ASGs (one per AZ), with a size of maximum size of 1.  Whenever a node dies, it spins up a new one, and (correct me if I am wrong), in the non-VPC world, it would go out and grab an EIP.  So how would we do it in VPC?  I thought about it more this weekend and the other alternative is to do it via \"Network Interfaces\" which you bind to a \"static IP\", configure route 53 accordingly, e.g. discover.us-west2c.company.com, and through metadata lookup the newly born Eureka instance will know what interface to grab and bind to itself as secondary interface.\nDoes our motivation make sense?  And if so, what are your thoruhgts?\nTHank you!\n--Nils\n. ",
    "danielkwinsor": "I will provide another pull request soon.  I found some new code in ApplicationInfoManager.refreshDataCenterInfoIfRequired where if the hostname changes it should update... I should do the same thing for instance ID.\n. https://groups.google.com/forum/#!topic/eureka_netflix/Rntihgo1i50\nhttps://github.com/Netflix/eureka/issues/24\nThere's no problem with the CI build, it just complains there is no junit test case.\n. Not sure how my latest commit got into the pull request, I didn't request that, will remove it.\n. ",
    "CH3CHO": "I also would like this pull request to be merged. Is there any other change needed to get it done?\n. I've looked ino that pull request. If I get it right, it only works for Amazon Data Center, not MyOwn Data Center. Unfortunately, we are using the latter one. So it would be better to have this instance level of configuration.\n. I don't think the test error is related to my change. Could you re-run the build? Thanks.\n. I just added the trailing \".\" check in the new commit.\n. But propMetadataNamespace is set in init method, L328.\njava\npropMetadataNamespace = namespace + \"metadata.\";\nIt ensures it must end with a \".\", unless someone changes this code. Do you think it is necessary to add this \"code-consistency\" test?\n. ",
    "jfenner": "Hi Karthik-vn,\nThanks for the reply.  I'm actually already setting that parameter, but it doesn't seem to make a difference.  Here's what I have for a config:\nTomcat setenv.sh:\nexport JAVA_OPTS=\"$JAVA_OPTS \\\n                   -Deureka.enableSelfPreservation=false \\\n                   -Deureka.registration.enabled=false \\\n                   -Deureka.environment=dev \\\n                   -Deureka.datacenter=ndc\"\necho $JAVA_OPTS\nAnd my eureka-server.properties (masked):\n```\nSet this only for this sample service without which starting the instance will by default wait for the default of 5 mins\neureka.waitTimeInMsWhenSyncEmpty=0\nAWS access key which has access to EIP binding and looking up autoscaling information\neureka.awsAccessId=*\neureka.awsSecretKey=****\n@next=eureka-${environment}-${region}.properties\n```\nAnd finally eureka-server-dev.properties (masked):\n```\nAWS access key which has access to EIP binding and looking up autoscaling information\neureka.awsAccessId=**\neureka.awsSecretKey=*\n```\n. ",
    "bpollack": "I'm also seeing this, even with eureka.waitTimeInMsWhenSyncEmpty set to 0.  While this is hard to see with Tomcat, attempting to run under Jetty shows a tremendous number of stack traces as Eureka server tries and fails to connect to itself with the Eureka client, presumably because it's still attempting to come up.\n. @NiteshKant @cfregly @karthik-vn This is actually happening in EurekaBootStrap.contextInitialized, when it calls registry.syncUp() (roughly line 102, depending on which PRs are merged when you look this up).  syncUp() will sleep up to, by default, five times, for 30 seconds, until it can find a peer to register with.  There's your 3-5 minute start-up time with the default .properties files.\nThere are two possible fixes to this:\n1. Modify the wiki to also note that you have to set eureka.numberRegistrySyncRetries to 0 for debugging\n2. Introduce a new setting, called something like eurekaServer.testingMode, that bypasses the initial syncUp call entirely.\nThe first is obviously less work, but second's also pretty simple.  Thoughts?\n. @NiteshKant Hmm, I like your idea.  Will quickly whip up a PR in that style for feedback.\n. I'd suggest we go ahead and close this; I hit a lot of this in #110, and I've grabbed a lot of the rest in stuff waiting on that to clear or get modified.\n. The console just being the main status page, or is there something else?  I'm happy to add this; I need/want to go clean up that page a bit today or tomorrow, anyway.\n. @NiteshKant Sure, go for it.\n. The other way to fix this, by the way, would be to both expand DiscoveryClientRegistryTest:51 to multiply by 20, rather than 10, pulling the general creation of mockLocalEurekaServer in front of the ConfigurationManager calls, and then changing the port each time through the loop.  That's just a more invasive change, IMHO, but it might be the better one.  I'm happy to submit either.\n. You got it @NiteshKant.  I'll modify this PR later today or early tomorrow with the second approach.\n. And incidentally, Java's not exactly my main language, so I apologize in advance if the code formatting is off.  I wanted to just tell IntelliJ to do its thing, but that reformatted a lot more than just my methods, so I wasn't really sure if that was actually a good way to proceed.\n. @NiteshKant Yeah, go ahead; I completely agree with @elandau that ephemeral ports are better, and feel silly for not thinking of that first.\n. Hey, I'm a bit nonplussed about this.  Running locally on 3e6e16ba0bb92159d6335da1d1cde13366aee72e, ./gradlew build test works just fine.  The first run of Cloudbees aborted due to timeout, and the second failed after much longer than usual due to an assert failure that I can't replicate.  Is there any way to get more insight into Cloudbees?\n. Cloudbees is flagging these due to the timing errors that I'm trying to fix, but I'm trying to clean up the code a bit and get a handle on how to approach fixing the timing issues first.  Sorry about the chicken/egg issue, but these should pass ./gradlew test locally.\n. Rebased onto master.  I ran tests at about half the commits (and all the ones that I had to tweak to rebase) to verify that I didn't accidentally break or regress anything, and the branch head obviously passes.\n. @NiteshKant Yeah; Peter and I have been fixing up some Eureka production issues the last few days, so I haven't had a chance to do another version of this, but there is one coming.  Please don't close it, but don't merge it yet, either.\n. @looztra I unfortunately got transferred off the deployment team right after committing to do this, so I don't have the time to do this anymore.  @pgkelley4 may know if that's still on the roadmap, though.\n. I don't really like converting a bogus value to an arbitrary value; Name.Amazon is just as likely to be correct as Name.MyOwn (and probably more so, given that part of Eureka's sweet-spot is in AWS deployments).\nAs far as I can tell, there are only two places we deserialize: in the server, when an app registers; and in the client, when we get data from the server.  In both cases, I think the actual best behavior would be to drop the bad registration on the floor: bad clients can't register, and if one somehow succeeds (talking to an old Eureka server, perhaps), we stop it replicating.\nThis implies to me that throwing a new exception, and catching it at the call sites to do something sane, is actually the best option, but it's also a much more invasive change.  As-is, this code ends up preventing bad clients from registering in the first place.\n. I guess that'd be okay. I shied away from that because I didn't like either the Eureka server not registering with itself (and you can't reliably special-case it, since, while we can easily infer localhost, I can't think of a sane way to infer the port).  That said, I do agree your idea in general smells better; what I've done here is a kluge.  A safe one, but a kluge.\nWhat's the best thing to do if we go to this mode by having no discovery servers?  Just accept that Eureka won't self-register?\n. ",
    "tbak": "To eliminate syncUp just set eureka.numberRegistrySyncRetries=0. Once it is set, the server starts up instantly.\nI propose to close this issue, as there was no follow up on it for some time, and there is alternative approach to achieve this goal.\n. It is supported via EventBus service, where discovery events are emitted (StatusChangeEvent and CacheRefreshedEvent).\n. This was greatly optimized in release 1.1.158\n. Fixed by PR #412\n. We completed migration to Java 7.\n. Rate limiter functionality was implemented for Eureka 1.0. The rate limiting is performed only for full/delta/application fetches. There are two quotas. One for all query types, and a dedicated one for the full registry fetch.\n. From the data model point of view (InstanceInfo, DataCenterInfo, etc) we shall not be very far away in 2.0 from what is in 1.0. The reactive interface will be obviously totally different. To easy the migration we could provide on top of Rx API, something closer to 1.0 synchronous API.\n. yes\nOn Thu, Sep 4, 2014 at 10:15 PM, Nitesh Kant notifications@github.com\nwrote:\n\n@tbak https://github.com/tbak This change is included in the other PR\n188 https://github.com/Netflix/eureka/pull/188, so I can close this\none?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/187#issuecomment-54585898.\n. You are right. I have checked that, and if user name/password is not set, that does not work.\nI will set defaults to guest/guest, so it is more self explanatory.\n. Would you like to work on this change? By default we should use current encoding mechanism with an option to turn off _ to __ conversion.\n\nIn Eureka 2.0 we will not be using this format anymore.\n. After looking at your change, I wonder why is it needed? By default eureka client is using Java system SSL socket factory, which I have just tested and it works. That includes reading the standard SSL system properties (javax.net.ssl.trustStore, javax.net.ssl.trustStorePassword, etc).\nCan you tell me what extra functionality apache client SSLSocketFactory.getSystemSocketFactory provides?\n. I was playing with this a little bit. I can get things working with the default SSLSocketFactory.getSocketFactory, but only for my truststore file (no client side authentication). Keystore is properly loaded only when SSLSocketFactory.getSystemSocketFactory is used. Lets move on with this change. Can you however refactor this code a little bit, in a way EurekaJerseyClient.createSSLJerseyClient factory method is implemented, by adding EurekaJerseyClient.createSystemSSLJerseyClient method, which would be conditionally called in DiscoveryClient durign jersey client creation. Now we have overlapping SSL setup for remote region connections.\n. RemoteRegionRegistry registry has separate SSL configuration, as typically traffic must be encrypted during cross region communication, but can be sent without encryption within a datacenter. We need to keep backwards compatibility here. If we enforce SSL configuration globally, this will obviously change. I will send more comments once I go through the pull requests.\nThanks \n. The implementation looks good, and covers all the important cases that I can think of.\n@NiteshKant Can you have a look at this pull request?\n. @keithbranton Thank you for your contribution.\n. Thank you for spotting this.\n. I fully agree, and that is our ultimate goal. In the first iteration, to avoid additional work required to provide proper abstraction for this separation, we decided to use servo directly. The direct usage of servo is limited to a few metrics classes, and should be easy to make pluggable, without affecting the rest of the code base.\n. Eureka 2.0 comes now with set of interfaces for metrics integration. \nThere are two implementations provided:\n- NoOp - void implementation, set by default for eureka-client\n- spectator plugin\n. As there was no further followup on this issue, I am closing it.\n. This is RxNetty issue, not Eureka's. I am closing it.\n. Eureka does not support multi-tenancy concept. It is possible to add arbitrary key/value pairs to the registry entries, so if security is not a concern for you, you can handle the filtering on the client side.\n. This is a pretty big change, and we should think it through carefully. The first two commits (Moving InstanceInfo related classes to a new package + Fix integTest shutdown), after minor correction could be merged immediately.\nRegarding \"Refactoring Sourced EurekaRegistry into eureka-core\" commit, I would do a step back, and think about reusing eviction concept on the client side without changing existing class hierarchy. Reusing the same registry implementation on both ends makes its implementation even more complex, and in the future, the complexity will only increase. We can/should still reuse the building blocks.\n. My point was that we can reuse most of the code, while keeping separation between client/server abstractions. Data source concept belongs to write server only. Client side registry is very thin, and we do not need the complexity coming with it.\n\nLet's take a step back and look at the channel-registry problem for both replication and interest.\n\nWe cannot reuse interest channel for replication, as we have additional handshake mechanism. But we can reuse the building blocks, which are eviction queue, PreservableRegistry  decorator, etc.\nOne problem with our channel abstraction is that we have a lot of code duplicated. If we would push it down to some common abstraction, it would be great.\n. Eureka was built previously with gradle 1.x. It has just been upgraded to gradle 2.x with a new nebula plugin. All scripts in gradle folder have been removed.\nPlease, try it again. Do not run your system installed gradle, but call ./gradlew which will execute configured gradle wrapper for Eureka.\n. @ddatsh Have you tried to build Eureka using the provided wrapper? If there were no other problems with that I would like to close this issue.\n. I propose to merge these changes in, and do the remaining updates in a separate pull request.\n. Looks good.\n. I agree, we should stick to one term.\nOn Sun, Jan 25, 2015 at 11:06 AM, qiangdavidliu notifications@github.com\nwrote:\n\nShip it.\nOn an unrelated note, we use the terms interest and discovery for the same\nmeaning interchangeably in our code. We should do a sweep through at the\nend and stick to one or the other.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/356#issuecomment-71386495.\n. Thanks for pointing this out. We have to make a few other changes to bump to higher version, as eureka-client is a direct or transitive dependency in other projects. We are working right now on this.\nFor the meantime, you have to overwrite the version in your gradle config.\n. I cannot replicate this error in my dev environment. With this change I want to narrow down the possible culprits.\n. Implemented by PR #403\n. This issue is a duplicate of #89.\n. Fixed by #412.\nOverridden status can be removed via DELETE REST call.\n. Fixed by PR #412\n. As currently setting status override modifies the status fields itself, this change would require bigger code refactoring. Instead, the status override DELETE will accept optional query parameter to set the desired status. If not set it will default to UNKNOWN.\n. We have transitive dependency that includes servlet-api 2.5 jar into eureka.war. The one eureka depends on directly (version 2.4) is marked as provided. I have just fixed that, and now I am able to run Eureka UI on tomcat 8.\n. I have just pushed a PR for this bug (#416).\n. Fixed by PR #433\n. As there was no follow up on this issue for long time, I am closing it.\n. Thank you for spotting this. We created recently a new Jenkins build job for Eureka at different location. I have pushed fix for this (#432).\n. I tried to setup StringConverter, and my custom converter implementation, but it never got triggered. Our custom serializers do not delegate processing further once they got basic types. If you know how to enforce delegation to StringConverter it would be much nicer implementation.\n. > Is there a value in having these as two different Status? IOW, why not have the components return InstanceInfo.State?\n\nI would like to expose internal system health, so having original status values is beneficial.\n\nI think we are conflating the health status with this granular information.\n\nIt is not health status in a sense we have it for external application monitoring. The point here is to have access to this granular information.\n\nBigger question: \"Can the subsystem status better be exposed via metrics and have the system health > as a status, potentially aggregated over multiple sources?\"\n\nMetrics are a must, and they are orthogonal to current status monitoring. Metric values could be collected from local counters (not remote monitoring system), and exposed as an additional insight information.\n\nIn absence of subsystem statuses, Is this just the forInterest endpoint otherwise available for any interest in eureka?\n\nUsing forInterest would incur additional delay, and if read node is disconnected from write server, it would  never provide up to date value. But the whole point of my proposal is to expose internal component status, as an additional insight information.\n. Following the discussion I am removing component specific STATE type parameter. Each component will emit InstanceInfo.Status values. This will simplify API and implementation. If we find it too restrictive (we are now limited practically to DOWN/UP status values with no way to express partial component failures), we may consider putting it back in the future.\n. I thought first about the same, but:\n1. the proxy code is very simple, and more efficient than maintaining\nparallel registry\n2. we would have to replicate 1.x registry to 2.x because of registering\n1.x clients\n3. we do not want to reuse replication mechanism from 1.x\n4. cross region replication should be bridged directly to Eureka 2 cross\nregion replication mechanism (whatever it will be)\nI think we would get ultimately in a lot of accidental complexity by\nbringing in all Eureka 1 server.\nBut data mode, codecs are reused in this implementation.\nOn Fri, Mar 6, 2015 at 1:47 PM, qiangdavidliu notifications@github.com\nwrote:\n\nRethinking this a little bit from a broader perspective, if we want to\nprovide backwards compatibility with Eureka1, it might be easier to\ndependent on eureka 1.x server modules and reuse the same server side core\ncomponents. The the work necessary will only be:\n- add the necessary rxNetty REST resources to talk to the 1.x server\n  components\n- bridge interest from 2.x registry to 1.x registry\n- bridge registrations to 1.x registry to the 2.x registry\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/454#issuecomment-77642107.\n. No, it is not possible. You will have to download all registry and do filtering yourself. Eureka supports application GETs, so if your application set is limited, you can try that route.\n. Looks good.\n. > InstanceInfo$Builder.setVIPAddress 10M\n\nI have added two more setters to InstanceInfo builder for vip/secure vip, that do not do macro expansion.\n. # Proposed implementation\nEureka server bootstrapping may happen from different sources, depending on Eureka cluster lifecycle:\n- for initial startup, there is no prior data available, so servers should start with empty registries\n- for existing cluster, when a new write server is brought up, it should ideally take full registry content from one of its peers\n- when full cluster is restarted, or there is other reason why a new server cannot bootstrap itself from a peer, it should load last known registry content from an external source/backup storage. Multiple backup storages may be implemented here.\nIn the original design, we envisaged that peer bootstrapping would be implemented within replication protocol itself:\n- a new node chooses one of its peers, and initiates full registry bootstrap\n- the chosen peer sends all its registry content, including local and any other registrations\n- one bootstrapping is done, a regular replication mode is enabled\nThis implementation has a few drawbacks:\n- complicates replication protocol, with additional mode of operation\n- has complex failover scenario - if bootstrapping from first node fails, we have to restart it from another peer, with which we may have already established replication channel.\n- it does not cover bootstrapping from external sources, and how the two would interact\nIn general, we need an API and some pluggability mechanism where multiple bootstrap sources may be provided. They should be also prioritized, so for example peer bootstrap is always first choice. The proposed API consists of two interfaces:\n``` java\npublic class RegistryBootstrapCoordinator {\n@Inject\npublic RegistryBootstrapCoordinator(RegistryBootstrapService primaryRegistryBootstrapService,\n                                    Set<RegistryBootstrapService> additionalRegistryBootstrapServices,\n                                    SourcedEurekaRegistry registry) {\n    // Setup bootstrap sources\n}\n\n@PostConstruct\npublic void bootstrap() {\n    // Initiate registry upload from the configured bootstrap source\n}\n\n}\npublic interface RegistryBootstrapService {\n Observable<Void> loadIntoRegistry(SourcedEurekaRegistry<InstanceInfo> registry, Source source);\n\n}\n```\nEach registry entry provided by bootstrap source is associated with Source.BOOTSTRAP, and is put immediately on eviction queue. If bootstrapping fails, the server is enabled anyway, as eventually the up to date state will be reconstructed from the registering clients. The bootstrap process is guarded by a timeout, which if crossed stops it and enables the normal operation mode of the server.\nPeer bootstrapping instead of replication protocol, uses regular interest subscription with full registry fetch, with failover mechanism switching to another available service.\nServer availability status\nWithin Eureka write cluster we cannot depend on instance registered status, when deciding if a server is up or down. Instead this information has to be provided somehow when connecting to the server. A few options may be envisaged here:\n- Embed server availability in a framing protocol itself, discarding all requests until server is up. A remote endpoint would receive a special frame asking it to disconnect.\n- Implement application level hello message exchange, and embedded server availability status within it.\n- Implement negative acknowledgment replies (NACK), carrying over detailed error status similarly to HTTP protocol. If NACK.SERVER_UNAVAILABLE reply is received, a connection to the given server should be dropped.\n. Some key points from our offline discussion:\n- bootstrapping from replication channel as a first step is a good thing, but slightly complex to implement. We will not do this now, but possibly some time in the future\n- doing full registry fetch from a peer or backup cluster should be fast enough, to not impact server bootstrapping time too much\n- we will have single external bootstrap source, so the hierarchy proposed above is not needed\nWhat we will provide now for write server bootstrap is a bootstrapping mechanism from either peer write cluster node or external backup cluster (configuration choice).\n. Implemented by PR #500 \n. XSD documentation was incomplete. I have added missing two states (OUT_OF_SERVICE and UNKNOWN).\nThank you for spotting this.\n. I was not able to reproduce this error. I think it was misunderstanding on my side. During bootstrapping we do full registry fetch over interest channel, but also replication channel is started in parallel. Some entries got loaded via replication, so when added afterwards when received from bootstrap source, there was no registry size change. This is consistent with observation, that ultimately final registry size was correct. I believe we can close this as no-issue.\n. I think it is more about transport optimization. If we access cross region data via read cluster, we minimize inter-region traffic + improve bootstrap latency.\n. Thank you for your PR. To align with other Netflix OSS projects (including eureka2), could you put both client and server into single gradle module eureka-examples? It will probably require some extra gradle scripting as application plugin does not support multiple apps by default, but it will be more concise.\n. Give me some time to think about it, and try it out. I would like to\nminimize number of gradle submodules.\nOn Wed, May 6, 2015 at 10:35 AM, Toby notifications@github.com wrote:\n\nNot sure I agree. This PR intentionally reflects that client and service\nare distinct programs, and the Gradle script is consequently minimal, fits\nthe expected pattern. Are you certain you want to go that way? (I\nalready tried to do this within the eureka-server module in early\nattempts to get the demo to run properly, and as you intuited, the Gradle\nwas obviously much less natural\u2014and actually never worked.)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/505#issuecomment-99546064.\n. Thank you for spotting it. We cannot merge this however, as this change is not backwards compatible (all user would have to update their configuration files). It is safer to leave it as it is, even if the property name is a bit misleading.\n. You are right. I have missed that we have also getPeerNodeTotalConnections, and the property names overlap:\n\n``` java\n @Override\n    public int getPeerNodeTotalConnections() {\n        return configInstance.getIntProperty(\n                namespace + \"peerNodeTotalConnections\", 1000).get();\n    }\n@Override\npublic int getPeerNodeTotalConnectionsPerHost() {\n    return configInstance.getIntProperty(\n            namespace + \"peerNodeTotalConnectionsPerHost\", 500).get();\n}\n\n```\nI definitely makes sense to merge this in. Thanks.\n. SerializedTaskInvoker is no longer used\n. Due to merge issues I need to close this PR and make a new one.\n. Looks good\n. Looks good.\n. Looks good\n. This was prototype work. With coming changes, we will have to visit VPC support.\n. We implement a new transport that will allow one to plug-in different HTTP client implementations. It is still on branch, but we will merge this to master probably next week. Once it is done, you can exclude jersey 1.x, and provide equivalent jersey 2.x implementation\nCheck: https://github.com/Netflix/eureka/tree/refactorings/transport/eureka-client/src/main/java/com/netflix/discovery/shared/transport\nIf we have time, we might provide a new module (eureka-client-jersey2), that would do exactly this.\n. For eureka-client, yes this could be anything that implements EurekaHttpClient API. But on the server side we depend heavily on JAX-RS.\n. We are working towards enabling multiple transports in Eureka client. There\nis already jersey2 implementation, however DiscoveryClient is still tightly\ncoupled with jersey1.x. We plan to re-write this code next month, after\nholiday season.\nOn Tue, Dec 1, 2015 at 6:17 AM, Fabi notifications@github.com wrote:\n\nHow its solved now? Do i still need to pimp like this?\ncom.spotify\ndocker-maven-plugin\norg.springframework.boot\nspring-boot-maven-plugin\n defined in spring-cloud-starter-parent pom (as documentation hint),\nbut needs to be repeated here \ncom.netflix.eureka\neureka-core\ncom.netflix.eureka\neureka-client\nor\norg.springframework.cloud\nspring-cloud-starter-eureka\njsr311-api\njavax.ws.rs\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/600#issuecomment-160981111.\n. Thanks\n. According to RFC2616:\n\"\n 406 Not Acceptable\nThe resource identified by the request is only capable of generating response entities which have content characteristics not acceptable according to the accept headers sent in the request.\n\"\nThis description fits the usage pattern.\n. You are right, status code 404 should be returned, and after checking the code it is implemented like that. In the latest release we added a filter that enforces GZIP replies for all GET requests. If you run GET with something like \"Accept-Encoding: identity\" you will get 406 in reply. If this is the case, your options would be:\n- remove the filter from the reference web.xml (gzipEncodingEnforcingFilter)\n- support gzip encoding in your client (either do not set Accept-Encoding header, which assumes gzip is supported, or add it explicitly)\n. Can you upgrade to latest version? 1.1.141 is quite old, and we have done quite a few updates.\n. As we have not received any more information about this issue, I am closing it.\n. Eureka has pretty complex configuration already, and we prefer not adding more properties to it. What you are requesting here, could be implemented in a more generic way as:\n- disabling heartbeats (not supported)\n- overriding current status (supported)\n\nHeartbeats/lease are essential concept in Eureka. Self preservation was provided to protect from loosing registry content during network failures or peer node crashes. You could try to set self preservation to 100%, which ideally would prohibit any node to be evicted. You can than override instance status with REST API call PUT /eureka/v2/apps/appID/instanceID/status?value=DOWN.\n. This behavior would require bigger changes in the code, and is not directly in line with Eureka architectural principles.\nWhat you want to achieve here is better handled by the health check poller mechanism. This is an external monitoring service that periodically calls each server of your fleet at a well know endpoint (Eureka provides healtcheck URL field for that in InstanceInfo), and if there is no successful reply marks an instance as down.\nIf you look at karyon3 (https://github.com/Netflix/karyon/tree/3.x), it provides a framework for application health evaluation + REST endpoint.\n. Thank you for your PR. To be backward compatible, can you add a fallback logic, so if a property with a namespace does not exist, it should read \"eureka.region\" as previously.\n. Thanks!\n. Yes, with the push model we are getting delays as low as ~5ms, depending of\ncourse on the system load and network bandwidth.\nOn Wed, Sep 16, 2015 at 3:35 PM, Adrian Ivan notifications@github.com\nwrote:\n\nHi,\nWill the Eureka 2.0 push model improve the delay for broadcasting topology\nchanges?\nRight now the Clients pull regularly hence the updates can take some time\nto the Client. I was wondering whether with the push model we will get\ncloser to realtime.\nThanks\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/641.\n. I understand that you have already custom serializer for your DataCenterInfo implementation. Can you tell us more about what is preventing you from implementing this interface?\n. Eureka1 default serialization engine is limited in practice to DataCenterInfo and AmazonInfo types. If a custom implementation is required, it should come with its serialization engine, possibly extending the default one.\n\nWe are in the process of migration from legacy encoding mechanism, that was both slow and memory hungry. We will remove the old code, as soon as we have enough confidence that all corner cases are covered in the new implementation. For the purpose of the migration we introduced an internal CodecWrapper API, but I would not  recommend to use it may be changed or removed in the near future.\nIn Eureka2 we provide BasicDataCenterInfo, in parallel with AWS implementation, which is aimed at DC deployments. I believe it makes sense to have it in Eureka1 as well. If this would solve your problem, lets go that route.\n. We do not do any schema based validation (it is JSON), but the request should not fail with 500 in such case. As each instance record must have associated data center info, an HTTP response with status code 400 would be more meaningful here.\nThank you for reporting this.\n. Fixed in PR https://github.com/Netflix/eureka/pull/651\n. Looks good\n. Looks good\n. Looks good.\n. Thank you for your comment. The DataCenterInfo API is really misleading. Probably we would need to have both getName and getInstanceId methods, with the former returning the data center name. This is actually the behavior in Eureka1.\n. Thank you for spotting this. I have just fixed that.\n. The example was setup with JacksonJsonMini codec, which omits all metadata\nin InstanceInfo object. I have changed it to the standard codec.\nThank you for spotting this.\n/Tomasz\nOn Wed, Nov 4, 2015 at 8:57 AM, Libor Rysavy notifications@github.com\nwrote:\n\nIt's really pita when you run example, add some metadata and when you\ngetMetadata() in the client it returns empty map even if you see those\nmetada when you query API directly. Then you search through documentation\nand other sources and there's no information anywhere, so one has to debug\nit to find out that there's some magic undocumented eureka.decoderName\nconfig property and when one has to set it to JacksonJson to make it work.\nPlease, improve your doc! It will make our lives easier! Thank you ;)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/697.\n. Thank you for spotting this. I have fixed this issue in this PR: https://github.com/Netflix/eureka/pull/701.\nYou should always call EurekaClient.shutdown(), which terminates all the allocated resources, including the thread pools.\n. Looking into the source code, this code path is executed only when the\ninjected decoder is not capable of handling the media type. It happens in\nthe replication path which should always use JSON encoding. There is a bug\nin the annotation value in ReplicationList/ReplicationResponse, which\ncontains \"jackson\", not the class name.\n\nCan you check what encoding format is used on the wire?\n/Tomasz\nOn Fri, Nov 6, 2015 at 11:54 AM, Spencer Gibb notifications@github.com\nwrote:\n\n2015-11-06 12:00:15.733  INFO 81323 --- [ost-startStop-1] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson\n2015-11-06 12:00:15.734  INFO 81323 --- [ost-startStop-1] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/702#issuecomment-154515411.\n. Which is strange the injected decoder does not handle this. We have this\ncode version running in the cloud with no such issue.\nCan you check with the debugger why the ISerializer is being used\nin DiscoveryJerseyProvider?\n\ndecoder.support(mediaType) returns false, so either Content-Type is not\ndefined in response, or it is not application/json.\nOn Fri, Nov 6, 2015 at 1:00 PM, Spencer Gibb notifications@github.com\nwrote:\n\nin\nJerseyReplicationClient.submitBatchUpdates(JerseyReplicationClient.java:120\nit sets\n.accept(MediaType.APPLICATION_JSON_TYPE)\n                .type(MediaType.APPLICATION_JSON_TYPE)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/702#issuecomment-154535654.\n. I will fix this, and make a new release, but probably not earlier than on\nMonday.\n\nOn Fri, Nov 6, 2015 at 1:34 PM, Spencer Gibb notifications@github.com\nwrote:\n\nThe problem happens when the mediaType is application/json; charset=UTF-8.\nThen it drops to the ISerializer.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/702#issuecomment-154548393.\n. Lets keep it open, as this problem may occur again and the root cause is not obviously visible.\nA simple fix would be to prevent any parameters in Content-Type header, and return a meaningful error reply.\n. Released in version 1.4.2\n. @spencergibb I have tried to reproduce this error with no success. I have seen servo ignores these kinds of errors internally (https://github.com/Netflix/servo/commit/0636b23a60889341a5c1d0dc8a1adc5b0c830180). Can you confirm?\n. When you shutdown a peer, other peers will continue sending replication data to this address, and for the time it is missing you will see transport related exceptions in the log file. We limit amount of errors logged in the replication channel, but we want to keep it at some level for diagnostic purposes.\n. Closing this issue for now. Please, reopen it if you want to further discuss this topic.\n. Thank you for spotting this. We no longer keep javadoc documentation in github. I have removed these links.\n. Javadoc documentation is uploaded to maven central. You IDE should be able\nto download it for you.\n\nOn Mon, Nov 16, 2015 at 4:24 PM, Kartik notifications@github.com wrote:\n\nThanks. Could you point me to the valid location of the JavaDoc?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/709#issuecomment-157218697.\n. Thank you for spotting this. I will provide fresh implementation for this class, without basing it on the existing jersey code.\n. Fixed in #713\n. CloudInstanceConfig depends on Amazon metadata. If access to metadata\nfails, and flag 'eureka.validateInstanceId' is set to false, as a fallback\na local host address is read. Possibly this is happening in your case.\nYou can always override the default CloudInstanceConfig implementation, and\nprovide your custom version that better handles docker environment.\n/Tomasz\n\nOn Fri, Dec 4, 2015 at 7:16 AM, Stefan Fussenegger <notifications@github.com\n\nwrote:\nI'm trying to get Eureka running in AWS EC2 Container Service (ECS).\nUnfortunately, CloudInstanceConfig relies on\nInetAddress.getLocalHost().getHostAddress() to get the IP address. In\ncase of Docker, this is the IP inside the Docker network (typically\nsomething like 172.17.0.2) which isn't very helpful.\nUsing MetaDataKey.localIpv4 should fix this problem without changing\ncurrent behavior:\n@Overridepublic String getIpAddress() {\n    return ((AmazonInfo) info).get(MetaDataKey.localIpv4);\n}\nhere's the current implementation of getHostName(..):\n@Overridepublic String getHostName(boolean refresh) {\n    if (refresh) {\n        refreshAmazonInfo();\n    }\n    return ((AmazonInfo) info).get(MetaDataKey.publicHostname);\n}\nAlternatively, there could be a new property to enable this behavior.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/715.\n. Looks good\n. InstanceStatus's purpose is to report an overall service state. You can still propagate this information using metadata field.\n. glad to help\n. You Eureka client/server configuration assumes that you run server on port\n80, and that the context path is 'eureka' (http://localhost/eureka/v2/apps).\nYou are using probably default configuration hence localhost address is\nused, not routable address of the host. Please consult\nhttps://github.com/Netflix/eureka/tree/master/eureka-examples/conf for\nexample configuration. You need to change 'eureka.serviceUrl.default' to\nyour eureka deployment URL.\n/Tomasz\n\nOn Mon, Dec 14, 2015 at 4:22 AM, omkar9999 notifications@github.com wrote:\n\ni'm unable to run eureka server on Weblogic 12c\nwar file is deployed successfully on Weblogic 12c but I'm receiving\nfollowing error in server logs:\n[2015-12-10T13:36:46135+05:30] [AdminServer] [ERROR] []\n[comnetflixeurekaPeerAwareInstanceRegistry] [tid: Eureka-EvictionTimer]\n[userId: ] [ecid: 4c164384-726a-4c35-a306-2cb86fb2103a-00000003,0:8] [APP:\neureka-server-1137] The lease expiration has been disabled since the number\nof renewals per minute is lower than the minimum threshold Number of\nRenewals Last Minute : 0 The Threshold is 085 of total instances : 0\n[2015-12-10T13:37:08337+05:30] [AdminServer] [ERROR] []\n[comnetflixdiscoveryDiscoveryClient] [tid:\nDiscoveryClient_ServiceURLUpdater] [userId: ] [ecid:\n4c164384-726a-4c35-a306-2cb86fb2103a-00000003,0:9] [APP:\neureka-server-1137] DISCOVERY: invalid zone - defaultZone defaulting to\ndefaultZone\n[2015-12-10T13:37:11702+05:30] [AdminServer] [WARNING] []\n[comnetflixdiscoveryDiscoveryClient] [tid: DiscoveryClient_CacheRefresher]\n[userId: ] [ecid: 4c164384-726a-4c35-a306-2cb86fb2103a-00000003,0:6] [APP:\neureka-server-1137] Action: Refresh => returned status of 404 from\nhttp://localhost/eureka/v2/apps/\n[2015-12-10T13:37:11704+05:30] [AdminServer] [ERROR] []\n[comnetflixdiscoveryDiscoveryClient] [tid: DiscoveryClient_CacheRefresher]\n[userId: ] [ecid: 4c164384-726a-4c35-a306-2cb86fb2103a-00000003,0:6] [APP:\neureka-server-1137] Can't get a response from\nhttp://localhost/eureka/v2/apps/[[\nCan't contact any eureka nodes - possibly a security group issue?\njavalangRuntimeException: Bad status: 404\nat\ncomnetflixdiscoveryDiscoveryClientmakeRemoteCall(DiscoveryClientjava:833)\nat\ncomnetflixdiscoveryDiscoveryClientmakeRemoteCall(DiscoveryClientjava:753)\nat\ncomnetflixdiscoveryDiscoveryClientgetAndStoreFullRegistry(DiscoveryClientjava:615)\nat comnetflixdiscoveryDiscoveryClientfetchRegistry(DiscoveryClientjava:562)\nat comnetflixdiscoveryDiscoveryClientaccess$1200(DiscoveryClientjava:87)\nat\ncomnetflixdiscoveryDiscoveryClient$CacheRefreshThreadrun(DiscoveryClientjava:1316)\nat javautilTimerThreadmainLoop(Timerjava:555)\nat javautilTimerThreadrun(Timerjava:505)\n]]\n[2015-12-10T13:37:11704+05:30] [AdminServer] [ERROR] []\n[comnetflixdiscoveryDiscoveryClient] [tid: DiscoveryClient_CacheRefresher]\n[userId: ] [ecid: 4c164384-726a-4c35-a306-2cb86fb2103a-00000003,0:6] [APP:\neureka-server-1137] DiscoveryClient_EUREKA/MACHINE_NAME - was unable to\nrefresh it's cache! status = Bad status: 404[[\njavalangRuntimeException: Bad status: 404\nat\ncomnetflixdiscoveryDiscoveryClientmakeRemoteCall(DiscoveryClientjava:833)\nat\ncomnetflixdiscoveryDiscoveryClientmakeRemoteCall(DiscoveryClientjava:753)\nat\ncomnetflixdiscoveryDiscoveryClientgetAndStoreFullRegistry(DiscoveryClientjava:615)\nat comnetflixdiscoveryDiscoveryClientfetchRegistry(DiscoveryClientjava:562)\nat comnetflixdiscoveryDiscoveryClientaccess$1200(DiscoveryClientjava:87)\nat\ncomnetflixdiscoveryDiscoveryClient$CacheRefreshThreadrun(DiscoveryClientjava:1316)\nat javautilTimerThreadmainLoop(Timerjava:555)\nat javautilTimerThreadrun(Timerjava:505)\n]]\nNOTE: MACHINE_NAME is a name of my windows machine which cannot be\ndisclosed\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/719.\n. I am closing this issue. Please, reopen it if you wish to continue this discussion.\n. If you shutdown single server, and it makes eureka enter self preservation mode, it means you have very few servers in the registry, and there is nothing else to do about it as to disable it. As you say it is in test, this should be probably ok with you. In prod, with more registry entries, self preservation should kick in only when there is  a serious issue causing massive registration expiries, like network failure.\n. I am closing this issue. Please, reopen it if you wish to continue this discussion.\n. You are using very old version with eureka. In later releases we improved DI support, so this should be no more an issue.\nFor the client I don't want to register an instance just be able to lookup using \n\nI do not understand this question. The reason to register with discovery is to be able to load server list for load balancing purposes. If you do not want to use Eureka registry, you can always use another ServerList implementation (for example ConfigurationBasedServerList).\n. @yairogen Regarding your question:\n\nSo - I was asking is it possible to be a eureka client just for lookup purposes and not register the client itself with its own instance properties as the client may not be a server in it self?\n\nIt is possible to configure eureka to only register (no registry fetch), or only do registry fetch (no registration). This is controlled via two properties:\n- eureka.registration.enabled\n- eureka.shouldFetchRegistry\n. I am closing this issue. Please, reopen it if you wish to continue this discussion.\n. Looks good\n. Can you point which methods have this behavior? Query by id is supported by this method:\njava\npublic List<InstanceInfo> getInstancesById(String id);\nAnd it should return empty list if no instance with the given id is found.\n. Thank you for spotting this.\n. Please, check this with feign project maintainers (https://github.com/Netflix/feign).\n. Looks good\n. Fixed by PR #751. Thank you for spotting this.\n. @spencergibb Thank you for the fix.\n. Sorry, my mistake. It is merged now.\nOn Mon, Feb 22, 2016 at 12:25 PM, Spencer Gibb notifications@github.com\nwrote:\n\n@tbak https://github.com/tbak closed but not merged?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/751#issuecomment-187368775.\n. Thanks!\n. @spencergibb It is done.\n. Looks good. Thanks\n. Eureka does not provide any authentication mechanism, but it supports SSL.\nTo secure your deployment you might create private key/certificates for\nboth endpoints, and enable client side authentication. To do that you must\ninject properly configured instance of EurekaJerseyClient (or build it\nwith EurekaJerseyClientBuilder). You can find those classes in\neureka-client package. There is unfortunately no documentation how to do\nthat.\nIf basic authentication is enough you can always configure it via servlet\ncontainer, and on the client side provide authentication credentials in\nEureka URLs (I have never tried that, so I am not 100% sure if this will\nwork).\n/Tomasz\n\nOn Thu, Feb 25, 2016 at 5:54 PM, Kennedy Oliveira notifications@github.com\nwrote:\n\nHello everyone!\nI used eureka in a private network and it's very fine, similar to AWS, but\nnow i need to use it exposed to the internet and was thinking if there is\nsome security like https and at least a basic auth to protect so other\npeople if they found the server can't register to it.\nIs there something? Because i can't use a firewall since the microservices\nwill have dynamic ips.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/755.\n. @spencergibb Good to know. We will fix it. I have created a separate issue to track it (https://github.com/Netflix/eureka/issues/756).\n. Sorry, we have been busy recently. Would you like to make a PR for this?\n. Servo can do probing automatically. Please, check how it is implemented in DiscoveryClient:\n\njava\n    @com.netflix.servo.annotations.Monitor(name = METRIC_REGISTRATION_PREFIX + \"lastSuccessfulHeartbeatTimePeriod\",\n            description = \"How much time has passed from last successful heartbeat\", type = DataSourceType.GAUGE)\n    private long getLastSuccessfulHeartbeatTimePeriodInternal() {\n        long delay = getLastSuccessfulHeartbeatTimePeriod();\n        heartbeatStalenessMonitor.update(computeStalenessMonitorDelay(delay));\n        return delay;\n    }\nCan you reimplement it using this approach?\n. @dcaba I propose to close this PR. As you have stated we have roughly equivalent metric already, and if we would like to implement this anyway, we should use servo annotations.\n. Eureka provides EurekaClientConfig configuration class, so you can always write your own implementation to set Eureka service urls with dynamic ports. If you need this for unit testing, please have a look at our DiscoveryClientResource junit resource that we use internally for testing (eureka-test-utils package). We are using ephemeral ports there.\n. @kennedyoliveira Eureka is starting the initialization immediately in the constructor. To delay it, you would have to implement a wrapper.\n. @kennedyoliveira Here is the fix restoring basic authentication. Most of the code there is the test code, to make sure we do not miss this feature in the future. We do not use HTTP basic authentication as it is inherently insecure.\n. @kennedyoliveira We are using client side certificates, to authenticate both sides of the connection.\n. @kennedyoliveira Sorry, I have to take it back about the client side certificate validation. There are however some ways to do that (via SSL system properties or creating custom EurekaJerseyClient).\n. During internal discussion we decided to handle this at REST layer, by not allowing registrations with OUT_OF_SERVICE status set.\n. We should use ephemeral ports in tests. We do this now in most of the tests that create server sockets, but not everywhere. Thank you for spotting this.\n. We should return Observable here, and for close as well.\n. At the protocol level we send key/value pairs in the update. On the client side, it means we need to calculate the diff prior to send, and on the server side we have to merge last InstanceInfo version with the received key/value pairs.\n. It is done at transport layer. Once the update observable completes, the acknowledgement is sent.\n. I do not understand forDeltas method's intent. We should create a distinct notification type, and send just delta with it, like:\njava\npublic Observable<ChangeNotification<InstanceInfo>> forDeltas(final InstanceInfo baseInstanceInfo) {\n        return Observable.from(deltas)\n                .map(new Func1<Delta, ChangeNotification<Delta>>() {...});\n}\nOn client side the flow would be:\n- client sets new InstanceInfo value, invalidating the previous one \n- in the channel we calculate the delta of type DeltaInstanceInfo\n- we send individual field updates to the server side\nOn server side:\n- We receive field level notifications\n- Channel keeps latest full InstanceInfo object\n- Channel creates a new instanceInfo by applying a delta\n- Channel updates the registry with new, complete InstanceInfo object\n  The downside on server side is that for each delta we will do the merge operations, so if client updates N fields, that will trigger N protocol messages, and N merge/registry update operations. We could think about batch updates, or sending a final flag with each update.\n. I agree that this is a bit abstract right now, but the operational model is very much improved. We can iterate over this implementation later.  I would merge this change, unless you have immediate idea how to improve it further.\n. This was may attempt to address channel failover scenario, where in case of a channel failure, and new connection will be automatically re-established with automated registration/interest subscription.\n. So, the idea is to eliminate the internal DiscoveryClient/RegistrationClient APIs, and embrace its logic into channel itself. It is ok, but this means we will have to handle REST in message passing way (so object mapping to REST URIs), which the former APIs were supposed to mitigate, and it was the reason for introducing them.\n. We need to figure out where to handle reconnects in a way transparent to external client. That could be very well yet another EurekaService implementation.\n. ServerConnection abstraction is identical to MessageBroker. The latter name is a bit unfortunate, and it stems from my initial idea to have Rx-style message broker intermediary with a set of features embedded. I propose to remove ServerConnection class hierarchy, and rename MessageBroker to ServerConnection + do some adjustments if needed.\n. \"Async\" is more generic term, and we will reuse this implementation to WebSockets as well. \n. Why do we need this, and not return directly connection.writeAndFlush observable?\n. Do we need two classes ServerConnection/ClientConnection?\n. For asynchronous message bus we do not know which was last ack-ed message. We could push 10 messages to the other end, and get ack for 5th only.\n. Using ribbon will introduce a lot of extra dependencies to the client. We could however make it possible to plug-in ribbon if somebody wants to (eureka-ribbon-client).\n. I agree. With web sockets support, having REST on client side would be\nredundant.\nOn Tue, Sep 2, 2014 at 10:19 AM, Nitesh Kant notifications@github.com\nwrote:\n\nIn\neureka-client/src/main/java/com/netflix/eureka/client/service/EurekaServiceImpl.java:\n\n\npublic EurekaServiceImpl(TransportClientProvider discoveryClientProvider,\nTransportClientProvider registrationClientProvider) {\nregistrationChannelMonitor = new RegistrationChannelMonitor(registrationClientProvider);\nregistrationChannelMonitor.start();\nprotected EurekaServiceImpl(boolean readClient, TransportClient aClient) {\n\n\nI haven't thought completely over the request-response style communication\nbut from the client end we do not need it as we will always use full duplex\ncommunication, rite?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/187/files#r17001060.\n. I think it would be dangerous to not always enforce those two clients. If somebody leaves them out, while adding other clients, we would face serious discovery outage.\n. Good point, I have totally forget about it. And since ReentrantLock has the same memory-visibility guarantees as synchronized, it is safe to use regular LinkedList. I will change this.\n. Local instanceInfo is provided during registration request, and it contains client specific information (apps, vips, etc). Do we need this information during LeasedInstanceRegistry creation? LeasedInstanceRegistry.getRegistryLocation has no usages in the code.\n. We need to handle/propagate transport errors. Here we swallow it.\n. Interests never complete, unless the channel is closed. Since we share single channel/registry, completing the interest invalidates both. We shall introduce explicit state management in this class like in channel implementation.\n. The contract for upgrade is that each time a full set of interests is passed. EurekaClientImpl must build an interest composite, adding/removing interests as necessary. \n. As discussed, lets keep this class immutable.\n. Is this removed by mistake?\n. Index extends rx.Subject which does not make sense for the composite interest. What index really is, it is an observable of events to which we can subscribe. hence the change. Index class is an internal implementation detail.\n. I had to do this, since IndexRegistry has type parameter, and this change introduces dependency form IndexRegistry to EurekaRegistry. You can see that LeasedInstanceRegistry is not generic.\nWith IndexProvider interface I have proposed above, we could revert this change.\n. We should reschedule the task if there is nothing to process. That could be\ndone within the task itself at a regular interval (possibly with\nexponential back off), or rescheduling could be done when we insert the\ntask into the queue, and there is no task already scheduled. The latter\nwould be more complex  to implement (race conditions) but more efficient.\n\nOn Mon, Sep 15, 2014 at 11:08 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka-client/src/main/java/com/netflix/eureka/client/InterestProcessor.java:\n\n\n@Override\npublic void call() {\nTask> task = taskQueue.poll();\nif (task != null) {\nInterest interest = task.getInput();\nif (interestStream != null) {\ninterestChannel.upgrade(interest).subscribe(task);\n} else {\ninterestStream = interestChannel.register(interest);\n}\n  +\n// subscribe the tasks to the (singleton) channel stream to propagate onError and onComplete\ninterestStream.ignoreElements().cast(Void.class).subscribe(task);\n}\n  +\ntaskProcessor.schedule(this);  // repeat\n\n\nIt is. Most of the time the work should be a queue.poll() and a task !=\nnull check. How optimized is the computation scheduler in rx? If a tight\nloop is expensive we can add a delay for each iteration.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/201/files#r17584836.\n. Our protocol semantic does not require waiting for ack, before submitting another message. For change notifications (which are also acked) this would incur too big round trip delay. For client side messages are sent less frequently, so syncing does not hurt, but do we need it?\n. we want to avoid register arrive after update?\n. Flattening does not work if we pass here MultipleInterests objects.\n. Nice Java7 addition. Good to know about it.\n. Module split into write/read server will complicate code sharing between the two. The common module is eureka-core which is also required by the client. Now if we want to add common audit service abstraction for both read and write server this will end up in eureka-core, so be part of eureka-client dependency. There will be more such things, possibly with dependency to third party libraries.\n. Looking throughout the code I see that interest removal is not implemented yet? That should come with interest ref counting.\n. Agree, but the ack comes from the server. Anyway it does not real matter for client, as w do not expect a flood of upgrade requests.\n. Ok, I have missed that.\n. Actually I would prefer to leave those number here, and get rid of the constants in EurekaTransports, but due to inverted project dependency it cannot be done that way. I will do as you suggest and use the constants in ProtocolType enum.\n. This class is never used.\n. I did not include this on purpose, as majority of clients will do full/delta registry fetch. If we would like to include this as well, we can add another target type.\n. I will add apps/ to the full fetch bucket.\n. We do not need this information on client side, but I understand it must be there because we share the registry code with the server. However, we could make it more readable, by putting server address (host:port).\nI would like to add server id concept, as depending on IPs to identify myself vs others is cumbersome. We have pending issue about that for Eureka 1.0 (https://github.com/Netflix/eureka/pull/119). It is purpose is to use in the replication channel, but once we have it, we could apply this more uniformly.\n. Why not just return toReturn observable? Blocking is dangerous.\n. We should reimplement SerializedTaskInvoker, so it does not do blocking. Once it is done, we can provide Scheduler constructor parameter, which will allow us to inject Schedulers.test implementation. Once it is done we can get rid of latches/blocking calls in unit tests.\nI am looking at this right now.\n. I would remove this method, and instead expect a user to create InstanceInfoFromConfig explicitly. InstanceInfoFromConfig is an active object (kind of resolver), while config classes are passive (pure java beans).\n. By making EurekaDashboardConfig extend EurekaServerConfig, we make it inherit all the read/write server specific properties, that was not present in the previous abstraction. It would be much better to make EurekaDashboardConfig extend EurekaCommonConfig.\n. Removing WriteServerConfig/ReadServerConfig forces both servers to have a superset of all the required properties, some of which may not be needed in one of the other.\n. I like this. We could apply this consistently across all metric classes.\n. What is the purpose of that? The just completed interest subscription will automatically remove the interest on unsubscribe. Why do we need here empty subscription?\n. I agree map would be sufficient here.\n. Only add/delete updates are generated in the original stream.\n. Yes + modify ChangeNotification does not make sense. The meaning would be that the IP or port of a service may dynamically change at any time. If there is such use case, we first need to implement deltas for Server objects.\n. This will trigger immediately interest subscription OnError, while we are not yet ready with new registry. We can shutdown old channel/registry only when new channel is swapped in.\n. We need to subscribe here, and it would be good to chain this with the return observable.\n. I think it is worth to keep this documentation (updated if needed).\n. We do not do reference counting here nor in InterestChannelImpl. If there are two (or more) subscriptions to the same interest, followed by single unsubscribe, the channel interest subscription set will be updated for all of them, and the other will get stale data. As we need reference counting in InterestChannelImpl, instead of redoing this here we could provide access to this information on the InterestChannelImpl (ClientInterestChannel.activeInterestSet).\n. We need to replay the subscription in the same way clients did it, so unsubscribe requests from clients will correctly update the channel. If we aggregate all this as a composite interest, this subscription will live until EurekaClient shuts down.\n. This field is not used. Can we add some retry specific metrics? Probably not here but in the RetryableServiceChannel.\n. We do not handle here instanceInfo == null case.\n. Can we use Rx retry here, and extract retry function out of this code? Ocelli is a good example how to do that.\n. With new, sourced implementation this class can be removed?\n. We have own set of hamcrest matchers for change notifications comparison (com.netflix.eureka2.testkit.junit.EurekaMatchers).\n. If we use blocked observable in test, we have to guard the test with timeout (@Test(timeout = 10000)), so in case of error, our tests will not hang forever.\n. We should declare local registry as EurekaRegistry.\n. We can replace moveToState(STATES.Registered, STATES.Registered) with state.get() == STATES.Registered.\n. Better test name? We do not convert to updates, but test multiple registrations for the same service.\n. Comment copy-paste. Does not fit here.\n. Invalid error.\n. I would decouple ClientInterestChannel from InterestChannel (rename to ServerInterestChannel). We have two set of methods, and having common interface is artificial.\n. I will fix this. We should transition to close.\n. Now we only log error messages if acks fail. I will add logging here.\nIn the future we will use acks for back pressure.\n. It cannot be there.\n. What will happen now when there is an error during unregistration? Shouldn't we close the channel as well?\n. Can we use here TestScheduler, and TestSubscriber and eliminate the latch?\n. As this is ConnectableObservable, shouldn't we call connect on it? According to the documentation, this observable should not emit any items without this call.\n. Is it possible to have more than one item in this stream?\n. There is no concept of sending an error on the transport. I think we should close eagerly here.\n. Updates are serialized and come from the registry. Also for concurrent updates, it is thread safe. The issue might be only when the same instance info is updated concurrently from two different threads. In such case we would end up with the problem we have in the registry. But fortunately this is not the case.\n. Why do we have to enforce Rx contract here? Notifications should be serialized, if not it is a bug.\n. We can use takeWhile + TestSubscriber or ExtTestSubscriber. The code is more compact this way.\n. Is there a way to avoid explicit sleeps?\n. Have you seen ExponentialBackoff or Retrys from ocelli? There are many standard algorithms implemented that we could reuse.\n. Is it visible in the API? If not, depending on ocelli is ok.\n\nOn Fri, Jan 16, 2015 at 11:35 AM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-core/src/main/java/com/netflix/eureka2/utils/rx/RetryStrategyFunc.java\nhttps://github.com/Netflix/eureka/pull/347#discussion-diff-23103609:\n\n@@ -0,0 +1,48 @@\n+package com.netflix.eureka2.utils.rx;\n+\n+import rx.Observable;\n+import rx.functions.Func1;\n+import rx.functions.Func2;\n+\n+import java.util.concurrent.TimeUnit;\n+\n+/\n- * A Func1 with retry options for use in .retryWhen(new RetryStrategyFunc())\n- \n- * @author David Liu\n- /\n  +public class RetryStrategyFunc implements Func1, Observable> {\n\nThe Ocelli version is nicer, but we don't want to have dependency on\nocelli for all the packages that needs retry. It feels like this is\nsomething useful to put in a more basic layer (rxjava/rxnetty)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/347/files#r23103609.\n. In this case there would be no point to return the status, as it always would be true. Now we return true only when the state changes. This is useful when we move to Close state, which guards cleanup code. We want to run it only once.\n. Originally metrics API were in a separate package and using Origin directly was not possible. I will fix that.\n. It is still work in progress. I need to fix/test all spectator metrics classes.\n. I need to cleanup metric names. Probably centralizing all these names in one class would be best.\n. Thanks for spotting this. It is a bug. I wanted to provide common implementation that both handles state transitions and related state metrics. I need to remove old implementation.\n. Why this test is extract in a separate class, and cannot be part of WriteServerStartupAndShutdownIntegrationTest?\n. But we need this test for read server as well. We should be able to\nconfigure write cluster addresses in read server properties file, and\nbootstrap it accordingly.\n\nOn Sun, Jan 25, 2015 at 10:41 AM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-integration/src/test/java/com/netflix/eureka2/integration/startup/FileBasedServerStartupAndShutdownIntegrationTest.java\nhttps://github.com/Netflix/eureka/pull/354#discussion_r23506376:\n\n@@ -0,0 +1,23 @@\n+package com.netflix.eureka2.integration.startup;\n+\n+import com.netflix.eureka2.server.EurekaWriteServer;\n+import org.junit.Test;\n+\n+/\n- * Since this test relies on Archaius which has some global settings, we can't have different tests for both read\n- * and write servers under the same JVM. As the tests are testing startup and shutdown behaviour that is common to\n- * both (within AbstractEurekaServer), we just pick one of the two server types (write servers) to test this.\n- \n- * @author David Liu\n- /\n  +public class FileBasedServerStartupAndShutdownIntegrationTest extends WriteServerStartupAndShutdownIntegrationTest {\n\nIt's in a separate class for clearer organisation. If we added it to the\nwrite test class chances are someone in the future might see the \"missing\"\ncomplementary test in the read class and add a read version back, which\nwill then get us back to the same problem as now.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/354/files#r23506376.\n. Closed. I have fixed that.\n. The state transition is driven by the client. This guard enforces single handshake that happens in the very beginning. We could add explicit channel close in case of failure, but we do not do this on the client side, and let the client handle the errors. We drift towards more \"standardized\" state machine in the channel. Lets revisit how we should handle it, including lifecycle/shutdown handling.\n. I have deliberately removed Idle state tracking, as it has unclear semantic. There was no connection attempt yet, just pure object construction. It is easy to put it back if we see value of it.\n. I have added this action, to handle remote endpoint disconnects. Handling of onComplete and onError is up to the client.\nI will add however a test that check, that in case of remote server disconnect, we detect if immediately and close the channel.\n. We cannot/shouldn't proceed with shutdown until unregister is completed. We cannot change shutdown() to return observable, as it is a pre-destroy hook.\n. Why it is not in shutdown hook override?\n. We can use TestSubscriber for that purpose.\n. This can be called concurrently, so we need thread safe subject.\n. In the current model we never onError to the client. It is fine, assuming we will refactor client API, and expose different result type.\n. Why is it here?\n. Should we merge this with lifecycle, so in case retries fail, ultimately we notify the client about an error. The only other way to do that would be to shutdown registry with an error, but we do not want to do that.\n. We have TestChannelFactory in test-utils. Cannot we reuse or extend that one?\n. I understand that this is type of connection where a client does not provide any operations. Can we pickup a better name for it, and also for unaryConnection? Some documentation would be useful, as well.\n. I have added in my branch \n\njava\nprotected abstract Observable<INPUT> connectToChannelInput(CHANNEL channel);\nHow can we expose channel input with this implementation?\n. Is it real time, or from TestScheduler? Why not schedule this as a task?\n. I understand that. But in nullaryConnection method name, it implies that the connection itself is nullary, and we actually mean here the operator. Maybe connectionWithNullaryOp?\n. That does not answer the question, how we can now pass channel input. Shall I keep the abstract method or add another function argument. For consistency the latter is better, but the number of arguments becomes too big. We might be force to introduce a builder for more clarity.\n. We should handle more gracefully errors here, as exceptions are very cryptic when class initialization fails. If property value cannot be parsed, we should log a warning and use a default.\n. Or just ConfigurationNames?\n. TansportNames? So we can do static import, and have a proper context in the class name.\n. We need a builder here, that plays well with EurekaBuilder.\nFor example:\njava\nnewEurekaBuilder().\n    .withTransport(newTransportConfig().withCodec(Codec.Avro))\n   .withXXX\nEurekaBuilder should accept both EurekaTransportConfig and EurekaTransportConfigBuilder for client convenience.\n. Can we still run EurekaRead server with arbitrary codec? JSON is very useful for debugging purposes.\n. It is more about client API usability. With builder we can have more fluent\nobject construction.\nOn Mon, Feb 9, 2015 at 1:00 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-core/src/main/java/com/netflix/eureka2/config/EurekaTransportConfig.java\nhttps://github.com/Netflix/eureka/pull/404#discussion_r24364815:\n\n@@ -0,0 +1,13 @@\n+package com.netflix.eureka2.config;\n+\n+import com.netflix.eureka2.transport.EurekaTransports;\n+\n+/*\n- * @author David Liu\n- /\n  +public interface EurekaTransportConfig {\n\nThere are only two variables right now. We can add a builder if this\nconfig grows in the future.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/404/files#r24364815.\n. How do we evict now replication channels? We need to put on the eviction queue a specific source.\n. Isn't it strange to always terminate a stream with an error? What was the original reason for this change?\n. Changed.\n. dataOnlyFilter sounds best\n. Done\n. Fixed\n. My mistake. I did some testing and I wanted to simplify configuration. I will revert this change.\n. It is a copy of NotificationsSubject, but not tied to ChangeNotification type. No changes are done to it other then type parameters. I will remove NotificationsSubject in a separate commit, as it will touch a lot of places in the code.\n. Following our discussion this is the new enum:\n\njava\npublic enum BufferState {Unknown, BufferStart, BufferEnd}\n. Changed\n. Changed\n. We have ad-hoc null filters created in a few places in the code. This is shared implementation from RxFunctions.\n. fixed\n. It is done only once (state Idle -> Open)\n. Good catch. I have also added localBatchingRegistry shutdown down there.\n. done\n. Good catch. I add shared implementation later, and forgot to update here.\n. changed\n. Fixed\n. changed\n. OnError/OnComplete have the same logic here, that is outside of the switch statement. I will add it anyway so it is more explicit in the code.\n. Makes sense for consistency with other places.\n. Should be doOnTerminate\n. We need to observe change so we can apply distinctUntilChanged operator at the end.\n. RxJava will handle exceptions for us, if they happen. And in this code we do not expect any exception so providing custom ones is not needed.\n. Description is different, but the expectation parts are identical, as we expect the same result.\n. Added testOverlappingBufferHintsFromCacheAndChannel\n. > onError and onCompleted cases for the attached data stream\n\nbehaviours for reconnecting data streams (this will be a common occurrence)\n\nThis is tested by testResetsStateAfterChannelReconnect method (onError only). I will add onComplete as well\n\ncase tests for the many different cases of shouldBatch\n\nWe test all the code paths. The logic is pretty simply in this class (unlike complex merging in BatchAwareIndexRegistry)\n\nshutdown cleanup test\n\nI will added it\n. Try/catch is a safeguard here if the observable creation fails for whatever reason. In such case the doOnTerminate will never be executed, as this observable do not exist yet nor is subscribed to.\nIt is to guarantee that we release resources (shutdown eureka client).\n. I agree. We will have to align this in other parts of code.\n. Absolutely. We should refactor it once new API is available.\n. We do not emit empty lists, which is what we would have to do if we have consecutive buffer sentinels issued. This is documented in @return description, but I will make it more explicit.\n. Done\n. As Server is part of public API, it should not reside in utils package. Can we move it to some other place (com.netflix.eureka2?)\n. I think we should split the builder in the same way EurekaClient was split. Now configuration properties specific to registration/interest subscription are mixed together. They are not many, but if we add more it will be less transparent to users which one are needed/important in a particular case.\n. I find RegistrationRequest name not fitting well here. RegistrationObservable is more transparent to the purpose of this object.\n. What is a retry policy on this observable? As discussed we should support it, and so it would be good to document it here.\n. What happens if we subscribe to this observable prior to subscribing to RegistrationRequest? It would be good to document interdependency between the two.\n. Can we align these names? Like replace from with createFromLifecycle.\n. This looks like repetitive two statements. We usually care about first registration and ignore lifecycle. It might be more handy if RegistrationRequest observable is for first registration, while there is registrationRequest.lifecycle() if somebody cares about it.\n. Why do we implement Source interface here?\n. Using String.intern() was technically forbidden in the past for string pool usage. This implementation of StringCache follows xstream's StringConverter which I tried to use, but since we have custom serializer it is never invoked.\nI checked again, and actually in Java7 the String.intern() implementation is fixed, and it is better alternative than having own string pools, but unless running on 7u40, it requires setting -XX:StringTableSize=N to proper value (before 7u40 default = 1009, later default = 60013 which is better but we might need even higher value). Check this article: http://java-performance.info/string-intern-in-java-6-7-8/\nGiven that we do not control which Java7 JVM versions clients run, and we cannot enforce proper JVM configuration, sticking to own String pool implementation seems to be better option short term. Medium/long term, if we want to make similar optimization in Eureka 2.x I would go for String.intern.\n. StringCache implementation follows xstream's StringConverter which has this optimization. Processing long strings is expensive, and probability of having duplicates decreases with increased string length.\nThis PR was a quick prototype to check how big is the benefit of pooling strings. We should revise it further if we agree we want this change.\n. Good catch. I will remove it.\n. Unfortunately we cannot do that, as retryableConnection is not constructed yet. But as these methods are protected, the risk of misuse is not big.\n. Sure, I will fix it.\n. I have added a comment. It would be actually good to have some flexibility in choosing which markers we prefer on registry/client API as technically we have both implementations. Possibly improvement in the future.\n. This client does more. It does not allow for any other interest subscriptions.\n. Can we rename Matcher to SourceMatcher? This name is used by many libraries.\n. Can we move this method to Source class? Might be useful in other places.\n. An update on existing entry will push it at the back of the queue, which I think is not what we want, especially for head.\nIf we do not remove this entry, the order will be preserved.\n. Origin, name, id?\n. Can we use custom comparator (by origin/name) and eliminate this data structure?\n. This method should not be called concurrently. If there might be concurrent\nupdates, it is up to the component itself to synchronize access.\nOn Fri, Feb 27, 2015 at 11:21 AM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-core/src/main/java/com/netflix/eureka2/health/AbstractHealthStatusProvider.java\nhttps://github.com/Netflix/eureka/pull/442#discussion_r25531203:\n\n\nprotected AbstractHealthStatusProvider(Status initialState, SubsystemDescriptor descriptor) {\nthis.currentStatus = new AtomicReference<>();\nthis.descriptor = descriptor;\nmoveHealthTo(initialState);\n}\n  +\n@Override\npublic Observable> healthStatus() {\nreturn healthSubject;\n}\n  +\npublic boolean moveHealthTo(Status newStatus) {\nif (currentStatus.getAndSet(newStatus) == newStatus) {\nreturn false;\n}\nhealthSubject.onNext(new HealthStatusUpdate(newStatus, descriptor));\n\n\nIs concurrency control important here? There is still no concurrency guard\nagainst two threads that execute in the following order:\nThread1 Thread2\nS1 -> S2\nS2 -> S3\nonNext S3\nonNext S2\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/442/files#r25531203.\n. My mistake. Should be distinctUntilChanged\n. Yes, it is RxNetty ObservableConnection handling code.\n. fromServerResolver? All methods excepted one connect to interest endpoint.\n. fromInterest? We could make it more flexible by providing InstanceInfoMatcher.\n. I would keep single fromInterest(ServerResolver, InstanceInfoMatcher). A user can create desired ServerResolver type from ServerResolvers. Otherwise we will have to sync both classes, and add new resolver types in multiple places.\n. Yes, here it is precisely REGISTRY_INITIAL_SIZE + 2 (read/write servers).\n. Done\n. I have added an explanation in comment.\n. state could be null which will not work for switch, and we have really one condition only here.\n. ServerResolverStep, to keep terminology consistent?\n. onError? According to the contract we shall always emit exactly one item.\n. We can do .cast(Observable.class) here\n. Can we add ServerResolverStep marker interface, which will connect all the step implementations into single rooted hierarchy?\n. it defaults to public\n. I would drop all forApps, forVips methods here in other places. We should use Interests.forXXX as a first class citizen, so we do not repeat ourselves.\n. copy-paste error\nfixed\n. delineatedBuffers is different, as it is using buffer start/end marker\n. copy-paste error again\n. We need to revisit the extensibility API, as it is very rigid now. If we keep ServerType, and keep it as an enum, the module themselves will have to handle \"default\" or unrecognized values properly.\n. I agree. I will rename all \"1x\"es to just \"1\"\n. Fixed\n. It is a bit tricky here, as we redirect clients which might be inside or outside.\nProbably best default would be:\n1. public hostname\n2. if not available private ip\nThis would work best in AWS, but for generic cloud deployment might be too restrictive\n\nPossibly we need some extensibility here, where the actual choice could be based on cloud type, and client IP address.\n. So here is the new code:\njava\n        ServiceEndpoint serviceEndpoint = HTTP_PUBLIC_SERVICE_SELECTOR.returnServiceEndpoint(readServerInfo);\n        String redirectHost = serviceEndpoint.getAddress().getHostName();\n        if(redirectHost == null) {\n            serviceEndpoint = HTTP_PRIVATE_SERVICE_SELECTOR.returnServiceEndpoint(readServerInfo);\n            redirectHost = serviceEndpoint.getAddress().getIpAddress();\n        }\n. These all views are connected to the same local registry (which is reads server registry). We do not do any remote calls here.\nWe could still save some cycles by doing conversion from v1 to v2 once, but I intentionally kept it simple. We do 30 sec batching (by default), so the load from it will be minimal anyway.\n. It really does not matter here as the handler is used internally here and\nno client depends on it. Synchronization will force any pending new\nregistrations/unregistrations to wait.\nOn Fri, Mar 6, 2015 at 1:39 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-ext/eureka2-eureka1x-rest-api/src/main/java/com/netflix/eureka2/eureka1x/rest/registry/Eureka1xRegistryProxyImpl.java\nhttps://github.com/Netflix/eureka/pull/454#discussion_r25980426:\n\n\nhandler.unregister();\nreturn Result.Ok;\n}\nreturn Result.InvalidArguments;\n}\n}\nreturn Result.NotFound;\n}\n  +\n@Override\npublic void unregister(RegistrationHandler cleanupHandler, long expiryTime) {\nsynchronized (handlers) {\nString instanceId = cleanupHandler.getV1InstanceInfo().getId();\nRegistrationHandler activeHandler = handlers.get(instanceId);\nif (cleanupHandler == activeHandler && activeHandler.getExpiryTime() <= expiryTime) {\nactiveHandler.unregister();\n\n\nremove first from map then call unregister for better synchronisation\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/454/files#r25980426.\n. InstanceInfo state does not change. Lease information is handled\nexclusively in the holder class. Unregister would close Eureka 2\nregistration session, and we do not want it.\n\nOn Fri, Mar 6, 2015 at 1:40 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-ext/eureka2-eureka1x-rest-api/src/main/java/com/netflix/eureka2/eureka1x/rest/registry/Eureka1xRegistryProxyImpl.java\nhttps://github.com/Netflix/eureka/pull/454#discussion_r25980492:\n\n\n}\n}\n}\n  +\n@Override\npublic Result renewLease(String appName, String instanceId) {\nsynchronized (handlers) {\nRegistrationHandler handler = handlers.get(instanceId);\nif (handler != null) {\nInstanceInfo v1InstanceInfo = handler.getV1InstanceInfo();\nif (appName.equalsIgnoreCase(v1InstanceInfo.getAppName())) {\nhandler.renew();\nexpiryQueue.enqueue(handler);\nreturn Result.Ok;\n}\nlogger.warn(\"Application name in the request, does not match the one in the instance info ({} != {}, instanceId={}\",\n\n\nfor this case we may want to do an unregister (from old) and re-register\n(with new).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/454/files#r25980492.\n. Implementation looks good. What about unit test to verify it?\n. To align it with rest of the methods in this class. They are all factories for functions.\n. The values are returned from cache, but the initial query will actually block, which is bad. Thanks for spotting this.\nWe have two choices here:\n1. populate view object with initial empty value or NO_VALUE marker\n2. Rx-fy Eureka2RegistryViewCache API\nI prefer the second route, and I will fix this accordingly.\n. I agree. All other methods use synchronize which is good enough here.\n. They build logically on each other: collapse -> aggregate -> aggregate with emit\nThere is also evaluate method in this spirit for list of change notifications. These functions are very useful when processing change notification streams, and I think we will have to provide them in some for as part of client API.\n. Added\n. Added more data to cover this case\n. We will always have at least one item. We have to do this that way for proper onComplete handling.\n. This will unsubscribe if there is no subscriber, and we want to cache it all the time, as building this view is very expensive.\n. Yes, having separate application views is not needed here.\n. Modify is not explicitly tested. I will add test for that.\n. We need to check for code 302. Status codes are analyzed by isOk method\nwhich accepts <200,300) + 302 always, plus 403/404 for certain actions.\nI have changed this condition to != 302 in another commit which I will push\nsoon.\n\nOn Mon, Mar 30, 2015 at 4:28 PM, Nitesh Kant notifications@github.com\nwrote:\n\nIn eureka-client/src/main/java/com/netflix/discovery/DiscoveryClient.java\nhttps://github.com/Netflix/eureka/pull/486#discussion_r27441830:\n\n\nlogger.warn(\"Trying backup: \" + eurekaServiceUrls.get().get(serviceUrlIndex));\nSERVER_RETRY_COUNTER.increment();\nreturn makeRemoteCall(action, serviceUrlIndex);\n} else {\nALL_SERVER_FAILURE_COUNT.increment();\nlogger.error(\"Can't contact any eureka nodes - possibly a security group issue?\", t);\nthrow t;\n}\n}\n}\n  +\nprivate ClientResponse makeRemoteCallWithFollowRedirect(Action action, String serviceUrl) throws Throwable {\nURI targetUrl = new URI(serviceUrl);\nfor(int followRedirectCount = 0; followRedirectCount < 10; followRedirectCount++) {\nClientResponse clientResponse = makeRemoteCall(action, targetUrl.toString());\nif(clientResponse.getStatus() < 300) {\n\n\nIsn't the below code checking for redirects? Shouldn't this check be\nchecking for code b/w 300-400 ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/486/files#r27441830.\n. There shouldn't be, assuming server is in charge of making the decision\nabout that. I will add a header that will notify server side if a\nparticular client request can be redirected (by default no). Even if client\nstates yes, some requests can be handled directly by server (for example\nfull/delta fetches that we do not support on bootstrap cluster,\nregistrations, etc).\n\nOn Mon, Mar 30, 2015 at 4:25 PM, Nitesh Kant notifications@github.com\nwrote:\n\nIn eureka-client/src/main/java/com/netflix/discovery/DiscoveryClient.java\nhttps://github.com/Netflix/eureka/pull/486#discussion_r27441671:\n\n\n} else {\nALL_SERVER_FAILURE_COUNT.increment();\nlogger.error(\"Can't contact any eureka nodes - possibly a security group issue?\", t);\nthrow t;\n}\n}\n}\n  +\nprivate ClientResponse makeRemoteCallWithFollowRedirect(Action action, String serviceUrl) throws Throwable {\nURI targetUrl = new URI(serviceUrl);\nfor(int followRedirectCount = 0; followRedirectCount < 10; followRedirectCount++) {\nClientResponse clientResponse = makeRemoteCall(action, targetUrl.toString());\nif(clientResponse.getStatus() < 300) {\nif(followRedirectCount > 0) {\nMatcher pathMatcher = REDIRECT_PATH_REGEX.matcher(targetUrl.getPath());\nif(pathMatcher.matches()) {\n\n\nAre there redirects from the server that we need to ignore?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/486/files#r27441671.\n. Is it possible that v1Update is null? It should never happen in properly working app.\n. why this dependency?\n. I have dropped Netflix part from it.\n. Good catch. I have fixed that.\n. Validation is done during initialization and there must be at least one service Url.\n. See note above.There should be always at least one entry.\n. Done\n. Some change in the legacy code will be required. We will see how much, and what is best way of supporting it. This is just first attempt.\n. Yes, I will add it.\n. Syntactically not, but conceptually yes, so I would keep it that way. We may also reintroduce some abstract methods in the future.\n. Added\n. Statics are removed from DnsEurekaEndpointResolver, which is package private now.\n. I would keep logic simple for now. Also even if status is not UP anymore, it might be very risky to start discarding connections, unless we have a notion of total/partial failures.\n. Done\n. I agree. I moved it to constructor.\n. As discussed, we cannot use here directly FullFetchInterestClient, but we will refactor this code base, so we have more flexibility.\n. Done\n. Bootstrap status can be true or false. We have here a filter that should terminate as soon as bootstrap == true is received. This implementation is however flawed. I have reimplemented it.\n. I have added more tests to cover different failure scenarios.\n. Renamed to BackupClusterBootstrapService.\n. Warmup time was a workaround needed prior to introducing buffer sentinels. As we have those now, I think we do not need it anymore.\n. Recent refactorings in ChangeNotifications allow for empty server lists. I think in the very beginning we should not emit empty list (filter empty lists out), but we should allow them afterwards, which means that all previously advertised server gone away.\nThe bottom line is that ChangeNotifications transformers must offer enough flexibility to do that.\n. This observable never completes, which will always result in a timeout below. We should use filter to get rid of empty server lists or just emit Observable.empty(). take(1) below will wait for first non-empty list.\n. I would do this module servers.size() to avoid Integer overflow. I know it is very unlikely, but still it is better to be strict if there is no cost to it.\n. Each subscription will create a new list/change notification objects. As ChangeNotification is not mutable we can create it eagerly or add share operator.\nI have seen mapping of T to ChangeNotification<T> in many places. Can we have a generic implementation in ChangeNotifications?\n. Yes, it is. I added a corresponding comment for drainPendingAckQueue()\nmethod.\n\nOn Mon, May 4, 2015 at 3:19 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka2-core/src/main/java/com/netflix/eureka2/transport/base/BaseMessageConnection.java\nhttps://github.com/Netflix/eureka/pull/507#discussion_r29629664:\n\nmetrics.incrementOutgoingMessageCounter(message.getClass(), 1);\n+\n-                        // Connection might be closed when we serve this request, and since\n-                        // pendingAckQueue and closed variables are not changed together atomically, we check\n-                        // close status after adding item to pendingAckQueue, and optionally drain it.\n-                        if (closed.get()) {\n-                            drainPendingAckQueue();\n\nIs this threadsafe? Seems like this can be called by multiple observable\nchains concurrently here.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/507/files#r29629664.\n. Will the shadow jar be properly published to repo?\n. It is useful to have more descriptive names, like registeringClient, lightInterestClient, etc. Ids will be still cryptic.\n. Yes, I was planning to do so, and missed that. This also pollutes stack trace.\n. Async subject provides guard here.\n. Good idea. I have added it.\n. Done\n. I will replace this with stack trimming function.\n. We might use the same class in different contexts. In this particular case it would work, but might not work in the other. I propose it keep it as an arbitrary name. In Eureka client it is even possible to set it explicitly via transport config.\n. Why this is not instance method of InstanceInfo, but static method?\n. We are at Java7 language level, so adding type parameters here on the left side is redundant.\n. Can we use EurekaClientConfig mock here, and avoid using archaius singleton?\n. PeerAwareInstanceRegistry is still a singleton. It should be easy to convert it to guice singleton, and inject all required dependencies.\n. We should protect this method with a guard to prevent executing it twice.\n. As this thread executes remote call, it is vulnerable to halts on socket IO operation.\n. Can these all sleeps be replaced with active pooling? This would speed up the test a lot. I have applied this strategy in replication tests, and they execute pretty fast.\n. Lets keep versions in root build.gradle for easy upgrade.\n. Is it possible to pass ApplicationInfoManager instance in constructor via injection to eliminate this singleton access?\n. Almost no change, except extraction of interface. Unfortunately git treats this as a new file.\n. All logic related to peer nodes management is taken out to PeerNodes class. No other changes.\n. This API maps one to one to existing client API, but you are right, we can\ndo simplification here.\n\nOn Tue, Jun 2, 2015 at 5:24 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka-client/src/main/java/com/netflix/discovery/shared/EurekaHttpClient.java\nhttps://github.com/Netflix/eureka/pull/529#discussion_r31584759:\n\n+\n+import com.netflix.appinfo.InstanceInfo;\n+import com.netflix.appinfo.InstanceInfo.InstanceStatus;\n+\n+/\n- * Low level Eureka HTTP client API.\n- \n- * @author Tomasz Bak\n- /\n  +public interface EurekaHttpClient {\n  +\n-    HttpResponse register(InstanceInfo info);\n  +\n-    HttpResponse cancel(String appName, String id);\n  +\n-    HttpResponse sendHeartBeat(String appName, String id, InstanceInfo info, InstanceStatus overriddenStatus);\n\nthe InstanceInfo should contain the appName and id, so no need to pass\nthese as params.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/529/files#r31584759.\n. Good point. We need to override this implementation in replicating client.\n\nOn Tue, Jun 2, 2015 at 5:42 PM, qiangdavidliu notifications@github.com\nwrote:\n\nIn\neureka-client/src/main/java/com/netflix/discovery/shared/JerseyEurekaHttpClient.java\nhttps://github.com/Netflix/eureka/pull/529#discussion_r31585722:\n\n+\n-    @Override\n-    public HttpResponse sendHeartBeat(String appName, String id, InstanceInfo info, InstanceStatus overriddenStatus) {\n-        ClientResponse response = null;\n-        try {\n-            String urlPath = \"apps/\" + appName + \"/\" + id;\n-            WebResource webResource = getJerseyApacheClient().resource(serviceUrl)\n-                    .path(urlPath)\n-                    .queryParam(\"status\", info.getStatus().toString())\n-                    .queryParam(\"lastDirtyTimestamp\", info.getLastDirtyTimestamp().toString());\n-            if (overriddenStatus != null) {\n-                webResource = webResource.queryParam(\"overriddenstatus\", overriddenStatus.name());\n-            }\n-            addExtraHeaders(webResource);\n-            response = webResource.accept(MediaType.APPLICATION_JSON_TYPE).put(ClientResponse.class);\n-            InstanceInfo infoFromPeer = null;\n\nCan we move these peer specific code to a server implementation of this\nclass? If we can break these out, it would be nice to refactor\nDiscoveryClient with this class.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/529/files#r31585722.\n. Why was it important to change this condition?\n. Shouldn't we have always single case here with sourced delegate?\n. Why not mock SourcedEurekaRegistry which is an interface?\n. Why this sleep here?\n. Why override here if we only call super?\n. There is no need for that as channel contract guarantees single subscription only.\n. I have missed the @Experimental annotation. Reading last value from subject let eliminate InstanceInfo field in the channel. I will have to put it back.\n. Changed.\n. RegistrationChannelImpl implementation is much simpler now, and we do not need this amount of tests.\n. Fixed here, and in a few other places.\n. Renamed to EvictionQuotaKeeper\n. Absolutely. Thanks for spotting this.\n. Done\n. We could do eager registration with initially empty subject, if id was not needed. With current API we can do this only on the first register, hence we have different code path. The return observable for update is a artificial with current API, as we do not provide per update state from the registry. I also do not think we should do that, as it would add a lot of extra cost with no benefit.\n. As we now share many types across different protocols, it makes sense to put them all into common \"model\" schema and leave protocol schemas with protocol specific declarations only (like ReplicationMessages below). This way we can avoid duplicating definitions.\n. Is this extra map step needed? Prev can be accessed directly in the flatMap below.\n. TCP replication handler is shared by all replication connections. We might get three new replication connections first, with random failures later on. How this scan process resolves this?\n. We need test here where multiple concurrent connections are established.\n. I understand that these methods are an alternative to DiscoveryClientOptionalArgs. As we use constructor injection everywhere, why not add yet another constructor that accepts the additional, optional values directly without a wrapper?\n. Is this refactoring needed to be able to extend serializer to support other data center types?\n. There is no need to cleanup these resources explicitly. EurekaDeployment tracks all registering/interest clients and disconnects them on shutdown. If that does not happen in some cases, there must be a bug.\n. This should not be needed. Eureka1ClientResource builds InstanceInfo explicitly.\n. Why provider in SelfInfoResolver directly?\n. PostInjector is a special annotation that will run annotated methods after injector is initialized. PostConstruct is non-deterministic, and the initialization may happen in any valid order. HealthStatusProviderRegistry emits events directly after the activate method is called, and if some components are not ready yet they will miss it.\n. Why in scope is needed here? We have already singleton annotation on the EmbeddedTcpInterestServer class.\n. Why provider?\n. I would keep codecs together in com.netflix.eureka2.codec package, just like metrics are aggregated.\n. override id == instance id. For clarity what about renaming Overrides.getId() to Overrides.getInstanceId()?\n. If operation fails, will this result in an exception or error code will be send in the result? In the latter case we should have error logging added.\n. We provide two alternative sources. Maybe instead of choosing here one of them we should provide a constructor with ExternalOverridesSource class as argument?\n. Given we have more tests like these, which are external systems integration tests, it would be good to define common runtime requirements, that once fulfilled would allow anybody to run those tests. In this particular case, AWS credentials would be sufficient.\n. Writes do not modify local map?\n. Since it is a very specific overrides setup, maybe the module should be renamed to InMemoryOverridesModule? Or we could provide alternatively a builder for the module itself.\n. Only top level classes must be registered here. Do we send DeltaDTO as a top level message?\n. Does it make sense to have single AwsConfiguration interface for all AWS configuration data?\n. This module is installed directly in WriteServerRunner. It is not installed in the embedded cluster.\n. Does it mean there is always in memory override registry?\n. Binding twice to the same InstanceStatusOverridesView class.\n. I have forgotten to add prefix here. The default is \"eureka2.\".\n. each server exposes status notification stream via web socket interface. We can also provide direct access to status aggregator component via EurekaServer API, and make it accessible via EurekaServerRunner.\n. Oh, I see you do exactly this for embedded server.\n. We should not put specific IPs in default config.\n. This is probably your test config :-)\n. After stabilization period we shall remove all legacy codecs which will leave us with options:\n- XML vs JSON (== MediaType)\n- full vs compact1 vs compact2 (== scope)\n\nI think public API shall be aligned with this target, while we will have to provide temporary means to specify an exact codec to use.\n. Shall we drop 'wrapper' term, as this is more like Eureka codec API now? (for example EurekaCodecBase, ...)\n. The replacement is not one to one, as EndpointUtils expects more arguments. Shall we create a new interface  for zone management? I am working now on transport refactoring, where I have introduced ClusterResolver abstraction. Zone analysis is done actually because of the transport needs, so probably lots of this logic will be used there.\nUsing singleton style access does not allow for customization. With an interface one could provide custom behavior for other clouds.\n. As we change the behavior lets specify the contract in more details in BackupRegistry class.\n. Is EncoderDecoderWrapper becoming our public API? The original intent was to support the migration process and erase it. For long-term public API we should make a few adjustments.\n. These abstractions were introduced for sake of unit testing, so we do not have to instantiate concrete objects. I think there is value in keeping those.\n. Do we have to do that? If there is false positive, we will wipe out whole registry, and force all clients to do the full registry fetch. The service is up for the whole time so clients may get empty/partial registry content. As we have eventually consistent system, there is no harm in skipping this step.\n. Not used in the code. Can be removed with its corresponding method.\n. The replication flag comes from REST API call, and we pass it down from there. I think it is fine to have this logic here.\n. Remote region abstraction is parallel to PeerAwareInstanceRegistry, I would leave it here as we actually use the remote data in this class.\n. It is no longer util. Can we convert this into a regular service with an interface and implementation, and inject it via constructor?\n. Never mind, I have seen it was just moved.\n. Do we need this lazy initialization?\n. PeerEurekaNodes has shutdown method.\n. Shall be in Key class?\n. Why not class level type parameter?\n. Dead code\n. Remove?\n. No actual test\n. Actually it is used by UI. Please, ignore it\n. In discovery-readonly I am doing exactly this. It is very unlikely we will\nreuse this code in different scenarios.\nOn Fri, Sep 18, 2015 at 2:25 PM, David Liu notifications@github.com wrote:\n\nIn\neureka-core/src/main/java/com/netflix/eureka/registry/ResponseCache.java\nhttps://github.com/Netflix/eureka/pull/644#discussion_r39902806:\n\n+\n-    AtomicLong getVersionDeltaWithRegions();\n  +\n-    /\n-     * Get the cached information about applications.\n-     \n-     * \n-     * If the cached information is not available it is generated on the first\n-     * request. After the first request, the information is then updated\n-     * periodically by a background thread.\n-     * \n-     \n-     * @param key the key for which the cached information needs to be obtained.\n-     * @return payload which contains information about the applications.\n-     */\n-     String get(KEY key);\n\nIf it at the class level then it'll need to be propagated all the way up\nto the PeerAwareRegistry, which gets messy. I'm not happy with the way\neither. Maybe this is over wrapping it and we should just let class Key be\npart of the interface.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/644/files#r39902806.\n. Converters provides XStream based serialization that we want to remove in the near future.\n. I wouldn't say this is public API. All codec stuff is internal\nimplementation until we provide \"official\" codec API.\n\nOn Wed, Sep 23, 2015 at 1:40 PM, David Liu notifications@github.com wrote:\n\nIn\neureka-client/src/main/java/com/netflix/discovery/converters/jackson/EurekaJsonJacksonCodec.java\nhttps://github.com/Netflix/eureka/pull/650#discussion_r40254790:\n\n@@ -37,7 +39,7 @@ public EurekaJsonJacksonCodec() {\n     public EurekaJsonJacksonCodec(final KeyFormatter keyFormatter, boolean compact) {\n\nI can imaging potential future cases where we may have multiple different\ncompact types. As this is exposed as public API, can we change this from a\nboolean to a more flexible type?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/650/files#r40254790.\n. We should verify media type in isReadable method, but there is no proper check there. I will add it.\n. I did not want to change DiscoveryClient constructor parameter list. I would revisit this when removing legacy code.\n. Good point, I will refactor that.\n. I am not sure if I understand. Host part will be identical to what was provided in service URI, without further resolve. We could provide ClusterResolver decorator that would resolve any host name to its IP value, to avoid transient DNS issues.\n. Yes. Certain resolvers take time to get their data (DNS), so this could block, and this would be in the request path. In the first iteration I have implemented reloading resolver with a background thread. Probably I should get it back.\n. The logic in if branch should be called only if atomic ref contains null.\n. Copy paste.\n. On a second thought, I am not sure about that. In ClusterResolver we have 'region' attribute. This is useful metadata, and it is convenient to carry it together with the ClusterResolver object, just like zone with EndpointResolver. In Eureka server we will have multiple copies of ClusterResolver, one for local, and a few for remote regions. We could provide AWS specific abstraction here as well, but in this case region name serves as an id.\nOther cloud providers use similar terms (Google Compute Engine region/zone, Azure/RackSpace region). At least 'region' seems to be a common one.\n. Fixed\n\nOn Wed, Sep 30, 2015 at 2:26 PM, David Liu notifications@github.com wrote:\n\nIn\neureka-core/src/main/java/com/netflix/eureka/cluster/PeerEurekaNode.java\nhttps://github.com/Netflix/eureka/pull/657#discussion_r40854272:\n\n\nReplicationTaskProcessor taskProcessor = new ReplicationTaskProcessor(targetHost, replicationClient);\nthis.batchingDispatcher = TaskDispatchers.createBatchingTaskDispatcher(\nbatcherName,\nconfig.getMaxElementsInPeerReplicationPool(),\nbatchSize,\nconfig.getMaxThreadsForPeerReplication(),\nmaxBatchingDelayMs,\nserverUnavailableSleepTimeMs,\nretrySleepTimeMs,\ntaskProcessor\n);\nthis.nonBatchingDispatcher = TaskDispatchers.createNonBatchingTaskDispatcher(\ntargetHost,\nconfig.getMaxElementsInStatusReplicationPool(),\nconfig.getMaxThreadsForStatusReplication(),\nMAX_BATCHING_DELAY_MS,\n\n\nwhy use the static and not the configurable value?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/657/files#r40854272.\n. Fixed\n. Fixed\n. Fixed\n. Done\n. Before that we need to get rid of legacy transport related code in DiscoveryClient. We want to keep it that way for some time, until we have enough confidence in the new transport implementation.\n. The test covers all combinations:\nEncoding ReplicationList using {JacksonJson,JacksonJson}\nEncoding ReplicationList using {JacksonJson,LegacyJacksonJson}\nEncoding ReplicationList using {LegacyJacksonJson,JacksonJson}\nEncoding ReplicationList using {LegacyJacksonJson,LegacyJacksonJson}\n\nEncoding ReplicationListResponse using {JacksonJson,JacksonJson}\nEncoding ReplicationListResponse using {JacksonJson,LegacyJacksonJson}\nEncoding ReplicationListResponse using {LegacyJacksonJson,JacksonJson}\nEncoding ReplicationListResponse using {LegacyJacksonJson,LegacyJacksonJson}\nOn Tue, Oct 6, 2015 at 2:50 PM, David Liu notifications@github.com wrote:\n\nIn\neureka-client/src/test/java/com/netflix/discovery/converters/EurekaCodecCompatibilityTest.java\nhttps://github.com/Netflix/eureka/pull/674#discussion_r41327448:\n\n\nAction.Register\n));\nfinal ReplicationList replicationList = new ReplicationList(replicationInstances);\n  +\nAction2 codingAction = new Action2() {\n@Override\npublic void call(EncoderWrapper encodingCodec, DecoderWrapper decodingCodec) throws IOException {\nString encodedString = encodingCodec.encode(replicationList);\n  +\nReplicationList decodedValue = decodingCodec.decode(encodedString, ReplicationList.class);\nassertThat(decodedValue.getReplicationList().size(), is(equalTo(1)));\n}\n};\n  +\n// In replication channel we use JSON only\nList jsonCodes = Arrays.asList(\n\n\nwhat about the reverse (encoded with JacksonJson and decoded with Legacy)?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/674/files#r41327448.\n. This should be added as static constructor in EurekaEndpoint.\n. All these values can be taken out of URI.\n. Shouldn't this be delayed?\n. It is a good practice to wrap Runnable.run in try/catch, so we do not silently swallow exceptions.\n. Do we want to have extended EurekaEndpoint interfaces, or just different implementations? In the latter case, I would drop the generic type parameter and use straight EurekaEndpoint as previously.\n. For stale data we will return an empty list, while the contract is that we should return previous value.\n. Why not returning List? Applications/Application are mutable and inconvenient to use.\n. It could be added to ServerStatusEvaluators. Might be useful in other places.\n. This factory creates Jersey connection pool, and must be shutdown. We could create a factory in getClusterEndpoints, and shut id down immediately after usage.\n. Maybe we should only set base name, and append protocol specific parts in the builder? So all those ifs can be replaced with single clientBuilder.withClientName(\"DiscoveryClient\")?\n. Why not using SplitEurekaHttpClient like it was before?\n. As most clients will not use this feature, lets create this on demand. Ideally, if turned off we should release resources as well. What do you think?\n. If this method is called during initialization, the new transport must be enabled before the service is started?\n. I do not see any usage of this method in this PR.\n. Lets always use milliseconds. Using seconds is bad for unit tests.\n. It is never referenced in the code.\n. It is never referenced in the code.\n. It is never referenced in the code.\n. I am not sure if this is good approach. If first 50% servers are down, and threshold is 50%, the client will never be able to connect to any healthy instance, as quarantine set will be just before the first live instance reset to zero.\n. We use consistently long for any time related properties. Here we map to legacy that will be removed in the future.\n. Why this need method is needed, if it just returns hostName?\n. I agree, and this patch should be removed in the future. Now it is the only way to prevent legacy client from crashing.\n. JSON version is not doing it, so NPE will be thrown. If we want to check it for XML documents, we have two choices:\n- throw an exception\n- provide default application name (like 'default') to allow deserialization to proceed\n\nGiven that we do explicit data validation on the server side that checks for application name existence, I would not do any more checking here.\n. I would assume Jackson is doing the necessary checking, but I will add extra guards.\n. JSON version is not present, and it is fully based on Jackson annotations. XML version did not work correctly with some Jackson versions, hence own deserializer.\n. This might cause ClassNotFoundException if jackson-dataformat-xml is not on classpath.\n. EurekaHttpClients should have no dependency on any transport implementation, as it is part of transport API.\n. Do we have any integration test that creates a custom filter? If not, it may be worth to add it.\n. Lets add information about recommended way of resolving cluster information.\n. We have timestamp attribute, so it should be printed here.\n. As all listeners can be injected via constructor, there is no pressing need to have this method. If we need it, we should add unregisterEventListener as well.\n. Currently event listeners Depend on DiscoveryEvent <- (CacheRefreshedEvent, StatusChangeEvent) hierarchy. The new API is not backwards compatible, and make break some clients.\n. By reverting this inheritance, we may fix the compatibility issue (CacheRefreshedEvent and StatusChangeEvent would still depend on DiscoveryEvent). However in this case why not stay with the original event model?\n. On a second thought. Since the new event model is not backward compatible, we should stay with the old one, and depend on constructor injection only. We can introduce the new event model with new EurekaClient implementation, and make it parallel to the old one. This is work that we plan to do in a new future.\n. As this is thread outermost loop try/catch we should catch Throwable exceptions. Otherwise the registry refresher may silently fail without us knowing about it.\n. I agree that this would be better, but it is not backward compatible change.\nWe plan to re-write EurekaClient, so we can leave the old event model with current DiscoveryClient implementation, and introduce new event model for the new implementation.\nAlternatively we can introduce now the new model in parallel with the old one.\n. ",
    "mampcs": "Created a pull request for the change.\n. Sure. I'll work on getting the changes done.\n. ",
    "rthomas": "Closed as it had additional commits from master that I didn't want in here.\n. Clone of PR #84, which was closed due to additional commits.\n. The reason I chose to have a new interface was to not introduce a breaking change for existing implementations of DataCenterInfo.\nIf that is acceptable however, I am happy to move it across.\nCheers,\nryan\n. ",
    "brenuart": "This may now be possible thanks to the DI-refactoring work introduced in recent versions. You may still be stuck by the issue https://github.com/Netflix/eureka/issues/554 though.\n. The self protection mode of our Eureka got activated for some reason so lease expiration was temporarily suspended. We then had a look at the registry lease data searching for instances that expired... and discovered that some had their lastRenewalTimestamp in the future... This is how we discovered the issue.\n. I will submit a PR for this.\nTo be honest, I don't understand why this extra RO cache helps to make performance better. There is already a first cache... why isn't it sufficient? \nI understand the RO cache has the same effect of delaying the invalidations - just like if you applied them in batch of say 100. Is that the objective?\n. Fine. Was working with version 1.1.147 \nSorry about this \"false\" issue :(\nCould you tell me in which version this fix has been made available?\n. The idea was that if I want to speed-up things, I had to use a lower value for the responseCacheUpdateIntervalMs, say I would have set it to 100ms. If not fast enough, I would have use 50ms, then 1ms... So at the end, 0 means immediate, and I get the desired behaviour.\nThis had the added benefit of not introducing a new configuration property in the game while still keeping an easy to understand meaning for the existing one.\nNow, if you prefer to add a new configuration property, I can update the PR with that. \nWhat property name would you suggest?\n. This is ok for me. The new config property allows me to disable the read only cache and have changes propagated immediately. Thanks.\n. This ok for me. \n. Some remarks:\n(1) First question is what kind of event do we need ?\nA CacheRefreshedEvent would simply tell the world the cache is refreshed and up-to-date. It doesn't say something has changed. We could leave the change detection to a separate component that would perform the diff and eventually send another event with the change information.\nA CacheUpdateEvent on the other hand would be sent only if there is a change. But I wonder is if it is useful at all if it doesn't hold information about what has actually changed:\n- new instance discovered (which one)?\n- instance gone (which one)?\n- instance status changed\n- etc\nIt start getting complicated. So my advice would be to go for the simplest CacheRefreshedEvent and possibly build a separate listener that would track changes. People interested in the actual delta could use it.\n(2) Event or listener?\nThe second question is whether we should plug into the eventBus or go for a simple listener. In the later case, interested parties would register with the DiscoveryClient to get the info.\nDrawback of the listener pattern: requires component to unregister\n(3) Starting hook\nAccording to me, it is probably better to hook into the fetchRegistry() method instead of the CacheRefreshThread. The fetchRegistry() method is where the actual work is done and can/could be invoked from many different places. Currently only at startup and then at regular intervals by the CacheRefreshThread. \nYour opinion?\n. @qiangdavidliu ping?\n. Don't see why the test failed - cannot reproduce the failure locally.\nJust wondering if it is not a timing issue?\n. Additional modifications after your comments:\n(point 2) \nA new CacheRefreshedEvent has been created and is automatically published by the DiscoveryClient if an EventBus is provided.\nI also made the StatusChangeEvent and CacheRefreshEvent inherit from the same parent DiscoveryEvent. Having a common parent for all events sent by the same source is quite convenient.\n(point 3)\nI moved the code not directly related to the refresh of the local cache outside of the scope of the timer.\n. The clientConfig static field is still used by static methods that are now deprecated. Removal of the static is therefore impossible until these methods are actually removed.\nIn the meantime, it would be useful to add a safe guard in the constructor to check if an instance has already been created and throw an exception otherwise. This would prevent people from creating multiple instances until actually supported.\nWhat do you think?\n. Don't you think it might be a better idea to simply prevent multiple instances from being created? I mean, if the the static field is already set, then throw an exception.\nThe now deprecated static methods are used by clients who assume the singleton pattern anyway - so they are not likely to create multiple instances. And if they do, they are already facing unexpected behaviour.\n. want a PR?\n. Would be even better if isLeaseExpirationEnabled() delegates to isBelowRenewThreshold() instead of copy/paste the code...\n. ",
    "cforce": "Is there an example how code looks like to do that multi register?\n. I have to somehow find a solution. Because of this feature missing i would do it in the client by missung the vip field - however this solution is a workaround. I hoped you maybe have an better idea or already had same thoughts in this direction.\n. Eureka v1 is the one released, isn't it?\nBut how can i search for \"in between \" or above \"v2.0\"?\n. How would you implement that?\n. How its solved now? Do i still need to pimp like this?\nxml\n <plugins>\n            <plugin>\n                <groupId>com.spotify</groupId>\n                <artifactId>docker-maven-plugin</artifactId>\n            </plugin>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n                <!-- defined in spring-cloud-starter-parent pom (as documentation hint), but needs to be repeated here -->\n                <configuration>\n                    <requiresUnpack>\n                        <dependency>\n                            <groupId>com.netflix.eureka</groupId>\n                            <artifactId>eureka-core</artifactId>\n                        </dependency>\n                        <dependency>\n                            <groupId>com.netflix.eureka</groupId>\n                            <artifactId>eureka-client</artifactId>\n                        </dependency>\n                    </requiresUnpack>\n                </configuration>\n            </plugin>\n        </plugins>\nor \nxml\n<dependency>\n        <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-eureka</artifactId>\n    <exclusions>                \n        <exclusion>\n            <artifactId>jsr311-api</artifactId>\n            <groupId>javax.ws.rs</groupId>\n        </exclusion>\n    </exclusions>\n</dependency>\n. Same issue here with Brixton. M4\n. There is such function, see http://projects.spring.io/spring-cloud/spring-cloud.html#ignore-network-interfaces \n. Its not working for me too.\nAs described in the kubernetes manual it should be possible to setup deployments/pods such way, that the (by k8 generated) pod name is registered at the kubernetes DNS (coredns)  so we are able to nslookup by podname additionally to lookup by service name (using the cluster ip)\nhttps://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pods\nWe tried to setup the deployment.yaml in different way, but never succeeded so far in the results that is described in the docs, that shall allow a nslookup to be resolved from pod  A for Pod B real IP using\npod-ip-address.my-namespace.pod.cluster.local \nor (what is even more wished)\npod-name.my-namespace.pod.cluster.local \nLike the doc says,  clusterIP: None and we tried with hostname set (or even not set and being generated by kubernetes itself\nWe verified the test runs using nslookup while ssh on console of Pod A.\nWith no approach there was ever a DNS resolution possible in Pod A   using B.dev.pod.cluster.local (or just B ) where the podname of B was a generated one which what listed in in k8 pod description and on POD B /etc/hosts  file.\n. ",
    "nekperu15739": "Could you please give it a sample, thanks. ",
    "elandau": "There was something wrong with the original pull request but I've since\nfixed it.  Yet the test still fails.  From looking at the code this seems\nto be a problem that always existed with the MockRemoteEurekaServer so I'm\nnot sure how this ever passed.  Although the fact that it ran before means\nthat I probably missed something.\nOn Tue, Apr 1, 2014 at 11:26 AM, Nitesh Kant notifications@github.comwrote:\n\nLooks like there's a problem with this pull request\nSince, the same test failed twice, which does not happen in other pull\nrequests. I suspect that there is a change in this PR that is causing the\nfailure. @elandau https://github.com/elandau can you verify?\n\nReply to this email directly or view it on GitHubhttps://github.com/Netflix/eureka/pull/94#issuecomment-39240617\n.\n. Please take a look at #94.  I ran into the same problem for a different feature and I've reworked the tests to use ephemeral ports instead of random ports.  Using ephemeral ports guarantees that there will be no port collisions whereas random ports requires unnecessary logic around port collisions. \n. Pull request looks ugly.  Created a new one #125 \n. Guava has some low level APIs that may be useful here.\n\nhttp://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/util/concurrent/RateLimiter.html\n. Removing the legacy libs would require a bit more work.  @qiangdavidliu may take a stab at it.\n. @mgtriffid From your description it sounds like you need a different randomization mechanisms for clients to find, fetch or register with eureka nodes.  Or do you need different randomization for eureka nodes to find each other?  Or both?  The PR you submitted only modified the behavior for inter node communication of the eureka cluster and has no effect on client side randomization.  That change would need to be wired into ZoneAffinityClusterResolver.  . Sorry, you are correct.  Not sure why I wasn't making that connection.. Done\n. Not sure attempting to register a null callback warrants throwing an exception.  I tried to keep the behavior similar to other APIs such as registerHealthCheckCallback.\n. This could be categorized as syntactic sugar.  We can have different RefreshCallback policies that don't need to store an instance of the client internally.  For example,\npublic class MyRefreshCallback implements RefreshCallback {\n     void postRefresh(DiscoveryClient client) {\n          // Do something with the client.\n    }\n}\nRefreshCallback callback = new MyRefreshCallback();\nclient.registerRefreshCallback(callback);\n...\nclient.unregisterRefreshCallback(callback);\n. I was thinking the same thing.  I am a bit concerned though that we may be overloading the event bus with too many types of events.  It would be used to track internal state, data events, stats events, etc...  We may want to create multiple instances of the event bus.  Part of the concern with tracking all of these on the same event bus is that internal state events may end up being tracked in components such as Pundit.\n. Only if a failure is guaranteed to not be a partial failure.  Can we assume that?\n. Not sure I follow.  Either way we should swallow this exception.  I'll add a log line.\n. By partial failure I mean that a failure occurred while updating the internal maps based on the response so only part of the updates were applied to the internal state.\n. I've noticed this pattern is existing code that polled discovery data to determine if an instance is up.  I can only assume that there was some issue with the application name associated with the instance in the discovery service somehow was different from the application name the client thinks it belongs to.  If that is the case then this seems like a bug somewhere else in eureka. \n. Seems like the appGroupName upper case invariant can be violated here and this may be an issue since appGroupName is volatile, hinting that it may be accessed by multiple threads.  A safer way to implement this function would be,\nif (appGroupName == null)\n    result.appGroupName = null;\nelse\n   result.appGroupName = appGroupName.toUpperCase();\nIt appears that we have several existing methods that should also be corrected this way\n. I agree that this might be seen as a nitpick but we should err on the side of code correctness, especially when this is a very easy change.  While we're on the subject of this builder it's important to point out that it is inherently flawed is that the builder maintains a reference to the returned InstanceInfo and can modify that object after it is returned.  The builder should actually return an immutable object.  Sure, this isn't an issue as long as the Builder is used correctly but can be the source of difficult to find bugs in the future.\n. This is mostly there for unit tests.  I suppose we can remove this since the next unit test will call setEurekaInstanceConfig\n. yep\n. I'll remove the atomic ref\n. I'll remove this\n. We can get rid of this one and just use the new Provider.  We can then just use HealthCheckCallbackToHandlerBridge as the default @ImplementedBy for HealthCheckHandler for now. \n. We should get rid of this check and just have a DefaultHealthCheckHandler that always returns UP\n. This Provider was just added this weekend.  All existing code should be using registerHealthCheckCallback which you've already modified to create HealthCheckCallbackToHandlerBridge.\n. @Singleton is unnecessary here.   Making the Provider @Singleton does not make MyDataCenterInstanceConfig a singleton.  You need to do that when you specify the binding.  This should also be a provider for EurekaInstanceConfig and not MyDataCenterInstanceConfig.\nbind(EurekaInstanceConfig.class).toProvider(MyDataCenterInstanceConfigProvider.class).in(Scopes.SINGLETON)\n. @Singleton not necessary \n. Is BackupRegistry supposed to be a singleton?  If so, then cache the reference in get().\n. Can be simplified with \nProviders.of(backupRegistry);\n. I'm using EurekaEvent since it is reference transitively through the EurekaClient API and is in the spirit of renaming 'discovery' to 'eureka'.\n. I updated the PR in a way that should be backwards compatible.  I'd rather not have two different event mechanisms unless absolutely necessary, especially since the older one can be built on top of the new one.  Let me know if the change addresses your backwards compatibility concerns.\n. Feels like this check should come first before initializing result\n. Can these four lines be consolidated into one?\n. Trim the results.  This can be done easily using Guava's Splitter.\n. +1 but don't use inheritance.  Create a new internal module with the common bindings\n. Looks like order is important when calling withVipAddressResolver and setVIPAddress.  A better approach would be to cache the value passed to setVIPAddress and call the resolver in build().  You can also set vipAddressResolver = LazyHolder.DEFAULT_VIP_ADDRESS_RESOLVER in the constructor if it's not set right before resolving the address.\n. This should be called before result is assigned\n. This code repeats for Archaius1 and Archaius2.  Any thoughts on creating an AbstractVipAddressResolver to hold the common code or put this in a utility class.\n. Both archaius1 and archaius2 already support string interpolation.  This is code is completely unnecessary. \n. I realize this class is temporary but the class name and especially the method name seem extremely specific.  Why not create an interpolator api instead.  It greatly clarifies the purpose of this class.\njava\npublic interface StringInterpolator {\n    String interpolate(String source);\n}\n. What's this?\n. Instead of using providers why not just mark these methods with @Inject?\n. My point is that you don't need to write any code here.  Annotating this method with @Inject can be done instead of annotating the 'eurekaInstanceConfig' field with @Inject.\n. This code is jumping through hoops to try to address the eager vs. lazy behavior of DiscoveryManager.  This should be handled outside of this class.\n. Just delete it!  It probably doesn't work anyway!\n. This null check is not necessary. This code is fairly deep down the call stack and I don't want to risk affecting any code that might already depend on specific exceptions by wrapping this.  What I really want here is to be able to log the service URL and any additional context that would help us debug these exceptions further.  . sure. I removed this logging as I actually don't think it'll help us much anyway.  The other changes provide more meaningful information.  . Yes, these two were reversed.  . This is a public API so let's go through a proper deprecation cycle. . ResolverUtils is a utility class and should have no state.  The static setter also makes it impossible to test different randomizers in parallel without forking the JVM.  While that may be an unlikely scenario we prefer to stick to this philosophy throughout the codebase. . Let's keep the urlRandomizer as a configurable aspect of the DiscoveryClient and not static state of ResolverUtils. \n This can be made customizable either via Guice bindings or configuration.  I'm also thinking this should be done as a ServiceUrlRandomizerFactory that takes an InstanceInfo argument. . Currently the local address is derived from the local InstanceInfo, which makes testing easier and keeps the source of truth for such information in once place.  For consistency I think it's best to continue using the local InstanceInfo. . DnsResolver was written as a utility class with only static methods.  This PR changes an implementation detail of this class so there's no need to make it possible to instantiate DnsResolver directly.  Also, I'm concerned about making such breaking changes to public methods. The PR can be greatly simplified if the static change were to be reverted. . ",
    "zhangdc007": "is the application group just a label to tell apart application ? or the different application group can not find other if they has not permission ?\nMy requirement is apps in different group and regist in a eureka ,for example ,group A and B\uff0cif A has permission to B,then apps in group A  can get  address in app Group B,so A can invoke B' api,if not ,A has no B's app's address,and can not invoke.. ",
    "howardyuan": "ScheduledExecutorService part looks fine.\n. Seems like assumption is that multiple applications can have the same instance id. DiscoveryClient.getInstanceById() seems returning a list of instances for the id. You might want to find out why?\n. Do you mean by getString(EUREKA_ENVIRONMENT, \"TEST\")?\n. No, I didn't see the TEST=\"test\" definition above. So np here.\n. ",
    "pgkelley4": "This change will break existing config files that specify serviceUrlPollIntervalMs, or that specify either eurekaServer.readTimeout or eurekaServer.connectTimeout as milliseconds, not seconds.\nTo fix the inconsistencies either the config files must be changed or the interface must be changed. I have changed the config files here, but I can submit the other if that is preferred. \n. This is passing tests locally.\nNote that this will still break with config files that specify either eurekaServer.readTimeout or eurekaServer.connectTimeout as milliseconds, not seconds.\n. @looztra We should be getting back to this within the next few weeks.\n. I looked at finishing this per your recommendations @NiteshKant, and I think that adding another property somewhat defeats the purpose. This can already be accomplished by changing a property. Internally we are now setting numberRegistrySyncRetries=0 to get essentially the same effect. Is there any reason this doesn't work in all cases?\nEither way, I think in another thread (https://github.com/Netflix/eureka/issues/42) you said that having a mode that starts without peers would be beneficial outside of this use case, if you are still thinking this makes sense I can fix up this PR.\nThoughts?\n. @NiteshKant I hit a few snags on this one...\n1) The proposal was to check if peerEurekaNodes was empty before syncUp. However, on my box when run locally, peerEurekaNodes is not empty becuase my local computer makes it into the list. This is because the PeerAwareInstanceRegistry.isThisMe method doesn't work in this circumstance.\nMy computers hostname is username.local, and the default files shipped with Eureka specify localhost as the default serviceUrl for testing locally. So the hostname comparison is never equal. (It works in AWS because the hostname is actually retrieved from ec2 metadata)\nPotential solutions for this: \n- When testing locally, have serviceUrls be \"localmode\" or some other non-URL flag that you special case.\n- Require people put their actual hostname in the config. (Not a big fan of this option, one more step to get everything up and running to test out Eureka)\nOther solutions to the original problem:\n- Leave the local computer in the peerEureka Nodes list. Now before syncUp see if that is the only peer in the list with a special case and skip the syncUp if it is.\n- The testing mode proposed could instead skip looking for other servers.\n- Just add to the wiki that people should set numberRegistrySyncRetries=0 for testing (worth considering again).\n2) I also looked at adding a new property to make it fail fast if the client doesn't discover any servers. But where would that go? There isn't a central place where the servers are resolved on startup (nor should there probably be). Am I missing some obvious place where this check could go?\nObviously 2 only applies if we stick with the approach we previously discussed. Tagging @bpollack so he sees this.\n. I thought about that and I think it is really no different from putting in a special flag in the service URL. In that case you would only be able to check if the service URL is equal to InetAddress.getLocalHost().getHostAddress() if the service URL is 127.0.0.1 (Because those are always equal). So instead it would make sense to just return true from isThisME() if the service URL is 127.0.0.1.\nI am fine with doing that and I can't think of any valid cases this would mess up. You could potentially deploy to ec2 with 127.0.0.1 as the service URL... but I don't think we really need to worry about that.\nIf we do go ahead with that, can you respond to point 2) in my post from 14 days ago.\n. I am fine with this being closed @qiangdavidliu. I do still think that it should be documented in the wiki if the code isn't changed though.\n. The log message is deceiving as-is. Another fix would be to change the log message to be:\nlogger.debug(\"The total number of UP instances in the client now is {}\", totInstances);\nLet me know which you would prefer.\n. A few points to make about the \"Fix appsHashCode not getting updated\" commit.\n- There could be other code paths I have missed where AppsHashCode isn't getting set correctly. It is currently inconsistent where it is set. In InstanceRegistry it is set in getApplicationsFromMultipleRegions but there isn't an analogous place in DiscoveryClient. This should probably be rethought, I think it made it easy to miss this bug.\n- Why is AbstractDiscoveryClientTester.CLIENT_REFRESH_RATE = 10? Can we lower it to speed up the tests?\n- This code reconcileHashCode.equals(delta.getAppsHashCode()) In fetchRegistry will not return false and log differences if one app goes from UP to DOWN and another from DOWN to UP. Is this not a concern?\n. My first point was more about when/where AppsHashCode should be set. I followed the pattern already in the code, but I really think it would be cleaner if it was managed by the Applications class, where it is stored. Then anytime the apps changed the AppsHashCode would be updated. This is a bit tricker because if someone changes instances through Application and not Applications, then AppHashCode would still have to be updated.\nEither way at this point that is something long term to consider. Please merge this immediate fix.\n. ",
    "looztra": "any news regarding this topic?\n. ",
    "ahu0605": "why i have two thread is same name \u201c Daemon Thread [Eureka-JerseyClient-Conn-Cleaner2] (Running)\u201d \n. ",
    "jhohertz": "Just an added data point, 1.1.131 is confirmed to work fine, so this regression comes from a later commit.\n. I've captured some logs, but they'e fairly long, happy to email them to you?\nFrom the client side of it, it looks to be trying the right thing, trying to reach an existing Eureka server via the DNS records, cycles through all of them (getting not found as nothing has bound the IPs yet), which is normal in my experience as it's initializing, once it's cycled through them all, I see this:\n2014-05-21 19:02:44,295 WARN  com.netflix.discovery.DiscoveryClient:1611 [main] [fetchRegistryFromBackup] No backup registry instance defined & unable to find any discovery servers.\n2014-05-21 19:02:44,298 INFO  com.netflix.discovery.DiscoveryClient:1048 [main] [initScheduledTasks] Starting heartbeat executor: renew interval is: 30\n2014-05-21 19:02:45,170 INFO  com.netflix.eureka.PeerAwareInstanceRegistry:218 [main] [updatePeerEurekaNodes] Adding replica node: http://ec2-54-243-35-38.compute-1.amazonaws.com:80/eureka/v2/\n2014-05-21 19:02:45,776 INFO  com.netflix.eureka.PeerAwareInstanceRegistry:218 [main] [updatePeerEurekaNodes] Adding replica node: http://ec2-54-243-35-32.compute-1.amazonaws.com:80/eureka/v2/\n2014-05-21 19:02:46,735 INFO  com.netflix.eureka.PeerAwareInstanceRegistry:218 [main] [updatePeerEurekaNodes] Adding replica node: http://ec2-54-243-35-42.compute-1.amazonaws.com:80/eureka/v2/\n2014-05-21 19:02:47,281 INFO  com.netflix.eureka.PeerAwareInstanceRegistry:236 [main] [updatePeerEurekaNodes] Updating the replica nodes as they seem to have changed from [] to [http://ec2-54-243-35-38.compute-1.amazonaws.com:80/eureka/v2/, http://ec2-54-243-35-32.compute-1.amazonaws.com:80/eureka/v2/, http://ec2-54-243-35-42.compute-1.amazonaws.com:80/eureka/v2/] \n2014-05-21 19:03:14,297 INFO  com.netflix.discovery.DiscoveryClient:638 [pool-4-thread-1] [fetchRegistry] Disable delta property : false\n2014-05-21 19:03:14,299 INFO  com.netflix.discovery.DiscoveryClient:639 [pool-4-thread-1] [fetchRegistry] Force full registry fetch : false\n2014-05-21 19:03:14,299 INFO  com.netflix.discovery.DiscoveryClient:640 [pool-4-thread-1] [fetchRegistry] Application is null : false\n2014-05-21 19:03:14,303 INFO  com.netflix.discovery.DiscoveryClient:641 [pool-4-thread-1] [fetchRegistry] Registered Applications size is zero : true\n2014-05-21 19:03:14,304 INFO  com.netflix.discovery.DiscoveryClient:643 [pool-4-thread-1] [fetchRegistry] Application version is -1: true\nAt which we cycle into the routine seeing as when we have a single node up and it's looking for it's peers endlessly.\nFrom the status page, it had all the replicas listed as available and registered....\n... and as I went to grab a screenshot of that, I now see it's gotten past this somehow, I have a valid 3-node cluster of nodes... perhaps I was too impatient with it earlier... I'll try shutting it down and up again a couple time to see if I just got lucky here...\n. I've so far been unable to reproduce the issue I reported, perhaps it was something transient. (No longer have the log from the original failure... so can't check)\n@NiteshKant,  my apologies for any harm to your signal-to-noise ratio, I'll close this off for now, can always re-open if I run into it again.\n. ",
    "jboulon": "See https://github.com/Netflix/eureka/pull/134 for the fix\n. I was thinking of doing that, however it does not solve the problem for current users running Eureka in DC so that's why I came with this patch which is the first one.\nThen, my idea was to open a new issue and fix it by implementing a new interface.\nThat interface will have a Type, Name and will implement isRegistrable as you said.\nOnce we will have that interface, we could then add another if to check for that new interface. However returning false for the default DataCenterInfo seems wrong to me since Eureka is not doing what it was designed to do.\nWithout this patch, everybody running in DC is at risk. After an Eureka re-start, the Eureka node will just never accept the renew of the lease.\nSo as an example:\n- Client1 register with Eureka1 for Service S1\n- Client1 renew with Eureka 2 for S1\n- Eureka3 goes down\n- Client1 renew with Eureka1 or Eureka2 for S1\n- Eureka3 get back online\n- Eureka3 will reject all existing node <-- Default is to return false\n- Client3 talk to Eureka3 and ask for service S1\n  ---> Eureka3 will return an empty list even if Client1 is actually registered on Eureka 1 and 2\nInstead what everybody is expecting to get the Client1 information.\nNobody expect this to be the default for Eureka. With this patch we can still return false if that what we want but I'm not sure why you'll want that?\nSo I can work on getting a new clean interface out but no matter what, the current code is not working for DC and should be fixed first.\nThen we can add a new if ( XXX instanceOf YYYY) check to implement something more like AmazonInfo but for data centers.\nMy answer will have been different if Java8 was in use everywhere since we could have play with the default implementation but this is not yet an option.\n. I'm actually running this code in production so the sooner it get merged, the better is.\nSo is it possible to merge this PR?\nThanks,\n. The default value for the property is True, so there's no need to add it to your config file and at the same time, it gives you the ability to have the same behavior as we used to have.\n. ",
    "christorpelund": "@NiteshKant we're trying to expose the mock eureka server as a test dependency so we can do TDD against our own opinionated client library.\n. ",
    "futurely": "Why not both ids?\nclass GloballyUniqueIDs {\n  String clientID;\n  String serverID;\n   ...\n}\n. Sync API over async implementation may not be beneficial.\nShould I expose synchronous wrappers for asynchronous methods?\nGood practice - Use the sync-over-async invocation pattern with caution\n. ",
    "davidcurrie": "Hi, nothing has happened at this point other than that the classes have been loaded. So, other than trying to hook a call to contextInitialized in to the static initialization (which seems completely wrong) I'm not sure where I could call this from. The initialization does happen, it's just after the statics have already tried to grab the uninitialized instances so deferring the latter through one of the three options above seems to make more sense.\n. Hi @qiangdavidliu - This is the WebSphere Liberty Profile, not Full Profile, so that classloader hierarchy does not apply. I should probably declare that I work for the IBM WebSphere development team so I know exactly where the JAX-RS classes are being initialised and I still think the right thing is for Eureka not to rely on the bootstrapping having occurred before then.\n. Hi @qiangdavidliu - the problem also applies (indirectly) to PeerAwareInstanceRegistry. Change would look as follows: https://github.com/davidcurrie/eureka/commit/7a3fd8bde67de4bcfdc623415924210279a3c822\n. Great - look forward to picking that up.\n. ",
    "bpitman": "Did you test this?  I'm pretty sure this alone won't get around the bug in the jersey apache client.  If proxyhost is set, username and password are required.\n. ",
    "pparth": "Anything new on that guys?\n. Sure! @krutsko and i, will give it a try.\n. So, @qiangdavidliu is this actually a bug or something? Can you explain please more about the issue and its impact to Eureka availability, reliability etc.?\nAlso, this issue seems that it is server-related only. Can we update only the server version and keep 1.1.151 for the clients?\n. Indeed, this has to do with the StatusResource and we do have a customised Eureka Service and do not use the original war. We were just wandering whether this error is not only about status and has a deeper root cause as we  have a replication issue. @drax68  please provide more info about this.\n. @qiangdavidliu \n- Unfortunately, we think this issue raises its ugly head not only in a manual/administrative cluster upgrade but also in a standard failure pattern where a client cannot communicate with a server instance due to a network issue (e.g. for us, the ELB in front of the instance, croaked). This led all clients registered to this instance to switch to another server instance, which is what expected from the highly available Eureka setup we have in place. However, everything went south, as all our clients register themselves as STARTING and then we switch them to UP through the REST API, as part of a deployment workflow process we have in place. So, we ended up with ALL these clients switching back to STARTING and then all traffic stopped! There goes the highly available cluster! \n- At any case, we thought that the STARTING status was in place exactly to support this kind of workflow process. What are we doing wrong then? That we override/change the status externally through the REST API? If we allowed the instance to change its status on its own, from STARTING to UP, is everything going to work ok? We can do that if this solves the issue, however, this does not feel right as we pretend that the instance knows when it is ok to receive traffic when this is definitely an external, deployment-driven decision.\n- Please provide then, what is the usefulness of having an override status in addition to the standard status. Why the REST API does not change the original status field? Where is the override concept used? \n- Can you explain more what is \"we set overrides at an (EC2) ASG level, and that is guarded by AwsAsgUtil.java\"?\n. Got it.\nUnfortunately, in our case, we maintain multiple Service types per machine in an ASG, so, we cannot link the ASG disables to a specific Service type Eureka status.\nRegarding the status overrides, it seems that we are back to zero. According to you, the overrides should be preserved in our case. So, @drax68  please check again about our case and dig up more information about what exactly happened in our system.\n. @qiangdavidliu Can you take a look at our latest information regarding the issue please?\n. Anything about this?. Any news here?. You cannot. Eureka is an instance-level registry. There is no place for service-level metadata in the registry hierarchy. Unfortunately, you will have to add any metadata at the instance level. \nConsul has support for service-level information. . @qiangdavidliu We have found out that when Eureka system gets into a \"registry inconsistency mode\" and many clients start executing full registry fetches, all these service instances exhibit high GC pauses for the specific time period, probably due to the downloading of full registries. This behaviour is definitely scary and we would like to know whether we operate at the limit of a Eureka system (at least one that is based on the open-sourced version) or not. We have around 1500 service instances registered in eureka now and the full registry fetch (along with the metadata we attach) is maybe 100MB of size. Do you feel that this may be a problematic setup? Do you have any information about scaling you can provide?. @qiangdavidliu  Are you using Eureka to store service instance metadata? Do you think that this is a bad practise?\nIf the size of your registry is orders of magnitude larger, how do you handle full registry fetches? When such fetches happen, they must download tons of data, no? . @qiangdavidliu Well, in our case, we consider frequent full registry fetches to be an issue. Especially in times when multiple clients execute full registry fetches at the same time, we have seen that we end up with resource starvation problems. What is your opinion on that?. @qiangdavidliu Any help here?. Any comment here guys?. Anything new about this guys? Are we ok to proceed with the PRs we submitted? . Shouldn't we open an issue first, linked to this PR?. Can someone check this PR please?. Can someone take a look and merge this PR please? It is rather straight forward. . ",
    "krutsko": "i created a PR https://github.com/Netflix/eureka/pull/272 with initial approach, please take a look.\n. @qiangdavidliu you're welcome. nice to be a little helpful :)\n. PR https://github.com/Netflix/eureka/pull/1125. PR #1132 . @qiangdavidliu It will be great to have this released sooner than later. Thanks!. @qiangdavidliu thanks for looking into this. I have fixed all comments.. @pparth  I guess it doesn't matter, but here it's https://github.com/Netflix/eureka/issues/1158. Can someone take a look at the PR, and re-run the tests (they all pass on my local machine) ?. who could take a look at the PR?\nThanks. Fixed. Make it local instance variable.\n. Fixed.. Fixed.. I have changed to INFO. If you think that DEBUG is even better here, let me know. In our case, we don't have so much spot-instances termination.. Got it. Fixed.. Right. Fixed.. Sure. Changed to spotTerminationTime.. it's not an expensive request, we don't make a network call, just initialize context where it re-check dns server on the local machine. \nHere the implementation of dns server resolution for Linux on AdoptOpenJDK 11 (a first link i can found) https://github.com/AdoptOpenJDK/openjdk-jdk11/blob/master/src/java.base/unix/classes/sun/net/dns/ResolverConfigurationImpl.java\nIt caches \"/etc/resolv.conf\" parsing for 5 minutes.. That's a good point. I have changed all invocations and ensure that this RuntimeException properly caught and logged.. @elandau thanks for looking into this.\nYes, i have reverted to static DnsResolver, somehow missed this at first place.. ",
    "keithbranton": "I'm not sure why/how this caused the cloudbees failure report. It's hard to tell if I introduced a regression - I can do a ./gradlew clean build on my fork without any tests breaking. If I did cause this, can you please give me a pointer and I'll fix it.\n. It causes keystore and truststore to be configured for the socket via\nsystem properties like:\n-Djavax.net.ssl.keyStoreType=pkcs12\n-Djavax.net.ssl.keyStore=src/test/resources/testServer.p12\n-Djavax.net.ssl.keyStorePassword=password\n-Djavax.net.ssl.trustStoreType=jks\n-Djavax.net.ssl.trustStore=src/test/resources/server.jks\n-Djavax.net.ssl.trustStorePassword=password\nWe use certificates to ensure a rogue service cannot impersonate a service,\nand in the case of eureka, register itself as a service that it is not.\n. The Eureka server seems to create three clients; the RemoteRegionRegistry\none at 78-98 which is easy, and one in DiscoveryClient line 295 which is a\nbit of a mess because of the proxy support, and it not using a factory\nmethod, and another in PeerEurekaNode line 114 which would be easy. Our\nminimalist patch deals with all three in one place and just a few lines of\ncode.\nDIscoveryClient is harder because it creates the connection manager, then\nsets up the proxy, then calls the JerseyClient constructor directly. Maybe\nthis should be refactored into another static factory method first -\nEurekaJerseyClient.createProxyJerseyClient? Either that or I could\nconditionally generate a different ClientConfig in DiscoveryClient around\nline 272, and then let all the proxy stuff go through as normal. I'm not\nsure that supporting https and proxy at the same time makes much sense\nthough - we certainly don't need it, and from the look of this line:\ncc.getProperties().put(DefaultApacheHttpClient4Config.PROPERTY_PROXY_URI,\n\"http://\" + proxyHost + \":\" + proxyPort);\nit wouldn't work without a little more work anyway.\nThis is your project, and I'm happy to spend more time getting this to a\npoint where you are happy with the pull request. I just wanted to check if\nyou really want this change made in so many places, and your preferred\napproach to DiscoveryClient.\nThanks.\n. @bitsofinfo It's been a long time and I haven't used this since I contributed it, but looking at the patch I think it should be working with the DiscoveryClient.\n. ",
    "bitsofinfo": "@keithbranton\nIs this supposed to be working w/ the discovery client or no (per the previous comments)?\n. @keithbranton k thanks, yeah it seems to be broken: https://github.com/Netflix/eureka/issues/812\n. Thank you, such a quick response. Thanks man\n. thanks, Yes I ran the 1.4.10-rc.1 in a debugger in my app and now it properly invokes createSystemSslCM()  when buildLegacy is invoked. \n@qiangdavidliu Quick question, what would be the best strategy to have this use a custom HostnameVerifier? I don't see a way to configure that. Should I open a separate ticket?\n. @Jumpy-Squirrel does this solve your issue at: https://github.com/spring-cloud/spring-cloud-netflix/issues/1077\n. should this be closed?. ",
    "benjchristensen": "Here is what I'm referencing in 2.x: https://github.com/Netflix/eureka/blob/2.x/eureka-core/build.gradle#L30\n. +1\n. Next week is good. Thank you.\n. ",
    "tkowalcz": "Sure I can. Somewhere on line 47?\n. ",
    "ghost": "Yup. Here is the test output as well as the standard out. The standard error follows:\njava.lang.AssertionError: Apps size from remote regions do not match expected:<2> but was:<1>\n    at org.junit.Assert.fail(Assert.java:93)\n    at org.junit.Assert.failNotEquals(Assert.java:647)\n    at org.junit.Assert.assertEquals(Assert.java:128)\n    at org.junit.Assert.assertEquals(Assert.java:472)\n    at com.netflix.eureka.InstanceRegistryTest.testGetAppsDeltaFromAllRemoteRegions(InstanceRegistryTest.java:41)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nStandard out:\nCreated eureka server mock with applications map { name : MYAPP , instance count: 1 } and applications delta map { name : MYAPP , instance count: 1 }\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860360861\n1416860360861\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860360861\n1416860360861\n\n\n\nCreated eureka server mock with applications map { name : MYAPP , instance count: 1 } and applications delta map { name : MYAPP , instance count: 1 }\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860362703\n1416860362703\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860362703\n1416860362703\n\n\n\nCreated eureka server mock with applications map { name : MYAPP , instance count: 1 } and applications delta map { name : MYAPP , instance count: 1 }\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363052\n1416860363052\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363052\n1416860363052\n\n\n\nCanceling application: MYLOCAPP from local registry.\nCanceling application: MYLOCAPP from local registry.\nCreated eureka server mock with applications map { name : MYAPP , instance count: 1 } and applications delta map { name : MYAPP , instance count: 1 }\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nSleeping for 10 seconds to let the remote registry fetch delta. Attempt: 0\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860363425\n1416860363425\n\n\n\nDone sleeping for 10 seconds to let the remote registry fetch delta\nCanceling application: MYLOCAPP from local registry.\nCreated eureka server mock with applications map { name : MYAPP , instance count: 1 } and applications delta map { name : MYAPP , instance count: 1 }\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860373803\n1416860373803\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860373803\n1416860373803\n\n\n\nCanceling application: MYLOCAPP from local registry.\nCreated eureka server mock with applications map { name : MYAPP , instance count: 1 } and applications delta map { name : MYAPP , instance count: 1 }\nEureka resource mock, received request on path: /eureka/v2/apps/delta. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/delta with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860374169\n1416860374169\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860374169\n1416860374169\n\n\n\nEureka resource mock, received request on path: /eureka/v2/apps/. HTTP method: |GET|\nEureka resource mock, sent response for request path: /eureka/v2/apps/ with content\n-1\nUP_1_\n\nMYAPP\n\nblah\nMYAPP\n10.10.101.1\nUP\nUNKNOWN\n7001\n7002\n1\n\nAmazon\n\nXXX\nblah\nblah\nXXX\nXXX\nXXX\nus-east-1c\n\n\n\n30\n90\n0\n0\n0\n0\n\n\nfalse\n1416860374169\n1416860374169\n\n\n\nCanceling application: MYLOCAPP from local registry.\nStandard Error:\n148 [Test worker] WARN com.netflix.config.sources.URLConfigurationSource - No URLs will be polled as dynamic configuration sources.\n163 [Test worker] INFO com.netflix.config.sources.URLConfigurationSource - To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.\n188 [Test worker] INFO com.netflix.config.DynamicPropertyFactory - DynamicPropertyFactory is initialized with configuration sources: com.netflix.config.ConcurrentCompositeConfiguration@48ba29f\n300 [Test worker] INFO org.mortbay.log - Logging to org.slf4j.impl.SimpleLogger(org.mortbay.log) via org.mortbay.log.Slf4jLog\n315 [Test worker] INFO org.mortbay.log - jetty-6.1H.22\n348 [Test worker] INFO org.mortbay.log - Started SocketConnector@0.0.0.0:7777\n387 [Test worker] WARN com.netflix.eureka.DefaultEurekaServerConfig - Cannot find the properties specified : eureka-server. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n495 [Test worker] WARN com.netflix.discovery.DefaultEurekaClientConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n1110 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Disable delta property : false\n1110 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null\n1110 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Force full registry fetch : false\n1110 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application is null : false\n1110 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true\n1110 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application version is -1: true\n1549 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server\n1610 [Test worker] INFO com.netflix.discovery.DiscoveryClient - The response status is 200\n1613 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30\n1629 [Test worker] WARN com.netflix.appinfo.PropertiesInstanceConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n1630 [Test worker] INFO com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider - Setting initial instance status as: STARTING\n1681 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n1823 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n1826 [Test worker] WARN com.netflix.eureka.PeerAwareInstanceRegistry - Cannot register the JMX monitor for the InstanceRegistry :\njava.lang.IllegalArgumentException: value cannot be empty\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:119)\n    at com.netflix.servo.tag.BasicTag.checkNotEmpty(BasicTag.java:40)\n    at com.netflix.servo.tag.BasicTag.(BasicTag.java:34)\n    at com.netflix.servo.tag.Tags.newTag(Tags.java:53)\n    at com.netflix.servo.monitor.MonitorConfig$Builder.withTag(MonitorConfig.java:57)\n    at com.netflix.servo.monitor.Monitors.newObjectConfig(Monitors.java:371)\n    at com.netflix.servo.monitor.Monitors.newObjectMonitor(Monitors.java:150)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:207)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:181)\n    at com.netflix.eureka.PeerAwareInstanceRegistry.(PeerAwareInstanceRegistry.java:138)\n    at com.netflix.eureka.AbstractTester$2.(AbstractTester.java:86)\n    at com.netflix.eureka.AbstractTester.setUp(AbstractTester.java:86)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n1830 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n1903 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n1990 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Disable delta property : false\n1990 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Application is null : false\n1990 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Registered Applications size is zero : true\n1990 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : false\n1998 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - The response status is 200\n1999 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Finished initializing remote region registries. All known remote regions: [us-east-1]\n1999 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: true, Regions argument [us-east-1]\n2105 [Test worker] INFO org.mortbay.log - jetty-6.1H.22\n2107 [Test worker] INFO org.mortbay.log - Started SocketConnector@0.0.0.0:7777\n2108 [Test worker] WARN com.netflix.eureka.DefaultEurekaServerConfig - Cannot find the properties specified : eureka-server. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2108 [Test worker] WARN com.netflix.discovery.DefaultEurekaClientConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2171 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Disable delta property : false\n2171 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null\n2171 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Force full registry fetch : false\n2171 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application is null : false\n2171 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true\n2171 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application version is -1: true\n2177 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server\n2181 [Test worker] INFO com.netflix.discovery.DiscoveryClient - The response status is 200\n2182 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30\n2187 [Test worker] WARN com.netflix.appinfo.PropertiesInstanceConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2187 [Test worker] INFO com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider - Setting initial instance status as: STARTING\n2192 [Test worker] WARN com.netflix.eureka.PeerAwareInstanceRegistry - Cannot register the JMX monitor for the InstanceRegistry :\njava.lang.IllegalArgumentException: value cannot be empty\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:119)\n    at com.netflix.servo.tag.BasicTag.checkNotEmpty(BasicTag.java:40)\n    at com.netflix.servo.tag.BasicTag.(BasicTag.java:34)\n    at com.netflix.servo.tag.Tags.newTag(Tags.java:53)\n    at com.netflix.servo.monitor.MonitorConfig$Builder.withTag(MonitorConfig.java:57)\n    at com.netflix.servo.monitor.Monitors.newObjectConfig(Monitors.java:371)\n    at com.netflix.servo.monitor.Monitors.newObjectMonitor(Monitors.java:150)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:207)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:181)\n    at com.netflix.eureka.PeerAwareInstanceRegistry.(PeerAwareInstanceRegistry.java:138)\n    at com.netflix.eureka.AbstractTester$2.(AbstractTester.java:86)\n    at com.netflix.eureka.AbstractTester.setUp(AbstractTester.java:86)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n2196 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n2263 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n2343 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Disable delta property : false\n2343 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Application is null : false\n2343 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Registered Applications size is zero : true\n2343 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : false\n2353 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - The response status is 200\n2353 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Finished initializing remote region registries. All known remote regions: [us-east-1]\n2454 [Test worker] INFO org.mortbay.log - jetty-6.1H.22\n2456 [Test worker] INFO org.mortbay.log - Started SocketConnector@0.0.0.0:7777\n2456 [Test worker] WARN com.netflix.eureka.DefaultEurekaServerConfig - Cannot find the properties specified : eureka-server. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2457 [Test worker] WARN com.netflix.discovery.DefaultEurekaClientConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2533 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Disable delta property : false\n2533 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null\n2533 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Force full registry fetch : false\n2533 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application is null : false\n2533 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true\n2533 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application version is -1: true\n2538 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server\n2542 [Test worker] INFO com.netflix.discovery.DiscoveryClient - The response status is 200\n2543 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30\n2549 [Test worker] WARN com.netflix.appinfo.PropertiesInstanceConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2549 [Test worker] INFO com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider - Setting initial instance status as: STARTING\n2553 [Test worker] WARN com.netflix.eureka.PeerAwareInstanceRegistry - Cannot register the JMX monitor for the InstanceRegistry :\njava.lang.IllegalArgumentException: value cannot be empty\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:119)\n    at com.netflix.servo.tag.BasicTag.checkNotEmpty(BasicTag.java:40)\n    at com.netflix.servo.tag.BasicTag.(BasicTag.java:34)\n    at com.netflix.servo.tag.Tags.newTag(Tags.java:53)\n    at com.netflix.servo.monitor.MonitorConfig$Builder.withTag(MonitorConfig.java:57)\n    at com.netflix.servo.monitor.Monitors.newObjectConfig(Monitors.java:371)\n    at com.netflix.servo.monitor.Monitors.newObjectMonitor(Monitors.java:150)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:207)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:181)\n    at com.netflix.eureka.PeerAwareInstanceRegistry.(PeerAwareInstanceRegistry.java:138)\n    at com.netflix.eureka.AbstractTester$2.(AbstractTester.java:86)\n    at com.netflix.eureka.AbstractTester.setUp(AbstractTester.java:86)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n2555 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n2631 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n2695 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Disable delta property : false\n2695 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Application is null : false\n2695 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Registered Applications size is zero : true\n2695 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : false\n2704 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - The response status is 200\n2704 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Finished initializing remote region registries. All known remote regions: [us-east-1]\n2723 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Registered instance id blahloc with status UP\n2724 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Registered instance id blahloc with status UP\n2724 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: true, Regions argument [us-east-1]\n2825 [Test worker] WARN com.netflix.eureka.InstanceRegistry - DS: Registry: cancel failed because Lease is not registered for: MYLOCAPP:MYLOCAPP\n2825 [Test worker] WARN com.netflix.eureka.InstanceRegistry - DS: Registry: cancel failed because Lease is not registered for: MYLOCAPP:MYLOCAPP\n2906 [Test worker] INFO org.mortbay.log - jetty-6.1H.22\n2908 [Test worker] INFO org.mortbay.log - Started SocketConnector@0.0.0.0:7777\n2909 [Test worker] WARN com.netflix.eureka.DefaultEurekaServerConfig - Cannot find the properties specified : eureka-server. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2909 [Test worker] WARN com.netflix.discovery.DefaultEurekaClientConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2966 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Disable delta property : false\n2966 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null\n2966 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Force full registry fetch : false\n2966 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application is null : false\n2966 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true\n2966 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application version is -1: true\n2970 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server\n2972 [Test worker] INFO com.netflix.discovery.DiscoveryClient - The response status is 200\n2973 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30\n2977 [Test worker] WARN com.netflix.appinfo.PropertiesInstanceConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n2977 [Test worker] INFO com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider - Setting initial instance status as: STARTING\n2978 [Test worker] WARN com.netflix.eureka.PeerAwareInstanceRegistry - Cannot register the JMX monitor for the InstanceRegistry :\njava.lang.IllegalArgumentException: value cannot be empty\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:119)\n    at com.netflix.servo.tag.BasicTag.checkNotEmpty(BasicTag.java:40)\n    at com.netflix.servo.tag.BasicTag.(BasicTag.java:34)\n    at com.netflix.servo.tag.Tags.newTag(Tags.java:53)\n    at com.netflix.servo.monitor.MonitorConfig$Builder.withTag(MonitorConfig.java:57)\n    at com.netflix.servo.monitor.Monitors.newObjectConfig(Monitors.java:371)\n    at com.netflix.servo.monitor.Monitors.newObjectMonitor(Monitors.java:150)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:207)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:181)\n    at com.netflix.eureka.PeerAwareInstanceRegistry.(PeerAwareInstanceRegistry.java:138)\n    at com.netflix.eureka.AbstractTester$2.(AbstractTester.java:86)\n    at com.netflix.eureka.AbstractTester.setUp(AbstractTester.java:86)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n2980 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n3035 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n3094 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Disable delta property : false\n3094 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Application is null : false\n3094 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Registered Applications size is zero : true\n3094 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : false\n3102 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - The response status is 200\n3102 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Finished initializing remote region registries. All known remote regions: [us-east-1]\n3102 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: true, Regions argument [us-east-1]\n3103 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Registered instance id blahloc2 with status UP\n6999 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n7353 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n7704 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n8102 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n11999 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n12353 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n12704 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n13102 [Eureka-RemoteRegionCacheRefresher] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : true\n13103 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: true, Regions argument [us-east-1]\n13204 [Test worker] WARN com.netflix.eureka.InstanceRegistry - DS: Registry: cancel failed because Lease is not registered for: MYLOCAPP:MYLOCAPP\n13205 [Test worker] INFO org.mortbay.log - jetty-6.1H.22\n13207 [Test worker] INFO org.mortbay.log - Started SocketConnector@0.0.0.0:7777\n13209 [Test worker] WARN com.netflix.eureka.DefaultEurekaServerConfig - Cannot find the properties specified : eureka-server. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n13209 [Test worker] WARN com.netflix.discovery.DefaultEurekaClientConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n13288 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Disable delta property : false\n13288 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null\n13288 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Force full registry fetch : false\n13288 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application is null : false\n13289 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true\n13289 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application version is -1: true\n13295 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server\n13299 [Test worker] INFO com.netflix.discovery.DiscoveryClient - The response status is 200\n13300 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30\n13306 [Test worker] WARN com.netflix.appinfo.PropertiesInstanceConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n13307 [Test worker] INFO com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider - Setting initial instance status as: STARTING\n13310 [Test worker] WARN com.netflix.eureka.PeerAwareInstanceRegistry - Cannot register the JMX monitor for the InstanceRegistry :\njava.lang.IllegalArgumentException: value cannot be empty\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:119)\n    at com.netflix.servo.tag.BasicTag.checkNotEmpty(BasicTag.java:40)\n    at com.netflix.servo.tag.BasicTag.(BasicTag.java:34)\n    at com.netflix.servo.tag.Tags.newTag(Tags.java:53)\n    at com.netflix.servo.monitor.MonitorConfig$Builder.withTag(MonitorConfig.java:57)\n    at com.netflix.servo.monitor.Monitors.newObjectConfig(Monitors.java:371)\n    at com.netflix.servo.monitor.Monitors.newObjectMonitor(Monitors.java:150)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:207)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:181)\n    at com.netflix.eureka.PeerAwareInstanceRegistry.(PeerAwareInstanceRegistry.java:138)\n    at com.netflix.eureka.AbstractTester$2.(AbstractTester.java:86)\n    at com.netflix.eureka.AbstractTester.setUp(AbstractTester.java:86)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n13312 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n13402 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n13463 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Disable delta property : false\n13463 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Application is null : false\n13463 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Registered Applications size is zero : true\n13463 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : false\n13469 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - The response status is 200\n13469 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Finished initializing remote region registries. All known remote regions: [us-east-1]\n13469 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Registered instance id blahloc with status UP\n13469 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: false, Regions argument []\n13570 [Test worker] WARN com.netflix.eureka.InstanceRegistry - DS: Registry: cancel failed because Lease is not registered for: MYLOCAPP:MYLOCAPP\n13570 [Test worker] INFO org.mortbay.log - jetty-6.1H.22\n13572 [Test worker] INFO org.mortbay.log - Started SocketConnector@0.0.0.0:7777\n13573 [Test worker] WARN com.netflix.eureka.DefaultEurekaServerConfig - Cannot find the properties specified : eureka-server. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n13573 [Test worker] WARN com.netflix.discovery.DefaultEurekaClientConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n13630 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Disable delta property : false\n13630 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Single vip registry refresh property : null\n13630 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Force full registry fetch : false\n13630 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application is null : false\n13630 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Registered Applications size is zero : true\n13630 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Application version is -1: true\n13635 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Getting all instance registry info from the eureka server\n13637 [Test worker] INFO com.netflix.discovery.DiscoveryClient - The response status is 200\n13637 [Test worker] INFO com.netflix.discovery.DiscoveryClient - Starting heartbeat executor: renew interval is: 30\n13640 [Test worker] WARN com.netflix.appinfo.PropertiesInstanceConfig - Cannot find the properties specified : eureka-client. This may be okay if there are other environment specific properties or the configuration is installed with a different mechanism.\n13640 [Test worker] INFO com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider - Setting initial instance status as: STARTING\n13642 [Test worker] WARN com.netflix.eureka.PeerAwareInstanceRegistry - Cannot register the JMX monitor for the InstanceRegistry :\njava.lang.IllegalArgumentException: value cannot be empty\n    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:119)\n    at com.netflix.servo.tag.BasicTag.checkNotEmpty(BasicTag.java:40)\n    at com.netflix.servo.tag.BasicTag.(BasicTag.java:34)\n    at com.netflix.servo.tag.Tags.newTag(Tags.java:53)\n    at com.netflix.servo.monitor.MonitorConfig$Builder.withTag(MonitorConfig.java:57)\n    at com.netflix.servo.monitor.Monitors.newObjectConfig(Monitors.java:371)\n    at com.netflix.servo.monitor.Monitors.newObjectMonitor(Monitors.java:150)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:207)\n    at com.netflix.servo.monitor.Monitors.registerObject(Monitors.java:181)\n    at com.netflix.eureka.PeerAwareInstanceRegistry.(PeerAwareInstanceRegistry.java:138)\n    at com.netflix.eureka.AbstractTester$2.(AbstractTester.java:86)\n    at com.netflix.eureka.AbstractTester.setUp(AbstractTester.java:86)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)\n    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)\n    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)\n    at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)\n    at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)\n    at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)\n    at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)\n    at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)\n    at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)\n    at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)\n    at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)\n    at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)\n    at org.junit.runners.ParentRunner.run(ParentRunner.java:300)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)\n    at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)\n    at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)\n    at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)\n    at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)\n    at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:483)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)\n    at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)\n    at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)\n    at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\n13643 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Adding replica node: http://localhost:7777/eureka/v2/\n13693 [Test worker] INFO com.netflix.eureka.PeerAwareInstanceRegistry - Updating the replica nodes as they seem to have changed from [] to [http://localhost:7777/eureka/v2/] \n13755 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Disable delta property : false\n13756 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Application is null : false\n13756 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Registered Applications size is zero : true\n13756 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - Getting instance registry info from the eureka server : http://localhost:7777//eureka/v2/ , delta : false\n13761 [Test worker] INFO com.netflix.eureka.RemoteRegionRegistry - The response status is 200\n13761 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Finished initializing remote region registries. All known remote regions: [us-east-1]\n13761 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: true, Regions argument [us-east-1]\n13762 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Registered instance id blahloc2 with status UP\n13762 [Test worker] INFO com.netflix.eureka.InstanceRegistry - Fetching applications registry with remote regions: true, Regions argument [us-east-1]\n13863 [Test worker] WARN com.netflix.eureka.InstanceRegistry - DS: Registry: cancel failed because Lease is not registered for: MYLOCAPP:MYLOCAPP\n. I'll do that. But, I am familiar with gradle.  I ran /gradlew clean build.\nI'll let you know what I come up with.\nOn Nov 25, 2014 1:46 AM, \"qiangdavidliu\" notifications@github.com wrote:\n\nHi, it looks like from the logs you are running the tests in a worker\nthread? Can you share your test setup (IDE, cmdline etc)? Additionally, can\nyou try to \"./gradlew clean test\" to see if a cmdline test of eureka works\nfor your environment? You can also use \"./gradlew\n-Dtest.single=InstanceRegistryTest :eureka-core:test\" to execute only the\nunit test in question on your cmdline. Thanks.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/265#issuecomment-64321319.\n. Im also running in Windoze. I know. I know. :-)\nOn Nov 25, 2014 1:46 AM, \"qiangdavidliu\" notifications@github.com wrote:\nHi, it looks like from the logs you are running the tests in a worker\nthread? Can you share your test setup (IDE, cmdline etc)? Additionally, can\nyou try to \"./gradlew clean test\" to see if a cmdline test of eureka works\nfor your environment? You can also use \"./gradlew\n-Dtest.single=InstanceRegistryTest :eureka-core:test\" to execute only the\nunit test in question on your cmdline. Thanks.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/265#issuecomment-64321319.\n. Thank you,that is great\n\n2016-03-31 3:46 GMT+08:00 David Liu notifications@github.com:\n\nClosed #762 https://github.com/Netflix/eureka/issues/762.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/issues/762#event-608808695\n. Rebased to fix the two conflicts.. Hello David,\n\nThank you for reviewing this pull request.\nI am currently traveling.  It might take me several days to make these\nchanges, but I will do so the soonest that I am able.\nDaniel\nOn Wed, Nov 1, 2017 at 2:34 PM, David Liu notifications@github.com wrote:\n\n@qiangdavidliu commented on this pull request.\nAgain thanks for the PR. Some minor nits.\nIn eureka-client/src/main/java/com/netflix/discovery/shared/\ntransport/decorator/RetryableEurekaHttpClient.java\nhttps://github.com/Netflix/eureka/pull/969#discussion_r148342330:\n\n@@ -126,7 +126,7 @@ public void shutdown() {\n                 }\n                 logger.warn(\"Request execution failure with status code {}; retrying on another server if available\", response.getStatusCode());\n             } catch (Exception e) {\n-                logger.warn(\"Request execution failed with message: {}\", e.getMessage());  // just log message as the underlying client should log the stacktrace\n+                logger.warn(\"Request execution failed with message: {}\", e.getMessage(), e);  // just log message as the underlying client should log the stacktrace\n\nThe full stacktrace is explicitly not logged here (see comment).\nIn eureka-resources/src/main/resources/css/main.css\nhttps://github.com/Netflix/eureka/pull/969#discussion_r148345599:\n\n@@ -146,7 +146,7 @@ tr.odd {\n span.hlist {\n   padding-right: 10px;\n   margin-right: 10px;\n-  #background-color: #ffffcc;\n+  background-color: #ffffcc;\n\nLet's keep the existing background-color please. Can just delete this line.\nIn eureka-client/src/main/java/com/netflix/discovery/DiscoveryClient.java\nhttps://github.com/Netflix/eureka/pull/969#discussion_r148345811:\n\n@@ -822,7 +820,7 @@ boolean renew() {\n         EurekaHttpResponse httpResponse;\n         try {\n             httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null);\n-            logger.debug(\"{} - Heartbeat status: {}\", PREFIX + appPathIdentifier, httpResponse.getStatusCode());\n+            logger.debug(PREFIX + \"{} - Heartbeat status: {}\", appPathIdentifier, httpResponse.getStatusCode());\n\nAll the PREFIX + in this class can also be moved to PREFIX +\nappPathIdentifier\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Netflix/eureka/pull/969#pullrequestreview-73569824,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAQ6rgOpx6rol3dtGi34nzqjZrPwdaB1ks5syLmqgaJpZM4OgXyf\n.\n. Also, the latest 5 commits are new to the PR.. I have now restored the is*Enabled() checks that guard against wasted computation.. \n",
    "xianhengma": "I see. Thanks for clarifying this!\n. ",
    "amit-git": "I am going to create a separate PR for re-connect logic, but merging this PR in order to get GSON serialization fix in.\n. chatted with David about this review, no major concern - merging\n. doesn't Observable.retry subscribe to the same stream ? I am trying to get a new stream from EurekaClient instead which would potentially connect to a different Read Server. I think I am missing something here\n. right, so I was handling deduping of the stream in browser client (see eureka-reg-ctrl.js). Tomaz mentioned it would be a problem once we have notification compaction in place. I think I'll implement clear reset notification instead. \n. ",
    "rspieldenner": "This will create jdk7 bytecode. We can add a sourceCompatibility line if you prefer jdk6.\nI removed the ide lines because the nebula.netflixoss plugin auto applies those.\n. LGTM. ",
    "scotte": "Looks good, thanks for fixing that! :boat:\n. ",
    "stephenlow": "Jersey Version needs to be updated in build.gradle\n. ",
    "ddatsh": "run it in tomcat 8 & jdk 1.8\n. ",
    "C0rWin": "Ok, I'll take another look and will remove code as you suggested.\n. ",
    "teeratpitakrat": "Hi @qiangdavidliu, I was trying to add eureka as a submodule inside another git project. Then, git modified .git folder of eureka and caused this problem.\nMy temporary solution is to clone eureka and put it inside that git project without committing (which is a little inconvenient).\nIt would be great if eureka can be built without the dependency to git.\n. @qiangdavidliu Unfortunately, I need to edit the source code.\n. ",
    "charleswhchan": "Thanks!\n. ",
    "aspyker": "The only further enhancements I can see:\nOf the 543M that is allocate with the new code:\nInstanceInfo$Builder.setVIPAddress  10M\n- this is due to the regex matching that I think is intended for eureka registration\n- this could benefit from a deser specific implementation\nAll of the other allocations are either for the String cache or HashMaps used by Jackson.  My only further questions if what the memory allocation would be if we used Jackson's native de-serialization.  I might ask the developers to see if they expect more or less allocation with their deserializers.  I think it might be likely as now all of our allocation is in HashMap allocation.  I can't see how they need to long term create HashMaps if we're directly creating POJO's.\n. @NiteshKant and @spencergibb A change to externalize the scheduling of any of the events (registry refresh, heartbeat, and instance info dirty check/update) isn't the intent of this patch.  Also, it isn't the intent to give any more configurability than already existed than the initial timing of heartbeat and instance info direct check/update.  This change was mainly to allow for us to register the instance in discovery as fast as possible on an external event (vs. some timing that doesn't align with the app container startup).\nThat said, @spencergibb could use this fix to be slower and when all data was available (as using the property will cause the initial registration to wait until the startInstanceInfoHeartBeatNow call).\n. Going to close due to #530 being a better solution\n. On shutdown of tomcat, I am consistently getting:\nSEVERE: The web application [] appears to have started a thread named [DiscoveryClient-InstanceInfoReplicator-0] but has failed to stop it. This is very likely to create a memory leak.\n. I tested this code and it does improve the startup time.  I am seeing ~30 seconds (instead of the previous 58).\n. ",
    "qu1j0t3": "Not sure I agree. This PR intentionally reflects that client and service are distinct programs, and the Gradle script is consequently minimal, and fits an expected pattern. Are you certain you want to go that way? (I already tried to do this within the eureka-server module in early attempts to get the demo to run properly, and as you intuited, the Gradle was less natural\u2014and I could never get it to work.)\n. @qiangdavidliu Thanks. I couldn't come up with a simpler result than this proposal, so I hope you'll consider its structure.\n. OK. Abandoning this PR. :)\n. No worries.\n. ",
    "toby5box": "Their configuration files are either setting the right parameter, in which case they do not need to change, or they intend to set the per host parameter but are actually setting the wrong one) in which case they are not having the desired effect with the existing code. Additionally, it seems very unlikely that any client is using the perHost parameters or they would have already noticed the bug.\nSo this seems safely mergeable.\n. ",
    "dat-vikash": "@qiangdavidliu thanks! this really helped clear up the distinction between client initialization and service registration :rocket: \n. ",
    "spencergibb": "Ping\n. No problem! Spring.  Specifically Spring Cloud Netflix.  In this PR we do\nConstructor<ApplicationInfoManager> constructor = ApplicationInfoManager.class\n                .getDeclaredConstructor(EurekaInstanceConfig.class, InstanceInfo.class);\nReflectionUtils.makeAccessible(constructor);\nreturn constructor.newInstance(instanceConfig, instanceInfo);\n. Thanks @qiangdavidliu!\n. I would be interested in this.  There are cases where all of the information to register a service isn't available when the object is constructed.  We go through some gyrations in spring-cloud-netflix to approximate this.\n. Not sure of the build failure.  Didn't change any behavior.\n. @tbak I make the DiscoveryClientOptionalArgs have a constructor.  It seems to be the simplest thing to do what I'd like to accomplish.\n. @tbak ping, I've rebased against master.\n. @qiangdavidliu or @tbak any idea of when you might have a release?\n. @qiangdavidliu thanks for the update!  Our team really appreciates it.\n. It's not a priority for them, but I'm sure they would look at a pull request.\n. @mattnelson we have users (large institutions) that would love have a jersey2 client working.\n. @qiangdavidliu I saw that a few days ago. I'll take a look.\n. @qiangdavidliu basically what we are doing is adding some functionality to serialization/deserialization of InstanceInfo.  We have sub-classed the existing serializer/deserializer and plugged in our code back into the right places.  Will we be able to do that in jackson_codec_ng? (still looking over it, it's big).\n. @qiangdavidliu that's what I was looking for, thanks.  What do you think would be best, for me to wait until jackson_codec_ng gets merged into master?\n. @qiangdavidliu will do.  If I get time, I'll make a pull to the branch, otherwise I'll wait.\n. No it is not.\n. I actually really agree with this one. We see lots of users asking about what look like errors in the logs that are warnings.\n. @qiangdavidliu thanks for the note!\n. :+1: \n@dsyer this will eliminate the need for us to do any custom codec stuff.\n. :+1: \n. @qiangdavidliu thanks for the quick turnaround!\n. @octonary you can set eureka.instanceId for each instance to handle that case. It's what we do in spring-cloud-netflix.\n. 2015-11-06 12:00:15.733  INFO 81323 --- [ost-startStop-1] c.n.d.provider.DiscoveryJerseyProvider   : Using encoding codec LegacyJacksonJson\n2015-11-06 12:00:15.734  INFO 81323 --- [ost-startStop-1] c.n.d.provider.DiscoveryJerseyProvider   : Using decoding codec LegacyJacksonJson\n. in JerseyReplicationClient.submitBatchUpdates(JerseyReplicationClient.java:120 it sets \n.accept(MediaType.APPLICATION_JSON_TYPE)\n.type(MediaType.APPLICATION_JSON_TYPE)\n. The problem happens when the mediaType is application/json; charset=UTF-8. Then it drops to the ISerializer.\n. I think I found in our code where the charset get's forcefully appended.\n. @tbak We're still on servo 0.10.0\n. :+1: \n. In our Brixton milestones we use later versions of eureka. It was a major refactoring to use it.\n. In Brixton snapshots spring-cloud-netflix has upgraded to 1.3.7.\n. What issues? It may be a spring Cloud issue, not eureka.\n. The next version of spring-cloud-netfix uses the latest version of eureka.\n. Is there anything I need to do to make sure it's built with java8?\n. This was set in 78677c43800e715a3e861536ba84e5ff82510090 by @qiangdavidliu \n. @qiangdavidliu spring Cloud will start moving to java 8 with spring 5 and boot 2. Spring 5 is due next year, milestones starting this year. We would be OK staying on an the 1.3.x line if you move to java 8 in 1.4.x\n. This will be very nice! /cc @dsyer \n. @tbak closed but not merged?\n. thanks!\n. NP @tbak, we appreciate the work and super fast turn around!\n. FYI @tbak\n. @tbak thanks for the quick merge! Any idea on a release date?\n. Sweet! @tbak you've been super helpful.\n. @tbak basic auto used to work (version < 1.3.xish). Something changed with the use of *Endpoint classes. https://github.com/spring-cloud/spring-cloud-netflix/commit/ca81f5671a029fe81d3fe88991d2abf782648310 is how we solved it.\n. @tbak thanks man!\n. Thanks @tbak, we have folks that use it in conjunction with SSL.  Looks good!\n. There's some SSL certificate security, but other than that...\n. nice :smiley: \n. Netflix doesn't maintain Spring Projects. You should probably report this here ttps://github.com/spring-cloud/spring-cloud-netflix/issues\n. I sent him here as the NPE is in pure eureka code \n. We have to do some odd workarounds for eureka's guice dependency sometimes https://github.com/spring-cloud/spring-cloud-netflix/commit/89e893fc9bfcbbd4fb531453430638d25ea8ee41\n. I'm memory\n. This is the wrong repo to ask. Use spring cloud Netflix please.\n. @qiangdavidliu thanks for jumping on this so quickly!\n. \ud83d\udc4d \n. This is not the forum for spring cloud. And, someone correct me if I'm wrong, but eureka 2 is on hold.\n. This is not the repo for Spring Cloud issues. This is not the proper forum for spring cloud Netflix. See https://github.com/spring-cloud/spring-cloud-netflix/issues/1666. If you are using spring-cloud-netflix, that is the right place to ask questions. Eureka has metadata you could use, but generally, if you ask for \"photo-service\", your client should know how to use it.. >  to dynamically identify the service API from registry and call the API, if possible.\nI don't think eureka is the right thing for that.. This is not the place for spring cloud Netflix. this should go in the spring-cloud-netflix issue tracker, not here.. \ud83d\udc4d . If you are using Spring Cloud, it works without v2. This is not the tracker for spring-cloud. https://github.com/spring-cloud/spring-cloud-netflix. Why not upgrade to 1.4.10 instead of putting a workaround in?. @brokenjpl this is not the issue tracker for spring-cloud-netflix. They don't support spring-boot/spring-cloud here. This isn't the issue tracker for spring cloud netflix.. Not the issue tracker for spring cloud. What version does this affect (where was the regression)?. OK. Wondering if you could patch the Java 7 version as well as master.. This is not the repository for spring cloud Netflix. Not the spring cloud Netflix repository. This is not the spring cloud Netflix issue tracker. Our non-jersey implementation doesn't use the Jackson codec do we still see the error. I guess I didn't pay enough attention to this since this doesn't actually fix our issue since the case we have is when we don't use jersey and therefore the Eureka codec.. https://github.com/spring-cloud/spring-cloud-netflix/issues/2756. this is not the spring cloud netflix issue tracker. Yup. This didn't fix things for us, since @JsonProperty(\"overriddenstatus\") is still the lowercase version :-(. Changing that to camel case breaks tests in EurekaCodecCompatibilityTest. Unrecognized field \"overriddenstatus\". The opposite of what we have. When you have something in a branch/fork somewhere, let me know, I'll build and try so we don't end up releasing it broken again.. applying your changes locally and testing. Looks good on my side.. @ryanjbaxter. This is not the spring cloud Netflix issue tracker. Though I'm not part of netflix, I'm fairly confident eureka will live on for quite a while.. You should use the gradle wrapper (./gradlew) rather than a gradle install.. They aren't an \"alternative to DiscoveryClientOptionalArgs\" as they are methods on the class.  I'll add the new constructor instead.\n. probably not.\n. Hmm, adding a new constructor to DiscoveryClient would seem more invasive than needs be.  Let me update and see what you think.\n. If it's newing up MyDataCenterInfo how can a custom one be used?\n. OK, if that's the case, the point of this was so we could set the id of the DataCenterInfo. MyDataCenterInfo doesn't implement UniqueIdentifier.\n. Why not inject the factory rather than having a static initializer?\n. sure, np\n. Whoops\n. I would hope a change like this would require a significant version change and not a patch version. . Why use static refs here and not DI friendly?. :+1: that way there isn't a change of behavior. ",
    "amanya": "@qiangdavidliu thanks for your comments :)\nI think I've managed to solve the first two issues, but for making the tests, I'll need to use a tool like Powermockito due to the static dependencies of the AwsAsgUtil class, right?\n. ",
    "KishorGrandhe": "are there any plans and timelines to fix the issue, thanks\n. ",
    "Novotarskyi": "@qiangdavidliu I could try and make a pull request for this one\n. ",
    "william-tran": "done\nOn Thu, Jul 16, 2015 at 8:03 PM, David Liu notifications@github.com wrote:\n\nHi @willtran- https://github.com/willtran- can you please do a rebase?\nThanks.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/Netflix/eureka/pull/588#issuecomment-122133875.\n. Hey @qiangdavidliu what do you think of this PR?\n. It would be great if we could get this backported to 1.4.x like in my fork, and release a v1.4.12 so we can include this fix in a Spring Cloud Camden SR.\n. \n",
    "brharrington": "How is this different than vip? You can already specify a list to eureka.vipAddress and then do the lookup for a given vip.\n. Can the legacy archaius bindings be pulled out to a separate lib so that if using archaius2 we don't have to pull in the legacy version?\n. @qiangdavidliu it might be a good idea to set the compatibility level explicitly on the build:\nsourceCompatibility = 1.8\ntargetCompatibility = 1.8\nThat should make the error message a bit easier to follow than cannot find symbol. For example on one of mine when trying to build on java 7 it gives:\n```\n* What went wrong:\nExecution failed for task ':spectator-api:compileJava'.\n\ninvalid source release: 1.8\n```\n. You should be able to do a delete request to clear the override:\n\nDELETE /eureka/v2/apps/appID/instanceID/status\n. It looks like that was added in 1.1.148: https://github.com/Netflix/eureka/releases/tag/1.1.148\n. For some background on the runtime dependencies issue with nebula, see: https://github.com/nebula-plugins/nebula-publishing-plugin/issues/31\nThe simplest short term work around I know of would be to just add the dependency directly to your project rather than relying on it being transitive. For com.netflix.config specifically, the dependency below provides that package:\nhttps://mvnrepository.com/artifact/com.netflix.archaius/archaius-core/0.7.4\n. Can you elaborate on what the issues are? Why not fix the prefixed views in archaius2?\n. I don't work on either and so may not have full context. At first glance these questions seem to pertain more to Zuul than Eureka.\n\nRumors say Netflix is currently working on quite another alternative to replace at least Eureka and Zuul. Is that true?\n\nI'm guessing this was in reference to the new version of Zuul. A 2.x version that was released a few months ago. There are some blog posts and presentations linked off the readme:\nhttps://github.com/Netflix/zuul/blob/2.1/README.md\n\nWill new version be included in Spring Cloud?\n\nFor Zuul 2 specifically, see: Netflix/zuul#298.. > Helps if Eureka is deployed not as Tomcat web app. Users may provide own registry and get metrics reported to Atlas, for example.\nA user can provide their own registry even if running as a Tomcat webapp, but they would probably need to pull it in as a library and build their own war file with additional config settings.\nAs a side note, you can also make Servo report into Atlas, either directly with:\nhttps://github.com/Netflix/servo/tree/master/servo-atlas\nRecent versions of Servo also have a SpectatorContext which can be used to have all servo monitors report in via a Spectator registry. This is what we are using internally now as we have to keep backwards compatibility for Servo instrumented apps for quite a while.. Most servlet containers have CORS filters you can use (see for example Tomcat and Jetty filters). So if you need that functionality you should be able to enable it.. Is the savings mostly because this data is repeated for many instances of the sample application? Why would you have many InstanceInfo objects with the same ip address? With recent jvms the default string table size is around 60k and I would expect interning the ips would quickly lead to collisions causing the performance to go down.\n. Looking at the discovery metadata for my apps these urls are absolute and contain the hostname. Would there actually be many copies of the same value?\n. 3.6.0 is the latest, any particular reason for updating to an old version?. It looks like this library is licensed with LGPL. I think there was general advice to keep everything Apache 2 if possible so the set of licenses consumers need to worry about is minimal.. In this particular case couldn't you just remove the condition? It is already using placeholders to avoid substituting in the string if debug is not enabled and the logging library will be doing the same check internally.. It looks like these are just here to allow access to the registry from a static context. Spectator has a notion of a global registry for that purpose. This would have two main benefits:\n\nWhen configuring the registry the user doesn't need to now about these specific methods scattered around various classes.\nYou could get rid of the null checks for the use. It will default to a noop implementation if no registries are added.. Typically we recommend modeling it so you can drill into the data easier. I would suggest making whether or not it is for replication a dimension, for example:\n\n```java\nprivate final Counter replicationCounter =\n    Spectator.globalRegistry().counter(\"eureka.\" + name, \"isReplication\", \"true\");\nprivate final Counter myZoneCounter =\n    Spectator.globalRegistry().counter(\"eureka.\" + name, \"isReplication\", \"false\");\npublic void increment(boolean isReplication) {\n  Counter c = isReplication ? replicationCounter : myZoneCounter;\n  c.increment();\n}\n```\nWhen querying the old count version would just be just restrict to a given name and it will automatically sum across the other dimensions. You could further restrict based on isReplication to get the part where that is true or false. This also makes it easy to group by isReplication to see both or visualize a percentage. . Are the servo stats still needed? Internally this will cause duplication with both getting sent into Atlas.. ",
    "seh": "\nYou can already specify a list to eureka.vipAddress and then do the lookup for a given vip.\n\nWhere in the Eureka code base does something interpret that property's value as a list?\n. Ah, there is com.netflix.discovery.shared.Applications#addInstanceToMap(), which contains this statement:\njava\nString[] vipAddressArray = vipAddresses.split(\",\");\n. ",
    "foo4u": "@qiangdavidliu can we shade the dependency on Jersey 1.x? Causing issues since most other frameworks have moved on to JAX-RS 2.0.\n. ",
    "efenderbosch": "Would that make it possible to use something other than Jersey? It is just required to be a JAX-RS implementation?\n. ",
    "singerdmx": "Any updates on Jersey2 version? Thanks!\n. ",
    "oembedler": "Could someone give rough estimate on how long it takes to decouple code from jersey v1? \nThanks!\n. ",
    "jasollien": "Hi guys. Uncopling of jersey1 is essential for us in order to use Eureka. Any update on the progress would be much appreciated.\n. I somehow got it working by using: \nDiscoveryManager.getInstance().getLookupService().getInstancesById(instanceInfo.getInstanceId()).get(0).getOverriddenStatus(), but it does not look nice\nUpdate: DiscoveryManager.getInstance().getLookupService().getApplication(info.getAppName()).getByInstanceId(info.getInstanceId()).getOverriddenStatus() also works. ",
    "saneItchyHog": "Eagerly awaiting this as well\n. ",
    "nick-pww": "@qiangdavidliu I think most of the folks following this would agree that removing the Jersey dependency from your side of things would be the 'best' solution for folks who are using this library. Personally, I don't care what you use for your underlying communications as long it's been well tested and vetted (which is what you are going for), AND doesn't get in the way of our own application development (which Jersey dependencies of any kind have the chance of doing).\ntl;dr: \ud83d\udc4d \nLook forward to the changes!\n. This is on 1.4.9. Also, I couldn't find anything that said it would matter but we are using spring-boots starter projects as the basis for the app, and the app is started with the following main class:\n```\n@SpringBootApplication\n@EnableEurekaServer\n@EnableAutoConfiguration\npublic class EurekaServer {\n@Value(\"${server.port}\")\nprivate Integer nonSecurePort;\n@Autowired\nprivate InetUtils utils;\n\npublic static void main(String[] args) {\n    new SpringApplicationBuilder(EurekaServer.class).web(true).run(args);\n}\n\n@Bean\n@Profile(\"aws\")\npublic EurekaInstanceConfigBean awsEurekaConfig() {\n    EurekaInstanceConfigBean b = new EurekaInstanceConfigBean(utils);\n    b.setNonSecurePort(nonSecurePort);\n    b.setSecurePortEnabled(false);\n    AmazonInfo info = AmazonInfo.Builder.newBuilder().autoBuild(\"eureka\");\n    b.setDataCenterInfo(info);\n    return b;\n}\n\n}\n``\n. @qiangdavidliu Can you point to where the dataCenterInfo is refreshed in the regular Eureka code? I could find where it got initialized, but nowhere where it might get refreshed. The only call I found wasApplicationManager.refreshDataCenterInfoIfRequired()`, but can't find any thing that actually calls this method.\nI'll keep digging and guess open an issue with spring-cloud folks too...\n. ",
    "mattnelson": "@qiangdavidliu \n\nwe are taking a more drastic direction w.r.t. the client side of eureka (thinner clients with no jersey dependencies at all), and is working more towards this goal at the moment.\n\nI am starting to look into eureka-client-jersey2 and picking up where you guys left off, but I wanted to put a feeler out to see what progress had been made on the jersey-agnostic client and if there was the possibility of a release candidate being available.\n. Got the PR out for this on #821 \n. The eureka-client.properties file will be in the META-INF resource folder and while it is the same file name, it would take some work for a user to incidentally put this file on the archaius path. I'll get started on the plugin updates as that seems to be to most correct way to resolve this. I'll have a follow up PR to change eureka to fall back to eureka-client.properties once the plugin updates are available.\n. The cluster health would depend on the deployment configuration? Using the EIP/DNS options would provide multiple levels of resiliency. Using the eureka.serviceUrl property could have huge impacts with a down replica.\nI think the isHealthy contract could be defined with the introduction of a new property which is the threshold of down replicas in which is it unhealthy due to the inability to replicate confidently.\n. For the sake of not losing the context of this discussion. I will make the changes and update the PR. I will try to get the proposed changes done in the next couple of days.\n. Finally got around to making these changes in bf6aa56945abbb3c067f6c4ae492fbe5f95bf489\n- Went with an integer for the number of required up replicas since I think the common uses cases would be a relatively low number of replicas.\n- Couldn't come up with a good name for the property so looking for suggestions there.\n- Handles the default property value of 0 to remain passive with the current functionality of an unset healthy flag.\n. @qiangdavidliu Addressed PR comments on bc336a27b5cb6ef45b4499c89f4e25d28ee07b9f\n. Not sure what caused the failure. I don't seem to be able to see the output of the travis build. I built the project locally several times to see if I could reproduce, but all the builds passed.\n. Figured out the failure reason. This branch wasn't rebased with the changes I introduced on #831.\nI cherry picked that commit over and fixed the tests.\n. Addressed with #808 \n. This has been released with 1.8.5\nhttps://github.com/Netflix/eureka/releases/tag/v1.8.5. @qiangdavidliu \n\nare you running both jersey2 client and server in your set up, or just the client?\n\nI am running both client and server. The environment I'm using has 4 clients and 1 server (I'll work on getting another server integrated to verify cluster replication) that are able to register and use ribbon with DiscoveryEnabledNIWSServerList.\n. Addressed comments on 7dbea2d1e1b5d3d2e816593f8542a27107cdc10d\n. @qiangdavidliu Finally had a chance to validate replication.\nHad 36 clients register with a cluster of 3 eureka servers. Then had an additional 2 eureka servers that were only configured with the other 3 eureka servers to ensure that the apps they got were only through replication. Took a while because I had to trace down a bug in PeerEurekaNodes. isThisMyUrl[1] and EurekaTransportConfig.applicationsResolverUseIp[2]. The virtualization environment I was using only supports IP resolution. I'll get a PR out for those changes as it will be a blocker for me to validate a release candidate of these changes.\n[1] https://github.com/Netflix/eureka/blob/v1.4.10/eureka-core/src/main/java/com/netflix/eureka/cluster/PeerEurekaNodes.java#L230-L234\n[2] https://github.com/Netflix/eureka/blob/v1.4.10/eureka-client/src/main/java/com/netflix/discovery/shared/transport/EurekaTransportConfig.java#L31\n. @qiangdavidliu Is there anything else you need in order to get this PR merged?\n. I can include them with this PR if you want, but they are not related to the jersey2 uplift. They are isolated to running eureka in IP address resolver transport mode.\n. Created #831 for the IP address transport issue.\n. @qiangdavidliu Now that https://github.com/Netflix/eureka/releases/tag/v1.4.11 is released, are there any other blockers? \n. Changes look good so far. I'll pull this branch down early next week and verify in my test environment.\n. Finally had a chance to validate these changes. Verified client registration with 30+ clients, replication, client status changes, ribbon load balancing.\n. @ayusun \nThere are some notes on the initial jersey2 PR #821. The readmes for eureka-client-jersey2/eureka-core-jersey2 could be updated before 1.6.0 is released.\n. The latency is likely being caused by the response cache.\nhttps://github.com/Netflix/eureka/blob/v1.6.1/eureka-core/src/main/java/com/netflix/eureka/registry/ResponseCache.java. @qiangdavidliu @twicksell Could I get a review on this?. Would you be willing to add support for the non-DI initComponent flows as well?\nhttps://github.com/Netflix/eureka/blob/v1.8.6/eureka-client/src/main/java/com/netflix/discovery/DiscoveryManager.java#L77. @qiangdavidliu I don't need it, only wanted to make sure that the other init flows were covered.. I believe that is the current allocated heap[1,2], not the max memory[3].\n[1] https://github.com/Netflix/eureka/blob/v1.9.0/eureka-core/src/main/java/com/netflix/eureka/util/StatusInfo.java#L75\n[2] https://docs.oracle.com/javase/7/docs/api/java/lang/Runtime.html#totalMemory()\n[3] https://docs.oracle.com/javase/7/docs/api/java/lang/Runtime.html#maxMemory(). I've seen a situation similar to this in which we had the renewal threshold at 85%. We took down an AZ which resulted in roughly 33% of the registrations disappearing, since this was higher than the threshold, the servers entered self preservation mode and were not able to exit this mode since the update threshold would not update as the services were rescheduled on the remaining AZs.. Can the existing instance id be used for self identification? It is already a unique identifier.\nIntroducing a new endpoint complicates deployment considerations with rollout of this feature and adds more complexity. Additionally, eureka is already pretty chatty between the peers and with heartbeats. I would like to explore other options that don't add more requests.. > 2. we actually run an autoscalable readonly tier in front of our fixed host write cluster that take all the read traffic.\n@qiangdavidliu  Can you provide more details on this? Is this using Eureka2? Which is introducing separate read/write clusters which has never progressed past a release candidate 3+ years ago. . Maybe I'm interpreting this wrong, but are the locks inverted? Could that be the root cause of this issue?\nMutative(write) actions are acquiring a read lock\nhttps://github.com/Netflix/eureka/blob/ec2649e3a0a7eae5d3daabd2dfff7f8c2a91cc49/eureka-core/src/main/java/com/netflix/eureka/registry/AbstractInstanceRegistry.java#L191-L193\nhttps://github.com/Netflix/eureka/blob/ec2649e3a0a7eae5d3daabd2dfff7f8c2a91cc49/eureka-core/src/main/java/com/netflix/eureka/registry/AbstractInstanceRegistry.java#L455-L459\nRead operations are acquiring a write lock\nhttps://github.com/Netflix/eureka/blob/ec2649e3a0a7eae5d3daabd2dfff7f8c2a91cc49/eureka-core/src/main/java/com/netflix/eureka/registry/AbstractInstanceRegistry.java#L865-L871. > and have since realized internally\nIs this via non open sourced updates? or is this via configuration mentioned to in https://github.com/Netflix/eureka/issues/1120#issuecomment-424957756 and introduced in #678 ?\n. This should be above the call to put.\n. How is this different from .post(Entity.json(info))?\n. Could use an entrySet.\n. Should this be a multimap?\n. Should be able to use add instead of put to avoid the list creation.\nhttp://docs.oracle.com/javaee/7/api/javax/ws/rs/core/MultivaluedMap.html#add-K-V-\n. Can a debug/trace level message be logged so this defaulting to unknown isn't completely ignored?. Should ConcurrentHashMap be used instead? or if thread safety doesn't matter since this is a cache and misses here aren't a big deal update the docs to call that out. As it is written it implies that the lack safety could be an issue.. Catch Exception instead.. Catch Exception instead.. Wouldn't it be better to wrap and throw as a RuntimeException instead of suppressing with a log message?. I know this is already merged, but it isn't released yet.\nThis should be catching Exception, there are very few scenarios in which Throwable should be caught and even worse here, swallowed.. Mention that this is because of the value being parsed from eureka.serviceUrl.default instead of the host from the instance registration.. ",
    "adoura": "@spencergibb now jersey 2 compatibility released in eureka 1.6.0 but you planning to upgrade to eureka 1.5.6 in 1.3.0.M1. \nis there possibility to push upgrades to 1.6.0 ?\n. @qiangdavidliu till now you still working on 1.5.x release train\nKindly any dates when release 1.6.0 containing this PR will be released ?\n. ",
    "nmadzharov": "Considering it has been over a year since the issue was closed and nowadays spring-boot applications with jersey 2 clients are widely-used, what is the recommended approach to use Eureka client in web services which also already use jersey 2 clients? \nFor instance, I have struggled to find a recommendation or example on using eureka clients with any spring boot app that utilizes spring-boot-starter-jersey or the likes (jersey 2 dependencies) which are included in most spring examples. . ",
    "thepoofy": "The \"resource identified\" criteria hasn't been met.  In the event there is no resource identifiable by the correct response code is 404.  Going back to the RFC:\n```\n10.4.5 404 Not Found\nThe server has not found anything matching the Request-URI. No\n   indication is given of whether the condition is temporary or\n   permanent.\n```\nSo when an Instance has been removed from Eureka due to a timeout the URI doesn't match any values known to Eureka and should be spitting out a 404.\nI was extra irked by this because using a Accept: */* still returned a 406.\n. Putting aside the gzip which is not relevant here; we're using version 1.1.141 and that is not the behavior we see.\n. ",
    "Swierkowski": "In my case, my service has already crashed. Therefore, the service is not able to change the status using REST API.\nMy service is written in Java. I have already registered a JVM shutdown hook which changes the status of my service to DOWN. The problem is that when the service was not stopped gracefully the shutdown hook is not executed. It is e.g. kill -9 or OutOfMemoryError.\nIn my case the only thing that Eureka server knows is that it has stopped receiving heartbeats. I would like this to be interpreted as the service is DOWN.\n. I have already implemented my own poller mechanism which is setting the status to down when there are no heartbeats. As I start Eureka server using spring boot, I have direct access to eureka registry.\n. ",
    "jaume-pinyol": "Done! Do you want to join commits?\n. ",
    "aivans": "Sounds great.\nI know there is an RC available, is there a timeline for a Production ready release?\nThanks\n. Thank you.\nLooking forward!\n. ",
    "jkschneider": "@tbak @spencergibb this pull request solves the issue we have in Spring Cloud: https://github.com/Netflix/eureka/pull/646\n. @tbak If BasicDataCenterInfo contains a customizable ID, then that is sufficient.  Custom metadata is icing on the cake, but there is no immediate need for it in Spring Cloud.\n. I'm curious what the purpose of supporting multiple codecs is.  Is it to be less opinionated about dependencies provided to downstreams?  If so, could you pick one and shade it instead?\n. I suppose we would use MyDataCenterInfo rather than a custom type.  Because of all that silliness around serializing any non-AmazonInfo with a @class attribute of  com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo, we are down to a binary choice: AmazonInfo or not.  At least this way we can hang metadata on our non-AmazonInfo choice.\n. We could be certain that we preserve existing behavior AND support a fully custom DataCenterInfo implementation if we add a fourth Custom type to the DataCenterInfo.Name enum, where we serialize the fully qualified class name of the custom type.  \n@tbak Would this break any eureka-clients using a version less than 1.2.5+?\n. 87de5c9 makes MyDataCenterInfo a UniqueIdentifier, but alters the contract of UniqueIdentifier to make its id nullable.  InstanceInfo.getId has been updated accordingly.\n. ",
    "aroger-r7": "no problem. will try do that asap\n. closed in favor of one on  di-friendly-server\n. ",
    "YunaiV": "@qiangdavidliu \nhello, why add \"adding jitter to sessionedClient's session duration\" .\nthank you!. @qiangdavidliu thx. ",
    "octonary": "Thanks! I will start setting the instanceId.\n. I couldn't get eureka.instanceId to work but setting eureka.instance.metadataMap.instanceId with the spring-cloud-netflix version seems to do the trick. Thanks again.\n. ",
    "Yannic92": "@tbak I can confirm this issue. I will try to provide a short example in the next days.\n. ",
    "alexandre-gauge": "Thanks @qiangdavidliu and @brharrington \n. ",
    "dearjadu": "Thanks. Could you point me to the valid location of the JavaDoc?\n. Got it. Merci\n. ",
    "jhmartin": "Any sort of ETA on the release? I am interested in running clients in ECS as well.\n. ",
    "abaculus": "The only allowed methods for endpoint is OPTIONS and PUT.\nUsing Eureka version 1.1.147\n. Aah, that explain things...\nThank you for your very helpful support! \nKudos\n. ",
    "andreaposadino": "Thank for your answer,\nI just tried with ApplicationInfoManager.getInstance().registerAppMetadata(Map appMetadata) method and worked. \nThank you again.\n. ",
    "yairogen": "@tbak Thanks for your reply.\nThe old version we use is coming from spring-cloud-netflix lib. I have no idea why but even thier latest version still uses eureka 1.1.147: https://repo1.maven.org/maven2/org/springframework/cloud/spring-cloud-netflix/1.0.4.RELEASE/spring-cloud-netflix-1.0.4.RELEASE.pom.\nAny idea why?\nRegatding the second part: I thought the A eureka client can be used for 2 puposes:\n- register a server\n- as a client, lookup other servers.\nSo - I was asking is it possible to be a eureka client just for lookup purposes and not register the client itself with its own instance properties as the client may not be a server in it self?\n. so - you recommend we try out this?\nhttp://repo.spring.io/libs-milestone-local/org/springframework/cloud/spring-cloud-netflix/1.1.0.M4/\n. ",
    "FabianWilms": "java\npublic InstanceInfo getNextServerFromEureka(String virtualHostname, boolean secure) {\n    List<InstanceInfo> instanceInfoList = this.getInstancesByVipAddress(\n            virtualHostname, secure);\n    if (instanceInfoList == null || instanceInfoList.isEmpty()) {\n        throw new RuntimeException(\"No matches for the virtual host name :\"\n                + virtualHostname);\n    }\n    Applications apps = this.localRegionApps.get();\n    int index = (int) (apps.getNextIndex(virtualHostname.toUpperCase(),\n            secure).incrementAndGet() % instanceInfoList.size());\n    return instanceInfoList.get(index);\n}\nThis is the method I'm talking about. getInstancesById is of course a good replacement.\n. ",
    "jylin": "This is the only thing that prevents building with Java 7 though.\n. ",
    "dcaba": "you're welcome!\n. Hi!\nI will assess this in the next days! The dedicated scheduler (plus polling) just for monitoring purposes looked a bit overkilling, but I thought may be the cleanest one until you presented this servo feature to me ;) . I will keep you posted,\nDaniel\n. Hi,\nI've been taking a look, and I guess we have two options:\n- discard this PR. I've been browsing the current metrics you are exporing, and bearing in mind the method \"isBelowRenewThreshold\" is also there, the additional metric this PR incorporates adds small value.\n- keep the suggested approach. Thanks to the additional schedule/thread, eureka will be logging if the instance is in self-preservation mode, or not. This could be interesting staff for admins. If we let servo to prove this, I understand the schedule (and the log generation) will be driven by external JMX polls, that does not look ideal. One point that can be interesting, though, is to log only transitions, instead of every renewalSelfPreservationStatusUpdateIntervalMs.\nThanks!\n. ",
    "sfussenegger": "@qiangdavidliu thanks for pointing this out. Just to clarify things a little further: we are talking [major].[minor].[patch] (as in semver), right? So client-server protocol has been backward-compatible for the whole 1.x releases? Therefore 1.1.147 clients (currently the latest used by spring-cloud-netflix) should be compatible with the currently latest server (that is 1.3.7), correct?\n. @kristofferpeterhansel we ended up using \"plain\" eureka server for the same reason. the spring-cloud version really doesn't add anything other than a nice launcher inside IDEs. Eureka documentation is scarce already and the spring-cloud version really doesn't help. \nIt's pretty much what Samsung does to Android. Changes are mostly a matter of taste, come with their own issues and you wait forever for updates ;)\n. ",
    "kristofferpeterhansel": "So spring-cloud-netflix Brixton RC1 is now using Eureka 1.4.4 and I am seeing some issues with connecting to the 1.1.x-based Eureka server (from a previous spring-cloud-netflix version)  we currently use. Is this supposed to be compatible?\n. Well. That was why I started asking in https://github.com/spring-cloud/spring-cloud-netflix/issues/953 . Since I am getting issues very similar to that.\nBasically the service registers fine. But updates fail with exceptions like this:\n```\n2016-04-13 15:06:13.289 ERROR 46782 --- [tbeatExecutor-0] c.n.d.s.t.d.RedirectingEurekaHttpClient  : Request execution error\njavax.ws.rs.WebApplicationException: null\n    at com.netflix.discovery.provider.DiscoveryJerseyProvider.readFrom(DiscoveryJerseyProvider.java:110) ~[eureka-client-1.4.4.jar:1.4.4]\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:634) ~[jersey-client-1.19.1.jar:1.19.1]\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586) ~[jersey-client-1.19.1.jar:1.19.1]\n    at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105) ~[eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73) ~[eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:89) ~[eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:823) [eureka-client-1.4.4.jar:1.4.4]\n    at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379) [eureka-client-1.4.4.jar:1.4.4]\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_73]\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_73]\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_73]\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_73]\n    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_73]\n```\n. @qiangdavidliu You are correct. It is exactly the scenario you describe. We run a spring-cloud-netflix 1.0.1-based Eureka server. Making it 1.1.147.\nI suppose there is technically no reason why we couldn't upgrade it - since it is only a Eureka server and have no other dependencies. But it is a bit of a problem if we have to kill all our Eureka instances at the same time to do it. And I suspect they would have the same problem and can't replicate data between an old and a new instance?\n. @qiangdavidliu Currently we run just two instances in each of our environments. There is no reason why I couldn't try it out in our test environment and see what happens. So I suppose I'll try that out when I\nI realise it is an old version. But since we are using the version that comes with Spring Cloud Netflix. That is sort of imposed on us by that. But I guess that is mainly a problem with that project not getting all that frequent updates. And a good reason to reconsider why we are using the Eureka server wrapped in Spring Boot.\n. ",
    "mrumpf": "I just saw that there is an algorithm to prefer IPs from NICs whose name ends with a \"0\".\nhttps://github.com/Netflix/eureka/blob/de24b9349fe579dba687f069f2bf495c8fe97c3f/eureka-client/src/main/java/com/netflix/discovery/util/SystemUtil.java\nWhen I run the code with some System.out.println() statements I get the following output on my Windows 7 machine:\nnicName=lo\n   ip: 127.0.0.1\n   ip: 0:0:0:0:0:0:0:1\nnicName=net0\nnicName=net1\nnicName=net2\nnicName=ppp0\nnicName=eth0\nnicName=eth1\nnicName=eth2\nnicName=ppp1\nnicName=net3\nnicName=eth3\n   ip: 192.168.0.125\n   ip: fe80:0:0:0:f427:8c69:7f63:a33c%eth3\nnicName=net4\nnicName=eth4\nnicName=net5\nnicName=wlan0\n   ip: fe80:0:0:0:5181:a1a4:46f2:3fbc%wlan0\nnicName=eth5\n   ip: fe80:0:0:0:ed7c:5cca:a408:9f9e%eth5\nnicName=net6\nnicName=wlan1\nnicName=net7\n   ip: fe80:0:0:0:0:5efe:a9fe:5f96%net7\nnicName=eth6\nnicName=net8\nnicName=net9\nnicName=eth7\n   ip: 169.254.95.150\n   ip: fe80:0:0:0:d999:4068:11a7:5f96%eth7\nnicName=net10\n   ip: fe80:0:0:0:0:5efe:ab1:c491%net10\nnicName=net11\nnicName=net12\nnicName=eth8\nnicName=eth9\nnicName=eth10\nnicName=eth11\nnicName=eth12\nnicName=wlan2\nnicName=wlan3\nnicName=eth13\nnicName=eth14\nnicName=eth15\nnicName=eth16\nnicName=wlan4\nnicName=eth17\nnicName=eth18\nnicName=eth19\nnicName=eth20\nnicName=eth21\nnicName=eth22\nnicName=eth23\nnicName=wlan5\nnicName=eth24\nnicName=wlan6\nnicName=wlan7\nnicName=ppp2\nFound IP=fe80:0:0:0:0:5efe:ab1:c491%net10\n   ip: 10.177.196.145\nThe code could be adapted to set the preferred NIC name instead of the default \"eth0\":\neureka.instance.preferredNic=net10 or ppp2\nMy ipconfig output (truncated) looks like this:\n```\nWindows IP Configuration\nPPP adapter Global Remote:\nConnection-specific DNS Suffix  . :\n   IPv4 Address. . . . . . . . . . . : 10.177.196.145\n   Subnet Mask . . . . . . . . . . . : 255.255.255.255\n   Default Gateway . . . . . . . . . : 0.0.0.0\nEthernet adapter Local Area Connection:\nConnection-specific DNS Suffix  . : lan\n   Link-local IPv6 Address . . . . . : fe80::f427:8c69:7f63:a33c%11\n   IPv4 Address. . . . . . . . . . . : 192.168.0.125\n   Subnet Mask . . . . . . . . . . . : 255.255.255.0\n   Default Gateway . . . . . . . . . : 192.168.0.5\n```\nForcing the host address to \"localhost/127.0.0.1\" would also be a good option for local development:\neureka.instance.forceHostAddress=127.0.0.1\n. The Spring Cloud Team claims to have this already fixed: https://github.com/spring-cloud/spring-cloud-netflix/issues/788\n. ",
    "pcornelissen": "You need a recent brixton version for it BTW.\nThen you can ignore all unwanded interfaces by:\n```\nspring:\n  cloud:\n    inetutils:\n      ignoredInterfaces:\n        - tun.*\n```\n. ",
    "maliksalman": "That must be new. I was working with spring-cloud-netflix-core 1.0.1 which includes eureka-client 1.1.147. I will look into this.\n@qiangdavidliu, thanks for the pointer.\n. ",
    "vikrantch-hk": "@spencergibb has this feature been introduced. @qiangdavidliu @robertnosburn I have similar requirement where I dont want any EIP binder is there a way to stop EIPManager . @marcosbarbero I have added this dependency as well but still getting same error. @marcosbarbero I was debugging the code and found that exception is being thrown from AbstractJerseyEurekaHttpClient at WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath); in below method\nprivate EurekaHttpResponse<Applications> getApplicationsInternal(String urlPath, String[] regions) {\n        ClientResponse response = null;\n        String regionsParamValue = null;\n        try {\n            WebResource webResource = jerseyClient.resource(serviceUrl).path(urlPath);\n            if (regions != null && regions.length > 0) {\n                regionsParamValue = StringUtil.join(regions);\n                webResource = webResource.queryParam(\"regions\", regionsParamValue);\n            }. \n```\npackage com.hk.web.listener;\nimport com.netflix.appinfo.InstanceInfo;\nimport com.netflix.appinfo.MyDataCenterInstanceConfig;\nimport com.netflix.discovery.DefaultEurekaClientConfig;\nimport com.netflix.discovery.DiscoveryManager;\npublic class EurekaClient {\npublic void registerClient() {\n\n    String vipAddress = \"NLPService\";\n\n    InstanceInfo nextServerInfo = null;\n    try {\n        DiscoveryManager.getInstance().initComponent(new MyDataCenterInstanceConfig(), new DefaultEurekaClientConfig());\n        nextServerInfo = EurekaConfiguration.getEurekaClient().getNextServerFromEureka(vipAddress, false);\n    } catch (Exception e) {\n        System.err.println(\"Cannot get an instance of example service to talk to from eureka\");\n        //System.exit(-1);\n    }\n\n    try {\n        Thread.sleep(2000);\n    } catch (InterruptedException e) {\n        // Nothing\n    }\n\n    // Now we change our status to UP\n    System.out.println(\"Done sleeping, now changing status to UP\");\n    DiscoveryManager.getInstance().getEurekaClient().getApplicationInfoManager().setInstanceStatus(InstanceInfo.InstanceStatus.UP);\n\n    System.out.println(\"Found an instance of example service to talk to from eureka: \"\n            + nextServerInfo.getVIPAddress() + \":\" + nextServerInfo.getPort());\n\n    String serviceBaseURL = \"http://\"+ nextServerInfo.getHostName()\n            +\":\"+nextServerInfo.getPort();\n\n\n    String nlpServiceURL = serviceBaseURL +\"/nlp\";\n\n   /* RestTemplate restTemplate = new RestTemplate();\n\n    NLPInputToBeTransformed input = new NLPInputToBeTransformed();\n    input.setInputText(\" Test Input \");\n\n\n    NLPResponse nlpResponse = restTemplate.postForObject\n            (nlpServiceURL, input, NLPResponse.class, new HashMap<>());*/\n\n    //System.out.println( \" Service Response  \" + nlpResponse.getTags());\n\n}\n\n}\n```\n```\npackage com.hk.web.listener;\nimport com.netflix.appinfo.ApplicationInfoManager;\nimport com.netflix.appinfo.EurekaInstanceConfig;\nimport com.netflix.appinfo.InstanceInfo;\nimport com.netflix.appinfo.MyDataCenterInstanceConfig;\nimport com.netflix.appinfo.providers.EurekaConfigBasedInstanceInfoProvider;\nimport com.netflix.discovery.DefaultEurekaClientConfig;\nimport com.netflix.discovery.DiscoveryClient;\nimport com.netflix.discovery.EurekaClientConfig;\n/*\n * Created by dhruv on 30/4/18.\n /\npublic class EurekaConfiguration {\n    public static ApplicationInfoManager applicationInfoManager;\npublic static com.netflix.discovery.EurekaClient eurekaClient;\n\n    private static synchronized ApplicationInfoManager initializeApplicationInfoManager(\n            EurekaInstanceConfig instanceConfig) {\n        if (applicationInfoManager == null) {\n            InstanceInfo instanceInfo = new EurekaConfigBasedInstanceInfoProvider(instanceConfig).get();\n            applicationInfoManager = new ApplicationInfoManager(instanceConfig, instanceInfo);\n        }\n\n        return applicationInfoManager;\n    }\n\n    private static synchronized com.netflix.discovery.EurekaClient initializeEurekaClient(ApplicationInfoManager applicationInfoManager,\n                                                                                          EurekaClientConfig clientConfig) {\n        if (eurekaClient == null) {\n            eurekaClient = new DiscoveryClient(applicationInfoManager, clientConfig);\n        }\n\n        return eurekaClient;\n    }\n\n    public static com.netflix.discovery.EurekaClient getEurekaClient()\n    {\n        ApplicationInfoManager applicationInfoManager = initializeApplicationInfoManager(new MyDataCenterInstanceConfig());\n        com.netflix.discovery.EurekaClient client = initializeEurekaClient(applicationInfoManager, new DefaultEurekaClientConfig());\n        return eurekaClient;\n    }\n\n}\n```\n```\npublic class HKStartupListener implements ServletContextListener {\nLogger logger = LoggerFactory.getLogger(HKStartupListener.class);\nprivate AppCacheService appCacheService;\n//  private LoadPropertyService loadPropertyService;\npublic HKStartupListener() {\n  }\npublic void contextInitialized(ServletContextEvent event) {\n    System.out.println(\"================  STARTING EDGE  ==================\");\nlogger.info(\".........  START CACHING  .........\");\nAppConstants.contextPath = event.getServletContext().getContextPath();\nAppConstants.appBasePath = event.getServletContext().getRealPath(\"/\");\n\nlogger.info(\".........  Reloading Memory Cache  .........\");\ngetAppCacheService().reloadAll();\n\nString runCronJobs = System.getProperty(EnvConstants.RUN_CRON_JOBS);\nlogger.info(\".........  RUN CRON: \" + runCronJobs + \"  .........\");\n\nif (StringUtils.isNotBlank(runCronJobs) && Boolean.parseBoolean(runCronJobs)) {\n  new EdgeScheduleManager().startup();\n}\n\nnew EdgeScheduleManager().startupAll();\nnew EurekaClient().registerClient();\n\n}\n```\ncomplete pom dependencies\n```\n\n netflix starts \n\ncom.sun.jersey\njersey-client\n1.12\n\n\ncom.netflix.eureka\neureka-client\n1.6.2\n\n\njavax.ws.rs\njsr311-api\n\n\n\n https://mvnrepository.com/artifact/com.netflix.governator/governator \n\ncom.netflix.governator\ngovernator\n1.17.5\n\n\ncom.netflix.archaius\narchaius-core\n0.7.6\n\n <dependency> <groupId>javax.ws.rs</groupId> <artifactId>jsr311-api</artifactId> \n        <version>1.1.1</version> </dependency> \n\ncom.netflix.servo\nservo-core\n0.12.21\n\n<!-- netflix ends -->\n\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n    <version>2.9.4</version>\n</dependency>\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-annotations</artifactId>\n    <version>2.9.4</version>\n</dependency>\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-core</artifactId>\n    <version>2.9.4</version>\n</dependency>\n\n\n\n<dependency>\n    <groupId>com.hk</groupId>\n    <artifactId>HKBridgeClient</artifactId>\n    <version>1.2</version>\n</dependency>\n\n<dependency>\n    <groupId>com.hk</groupId>\n    <artifactId>HKJms</artifactId>\n    <version>2.0</version>\n</dependency>\n\n<dependency>\n    <groupId>com.hk</groupId>\n    <artifactId>securePay</artifactId>\n    <version>1.48-SNAPSHOT</version>\n</dependency>\n\n<!--<dependency> <groupId>com.hk</groupId> <artifactId>producer</artifactId> \n    <version>5.0-SNAPSHOT</version> </dependency> -->\n\n<!-- https://mvnrepository.com/artifact/org.json/json -->\n<dependency>\n    <groupId>org.json</groupId>\n    <artifactId>json</artifactId>\n    <version>20070829</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.activemq/activemq-core -->\n<dependency>\n    <groupId>org.apache.activemq</groupId>\n    <artifactId>activemq-core</artifactId>\n    <version>5.7.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.activemq/activemq-pool -->\n<dependency>\n    <groupId>org.apache.activemq</groupId>\n    <artifactId>activemq-pool</artifactId>\n    <version>5.7.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/javax.enterprise.concurrent/javax.enterprise.concurrent-api -->\n<dependency>\n    <groupId>javax.enterprise.concurrent</groupId>\n    <artifactId>javax.enterprise.concurrent-api</artifactId>\n    <version>1.0</version>\n    <scope>provided</scope>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/javax.servlet/javax.servlet-api -->\n<dependency>\n    <groupId>javax.servlet</groupId>\n    <artifactId>javax.servlet-api</artifactId>\n    <version>3.1.0</version>\n    <scope>provided</scope>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/com.hazelcast/hazelcast -->\n<dependency>\n    <groupId>com.hazelcast</groupId>\n    <artifactId>hazelcast</artifactId>\n    <version>3.8.3</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.hazelcast/hazelcast-client -->\n<dependency>\n    <groupId>com.hazelcast</groupId>\n    <artifactId>hazelcast-client</artifactId>\n    <version>3.8.3</version>\n</dependency>\n\n<dependency>\n    <groupId>io.connecto</groupId>\n    <artifactId>connecto-java</artifactId>\n    <version>0.9.4</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/com.contentful.java/java-sdk -->\n<dependency>\n    <groupId>com.contentful.java</groupId>\n    <artifactId>java-sdk</artifactId>\n    <version>2.0.0</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/com.amazon`/aws-java-sdk -->\n<dependency>\n    <groupId>com.amazonaws</groupId>\n    <artifactId>aws-java-sdk</artifactId>\n    <version>1.11.73</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/backport-util-concurrent/backport-util-concurrent -->\n<dependency>\n    <groupId>backport-util-concurrent</groupId>\n    <artifactId>backport-util-concurrent</artifactId>\n    <version>3.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.google.api-client/google-api-client -->\n<dependency>\n    <groupId>com.google.api-client</groupId>\n    <artifactId>google-api-client</artifactId>\n    <version>1.20.0</version>\n    <exclusions>\n        <exclusion>\n            <groupId>com.google.guava</groupId>\n            <artifactId>guava-jdk5</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<!-- https://mvnrepository.com/artifact/com.google.api-client/google-api-client-gson -->\n<dependency>\n    <groupId>com.google.api-client</groupId>\n    <artifactId>google-api-client-gson</artifactId>\n    <version>1.23.0</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/com.google.http-client/google-http-client -->\n<dependency>\n    <groupId>com.google.http-client</groupId>\n    <artifactId>google-http-client</artifactId>\n    <version>1.20.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.google.code.gson/gson -->\n<dependency>\n    <groupId>com.google.code.gson</groupId>\n    <artifactId>gson</artifactId>\n    <version>2.2.4</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/javax.servlet.jsp/jsp-api -->\n<dependency>\n    <groupId>javax.servlet.jsp</groupId>\n    <artifactId>jsp-api</artifactId>\n    <version>2.2</version>\n    <scope>provided</scope>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.aspectj/aspectjrt -->\n<dependency>\n    <groupId>org.aspectj</groupId>\n    <artifactId>aspectjrt</artifactId>\n    <version>1.8.10</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver -->\n<dependency>\n    <groupId>org.aspectj</groupId>\n    <artifactId>aspectjweaver</artifactId>\n    <version>1.8.10</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-codec/commons-codec -->\n<dependency>\n    <groupId>commons-codec</groupId>\n    <artifactId>commons-codec</artifactId>\n    <version>1.10</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/commons-logging/commons-logging -->\n<dependency>\n    <groupId>commons-logging</groupId>\n    <artifactId>commons-logging</artifactId>\n    <version>1.2</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient -->\n<dependency>\n    <groupId>org.apache.httpcomponents</groupId>\n    <artifactId>httpclient</artifactId>\n    <version>4.5.3</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/software.amazon.ion/ion-java -->\n<dependency>\n    <groupId>software.amazon.ion</groupId>\n    <artifactId>ion-java</artifactId>\n    <version>1.0.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.dataformat/jackson-dataformat-cbor -->\n<dependency>\n    <groupId>com.fasterxml.jackson.dataformat</groupId>\n    <artifactId>jackson-dataformat-cbor</artifactId>\n    <version>2.6.6</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/com.amazonaws/jmespath-java -->\n<dependency>\n    <groupId>com.amazonaws</groupId>\n    <artifactId>jmespath-java</artifactId>\n    <version>1.11.203</version>\n    <exclusions>\n        <exclusion>\n            <groupId>com.fasterxml.jackson.core</groupId>\n            <artifactId>jackson-databind</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<!-- https://mvnrepository.com/artifact/joda-time/joda-time -->\n<dependency>\n    <groupId>joda-time</groupId>\n    <artifactId>joda-time</artifactId>\n    <version>2.9.9</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-beans -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-beans</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-context -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-context</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-core -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-core</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-aop -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-aop</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-jms -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-jms</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n\n<!-- ************* barcode *************** -->\n<!-- https://mvnrepository.com/artifact/net.sf.barcode4j/barcode4j -->\n<dependency>\n    <groupId>net.sf.barcode4j</groupId>\n    <artifactId>barcode4j</artifactId>\n    <version>2.1</version>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n\n<!-- ************* citrus *************** -->\n\n<!-- https://mvnrepository.com/artifact/cryptix/cryptix -->\n<dependency>\n    <groupId>cryptix</groupId>\n    <artifactId>cryptix</artifactId>\n    <version>3.2.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/jboss/jnet -->\n<dependency>\n    <groupId>jboss</groupId>\n    <artifactId>jnet</artifactId>\n    <version>3.2.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jglobus/jsse -->\n<dependency>\n    <groupId>org.jglobus</groupId>\n    <artifactId>jsse</artifactId>\n    <version>2.1.0</version>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* commons *************** -->\n\n<!-- https://mvnrepository.com/artifact/commons-beanutils/commons-beanutils -->\n<dependency>\n    <groupId>commons-beanutils</groupId>\n    <artifactId>commons-beanutils</artifactId>\n    <version>1.9.3</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/commons-collections/commons-collections -->\n<dependency>\n    <groupId>commons-collections</groupId>\n    <artifactId>commons-collections</artifactId>\n    <version>3.2.2</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.commons/commons-dbcp2 -->\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-dbcp2</artifactId>\n    <version>2.0.1</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.apache.commons/commons-email -->\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-email</artifactId>\n    <version>1.5</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload -->\n<dependency>\n    <groupId>commons-fileupload</groupId>\n    <artifactId>commons-fileupload</artifactId>\n    <version>1.3.3</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-httpclient/commons-httpclient -->\n<dependency>\n    <groupId>commons-httpclient</groupId>\n    <artifactId>commons-httpclient</artifactId>\n    <version>3.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-io/commons-io -->\n<dependency>\n    <groupId>commons-io</groupId>\n    <artifactId>commons-io</artifactId>\n    <version>2.5</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-lang/commons-lang -->\n<dependency>\n    <groupId>commons-lang</groupId>\n    <artifactId>commons-lang</artifactId>\n    <version>2.6</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-pool/commons-pool -->\n<dependency>\n    <groupId>commons-pool</groupId>\n    <artifactId>commons-pool</artifactId>\n    <version>1.6</version>\n</dependency>\n\n\n\n<!-- https://mvnrepository.com/artifact/com.restfb/restfb -->\n<dependency>\n    <groupId>com.restfb</groupId>\n    <artifactId>restfb</artifactId>\n    <version>1.45.0</version>\n</dependency>\n\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* freemarker *************** -->\n\n<!-- https://mvnrepository.com/artifact/org.freemarker/freemarker -->\n<dependency>\n    <groupId>org.freemarker</groupId>\n    <artifactId>freemarker</artifactId>\n    <version>2.3.23</version>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* http *************** -->\n\n<!-- https://mvnrepository.com/artifact/com.google.guava/guava -->\n<dependency>\n    <groupId>com.google.guava</groupId>\n    <artifactId>guava</artifactId>\n    <version>15.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.ning/async-http-client -->\n<dependency>\n    <groupId>com.ning</groupId>\n    <artifactId>async-http-client</artifactId>\n    <version>1.9.40</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpcore-nio -->\n<dependency>\n    <groupId>org.apache.httpcomponents</groupId>\n    <artifactId>httpcore-nio</artifactId>\n    <version>4.4.7</version>\n</dependency>\n\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* infispan *************** -->\n\n<!-- local -->\n<dependency>\n    <groupId>org.infinispan</groupId>\n    <artifactId>infinispan-core</artifactId>\n    <version>5</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.logging/jboss-logging -->\n<dependency>\n    <groupId>org.jboss.logging</groupId>\n    <artifactId>jboss-logging</artifactId>\n    <version>3.3.1.Final</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.marshalling/jboss-marshalling -->\n<dependency>\n    <groupId>org.jboss.marshalling</groupId>\n    <artifactId>jboss-marshalling</artifactId>\n    <version>1.3.11.GA</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.marshalling/jboss-marshalling-river -->\n<dependency>\n    <groupId>org.jboss.marshalling</groupId>\n    <artifactId>jboss-marshalling-river</artifactId>\n    <version>1.3.11.GA</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.spec.javax.transaction/jboss-transaction-api_1.1_spec -->\n<dependency>\n    <groupId>org.jboss.spec.javax.transaction</groupId>\n    <artifactId>jboss-transaction-api_1.1_spec</artifactId>\n    <version>1.0.1.Final</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/net.jcip/jcip-annotations -->\n<dependency>\n    <groupId>net.jcip</groupId>\n    <artifactId>jcip-annotations</artifactId>\n    <version>1.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jgroups/jgroups -->\n<dependency>\n    <groupId>org.jgroups</groupId>\n    <artifactId>jgroups</artifactId>\n    <version>3.0.11.Final</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/log4j/log4j -->\n<dependency>\n    <groupId>log4j</groupId>\n    <artifactId>log4j</artifactId>\n    <version>1.2.13</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.osgi/org.osgi.core -->\n<dependency>\n    <groupId>org.osgi</groupId>\n    <artifactId>org.osgi.core</artifactId>\n    <version>6.0.0</version>\n    <scope>provided</scope>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.rhq.helpers/rhq-pluginAnnotations -->\n<dependency>\n    <groupId>org.rhq.helpers</groupId>\n    <artifactId>rhq-pluginAnnotations</artifactId>\n    <version>3.0.4</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.codehaus.woodstox/stax2-api -->\n<dependency>\n    <groupId>org.codehaus.woodstox</groupId>\n    <artifactId>stax2-api</artifactId>\n    <version>3.1.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.codehaus.woodstox/woodstox-core-asl -->\n<dependency>\n    <groupId>org.codehaus.woodstox</groupId>\n    <artifactId>woodstox-core-asl</artifactId>\n    <version>4.4.1</version>\n</dependency>\n\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* intellij *************** -->\n\n<!-- https://mvnrepository.com/artifact/com.intellij/annotations -->\n<dependency>\n    <groupId>com.intellij</groupId>\n    <artifactId>annotations</artifactId>\n    <version>12.0</version>\n</dependency>\n\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* itext *************** -->\n\n<!-- https://mvnrepository.com/artifact/com.lowagie/itext -->\n<dependency>\n    <groupId>com.lowagie</groupId>\n    <artifactId>itext</artifactId>\n    <version>4.2.2</version>\n    <type>pom</type>\n</dependency>\n\n\n<!-- ************* ********* *************** -->\n\n\n<!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-analyzers -->\n<!-- <dependency> <groupId>org.apache.lucene</groupId> <artifactId>lucene-analyzers</artifactId> \n    <version>3.6.2</version> </dependency> -->\n<!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-core -->\n<dependency>\n    <groupId>org.apache.lucene</groupId>\n    <artifactId>lucene-core</artifactId>\n    <version>${lucene.version}</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-highlighter -->\n<dependency>\n    <groupId>org.apache.lucene</groupId>\n    <artifactId>lucene-highlighter</artifactId>\n    <version>${lucene.version}</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-memory -->\n<dependency>\n    <groupId>org.apache.lucene</groupId>\n    <artifactId>lucene-memory</artifactId>\n    <version>4.10.3</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.lucene/lucene-queries -->\n<dependency>\n    <groupId>org.apache.lucene</groupId>\n    <artifactId>lucene-queries</artifactId>\n    <version>${lucene.version}</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.xerial.snappy/snappy-java -->\n<dependency>\n    <groupId>org.xerial.snappy</groupId>\n    <artifactId>snappy-java</artifactId>\n    <version>1.1.4</version>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* json *************** -->\n\n<!-- https://mvnrepository.com/artifact/net.sf.ezmorph/ezmorph -->\n<dependency>\n    <groupId>net.sf.ezmorph</groupId>\n    <artifactId>ezmorph</artifactId>\n    <version>1.0.6</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/net.sf.json-lib/json-lib -->\n<dependency>\n    <groupId>net.sf.json-lib</groupId>\n    <artifactId>json-lib</artifactId>\n    <version>2.3</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.googlecode.json-simple/json-simple -->\n<dependency>\n    <groupId>com.googlecode.json-simple</groupId>\n    <artifactId>json-simple</artifactId>\n    <version>1.1.1</version>\n</dependency>\n\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* logger *************** -->\n\n\n\n<!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api -->\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-api</artifactId>\n    <version>1.5.10</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 -->\n<dependency>\n    <groupId>org.slf4j</groupId>\n    <artifactId>slf4j-log4j12</artifactId>\n    <version>1.5.10</version>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* mysql *************** -->\n\n<!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java -->\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>6.0.6</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.tomcat/tomcat-jdbc -->\n<dependency>\n    <groupId>org.apache.tomcat</groupId>\n    <artifactId>tomcat-jdbc</artifactId>\n    <version>8.5.21</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.codehaus.jackson/jackson-jaxrs -->\n<dependency>\n    <groupId>org.codehaus.jackson</groupId>\n    <artifactId>jackson-jaxrs</artifactId>\n    <version>1.9.12</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.resteasy/jaxrs-api -->\n<dependency>\n    <groupId>org.jboss.resteasy</groupId>\n    <artifactId>jaxrs-api</artifactId>\n    <version>3.0.12.Final</version>\n</dependency>\n<dependency>\n    <groupId>javax.ws.rs</groupId>\n    <artifactId>javax.ws.rs-api</artifactId>\n    <version>2.1</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.jboss.resteasy/resteasy-guice -->\n<dependency>\n    <groupId>org.jboss.resteasy</groupId>\n    <artifactId>resteasy-guice</artifactId>\n    <version>3.0.9.Final</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.resteasy/resteasy-jackson-provider -->\n<dependency>\n    <groupId>org.jboss.resteasy</groupId>\n    <artifactId>resteasy-jackson-provider</artifactId>\n    <version>3.0.9.Final</version>\n    <exclusions>\n        <exclusion>\n            <groupId>org.codehaus.jackson</groupId>\n            <artifactId>jackson-xc</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.resteasy/resteasy-jaxrs -->\n<dependency>\n    <groupId>org.jboss.resteasy</groupId>\n    <artifactId>resteasy-jaxrs</artifactId>\n    <version>3.0.9.Final</version>\n    <!-- <exclusions> <exclusion> <groupId>org.jboss.resteasy</groupId> <artifactId>jaxrs-api</artifactId> \n        </exclusion> </exclusions> -->\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.resteasy/resteasy-multipart-provider -->\n<dependency>\n    <groupId>org.jboss.resteasy</groupId>\n    <artifactId>resteasy-multipart-provider</artifactId>\n    <version>3.0.9.Final</version>\n    <exclusions>\n        <exclusion>\n            <groupId>org.jboss.resteasy</groupId>\n            <artifactId>resteasy-client</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jboss.resteasy/resteasy-spring -->\n<dependency>\n    <groupId>org.jboss.resteasy</groupId>\n    <artifactId>resteasy-spring</artifactId>\n    <version>3.0.9.Final</version>\n    <exclusions>\n        <exclusion>\n            <groupId>org.jboss.resteasy</groupId>\n            <artifactId>resteasy-jettison-provider</artifactId>\n        </exclusion>\n        <exclusion>\n            <groupId>org.jboss.resteasy</groupId>\n            <artifactId>jaxrs-api</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n<!-- ************* ********* *************** -->\n\n<!-- https://mvnrepository.com/artifact/javax.servlet/jstl -->\n<dependency>\n    <groupId>javax.servlet</groupId>\n    <artifactId>jstl</artifactId>\n    <version>1.2</version>\n</dependency>\n\n\n\n<!-- https://mvnrepository.com/artifact/org.apache.commons/commons-lang3 -->\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-lang3</artifactId>\n    <version>3.6</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/dom4j/dom4j -->\n<dependency>\n    <groupId>dom4j</groupId>\n    <artifactId>dom4j</artifactId>\n    <version>1.6.1</version>\n</dependency>\n\n<!-- &lt;!&ndash; https://mvnrepository.com/artifact/org.hibernate/hibernate-annotations \n    &ndash;&gt; <dependency> <groupId>org.hibernate</groupId> <artifactId>hibernate-annotations</artifactId> \n    <version>3.5.6-Final</version> </dependency> -->\n\n<!-- https://mvnrepository.com/artifact/org.hibernate/hibernate-core -->\n<dependency>\n    <groupId>org.hibernate</groupId>\n    <artifactId>hibernate-core</artifactId>\n    <version>4.3.11.Final</version>\n</dependency>\n\n\n\n<!-- ************* ********* *************** -->\n\n\n\n<!-- ************* hibernate *************** -->\n\n<!-- https://mvnrepository.com/artifact/net.sourceforge.stripes/stripes -->\n<dependency>\n    <groupId>net.sourceforge.stripes</groupId>\n    <artifactId>stripes</artifactId>\n    <version>1.5.7</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.openjpa/openjpa -->\n<dependency>\n    <groupId>org.apache.openjpa</groupId>\n    <artifactId>openjpa</artifactId>\n    <version>2.4.2</version>\n    <exclusions>\n        <exclusion>\n            <groupId>org.apache.geronimo.specs</groupId>\n            <artifactId>geronimo-jpa_2.0_spec</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-dao -->\n<!-- <dependency> <groupId>org.springframework</groupId> <artifactId>spring-dao</artifactId> \n    <version>2.0.8</version> </dependency> -->\n\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-orm -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-orm</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.shiro/shiro-all -->\n<dependency>\n    <groupId>shiro</groupId>\n    <artifactId>shiro-all</artifactId>\n    <version>1.0-incubating-SNAPSHOT</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.springframework/spring-web -->\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-web</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.sanselan/sanselan -->\n<dependency>\n    <groupId>org.apache.sanselan</groupId>\n    <artifactId>sanselan</artifactId>\n    <version>0.97-incubator</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.sun.media/jai-codec -->\n<dependency>\n    <groupId>com.sun.media</groupId>\n    <artifactId>jai-codec</artifactId>\n    <version>1.1.3</version>\n</dependency>\n\n<!-- Local -->\n<dependency>\n    <groupId>com.sun.media</groupId>\n    <artifactId>jai_imageio</artifactId>\n    <version>1.1</version>\n</dependency>\n\n<!-- local -->\n<dependency>\n    <groupId>javax.media</groupId>\n    <artifactId>jai_core</artifactId>\n    <version>1.1.3</version>\n</dependency>\n\n<!-- local -->\n<dependency>\n    <groupId>thirdparty</groupId>\n    <artifactId>mediautil</artifactId>\n    <version>1.0</version>\n</dependency>\n\n<!-- &lt;!&ndash; https://mvnrepository.com/artifact/org.apache.shiro/shiro-web \n    &ndash;&gt; <dependency> <groupId>org.apache.shiro</groupId> <artifactId>shiro-web</artifactId> \n    <version>1.4.0</version> </dependency> -->\n\n<!-- https://mvnrepository.com/artifact/concurrent/concurrent -->\n<dependency>\n    <groupId>concurrent</groupId>\n    <artifactId>concurrent</artifactId>\n    <version>1.3.4</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.mindrot/jbcrypt -->\n<dependency>\n    <groupId>org.mindrot</groupId>\n    <artifactId>jbcrypt</artifactId>\n    <version>0.4</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.poi/poi -->\n<dependency>\n    <groupId>org.apache.poi</groupId>\n    <artifactId>poi</artifactId>\n    <version>3.17</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/net.spy/spymemcached -->\n<dependency>\n    <groupId>net.spy</groupId>\n    <artifactId>spymemcached</artifactId>\n    <version>2.12.3</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/javax.interceptor/javax.interceptor-api -->\n<dependency>\n    <groupId>javax.interceptor</groupId>\n    <artifactId>javax.interceptor-api</artifactId>\n    <version>1.2.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.tinify/tinify -->\n<dependency>\n    <groupId>com.tinify</groupId>\n    <artifactId>tinify</artifactId>\n    <version>1.5.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/net.java.dev.jets3t/jets3t -->\n<dependency>\n    <groupId>net.java.dev.jets3t</groupId>\n    <artifactId>jets3t</artifactId>\n    <version>0.9.4</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.jsoup/jsoup -->\n<dependency>\n    <groupId>org.jsoup</groupId>\n    <artifactId>jsoup</artifactId>\n    <version>1.7.2</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.elasticsearch/elasticsearch -->\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>6.1.1</version>\n</dependency>\n<!-- https://mvnrepository.com/artifact/org.elasticsearch.client/transport -->\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>transport</artifactId>\n    <version>6.1.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.itextpdf/itextpdf -->\n<dependency>\n    <groupId>com.itextpdf</groupId>\n    <artifactId>itextpdf</artifactId>\n    <version>5.2.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.lowagie/itext -->\n<dependency>\n    <groupId>com.lowagie</groupId>\n    <artifactId>itext</artifactId>\n    <version>1.4.8</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.xhtmlrenderer/core-renderer -->\n<dependency>\n    <groupId>org.xhtmlrenderer</groupId>\n    <artifactId>core-renderer</artifactId>\n    <version>R8pre2</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/de.congrace/exp4j -->\n<dependency>\n    <groupId>de.congrace</groupId>\n    <artifactId>exp4j</artifactId>\n    <version>0.3.11</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/com.mchange/c3p0 -->\n<dependency>\n    <groupId>com.mchange</groupId>\n    <artifactId>c3p0</artifactId>\n    <version>0.9.5.2</version>\n</dependency>\n\n<!-- Local -->\n<dependency>\n    <groupId>thirdparty</groupId>\n    <artifactId>lzstring4j</artifactId>\n    <version>unknown</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.codehaus.groovy/groovy-all -->\n<dependency>\n    <groupId>org.codehaus.groovy</groupId>\n    <artifactId>groovy-all</artifactId>\n    <version>2.4.12</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/javax.servlet.jsp/jsp-api -->\n<dependency>\n    <groupId>javax.servlet.jsp</groupId>\n    <artifactId>jsp-api</artifactId>\n    <version>2.2</version>\n    <scope>provided</scope>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/jfree/jcommon -->\n<dependency>\n    <groupId>jfree</groupId>\n    <artifactId>jcommon</artifactId>\n    <version>1.0.16</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/bsh/bsh -->\n<dependency>\n    <groupId>bsh</groupId>\n    <artifactId>bsh</artifactId>\n    <version>1.3.0</version>\n</dependency>\n\n<!-- local -->\n<dependency>\n    <groupId>org.stripesstuff</groupId>\n    <artifactId>stripesstuff</artifactId>\n    <version>0.1</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.apache.maven.plugins/maven-resources-plugin -->\n<dependency>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-resources-plugin</artifactId>\n    <version>3.0.2</version>\n</dependency>\n\n\n<!-- https://mvnrepository.com/artifact/org.apache.maven.plugins/maven-war-plugin -->\n<dependency>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-war-plugin</artifactId>\n    <version>3.2.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.mongodb/mongo-java-driver -->\n<dependency>\n    <groupId>org.mongodb</groupId>\n    <artifactId>mongo-java-driver</artifactId>\n    <version>3.3.0</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/org.springframework.data/spring-data-mongodb -->\n<dependency>\n    <groupId>org.springframework.data</groupId>\n    <artifactId>spring-data-mongodb</artifactId>\n    <version>1.9.2.RELEASE</version>\n    <exclusions>\n        <exclusion>\n            <groupId>org.slf4j</groupId>\n            <artifactId>jcl-over-slf4j</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n\n```\nIs some dependency version mismatch possible here. ```\n[INFO]\n[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ HKEdge ---\n[WARNING] The artifact com.lowagie:itext:pom:4.2.2 has been relocated to com.itextpdf:itextpdf:pom:5.5.6\n[INFO] HKEdge:HKEdge:war:0.0.1-SNAPSHOT\n[INFO] +- com.netflix.eureka:eureka-client:jar:1.6.2:compile\n[INFO] |  +- org.codehaus.jettison:jettison:jar:1.3.7:runtime\n[INFO] |  |  - stax:stax-api:jar:1.0.1:runtime\n[INFO] |  +- com.netflix.netflix-commons:netflix-eventbus:jar:0.3.0:runtime\n[INFO] |  |  +- com.netflix.netflix-commons:netflix-infix:jar:0.3.0:runtime\n[INFO] |  |  |  +- commons-jxpath:commons-jxpath:jar:1.3:runtime\n[INFO] |  |  |  +- javax.servlet:servlet-api:jar:2.5:runtime\n[INFO] |  |  |  - org.antlr:antlr-runtime:jar:3.4:runtime\n[INFO] |  |  |     - org.antlr:stringtemplate:jar:3.2.1:runtime\n[INFO] |  |  - org.apache.commons:commons-math:jar:2.2:runtime\n[INFO] |  +- com.thoughtworks.xstream:xstream:jar:1.4.9:compile\n[INFO] |  |  +- xmlpull:xmlpull:jar:1.1.3.1:compile\n[INFO] |  |  - xpp3:xpp3_min:jar:1.1.4c:compile\n[INFO] |  +- com.sun.jersey:jersey-core:jar:1.19.1:runtime\n[INFO] |  +- com.sun.jersey:jersey-client:jar:1.19.1:runtime\n[INFO] |  +- com.sun.jersey.contribs:jersey-apache-client4:jar:1.19.1:runtime\n[INFO] |  - com.google.inject:guice:jar:4.1.0:compile\n[INFO] |     +- javax.inject:javax.inject:jar:1:compile\n[INFO] |     - aopalliance:aopalliance:jar:1.0:compile\n[INFO] +- com.netflix.governator:governator:jar:1.17.5:compile\n[INFO] |  +- com.netflix.governator:governator-api:jar:1.17.5:compile\n[INFO] |  +- com.netflix.governator:governator-core:jar:1.17.5:compile\n[INFO] |  |  +- com.google.inject.extensions:guice-multibindings:jar:4.1.0:compile\n[INFO] |  |  - com.google.inject.extensions:guice-grapher:jar:4.1.0:compile\n[INFO] |  |     - com.google.inject.extensions:guice-assistedinject:jar:4.1.0:compile\n[INFO] |  - org.ow2.asm:asm:jar:5.0.4:compile\n[INFO] +- com.netflix.archaius:archaius-core:jar:0.7.6:compile\n[INFO] |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile\n[INFO] |  - commons-configuration:commons-configuration:jar:1.8:runtime\n[INFO] +- com.netflix.servo:servo-core:jar:0.12.21:compile\n[INFO] +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.4:compile\n[INFO] +- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.4:compile\n[INFO] +- com.fasterxml.jackson.core:jackson-core:jar:2.9.4:compile\n[INFO] +- com.hk:HKBridgeClient:jar:1.2:compile\n[INFO] +- com.hk:HKJms:jar:2.0:compile\n[INFO] +- com.hk:securePay:jar:1.48-SNAPSHOT:compile\n[INFO] +- org.json:json:jar:20070829:compile\n[INFO] +- org.apache.activemq:activemq-core:jar:5.7.0:compile\n[INFO] |  +- org.apache.geronimo.specs:geronimo-jms_1.1_spec:jar:1.1.1:compile\n[INFO] |  +- org.apache.activemq:kahadb:jar:5.7.0:compile\n[INFO] |  +- org.apache.activemq.protobuf:activemq-protobuf:jar:1.1:compile\n[INFO] |  +- org.fusesource.mqtt-client:mqtt-client:jar:1.3:compile\n[INFO] |  |  +- org.fusesource.hawtdispatch:hawtdispatch-transport:jar:1.11:compile\n[INFO] |  |  |  - org.fusesource.hawtdispatch:hawtdispatch:jar:1.11:compile\n[INFO] |  |  - org.fusesource.hawtbuf:hawtbuf:jar:1.9:compile\n[INFO] |  +- org.apache.geronimo.specs:geronimo-j2ee-management_1.1_spec:jar:1.0.1:compile\n[INFO] |  +- commons-net:commons-net:jar:3.1:compile\n[INFO] |  - org.jasypt:jasypt:jar:1.9.0:compile\n[INFO] +- org.apache.activemq:activemq-pool:jar:5.7.0:compile\n[INFO] |  - org.apache.geronimo.specs:geronimo-jta_1.0.1B_spec:jar:1.0.1:compile\n[INFO] +- javax.enterprise.concurrent:javax.enterprise.concurrent-api:jar:1.0:provided\n[INFO] +- javax.servlet:javax.servlet-api:jar:3.1.0:provided\n[INFO] +- com.hazelcast:hazelcast:jar:3.8.3:compile\n[INFO] +- com.hazelcast:hazelcast-client:jar:3.8.3:compile\n[INFO] +- io.connecto:connecto-java:jar:0.9.4:compile\n[INFO] +- com.contentful.java:java-sdk:jar:2.0.0:compile\n[INFO] |  +- com.squareup.retrofit:retrofit:jar:1.8.0:compile\n[INFO] |  - io.reactivex:rxjava:jar:1.0.0:compile\n[INFO] +- com.amazonaws:aws-java-sdk:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-pinpoint:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-xray:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-opsworkscm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-support:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-simpledb:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-servicecatalog:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-servermigration:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-simpleworkflow:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-storagegateway:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-route53:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-s3:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-importexport:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-sts:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-sqs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-rds:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-redshift:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticbeanstalk:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-glacier:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-iam:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-datapipeline:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticloadbalancing:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticloadbalancingv2:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-emr:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticache:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elastictranscoder:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ec2:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-dynamodb:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-sns:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-budgets:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudtrail:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudwatch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-logs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-events:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cognitoidentity:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cognitosync:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-directconnect:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudformation:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudfront:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-kinesis:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-opsworks:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ses:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-autoscaling:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudsearch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudwatchmetrics:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codedeploy:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codepipeline:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-kms:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-config:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-lambda:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ecs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ecr:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudhsm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ssm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-workspaces:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-machinelearning:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-directory:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-efs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codecommit:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-devicefarm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticsearch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-waf:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-marketplacecommerceanalytics:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-inspector:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-iot:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-api-gateway:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-acm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-gamelift:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-dms:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-marketplacemeteringservice:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cognitoidp:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-discovery:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-applicationautoscaling:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-snowball:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-rekognition:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-polly:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-lightsail:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-stepfunctions:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-health:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codebuild:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-appstream:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-shield:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-batch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-core:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-models:jar:1.11.73:compile\n[INFO] |  - com.amazonaws:aws-java-sdk-swf-libraries:jar:1.11.22:compile\n[INFO] +- backport-util-concurrent:backport-util-concurrent:jar:3.0:compile\n[INFO] +- com.google.api-client:google-api-client:jar:1.20.0:compile\n[INFO] |  +- com.google.oauth-client:google-oauth-client:jar:1.20.0:compile\n[INFO] |  - com.google.http-client:google-http-client-jackson2:jar:1.20.0:compile\n[INFO] +- com.google.api-client:google-api-client-gson:jar:1.23.0:compile\n[INFO] |  - com.google.http-client:google-http-client-gson:jar:1.23.0:compile\n[INFO] +- com.google.http-client:google-http-client:jar:1.20.0:compile\n[INFO] +- com.google.code.gson:gson:jar:2.2.4:compile\n[INFO] +- javax.servlet.jsp:jsp-api:jar:2.2:provided\n[INFO] +- org.aspectj:aspectjrt:jar:1.8.10:compile\n[INFO] +- org.aspectj:aspectjweaver:jar:1.8.10:compile\n[INFO] +- commons-codec:commons-codec:jar:1.10:compile\n[INFO] +- commons-logging:commons-logging:jar:1.2:compile\n[INFO] +- org.apache.httpcomponents:httpclient:jar:4.5.3:compile\n[INFO] |  - org.apache.httpcomponents:httpcore:jar:4.4.6:compile\n[INFO] +- software.amazon.ion:ion-java:jar:1.0.1:compile\n[INFO] +- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.6.6:compile\n[INFO] +- com.amazonaws:jmespath-java:jar:1.11.203:compile\n[INFO] +- joda-time:joda-time:jar:2.9.9:compile\n[INFO] +- org.springframework:spring-beans:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-context:jar:4.3.11.RELEASE:compile\n[INFO] |  - org.springframework:spring-expression:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-core:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-aop:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-jms:jar:4.3.11.RELEASE:compile\n[INFO] |  +- org.springframework:spring-messaging:jar:4.3.11.RELEASE:compile\n[INFO] |  - org.springframework:spring-tx:jar:4.3.11.RELEASE:compile\n[INFO] +- net.sf.barcode4j:barcode4j:jar:2.1:compile\n[INFO] |  +- avalon-framework:avalon-framework-impl:jar:4.2.0:compile\n[INFO] |  +- commons-cli:commons-cli:jar:1.0:compile\n[INFO] |  - org.apache.ant:ant:jar:1.7.1:compile\n[INFO] |     - org.apache.ant:ant-launcher:jar:1.7.1:compile\n[INFO] +- cryptix:cryptix:jar:3.2.0:compile\n[INFO] +- jboss:jnet:jar:3.2.1:compile\n[INFO] +- org.jglobus:jsse:jar:2.1.0:compile\n[INFO] |  - org.jglobus:ssl-proxies:jar:2.1.0:compile\n[INFO] +- commons-beanutils:commons-beanutils:jar:1.9.3:compile\n[INFO] +- commons-collections:commons-collections:jar:3.2.2:compile\n[INFO] +- org.apache.commons:commons-dbcp2:jar:2.0.1:compile\n[INFO] |  - org.apache.commons:commons-pool2:jar:2.2:compile\n[INFO] +- org.apache.commons:commons-email:jar:1.5:compile\n[INFO] |  - com.sun.mail:javax.mail:jar:1.5.6:compile\n[INFO] +- commons-fileupload:commons-fileupload:jar:1.3.3:compile\n[INFO] +- commons-httpclient:commons-httpclient:jar:3.1:compile\n[INFO] +- commons-io:commons-io:jar:2.5:compile\n[INFO] +- commons-lang:commons-lang:jar:2.6:compile\n[INFO] +- commons-pool:commons-pool:jar:1.6:compile\n[INFO] +- com.restfb:restfb:jar:1.45.0:compile\n[INFO] +- org.freemarker:freemarker:jar:2.3.23:compile\n[INFO] +- com.google.guava:guava:jar:15.0:compile\n[INFO] +- com.ning:async-http-client:jar:1.9.40:compile\n[INFO] |  - io.netty:netty:jar:3.10.6.Final:compile\n[INFO] +- org.apache.httpcomponents:httpcore-nio:jar:4.4.7:compile\n[INFO] +- org.infinispan:infinispan-core:jar:5:compile\n[INFO] +- org.jboss.logging:jboss-logging:jar:3.3.1.Final:compile\n[INFO] +- org.jboss.marshalling:jboss-marshalling:jar:1.3.11.GA:compile\n[INFO] +- org.jboss.marshalling:jboss-marshalling-river:jar:1.3.11.GA:compile\n[INFO] +- org.jboss.spec.javax.transaction:jboss-transaction-api_1.1_spec:jar:1.0.1.Final:compile\n[INFO] +- net.jcip:jcip-annotations:jar:1.0:compile\n[INFO] +- org.jgroups:jgroups:jar:3.0.11.Final:compile\n[INFO] +- log4j:log4j:jar:1.2.13:compile\n[INFO] +- org.osgi:org.osgi.core:jar:6.0.0:provided\n[INFO] +- org.rhq.helpers:rhq-pluginAnnotations:jar:3.0.4:compile\n[INFO] +- org.codehaus.woodstox:stax2-api:jar:3.1.1:compile\n[INFO] |  - javax.xml.stream:stax-api:jar:1.0-2:compile\n[INFO] +- org.codehaus.woodstox:woodstox-core-asl:jar:4.4.1:compile\n[INFO] +- com.intellij:annotations:jar:12.0:compile\n[INFO] +- com.itextpdf:itextpdf:pom:5.5.6:compile\n[INFO] +- org.apache.lucene:lucene-core:jar:7.1.0:compile\n[INFO] +- org.apache.lucene:lucene-highlighter:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-analyzers-common:jar:7.1.0:compile\n[INFO] |  - org.apache.lucene:lucene-join:jar:7.1.0:compile\n[INFO] +- org.apache.lucene:lucene-memory:jar:4.10.3:compile\n[INFO] +- org.apache.lucene:lucene-queries:jar:7.1.0:compile\n[INFO] +- org.xerial.snappy:snappy-java:jar:1.1.4:compile\n[INFO] +- net.sf.ezmorph:ezmorph:jar:1.0.6:compile\n[INFO] +- net.sf.json-lib:json-lib:jar:2.3:compile\n[INFO] +- com.googlecode.json-simple:json-simple:jar:1.1.1:compile\n[INFO] |  - junit:junit:jar:4.10:compile\n[INFO] |     - org.hamcrest:hamcrest-core:jar:1.1:compile\n[INFO] +- org.slf4j:slf4j-api:jar:1.5.10:compile\n[INFO] +- org.slf4j:slf4j-log4j12:jar:1.5.10:compile\n[INFO] +- mysql:mysql-connector-java:jar:6.0.6:compile\n[INFO] +- org.apache.tomcat:tomcat-jdbc:jar:8.5.21:compile\n[INFO] |  - org.apache.tomcat:tomcat-juli:jar:8.5.21:compile\n[INFO] +- org.codehaus.jackson:jackson-jaxrs:jar:1.9.12:compile\n[INFO] |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.12:compile\n[INFO] |  - org.codehaus.jackson:jackson-mapper-asl:jar:1.9.12:compile\n[INFO] +- org.jboss.resteasy:resteasy-guice:jar:3.0.9.Final:compile\n[INFO] |  - javax.annotation:jsr250-api:jar:1.0:compile\n[INFO] +- org.jboss.resteasy:resteasy-jackson-provider:jar:3.0.9.Final:compile\n[INFO] +- org.jboss.resteasy:resteasy-jaxrs:jar:3.0.9.Final:compile\n[INFO] |  +- org.jboss.resteasy:jaxrs-api:jar:3.0.9.Final:compile\n[INFO] |  +- org.jboss.spec.javax.annotation:jboss-annotations-api_1.1_spec:jar:1.0.1.Final:compile\n[INFO] |  - javax.activation:activation:jar:1.1:compile\n[INFO] +- org.jboss.resteasy:resteasy-multipart-provider:jar:3.0.9.Final:compile\n[INFO] |  +- org.jboss.resteasy:resteasy-jaxb-provider:jar:3.0.9.Final:compile\n[INFO] |  |  - com.sun.xml.bind:jaxb-impl:jar:2.2.7:compile\n[INFO] |  |     +- com.sun.xml.bind:jaxb-core:jar:2.2.7:compile\n[INFO] |  |     |  +- javax.xml.bind:jaxb-api:jar:2.2.7:compile\n[INFO] |  |     |  - com.sun.istack:istack-commons-runtime:jar:2.16:compile\n[INFO] |  |     - com.sun.xml.fastinfoset:FastInfoset:jar:1.2.12:compile\n[INFO] |  |        - javax.xml.bind:jsr173_api:jar:1.0:compile\n[INFO] |  +- javax.mail:mail:jar:1.5.0-b01:compile\n[INFO] |  - org.apache.james:apache-mime4j:jar:0.6:compile\n[INFO] +- org.jboss.resteasy:resteasy-spring:jar:3.0.9.Final:compile\n[INFO] +- javax.servlet:jstl:jar:1.2:compile\n[INFO] +- org.apache.commons:commons-lang3:jar:3.6:compile\n[INFO] +- dom4j:dom4j:jar:1.6.1:compile\n[INFO] |  - xml-apis:xml-apis:jar:1.0.b2:compile\n[INFO] +- org.hibernate:hibernate-core:jar:4.3.11.Final:compile\n[INFO] |  +- org.jboss.logging:jboss-logging-annotations:jar:1.2.0.Beta1:compile\n[INFO] |  +- org.jboss.spec.javax.transaction:jboss-transaction-api_1.2_spec:jar:1.0.0.Final:compile\n[INFO] |  +- org.hibernate.common:hibernate-commons-annotations:jar:4.0.5.Final:compile\n[INFO] |  +- org.hibernate.javax.persistence:hibernate-jpa-2.1-api:jar:1.0.0.Final:compile\n[INFO] |  +- org.javassist:javassist:jar:3.18.1-GA:compile\n[INFO] |  +- antlr:antlr:jar:2.7.7:compile\n[INFO] |  - org.jboss:jandex:jar:1.1.0.Final:compile\n[INFO] +- net.sourceforge.stripes:stripes:jar:1.5.7:compile\n[INFO] +- org.apache.openjpa:openjpa:jar:2.4.2:compile\n[INFO] |  +- net.sourceforge.serp:serp:jar:1.15.1:compile\n[INFO] |  +- org.apache.geronimo.specs:geronimo-jta_1.1_spec:jar:1.1.1:compile\n[INFO] |  - org.apache.xbean:xbean-asm5-shaded:jar:3.17:compile\n[INFO] +- org.springframework:spring-orm:jar:4.3.11.RELEASE:compile\n[INFO] |  - org.springframework:spring-jdbc:jar:4.3.11.RELEASE:compile\n[INFO] +- shiro:shiro-all:jar:1.0-incubating-SNAPSHOT:compile\n[INFO] +- org.springframework:spring-web:jar:4.3.11.RELEASE:compile\n[INFO] +- org.apache.sanselan:sanselan:jar:0.97-incubator:compile\n[INFO] +- com.sun.media:jai-codec:jar:1.1.3:compile\n[INFO] |  - javax.media:jai-core:jar:1.1.3:compile\n[INFO] +- com.sun.media:jai_imageio:jar:1.1:compile\n[INFO] +- javax.media:jai_core:jar:1.1.3:compile\n[INFO] +- thirdparty:mediautil:jar:1.0:compile\n[INFO] +- concurrent:concurrent:jar:1.3.4:compile\n[INFO] +- org.mindrot:jbcrypt:jar:0.4:compile\n[INFO] +- org.apache.poi:poi:jar:3.17:compile\n[INFO] |  - org.apache.commons:commons-collections4:jar:4.1:compile\n[INFO] +- net.spy:spymemcached:jar:2.12.3:compile\n[INFO] +- javax.interceptor:javax.interceptor-api:jar:1.2.1:compile\n[INFO] +- com.tinify:tinify:jar:1.5.1:compile\n[INFO] |  - com.squareup.okhttp3:okhttp:jar:3.8.1:compile\n[INFO] |     - com.squareup.okio:okio:jar:1.13.0:compile\n[INFO] +- net.java.dev.jets3t:jets3t:jar:0.9.4:compile\n[INFO] |  +- org.bouncycastle:bcprov-jdk15on:jar:1.52:compile\n[INFO] |  - com.jamesmurty.utils:java-xmlbuilder:jar:1.1:compile\n[INFO] |     - net.iharder:base64:jar:2.3.8:compile\n[INFO] +- org.jsoup:jsoup:jar:1.7.2:compile\n[INFO] +- org.elasticsearch:elasticsearch:jar:6.1.1:compile\n[INFO] |  +- org.apache.lucene:lucene-backward-codecs:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-grouping:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-misc:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-queryparser:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-sandbox:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-spatial:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-spatial-extras:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-spatial3d:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-suggest:jar:7.1.0:compile\n[INFO] |  +- org.elasticsearch:securesm:jar:1.2:compile\n[INFO] |  +- org.elasticsearch:elasticsearch-cli:jar:6.1.1:compile\n[INFO] |  |  - net.sf.jopt-simple:jopt-simple:jar:5.0.2:compile\n[INFO] |  +- com.carrotsearch:hppc:jar:0.7.1:compile\n[INFO] |  +- org.yaml:snakeyaml:jar:1.17:compile\n[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-smile:jar:2.8.10:compile\n[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.8.10:compile\n[INFO] |  +- com.tdunning:t-digest:jar:3.0:compile\n[INFO] |  +- org.hdrhistogram:HdrHistogram:jar:2.1.9:compile\n[INFO] |  +- org.apache.logging.log4j:log4j-api:jar:2.9.1:compile\n[INFO] |  - org.elasticsearch:jna:jar:4.4.0-1:compile\n[INFO] +- org.elasticsearch.client:transport:jar:6.1.1:compile\n[INFO] |  +- org.elasticsearch.plugin:transport-netty4-client:jar:6.1.1:compile\n[INFO] |  |  +- io.netty:netty-buffer:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-codec:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-codec-http:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-common:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-handler:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-resolver:jar:4.1.13.Final:compile\n[INFO] |  |  - io.netty:netty-transport:jar:4.1.13.Final:compile\n[INFO] |  +- org.elasticsearch.plugin:reindex-client:jar:6.1.1:compile\n[INFO] |  |  - org.elasticsearch.client:elasticsearch-rest-client:jar:6.1.1:compile\n[INFO] |  |     - org.apache.httpcomponents:httpasyncclient:jar:4.1.2:compile\n[INFO] |  +- org.elasticsearch.plugin:lang-mustache-client:jar:6.1.1:compile\n[INFO] |  |  - com.github.spullara.mustache.java:compiler:jar:0.9.3:compile\n[INFO] |  +- org.elasticsearch.plugin:percolator-client:jar:6.1.1:compile\n[INFO] |  - org.elasticsearch.plugin:parent-join-client:jar:6.1.1:compile\n[INFO] +- com.itextpdf:itextpdf:jar:5.2.1:compile\n[INFO] +- com.lowagie:itext:jar:1.4.8:compile\n[INFO] +- org.xhtmlrenderer:core-renderer:jar:R8pre2:compile\n[INFO] +- de.congrace:exp4j:jar:0.3.11:compile\n[INFO] +- com.mchange:c3p0:jar:0.9.5.2:compile\n[INFO] |  - com.mchange:mchange-commons-java:jar:0.2.11:compile\n[INFO] +- thirdparty:lzstring4j:jar:unknown:compile\n[INFO] +- org.codehaus.groovy:groovy-all:jar:2.4.12:compile\n[INFO] +- jfree:jcommon:jar:1.0.16:compile\n[INFO] +- bsh:bsh:jar:1.3.0:compile\n[INFO] +- org.stripesstuff:stripesstuff:jar:0.1:compile\n[INFO] +- org.apache.maven.plugins:maven-resources-plugin:jar:3.0.2:compile\n[INFO] |  +- org.apache.maven:maven-plugin-api:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-artifact:jar:3.0:compile\n[INFO] |  |  - org.sonatype.sisu:sisu-inject-plexus:jar:1.4.2:compile\n[INFO] |  |     - org.sonatype.sisu:sisu-inject-bean:jar:1.4.2:compile\n[INFO] |  |        - org.sonatype.sisu:sisu-guice:jar:noaop:2.1.7:compile\n[INFO] |  +- org.apache.maven:maven-core:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-settings:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-settings-builder:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-repository-metadata:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-model-builder:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-aether-provider:jar:3.0:runtime\n[INFO] |  |  +- org.sonatype.aether:aether-impl:jar:1.7:compile\n[INFO] |  |  |  - org.sonatype.aether:aether-spi:jar:1.7:compile\n[INFO] |  |  +- org.sonatype.aether:aether-api:jar:1.7:compile\n[INFO] |  |  +- org.sonatype.aether:aether-util:jar:1.7:compile\n[INFO] |  |  +- org.codehaus.plexus:plexus-classworlds:jar:2.2.3:compile\n[INFO] |  |  +- org.codehaus.plexus:plexus-component-annotations:jar:1.5.5:compile\n[INFO] |  |  - org.sonatype.plexus:plexus-sec-dispatcher:jar:1.3:compile\n[INFO] |  |     - org.sonatype.plexus:plexus-cipher:jar:1.4:compile\n[INFO] |  +- org.apache.maven:maven-model:jar:3.0:compile\n[INFO] |  +- org.codehaus.plexus:plexus-utils:jar:3.0.24:compile\n[INFO] |  +- org.apache.maven.shared:maven-filtering:jar:3.1.1:compile\n[INFO] |  |  +- org.apache.maven.shared:maven-shared-utils:jar:3.0.0:compile\n[INFO] |  |  - org.sonatype.plexus:plexus-build-api:jar:0.0.7:compile\n[INFO] |  - org.codehaus.plexus:plexus-interpolation:jar:1.24:compile\n[INFO] +- org.apache.maven.plugins:maven-war-plugin:jar:3.2.0:compile\n[INFO] |  +- org.apache.maven:maven-archiver:jar:3.2.0:compile\n[INFO] |  +- org.codehaus.plexus:plexus-archiver:jar:3.5:compile\n[INFO] |  |  +- org.codehaus.plexus:plexus-io:jar:3.0.0:compile\n[INFO] |  |  +- org.apache.commons:commons-compress:jar:1.14:compile\n[INFO] |  |  +- org.iq80.snappy:snappy:jar:0.4:compile\n[INFO] |  |  - org.tukaani:xz:jar:1.6:runtime\n[INFO] |  - org.apache.maven.shared:maven-mapping:jar:3.0.0:compile\n[INFO] +- org.mongodb:mongo-java-driver:jar:3.3.0:compile\n[INFO] +- org.springframework.data:spring-data-mongodb:jar:1.9.2.RELEASE:compile\n[INFO] |  - org.springframework.data:spring-data-commons:jar:1.12.2.RELEASE:compile\n[INFO] - hk.kinesis.producer:kinesis-config:jar:0.0.1-SNAPSHOT:compile\n[INFO]    +- com.amazonaws:amazon-kinesis-client:jar:1.9.0:compile\n[INFO]    |  - com.google.protobuf:protobuf-java:jar:2.6.1:compile\n[INFO]    - com.amazonaws:amazon-kinesis-producer:jar:0.12.8:compile\n[INFO] ------------------------------------------------------------------------\n```. sorry my mistake I added javax.ws.rs-api dependency today after your suggestion and took dependency tree output from yesterday. Below is dependency tree output now \n```\n[INFO] --- maven-dependency-plugin:2.8:tree (default-cli) @ HKEdge ---\n[WARNING] The artifact com.lowagie:itext:pom:4.2.2 has been relocated to com.itextpdf:itextpdf:pom:5.5.6\n[INFO] HKEdge:HKEdge:war:0.0.1-SNAPSHOT\n[INFO] +- com.sun.jersey:jersey-client:jar:1.12:compile\n[INFO] |  - com.sun.jersey:jersey-core:jar:1.12:compile\n[INFO] +- com.netflix.eureka:eureka-client:jar:1.6.2:compile\n[INFO] |  +- org.codehaus.jettison:jettison:jar:1.3.7:runtime\n[INFO] |  |  - stax:stax-api:jar:1.0.1:runtime\n[INFO] |  +- com.netflix.netflix-commons:netflix-eventbus:jar:0.3.0:runtime\n[INFO] |  |  +- com.netflix.netflix-commons:netflix-infix:jar:0.3.0:runtime\n[INFO] |  |  |  +- commons-jxpath:commons-jxpath:jar:1.3:runtime\n[INFO] |  |  |  +- javax.servlet:servlet-api:jar:2.5:runtime\n[INFO] |  |  |  - org.antlr:antlr-runtime:jar:3.4:runtime\n[INFO] |  |  |     - org.antlr:stringtemplate:jar:3.2.1:runtime\n[INFO] |  |  - org.apache.commons:commons-math:jar:2.2:runtime\n[INFO] |  +- com.thoughtworks.xstream:xstream:jar:1.4.9:compile\n[INFO] |  |  +- xmlpull:xmlpull:jar:1.1.3.1:compile\n[INFO] |  |  - xpp3:xpp3_min:jar:1.1.4c:compile\n[INFO] |  +- com.sun.jersey.contribs:jersey-apache-client4:jar:1.19.1:runtime\n[INFO] |  - com.google.inject:guice:jar:4.1.0:compile\n[INFO] |     +- javax.inject:javax.inject:jar:1:compile\n[INFO] |     - aopalliance:aopalliance:jar:1.0:compile\n[INFO] +- com.netflix.governator:governator:jar:1.17.5:compile\n[INFO] |  +- com.netflix.governator:governator-api:jar:1.17.5:compile\n[INFO] |  +- com.netflix.governator:governator-core:jar:1.17.5:compile\n[INFO] |  |  +- com.google.inject.extensions:guice-multibindings:jar:4.1.0:compile\n[INFO] |  |  - com.google.inject.extensions:guice-grapher:jar:4.1.0:compile\n[INFO] |  |     - com.google.inject.extensions:guice-assistedinject:jar:4.1.0:compile\n[INFO] |  - org.ow2.asm:asm:jar:5.0.4:compile\n[INFO] +- com.netflix.archaius:archaius-core:jar:0.7.6:compile\n[INFO] |  +- com.google.code.findbugs:jsr305:jar:3.0.1:compile\n[INFO] |  - commons-configuration:commons-configuration:jar:1.8:runtime\n[INFO] +- com.netflix.servo:servo-core:jar:0.12.21:compile\n[INFO] +- com.fasterxml.jackson.core:jackson-databind:jar:2.9.4:compile\n[INFO] +- com.fasterxml.jackson.core:jackson-annotations:jar:2.9.4:compile\n[INFO] +- com.fasterxml.jackson.core:jackson-core:jar:2.9.4:compile\n[INFO] +- com.hk:HKBridgeClient:jar:1.2:compile\n[INFO] +- com.hk:HKJms:jar:2.0:compile\n[INFO] +- com.hk:securePay:jar:1.48-SNAPSHOT:compile\n[INFO] +- org.json:json:jar:20070829:compile\n[INFO] +- org.apache.activemq:activemq-core:jar:5.7.0:compile\n[INFO] |  +- org.apache.geronimo.specs:geronimo-jms_1.1_spec:jar:1.1.1:compile\n[INFO] |  +- org.apache.activemq:kahadb:jar:5.7.0:compile\n[INFO] |  +- org.apache.activemq.protobuf:activemq-protobuf:jar:1.1:compile\n[INFO] |  +- org.fusesource.mqtt-client:mqtt-client:jar:1.3:compile\n[INFO] |  |  +- org.fusesource.hawtdispatch:hawtdispatch-transport:jar:1.11:compile\n[INFO] |  |  |  - org.fusesource.hawtdispatch:hawtdispatch:jar:1.11:compile\n[INFO] |  |  - org.fusesource.hawtbuf:hawtbuf:jar:1.9:compile\n[INFO] |  +- org.apache.geronimo.specs:geronimo-j2ee-management_1.1_spec:jar:1.0.1:compile\n[INFO] |  +- commons-net:commons-net:jar:3.1:compile\n[INFO] |  - org.jasypt:jasypt:jar:1.9.0:compile\n[INFO] +- org.apache.activemq:activemq-pool:jar:5.7.0:compile\n[INFO] |  - org.apache.geronimo.specs:geronimo-jta_1.0.1B_spec:jar:1.0.1:compile\n[INFO] +- javax.enterprise.concurrent:javax.enterprise.concurrent-api:jar:1.0:provided\n[INFO] +- javax.servlet:javax.servlet-api:jar:3.1.0:provided\n[INFO] +- com.hazelcast:hazelcast:jar:3.8.3:compile\n[INFO] +- com.hazelcast:hazelcast-client:jar:3.8.3:compile\n[INFO] +- io.connecto:connecto-java:jar:0.9.4:compile\n[INFO] +- com.contentful.java:java-sdk:jar:2.0.0:compile\n[INFO] |  +- com.squareup.retrofit:retrofit:jar:1.8.0:compile\n[INFO] |  - io.reactivex:rxjava:jar:1.0.0:compile\n[INFO] +- com.amazonaws:aws-java-sdk:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-pinpoint:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-xray:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-opsworkscm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-support:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-simpledb:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-servicecatalog:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-servermigration:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-simpleworkflow:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-storagegateway:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-route53:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-s3:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-importexport:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-sts:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-sqs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-rds:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-redshift:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticbeanstalk:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-glacier:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-iam:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-datapipeline:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticloadbalancing:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticloadbalancingv2:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-emr:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticache:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elastictranscoder:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ec2:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-dynamodb:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-sns:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-budgets:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudtrail:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudwatch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-logs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-events:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cognitoidentity:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cognitosync:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-directconnect:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudformation:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudfront:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-kinesis:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-opsworks:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ses:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-autoscaling:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudsearch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudwatchmetrics:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codedeploy:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codepipeline:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-kms:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-config:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-lambda:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ecs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ecr:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cloudhsm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-ssm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-workspaces:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-machinelearning:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-directory:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-efs:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codecommit:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-devicefarm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-elasticsearch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-waf:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-marketplacecommerceanalytics:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-inspector:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-iot:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-api-gateway:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-acm:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-gamelift:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-dms:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-marketplacemeteringservice:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-cognitoidp:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-discovery:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-applicationautoscaling:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-snowball:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-rekognition:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-polly:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-lightsail:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-stepfunctions:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-health:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-codebuild:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-appstream:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-shield:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-batch:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-core:jar:1.11.73:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-models:jar:1.11.73:compile\n[INFO] |  - com.amazonaws:aws-java-sdk-swf-libraries:jar:1.11.22:compile\n[INFO] +- backport-util-concurrent:backport-util-concurrent:jar:3.0:compile\n[INFO] +- com.google.api-client:google-api-client:jar:1.20.0:compile\n[INFO] |  +- com.google.oauth-client:google-oauth-client:jar:1.20.0:compile\n[INFO] |  - com.google.http-client:google-http-client-jackson2:jar:1.20.0:compile\n[INFO] +- com.google.api-client:google-api-client-gson:jar:1.23.0:compile\n[INFO] |  - com.google.http-client:google-http-client-gson:jar:1.23.0:compile\n[INFO] +- com.google.http-client:google-http-client:jar:1.20.0:compile\n[INFO] +- com.google.code.gson:gson:jar:2.2.4:compile\n[INFO] +- javax.servlet.jsp:jsp-api:jar:2.2:provided\n[INFO] +- org.aspectj:aspectjrt:jar:1.8.10:compile\n[INFO] +- org.aspectj:aspectjweaver:jar:1.8.10:compile\n[INFO] +- commons-codec:commons-codec:jar:1.10:compile\n[INFO] +- commons-logging:commons-logging:jar:1.2:compile\n[INFO] +- org.apache.httpcomponents:httpclient:jar:4.5.3:compile\n[INFO] |  - org.apache.httpcomponents:httpcore:jar:4.4.6:compile\n[INFO] +- software.amazon.ion:ion-java:jar:1.0.1:compile\n[INFO] +- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.6.6:compile\n[INFO] +- com.amazonaws:jmespath-java:jar:1.11.203:compile\n[INFO] +- joda-time:joda-time:jar:2.9.9:compile\n[INFO] +- org.springframework:spring-beans:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-context:jar:4.3.11.RELEASE:compile\n[INFO] |  - org.springframework:spring-expression:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-core:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-aop:jar:4.3.11.RELEASE:compile\n[INFO] +- org.springframework:spring-jms:jar:4.3.11.RELEASE:compile\n[INFO] |  +- org.springframework:spring-messaging:jar:4.3.11.RELEASE:compile\n[INFO] |  - org.springframework:spring-tx:jar:4.3.11.RELEASE:compile\n[INFO] +- net.sf.barcode4j:barcode4j:jar:2.1:compile\n[INFO] |  +- avalon-framework:avalon-framework-impl:jar:4.2.0:compile\n[INFO] |  +- commons-cli:commons-cli:jar:1.0:compile\n[INFO] |  - org.apache.ant:ant:jar:1.7.1:compile\n[INFO] |     - org.apache.ant:ant-launcher:jar:1.7.1:compile\n[INFO] +- cryptix:cryptix:jar:3.2.0:compile\n[INFO] +- jboss:jnet:jar:3.2.1:compile\n[INFO] +- org.jglobus:jsse:jar:2.1.0:compile\n[INFO] |  - org.jglobus:ssl-proxies:jar:2.1.0:compile\n[INFO] +- commons-beanutils:commons-beanutils:jar:1.9.3:compile\n[INFO] +- commons-collections:commons-collections:jar:3.2.2:compile\n[INFO] +- org.apache.commons:commons-dbcp2:jar:2.0.1:compile\n[INFO] |  - org.apache.commons:commons-pool2:jar:2.2:compile\n[INFO] +- org.apache.commons:commons-email:jar:1.5:compile\n[INFO] |  - com.sun.mail:javax.mail:jar:1.5.6:compile\n[INFO] +- commons-fileupload:commons-fileupload:jar:1.3.3:compile\n[INFO] +- commons-httpclient:commons-httpclient:jar:3.1:compile\n[INFO] +- commons-io:commons-io:jar:2.5:compile\n[INFO] +- commons-lang:commons-lang:jar:2.6:compile\n[INFO] +- commons-pool:commons-pool:jar:1.6:compile\n[INFO] +- com.restfb:restfb:jar:1.45.0:compile\n[INFO] +- org.freemarker:freemarker:jar:2.3.23:compile\n[INFO] +- com.google.guava:guava:jar:15.0:compile\n[INFO] +- com.ning:async-http-client:jar:1.9.40:compile\n[INFO] |  - io.netty:netty:jar:3.10.6.Final:compile\n[INFO] +- org.apache.httpcomponents:httpcore-nio:jar:4.4.7:compile\n[INFO] +- org.infinispan:infinispan-core:jar:5:compile\n[INFO] +- org.jboss.logging:jboss-logging:jar:3.3.1.Final:compile\n[INFO] +- org.jboss.marshalling:jboss-marshalling:jar:1.3.11.GA:compile\n[INFO] +- org.jboss.marshalling:jboss-marshalling-river:jar:1.3.11.GA:compile\n[INFO] +- org.jboss.spec.javax.transaction:jboss-transaction-api_1.1_spec:jar:1.0.1.Final:compile\n[INFO] +- net.jcip:jcip-annotations:jar:1.0:compile\n[INFO] +- org.jgroups:jgroups:jar:3.0.11.Final:compile\n[INFO] +- log4j:log4j:jar:1.2.13:compile\n[INFO] +- org.osgi:org.osgi.core:jar:6.0.0:provided\n[INFO] +- org.rhq.helpers:rhq-pluginAnnotations:jar:3.0.4:compile\n[INFO] +- org.codehaus.woodstox:stax2-api:jar:3.1.1:compile\n[INFO] |  - javax.xml.stream:stax-api:jar:1.0-2:compile\n[INFO] +- org.codehaus.woodstox:woodstox-core-asl:jar:4.4.1:compile\n[INFO] +- com.intellij:annotations:jar:12.0:compile\n[INFO] +- com.itextpdf:itextpdf:pom:5.5.6:compile\n[INFO] +- org.apache.lucene:lucene-core:jar:7.1.0:compile\n[INFO] +- org.apache.lucene:lucene-highlighter:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-analyzers-common:jar:7.1.0:compile\n[INFO] |  - org.apache.lucene:lucene-join:jar:7.1.0:compile\n[INFO] +- org.apache.lucene:lucene-memory:jar:4.10.3:compile\n[INFO] +- org.apache.lucene:lucene-queries:jar:7.1.0:compile\n[INFO] +- org.xerial.snappy:snappy-java:jar:1.1.4:compile\n[INFO] +- net.sf.ezmorph:ezmorph:jar:1.0.6:compile\n[INFO] +- net.sf.json-lib:json-lib:jar:2.3:compile\n[INFO] +- com.googlecode.json-simple:json-simple:jar:1.1.1:compile\n[INFO] |  - junit:junit:jar:4.10:compile\n[INFO] |     - org.hamcrest:hamcrest-core:jar:1.1:compile\n[INFO] +- org.slf4j:slf4j-api:jar:1.5.10:compile\n[INFO] +- org.slf4j:slf4j-log4j12:jar:1.5.10:compile\n[INFO] +- mysql:mysql-connector-java:jar:6.0.6:compile\n[INFO] +- org.apache.tomcat:tomcat-jdbc:jar:8.5.21:compile\n[INFO] |  - org.apache.tomcat:tomcat-juli:jar:8.5.21:compile\n[INFO] +- org.codehaus.jackson:jackson-jaxrs:jar:1.9.12:compile\n[INFO] |  +- org.codehaus.jackson:jackson-core-asl:jar:1.9.12:compile\n[INFO] |  - org.codehaus.jackson:jackson-mapper-asl:jar:1.9.12:compile\n[INFO] +- org.jboss.resteasy:jaxrs-api:jar:3.0.12.Final:compile\n[INFO] +- javax.ws.rs:javax.ws.rs-api:jar:2.1:compile\n[INFO] +- org.jboss.resteasy:resteasy-guice:jar:3.0.9.Final:compile\n[INFO] |  - javax.annotation:jsr250-api:jar:1.0:compile\n[INFO] +- org.jboss.resteasy:resteasy-jackson-provider:jar:3.0.9.Final:compile\n[INFO] +- org.jboss.resteasy:resteasy-jaxrs:jar:3.0.9.Final:compile\n[INFO] |  +- org.jboss.spec.javax.annotation:jboss-annotations-api_1.1_spec:jar:1.0.1.Final:compile\n[INFO] |  - javax.activation:activation:jar:1.1:compile\n[INFO] +- org.jboss.resteasy:resteasy-multipart-provider:jar:3.0.9.Final:compile\n[INFO] |  +- org.jboss.resteasy:resteasy-jaxb-provider:jar:3.0.9.Final:compile\n[INFO] |  |  - com.sun.xml.bind:jaxb-impl:jar:2.2.7:compile\n[INFO] |  |     +- com.sun.xml.bind:jaxb-core:jar:2.2.7:compile\n[INFO] |  |     |  +- javax.xml.bind:jaxb-api:jar:2.2.7:compile\n[INFO] |  |     |  - com.sun.istack:istack-commons-runtime:jar:2.16:compile\n[INFO] |  |     - com.sun.xml.fastinfoset:FastInfoset:jar:1.2.12:compile\n[INFO] |  |        - javax.xml.bind:jsr173_api:jar:1.0:compile\n[INFO] |  +- javax.mail:mail:jar:1.5.0-b01:compile\n[INFO] |  - org.apache.james:apache-mime4j:jar:0.6:compile\n[INFO] +- org.jboss.resteasy:resteasy-spring:jar:3.0.9.Final:compile\n[INFO] +- javax.servlet:jstl:jar:1.2:compile\n[INFO] +- org.apache.commons:commons-lang3:jar:3.6:compile\n[INFO] +- dom4j:dom4j:jar:1.6.1:compile\n[INFO] |  - xml-apis:xml-apis:jar:1.0.b2:compile\n[INFO] +- org.hibernate:hibernate-core:jar:4.3.11.Final:compile\n[INFO] |  +- org.jboss.logging:jboss-logging-annotations:jar:1.2.0.Beta1:compile\n[INFO] |  +- org.jboss.spec.javax.transaction:jboss-transaction-api_1.2_spec:jar:1.0.0.Final:compile\n[INFO] |  +- org.hibernate.common:hibernate-commons-annotations:jar:4.0.5.Final:compile\n[INFO] |  +- org.hibernate.javax.persistence:hibernate-jpa-2.1-api:jar:1.0.0.Final:compile\n[INFO] |  +- org.javassist:javassist:jar:3.18.1-GA:compile\n[INFO] |  +- antlr:antlr:jar:2.7.7:compile\n[INFO] |  - org.jboss:jandex:jar:1.1.0.Final:compile\n[INFO] +- net.sourceforge.stripes:stripes:jar:1.5.7:compile\n[INFO] +- org.apache.openjpa:openjpa:jar:2.4.2:compile\n[INFO] |  +- net.sourceforge.serp:serp:jar:1.15.1:compile\n[INFO] |  +- org.apache.geronimo.specs:geronimo-jta_1.1_spec:jar:1.1.1:compile\n[INFO] |  - org.apache.xbean:xbean-asm5-shaded:jar:3.17:compile\n[INFO] +- org.springframework:spring-orm:jar:4.3.11.RELEASE:compile\n[INFO] |  - org.springframework:spring-jdbc:jar:4.3.11.RELEASE:compile\n[INFO] +- shiro:shiro-all:jar:1.0-incubating-SNAPSHOT:compile\n[INFO] +- org.springframework:spring-web:jar:4.3.11.RELEASE:compile\n[INFO] +- org.apache.sanselan:sanselan:jar:0.97-incubator:compile\n[INFO] +- com.sun.media:jai-codec:jar:1.1.3:compile\n[INFO] |  - javax.media:jai-core:jar:1.1.3:compile\n[INFO] +- com.sun.media:jai_imageio:jar:1.1:compile\n[INFO] +- javax.media:jai_core:jar:1.1.3:compile\n[INFO] +- thirdparty:mediautil:jar:1.0:compile\n[INFO] +- concurrent:concurrent:jar:1.3.4:compile\n[INFO] +- org.mindrot:jbcrypt:jar:0.4:compile\n[INFO] +- org.apache.poi:poi:jar:3.17:compile\n[INFO] |  - org.apache.commons:commons-collections4:jar:4.1:compile\n[INFO] +- net.spy:spymemcached:jar:2.12.3:compile\n[INFO] +- javax.interceptor:javax.interceptor-api:jar:1.2.1:compile\n[INFO] +- com.tinify:tinify:jar:1.5.1:compile\n[INFO] |  - com.squareup.okhttp3:okhttp:jar:3.8.1:compile\n[INFO] |     - com.squareup.okio:okio:jar:1.13.0:compile\n[INFO] +- net.java.dev.jets3t:jets3t:jar:0.9.4:compile\n[INFO] |  +- org.bouncycastle:bcprov-jdk15on:jar:1.52:compile\n[INFO] |  - com.jamesmurty.utils:java-xmlbuilder:jar:1.1:compile\n[INFO] |     - net.iharder:base64:jar:2.3.8:compile\n[INFO] +- org.jsoup:jsoup:jar:1.7.2:compile\n[INFO] +- org.elasticsearch:elasticsearch:jar:6.1.1:compile\n[INFO] |  +- org.apache.lucene:lucene-backward-codecs:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-grouping:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-misc:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-queryparser:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-sandbox:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-spatial:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-spatial-extras:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-spatial3d:jar:7.1.0:compile\n[INFO] |  +- org.apache.lucene:lucene-suggest:jar:7.1.0:compile\n[INFO] |  +- org.elasticsearch:securesm:jar:1.2:compile\n[INFO] |  +- org.elasticsearch:elasticsearch-cli:jar:6.1.1:compile\n[INFO] |  |  - net.sf.jopt-simple:jopt-simple:jar:5.0.2:compile\n[INFO] |  +- com.carrotsearch:hppc:jar:0.7.1:compile\n[INFO] |  +- org.yaml:snakeyaml:jar:1.17:compile\n[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-smile:jar:2.8.10:compile\n[INFO] |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:jar:2.8.10:compile\n[INFO] |  +- com.tdunning:t-digest:jar:3.0:compile\n[INFO] |  +- org.hdrhistogram:HdrHistogram:jar:2.1.9:compile\n[INFO] |  +- org.apache.logging.log4j:log4j-api:jar:2.9.1:compile\n[INFO] |  - org.elasticsearch:jna:jar:4.4.0-1:compile\n[INFO] +- org.elasticsearch.client:transport:jar:6.1.1:compile\n[INFO] |  +- org.elasticsearch.plugin:transport-netty4-client:jar:6.1.1:compile\n[INFO] |  |  +- io.netty:netty-buffer:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-codec:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-codec-http:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-common:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-handler:jar:4.1.13.Final:compile\n[INFO] |  |  +- io.netty:netty-resolver:jar:4.1.13.Final:compile\n[INFO] |  |  - io.netty:netty-transport:jar:4.1.13.Final:compile\n[INFO] |  +- org.elasticsearch.plugin:reindex-client:jar:6.1.1:compile\n[INFO] |  |  - org.elasticsearch.client:elasticsearch-rest-client:jar:6.1.1:compile\n[INFO] |  |     - org.apache.httpcomponents:httpasyncclient:jar:4.1.2:compile\n[INFO] |  +- org.elasticsearch.plugin:lang-mustache-client:jar:6.1.1:compile\n[INFO] |  |  - com.github.spullara.mustache.java:compiler:jar:0.9.3:compile\n[INFO] |  +- org.elasticsearch.plugin:percolator-client:jar:6.1.1:compile\n[INFO] |  - org.elasticsearch.plugin:parent-join-client:jar:6.1.1:compile\n[INFO] +- com.itextpdf:itextpdf:jar:5.2.1:compile\n[INFO] +- com.lowagie:itext:jar:1.4.8:compile\n[INFO] +- org.xhtmlrenderer:core-renderer:jar:R8pre2:compile\n[INFO] +- de.congrace:exp4j:jar:0.3.11:compile\n[INFO] +- com.mchange:c3p0:jar:0.9.5.2:compile\n[INFO] |  - com.mchange:mchange-commons-java:jar:0.2.11:compile\n[INFO] +- thirdparty:lzstring4j:jar:unknown:compile\n[INFO] +- org.codehaus.groovy:groovy-all:jar:2.4.12:compile\n[INFO] +- jfree:jcommon:jar:1.0.16:compile\n[INFO] +- bsh:bsh:jar:1.3.0:compile\n[INFO] +- org.stripesstuff:stripesstuff:jar:0.1:compile\n[INFO] +- org.apache.maven.plugins:maven-resources-plugin:jar:3.0.2:compile\n[INFO] |  +- org.apache.maven:maven-plugin-api:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-artifact:jar:3.0:compile\n[INFO] |  |  - org.sonatype.sisu:sisu-inject-plexus:jar:1.4.2:compile\n[INFO] |  |     - org.sonatype.sisu:sisu-inject-bean:jar:1.4.2:compile\n[INFO] |  |        - org.sonatype.sisu:sisu-guice:jar:noaop:2.1.7:compile\n[INFO] |  +- org.apache.maven:maven-core:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-settings:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-settings-builder:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-repository-metadata:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-model-builder:jar:3.0:compile\n[INFO] |  |  +- org.apache.maven:maven-aether-provider:jar:3.0:runtime\n[INFO] |  |  +- org.sonatype.aether:aether-impl:jar:1.7:compile\n[INFO] |  |  |  - org.sonatype.aether:aether-spi:jar:1.7:compile\n[INFO] |  |  +- org.sonatype.aether:aether-api:jar:1.7:compile\n[INFO] |  |  +- org.sonatype.aether:aether-util:jar:1.7:compile\n[INFO] |  |  +- org.codehaus.plexus:plexus-classworlds:jar:2.2.3:compile\n[INFO] |  |  +- org.codehaus.plexus:plexus-component-annotations:jar:1.5.5:compile\n[INFO] |  |  - org.sonatype.plexus:plexus-sec-dispatcher:jar:1.3:compile\n[INFO] |  |     - org.sonatype.plexus:plexus-cipher:jar:1.4:compile\n[INFO] |  +- org.apache.maven:maven-model:jar:3.0:compile\n[INFO] |  +- org.codehaus.plexus:plexus-utils:jar:3.0.24:compile\n[INFO] |  +- org.apache.maven.shared:maven-filtering:jar:3.1.1:compile\n[INFO] |  |  +- org.apache.maven.shared:maven-shared-utils:jar:3.0.0:compile\n[INFO] |  |  - org.sonatype.plexus:plexus-build-api:jar:0.0.7:compile\n[INFO] |  - org.codehaus.plexus:plexus-interpolation:jar:1.24:compile\n[INFO] +- org.apache.maven.plugins:maven-war-plugin:jar:3.2.0:compile\n[INFO] |  +- org.apache.maven:maven-archiver:jar:3.2.0:compile\n[INFO] |  +- org.codehaus.plexus:plexus-archiver:jar:3.5:compile\n[INFO] |  |  +- org.codehaus.plexus:plexus-io:jar:3.0.0:compile\n[INFO] |  |  +- org.apache.commons:commons-compress:jar:1.14:compile\n[INFO] |  |  +- org.iq80.snappy:snappy:jar:0.4:compile\n[INFO] |  |  - org.tukaani:xz:jar:1.6:runtime\n[INFO] |  - org.apache.maven.shared:maven-mapping:jar:3.0.0:compile\n[INFO] +- org.mongodb:mongo-java-driver:jar:3.3.0:compile\n[INFO] +- org.springframework.data:spring-data-mongodb:jar:1.9.2.RELEASE:compile\n[INFO] |  - org.springframework.data:spring-data-commons:jar:1.12.2.RELEASE:compile\n[INFO] - hk.kinesis.producer:kinesis-config:jar:0.0.1-SNAPSHOT:compile\n[INFO]    +- com.amazonaws:amazon-kinesis-client:jar:1.9.0:compile\n[INFO]    |  - com.google.protobuf:protobuf-java:jar:2.6.1:compile\n[INFO]    - com.amazonaws:amazon-kinesis-producer:jar:0.12.8:compile\n```. not right now it's a legacy project which we are trying to integrate with zuul, should I look at some jersey dependencies as it also has RuntimeDelegate class. @narenchoudhary it works with Spring boot, is there any similar property for eureka-client in non spring boot applications. ",
    "bsushant-athena": "@maliksalman is it possible for you to share repo link? I also need to implement same feature set into our eureka which runs in same zone on aws vpc without ASG/DNS based peerawareness.. @qiangdavidliu what value to provide for eureka.serviceUrl.us-east-1a= ??\nAs private IP's are assigned automatically so we can not hardcode in the code ?\n. we are also facing similar kind of issue where heartbeat fails continuously and not able to re-register itself. We are on dalston sr1 version. @ryanjbaxter \n2018-10-22 10:50:38,335 [] DEBUG [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.provider.DiscoveryJerseyProvider  - Cannot parse request body\ncom.fasterxml.jackson.databind.JsonMappingException: Root name 'timestamp' does not match expected ('instance') for type [simple type, class com.netflix.appinfo.InstanceInfo]\n at [Source: com.sun.jersey.client.apache4.ApacheHttpClient4Handler$HttpClientResponseInputStream@67ad1f4d; line: 1, column: 2]\n    at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)\n    at com.fasterxml.jackson.databind.ObjectReader._unwrapAndDeserialize(ObjectReader.java:1584)\n    at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1508)\n    at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1102)\n    at com.netflix.discovery.converters.EurekaJacksonCodec.readValue(EurekaJacksonCodec.java:178)\n    at org.springframework.cloud.netflix.eureka.server.CloudJacksonJson.decode(CloudJacksonJson.java:67)\n    at com.netflix.discovery.provider.DiscoveryJerseyProvider.readFrom(DiscoveryJerseyProvider.java:103)\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:634)\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586)\n    at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118)\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815)\n    at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\n2018-10-22 10:50:38,340 [] DEBUG [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient  - Jersey HTTP PUT http://eureka0-P2AG-214210.aws.athenahealth.com/eureka//apps/GATEWAY/Gateway:0b238b0461358c296d6dc20096e44810; statusCode=404\n2018-10-22 10:50:38,340 [] ERROR [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient  - Request execution error\njavax.ws.rs.WebApplicationException\n    at com.netflix.discovery.provider.DiscoveryJerseyProvider.readFrom(DiscoveryJerseyProvider.java:110)\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:634)\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586)\n    at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118)\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815)\n    at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748)\n2018-10-22 10:50:38,341 [] WARN  [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient  - Request execution failed with message: null\n2018-10-22 10:50:38,341 [] ERROR [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.DiscoveryClient  - DiscoveryClient_GATEWAY/Gateway:0b238b0461358c296d6dc20096e44810 - was unable to send heartbeat!\ncom.netflix.discovery.shared.transport.TransportException: Retry limit reached; giving up on completing the request\n    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:138)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n    at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815)\n    at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379)\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at java.lang.Thread.run(Thread.java:748). @youtianhong can you please share your eureka config?\n. 2017-10-31 07:22:42.264 DEBUG 1 --- [tbeatExecutor-0] org.apache.http.wire                     :  << \"{\"timestamp\":1509434562261,\"status\":404,\"error\":\"Not Found\",\"message\":\"Not Found\",\"path\":\"//eureka/apps/SIMPLE-JAVA-CLIENT/simple-java-client:8761:0efbd711f98af82c198a1a6156cc1fce\"}\"\n2017-10-31 07:22:42.264 DEBUG 1 --- [tbeatExecutor-0] c.n.d.shared.MonitoredConnectionManager  : Released connection is reusable.\n2017-10-31 07:22:42.264 DEBUG 1 --- [tbeatExecutor-0] c.n.d.shared.NamedConnectionPool         : Releasing connection [{}->http://localhost:18888][null]\n2017-10-31 07:22:42.264 DEBUG 1 --- [tbeatExecutor-0] c.n.d.shared.NamedConnectionPool         : Pooling connection [{}->http://localhost:18888][null]; keep alive indefinitely\n2017-10-31 07:22:42.264 DEBUG 1 --- [tbeatExecutor-0] c.n.d.shared.NamedConnectionPool         : Notifying no-one, there are no waiting threads\n2017-10-31 07:22:42.264 DEBUG 1 --- [tbeatExecutor-0] c.n.d.provider.DiscoveryJerseyProvider   : Cannot parse request body\ncom.fasterxml.jackson.databind.JsonMappingException: Root name 'timestamp' does not match expected ('instance') for type [simple type, class com.netflix.appinfo.InstanceInfo]\n at [Source: com.sun.jersey.client.apache4.ApacheHttpClient4Handler$HttpClientResponseInputStream@561b2cdd; line: 1, column: 2]\n    at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:261) ~[jackson-databind-2.8.3.jar!/:2.8.3]\n    at com.fasterxml.jackson.databind.DeserializationContext.reportMappingException(DeserializationContext.java:1234) ~[jackson-databind-2.8.3.jar!/:2.8.3]\n    at com.fasterxml.jackson.databind.ObjectReader._unwrapAndDeserialize(ObjectReader.java:1690) ~[jackson-databind-2.8.3.jar!/:2.8.3]\n    at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1620) ~[jackson-databind-2.8.3.jar!/:2.8.3]\n    at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1183) ~[jackson-databind-2.8.3.jar!/:2.8.3]\n    at com.netflix.discovery.converters.EurekaJacksonCodec.readValue(EurekaJacksonCodec.java:178) ~[eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.converters.wrappers.CodecWrappers$LegacyJacksonJson.decode(CodecWrappers.java:314) ~[eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.provider.DiscoveryJerseyProvider.readFrom(DiscoveryJerseyProvider.java:103) ~[eureka-client-1.6.2.jar!/:1.6.2]\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:634) [jersey-client-1.19.1.jar!/:1.19.1]\n    at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586) [jersey-client-1.19.1.jar!/:1.19.1]\n    at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815) [eureka-client-1.6.2.jar!/:1.6.2]\n    at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379) [eureka-client-1.6.2.jar!/:1.6.2]\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_141]\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_141]\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_141]\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_141]\n    at java.lang.Thread.run(Thread.java:748) [na:1.8.0_141]\n2017-10-31 07:22:42.265 DEBUG 1 --- [tbeatExecutor-0] n.d.s.t.j.AbstractJerseyEurekaHttpClient : Jersey HTTP PUT http://localhost:18888/public/eureka//apps/SIMPLE-JAVA-CLIENT/simple-java-client:8761:0efbd711f98af82c198a1a6156cc1fce; statusCode=404. @dsyer are you talking about the client or the server side version ? \n. on server side it is not possible to update.\ncurrently server side sprint boot :1.4.3 and cloud is Camden.SR4.\nYes the error is from client. @dsyer I updated the client i.e. spring boot: 1.5.1 and spring cloud: 1.3.5 , but still after 4-5 hours the clients disconnects and in the logs I see same error. \nAlso with that double // it worked for 4-5 hours. . yes, we have a proxy which is the marathon lb.. Thanks @dsyer\nSo the same error occurs on server side as well(which is occurring on client side). But later we changed the eureka server instances from 3 to 1 and now the client is not failing. \nDo you know what can be the possible reasons for this ? Also one more thing we have noticed is that even though now the instances are only 1 , when we see the /eureka/apps/ the eureka server instance gets deregistered immediately . \ne.g. after restarting the server I could see the eureka server registered as \"Gateway\" on /eureka/apps endpoint but after sometime it disappears. \ncan you please provide your thoughts on this as well? Is this something with the instance replicator?. As soon as I start my server I see some connection refused error and then this below one:\n```\n2017-11-13 23:37:56.763  WARN 85576 --- [nfoReplicator-0] c.n.discovery.InstanceInfoReplicator     : There was a problem with the instance info replicator\ncom.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server\n    at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$1.execute(EurekaHttpClientDecorator.java:59) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.register(EurekaHttpClientDecorator.java:56) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at com.netflix.discovery.DiscoveryClient.register(DiscoveryClient.java:815) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at com.netflix.discovery.InstanceInfoReplicator.run(InstanceInfoReplicator.java:104) ~[eureka-client-1.4.12.jar!/:1.4.12]\n    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_111]\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_111]\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_111]\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) [na:1.8.0_111]\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_111]\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_111]\n    at java.lang.Thread.run(Thread.java:745) [na:1.8.0_111]\n```. Ok so we moved to peer awareness mode to solve this problem and also updated to dalston sr1 \n:cheers. After restarting an eureka instance, it fails to re-register and we are again getting similar kind of error. Can somebody look into this?\ndev_gateway_zuul | com.fasterxml.jackson.databind.JsonMappingException: Root name 'timestamp' does not match expected ('instance') for type [simple type, class com.netflix.appinfo.InstanceInfo]\ndev_gateway_zuul |  at [Source: com.sun.jersey.client.apache4.ApacheHttpClient4Handler$HttpClientResponseInputStream@7c628fbd; line: 1, column: 2]\ndev_gateway_zuul |  at com.fasterxml.jackson.databind.JsonMappingException.from(JsonMappingException.java:148)\ndev_gateway_zuul |  at com.fasterxml.jackson.databind.ObjectReader._unwrapAndDeserialize(ObjectReader.java:1584)\ndev_gateway_zuul |  at com.fasterxml.jackson.databind.ObjectReader._bindAndClose(ObjectReader.java:1508)\ndev_gateway_zuul |  at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:1102)\ndev_gateway_zuul |  at com.netflix.discovery.converters.EurekaJacksonCodec.readValue(EurekaJacksonCodec.java:178)\ndev_gateway_zuul |  at org.springframework.cloud.netflix.eureka.server.CloudJacksonJson.decode(CloudJacksonJson.java:67)\ndev_gateway_zuul |  at com.netflix.discovery.provider.DiscoveryJerseyProvider.readFrom(DiscoveryJerseyProvider.java:103)\ndev_gateway_zuul |  at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:634)\ndev_gateway_zuul |  at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815)\ndev_gateway_zuul |  at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379)\ndev_gateway_zuul |  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\ndev_gateway_zuul |  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\ndev_gateway_zuul |  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\ndev_gateway_zuul |  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\ndev_gateway_zuul |  at java.lang.Thread.run(Thread.java:748)\ndev_gateway_zuul | 2018-10-24 01:26:20,196 [] DEBUG [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient  - Jersey HTTP PUT http://zuulgateway:80/eureka//apps/GATEWAY/Gateway:c9c4a1bccab0e51d7d4f7a78e440e0b1; statusCode=404\ndev_gateway_zuul | 2018-10-24 01:26:20,197 [] ERROR [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient  - Request execution error\ndev_gateway_zuul | javax.ws.rs.WebApplicationException\ndev_gateway_zuul |  at com.netflix.discovery.provider.DiscoveryJerseyProvider.readFrom(DiscoveryJerseyProvider.java:110)\ndev_gateway_zuul |  at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:634)\ndev_gateway_zuul |  at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815)\ndev_gateway_zuul |  at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379)\ndev_gateway_zuul |  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\ndev_gateway_zuul |  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\ndev_gateway_zuul |  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\ndev_gateway_zuul |  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\ndev_gateway_zuul |  at java.lang.Thread.run(Thread.java:748)\ndev_gateway_zuul | 2018-10-24 01:26:20,197 [] WARN  [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient  - Request execution failed with message: null\ndev_gateway_zuul | 2018-10-24 01:26:20,197 [] ERROR [DiscoveryClient-HeartbeatExecutor-0]  com.netflix.discovery.DiscoveryClient  - DiscoveryClient_GATEWAY/Gateway:c9c4a1bccab0e51d7d4f7a78e440e0b1 - was unable to send heartbeat!\ndev_gateway_zuul | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\ndev_gateway_zuul |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\ndev_gateway_zuul |  at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:815)\ndev_gateway_zuul |  at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1379)\ndev_gateway_zuul |  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\ndev_gateway_zuul |  at java.util.concurrent.FutureTask.run(FutureTask.java:266)\ndev_gateway_zuul |  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\ndev_gateway_zuul |  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\ndev_gateway_zuul |  at java.lang.Thread.run(Thread.java:748)\ndev_gateway_zuul | 2018-10-24 01:26:20,393 [] DEBUG [PollingServerListUpdater-0]  com.netflix.loadbalancer.DynamicServerListLoadBalancer  - List of Servers for gatewaysupport obtained from Discovery client: [nodegateway:nodegateway:GATEWAYSUPPORT:3000]\ndev_gateway_zuul | 2018-10-24 01:26:20,393 [] DEBUG [PollingServerListUpdater-0]  com.netflix.loadbalancer.ZoneAffinityServerListFilter  - Determining if zone affinity should be enabled with given server list: [nodegateway:nodegateway:GATEWAYSUPPORT:3000]\ndev_gateway_zuul | 2018-10-24 01:26:20,393 [] DEBUG [PollingServerListUpdater-0]  com.netflix.loadbalancer.ZoneAffinityServerListFilter  - zoneAffinity is overriden. blackOutServerPercentage: 0.0, activeReqeustsPerServer: 0.0, availableServers: 1\n@dsyer \nI tried to write a filter where I'll pass empty body response but the filter is not triggering .. We are using spring-cloud dalston sr1 version. I've a jar file but not sure how to share. \nIn my local testing I run the java jar file , once the self registration is done I disconnect the internet for 5 min then brings back the internet but then the renew calls fails.\nBelow is my mvn dependency:tree:::\n[INFO] --- maven-dependency-plugin:2.10:tree (default-cli) @ gateway-run ---\n[INFO] com.abb.platform:gateway-run:jar:0.0.1-SNAPSHOT\n[INFO] +- com.abb.platform:gateway-endpoint:jar:0.0.1-SNAPSHOT:compile\n[INFO] |  +- com.abb.platform:platform-configuration:jar:1.2.0-SNAPSHOT:compile\n[INFO] |  |  +- org.cfg4j:cfg4j-consul:jar:4.4.0:compile\n[INFO] |  |  |  +- com.orbitz.consul:consul-client:jar:0.10.1:compile\n[INFO] |  |  |  |  +- javax.ws.rs:javax.ws.rs-api:jar:2.0.1:compile\n[INFO] |  |  |  |  +- javax.annotation:javax.annotation-api:jar:1.2:compile\n[INFO] |  |  |  |  +- org.immutables:value:jar:2.1.12:compile\n[INFO] |  |  |  |  +- com.fasterxml.jackson.datatype:jackson-datatype-guava:jar:2.6.3:compile\n[INFO] |  |  |  |  +- com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:jar:2.6.3:compile\n[INFO] |  |  |  |  \\- com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:jar:2.6.3:compile\n[INFO] |  |  |  +- org.apache.cxf:cxf-rt-transports-http-hc:jar:3.1.6:compile\n[INFO] |  |  |  |  +- org.apache.cxf:cxf-core:jar:3.1.6:compile\n[INFO] |  |  |  |  |  \\- org.apache.ws.xmlschema:xmlschema-core:jar:2.2.1:compile\n[INFO] |  |  |  |  +- org.apache.cxf:cxf-rt-transports-http:jar:3.1.6:compile\n[INFO] |  |  |  |  +- org.apache.httpcomponents:httpcore-nio:jar:4.4.4:compile\n[INFO] |  |  |  |  \\- org.apache.httpcomponents:httpasyncclient:jar:4.1.1:compile\n[INFO] |  |  |  \\- org.apache.cxf:cxf-rt-rs-client:jar:3.1.6:compile\n[INFO] |  |  |     \\- org.apache.cxf:cxf-rt-frontend-jaxrs:jar:3.1.6:compile\n[INFO] |  |  \\- org.cfg4j:cfg4j-git:jar:4.4.0:compile\n[INFO] |  |     \\- org.eclipse.jgit:org.eclipse.jgit:jar:4.3.0.201604071810-r:compile\n[INFO] |  |        +- com.jcraft:jsch:jar:0.1.53:compile\n[INFO] |  |        \\- com.googlecode.javaewah:JavaEWAH:jar:0.7.9:compile\n[INFO] |  +- com.abb.platform:foundation-services-core:jar:1.0.0-SNAPSHOT:compile\n[INFO] |  |  +- org.bitbucket.b_c:jose4j:jar:0.5.2:compile\n[INFO] |  |  +- com.google.guava:guava:jar:18.0:compile\n[INFO] |  |  +- commons-codec:commons-codec:jar:1.9:compile\n[INFO] |  |  +- com.fasterxml.jackson.core:jackson-core:jar:2.6.6:compile\n[INFO] |  |  \\- com.fasterxml.jackson.core:jackson-annotations:jar:2.6.6:compile\n[INFO] |  +- com.netflix.netflix-commons:netflix-commons-util:jar:0.1.1:compile\n[INFO] |  +- org.springframework.cloud:spring-cloud-starter-eureka-server:jar:1.3.1.RELEASE:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-starter:jar:1.2.2.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.boot:spring-boot-starter:jar:1.5.3.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.cloud:spring-cloud-context:jar:1.2.2.RELEASE:compile\n[INFO] |  |  |  |  \\- org.springframework.security:spring-security-crypto:jar:4.2.2.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.cloud:spring-cloud-commons:jar:1.2.2.RELEASE:compile\n[INFO] |  |  |  \\- org.springframework.security:spring-security-rsa:jar:1.0.3.RELEASE:compile\n[INFO] |  |  |     \\- org.bouncycastle:bcpkix-jdk15on:jar:1.55:compile\n[INFO] |  |  |        \\- org.bouncycastle:bcprov-jdk15on:jar:1.55:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-netflix-eureka-server:jar:1.3.1.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.boot:spring-boot-starter-freemarker:jar:1.5.3.RELEASE:compile\n[INFO] |  |  |  |  +- org.freemarker:freemarker:jar:2.3.26-incubating:compile\n[INFO] |  |  |  |  \\- org.springframework:spring-context-support:jar:4.3.8.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.cloud:spring-cloud-netflix-eureka-client:jar:1.3.1.RELEASE:compile\n[INFO] |  |  |  +- com.netflix.eureka:eureka-client:jar:1.6.2:compile\n[INFO] |  |  |  |  +- org.codehaus.jettison:jettison:jar:1.3.7:runtime\n[INFO] |  |  |  |  |  \\- stax:stax-api:jar:1.0.1:runtime\n[INFO] |  |  |  |  +- com.netflix.netflix-commons:netflix-eventbus:jar:0.3.0:runtime\n[INFO] |  |  |  |  |  +- com.netflix.netflix-commons:netflix-infix:jar:0.3.0:runtime\n[INFO] |  |  |  |  |  |  +- commons-jxpath:commons-jxpath:jar:1.3:runtime\n[INFO] |  |  |  |  |  |  \\- org.antlr:antlr-runtime:jar:3.4:runtime\n[INFO] |  |  |  |  |  |     +- org.antlr:stringtemplate:jar:3.2.1:runtime\n[INFO] |  |  |  |  |  |     \\- antlr:antlr:jar:2.7.7:runtime\n[INFO] |  |  |  |  |  \\- org.apache.commons:commons-math:jar:2.2:runtime\n[INFO] |  |  |  |  +- com.sun.jersey:jersey-client:jar:1.19.1:runtime\n[INFO] |  |  |  |  +- com.sun.jersey.contribs:jersey-apache-client4:jar:1.19.1:runtime\n[INFO] |  |  |  |  \\- com.google.inject:guice:jar:4.1.0:runtime\n[INFO] |  |  |  |     \\- aopalliance:aopalliance:jar:1.0:runtime\n[INFO] |  |  |  +- com.netflix.eureka:eureka-core:jar:1.6.2:compile\n[INFO] |  |  |  |  \\- org.codehaus.woodstox:woodstox-core-asl:jar:4.4.1:compile\n[INFO] |  |  |  |     \\- javax.xml.stream:stax-api:jar:1.0-2:compile\n[INFO] |  |  |  +- com.netflix.archaius:archaius-core:jar:0.7.4:compile\n[INFO] |  |  |  |  \\- com.google.code.findbugs:jsr305:jar:3.0.1:runtime\n[INFO] |  |  |  +- javax.inject:javax.inject:jar:1:compile\n[INFO] |  |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-xml:jar:2.8.8:compile\n[INFO] |  |  |  |  +- com.fasterxml.jackson.module:jackson-module-jaxb-annotations:jar:2.8.8:compile\n[INFO] |  |  |  |  +- org.codehaus.woodstox:stax2-api:jar:3.1.4:compile\n[INFO] |  |  |  |  \\- com.fasterxml.woodstox:woodstox-core:jar:5.0.3:compile\n[INFO] |  |  |  \\- com.thoughtworks.xstream:xstream:jar:1.4.9:compile\n[INFO] |  |  |     +- xmlpull:xmlpull:jar:1.1.3.1:compile\n[INFO] |  |  |     \\- xpp3:xpp3_min:jar:1.1.4c:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-starter-archaius:jar:1.3.1.RELEASE:compile\n[INFO] |  |  |  \\- commons-configuration:commons-configuration:jar:1.8:compile\n[INFO] |  |  |     \\- commons-lang:commons-lang:jar:2.6:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-starter-ribbon:jar:1.3.1.RELEASE:compile\n[INFO] |  |  |  +- com.netflix.ribbon:ribbon:jar:2.2.2:compile\n[INFO] |  |  |  |  +- com.netflix.ribbon:ribbon-transport:jar:2.2.2:runtime\n[INFO] |  |  |  |  |  +- io.reactivex:rxnetty-contexts:jar:0.4.9:runtime\n[INFO] |  |  |  |  |  \\- io.reactivex:rxnetty-servo:jar:0.4.9:runtime\n[INFO] |  |  |  |  \\- io.reactivex:rxnetty:jar:0.4.9:runtime\n[INFO] |  |  |  |     +- io.netty:netty-codec-http:jar:4.0.27.Final:runtime\n[INFO] |  |  |  |     |  +- io.netty:netty-codec:jar:4.0.27.Final:runtime\n[INFO] |  |  |  |     |  \\- io.netty:netty-handler:jar:4.0.27.Final:runtime\n[INFO] |  |  |  |     \\- io.netty:netty-transport-native-epoll:jar:4.0.27.Final:runtime\n[INFO] |  |  |  |        +- io.netty:netty-common:jar:4.0.27.Final:runtime\n[INFO] |  |  |  |        +- io.netty:netty-buffer:jar:4.0.27.Final:runtime\n[INFO] |  |  |  |        \\- io.netty:netty-transport:jar:4.0.27.Final:runtime\n[INFO] |  |  |  +- com.netflix.ribbon:ribbon-core:jar:2.2.2:compile\n[INFO] |  |  |  +- com.netflix.ribbon:ribbon-httpclient:jar:2.2.2:compile\n[INFO] |  |  |  |  \\- commons-collections:commons-collections:jar:3.2.1:runtime\n[INFO] |  |  |  +- com.netflix.ribbon:ribbon-loadbalancer:jar:2.2.2:compile\n[INFO] |  |  |  |  \\- com.netflix.netflix-commons:netflix-statistics:jar:0.1.1:runtime\n[INFO] |  |  |  \\- io.reactivex:rxjava:jar:1.1.10:compile\n[INFO] |  |  \\- com.netflix.ribbon:ribbon-eureka:jar:2.2.2:compile\n[INFO] |  +- org.springframework.cloud:spring-cloud-starter-zuul:jar:1.3.1.RELEASE:compile\n[INFO] |  |  +- org.springframework.boot:spring-boot-starter-web:jar:1.5.3.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.boot:spring-boot-starter-tomcat:jar:1.5.3.RELEASE:compile\n[INFO] |  |  |  |  +- org.apache.tomcat.embed:tomcat-embed-core:jar:8.5.14:compile\n[INFO] |  |  |  |  +- org.apache.tomcat.embed:tomcat-embed-el:jar:8.5.14:compile\n[INFO] |  |  |  |  \\- org.apache.tomcat.embed:tomcat-embed-websocket:jar:8.5.14:compile\n[INFO] |  |  |  +- org.hibernate:hibernate-validator:jar:5.3.5.Final:compile\n[INFO] |  |  |  |  +- javax.validation:validation-api:jar:1.1.0.Final:compile\n[INFO] |  |  |  |  \\- org.jboss.logging:jboss-logging:jar:3.3.0.Final:compile\n[INFO] |  |  |  \\- org.springframework:spring-webmvc:jar:4.3.8.RELEASE:compile\n[INFO] |  |  +- org.springframework.boot:spring-boot-starter-actuator:jar:1.5.3.RELEASE:compile\n[INFO] |  |  |  \\- org.springframework.boot:spring-boot-actuator:jar:1.5.3.RELEASE:compile\n[INFO] |  |  \\- com.netflix.zuul:zuul-core:jar:1.3.0:compile\n[INFO] |  |     \\- com.netflix.servo:servo-core:jar:0.7.2:compile\n[INFO] |  +- org.springframework.boot:spring-boot-starter-log4j2:jar:1.5.9.RELEASE:compile\n[INFO] |  |  +- org.apache.logging.log4j:log4j-slf4j-impl:jar:2.7:compile\n[INFO] |  |  +- org.apache.logging.log4j:log4j-api:jar:2.7:compile\n[INFO] |  |  \\- org.apache.logging.log4j:log4j-core:jar:2.7:compile\n[INFO] |  +- org.springframework.cloud:spring-cloud-starter-hystrix-dashboard:jar:1.3.1.RELEASE:compile\n[INFO] |  |  \\- org.springframework.cloud:spring-cloud-netflix-hystrix-dashboard:jar:1.3.1.RELEASE:compile\n[INFO] |  |     +- org.webjars:jquery:jar:2.1.1:compile\n[INFO] |  |     \\- org.webjars:d3js:jar:3.4.11:compile\n[INFO] |  +- org.springframework.cloud:spring-cloud-starter-hystrix:jar:1.3.1.RELEASE:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-netflix-core:jar:1.3.1.RELEASE:compile\n[INFO] |  |  |  +- org.springframework.boot:spring-boot:jar:1.5.3.RELEASE:compile\n[INFO] |  |  |  \\- org.springframework.boot:spring-boot-autoconfigure:jar:1.5.3.RELEASE:compile\n[INFO] |  |  +- com.netflix.hystrix:hystrix-core:jar:1.5.12:compile\n[INFO] |  |  |  \\- org.hdrhistogram:HdrHistogram:jar:2.1.9:compile\n[INFO] |  |  +- com.netflix.hystrix:hystrix-metrics-event-stream:jar:1.5.12:compile\n[INFO] |  |  |  \\- com.netflix.hystrix:hystrix-serialization:jar:1.5.12:runtime\n[INFO] |  |  |     \\- com.fasterxml.jackson.module:jackson-module-afterburner:jar:2.7.5:runtime\n[INFO] |  |  \\- com.netflix.hystrix:hystrix-javanica:jar:1.5.12:compile\n[INFO] |  |     \\- org.ow2.asm:asm:jar:5.0.4:runtime\n[INFO] |  +- org.springframework.cloud:spring-cloud-starter-turbine:jar:1.3.1.RELEASE:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-starter-eureka:jar:1.3.1.RELEASE:compile\n[INFO] |  |  +- org.springframework.cloud:spring-cloud-netflix-turbine:jar:1.3.1.RELEASE:compile\n[INFO] |  |  \\- com.netflix.turbine:turbine-core:jar:1.0.0:compile\n[INFO] |  |     +- org.codehaus.jackson:jackson-mapper-asl:jar:1.9.2:compile\n[INFO] |  |     \\- org.codehaus.jackson:jackson-core-asl:jar:1.9.2:compile\n[INFO] |  +- de.ahus1.prometheus.hystrix:prometheus-hystrix:jar:3.4.0:compile\n[INFO] |  +- io.springfox:springfox-swagger2:jar:2.5.0:compile\n[INFO] |  |  +- io.swagger:swagger-annotations:jar:1.5.9:compile\n[INFO] |  |  +- io.swagger:swagger-models:jar:1.5.9:compile\n[INFO] |  |  +- io.springfox:springfox-spi:jar:2.5.0:compile\n[INFO] |  |  |  \\- io.springfox:springfox-core:jar:2.5.0:compile\n[INFO] |  |  +- io.springfox:springfox-schema:jar:2.5.0:compile\n[INFO] |  |  +- io.springfox:springfox-spring-web:jar:2.5.0:compile\n[INFO] |  |  +- com.fasterxml:classmate:jar:1.3.1:compile\n[INFO] |  |  +- org.springframework.plugin:spring-plugin-core:jar:1.2.0.RELEASE:compile\n[INFO] |  |  +- org.springframework.plugin:spring-plugin-metadata:jar:1.2.0.RELEASE:compile\n[INFO] |  |  \\- org.mapstruct:mapstruct:jar:1.0.0.Final:compile\n[INFO] |  \\- io.springfox:springfox-swagger-ui:jar:2.5.0:compile\n[INFO] +- com.abb.platform:messaging-runtime-swagger:jar:1.0.0-SNAPSHOT:compile\n[INFO] |  +- org.cfg4j:cfg4j-core:jar:4.4.0:compile\n[INFO] |  |  +- org.json:json:jar:20160212:compile\n[INFO] |  |  +- io.dropwizard.metrics:metrics-core:jar:3.1.2:compile\n[INFO] |  |  +- com.github.drapostolos:type-parser:jar:0.5.0:compile\n[INFO] |  |  \\- org.yaml:snakeyaml:jar:1.17:compile\n[INFO] |  +- org.springframework:spring-web:jar:4.3.8.RELEASE:compile\n[INFO] |  |  +- org.springframework:spring-aop:jar:4.3.8.RELEASE:compile\n[INFO] |  |  +- org.springframework:spring-beans:jar:4.3.8.RELEASE:compile\n[INFO] |  |  \\- org.springframework:spring-context:jar:4.3.8.RELEASE:compile\n[INFO] |  |     \\- org.springframework:spring-expression:jar:4.3.8.RELEASE:compile\n[INFO] |  \\- commons-io:commons-io:jar:2.2:compile\n[INFO] +- com.sun.jersey:jersey-servlet:jar:1.11:compile\n[INFO] +- com.sun.jersey:jersey-server:jar:1.11:compile\n[INFO] |  +- asm:asm:jar:3.1:compile\n[INFO] |  \\- com.sun.jersey:jersey-core:jar:1.11:compile\n[INFO] +- org.mockito:mockito-core:jar:1.10.19:test\n[INFO] |  \\- org.objenesis:objenesis:jar:2.1:test\n[INFO] +- org.hamcrest:hamcrest-core:jar:1.3:test\n[INFO] +- org.hamcrest:hamcrest-library:jar:1.3:test\n[INFO] +- org.springframework:spring-test:jar:4.3.8.RELEASE:test\n[INFO] |  \\- org.springframework:spring-core:jar:4.3.8.RELEASE:compile\n[INFO] |     \\- commons-logging:commons-logging:jar:1.2:compile\n[INFO] +- org.powermock:powermock-module-junit4:jar:1.6.5:test\n[INFO] |  \\- org.powermock:powermock-module-junit4-common:jar:1.6.5:test\n[INFO] |     +- org.powermock:powermock-core:jar:1.6.5:test\n[INFO] |     |  \\- org.javassist:javassist:jar:3.20.0-GA:test\n[INFO] |     \\- org.powermock:powermock-reflect:jar:1.6.5:test\n[INFO] +- org.powermock:powermock-api-mockito:jar:1.6.5:test\n[INFO] |  \\- org.powermock:powermock-api-mockito-common:jar:1.6.5:test\n[INFO] |     \\- org.powermock:powermock-api-support:jar:1.6.5:test\n[INFO] +- junit:junit:jar:4.12:test\n[INFO] +- io.prometheus:simpleclient_spring_boot:jar:0.2.0:compile\n[INFO] |  +- io.prometheus:simpleclient:jar:0.2.0:compile\n[INFO] |  +- io.prometheus:simpleclient_common:jar:0.2.0:compile\n[INFO] |  +- io.prometheus:simpleclient_spring_web:jar:0.2.0:compile\n[INFO] |  |  \\- org.aspectj:aspectjweaver:jar:1.8.6:compile\n[INFO] |  \\- org.apache.commons:commons-lang3:jar:3.4:compile\n[INFO] +- io.prometheus:simpleclient_hotspot:jar:0.2.0:compile\n[INFO] +- io.prometheus:simpleclient_servlet:jar:0.2.0:compile\n[INFO] +- org.slf4j:slf4j-jdk14:jar:1.7.5:compile\n[INFO] +- org.springframework.boot:spring-boot-starter-log4j:jar:1.3.8.RELEASE:compile\n[INFO] |  +- org.slf4j:jul-to-slf4j:jar:1.7.21:compile\n[INFO] |  +- org.slf4j:slf4j-log4j12:jar:1.7.5:compile\n[INFO] |  \\- log4j:log4j:jar:1.2.17:compile\n[INFO] +- com.google.code.gson:gson:jar:2.8.5:compile\n[INFO] +- com.amazonaws:aws-java-sdk-s3:jar:1.11.370:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-kms:jar:1.11.370:compile\n[INFO] |  +- com.amazonaws:aws-java-sdk-core:jar:1.11.370:compile\n[INFO] |  |  +- org.apache.httpcomponents:httpclient:jar:4.5.5:compile\n[INFO] |  |  |  \\- org.apache.httpcomponents:httpcore:jar:4.4.9:compile\n[INFO] |  |  +- software.amazon.ion:ion-java:jar:1.0.2:compile\n[INFO] |  |  +- com.fasterxml.jackson.core:jackson-databind:jar:2.6.6:compile\n[INFO] |  |  +- com.fasterxml.jackson.dataformat:jackson-dataformat-cbor:jar:2.6.7:compile\n[INFO] |  |  \\- joda-time:joda-time:jar:2.8.1:compile\n[INFO] |  \\- com.amazonaws:jmespath-java:jar:1.11.370:compile\n[INFO] +- com.amazonaws:aws-java-sdk-sts:jar:1.11.370:compile\n[INFO] +- org.slf4j:slf4j-api:jar:1.7.5:compile\n[INFO] +- org.slf4j:jcl-over-slf4j:jar:1.7.5:compile\n[INFO] +- log4j:apache-log4j-extras:jar:1.2.17:compile\n[INFO] +- javax.ws.rs:jsr311-api:jar:1.1.1:provided\n[INFO] \\- org.projectlombok:lombok:jar:1.16.10:compile\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 8.168 s\n[INFO] Finished at: 2018-10-26T06:36:01+05:30\n[INFO] Final Memory: 33M/345M\n[INFO]  . after adding static zuul routes, this issue is fixed. :cheers . Apart from the below mentioned way is there any other way to achive the same?\nhttps://github.com/Netflix/eureka/wiki/Deploying-Eureka-Servers-in-EC2#configuring-eips-using-dns. currently using below config it works but not flexible enough!!\n```\neureka:\n  datacenter: cloud\n  name: eureka\n  server:\n    port: 8093\n    preferSameZone: false\n    enable-self-preservation: false\n  instance:\n    preferIpAddress: true\n    instanceId: ${spring.application.name}-${HOST}-${PORT0}\n    metadataMap:\n      instanceId: ${spring.application.name}-${HOST}-${PORT0}\n      dockerImage: \"gateway\"\n      enableRegisterFilter: \"false\"\n  client:\n    registerWithEureka: true\n    region: us-east-1\n    fetchRegistry: true\n    availabilityZones:\n      us-east-1: us-east-1a\n    serviceUrl:\n      defaultZone: http://ec2-18-200-134-44.compute-1.amazonaws.com/eureka/\n      us-east-1a: http://ec2-18-200-134-44.compute-1.amazonaws.com/eureka/\nzuul:\n  host:\n    connect-timeout-millis: 10000\n    socket-timeout-millis: 60000\n  server:\n    port: 8093\n  eureka:\n    datacenter: cloud\n    #hostname: localhost\n    instance:\n      preferIpAddress: true\n      metadataMap:\n        instanceId: ${spring.application.name}-${HOST}-${PORT0}\n    client:\n      registerWithEureka: true\n      region: us-east-1\n      availabilityZones:\n        us-east-1: us-east-1a\n      serviceUrl:\n        defaultZone: http://ec2-18-200-134-44.compute-1.amazonaws.com/eureka/\n        us-east-1a: http://ec2-18-200-134-44.compute-1.amazonaws.com/eureka/\n  sensitiveHeaders:\n  routes:\n    iam:\n      path: /iam/**\n      url: http://iams_auth:20020\nserver:\n  port: 8093\n.\neureka:\n  datacenter: cloud\n  name: eureka\n  #https://github.com/spring-cloud/spring-cloud-netflix/issues/1816\n  #asgName: EurekaEIPASG\n  server:\n    port: 8093\n    preferSameZone: false\n    enable-self-preservation: false\n  instance:\n    hostname: localhost\n    preferIpAddress: true\n    instanceId: ${spring.application.name}-${HOST}-${PORT0}\n    metadataMap:\n      instanceId: ${spring.application.name}-${HOST}-${PORT0}\n      dockerImage: \"gateway\"\n      enableRegisterFilter: \"false\"\n  client:\n    registerWithEureka: true\n    #This must be true for DNS based configuration\n    useDnsForFetchingServiceUrls: true\n    #This is the suffix added to the DNS requests, so must match the records you create\n    eurekaServerDNSName: eurekagw.aws.abc.com\n    #This is the url added to the servers returned from DNS. e.g. eurekagw.aws.abc.com will become  http://eurekagw.aws.athenahealth.com/eureka\n    eurekaServerURLContext: eureka\n    region: us-east-1\n    fetchRegistry: true\nzuul:\n  host:\n    connect-timeout-millis: 10000\n    socket-timeout-millis: 60000\n  server:\n    port: 8093\n  eureka:\n    datacenter: cloud\n    hostname: localhost\n    instance:\n      preferIpAddress: true\n      metadataMap:\n        instanceId: ${spring.application.name}-${HOST}-${PORT0}\n    client:\n      registerWithEureka: true\n      #For DNS based matching\n      useDnsForFetchingServiceUrls: true\n      eurekaServerDNSName: eurekagw.aws.abc.com\n      eurekaServerURLContext: eureka\n      region: us-east-1\n  sensitiveHeaders:\n  routes:\n    iam:\n      path: /iam/**\n      url: http://iams_auth:20020\nserver:\n  port: 8093\n```\nWith this config I get following error\n2018-08-19 15:30:29,826 [] DEBUG [main]  org.springframework.beans.factory.support.DefaultListableBeanFactory  - Eagerly caching bean 'zuul-org.springframework.cloud.netflix.zuul.filters.ZuulProperties' to allow for resolving potential circular references\n2018-08-19 15:30:29,830 [] ERROR [main]  org.springframework.boot.SpringApplication  - Error handling failed\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.cloud.netflix.zuul.ZuulProxyConfiguration': Initialization of bean failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'zuul-org.springframework.cloud.netflix.zuul.filters.ZuulProperties': Initialization of bean failed; nested exception is java.lang.IllegalStateException: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@229d10bd has not been refreshed yet\nI'm creating txt records in aws route53 for txt.us-east-1a.eurekagw.aws.abc.com. the  approach of hardcoding the EIP works fine now, so closing it.. ",
    "drax68": "@qiangdavidliu Correction, we currently use 1.1.151 version\n. Please advise, which version (1.2, 1.3) should we use to fix mentioned issue.\n. @qiangdavidliu we have reproducible test case, where changes in eureka cluster contents (addition/removal of eureka servers to/from txt dns records) causes loss of overriden data in registry on all eureka servers (overriden statuses, custom metadata). Is this something known, or will require separate issue to investigate?\n. Re-tested that case, it's reproducible:\nEureka server configuration\neureka.appinfo.replicate.interval = 15\neureka.client.refresh.interval = 15\neureka.client.registerWithEureka = true\neureka.datacenter = cloud\neureka.environment = env\neureka.eurekaServer.context = eureka/v2\neureka.eurekaServer.domainName = eureka.env.example.com\neureka.eurekaServer.port = 8010\neureka.lease.duration = 45\neureka.lease.renewalInterval = 15\neureka.name = eureka\neureka.peerEurekaStatusRefreshTimeIntervalMs = 15000\neureka.port = 8010\neureka.preferSameZone = false\neureka.region = us-west-1\neureka.remoteRegion.registryFetchIntervalInSeconds = 15\neureka.serviceEnabled = true\neureka.serviceUrl.us-west-1a = {{us-west-1a-eureka-instance}}/eureka/v2/\neureka.serviceUrl.us-west-1c = {{us-west-1c-eureka-instance}}/eureka/v2/\neureka.shouldUseDns = true\neureka.statusPageUrlPath = /eureka/status\neureka.us-west-1.availabilityZones = us-west-1a,us-west-1c\neureka.vipAddress = eureka.example.com\nEureka dns name txt.us-west-1.eureka.env.example.com resolves to TXT record\n\"txt.us-west-1a.eureka.env.example.com\" \"txt.us-west-1c.eureka.env.example.com\"\ntxt.us-west-1a.eureka.env.example.com resolves to\n\"elb1\"\ntxt.us-west-1c.eureka.env.example.com resolves to\n\"elb2\"\nTest case is:\n1. Deploy new pair of eureka instances behind individual elb\n2. Wait for initial sync (let's say existing eureka instances has STARTING_17_UP_122_ and newly-created UP_118_)\n3. Append new instances to az-specific txt records:\ntxt.us-west-1a.eureka.env.example.com resolves to\n\"elb1\" \"elb3\"\ntxt.us-west-1c.eureka.env.example.com resolves to\n\"elb2\" \"elb4\"\n4. Logs contains:\nUpdating the serviceUrls as they seem to have changed from [elb1, elb2] to [elb1, elb2, elb3, elb4] \nUpdating the replica nodes as they seem to have changed from [elb1, elb2] to [elb1, elb2, elb3, elb4]\nAnd after that many service entries expiring with:\nDS: Registry: expired lease for SERVICENAME - i-foobar\nNot all services expiring at that moment, only about 30% of registered services.\nOther services registry data remain unchanged, and all overrides migrated to a new nodes.\nAs I understand, service completely de-registered on expiration.\nWhat can be the source of this massive expiration on cluster contents changes?\n. Thank you, @qiangdavidliu \nThat sequence helped with unexpected registry data expiration.\n. ",
    "hw1995": "i don't know english. ",
    "kennedyoliveira": "Thank you everyone for the feedback, i'll wait a solution for #756, and while it doesn't ready i'm gonna try spring cloud netflix.\n. Hello! Any news on this topic?\n. I would love to, but don't know how can i make it, if you give me some hints, i don't understand the eureka server, well didn't looked at the source through.\nAnyway, i'll try, but would be very helpful if you could give me some advices.\nThank you!\n. Hey @tbak, thank you, i'll sure check your implementation and maybe try to create my own.\nQuick question, i noticed when i start the injector the eureka-client begins the initialisation, there is a way to delay it till i call something to start it?\n. @tbak, got it, thank you for clarifying my doubts!\n. @tbak, thank you very much! I know it's not safe, but i was planing to use with SSL as @spencergibb, there is any alternative to this method for eureka?\n. @tbak, sounds interesting, how is that?\n. @tbak, hmm i will search about that, i don't know much about SSL, just the basic, anyway, thank you for fixing it! If you have any source of documentation/books/ anything about this case and could tell me, i appreciate :D\n. ",
    "YangGuang001": "i use jks credential, i create it on jvm (build 1.8.0_151-b12),  in the server i use server.keystore,  in the client i use server.cer.\nbut error message:\nCaused by: java.io.IOException: Invalid keystore format\n    at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java:658) ~[na:1.8.0_111]\n    at sun.security.provider.JavaKeyStore$JKS.engineLoad(JavaKeyStore.java:56) ~[na:1.8.0_111]\n    at sun.security.provider.KeyStoreDelegator.engineLoad(KeyStoreDelegator.java:224) ~[na:1.8.0_111]\n    at sun.security.provider.JavaKeyStore$DualFormatJKS.engineLoad(JavaKeyStore.java:70) ~[na:1.8.0_111]\nserver.keystore:\nkeytool -validity 365 -genkey -v -alias server -keyalg RSA -keystore server.keystore -dname \"CN=127.0.0.1,OU=icesoft,O=icesoft,L=Haidian,ST=Beijing,c=cn\" -storepass 123456 -keypass 123456 \nserver.cer:\nkeytool -export -v -alias server -keystore server.keystore -storepass 123456 -rfc -file server.cer\njava\n@Configuration\npublic class EurekaJerseyClientAdapter\n{\n    @Bean\n    public EurekaJerseyClient eurekaJerseyClient()\n    {\n        EurekaJerseyClientImpl.EurekaJerseyClientBuilder builder = new\n                EurekaJerseyClientImpl.EurekaJerseyClientBuilder()\n                .withTrustStoreFile(\"server.cer\",\"123456\");\n        return builder.build();\n    }\n}. Invalid Keystore format\ni use jks, . ",
    "twicksell": "Looks good\n. lgtm \n. lgtm\n. :thumbsup:\n. :thumbsup:\n. Should consider making this true by default. \n. If eureka-client depends directly on archaius-core, then this exclude will not prevent them from getting it. Excludes are not transitive, so while archaius1 may not appear in this project, it will be present for everyone who depends on it. We may need to consider refactoring eureka-client to shift this dependency to another place.\n. What will be the replacement for this?\n. If we need to do this, I feel like we can at least do this somewhere else. A binding for something like DiscoveryManagerInitializer with dependencies on these Config classes might work.\n. Don't see a lot of differences between this and Ec2EurekaClientModule. Should one install the other, or have some kind of inheritance to avoid the duplicate code?\n. Some known issues in 2.1.4. Best to wait for a patch release or go back to 2.0.6\n. Pretty difficult to distinguish this module from the other. Slightly different names, same packages. Bound to confuse someone.\n. ",
    "lenadroid": "@qiangdavidliu yeah, from the same. \n. ",
    "SphereUser": "eureka is pretty unstable and avoid to use it in serious applications.\n. ",
    "andreldm": "I was trying to limit the number of instance to only one at a time. Now I'm convinced this defeats the whole point of service discovery, so Eureka should not be ideal to my case.\n. ",
    "hieurl": "Quick check using python awscli\n\naws ec2 describe-addresses --public-ips | jq '.Addresses[0]'\n{\n  \"InstanceId\": \"i-xxxxx\",\n  \"PublicIp\": \"xxx.xxx.xxx.xxx\",\n  \"Domain\": \"standard\"\n}\n. @qiangdavidliu seem reasonable to me. I'm going to push a commit.\n. \n",
    "fangzhining": "I hava done what you said ,but it does not work.\nThe Error log almost is the same.It can only find one txtRecord.\n2016-04-18 20:33:20,733 INFO  com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver:40 [localhost-startStop-1] [getClusterEndpoints] Resolving eureka endpoints via DNS\nThe txtRecord is : us-east-1d.bar.skydns.paas\nThe cnamesString is : [us-east-1d.bar.skydns.paas]\nThe rootClusterDNS is : txt.us-east-1.bar.skydns.paas\nThe zoneDomain is : us-east-1d.bar.skydns.paas\nThe txtRecord is : http://10.120.180.117:8080/eureka/v2/\nThe cnamesString is : [http://10.120.180.117:8080/eureka/v2/]\nThe txtRecord is : http://10.120.180.117:8080/eureka/v2/\nThe cnamesString is : [http://10.120.180.117:8080/eureka/v2/]\nThe zoneAddresses is : http://10.120.180.117:8080/eureka/v2/\n2016-04-18 20:33:20,807 INFO  com.netflix.discovery.DiscoveryClient:920 [localhost-startStop-1] [fetchRegistry] Disable delta property : false\n2016-04-18 20:33:20,807 INFO  com.netflix.discovery.DiscoveryClient:921 [localhost-startStop-1] [fetchRegistry] Single vip registry refresh property : null\n2016-04-18 20:33:20,807 INFO  com.netflix.discovery.DiscoveryClient:922 [localhost-startStop-1] [fetchRegistry] Force full registry fetch : false\n2016-04-18 20:33:20,807 INFO  com.netflix.discovery.DiscoveryClient:923 [localhost-startStop-1] [fetchRegistry] Application is null : false\n2016-04-18 20:33:20,807 INFO  com.netflix.discovery.DiscoveryClient:924 [localhost-startStop-1] [fetchRegistry] Registered Applications size is zero : true\n2016-04-18 20:33:20,808 INFO  com.netflix.discovery.DiscoveryClient:926 [localhost-startStop-1] [fetchRegistry] Application version is -1: true\n2016-04-18 20:33:20,808 INFO  com.netflix.discovery.DiscoveryClient:1009 [localhost-startStop-1] [getAndStoreFullRegistry] Getting all instance registry info from the eureka server\n2016-04-18 20:33:20,899 ERROR com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient:83 [localhost-startStop-1] [execute] Request execution error\ncom.sun.jersey.api.client.ClientHandlerException: java.net.UnknownHostException: http: unknown error\n        at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:187)\n        at com.sun.jersey.api.client.filter.GZIPContentEncodingFilter.handle(GZIPContentEncodingFilter.java:123)\n        at com.netflix.discovery.EurekaIdentityHeaderFilter.handle(EurekaIdentityHeaderFilter.java:27)\n        at com.sun.jersey.api.client.Client.handle(Client.java:652)\n        at com.sun.jersey.api.client.WebResource.handle(WebResource.java:682)\n        at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)\n        at com.sun.jersey.api.client.WebResource$Builder.get(WebResource.java:509)\n        at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.getApplicationsInternal(AbstractJerseyEurekaHttpClient.java:194)\n        at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.getApplications(AbstractJerseyEurekaHttpClient.java:165)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)\n        at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)\n        at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118)\n        at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)\n        at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)\n        at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)\n        at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1013)\n        at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:927)\n        at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:441)\n        at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:304)\n        at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:300)\n        at com.netflix.eureka.EurekaBootStrap.initEurekaServerContext(EurekaBootStrap.java:147)\n        at com.netflix.eureka.EurekaBootStrap.contextInitialized(EurekaBootStrap.java:96)\n        at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4812)\n        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5255)\n        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:147)\n        at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:725)\n        at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:701)\n        at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:717)\n        at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:939)\n        at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1812)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\nCaused by: java.net.UnknownHostException: http: unknown error\n        at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)\n        at java.net.InetAddress$2.lookupAllHostAddr(InetAddress.java:928)\n        at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1323)\n        at java.net.InetAddress.getAllByName0(InetAddress.java:1276)\n        at java.net.InetAddress.getAllByName(InetAddress.java:1192)\n        at java.net.InetAddress.getAllByName(InetAddress.java:1126)\n        at org.apache.http.impl.conn.SystemDefaultDnsResolver.resolve(SystemDefaultDnsResolver.java:44)\n at org.apache.http.impl.conn.DefaultClientConnectionOperator.resolveHostname(DefaultClientConnectionOperator.java:259)\n        at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:159)\n        at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:144)\n        at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:131)\n        at org.apache.http.impl.client.DefaultRequestDirector.tryConnect(DefaultRequestDirector.java:611)\n        at org.apache.http.impl.client.DefaultRequestDirector.execute(DefaultRequestDirector.java:446)\n        at org.apache.http.impl.client.AbstractHttpClient.doExecute(AbstractHttpClient.java:863)\n        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:115)\n        at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:57)\n        at com.sun.jersey.client.apache4.ApacheHttpClient4Handler.handle(ApacheHttpClient4Handler.java:173)\n        ... 41 more\n2016-04-18 20:33:20,902 WARN  com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient:129 [localhost-startStop-1] [execute] Request execution failure\n2016-04-18 20:33:20,903 ERROR com.netflix.discovery.DiscoveryClient:934 [localhost-startStop-1] [fetchRegistry] DiscoveryClient_EUREKA/SZV1000048538 - was unable to refresh its cache! status = Cannot execute request on any known server\ncom.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server\n        at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137)\n        at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134)\n        at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1013)\n        at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:927)\n        at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:441)\n        at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:304)\n        at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:300)\n        at com.netflix.eureka.EurekaBootStrap.initEurekaServerContext(EurekaBootStrap.java:147)\n        at com.netflix.eureka.EurekaBootStrap.contextInitialized(EurekaBootStrap.java:96)\n        at org.apache.catalina.core.StandardContext.listenerStart(StandardContext.java:4812)\n        at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:5255)\n        at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:147)\n        at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:725)\n        at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:701)\n        at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:717)\n        at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:939)\n        at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:1812)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n. @qiangdavidliu ,thank you for you solution,but i hava done this too,the following are my attempts;\nThe first trying:\nThe metadata in DNS:\ndig txt.us-east-1.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1.bar.skydns.paas. IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1.bar.skydns.paas. 3600 IN  TXT \"us-east-1d.bar.skydns.paas\"\ntxt.us-east-1.bar.skydns.paas. 3600 IN  TXT \"us-east-1c.bar.skydns.paas\"\ndig txt.us-east-1c.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1c.bar.skydns.paas.    IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1c.bar.skydns.paas. 3600 IN TXT \"10.120.180.235\"\ndig txt.us-east-1d.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1d.bar.skydns.paas.    IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1d.bar.skydns.paas. 3600 IN TXT \"10.120.180.117\"\nThe result:\nIt can only get  one eureka endpoints via DNS, and at last\n2016-04-19 09:44:17,986 WARN  com.netflix.config.util.ConfigurationUtils:177 [localhost-startStop-1] [getConfigFromPropertiesFile] file:/usr/local/apache-tomcat-8.0.32/webapps/eureka/WEB-INF/classes/eureka-client.properties is already loaded\n2016-04-19 09:44:18,334 INFO  com.netflix.discovery.provider.DiscoveryJerseyProvider:70 [localhost-startStop-1] [] Using JSON encoding codec LegacyJacksonJson\n2016-04-19 09:44:18,335 INFO  com.netflix.discovery.provider.DiscoveryJerseyProvider:71 [localhost-startStop-1] [] Using JSON decoding codec LegacyJacksonJson\n2016-04-19 09:44:18,335 INFO  com.netflix.discovery.provider.DiscoveryJerseyProvider:80 [localhost-startStop-1] [] Using XML encoding codec XStreamXml\n2016-04-19 09:44:18,335 INFO  com.netflix.discovery.provider.DiscoveryJerseyProvider:81 [localhost-startStop-1] [] Using XML decoding codec XStreamXml\n2016-04-19 09:44:18,600 INFO  com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver:40 [localhost-startStop-1] [getClusterEndpoints] Resolving eureka endpoints via DNS\nThe txtRecord is : us-east-1c.bar.skydns.paas\nThe cnamesString is : [us-east-1c.bar.skydns.paas]\nThe rootClusterDNS is : txt.us-east-1.bar.skydns.paas\nThe zoneDomain is : us-east-1c.bar.skydns.paas\nThe txtRecord is : 10.120.180.235\nThe cnamesString is : [10.120.180.235]\nThe txtRecord is : 10.120.180.235\nThe cnamesString is : [10.120.180.235]\nThe zoneAddresses is : 10.120.180.235\n2016-04-19 09:44:18,646 INFO  com.netflix.discovery.DiscoveryClient:920 [localhost-startStop-1] [fetchRegistry] Disable delta property : false\n2016-04-19 09:44:18,646 INFO  com.netflix.discovery.DiscoveryClient:921 [localhost-startStop-1] [fetchRegistry] Single vip registry refresh property : null\n2016-04-19 09:44:18,646 INFO  com.netflix.discovery.DiscoveryClient:922 [localhost-startStop-1] [fetchRegistry] Force full registry fetch : false\n2016-04-19 09:44:18,646 INFO  com.netflix.discovery.DiscoveryClient:923 [localhost-startStop-1] [fetchRegistry] Application is null : false\n2016-04-19 09:44:18,647 INFO  com.netflix.discovery.DiscoveryClient:924 [localhost-startStop-1] [fetchRegistry] Registered Applications size is zero : true\n2016-04-19 09:44:18,647 INFO  com.netflix.discovery.DiscoveryClient:926 [localhost-startStop-1] [fetchRegistry] Application version is -1: true\n2016-04-19 09:44:18,647 INFO  com.netflix.discovery.DiscoveryClient:1009 [localhost-startStop-1] [getAndStoreFullRegistry] Getting all instance registry info from the eureka server\nthe response of \"http://10.120.180.117:8080/eureka/\"\nDS Replicas: 10.120.180.235\nInstances currently registered with Eureka\nApplication\nSearch Application\nAMIs\nSearch AMIs\nAvailability Zones\nSearch Availability Zones\nStatus\nSearch Status\nApplication AMIs    Availability Zones  Status\nNo data available in table\nGeneral Info\nName    Value\nenvironment prod\nnum-of-cpus 4\ntotal-avail-memory  567mb\ncurrent-memory-usage    237mb (41%)\nserver-uptime   00:02\nregistered-replicas http://10.120.180.235:8080/eureka/v2/\navailable-replicas\nunavailable-replicas    http://10.120.180.235:8080/eureka/v2/,\nInstance Info\nName    Value\nipAddr  10.120.180.117\nstatus  UP\nThe Second trying:\nThe metadata in DNS:\ndig txt.us-east-1.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1.bar.skydns.paas. IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1.bar.skydns.paas. 3600 IN  TXT \"us-east-1c.bar.skydns.paas\"\ndig txt.us-east-1c.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1c.bar.skydns.paas.    IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1c.bar.skydns.paas. 3600 IN TXT \"10.120.180.235 10.120.180.117\"\nBut the Domain Name Resolution is wrong, there will be get a extra \",like \nthe response of \"http://10.120.180.235:8080/eureka/\"\nDS Replicas:\nInstances currently registered with Eureka\nApplication\nSearch Application\nAMIs\nSearch AMIs\nAvailability Zones\nSearch Availability Zones\nStatus\nSearch Status\nApplication AMIs    Availability Zones  Status\nNo data available in table\nGeneral Info\nName    Value\nenvironment prod\nnum-of-cpus 4\ntotal-avail-memory  562mb\ncurrent-memory-usage    317mb (56%)\nserver-uptime   00:01\nregistered-replicas http://\"10.120.180.235:8080/eureka/v2/, http://10.120.180.117\":8080/eureka/v2/\navailable-replicas\nunavailable-replicas    http://\"10.120.180.235:8080/eureka/v2/,http://10.120.180.117\":8080/eureka/v2/,\nInstance Info\nName    Value\nipAddr  10.120.180.235\nstatus  UP\n2016-04-19 10:02:48,307 ERROR com.netflix.eureka.util.StatusUtil:72 [http-nio-8080-exec-6] [isReplicaAvailable] Could not determine if the replica is available\njava.net.URISyntaxException: Illegal character in authority at index 7: http://10.120.180.117\":8080/eureka/v2/\nif i set this in DNS ,the eureka can only find the IP \"10.120.180.235\"  like the first trying\uff1a\ndig txt.us-east-1c.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1c.bar.skydns.paas.    IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1c.bar.skydns.paas. 3600 IN TXT \"10.120.180.235\"\ntxt.us-east-1c.bar.skydns.paas. 3600 IN TXT \"10.120.180.117 \"\nThe Third trying:\nThe metadata in DNS:\ndig txt.us-east-1.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1.bar.skydns.paas. IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1.bar.skydns.paas. 3600 IN  TXT \"us-east-1c.bar.skydns.paas\"\ndig txt.us-east-1c.bar.skydns.paas txt\n;; QUESTION SECTION:\n;txt.us-east-1c.bar.skydns.paas.    IN  TXT\n;; ANSWER SECTION:\ntxt.us-east-1c.bar.skydns.paas. 3600 IN TXT \" 10.120.180.235 10.120.180.117 \"\nBut the Domain Name Resolution is wrong, there will be get a extra \u201chttp://\":8080/eureka/v2/ \u201d,like \nthe response of \"http://10.120.180.235:8080/eureka/\"\nDS Replicas: 10.120.180.23510.120.180.117\nInstances currently registered with Eureka\nApplication\nSearch Application\nAMIs\nSearch AMIs\nAvailability Zones\nSearch Availability Zones\nStatus\nSearch Status\nApplication AMIs    Availability Zones  Status\nEUREKA  n/a (2),    (2),    UP (2) - SZV1000048497, SZV1000048537,\nGeneral Info\nName    Value\nenvironment prod\nnum-of-cpus 4\ntotal-avail-memory  374mb\ncurrent-memory-usage    299mb (79%)\nserver-uptime   00:00\nregistered-replicas http://10.120.180.235:8080/eureka/v2/, http://\":8080/eureka/v2/, http://10.120.180.117:8080/eureka/v2/\navailable-replicas\nunavailable-replicas    http://10.120.180.235:8080/eureka/v2/,http://\":8080/eureka/v2/,http://10.120.180.117:8080/eureka/v2/,\nInstance Info\nName    Value\nipAddr  10.120.180.235\nstatus  UP\nIs this the cluster of eureka?    if yes,how could i rm the http://\":8080/eureka/v2/ ?\nwhen i use the  cluster of eureka ,are there will be any problems?\n. @qiangdavidliu , i may have found what is wrong.i use skydns as my DNS,when i set the domain,it is not the format such as :\ntxt.us-east-1.mydomaintest.netflix.net=\"us-east-1c.mydomaintest.netflix.net\" \n\"us-east-1d.mydomaintest.netflix.net\" \"us-east-1e.mydomaintest.netflix.net\"\nbut like this:\ncurl -XPUT http://127.0.0.1:4001/v2/keys/skydns/paas/skydns/bar/us-east-1/txt/x1 -d value='{\"text\":\"us-east-1c.bar.skydns.paas\",\"targetstrip\":1}'\ncurl -XPUT http://127.0.0.1:4001/v2/keys/skydns/paas/skydns/bar/us-east-1/txt/x2 -d value='{\"text\":\"us-east-1d.bar.skydns.paas\",\"targetstrip\":1}'\nand the function of  _getCNamesFromTxtRecord in DnsResolver.java _,always only find the first one.\nthen in order to adapt to the format, i set domain in skydns like this \uff1a\ncurl -XPUT http://127.0.0.1:4001/v2/keys/skydns/paas/skydns/bar/us-east-1/txt/x1 -d value='{\"text\":\"us-east-1c.bar.skydns.paas us-east-1d.bar.skydns.paas\",\"targetstrip\":1}'\nthere will be another problem,when the function of  getCNamesFromTxtRecord in DnsResolver.java **  run the code:String[] cnames = txtRecord.split(\" \");**.\nthe cnames  is \uff1a[\"us-east-1d.bar.skydns.paas,us-east-1c.bar.skydns.paas\"]. it is not right.\nso, at last ,i change the function getCNamesFromTxtRecord,rm the \" in the element of cnames  ,it seems to be all right the result is as the following:\nthe response of http://10.120.180.235:8080/eureka/\nDS Replicas: 10.120.180.23510.120.180.11710.120.175.175\nInstances currently registered with Eureka\nApplication\nSearch Application\nAMIs\nSearch AMIs\nAvailability Zones\nSearch Availability Zones\nStatus\nSearch Status\nApplication AMIs    Availability Zones  Status\nEUREKA  n/a (3),    (3),    UP (3) - SZV1000048497, SZV1000048537, SZV1000048538,\nSAMPLEREGISTERINGSERVICE    n/a (1),    (1),    UP (1) - SZV1000048389,\nGeneral Info\nName    Value\nenvironment prod\nnum-of-cpus 4\ntotal-avail-memory  638mb\ncurrent-memory-usage    278mb (43%)\nserver-uptime   00:15\nregistered-replicas http://10.120.180.235:8080/eureka/v2/, http://10.120.180.117:8080/eureka/v2/, http://10.120.175.175:8080/eureka/v2/\navailable-replicas\nunavailable-replicas    http://10.120.180.235:8080/eureka/v2/,http://10.120.180.117:8080/eureka/v2/,http://10.120.175.175:8080/eureka/v2/,\nInstance Info\nName    Value\nipAddr  10.120.180.235\nstatus  UP\nthe response of http://10.120.180.117:8080/eureka/\nDS Replicas: 10.120.180.23510.120.180.11710.120.175.175\nInstances currently registered with Eureka\nApplication\nSearch Application\nAMIs\nSearch AMIs\nAvailability Zones\nSearch Availability Zones\nStatus\nSearch Status\nApplication AMIs    Availability Zones  Status\nEUREKA  n/a (3),    (3),    UP (3) - SZV1000048497, SZV1000048537, SZV1000048538,\nSAMPLEREGISTERINGSERVICE    n/a (1),    (1),    UP (1) - SZV1000048389,\nGeneral Info\nName    Value\nenvironment prod\nnum-of-cpus 4\ntotal-avail-memory  632mb\ncurrent-memory-usage    277mb (43%)\nserver-uptime   00:15\nregistered-replicas http://10.120.180.235:8080/eureka/v2/, http://10.120.180.117:8080/eureka/v2/, http://10.120.175.175:8080/eureka/v2/\navailable-replicas\nunavailable-replicas    http://10.120.180.235:8080/eureka/v2/,http://10.120.180.117:8080/eureka/v2/,http://10.120.175.175:8080/eureka/v2/,\nInstance Info\nName    Value\nipAddr  10.120.180.117\nstatus  UP\n. ",
    "iamzken": "service-hi_1     | 2017-07-18 12:33:41.357 ERROR 1 --- [           main] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_SERVICE-HI/18b4cd4a712a:service-hi:8763 - was unable to refresh its cache! status = Cannot execute request on any known server\nservice-hi_1     | \nservice-hi_1     | com.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server\nservice-hi_1     |  at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111) ~[eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$6.execute(EurekaHttpClientDecorator.java:137) ~[eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77) ~[eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.getApplications(EurekaHttpClientDecorator.java:134) ~[eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.DiscoveryClient.getAndStoreFullRegistry(DiscoveryClient.java:1013) [eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.DiscoveryClient.fetchRegistry(DiscoveryClient.java:927) [eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:408) [eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:266) [eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at com.netflix.discovery.DiscoveryClient.(DiscoveryClient.java:262) [eureka-client-1.6.1.jar!/:1.6.1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.CloudEurekaClient.(CloudEurekaClient.java:60) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration.eurekaClient(EurekaClientAutoConfiguration.java:225) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$6eaebe88.CGLIB$eurekaClient$0() [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$6eaebe88$$FastClassBySpringCGLIB$$fe359a98.invoke() [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cglib.proxy.MethodProxy.invokeSuper(MethodProxy.java:228) [spring-core-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.context.annotation.ConfigurationClassEnhancer$BeanMethodInterceptor.intercept(ConfigurationClassEnhancer.java:358) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration$RefreshableEurekaClientConfiguration$$EnhancerBySpringCGLIB$$6eaebe88.eurekaClient() [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]\nservice-hi_1     |  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]\nservice-hi_1     |  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]\nservice-hi_1     |  at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]\nservice-hi_1     |  at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:162) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:588) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:345) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.cloud.context.scope.GenericScope$BeanLifecycleWrapper.getBean(GenericScope.java:359) [spring-cloud-context-1.2.0.RC1.jar!/:1.2.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.context.scope.GenericScope.get(GenericScope.java:176) [spring-cloud-context-1.2.0.RC1.jar!/:1.2.0.RC1]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:340) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197) [spring-beans-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35) [spring-aop-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getTargetObject(EurekaRegistration.java:133) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaRegistration.getEurekaClient(EurekaRegistration.java:122) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.maybeInitializeClient(EurekaServiceRegistry.java:56) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:37) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:73) [spring-cloud-netflix-eureka-client-1.3.0.RC1.jar!/:1.3.0.RC1]\nservice-hi_1     |  at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:175) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:50) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:348) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:151) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.context.support.DefaultLifecycleProcessor.onRefresh(DefaultLifecycleProcessor.java:114) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.context.support.AbstractApplicationContext.finishRefresh(AbstractApplicationContext.java:879) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.finishRefresh(EmbeddedWebApplicationContext.java:144) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:545) [spring-context-4.3.7.RELEASE.jar!/:4.3.7.RELEASE]\nservice-hi_1     |  at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at org.springframework.boot.SpringApplication.run(SpringApplication.java:314) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151) [spring-boot-1.5.2.RELEASE.jar!/:1.5.2.RELEASE]\nservice-hi_1     |  at com.forezp.ServiceHiApplication.main(ServiceHiApplication.java:17) [classes!/:0.0.1-SNAPSHOT]\nservice-hi_1     |  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_131]\nservice-hi_1     |  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_131]\nservice-hi_1     |  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_131]\nservice-hi_1     |  at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_131]\nservice-hi_1     |  at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:48) [app.jar:0.0.1-SNAPSHOT]\nservice-hi_1     |  at org.springframework.boot.loader.Launcher.launch(Launcher.java:87) [app.jar:0.0.1-SNAPSHOT]\nservice-hi_1     |  at org.springframework.boot.loader.Launcher.launch(Launcher.java:50) [app.jar:0.0.1-SNAPSHOT]\nservice-hi_1     |  at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:51) [app.jar:0.0.1-SNAPSHOT]\n. ",
    "ervansetiawan": "I don't see any client registration failures in the logs. The two Eureka instances are registered with UP status. \n2016-04-22 19:50:14,298 INFO  com.netflix.eureka.registry.AbstractInstanceRegistry:266 [http-nio-8080-exec-10] [register] Registered instance EUREKA/i-b0019a0c with status UP (replication=true)\n2016-04-22 19:50:16,852 WARN  com.netflix.eureka.registry.AbstractInstanceRegistry:353 [http-nio-8080-exec-1] [renew] DS: Registry: lease doesn't exist, registering resource: EUREKA - i-8371d13e\n2016-04-22 19:50:16,852 WARN  com.netflix.eureka.resources.InstanceResource:116 [http-nio-8080-exec-1] [renewLease] Not Found (Renew): EUREKA - i-8371d13e\n2016-04-22 19:50:17,366 INFO  com.netflix.eureka.registry.AbstractInstanceRegistry:266 [http-nio-8080-exec-2] [register] Registered instance EUREKA/i-8371d13e with status UP (replication=true)\n2016-04-22 19:50:23,787 WARN  com.netflix.appinfo.CloudInstanceConfig:183 [DiscoveryClient-InstanceInfoReplicator-0] [shouldUpdate] Newly resolved AmazonInfo contains less data than previous old:10 -> new:9, skipping an update cycle\n2016-04-22 19:50:53,798 WARN  com.netflix.appinfo.CloudInstanceConfig:183 [DiscoveryClient-InstanceInfoReplicator-0] [shouldUpdate] Newly resolved AmazonInfo contains less data than previous old:10 -> new:9, skipping an update cycle\n2016-04-22 19:51:13,796 INFO  com.netflix.discovery.DiscoveryClient:921 [DiscoveryClient-HeartbeatExecutor-0] [renew] DiscoveryClient_EUREKA/i-b0019a0c - Re-registering apps/EUREKA\n2016-04-22 19:51:13,796 INFO  com.netflix.discovery.DiscoveryClient:862 [DiscoveryClient-HeartbeatExecutor-0] [register] DiscoveryClient_EUREKA/i-b0019a0c: registering service...\n2016-04-22 19:51:13,802 WARN  com.netflix.discovery.DiscoveryClient:1250 [DiscoveryClient-CacheRefreshExecutor-0] [reconcileAndLogDifference] The Reconcile hashcodes do not match, client : UP_2_, server : UP_1_. Getting the full registry\n2016-04-22 19:51:13,807 INFO  com.netflix.discovery.DiscoveryClient:881 [DiscoveryClient-HeartbeatExecutor-0] [register] DiscoveryClient_EUREKA/i-b0019a0c - registration status: 204\n2016-04-22 19:51:13,810 WARN  com.netflix.discovery.DiscoveryClient:1288 [DiscoveryClient-CacheRefreshExecutor-0] [reconcileAndLogDifference] The reconcile string is\n2016-04-22 19:51:13,811 WARN  com.netflix.discovery.DiscoveryClient:1296 [DiscoveryClient-CacheRefreshExecutor-0] [reconcileAndLogDifference] The Reconcile hashcodes after complete sync up, client : UP_1_, server : UP_1_.\n2016-04-22 19:51:14,036 INFO  com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl:222 [Eureka-EIPBinder] [openForTraffic] Got 0 instances from neighboring DS node\n2016-04-22 19:51:14,036 INFO  com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl:223 [Eureka-EIPBinder] [openForTraffic] Renew threshold is: 0\n2016-04-22 19:51:14,036 INFO  com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl:231 [Eureka-EIPBinder] [openForTraffic] Priming AWS connections for all replicas..\n2016-04-22 19:51:14,036 INFO  com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl:264 [Eureka-EIPBinder] [primeAwsReplicas] No peers needed to prime.\n2016-04-22 19:51:14,037 INFO  com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl:234 [Eureka-EIPBinder] [openForTraffic] Changing status to UP\nThis is the registration information from one of the Eureka nodes.\n<instance>\n      <instanceId>i-8371d13e</instanceId>\n      <hostName>10.0.1.5</hostName>\n      <app>EUREKA</app>\n      <ipAddr>10.0.1.5</ipAddr>\n      <status>UP</status>\n      <overriddenstatus>UNKNOWN</overriddenstatus>\n      <port enabled=\"true\">8080</port>\n      <securePort enabled=\"false\">443</securePort>\n      <countryId>1</countryId>\n      <dataCenterInfo class=\"com.netflix.appinfo.AmazonInfo\">\n        <name>Amazon</name>\n        <metadata>\n          <accountId>xxxxxxxxxxxxx</accountId>\n          <local-hostname>ip-10-0-1-5.eu-central-1.compute.internal</local-hostname>\n          <public-hostname>10.0.1.5</public-hostname>\n          <instance-id>i-8371d13e</instance-id>\n          <local-ipv4>10.0.1.5</local-ipv4>\n          <instance-type>t2.micro</instance-type>\n          <vpc-id>vpc-7a035213</vpc-id>\n          <ami-id>ami-bc5b48d0</ami-id>\n          <mac>02:4a:4e:75:bf:f9</mac>\n          <availability-zone>eu-central-1a</availability-zone>\n        </metadata>\n      </dataCenterInfo>\n      <leaseInfo>\n        <renewalIntervalInSecs>30</renewalIntervalInSecs>\n        <durationInSecs>90</durationInSecs>\n        <registrationTimestamp>1461354527294</registrationTimestamp>\n        <lastRenewalTimestamp>1461354646800</lastRenewalTimestamp>\n        <evictionTimestamp>0</evictionTimestamp>\n        <serviceUpTimestamp>1461354527294</serviceUpTimestamp>\n      </leaseInfo>\n      <metadata class=\"java.util.Collections$EmptyMap\"/>\n      <appGroupName>UNKNOWN</appGroupName>\n      <homePageUrl>http://10.0.1.5:8080/</homePageUrl>\n      <statusPageUrl>http://10.0.1.5:8080/Status</statusPageUrl>\n      <healthCheckUrl>http://10.0.1.5:8080/healthcheck</healthCheckUrl>\n      <vipAddress>eureka.mydomain.net</vipAddress>\n      <isCoordinatingDiscoveryServer>true</isCoordinatingDiscoveryServer>\n      <lastUpdatedTimestamp>1461354527294</lastUpdatedTimestamp>\n      <lastDirtyTimestamp>1461353686823</lastDirtyTimestamp>\n      <actionType>ADDED</actionType>\n    </instance>\nThis is the Eureka dashboard \n```\nDS Replicas: ip-10-0-1-5.eu-central-1.compute.internalip-10-0-2-5.eu-central-1.compute.internal\nInstances currently registered with Eureka\nApplication AMIs    Availability Zones  Status\nApplication AMIs    Availability Zones  Status\nEUREKA  ami-bc5b48d0 (2),   eu-central-1a (1), eu-central-1b (1),   UP (2) - i-b0019a0c, i-8371d13e,\nGeneral Info\nName    Value\nenvironment test\nnum-of-cpus 1\ntotal-avail-memory  80mb\ncurrent-memory-usage    46mb (57%)\nserver-uptime   00:19\nregistered-replicas http://ip-10-0-1-5.eu-central-1.compute.internal:8080/eureka/v2/, http://ip-10-0-2-5.eu-central-1.compute.internal:8080/eureka/v2/\navailable-replicas\nunavailable-replicas    http://ip-10-0-1-5.eu-central-1.compute.internal:8080/eureka/v2/,http://ip-10-0-2-5.eu-central-1.compute.internal:8080/eureka/v2/,\nInstance Info\nName    Value\npublic-ipv4 null\npublic-hostname 10.0.1.5\ninstance-id i-8371d13e\ninstance-type   t2.micro\nami-id  ami-bc5b48d0\nipAddr  10.0.1.5\nstatus  UP\navailability-zone   eu-central-1a\n```\nOne thing that I also noticed is that I have two Eureka servers so I am expecting to only see one registered replica. As you can see in that dashboard, there are two registered replicas. Somehow the Eureka server considers itself as it's own replica. I did not see that behavior when I use EIPs in public subnets.\n. I finally got this to work internally. It appears that the root cause is the fact that com.netflix.eureka.util.StatusUtil.isReplicaAvailable is comparing the values of serviceUrl param with the hostName in the registry. \nSince I am running Eureka cluster in a private subnet, the hostName in the registry is the private IP address (i.e. 10.0.0.5). In my original configuration, I had set up the Eureka nodes to use private DNS name (ip-1-0-0-5.region.compute.internal) as the serviceUrl. They don't match up, thus, the unavailable replicas.\nMy fix is to simply use the private IP addresses as the serviceUrls of the Eureka nodes.\n. @jelez We are using Elastic Network Interface to provide static private IP addresses. \n. ",
    "jelez": "I am curious about setting up eureka in VPC with private IPs - could you share how you set it up?\n. ",
    "bobbychef64": "@ervansetiawan  I am facing the same problem. I am not seeing any available replicas. This is my eureka client properties file. \nregistered-replicas | 172.X.X.X, 172.X.X.X, 172.X.X.X\n-- | --\navailable-replicas | \u00a0\nunavailable-replicas | 172.X.X.X,172.X.X.X,172.X.X.X\nI am not seeing the replicas and i found this error in the log file.\n2017-08-17 02:59:32,503 ERROR com.netflix.discovery.DiscoveryClient:943 [DiscoveryClient-CacheRefreshExecutor-0] [fetchRegistry] DiscoveryClient_EUREKALATEST/i-08a03bc3538034239 - was unable to refresh its cache! status = There is no known eureka server; cluster server list is empty\ncom.netflix.discovery.shared.transport.TransportException: There is no known eureka server; cluster server list is empty\nHere are my eureka client properties and server properties file.\n** cat eureka-client.properties\nEureka Client configuration for Eureka Service\nProperties based configuration for eureka client. The properties specified here is mostly what the users\nneed to change. All of these can be specified as a java system property with -D option (eg)-Deureka.region=us-east-1\nRegion where eureka is deployed -For AWS specify one of the AWS regions, for other datacenters specify a arbitrary string\nindicating the region.This is normally specified as a -D option (eg) -Deureka.region=us-east-1\neureka.region=us-east-1\neureka.region=${archaius.deployment.region}\neureka.us-east-1.availabilityZones=us-east-1b,us-east-1c,us-east-1d\nName of the application to be identified by other services\neureka.name=eurekalatest\neureka.serviceUrl.us-east-1b=172...*\neureka.serviceUrl.us-east-1c=172....\neureka.serviceUrl.us-east-1d=172....\nVirtual host name by which the clients identifies this service\neureka.vipAddress=eureka.${aesd.archaius.deployment.domain}\nThe port where the service will be identified and will be serving requests\neureka.port=8080\nFor eureka clients running in eureka server, it needs to connect to servers in other zones\neureka.preferSameZone=false\nChange this if you want to use a DNS based lookup for determining other eureka servers. For example\nof specifying the DNS entries, check the eureka-client-test.properties, eureka-client-prod.properties\neureka.shouldUseDns=true\neureka.eurekaServer.domainName=${aesd.archaius.deployment.domain}\neureka.eurekaServer.context=eureka/v2\neureka.healthCheckUrl=http://${archaius.deployment.serverPrivIP}:8080/eureka/healthcheck\neureka.registration.enabled=false\n**\n. ",
    "n0mer": "@qiangdavidliu eureka supports DNS querying mode, so i think floating IPs are valid option: https://github.com/Netflix/eureka/wiki/Deploying-Eureka-Servers-in-EC2#configuring-eips-using-dns. ",
    "tewner": "I'm having this same issue while using ActiveDirectory as my DNS server:\n2017-12-21 17:43:45.457  WARN 3136 --- [nfoReplicator-0] c.n.d.s.t.d.RetryableEurekaHttpClient    : Request execution failed with message: Illegal character in authority at index 7: http://eureka02.mydomain.com\":8761\n2017-12-21 17:43:45.458  WARN 3136 --- [nfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_UNKNOWN/eureka02.mydomain.com:8761 - registration failed Cannot execute request on any known server\nNotice the quote appended to URL\nIs this just something which works in Route53 and not on other DNS servers?\n```\n[eureka02 eureka]# dig txt.office-1a.eureka.mydomain.com TXT\n; <<>> DiG 9.9.4-RedHat-9.9.4-51.el7 <<>> txt.office-1a.eureka.mydomain.com TXT\n;; QUESTION SECTION:\n;txt.office-1a.eureka.mydomain.com. IN TXT\n;; ANSWER SECTION:\ntxt.office-1a.eureka.mydomain.com. 38400 IN TXT \"eureka01.mydomain.com eureka02.mydomain.com\"\n```\n. ",
    "wangwenyao": "I\u2019m having this same issue, when fix it?\nThe problem is in DnsResolver.getCNamesFromTxtRecord(), \n` \n    if (attr != null) {\n        txtRecord = attr.get().toString();\n    }\n    Set<String> cnamesSet = new TreeSet<String>();\n    if (txtRecord == null || txtRecord.trim().isEmpty()) {\n        return cnamesSet;\n    }\n    String[] cnames = txtRecord.split(\" \");\n\n`\ntxtRecord = attr.get().toString();. http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.839 c.n.d.DiscoveryClient[852] - Shutting down DiscoveryClient ...\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.840 o.s.c.n.e.InstanceInfoFactory[70] - Setting initial instance status as: STARTING\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.841 c.n.d.DiscoveryClient[884] - Unregistering ...\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.846 c.n.d.DiscoveryClient[886] - DiscoveryClient_CONFIG-CENTER/xxx.xxx.xxx.xxx:8102 - deregister  status: 200\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.848 c.n.d.DiscoveryClient[873] - Completed shut down of DiscoveryClient\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.850 c.n.d.DiscoveryClient[344] - Initializing Eureka in region us-east-1\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.852 c.n.d.p.DiscoveryJerseyProvider[70] - Using JSON encoding codec LegacyJacksonJson\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.852 c.n.d.p.DiscoveryJerseyProvider[71] - Using JSON decoding codec LegacyJacksonJson\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.852 c.n.d.p.DiscoveryJerseyProvider[80] - Using XML encoding codec XStreamXml\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.852 c.n.d.p.DiscoveryJerseyProvider[81] - Using XML decoding codec XStreamXml\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.939 c.n.d.s.r.a.ConfigClusterResolver[43] - Resolving eureka endpoints via configuration\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.940 c.n.d.DiscoveryClient[1244] - Starting heartbeat executor: renew interval is: 10\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.940 c.n.d.InstanceInfoReplicator[59] - InstanceInfoReplicator onDemand update allowed rate per min is 4\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.941 c.n.d.DiscoveryClient[425] - Discovery Client initialized at timestamp 1505187917941 with initial instances count: 0\n[DiscoveryClient-InstanceInfoReplicator-0] INFO  2017-09-12 11:45:17.941 c.n.d.DiscoveryClient[795] - DiscoveryClient_CONFIG-CENTER/xxx.xxx.xxx.xxx:8102: registering service...\n[DiscoveryClient-InstanceInfoReplicator-0] INFO  2017-09-12 11:45:17.947 c.n.d.DiscoveryClient[804] - DiscoveryClient_CONFIG-CENTER/xxx.xxx.xxx.xxx:8102 - registration status: 204\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.949 o.s.c.n.e.s.EurekaServiceRegistry[64] - Unregistering application config-center with eureka with status DOWN\n[http-nio-8102-exec-2] INFO  2017-09-12 11:45:17.950 o.s.c.n.e.s.EurekaServiceRegistry[40] - Registering application config-center with eureka with status UP\n[http-nio-8102-exec-2] WARN  2017-09-12 11:45:17.950 c.n.d.DiscoveryClient[1277] - Saw local status change event StatusChangeEvent [timestamp=1505187917950, current=UP, previous=DOWN]\n[DiscoveryClient-InstanceInfoReplicator-0] INFO  2017-09-12 11:45:17.950 c.n.d.DiscoveryClient[795] - DiscoveryClient_CONFIG-CENTER/xxx.xxx.xxx.xxx:8102: registering service...\n[DiscoveryClient-InstanceInfoReplicator-0] INFO  2017-09-12 11:45:17.953 c.n.d.DiscoveryClient[804] - DiscoveryClient_CONFIG-CENTER/xxx.xxx.xxx.xxx:8102 - registration status: 204\n[http-nio-8102-exec-2] ERROR 2017-09-12 11:45:18.010 o.a.c.c.C.[.[.[.[dispatcherServlet][181] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@975b946 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2b6f6092[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 6]] with root cause\njava.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@975b946 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@2b6f6092[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 6]\n    at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)\n    at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)\n    at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)\n    at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)\n    at java.util.concurrent.ScheduledThreadPoolExecutor.submit(ScheduledThreadPoolExecutor.java:632)\n    at com.netflix.discovery.InstanceInfoReplicator.onDemandUpdate(InstanceInfoReplicator.java:77)\n    at com.netflix.discovery.DiscoveryClient.registerHealthCheck(DiscoveryClient.java:618)\n    at com.netflix.discovery.DiscoveryClient$$FastClassBySpringCGLIB$$a84c8cb4.invoke(<generated>)\n    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:204)\n    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:738)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)\n    at org.springframework.cloud.context.config.StandardBeanLifecycleDecorator$2.invoke(StandardBeanLifecycleDecorator.java:85)\n    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)\n    at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673)\n    at org.springframework.cloud.netflix.eureka.CloudEurekaClient$$EnhancerBySpringCGLIB$$af46ce7b.registerHealthCheck(<generated>)\n    at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaServiceRegistry.register(EurekaServiceRegistry.java:49)\n    at org.springframework.cloud.netflix.eureka.serviceregistry.EurekaAutoServiceRegistration.start(EurekaAutoServiceRegistration.java:73)\n    at org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration$EurekaClientConfigurationRefresher.onApplicationEvent(EurekaDiscoveryClientConfiguration.java:79)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.springframework.context.event.ApplicationListenerMethodAdapter.doInvoke(ApplicationListenerMethodAdapter.java:256)\n    at org.springframework.context.event.ApplicationListenerMethodAdapter.processEvent(ApplicationListenerMethodAdapter.java:177)\n    at org.springframework.context.event.ApplicationListenerMethodAdapter.onApplicationEvent(ApplicationListenerMethodAdapter.java:140)\n    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:167)\n    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139)\n    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393)\n    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347)\n    at org.springframework.cloud.context.scope.refresh.RefreshScope.refreshAll(RefreshScope.java:146)\n    at org.springframework.cloud.context.refresh.ContextRefresher.refresh(ContextRefresher.java:58)\n    at org.springframework.cloud.bus.event.RefreshListener.onApplicationEvent(RefreshListener.java:43)\n    at org.springframework.cloud.bus.event.RefreshListener.onApplicationEvent(RefreshListener.java:30)\n    at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:167)\n    at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:139)\n    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:393)\n    at org.springframework.context.support.AbstractApplicationContext.publishEvent(AbstractApplicationContext.java:347)\n    at org.springframework.cloud.bus.endpoint.AbstractBusEndpoint.publish(AbstractBusEndpoint.java:48)\n    at org.springframework.cloud.bus.endpoint.RefreshBusEndpoint.refresh(RefreshBusEndpoint.java:45)\n    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n    at java.lang.reflect.Method.invoke(Method.java:498)\n    at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:205)\n    at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:133)\n    at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:97)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:827)\n    at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:738)\n    at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:967)\n    at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901)\n    at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)\n    at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:661)\n    at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)\n    at javax.servlet.http.HttpServlet.service(HttpServlet.java:742)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.boot.web.filter.ApplicationContextHeaderFilter.doFilterInternal(ApplicationContextHeaderFilter.java:55)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.springframework.boot.actuate.autoconfigure.MetricsFilter.doFilterInternal(MetricsFilter.java:106)\n    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)\n    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193)\n    at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166)\n    at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198)\n    at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96)\n    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478)\n    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140)\n    at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80)\n    at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87)\n    at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342)\n    at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799)\n    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66)\n    at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868)\n    at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1455)\n    at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n    at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)\n    at java.lang.Thread.run(Thread.java:748). \u6211\u7406\u89e3\u8fd9\u4e2a\u5f02\u5e38\u662f\u7531\u4e8estatusChangeListener \u5df2\u7ecf\u6ce8\u518c\u5e76\u751f\u6548\uff0c\u4f46instanceInfoReplicator\u8fd8\u672a\u542f\u52a8\u9020\u6210\u7684\u3002. \n. ",
    "cschneider": "I know 2.x is not yet released. We are currently evaluating registries and eureka 2 sounds quite good from the API perspective. \nDoes it make sense to already look into eureka2? Our product is going to go into production end of this year. Do you think eureka2 will be out until then?\nIf yes how do I start the server? I do not have the requirement for it to be a war.\n. ",
    "jc89": "@qiangdavidliu a few dns record examples:\ntxt.us-east-1.eureka=\"us-east-1a.eureka\" \"us-east-1b.eureka\"\ntxt.us-east-1a.eureka=\"ip-172-31-y-y.ec2.internal\"\ntxt.us-east-1b.eureka=\"ip-172-31-x-x.ec2.internal\"\nwhere \"ip-172-31-x-x.ec2.internal\" is the ENI private dns\nNo tags are requiered for the enis, just like with elastic ips, are deduced from service urls or dns records.\nI will add more later\n. If you'd like to configure it via service urls, the service urls should look like this\neureka.awsBindingStrategy=ENI\neureka.serviceUrl.us-east-1a=http://ip-172-31-35-108.ec2.internal:7001/eureka/v2/\n. @qiangdavidliu Done\n. ",
    "remesh22": "Thanks.Reporting as an issue in htps://github.com/spring-cloud/spring-cloud-netflix/issues.\n. ",
    "zgagnon": "+1\n. Have resolved the issue.\nOur Eureka instance was in self-preservation mode due to a large number of instances being turned off at once. After manually deleting all extraneous instances that we could, the invalid id instance (http://127.0.0.1) failed its heartbeats and was removed. In this case, a different app had 50+ instances registered at one point (which were all disabled), and after removing them one-by-one, the problem resolved.\nWith either case, being able to delete the app would have made this a bit easier.\n. ",
    "tsjsdbd": "thanks for kindly reply, I agree that no need to return unzipped data for most scenario.\nbut on another hand, if the low level implementation finished the job about the feature, the appliacation level should no do it again, just focus on application logic maybe is more concise :-) \n(it have a little code deal with the HTTP header, and judge whether compress the response, and some code for compress algorithm)\n. ",
    "alessnet": "@qiangdavidliu\nI'm using the REST API in C#. Using the java client (event in a separate process) not an option unfortunately.\nI'm specifying the dirtytimestamp myself during registration at client side (in case the timers on the two eureka servers are slightly off). But the issue persists if I don't specify it. What should I put in this field ?\nI agree that a correct load balancer will minimize switches and will try to stick to MACHINE1 for the second register. But in my understanding you can still have this issue in real live production. If MACHINE1 doesn't answer to the second register, the load balancer will redirect the call to MACHINE2. If the replication between MACHINE1 and MACHINE2 is slow for some reason, you will end up with the exact same situation where the second register is discarded on MACHINE2 after the replication.\nCan you please explain me how the java client handles this situation ? (or lead me more precisely to the source file). \nThank you ! :)\n. @qiangdavidliu\nFirst of all, thank you for taking the time to answer my questions :)\nI'm sending a dirty timestamp and commands are correctly serialized at clientside (so the second register is correctly sent after the first one correctly finished). This is similar to your java code, so I can assure you that I don't make two write operations in parallel.\nThe only difference I see is that every command is delayed by x seconds while my implementation does not. And that was my original question : if you say that the race condition I had could be avoided only by delaying each command, how is that possible? There always could be a lag/partition in the network that could last longer that the chosen delay. Waiting at client side to hope for a correct sync between replicas seems wrong.\n\nThe server side replication logic also utilize the dirtyTimestamp to deal with conflict as you described.\n\nIn the log I have attached, you see that one of the server (which will end up showing the wrong state) print a warning about a old dirtytimestamp (replication=true). If I understand this correctly, in  AbstractInstanceRegistry the server takes the expired entry (\"STARTING\") anyway but keep the more recent dirtystimestamp (the one of the \"UP\"). It seems that If the server had ignored this expired command, the server would have kept the \"UP\" as expected.\nWhen this occurs, no matter how much time I wait, the two servers doesn't see the same status. Why is this related to the client and why the servers cannot agree of the final status?\n. Hi @qiangdavidliu, did you manage to reproduce this?\n. ",
    "tcellucci": "hey David, I can see that this change will fix the NPE problem, but wanted to suggest that an underlying problem is still present.  It looks like the root issue is that MeasuredRate doesn't manage its resources (Timer, TimerTask) in a way that's compatible with AbstractInstanceRegistry.  Since MeasuredRate starts its internal timer in construction, AbstractInstanceRegistry can't instantiate it until 'postInit' and that led to the NPE you fixed.\nIf MeasuredRate had lifecycle methods (start, stop) to handle timer activity, then it could be constructed immediately by AbstractInstanceRegistry and avoid NPEs altogether.  Additionally the 'stop' method would enable AbstractInstanceRegistry to free up its resources on shutdown().\n. looks good.  I had one comment on use of 'volatile' but not a blocker.\n. name AmazonInfo is overly broad; they (amazon guys) call it InstanceMetadata in the documentation and I think that's on-target.\n. had some more changes, going to close this PR and resubmit. merging to create a candidate release, v1.8.0-rc.1. looks good. volatile is not necessary here, since both start and stop methods are synchronized and isActive is used only in these methods.   (synchronized methods force a sync with object's entire state prior to execution)\n. seems like this class should implement standard interface like Supplier or Provider, for better interop with java api\n. must\n. failed\n. the raison d'etre of DeserializerStringCache is to cache in a single-threaded context and thereby avoid the expense of locking.  I'll update the class-level documentation to call this out more clearly.. added comment explaining why ignored. code will iterate and filter whether remote indexing is active or not; here's the guard condition:\nif (remoteIndexingActive OR filterUpInstances) {\n if filterUpInstances [do filtering]\n if remoteIndexingActive [do remote indexing]\n}\n.. that's existing code, relocated to an out-of-the-way method that preserves backward compatibility.  For DI, use the two-arg constructor that requires neither DiscoveryManager nor EurekaClientConfig.. this release will get tagged as a minor version, moving from 1.7.x to 1.8.x. yes, it's been moved into Applications.getNextIndex for consistency (previously Applications class applies 'toUpperCase' to some of its other method parameters but not this one). some maths :). \nIf you sum the lengths of each member in InstanceStatus (35), add in 2 * InstanceStatus.length for the separators that the hashing implementation adds (10), and figure an max size of 6 characters for the stringified 'count' associated with each status (30), then you get 75.. these methods part of public api, can't consolidate without breaking compatibility. there are three other pre-existing usages (constructor + 2 'newBuilder' factory methods) that call this new private constructor.  Each of those usages would have to specify StringCache::intern as the interning function, instead of having the default established in a single place.. ",
    "Writtscher": "Well thanks for the quick answer. I'm fine for now pulling the new library and exclude the jsr311 dependecy as there is no failure at the moment. \n. ",
    "drtechniko": "@qiangdavidliu Here you go. Let's chat so I can fill you in if you have any questions.\n. There is more room for making this more DI friendly (AwsInstanceRegistry for example) but I didn't want to stir the waters too much in this PR.\n. good point. I updated all the rule comments to be self-contained. Moved descriptions of rule order to the registries.\n. good idea. done.\n. done\n. renamed to AlwaysMatchInstanceStatusRule\n. done\n. done\n. ",
    "robertnosburn": "Hi David,\nI think that you are correct, I do not have any EIPs and so the EIPBinder would be unnecessary.  My Eureka runs in a docker container in an ec2 instance with a loadbalancer and a route-53 entry pointing to it.  This is how it's getting a fixed IP.  My microservices with Eureka clients know the location of the Eureka server by it's route-53 cname.  It does not need an internet routable.\nLooking through the code I also saw \"e-ipbind-rebind-retries\", which I tried setting to 0 in my application.yml both as \neureka:\ne-ipbind-rebind-retries: 0\ne-ipbinding-retry-interval-ms-when-unbound: 86400000\nand \neureka:\nserver:\ne-ipbind-rebind-retries: 0\ne-ipbinding-retry-interval-ms-when-unbound: 86400000\nIt looked as though this would allow the Binder to run once per day and not actually try to do the bind, but for some reason these values weren't getting picked up.\nSo yes, if I could persuade the EIPBinder to not run, that would be ideal.\nAs a side note, I think that my PR should still stand, it's probably not a bad idea to validate an index before using it in a substring, don't you think?\nThanks and Regards\n. David,\nI found the \"eureka.server.binding-strategy\" and set it to route53.  This causes a NPE on the EurekaController:\n2016-07-20 23:44:54.878 ERROR 5 --- [nio-8761-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.NullPointerException] with root cause\njava.lang.NullPointerException: null\n        at org.springframework.cloud.netflix.eureka.server.EurekaController.getServerContext(EurekaController.java:143) ~[spring-cloud-netflix-eureka-server-1.1.4.RELEASE.jar!/:1.1.4.RELEASE]\n        at org.springframework.cloud.netflix.eureka.server.EurekaController.getRegistry(EurekaController.java:139) ~[spring-cloud-netflix-eureka-server-1.1.4.RELEASE.jar!/:1.1.4.RELEASE]\nThoughts?\nThanks,\n. David,\nDigging a little further, the actual exception is:\njava.lang.RuntimeException: Cannot bootstrap eureka server :\n        at org.springframework.cloud.netflix.eureka.server.EurekaServerBootstrap.contextInitialized(EurekaServerBootstrap.java:87) ~[spring-cloud-netflix-eureka-server-1.1.4.RELEASE.jar!/:1.1.4.RELEASE]\n        at org.springframework.cloud.netflix.eureka.server.EurekaServerInitializerConfiguration$1.run(EurekaServerInitializerConfiguration.java:70) ~[spring-cloud-netflix-eureka-server-1.1.4.RELEASE.jar!/:1.1.4.RELEASE]\n        at java.lang.Thread.run(Thread.java:745) [na:1.8.0_91]\nCaused by: java.lang.NoSuchMethodError: com.amazonaws.AmazonWebServiceRequest.copyPrivateRequestParameters()Ljava/util/Map;\n        at com.amazonaws.services.route53.AmazonRoute53Client.invoke(AmazonRoute53Client.java:1544) ~[aws-java-sdk-route53-1.9.3.jar!/:na]\n        at com.amazonaws.services.route53.AmazonRoute53Client.listHostedZones(AmazonRoute53Client.java:382) ~[aws-java-sdk-route53-1.9.3.jar!/:na]\n        at com.netflix.eureka.aws.Route53Binder.getHostedZone(Route53Binder.java:238) ~[eureka-core-1.4.9.jar!/:1.4.9]\n        at com.netflix.eureka.aws.Route53Binder.getResourceRecordSetWithHostedZone(Route53Binder.java:212) ~[eureka-core-1.4.9.jar!/:1.4.9]\n        at com.netflix.eureka.aws.Route53Binder.doBind(Route53Binder.java:109) ~[eureka-core-1.4.9.jar!/:1.4.9]\n        at com.netflix.eureka.aws.Route53Binder.start(Route53Binder.java:89) ~[eureka-core-1.4.9.jar!/:1.4.9]\nHowever that method exists in the 1.9.3 version of the aws-sdk-core jar.\nBUT..\nA dependency:tree on my project reveals:\n[INFO] |  |  +- com.netflix.eureka:eureka-core:jar:1.4.9:compile\n[INFO] |  |  |  +- com.amazonaws:aws-java-sdk-core:jar:1.10.30:runtime\n[INFO] |  |  |  +- com.amazonaws:aws-java-sdk-ec2:jar:1.10.30:runtime\n[INFO] |  |  |  +- com.amazonaws:aws-java-sdk-autoscaling:jar:1.9.3:runtime\n[INFO] |  |  |  +- com.amazonaws:aws-java-sdk-sts:jar:1.9.3:runtime\n[INFO] |  |  |  +- com.amazonaws:aws-java-sdk-route53:jar:1.9.3:runtime\nI have performed a thorough search and I cannot see any reason why v1.10.30 of ec2 and core should be included, instead of the 1.9.3, as specified in the gradle files in tag v1.4.9\nThanks,\n. ",
    "ibaiul": "@robertnosburn, @qiangdavidliu   I have a problem with aws-java-sdk-core:jar:1.10.30:runtime and aws-java-sdk-ec2:jar:1.10.30:runtime dependencies as well.\nNotice:\nI am using aws-java-sdk-sqs:1.10.72 which depends on aws-java-sdk-core:jar:1.10.72\nI am using eureka-core:jar:1.4.10 which depends on aws-java-sdk-core:jar:1.9.3 and aws-java-sdk-ec2:jar:1.9.3\nDependency tree for -Dincludes=com.amazonaws:\n[INFO] |  - com.amazonaws:aws-java-sdk-sqs:jar:1.10.72:compile\n[INFO] |     - (com.amazonaws:aws-java-sdk-core:jar:1.10.30:compile - version managed from 1.10.72; omitted for duplicate)\n[INFO] +- org.springframework.cloud:spring-cloud-starter-eureka:jar:1.1.5.RELEASE:compile\n[INFO] |  - com.netflix.eureka:eureka-core:jar:1.4.10:compile\n[INFO] |     +- (com.amazonaws:aws-java-sdk-core:jar:1.10.30:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     +- com.amazonaws:aws-java-sdk-ec2:jar:1.10.30:runtime (version managed from 1.9.3)\n[INFO] |     |  - (com.amazonaws:aws-java-sdk-core:jar:1.10.30:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     +- com.amazonaws:aws-java-sdk-autoscaling:jar:1.9.3:runtime\n[INFO] |     |  - (com.amazonaws:aws-java-sdk-core:jar:1.10.30:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     +- com.amazonaws:aws-java-sdk-sts:jar:1.9.3:runtime\n[INFO] |     |  - (com.amazonaws:aws-java-sdk-core:jar:1.10.30:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     - com.amazonaws:aws-java-sdk-route53:jar:1.9.3:runtime\n[INFO] |        - (com.amazonaws:aws-java-sdk-core:jar:1.10.30:runtime - version managed from 1.9.3; omitted for duplicate)\nWhich causes java.lang.ClassNotFoundException: com.amazonaws.ClientConfigurationFactory\nWhen I explicitly declare the dependency aws-java-sdk-core:1.10.72 it fixes my problem with the aws-java-sdk-core dependency and I can run my application, but the dependency tree still shows that something is forcing the version aws-java-sdk-ec2:jar:1.10.30\n[INFO] |  - com.amazonaws:aws-java-sdk-sqs:jar:1.10.72:compile\n[INFO] |     - (com.amazonaws:aws-java-sdk-core:jar:1.10.72:compile - omitted for duplicate)\n[INFO] +- org.springframework.cloud:spring-cloud-starter-eureka:jar:1.1.5.RELEASE:compile\n[INFO] |  - com.netflix.eureka:eureka-core:jar:1.4.10:compile\n[INFO] |     +- (com.amazonaws:aws-java-sdk-core:jar:1.10.72:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     +- com.amazonaws:aws-java-sdk-ec2:jar:1.10.30:runtime (version managed from 1.9.3)\n[INFO] |     |  - (com.amazonaws:aws-java-sdk-core:jar:1.10.72:runtime - version managed from 1.10.30; omitted for duplicate)\n[INFO] |     +- com.amazonaws:aws-java-sdk-autoscaling:jar:1.9.3:runtime\n[INFO] |     |  - (com.amazonaws:aws-java-sdk-core:jar:1.10.72:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     +- com.amazonaws:aws-java-sdk-sts:jar:1.9.3:runtime\n[INFO] |     |  - (com.amazonaws:aws-java-sdk-core:jar:1.10.72:runtime - version managed from 1.9.3; omitted for duplicate)\n[INFO] |     - com.amazonaws:aws-java-sdk-route53:jar:1.9.3:runtime\n[INFO] |        - (com.amazonaws:aws-java-sdk-core:jar:1.10.72:runtime - version managed from 1.9.3; omitted for duplicate)\nI took a look at the gradle and pom files of eureka-core:1.4.10 and both declare dependencies to aws-java-sdk-core:1.9.3 and aws-java-sdk-ec2:1.9.3 so I don't know what is forcing the version 1.10.30\n. ",
    "fengbaicanhe": "@qiangdavidliu  Is there any plan for this feature?\n. ok, thanks @qiangdavidliu \n. ",
    "Luuuuuu": "Hi @qiangdavidliu is there any detail explanation about cache level implementation? thanks. ",
    "tapitoe": "@mattnelson Can you please share any documentation available to use Eureka with Jersey2. I am looking to run Eureka Server as a packaged web app in a servlet container which isn't compatible with Jersey 1.. ",
    "silentAllay": "if all the eureka servers crash, how to recover registration data?\n. @marcosbarbero , OK, got it, thx~\n. @spencergibb , OK, I create a issue in spring cloud netflix:\nhttps://github.com/spring-cloud/spring-cloud-netflix/issues/1222\n. @qiangdavidliu, what about the IP address? \n. @qiangdavidliu,what if the server have multi network interfaces?\n. How does eureka-client decide which ip should use if have two interfaces?\n. @rfoltyns , I extends com.netflix.appinfo.MyDataCenterInstanceConfig to override getHostName() and getIpAddress(), is that OK?\n. @qiangdavidliu, the example still use the property file:sample-eureka-client.properties.\nHow to set properties value in java code dynamicly?\n. ",
    "marcosbarbero": "@killjason if it all crashes the data will be rebuilt by the service registration heartbeat. As the first startup happens.\n. Do you have the following dependency?\nxml\n<dependency>\n    <groupId>javax.ws.rs</groupId>\n    <artifactId>javax.ws.rs-api</artifactId>\n    <version>2.1</version>\n</dependency>. can you share some code/sample project? I would like to see it.. maybe a mvn dependency:tree?. based on this output your project doesn't seem to have javax.ws.rs-api at all.. Do you have any shareable project with this issue? it will be easier.. ",
    "dajester2013": "thanks for the info - i posted a comment there with a suggested fix from the gradle forums.  it's really unfortunate that i either have to use gradle or spend so much time inspecting eureka's (or any other netflix-developed component's) dependency tree and manually configuring my maven dependencies.  that is a complete waste of my time, and speaks very poorly of gradle to me.\n. ",
    "miggy8234": "Hello @qiangdavidliu , No I mean if I download the latest jar from the maven central repository and deploy it to a server. The eureka.property files will have the same content as the MANIFEST.MF.\nDownloaded from here: http://search.maven.org/#search%7Cga%7C1%7Ceureka-client\n. ",
    "rs017991": "It's the war file itself:\nhttps://repo1.maven.org/maven2/com/netflix/eureka/eureka-server/1.5.3/eureka-server-1.5.3.war\nTake a look at META-INF/eureka-server.properties\n. If keeping this, should use logger and reformat the message to give more context.. ",
    "lijunyong": "@qiangdavidliu tomcat 8.0.33\n. ",
    "iamzhout": "Thanks @qiangdavidliu for your reply.\nCurrently, we are doing some performance test purely on eureka to check its capability and performance in large scale, and found some problems during the process, mainly are:\n1.  after registered 100,000 service instances to eureka, and then call delete API (~200 threads concurrently), eureka will be extremely slow of response\n2.   after registered 10,000 service instances to eureka, and refresh server list with \"/eureka/v2/apps/delta\" API every 30 seconds (~200 threads), eureka will slow of response; and the response size is quite large, about 1MB for single request.\nWhat's your suggestion on above performance issue, is it because we didn't call the correct API, use eureka in the right way, or it do have reached the uplimit of eureka itself?  What's the recommended/suitable refresh/hearbeat interval under 100s of thousands service instances?\nThanks,\nTao\n. ",
    "rfoltyns": "@killjason You can pass your own implementation of PropertiesInstanceConfig to the ApplicationManager. This implementation can override getHostName() and getIpAddress() in a way you want.\n. @killjason yeah, MyDataCenterInstanceConfig also extends this class\n. ",
    "mrvon2015": "How to avoid this waing?. ",
    "ayusun": "If it turns out to be valid, I can probably send a pull request, if required\nThough I am not sure, how the build is passing over here\n. Closing it, for some reason it passed in my another machine.\n. We don't have any example on how to use it? Can you share some, or guide us to some documents, so that it will be easier for us.\nThanks.\n. ",
    "deekshasharma": "Thanks for the reply!\nYes I am using http POST to send the registration payload via a Node JS eurekaClient.\nI got it what you are saying. We are anyways customizing the appName and port when sending the registration info. We can also do the same for instance-id. \nSo to resolve this issue we are currently providing a suffix to our service name like \n(myservice-port1, myservice-port2) and doing that resolves our issue even though the instance-id is same for all.\n. ",
    "shenpei1989": "I have the same error now,how did you solve? Can you give me a example of json? Thanks! @drse \nThere is no problem when use xml ,when I use json ,it give me this error message.\nI have found the problem,json should like this:\n{\n    \"instance\" :{\n    \"hostName\": \"myHost\",\n    \"app\": \"myApp\",\n    \"ipAddr\": \"127.0.0.1\",\n    \"port\": {\"$\": 8080,\"@enabled\": \"true\"},\n    \"securePort\": {\"$\": 433,\"@enabled\": \"false\"},\n    \"dataCenterInfo\": { \"name\": \"MyOwn\",\"@class\":\"com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo\" }\n    }\n}. ",
    "shenwenxin": "account same questions, hope get reply!. ",
    "Emmachen": "Hope the error message can be more readable! that would be very helpful. ",
    "csterwa": "Thank you for the response @qiangdavidliu. We are having difficulty thinking of use cases where virtual hostname and secure virtual hostname should have different non-null property values. Would you be able to point towards customer use cases where this is used?\n. ",
    "elnur": "I gave full EC2 profile permissions for Route53, EC2, and ASG just in case it could be a permission problem. But it didn't help.\n. Okay, it looks like it's intentional. The binder only looks for free domains. That doesn't make much sense though. Thanks to autoscaling, instances come and go but it'd be nice to have a fixed number of domains to have stable locations of Eureka instances. So if an instance a domain points to is long gone, this Route53 binder can't update the domain to point to a new Eureka instance.\n. Later, I've figured out that the Route53 binder unbinds itself from domain name on shutdown. But it was too late since I got it all working with EIP. \ud83d\ude42 \nThe EIP approach is more predictable here because an EIP gets released when an EC2 instance dies without a clean shutdown, and hence Eureka will assign an EIP to itself in any case. While the Route53 binder relies on proper shutdown to unbind itself.\n. ",
    "flamhaze5946": "Now I try to registerAppMetadata to achieve it, thanks\n. ",
    "arakelian": "@qiangdavidliu, Respectfully, you could still guard against cases likes like this, by making it the default setting, but still allow someone to configure it so that it doesn't load immediately. I'd be happy to submit a PR for this change if I thought that it would be merged.. Closing this as I'm currently not using Eureka. Thank you.. ",
    "jameskaron": "Could you tell me how you solved the problem?. ",
    "HansRA": "I had the same difficulty of registering services with spring mvc 4 with eureka but using the SIDECAR of spring I could solve it and be able to add the other components such as Ribbon, so you must create a spring-boot project to add the dependency of sidecar, then to the spring mvc project when deploying modify the port so that it leaves like this (example: localhost: 9090 / service1) also you must have a service that is \"health\" with this name that returns \"status: UP\" (localhost: 9090 / health), I found all this configuration in this project of which I was guided (https://github.com/BarathArivazhagan/spring-cloud-sidecar-sample)\nAlso the sidecar is independent of the language of the service only needs the service \"Health\" to be able to register it in eureka.Therefore you have a sidecar which listens to the project with spring mvc, the eureka escuha to the sidecar.In the repository of which I There is a complete description of how the components interact.. ",
    "muraliguttha": "Able to solve this problem. There are conflicts with libraries in WLS.\nAble to proceed after providing libraries details.\n. ",
    "silentFred": "@muraliguttha care to share some details? =). ",
    "lalitha7": "\nAble to solve this problem. There are conflicts with libraries in WLS.\nAble to proceed after providing libraries details.\n\n@muraliguttha could you please share what libraries did you fix to resolve the issue?. ",
    "klues": "created pull request for this issue\n. see https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ThreadPoolExecutor.html#shutdown() for effects of shutdown() and shutdownNow()\n. I built my own release containing this fix and we are using it in our project. I don't know why it is not being merged. If you need the release containing the fix and you don't want to build it on your own just contact me.. see https://github.com/klues/eureka/tree/jar-containing-memory-leak-fix/bin for my built release containing this fix. Its based on version 1.4.11. ",
    "pauldburton": "This solved the same issue in our shared tomcat environment is there any chance of it being merged?. ",
    "TatsianaKTV": "Hi @klues . If it possible give me please credentials for your eureka realise fix. Thanks.. @klues thanks.. ",
    "tianxiaoliang": "Also the heartbeat perf is 5w tps, it became 16w TPS after I open keep alive in tomcat,but register instance API perf is still 2k,and in response header there is no connection:keep-alive header.\nSo in server side,the register instance handler disabled keep alive? Why?. I found there is a lock in register method, that makes perf low and low cpu usage\uff0cwhy eureka lock before register a instance\uff1f\nprivate final Lock read = readWriteLock.readLock();. ",
    "qiukeren": "2K TPS is enough for most conditions.\nEven in alibaba, the registry center is far from 2K TPS.\n100 can be considered as a huge load.\n2K \u7684TPS\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u5df2\u7ecf\u591f\u4e86\u3002\n\u5373\u4fbf\u662f\u963f\u91cc\uff0c\u6ce8\u518c\u4e2d\u5fc3\u6bcf\u79d2\u4e5f\u4e0d\u4f1a\u6ce8\u518c2K\u4e2a\u5e94\u7528\u3002\u4e0a\u767e\u4e2a\u5c31\u5df2\u7ecf\u5f88\u591a\u4e86\u3002. ",
    "samdvr": "Each region is a geographical location in AWS, every region has multiple availability zone which are completely isolated from each other(Think of it as a separate datacenter)\nFor example U.S. East(Virginia) is one region with: us-east-1b, us-east-1c, us-east-1d availability zones. More info here . ",
    "eacdy": "@samdvr Got it.\nSeems that eureka can be deployed in different zones, so I wonder whether the picture I drew is right.. ",
    "jebeaudet": "I'd like some input as well, we had the same problem. @995270418L It's added automatically by the eureka client. We were using a custom UI that made ajax requests without the lastDirtyTimestamp parameter (it's optional).. @sangyuruo you might need https://github.com/Netflix/eureka/issues/933 as well for a complete fix for this issue.. Thanks for the quick feedback @qiangdavidliu, this is valuable information to me and many others that will end up here with a google search, I could not find any information about upgrades anywhere. Thanks again!. Sorry for the amended commits noise :). @qiangdavidliu Have you had the chance to give it a look? We're releasing this patch in our production environment soon and I'd sleep better if I had your green thumbs on it :wink: . @qiangdavidliu Did you get a chance to test it enough to remove the failguard of https://github.com/Netflix/eureka/commit/6f3f997d640c32b2d391f6555a5cdaa7cd66e7c0?. @qiangdavidliu Any info about that safeguard? Thanks!. Thanks for heads up, let me know if you find anything related to it. . @qiangdavidliu Did you encounter any problem with it in the end? Thanks for the feedback. @qiangdavidliu you should log the whole exception and not the message here, the e.getMessage() will not log nothing here as there is no {} attached to it. . ",
    "fredboutin": "Thanks for your answer, I guess this is our problem! When we put it out of service, we use this call manually (in a custom UI) : PUT /eureka/apps/{applicationId}/{instanceId}/status?value=UP and we are not specifying any lastDirtyTimestamp.. We corrected the way we call eureka by adding the lastDirtyTimestamp parameter, no version update was necessary.. ",
    "995270418L": "and how to specifying the lastDirtyTimestamp param or where add it into eureka client. ",
    "sangyuruo": "@fredboutin @jebeaudet  Which version has corrected this Issue? thanks!. @fredboutin @jebeaudet Thanks for your answer!. ",
    "cloudgc": "how did  you  resolve ,i hava same quesition. ",
    "asarkar": "@qiangdavidliu Thanks for your response. Not all my questions have been answered. If you read my blog, you'd have seen references to 2 tickets opened on Spring Cloud that're still open. For the sake of completion, if you could take the time to answer those, I think the blog will become more useful.\nspring-cloud-netflix#373\nspring-cloud-netflix#203\nAlso, I'm interested in knowing what are the improvements in Eureka you mentioned. We've moved to using Kubernetes service discovery from Eureka so I don't have a ready answer of what version we were previously using.. ",
    "erikgollot": "And some services are provided by the local information system and orher by the Group level information system. Oh yes thanks\nIt could be nice to add this capability into the annotation. I wiil see if I can investigate this. ",
    "shivamgoel": "Is there a work around ?. ",
    "jonbcs": "Any solutions here. Surely one can exclude logging the defaultZone URL's at least?. ",
    "ajayaks": "Would you please suggest or redirect me for the correct forum.. ",
    "rrpod": "Are you using a self-signed certificate? \nSince you are using Tomcat, ensure that you have assigned the keystore in the conf/server.xml file. \n(https://hutter.io/2016/02/09/java-create-self-signed-ssl-certificates-for-tomcat/)\nNext for the service which is registering to Eureka, it has to add the self-signed certificate to its truststore. If it is a java application, you can run it with -Djavax.net.ssl.trustStore parameter. \nYou can read (https://www.sslshopper.com/article-most-common-java-keytool-keystore-commands.html) to view the basic keytool commands required to create keystore & import certificates to a truststore. . ",
    "rqw": "Do I need to set the parameters when I use?\n. Hi @qiangdavidliu ,Thank you for your answer.\nI try last version.. ",
    "ericis": "Same issue here and using the latest from Spring Cloud. I have one Eureka server and two microservices, with one upstream from the other. When I use RestTemplate to call the other microservice, I get the same error referenced by spring-cloud/spring-cloud-netflix#1060. ",
    "lferna": "Same problem as @ericis and no news about the solution, thanks. Only change the log level?. ",
    "zenger380": "\u4e3a\u4ec0\u4e48\u6ce8\u518c\u4e00\u4e2a\u670d\u52a1\u8fd9\u4e48\u6162? (Why is it so Slow to Register a Service?)\nBeing an instance also involves a periodic heartbeat to the registry (via the client\u2019s serviceUrl) with default duration 30 seconds. A service is not available for discovery by clients until the instance, the server and the client all have the same metadata in their local cache (so it could take 3 heartbeats). You can change the period using eureka.instance.leaseRenewalIntervalInSeconds and this will speed up the process of getting clients connected to other services. In production it\u2019s probably better to stick with the default because there are some computations internally in the server that make assumptions about the lease renewal period.\n\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u4f8b\u5411\u6ce8\u518c\u4e2d\u5fc3\u8fd8\u5305\u62ec\u4e00\u4e2a\u9ed8\u8ba4\u6301\u7eed30\u79d2\u7684\u5468\u671f\u5fc3\u8df3(\u901a\u8fc7\u5ba2\u6237\u7684serviceUrl)\u3002\u4e00\u4e2a\u670d\u52a1\u5bf9\u4e8e\u5ba2\u6237\u7aef\u7684discovery\u4e0d\u53ef\u7528\u7684\uff0c\u76f4\u5230\u5b9e\u4f8b\u3001\u670d\u52a1\u7aef\u548c\u5ba2\u6237\u7aef\u5168\u90fd\u62e5\u6709\u76f8\u540c\u7684\u5143\u6570\u636e\u5728\u5b83\u4eec\u7684\u7f13\u5b58\u91cc\u9762\uff08\u8fd9\u53ef\u80fd\u8fd8\u9700\u89813\u6b21\u5fc3\u8df3\uff09\u3002\u4f60\u53ef\u4ee5\u6539\u53d8\u4f7f\u7528eureka.instance.leaseRenewalIntervalInSeconds\u5e76\u4e14\u8fd9\u5c06\u52a0\u5feb\u8fd9\u4e00\u8fdb\u7a0b\u7684\u5ba2\u6237\u7aef\u8fde\u63a5\u5230\u5176\u4ed6\u670d\u52a1\u3002\u5728\u5b9e\u9645\u751f\u4ea7\u4e2d\u575a\u6301\u9ed8\u8ba4\u53ef\u80fd\u662f\u66f4\u597d\u7684\uff0c\u56e0\u4e3a\u6709\u4e00\u4e9b\u5728\u670d\u52a1\u5668\u5185\u90e8\u8ba1\u7b97\u5bf9\u79df\u8d41\u590d\u5174\u65f6\u671f\u505a\u51fa\u5047\u8bbe\u3002. ",
    "bingge1": "Thanks for Everybody , i add the retry to the application ,is ok. ",
    "jaychang9": "@zenger380  @qiangdavidliu \n\u610f\u601d\u662f\u8bf4\u670d\u52a1\u63d0\u4f9b\u65b9\u3001\u670d\u52a1\u8c03\u7528\u65b9\u3001eureka\u670d\u52a1\u4e09\u65b9\u7f13\u5b58\u4e2d\u90fd\u6709\u4e86\u76f8\u540c\u7684\u5143\u6570\u636e\uff08\u5e94\u8be5\u5c31\u662f\u670d\u52a1\u63d0\u4f9b\u65b9\u5730\u5740\u3001\u7aef\u53e3\u53f7\u3001\u53ca\u63a5\u53e3\u5217\u8868\u4fe1\u606f\uff09\uff0c\u624d\u8ba4\u4e3a\u670d\u52a1\u88ab\u6ce8\u518c\u4e86\u5417\uff1f\u4f46\u597d\u50cf\u8fd8\u662f\u6ca1\u6709\u89e3\u91ca\u4e3a\u4ec0\u4e48\u662f3\u6b21\u5fc3\u8df3\uff0c\u8fd8\u6709\u54ea\u4e2a\u9700\u89813\u6b21\u5fc3\u8df3\uff08\u670d\u52a1\u63d0\u4f9b\u65b9\uff1f\u8fd8\u662f\u670d\u52a1\u8c03\u7528\u65b9\uff1f\u8fd8\u662feureka\u6ce8\u518c\u4e2d\u5fc3\u670d\u52a1\uff09. @bingge1 How do you understand this problem?Can you describe it . ",
    "applelight": "Thank you for the answer, on my side, I was able (in a small testing env.) to set RAM and CPU to 1GB ans 1 CPU utilisation without any problem. Just under that seem`s to be problematic. \nThank you again.. ",
    "haripalpatil": "Thanks,\nWe are trying to use  Netflix Eureka as a service registry to register our services on Pivotal Cloud Foundry. Not sure which is correct place to ask this question.\nYes agree Eureka has metadata information but it does not expose the REST API level detail for individual service in metadata. \nIt contain detail such as \"registrar_uri\", \"instanceId\", \"zone\" etc those are mostly the service registry detail and not the service level detail.\nThe 'photo-service' is just an example. Yes client should be aware of the service but just looking for option to dynamically identify the service API from registry and call the API, if possible.. Thanks Spencer for confirmation !!\nHi All - Request to please update here, if anyone is aware of any other way/tool to dynamically call API other than eureka on PCF, or else will close this issue in few days. Thanks all in advance.. ",
    "ugofc81": "I am facing the same issue, with same stack trace and error message. Apparently the services keep being registered with Eureka even after the connection failure, but we were not yet able to exclude any data loss because of this error.. ",
    "kosurusekhar": "@qiangdavidliu Thanks for the reply,  is there any compatible issues? We are using Eureka Client 1.4.9 and 1.6.x in some services.  Please let me know what is compatible version of server. \nIf we have compatible issues then it should not register at all right? we are seeing that our services are registering and working for 20-30 days, then we are seeing these kind of heartbeat errors and disconnect with eureka. Once we got into this then we have to reboot the instance to get back normal. Is there any config or something to reconnect automatically after some retries of failure heart beats?\nThanks.\n. ",
    "goatherder": "I also see this issue with newer spring clients and old eureka servers.  Seems to be due to 404's returning Content-Type: text/html (not handled) vs Content-Type: application/xml (this is OK).\neg:  from a 1.1.147 & 1.1.159  (note: currently upgrading these - but trying to find a suitable version to step up to without causing impact) - we get responses:\n\nGET /eureka/v2/apps/TEST/i-ababababa HTTP/1.1\nHost: ................\nUser-Agent: curl/7.51.0\nAccept:application/json\n< HTTP/1.1 404 Not Found\n< Server: Apache-Coyote/1.1\n< Content-Type: text/html;charset=utf-8\n< Content-Language: en\n< Content-Length: 985\n\nWhich result in the OP's exceptions (and hence - the service will never re-register.  We have to restart the client).\nWhere-as on a 1.6.2 server - we get:\n\nGET /eureka/v2/apps/TEST/i-abababababa HTTP/1.1\nHost: ..................\nUser-Agent: curl/7.51.0\nAccept: /\n< HTTP/1.1 404 Not Found\n< Server: Apache-Coyote/1.1\n< Vary: Accept-Encoding\n< Content-Type: application/xml\n< Content-Length: 0\n. \n",
    "GerardMasip": "Facing the same problem, any news on this issue?. ",
    "JavierOrtuno": "What about the issue?. ",
    "svoeller99": "we're also facing this issue - any update?. ",
    "ssozonoff": "Any updates ?. ",
    "yzs2008": "eureka client 1.4.6, server 1.1.1 do not have this problem.. ",
    "LionsWang": "we're also facing this issue - Edgware.SR2. spring cloud version:Edgware.SR2. ",
    "aperhaite": "I think it's a compatibility issue between client and server. Based on their documentation it's always safer to have the servers be on a newer version than clients.\nReference:\nhttps://github.com/Netflix/eureka/wiki/Configuring-Eureka#clientserver-version-compatibility. ",
    "cptstffn": "We facing the same error. We use Edgware.SR2 as well. Has anyone new Infos?\nI can reproduce the error with our new Release (Update from Dalston.SR5 to Edgware.SR3.) in the Cloud and also Local. \n\nTest One:\n- Eureka Server (Edgeware.SR3) \n- ServiceA (Edgeware.SR3) \nTest-Steps:\n--> Step One: First Start (order is not important): Everything works well. ServiceA register itself at eureka. heartbeat is send.\n--> Step Two: Re-Start Eureka. ServiceA can't register again and always gets a 404. \n\nSecond Test (Went back to our last Release). \n- Eureka Server (Still Edgeware.SR3 for testing). \n- ServiceA back to Dalston.SR5. (spring-cloud-starter-netflix-eureka-client in Version 1.4.0.RELEASE)\n- ServiceB (Still with Edgeware.SR3 for negativ Test)\nTest-Steps:\n--> Reproduce Step One. Everything works.\n-->Reproduce Step Two. After the Restart: ServiceA with Dalston.SR5 can successful register \n again. ServiceB with Edgware still faces the problem.\n\nSo i came to the conclusion that it's a bug or I'm missing a new configuration detail in Edgware? \nIt's super strange, but it looks like we need to downgrade to our last release. \n@ryanjbaxter Maybe you have a hpt tip for us? . Really can't see a difference. I will take a deeper look. . I found the problem. It's a fault in our pom configuration. There was a exclusion for jersey-client and apache client4. I really don't know why it's there. I will do some research to understand why they excluded it. Sorry that I didn't saw that earlier. My apologize. . https://eureka-url/eureka/status\nStill returns (with  Accept Application/JSON) HTTP Status: 200 but as body: \nExpected ',' instead of ''\nhttps://eureka-url/eureka/apps\ninstead is able to return the content as a valid json. \nIs number one a misconfiguration from us or a common problem? \n. Any news?. ",
    "ryanjbaxter": "This doesnt seem to be a Spring issue, it appears from the comments above that it is a compatibility issue between the Eureka client and server.\n@qiangdavidliu did you ever look into this?. @qiangdavidliu yes those versions are correct.. @bsushant-athena this repo is for Netflix Eureka not for Spring Cloud Eureka.  If you believe there is a problem with Spring Cloud, please open an issue here https://github.com/spring-cloud/spring-cloud-netflix. The same problem does not show up when you look at the XML response. Awesome thanks, I will bump the version in Spring Cloud Netflix.. @qiangdavidliu We are using Eureka 1.9 but I can still reproduce this. @spencergibb I think this will fix https://github.com/spring-cloud/spring-cloud-netflix/issues/2941, do you agree?. Looks good \ud83d\udc4d . ",
    "youtianhong": "I also met this issue. I did not find anything wrong config with jersey in pom.xml.  Would you help me to fix it please?\nMy issue is randomly happened.\nWhen I stop the eureka server and then  restart the server, the server A can not re-registered success.\nThe error follow below here:(It will retry send heart beat intervaly 30 secs by default)\n2018-10-11 10:45:57,198 [DiscoveryClient-HeartbeatExecutor-0] ERROR c.n.d.s.t.d.RedirectingEurekaHttpClient - Request execution error\ncom.sun.jersey.api.client.ClientHandlerException: A message body reader for Java class com.netflix.appinfo.InstanceInfo, and Java type class com.netflix.appinfo.InstanceInfo, and MIME media type text/html was not found\n        at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:630)\n        at com.sun.jersey.api.client.ClientResponse.getEntity(ClientResponse.java:586)\n        at com.netflix.discovery.shared.transport.jersey.AbstractJerseyEurekaHttpClient.sendHeartBeat(AbstractJerseyEurekaHttpClient.java:105)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n        at com.netflix.discovery.shared.transport.decorator.MetricsCollectingEurekaHttpClient.execute(MetricsCollectingEurekaHttpClient.java:73)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n        at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.executeOnNewServer(RedirectingEurekaHttpClient.java:118)\n        at com.netflix.discovery.shared.transport.decorator.RedirectingEurekaHttpClient.execute(RedirectingEurekaHttpClient.java:79)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n        at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:119)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n        at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n        at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:824)\n        at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1393)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n2018-10-11 10:45:57,199 [DiscoveryClient-HeartbeatExecutor-0] WARN  c.n.d.s.t.d.RetryableEurekaHttpClient - Request execution failed with message: A message body reader for Java class com.netflix.appinfo.InstanceInfo, and Java type class com.netflix.appinfo.InstanceInfo, and MIME media type text/html was not found\n2018-10-11 10:45:57,199 [DiscoveryClient-HeartbeatExecutor-0] ERROR c.n.d.DiscoveryClient - DiscoveryClient_OSM-ADMIN/10.132.81.36:osm-admin:8082 - was unable to send heartbeat!\ncom.netflix.discovery.shared.transport.TransportException: Cannot execute request on any known server\n        at com.netflix.discovery.shared.transport.decorator.RetryableEurekaHttpClient.execute(RetryableEurekaHttpClient.java:111)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator$3.execute(EurekaHttpClientDecorator.java:92)\n        at com.netflix.discovery.shared.transport.decorator.SessionedEurekaHttpClient.execute(SessionedEurekaHttpClient.java:77)\n        at com.netflix.discovery.shared.transport.decorator.EurekaHttpClientDecorator.sendHeartBeat(EurekaHttpClientDecorator.java:89)\n        at com.netflix.discovery.DiscoveryClient.renew(DiscoveryClient.java:824)\n        at com.netflix.discovery.DiscoveryClient$HeartbeatThread.run(DiscoveryClient.java:1393)\n        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n        at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n        at java.lang.Thread.run(Thread.java:745)\n. @bsushant-athena  Not sure your issue whether as same as me.\nMy issue had been fixed. The issue is caused by wrong nginx configuration of eureka url.\nOur nginx configuration will encapsulate 500,502 error as 404.\nIt works after removing this ngx config for eureka server url.\n. I also met this issue. Why did you close it? Do you have anything updates? Thanks a lot.. > I'm facing the same issue. Any updates? thanks\nMy issue had been fixed. The issue is caused by wrong nginx configuration of eureka url.\nOur nginx configuration will encapsulate 500,502 error as 404.\nIt works fine after removing this ngx config for eureka server url.\nYou can refer to  my question https://github.com/Netflix/eureka/issues/1130. @arpanagr Is there any other solution ? If there are many services registered in eureka server, we can not demand all services of client to restart,this is a very bad way.. My issue had been fixed. The issue is caused by wrong nginx configuration of eureka url.\nOur nginx configuration will encapsulate 500,502 error as 404.\nIt works fine after removing this ngx config for eureka server url.. ",
    "mgddp": "@pktippa Where you able to get any solution to this ? . ",
    "aasthasmile": "I am stuck at the same point. Eureka Server is registered on Pivotal Cloud Foundry and services are registered there but I am not able to find services in the client using @DiscoveryClient from Cloud services. If you were able to solve this issue ,please mention a version of your solution??. ",
    "KonradEichstaedt": "Hi Erik, \nyes we did this several times. Using Google to produce the client like this: \n@Produces\n  public EurekaClient getEurekaClient() {\n    if (client == null) {\n      synchronized (lock) {\n        if (client == null) {\n          Injector injector =\n              Guice.createInjector(Modules.override(new EurekaModule()).with(new AbstractModule() {\n            /*\n             * Overriding the default inject because using the lokal Config instead of AWS\n             * Config\n             */\n\n            @Override\n            protected void configure() {\n\n              bind(EurekaInstanceConfig.class)\n                  .toProvider(MyDataCenterInstanceConfigProvider.class).in(Scopes.SINGLETON);\n\n              bind(EurekaClientConfig.class).toProvider(DefaultEurekaClientConfigProvider.class)\n                  .in(Scopes.SINGLETON);\n\n              // this is the self instanceInfo used for registration purposes\n              bind(InstanceInfo.class).toProvider(EurekaConfigBasedInstanceInfoProvider.class)\n                  .in(Scopes.SINGLETON);\n\n              bind(EurekaClient.class).to(DiscoveryClient.class).in(Scopes.SINGLETON);\n\n            }\n          }));\n\n      client = injector.getInstance(EurekaClient.class);\n      ApplicationInfoManager.getInstance().setInstanceStatus(InstanceStatus.UP);\n    }\n  }\n}\n\nreturn client;\n\n}. you need this dependencies: \n\ncom.google.inject\nguice\n4.1.0\n\n    <dependency>\n        <groupId>com.google.guava</groupId>\n        <artifactId>guava</artifactId>\n        <version>21.0</version>\n    </dependency>\n\n    <dependency>\n        <groupId>org.apache.httpcomponents</groupId>\n        <artifactId>httpclient</artifactId>\n        <version>4.5.2</version>\n    </dependency>\n\n    <dependency>\n        <groupId>com.netflix.eureka</groupId>\n        <artifactId>eureka-client</artifactId>\n        <version>1.6.2</version>\n    </dependency>.\n",
    "m-a-l-p": "Hi,\nI have the same case. I need to implement a EurekaClient for our JAX-RS rest endpoints. I'm assuming that this is how i would be able to do it as well, is that right?\nMay I know why Guice is needed? is it the one that would handle the maintenance/lifecyle of the EurekaClient singleton? What about netflix.governator?\nIs there a need to handle the shutting down of EurekaClient singleton anywhere in the jersey?\nBy the way, i tried this and i got a warning that ApplicationInfoManager.getInstance() is already deprecated and the javadocs suggests to use DI.\nMany thanks,\nToni\n. ",
    "smkb80": "Hi @qiangdavidliu,\nThere is no other transitive dependency on jackson version 2.8.3.. Hi @qiangdavidliu ,\neureka-client 1.6.2 got built using  jackson-annotations 2.5.4. Setting eureka.registration.enabled=false for the composite service stopped an unknown service getting registered.. ",
    "maximkir": "No, I just inspected the tread pools that created by the discovery client and their roles. The fixed value catch my eye with comparison to other pools. \nA comment that explains the fixed value can be nice for future readers.. ",
    "kenttanl": "o....  sorry.... embarrassed....  :laughing:. Has been solved, see https://github.com/spring-cloud/spring-cloud-netflix/issues/1905. SEE THIS https://github.com/spring-cloud/spring-cloud-netflix/issues/1905. ",
    "hkharikrishnan857": "the above url showing error page kenttanl. ",
    "afilichkin": "Let me summarize this stuff.\nSo, Eureka works fine with AWS ESC if we have static Docker port. We just need expose this port then Eureka can resolve AWS host using AmazonInfo (http://cloud.spring.io/spring-cloud-netflix/spring-cloud-netflix.html#_using_eureka_on_aws)\nBut Eureka doesn\u2019t help you if you want to use ECS autoscalling feature.\nActually, we can use Eureka with ECS(autoscalling) and Docker only with Docker network host (docker run --net=host). But this approach is not good. For Kubernetes it\u2019s OK, because each Docker image is isolated in Pod(some Kubernetes expert mentioned that they are going to remove Eureka, because Kubernetes itself can do all this stuff).\nCurrently, it\u2019s not possible to run Eureka with ECS if you need dynamic Docker port. Amazon ECS agent doesn\u2019t support it yet( https://github.com/aws/amazon-ecs-agent/issues/151)\n. ",
    "DirkLachowski": "We have solved that by enabling the docker rest api on the ecs host. You can then create an introspector that asks the docker daemon on the host for the port mapping and use that info in a custom  Eureka instance config bean.. ",
    "bhanu-singh": "please read article at https://medium.com/@bhanu.pratap/service-discovery-in-spring-cloud-using-netflix-eureka-in-aws-fargate-2c5c294fee5c\n. ",
    "shmulika": "Hi @wimnat, did you follow up on this and got an answer?\nHope I'm not contaminating this forum. Hi @wimnat and @qiangdavidliu , I think something is missing in the solution and I think it might still be related to Netflix/eureka original code/compatibility.\nIn order for Spring Netflix Eureka to return isAws true and bind to an EIP it seems to require this bean configured (as seen on several posts e.g. https://github.com/spring-cloud/spring-cloud-netflix/issues/102):\n@Bean\n    public EurekaInstanceConfigBean eurekaInstanceConfigBean(InetUtils inetUtils) {\n        EurekaInstanceConfigBean b = new EurekaInstanceConfigBean(inetUtils);\n        AmazonInfo info = AmazonInfo.Builder.newBuilder().autoBuild(\"eureka\");\n        b.setDataCenterInfo(info);\n        return b;\n    }\nThis seemingly works nicely, isAws=true and the instance binds to the EIP. However, it does not take into consideration that the publicIpv4 address changes and enters a buggy state.\nThe instance still remembers the previous publicIpv4 address when checking if EIP is bound:\nThe function isEIPBound() at https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/aws/EIPManager.java returns false (because it checks against the previous ipv4 address prior to the eip binding) and causes the registry to be cleared. This happens periodically at whatever interval EIP binding is checked.\nIf I restart the instance everythings starts working OK (because the instance has no state of the previous ipv4 adress).\nIf I understand correctly this is the result of the EurekaInstanceConfigBean and the DataCenterInfo being static.\n@wimnat  - did you encounter this also?\n@qiangdavidliu - I assume Eureka can be made to detect AWS and learn the IPv4 including changes without this configuration? Or is this not part of the open source project?\nThanks!. Sorry for not being clear enough - I AM using EIPs. But the very first time the instance comes up, the EC2 is still not bound to the EIP (it has some random IPv4 address until Eureka performs the binding to the EIP). \nHowever, it is the first time that counts.... Please have a look at how it behaves on the first run (after once initially binding the EIP):\n2017-06-15 14:05:46.528  INFO 1443 --- [ureka-EIPBinder] com.netflix.eureka.aws.EIPManager        : My instance i-07a576cc81e58c0d3 seems to be already associated with the EIP 34.209.218.21\n2017-06-15 14:06:46.312  INFO 1443 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-15 14:06:46.529  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node\n2017-06-15 14:06:46.529  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1\n2017-06-15 14:06:46.529  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP\n2017-06-15 14:06:46.672  INFO 1443 --- [ureka-EIPBinder] com.netflix.eureka.aws.EIPManager        : My instance i-07a576cc81e58c0d3 seems to be already associated with the EIP 34.209.218.21\n2017-06-15 14:07:46.529  INFO 1443 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-15 14:07:46.673  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node\n2017-06-15 14:07:46.673  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1\n2017-06-15 14:07:46.673  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP\n2017-06-15 14:07:46.738  INFO 1443 --- [ureka-EIPBinder] com.netflix.eureka.aws.EIPManager        : My instance i-07a576cc81e58c0d3 seems to be already associated with the EIP 34.209.218.21\n2017-06-15 14:08:46.674  INFO 1443 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-15 14:08:46.739  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node\n2017-06-15 14:08:46.739  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1\n2017-06-15 14:08:46.739  INFO 1443 --- [ureka-EIPBinder] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP\nThis might look OK, but actually everytime this repeats the registry is completely cleared.\nIf I manually restart the Eureka instance (where EIP is already bounded by previous run), the log looks like this:\n2017-06-14 11:47:10.019  INFO 4639 --- [ureka-EIPBinder] com.netflix.eureka.aws.EIPManager        : My instance i-0fa10ad77743e213a seems to be already associated with the public ip 34.209.218.21\n2017-06-14 11:47:10.025  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:48:10.025  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:49:10.025  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:50:10.025  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:51:10.026  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:52:10.020  INFO 4639 --- [ureka-EIPBinder] com.netflix.eureka.aws.EIPManager        : My instance i-0fa10ad77743e213a seems to be already associated with the public ip 34.209.218.21\n2017-06-14 11:52:10.026  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:53:10.026  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:54:10.027  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:55:10.027  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:56:10.027  INFO 4639 --- [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms\n2017-06-14 11:57:10.020  INFO 4639 --- [ureka-EIPBinder] com.netflix.eureka.aws.EIPManager        : My instance i-0fa10ad77743e213a seems to be already associated with the public ip 34.209.218.21\n(Please don't put any order meaning to the dates, June 14th vs 15th, I've tested it many times over these are just the copy-pastes I've made)\nThe message from EIPBinder looks very similar, by indeed the first one reveals that the instance fails to verify that it's public ip is the same as the desired EIP; but then when trying to re-bind the EIP discovers that it is already bound.... Hi,\nAfter many Googling I've found a thread dealing with this exact issue:\nhttps://github.com/spring-cloud/spring-cloud-netflix/issues/1321\nThanks for the assist this far\n. ",
    "wimnat": "@shmulika - i posted an answer on the SO post. I did not encounter this issue because I'm using an EIP. EIPs do not change. This is what the documentation states to do. Is there a particular reason you're not using an EIP?. Of course. A starting instance will not start with a bound EIP. Don't worry\nthough. The EIP will bound before Eureka starts.\nOn 18 Jun. 2017 6:38 pm, \"shmulika\" notifications@github.com wrote:\n\nSorry for not being clear enough - I AM using EIPs. But the very first\ntime the instance comes up, the EC2 is still not bound to the EIP (it has\nsome random IPv4 address until Eureka performs the binding to the EIP).\nHowever, it is the first time that counts...\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/Netflix/eureka/issues/942#issuecomment-309264459, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AHFORm-JRxK87hUF0lpfEERFzE2En9Lnks5sFOH-gaJpZM4NbD63\n.\n. \n",
    "leiy88": "@qiangdavidliu \nFor example:\nRequest URL:http://localhost:8761/eureka/apps\nRequest Method:GET\nStatus Code:200 \nRemote Address:[::1]:8761\nRequest URL:http://localhost:8761/eureka/v2/apps\nRequest Method:GET\nStatus Code:404 \nRemote Address:[::1]:8761. ",
    "kingschan1204": "mark. ",
    "HaoChou": "mark. ",
    "cherrishccl": "mark. ",
    "hao0111": "sorry,i got it!thank you. ",
    "thank037": "953 Hello @zkwentz .",
    "nageshever": "Hi, can I make correction to this documentation? Please let me know. ",
    "Lovett1991": "After looking through source, I have found that eureka does effectively have a delayed event so updates are grouped before being replicated.\nIs it possible to have this documented, as well as what the effects of reducing the number of workers for replication will have?. ",
    "harishkadamudi": "When setup in cluster, somehow Eureka will share registered services information with each other,\neven if services are registered with only one Eureka Instance.. ",
    "borlafu": "+1: Makes sense. Had to modify the tests as the exception thrown is different to the one from the workaround.\n. ",
    "brokenjpl": "@spencergibb Thanks for replying. I believe that my issue is with programmatically registering my service to Eureka, specifically with the ServiceDiscoveryManager. If you believe the issue lies with spring-cloud-netflix, then I can close this issue and re-open there.. ",
    "timbozo": "If you're still facing this issue, the above comment is correct.  spring-cloud-netflix is the best place to get support.  I'll close this issue, and if you are unable to resolve with spring-cloud-netflix, please feel free to re-open.. Thanks for letting us know you've resolved your issue!. ",
    "luzhiming": "Hi, I have the same problem , is this a bug?. ",
    "flyhero": "I wrote it like this\uff1a\n{\n    \"instance\": {\n        \"instanceId\":\"192.168.0.102:qrcode-service:8990\",\n        \"hostName\": \"192.168.0.102\",\n        \"app\": \"QRCODE-SERVICE\",\n        \"vipAddress\": \"qrcode-service\",\n        \"secureVipAddress\": \"qrcode-service\",\n        \"ipAddr\": \"192.168.0.102\",\n        \"status\": \"UP\",\n        \"port\": {\"$\": \"8990\", \"@enabled\": \"true\"},\n        \"securePort\": {\"$\": \"443\", \"@enabled\": \"true\"},\n        \"healthCheckUrl\": \"http://192.168.0.102:8990/health\",\n        \"statusPageUrl\": \"http://192.168.0.102:8990/info\",\n        \"homePageUrl\": \"http://192.168.0.102:8990\",\n        \"dataCenterInfo\": {\n            \"@class\": \"com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo\", \n            \"name\": \"MyOwn\"\n        }\n    }\n}. you need to change here :  \"securePort\": {\"$\": \"443\", \"@enabled\": \"false\"}. ",
    "Z-starts": "@flyhero its error:\n{\n    \"error\": \"cannot parse request body\"\n}. \"dataCenterInfo\": {\n      \"@class\": \"com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo\",\n      \"name\": \"MyOwn\"\n    }\nand how to add metadata with json. @flyhero . ",
    "junneyang": "anyone has solved yet? thanks. this works for me\n```\n{\n    \"instance\": {\n        \"instanceId\": \"192.168.0.1:plugin-test-aaa-service:80\",\n        \"hostName\": \"192.168.0.1\",\n        \"app\": \"plugin-test-aaa-service\",\n        \"ipAddr\": \"192.168.0.1\",\n        \"vipAddress\": \"plugin-test-aaa-service\",\n        \"status\": \"UP\",\n        \"port\": {\n            \"$\": 80,\n            \"@enabled\": True,\n    },\n    \"securePort\": {\n        \"$\": 443,\n        \"@enabled\": False,\n\n    },\n    \"homePageUrl\": None,\n    \"statusPageUrl\": \"http://192.168.0.1:80/plugin-test/aaa-service/hello\",\n    \"healthCheckUrl\": None,\n    \"dataCenterInfo\": {\n        \"@class\": \"com.netflix.appinfo.MyDataCenterInfo\",\n        \"name\": \"MyOwn\"\n    },\n    'leaseInfo': {\n        'renewalIntervalInSecs': 15,\n        'durationInSecs': 60\n    }\n}\n\n}\n```. ",
    "mrcnc": "Try removing the v2. ",
    "tietang": "GET http://localhost:8761/eureka/apps. ",
    "jingege": "PR #974 . @qiangdavidliu Thx for your advice. I updated the PR.. @qiangdavidliu Very sorry for not responding this issue so long. I was so busy these days and missed the notification. @abracadv8 Thank you very much for finishing this PR.. ",
    "abracadv8": "@qiangdavidliu - This user has not been active since this pull request.  I created a second pull request based on their work #1023 - Can you review that?. ",
    "pkwenda": "i have same error log:\n```log\norg.gradle.api.ProjectConfigurationException: A problem occurred configuring root project 'eureka'.\n    at org.gradle.configuration.project.LifecycleProjectEvaluator.addConfigurationFailure(LifecycleProjectEvaluator.java:79)\n    at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:57)\n    at org.gradle.api.internal.project.AbstractProject.evaluate(AbstractProject.java:510)\n    at org.gradle.api.internal.project.AbstractProject.evaluate(AbstractProject.java:90)\n    at org.gradle.execution.TaskPathProjectEvaluator.configureHierarchy(TaskPathProjectEvaluator.java:42)\n    at org.gradle.configuration.DefaultBuildConfigurer.configure(DefaultBuildConfigurer.java:35)\n    at org.gradle.initialization.DefaultGradleLauncher$2.run(DefaultGradleLauncher.java:125)\n    at org.gradle.internal.Factories$1.create(Factories.java:22)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:52)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:122)\n    at org.gradle.initialization.DefaultGradleLauncher.access$200(DefaultGradleLauncher.java:32)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:99)\n    at org.gradle.initialization.DefaultGradleLauncher$1.create(DefaultGradleLauncher.java:93)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:90)\n    at org.gradle.internal.progress.DefaultBuildOperationExecutor.run(DefaultBuildOperationExecutor.java:62)\n    at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:93)\n    at org.gradle.initialization.DefaultGradleLauncher.getBuildAnalysis(DefaultGradleLauncher.java:87)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter$DefaultBuildController.configure(InProcessBuildActionExecuter.java:102)\n    at org.gradle.tooling.internal.provider.runner.ClientProvidedBuildActionRunner.run(ClientProvidedBuildActionRunner.java:45)\n    at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\n    at org.gradle.tooling.internal.provider.runner.SubscribableBuildActionRunner.run(SubscribableBuildActionRunner.java:58)\n    at org.gradle.launcher.exec.ChainingBuildActionRunner.run(ChainingBuildActionRunner.java:35)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:43)\n    at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:28)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:78)\n    at org.gradle.launcher.exec.ContinuousBuildActionExecuter.execute(ContinuousBuildActionExecuter.java:48)\n    at org.gradle.launcher.daemon.server.exec.ExecuteBuild.doBuild(ExecuteBuild.java:52)\n    at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.WatchForDisconnection.execute(WatchForDisconnection.java:37)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.ResetDeprecationLogger.execute(ResetDeprecationLogger.java:26)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.RequestStopIfSingleUsedDaemon.execute(RequestStopIfSingleUsedDaemon.java:34)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:74)\n    at org.gradle.launcher.daemon.server.exec.ForwardClientInput$2.call(ForwardClientInput.java:72)\n    at org.gradle.util.Swapper.swap(Swapper.java:38)\n    at org.gradle.launcher.daemon.server.exec.ForwardClientInput.execute(ForwardClientInput.java:72)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.health.DaemonHealthTracker.execute(DaemonHealthTracker.java:47)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.LogToClient.doBuild(LogToClient.java:66)\n    at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.EstablishBuildEnvironment.doBuild(EstablishBuildEnvironment.java:72)\n    at org.gradle.launcher.daemon.server.exec.BuildCommandOnly.execute(BuildCommandOnly.java:36)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.health.HintGCAfterBuild.execute(HintGCAfterBuild.java:41)\n    at org.gradle.launcher.daemon.server.api.DaemonCommandExecution.proceed(DaemonCommandExecution.java:120)\n    at org.gradle.launcher.daemon.server.exec.StartBuildOrRespondWithBusy$1.run(StartBuildOrRespondWithBusy.java:50)\n    at org.gradle.launcher.daemon.server.DaemonStateCoordinator$1.run(DaemonStateCoordinator.java:246)\n    at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54)\n    at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: org.gradle.internal.exceptions.LocationAwareException: Build file '/Users/zhuang/Desktop/git-company/eureka/build.gradle' line: 15\nError resolving plugin [id: 'nebula.netflixoss', version: '3.6.0']\n    at org.gradle.plugin.use.internal.DefaultPluginRequestApplicator.resolveToFoundResult(DefaultPluginRequestApplicator.java:190)\n    at org.gradle.plugin.use.internal.DefaultPluginRequestApplicator.access$000(DefaultPluginRequestApplicator.java:44)\n    at org.gradle.plugin.use.internal.DefaultPluginRequestApplicator$1.transform(DefaultPluginRequestApplicator.java:67)\n    at org.gradle.plugin.use.internal.DefaultPluginRequestApplicator$1.transform(DefaultPluginRequestApplicator.java:65)\n    at org.gradle.util.CollectionUtils.collect(CollectionUtils.java:160)\n    at org.gradle.util.CollectionUtils.collect(CollectionUtils.java:155)\n    at org.gradle.plugin.use.internal.DefaultPluginRequestApplicator.applyPlugins(DefaultPluginRequestApplicator.java:65)\n    at org.gradle.configuration.DefaultScriptPluginFactory$ScriptPluginImpl.apply(DefaultScriptPluginFactory.java:126)\n    at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:38)\n    at org.gradle.configuration.project.BuildScriptProcessor.execute(BuildScriptProcessor.java:25)\n    at org.gradle.configuration.project.ConfigureActionsProjectEvaluator.evaluate(ConfigureActionsProjectEvaluator.java:34)\n    at org.gradle.configuration.project.LifecycleProjectEvaluator.evaluate(LifecycleProjectEvaluator.java:55)\n    ... 56 more\nCaused by: org.gradle.api.GradleException: Error resolving plugin [id: 'nebula.netflixoss', version: '3.6.0']\n    ... 68 more\nCaused by: org.gradle.api.GradleException: Plugin cannot be resolved from https://plugins.gradle.org/api/gradle because Gradle is running in offline mode\n    at org.gradle.plugin.use.resolve.service.internal.OfflinePluginResolutionServiceClient.queryPluginMetadata(OfflinePluginResolutionServiceClient.java:26)\n    at org.gradle.plugin.use.resolve.service.internal.PersistentCachingPluginResolutionServiceClient$1.create(PersistentCachingPluginResolutionServiceClient.java:60)\n    at org.gradle.plugin.use.resolve.service.internal.PersistentCachingPluginResolutionServiceClient$1.create(PersistentCachingPluginResolutionServiceClient.java:58)\n    at org.gradle.plugin.use.resolve.service.internal.PersistentCachingPluginResolutionServiceClient.fetch(PersistentCachingPluginResolutionServiceClient.java:110)\n    at org.gradle.plugin.use.resolve.service.internal.PersistentCachingPluginResolutionServiceClient.maybeFetch(PersistentCachingPluginResolutionServiceClient.java:103)\n    at org.gradle.plugin.use.resolve.service.internal.PersistentCachingPluginResolutionServiceClient.maybeFetch(PersistentCachingPluginResolutionServiceClient.java:91)\n    at org.gradle.plugin.use.resolve.service.internal.PersistentCachingPluginResolutionServiceClient.queryPluginMetadata(PersistentCachingPluginResolutionServiceClient.java:67)\n    at org.gradle.plugin.use.resolve.service.internal.InMemoryCachingPluginResolutionServiceClient$1.create(InMemoryCachingPluginResolutionServiceClient.java:47)\n    at org.gradle.plugin.use.resolve.service.internal.InMemoryCachingPluginResolutionServiceClient$1.create(InMemoryCachingPluginResolutionServiceClient.java:45)\n    at org.gradle.plugin.use.resolve.service.internal.InMemoryCachingPluginResolutionServiceClient.getResponse(InMemoryCachingPluginResolutionServiceClient.java:76)\n    at org.gradle.plugin.use.resolve.service.internal.InMemoryCachingPluginResolutionServiceClient.queryPluginMetadata(InMemoryCachingPluginResolutionServiceClient.java:42)\n    at org.gradle.plugin.use.resolve.service.internal.DeprecationListeningPluginResolutionServiceClient.queryPluginMetadata(DeprecationListeningPluginResolutionServiceClient.java:48)\n    at org.gradle.plugin.use.resolve.service.internal.PluginResolutionServiceResolver.resolve(PluginResolutionServiceResolver.java:84)\n    at org.gradle.plugin.use.resolve.internal.CompositePluginResolver.resolve(CompositePluginResolver.java:33)\n    at org.gradle.plugin.use.resolve.internal.NotNonCorePluginOnClasspathCheckPluginResolver.resolve(NotNonCorePluginOnClasspathCheckPluginResolver.java:42)\n    at org.gradle.plugin.use.internal.DefaultPluginRequestApplicator.resolveToFoundResult(DefaultPluginRequestApplicator.java:188)\n    ... 67 more\n```. ",
    "skyesx": "here's a relative pull request #1031. It didn't happen in our product environment.But it had  happen in our stress and develop environment.It's going to happen when 2K or more instances are registed in stress environment.In our develop environment , it happened once,  with nearly 1k instances, it last for a period of time, and then it recovered automatically .. ",
    "fisache": "I think it is my mistake..\nI will refernce to https://dzone.com/articles/spring-cloud-sidecar\nhaha.. :). ",
    "wangpenghit2155": "It is a typical problem. My solution is: you can use NodePort in kubernetes service yaml. And in Dockerfile you can pass \"--eureka.instance.nonSecurePort\" and \"--eureka.instance.ip-address\" to your service  . ",
    "zhrum": "@wangpenghit2155 I don't understand what you mean.... ",
    "dshamanthreddy": "It is not woking for me. ",
    "igorbljahhin": "I discovered the source of the issue. It happened when I connected to same Eureka two instances of my app: one was deployed in Amazon and second was started locally on my computer.. ",
    "dsyer": "We aren\u2019t ready very keen in supporting older versions. And chance you can update to Dalston and Boot 1.5?. Also there\u2019s a double // in your eureka url. Could be a normalization problem.. Both. But the error is from the client isn't it?. Well how about updating the client? And fixing the double //?. Don't know then. Seems like it must be an environment issue. What kind of connection does the client have to eureka? Is there a proxy? More than one?. I would be looking there for clues then. Something started messing with your traffic. Also look at the logs and /trace from the eureka server.. This issue was closed 9 months ago. If you are running the latest versions your symptoms may look similar, but it seems unlikely to be the same cause. Can you show how to reproduce the issue? It looks like the eureka server is down/broken/refusing connections.. Dalston.SR1 is not the latest release. We have Finchley.SR2 now.. ",
    "jeven2016": "I also encounter this issue, do you have new discovery now?. ",
    "GhaTMA": "+1. Thanks for your reply @mechero. But even with eureka.instance.appname set, the problem is still visible in the UI. The replicas do synchronize with eachother but they are not recognized as available-replicas.. @mechero: Thanks for the extensive explanation! \nI will look deeper into this.. ",
    "mgvinuesa": "+1. ",
    "mechero": "Hi, I know this issue is already closed but I noticed that the problem you had was actually related to the property eureka.instance.appname, and not really related to spring boot. If you want to make the cluster work, you need to use the same application name in both profiles. \nI went through a lot of tricky issues as well, so I decided to write a blog post and a sample project to try to clarify the configuration to others. I hope it helps!. @GhaTMA, I got it working with a similar scenario, and with the replica listed as available-replicas, so there might be something else that is wrong in the configuration (or the setup). \nMy conclusions about how the logic behind Available/Unavailable replica works:\n TheStatusUtil class (check this line) retrieves all instances that are registered in Eureka with the same name as the running instance (which are the running instance and the peer).\n It then picks the one which is located at the specified serviceUrl. Since you need to register each instance on the peer, it picks the peer instance. \nYou can debug those specific lines and check if you really got two instances or just one, and then check if URLs match or not. \nI also included Docker configuration in the example, so feel free to give it a try since it should work out of the box with the sample code (no need to change hostnames). . ",
    "walt79": "Had the same issue as reported by OP while running 3 Eureka's in a cluster via docker-compose. Issue was resolved through setting eureka.instance.preferIpAddress: false.\nPerhaps this relates to the eureka.client.serviceUrl.defaultZone containing an explicit host name (no ip address, but explictly eureka-a, eureka-b) in my docker-compose configuration: for example eureka.client.serviceUrl.defaultZone: http://eureka-a:18671/eureka,http://eureka-b:18672/eureka passed on as environment vars to the Eureka instance ('eureka-c' in this case).. ",
    "holy12345": "@qiangdavidliu Thank you, may I ask which version of eureka can see this fix. Best wishes\uff01. @qiangdavidliu Thank you very much for your reply : )\nNot very urgent, but I'm worried that the user does not know the meaning of this parameter (the official document did not say.) If the value is greater than 1 may lead to some problems with the production.\nIn addition, I submitted two PRs(#1021 #1020), please check, if there is no problem, hope to merge it. \nFinally, I would like to ask you, can you give me your email address\uff1f\nbest wishes:). @qiangdavidliu Hello, hope to pass this pr, the best wishes. @qiangdavidliu Hello, look forward to your reply, thank you very much, best wishes\uff01. @qiangdavidliu Hello, can you review this PR? Thank you, best wishes \uff1a). @qiangdavidliu  ping.... Hello @qiangdavidliu \nThank you for your answer, probably because my English is not very good and did not express clearly. Please forgive me if you have caused any confusion.\nNow I re-answer the following(Reference eureka official document sentence):\nIf any time, the renewals falls below the percent configured for that value (below 85% within 15 mins), the server stops expiring instances to protect the current instance registry information.\nThis sentence has two main points:\n\n\nWhether to open the self-preservation mechanism (If not then in any case be updated)\n\n\nCurrently, the number of Eureka Clients with normal heartbeat accounts for more than 85% of Eureka Server's total storage\n\n\nThe code to accomplish the above two key points is as follows:\nif ((count * 2) > (serverConfig.getRenewalPercentThreshold() * numberOfRenewsPerMinThreshold)\n                    || (!this.isSelfPreservationModeEnabled())) {\n                this.expectedNumberOfRenewsPerMin = count * 2;\n                this.numberOfRenewsPerMinThreshold = (int) ((count * 2) * serverConfig.getRenewalPercentThreshold());\n        }\nMy understanding is as follows:\nIf you turn off self-preservation, these two parameters are updated under any circumstances.\nIf we open the self-preservation, then only if  the number of Eureka Clients with normal heartbeat accounts for more than 85% of Eureka Server's total storage will be updated.\nWhat I think is the problem is the formula in the code (count * 2) > (serverConfig.getRenewalPercentThreshold() * numberOfRenewsPerMinThreshold)\nIn my opinion it should be  (count * 2) > (serverConfig.getRenewalPercentThreshold() * expectedNumberOfRenewsPerMin)\nMaybe my understanding is not correct, I hope you can help me. Any one of your answers are a great encouragement to me, thanks again\n. Hi @qiangdavidliu \nThank you for your reply, thank you very much.\nI will try to validate my logic by adding test code because the update is done in a thread and I currently have no idea how to test it(These days I have been looking for ways  but unfortunately did not find) .but do not worry I'm trying to figure out how to solve this problem. Hi @qiangdavidliu \nFirst of all, I'm sorry. I've been very busy before and I haven't updated this question.I think I'll close it f and when I think of a solution, I'll reopen it.\nThanks again : ). @qiangdavidliu Okay, I removed it as you suggested. I apologize for the troubles caused to you. Thank you. Hi @vidurananayakkara \nAFAIK Eureka have two cache, so which one you want refresh? In default eureka use two cache, one is guava cache the other is Map\nIn normal like this\nClient --- > mapCache ---> guave cache\n. @neoremind \nHi First of all I think you logic is right : )\nIn fact this Issues i have already submit a PR, but the author think  i should add some test code. But I not find a best way to test this code , so I close the PR(#1020) If you find the best way to test the code, please tell me.\nthanks\n. I want to more talk about this issue. In my mind, if client has not send heartbeat,eureka server will remove it. but during remove it , Eureka server why not update those number .(Eureka server use a background task do update two numbers).\nI understand this is Eureka architect, but can you explain more why design like this.\nI will appreciate you answer.\nThanks . Thanks for you answer, but in my mind evict method just remove client information, but not update those two numbers Immediately. Update is on the background task.\nWhy not update immediately when evict method remove client information.. OK I get it.\n\nBut in expired cases, the value will not be updated since self-preservation relies on the value to determine if heartbeats drop below 85% of the expected number, so Eureka should not update this value when removing expired instances.\n\nis the reason.. All guys\nI want to know more about this, there is issues also in Netflix production? I agree with @neoremind (its a core logic). so cloud you please tell more things about Netflix how to use eureka in production\nGreat thanks @qiangdavidliu . Hi @neoremind \nAs far as i know , When the eureka client Down it will sent a message to Eureka Server, so Eureka Server can know its down, also Eureka server can recalculate numbers. If you use kill -9 The Client will not send message to Eureka Server. So at this time The Eureka Server not recalculate numbers. \nBut Eureka server have a  task in background, it will evict client which not sent heartbeat.\nIf you have any question, Maybe can we use Chinese to communication : )\nI hope i can help you!\nthanks again \n. Hi @mgtriffid \nI face the issue which maybe the same to you.\nWhen I start a eureka server in local, and start a eureka client,  I see the server log has two register log. By the debug the source code , I found isThisMyUrl is check not total right\nIn my mind I think when a eureka client start It will register to eureka server and eureka server will replicate to peer node(In replicate logic, it should skip itself).\nBut I found it not skip itself : (\n. @mgtriffid Thanks your PR : )\nTiny things.\nCould you please add some validate about serverConfig.getExpectedClientRenewalIntervalSeconds() is not zero.. Hi @addozhang\nI submit a PR about this issues, welcome you check it.\nThanks . @qiangdavidliu Great thanks : )\nI will add some test for this PR.\nOne more things could you please give me your personal email? If you think it inconvenient to disclose it in public, I can give you my email address(Because I want more discuss with you about eureka).\nMy email address is spring_holy@163.com\nThanks again. Hi @qiangdavidliu  First of all thank you!\nI add some test case for this PR, please you check it .\nYou say \n\nremoval of apps is not something that expected in current client behaviour\n\nSo I think in some case there have many application has no instanceInfo when merge the delta information(the action type is DELETE)\nAccording to your thoughts which is best ?\n\n\nWhen application has no instanceInfo, we remove application(this PR logic)\n\n\nOptimize the original logic, the code like this\n\n\nif (ActionType.DELETED.equals(instance.getActionType())) {\n    Application existingApp = applications.getRegisteredApplications(instance.getAppName());\n    if (existingApp != null) {\n        logger.debug(\"Deleted instance {} to the existing apps \", instance.getId());\n        applications.getRegisteredApplications(instance.getAppName()).removeInstance(instance);\n    }\n}\nThanks again : ). HI @AlbertoImpl \nHave you configured several eureka servers on your client side? I assume that your client configuration is as follows\ndefaultZone = eurekaServer1, eurekaServer2, eurekaServer3\nIn my mind if your shut-down eurekaServer1 then client will sent heartbeat will failed, but client will auto choose next one(eurekaServer2)\nHope can help you \nThanks. Hi @AlbertoImpl \nIn my mind there is no such mechanism, because the eureka client does not know whether the eureka server is down or the heartbeat fails due to network problems.\nYour thoughts?\nThanks. Hi @qiangdavidliu  : )\nCould you please give some suggestion?. @qiangdavidliu  Thanks : ). HI @mgtriffid  \nThanks this question, I think this is question interesting. I notice this case you have two eureka server. one of eureka server means eureka client for other. we know eureka client can fetch instancesInfo from eureka server so this server fetch all instanceInfo from other and filter which status are notUP and cause the issue which you mention  (I think this is key point)\nthanks : )\n. Hi @jishamenon2207 \nI think is issues has same request #1076 \nSo far there is no way can edit the eureka dashboard : ( but if you will you can submit a PR : )\nthanks\n. Hi @qiangdavidliu \nThis issues maybe make eureka server self preservation invalid, could you please include this PR in next release and do you have any plans for next release? thanks : ). HI @andyzhaozhao \nYou say you have 21 clients so in my experience you can start 3 eureka server(One Eureka server obviously not reasonable)\nFor you question whats the BEST number I think maybe no accurate answer.\n@qiangdavidliu  Any thoughts?\n. Hi @yikangfeng \nCould you please speak more in detail? Thanks\n. ",
    "chillzhuang": "You should believe Mr Chun, then there was no bug can catch you. ",
    "HashZhang": "I got it.TKS~. ",
    "ex00": "Hi @qiangdavidliu \nThanks for you reply! Do you talk about EurekaEvent?\nI woluld like register listener for events about register new application in server. Wich implementation of EurekaEvent I could use for it?\n. I changed logic of my application and this issue is not actual already. Thaks for help!. ",
    "dulimitta": "Sorry for the late reply. How would I get system information in other ways? Can you please suggest.. Thank you @jussiseppala. I will look into it. We are using ECS with EC2 for now.. @Sridharc20 we are using ECS with EC2. You can refer to @jussiseppala the last comment to get the container IP. \n. ",
    "jussiseppala": "Fargate platform version 1.1 seems to support metadata for ECS. \nSee anouncement.\nI think that eureka-client does not support this.\nSee AmazonInfo.java\nIn case anyone already has implemented this could you please point me to that. Anyway, it would be great to have eureka-client to support ECS (and especially Fargate).\nOne way to get metadata is to do it as described here.. I created a sample  how to do this. \nHope this helps!. ",
    "Sridharc20": "Was this case resolved, can somebody post on how to get the container ip and port from the ecs containers (services) and send it to Eureka Server (ecs container).. ",
    "yashonting": "Try the latest version of nebula.netflixoss.\nhttps://plugins.gradle.org/plugin/nebula.netflixoss. ",
    "sarbull": "+1. ",
    "rexroyl": "I'm facing the same issue. Any updates? thanks. ",
    "dragontree101": "ok, i issue to spring cloud netfilx, close this issue. thanks, change eureka to consul is hard ...      :( \n. ",
    "qinxiongzhou": "Hi @qiangdavidliu ,I also encountered this exception. After the eureka cluster has been running for a while, this error is reported from time to time. It is estimated that it will be reported once in three hours. I pinged the server ip, ttl is about 64ms. Do you know what is going on here?. ",
    "dougbacelar": "https://cloud.spring.io/spring-cloud-netflix/multi/multi__service_discovery_eureka_clients.html#_zones. ",
    "mengjiann": "Thanks. I will read on the references.. ",
    "artgon": "As @brharrington mentioned Zuul 2 has recently been released, see the link to the github issue above. More info on getting started here: https://github.com/Netflix/zuul/wiki/Getting-Started-2.0\nAFAIK, Spring Cloud is not going to use Zuul 2 but you'll have to confirm with them.\nI'm not sure what rumors you're referring to but both Zuul (specifically version 2) and Eureka are core products for Netflix and almost all traffic that comes in touches both.. ",
    "beastovest": "Hey there,\nHave you check this - https://github.com/spring-cloud/spring-cloud-netflix/issues/2754 ?. ",
    "Bangic": "@beastovest thanks! it's works. @spencergibb  thanks! . ",
    "dosdebug": "@ryanjbaxter Is this added in Finchley.RC1, because I am still facing issue with mentioned release.. Nevermind, Finchley.RC1 still uses 1.8.8. ",
    "arpanagr": "It got resolved somehow after doing a restart. Not sure what was wrong though. But closing it for the moment.. ",
    "narenchoudhary": "When the number of instances are less, eureka.server.renewalPercentThreshold can cause this behavior. You have not provided your Eureka server and client configurations. \nPlease provide configuration and check out this similar issue.. eureka.instance.preferIpAddress=true will make instance register to Eureka server with IP address. You do not need  to provide IP address in any configuration as that will be automatically picked up from system by the application. \n. This configuration is not related to spring boot. Netflix OSS libraries (at least netflix-eureka) do not have any dependency on spring-boot.\nexamples folder has an example project which does not use spring-boot.\nThis SO question is also very similar to your query. . ",
    "Sanisy": "you can do this by declear your own customization config by extend the MyDataCenterInstanceConfig.\nDynamicPropertyFactory configInstance = com.netflix.config.DynamicPropertyFactory.getInstance();\n        ApplicationInfoManager applicationInfoManager = initializeApplicationInfoManager(new CustomInstanceConfig ());\n        EurekaClient eurekaClient = initializeEurekaClient(applicationInfoManager, new DefaultEurekaClientConfig());\npublic class CustomInstanceConfig extends MyDataCenterInstanceConfig{\n    /**\n     * prefer ip instant of hostname\n     * @param refresh\n     * @return\n     */\n    @Override\n    public String getHostName(boolean refresh) {\n        try {\n            return InetAddress.getLocalHost().getHostAddress();\n        } catch (UnknownHostException e) {\n            return super.getHostName(refresh);\n        }\n    }\n}. ",
    "neoremind": "@holy12345 thanks for your reply. I am working on adding test case for the scenario, but before that I got one important question to confirm https://github.com/Netflix/eureka/issues/1073. Feel free to add comments.. @holy12345 @qiangdavidliu \nI have added test case for this scenario, please review my code. Many thanks.\nI will clarify briefly about what I have done. I create a new testcase named TimeConsumingInstanceRegistryTest.java which will run a bunch of sequential events in 2 minutes. I have added detailed comments about the steps that will be executed. \nHere I will paste them out for you to take a look.\n```\nVerify the following behaviors, the test case will run for 2 minutes.\n1. Registration of new instances.\n2. Lease expiration.\n3. NumOfRenewsPerMinThreshold will be updated. Since this threshold will be updated according to EurekaServerConfig.getRenewalThresholdUpdateIntervalMs(), and discovery client will try to get applications count from peer or remote Eureka servers, the count number will be used to update threshold.\nBelow shows the time line of a bunch of events in 120 seconds. Here the following setting are configured during registry startup: eureka.renewalThresholdUpdateIntervalMs=5000, eureka.evictionIntervalTimerInMs=10000\n       TimeInSecs 0          15         30    40   45         60        75   80      90         105       120\n                  |----------|----------|------|----|----------|---------|----|-------|----------|---------|\n       Events    (1)        (2)               (3)  (4)        (5)       (6)  (7)                (8)       (9)\n(1). Remote server started on random port, local registry started as well. 50 instances will be registered to local registry with application name of LOCAL_REGION_APP_NAME and lease duration set to 30 seconds. At this time isLeaseExpirationEnabled=false, getNumOfRenewsPerMinThreshold= (502 + 1(initial value))85%=86\n(2). 45 out of the 50 instances send heartbeats to local registry.\n(3). Check registry status, isLeaseExpirationEnabled=false, getNumOfRenewsInLastMin=0, getNumOfRenewsPerMinThreshold=86, registeredInstancesNumberOfMYLOCALAPP=50\n(4). 45 out of the 50 instances send heartbeats to local registry.\n(5). Accumulate one minutes data, and from now on, isLeaseExpirationEnabled=true, getNumOfRenewsInLastMin=90. Because lease expiration is enabled, and lease for 5 instance are expired, so evict 5 instances.\n(6). 45 out of the 50 instances send heartbeats to local registry.\n(7). Check registry status, isLeaseExpirationEnabled=true, getNumOfRenewsInLastMin=90, getNumOfRenewsPerMinThreshold=86, registeredInstancesNumberOfMYLOCALAPP=45\nRemote region add another 150 instances to application of LOCAL_REGION_APP_NAME. This will make PeerAwareInstanceRegistryImpl.updateRenewalThreshold() to refresh AbstractInstanceRegistry.numberOfRenewsPerMinThreshold.\n(8). 45 out of the 50 instances send heartbeats to local registry.\n(9). Check registry status, isLeaseExpirationEnabled=false, getNumOfRenewsInLastMin=90, getNumOfRenewsPerMinThreshold=256, registeredInstancesNumberOfMYLOCALAPP=45\nNote that there is a thread retrieving and printing out registry status for debugging purpose.\n```\nAfter reviewing the history of method updateRenewalThreshold(). I assume the logic is for the following scenario.\nAssuming there are 2 servers, server-A and server-B, each has total 100 heartbeats expected, and expiration threshold is 85. After sometime, server-A becomes an isolated island, losting connection with all clients and peer server-B. Then server-A enables preservation mode to avoid evict many instances. After a while when connection comes back to normal, it finds there are total 200 heartbeats expected from server-B which satisfy the condition of updateRenewalThreshold(), if the count is bigger than 85% * numberOfRenewsPerMinThreshold, then server-A will update its renewal threshold to 170 as what server-B does. And after a while with new heartbeats to server-B and replicating to server-A, server-A will catch up and eventually the two servers are consistent.\n@qiangdavidliu could you help me review the case? or if you have more insights. Thanks!. @qiangdavidliu would you please review this PR? I suppose you are busy working, but still really appreciate if you could take a look. many thanks. :-) . @qiangdavidliu Thanks very much! Take your time.. @holy12345 As far as I know, Eureka will update numberOfRenewsPerMinThreshold in 4 cases:\n Register new instance.\n Cancel one instance proactively.\n Eureka server opening for traffic and this value is the number of instances replicated from peer.\n In updateRenewalThreshold() method where it will be updated in 15mins in background.\nBut in expired cases, the value will not be updated since self-preservation relies on the value to determine if heartbeats drop below 85% of the expected number, so Eureka should not update this value when removing expired instances.. @holy12345 you got it :). @qiangdavidliu Sorry to bring you back, would you please review this PR and test case? I think this could help a lot on the core logic verification. Many thanks! . @mattnelson In normal case, updateRenewalThreshold will only be updated when adding or dropping instances, if self perseveration is enabled, then if the heartbeats from instances drop below 85% of the expected value, eureka server stops to expire instance and will not quit unless the lost instances are back online to register/renew with eureka server. \nEureka will also try to get applications from peers, if the count is bigger than the threshold, it will update the updateRenewalThreshold of itself, this is what this PR works on to adjust and clarify.\nIn my opinion, if Eureka enters self preservation mode, and you deliberately offline some servers, Eureka will not quit. . @qiangdavidliu Understand the situation that you are overwhelmed, Netflix grows so fast \ud83d\udc4d If this logic seems unnecessary, how about only adding the test case to eureka? . @qiangdavidliu many thanks! Appreciate your help! :). @holy12345 The background task is to evict those ones do not send heartbeats as regular basis, but if expiration is disabled, the background task is not able to perform, so those unavailable endpoints will stay if eureka does not enable expiration.. @qiangdavidliu Thanks for your answer. What you explained makes sense. Abnormal offline instances should be considered as failure endpoints and expected to be back, normal offline is what Eureka expects clients to do. \nIn our system, we make self preservation to be dynamic configurable, so that we can change the behavior in runtime.  . 1.X is pretty stable and in production-level, spring-cloud relies on 1.X. If there is demand I think community would play a big role in maintaining this. For your question, I think @qiangdavidliu might be the right person to answer.. same concern. https://github.com/Netflix/eureka/issues/1090. @spencergibb thumb up! . I think there might be a more aggressive solution to make heartbeats interval configurable. Because there are too many hard code by / 2 in class AbstractInstanceRegistry and PeerAwareInstanceRegistryImpl, if we set so then there is no need to add this parameter. . ",
    "HikariShine": "Oh good. Thank you!\nThree days ago i find this logic, but i cann't understand it. I think it is a bug, because it seems all situdation will trigger this update, but i have no confidence.\nThen i use one day to read the relative logic and one day to search in baidu.\nAt the third day, i found you pull request, it's a big help for me to understand the logic, thank you! . ",
    "sabareeshkkanan": "I am voting for this as well because of future compatibility regarding reflection issue\nhttps://github.com/Netflix/eureka/issues?utf8=%E2%9C%93&q=is%3Aissue+is%3Aopen+xstream. ",
    "zhao41654828": "I have the same need...\nadd a remove button for micro service out of service. . ",
    "mgtriffid": "In our custom build we ended up with following solution.\nEach Eureka node generates random UUID, and exposes an endpoint which just returns this UUID.\nCustom implementation of PeerEurekaNodes overrides method isThisMyUrl, and in this method it first calls mentioned endpoint of passed host. And if this call returns the same UUID this node has generated, it means \"this is my url\", and Eureka remembers that host and always thinks it is it's own host. But I'm not sure how to implement similar functionality in original Eureka, as can't foresee all possible cases. Just sharing an idea here.. Submitted a PR, @qiangdavidliu .\nWith this PR Eureka still first tries to perform regular check, and only if it fails, we try to fetch peer id.\nAlso, I've added check only for replications and not for initial resolving peers, because in common scenario (when several instances are starting at the same time) we can't contact peers, as they are not open for traffic yet. Also wanted to perform calls to peers through common mechanism of EurekaHttpClient, hence, had to add method to PeerEurekaNode, and we don't have instances of PeerEurekaNode during initial URLs resolution.. @holy12345 , PR https://github.com/Netflix/eureka/pull/1107 is merged and included in 1.9.4, please see if new config parameter fits your needs.\nI guess we can close this now.. > I think you may need to make a change here too:\nhttps://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/registry/PeerAwareInstanceRegistryImpl.java#L294\nSorry, I don't get it what do these two minutes mean. This seems to be an expiration check, but it uses lease duration and last lease renewal, and I can't understand why do we need to add 2 minutes. Could you kindly explain, @qiangdavidliu ?\nAddressed other comments.. @mattnelson , probably, yes, existing instance id should work.\nSpeaking of not introducing new requests. When Eureka resolves addresses of peers through DNS, hosts in txt records are the only information it has. Sorry, I don't understand, how can Eureka find corresponding instance ids if not trying these hosts?\nMaybe there already exists some request from which we could understand if caller == callee? If so, could you please suggest, where should I look?\nSpeaking of peers being chatty - please note that these requests are executed only for some short time after deployment, until Eureka finally calls itself and understands \"yeah, this peer is actually me\". After that, these requests don't happen.\nSpeaking of complicated deployment - yes, adding new resource to web server is required. But gradual rollout shouldn't be a problem: at some point Eureka will finally call itself (and if Eureka has this check - it means it has endpoint too), will figure out that called peer is actually the same node, and will stop doing these requests.\nOverall, I certainly understand that this looks like a kludge, would be happy to find better solution.. @qiangdavidliu , @mattnelson , thanks for ideas! Yes, this option with new configuration parameter is certainly much easier. Submitted new PR https://github.com/Netflix/eureka/pull/1107, declining this one.. Hm, on my local machine all tests pass well, is there any way to re-run Travis build?. Thanks for approval and merge @qiangdavidliu !\nMay I ask, when should we expect next release to happen?. @yangpancode , even if you DELETE instance from Eureka via REST API, your instance still continues to send heartbeats, and when server receives heartbeat for instance it does not know about, server registers it. I'd suggest to set status OUT_OF_SERVICE instead DELETE, if you just want to stop routing traffic to problematic instance.. > Recent versions of Servo also have a SpectatorContext which can be used to have all servo monitors report in via a Spectator registry. This is what we are using internally now as we have to keep backwards compatibility for Servo instrumented apps for quite a while.\nWow, that's actually great, I think for our needs we may just increase version of Servo dependency to 0.12.25 and simply use SpectatorContext. Thanks for sharing this!\nGiven that you guys already have some solution for reporting this to Atlas (@brharrington mentioned duplication), and newer Servo provides a solution for this case, I think we can simply decline this PR - with SpectatorContext anybody can add Spectator and Atlas without any difficulties.. @hashstax, I'm not sure if this fit your needs, but as you probably know, clients fetch apps/delta to renew local registry, and in particular they return removed instances with <actionType>DELETED</actionType>. Try to experiment with this.. We consider invalid responses for apps/delta to be a bug, so would very appreciate some feedback :). Hi @qiangdavidliu , thank you for your response!\nWe are also using Eureka's Java client, and we see that fallback to full fetch works just fine. However, the problem is, when Eureka's response contradicts itself (hash string doesn't match delta), then, because of Eureka response caching, many clients receive such response, and many clients fallback to full fetch, and that puts significant load on Eureka server. So I think we'll try to move serialization of /apps and /apps/delta under the write lock and see if it helps, and provide the PR.\nCould you kindly tell more about that side app, if that doesn't violate your NDA? :). Submitted PR #1126 for this. Was able to easily reproduce inconsistent responses without this fix, totally cannot reproduce them with this fix. Please review.. @rickywu , Eureka keeps responses for /apps, /apps/delta and /apps/ cached for some time. In eventually consistent system like Eureka we can afford small delay of status change. Anyway, clients poll Eureka server periodically, so delivery of information about status changes is already not instant.. Fixes #1120 . I don't think so, @mattnelson . RRWL's read lock can be entered by multiple threads, but if write lock is not locked, then other threads cannot enter even read lock. I think the intention here was to allow many threads modify different registered instances (statuses, metadata), but if response cache needs to be loaded - we take a pause and prepare response. But let's better wait for @qiangdavidliu  to respond to your concern.. Thanks for pointing this out, I actually was concerned about performance too, for some reason thought serialization is quick. Good that you have some stats from production of your scale.\nNaive benchmark shows that on average calling copying constructors is 11 times faster:\nEncoding: 84819\nCopying constructors: 6561\nNow actual test:\nEncoding: 81785\nCopying constructors: 6803\nNow without metadata\nEncoding: 82318\nCopying constructors: 7140\nWill update PR.. Moved locks to original place, added copying constructors.. @qiangdavidliu , well, at least with this fix I cannot reproduce that issue, while without this fix I can do that easily.. @rajgoothy , not enough information here. Could you provide all your eureka-related configuration parameters?. @rajgoothy , all I can suggest is to assure that your Eureka server is actually running on 127.0.0.1:9000. Please consider asking Spring Cloud developers, they may know more about your setup.. @rajgoothy , really, try to ask here https://github.com/spring-cloud/spring-cloud-netflix , people there will more likely be able to help you. This project is Eureka itself, and integration with Spring brings too many new variables, unknown to people here, to the equation.. Well, I see replica is displayed as \"unavailable\" if Eureka cannot find InstanceInfo for Eureka which has hostname same as configured. See https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/util/StatusUtil.java#L68 . So in your situation each Eureka instance has \"EC2\" IP in registry, but DNS resolves into different IP, I think this explains such behavior. . This should probably be posted in spring-cloud project. Though I'm not sure.\nCould you please clarify, what exactly do you mean saying \"latest spring-boot context configuration\"? What is the origin of this parameter? Spring framework, Jetty, or servlet container spec?. Anyway, please try to ask in Spring Cloud project. Spring brings many new variables to the equation. This Github project is specifically for Eureka, and what you are using is some integration made by Spring Cloud developers. So, they very likely know more about your question.. Hi Vishnu,\nThe thing is that Eureka Client keeps information about services in memory. And periodically it contacts Eureka Server to refresh that information. If your Eureka is unavailable, it simply fails to refresh info, and just uses previous.. Fixes #1146 . Hm, strange, on my machine all tests passed. Could somebody please restart?. @elandau , we need different randomization for clients to choose Eureka nodes. And actually with my changes if I do\njava\n        ResolverUtils.setRandomizer(new Randomizer() {\n            private final int seed = new Random().nextInt();\n            @Override\n            public void randomize(List randomList) {\n                if (randomList.size() < 2) {\n                    return;\n                }\n                Random random = new Random(seed);\n                int last = randomList.size() - 1;\n                for (int i = 0; i < last; i++) {\n                    int pos = random.nextInt(randomList.size() - i);\n                    if (pos != i) {\n                        Collections.swap(randomList, i, pos);\n                    }\n                }\n            }\n        });\nsomewhere before Eureka Guice module is configured, this does the trick for me: seed is different every time, but order of preference remains the same. This implementation of Randomizer just uses random number instead of local IP hashcode.\n\nThat change would need to be wired into ZoneAffinityClusterResolver.\n\nAs you can see, ZoneAffinityClusterResovler just calls ResolverUtils.randomize, so logic is actually wired into there.\nAm I missing something else?. Wow, quite a lot of libraries involved here :) It may be Eureka who behaves not like you expect, it may be Ribbon.\nFirst, could you please isolate the problem?\nYou can use Eureka REST API to get registry directly from Eureka and check how soon does your instance in fact change status. If Eureka consistently returns you fresh information within 10 seconds, then it's wrong place to dig. In such case I'd suggest you to post your question in Ribbon project, or maybe even Spring Cloud.. One of possible fixes for #1149 .. Related PR is merged, so closing this.. Fixes #1154.. Well, I can't say this is surprising - Eureka allocates objects when you call this API, but most are supposed to be collected by GC. Does memory utilization continue to grow steadily even after garbage collection? In other words, do you experience a memory leak? Also please let us know what's the version you are using.. Hi @yikangfeng , please check if your Eureka server has property eureka.shouldFilterOnlyUpInstances configured as false. See #1127 for details. Please read the first post there and see if it describes your situation.. Not sure if I understand the first part of this condition, but maybe your intention was to check shouldFetchRegistry here and shouldRegisterWithEureka above?. We can see that this method can throw new RuntimeException. It's okay to throw this when application starts: this is a critical problem which has rights to prevent application startup. But did you check what are the consequences of this happening at some point in time when application is already operating and just wants to refresh list of Eureka nodes?. Also this is now called N+1 times, where N is number of zones. Are we okay with this? Isn't it time-consuming? (IMHO even if it is, it's not critical, but maybe somebody has another opinion).. ",
    "tdanylchuk": "My pleasure, thank you for supporting the project.. ",
    "icestari": "But now I'm confused about \"extension work on eureka 1.x has moved internally within Netflix.\".\n. ",
    "gaoyining": "comment. ",
    "wayilau": "because your server is registering to other eureka server. you may config as below\uff1a\nregisterWithEureka: false. ",
    "trickert76": "Ah, I forgot - in this situation - when I use a Feign client, this client doesn't work too, becaus it uses the same mechanism from the Eureka client.. ",
    "rongbo-j": "resolved by modify eureka/build.gradle file:\n_```\nbuildscript {\n    repositories {\n        jcenter()\n        mavenCentral()\n        maven{\n            url \"https://plugins.gradle.org/m2/\"\n        }\n    }\ndependencies {\n    classpath \"com.netflix.nebula:gradle-extra-configurations-plugin:3.3.0\"\n    classpath 'com.netflix.nebula:gradle-netflixoss-project-plugin:5.1.1'\n}\n\n}\nplugins {\n    id 'nebula.netflixoss' version '5.1.1'\n    id \"nebula.provided-base\" version \"3.3.0\"\n}\n......\n```_. ",
    "AlbertoImpl": "Hi @holy12345 thanks for commenting.\nHowever, we are not running it with multiple servers. \nWe want to go from 1 working instance to 0 working instances avoiding the client apps to keep sending requests indefinitely when there are no working instances.\nThanks!. Hi @holy12345  thanks again.\nFor context:\nWe have a scenario where we have multiple client apps that intentionally can be connected to one eureka server that can be shut down.\nOnce that server is intentionally shut down, client apps keep sending the requests every couple of seconds and failing with the exception posted before.\nWhat about having a max-retry that defaults to 0 been keeping the same default retry-forever functionality and be able to configure that number for having a more fine-grained retry policy?\nWondering if that makes sense, and if it does, if it's the DiscoveryClient responsibility or if it should be a different handling in the RetryableEurekaHttpClient\nThanks\n. Hi @qiangdavidliu thanks for responding!\nIt isn't because of the logs.\nImagine the eureka-server is secured and it goes down. Now our client app has to go and authenticate once a while trying to reach nothing.\nHowever, if eureka is doing it so by design. I completely understand.\nThanks!\n. ",
    "ileler": "It's my pleasure.. ",
    "rickywu": "@mgtriffid  OK, so I have to wait for seconds till cache refreshed?. ",
    "iver3on": "eureka:\n  client:\n    serviceUrl:\n      defaultZone: http://xxxxxx.xxxxx.com/eureka/\n  instance:\n    hostname: http://xxxx.xxx..com\n    instance-id: http://xxxx.xxx.com\nnot working. ",
    "thinker8581": "using prefer-ip-address: false, then try again.. ",
    "yikangfeng": "\nEnvironment:\nCluster of 2 Eureka nodes of freshest version\neureka.enableSelfPreservation=true\neureka.expectedClientRenewalIntervalSeconds=15\neureka.renewalThresholdUpdateIntervalMs=240000 //default is 15 minutes, we just want to speed up testing\n16 client instances talking to this cluster\neureka.client.refresh.interval=15\nExperiment 1: confirming issue\n15:00: 16 client instances in UP plus 2 Eurekas. Threshold is 61 = 18 * 4 * 0.85, 68 renews comes minutely, renews are above threshold, all is fine.\n15:02: 4 client instances were put into OUT_OF_SERVICE state via Eureka\u2019s REST API.\n15:03: Logs indicate that this method updating threshold was called, and they say threshold is still 61. This is expected, we did not delete anything, so threshold should be the same.\n15:04: We kill -9 one of clients and wait for eviction to happen.\n15:06: Logs show that eviction happened.\n15:06: /eureka/status endpoint says that only 64 renews came last minute. Reasonable: we had 68 per minute, killed one service, now we have 64.\n15:07: Logs indicate that this method updating threshold was called, and they say threshold is still 61. Now this is becoming problematic. Common sense says: \u201cOnly 1 instance was evicted, 1 < 0.15 * 18, evictions happen from time to time, we should adjust self-preservation threshold now\u201d. But tricky condition of method updateRenewalThreshold comes into play:\neureka/eureka-core/src/main/java/com/netflix/eureka/registry/PeerAwareInstanceRegistryImpl.java\nLines 533 to 537 in b2c5ea6\nif ((count) > (serverConfig.getRenewalPercentThreshold() * expectedNumberOfClientsSendingRenews) \n         || (!this.isSelfPreservationModeEnabled())) { \n     this.expectedNumberOfClientsSendingRenews = count; \n     updateRenewsPerMinThreshold(); \n } \nThis code now thinks that count == 13, not 17 (11 instances in UP plus two Eurekas). And previous value of expectedNumberOfClientsSendingRenews was 18, as in the beginning we had everything in UP. Condition evaluates to\n((13) > (0.85 * 18)) == ((13) > 15.3) == false\n, and threshold is not updated, and expectedNumberOfClientsSendingRenews is still 18.\n15:11: Started previously killed client again. Client registers, and on new registration Eureka increments expectedNumberOfClientsSendingRenews, it is now 19. It also recalculates threshold: (int) (19 * 0.85 * 60 / 15) == 64.\nSo, we returned the system to previous state, but threshold changed from 61 to 64. This is wrong, and it actually can lead to unwanted self-preservation if there is a significant number of instances in status different than UP.\nExperiment 2: looking for fix\nThis time we configure eureka.shouldFilterOnlyUpInstances=false on Eureka nodes.\n15:33: 16 client instances in UP plus 2 Eurekas. Threshold is 61 = 18 * 4 * 0.85, 68 renews comes minutely, renews are above threshold, all is fine\n15:34: 4 client instances were put into OUT_OF_SERVICE state via Eureka\u2019s REST API.\n15:37: Logs indicate that this method updating threshold was called, and they say threshold is still 61. This is expected, we did not delete anything, so threshold should be the same.\n15:43: We kill -9 one of clients and wait for eviction to happen.\n15:44: Logs show that eviction happened.\n15:45: /eureka/status endpoint says that only 64 renews came last minute. Reasonable: we had 68 per minute, killed one service, now we have 64.\n15:45: Threshold updated, and it is 57, and this is what makes the difference! Now that check thought count was 17.\n((17) > (0.85 * 18)) == ((17) > 15.3) == true\nexpectedNumberOfClientsSendingRenews becomes 17, threshold is updated to (int) (17 * 0.85 * 60 / 15) == 57.\nConclusion:\nProbably, we should instruct users to configure eureka.shouldFilterOnlyUpInstances=false on Eureka server and add this configuration as default for eureka-server module which assembles .war file\nQuestion:\nBut why do we actually calculate registry size using Eureka client and not, well, registry size? It looks like I am missing something not obvious, but critical. Could you kindly clarify?\nThanks!\n\nWhy is count 13 after killing a service in the Experiment 1? Should it be 17? Thank you. > > Environment:\n\n\nCluster of 2 Eureka nodes of freshest version\neureka.enableSelfPreservation=true\neureka.expectedClientRenewalIntervalSeconds=15\neureka.renewalThresholdUpdateIntervalMs=240000 //default is 15 minutes, we just want to speed up testing\n16 client instances talking to this cluster\neureka.client.refresh.interval=15\nExperiment 1: confirming issue\n15:00: 16 client instances in UP plus 2 Eurekas. Threshold is 61 = 18 * 4 * 0.85, 68 renews comes minutely, renews are above threshold, all is fine.\n15:02: 4 client instances were put into OUT_OF_SERVICE state via Eureka\u2019s REST API.\n15:03: Logs indicate that this method updating threshold was called, and they say threshold is still 61. This is expected, we did not delete anything, so threshold should be the same.\n15:04: We kill -9 one of clients and wait for eviction to happen.\n15:06: Logs show that eviction happened.\n15:06: /eureka/status endpoint says that only 64 renews came last minute. Reasonable: we had 68 per minute, killed one service, now we have 64.\n15:07: Logs indicate that this method updating threshold was called, and they say threshold is still 61. Now this is becoming problematic. Common sense says: \u201cOnly 1 instance was evicted, 1 < 0.15 * 18, evictions happen from time to time, we should adjust self-preservation threshold now\u201d. But tricky condition of method updateRenewalThreshold comes into play:\neureka/eureka-core/src/main/java/com/netflix/eureka/registry/PeerAwareInstanceRegistryImpl.java\nLines 533 to 537 in b2c5ea6\nif ((count) > (serverConfig.getRenewalPercentThreshold() * expectedNumberOfClientsSendingRenews)\n|| (!this.isSelfPreservationModeEnabled())) {\nthis.expectedNumberOfClientsSendingRenews = count;\nupdateRenewsPerMinThreshold();\n}\nThis code now thinks that count == 13, not 17 (11 instances in UP plus two Eurekas). And previous value of expectedNumberOfClientsSendingRenews was 18, as in the beginning we had everything in UP. Condition evaluates to\n((13) > (0.85 * 18)) == ((13) > 15.3) == false\n, and threshold is not updated, and expectedNumberOfClientsSendingRenews is still 18.\n15:11: Started previously killed client again. Client registers, and on new registration Eureka increments expectedNumberOfClientsSendingRenews, it is now 19. It also recalculates threshold: (int) (19 * 0.85 * 60 / 15) == 64.\nSo, we returned the system to previous state, but threshold changed from 61 to 64. This is wrong, and it actually can lead to unwanted self-preservation if there is a significant number of instances in status different than UP.\nExperiment 2: looking for fix\nThis time we configure eureka.shouldFilterOnlyUpInstances=false on Eureka nodes.\n15:33: 16 client instances in UP plus 2 Eurekas. Threshold is 61 = 18 * 4 * 0.85, 68 renews comes minutely, renews are above threshold, all is fine\n15:34: 4 client instances were put into OUT_OF_SERVICE state via Eureka\u2019s REST API.\n15:37: Logs indicate that this method updating threshold was called, and they say threshold is still 61. This is expected, we did not delete anything, so threshold should be the same.\n15:43: We kill -9 one of clients and wait for eviction to happen.\n15:44: Logs show that eviction happened.\n15:45: /eureka/status endpoint says that only 64 renews came last minute. Reasonable: we had 68 per minute, killed one service, now we have 64.\n15:45: Threshold updated, and it is 57, and this is what makes the difference! Now that check thought count was 17.\n((17) > (0.85 * 18)) == ((17) > 15.3) == true\nexpectedNumberOfClientsSendingRenews becomes 17, threshold is updated to (int) (17 * 0.85 * 60 / 15) == 57.\nConclusion:\nProbably, we should instruct users to configure eureka.shouldFilterOnlyUpInstances=false on Eureka server and add this configuration as default for eureka-server module which assembles .war file\nQuestion:\nBut why do we actually calculate registry size using Eureka client and not, well, registry size? It looks like I am missing something not obvious, but critical. Could you kindly clarify?\nThanks!\n\nWhy is count 13 after killing a service in the Experiment 1? Should it be 17? Thank you\n\nSorry, it should be four OUT_OF_SERVICE services plus one KILL service, right?. > Hi @yikangfeng , please check if your Eureka server has property eureka.shouldFilterOnlyUpInstances configured as false. See #1127 for details. Please read the first post there and see if it describes your situation.\nWell, thank you very much.. ",
    "rajgoothy": "can any body help us..\n. Ok.. will provide here .... \n-- api gate way of application.yml\nspring:\n  application:\n    name: gpbs-api-gateway\nlogging:\n  level:\n    root: INFO\n    org:\n      springframework:\n       web: INFO\n      hibernate: INFO\n      apache: ERROR\n  path:  C:/gpbs_logs/\n  file: C:/gpbs_logs/gpbs-api-gateway.log    \nspring.cloud.config.fail-fast=true\nserver:\n  port: 8760\n  tomcat:\n    max-threads: 20\neureka: \n  client: \n    register-with-eureka: true\n    fetch-registry: true\n    service-url: \n      defaultZone: http://127.0.0.1:9000/eureka\n      healthcheck: \n        enabled: true\n  instance:\n    leaseExpirationDurationInSeconds: 30000000\n    leaseRenewalIntervalInSeconds: 300000\n    preferIpAddress: true\n  #fetchRegistry: true\n==================\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\nimport org.springframework.cloud.netflix.zuul.EnableZuulProxy;\nimport org.springframework.context.annotation.Bean;\nimport com.scb.gpbs.filter.GpbsLoggingFilter;\n@SpringBootApplication\n@EnableZuulProxy\n@EnableEurekaClient\npublic class ApiGatewayApplication {\npublic static void main(String[] args) {\n    SpringApplication.run(GpbsApiGatewayApplication.class, args);\n}\n\n@Bean\npublic GpbsLoggingFilter simpleFilter() {\n    return new GpbsLoggingFilter();\n  }\n\n}\n=======\nMy Proxy interface: \nimport org.springframework.cloud.netflix.feign.FeignClient;\nimport org.springframework.cloud.netflix.ribbon.RibbonClient;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestBody;\nimport com.scb.gpbs.json.vo.ProductMapVO;\n@FeignClient(name=\"gpbs-api-gateway\")\n@RibbonClient(name=\"gpbs-rules-service\")\npublic interface GpbsRulesServiceProxy {\n@PostMapping(value = \"/gpbs-rules-service/gpbs/v1/product\",produces=\"application/json\",consumes=\"application/json\")\npublic String  getProduct(@RequestBody ProductMapVO productMapVO);\n\n@PostMapping(value = \"/gpbs-rules-service/gpbs/v1/product2\",produces=\"application/json\",consumes=\"application/json\")\npublic String  getProduct2(@RequestBody ProductMapVO productMapVO);\n\n@GetMapping(value = \"/gpbs-rules-service/test\")\npublic String test();\n\n}\nzull MS pom.xml:\n==============\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>1.5.10.RELEASE</version>\n    <relativePath/> <!-- lookup parent from repository -->\n</parent>\n\n<properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>\n    <java.version>1.8</java.version>\n    <spring-cloud.version>Edgware.SR2</spring-cloud.version>\n</properties>\n\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-actuator</artifactId>\n    </dependency>\n<!--    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-jdbc</artifactId>\n    </dependency> -->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-netflix-zuul</artifactId>\n    </dependency>\n    <!-- <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-oauth2</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-security</artifactId>\n    </dependency> -->\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-sleuth</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.cloud</groupId>\n        <artifactId>spring-cloud-starter-zipkin</artifactId>\n    </dependency>\n    <!-- <dependency>\n        <groupId>org.springframework.session</groupId>\n        <artifactId>spring-session-jdbc</artifactId>\n    </dependency> -->\n\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n    <dependency>\n        <groupId>org.projectlombok</groupId>\n        <artifactId>lombok</artifactId>\n        <version>1.16.22</version>\n    </dependency>\n</dependencies>\n\n\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-dependencies</artifactId>\n            <version>${spring-cloud.version}</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n\n\n. @mgtriffid,\nI have provided all the details . Please verify and suggest.\nI have provided a pre, post filter as component.. @mgtriffid , Thanks for the update and suggestion.. \nis any body able to verify this?. ",
    "ksurent": "Thanks @qiangdavidliu and @mattnelson! Your insight is appreciated.\nClosing the ticket because my curiosity has been satisfied.. ",
    "jishamenon2207": "@qiangdavidliu @holy12345 : Would love to try it out. Do you have any guidance for me? \ud83d\ude04\ncould u please give me the github link for eureka-dashboard code? Thanks a zillion. ",
    "jawitthuhn": "Is the issue with lines 353-358 of EIPManager (https://github.com/Netflix/eureka/blob/master/eureka-core/src/main/java/com/netflix/eureka/aws/EIPManager.java#L353)?\nThe comment indicates that the if check on line 358 is designed to prevent us from hitting that code if \"ec2-\" isn't in the hostname. But that isn't the effect of the code. If \"ec2-\" isn't in the hostname, then beginIndex will be set to \"3\" and we'll still go into the if check. As written, I think that if check is impossible not to hit.. Is there a property that I could set that would fix that, and tell the Eureka client to register under the IP address of the network interface that I attached? Is that the behavior something that  eureka.vipAddress might set?\nAlso, I submit a pull request for the exception I was seeing. I'm not 100% sure if that resolves my particular issue, but I think it is a bug fix that is needed anyhow, right? This was #1135 . @qiangdavidliu - I believe I've made the requested changes. Could you check?. ",
    "leonayx123": "\nThis should probably be posted in spring-cloud project. Though I'm not sure.\nCould you please clarify, what exactly do you mean saying \"latest spring-boot context configuration\"? What is the origin of this parameter? Spring framework, Jetty, or servlet container spec?\n\nThank you for your reply.\nSorry, my English is not very good...\nLet me clarify it again\u3002\nI use the tomcat plug-in as the container of  eruka(dependence spring boot2)\uff0crun with IntelliJIDEA\u3002\n\"Server.content-path\" is no longer recommended~~\n```\norg.springframework.cloud.net flix. Eureka. EurekaClientAutoConfiguration 125 lines.\nString serverContextPath = this.env.getproperty (\" server.content-path \", \"/\");\n```\nthis line  is still used    outdated  \u201cserver.content-path\u201d   on this line of the class.\nHe will lead to the healthCheckUrl is not my actual address\nThat's what I mean~~~\n. > Anyway, please try to ask in Spring Cloud project. Spring brings many new variables to the equation. This Github project is specifically for Eureka, and what you are using is some integration made by Spring Cloud developers. So, they very likely know more about your question.\nOk, thanks for your patient reply. ",
    "takZhang": "good job. ",
    "yugj": "\nWow, quite a lot of libraries involved here :) It may be Eureka who behaves not like you expect, it may be Ribbon.\nFirst, could you please isolate the problem?\nYou can use Eureka REST API to get registry directly from Eureka and check how soon does your instance in fact change status. If Eureka consistently returns you fresh information within 10 seconds, then it's wrong place to dig. In such case I'd suggest you to post your question in Ribbon project, or maybe even Spring Cloud.\n\nthx, eureka rest api get registry immediately, i dig wrong place. ",
    "machinelife1989": "although this issue is closed, below parameter is missed:\nribbon.NFLoadBalancerPingInterval: 5  # default 30s. ",
    "troshko111": "Duplicates #1155.. Resolved. nit: this seems to contain an extra leading whitespace.. Seems to be an issue on latest Chrome for Linux, don't see it on Firefox, closing.. This change is unrelated and I'd suggest to submit a separate PR for style only fixes if you're interested.. Again would suggest to separate, but I understand these are minor so up to you.. ",
    "halower": "@xcbeyond i met, too. but I thought it was not necessary that in a production environment, you don't have to call the rest api directly. you can introduced zuul  or nginx , seems Eureka is not supposed to be exposed to the outside. ",
    "xcbeyond": "@halower @brharrington thank you.I rewrite rest api to call the rest api directly.(springCloudEureka-rest). ",
    "HieronymusLex": "@dersteve did you manage to find a solution to this?\nI tried without ECS Service Discovery since it creates only SRV or A records. Instead I associated a private hosted zone with the VPC and had a subset of private IP addresses dedicated for the instances Eureka is being launched on (bridge mode being used in ECS), then I have a separate process which keeps the txt records up to date with these private IPs. was running into issues with hostname mismatches in the containers. ",
    "dersteve": "@HieronymusLex No, I actually didn't manage to do it. We were thinking about a solution along your lines, but were a bit afraid of all the necessary stuff. We are now close to finish a version where we don't use Eureka on ECS. \nInstead we use a private hosted zone and a A-Record for each service so we can address a service in a resttemplate with its name, e.g. \"customer\" (as we did with Eureka/Ribbon/LoadBalanced Resttemplate before) and have the A-Record in the private zone pointed to a ALB that distributes the load between the service instances. . ",
    "advanceyang": "This is actuator's warning.  and  hystrix.stream is the same. ",
    "piyushkumar13": "@qiangdavidliu @tbak could you please provide some help on this.. Thanks @qiangdavidliu . ",
    "abhishek-anand13": "yup..got it..thanks. ",
    "jbrew8": "In my original post I said everything appeared to be working fine despite the exceptions, but this was wrong: clients were not automatically re-registering with the server when the server was restarted.\nBut- this might not be a bug after all. I had eureka running as an aws elastic beanstalk app using tomcat and httpd. The httpd config had mod_deflate enabled, which appears to have caused all of the empty response bodies to be compressed into an empty gzip file. The discovery client through exceptions when trying to parse this empty response body. Disabling gzip compression on the eureka server solved this issue.\n. ",
    "CodeRaju": "internal issue. resolved now. ",
    "zarfide": "I believe there is a problem with this approach, specifically that by pulling the the credentials out of an On-Instance Provider, the credentials will expire after 12 hours by default.  The net result is that this AmazonEC2 object will self-destruct after 12 hours, which could have unintended consequences down the road.\nI applaud the incorporation of On-Instance providers; however, I believe the provider needs to be funneled directly into the Amazon Objects in order for it to be safe. \nThanks,\nJay\n. ",
    "stevenzwu": "does this mean we can only register one callback? most listener model allow a list of listeners/callbacks.\n. Preconditions.checkNull(callback)\n. maybe also provide a \"deregisterRefreshCallback\" method?\n. ",
    "november-yankee": "Use http://www.cs.oberlin.edu/~jwalker/nullObjPattern/\n. Use http://www.cs.oberlin.edu/~jwalker/nullObjPattern/\n. ",
    "lqjack": "got it , i clone the master branch. when i compile the project , get some error. \ni fix the issue by updating the version. . ",
    "jhspaybar": "The behavior through here doesn't look quite equivalent anymore.  It seems the old behavior would have gotten non-UP instances filtered out even when an instanceRegionChecker was null for example, but that the new behavior won't end up filtering out non-UP instances?. ",
    "encyphered": "You are right. Added commit to append slash.. "
}