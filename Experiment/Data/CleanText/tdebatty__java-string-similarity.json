{
    "tdebatty": "Hi! Thank you for you for your optimisation!\nI'm currently completing the library (Damerau distance) and correcting some bugs.\nIn a second step I will indeed review the code to optimise it... Any advice or pull requests are welcome!\n. Hello,\nIndeed, I realized I had mixed the algorithms for QGram and Jaccard\nsimilarity. So I corrected this...\nI'm glad it's helpull for you..\nRegards,\nOn Sat, Apr 11, 2015 at 6:23 AM, hrj notifications@github.com wrote:\n\nHi!\nThere seems to have been a lot of activity in the project in the last few\ndays! Cool!\nDid you change the definition of QGram? It looks like new Jaccard(2) is\nthe new way to get the functionality of the erstwhile new QGram(2). Am I\nright?\nI am not really familiar with the different algorithms. I had just picked\nup one that seemed to give the best results for my use-case in the shortest\ntime.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/pull/1#issuecomment-91757838\n.\n. Hello,\n\nWhat you are describing here is the nearest neighbor search (nn-search)\nproblem, which is a very broad, and sometimes complicated topic.\nIt is actually the subject I'm currently investigating, and the reason why\nI started implementing the string similarity library.\nSo I will definitely add some nn-search algorithms, but in a separate\nproject as there are a lot of algorithms and approaches that are possible.\nI will try to create the project this week, and drop some starting code.\nThen of course we could add some more fancy algorithms...\nBy the way, be aware that the algorithm you proposed will not necessarily\nprovide you with the most similar item, for example if the query string (Q)\ncontains a character sequence that was not present in the original dataset\n(L). Nevertheless, I think the idea is still very interesting. I will also\ntry to investigate about it this week...\nWhat do you think about this?\nRegards,\nThibault\nOn Sat, Apr 11, 2015 at 6:57 AM, hrj notifications@github.com wrote:\n\nUse-case: Searching for a best match\nGiven a string Q, and a list of strings L, I want to find the distance\nbetween Q and every element of L and then pick the element with the\nshortest distance.\nCurrent solution\nThe current solution is to call a distance function with two String\nparameters. This function assumes nothing about the Strings and hence some\ninformation is recomputed every time (for example, profiles of a string).\nProposal\nTwo additional APIs can be provided to improve performance:\nProfile getStringProfile(String)\ndouble distance(Profile p1, Profile p2)\nFor convenience, a third API would also be useful:\ndouble distance(Profile p, String s) {\n    return distance(p, getProfile(s));\n  }\nThis can be used like this:\nString query = \"alex\";\n  QGram qg = new QGram(2);\n  Profile queryProfile = qg.getProfile(query);\n  list forEach { element ->\n    println(qg.distance(queryProfile, element));\n  }\nFurther, if the list is going to be persistent, it could also be possible\nto serialize the profile of each element of the list into the persistent\nstore. Then, both the query string and the list element's profile need not\nbe recomputed every time!\nIf the overall idea sounds good to you, I will write more about how the\nProfile type could be made type safe across the different implementations\nof StringSimilarityInterface.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/2.\n. Hello,\n\nJuste dropped a new release, with this modification in mind.\nFor Jaccard similarity, there is now a method\nsimilarity(profile1, profile2)\nCould you give this one a try?\nIf it works fine, I will probably add the same method to the other\nshingle-based similaritiies (Cosine, Soresen and Q-Gram)\nBy the way, what is your project about? I'm quite curious about the kind\napplications that use these algorithms...\nRegards,\nOn Mon, Apr 13, 2015 at 9:45 AM, hrj notifications@github.com wrote:\n\n\u200bOh! I might have described this wrong.\nI didn't mean to suggest an implementation of the search algorithm in this\nproject. Rather, some additional APIs in the similarity algorithms to help\nspeed up the search algorithms.\nIn my project, I have a crude implementation of the search algorithm that\ncould benefit from the above APIs. Would be great to see your research when\nyou publish it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/2#issuecomment-92254791\n.\n. Hello,\n\nJust released a new version, that should be much more faster...\nLet me know what you think about it...\nRegards,\nOn Wed, Apr 22, 2015 at 10:06 PM, hrj notifications@github.com wrote:\n\nHi! Thanks for considering my suggestions. But I am not sure whether the\nnet result of your changes is going to improve performance. There are now\nHashMaps and Sets of strings instead of arrays of integers. I had imagined\nthe changes would have been simpler, but maybe I was wrong.\nMy project involves management of patient records. They need to be\nsearched by name and the search needs to be fuzzy since there are many\nspelling mistakes or alternative spellings in the records. I am using\nsimilarity measures to implement the fuzzy search.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/2#issuecomment-95321723\n.\n. Hello,\n\nThank you for your interest!\nThe license is MIT:\nhttps://github.com/tdebatty/java-string-similarity/blob/master/pom.xml\nNow I just added a LICENSE.md file...\nRegards,\nThibault\nOn Mon, Oct 12, 2015 at 6:19 PM, Patrick Farrell notifications@github.com\nwrote:\n\nCan you attach a license to this project? I'm interested in using and\npossibly contributing, but without a license, I can't be sure of your\nintentions.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/3.\n. Hi,\n\nThank you for the info!! I will update the readme!\nRegards, and best wishes,\nThibault\nLe mar. 29 d\u00e9c. 2015 \u00e0 16:02, Chris B notifications@github.com a \u00e9crit :\n\nHi I noticed something whilst browsing this git\nThe readme states that the triangle inequality does not hold for the\nDemerau-Levenshtein algorithm This is only true if you use a restricted\nedit distance implementation of the algorithm If you allow for the\n'unrestricted' case (of adjacent transpositions) the inequality will hold\nThis is, however, at the expense of added computational complexity See\nhere\nhttps://enwikipediaorg/wiki/Damerau%E2%80%93Levenshtein_distance#Algorithm\nImplementing the adjacent transposition calc will allow you to use\nDemerau-Levenshtein in a metric tree, for example\nCheers\nChris\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/4.\n. Just corrected the README...\n. Hi,\n\nCurrently, none of them can be considered thread safe. I might add some thread safe wrapper classes (as soon as I get some time). In the meantime I will leave this issue open...\nBest regards,\nThibault\n. Hi,\nI finished checking the different classes and they are all thread safe now. I also marked them with Immutable annotation.\nBest regards,\n. Hi,\nThe current release is 013...\nMaybe another artifact?\nBest regards!\n. Hi,\nThank you @annttiigs for your feedback!\nThe library is indeed independent of the language. It can be used with any language as long as the characters are supported by Java, which uses UTF-16 internally: \nhttp://docs.oracle.com/javase/7/docs/technotes/guides/intl/overview.html#textrep\n. Duplicate of #7 \n. Hi,\nThanks @manalalonaizan for the feedback, and thanks (once again) @mpkorstanje for the debugging!\nI juste made the correction.\nI will make a new release later today.\nBut I will leave the issue open, as I should check the rest of the code for similar bugs!\n. Hi,\nThank you @avinashdudi for your interest, and thank you @jaredsburrows  and @mpkorstanje for your quick answers!\n@avinashdudi : as stated, could you provide more info?\n. Hi,\njava 1.5 is actually the default version for maven projects: \nhttps://maven.apache.org/plugins/maven-compiler-plugin/\nIn anyway I removed the override annotation from NGram.distance() as it was not required...\nBest regards!\n. thank you @mpkorstanje !\n. Thanks for the contribution!\n. Hi,\nCould you describe the issue in English?\n. Hi,\nLooks nice!\nCould you make a pull request?\nAnd maybe write a small unit test based on the wikipedia example?\nThanks a lot!\n. Pull request merged, and new version released:\nhttps://github.com/tdebatty/java-string-similarity/releases/tag/v0.18\nShould be available on Maven within a few hours...\n. Sure! Thanks!\nLe sam. 27 janv. 2018 \u00e0 00:48, Anupam Seth notifications@github.com a\n\u00e9crit :\n\nHi,\nIs it ok if I pick this up?\nThanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/17#issuecomment-360936489,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA1SDP1DpM8AQmLxIQH-8CpCqEq-l8DPks5tOmRKgaJpZM4Jh3bi\n.\n. Thanks a lot!\n. Just published release 0.17\n. Hi,\nThanks for letting me know!\nI mentioned your port in the Users section of the README...\nBest regards,\n. Thank you!\n. Thank you for the hint.\nIs now fixed\n. Fixed\n. Indeed, I don't understand is here?\nNormalized levenshtein is one kind of generalized string distance measure. There are others, which are not computed the same way...\n. Hi,\nCould be interesting, indeed!\nJust, do you have some kind of theoretical document explaining the working of SIFT4, like a conference or journal paper? I think the page you mention lacks some theoretical explanation.\nFor example, what is the upper bound on the computed distance?\nIf I understand the algorithm correctly, the upper bound on computation cost is actually O(n . offset) if both strings are completely different? And the lower bound is O(n), when both strings are equal. And n is the length of the longest string?\n. Then maybe I could integrate it in a separate package \"stringsimilarity.experimental\" for algorithms that just work and are experimentally tested, although without theoretical background.. Hi,\nI added your java code and a basic test in a new branch sift4:\nhttps://github.com/tdebatty/java-string-similarity/tree/sift4\nhttps://github.com/tdebatty/java-string-similarity/commit/43354cac4b672d868bc05a087fcbe98c9e2ce567#diff-cc6f7c8f82621204f1c4d0661d24cbc0\n\nAccording to https://siderite.blogspot.com/2014/11/super-fast-and-accurate-string-distance.html the result should be 11.\nBut the test currently fails (returns 10):\nhttps://travis-ci.org/tdebatty/java-string-similarity/branches\nAny idea?. Pay attention that in Java, LinkedList.push() will add the element at the front of the list. It's the same behavior as stack.push().\nIf I'm correct (but I'm no JS specialist) the JavaScript code uses Array.push(), which adds the element at the end of the array. This might make a difference.... Corrected and released.... Thank you for your contribution!. Hi,\nThank you!\nThis happens because the strings \"S\" are two short (less then 2\ncharacters). I will correct this and publish a new release...\n. Fixed in release 0.21. Hi,\nAs a quick fix, I would recommend you add the test to your own code...\nFrom the theory point of view, I think for most algorithms the result of comparing two empty strings is actually undefined. Hence both implementations are correct. Comparing two empty strings can either return 0 or 1, it depends on the application.\nFor this library, I would like to be consistent, choose one option and implement it in all algorithms. And of course it would be best to know what the most common use case is...\n. Hi,\nThank you all for the contributions!\nBased on these comments I think indeed that throwing an NPE is the best way\nto go...\nLe ven. 20 janv. 2017 \u00e0 00:14, Paul Irwin notifications@github.com a\n\u00e9crit :\n\nOn my trip home I convinced myself that throwing an NPE with a meaningful\nmessage and listed in the JavaDoc would be best.\nMy specific use case coalesces null to empty, as I'm calculating the\nsimilarity of an optional \"Address Line 2\" field against a provided value,\nbut that's my specific case - there's no good reason to impose that on\nothers. Also null != \"\" so that shouldn't evaluate to a normalized\nsimilarity of 1.\n@tdebatty https://github.com/tdebatty If you're in agreement let me\nknow and I'll update the PR.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/pull/29#issuecomment-273928876,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA1SDIT-avyyuTn0aajYq8cIwzCny2c5ks5rT-5GgaJpZM4Lnp9s\n.\n. Just created a new release. Should be available on maven within a few hours...\n\nThanks!. Strange...\nI had to completely delete and reconfigure the coveralls repository. Apparently it's working now...\n. Hi,\nI created a small example to reproduce your case:\nhttps://github.com/tdebatty/java-string-similarity/blob/master/src/main/java/info/debatty/java/stringsimilarity/examples/nischay21.java\nThe result of running this example is:\n```\nS1 vs S2\nJaroWinkler : 0.6083333492279053\nLevenshtein : 75.0\nNGram : 0.9375\nDamerau : 75.0\nJaccard : 1.0\nSorensenDice : 1.0\nCosine : 1.0\nS1 vs S3\nJaroWinkler : 0.5642857253551483\nLevenshtein : 133.0\nNGram : 0.9535714387893677\nDamerau : 133.0\nJaccard : 1.0\nSorensenDice : 1.0\nCosine : 1.0\nWith .toLower()\nS1 vs S2\nJaroWinkler : 0.3916666507720947\nLevenshtein : 64.0\nNGram : 0.8062499761581421\nDamerau : 64.0\nJaccard : 0.8194444444444444\nSorensenDice : 0.6941176470588235\nCosine : 0.4427217874246471\nS1 vs S3\nJaroWinkler : 0.42023807764053345\nLevenshtein : 128.0\nNGram : 0.925000011920929\nDamerau : 128.0\nJaccard : 1.0\nSorensenDice : 1.0\nCosine : 1.0\n```\nMy first idea is that all those algorithms are case sensitive. From your description, I guess this is not the case for your application, so you should use .toLowerCase before calling the method distance(s1, s2), as shown in the example.\nWhen using .toLowerCase, the distance method with s1 and s3 will produce a higher score then comparing s1 and s2 with the same algorithm.. Hi,\nIndeed, at release 0.19 shingle based algorithms have been refactored, and these classes were dropped.\nHowever, it is still possible to precompute string profiles, if this is what you need:\nhttps://github.com/tdebatty/java-string-similarity/blob/master/src/main/java/info/debatty/java/stringsimilarity/examples/PrecomputedCosine.java. @Aleyasen you're right, chame on me! :-/\nI just added the required method and published a new release:\nhttps://github.com/tdebatty/java-string-similarity/releases/tag/v0.23\nIt should be available on Maven central within a few hours...\n. Thank you!. Hi! Thanks a lot!. Thank you!. Thank you!\nThis is now fixed. Hi! Thank you for the hint! I made the modification myself as you pull request was causing a checkstyle error... The new code is now released as 1.0.1\nBest regards!. Hi,\nThe main reason is that I started this library for my PhD. I use this code\nto test Apache Spark algorithms with different similarity measures.\nTherefore it was easier to have similarity objects (instead of static\nmethods), and Apache Spark required the Serializable interface...\nLe mer. 6 d\u00e9c. 2017 \u00e0 17:10, tantin notifications@github.com a \u00e9crit :\n\n1.\nWould you explain why you decided not to make StringDistance.distance()\n   non-static? Why is it necessary to create an instance of StringDistance\n   (or of a derived class) to compute the distance? The method does not use\n   this anyway...\n   2.\nAlso, why StringDistance derives from java.io.Serializable?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/40, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AA1SDHQ13PjfEa8dT69i2pbVjro54JOtks5s9rxzgaJpZM4Q4KWn\n.\n. Hi,\nThank you for the suggestion. I just started a column, although for now I don't have a lot to fill..\nBest regards,. Hi! Thank you for your feedback! And sorry for the long delay!\nThe README is now updated!\nBest regards!. Thank you for your review!. Nice job! Thanks!. I just created release 1.1.0 with your contribution. Should be available within 24h on Maven.... Thank you!. Thank you!. Just released version 1.2.0\nShould be available on Maven Central within a few hours.... They are not used anymore, and hence were removed. See commits \n\n\nhttps://github.com/tdebatty/java-string-similarity/commit/5bec82bf5dced807d212e314bfc52decee232116\nhttps://github.com/tdebatty/java-string-similarity/commit/1afdc76eef523b144c73be3c3fc7df88f93fe9b7\n. \n",
    "hrj": "Hi!\nThere seems to have been a lot of activity in the project in the last few days! Cool!\nDid you change the definition of QGram? It looks like new Jaccard(2) is the new way to get the functionality of the erstwhile new QGram(2). Am I right?\nI am not really familiar with the different algorithms. I had just picked up one that seemed to give the best results for my use-case in the shortest time.\n. \u200bOh! I might have described this wrong.\nI didn't mean to suggest an implementation of the search algorithm in this\nproject. Rather, some additional APIs in the similarity algorithms to help\nspeed up the search algorithms.\nIn my project, I have a crude implementation of the search algorithm that\ncould benefit from the above APIs. Would be great to see your research when\nyou publish it.\n. Hi! Thanks for considering my suggestions. But I am not sure whether the net result of your changes is going to improve performance. There are now HashMaps and Sets of strings instead of arrays of integers. I had imagined the changes would have been simpler, but maybe I was wrong.\nMy project involves management of patient records. They need to be searched by name and the search needs to be fuzzy since there are many spelling mistakes or alternative spellings in the records. I am using similarity measures to implement the fuzzy search.\n. Whoa; you are moving very fast; hard for me to keep up :)\nI am deep in another context for a couple of days. Will give you some feedback after I am back.\nbest,\nhrj\n. ",
    "DwayneSmurdon": "I might also add that at the same time we update these to use Java 8, so that we can safely use parallelStream().  \nI can potentially see two options here:  The methods themselves can use parallelStream() or we can just make it safe for the caller to use parallelStream() on a list of words they are processing.  There are probably other considerations and thoughts, but this is just off the top of my head right now.\n. ",
    "mpkorstanje": "If you need thread-safety you may want to look at Simmetrics. If you are going to compare N x N strings based on their tokens, do consider tokenizing them first and comparing the N x N token sets instead.\n. Keep in mind that for some applications you have to do something with the diacritics as depending on how the string is normalized they can either be one single or two separate characters.\nFor example \u00d1 is U+00D1 while \u00f1 is U+00F1. But they also be written using the combining tilde \u2b1a\u0303, U+0303 followed by N or n. So n_ might be 50% similar to \u00f1 or even worse \u00f1 might be 50% similar to \u00f1.\nAdditionally as \u00f1 is considered its own letter in Spanish confusing them can lead to all sorts of interesting situations. For example pe\u00f1a means rocky hill and pena means sorrow. But they're both also common last names, the later being the Anglicised version. \nFrench has similar issues with the accents.\n\nNow I hope tdebatty doesn't mind if I plug my own repo here.\nSome metrics in Simmetrics work on generic collections. Using Characters.codePoints() you could tokenize the string into unicode code points or groups of codepoints and compare them using the metric. \nThis should help with languages that are higher up in the unicode space. Beyond that I'm afraid I'm not doing much to make unicode easy either.\n. See your old question at: https://github.com/tdebatty/java-string-similarity/issues/7\n. Am able to reproduce this. Using Simmetrics with an n-gram size of 3 I'm getting a value of about .8 for the similarity. Feels about right, small n-gram, large files, should be very similar.\nLooks like the mistake might be in the KShingling but I'm not seeing it right now.\nedit: Noticed KShinling takes out whitespace and replaces it with a single space. Doing the same with Simmetrics. Doesn't change the end result much. Attached comparison.\ntest.zip\n. Found it. Both norm and dotProduct multiply integers which overflow into negative values. These should be cast to doubles or floats before being multiplied.\n```\n    protected static double norm(int[] profile) {\n        double agg = 0;\n    for (int v : profile) {\n        agg += v * v;\n    }\n\n    return Math.sqrt(agg);\n}\n\nprotected static double dotProduct(int[] profile1, int[] profile2) {\n    int length = Math.max(profile1.length, profile2.length);\n    profile1 = java.util.Arrays.copyOf(profile1, length);\n    profile2 = java.util.Arrays.copyOf(profile2, length);\n\n    double agg = 0;\n    for (int i = 0; i < length; i++) {\n        agg += profile1[i] * profile2[i];\n    }\n    return agg;\n}\n\n```\n. Looks like a duplicate of #11. You may want to check your IDE's settings. This is a Java 5 project.\n. I'm afraid you are mistaken. If check the pom you you'll see this is a java 5 project. You may want to check your IDE's setting.\n<plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <version>2.3.2</version>\n                <configuration>\n                    <source>1.5</source>\n                    <target>1.5</target>\n                </configuration>\n           </plugin>\n. Seeing how the KShingling is actually a hash based multiset of a tokenized strings I think you should use that data structure instead. The metric itself becomes ridiculously simple when it operates on those data sets.\nCreating the hash multisets can then be done in parallel. \n. This doesn't seem right. \nLevensthein can be normalized by dividing it with the string length because it returns a count of characters that are different. The count and string length have the same unit.\nHowever this need not be true for all distance measures.\n. From a developer perspective I would recommend that any normalized similarity measure should be consistent with equals such that a.equals(b) => compare(a,b) == 1.0. For distance metrics a.equals(b) => distance(a,b) == 0.0.\nThis keeps everything consistent. e.g.\ndistance(\"a\", \"b\") == 1.0\ndistance(\"a\", \"a\") == 0.0\ndistance(\"\", \"\") == 0.0. I regret providing this comment this late. However I don't think that treating null and empty string is a good thing. The difference between the empty string \"\" and any other string \"hello world\" can be measured. However the difference between the empty string and no string at all is of a different category.\n\nNull pointers aren't an annoyance, rather they let you know that your input is not what you expect it to be.. Agreed. The handling should be consistent for all metrics. \nI would suggest using NPE. I agree it is inconsistent with the semantics of NPE but it is consistent with Objects.requireNonNull from Java 7 and Guava's Precondition.checkNotNull.\nSo I would consider the following behavior to be correct:\ndistance(null,\"\") // throws nullpointer exception\ndistance(\"\",null); // throws nullpointer exception\ndistance(null,null); // throws nullpointer exception\ndistance(\"\",\"\") == 0.0\n\nI've enforced the same behavior in Simmetrics. Most of it through the early out checks for empty strings. This avoids the overhead of actually dedicating a specific check to the nullity of the arguments and works nicely with java's confusion of NPE and IllegalArgumentException. \nI can't contributed to consensus. @tdebatty is the owner, I'm merely giving my advice as to the best practices. . I'm thinking that not creating the union and instead only calculating the intersection would be faster. Especially when the intersection is calculated by iterating over the elements of the smaller and looking them up in the larger set.\nfinal int intersection = intersection(profile1, profile2);\nreturn intersection / (double) (profile1.size() + profile2.size() - intersection);. This appears to be a good reference:\nhttps://ilyankou.files.wordpress.com/2015/06/ib-extended-essay.pdf\n. ",
    "annttiigs": "i have applied this for a auto file convert tool which was working between\nEnglish and Turkish languages.\n2016-05-13 11:54 GMT+03:00 hanasian notifications@github.com:\n\nHello!\nCan the java-string-similarity be applied to many languages such as\nGermany,French,Chinese and so on.Can it be is relative to language type?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/7\n\n\nOlgun KAYA\n. ",
    "jaredsburrows": "@avinashdudi What did you try? Its on TravisCI and the build is passing.\nHere is how to do it via the command line:\n1. git clone https://github.com/tdebatty/java-string-similarity\n2. cd java-string-similarity\n3. mvn install -DskipTests=true -Dmaven.javadoc.skip=true -Dgpg.skip=true (Look herehttps://github.com/tdebatty/java-string-similarity/blob/master/.travis.yml)\n4. mvn test\n. @tdebatty You can just close this unless there is a stacktrace of evidence of a build failure.\n. ",
    "arbitdudi": "@tdebatty I didn't know it was Java 5 proj. I will try to build it with jdk5 and let you know. Is there a speciific reason for writing it in 5 or just it was 5 when you developerd?\n@jaredsburrows  Thanks, I didnt check on the trail. Sorry for late comments.\n. ",
    "amriteya": "I just saw that. Thanks\n. ",
    "coveralls": "\nCoverage remained the same at 58.641% when pulling 97f3024b01904b55094157bdf7fe52edb85472d8 on vpop:update/integral-division into 0b69a69f3c64216003880b773dfc9b43fcfb8cb4 on tdebatty:master.\n. \nCoverage decreased (-0.5%) to 58.978% when pulling 82c9566b5133743e4d3892665b5f9115c7fb3ce7 on emmettu:divide-by-zero into 6671ba2f128dc3334457684b62f15bffd6351c91 on tdebatty:master.\n. \nCoverage increased (+1.0%) to 59.972% when pulling 8e80da4a4b940394ab1d56bcf5fad34fae3dedec on MpoMp:master into b1eaf3ffb67f47e8371527af5e5ad94205cf9c71 on tdebatty:master.\n. \nCoverage remained the same at 59.81% when pulling 6d4c08e16a81ee09f4605d61223843accd6c1756 on laxatives:master into 9e46d41ed1d992034b897b2abecdf5cb246123fe on tdebatty:master.\n. \nCoverage decreased (-0.1%) to 66.193% when pulling 4a5c69046d348525106781a660fd0de79160f328 on linterpreteur:master into d9439d65c2241138fa722a80b684b176980aef81 on tdebatty:master.\n. \n\nCoverage increased (+0.3%) to 66.562% when pulling 990161d81f7af69d483cd0d7b3400e05591d92d7 on JPMoresmau:perf/containskey into d9439d65c2241138fa722a80b684b176980aef81 on tdebatty:master.\n. \n\nCoverage increased (+3.7%) to 73.324% when pulling d8ef94f06b18efa8bd9037b1a93ec3ad7ee23d17 on paulirwin:issue/28 into 471682eaa78915ad5912fd7c85b045e4e15f3dbe on tdebatty:master.\n. \n\nCoverage increased (+6.6%) to 76.235% when pulling b517f003239c98a848895d761f65727ce0c14213 on paulirwin:issue/28 into 471682eaa78915ad5912fd7c85b045e4e15f3dbe on tdebatty:master.\n. \n\nCoverage increased (+8.5%) to 78.17% when pulling 6135d392515b3b48db2d024316b2e3b4a30f8d35 on paulirwin:issue/28 into 471682eaa78915ad5912fd7c85b045e4e15f3dbe on tdebatty:master.\n. \n\nCoverage increased (+8.9%) to 78.507% when pulling 75142c0ce40a72dadb447bd92c3ebd80b57127c8 on paulirwin:issue/28 into 471682eaa78915ad5912fd7c85b045e4e15f3dbe on tdebatty:master.\n. \n\nCoverage increased (+8.7%) to 78.361% when pulling 3406d2cfd853ca385090d144eed117f636ebd304 on paulirwin:issue/28 into 471682eaa78915ad5912fd7c85b045e4e15f3dbe on tdebatty:master.\n. \n\nCoverage remained the same at 78.389% when pulling 7e232e70584bf96254ea9f4fa602b7a332b09ddd on dwiajik:master into cb812e84faca938fdc20dcc076cb13adea7fbd56 on tdebatty:master.\n. \n\nCoverage remained the same at 94.316% when pulling 7232169ceb3431b32aabd234f4469b0e77456c7b on wsdonny:patch-1 into 5c4652ff7abf77f9fbf038c3da64b7a9a7aba38f on tdebatty:master.\n. \n\nCoverage remained the same at 94.802% when pulling 5b96163e49582e574c60beb287f812120d949a4c on NationalBI:fix-javadoc-entities into a5d842111753f77bb679c82c37628338f868aec8 on tdebatty:master.\n. \n\nCoverage increased (+0.1%) to 94.949% when pulling cfcde791e2bbbe50fcdec2e3c3a983722113d6fc on NationalBI:weighted-levenshtein-ins-del into a5d842111753f77bb679c82c37628338f868aec8 on tdebatty:master.\n. \n\nCoverage remained the same at 94.949% when pulling ba484f97fbc34fb549c135a0058198e3db404dd5 on fabriziofortino:patch-1 into 77ceea746f685ede2fbac526d4f7a51466479eb7 on tdebatty:master.\n. \n\nCoverage increased (+0.1%) to 95.05% when pulling 624fe288f34eb14ac7f9db1a7695ad74525fb94b on NationalBI:levenshtein-limits into 495656d1d03b2eb3247f873a8d21745da64aa23e on tdebatty:master.\n. ",
    "MpoMp": "How about using the Lucene implementation ?\n. Looks like I misinterpreted the issue in the first place.\nAs @tdebatty mentions in the README:\n\nThe algorithm uses affixing with special character '\\n' to increase the weight of first characters. The normalization is achieved by dividing the total similarity score the original length of the longest word.\nIn the paper, Kondrak also defines a similarity measure, which is not implemented (yet).\n\nWhich probably refers to the algorithms described on page 8 here.\n. Here's a quick one, no tests yet, the Wikipedia example comparison works fine. \nOSA source\nLet me know what you think. :)\n. Sure I'll do it asap because I am away from my desk!\nOn Sep 7, 2016 5:12 PM, \"Thibault Debatty\" notifications@github.com wrote:\n\nHi,\nLooks nice!\nCould you make a pull request?\nAnd maybe write a small unit test based on the wikipedia example?\nThanks a lot!\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/tdebatty/java-string-similarity/issues/16#issuecomment-245293031,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABHdAtvIuFeK-mEk4WKLiEtZnWo6EXXmks5qnsZBgaJpZM4Jh3XS\n.\n. \n",
    "paulirwin": "@MpoMp Sounds like a good idea. Based on my interpretation of the Apache license, I assume we would just need to make sure to include the Apache license header and indicate that we changed the code (to fit this library's constraints)? Despite being an ASF member and my familiarity with Lucene and its respective projects, I'm not an expert in licenses and copying the actual code.\n(To introduce myself, I'm a member of the team that ported this library to .NET, and a member of the Lucene.NET PMC.) \ncc @jamesmblair\n. Disregard my deleted comment. What I meant was, isn't this the same as src/main/java/info/debatty/java/stringsimilarity/NGram.java?\n. Agreed with @mpkorstanje. Two empty strings are equal and should have a distance of 0. I'd be happy to submit a PR for this if no one else is working on it.. I just discovered a bug that \"\" and null together are not treated correctly. Will update soon with additional tests for that case.. Fixed the case of passing (null, \"\"). Also refactored my changes to the unit tests to reduce the amount of test code, and also added tests for WeightedLevenshtein.. @mpkorstanje The existing code wasn't handling null values consistently or even caring about them at all - it was getting as far as it could into the algorithm before letting an NPE happen. Either the methods should enforce it via an IllegalArgumentException up front at the beginning of the method (or NPE, there is some disagreement about this) and either mention that in the JavaDoc or be checked (ugh), or coalesce it to empty and do a comparison on them. I'm fine with modifying this PR to throw one of those exceptions and list it in the JavaDoc instead of coalescing it to empty if that's the consensus here.. On my trip home I convinced myself that throwing an NPE with a meaningful message and listed in the JavaDoc would be best.\nMy specific use case coalesces null to empty, as I'm calculating the similarity of an optional \"Address Line 2\" field against a provided value, but that's my specific case - there's no good reason to impose that on others. Also null != \"\" so that shouldn't evaluate to a normalized similarity of 1.\n@tdebatty If you're in agreement let me know and I'll update the PR.. The code to throw NPEs is now complete, I haven't yet updated the JavaDocs. I will do that soon.. ",
    "a-seth": "Hi,\nIs it ok if I pick this up?\nThanks.\n. Cool, will create a PR. ",
    "emmettu": "Great thanks :+1: \n. ",
    "wooseopkim": "Looks like I had some misconception. I'm closing this PR. Thanks for your replies, guys.\n. ",
    "kag0": "I don't think @siderite has any more details than are on his post, it is largely a code reading exercise to understand its workings. \nIf I understand correctly, upper bound on distance should be something like the length of the longer string being compared. Your estimation of the costs seem correct to me as well.. Sounds good to me. Only comment would be maybe either name the package something other than \"experimental\" or document somewhere that the code is production ready, it's just the algorithms that don't have a theoretical background. . We can see here the differences are that in the java version there is no max distance (which isn't the problem, that can only cause the js version to return a smaller distance), and I've used a LinkedList in place of the js array. For the LinkedList it's safe to say that push, size/length, and get(i)/[i] all work the same as in js. The only other difference is offset_arr.splice(i,1); vs offset_arr.remove(i); In java this \n\nRemoves the element at the specified position in this list. Shifts any subsequent elements to the left (subtracts one from their indices).\n\nSo: unless that splice works differently than remove then we've got a funkier issue on our hands.\nAnd for the record, running the java version locally does return 10 for me as well.. I'm (obviously) no js specialist either, but you're right. Good catch.\nChanging push to add causes it to return 11 as desired.\nupdated https://gist.github.com/kag0/5fe7ba9f3f400c00c74698924e5fe4d0\nfor ref:\nadding element to the end of the list:\nlcss : 19\ntrans : 4\nresult: 11\nadding element to front of the list\nlcss : 19\ntrans : 3\nresult: 10. ",
    "Siderite": "Yeah, sorry, guys! Not much on theory, me. I just wrote the thing and made it work for most cases. Then made it more generic.. Haven't had the time to look at it in depth, but it might be the rounding. In .NET I had to add an extra MidpointRounding parameter to round away from zero and not the default which some economics crap that depends on whether the closest integer is odd or even. Maybe Java is similarly impaired,. On second look there are no roundings involved. The longest string is 26 characters long, the lcss is 19, no matter the order in which they are taken and the transpositions are 4. So 26-(19-4)=11. The Java code seems to be an almost exact copy of the common algorithm without the maxDistance calculation. I don't see why your Java code would fail. Are you sure you are testing the code that appears at https://github.com/tdebatty/java-string-similarity/blob/sift4/src/main/java/info/debatty/java/stringsimilarity/experimental/Sift4.java with the test at https://github.com/tdebatty/java-string-similarity/blob/sift4/src/test/java/info/debatty/java/stringsimilarity/experimental/Sift4Test.java ? I don't see how it returns 10.. I mean, I copied the code in Java, copy pasted it in an HTML file, turned it into Javascript, executed it, and it returned 11. :). It's a good catch, but inserting at the beginning of the array is arr.splice(0,0,item) in javascript and it makes no difference, the result is still 11. Can you debug and see what is going on? What are the various values at the end? I mean lcss and trans?. Strange. I can't get it to return 10 in Javascript no matter if it pushes the value or inserts it. Anyway, good that it works now.. Changed push to add in the Java implementation in the blog post.. ",
    "dodgy99": "@paulirwin that would be great and much appreciated. ",
    "nischay21": "@tdebatty Thank you, your solution was very helpful and worked perfectly after performing .toLowerCase.. ",
    "Aleyasen": "@tdebatty Thanks for your quick reply. Could you please let me know what if I want to use Q-Gram with profile, what method I should use? QGram only has a distance method that the parameters are String not  Profile (or Map).\n. Wow, thank you very much for the quick release, I appreciate it :)\n. ",
    "antkillerfarm": "I just give an idea, not the implement. No matter how to do, union or  intersection should only be calculated once.. ",
    "wagjo": "Thanks!. ",
    "pellcorp": "Yep Ratcliff scores better in many cases than jaro winkler. In a poc I did, I used maven coordinates: com.rockymadden.stringmetric:stringmetric-core:0.26.1\nThis corresponds to github project: \nhttps://github.com/rockymadden/stringmetric\nI tested the Ratcliff/Obershelp impl in the stringmetric-core project against known good test data\n. ",
    "lvjiujin": "\nThere is a library which has an accurate implementation but its based on scala.\n\nwhere is the link?. ",
    "ewanmellor": "It's working great, thanks for the fast release @tdebatty . ",
    "saschaszott": "The Jaro Similarity of ed and red is 0, since the number of matching characters (parameter m) is 0.\nFurthermore, the length of the common prefix of s1 and s2 (parameter l) is 0.\nThis results in a Jaro-Winkler Similarity of 0 as\nsim_jw = sim_j + l * 0.1 * (1 - sim_j) = 0 + 0 * 0.1 * 1 = 0\nJaro-Winkler gives more favorable ratings to strings that match from the beginning. . "
}